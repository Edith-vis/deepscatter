id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
4e24edcd2344fd0fab9b18fbe6197f13c635e2c2	on-line learning and the metrical task system problem	metric space;decision theoretic;computational learning theory;on line algorithm;algorithm design;on line learning	The problem of combining expert advice, studied extensively in the Computational Learning Theory literature, and the Metrical Task System (MTS) problem, studied extensively in the area of On-line Algorithms, contain a number of interesting similarities. In this paper we explore the relationship between these problems and show how algorithms designed for each can be used to achieve good bounds and new approaches for solving the other. Specific contributions of this paper include:	metrical task system	Avrim Blum;Carl Burch	1997		10.1145/267460.267475	algorithm design;mathematical optimization;metric space;computer science;artificial intelligence;machine learning;mathematics;stability;computational learning theory;algorithm	Theory	22.537136931176327	-17.420948102833474	43543
000ebc47980dd20fbdb803f9522e47db9d6b05fd	a neuroevolution strategy using multi-agent incorporated hierarchical ensemble model		In this study, a neuroevolution strategy using Multi-Agent Incorporated Hierarchical Ensemble Model (MAIHEM) inspired by human incorporated company structure is proposed. It utilizes the hierarchical structure to ensemble modules of entities into firms to preserve complex structure at lower level, and at higher level incorporates firms into departments to facilitate multiple objectives. The corporate level structure from the top guides and reviews their overall performance. The ensemble structure not only compete within their own ranks, but also cooperate and swap/merger underlying units for fast adaptation without compromising their existing structures. The preliminary result with multi-constrained music melody generation shows this strategy can not only solve complex multi-objective tasks steadily but also preserve diversity in the population.	entity;level structure;multi-agent system;neuroevolution;paging	Kuan-Wu Su;Min-Chieh Yu;Jenq-Shiou Leu	2018		10.1145/3205651.3205693	computer science;artificial intelligence;ensemble forecasting;artificial neural network;machine learning;genetic algorithm;organizational structure;level structure;neuroevolution;population;multi-agent system	AI	21.87012708314777	-11.294194174998287	43658
c4e43d7935787bd0888faf62c97bff69dd3e9863	a study of multivariate process capability indices in manufacturing processes	furnaces;hardening and tempering processes process capability uvpci mvpci forging centrifugal casting;hardening multivariate process capability indices manufacturing processes manufacturing process single quality variable univariate process capability indices uvpci mvpci centrifugal casting tempering processes percentage conforming products;tempering casting hardening manufacturing systems process capability analysis;casting indexes grippers wheels gears furnaces manufacturing processes;indexes;manufacturing processes;casting;gears;grippers;wheels	Process capability indices are assumed as an important tool for measurement of performance of a manufacturing process [1]. Single quality variable is considered in case of univariate process capability indices (UVPCI) for example Cp, Cpk and Cpm where as multiple quality variables are considered in multivariate process capability indices (MVPCI) [1, 2]. UVPCIs are extensively studied by a large number of researchers and practioners. However, till today no efficient MVPCI is developed for the assessment capability of a process with proper application in manufacturing processes. This paper therefore highlighted on the application of the different multivariate process capability indices developed so far in three different case studies, forging, centrifugal casting, and hardening and tempering processes [1, 2]. The results are compared with percentage conforming products as well as amongst the indices themselves. The results show that hardening and tempering is the most and forging is the least capable process.	centrifugal governor	S. C. Mondal	2015	2015 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)	10.1109/IEEM.2015.7385874	database index;casting;gear;computer science;engineering;operations management;engineering drawing;manufacturing engineering	Robotics	14.06641085244852	-12.432837731343751	43853
020f6457af71c6926281b06f5c5bb8222fa45ce6	off-policy temporal difference learning with function approximation	reinforcement learning;linear functionals;function approximation;policy evaluation;value function;temporal difference learning;algorithm design	"""We introduce the first algorithm for off-policy temporal-difference learning that is stable with linear function approximation. Off-policy learning is of interest because it forms the basis for popular reinforcement learning methods such as Q-learning, which has been known to diverge with linear function approximation, and because it is critical to the practical utility of multi-scale, multi-goal, learning frameworks such as options, HAMs, and MAXQ. Our new algorithm combines TD(λ) over state–action pairs with importance sampling ideas from our previous work. We prove that, given training under any """"-soft policy, the algorithm converges w.p.1 to a close approximation (as in Tsitsiklis and Van Roy, 1997; Tadic, 2001) to the action-value function for an arbitrary target policy. Variations of the algorithm designed to reduce variance introduce additional bias but are also guaranteed convergent. We also illustrate our method empirically on a small policy evaluation problem. Our current results are limited to episodic tasks with episodes of bounded length. 1Although Q-learning remains the most popular of all reinforcement learning algorithms, it has been known since about 1996 that it is unsound with linear function approximation (see Gordon, 1995; Bertsekas and Tsitsiklis, 1996). The most telling counterexample, due to Baird (1995) is a seven-state Markov decision process with linearly independent feature vectors, for which an exact solution exists, yet This is a re-typeset version of an article published in the Proceedings of the 18th International Conference on Machine Learning (2001). It differs from the original in line and page breaks, is crisper for electronic viewing, and has this funny footnote, but otherwise it is identical to the published article. for which the approximate values found by Q-learning diverge to infinity. This problem prompted the development of residual gradient methods (Baird, 1995), which are stable but much slower than Q-learning, and fitted value iteration (Gordon, 1995, 1999), which is also stable but limited to restricted, weaker-than-linear function approximators. Of course, Q-learning has been used with linear function approximation since its invention (Watkins, 1989), often with good results, but the soundness of this approach is no longer an open question. There exist non-pathological Markov decision processes for which it diverges; it is absolutely unsound in this sense. A sensible response is to turn to some of the other reinforcement learning methods, such as Sarsa, that are also efficient and for which soundness remains a possibility. An important distinction here is between methods that must follow the policy they are learning about, called on-policy methods, and those that can learn from behavior generated by a different policy, called off-policy methods. Q-learning is an off-policy method in that it learns the optimal policy even when actions are selected according to a more exploratory or even random policy. Q-learning requires only that all actions be tried in all states, whereas on-policy methods like Sarsa require that they be selected with specific probabilities. Although the off-policy capability of Q-learning is appealing, it is also the source of at least part of its instability problems. For example, in one version of Baird’s counterexample, the TD(λ) algorithm, which underlies both Qlearning and Sarsa, is applied with linear function approximation to learn the action-value function Qπ for a given policy π. Operating in an on-policy mode, updating state– action pairs according to the same distribution they would be experienced under π, this method is stable and convergent near the best possible solution (Tsitsiklis and Van Roy, 1997; Tadic, 2001). However, if state-action pairs are updated according to a different distribution, say that generated by following the greedy policy, then the estimated values again diverge to infinity. This and related counterexamples suggest that at least some of the reason for the instability of Q-learning is that it is an off-policy method; they also make it clear that this part of the problem can be studied in a purely policy-evaluation context. Despite these problems, there remains substantial reason for interest in off-policy learning methods. Several researchers have argued for an ambitious extension of reinforcement learning ideas into modular, multi-scale, and hierarchical architectures (Sutton, Precup & Singh, 1999; Parr, 1998; Parr & Russell, 1998; Dietterich, 2000). These architectures rely on off-policy learning to learn about multiple subgoals and multiple ways of behaving from the singular stream of experience. For these approaches to be feasible, some efficient way of combining off-policy learning and function approximation must be found. Because the problems with current off-policy methods become apparent in a policy evaluation setting, it is there that we focus in this paper. In previous work we considered multi-step off-policy policy evaluation in the tabular case. In this paper we introduce the first off-policy policy evaluation method consistent with linear function approximation. Our mathematical development focuses on the episodic case, and in fact on a single episode. Given a starting state and action, we show that the expected offpolicy update under our algorithm is the same as the expected on-policy update under conventional TD(λ). This, together with some variance conditions, allows us to prove convergence and bounds on the error in the asymptotic approximation identical to those obtained by Tsitsiklis and Van Roy (1997; Bertsekas and Tsitsiklis, 1996). 1. Notation and Main Result We consider the standard episodic reinforcement learning framework (see, e.g., Sutton & Barto, 1998) in which a learning agent interacts with a Markov decision process (MDP). Our notation focuses on a single episode of T time steps, s0, a0, r1, s1, a1, r2, . . . , rT , sT , with states st ∈ S, actions at ∈ A, and rewards rt ∈ """". We take the initial state and action, s0 and a0, to be given arbitrarily. Given a state and action, st and at, the next reward, rt+1, is a random variable with mean rat st and the next state, st+1, is chosen with probabilities pat stst+1 . The final state is a special terminal state that may not occur on any preceding time step. Given a state, st, 0 < t < T , the action at is selected according to probability π(st, at) or b(st, at) depending on whether policy π or policy b is in force. We always use π to denote the target policy, the policy that we are learning about. In the on-policy case, π is also used to generate the actions of the episode. In the off-policy case, the actions are instead generated by b, which we call the behavior policy. In either case, we seek an approximation to the action-value function Qπ : S ×A $→ """" for the target policy π: Q(s, a) = Eπ { rt+1 + · · · + γrT | st = s, at = a } , where 0 ≤ γ ≤ 1 is a discount-rate parameter. We consider approximations that are linear in a set of feature vectors {φsa}, s ∈ S, a ∈ A: Q(s, a) ≈ θ φsa = n ∑"""	andrew barto;approximation algorithm;bellman equation;feature vector;gradient;greedy algorithm;importance sampling;instability;international conference on machine learning;iteration;linear function;markov chain;markov decision process;mathematical model;q-learning;reinforcement learning;sampling (signal processing);state-action-reward-state-action;table (information);temporal difference learning;witsenhausen's counterexample	Doina Precup;Richard S. Sutton;Sanjoy Dasgupta	2001			temporal difference learning;algorithm design;mathematical optimization;function approximation;computer science;machine learning;pattern recognition;mathematics;bellman equation;reinforcement learning;generalization error	ML	22.573646140580173	-19.220114275322278	43900
286ad2d35e0bbf0015b5c41df29c3db2741a9dad	abductive reasoning in bayesian belief networks using a genetic algorithm	abduction;belief;search space;random sampling;algoritmo genetico;raisonnement;genetics;bayesian belief networks;croyance;abduccion;computer experiment;bayesian belief network;razonamiento;algorithme genetique;abductive reasoning;genetic algorithm;genetic algorithms;reasoning;creencia;bayes belief networks	A set of computational experiments is described in which genetic algorithms are used for abductive reasoning in Bayesian belief networks. It is shown that good solutions and explanations are consistently found with high probabilities. The efficiency of genetic sampling w.r.t. random sampling is shown to increase with increasing complexity of the search space and with increasing complexity of the search goal.	abductive reasoning;bayesian network;genetic algorithm	Edzard S. Gelsema	1995	Pattern Recognition Letters	10.1016/0167-8655(95)00046-J	genetic algorithm;abductive reasoning;computer science;artificial intelligence;machine learning;bayesian network;mathematics;algorithm;abductive logic programming	AI	20.960916321564042	-12.434632542714345	43979
b814bedb56bb96b020b0e357872ff6ac0c6d72f6	prediction and simulation in categorical fields: a transition probability combination approach	conditional independence;gaussian field;geographic information science;uncertainty modeling;spatial data;probabilistic method;transition probability;gaussian random field;tau model;posterior probability;spatial data mining;spatial pattern;analytical method;land use and land cover;categorical data	The investigation of spatial patterns implied in categorical spatial data, such as land use and land cover (LULC) classes and socio-economic statistics data, is involved in many aspects of geographical information science, such as spatial uncertainty modeling and spatial data mining. The discrete nature of categorical fields limits the application of traditional analytical methods, such as kriging-type algorithms, widely used in Gaussian random fields. This paper presents a new probabilistic method for modeling the posterior probabilities of class occurrence at any location in space given known class labels at data locations within a neighborhood around that prediction location. In the proposed method, the conditional or posterior (multi-point) probabilities are approximated by weighted combinations of pre-posterior (two-point) transition probabilities (rather than indicator covariances or vari-ograms) while accounting for spatial interdependencies that most of current approaches often ignore. Using sequential indicator simulation based on the properties of a truncated multi-variate Gaussian field as reference, the advantages and disadvantages of this new proposed approach are analyzed and highlighted.	approximation algorithm;data mining;decision theory;geographic information system;information science;interdependence;kriging;markov chain;simulation	Guofeng Cao;Phaedon C. Kyriakidis;Michael F. Goodchild	2009		10.1145/1653771.1653853	gaussian random field;econometrics;markov chain;common spatial pattern;conditional independence;categorical variable;probabilistic method;data mining;mathematics;spatial analysis;geographic information system;posterior probability;statistics	ML	24.556007223359163	-22.26318449304786	44197
14b4d6ba81fc5c3fcf1b0850832fe843ca16da48	utile distinction hidden markov models	bayesian estimation;partially observed markov decision process;hidden markov model;reinforcement learning;baum welch;action selection;bias;action observation;partial observation;markov processes;wiskunde en informatica wiin;variance	This paper addresses the problem of constructing good action selection policies for agents acting in partially observable environments, a class of problems generally known as Partially Observable Markov Decision Processes. We present a novel approach that uses a modification of the well-known Baum-Welch algorithm for learning a Hidden Markov Model (HMM) to predict both percepts and utility in a non-deterministic world. This enables an agent to make decisions based on its previous history of actions, observations, and rewards. Our algorithm, called Utile Distinction Hidden Markov Models (UDHMM), handles the creation of memory well in that it tends to create perceptual and utility distinctions only when needed, while it can still discriminate states based on histories of arbitrary length. The experimental results in highly stochastic problem domains show very good performance.	action selection;baum–welch algorithm;hidden markov model;markov chain;partially observable markov decision process;problem domain;welch's method;whole earth 'lectronic link	Daan Wierstra;Marco Wiering	2004		10.1145/1015330.1015346	forward algorithm;markov decision process;markov chain;maximum-entropy markov model;markov kernel;action selection;bayes estimator;partially observable markov decision process;markov property;viterbi algorithm;computer science;baum–welch algorithm;artificial intelligence;machine learning;causal markov condition;hidden semi-markov model;bias;pattern recognition;mathematics;markov renewal process;markov algorithm;variance;markov process;markov model;reinforcement learning;hidden markov model;statistics;variable-order markov model	ML	22.19151219919699	-18.7898416173387	44318
a41e4efa1b4ecc1af683b293cd38f7afff432649	addressing uncertainty in hierarchical user-centered planning		Companion-Systems need to reason about dynamic properties of their users, e.g., their emotional state, and the current state of the environment. The values of these properties are often not directly accessible, hence information on them must be pieced together from indirect, noisy or partial observations. To ensure probability-based treatment of partial observability on the planning level, planning problems can be modeled as Partially Observable Markov Decision Processes (POMDPs). While POMDPs can model relevant planning problems, it is algorithmically difficult to solve them. A starting point for mitigating this is that many domains exhibit hierarchical structures where plans consist of a number of higher-level activities, each of which can be implemented in different ways that are known a priori. We show how to make use of such structures in POMDPs using the Partially Observable HTN (POHTN) planning approach by developing a Partially Observable HTN (POHTN) action hierarchy for an example domain derived from an existing deterministic demonstration domain. We then apply Monte-Carlo Tree Search to POHTNs for generating plans and evaluate both the developed domain and the POHTN approach empirically.	algorithm;blue (queue management algorithm);experiment;hierarchical task network;home theater in a box;markov chain;monte carlo tree search;partially observable markov decision process	Felix Richter;Susanne Biundo-Stephan	2017		10.1007/978-3-319-43665-4_6	machine learning;observability;state of the environment;observable;markov decision process;computer science;artificial intelligence	AI	20.432839572173176	-15.523160487110657	44350
d72024a503eb49ca887c67005d816914ee34ec59	online reinforcement learning for real-time exploration in continuous state and action markov decision processes		This paper presents a new method to learn online policies in continuous state, continuous action, model-free Markov decision processes, with two properties that are crucial for practical applications. First, the policies are implementable with a very low computational cost: once the policy is computed, the action corresponding to a given state is obtained in logarithmic time with respect to the number of samples used. Second, our method is versatile: it does not rely on any a priori knowledge of the structure of optimal policies. We build upon the Fitted Q-iteration algorithm which represents the Q-value as the average of several regression trees. Our algorithm, the Fitted Policy Forest algorithm (FPF), computes a regression forest representing the Q-value and transforms it into a single tree representing the policy, while keeping control on the size of the policy using resampling and leaf merging. We introduce an adaptation of Multi-Resolution Exploration (MRE) which is particularly suited to FPF. We assess the performance of FPF on three classical benchmarks for reinforcement learning: the ”Inverted Pendulum”, the ”Double Integrator” and ”Car on the Hill” and show that FPF equals or outperforms other algorithms, although these algorithms rely on the use of particular representations of the policies, especially chosen in order to fit each of the three problems. Finally, we exhibit that the combination of FPF and MRE allows to find nearly optimal solutions in problems where -greedy approaches would fail.	algorithm;algorithmic efficiency;benchmark (computing);computation;control theory;decision tree;humanoid robot;inverted pendulum;iteration;iterative method;markov chain;markov decision process;real-time transcription;reinforcement learning;time complexity	Ludovic Hofer;Hugo Gimbert	2016	CoRR		simulation;computer science;artificial intelligence;machine learning;mathematics;statistics	ML	22.148322108143418	-18.743148311998116	44364
71dc40912b8f7f18496cb9ed3e72f2c50281db66	modeling of asphalt concrete via simulated annealing	asphalt core;simulated annealing;objective function;optimization;asphalt concrete;marshall stability;physical properties;model simulation	0965-9978/$ see front matter 2009 Elsevier Ltd. A doi:10.1016/j.advengsoft.2009.10.011 * Corresponding author. Tel.: +90 380 542 11 33; f E-mail addresses: ercanozgan@gmail.com (E. Ö edu.tr (H. Saruhan). In this study, 65 asphalt core specimens taken from D100/11 state highway section in Turkey were examined for their physical properties in the laboratory. Analysis of data was conducted to determine the effects of the varying environment temperature and varying length of exposure to these temperatures on the stability of the asphalt core samples using destructive, Marshall, method. The asphalt core samples were determined using SPSS statistical program for modeling. Simulated annealing was implemented to determine a set of unknown parameters which best matched the asphalt concrete model predictions with experimental data. This modeling procedure can be used as a guideline for experiments to improve the stability of the asphalt concrete. The stability of the asphalt concrete is taken as the main objective function with respect to voids of volume, saturated unit volume weight, air dry unit volume weight, environment temperature, and exposure time. 2009 Elsevier Ltd. All rights reserved.	experiment;loss function;mathematical optimization;optimization problem;robust optimization;spss;simulated annealing	Ercan Özgan;Hamit Saruhan	2010	Advances in Engineering Software	10.1016/j.advengsoft.2009.10.011	structural engineering;mathematical optimization;simulated annealing;computer science;mathematics;geotechnical engineering;forensic engineering;physical property	SE	12.535071267564222	-19.896447786467736	44504
87040c64ec2ea6b33add88ce29aca82c744e0551	learning to hire teams	teams;hiring;crowdsourcing	Crowdsourcing and human computation has been employed in increasingly sophisticated projects that require the solution of a heterogeneous set of tasks. We explore the challenge of building or hiring an effective team, for performing tasks required for such projects on an ongoing basis, from an available pool of applicants or workers who have bid for the tasks. The recruiter needs to learn workers’ skills and expertise by performing online tests and interviews, and would like to minimize the amount of budget or time spent in this process before committing to hiring the team. How can one optimally spend budget to learn the expertise of workers as part of recruiting a team? How can one exploit the similarities among tasks as well as underlying social ties or commonalities among the workers for faster learning? We tackle these decision-theoretic challenges by casting them as an instance of online learning for best action selection. We present algorithms with PAC bounds on the required budget to hire a near-optimal team with high confidence. Furthermore, we consider an embedding of the tasks and workers in an underlying graph that may arise from task similarities or social ties, and that can provide additional side-observations for faster learning. We then quantify the improvement in the bounds that we can achieve depending on the characteristic properties of this graph structure. We evaluate our methodology on simulated problem instances as well as on real-world crowdsourcing data collected from the oDesk platform. Our methodology and results present an interesting direction of research to tackle the challenges faced by a recruiter for contract-based crowdsourcing.	action selection;algorithm;crowdsourcing;directed graph;experiment;graph (discrete mathematics);human-based computation;online shopping;theory	Adish Singla;Eric Horvitz;Pushmeet Kohli;Andreas Krause	2015			simulation;computer science;knowledge management;management science;crowdsourcing	Web+IR	18.817764192338807	-14.6137057770561	44942
6b38b4983cb661638f2f8a85c5735df093493e51	neural networks for estimating the tool path length in concurrent engineering applications	computer aided design;random design;computer numerically controlled;product design;manufacturing system;concurrent engineering;neural network	This paper deals with the development of a neural computing system that can predict the cutting tool path length for milling an arbitrary pocket defined within the domain of a product design, in a computer numerically controlled (CNC) setting. Existing computer aided design and manufacturing systems (CAD/CAM) consume significant amounts of time in terms of data entry pertaining to the geometries and subsequent modifications to them. In the concurrent engineering environment, where even the designer needs information from the CAD/CAM systems, such time-consuming processes can be expensive. To alleviate this problem, a neural network system can be used to estimate machining time by predicting cost-dependent variables such as tool path length for the pocket milling operation. Pockets are characterized and classified into various groups. A randomized design is described so that the training samples that have been chosen represent the domain evenly. An appropriate network was built and trained with the sample pocket geometries. The analysis of the performance of the system in terms of tool path length prediction for new pocket geometries is presented.	artificial neural network	B. Gopalakrishnan;Vinay K. Reddy;Deepak Prakash Gupta	2004	J. Intelligent Manufacturing	10.1023/B:JIMS.0000010071.23816.60	simulation;computer science;engineering;artificial intelligence;machine learning;product design;engineering drawing;artificial neural network;concurrent engineering	Robotics	14.158700944284652	-20.161111764324122	44971
9f9a522e450ecbce4543a1f9c9f5314832f19eaa	multithreaded and distributed simulation of large biological neuronal networks	information processing;neuronal network;distributed simulation	To understand the principles of information processing in the brain, we depend on models with more than 105 neurons and 109 connections [1]. These networks can be described as graphs of threshold elements that exchange point events.	simulation;thread (computing)	Jochen M. Eppler;Hans Ekkehard Plesser;Abigail Morrison;Markus Diesmann;Marc-Oliver Gewaltig	2007		10.1007/978-3-540-75416-9_55	parallel computing;computer science;theoretical computer science;distributed computing	HPC	15.424966412314689	-10.648541632538485	45031
300137cd89e666c162e818524018aa739f0648e2	prediction of water inrush from coal floor based on small sample data mining technology and realization using matlab	support vector machine	For there are few samples of water inrush from coal floor, how to dig wider information under the circumstance of limited sample data is to improve the prediction accuracy of water inrush form coal floor. Therefore, prediction model of water inrush is established based on correlation analysis and support vector machine (SVM). Not only does the model simplify the influenced indexes to construct the index system of water inrush from coal floor, but also dig the value of sample data to solve the problem of small sample and nonlinear prediction. Through the empirical analysis, the model using MATLAB can accurately predict whether water inrush from coal floor occurs.	data mining;matlab;nonlinear system;support vector machine;water cooling;water model	Lei Yang;Chengcheng Liu;Jing Han;Wu Sheng	2012	JSW		support vector machine;computer science;machine learning;data mining	ML	10.728329898310378	-19.56666435071997	45055
df3743b189f4e62fdc33135cdc90445f31973d1c	optimal cost drivers in activity based costing based on an artificial neural network	artificial neural network optimal cost drivers activity based costing;production facilities artificial neural networks cost accounting decision making accuracy;optimal cost drivers;activity based costing;production engineering computing automobile industry backpropagation cost accounting feedforward neural nets least mean squares methods;mse optimal cost drivers activity based costing artificial neural network abc system ocd thai automotive parts industry traditional cost accounting tca distortion production cost ann multilayered feed forward neural nets backpropagation neural nets mean square error;artificial neural network	This study focuses on the development of Activity Based Costing (ABC) system by using optimal cost drivers (OCD) for the Thai automotive parts industry. Recently, traditional cost accounting (TCA) has been used to calculate production costs. However, the difficulty of TCA appears in the indirect or overhead costs which can be considered as a distortion production cost. Although the factory used the ABC system, inappropriate methods were utilized in order to solve this problem. The selected cost driver may not be the only factor affecting production costs. However, it was found that using OCD in ABC calculation resulted in more accurate production costs. The estimated production cost using artificial neural networks (ANNs) as a tool for identifying optimal production costs, because this method is effective for resolving both linear and non-linear problems. ANNs are designed and tested to estimate production costs by using the input and output data in the activities and production costs, and utilize a multi-layered feed forward and a back-propagation. The testing results of the production cost and the estimated cost for product A were applied to ABC by OCD in December, 2013. The production cost, estimated cost and mean square error (MSE) are equal to 47.337, 47.282 Thai baht, and 0.000036017, respectively.	advanced telecommunications computing architecture;artificial neural network;backpropagation;distortion;input/output;mean squared error;nonlinear system;overhead (computing);software propagation	Noppadol Amdee;Kawin Sonthipermpoon;Thongchai Arunchai;Phanboonmee Warawut	2014	2014 IEEE International Conference on Industrial Engineering and Engineering Management	10.1109/IEEM.2014.7058732	simulation;economics;computer science;engineering;artificial intelligence;operations management;machine learning;data mining;artificial neural network;activity-based costing	Robotics	10.65426020771179	-18.00627133293055	45384
8acb8b4672f3ff4fcc4bc571f3532e90cda1cbf3	a new approach for machine learning-based fault detection and classification in power systems		The detection and classification of faulty conditions in power systems is a task of crucial importance for a reliable operation. Recently, the use of high-resolution synchronized phasor measurements has been proposed by several researchers for fault detection and classification. Unlike the proposed approaches available in the literature, the central idea in this work is to leverage the delay information of phasor measurement streams to enable a faster recognition of faulty operation. In this work, therefore, we focus on the effect of the communication network delays on the fault detection time, and propose a novel training technique for fault detection and classification which takes delayed measurements into consideration. The performance of the proposed approach is verified using simulated power system data, where artificial neural networks are used for fault detection and classification.	artificial neural network;fault detection and isolation;ibm power systems;image resolution;machine learning;phasor;power management unit;real-time clock;simulation;statistical classification;telecommunications network	Halil Alper Tokel;Rana Al Halaseh;Gholamreza Alirezaei;Rudolf Mathar	2018	2018 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT)	10.1109/ISGT.2018.8403343	streams;telecommunications network;artificial neural network;electric power system;fault detection and isolation;machine learning;phasor;computer science;artificial intelligence	EDA	14.382544322123467	-16.688557116171726	45845
143aa41319c1af755ed192b6b2a3848faa2d299e	learning classifier system equivalent with reinforcement learning with function approximation	reinforcement learning;learning classifier systems;linear approximation;learning classifier system;derived equivalence;simulation experiment;function approximation;theoretical analysis;genetics based machine learning;genetic based machine learning	We present an experimental comparison of the reinforcement process between Learning Classifier System (LCS) and Reinforcement Learning (RL) with function approximation (FA) method, regarding their generalization mechanisms. To validate our previous theoretical analysis that derived equivalence of reinforcement process between LCS and RL, we introduce a simple test environment named Gridworld, which can be applied to both LCS and RL with three different classes of generalization: (1) tabular representation; (2) state aggregation; and (3) linear approximation. From the simulation experiments comparing LCS with its GA-inactivated and corresponding RL method, all the cases regarding the class of generalization showed identical results with the criteria of performance and temporal difference (TD) error, thereby verifying the equivalence predicted from the theory.	ap computer science a;deployment environment;experiment;learning classifier system;linear approximation;reinforcement learning;simulation;software release life cycle;table (information);temporal difference learning;turing completeness;verification and validation	Atsushi Wada;Keiki Takadama;Katsunori Shimohara	2005		10.1145/1102256.1102277	temporal difference learning;unsupervised learning;function approximation;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;learning classifier system;stability;reinforcement learning;linear approximation;generalization error	ML	17.492663790296067	-23.55500888768389	45944
2e94fe6474a0fb704cdf248468732921dd77b7a2	optimally solving dec-pomdps as continuous-state mdps	partially observable markov decision processes;decentralized control;optimal planning	Optimally solving decentralized partially observable Markov decision processes (Dec-POMDPs) is a hard combinatorial problem. Current algorithms search through the space of full histories for each agent. Because of the doubly exponential growth in the number of policies in this space as the planning horizon increases, these methods quickly become intractable. However, in real world problems, computing policies over the full history space is often unnecessary. True histories experienced by the agents often lie near a structured, low-dimensional manifold embedded into the history space. We show that by transforming a Dec-POMDP into a continuous-state MDP, we are able to find and exploit these low-dimensional representations. Using this novel transformation, we can then apply powerful techniques for solving POMDPs and continuous-state MDPs. By combining a general search algorithm and dimension reduction based on feature selection, we introduce a novel approach to optimally solve problems with significantly longer planning horizons than previous methods.	bellman equation;computation;constrained optimization;dec alpha;dimensionality reduction;embedded system;feature selection;grammar-based code;graphical model;heuristic;iteration;locality of reference;markov chain;mathematical optimization;norsk data;partially observable markov decision process;partially observable system;piecewise linear continuation;scalability;search algorithm;time complexity	Jilles Steeve Dibangoye;Christopher Amato;Olivier Buffet;François Charpillet	2013		10.1613/jair.4623	mathematical optimization;simulation;partially observable markov decision process;decentralised system;computer science;artificial intelligence;machine learning;mathematics	AI	21.353148027443474	-16.21045240715126	46002
a5f811544bd3dfb8546b55724737e4e1e9b5e940	application of learning theory to an artificial neural network that detects incipient faults in single-phase induction motors	induction motor;learning theory;artificial neural network	The generalization ability of a neural network in a specific application is of interest to many neural network designers. In this paper, learning theory is applied to a neural network used for incipient fault detection in single-phase induction motors. This paper will show that learning theory can help determine the proper number of training examples needed to reach a specific performance level, so that excessive and unnecessary training examples can be avoided. Comparisons of the results of learning theory and Monte Carlo estimate are presented, showing that learning theory is a useful and reliable tool to obtain information about the training process of a given neural network.	artificial neural network	Mo-Yuen Chow;Griff L. Bilbro;Sui Oi Yee	1991	Int. J. Neural Syst.	10.1142/S012906579100008X	stochastic neural network;wake-sleep algorithm;computer science;artificial intelligence;recurrent neural network;machine learning;learning theory;induction motor;time delay neural network;stability;competitive learning;artificial neural network;algorithm	NLP	14.683811808338756	-21.86067616518674	46039
e47150b16570df0578f1e22aba9372918d3ef9f7	using a neural-fuzzy approach for improving the perpendicular magnetic recording head manufacturing process	modelizacion;quality assurance;tete magnetique;floppy disk;areal density;cabeza lectura;disco magnetico flojo;neural networks;etude experimentale;enregistrement magnetique;logique floue;process yield;logica difusa;tete enregistrement;disco duro;hard disk;neural fuzzy model;production process;hdds;administracion deposito;tete lecture;fuzzy logic;modelisation;aseguracion calidad;control proceso;rectification superfine;retroaccion;magnetic head;retroaction;read head;hard disk drives;magnetic recording head manufacturing;process control;processus fabrication;feedback regulation;gestion stock;neural fuzzy modelling;magnetic recording heads;recording head;cabeza registro;magnetic write width targeting;reseau neuronal;product quality;magnetic recording;modeling;assurance qualite;inventory control;rectificacion superfina;estudio experimental;red neuronal;commande processus;proceso fabricacion;disque magnetique souple;perpendicular recording heads;disque dur;grabacion magnetica;cabeza magnetica;neural network;lapping	Magnetic write width targeting is a critical process in achieving high process yield and good quality in manufacturing perpendicular magnetic recording heads for hard disk drives. The current approach is an experimentally based feedback process in which the quality is highly dependent on the testing accuracy and the sensitivity assumptions. This paper proposes a new approach based on neural-fuzzy based modelling for improving the quality of the magnetic write width targeting. The model consists of a neural network for 1 suggesting changes in the lapping parameters, together with a fuzzy reasoning mechanism 2 obtaining fine-tuned lapping parameter values based on the parameters derived from the neural network. Through improvement in the magnetic write width targeting process, the overall process yield, and product quality can be improved and the overall cost of the magnetic recording heads will be significantly reduced.	artificial neural network;experiment;fuzzy logic;hard disk drive;magnetic storage;mathematical optimization;next-generation network;perpendicular recording	A. K. K. Fok;Henry C. W. Lau;Ying Kei Tse	2010	IJIIDS	10.1504/IJIIDS.2010.035770	fuzzy logic;inventory control;systems modeling;telecommunications;computer science;area density;machine learning;scheduling;artificial neural network;lapping	AI	14.375794794128945	-19.261453444010545	46092
a10e7c04f17c9b268f8ac6820cea7e18898f1399	optimizing hidden markov models with a genetic algorithm	genetic algorithm;optimizing hidden markov models	In this paper is presented the application of genetic algorithms (GAs) to the learning of hidden Markov models (HMMs). The Baum-Welch algorithm (BW), which optimizes the coefficients of a HMM, is improved by the use of a GA. The GA is able to find rapidly a good initial model compared to random generation, and this initial model is optimized further with BW. A representation and adapted genetic operators have been introduced in order to evolve matrix of probabilities. Several tests on artificial data show the interest in using a GA with BW.	genetic algorithm;hidden markov model;markov chain;optimizing compiler	Mohamed Slimane;Gilles Venturini;Jean Pierre Asselin de Beauville;Thierry Brouard;A. Brandeau	1995		10.1007/3-540-61108-8_52	forward algorithm;maximum-entropy markov model;variable-order bayesian network;viterbi algorithm;baum–welch algorithm;markov blanket;forward–backward algorithm;markov model;hidden markov model;variable-order markov model	AI	14.663277416257255	-23.127787781301844	46287
de88c8ef1cdc582b3075a20d148c50765b6bf049	improving delete relaxation heuristics through explicitly represented conjunctions	journal article	Heuristic functions based on the delete relaxation compute upper and lower bounds on the optimal delete-relaxation heuristic h, and are of paramount importance in both optimal and satisficing planning. Here we introduce a principled and flexible technique for improving h, by augmenting delete-relaxed planning tasks with a limited amount of delete information. This is done by introducing special fluents that explicitly represent conjunctions of fluents in the original planning task, rendering h the perfect heuristic h∗ in the limit. Previous work has introduced a method in which the growth of the task is potentially exponential in the number of conjunctions introduced. We formulate an alternative technique relying on conditional effects, limiting the growth of the task to be linear in this number. We show that this method still renders h the perfect heuristic h∗ in the limit. We propose techniques to find an informative set of conjunctions to be introduced in different settings, and analyze and extend existing methods for lower-bounding and upperbounding h in the presence of conditional effects. We evaluate the resulting heuristic functions empirically on a set of IPC benchmarks, and show that they are sometimes much more informative than standard delete-relaxation heuristics.	fluent (artificial intelligence);heuristic (computer science);information;linear programming relaxation;rendering (computer graphics);time complexity	Emil Ragip Keyder;Jörg Hoffmann;Patrik Haslum	2014	J. Artif. Intell. Res.	10.1613/jair.4277	computer science;artificial intelligence;machine learning;mathematics;algorithm	AI	21.013173936376624	-14.17586715888156	46686
dc56588b2b439a910d756011c8fdbe3b48f06d89	a novel time-depended evolutionary fuzzy svm inference model for estimating construction project at completion	fast messy genetic algorithm;fuzzy logic;weighted support vector machine;estimate at completion;time series prediction	Construction projects frequently face cost overruns during the construction phase. Thus, a proactive approach is essential for monitoring project costs and detection of potential problems. In construction management, Estimate at Completion (EAC) is an indicator for assisting project managers in identifying potential problems and developing appropriate responses. This study utilizes weighted Support Vector Machine (wSVM), fuzzy logic, and fast messy Genetic Algorithm (fmGA) to handle distinct characteristics in EAC prediction. The wSVM is employed as a supervised learning technique that can address the features of time series data. The fuzzy logic is aimed to enhance the model capability of approximate reasoning and to deal with uncertainty in EAC prediction. Moreover, fmGA is utilized to optimize model’s tuning parameters. Simulation results show that the new developed model has achieved a significant improvement in EAC forecasting. & 2011 Elsevier Ltd. All rights reserved.	approximation algorithm;artificial intelligence;fuzzy logic;genetic algorithm;input/output;mathematical optimization;proactive parallel suite;simulation;supervised learning;support vector machine;time series	Min-Yuan Cheng;Nhat-Duc Hoang;Andreas F. von Roy;Yu-Wei Wu	2012	Eng. Appl. of AI	10.1016/j.engappai.2011.09.022	fuzzy logic;mathematical optimization;computer science;artificial intelligence;machine learning;time series;data mining;statistics	AI	10.574096556306399	-21.778527599327894	46831
c3cc842a328fc2fc1a655eedda328d66eea3a0e5	intelligent use of data to optimize compressive strength of cellulose-derived composites	compressive strength;genetic algorithm;hybrid soft computing;carbon polymer composites;neural network	Neural network is trained to predict the compressive strength of composites from experimental variables.Input variables are optimized to maximize compressive strength, by genetic algorithm.Experimental constraints are considered during optimization.The consistency of the analysis is verified by laboratory experiments. Two soft-computing techniques are implemented to model and optimize the compressive strength of carbon/polymer composites. Artificial neural network is used to establish a relationship between the uniaxial compressive strength of fabricated materials and the most significant processing parameters. To put together a database, three different types of wood are carbonized at various heat treatment temperatures, in specific pyrolysis time periods. Compression tests are then conducted at room temperature on the composites, at a constant strain rate. The collected data of compressive strength and the related fabrication parameters are used as sets of data for training a neural network. A nested cross validation scheme is used to ensure the efficiency of the network. Results are indicative of a very good network, which generalizes very well. Next, an attempt is made to optimize the compressive behavior of the composites by controlling carbonization temperature, time and also starting material type with the aid of a genetic algorithm coupled with the trained network. The optimization system yields promising results, significantly enhancing the compressive strength. The validity of the optimal experiment, as proposed by the soft-computing system, is verified by subsequent laboratory testing.		H. Vafaeenezhad;S. R. Asadolahpour;N. Nayebpashaee;S. H. Seyedein;M. R. Aboutalebi	2016	Appl. Soft Comput.	10.1016/j.asoc.2015.12.029	genetic algorithm;computer science;machine learning;compressive strength;artificial neural network	HCI	12.646337392191443	-19.77514457378866	47228
e701b8aa4e6d3c44c8adf4a94eb2443f2f4dcb23	solving hidden-semi-markov-mode markov decision problems		Hidden-Mode Markov Decision Processes (HM-MDPs) were proposed to represent sequential decision-making problems in non-stationary environments that evolve according to a Markov chain. We introduce in this paper Hidden-Semi-Markov-Mode Markov Decision Processes (HS3MDPs), a generalization of HM-MDPs to the more realistic case of non-stationary environments evolving according to a semi-Markov chain. Like HM-MDPs, HS3MDPs form a subclass of Partially Observable Markov Decision Processes. Therefore, large instances of HS3MDPs (and HM-MDPs) can be solved using an online algorithm, the Partially Observable Monte Carlo Planning (POMCP) algorithm, based on Monte Carlo Tree Search exploiting particle filters for belief state approximation. We propose a first adaptation of POMCP to solve HS3MDPs more efficiently by exploiting their structure. Our empirical results show that the first adapted POMCP reaches higher cumulative rewards than the original algorithm. However, in larger instances, POMCP may run out of particles. To solve this issue, we propose a second adaptation of POMCP, replacing particle filters by exact representations of beliefs. Our empirical results indicate that this new version reaches high cumulative rewards faster than the former adapted POMCP and still remains efficient even for large problems.	approximation;automated planning and scheduling;hidden markov model;markov chain;monte carlo method;monte carlo tree search;multi-armed bandit;online algorithm;partially observable markov decision process;particle filter;performance;reinforcement learning;semiconductor industry;simulation;stationary process	Emmanuel Hadoux;Aurélie Beynier;Paul Weng	2014		10.1007/978-3-319-11508-5_15	markov decision process;markov chain;mathematical optimization;markov kernel;partially observable markov decision process;artificial intelligence;machine learning;mathematics;markov process;markov model;statistics;variable-order markov model	AI	21.741825649101255	-17.88661016753645	47357
357ae0121c7f04da879342582ce2f8634af62963	traffic incident detection using particle swarm optimization	ann traffic incident detection particle swarm optimization automatic incident detection traffic highways backpropagation pso artificial neural networks;optimisation;automatic incident detection;convergence;evolutionary computation;neural networks;neural nets;particle swarm optimization artificial neural networks automated highways telecommunication traffic costs backpropagation convergence neural networks road transportation testing;automated highways;ann;testing;pso;backpropagation;artificial neural networks;telecommunication traffic;particle swarm optimizer;backpropagation algorithm;particle swarm optimization;traffic engineering computing;search problems;traffic incident detection;traffic highways;learning artificial intelligence;neural nets learning artificial intelligence optimisation traffic engineering computing evolutionary computation search problems;road transportation;local minima;artificial neural network;neural network	AbstrocfThin paper proposes a new approach to Automatic Incident Detection on trsllic highways using Particle Swarm Optimization (PSO). The rampant growth in tralfic incidenls, which is high cost incurring, has led to significant interest in Ihe development 01 ellective incident detection techniques in recent years. Various techniques have been proposed to elfectively address this problem, the most promising olwhich are Artificial Neural Networks (ANN) based methods. Back-propagation (BP) has proven to be one 01 the best melhods to train weights 01 ANN lor incident detection. However it has several limitations including slow convergence. heuristic determination 01 parameters and possibility of getting stuck in a local minima. This paper overcomes these problems by using particle swarm optimization to train a neural network in place 01 BP. Actual data lrom a highway was used lo r training and testing of this method. Simulation results show that PSO performed better than Back-propagation algorithm.	algorithm;artificial neural network;backpropagation;heuristic;mathematical optimization;maxima and minima;neural networks;particle swarm optimization;phase-shift oscillator;simulation;software propagation	Dipti Srinivasan;Wee Hoon Loo;Ruey Long Cheu	2003		10.1109/SIS.2003.1202260	multi-swarm optimization;simulation;engineering;artificial intelligence;machine learning	ML	11.761065082868145	-22.284416362701936	47394
75367926a8705428fa9c75d74736fa069aafda0a	the significance of temporal-difference learning in self-play training td-rummy versus evo-rummy	reinforcement learning;value function;temporal difference learning;game playing	Reinforcement learning has been used for training game playing agents. The value function for a complex game must be approximated with a continuous function because the number of states becomes too large to enumerate. Temporal-difference learning with self-play is one method successfully used to derive the value approximation function. Coevolution of the value function is also claimed to yield good results. This paper reports on a direct comparison between an agent trained to play gin rummy using temporal difference learning, and the same agent trained with co-evolution. Coevolution produced superior results.	approximation algorithm;bellman equation;enumerated type;reinforcement learning;temporal difference learning	Clifford Kotnik;Jugal K. Kalita	2003			temporal difference learning;error-driven learning;simulation;computer science;artificial intelligence;machine learning;bellman equation;reinforcement learning;q-learning	ML	19.378473114200045	-19.661637982368934	47849
2e52ed9601bae3f659f757438447f6ad8d9087e9	autonomous driving: a comparison of machine learning techniques by means of the prediction of lane change behavior	traffic simulation;feed forward neural network;support vector machines;behavioural sciences computing;training;roads vehicles support vector machines machine learning training neurons humans;machine learning;roads;driver assistant systems autonomous driving machine learning techniques lane change behavior prediction feature combinations traffic simulator nisys trs recurrent neural network feed forward neural network support vector machines;feedforward neural nets;humans;vehicles;recurrent neural nets;neurons;recurrent neural network;support vector machine;learning artificial intelligence;driver information systems;simulation environment;support vector machines behavioural sciences computing driver information systems feedforward neural nets learning artificial intelligence recurrent neural nets	In the presented work we compare machine learning techniques in the context of lane change behavior performed by humans in a semi-naturalistic simulated environment. We evaluate different learning approaches using differing feature combinations in order to identify appropriate feature, best feature combination, and the most appropriate machine learning technique for the described task. Based on the data acquired from human drivers in the traffic simulator NISYS TRS1, we trained a recurrent neural network, a feed forward neural network and a set of support vector machines. In the followed test drives the system was able to predict lane changes up to 1.5 sec in beforehand.	artificial neural network;autonomous car;machine learning;recurrent neural network;semiconductor industry;support vector machine;virtual reality	Ürün Dogan;Johann Edelbrunner;Ioannis Iossifidis	2011	2011 IEEE International Conference on Robotics and Biomimetics	10.1109/ROBIO.2011.6181557	support vector machine;feature learning;simulation;computer science;artificial intelligence;online machine learning;machine learning;active learning	Robotics	17.547127456433962	-20.475263691801967	47955
59302701b13ae31cdddc08bbd6b24ca6ca558673	a theory of goal-oriented mdps with dead ends		Stochastic Shortest Path (SSP) MDPs is a problem class widely studied in AI, especially in probabilistic planning. They describe a wide range of scenarios but make the restrictive assumption that the goal is reachable from any state, i.e., that dead-end states do not exist.Because of this, SSPs are unable to model various scenarios that may have catastrophic events (e.g., an airplane possibly crashing if it flies into a storm). Even though MDP algorithms have been used for solving problems with dead ends, a principled theory of SSP extensions that would allow dead ends, including theoretically sound algorithms for solving such MDPs, has been lacking. In this paper, we propose three new MDP classes that admit dead ends under increasingly weaker assumptions. We present Value Iteration-based as well as the more efficient heuristic search algorithms for optimally solving each class, and explore theoretical relationships between these classes. We also conduct a preliminary empirical study comparing the performance of our algorithms on different MDP classes, especially on scenarios with unavoidable dead ends.	artificial intelligence;heuristic;iteration;markov decision process;search algorithm;shortest path problem;state (computer science)	Andrey Kolobov;Mausam;Daniel S. Weld	2012			mathematical optimization;simulation;artificial intelligence;machine learning;mathematics;algorithm	AI	19.80342308660559	-13.411093657892714	47976
7eacd4b192f84de968e8802fe6ea149989f7f296	joint screening tests for lasso		This paper focusses on “safe” screening techniques for the LASSO problem. Motivated by the need for low-complexity algorithms, we propose a new approach, dubbed “joint screening test”, allowing to screen a set of atoms by carrying out one single test. The approach is particularized to two different sets of atoms, respectively expressed as sphere and dome regions. After presenting the mathematical derivations of the tests, we elaborate on their relative effectiveness and discuss the practical use of such procedures.	algorithm;lasso	Cédric Herzet;Angélique Dremeau	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8462530	artificial intelligence;machine learning;lasso (statistics);screening techniques;computer science	Robotics	17.022478722480226	-13.65398971333823	47991
0d53cbec7dd80dc47db4b18d353dbdf50d9a1e2a	a pgm framework for recursive modeling of players in simple sequential bayesian games	limids;bayesian network;computacion informatica;optimal policy;sequential bayesian games;recursive modeling method;ciencias basicas y experimentales;influence diagrams;grupo a;multiple agents;private information;influence diagram;bayesian game	We consider the situation where two agents try to solve each their own task in a common environment. In particular, we study simple sequential Bayesian games with unlimited time horizon where two players share a visible scene, but where the tasks (termed assignments) of the players are private information. We present an influence diagram framework for representing simple type of games, where each player holds private information. The framework is used to model the analysis depth and time horizon of the opponent and to determine an optimal policy under various assumptions on analysis depth of the opponent. Not surprisingly, the framework turns out to have severe complexity problems even in simple scenarios due to the size of the relevant past. We propose two approaches for approximation. One approach is to use Limited Memory Influence Diagrams (LIMIDs) in which we convert the influence diagram into a set of Bayesian networks and perform single policy update. The other approach is information enhancement, where it is assumed that the opponent in a few moves will know your assignment. Empirical results are presented using a simple board game.	recursion	Nicolaj Søndberg-Jeppesen;Finn Verner Jensen	2010	Int. J. Approx. Reasoning	10.1016/j.ijar.2010.01.015	bayesian game;simulation;influence diagram;computer science;artificial intelligence;machine learning;mathematics;statistics	AI	20.63721349954465	-17.161897281455246	48029
cf7abe59270170fbcbd067069317afa976d121d8	markov chains and ranking problems in web search		Markov chains refer to stochastic processes whose states change according to transition probabilities determined only by the states of the previous time step. They have been crucial for modeling large-scale systems with random behavior in various fields such as control, communications, biology, optimization, and economics. In this article, we focus on their recent application to the area of search engines, namely, the PageRank algorithm employed at Google, which provides a measure of importance for each page in the web. We present several researches carried out with control theoretic tools such as aggregation, distributed randomized algorithms, and PageRank optimization. Due to the large size of the web, computational issues are the underlying motivation of these studies.	complex systems;computation;markov chain;mathematical optimization;pagerank;paging;randomized algorithm;stochastic process;theory;web search engine	Hideaki Ishii;Roberto Tempo	2015		10.1007/978-1-4471-5102-9_135-1	simulation;computer science;theoretical computer science;data mining	ML	14.703255701199133	-10.581370864086157	48555
a87a27efc1b851f90c8e5ba7f54d755138666920	forecasting for the risk of transmission line galloping trip based on bp neural network		Due to the strong randomness and nonlinear characteristics of the transmission line galloping, the prediction of the intensity and the characteristics (amplitude, frequency, trip rate, etc.) of the galloping cannot reach a high precision. A BP neural network model is employed to map three main meteorological factors and galloping trip-out risk. Three main meteorological factors, temperature, humidity and wind speed were used as input parameters and the risk of galloping trip as the output parameter of the model. Typical galloping data from State Grid Corporation were used to verify the validity of the model. In order to counteract random factors, the operations were performed for 20 times with the same training and testing data. All of the network results had more than 90% accuracy and the average rate was 92.3%. The results show that it is feasible to use this model to predict the risk of transmission line galloping trip. The research results can provide support for the transmission line galloping prediction and early warning technology, so as to improve the level of intelligent operation and maintenance of power grid.	artificial neural network;transmission line	Lichun Zhang;Bin Liu;Bin Zhao;Xiangze Fei;Yongfeng Cheng	2016		10.1007/978-981-10-3966-9_18	telecommunications;artificial intelligence	ML	10.278950550977717	-18.465027865029192	48728
143887fc393e379504cb30fc0db10e510f935113	a computational decision theory for interactive assistants		We study several classes of interactive assistants from the points of view of decision theory and computational complexity. We first introduce a special class of POMDPs called hidden-goal MDPs (HGMDPs), which formalize the problem of interactively assisting an agent whose goal is hidden and whose actions are observable. In spite of its restricted nature, we show that optimal action selection in finite horizon HGMDPs is PSPACEcomplete even in domains with deterministic dynamics. We then introduce a more restricted model called helper action MDPs (HAMDPs), where the assistant’s action is accepted by the agent when it is helpful, and can be easily ignored by the agent otherwise. We show classes of HAMDPs that are complete for PSPACE and NP along with a polynomial time class. Furthermore, we show that for general HAMDPs a simple myopic policy achieves a regret, compared to an omniscient assistant, that is bounded by the entropy of the initial goal distribution. A variation of this policy is also shown to achieve worst-case regret that is logarithmic in the number of goals for any goal distribution.	action selection;best, worst and average case;computation;computational complexity theory;decision theory;interactivity;np (complexity);observable;pspace;polynomial;regret (decision theory);time complexity	Alan Fern;Prasad Tadepalli	2010			mathematical optimization;artificial intelligence;machine learning;mathematics	ML	20.640397403739847	-16.776627181838077	48961
3b474d74720192c54b9a7341b6191c1c2f00a9e9	pseudo neural networks for iris data classification		This research deals with a novel approach to classification. Iris data was used for the experiments. Classical artificial neural networks, where a relation between inputs and outputs is based on the mathematical transfer functions and optimized numerical weights, was an inspiration for this work. Artificial neural networks need to optimize weights, but the structure and transfer functions are usually set up before the training. The proposed method utilizes the symbolic regression for synthesis of a whole structure, i.e. the relation between inputs and output(s). This paper differs from the previous approach where only one output pseudo node was used even for more classes. In this case, there were synthesized more node output equations as in classical artificial neural networks. The benchmark was iris data as in previous research. For experimentation, Differential Evolution (DE) for the main procedure and also for meta-evolution version of analytic programming (AP) was used.	artificial intelligence;benchmark (computing);chaos theory;differential evolution;email;engineering cybernetics;engineering informatics;evolutionary computation;experiment;in-game advertising;mathematical optimization;neural networks;numerical analysis;roman seleznev;soft computing;symbolic regression;transfer function	Zuzana Komínková Oplatková;Roman Senkerik;Ales Kominek	2014		10.7148/2014-0387		ML	13.18734402914201	-23.25276938596211	49188
2728ef33147b97ec9c38f5863c569f5dd207c115	from pixels to torques: policy learning with deep dynamical models	signalbehandling;report;signal processing	Data-efficient learning in continuous state-action spaces using very high-dimensional observations remains a key challenge in developing fully autonomous systems. In this paper, we consider one instance of this challenge, the pixels to torques problem, where an agent must learn a closed-loop control policy from pixel information only. We introduce a data-efficient, model-based reinforcement learning algorithm that learns such a closed-loop policy directly from pixel information. The key ingredient is a deep dynamical model that uses deep autoencoders to learn a low-dimensional embedding of images jointly with a predictive model in this low-dimensional feature space. Joint learning ensures that not only static but also dynamic properties of the data are accounted for. This is crucial for long-term predictions, which lie at the core of the adaptive model predictive control strategy that we use for closed-loop control. Compared to state-of-the-art reinforcement learning methods for continuous states and actions, our approach learns quickly, scales to highdimensional state spaces and is an important step toward fully autonomous learning from pixels to torques.	algorithm;autonomous robot;autonomous system (internet);bellman equation;control theory;feature model;feature vector;on the fly;pixel;predictive modelling;rl (complexity);reinforcement learning	Niklas Wahlstrom;Thomas B. Schön;Marc Peter Deisenroth	2015	CoRR		simulation;computer science;signal processing;control theory	ML	20.047537327800278	-21.763523472217898	49274
0a4a586d03a086ba963d68382c32fecc0e641bc6	action refinement in reinforcement learning by probability smoothing	learning process;transition probability;reinforcement learning;prior information;reinforcement learn ing	In many reinforcement learning applications, the set of possible actions can be partitioned by the programmer into subsets of similar actions. This paper presents a technique for exploiting this form of prior information to speed up model-based reinforcement learning. We call it an action refinement method, because it treats each subset of similar actions as a single “abstract” action early in the learning process and then later “refines” the abstract action into individual actions as more experience is gathered. Our method estimates the transition probabilities P (s′|s, a) for an action a by combining the results of executions of action a with executions of other actions in the same subset of similar actions. This is a form of “smoothing” of the probability estimates that trades increased bias for reduced variance. The paper derives a formula for optimal smoothing which shows that the degree of smoothing should decrease as the amount of data increases. Experiments show that probability smoothing is better than two simpler action refinement methods on a synthetic maze problem. Action refinement is most useful in problems, such as robotics, where training experiences are expensive.	experience;experiment;markov chain;programmer;refinement (computing);reinforcement learning;robotics;smoothing;synthetic intelligence	Thomas G. Dietterich;Dídac Busquets;Ramón López de Mántaras;Carles Sierra	2002			temporal difference learning;unsupervised learning;markov chain;error-driven learning;computer science;artificial intelligence;machine learning;pattern recognition;reinforcement learning;statistics	AI	21.48146013006004	-21.046991849572603	49564
f7ae968b785b9ca2befe2bdb19ab92b0e5f233c4	regularized recurrent neural networks for data efficient dual-task learning		We introduce a regularization technique to improve system identification for dual-task learning with recurrent neural networks. In particular, the method is introduced using the Factored Tensor Recurrent Neural Networks first presented in (1). Our goal is to identify a dynamical system with few available observations by augmenting them with data from a sufficiently observed similar system. In our previous work, we discovered that the model accuracy degrades whenever little data of the system of interest is available. The presented regularization term in this work allows to significantly reduce the model error thereby improving the exploitation of knowledge of the well observed system. This scenario is crucial in many real world applications, where data efficiency plays an important role. We motivate the problem setting and our regularized dual-task learning approach by industrial use cases, e.g. gas or wind turbine modeling for optimization and monitoring. Then, we formalize the problem and describe our regularization term by which the learning objective of the Factored Tensor Recurrent Neural Network is extended. Finally, we demonstrate its effectiveness on the cart-pole and mountain car benchmarks.	recurrent neural network	Sigurd Spieckermann;Siegmund Düll;Steffen Udluft;Thomas A. Runkler	2014		10.1007/978-3-319-11179-7_3	simulation;computer science;artificial intelligence;machine learning	ML	21.292355094272388	-23.513364851577467	49662
c4852e01d286e6da9ad19f4f038bbf3d14dd3602	fault forecast of electronic equipment based on ε -svr	e svr;fault forecast;kernel function;data mining	In order to ensure security and reliability of the equipment, so as to decrease the maintenance cost, combining with the characteristics of fault data, this paper adopts e – support vector regression to establish a fault forecast model and evaluation system to prediction model effect which are proper to the electronic equipment. Selecting multi-electronic equipment and training on the e – SVR with different kernel functions. It is demonstrated that the prediction effect is better and it is still of vital realistic significance for realizing condition-based maintenance of modern electronic equipment.		Lina Liu;Jihong Shen;Hui Zhao	2012		10.1007/978-3-642-33469-6_64	kernel;computer science;machine learning;data mining	AI	12.677049319960101	-17.720395480318476	49785
236b7be4198d547cff8af2420f8fd1b7e462634f	discovering underlying plans based on distributed representations of actions	distributed representation;plan recognition;planning	Plan recognition aims to discover target plans (i.e., sequences of actions) behind observed actions, with history plan libraries or domain models in hand. Previous approaches either discover plans by maximally “matching” observed actions to plan libraries, assuming target plans are from plan libraries, or infer plans by executing domain models to best explain the observed actions, assuming complete domain models are available. In real world applications, however, target plans are often not from plan libraries and complete domain models are often not available, since building complete sets of plans and complete domain models are often difficult or expensive. In this paper we view plan libraries as corpora and learn vector representations of actions using the corpora; we then discover target plans based on the vector representations. Our approach is capable of discovering underlying plans that are not from plan libraries, without requiring domain models provided. We empirically demonstrate the effectiveness of our approach by comparing its performance to traditional plan recognition approaches in three planning domains.	algorithm;automated planning and scheduling;causal filter;dup;domain model;ibm notes;iteration;library (computing);precondition;recommender system;sampling (signal processing);sensor;skip list;social media;text corpus;web search engine;web search query	Xin Tian;Hankui Zhuo;Subbarao Kambhampati	2016			planning;simulation;artificial intelligence;data mining	AI	20.43049893801334	-14.51408762690655	49893
7124b2fd7303e1f735436cfa5dd018b92c62458b	smart solving: tools and techniques for satisfiability solvers	complexity theory;search space;look ahead;satisfiability;decision problem;bounded model checking;communication skill;look ahead solver architecture;on the fly;scheduling problem;tools and techniques;adaptive heuristics;sat solver	The satisfiability problem (Sat) lies at the core of the complexity theory. This is a decision problem: Not the solution itself, but whether or not a solution exists given a specified set of requirements is the central question. Over the years, the satisfiability problem has taken center stage as a means of effective representation to tackle problems with different characteristics: Many problems can first be translated into Sat and then solved by means of software dedicated to the Sat problem. Due to the increasing power of these Sat solvers, the number of applications climbs every year. Examples of this kind of translatable problems are scheduling problems, verification of software and hardware, bounded model checking and a wide variety of mathematical puzzles. #N##N#Sat solvers come in two flavors: Complete and incomplete. Complete solvers systematically go over the whole search space and are able to determine with certainty whether a solution exists. Incomplete Sat solvers look for a solution at a venture. They dont follow a system, yet they might hit a solution. Most complete Sat solvers are based on the ConflictDriven architecture.#N#At a dead end, they analyze what went wrong and where in the search space it happened. Then they resume the search from there. Conflict-driven solvers make relatively cheap decisions (in terms of computational costs), which enables them to search the space swiftly. Only a few complete Sat solvers are based on an architecture that chooses its battles, so to speak. The LookAhead architecture peers further into the search space before making the next move. Look-ahead solvers make expensive decisions in order to keep the search space as small as possible. Incomplete Sat solvers have a dominant and a rare type of architecture as well. The commonly used WalkSat makes cheap decisions, while UnitWalk a bit off the wall makes more costly moves.#N##N#This thesis deals with a number of contributions to the development of Sat solvers both complete and incomplete. With the adagium poundwise,#N#Pennyfoolish in mind, its focus is primarily set on both rare, more expensive approaches. On one hand, expensive procedures are implemented efficiently to reduce their relative costs, while they maintain their impact on the search space.#N#On the other hand, building up reasoning power further limits the search space.#N##N#The growing attention for Sat solvers generates a growing group of users. More and more of them will not be familiar with the specific ins and outs of their application, which makes it difficult to tune the Sat solvers. Here, adaptive heuristics may be of use. Given a specific problem, these heuristics set the parameters in such a way that the solver performs (almost) optimally. This thesis presents some elegant adaptive heuristics for a technique that looks even further ahead into the search area to learn even more: The DoubleLook procedure. Thanks to these adaptive heuristics that keep on fine-tuning the parameters on the fly this binocular-technique can be helpful to solve more problems. #N##N#The raison detre of incomplete Sat solvers is the assumption that on many problems, they find a solution faster than complete solvers. Yet they are only superior within a certain niche; they work well on big (random) problems. To extend the span of incomplete Sat solvers, this thesis presents a Sat solver with the more rarely used UnitWalk architecture. Several expensive calculations are run simultaneously on a single processor which keeps costs relatively#N#low. In addition, the solver features some communicative skills: Whenever a solution is found for part of the problem, all further calculations will run more efficiently. Despite these enhancements and its good results, this solver is not (yet) competitive on structured problems; an field dominated by complete Sat solvers.#N##N#However, our complete Sat solver march, based on the LookAhead architecture, has won many awards in the prestigious Sat competitions, among which the gold medal for random problems without solutions (2007); a traditional stronghold of LookAhead solvers. More intriguing is the gold medal for crafted problems with solutions (2007). This is a field which is dominated besides march by conflict-driven solvers. In conclusion, the new techniques presented in this thesis have enhanced the LookAhead architecture to such an extend, that this type of solvers can compete on more problems while sustaining dominance on random instances.	boolean satisfiability problem	Marijn Heule	2008			mathematical optimization;theoretical computer science;mathematics;algorithm	Logic	18.678496580813498	-11.46535030577643	49896
250b47a2250193c43a1cd6b91b22ff8aa2078ccd	on the online generation of effective macro-operators	qa75 electronic computers computer science;qa76 computer software	Macro-operator (“macro”, for short) generation is a well-known technique that is used to speed-up the planning process. Most published work on using macros in automated planning relies on an offline learning phase where training plans, that is, solutions of simple problems, are used to generate the macros. However, there might not always be a place to accommodate training. In this paper we propose OMA, an efficient method for generating useful macros without an offline learning phase, by utilising lessons learnt from existing macro learning techniques. Empirical evaluation with IPC benchmarks demonstrates performance improvement in a range of state-of-the-art planning engines, and provides insights into what macros can be generated without training.	agile software development;automated planning and scheduling;expectation propagation;marvin (robot);oma;offline learning;online and offline;predictive modelling	Lukás Chrpa;Mauro Vallati;T. L. McCluskey	2015			real-time computing;simulation;computer science;machine learning;programming language	AI	18.05847505570175	-11.828360093523596	50314
dcfc1da9f3b71a9136a3eed03149c745abbd1a38	expert system applied to high-speed railway track circuit coding and its simulation	simulation;track circuit coding;high speed railway;expert system	Track circuit coding can be realized by Train Control Center in Highspeed Railway to keep the train running safe. This paper looks into the track circuit coding method using expert system, in which the reasoning process of track circuit coding was realized using software simulation with the data of Beijing-Shanghai High Speed Railway. Combined with test cases, the joint debugging is realized and the track circuit coding expert system is assessed. Final simulation results support that this prospecting method is both feasible and effective, which can secure the safety of the track circuit coding information as well.	computer simulation;debugging;expert system;test case	Yan Li;Dewang Chen;Xuan S. Yang	2011		10.1007/978-3-642-23881-9_67	embedded system;real-time computing;simulation;computer science;artificial intelligence;expert system	HCI	16.225826002489494	-14.185125153932699	50497
f28f603886ccbcd4e054b67fc4d6c1274ad1cf33	learning the neuron functions within a neural network via genetic programming: applications to geophysics and hydrogeology	neurons neural networks genetic programming geophysics biological neural networks feedforward neural networks biological cells feeds gene expression arctic;neural network neurons;feedforward neural networks;genetic program;evolutionary computation;geophysics;neural networks;neural nets;activation function;feeds;hydrogeology;neural network classifier;genetic programming;data mining;arctic;gene expression;artificial neural networks;biological cells;geophysical measurements;geophysics computing;neuron functions;hydrology;genetic algorithms;gene expression programming;neurons;gene expression programming neuron functions neural network classifier genetic programming geophysics hydrogeology neural network neurons;programming;neural nets genetic algorithms geophysics geophysics computing hydrology;biological neural networks;neural network	A neural network classifier is sought. Classical neural network neurons are aggregations of a weight multiplied by an input value and then controlled via an activation function. This paper learns everything within the neuron using a variant of Genetic Programming called Gene Expression Programming. That is, this paper does not explicitly use weights or activation functions within a neuron, nor bias nodes within a layer. Promising preliminary results are reported for a study of the detection of underground caves (a 1 class problem) and for a study of the interaction of water and minerals near a glacier in the Arctic (a 5 class problem).	activation function;aggregate function;algorithm;artificial neural network;emoticon;evolutionary computation;experiment;gene expression programming;genetic programming;neuron;orchard;parameter (computer programming);the 3-d battles of worldrunner	Alan J. Barton;Julio J. Valdés;Robert Orchard	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178731	genetic programming;programming;gene expression;genetic algorithm;arctic;computer science;bioinformatics;artificial intelligence;machine learning;hydrogeology;activation function;artificial neural network	ML	13.282255847693701	-23.78741200957138	50750
273c0cbfdcda7e89f6eb63cdd5cfea76878898ad	expert prediction, symbolic learning, and neural networks. an experiment on greyhound racing	learning algorithm;game theory;decision tree;neural nets;search space;uncertainty handling;trees mathematics;backpropagation;human tracking;journal article paginated;prediction theory;machine learning;neural networks machine learning machine learning algorithms uncertainty backpropagation algorithms humans game theory problem solving decision making decision trees;decision theory;artificial intelligence;search space expert prediction symbolic learning neural networks greyhound racing problem solving decision making machine learning hidden knowledge prediction performances human track expert decision tree building algorithm id3 neural network learning algorithm backpropagation problem solving scenario game playing competing dogs historical information;learning artificial intelligence;game playing;problem solving;neural network;trees mathematics game theory uncertainty handling learning artificial intelligence neural nets backpropagation prediction theory decision theory	Uncertainty is inevitable in problem solving and decision making. One way to reduce it is by seeking the advice of an expert. When we use computers to reduce uncertainty, the computer itself can become an expert in a specific field through a variety of methods. One such method is machine learning, which involves using a computer algorithm to capture hidden knowledge from data. We compared the prediction performances of three human track experts with those of two machine learning techniques: a decision tree building algorithm (ID3), and a neural network learning algorithm (backpropagation). For our research, we investigated a problem solving scenario called game playing, which is unstructured, complex, and seldom studied. We considered several real life game playing scenarios and decided on greyhound racing, a complex domain that involves about 50 performance variables for eight competing dogs in a race. For every race, each dog's past history is complete and freely available to bettors. This is a large amount of historical information-some accurate and relevant, some noisy and irrelevant-that must be filtered, selected, and analyzed to assist in making a prediction. This large search space poses a challenge for both human experts and machine learning algorithms. The questions then become: can machine learning techniques reduce the uncertainty in a complex game playing scenario? Can these methods outperform human experts in prediction? Our research sought to answer these questions.<<ETX>>	algorithm;artificial neural network;backpropagation;computer;decision tree;machine learning;performance;problem solving;real life;relevance	Hsinchun Chen;Peter Buntin Rinde;Linlin She;Siunie Sutjahjo;Chris Sommer;Daryl Neely	1994	IEEE Expert	10.1109/64.363260	simulation;decision theory;computer science;artificial intelligence;backpropagation;online machine learning;machine learning;decision tree;artificial neural network	ML	20.27540879244796	-19.692126975715436	51071
3e4583caaf1d010d50c8498d7398192b82378d93	quantitative structure-property relationships for the estimation of boiling point and flash point using a radial basis function neural network	quantitative structure property relationship;radial basis function neural network	Radial basis function (RBF) neural network models for the simultaneous estimation of flash point (Tf) and boiling point (Tb) based on 25 molecular functional groups and their first-order molecular connectivity index (1χ) have been developed. The success of the whole modeling process depended on a network optimization strategy based on biharmonic spline interpolation for the selection of an optimum number of RBF neurons (n) in the hidden layer and their associated spread parameter (σ). The RBF networks were trained by the Orthogonal Least Squares (OLS) learning algorithm. After dividing the total database of 400 compounds into training (134), validation (133), and testing (133), the average absolute errors obtained for the validation and testing sets ranges from 10 °C to 12 °C and 11 °C to14 °C for Tf and Tb, respectively, and are in agreement with the experimental value of about 10 °C. Results of a standard Partial Least Square (PLS) regression model for single output predictions range from 23 °C to 24 °C...	artificial neural network;radial (radio);radial basis function	John Tetteh;Takahiro Suzuki;Ed Metcalfe;Sian Howells	1999	Journal of Chemical Information and Computer Sciences	10.1021/ci980026y	mathematical optimization;chemistry;machine learning;mathematics;statistics	ML	12.608267150800044	-20.69936360691673	51251
c86595afce05b06f1a93782be7d24d6acbc4a858	analyzing simulations in monte-carlo tree search for the game of go		In Monte Carlo Tree Search, simulations play a crucial role since they replace the evaluation function used in classical game tree search and guide the development of the game tree. Despite their importance, not too much is known about the details of how they work. This paper starts a more in-depth study of simulations, using the game of Go, and in particular the program Fuego, as an example. Playout policies are investigated in terms of the number of blunders they make, and in terms of how many points they lose over the course of a simulation. The result is a deeper understanding of the different components of the Fuego playout policy, as well as an analysis of the shortcomings of current methods for evaluating playouts.	computer simulation;evaluation function;monte carlo method;monte carlo tree search;playout	Sumudu Fernando;Martin Müller	2013		10.1007/978-3-319-09165-5_7	simulation;computer science;artificial intelligence;algorithm	AI	18.763467598656746	-12.713712067750683	51557
24bbe5e4583b328c1e262b94821faeb6f0d206e8	optimization of wind direction distribution parameters using particle swarm optimization		Data describing various natural and industrial phenomena can be modeled by directional statistical distributions. In the field of energy, wind direction and wind speed are the most important variables for wind energy generation, integration, and management. This work proposes and evaluates a new method for accurate estimation of wind direction distribution parameters utilizing the well-known Particle Swarm Optimization algorithm. It is used to optimize the parameters of a site-specific wind direction distribution model realized as a finite mixture of circular normal von Mises statistical distributions. The evaluation of the proposed algorithm is carried out using a data set describing annual wind direction on two distinct locations. Experimental results show that the proposed method is able to find good model parameters corresponding to input data.	particle swarm optimization;program optimization	Jana Heckenbergerova;Petr Musílek;Pavel Krömer	2014		10.1007/978-3-319-13572-4_2	multi-swarm optimization;particle swarm optimization	Vision	10.855844047472255	-17.189144972650364	51670
0c57c060ce3db36f95e37d13f8ae6703fff4510a	a hierarchical soft computing model for parameter estimation of curve fitting problems			curve fitting;estimation theory;soft computing	Yusuf Karadede;Gültekin Özdemir	2018	Soft Comput.	10.1007/s00500-018-3413-5	machine learning;mathematical optimization;computer science;artificial intelligence;least squares;soft computing;estimation theory;curve fitting	Robotics	12.059199641561559	-23.214254560920715	51845
dbf3ab94623b5506a98e9604d85503dfcc8638b1	moneybarl: exploiting pitcher decision-making using reinforcement learning	algorithmic statistics;markov;simulation;baseball;sports	"""This manuscript uses machine learning techniques to exploit baseball pitchers' decision making, so-called """" Baseball IQ, """" by modeling the at-bat information, pitch selection and counts, as a Markov Decision Process (MDP). Each state of the MDP models the pitcher's current pitch selection in a Markovian fashion, conditional on the information immediately prior to making the current pitch. This includes the count prior to the previous pitch, his ensuing pitch selection , the batter's ensuing action and the result of the pitch. The necessary Markovian probabilities can be estimated by the relevant observed conditional proportions in MLB pitch-by-pitch game data. These probabilities could be pitcher-specific, using only the data from one pitcher, or general, using the data from a collection of pitchers. Optimal batting strategies against these estimated conditional distributions of pitch selection can be ascertained by Value Iteration. Optimal batting strategies against a pitcher-specific conditional distribution can be contrasted to those calculated from the general conditional distributions associated with a collection of pitchers. In this manuscript, a single season of MLB data is used to calculate the conditional distributions to find optimal pitcher-specific and general (against a collection of pitchers) batting strategies. These strategies are subsequently evaluated by conditional distributions calculated from a different season for the same pitchers. Thus, the batting strategies are conceptually tested via a collection of simulated games, a """" mock season, """" governed by distributions not used to create the strategies. (Simulation is not needed, as exact calculations are available.) Instances where the pitcher-specific batting strategy outperforms the general batting strategy suggests that the pitcher is exploitable— knowledge of the conditional distributions of their pitch-making decision process in a different season yielded a strategy that worked better in a new season than a general batting strategy built on a population of pitchers. A permutation-based test of exploitability of the collection of pitchers is given and evaluated under two sets of assumptions. To show the practical utility of the approach, we introduce a spatial component that classifies each pitcher's pitch-types using a batter-parameterized spatial trajectory for each pitch. We found that heuristically labeled """" nonelite """" batters benefit from using the exploited pitchers' pitcher-specific strategies, whereas (also heuristically labeled) """" elite """" players do not."""	heuristic;iteration;machine learning;markov chain;markov decision process;mock object;pitch (music);reinforcement learning;simulation	Gagan Sidhu;Brian Caffo	2014	CoRR	10.1214/13-AOAS712	markov chain;simulation;speech recognition;artificial intelligence;mathematics;statistics	ML	21.433745553904867	-17.87729449439458	51957
8fb00171b8ca2de5d9438434ee58477cfcf033e7	ordered landmarks in planning	artificial intelligent;performance improvement;electronic computers computer science	Many known planning tasks have inherent constraints concerning the best order in which to achieve the goals. A number of research efforts have been made to detect such constraints and to use them for guiding search, in the hope of speeding up the planning process. We go beyond the previous approaches by considering ordering constraints not only over the (top-level) goals, but also over the sub-goals that will necessarily arise during planning. Landmarks are facts that must be true at some point in every valid solution plan. We extend Koehler and Hoffmann’s definition of reasonable orders between top level goals to the more general case of landmarks. We show how landmarks can be found, how their reasonable orders can be approximated, and how this information can be used to decompose a given planning task into several smaller sub-tasks. Our methodology is completely domainand planner-independent. The implementation demonstrates that the approach can yield significant runtime performance improvements when used as a control loop around state-of-the-art sub-optimal planning systems, as exemplified by FF and LPG.	approximation algorithm;automated planning and scheduling;control system;loop around;national land and property gazetteer;run time (program lifecycle phase)	Jörg Hoffmann;Julie Porteous;Laura Sebastia	2004	J. Artif. Intell. Res.	10.1613/jair.1492	simulation;computer science;artificial intelligence;machine learning;mathematics	AI	18.90781407811665	-10.889012943291352	52203
bbedb210c8ff59b856d9936def5bb78e1ae7cd3f	ttree: tree-based state generalization with temporally abstract actions	arbre graphe;multiagent system;trajectoire;generic model;tree graph;proceso markov;abstraction;decision markov;intelligence artificielle;abstraccion;trajectory;temporal abstraction;processus markov;state space;processus semi markovien;markov process;markov decision problem;proceso semi markoviano;algorithme arbre trajectoire;artificial intelligence;markov decision;trayectoria;inteligencia artificial;arbol grafo;sistema multiagente;semimarkovian process;systeme multiagent	In this chapter we describe the Trajectory Tree, or TTree, algorithm. TTree uses a small set of supplied policies to help solve a Semi-Markov Decision Problem (SMDP). The algorithm uses a learned tree based discretization of the state space as an abstract state description and both user supplied and auto-generated policies as temporally abstract actions. It uses a generative model of the world to sample the transition function for the abstract SMDP defined by those state and temporal abstractions, and then finds a policy for that abstract SMDP. This policy for the abstract SMDP can then be mapped back to a policy for the base SMDP, solving the supplied problem. In this chapter we present the TTree algorithm and give empirical comparisons to other SMDP algorithms showing its effectiveness.		William T. B. Uther;Manuela M. Veloso	2002		10.1007/3-540-45622-8_24	computer science;state space;artificial intelligence;trajectory;machine learning;mathematics;abstraction;markov process;tree;algorithm	ML	23.14554428837805	-14.513083877661394	52325
a74c4d76463a4e5767a9855e11b6af03f25288da	dynamic neural network approach for tool cutting force modelling of end milling operations	machining;experimental measurements;cutting forces;condition monitoring;dynamic neural network;end milling;experimental measurement;modeling;cutting force;milling;artificial neural network;neural network	This paper uses the artificial neural networks (ANN’s) approach to evolve an efficient model for estimation of cutting forces, based on a set of input cutting conditions. Neural network algorithms are developed for use as a direct modeling method, to predict forces for ball-end milling operations. Prediction of cutting forces in ball-end milling is often needed in order to establish automation or optimization of the machining processes. Supervised neural networks are used to successfully estimate the cutting forces developed during end milling processes. The training of the networks is preformed with experimental machining data. The predictive capability of using analytical and neural network approaches is compared. Neural network predictions for three cutting force components were predicted with 4% error by comparing with the experimental measurements. Exhaustive experimentation is conduced to develop the model and to validate it. By means of the developed method it is possible to forecast the development of events that will take place during the milling process without executing the tests. The force model can be used for simulation purposes and for defining threshold values in cutting tool condition monitoring system. It can be used also in the combination for monitoring and optimizing of the machining process cutting parameters.	algorithm;artificial neural network;explicit modeling;mathematical optimization;simulation	Franc Cus;Uros Zuperl;Matjaz Milfelner	2006	Int. J. General Systems	10.1080/03081070600782022	systems modeling;machining;computer science;machine learning;artificial neural network	ML	12.96058272384333	-19.40866890505027	52385
05bbcac27c75f8caaa8ba64a102a3e62199b9fd6	bias in algorithm portfolio performance evaluation		A Virtual Best Solver (VBS) is a hypothetical algorithm that selects the best solver from a given portfolio of alternatives on a per-instance basis. The VBS idealizes performance when all solvers in a portfolio are run in parallel, and also gives a valuable bound on the performance of portfolio-based algorithm selectors. Typically, VBS performance is measured by running every solver in a portfolio once on a given instance and reporting the best performance over all solvers. Here, we argue that doing so results in a flawed measure that is biased to reporting better performance when a randomized solver is present in an algorithm portfolio. Specifically, this flawed notion of VBS tends to show performance better than that achievable by a perfect selector that for each given instance runs the solver with the best expected running time. We report results from an empirical study using solvers and instances submitted to several SAT competitions, in which we observe significant bias on many random instances and some combinatorial instances. We also show that the bias increases with the number of randomized solvers and decreases as we average solver performance over many independent runs per instance. We propose an alternative VBS performance measure by (1) empirically obtaining the solver with best expected performance for each instance and (2) taking bootstrap samples for this solver on every instance, to obtain a confidence interval on VBS performance. Our findings shed new light on widely studied algorithm selection benchmarks and help explain performance gaps observed between VBS and state-of-the-art algorithm selection approaches.	algorithm selection;boolean satisfiability problem;bootstrapping (statistics);central processing unit;computer cluster;mike lesser;parallel algorithm;performance evaluation;randomized algorithm;sampling (signal processing);solver;time complexity;vbscript;westgrid	Chris Cameron;Holger H. Hoos;Kevin Leyton-Brown	2016			machine learning;empirical research;artificial intelligence;mathematical optimization;algorithm selection;confidence interval;computer science;algorithm;solver;portfolio	AI	20.10839949243425	-12.44652554525378	52637
dc93ae7c5cd6832245c900c0bfed3850870ab0aa	eliciting consumer preferences using robust adaptive choice questionnaires	consumidor;experimental design;sistema interactivo;metodo adaptativo;market research;markets;polyedre;analisis estadistico;support vector machines;mercado;consommateur;poliedro;comercializacion;plan experiencia;customization;personnalisation;robustness machine learning design for experiments statistical learning error correction support vector machines jacobian matrices market research benchmark testing interactive systems;polyhedron;methode adaptative;intelligence artificielle;aprendizaje probabilidades;acquisition connaissances;probabilistic approach;personalization;consumer preference;systeme conversationnel;commercialisation;statistical learning;statistical analysis;machine learning;plan experience;interactive system;design for experiments;statistical learning theory;marketing;consumer;enfoque probabilista;approche probabiliste;error correction;knowledge acquisition;knowledge acquisition marketing machine learning statistical interactive systems personalization;marche;adaptive method;analyse statistique;personalizacion;preferencia;apprentissage probabilites;artificial intelligence;robustness;preference;inteligencia artificial;statistical;adquisicion de conocimientos;jacobian matrices;interactive systems;benchmark testing;probability learning	We propose a framework for designing adaptive choice-based conjoint questionnaires that are robust to response error. It is developed based on a combination of experimental design and statistical learning theory principles. We implement and test a specific case of this framework using Regularization Networks. We also formalize within this framework the polyhedral methods recently proposed in marketing. We use simulations as well as an online market research experiment with 500 participants to compare the proposed method to benchmark methods. Both experiments show that the proposed adaptive questionnaires outperform existing ones in most cases. This work also indicates the potential of using machine learning methods in marketing.	benchmark (computing);design of experiments;endogeneity (econometrics);experiment;heuristic (computer science);machine learning;matrix regularization;polyhedron;rate of convergence;simulation;statistical learning theory	Jacob D. Abernethy;Theodoros Evgeniou;Olivier Toubia;Jean-Philippe Vert	2008	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2007.190632	market research;simulation;computer science;artificial intelligence;machine learning;data mining;personalization;database;algorithm;statistics	ML	22.79405885971452	-22.704107614007416	52921
cf8f5d8e105ca329c419439c18e9481c8f4b3d45	increasingly cautious optimism for practical pac-mdp exploration		Exploration strategy is an essential part of learning agents in model-based Reinforcement Learning. R-MAX and V-MAX are PAC-MDP strategies proved to have polynomial sample complexity; yet, their exploration behavior tend to be overly cautious in practice. We propose the principle of Increasingly Cautious Optimism (ICO) to automatically cut off unnecessarily cautious exploration, and apply ICO to R-MAX and V-MAX, yielding two new strategies, namely Increasingly Cautious R-MAX (ICR) and Increasingly Cautious V-MAX (ICV). We prove that both ICR and ICV are PACMDP, and show that their improvement is guaranteed by a tighter sample complexity upper bound. Then, we demonstrate their significantly improved performance through empirical results.	ico;intelligent character recognition;max;oracle identity management;pac-nbook 1;polynomial;probably approximately correct learning;reinforcement learning;sample complexity	Liangpeng Zhang;Ke Tang;Xin Yao	2015			simulation;artificial intelligence	AI	23.05323101756	-17.628107653786113	52961
1625400a959152a234854316fecef6016e5195e0	fem-based neural network modeling of laser-assisted bending		An artificial neural network (ANN) model of laser-assisted bending is developed based on the data obtained from a finite element method (FEM) model. FEM model is validated with the experiments. In the experimental setup, the sheet is clamped like a cantilever beam with mechanical load on the free end. A laser beam scans the bend line for reducing the flow stress of the material locally. ANN considers four process parameters viz., laser power, mechanical load, distance of the scan-line from the free end, and scan speed. The ANN predicts the most likely, upper, and lower estimates of the bend angle. Commercial package MATLAB® is used for developing the ANN model. First, a multilayer perceptron (MLP) neural network is trained and tested using the data from the FEM model. Using the best fit model of the MLP, additional data are generated for training a radial basis function (RBF) neural network. The RBF neural network is tested and validated against experimental data and subsequently used for obtaining the most likely, lower, and upper estimates of bend angle as a function of the considered process parameters. A parametric study is also carried out based on the RBF neural network model. Finally, it is shown that the neural network can be used for the inverse prediction using the bisection method.	artificial neural network;bisection method;clamping (graphics);cubic function;curve fitting;experiment;finite element method;least-angle regression;matlab;mathematical model;memory-level parallelism;multilayer perceptron;network model;quad flat no-leads package;radial (radio);radial basis function;scan line;simulation;viz: the computer game	Besufekad N. Fetene;Rajkumar Shufen;Uday S. Dixit	2016	Neural Computing and Applications	10.1007/s00521-016-2544-9	artificial intelligence;machine learning	ML	12.901884710618756	-20.25131459907495	53206
154b017714a7da4ab7585ae18ca66d09a28c0ad2	assessing the influence of an individual event in complex fault spreading network based on dynamic uncertain causality graph	uncertainty;complex networked systems complex fault spreading network fault propagation processes maintenance decision making complex systems emergency situations dynamic uncertain causality graph based method system components fault conditions fault origins probabilistic reasoning node time variant betweenness centrality fault propagation network real time spreading behaviors real time spreading dynamics power grid fault management;prediction algorithms;complex systems heuristic algorithms prediction algorithms power system dynamics fault diagnosis power grids uncertainty;power system dynamics;heuristic algorithms;smart power grids fault diagnosis inference mechanisms maintenance engineering network theory graphs power engineering computing power system faults power system management;uncertain causality representation causal influence strength dynamics fault spreading model probabilistic reasoning and prediction time variant betweenness centrality tvbc;complex systems;power grids;fault diagnosis	Identifying the pivotal causes and highly influential spreaders in fault propagation processes is crucial for improving the maintenance decision making for complex systems under abnormal and emergency situations. A dynamic uncertain causality graph-based method is introduced in this paper to explicitly model the uncertain causalities among system components, identify fault conditions, locate the fault origins, and predict the spreading tendency by means of probabilistic reasoning. A new algorithm is proposed to assess the impacts of an individual event by investigating the corresponding node's time-variant betweenness centrality and the strength of global causal influence in the fault propagation network. The algorithm does not depend on the whole original and static network but on the real-time spreading behaviors and dynamics, which makes the algorithm to be specifically targeted and more efficient. Experiments on both simulated networks and real-world systems demonstrate the accuracy, effectiveness, and comprehensibility of the proposed method for the fault management of power grids and other complex networked systems.	algorithm;anatomic node;behavior;betweenness centrality;causality;complex systems;congenital abnormality;decision making;experiment;graph - visual representation;inference;national origin;real-time clock;real-time computing;simulation;software propagation;sysop;world-system;spreaders	Chunling Dong;Yue Zhao;Qin Zhang	2016	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2016.2547339	complex systems;uncertainty;prediction;computer science;theoretical computer science;machine learning;fault model;mathematics;distributed computing;statistics	ML	13.199152393766926	-13.76428117146856	53615
18b2bf6c79319e8981148e1c68cf8d2ba9293c02	predictive analysis of mission critical systems dependability	railway engineering;reliability;mechanical engineering computing;signalling;reliability standards unified modeling language mathematical model rail transportation safety object oriented modeling;fmea fmeca;failure analysis;dependebility computation;predictive analysis;shamap dependebility computation fmea fmeca railway signalling equipment predictive analysis hierarchical model;unified modeling language;shamap;unified modeling language failure analysis mechanical engineering computing railway engineering reliability signalling;railway signalling equipment;hierarchical model;uml predictive analysis mission critical system dependability predictive reliability hierarchical models generally acclaimed standard mil hdbk 217f railway interlocking system czech republic	This paper describes the analysis of dependability and predictive reliability. The proposed methodology is based on hierarchical models and the generally acclaimed standard MIL-HDBK 217F. The equipment is a real component of the railway interlocking system in Czech Republic. The equipment is designed for high dependability and with respect of disturbances caused by the near environment. A possible encapsulation using UML to model processes affecting the reliability is shown.	bayesian network;dependability;encapsulation (networking);mil-std-810;mission critical;reliability engineering;unified modeling language	Martin Danhel;Hana Kubatova;Radek Dobias	2013	2013 Euromicro Conference on Digital System Design	10.1109/DSD.2013.66	unified modeling language;embedded system;signalling;failure analysis;predictive analytics;computer science;railway engineering;reliability;dependability;hierarchical database model	Robotics	12.299113206087387	-12.845813640562332	53693
51f532c84b80188ee6c7a208c1af5bc2066b14b6	detecting anomalies in process control networks	induction machine;learning process;distributed control system;anomaly detection;logistic regression;control system;maximum likelihood estimate;process control;probability mass function	This paper presents the estimation-inspection algorithm, a statistical algorithm for anomaly detection in process control networks. The algorithm determines if the payload of a network packet that is about to be processed by a control system is normal or abnormal based on the effect that the packet will have on a variable stored in control system memory. The estimation part of the algorithm uses logistic regression integrated with maximum likelihood estimation in an inductive machine learning process to estimate a series of statistical parameters; these parameters are used in conjunction with logistic regression formulas to form a probability mass function for each variable stored in control system memory. The inspection part of the algorithm uses the probability mass functions to estimate the normalcy probability of a specific value that a network packet writes to a variable. Experimental results demonstrate that the algorithm is very effective at detecting anomalies in process control networks.	algorithm;anomaly detection;cns;control system;cyber-physical system;ibm notes;julian day;logistic regression;machine learning;network packet;sensor;testbed	Julian L. Rrushi;Kyoung-Don Kang	2009		10.1007/978-3-642-04798-5_11	computer science;machine learning;pattern recognition;statistics	ML	15.365846464603	-17.54073625485662	54080
785f4c88976a52031697d4d6903c5dbf0f649843	a wearable device for sport performance analysis and monitoring		In this paper the use of a wearable device is considered in order to evaluate the performance of an athlete during her/his sport activities. The preliminary step consists of recording the motion variables at a sufficiently high sampling rate throughout the experimental campaign. The collected data are then elaborated by a PC-based application to identify the system dynamics and derive some synthetic performance indicators, by taking into account also the experience of the sport professionals. The extraction of the indicators is based on basic signal processing that can be implemented in algorithms run directly on the microcontroller unit (MCU) of the device. The key indicators values can be sent to other electronic devices by using one of the available wireless network connections at a reduced transmission rate. Some experimental data are also reported to illustrate the effectiveness of the approach.	algorithm;computation;gait analysis;hardware acceleration;microcontroller;microelectromechanical systems;profiling (computer programming);sampling (signal processing);signal processing;synthetic intelligence;system dynamics;wearable technology	Raffaele Iervolino;Francesco Bonavolontà;Adolfo Cavallari	2017	2017 IEEE International Workshop on Measurement and Networking (M&N)	10.1109/IWMN.2017.8078375	experimental data;microcontroller;performance indicator;wireless network;sampling (signal processing);signal processing;simulation;accelerometer;wearable computer;engineering	Mobile	16.429254834492077	-11.4785843932223	54090
6b31761f76918fec081ef74e3edbfe3c1b74dcb9	adding reinforcement learning features to the neural-gas method	neural nets;learning neural networks head target tracking biological system modeling robot control biological control systems vectors argon phase estimation;reinforcement learning;neural gas;multi dimensional;function approximation;learning artificial intelligence;function approximation learning artificial intelligence neural nets;approximating function reinforcement learning neural gas method	We propose a new neural approach for approximating function using a reinforcement-type learning: each time the network generates an output, the environment responds with the scalar distance between the delivered output and the expected one. Thus, this distance is the only information the network can use to modify the estimation of the multi-dimensional output. This reinforcement feature is embedded in a neuralgas method, taking advantages of the different facilities it offers. We detail the global algorithm and we present some simulation results in order to show the behaviour of the developed method.	algorithm;embedded system;neural gas;reinforcement learning;simulation	M. Winter;Giorgio Metta;Giulio Sandini	2000		10.1109/IJCNN.2000.860827	neural gas;temporal difference learning;unsupervised learning;self-organizing map;types of artificial neural networks;wake-sleep algorithm;function approximation;computer science;artificial intelligence;machine learning;pattern recognition;time delay neural network;deep learning;learning classifier system;competitive learning;evolutionary robotics;reinforcement learning;artificial neural network	ML	18.404048185715247	-22.093932660651394	54409
20961bf7eb743226cc97db7eae714f800fa423e0	on synergistic interactions between evolution, development and layered learning	grammar;arbre graphe;regularite;organisms;genomics;genetic program;evolucion biologica;evolution biologique;complexity theory;structural developmental evaluation genetic programming incremental evolution layered learning modularity regularity;tree graph;regularidad;developmental;systeme modulaire;structural;evolution biology genomics bioinformatics complexity theory organisms biological information theory;regularity;sistema modular;indice aptitud;biology;genetic programming;algoritmo genetico;effet dimensionnel;learning systems biology genetic algorithms;animal;evolution biology;learning systems;indice aptitude;biological evolution;capability index;grammaire;size effect;modular system;algorithme genetique;plant development evolution learning development learning lifelong layered learning evolutionary developmental evaluation tree adjoining grammar guided genetic programming learning theory perspective biological evolution animal development;biological information theory;algorithme evolutionniste;genetic algorithm;genetic algorithms;evaluation;algoritmo evolucionista;modularity;evolutionary algorithm;efecto dimensional;arbol grafo;gramatica;information theory;incremental evolution;layered learning;bioinformatics	We investigate interactions between evolution, development and lifelong layered learning in a combination we call evolutionary developmental evaluation (EDE), using a specific implementation, developmental tree-adjoining grammar guided genetic programming (GP). The approach is consistent with the process of biological evolution and development in higher animals and plants, and is justifiable from the perspective of learning theory. In experiments, the combination is synergistic, outperforming algorithms using only some of these mechanisms. It is able to solve GP problems that lie well beyond the scaling capabilities of standard GP. The solutions it finds are simple, succinct, and highly structured. We conclude this paper with a number of proposals for further extension of EDE systems.	algorithm;ede;evolution;experiment;genetic programming;image scaling;interaction;synergy;tree-adjoining grammar	Tuan Hao Hoang;Robert I. McKay;Daryl Essam;Nguyen Xuan Hoai	2011	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2011.2150752	genomics;genetic algorithm;information theory;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;algorithm	Robotics	23.606755417082905	-13.112459528481248	54610
e80ad789eca215bb93ec675c6d973119ca5982a8	reinforcement learning applied to simulated basketball balancing	reinforcement learning		reinforcement learning	William W. Armstrong	1998			mathematics;artificial intelligence;machine learning;reinforcement learning;basketball	NLP	19.515380135996622	-20.02431009767089	54856
228352abc521ae9e98e4087e6c809c4189d6170e	a comparison of machine learning methods for cutting parameters prediction in high speed turning process		Support vector machines are arguably one of the most successful methods for data classification, but when using them in regression problems, literature suggests that their performance is no longer state-of-the-art. This paper compares performances of three machine learning methods for the prediction of independent output cutting parameters in a high speed turning process. Observed parameters were the surface roughness (Ra), cutting force \((F_{c})\), and tool lifetime (T). For the modelling, support vector regression (SVR), polynomial (quadratic) regression, and artificial neural network (ANN) were used. In this research, polynomial regression has outperformed SVR and ANN in the case of \(F_{c}\) and Ra prediction, while ANN had the best performance in the case of T, but also the worst performance in the case of \(F_{c}\) and Ra. The study has also shown that in SVR, the polynomial kernel has outperformed linear kernel and RBF kernel. In addition, there was no significant difference in performance between SVR and polynomial regression for prediction of all three output machining parameters.		Zoran Jurkovic;Goran Cukor;Miran Brezocnik;Tomislav Brajkovic	2018	J. Intelligent Manufacturing	10.1007/s10845-016-1206-1	engineering;artificial intelligence;machine learning;pattern recognition	ML	11.485350663134218	-20.286629686996402	54952
c971474a5d0d72a7ff0307f230322d9d2f6e968d	seasonal arma-based spc charts for anomaly detection: application to emergency department systems	emergency department;anomaly detection;time series;ewma control scheme;spc schemes;sarma	Monitoring complex production systems is primordial to ensure management, reliability and safety as well as maintaining the desired product quality. Early detection of emergent abnormal behaviour in monitored systems allows pre-emptive action to prevent more serious consequences, to improve system operations and to reduce manufacturing and/or service costs. This study reports the design of a new models and statistical process control (SPC) tools for the joint development of a monitoring system to help supervising of the behaviour of emergency department services (EDs). The monitoring system developed is able to provide early alerts in the event of abnormal situations. The seasonal autoregressive moving average (SARMA)-based exponentially weighted moving average (EWMA) anomaly detection scheme proposed was successfully applied to the practical data collected from the database of the paediatric emergency department (PED) at Lille regional hospital centre, France. The method developed utilizes SARMA as a modelling framework and EWMA for anomaly detection. The EWMA control chart is applied to the uncorrelated residuals obtained from the SARMA model. The detection results of the EWMA chart are compared with two other commonly applied residual-based tests: a Shewhart individuals chart and a Cumulative Sum (CUSUM) control chart. & 2015 Elsevier B.V. All rights reserved.	anomaly detection;autoregressive model;chart;curve fitting;decision support system;downstream (software development);emergence;fault detection and isolation;moving-average model;production system (computer science);real-time clock;reference model;sensor;simulation;stationary process;time series	Farid Kadri;Fouzi Harrou;Sondès Chaabane;Ying Sun;Christian Tahon	2016	Neurocomputing	10.1016/j.neucom.2015.10.009	ewma chart;anomaly detection;computer science;machine learning;time series;operations research;statistics	AI	13.525729907836507	-14.58731025978274	55057
94a4bfaede629c0b91a50ef693d51d5e2d107f6e	capturing causality for fault diagnosis based on multi-valued alarm series using transfer entropy		Transfer entropy (TE) is a model-free approach based on information theory to capture causality between variables, which has been used for the modeling and monitoring of, and fault diagnosis in, complex industrial processes. It is able to detect the causality between variables without assuming any underlying model, but it is computationally burdensome. To overcome this limitation, a hybrid method of TE and the modified conditional mutual information (CMI) approach is proposed by using generated multi-valued alarm series. In order to obtain a process topology, TE can generate a causal map of all sub-processes and modified CMI can be used to distinguish the direct connectivity from the above-mentioned causal map by using multi-valued alarm series. The effectiveness and accuracy rate of the proposed method are validated by simulated and real industrial cases (the Tennessee-Eastman process) to capture process topology by using multi-valued alarm series.	causality;computation;computational complexity theory;computer memories inc.;conditional mutual information;information theory;portable document format;simulation;software propagation;test engineer;transfer entropy	Jianjun Su;Dezheng Wang;Yinong Zhang;Fan Yang;Yan Zhao;Xiangkun Pang	2017	Entropy	10.3390/e19120663	mathematical optimization;information theory;machine learning;mathematics;transfer entropy;causality;conditional mutual information;artificial intelligence	Robotics	13.202375980058767	-13.825436470474536	55154
359fef156197d287eaef2ea9c81e81bf653848c7	maximin action identification: a new bandit framework for games	multi armed bandit problems;racing;best arm identification;games;lucb	We study an original problem of pure exploration in a strategic bandit model motivated by Monte Carlo Tree Search. It consists in identifying the best action in a game, when the player may sample random outcomes of sequentially chosen pairs of actions. We propose two strategies for the fixed-confidence setting: Maximin-LUCB, based on lowerand upperconfidence bounds; and Maximin-Racing, which operates by successively eliminating the sub-optimal actions. We discuss the sample complexity of both methods and compare their performance empirically. We sketch a lower bound analysis, and possible connections to an optimal algorithm.	algorithm;limit analysis;minimax;monte carlo method;monte carlo tree search;multi-armed bandit;sample complexity;wald's maximin model	Aurélien Garivier;Emilie Kaufmann;Wouter M. Koolen	2016			games;computer science	AI	23.136098129961404	-17.2334417305108	55178
cd08ad7e94661bdfce25505923f5f1677576622a	path planning with user route preference - a reward surface approximation approach using orthogonal legendre polynomials	databases;automobiles;path planning;planning;markov processes;learning artificial intelligence;real time systems	As self driving cars become more ubiquitous, users would look for natural ways of informing the car AI about their personal choice of routes. This choice is not always dictated by straightforward logic such as shortest distance or shortest time, and can be influenced by hidden factors, such as comfort and familiarity. This paper presents a path learning algorithm for such applications, where from limited positive demonstrations, an autonomous agent learns the user's path preference and honors that choice in its route planning, but has the capability to adopt alternate routes, if the original choice(s) become impractical. The learning problem is modeled as a Markov decision process. The states (way-points) and actions (to move from one way-point to another) are pre-defined according to the existing network of paths between the origin and destination and the user's demonstration is assumed to be a sample of the preferred path. The underlying reward function which captures the essence of the demonstration is computed using an inverse reinforcement learning algorithm and from that the entire path mirroring the expert's demonstration is extracted. To alleviate the problem of state space explosion when dealing with a large state space, the reward function is approximated using a set of orthogonal polynomial basis functions with a fixed number of coefficients regardless of the size of the state space. A six fold reduction in total learning time is achieved compared to using simple basis functions, that has dimensionality equal to the number of distinct states.	approximation algorithm;autonomous agent;autonomous robot;basis function;coefficient;debugging;disk mirroring;human–robot interaction;legendre polynomials;markov chain;markov decision process;motion planning;natural language processing;polynomial basis;reinforcement learning;rescue robot;state space;turtle (robot);user (computing);waypoint	Aravinda Ramakrishnan Srinivasan;Subhadeep Chakraborty	2016	2016 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2016.7743527	simulation;artificial intelligence;machine learning;mathematics	Robotics	20.914407522705623	-21.159885862331343	55221
f87c93fc98031e696dbde01afb12cedc7b0f5821	an interval type-2 fuzzy logic system-based method for prediction interval construction	uncertainty;technology;computer science artificial intelligence;science technology;computer science interdisciplinary applications;controllers;design;genetic algorithm;interval type 2 fuzzy logic;computer science;sets;prediction interval;neural network	This paper introduces a new non-parametric method for uncertainty quantification through construction of prediction intervals (PIs). The method takes the left and right end points of the type-reduced set of an interval type-2 fuzzy logic system (IT2FLS) model as the lower and upper bounds of a PI. No assumption is made in regard to the data distribution, behaviour, and patterns when developing intervals. A training method is proposed to link the confidence level (CL) concept of PIs to the intervals generated by IT2FLS models. The new PI-based training algorithm not only ensures that PIs constructed using IT2FLS models satisfy the CL requirements, but also reduces widths of PIs and generates practically informative PIs. Proper adjustment of parameters of IT2FLSs is performed through the minimization of a PI-based objective function. A metaheuristic method is applied for minimization of the non-linear non-differentiable cost function. Performance of the proposed method is examined for seven synthetic and real world benchmark case studies with homogenous and heterogeneous noise. The demonstrated results indicate that the proposed method is capable of generating high quality PIs. Comparative studies also show that the performance of the proposed method is equal to or better than traditional neural network-based methods for construction of PIs in more than 90% of cases. The superiority is more evident for the case of data with a heterogeneous noise. © 2014 Elsevier B.V. All rights reserved.	algorithm;artificial neural network;benchmark (computing);dhrystone;display resolution;fuzzy logic;gene prediction;information;loss function;metaheuristic;nonlinear system;optimization problem;requirement;teaching method;uncertainty quantification	Abbas Khosravi;Saeid Nahavandi	2014	Appl. Soft Comput.	10.1016/j.asoc.2014.06.039	design;mathematical optimization;genetic algorithm;uncertainty;prediction interval;computer science;artificial intelligence;machine learning;artificial neural network;algorithm;statistics;technology	AI	13.187836636651573	-23.75208767469498	55247
2ec3d7abdf5e3bd4e872cbe75aa3a42ccfef94c7	short-term electric power load forecasting based on cosine radial basis function neural networks: an experimental evaluation	forecasting;puissance electrique;prevision;reseau electrique;weather;tiempo meteorologico;electrical network;red electrica;fonction base radiale;temps meteorologique;load forecasting;radial basis function;radial basis function neural network;court terme;potencia electrica;experimental evaluation;electric power;reseau neuronal;funcion radial base;red neuronal;corto plazo;short term;neural network	Abstract#R##N##R##N#This article presents the results of a study aimed at the development of a system for short-term electric power load forecasting. This was attempted by training feedforward neural networks (FFNNs) and cosine radial basis function (RBF) neural networks to predict future power demand based on past power load data and weather conditions. This study indicates that both neural network models exhibit comparable performance when tested on the training data but cosine RBF neural networks generalize better since they outperform considerably FFNNs when tested on the testing data. © 2005 Wiley Periodicals, Inc. Int J Int Syst 20: 591–605, 2005.	artificial neural network;radial (radio);radial basis function	Nicolaos B. Karayiannis;Mahesh Balasubramanian;Heidar A. Malki	2005	Int. J. Intell. Syst.	10.1002/int.20084	electrical network;radial basis function;electric power;telecommunications;forecasting;computer science;artificial intelligence;machine learning;short-term memory;artificial neural network	ML	10.096241090020387	-18.048879614311918	55474
1bf036fa13706546bd21c8f6b6c649afc5f75557	variational policy search via trajectory optimization		In order to learn effective control policies for dynamical systems, policy search methods must be able to discover successful executions of the desired task. While random exploration can work well in simple domains, complex and highdimensional tasks present a serious challenge, particularly when combined with high-dimensional policies that make parameter-space exploration infeasible. We present a method that uses trajectory optimization as a powerful exploration strategy that guides the policy search. A variational decomposition of a maximum likelihood policy objective allows us to use standard trajectory optimization algorithms such as differential dynamic programming, interleaved with standard supervised learning for the policy itself. We demonstrate that the resulting algorithm can outperform prior methods on two challenging locomotion tasks.	algorithm;calculus of variations;differential dynamic programming;dynamical system;mathematical optimization;supervised learning;trajectory optimization;variational principle	Sergey Levine;Vladlen Koltun	2013			mathematical optimization;simulation;computer science;machine learning	ML	21.277370861219808	-19.434940189260097	55748
c3eb7c5c39211af45fb687d1439581378fd813b0	prediction of precipitation based on artificial neural networks by free search	bp neural network;free search;precipitation;prediction	FS-BP model was used to try to predict precipitation. The last six years' precipitation were selected as input variable and the next year's precipitation as output variable. The results show that the mean relative error of the prediction is 2.92%. T-test and regression analysis indicates that the predicted value differs just slightly from the observed value and their correlation coefficient was 0.9901.The FS-BP model is quite higher than BP model in accuracy and stability, and serves as useful tool in further research on prediction of precipitation. © 2011 Springer-Verlag Berlin Heidelberg.	artificial neural network;neural networks	Guang-Hua Yin;Jian Hua Gu;Fa-Sheng Zhang;Ye-Jie Shen;Zuo-xin Liu	2011		10.1007/978-3-642-23756-0_61	statistics;regression analysis;artificial neural network;correlation coefficient;approximation error;precipitation;mathematics	ML	10.398087119508176	-19.478392209396155	55976
af242e99f149e8db8bfc6ab7912a8324d503e374	deep reinforcement learning with model learning and monte carlo tree search in minecraft		Deep reinforcement learning has been successfully applied to several visual-input tasks using model-free methods. In this paper, we propose a model-based approach that combines learning a DNN-based transition model with Monte Carlo tree search to solve a block-placing task in Minecraft. Our learned transition model predicts the next frame and the rewards one step ahead given the last four frames of the agent’s first-person-view image and the current action. Then a Monte Carlo tree search algorithm uses this model to plan the best sequence of actions for the agent to perform. On the proposed task in Minecraft, our model-based approach reaches the performance comparable to the Deep Q-Network’s, but learns faster and, thus, is more training sample efficient.	artificial neural network;deep learning;greedy algorithm;minecraft;monte carlo method;monte carlo tree search;recurrent neural network;reinforcement learning;search algorithm;tree traversal	Stephan Alaniz	2018	CoRR		machine learning;computer science;artificial intelligence;reinforcement learning;monte carlo tree search	AI	20.00051127912309	-20.13037724061947	56097
82bef86adaed972d2fd871c8f5476a7d1b332dd1	application of the stepping stress acceleration life test in the product storage life forecast	cybernetics;inventory management;life cycle cost;storage management;data processing;accelerated life testing;failure mechanism;mathematical model;life cycle costs;forecasting method;design methodology	Purpose – The purpose of this paper is to forecast the reliable storage life of a certain kind of equipment under the normal stress level. Design/methodology/approach – Through the stepping stress acceleration life test and the failure mechanism analysis, this paper aims to confirm the stress level for the stepping stress acceleration life test of a certain kind of equipment and establish the data processing mathematical model and storage life forecasting method. Findings – The stress level for the stepping stress acceleration life test of a certain kind of equipment is confirmed and the data processing mathematical model and storage life forecasting method is established. Research limitations/implications – Availability of data is the main limitation affecting which model will be applied. Practical implications – Useful advice for products’ storage life forecasting. Originality/value – The paper presents a new approach to product storage life estimation.	failure cause;mathematical model;stepping level;stress testing	Pengcheng Yan;Dongqing Liu;Bo Zheng	2009	Kybernetes	10.1108/03684920910994268	simulation;accelerated life testing;data processing;cybernetics;design methods;computer science;artificial intelligence;mathematical model;operations research	SE	10.803079467932545	-14.75140069699663	56107
32d004bd35579ccc424904926d0a631387af439a	the power quality forecasting model for off-grid system supported by multiobjective optimization		Measurement and control of electric power quality (PQ) parameters in off-grid systems has played an important role in recent years. The purpose is to detect or forecast the presence of PQ parameter disturbances to be able to suppress or to avoid their negative effects on the power grid and appliances. This paper focuses on several PQ parameters in off-grid systems and it defines three evaluation criteria that are supposed to estimate the performance of a new forecasting model combining all the involved PQ parameters. These criteria are based on common statistical evaluations of computational models from the machine learning field of study. The studied PQ parameters are voltage, power frequency, total harmonic distortion, and flicker severity. The approach presented in this paper also applies a machine learning based model of random decision forest for PQ forecasting. The database applied in this task contains real off-grid data from long-term one-minute measurements. The hyperparameters of the model are optimized by multiobjective optimization toward the defined evaluation criteria.	computational model;electric power quality;flicker (screen);machine learning;mathematical optimization;multi-objective optimization;program optimization;total harmonic distortion	Tomas Vantuch;Stanislav Mi&#x0161;&#x00E1;k;Tom&#x00E1;&#x0161; Je&#x017E;owicz;Tom&#x00E1;&#x0161; Buri&#x00E1;nek;V&#x00E1;clav Sn&#x00E1;&#x0161;el	2017	IEEE Transactions on Industrial Electronics	10.1109/TIE.2017.2711540	reliability engineering;simulation	DB	11.236877869840468	-15.266749650699778	56292
9b936b05053124643496ce498330d264cf5b063f	learning a mixture of search heuristics		Problem solvers have at their disposal many heuristics that may support effective search. The efficacy of these heuristics, however, varies with the problem class, and their mutual interactions may not be well understood. The long-term goal of our work is to learn how to select appropriately from among a large body of heuristics, and how to combine them into a weighted mixture that works well on a specific class of problems. During learning, search heuristics’ weights are used to solve a problem and then updated based on their subsequent performance. This paper proposes and demonstrates a variety of ways to gauge and adapt search performance, and shows how their application can improve subsequent search performance.	ace;boosting (machine learning);communication endpoint;decision problem;decision quality;factor analysis;feature selection;heuristic (computer science);interaction;mathematical optimization;mutual exclusion;norm (social);optimization problem;randomness;solver;vertex (graph theory)	Susan L. Epstein;Smiljana Petrovic	2011		10.1007/978-3-642-21434-9_5	machine learning;pattern recognition;hyper-heuristic	AI	23.339125135853596	-15.87041048407901	56380
21364ded6257de72cd2516f9f0fe2df9db3f1fbc	fault detection and diagnosis for nonlinear systems: a support vector machine approach		Abstract   Abstract  In this paper, a fault detection and diagnosis (FDD) technique for nonlinear systems based on support vector machines (SVM) is presented. Support vector regression (SVR) has been used in fault detection process and support vector classification (SVC) has been used in diagnosis process. In fault detection process, the confidence band idea represents the normal operating conditions of the system. The upper and the lower boundaries of the confidence band are modelled by two different SVR machines. A fault is detected when an output signal exceeds the upper or lower bounds of the generated confidence band. A support vector multi-classification method, one-against-all, has been used to classify the occurring fault within the group of expected and predefined faults in technical system. The performance of the proposed FDD method is illustrated on simulation example involving a two-tank water level control system under faulty conditions.	nonlinear system;support vector machine	Rana Ortaç-Kabaoglu;Ibrahim Eksin;Engin Yesil;Müjde Güzelkaya	2009		10.3182/20090921-3-TR-3005.00063	real-time computing;stuck-at fault;machine learning	ML	13.23241261338828	-16.336671237622763	56617
c8520d3d624f05ead672098cb98c0f0efebcfa77	models for spatial interaction data: computation and interpretation of accessibility	interpreting sensitivity analysis;origin and destination specific parameters;dual variables;computational properties	"""The paper is in the area of spatial optimization, for simulating and understanding spatial interaction. The model foundation is from Wilson's """"doubly constrained"""" model of spatial interaction. The idea is to perform a sensitivity analysis on the parameters of this model and to interpret the results in terms of accessibility. The main purpose of this type of analysis is to use data from interaction systems to uncover structural effects that help to understand the role of origin and destination location, and accessibility. US air passenger traffic is used as the starting point for the model. The model reproduces many of the features of the data with a parsimonious set of parameters, leaving some aspects of the analysis open to interpretation. An innovative idea in this paper is to compute averages and other measures directly from the data, fit a model to these data, and then to use the fitted (and observed) matrices to evaluate numerous theoretically inspired measurements. This paper (in a modular way) develops the introduction and context, and then moves to theory, spatial disaggregation, and empirical applications."""		Morton E. O'Kelly	2012		10.1007/978-3-642-31075-1_19	econometrics;mathematical optimization;computer science;artificial intelligence;machine learning;data mining;mathematics;statistics	HCI	23.956398083696936	-22.045580824852216	56933
0dd370b6a0b040af18981502f5524e913834acb6	interactive pomdp lite: towards practical planning to predict and exploit intentions for interacting with self-interested agents	interactive pomdp lite;performance loss;resulting planning policy;expensive cost;intelligent agent;self-interested agent;key challenge;efficient intention-aware planning;efficient planning algorithm;robust performance;intention prediction;practical planning;empirical evaluation	A key challenge in non-cooperative multi-agent systems is that of developing efficient planning algorithms for intelligent agents to interact and perform effectively among boundedly rational, selfinterested agents (e.g., humans). The practicality of existing works addressing this challenge is being undermined due to either the restrictive assumptions of the other agents’ behavior, the failure in accounting for their rationality, or the prohibitively expensive cost of modeling and predicting their intentions. To boost the practicality of research in this field, we investigate how intention prediction can be efficiently exploited and made practical in planning, thereby leading to efficient intention-aware planning frameworks capable of predicting the intentions of other agents and acting optimally with respect to their predicted intentions. We show that the performance losses incurred by the resulting planning policies are linearly bounded by the error of intention prediction. Empirical evaluations through a series of stochastic games demonstrate that our policies can achieve better and more robust performance than the state-of-the-art algorithms.	adobe flash lite;algorithm;holographic principle;intelligent agent;linear bounded automaton;multi-agent system;partially observable markov decision process;partially observable system;programming paradigm;rationality;theory	Trong Nghia Hoang;Kian Hsiang Low	2013			simulation;artificial intelligence;machine learning;management science	AI	19.858992452191767	-15.764416854524361	57112
43474447d142ebc15eeaa79c00b7e0ed529fd00a	predicting the outcome of small battles in starcraft		Real-Time Strategy (RTS) games are popular testbeds for AI researchers. In this paper we compare different machine learning algorithms to predict the outcome of small battles of marines in StarCraft, a popular RTS game. The predictions are made from the perspective of an external observer of the game and they are based only on the actions that the different units perform in the battlefield. Our empirical results show that case-based approaches based on k-Nearest Neighbor classification outperform other standard classification algorithms like Linear and Quadratic Discriminant Analysis or Support Vector Machines.	artificial intelligence;k-nearest neighbors algorithm;linear discriminant analysis;machine learning;quadratic classifier;real-time transcription;starcraft;support vector machine;testbed	Antonio A. Sánchez-Ruiz-Granados	2015			simulation;engineering;artificial intelligence;operations research	AI	10.930501103634203	-23.490089121910195	57684
0deb2c26da99002f8566bcd62709df6ab545ba6a	an analysis of the pheromone q-learning algorithm	optimal solution;solution optimale;learning algorithm;speed of convergence;phenomene q learning;algorithme apprentissage;machine learning;solucion optima;evaporation;computer science and informatics;learning artificial intelligence;algoritmo aprendizaje;evaporacion;apprentissage intelligence artificielle	The Phe-Q machine learning technique, a modified Q-learning technique, was developed to enable co-operating agents to communicate in learning to solve a problem. The Phe-Q learning technique combines Q-learning with synthetic pheromone to improve on the speed of convergence. The Phe-Q update equation includes a belief factor that reflects the confidence the agent has in the pheromone (the communication) deposited in the environment by other agents. With the Phe-Q update equation, speed of convergence towards an optimal solution depends on a number parameters including the number of agents solving a problem, the amount of pheromone deposited, and the evaporation rate. In this paper, work carried out to optimise speed of learning with the Phe-Q technique is described. The objective was to to optimise Phe-Q learning with respect to pheromone deposition rates, evaporation rates.	algorithm;brute-force search;chemical vapor deposition;computation;evaporation;machine learning;multi-agent system;physical vapor deposition;q-learning;rate of convergence;synthetic intelligence	Dorothy Ndedi Monekosso;Paolo Remagnino	2002		10.1007/3-540-36131-6_23	simulation;computer science;artificial intelligence;online machine learning;machine learning;evaporation	ML	18.01106041427745	-22.045838043015266	58001
f681e979d5dbe669e60d229949b0319a03605862	continuous q-learning for multi-agent cooperation	multi agent system;learning model;q learning;action selection;state space;stochastic recording real valued unit;probability distribution function	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	action selection;algorithm;categorization;francis;fuzzy control system;maxima and minima;maximal set;primary source;q-learning;simulation;state space	Kao-Shing Hwang;Wei-Cheng Jiang;Yu-Hong Lin;Li-Hsin Lai	2012	Cybernetics and Systems	10.1080/01969722.2012.660032	probability density function;simulation;action selection;computer science;state space;artificial intelligence;machine learning;multi-agent system;mathematics;q-learning	Robotics	23.07153136767209	-13.499564988730453	58115
429321cea58bab26b2338a1d400449d4e9fd85ad	utility-based multi-agent system for performing repeated navigation tasks	multi agent system;mobile agents;autonomous agent;mobile agent;applications of autonomous agents multi agent systems	Suppose that a number of mobile agents need to travel back and forth between two locations in an unknown environment a given number of times. These agents need to find the right balance between exploration of the environment and performing the actual task via a known suboptimal path. Each agent should decide whether to follow the best known path or to devote its effort for further exploration of the graph so as to improve the path for future usage. We introduce a utility-based approach which chooses its next job such that the estimation of global utility is maximized. We compare this approach to a stochastic greedy approach which chooses its next job randomaly so as to increase the diversity of the known graph. We apply these approaches to different environments and to different communication paradigms. Experimental results show that an intelligent utility-based multi-agent system outperforms a stochastic greedy multi-agent system. In addition the utility-based approach was robust under inaccurate input and limitation of the communication abilities.	dos;graph (discrete mathematics);greedy algorithm;mobile agent;multi-agent system;stochastic gradient descent	Ram Meshulam;Ariel Felner;Sarit Kraus	2005		10.1145/1082473.1082608	simulation;computer science;artificial intelligence;autonomous agent;multi-agent system;mobile agent	AI	19.470555886364018	-14.05510413817765	58158
ae5bfbca567c9a655fcba058e26337118235b7a5	condition-based maintenance with multi-target classification models	condition-based maintenance;telematics;prognostics;vehicle health management;reliability;multi-target classification;info-fuzzy networks	Condition-based maintenance (CBM) recommends maintenance actions based on the information collected through condition monitoring. In many modern cars, the condition of each subsystem can be monitored by onboard vehicle telematics systems. Prognostics is an important aspect in a CBM program as it deals with prediction of future faults. In this paper, we present a data mining approach to prognosis of vehicle failures. A multitarget probability estimation algorithm (M-IFN) is applied to an integrated database of sensor measurements and warranty claims with the purpose of predicting the probability and the timing of a failure in a given subsystem. The results of the multi-target algorithm are shown to be superior to a singletarget probability estimation algorithm (IFN) and reliability modeling based on Weibull analysis.	bootstrap aggregating;data mining;ensemble learning;genetic algorithm;reliability engineering;synthetic intelligence;telematics	Mark Last;Alla Sinaiski;Halasya Siva Subramania	2010	New Generation Computing	10.1007/s00354-010-0301-7	data mining	AI	13.134501446536175	-14.818682841314166	58331
7c4f16b7be4d49d01986b9f40f66945e75bf7152	two fault classification methods for large systems when available data are limited	bayes estimation;arbol defecto;fault tree;bayes classification;geometric classification;classification;estimacion bayes;diagnostic panne;arbre defaut;fault diagnostic;diagnostico pana;clasificacion;unwanted symptom;fault diagnosis;estimation bayes	In this paper, we consider the problem of fault diagnosis for a system with many possible fault types. Two approaches are presented that are useful for initial diagnosis of system-wide faults, assuming that no data are available before commissioning the system but the possibility of the occurrence of each symptom is known for each fault. The first method uses a fault tree approach to reduce the solution space before applying the geometric classification method, the assumption being that no unwanted symptoms are possible. This method is nonparametric and thus does not require any data to estimate the underlying distribution of faults and symptoms. The second method is based on the Bayes classification approach to utilize the subjective information and the limited data that may be available. The two methods are generic and applicable to a variety of industrial processes.		Kyungmee O. Kim;Ming Jian Zuo	2007	Rel. Eng. & Sys. Safety	10.1016/j.ress.2006.02.001	reliability engineering;fault tree analysis;biological classification;engineering;pattern recognition;data mining;mathematics;statistics	ML	13.349745019231921	-14.68673385340649	58360
c2c3706c2c59c409e9171f75983ad5bf75217850	epmas: evolutionary programming multi-agent systems		Evolutionary Programming (EP) seems a promising methodology to automatically find programs to solve new computing challenges. The Evolutionary Programming techniques use classical genetic operators (selection, crossover and mutation) to automatically generate programs targeted to solve computing problems or specifications. Among the methodologies related with Evolutionary Programming we can find Genetic Programming, Analytic Programming and Grammatical Evolution. In this paper we present the Evolutionary Programming Multiagent Systems (EPMAS) framework based on Grammatical Evolution (GE) to evolutionary generate Multi-agent systems (MAS) ad-hoc. We also present two case studies in MAS scenarios for applying our EPMAS framework: the predator-prey problem and the Iterative Prisoner’s Dilemma.	agent-based model;crossover (genetic algorithm);evolutionary programming;expectation propagation;genetic operator;genetic programming;grammatical evolution;hoc (programming language);iterative method;lotka–volterra equations;multi-agent system;mutation (genetic algorithm);prey;prisoner's dilemma;selection (genetic algorithm)	Ana Peleteiro-Ramallo;Juan C. Burguillo;Zuzana Komínková Oplatková;Ivan Zelinka	2010		10.7148/2010-0027-0033	evolutionary programming;genetic programming;interactive evolutionary computation;human-based evolutionary computation;functional reactive programming;java evolutionary computation toolkit;evolutionary acquisition of neural topologies;genetic representation	AI	23.15126582696144	-9.975377984272955	58378
1ba37f3940bac344506d0f09ba21172b52cbb1fe	planning with pomdps using a compact, logic-based representation	logic based representation;optimal plan logic based representation partially observable markov decision process artificial intelligence planning decision theory belief state heuristic search;partially observed markov decision process;logic;planning artificial intelligence;planning artificial intelligence decision theory formal logic markov processes;heuristic search;optimal plan;compact representation;state space;decision theory;relative efficiency;action observation;partially observable markov decision process;formal logic;artificial intelligence;planning;markov processes;belief state;logic artificial intelligence state space methods process planning decision making stochastic processes computer science decision theory random variables vocabulary;ai planning;artificial intelligence planning	Partially observable Markov decision processes (POMDPs) provide a general framework for AI planning, but they lack the structure for representing real world planning problems in a convenient and efficient way. Representations built on logic allow for problems to be specified in a compact and transparent manner. Moreover, decision making algorithms can assume and exploit structure found in the state space, actions, observations, and success criteria, and can solve with relative efficiency problems with large state spaces. In recent years researchers have sought to combine the benefits of logic with the expressiveness of POMDPs. In this paper, we show how to build upon and extend the results in this fusing of logic and decision theory. In particular, we present a compact representation of POMDPs and a method to update beliefs after actions and observations. The key contribution is our compact representation of belief states and of the operations used to update them. We then use heuristic search to find optimal plans that maximize expected total reward given an initial belief state	algorithm;approximation;automated planning and scheduling;decision theory;diagram;experiment;first-order logic;first-order predicate;heuristic;heuristic (computer science);linear algebra;markov chain;partially observable markov decision process;semantics (computer science);state space	Chenggang Wang;James G. Schmolze	2005	17th IEEE International Conference on Tools with Artificial Intelligence (ICTAI'05)	10.1109/ICTAI.2005.96	automated planning and scheduling;mathematical optimization;heuristic;computer science;artificial intelligence;machine learning;mathematics;logic	AI	21.20484922493778	-15.347865632381826	58394
52dcdf5275b99e22fa60428ee15d364f07e0007a	planning to give information in partially observed domains with a learned weighted entropy model		In many robotic applications, an autonomous agent must act within and explore a partially observed environment that is unobserved by its human teammate. We consider such a setting in which the agent can, while acting, transmit declarative information to the human that helps them understand aspects of this unseen environment. Naturally, the human will have preferences about what information they are given. This work adopts an information-theoretic view of the human’s preferences: the human scores information based on the induced change in weighted entropy of their belief about the environment state. We formulate this setting as a belief MDP and give an algorithm for solving it approximately. Then, we give an algorithm that allows the agent to learn the human’s preferences online. We validate our approach experimentally in simulated discrete and continuous partially observed search-and-recover domains.	algorithm;autonomous agent;autonomous robot;declarative programming;entropy (information theory);experiment;information gain in decision trees;information theory;kullback–leibler divergence;transmitter;weight function	Rohan Chitnis;Leslie Pack Kaelbling;Tomás Lozano-Pérez	2018	CoRR		artificial intelligence;machine learning;autonomous agent;computer science	AI	20.321807970451523	-16.515044745479994	58407
43a4dcc65fb4503f8dd61d5bc3ac3778f3fadd22	improving the performance of complex agent plans through reinforcement learning	004;agent programming planning reinforcement learning semi non markov decision process	Agent programming in complex, partially observable, and stochastic domains usually requires a great deal of understanding of both the domain and the task in order to provide the agent with the knowledge necessary to act effectively. While symbolic methods allow the designer to specify declarative knowledge about the domain, the resulting plan can be brittle since it is difficult to supply a symbolic model that is accurate enough to foresee all possible events in complex environments, especially in the case of partial observability. Reinforcement Learning (RL) techniques, on the other hand, can learn a policy and make use of a learned model, but it is difficult to reduce and shape the scope of the learning algorithm by exploiting a priori information. We propose a methodology for writing complex agent programs that can be effectively improved through experience. We show how to derive a stochastic process from a partial specification of the plan, so that the latter’s perfomance can be improved solving a RL problem much smaller than classical RL formulations. Finally, we demonstrate our approach in the context of Keepaway Soccer, a common RL benchmark based on a RoboCup Soccer 2D simulator.	algorithm;benchmark (computing);partially observable system;reinforcement learning;sensible soccer;simulation;stochastic optimization;stochastic process	Matteo Leonetti;Luca Iocchi	2010		10.1145/1838206.1838302	error-driven learning;simulation;computer science;artificial intelligence;machine learning	AI	20.545005901221806	-15.77231496147109	58556
90aa891d181d918aafdf1a29d8620bc7859294b5	bayesian group testing under sum observations: a parallelizable two-approximation for entropy loss	selected works;bayes methods;testing;computational modeling;games;bepress;ip networks;entropy;probabilistic logic	We consider the problem of group testing with sum observations and noiseless answers, in which we aim to locate multiple objects by querying the number of objects in each of a sequence of chosen sets. We study a probabilistic setting with entropy loss, in which we assume a joint Bayesian prior density on the locations of the objects and seek to choose the sets queried to minimize the expected entropy of the Bayesian posterior distribution after a fixed number of questions. We present a new non-adaptive policy, called the dyadic policy, show that it is optimal among non-adaptive policies, and is within a factor of two of optimal among adaptive policies. This policy is quick to compute, its nonadaptive nature makes it easy to parallelize, and our bounds show that it performs well even when compared with adaptive policies. We also study an adaptive greedy policy, which maximizes the one-step expected reduction in entropy, and show that it performs at least as well as the dyadic policy, offering greater query efficiency but reduced parallelism. Numerical experiments demonstrate that both procedures outperform a divide-and-conquer benchmark policy from the literature, called sequential bifurcation, and show how these procedures may be applied in a stylized computer vision problem.	approximation;benchmark (computing);bifurcation theory;computer vision;dyadic transformation;experiment;greedy algorithm;parallel computing	Weidong Han;Purnima Rajan;Peter I. Frazier;Bruno Jedynak	2017	IEEE Transactions on Information Theory	10.1109/TIT.2016.2628784	games;entropy;mathematical optimization;computer science;machine learning;data mining;mathematics;software testing;probabilistic logic;computational model;statistics	ML	24.3234986733226	-17.894856128176507	58569
fd764a6572812a373e9f1c3ef834a342edfe2d35	real-time detection of in-flight aircraft damage	ensemble learning;sliding window;aviation safety	When there is damage to an aircraft, it is critical to be able to quickly detect and diagnose the problem so that the pilot can attempt to maintain control of the aircraft and land it safely. We develop methodology for real-time classification of flight trajectories to be able to distinguish between an undamaged aircraft and five different damage scenarios. Principal components analysis allows a lower-dimensional representation of multi-dimensional trajectory information in time. Random Forests provide a computationally efficient approach with sufficient accuracy to be able to detect and classify the different scenarios in real-time. We demonstrate our approach by classifying realizations of a 45 degree bank angle generated from the Generic Transport Model flight simulator in collaboration with NASA.	algorithm;algorithmic efficiency;cross-validation (statistics);flight simulator;generative topographic map;laptop;onset (audio);principal component analysis;random forest;real-time clock;real-time computing;real-time transcription;rudder;simulation;statistical classification	Brenton Blair;Herbert K. H. Lee;Misty Davies	2017	J. Classification	10.1007/s00357-017-9237-7	random forest;mathematics;sliding window protocol;flight simulator;simulation;ensemble learning;trajectory;principal component analysis;aviation safety	ML	11.977302908844122	-14.32236857327996	58748
d32bec8b34c302b2f255781eec4fb0b3a8a70739	hybrid multi-model forecasting system: a case study on display market	average square root error asre;hybrid multi model forecasting system;mean absolute percentage error mape;mean square error mse;article;prediction;display markets	Keywords: Hybrid multi-model forecasting system Prediction Display markets Mean square error (MSE) Mean absolute percentage error (MAPE) Average square root error (ASRE) a b s t r a c t This paper provides a novel hybrid multi-model forecasting system, with a special focus on the changing regional market demand in the display markets. Through an intensive case study of the ups and downs of the display industry, this paper examines the panel makers suffered from low panel price and unstable market demand, then they have changed to react to the rapid demand in the market or have lower panel stock for keeping supply and demand more balanced. In addition, this paper suggests a co-evolution forecasting process of sales and market factor. It can automatically apply various combinations of both linear and nonlinear models, and which alternatives deliver the lowest statistical error and produce a good estimate for the prediction of markets. Moreover, this article shows how the system is modeled and its accuracy is proved by means of experimental results; and judged by 3 evaluation criteria, including the mean square error (MSE), the mean absolute percentage error (MAPE), and the average square root error (ASRE) were used as the performance criteria to automatically select the optimal forecasting model. Finally, the results showed that the proposed system had considerably better predictive performance than previous and individual models. To summarize, the proposed system can reduce the user's effort for easier obtaining the desired forecasting results and create high quality forecasts. The flat-panel display (FPD) is a landmark sector all over the world in terms of technology innovation. This market is growing based on the competitiveness of three major technologies: thin-film transistor-liquid crystal displays (TFT-LCD), plasma display panels (PDP) and organic light-emitting diodes (OLED). TFT-LCD has the largest market share. This technology dominates the market, as it can be used in different types of applications, ranging from small devices including mobile phones to large applications including televisions. However, TFT-LCD manufacture has high risk and low affixa-tion. Because high-risk industry where failure for market estimation can lead to the elimination of an enterprise and where a timely, large-scale investment is essential; industry where large companies that should have the capacity to mobilize large capital are fully equipped with necessary parts and materials. Research on flat panel displays (FPD), which started in the 1960s, has finally reached the commercialization stage in the form of large …	adaptive neuro fuzzy inference system;approximation error;autoregressive integrated moving average;control theory;database;diode;display resolution;entity–relationship model;flat panel detector;flat panel display;graphical user interface;linear model;mean squared error;mobile phone;national supercomputer centre in sweden;nonlinear system;oled;plasma display;spreadsheet;television;thin-film transistor;thin-film-transistor liquid-crystal display;time series	Chen-Chun Lin;Chun-Ling Lin;Joseph Z. Shyu	2014	Knowl.-Based Syst.	10.1016/j.knosys.2014.08.004	prediction;statistics	ML	11.626991100884405	-17.96324271110419	58872
5531300f080ecb5a20145d0fadf238a07a64c3d4	real-time reliability prediction for dynamic systems with both deteriorating and unreliable components	integrated approach;time varying;reliability;failure prognostics;real time;fault prediction;dynamic system;dynamic systems;xu zhengguo ji yindong zhou donghua 可靠性预测 系统级 实时 恶化 组件 相互作用多模型 故障过程 组成部分 real time reliability prediction for dynamic systems with both deteriorating and unreliable components;linear functionals;predictive maintenance;particle filter;random variable;particle filtering;exponential smoothing;monte carlo;computer simulation;interacting multiple model	As an important technology for predictive maintenance, failure prognosis has attracted more and more attentions in recent years. Real-time reliability prediction is one effective solution to failure prognosis. Considering a dynamic system that is composed of normal, deteriorating and unreliable components, this paper proposes an integrated approach to perform real-time reliability prediction for such a class of systems. For a deteriorating component, the degradation is modeled by a time-varying fault process which is a linear or approximately linear function of time. The behavior of an unreliable component is described by a random variable which has two possible values corresponding to the operating and malfunction conditions of this component. The whole proposed approach contains three algorithms. A modified interacting multiple model particle filter is adopted to estimate the dynamic system’s state variables and the unmeasurable time-varying fault. An exponential smoothing algorithm named the Holt’s method is used to predict the fault process. In the end, the system’s reliability is predicted in real time by use of the Monte Carlo strategy. The proposed approach can effectively predict the impending failure of a dynamic system, which is verified by computer simulations based on a three-vessel water tank system.	algorithm;computer simulation;dynamical system;elegant degradation;horner's method;interaction;linear function;monte carlo method;particle filter;radar tracker;real-time clock;real-time transcription;smoothing;time complexity	Zhengguo Xu;Yindong Ji;Donghua Zhou	2009	Science in China Series F: Information Sciences	10.1007/s11432-009-0179-5	computer simulation;mathematical optimization;real-time computing;particle filter;dynamical system;control theory;mathematics;statistics	Robotics	14.538729061837486	-15.069752654944281	59145
58f985be1b82cd54189e17fcaead1081aac5a8ad	integrated quality diagnosis algorithm method based on neural network and sensitivity analysis to input parameters	input parameters;control chart;sensitivity analysis;quality diagnosis;neural network	In order to find out the key input parameters, which aroused the output quality out of control during the manufacturing process, an integrated quality diagnosis algorithm for input parameters was proposed. The diagnosis method extends the traditional quality control and diagnosis method that only for the output quality of manufacturing process. It can detect the input parameters of the manufacturing process and provide sensitivities of input parameter for adjustment. Firstly, through the establishment of residual error T control chart, the quality failure situation can be detected. Then, the BN-MTY method was applied to explain the reason of quality failure in T control chart and the root output quality characteristic that aroused the process quality anomaly was located. The integrated method of neural network and sensitivity analysis was used to get the weight and threshold value of never cell in the forecasting network. They were applied to calculate the sensitivities of input parameters to the root output quality. Sensitivities represent the importance of the input parameters to the output quality failure. This integrated quality diagnosis method can both diagnose the output quality characteristics and the input parameters.	anomaly detection;artificial neural network;input/output;medical algorithm;parameter (computer programming)	Wen-jie Xu;Jin Yao	2013	JNW	10.4304/jnw.8.6.1307-1314	control chart;computer science;sensitivity analysis;artificial neural network	Graphics	13.015734947469857	-17.53663571665418	59367
70327147639fecad2d1e23db64c2491c81afd190	twenty questions, focus of attention, and a*: a theoretical comparison of optimization strategies	decision tree;bayesian probability theory;search algorithm;dynamic program;artificial intelligent;optimization problem;focus of attention;aerial photograph	Many vision problems involve the detection of the boundary of an object, like a hand, or the tracking of a one-dimensional structure, such as a road in an aerial photograph. These problems can be formulated in terms of Bayesian probability theory and hence expressed as optimization problems on trees or graphs. The twenty questions, or minimum entropy, algorithm has recently been developed by Geman and Jedynak (1994) as a highly effective, and intuitive, tree search algorithm for road tracking. In this paper we analyse this algorithm to understand how it compares to existing algorithms used for vision, and related, optimization problems. First we show that it is a special case of the focus of attention planning strategy used on causal graphs, or Bayes nets, [18]. We then show its relations to standard methods, already successfully applied to vision optimization problems, such as dynamic programming, decision trees, the A* algorithm used in artificial intelligence [22] and the, closely related, Dijkstra algorithm of computer science [4]. These comparisons show that twenty questions is often equivalent to an algorithm, which we call A+, which tries to explore the most probable paths first. We show that A+ is a greedy, and suboptimal, variant of A*. This suggests that A+ and twenty questions will be faster than A* and Dijkstra for certain problems but they may occasionally converge to the wrong answer. However, the fact that A+ and twenty questions maintain a probabilistic estimate of how well they are doing may give warning of faulty convergence and also allow intelligent pruning to speed up the search.	program optimization	Alan L. Yuille;James M. Coughlan	1997		10.1007/3-540-62909-2_81	optimization problem;simulation;computer science;artificial intelligence;machine learning;decision tree;aerial photography;search algorithm	Vision	19.360930806237274	-12.98977619084153	59420
a8fa41b2a9ac8609fa7098b53695310dfa7379e2	revising engineering models: combining computational discovery with knowledge	teledetection spatiale;learning algorithm;model combination;space remote sensing;intelligence artificielle;algorithme apprentissage;domain knowledge;teledeteccion espacial;hybrid approach;machine learning;decouverte connaissance;mathematical model;artificial intelligence;descubrimiento conocimiento;inteligencia artificial;algoritmo aprendizaje;knowledge discovery	Developing mathematical models that represent physical devices is a difficult and time consuming task. In this paper, we present a hybrid approach to modeling that combines machine learning methods with knowledge from a human domain expert. Specifically, we propose a system for automatically revising an initial model provided by an expert with an equation discovery program that is tightly constrained by domain knowledge. We apply our system to learning an improved model of a battery on the International Space Station from telemetry data. Our results suggest that this hybrid approach can reduce model development time and improve model quality.	computation	Stephen D. Bay;Daniel G. Shapiro;Pat Langley	2002		10.1007/3-540-36755-1_2	simulation;computer science;artificial intelligence;machine learning;mathematical model;knowledge extraction;domain knowledge	AI	13.845331051839246	-21.80517384256219	59471
617e270b1493e4c35ef8e272d505afdcd3f64969	collision avoidance in multi-robot systems based on multi-layered reinforcement learning	mobile robot;reinforcement learning;multi robot system;adaptive behavior;local community;local communication;multi layered learning;collision avoidance	It is important for a robot to acquire adaptive behaviors for avoiding surrounding robots and obstacles in complicated environments. Although the introduction of a learning scheme is expected to be one of the solutions for this purpose, a large size of memory and a large calculation cost are required to handle useful information such as motions of robots. In this paper, we introduce the multi-layered reinforcement learning method. By dividing a learning curriculum into multiple layers, the number of expected situations can be reduced. It is shown that real robots can adaptively avoid collision with each other and to obstacles in a complicated situation. © 1999 Elsevier Science B.V. All right reserved.	reduction (complexity);reinforcement learning;robot	Yoshikazu Arai;Teruo Fujii;Hajime Asama;Hayato Kaetsu;Isao Endo	1999	Robotics and Autonomous Systems	10.1016/S0921-8890(99)00035-4	mobile robot;robot learning;error-driven learning;simulation;computer science;artificial intelligence;adaptive behavior;machine learning;reinforcement learning	Robotics	18.49432409293983	-21.42695568202546	59480
61c989176176cf02a56958d6805a250a9138da5a	a multi-agent reinforcement learning approach to robot soccer	multi agent system;reinforcement learning;robot soccer;probabilistic neural network	In this paper, a multi-agent reinforcement learning method based on action prediction of other agent is proposed. In a multi-agent system, action selection of the learning agent is unavoidably impacted by other agents’ actions. Therefore, joint-state and joint-action are involved in the multi-agent reinforcement learning system. A novel agent action prediction method based on the probabilistic neural network (PNN) is proposed. PNN is used to predict the actions of other agents. Furthermore, the sharing policy mechanism is used to exchange the learning policy of multiple agents, the aim of which is to speed up the learning. Finally, the application of presented method to robot soccer is studied. Through learning, robot players can master the mapping policy from the state information to the action space. Moreover, multiple robots coordination and cooperation are well realized.	action selection;approximation algorithm;artificial neural network;experiment;fuzzy control system;fuzzy logic;fuzzy rule;multi-agent system;probabilistic neural network;rl (complexity);real-time transcription;reinforcement learning;requirement;robot;robotic mapping;serial ata;state space;visual intercept	Yong Duan;Baoxia Cui;Xinhe Xu	2011	Artificial Intelligence Review	10.1007/s10462-011-9244-8	robot learning;error-driven learning;probabilistic neural network;simulation;computer science;artificial intelligence;machine learning;learning classifier system;reinforcement learning	AI	18.44757462830533	-20.242964517751172	59485
1a13bf52a80c542850d690c0f3963ab9399f1900	comparison of ann and principal component analysis-multivariate linear regression models for predicting the river flow based on developed discrepancy ratio statistic	artificial neural networks;developed discrepancy ratio statistic;principal component analysis;stream flow;water resource management;monthly flow;artificial neural network;multivariate linear regression	Predicting the stream flow is one of the most important steps in the water resources management. Artificial neural network (ANN) has been suggested and applied for this purpose by many of researchers. In such studies for verification and comparison of ANN results usually the popular methods such as multivariate linear regression (MLR) is used. Unfortunately, the presented methodology in some researches is faced with some problems. Thus, in this paper we have tried to find out the deficiencies of them and subsequently to present a correct the MLR methodology based on principal component analysis (PCA) for prediction of monthly stream flow. Then, assessment of different training functions on ANN operation is investigated and the best training function for optimizing the ANN parameters is selected. Afterward, the imperfections of the discrepancy ration (DR) statistic are remedied and a proper DR statistic is developed. Finally, the error distribution for testing stage of MLR and ANN models are calculated using developed DR statistic. The results of comparison show that the presented methodology in this research has improved the MLR operation. Also, comparing with the MLR, the ANN model possesses satisfactory predicting performance. 2010 Elsevier Ltd. All rights reserved.	artificial neural network;discrepancy function;general linear model;learning to rank;low-discrepancy sequence;principal component analysis	Roohollah Noori;Amir Khakpour;Babak Omidvar;Ashkan Farokhnia	2010	Expert Syst. Appl.	10.1016/j.eswa.2010.02.020	econometrics;computer science;machine learning;bayesian multivariate linear regression;streamflow;artificial neural network;statistics;principal component analysis	AI	11.361744854410842	-19.315200989618805	59804
8139b9b0aa0dda3f2f6fc1cfdd1a9a34f88281bf	nonlinear system identification of large-scale smart pavement systems	fuzzy logic;pipe network;system identification;smart pavement system;adaptive neuro fuzzy inference system anfis;neural network	This paper proposes a novel model for predicting complex behavior of smart pavements under a variety of environmental conditions. The mathematical model is developed through an adaptive neuro fuzzy inference system (ANFIS). To evaluate the effectiveness of the ANFIS model, the temperature fluctuations at different locations in smart pavement systems equipped with pipe network systems under solar radiations is investigated. To develop the smart pavement ANFIS model, various sets of input and output field experimental data are collected from large-scale experimental test beds. The solar radiation and the inlet water flow are used as input signals for training complex behavior of the smart pavement ANFIS model, while the temperature fluctuation of the smart pavement system is used for the output signal. The trained model is validated using 20 different data sets that are not used for the training process. It is demonstrated from the simulation that the ANFIS identification approach is effective in modeling complex behavior of the pavement-fluid system under a variety of environmental conditions. Comparison with high fidelity data proves the viability of the proposed approach in pavement health monitoring setting, as well as automatic control systems.	nonlinear system identification	Yeesock Kim;Rajib Mallick;Sankha Bhowmick;Baoliang Chen	2013	Expert Syst. Appl.	10.1016/j.eswa.2012.12.062	fuzzy logic;simulation;system identification;adaptive neuro fuzzy inference system;computer science;artificial intelligence;machine learning;artificial neural network	HCI	10.72023315257928	-18.74611859090521	59859
7e2f49c5e7cffad962af295fc4b175d9ec534abd	effluent quality prediction of wastewater treatment plant based on fuzzy-rough sets and artificial neural networks	nh 3 wastewater treatment plant fuzzy rough set artificial neural network ammonia nitrogen chemical oxygen demand total nitrogen removal soft computing approach backpropagation neural networks cod concentration effluent quality prediction;ammonia nitrogen;total nitrogen removal;total nitrogen;performance indicator;soft computing neural network fuzzy rough sets input variable selection wastewater treatment prediction;soft computing approach;neural nets;effluents;rough set theory;soft computing;model performance;nh 3;backpropagation;chemical oxygen demand;fuzzy set theory;fuzzy rough set;artificial neural networks;computational modeling;wastewater treatment plant;input variable selection;mathematical model;rough sets;predictive models;fuzzy rough sets;backpropagation neural networks;wastewater treatment backpropagation effluents fuzzy set theory neural nets rough set theory;rough set;prediction;back propagation;effluents wastewater treatment artificial neural networks predictive models chemical processes nitrogen computer networks demand forecasting set theory neural networks;wastewater treatment;effluent quality prediction;artificial neural network;cod concentration;data models;neural network;nitrogen	Effluent ammonia-nitrogen (NH3-N), chemical oxygen demand (COD) and total nitrogen (TN) removals are the most common environmental and process performance indicator for all types of wastewater treatment plants (WWTPs). In this paper, a soft computing approach based on the back propagation (BP) neural networks and fuzzy-rough sets (FR-BP) has been applied for forecasting effluent NH3-N, COD and TN concentration of a real WWTP, in which the fuzzy-rough sets theory is employed to perform input selection of neural network which can reduce the influence due to the drawbacks of BP such as low training speed and easily affected by noise and weak interdependency data. The model performance is evaluated with statistical parameters and the simulation results indicates that the FR-BP modeling approach achieves much more accurate predictions as compared with the other traditional modeling approaches.	backpropagation;feature selection;interdependence;knowledge representation and reasoning;neural networks;real-time computing;rough set;sensor;simulation;soft computing;software propagation;twisted nematic field effect;whole earth 'lectronic link	Fei Luo;Ren-hui Yu;Yuge Xu;Yan Li	2009	2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2009.494	rough set;computer science;artificial intelligence;machine learning;artificial neural network	Robotics	12.126847151967363	-20.709123484456537	59876
fe29ae9cfcd3e02e20b99b46c0f22d99e7055527	use of adaptive network fuzzy inference system to predict plasma charging damage on electrical mosfet properties	root mean square error;metal oxide semiconductor field effect transistors;regression model;process parameters;threshold voltage;membership function;fuzzy inference system;plasma;prediction model;electrical properties;charging damage;adaptive network fuzzy inference system;metal oxide semiconductor field effect transistor	A prediction model of plasma-induced charging damage is presented. The model was constructed using adaptive network fuzzy inference system (ANFIS). The prediction performance of ANFIS model was optimized as a function of training factors, including a step-size, a normalization factor, and type of membership function. Charging damage data were obtained from antenna-structured MOSFET with the variations in process parameters. For a systematic modeling, the experiment was characterized by means of a face-centered Box Wilson experiment. Electrical properties modeled include a threshold voltage (V), a subthreshold swing (S), and a transconductance (G). Both S and G were found to be considerably affected by the normalization factor. For the variations in the type of membership function, either V or S was the most significantly influenced. The optimized root mean square errors are about 0.041 (V), 5.040 (mV/decade), and 12.311 (x10^-^6/@W), respectively. Better predictions were demonstrated against statistical regression models and the improvements were even more than 15% for V and S models.	inference engine;plasma active	Byungwhan Kim;Hee Ju Kwon;Seongjin Choi	2009	Expert Syst. Appl.	10.1016/j.eswa.2008.07.034	plasma;membership function;computer science;machine learning;mean squared error;predictive modelling;threshold voltage;regression analysis	AI	13.439169803384795	-19.538986755940588	59941
6efc4c22c7dc4e6f1e4374e500e1972351ae49eb	parallel investigations of the dynamics of neural microcircuits	neural microtechnology;neural model;neural nets;chaos;computer model;biological system modeling;small world;hodgkin huxley based model neural microcircuit many core system multicore system computational neuroscience simulation spiking neural microcircuit parallelisation technique biologically based neural model small world neural network openmp parallelisation;computational neuroscience simulation;computational neuroscience;computational modeling;parallel processing multiprocessing systems neural nets;multicore system;neural microcircuit;many core system;mathematical model;small world neural network;spiking neural microcircuit;biologically based neural model;biological information theory;parallel implementation;hodgkin huxley based model;multiprocessing systems;biological system modeling computational modeling neurons neural microtechnology biological information theory chaos mathematical model;neurons;openmp parallelisation;simulation model;parallelisation technique;parallel processing;hodgkin huxley;information theory;neural network	The advent of multicore and many core technologies opens new frontiers in computational sciences, making possible intensive computations on affordable computer systems. Our ongoing work is focused on the investigation of the suitability of many core and multicore systems to computational neuroscience simulations. We aim at providing a deeper understanding of the influence the various parallelisation techniques have on the dynamics of spiking neural microcircuits -- as they show an almost chaotic behaviour. For that, we are developing a methodology for the evaluation of parallel implementations of biologically-based neural models and small world neural networks. Following our methodology, we designed a framework to assess the behaviour and performance of different parallel and sequential implementations of simulation models and techniques. We present first results obtained on multicore systems with OpenMP parallelisation of Hodgkin-Huxley based-models.	algorithm;artificial neural network;cns;chaos theory;computation;computational neuroscience;computational science;fractal dimension;hodgkin–huxley model;huxley: the dystopia;interconnection;manycore processor;multi-core processor;openmp;parallel computing;prototype;simulation	Ioan Lucian Muntean;Marius Joldos;Ilinca Raluca Ban;Iulia Maria Morariu	2011	2011 10th International Symposium on Parallel and Distributed Computing	10.1109/ISPDC.2011.47	computer science;artificial intelligence;theoretical computer science;simulation modeling;mathematical model;computational model;artificial neural network;hodgkin–huxley model	HPC	15.486480888606069	-10.605000988396993	60177
42f8290254f5abca4b046a8cb21c8a73f6a4db86	prediction of gas chromatographic retention index for hydrocarbons in fcc gasoline	multiple linear regression;quantitative structure retention relationships qsrr;chemical engineering computing;multiple linear regression mlr;petrochemicals;neural nets;quantitative structure retention relationships;multiple linear regression gas chromatographic retention index fcc gasoline hydrocarbons quantitative structure retention relationships molecular descriptors dragon software artificial neural network;hydrocarbons fcc petroleum computer science;gas chromatograph;fcc gasoline;data mining;production engineering computing;gas chromatographic retention index;petroleum;retention index;artificial neural network ann quantitative structure retention relationships qsrr retention index ri multiple linear regression mlr;dragon software;molecular descriptor;regression analysis chemical engineering computing chromatography neural nets petrochemicals petroleum petroleum industry production engineering computing;retention index ri;petroleum industry;hydrocarbons;molecular descriptors;regression analysis;computer science;correlation coefficient;artificial neural network ann;chromatography;artificial neural network	A series of hydrocarbons in FCC gasoline have been used to develop quantitative structure-retention relationships (QSRR) for their gas chromatographic retention index (RI) by using molecular descriptors which were calculated by Dragon software. QSRR models were built by adopting Multiple Linear Regression (MLR) and Artificial Neural Network (ANN). However, the results showed more or less the same quality with the predictive correlation coefficient R of 0.9952 and 0.9953 for MLR and ANN respectively. The obtained results told us that linear method is good enough to model the gas chromatographic retention index at least to the current dataset.	artificial neural network;coefficient;learning to rank;molecular descriptor;principle of good enough	Ling Ding;Xiaotong Zhang;Zhaolin Sun;Lijuan Song;Ting Sun	2009	2009 WRI World Congress on Computer Science and Information Engineering	10.1109/CSIE.2009.302	molecular descriptor;econometrics;computer science;machine learning;artificial neural network	ML	11.8942029127826	-19.854826209071593	60784
a2cf7ba63e8883d6630b7a7d7730553f81b3c40c	a dynamic migration model for self-adaptive genetic algorithms	modelo dinamico;modelizacion;migracion poblacion;adaptability;adaptabilite;algorithm performance;incertidumbre;algoritmo adaptativo;uncertainty;adaptive genetic algorithm;search space;computer science information science engineering;dynamic model;population size;mutation rate;taille population;population migration;migration population;intelligence artificielle;algoritmo genetico;adaptabilidad;modelisation;adaptive algorithm;algorithme adaptatif;resultado algoritmo;modele dynamique;decouverte connaissance;performance algorithme;algorithme genetique;artificial intelligence;descubrimiento conocimiento;genetic algorithm;incertitude;inteligencia artificial;modeling;tamano poblacion;knowledge discovery;others	In this paper, we propose a self Adaptive Migration Model for Genetic Algorithms, where parameters of population size, the number of points of crossover and mutation rate for each population are fixed adaptively. Further, the migration of individuals between populations is decided dynamically. This paper gives a mathematical schema analysis of the method stating and showing that the algorithm exploits previously discovered knowledge for a more focused and concentrated search of heuristically high yielding regions while simultaneously performing a highly explorative search on the other regions of the search space. The effective performance of the algorithm is then shown using standard testbed functions, when compared with Island model GA(IGA) and Simple GA(SGA).	genetic algorithm	K. G. Srinivasa;Karthik Sridharan;P. Deepa Shenoy;K. R. Venugopal;Lalit M. Patnaik	2005		10.1007/11508069_72	mutation rate;population size;adaptability;systems modeling;genetic algorithm;uncertainty;computer science;artificial intelligence;knowledge extraction;algorithm	NLP	23.458763177505343	-10.84317792008481	60968
887a2c8e68ba6ab3bde530f688e7f4897d1ed49c	a malicious attack on the machine learning policy of a robotic system		The field of robotics has matured using artificial intelligence and machine learning such that intelligent robots are being developed in the form of autonomous vehicles. The anticipated widespread use of intelligent robots and their potential to do harm has raised interest in their security. This research evaluates a cyberattack on the machine learning policy of an autonomous vehicle by designing and attacking a robotic vehicle operating in a dynamic environment. The primary contribution of this research is an initial assessment of effective manipulation through an indirect attack on a robotic vehicle using the Q learning algorithm for real-time routing control. Secondly, the research highlights the effectiveness of this attack along with relevant artifact issues.	algorithm;artificial intelligence;autonomous car;autonomous robot;machine learning;q-learning;real-time clock;routing	George W. Clark;Michael V. Doran;William Glisson	2018	2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE)	10.1109/TrustCom/BigDataSE.2018.00079	q-learning;robot;machine learning;computer science;robotics;artificial intelligence	Robotics	17.98866090464069	-19.288296345452096	61044
19b0f05e7053b00661d14980560d4393949a14c9	estimating the maximum expected value in continuous reinforcement learning problems		This paper is about the estimation of the maximum expected value of an infinite set of random variables. This estimation problem is relevant in many fields, like the Reinforcement Learning (RL) one. In RL it is well known that, in some stochastic environments, a bias in the estimation error can increase step-by-step the approximation error leading to large overestimates of the true action values. Recently, some approaches have been proposed to reduce such bias in order to get better action-value estimates, but are limited to finite problems. In this paper, we leverage on the recently proposed weighted estimator and on Gaussian process regression to derive a new method that is able to natively handle infinitely many random variables. We show how these techniques can be used to face both continuous state and continuous actions RL problems. To evaluate the effectiveness of the proposed approach we perform empirical comparisons with related approaches.	algorithm;approximation error;bellman equation;computation;discretization;estimation theory;experiment;global positioning system;kriging;online and offline;reinforcement learning;robustness (computer science);state space;windows me	Carlo D'Eramo;Alessandro Nuara;Matteo Pirotta;Marcello Restelli	2017			machine learning;q-learning;mathematical optimization;computer science;expected value;reinforcement learning;pattern recognition;artificial intelligence	AI	23.006581654871926	-19.39895585460761	61170
73f486c225498b14ca51d642ef37e4493c5d2c64	regression kernel for prognostics with support vector machines		Estimating the remaining useful life (RUL) of systems and/or equpipments has been an important goal for reliable, safe, and profitable operation of industrial plants. However, traditional mathematical and statistical modeling based approaches are difficult to design and they adapt poorly to the ever changing operating and environmental conditions in real-world industries. With recent developments in computational technologies, data storage, and industrial automation recording and storage of large amounts of historical plant data from embedded sensors and maintenance records have become easy. Availability of large data sets together with advancements in data driven machine learning algorithms has been the key driver for prognostic and diagnostic research in the industry as well as by academia. Nevertheless, developing generalized machine learning algorithms for the prognostic domain has been challenging due to the very nature of the problem. This paper describes some of these challenges and proposes a modified regression kernel that can be used by support vector regression (SVR) for prognostic problems. The method is tested on a simplified simulated time-series data set that is modeled to represent the challenges presented.	approximation algorithm;automation;computation;computer data storage;embedded system;kernel (operating system);machine learning;scheduling (computing);sensor;simulation;statistical model;support vector machine;time series	Josey Mathew;Ming Luo;Chee Khiang Pang	2017	2017 22nd IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)	10.1109/ETFA.2017.8247740	predictive maintenance;real-time computing;data mining;automation;support vector machine;data modeling;engineering;prognostics;statistical model;data set;computer data storage	Robotics	13.85437053519285	-16.336823250248813	61615
2b337a2f8edd4ecf9f82e5194bf9d2ed34cd48cc	exploring the effect rules of paddy drying on a deep fixed-bed		In this paper, a series of paddy drying experiments were conducted on a deep fixed-bed and we investigated the effect rules of five influencing parameters on drying time of paddy. By using the quadratic orthogonal rotation combination design, the nonlinear function between the drying time and the five influencing parameters are built up. Then a detailed study of the qualitative and quantitative effect rules of each influencing factor is elaborated. The results of this paper conclude the rules of how drying parameters influencing the dry time of paddy. And also, it reveals how to reduce paddy drying time and improve the productivity, which have significance in practical productions.		Danyang Wang;Chenghua Li;Benhua Zhang;Ling Tong	2015		10.1007/978-3-319-48357-3_45	mathematical optimization;mathematics	ECom	12.70940282223763	-19.62073808651986	61783
43f296d5fa2101433417b7a0a514eb852893d5af	gambling in a rigged casino: the adversarial multi-armed bandit problem	rate of convergence;stochastic games game theory;convergence;communication networks;game theory;stochastic process;routing;well behaved stochastic process;bandit problem;machine learning;stochastic processes;matrix game;process control;statistics;arm;matrix game multi armed bandit problem slot machines bandit problem well behaved stochastic process rate of convergence;costs statistics stochastic processes process control convergence machine learning arm communication networks routing;multi armed bandit problem;stochastic games;slot machines	In the multi-armed bandit problem, a gambler must decide which arm ofKnon-identical slot machines to play in a sequence of trials so as to maximize his reward. This classical problem has received much attention because of the simple model it provides of the trade-off between exploration (trying out each arm to find the best one) and exploitation (playing the arm believed to give the best payoff). Past solutions for the bandit problem have almost always relied on assumptions about the statistics of the slot machines. In this work, we make no statistical assumptions whatsoever about the nature of the process generating the payoffs of the slot machines. We give a solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs. In a sequence of T plays, we prove that the expected per-round payoff of our algorithm approaches that of the best arm at the rate	adversary (cryptography);algorithm;casino;exploit (computer security);multi-armed bandit;stochastic process	Peter Auer;Nicolò Cesa-Bianchi;Yoav Freund;Robert E. Schapire	1995	Electronic Colloquium on Computational Complexity (ECCC)	10.1109/SFCS.1995.492488	stochastic process;mathematical optimization;routing;convergence;multi-armed bandit;computer science;artificial intelligence;machine learning;mathematics;rate of convergence;arm architecture;statistics	Theory	23.208825458368274	-17.537908583904027	61941
adb925a9e774bf6e1dec94a1ee71aa369a9a0894	a study of machine learning using the game of fox and geese	machine learning	The game Fox and Geese is solved using retrograde analysis. A neural network trained using a co-evolutionary genetic algorithm with the help of the expert knowledge database was found to be a very capable Fox and Geese player after training, and quickly learned to beat training opponents. Key-Words: Game theory, rote-learning, neural networks, genetic algorithms, co-evolution.	artificial neural network;game theory;genetic algorithm;machine learning	Kenneth Chisholm;Donald Fleming	2005			artificial intelligence;simulation;machine learning;computer science	ML	18.5767236351375	-18.274241673407392	62045
452ac69a8af5366778f3be178966433f2b6bf70a	concrete dropout		Dropout is used as a practical tool to obtain uncertainty estimates in large vision models and reinforcement learning (RL) tasks. But to obtain well-calibrated uncertainty estimates, a grid-search over the dropout probabilities is necessary— a prohibitive operation with large models, and an impossible one with RL. We propose a new dropout variant which gives improved performance and better calibrated uncertainties. Relying on recent developments in Bayesian deep learning, we use a continuous relaxation of dropout’s discrete masks. Together with a principled optimisation objective, this allows for automatic tuning of the dropout probability in large models, and as a result faster experimentation cycles. In RL this allows the agent to adapt its uncertainty dynamically as more data is observed. We analyse the proposed variant extensively on a range of tasks, and give insights into common practice in the field where larger dropout probabilities are often used in deeper model layers.	concrete security;deep learning;dropout (neural networks);linear programming relaxation;mathematical optimization;reinforcement learning;variational principle	Yarin Gal;Jiri Hron;Alex Kendall	2017			machine learning;computer science;artificial intelligence;deep learning;reinforcement learning;bayesian probability	ML	22.174247119502326	-20.536397038011582	62455
148e3734817eb184fb04b134cf1db11662bab354	in-process regressions and adaptive multicriteria neural networks for monitoring and supervising machining operations	multi criteria decision making;multiple criteria decision making;regression model;decision maker;tool life;monitoring system;production rate;artificial neural network;neural network	The authors develop a monitoring and supervising system for machining operations using in-process regressions (for monitoring) and adaptive feedforward artificial neural networks (for supervising). The system is designed for: (1) in-process tool life measurement and prediction; (2) supervision of machining operations in terms of the best machining setup; and (3) catastrophic tool failure monitoring. The monitoring system predicts tool life by using different sensors for gathering information based on a regression model that allows for the variations between tools and different machine setups. The regression model makes its prediction by using the history of other tools and combining it with the information obtained about the tool under consideration. The supervision system identifies the best parameters for the machine setup problem within the framework of multiple criteria decision making. The decision maker (operator) considers several criteria, such as cutting quality, production rate and tool life. To make the optimal decision with several criteria, an adaptive feedforward artificial neural network is used to assess the decision maker's preferences. The authors' neural network approach learns from the decision maker's complex behavior and hence, in automatic mode, can make decisions for the decision maker. The approach is not computationally demanding, and experiments demonstrate that its predictions are accurate.	artificial neural network;experiment;feedforward neural network;sensor;software regression	Behnam Malakooti;Ying Q. Zhou;Evan C. Tandler	1995	J. Intelligent Manufacturing	10.1007/BF00123676	decision-making;computer science;engineering;artificial intelligence;machine learning;operations research;artificial neural network;regression analysis	ML	12.869946221739632	-16.148647619824715	62565
34cd3d3e10c1c2bec649db31f77e94fe0fb7e227	optimal control of multiple csps system based on event-based q learning	manufacturing systems;optimisation;learning algorithm;learning;look ahead;optimisation conveyors learning systems manufacturing systems multivariable control systems optimal control;optimal control production systems computer science costs control systems stochastic processes sensor systems equations computer science education robotic assembly;data mining;optimal control;learning systems;control problem;performance criteria optimal control multiple csps system event based q learning multiple conveyor serviced production station system part processing rate maximization coordinate look ahead control strategy event based optimization performance potential;conveyors;mathematical model;assembly systems;optimization;multivariable control systems;control strategy;optimal control problem	The optimal control problem of multiple conveyor-serviced production station (CSPS) system is concerned, and the objective is to maximize the part-processing rate of the entire system by choosing a coordinate look-ahead control strategy for each station. According to the idea of event-based optimization, and by using the concept of performance potentials, an event-based Q-learning algorithm is proposed to solve the coordinated look-ahead control problem with either discounted or average performance criteria. A simulation example is used to illustrate the effectiveness of the proposed algorithm, and the derived results show that the part-processing rate of the entire system is increased significantly compared to that obtained by a Wolf-PHC algorithm.	algorithm;approximation;best, worst and average case;control theory;mathematical optimization;multi-agent system;optimal control;q-learning;reinforcement learning;simulation	Hao Tang;Haifeng Wan;Lei Zhou;Jianghong Han	2009	Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference	10.1109/CDC.2009.5400829	control engineering;mathematical optimization;optimal control;computer science;mathematical model;control theory;mathematics	Robotics	19.310533728476386	-18.86202538544041	62883
20096e1f9c276ed743a6c677f5d1f44e804cbe8e	accelerated bayesian learning for decentralized two-armed bandit based decision making with applications to the goore game	bandit problems;decentralized decision making;journal article;peer reviewed;bayesian learning;quality of service control;wireless sensor networks;goore game	The two-armed bandit problem is a classical optimization problem where a decision maker sequentially pulls one of two arms attached to a gambling machine, with each pull resulting in a random reward. The reward distributions are unknown, and thus, one must balance between exploiting existing knowledge about the arms, and obtaining new information. Bandit problems are particularly fascinating because a large class of real world problems, including routing, Quality of Service (QoS) control, game playing, and resource allocation, can be solved in a decentralized manner when modeled as a system of interacting gambling machines. Although computationally intractable in many cases, Bayesian methods provide a standard for optimal decision making. This paper proposes a novel scheme for decentralized decision making based on the Goore Game in which each decision maker is inherently Bayesian in nature, yet avoids computational intractability by relying simply on updating the hyper parameters of sibling conjugate priors, and on random sampling from these posteriors. We further report theoretical results on the variance of the random rewards experienced by each individual decision maker. Based on these theoretical results, each decision maker is able to accelerate its own learning by taking advantage of the increasingly more reliable feedback that is obtained as exploration gradually turns into exploitation in bandit problem based learning. Extensive experiments, involving QoS control in simulated wireless sensor networks, demonstrate that the accelerated learning allows us to combine the benefits of conservative learning, which is high accuracy, with the benefits of hurried learning, which is fast convergence. In this manner, our scheme outperforms recently proposed Goore Game solution schemes, where one has to trade off accuracy with speed. As an additional benefit, performance also becomes more stable. We thus believe that our methodology opens avenues for improved performance in a number of applications of bandit based decentralized decision making.	coat of arms;computational complexity theory;experiment;exploit (computer security);interaction;kalman filter;mathematical optimization;multi-armed bandit;optimization problem;quality of service;routing;sampling (signal processing);scheduling (computing);simulation;stationary process	Ole-Christoffer Granmo;Sondre Glimsdal	2012	Applied Intelligence	10.1007/s10489-012-0346-z	peer review;simulation;wireless sensor network;influence diagram;multi-armed bandit;computer science;artificial intelligence;machine learning;bayesian inference;statistics	AI	23.302617454057053	-17.837715427233903	62964
697e0deaa4af4b2a8cd17828e361ce91e35d342d	embedded neural network for swarm learning of physical robots	evaluation function;learning process;resource limitation;real time;dynamic environment;initial condition;autonomous robot;neural network;environmental factor	In this study we ran real time learning of multiple physical autonomous robots situated in a real dynamic environment. Each robot has an onboard micro controller where a simple neural network is embedded. The neural network was built with the consideration of the power and calculation resources limitation which is a general characteristic of simple robots. In the experiments, several autonomous robots were placed in one environment, where each of them was given a specific task which was expressed as the evaluation function for the robot's neural network. The learning processes of the robots were started simultaneously from their randomized initial conditions. The presence of several robots consequently formed a dynamic environment, in which an action of one robot affected the learning process of others. We demonstrated the efficiency of the embedded learning mechanism with respect to different environmental factors.	artificial neural network;embedded system;robot;swarm	Pitoyo Hartono;Sachiko Kakita	2008		10.1007/978-3-540-87559-8_15	mobile robot;robot learning;simulation;computer science;artificial intelligence;social robot;machine learning;evaluation function;robot control;initial value problem;artificial neural network	Robotics	17.955469300300894	-21.782391888525876	63222
7ca4746e35e39cf0a1c483c1783c804a0bcf3835	progressive mining of transition dynamics for autonomous control	reinforcement learning;optimal control control engineering computing data mining learning artificial intelligence multi agent systems;data mining transition dynamics progressive mining autonomous agent autonomous control reinforcement learning optimal control policy feature subspace identification feature selection algorithm;data mining;optimal control;multi agent systems;heuristic algorithms data mining autonomous agents sensors silicon aggregates algorithm design and analysis;control engineering computing;learning artificial intelligence;transition dynamics data;reinforcement learning progressive feature selection transition dynamics data;progressive feature selection	Autonomous agents are emerging in diverse areas and many rely on reinforcement learning (RL) to learn optimal control policies by acting in the environment. This form of learning generates large amounts of transition dynamics data, which can be mined to improve the agent's understanding of the environment. There could be many uses for this data, here we focus on mining it to identify a relevant feature subspace. This is vital since RL performs poorly in high-dimensional spaces, such as those that autonomous agents would commonly face in real-world problems. This paper demonstrates the necessity and feasibility of integrating data mining into the learning process while an agent is learning, enabling it to learn to act by both acting and understanding. Doing so requires overcoming challenges regarding data quantity and quality, and difficulty measuring feature relevance with respect to the control policy. We propose the progressive mining framework to address these challenges by relying on cyclic interaction between data mining and RL. We show that a feature selection algorithm developed under this framework, PROFESS, can improve RL scalability better than a competing approach.	autonomous agent;autonomous robot;computer performance;data mining;feature selection;mined;optimal control;reinforcement learning;relevance;scalability;selection algorithm	Steven Loscalzo;Robert William Wright;Kevin Acunto;Lei Yu	2012	2012 IEEE 12th International Conference on Data Mining	10.1109/ICDM.2012.47	error-driven learning;optimal control;computer science;artificial intelligence;machine learning;data mining;reinforcement learning	ML	19.539246465409363	-20.712888962253913	63223
6d85166a258a0d1b4dc1f5ccc959a742504b2ace	experimental comparisons with respect to the usage of the promising relations in eda-based causal discovery		A Bayesian network is a promising probabilistic model to represent causal relations between nodes (random variables). One of the major research issue in a Bayesian network is how to infer causal relations from a dataset by constructing better heuristic learning algorithms. Many kinds of approaches were so far introduced, and estimation of distribution algorithms (EDAs) are one of the promising causal discovery algorithms. However, the performance of EDAs is considerably dependent on the quality of the first population because new individuals are reproduced from the previous populations. In this paper, we introduce a new initialization method for EDAs that extracts promising candidate causal relations based on causal scores. Then, we used the promising relations to construct a better first population and to reproduce better individuals until the learning algorithm is terminated. Experimental results show that EDAs infer a more number of correct causal relations when promising relations were used in EDA based structure learning. It means that the performance of EDAs can be improved by providing better local search space, and it was the promising relations in this paper.	causal filter;electronic design automation	Song Ko;Hyunki Lim;Hoon Ko;Dae-Won Kim	2018	Annals OR	10.1007/s10479-016-2390-2	econometrics;machine learning;data mining;mathematics	NLP	21.574648842982057	-13.12272794872192	63258
8e32540ab9023783d11b369f5a561001fc3f5500	motor control and movement optimization learned by combining auto-imitative and genetic algorithms	genetic algorithm;inverse modeling;supervised learning;motor control;degree of freedom;hebbian learning;motor learning	"""In sensorimotor behaviour often a great movement execution variability is combined with a relatively low error in reaching the intended goal. This phenomenon can especially be observed if the limb chain under regard has redundant degrees of freedom. Such a redundancy, however, is a pre-requisit of movement optimization, because without variability changes in movement execution are impossible. It is, therefore, suggested, that, given a fitness criterion, a related optimal movement trajectory can be learned by an genetic algorithm. However, precise reaching must also be learned. This requires to establish at least an internal inverse model of the (forward) """"tool transformation"""" governing the physical behaviour of the limb chain. Learning of an inverse model can be performed best applying the so called autoimitation algorithm, a non-supervised learning mechanism equivalent to (modified) Hebbian learning. The paper shows theoretically, how these two learning algorithms can be combined in motor learning, and exemplifies by simulation of a three-jointed arm confined in a plane, how the problem of combining goal invariance under motor variability with movement optimization can be solved practically in a biologically plausible manner."""	genetic algorithm;heart rate variability;hebbian theory;machine learning;mathematical optimization;piaget's theory of cognitive development;robotic arm;simulation;spatial variability;supervised learning	Karl-Theodor Kalveram;Ulrich Nakte	2001			supervised learning;machine learning;semi-supervised learning;competitive learning;motor learning;motor control;active learning (machine learning);stability (learning theory);computer science;leabra;artificial intelligence	ML	18.676926447527833	-21.987143205392982	63313
db6328e4bf6ffdc1b990b324413994ccc0ec67d6	the move-decision strategy of indigo	urgent move selection;quick & slow evaluation;strategic evaluation;single-agent & two-agent search.;computer go;evaluation function	This paper describes the move decision strategy of Indigo. By using the example of Indigo, the paper shows that the move decision process of a Go program can be very different from the processes used in other games with lower complexity than the complexity of Go, even if the basic modules are conventional (move generator, evaluation function and tree search). Indigo uses them in a specific way, adapted to computer Go, which may be of interest for researchers on other mind games as complex as Go. The evaluation function can be “quick”, “slow” or “strategic”. It may or may not include local tree search. The move generation brings about different kinds of moves : “urgent” moves, “life and death” moves and “calm” moves. Urgent moves are statically qualified with a global urgency. A two-player quiescence search verifies that the urgent move does not decrease the position evaluation. Calm moves are used within two-player selective global search at a very low depth. Besides, Indigo also uses single-agent search to refine the strategic importance of goals. Lastly, Indigo chooses either the calm move, the life and death move or the urgent move to be the global move. keywords: computer go, quick & slow evaluation, strategic evaluation, urgent move selection, single-agent & two-agent search.	computer go;decision theory;evaluation function;life & death;quiescence search	Bruno Bouzy	2003	ICGA Journal	10.3233/icg-2003-26105	simulation;indigo;evaluation function;artificial intelligence;computer go;computer science	AI	18.780009824246868	-12.518648746773113	63337
c1191731801db1846bc0fdbc0232643cae2f0ddf	joint data-driven fault diagnosis integrating causality graph with statistical process monitoring for complex industrial processes		In this paper, an integrated fault diagnosis method is proposed to deal with fault location and propagation path identification. A causality graph is first constructed for the system according to the a priori knowledge. Afterward, a correlation index (CI) based on the partial correlation coefficient is proposed to analyze the correlation of variables in causality graph quantitatively. To achieve accurate fault detection results, the proposed CI is monitored by probability principal component analysis. Moreover, the concept of weighted average value is introduced to identify fault propagation path based on reconstruction-based contribution and causality graph after detecting a fault. Finally, the new proposed scheme would be practiced with real industrial HSMP data, where the individual steps as well as the complete framework were extensively tested.	causality;coefficient;fault detection and isolation;principal component analysis;sensor;software propagation	Jie Dong;Mengyuan Wang;Xiong Zhang;Liang Ma;Kaixiang Peng	2017	IEEE Access	10.1109/ACCESS.2017.2766235	computer science;principal component analysis;statistical process control;causality;machine learning;fault detection and isolation;artificial intelligence;weighted arithmetic mean;graph;partial correlation	EDA	13.385025200737891	-14.250595133100855	63468
1c81407966fecf668186c3bcda39c58fc07a7e7f	detecting and correcting model anomalies in subspaces of robot planning domains	single and multi agent learning;fault tolerance and resilience;robot planning and plan execution;multi robot systems	Making decisions based on accurate models enables robots to exploit domain knowledge to act intelligently. However, in many realistic domains, it is impossible to have globally accurate models, as the world may exhibit modes of behavior during deployment that were unforeseeable during model building. This paper addresses the problem of adaptation in domains in which robots have access to a model of the world that is generally accurate, but which is inadequate in particular sets of similar situations –i.e., subspaces of the task domain. Using optimization techniques to find parametric approximations to these subspaces, our framework generalizes from sparse observations to find and correct for statistical incongruences between expected and observed behavior. We demonstrate this framework in a domain in which single deployment adaptation is essential: a team of soccer robots keeping the ball away from a previously unknown opponent. Empirical results show that the framework improves model accuracy and task performance over timescales comparable to a single soccer game.	approximation;feature vector;mathematical optimization;robot;sensor;software deployment;sparse matrix	Juan Pablo Mendoza;Manuela M. Veloso;Reid G. Simmons	2015			simulation;artificial intelligence;machine learning	Robotics	20.993901596450083	-20.77120965126518	63471
8ab5767205b3de9a75cae470f7b29613051d0529	genetic optimization-driven multi-layer hybrid fuzzy neural networks	fuzzy neural network;comparative analysis;polynomial neural network;rule based;genetics;hybrid fuzzy neural networks;genetic algorithm;multi layer perceptron;parametric optimization;numerical experiment;fuzzy neural networks;group method of data handling;polynomial neural networks;back propagation;genetic optimization;design methodology	In this study, we introduce a new architecture of hybrid fuzzy neural networks (gHFNNs) and offer a comprehensive design methodology that supports their development. The gHFNN rule-based architecture results from a synergistic usage of Fuzzy Neural Networks (FNNs) with Polynomial Neural Networks (PNNs). The FNN contributes to the formation of the premise part of the overall network of the gHFNN. The consequence part of the gHFNN is designed taking advantage of PNNs. The optimization of the FNN is realized with the aid of a standard back-propagation learning combined with genetic optimization. The development of the PNN dwells on the extended Group Method of Data Handling (GMDH) and Genetic Algorithms (GAs). Through the consecutive process of such structural and parametric optimization, an optimized topology of the PNN becomes generated in a dynamic fashion. The performance of the gHFNN is evaluated through a series of numeric experiments. A comparative analysis shows that the proposed gHFNN is characterized by higher accuracy as well as significant predictive capabilities when contrasted with other neurofuzzy models presented in the literature. 2005 Elsevier B.V. All rights reserved.	backpropagation;experiment;genetic algorithm;group method of data handling;layer (electronics);logic programming;mathematical optimization;neural networks;polynomial;qualitative comparative analysis;software propagation;synergy	Sung-Kwun Oh;Witold Pedrycz	2006	Simulation Modelling Practice and Theory	10.1016/j.simpat.2005.10.009	rule-based system;qualitative comparative analysis;genetic algorithm;design methods;computer science;artificial intelligence;backpropagation;machine learning;group method of data handling;data mining;multilayer perceptron	AI	10.867347725847257	-23.37406117200221	63542
3bf79ecb9216e44066a7e27527e2a0a9de37bf6f	an innovative approach for modeling of hysteretic energy demand in steel moment resisting frames		This paper presents a new nonlinear model for the prediction of hysteretic energy demand in steel moment resisting frames using an innovative genetic-based simulated annealing method called GSA. The hysteretic energy demand was formulated in terms of several effective parameters such as earthquake intensity, number of stories, soil type, period, strength index, and energy imparted to the structure. The performance and validity of the model were further tested using several criteria. The proposed model provides very high correlation coefficient (R = 0.985), and low root mean absolute error (RMSE = 1,346.1) and mean squared error (MAE = 1,037.6) values. The obtained results indicate that GSA is an effective method for the estimation of the hysteretic energy. The proposed GSA-based model is valuable for routine design practice. The prediction performance of the optimal GSA model was found to be better than that of the existing models.	approximation error;coefficient;effective method;framing (world wide web);global storage architecture;hysteresis;mean squared error;nonlinear system;simulated annealing	Amir Hossein Gandomi;Amir Hossein Alavi;Abazar Asghari;Hadi Niroomand;Ali Matin Nazar	2013	Neural Computing and Applications	10.1007/s00521-013-1342-x	simulation	SE	11.339152264008108	-17.8135630483874	63590
4fe47e871a7e868cd53e529e9df2a53789fa32fa	a strategy-aware technique for learning behaviors from discrete human feedback	learning from feedback;reinforcement learning;bayesian inference;learning from demonstration;machine learning;expectation maximization;dog training;interactive learning;technical report	This paper introduces two novel algorithms for learning behaviors from human-provided rewards. The primary novelty of these algorithms is that instead of treating the feedback as a numeric reward signal, they interpret feedback as a form of discrete communication that depends on both the behavior the trainer is trying to teach and the teaching strategy used by the trainer. For example, some human trainers use a lack of feedback to indicate whether actions are correct or incorrect, and interpreting this lack of feedback accurately can significantly improve learning speed. Results from user studies show that humans use a variety of training strategies in practice and both algorithms can learn a contextual bandit task faster than algorithms that treat the feedback as numeric. Additionally, simulated trainers are employed to evaluate the algorithms in both contextual bandit and sequential decision-making tasks with similar results. Introduction A significant body of work exists on the problem of learning from human trainers [12, 7, 3], and specifically on the problem of learning from trainer-provided feedback [6, 9]. Existing work can be grouped into two broad categories: (1) learning from demonstration, which treats inputs from human trainers as examples of some target behavior; and (2) learning from trainer-provided feedback, which models the learning problem as a reinforcementlearning task. While exciting developments have been made in both these areas, we argue neither is always an appropriate model for learning in a common paradigm of human teaching. First, providing examples of behavior is not always feasible or desirable. Second, the positive or negative feedback given by humans is not representative of a numerical reward value. Feedback is a form of discrete communication between a trainer and a learning agent. Accordingly, that communication can be implemented using a few different training strategies that describe how trainers choose what feed-	algorithm;correctness (computer science);experiment;feedback;human–computer interaction;ibm notes;machine learning;numerical analysis;simulation;usability testing	Robert Tyler Loftin;James MacGlashan;Bei Peng;Matthew E. Taylor;Michael L. Littman;Jeff Huang;David L. Roberts	2014			semi-supervised learning;unsupervised learning;robot learning;error-driven learning;simulation;expectation–maximization algorithm;computer science;artificial intelligence;technical report;machine learning;learning classifier system;computational learning theory;bayesian inference;reinforcement learning	AI	21.20015257695965	-20.48723432253083	63759
536a258385d13c6f02431f33923993f76f667753	cartesian genetic programming in a changing environment		Evolutionary algorithm are prevalently being used in static environments. In a dynamically changing environment an evolutionary algorithm must be also able to cope with the changes of the environment. This paper describes an algorithm based on Cartesian Genetic Programming (CGP) that is used to design and optimise a solution in a simulated symbolic regression problem in a changing environment. A modified version of the Age-Layered Population Structure (ALPS) algorithm is being used in cooperation with CGP. It is shown that the usage of ALPS can improve the performance on of CGP when solving problems in a changing environment.	application-level profile semantics (alps);best, worst and average case;cartesian closed category;evolutionary algorithm;experiment;genetic programming;symbolic regression;test set	Karel Slaný	2015	2015 7th International Joint Conference on Computational Intelligence (IJCCI)		evolutionary programming;programming;simulation;computer science;artificial intelligence;machine learning	Robotics	23.460533705272294	-10.635061294168697	63920
c5841c46a9ca003e5633a77d1c7d50d3c898c84a	the gf-3 sar data processor	gaofen-3;sar;data processor;format of products;processing algorithm;system architecture	The Gaofen-3 (GF-3) data processor was developed as a workstation-based GF-3 synthetic aperture radar (SAR) data processing system. The processor consists of two vital subsystems of the GF-3 ground segment, which are referred to as data ingesting subsystem (DIS) and product generation subsystem (PGS). The primary purpose of DIS is to record and catalogue GF-3 raw data with a transferring format, and PGS is to produce slant range or geocoded imagery from the signal data. This paper presents a brief introduction of the GF-3 data processor, including descriptions of the system architecture, the processing algorithms and its output format.	algorithm;aperture (software);description;ingestion;synthetic data;systems architecture;workstation	Bing Han;Chibiao Ding;Li-Hua Zhong;Jiayin Liu;Xiaolan Qiu;Yuxin Hu;Bin Lei	2018		10.3390/s18030835	electronic engineering;raw data;slant range;engineering;systems architecture;synthetic aperture radar;computer vision;data processing system;geocoding;workstation;artificial intelligence;ground segment	Arch	16.257442353730113	-11.942423129097087	64461
58a44c2fcbe282a0b8fe354e33703458640b4c28	fast policy learning through imitation and reinforcement		Imitation learning (IL) consists of a set of tools that leverage expert demonstrations to quickly learn policies. However, if the expert is suboptimal, IL can yield policies with inferior performance compared to reinforcement learning (RL). In this paper, we aim to provide an algorithm that combines the best aspects of RL and IL. We accomplish this by formulating several popular RL and IL algorithms in a common mirror descent framework, showing that these algorithms can be viewed as a variation on a single approach. We then propose LOKI, a strategy for policy learning that first performs a small but random number of IL iterations before switching to a policy gradient RL method. We show that if the switching time is properly randomized, LOKI can learn to outperform a suboptimal expert and converge faster than running policy gradient from scratch. Finally, we evaluate the performance of LOKI experimentally in several simulated environments.	converge;experiment;gradient;ibm notes;iteration;random number generation;randomized algorithm;reinforcement learning;switching time	Ching-An Cheng;Xinyan Yan;Nolan Wagener;Byron Boots	2018			computer science;machine learning;artificial intelligence;scratch;reinforcement learning;policy learning;imitation;reinforcement	ML	21.114511773600444	-20.39968606208884	64614
073a3198581f6010751c0f4cd489ea73f780759a	planning under continuous time and resource uncertainty: a challenge for ai	continuous time;roving vehicles;failure;decision theory;markov decision process;mars surface	We outline a class of problems, typical of Mars rover operations, that are problematic for current methods of planning under uncertainty. The existing methods fail because they suffer from one or more of the following limitations: 1) they rely on very simple models of actions and time, 2) they assume that uncertainty is manifested in discrete action outcomes, 3) they are only practical for very small problems. For many real world problems, these assumptions fail to hold. In particular, when planning the activities for a Mars rover, none of the above assumptions is valid: 1) actions can be concurrent and have differing durations, 2) there is uncertainty concerning action durations and consumption of continuous resources like power, and 3) typical daily plans involve on the order of a hundred actions. This class of problems may be of particular interest to theUAI community because both classical and decision-theoretic planning techniques may be useful in solving it. We describe the rover problem, discuss previous work on planning under uncertainty, and present a detailed, but very small, example illustrating some of the difficulties of finding good plans.	automated planning and scheduling;computer data storage;contingency (philosophy);frank soltis;heuristic;pervasive informatics;rover (the prisoner);theory	John L. Bresina;Richard Dearden;Nicolas Meuleau;Sailesh Ramakrishnan;David E. Smith;Richard Washington	2002			markov decision process;simulation;decision theory;computer science;artificial intelligence;machine learning;mathematics;statistics	AI	20.323278834665135	-15.001751877923068	64693
959f8cef4315e0e49a6227f65a01c25e04965fbb	entropy and mutual information can improve fitness evaluation in coevolution of neural networks	neural nets entropy;atmospheric measurements;neural networks;neural nets;particle measurements;evolving neural networks;coevolution;neuroscience;evolution biology;control problem;robust controllers entropy mutual information fitness evaluation neural networks cooperative coevolution information theory neuroscience;robust controllers;entropy mutual information neural networks neurons biological neural networks information theory testing robustness particle measurements neuroscience;mutual information;entropy;neurons;fitness evaluation;cooperative coevolution;information theory;neural network	Accurate fitness estimates are notoriously difficult to attain in cooperative coevolution, as it is often unclear how to reward the individual parts given an evaluation of the evolved system as a whole. This is particularly true for cooperative approaches to neuroevolution, where neurons or neuronal groups are highly interdependent. In this paper we investigate this problem in the context of evolving neural networks for unstable control problems. We use measures from information theory and neuroscience to reward neurons in a neural network based on their degree of participation in the behavior of the network as a whole. In particular, we actively seek networks with high complexity and little redundancy, and argue that this can lead to efficient evolution of robust controllers. Preliminary results support this claim, and indicate that measures from information theory may provide meaningful information about the role of each neuron in a network.	artificial neural network;control theory;cooperative coevolution;information theory;interdependence;mutual information;neuroevolution;neuron	Boye Annfelt Høverstad;Haaken A. Moe;Min Shi	2009	2009 IEEE Congress on Evolutionary Computation	10.1109/CEC.2009.4983349	entropy;coevolution;computer science;artificial intelligence;machine learning;mutual information;artificial neural network;statistics	ML	16.97825583360169	-22.21035214142354	64728
7980f89c96012b433200ca974fbb206f8bc0f413	focusing search by using problem solving experience	problem solving	"""Case-based reasoning (CBR) aims at using experience from the past in order to guide future problem solving rather than """"starting from scratch"""" every time. We propose a CBR strategy particularly suitable for realizing this principle if heuristic search is used as a problem solving method: Given a new problem, a CBR method exploits previously solved problems in order to predict a region of the search space which is (provably) probable to contain the solution. The efficiency of a search method applied afterwards for actually finding the solution is then improved by focusing on this region. Our results provide a formal basis for the intuitively meaningful (even though not always justified) idea to concentrate on those parts of the search space where solutions to similar problems have already been found. The approach outlined in this paper either can be seen as one of CBR-supported heuristic search or as a formal framework of search-oriented CBR."""	problem solving	Eyke Hüllermeier	2000			beam search;mathematical optimization;computer science;artificial intelligence;incremental heuristic search;algorithm	AI	18.62519165203806	-11.696193419265589	64739
529563b8d881efe3ebbce68e449bdd978a02764b	flexible object architectures for hybrid neural processing systems		This paper introduces an initial object architecture and prototype for the flexible, hybrid genetic-neural processing environment called ELYSE, the Evolving, Life-like Yielding, Symbiotic Environment. This architecture will allow the system to dynamically adapt its structure as it evolves and learns more about the types of environments it must deal with. The architecture accommodates a variety of memory classes and algorithm methods. The basic building blocks of ELYSE, the fuzzy, genetic perceptron, may be added or deleted from the system, depending on the complexity of the classes of information the system must process. Presented will be a theoretical description of dynamic adaptation along with the object architecture and high-level requirements for the system.		James Crowder	2010			real-time computing;simulation;computer science;artificial intelligence	ML	16.898306035711805	-23.585298941520776	64945
b1129d8cecd816ebbc26de8f8a0a7848b3b02f7d	features selection for training generator excitation neurocontroller using statistical methods		Essentially, control system requires suitable control signal for yielding desired response of a physical process.Control of synchronous generator has always remained very critical in power system operation and control. For certain well known reasons power generators are normally operated well below their steady state stability limit. This raises demand for efficient and fast controllers. Artificial intelligence has been reported to give revolutionary outcomes in the field of control engineering. The capability of Artificial Neural Network (ANN) to map any nonlinear function satisfactorily based on input-output data has been widely established in intelligent control. Selecting optimum features to train a neurocontroller is very critical because correlation between features of parameters may avert learning capability of an ANN. In this work statistical methods are employed to select independent factors for ANN training.		Abdul Ghani Abro;Junita Mohamad-Saleh;Syafrudin bin Masri	2011		10.1007/978-3-642-22170-5_31	control engineering;electronic engineering;machine learning	AI	14.719122505217713	-21.748226121749397	65234
f18435fd1eb18203278485bd612856e3011edfbb	uncertainty analysis of the loca break size prediction model using gmdh		When transients or accidents occur in the nuclear power plants, the plant operators and technical staffs are provided with only partial information and faced with a number of signals and alarms. Therefore, providing information such as a break size in case of LOCA is essential to control these events successively. In this paper, in order to predict the LOCA break size, a prediction model was developed by using group method of data handling (GMDH) algorithm, and we have conducted its uncertainty analysis. The proposed prediction model was verified using the acquired data from the OPR1000 nuclear power plant.	algorithm;fits;group method of data handling;simulation;test data	Soon Ho Park;Jae Hwan Kim;Dae Seop Kim;Man Gyun Na	2013		10.5220/0004481002210226	control engineering;reliability engineering;engineering;uncertainty analysis	ML	12.776957748756294	-14.651699117287896	65257
130442c483e32ff54be5e2cd2c762af3b80c2528	a mobile agent team works model for hpc big data analysis: fuzzy logic application	computational modeling image segmentation mobile agents algorithm design and analysis mobile communication convergence fuzzy logic;parallel and distributed computing distributed type 2 fuzzy algorithm image processing mobile agents;convergence;image segmentation;mobile agents;fuzzy logic;mobile agent team works model high performance computing avpe encapsulation magnetic resonance images big data mri big data image segmentation agent virtual processing elements cooperative mobile agent model single program multiple data architecture spmd distributed computing platform t2fl algorithm type 2 fuzzy logic hpc big data analysis;computational modeling;parallel processing big data biomedical mri data analysis data encapsulation fuzzy logic image segmentation mobile agents;mobile communication;algorithm design and analysis	The aim of this paper is to present a distributed implementation of the Type-2 Fuzzy Logic (T2FL) algorithm in a mobile agent based distributed computing platform. The proposed algorithm is assigned to be implemented on an SPMD (Single Program Multiple Data) architecture which is based on a cooperative mobile agent model. It is constituted by a set of mobile agents as AVPEs (Agent Virtual Processing Elements) in order to improve the processing resources needed for performing the big data image segmentation. In this work we focused on the application of this algorithm to process the big data MRI (Magnetic Resonance Images) image. The input image is splitted into elementary images by the Mobile Team leader Agent and encapsulated one per AVPE. Each AVPE perform and exchange the segmentation results and maintain asynchronous communication with their Team leader agent until the convergence of this algorithm. The obtained experimental results in terms of accuracy and efficiency analysis of the proposed distributed implementation are achieved thanks to the mobile agents several interesting skills introduced in this distributed computational model.	agent-based model;big data;computational model;distributed computing;fuzzy logic;image analysis;image segmentation;mobile agent;parallel algorithm;resonance;spmd;scalability	Fatema Zahra Benchara;Mohamed Youssfi;Omar Bouattane;Hassan Ouajji	2015	2015 5th International Conference on Information & Communication Technology and Accessibility (ICTA)	10.1109/ICTA.2015.7426917	fuzzy logic;algorithm design;computer vision;convergence;mobile telephony;computer science;artificial intelligence;theoretical computer science;operating system;machine learning;data mining;mobile agent;database;distributed computing;image segmentation;computational model	Robotics	16.815918212439755	-14.192583204708415	65373
9ad4e1ed379c7bbb260c9631686b874ec586d888	dynamic planning networks		We introduce Dynamic Planning Networks (DPN), a novel architecture for deep reinforcement learning, that combines model-based and model-free aspects for online planning. Our architecture learns to dynamically construct plans using a learned state-transition model by selecting and traversing between simulated states and actions to maximize valuable information before acting. In contrast to model-free methods, model-based planning lets the agent efficiently test action hypotheses without performing costly trial-and-error in the environment. DPN learns to efficiently form plans by expanding a single action-conditional state transition at a time instead of exhaustively evaluating each action, reducing the required number of state-transitions during planning by up to 96%. We observe various emergent planning patterns used to solve environments, including classical search methods such as breadth-first and depth-first search. Learning To Plan shows improved data efficiency, performance, and generalization to new and unseen domains in comparison to several baselines.		Norman L. Tasfi;Miriam A. M. Capretz	2018	CoRR			AI	20.229579270566376	-20.431072718373933	65466
a41966485d0cef77699458a39c4172ecc10b5dd7	unimodal thompson sampling for graph-structured arms		We study, to the best of our knowledge, the first Bayesian algorithm for unimodal Multi–Armed Bandit (MAB) problems with graph structure. In this setting, each arm corresponds to a node of a graph and each edge provides a relationship, unknown to the learner, between two nodes in terms of expected reward. Furthermore, for any node of the graph there is a path leading to the unique node providing the maximum expected reward, along which the expected reward is monotonically increasing. Previous results on this setting describe the behavior of frequentist MAB algorithms. In our paper, we design a Thompson Sampling–based algorithm whose asymptotic pseudo–regret matches the lower bound for the considered setting. We show that—as it happens in a wide number of scenarios—Bayesian MAB algorithms dramatically outperform frequentist ones. In particular, we provide a thorough experimental evaluation of the performance of our and state– of–the–art algorithms as the properties of the graph vary. Introduction Multi–Armed Bandit (MAB) algorithms (Auer, CesaBianchi, and Fischer 2002) have been proven to provide effective solutions for a wide range of applications fitting the sequential decisions making scenario. In this framework, at each round over a finite horizon T , the learner selects an action (usually called arm) from a finite set and observes only the reward corresponding to the choice she made. The goal of a MAB algorithm is to converge to the optimal arm, i.e., the one with the highest expected reward, while minimizing the loss incurred in the learning process and, therefore, its performance is measured through its expected regret, defined as the difference between the expected reward achieved by an oracle algorithm always selecting the optimal arm and the one achieved by the considered algorithm. We focus on the so–called Unimodal MAB (UMAB), introduced in (Combes and Proutiere 2014a), in which each arm corresponds to a node of a graph and each edge is associated with a relationship specifying which node of the edge gives the largest expected reward (providing thus a partial ordering over the arm space). Furthermore, from any node there is a path leading to the unique node with the maximum expected reward along which the expected reward is monotonically Copyright c © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. increasing. While the graph structure may be (not necessarily) known a priori by the UMAB algorithm, the relationship defined over the edges is discovered during the learning. In the present paper, we propose a novel algorithm relying on the Bayesian learning approach for a generic UMAB setting. Models presenting a graph structure have become more and more interesting in last years due to the spread of social networks. Indeed, the relationships among the entities of a social network have a natural graph structure. A practical problem in this scenario is the targeted advertisement problem, whose goal is to discover the part of the network that is interested in a given product. This task is heavily influenced by the graph structure, since in social networks people tend to have similar characteristics to those of their friends (i.e., neighbor nodes in the graph), therefore interests of people in a social network change smoothly and neighboring nodes in the graph look similar to each other (McPherson, Smith-Lovin, and Cook 2001; Crandall et al. 2008). More specifically, an advertiser aims at finding those users that maximize the ad expected revenue (i.e., the product between click probability and value per click), while at the same time reducing the amount of times the advertisement is presented to people not interested in its content. Under the assumption of unimodal expected reward, the learner can move from low expected rewards to high ones just by climbing them in the graph, preventing from the need of a uniform exploration over all the graph nodes. This assumption reduces the complexity in the search for the optimal arm, since the learning algorithm can avoid to pull the arms corresponding to some subset of non– optimal nodes, reducing thus the regret. Other applications might benefit from this structure, e.g., recommender systems which aims at coupling items with those users are likely to enjoy them. Similarly, the use of the unimodal graph structure might provide more meaningful recommendations without testing all the users in the social network. Finally, notice that unimodal problems with a single variable, e.g., in sequential pricing (Jia and Mannor 2011), bidding in online sponsored search auctions (Edelman and Ostrovsky 2007) and single–peak preferences economics and voting settings (Mas-Collel, Whinston, and Green 1995), are graph–structured problems in which the graph is a line. Frequentist approaches for UMAB with graph structure ar X iv :1 61 1. 05 72 4v 2 [ cs .L G ] 2 2 N ov 2 01 6 are proposed in (Jia and Mannor 2011) and (Combes and Proutiere 2014a). Jia and Mannor (2011) introduce the GLSE algorithm with a regret of order O( √ T log(T )). However, GLSE performs better than classical bandit algorithms only when the number of arms is Θ(T ). Combes and Proutiere (2014a) present the OSUB algorithm—based on KLUCB—achieving asymptotic regret ofO(log(T )) and outperforming GLSE in settings with a few arms. To the best of our knowledge, no Bayesian approach has been proposed for unimodal bandit settings, included the UMAB setting we study. However, it is well known that Bayesian MAB algorithms—the most popular is Thompson Sampling (TS)—usually suffer of same order of regret as the best frequentist one (e.g., in unstructured settings (Kaufmann, Korda, and Munos 2012)), but they outperform the frequentist methods in a wide range of problems (e.g., in bandit problems without structure (Chapelle and Li 2011) and in bandit problems with budget (Xia et al. 2015)). Furthermore, in problems with structure, the classical Thompson Sampling (not exploiting the problem structure) may outperform frequentist algorithms exploiting the problem structure. For this reason, in this paper we explore Bayesian approaches for the UMAB setting. More precisely, we provide the following original contributions: • we design a novel Bayesian MAB algorithm, called UTS and based on the TS algorithm; • we derive a tight upper bound over the pseudo–regret for UTS, which asymptotically matches the lower bound for the UMAB setting; • we describe a wide experimental campaign showing better performance of UTS in applicative scenarios than those of state–of–the–art algorithms, evaluating also how the performance of the algorithms (ours and of the state of the art) varies as the graph structure properties vary. Related work Here, we mention the main works related to ours. Some works deal with unimodal reward functions in continuous armed bandit setting (Jia and Mannor 2011; Combes and Proutiere 2014b; Kleinberg, Slivkins, and Upfal 2008). In (Jia and Mannor 2011) a successive elimination algorithm, called LSE, is proposed achieving regret of O( √ T log T ). In this case, assumptions over the minimum local decrease and increase of the expected reward is required. Combes and Proutiere (2014b) consider stochastic bandit problems with a continuous set of arms and where the expected reward is a continuous and unimodal function of the arm. They propose the SP algorithm, based on the stochastic pentachotomy procedure to narrow the search space. Unimodal MABs on metric spaces are studied in (Kleinberg, Slivkins, and Upfal 2008). An application–dependent solution to the recommendation systems which exploits the similarity of the graph in social network in targeted advertisement has been proposed in (Valko et al. 2014). Similar information has been considered in (Caron and Bhagat 2013) where the problem of cold–start users (i.e., new users) is studied. Another type of structure considered in sequential games is the one of monotonicity of the conversion rate in the price (Trovò et al. 2015). Interestingly, the assumptions of monotonicity and unimodality are orthogonal, none of them being a special case of the other, therefore the results for monotonic setting cannot be used in unimodal bandits. In (Alon et al. 2013; Mannor and Shamir 2011), a graph structure of the arm feedback in an adversarial setting is studied. More precisely, they assume to have correlation over rewards and not over the expected values of arms. Problem Formulation A learner receives in input a finite undirected graph MAB settingG = (A,E), whose verticesA = {a1, . . . , aK} with K ∈ N correspond to the arms and an edge (aiaj) ∈ E exists only if there is a direct partial order relationship between the expected rewards of arms ai and aj . The leaner knows a priori the nodes and the edges (i.e., she knows the graph), but, for each edge, she does not know a priori which is the node of the edge with the largest expected reward (i.e., she does not know the ordering relationship). At each round t over a time horizon of T ∈ N the learner selects an arm ai and gains the corresponding reward xi,t. This reward is drawn from an i.i.d. random variable Xi,t (i.e., we consider a stochastic MAB setting) characterized by an unknown distribution Di with finite known support Ω ⊂ R (as customary in MAB settings, from now on we consider Ω ⊆ [0, 1]) and by unknown expected value μi := E[Xi,t]. We assume that there is a single optimal arm, i.e., there exists a unique arm ai∗ s.t. its expected value μi∗ = maxi μi and, for sake of notation, we denote μi∗ with μ∗. Here we analyze a graph bandit setting with unimodality property, defined as: Definition 1. A graph unimodal MAB (UMAB) settingG = (A,E) is a graph bandit setting G s.t. for each sub–optimal arm ai, i 6= i∗ it exists a finite path p = (i1 = i, . . . , im = i∗) s.t. μik < μik+1 and (aik , aik+1) ∈ E for each k ∈ {1, . . . ,m− 1}. This definition assures that if one is able to identify a n	arm architecture;algorithm;applicative programming language;artificial intelligence;coat of arms;converge;conversion marketing;entity;gibbs sampling;graph (discrete mathematics);michael j. fischer;multi-agent system;multi-armed bandit;node (computer science);recommender system;regret (decision theory);richard crandall;search engine marketing;smoothing;social network;thompson sampling;uts;unimodal thresholding;word lists by frequency	Stefano Paladino;Francesco Trovò;Marcello Restelli;Nicola Gatti	2017			mathematical optimization;combinatorics;machine learning;mathematics;statistics	AI	23.292402734490487	-17.41719339642834	65664
a31d03f272d410ebb86001aab0b7a02f0f0fb613	flexible pomdp framework for human-robot cooperation in escort tasks	pomdp;hri;joint task	We describe a novel method for ensuring cooperation between human and robot. First, we present a flexible and hierarchical framework based on POMDPs. Second, we introduce a set of cooperative states within the state-space of the POMDP. Third, for ensuring an efficient scalability, the framework partitions the overall task into independent planning modules. Lastly, for a robust execution of the POMDP policies we use Petri Net Plans, which have already been used to execute MDP policies. To this end, we describe how to convert a POMDP policy into an executable Petri Net Plan. We implement our approach and develop experiments on simulation and on a real robot in an escorting task where the robot guides a customer to the desired place in a public space.	executable;experiment;partially observable markov decision process;petri net;robot;scalability;simulation;state space	Fabio-Valerio Ferrari;Laurent Jeanpierre;Abdel-Illah Mouaddib	2017			simulation;partially observable markov decision process;computer science;artificial intelligence	Robotics	18.067519573750083	-16.22352434185684	65811
05880b1c72c15f077f60d9149ec2e6b1b59b091c	a study on the application of regression trees and adaptive neuro-fuzzy inference system in glass manufacturing process for packaging	anfis;cart;glass;model	ANFIS and other algorithms were used for the classification of the defects that occur in the production process of glass for packing. In this study we used the Project “Newglass” installed in Portugal. This project used a model of Manufactures to study the process of manufacturing glass packaging. The database Project “Newglass” consists of the operating variables of the furnace and the percentage of defects found in end products of the factory model. The classification obtained through the ANFIS was compared with the results obtained in the manufacture of glass for packing. The classifications obtained in the manufacture and in the ANFIS software were also compared with the classification obtained with CART (Classification and Regression Tree).	adaptive neuro fuzzy inference system;algorithm;decision tree learning;inference engine;neuro-fuzzy;set packing	Herbert R. do N. Costa;Alessandro La Neve	2016	2016 Annual Conference of the North American Fuzzy Information Processing Society (NAFIPS)	10.1109/NAFIPS.2016.7851584	engineering;operations management;engineering drawing;manufacturing engineering	Robotics	13.105823362316016	-18.476395185093043	65914
0a28e2734ff6291c5f342b9194f156edbd145bdb	correcting sensor drift and intermittency faults with data fusion and automated learning	drift fault;detection logic;fuzzy neural nets;particle swarm optimization approach;sensor fusion sensor phenomena and characterization fault detection redundancy sensor systems temperature sensors monitoring logic filtering predictive models;sensor drift correction;soft fault data fusion drift fault fuzzy fusion intermittency intermittent fault sensor validation;data fusion;sensor fusion fault diagnosis fuzzy neural nets genetic algorithms learning artificial intelligence particle swarm optimisation;monitoring system;particle swarm optimizer;fuzzy fusion;fault detection;intermittency;transportation industry;fault signature;genetic algorithm;genetic algorithms;intermittency fault detection algorithm;sensor validation technique;sensor fusion;learning artificial intelligence;false positive;intermittent fault;soft fault;fuzzy principle;particle swarm optimisation;early detection;neural network sensor drift correction intermittency fault detection algorithm data fusion automated learning fault signature monitoring system detection logic sensor validation technique fuzzy principle particle swarm optimization approach genetic algorithm transportation industry;automated learning;sensor validation;fault diagnosis;neural network	Many fault detection algorithms deal with fault signatures that manifest themselves as step changes. While detection of these step changes can be difficult due to noise and other complicating factors, detecting slowly developing faults is usually even more complicated. Tradeoffs between early detection and false positive avoidance are more difficult to establish. Often times, slow drift faults go completely undetected because the monitoring systems assume that they are ordinary system changes and some monitoring schemes may adapt to the changes. Where redundant sensors are used, a drifting sensor may cause the logic to latch on to the ldquobadrdquo sensor. Another problem may be intermittent sensors faults where the detection logic is too sluggish to recognize a problem before the sensor has returned to seemingly normal behavior. To address these classes of problems, we introduce here a set of algorithms that learns to avoid the bad sensor, thus indirectly recognizing the aberrant sensor. We combine advanced sensor validation techniques with learning. The sensor validation is inspired by fuzzy principles. The parameters of this algorithm are learned using competing optimization approaches. We compare the results from a particle swarm optimization approach with those obtained from genetic algorithms. Results are shown for an application in the transportation industry.	electronic signature;fault detection and isolation;genetic algorithm;mathematical optimization;particle swarm optimization;sensor	Kai Goebel;Weizhong Yan	2008	IEEE Systems Journal	10.1109/JSYST.2008.925262	control engineering;electronic engineering;genetic algorithm;soft sensor;computer science;engineering;machine learning;sensor fusion;artificial neural network	Robotics	14.67881966163148	-14.199972138246647	65941
521c5092f7ff4e1fdbf607e2f54e8ce26b51bd27	active imitation learning via reduction to i.i.d. active learning		In standard passive imitation learning, the goal is to learn a target policy by passively observing full execution trajectories of it. Unfortunately, generating such trajectories can require substantial expert effort and be impractical in some cases. In this paper, we consider active imitation learning with the goal of reducing this effort by querying the expert about the desired action at individual states, which are selected based on answers to past queries and the learner’s interactions with an environment simulator. We introduce a new approach based on reducing active imitation learning to i.i.d. active learning, which can leverage progress in the i.i.d. setting. Our first contribution, is to analyze reductions for both non-stationary and stationary policies, showing that the label complexity (number of queries) of active imitation learning can be substantially less than passive learning. Our second contribution, is to introduce a practical algorithm inspired by the reductions, which is shown to be highly effective in four test domains compared to a number of alternatives.	algorithm;dreamwidth;interaction;simulation;stationary process	Kshitij Judah;Alan Fern;Thomas G. Dietterich	2012			active learning;leverage (finance);machine learning;passive learning;computer science;error-driven learning;artificial intelligence;imitation;active learning (machine learning);proactive learning	ML	21.59330458923514	-19.004586747136727	66078
5277d201eb983082eca8161d55d53968d5e0efe8	the quality prediction of iron ore pellets in grate-kiln-cooler system using artificial neural network	blast furnaces;levenberg marquardt;single layer back propagation artificial neural networks;optimisation;blast furnace iron ore pellets quality prediction grate kiln cooler system single layer back propagation artificial neural networks compression strength shatter strength shougang mining company levenberg marquardt optimization arithmetic;kilns;neural nets;shougang mining company;grate kiln cooler system;compression strength;artificial nerural network;pellet;iron;backpropagation;quality control backpropagation blast furnaces cooling kilns neural nets optimisation production engineering computing;production engineering computing;training data;artificial neural networks;blast furnace;quality prediction;grate kiln cooler;compressive strength;production;production artificial neural networks predictive models blast furnaces iron kilns training data;predictive models;levenberg marquardt optimization arithmetic;shatter strength;quality control;back propagation;iron ore pellets quality prediction;artificial neural network;cooling;quality prediction pellet grate kiln cooler artificial nerural network	A model of three single layer back propagation(BP) artificial neural networks has been established to predict the compression strength of final pellets and dried pellets, the same as the shatter strength of the green pellets, according to the production data from SHOUGANG Mining Company. The Levenberg-Marquardt optimization arithmetic was used to train the model with the production data. After training, the error of the prediction result is less than 3%. The developed model can meet the requirement from production with a high accuracy and a wide flexibility.	artificial neural network;levenberg–marquardt algorithm;mathematical optimization;shattered set	Junxiao Feng;Yang Qiao	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5584645	engineering;forensic engineering;mechanical engineering	Robotics	12.425145706410737	-19.896118212093846	66142
21dc7cfba2c1d42308c97bcd87223cde3aa49fe7	centrality measures for disease transmission networks	maladie infectieuse;network measurement;probability;disease transmission;toxicomane;sida;centralite;network analysis;probabilite;aids;contamination;drug addict;analyse de reseau;infectious desease;prestige	Ž This paper addresses the issue of the applicability of various network measures provided by analysis . programs such as UCINET for the analysis of a disease transmission network. A simulation was conducted to estimate HIV transmission probabilities within an empirical network of cocaine injectors. The results of the simulation were then used as a criterion to evaluate network measures of disease vulnerability and infectivity. The analysis concludes that, for the type of disease transmission network studied, relatively simple ego-network-based network measures can be adequate to the measurement of vulnerability to disease and infectivity. q 1999 Elsevier Science B.V. All rights reserved.	centrality;simulation	David C. Bell;John S. Atkinson;Jerry W. Carlson	1999	Social Networks	10.1016/S0378-8733(98)00010-0	network analysis;probability;mathematics;contamination;operations research;statistics	Security	13.50307295842362	-9.924564081372681	66242
4e0610ac4c5e055ac56b2ae0d91386a10ffbd325	efficient cross-domain learning of complex skills	transfer learning;deep feature learning;learner modeling	Building an intelligent agent that simulates human learning of math and science could potentially benefit both education, by contributing to the understanding of human learning, and artificial intelligence, by advancing the goal of creating human-level intelligence. However, constructing such a learning agent currently requires significant manual encoding of prior domain knowledge; in addition to being a poor model of human acquisition of prior knowledge, manual knowledgeencoding is both time-consuming and error-prone. Recently, we proposed an efficient algorithm that automatically acquires domain-specific prior knowledge in the form of deep features. We integrate this deep feature learner into a machine-learning agent, SimStudent. To evaluate the generality of the proposed approach and the effect of integration on prior knowledge, we carried out a controlled simulation study in three domains, fraction addition, equation solving, and stoichiometry, using problems solved by human students. The results show that the integration reduces SimStudent’s dependence over domain-specific prior knowledge, while maintains SimStudent’s performance.	algorithm;artificial intelligence;cognitive dimensions of notations;equation solving;intelligent agent;machine learning;simulation	Nan Li;William W. Cohen;Kenneth R. Koedinger	2012		10.1007/978-3-642-30950-2_63	transfer of learning;computer science;knowledge management;artificial intelligence;machine learning	AI	19.940153989688508	-21.535783386933886	66993
a0c3a7948044f838687ae04e28fd8c7d1c48ec98	tuning the structure and parameters of a neural network by using hybrid taguchi-genetic algorithm	feedforward neural network;feedforward neural networks;memoire associative;performance evaluation;neural networks;neural networks nn;tuning feedforward neural network hybrid taguchi genetic algorithm network structure systematic reasoning capability associative memory;solar activity;robust statistics;methode taguchi;inference mechanisms;numerical optimization;hybrid taguchi genetic algorithm;algoritmo genetico;genetics;inference mechanisms feedforward neural nets taguchi methods genetic algorithms content addressable storage tuning;artificial neural networks;reseau neuronal non boucle;tuning;computer experiment;taguchi method genetic algorithm ga neural networks nn;systematic reasoning capability;algorithme genetique;associative memory;memoria asociativa;algorithms;genetic algorithm;robustness;genetic algorithms;algorithms genetics memory neural networks computer solar activity;feedforward neural nets;neural networks feedforward neural networks artificial neural networks genetic algorithms signal processing algorithms genetic mutations robustness associative memory costs performance evaluation;genetic mutations;network structure;taguchi methods;reseau neuronal;neural networks computer;signal processing algorithms;content addressable storage;metodo taguchi;taguchi method;red neuronal;memory;genetic algorithm ga;neural network	In this paper, a hybrid Taguchi-genetic algorithm (HTGA) is applied to solve the problem of tuning both network structure and parameters of a feedforward neural network. The HTGA approach is a method of combining the traditional genetic algorithm (TGA), which has a powerful global exploration capability, with the Taguchi method, which can exploit the optimum offspring. The Taguchi method is inserted between crossover and mutation operations of a TGA. Then, the systematic reasoning ability of the Taguchi method is incorporated in the crossover operations to select the better genes to achieve crossover, and consequently enhance the genetic algorithms. Therefore, the HTGA approach can be more robust, statistically sound, and quickly convergent. First, the authors evaluate the performance of the presented HTGA approach by studying some global numerical optimization problems. Then, the presented HTGA approach is effectively applied to solve three examples on forecasting the sunspot numbers, tuning the associative memory, and solving the XOR problem. The numbers of hidden nodes and the links of the feedforward neural network are chosen by increasing them from small numbers until the learning performance is good enough. As a result, a partially connected feedforward neural network can be obtained after tuning. This implies that the cost of implementation of the neural network can be reduced. In these studied problems of tuning both network structure and parameters of a feedforward neural network, there are many parameters and numerous local optima so that these studied problems are challenging enough for evaluating the performances of any proposed GA-based approaches. The computational experiments show that the presented HTGA approach can obtain better results than the existing method reported recently in the literature.	artificial neural network;benchmark (computing);biological neural networks;classification;clinical act of insertion;computation;computer hardware;content-addressable memory;convergence (action);design of experiments;dimensions;exclusive or;experiment;feedforward neural network;gallium;genetic algorithm;hl7publishingsubsection <operations>;local optimum;mathematical optimization;multitier architecture;mutation;neural network simulation;performance;principle of good enough;projections and predictions;reasoning - publishing subsection;signal-to-noise ratio;small;software release life cycle;tbx1 wt allele;taguchi methods;truevision tga;executing - querystatuscode	Jinn-Tsong Tsai;Jyh-Horng Chou;Tung-Kuan Liu	2006	IEEE Transactions on Neural Networks	10.1109/TNN.2005.860885	feedforward neural network;taguchi methods;genetic algorithm;computer science;artificial intelligence;machine learning;artificial neural network;algorithm	ML	13.710509044064725	-23.730505952899758	67020
0d1eec4804f88ce9dfc243f9c2c6c7832901b74d	adaptive diagnosis of faulty systems		A model is developed for diagnosis of faulty systems when symptoms are observable. The model considers the probabilities of various malfunctions conditioned on the observable symptom, pij the probability of having the ith malfunction when observing the jth symptom, and the costs of testing various malfunctions. In practice, the exact values of these parameters are very difficult to obtain; under this condition, adaptive techniques can be used to improve our knowledge of these unknown parameters from results of past diagnoses leaning observations. When the learning observations used to improve the knowledge of pij are from the successful diagnosis in which the malfunction was found, then the optimal adaptive diagnostic procedure is defined as the one that yields minimum expected mean diagnostic cost based on the present state of knowledge of pij. The necessary and sufficient conditions satisfied by such a procedure are derived. The value of learning observations is the difference in the expected cost of the diagnostic procedure with and without learning observation data. A method for computing this value is presented.		Wesley W. Chu	1968	Operations Research	10.1287/opre.16.5.915	simulation;artificial intelligence;machine learning	Theory	14.940106837960677	-16.65232611786992	67155
3df1241bec018b3c34d863b28da27f4d95f24bc4	sample-based planning for continuous action markov decision processes		In this paper, we present a new algorithm that integrates recent advances in solving continuous bandit problems with sample-based rollout methods for planning in Markov Decision Processes (MDPs). Our algorithm, Hierarchical Optimistic Optimization applied to Trees (HOOT) addresses planning in continuous action MDPs, directing the exploration of the search tree using insights from recent bandit research. Empirical results are given that show that the performance of our algorithm meets or exceeds that of a similar discrete action planner by eliminating the problem of manual discretization of the action space.	algorithm;automated planning and scheduling;discretization;markov chain;markov decision process;search tree	Christopher R. Mansley;Ari Weinstein;Michael L. Littman	2011			mathematical optimization;computer science;artificial intelligence;machine learning	AI	21.40260278222132	-16.689206445590326	67285
f0df326e60ce2478cfdf58af09719ce4d7aa8a35	anxious learning in real-time heuristic search		"""Real-time heuristic search methods are used when planning time available per agent’s move is severely limited (e.g., while pathfinding in a video game). Such agents interleave planning and plan execution. As the agent has to move before a complete plan is computed, it is prone to be misguided by inaccuracies in its heuristic. To get out of heuristic depressions, such agents update their heuristic over time. The usual update process requires multiple state revisits which can make the agent appear irrational to the player. To alleviate such map """"scrubbing"""" we propose a new learning mechanism inspired by the psychological notion of anxiety. Our agent maintains a level of anxiety which increases due to state revisits and decays naturally over time. Agent’s anxiety causes it to update the heuristic more aggressively thus filling heuristic depressions quicker. Such anxiety-accelerated learning can be used on top of other real-time heuristic search techniques. Empirical evaluation on video-game pathfinding benchmarks demonstrates benefits for the average solution quality when the new mechanism is used by itself or in combination with expendable state marking."""	data scrubbing;heuristic;item unique identification;pathfinding;real-time locating system;real-time transcription	Vadim Bulitko;Kacy Doucet	2018	2018 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2018.8490400	machine learning;artificial intelligence;data scrubbing;heuristic;computer science;anxiety;benchmark (computing);pathfinding	AI	19.228949082996525	-11.583096443676688	67323
99fece3c31470f3d41478804a6b2f849173b8f54	load forecasting based on chaotic support vector machine with incorporated intelligence algorithm	support vector machines;chaos;time series;intelligence algorithm;time delay;load forecasting;chaotic support vector machine;phase space reconstruction;time series matrix;electric power system;power engineering computing;inner mongolia;lyapunov matrix equations;lyapunov exponent;support vector machine;electricity load forecasting;nonlinear character analysis;delays	Accurate power load forecasting is important for electric power system, for it guarantees its economical and safe operation. Electricity load forecasting is complex to conduct due to its nonlinearity of influenced factors. According to the chaotic and nonlinear characters analyze of power load data, the model of support vector machines (SVM) based on Lyapunov exponents was established. The time series matrix was established according to the theory of phase-space reconstruction, and then Lyapunov exponents was computed to determine time delay and embedding dimension. A new incorporated intelligence algorithm is proposed and used to determine free parameters of support vector machines. Subsequently, examples of electricity load data from a city in inner Mongolia autonomous region. The empirical results reveal that the proposed model outperforms the SVM model, BP algorithm was used to compare with the result of SVM. The results show that the presented method is feasible and effective	algorithm;autonomous robot;backpropagation;broadcast delay;lyapunov fractal;nonlinear system;support vector machine;time series	Jingmin Wang;Guoqiao Ren	2006	First International Conference on Innovative Computing, Information and Control - Volume I (ICICIC'06)	10.1109/ICICIC.2006.468	support vector machine;computer science;artificial intelligence;machine learning;control theory	HPC	10.246106181077892	-21.02420608960055	67327
ed87303680585635e4b438ee0643d249a0758f24	argumentation accelerated reinforcement learning	thesis or dissertation	Reinforcement Learning (RL) is a popular statistical Artificial Intelligence (AI) technique for building autonomous agents, but it suffers from the curse of dimensionality: the computational requirement for obtaining the optimal policies grows exponentially with the size of the state space. Integrating heuristics into RL has proven to be an effective approach to combat this curse, but deriving high-quality heuristics from people’s (typically conflicting) domain knowledge is challenging, yet it received little research attention. Argumentation theory is a logic-based AI technique well-known for its conflict resolution capability and intuitive appeal. In this thesis, we investigate the integration of argumentation frameworks into RL algorithms, so as to improve the convergence speed of RL algorithms. In particular, we propose a variant of Value-based Argumentation Framework (VAF) to represent domain knowledge and to derive heuristics from this knowledge. We prove that the heuristics derived from this framework can effectively instruct individual learning agents as well as multiple cooperative learning agents. In addition,we propose the Argumentation Accelerated RL (AARL) framework to integrate these heuristics into different RL algorithms via Potential Based Reward Shaping (PBRS) techniques: we use classical PBRS techniques for flat RL (e.g. SARSA(λ)) based AARL, and propose a novel PBRS technique for MAXQ0, a hierarchical RL (HRL) algorithm, so as to implement HRL based AARL. We empirically test two AARL implementations — SARSA(λ)-based AARL and MAXQ-based AARL — in multiple application domains, including single-agent and multi-agent learning problems. Empirical results indicate that AARL can improve the convergence speed of RL, and can also be easily used by people that have little background in Argumentation and RL.	algorithm;argumentation framework;artificial intelligence;autonomous robot;curse of dimensionality;heuristic (computer science);multi-agent system;noise shaping;reinforcement learning;state space	Yang Gao	2014			computer science;artificial intelligence;machine learning;pedagogy	AI	19.606134803090267	-17.804828481351553	67535
41e814db62af6d32b7a70de69c636c362587bd05	a quantitative assessment of lcos for operations using system dynamics	analyse risque;indisponibilite;system reliability;time dependent;fiabilite systeme;condiciones limites;condition limitante pour operation;condition aux limites;analyse fonctionnement;risk analysis;system dynamics;specification;gestion risque;risk management;limiting conditions for operations;fiabilidad sistema;probabilistic risk assessment;analisis riesgo;dynamique systeme;outage;operating system;especificacion;boundary condition;estimacion probabilista;specification technique;risk assessment;estimation probabiliste;nuclear power plant;safety analysis report;gestion riesgo;core damage frequency;indisponibilidad;operation study;analisis funcionamiento;probabilistic assessment;evaluation risque;technical specifications	Limiting conditions for operations (LCOs) define the allowed outage times (AOTs) and the actions to be taken if the repair cannot be completed within the AOT. Typically plant shutdown is required. In situations where the risk associated with the action, i.e. the risk of plant shutdown given a failure of the safety system, may be substantial, a strategy is needed to control the plant risk. In this study the changing operation modes are evaluated quantitatively and dynamically using the tool of system dynamics. System dynamics has been developed to analyze the dynamic reliability of a complicated system. System dynamics using the Vensim software have been applied to LCOs assessment for an example system, the auxiliary feed water system of a reference nuclear power plant. Analysis results of both full power operation and shutdown operation have been compared for a measure of core damage frequency. The increase in core damage frequency is used as a measure in this study. A time dependent framework developed in this study has been shown to be very flexible in that it can be applied to assess LCOs quantitatively under any operational context of the Technical Specifications in Final Safety Analysis Report of the reference plant. q 2004 Elsevier Ltd. All rights reserved.	ahead-of-time compilation;causal filter;diagram;downtime;liquid crystal on silicon;requirement;shutdown (computing);system dynamics;vensim	Kyung-Min Kang;Moosung Jae	2005	Rel. Eng. & Sys. Safety	10.1016/j.ress.2004.04.014	reliability engineering;risk assessment;risk analysis;risk management;boundary value problem;engineering;mathematics;system dynamics;probabilistic risk assessment;operations research;specification	SE	12.845505819137808	-10.274803087726802	67754
805a0a3a571fbb72fc85e5edb17443aa1ce69b25	the possibilistic reward method and a dynamic extension for the multi-armed bandit problem: a numerical study		Different allocation strategies can be found in the literature to deal with the multi-armed bandit problem under a frequentist view or from a Bayesian perspective. In this paper, we propose a novel allocation strategy, the possibilistic reward method. First, possibilistic reward distributions are used to model the uncertainty about the arm expected rewards, which are then converted into probability distributions using a pignistic probability transformation. Finally, a simulation experiment is carried out to find out the one with the highest expected reward, which is then pulled. A parametric probability transformation of the proposed is then introduced together with a dynamic optimization, which implies that neither previous knowledge nor a simulation of the arm distributions is required. A numerical study proves that the proposed method outperforms other policies in the literature in five scenarios: a Bernoulli distribution with very low success probabilities, with success probabilities close to 0.5 and with success probabilities close to 0.5 and Gaussian rewards; and truncated in [0,10] Poisson and exponential distributions.	bernoulli polynomials;dynamic programming;euler–bernoulli beam theory;heart rate variability;mathematical optimization;multi-armed bandit;numerical analysis;performance rating;regret (decision theory);sampling (signal processing);simulation;time complexity	Miguel Martín;Antonio Jiménez-Martín;Alfonso Mateos	2017		10.5220/0006186400750084	mathematical optimization;artificial intelligence;machine learning;mathematics	AI	23.981346506638367	-18.11036459575818	67906
566c879e8a560e4193b633b4112c8ee836bcb339	neural network modeling of ternary solubilities of 2-naphthol in supercritical co2: a comparative study	cosolvent;solid solubility;supercritical fluid;equation of state;artificial neural network	A back-propagation multilayer artificial neural network (ANN) has been constructed for prediction of the solubility of 2-naphthol in ternary systems. Different networks were trained and tested with different network parameters using training and testing data sets. Using a validating data set the network having the highest regression coefficient and the lowest mean square error was selected. The comparison with the Peng–Robinson (PR) equation of state (EoS)was investigated. The binary interaction parameterswere calculated by fitting the solubility data of the constituent binary systems. However, the predicted average relative deviation (ARD) and the root mean squared error (RMSD) for the trained ANNs data points were 3.15 and 0.81%, respectively. For the PR EoS, the overall average predicted ARD and RMSD for all systems were as high as 11.82 and 8.44%, respectively. The present work demonstrates that the ANN method is a powerful approach with better accuracy compared with the classical thermodynamic methods. © 2011 Elsevier Ltd. All rights reserved.		Yousef Bakhbakhi	2012	Mathematical and Computer Modelling	10.1016/j.mcm.2011.11.051	supercritical fluid;artificial intelligence;machine learning;equation of state;thermodynamics;artificial neural network	AI	12.447735215938446	-20.484268090865143	68165
8d13af77a4967e64a429fca0a3fde6fdeec57c66	handling of variability in probabilistic and possibilistic failure analysis of corroded pipes	failure analysis;pipeline failures;probability;reliability analysis;structural integrity	The evaluation of the safe maximum working pressure and the probability of failure of corroded pipes are important steps in the development of risk-based strategies for the inspection and maintenance of pipes carrying oil and gas. These parameters are often calculated based on the inspection results and using probabilistic analysis. To account for the variations in the dimensions of the inspected corrosion pits, the probabilistic approach combines a corroded pipe integrity model, like the ASME B31G, with the probability density functions of the input parameters—pipe wall thickness, corrosion pit length, corrosion pit depth and applied pressure—to predict the probability of failure. This paper compares the traditional probabilistic approach with an alternative possibilistic approach. In the possibilistic approach the input variables are regarded as fuzzy variables whose membership functions are developed from the statistical inspection data. The calculations are carried out using fuzzy arithmetic based on extended interval analysis. Instead of the probability of failure, the possibilistic approach gives the possibility and necessity measures of the likelihood of failure. The possibility and necessity measures are, respectively, more and less conservative than the probability of failure.	failure analysis;heart rate variability	Maneesh Kumar Singh;Tore Markeset	2014	Int. J. Systems Assurance Engineering and Management	10.1007/s13198-013-0197-y	structural engineering;reliability engineering;engineering;forensic engineering	SE	14.55233646662837	-13.53696905503328	68214
88786d1f99fbb223db80bbe169789424d915963a	a model of evolution and learning	autoapprentissage;learning;pricing;baldwin effect;effet baldwin;adaptive agents;fijacion precios;systeme adaptatif;autodidactismo;self learning;stock price;adaptive critic design;adaptive system;sistema adaptativo;neural network adaptive critic;reseau neuronal;red neuronal;fixation prix;neural network;evolution	We study a model of evolving populations of self-learning agents and analyze the interaction between learning and evolution. We consider an agent-broker that predicts stock price changes and uses its predictions for selecting actions. Each agent is equipped with a neural network adaptive critic design for behavioral adaptation. We discuss three cases in which either evolution or learning, or both, are active in our model. We show that the Baldwin effect can be observed in our model, viz. originally acquired adaptive policy of best agent-brokers becomes inherited over the course of the evolution. We also compare the behavioral tactics of our agents to the searching behavior of simple animals.	acclimatization;artificial neural network;biological neural networks;models of dna evolution;population;viz: the computer game	Vladimir G. Red'ko;Oleg P. Mosalov;Danil V. Prokhorov	2005	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2005.06.005	pricing;simulation;computer science;artificial intelligence;adaptive system;machine learning;evolution;baldwin effect;operations research;artificial neural network	ML	23.16790434547937	-12.353314887134726	68219
2c8a36208cfec6cf8397d2781ac33d246d0eadbc	towards a unified neurobiological theory of creative problem solving	neural nets;psychology;psychology neural nets problem solving;problem solving psychology cognition search problems mathematical model computational modeling computer architecture;brain circuit unified neurobiological theory creative problem solving representational problem search problem integrative biological theory neuro eii explicit implicit interaction theory lexical decision task psychology clarion cognitive architecture behavioral data simulation;problem solving	Very little work in psychology has tried to simultaneously tackle the representational problem and the search problem in creative problem solving. Unifying these two fields is critical, because building and searching the problem space may be highly interactive activities that cannot be decoupled and studied in isolation. In addition. neuroscientific explanations of creative problem solving have been elusive. In this article, we propose an integrative biological theory called Neuro-EII to address these problems. Neuro-EII is based on the Explicit-Implicit Interaction (EII) theory of creative problem solving. Like EII, Neuro-EII is implemented using the CLARION cognitive architecture and can be used to simulate behavioral data. We present simulation results of a lexical decision task and use Neuro-EII to generate testable neuroscientific predictions. We conclude by discussing how the Neuro-EII theory can contribute to solving the seemingly intractable problem of identifying the brain circuit(s) supporting creative problem solving.	clarion (cognitive architecture);cognitive architecture;computational complexity theory;computational neuroscience;electroencephalography;neuro-fuzzy;problem domain;problem solving;search problem;simulation	Sébastien Hélie	2013	The 2013 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2013.6706934	computational problem;toy problem;computer science;artificial intelligence;machine learning;clarion;artificial neural network;cognitive science	AI	16.05640004430999	-23.539503967647555	68241
580e2a009b7aa515715c10fef3a3bfef7eedc838	comparison of tdnn and rnn performances for neuro-identification on small to medium-sized power systems	recurrent neural network performance tdnn performance rnn performance neuroidentification power system artificial neural network ann smart grid scaling up distributed approach scaling up centralized approach new england new york 68 bus power network time delay neural network performance;generators;power system identification;training;power system dynamics;testing;test bed;scaling up;artificial neural networks;time delay neural network;power engineering computing;smart power grids;recurrent neural network power system identification artificial neural networks time delay neural network;smart power grids delays power engineering computing power system identification recurrent neural nets;power system;artificial neural networks power system dynamics recurrent neural networks training generators testing;recurrent neural nets;recurrent neural networks;recurrent neural network;delays;artificial neural network;new england	For Artificial Neural Networks (ANN) to become more widely used in power systems and the future smart grids, ANN based algorithms must be capable of scaling up as they try to identify and control larger and larger parts of a power system. This paper goes through the process of scaling up an ANN based identifier as it is driven to identify increasingly larger portions of a power system. Distributed and centralized approaches for scaling up are taken and the pros and cons of each are presented. The New England/New York 68-bus power network is used as the test bed for the studies. It is shown that while a fully-connected (centralized) ANNs is capable of identification of the system with appropriate accuracy, the increase in the training times required to obtain an acceptable set of weights becomes prohibitive as the system size is increased.	algorithm;artificial neural network;centralized computing;ibm power systems;identifier;image scaling;neural networks;performance;random neural network;testbed;time delay neural network	Diogenes Molina;Jiaqi Liang;Ronald G. Harley;Ganesh K. Venayagamoorthy	2011	2011 IEEE Symposium on Computational Intelligence Applications In Smart Grid (CIASG)	10.1109/CIASG.2011.5953344	control engineering;engineering;artificial intelligence;machine learning	Embedded	10.656011294745221	-17.435534772116807	68531
02f6065a43dc7ac3dc0cc4afc312da8121593cca	comparison of markov chain abstraction and monte carlo simulation for the safety assessment of autonomous cars	threat level;probability;automobiles;autonomous vehicle;safety assessment;road traffic;computer model;probabilistic occupancy;road traffic automated highways automobiles collision avoidance markov processes mobile robots monte carlo methods probability;simulation;automated highways;collisions;mobile robots;markov processes probabilistic logic computational modeling vehicle safety monte carlo methods;computational modeling;markov chain monte carlo;monte carlo method;autonomous cars;markov process;crashes;behavior prediction;collision avoidance;vehicle safety;markov processes;probabilistic logic;monte carlo simulation;threat level autonomous cars behavior prediction crash probability markov chains monte carlo simulation probabilistic occupancy safety assessment;crash probability;autonomous cars probabilistic prediction road traffic probabilistic occupancy collision risk autonomous vehicles planned maneuver markov chain abstraction monte carlo simulation;autonomous land vehicles;monte carlo methods;markov chains;markov chain	The probabilistic prediction of road traffic scenarios is addressed. One result is a probabilistic occupancy of traffic participants, and the other result is the collision risk for autonomous vehicles when executing a planned maneuver. The probabilistic occupancy of surrounding traffic participants helps to plan the maneuver of an autonomous vehicle, whereas the computed collision risk helps to decide if a planned maneuver should be executed. Two methods for the probabilistic prediction are presented and compared: 1) Markov chain abstraction and 2) Monte Carlo simulation. The performance of both methods is evaluated with respect to the prediction of the probabilistic occupancy and the collision risk. For each comparison test, we use the same models that generate the probabilistic behavior of traffic participants, where the generation of these data is not compared with real-world data. However, the results independently show the behavior generation that Markov chains are preferred for the probabilistic occupancy, whereas Monte Carlo simulation is clearly preferred for determining the collision risk.	autonomous car;autonomous robot;markov chain;monte carlo method;simulation	Matthias Althoff;Alexander Mergel	2011	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2011.2157342	computer simulation;simulation;engineering;mathematics;computer security;statistics;monte carlo method	Robotics	10.19696651542699	-11.445624474825957	68662
3c3843fa74ac0c06dfa086c5f425c235551106f6	variance adjusted actor critic algorithms		We present an actor-critic framework for MDPs where the obje ctiv is the variance-adjusted expected return. Our critic uses linear function approximation, and we extend the concept of compatible features to the variance-adjusted setting. We present an episodic ac tor-critic algorithm and show that it converges almost surely to a locally optimal point of the objective fun ction. Index Terms Reinforcement Learning, Risk, Markov Decision Processes.	actor model;algorithm;approximation;convex function;linear function;local optimum;markov chain;markov decision process;reinforcement learning;tor messenger	Aviv Tamar;Shie Mannor	2013	CoRR		mathematical optimization;artificial intelligence;machine learning;mathematics	ML	21.996866362312126	-17.46409951904156	68852
aee36f28fc06a5bf0575cffc3ed16f79211b2052	the application of improved d-s evidence theory to single-phase fault line selection	selection model;small current grounded system;phase measurement;d s evidence theory;reliability;grounding;circuit faults;uncertainty;single phase fault line selection;dempster shafer theory d s evidence theory single phase fault line selection small current grounded system correlation symptom terms fault line selection model information entropy information capacity;evidence theory;information entropy d s evidence theory reliability correlation;circuit faults information entropy grounding fault diagnosis computational intelligence reliability theory voltage power generation control systems intelligent control;entropy case based reasoning;correlation symptom terms;fault line selection model;dempster shafer theory;information capacity;entropy;correlation;information entropy;case based reasoning;fault diagnosis	To overcome the poor accuracy of fault line selection in small current grounded system, which induced by the reliability of symptom and the correlation symptom terms, a novel fault line selection method is proposed based on improved D-S evidence theory in the paper. Firstly, the fault line selection model is established based on traditional D-S evidence theory. Secondly, the effective measuring for the reliability of symptom and the correlation symptom terms is solved by information entropy and information capacity. Finally, the novel method is verified by an actual example.	channel capacity;entropy (information theory)	Jianjun Zhao;Weixing Xu;Yandong Hou;Hongliang Tian;Xin Li	2009	2009 Second International Symposium on Computational Intelligence and Design	10.1109/ISCID.2009.196	ground;case-based reasoning;entropy;uncertainty;dempster–shafer theory;artificial intelligence;machine learning;reliability;correlation;statistics;entropy	Logic	12.894412154682536	-12.967861090941394	68903
dbf597e2a54de652edd03f9abe821a4a18ff955f	evolving beharioral strategies in predators and prey	evolving beharioral strategies	? Abstract. The predator/prey domain is utilized to conduct research in Distributed Artiicial Intelligence. Genetic Programming is used to evolve behavioral strategies for the predator agents. To further the utility of the predator strategies, the prey population is allowed to evolve at the same time. The expected competitive learning cycle did not surface. This failing is investigated, and a simple prey algorithm surfaces, which is consistently able to evade capture from the predator algorithms.	ap computer science a;agent-based model;competitive learning;experiment;failure;genetic programming;greedy algorithm;heuristic;prey	Thomas Haynes;Sandip Sen	1995		10.1007/3-540-60923-7_22	machine learning;parse tree;genetic programming;artificial intelligence;competitive learning;population;predator;predation;computer science	AI	23.10450179102137	-10.314887272902023	69051
b8252b57b70f99eec30eabf6b35ff530c1c28da0	an evolutionary approach to system-level fault diagnosis	evolutionary computation;artificial immune system;multiprocessing systems data analysis evolutionary computation fault diagnosis;evolutionary approach;data mining;cloning;function optimization;data analysis;ieee;theoretical analysis;fault diagnosis system testing artificial immune systems educational institutions computer science information technology data engineering data analysis computer errors fault detection;immune system;multiprocessor and multicomputer systems artificial immune systems system level fault diagnosis;system level fault diagnosis;simulation study;multimodal function optimization;multiprocessing systems;error detection;ais based diagnosis approach;program processors;artificial immune systems;ais based diagnosis approach evolutionary approach system level fault diagnosis artificial immune systems data analysis multimodal function optimization error detection;multiprocessor and multicomputer systems;cells biology;fault diagnosis	Artificial immune systems (AIS) have been widely applied to many fields such as data analysis, multimodal function optimization, error detection, etc. In this paper, we show how AIS can be used for system-level fault diagnosis. Experimental results from a thorough simulation study and theoretical analysis demonstrate the effectiveness of the AIS-based diagnosis approach for different small and large systems in both the worst and average cases, making it a viable addition to the existing diagnosis algorithms.	algorithm;artificial immune system;error detection and correction;iterative and incremental development;mathematical optimization;multimodal interaction;simulation	Hui Yang;Mourad Elhadef;Amiya Nayak;Xiaofan Yang	2009	2009 IEEE Congress on Evolutionary Computation	10.1109/CEC.2009.4983108	embedded system;real-time computing;computer science;artificial intelligence;theoretical computer science;machine learning;artificial immune system;evolutionary computation	AI	16.327880282596947	-14.638447924304218	69119
7737a00826a18f28d65b155fac73ff1bc7e53c43	"""on addressing the challenges of complex stochastic games using """"representative"""" moves"""		The problem of achieving competitive game play in a board game, against an intelligent opponent, is a well-known and studied field of Artificial Intelligence (AI). This area of research has seen major breakthroughs in recent years, particularly in the game of Go. However, popular hobby board games, and particularly Trading Card Games, have unique qualities that make them very challenging to existing game playing techniques, partly due to enormous branching factors. This remains a largely unexamined domain and is the arena we operate in. To attempt to tackle some of these daunting requirements, we introduce the novel concept of “Representative” Moves (RMs). Rather than examine the complete list of available moves at a given node, we rather propose the strategy of considering only a subset of moves that are determined to be representative of the player’s strategic options. We demonstrate that in the context of a simplified Trading Card Game, the use of RMs leads to a greatly improved search speed and an extremely limited branching factor. This permits the AI player to play more intelligently than the same algorithm that does not employ them.		Armando H. Taucer;Spencer Polk;B. John Oommen	2018		10.1007/978-3-319-92007-8_1	computer science;machine learning;artificial intelligence;adversary;branching (version control);hobby;branching factor	AI	18.429327064960113	-17.415961865417543	69234
475ee97b924d66bae13bd486137deaf3aa5a83e2	development of a neural network heating controller for solar buildings	gestion energia;energie solaire;systeme commande;regulateur temperature;neural controllers;sistema control;feed forward;heating system control;solar irradiance;energy demand;solar irradiance forecasting;energia solar;industrie bâtiment;regulador temperatura;building industry;solar energy;ambient temperature forecasting;artificial neural networks;control system;gestion energie;temperature regulator;weather condition;solar buildings;industria construccion;ambient temperature;reseau neuronal;feed forward back propagation;back propagation;red neuronal;thermal comfort;simulation environment;energy saving;artificial neural network;energy management;neural network	Artificial neural networks (ANN's) are more and more widely used in energy management processes. ANN's can be very useful in optimizing the energy demand of buildings, especially of those of high thermal inertia. These include the so-called solar buildings. For those buildings, a controller able to forecast not only the energy demand but also the weather conditions can lead to energy savings while maintaining thermal comfort. In this paper, such an ANN controller is proposed. It consists of a meteorological module, forecasting the ambient temperature and solar irradiance, the heating energy switch predictor module and the indoor temperature-defining module. The performance of the controller has been tested both experimentally and in a building thermal simulation environment. The results showed that the use of the proposed controller can lead to 7.5% annual energy savings in the case of a highly insulated passive solar test cell.	artificial neural network;controller (computing);controllers;experiment;heating;kerrison predictor;projections and predictions	Athanassios A. Argiriou;Ioannis Bellas-Velidis;Constantinos A. Balaras	2000	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(00)00057-5	thermal comfort;simulation;computer science;solar irradiance;backpropagation;machine learning;solar energy;room temperature;feed forward;artificial neural network;energy management	Arch	10.416216626544875	-18.024775854878577	69515
09e8d17c5dda7cb649dbde102dcb926d8c583e95	elastic bands across the path: a new framework and methods to lower bound dtw		The Nearest Neighbour algorithm coupled with the Dynamic Time Warping similarity measure (NN-DTW) is at the core of state-of-the-art classification algorithms including Ensemble of Elastic Distances and Collection of TransformationBased Ensemble. DTW’s complexity makes NN-DTW highly computationally demanding. To combat this, lower bounds to DTW are used to minimize the number of times the expensive DTW need be computed during NN-DTW search. Effective lower bounds must balance ‘time to calculate’ vs ‘tightness to DTW.’ On the one hand, the tighter the bound the fewer the calls to the full DTW. On the other, calculating tighter bounds usually requires greater computation. Numerous lower bounds have been proposed. Different bounds provide different trade-offs between compute time and tightness. In this work, we present a new class of lower bounds that are tighter than the popular Keogh lower bound, while requiring similar computation time. Our new lower bounds take advantage of the DTW boundary condition, monotonicity and continuity constraints. In contrast to most existing bounds, they remain relatively tight even for large windows. A single parameter to these new lower bounds controls the speed-tightness trade-off. We demonstrate that these new lower bounds provide an exceptional balance between computation time and tightness for the NNDTW time series classification task, resulting in greatly improved efficiency for NN-DTW lower bound search.	benchmark (computing);computation;dynamic time warping;lattice boltzmann methods;microsoft windows;multiple encryption;nearest neighbour algorithm;nn (newsreader);scott continuity;similarity measure;time complexity;time series	Chang Wei Tan;François Petitjean;Geoffrey I. Webb	2018	CoRR		mathematical optimization;speedup;monotonic function;image warping;mathematics;k-nearest neighbors algorithm;cluster analysis;upper and lower bounds;dynamic time warping;statistical classification	ML	16.83160132262148	-16.338539259243948	69846
822600d394df0903bc9e1e3d3a1e501fbf7f7a50	energy-efficient data processing through data sparsing with artifacts		Improving the energy efficiency of software running in a data center is a challenging task. Several application-specific techniques, such as energy-aware heuristics, controlled approximation and energy-conserving I/O, have been proposed to tackle this problem. In this paper, we introduce data sparsing with artifacts, a novel approach to increase the energy efficiency of applications that are robust to input variations, such as speech and image processing. Data sparsing with artifacts is aimed at reducing the processing times and thus the energy efficiency of such applications while preserving the quality of the results by replacing a random subset of the original data with application-specific artifacts. In contrast to previous work, the proposed approach introduces artifacts at the data layer, without application layer modifications and with general purpose hardware. Data sparsing with artifacts has been integrated into a prototypical file system in userspace (FUSE) and the Hadoop Distributed File System (HDFS). Experiments with MapReduce-based face detection, face recognition and speech recognition algorithms show promising energy savings of up to 10 % with moderate accuracy losses for different data sparsing rates and artifacts.		Pablo Graubner;Patrick Heckmann;Bernd Freisleben	2015		10.1007/978-3-319-20119-1_23	distributed file system;parallel computing;image processing;word error rate;block (data storage);file system;data access layer;heuristics;computer vision;computer science;face detection;artificial intelligence	DB	16.72320583773038	-16.626871648889324	69970
ecae6d31d3eda36bc125d2d139b6b0c1e4a42900	infinite horizon multi-armed bandits with reward vectors: exploration/exploitation trade-off		We focus on the effect of the exploration/exploitation trade-off strategies on the algorithmic design off multi-armed bandits (MAB) with reward vectors. Pareto dominance relation assesses the quality of reward vectors in infinite horizon MABs, like the UCB1 and UCB2 algorithms. In single objective MABs, there is a trade-off between the exploration of the suboptimal arms, and exploitation of a single optimal arm. Pareto dominance based MABs fairly exploit all Pareto optimal arms, and explore suboptimal arms. We study the exploration vs exploitation trade-off for two UCB like algorithms for reward vectors. We analyse the properties of the proposed MAB algorithms in terms of upper regret bounds and we experimentally compare their exploration vs exploitation trade-off on a bi-objective Bernoulli environment coming from control theory.		Madalina M. Drugan	2015		10.1007/978-3-319-27947-3_7	simulation;artificial intelligence	ML	23.348578362214855	-17.26481819663174	69994
344f11a1d346eaccd27b6d9714eaef395e9d1de1	an agent-based self-adaptive mechanism with  reinforcement learning	computers;software;electronic mail;multi agent system;selfadaptive;reinforcement learning;会议论文;multi agent systems learning artificial intelligence;software engineering;adaptive systems;selfadaptive mechanism;learning artificial intelligence;algorithm design and analysis;learning artificial intelligence software electronic mail algorithm design and analysis software engineering adaptive systems computers;learning results agent based self adaptive mechanism reinforcement learning agent execution strategy q learning algorithm	In order to solve the problem in choosing action for a system in a dynamic environment, a self-adaptive mechanism combining the technology of agent and reinforcement learning is presented in this paper. With such a mechanism, the system determines all possible initial states of the agent's execution strategy, and adopts Q-learning algorithm on all the initial states. And then, the best result of all learning results is chosen as the current execution strategy. Meanwhile, agents can share learning results to improve the efficiency of the system. At the end of this paper, a case study is illustrated to validate the effectiveness of the proposed mechanism.	algorithm;q-learning;reinforcement learning	Danni Yu;Qingshan Li;Lu Wang;Yishuai Lin	2015	2015 IEEE 39th Annual Computer Software and Applications Conference	10.1109/COMPSAC.2015.276	robot learning;algorithm design;instance-based learning;error-driven learning;simulation;computer science;artificial intelligence;online machine learning;machine learning;multi-agent system;learning classifier system;reinforcement learning;active learning;hyper-heuristic	Robotics	18.40916101235227	-20.7109170967288	70596
2bf1633c447e41431b283327d790bb6ba7e1947b	comparative analysis of parameter extraction techniques for algan/gan hemt on silicon/sapphire substrate		Abstract We report a comparative study of artificial neural network (ANN) model and small signal model (SSM) based on extracted parameters. ANN model training is done using Levenberg-Marquardt back propagation algorithm, whereas SSM is formed by extracting circuit parameters from measured S-parameters of GaN HEMT on Silicon and Sapphire. It has been found that, for the GaN HEMT parameter extraction, it takes 85 hidden layer neurons to produce the output with higher accuracy. The optimized test and training error/performance are found to be 1.12 × 10 − 8 /0.97 and 1 × 10 − 8 /0.99, respectively.		Shubhankar Majumdar;Ankush Bag;Dhrubes Biswas	2017	Microelectronics Reliability	10.1016/j.microrel.2017.08.016	electronic engineering;engineering;small-signal model;artificial neural network;high-electron-mobility transistor;sapphire;silicon;backpropagation	EDA	13.685959318758139	-19.47149114972974	70650
26e17fef44f4965048a6a62f70a79f3f0b63185f	ideal chaotic pattern recognition is achievable: the ideal-m-adnn - its design and properties	chaotic pattern recognition;adachi like neural networks;peer reviewed;chapter;chaotic neural networks	This paper deals with the relatively new field of designing a Chaotic Pattern Recognition (PR) system. The benchmark of such a system is the following: First of all, one must be able to train the system with a set of “training” patterns. Subsequently, as long as there is no testing pattern, the system must be chaotic. However, if the system is, thereafter, presented with an unknown testing pattern, the behavior must ideally be as follows. If the testing pattern is not one of the trained patterns, the system must continue to be chaotic. As opposed to this, if the testing pattern is truly one of the trained patterns (or a noisy version of a trained pattern), the system must switch to being periodic, with the specific trained pattern appearing periodically at the output. This is truly an ambitious goal, with the requirement of switching from chaos to periodicity being the most demanding. Some related work has been done in this regard. The Adachi Neural Network (AdNN) [1–5] has properties which are pseudo-chaotic, but it also possesses limited PR characteristics. As opposed to this, the Modified Adachi Neural Network (M-AdNN) proposed by Calitoiu et al [6], is a fascinating NN which has been shown to possess the required periodicity property desirable for PR applications. However, in this paper, we shall demonstrate that the PR properties claimed in [6] are not as powerful as originally reported. Indeed, the claim of the authors of [6] is true, in that it resonates periodically for trained input patterns. But unfortunately, the M-AdNN also resonates for unknown patterns and produces these unknown patterns at the output periodically. However, we describe how the parameters of the M-AdNN for its weights, steepness and external inputs, can be specified so as to yield a new NN, which we shall refer to as the Ideal-M-AdNN. The work of this author was partially supported by grant No. 2012HH0003 and 9140A17060411DZ02. Chancellor’s Professor ; Fellow : IEEE and Fellow : IAPR. This author is also an Adjunct Professor with the University of Agder in Grimstad, Norway. The work of this author was partially supported by NSERC, the Natural Sciences and Engineering Research Council of Canada. N.T. Nguyen (Ed.): Transactions on CCI XI, LNCS 8065, pp. 22–51, 2013. c © Springer-Verlag Berlin Heidelberg 2013 Ideal Chaotic Pattern Recognition Is Achievable 23 Using a rigorous Lyapunov analysis, we shall analyze the chaotic properties of the Ideal-M-AdNN, and demonstrate its chaotic characteristics. Thereafter, we shall verify that the system is also truly chaotic for untrained patterns. But most importantly, we demonstrate that it is able to switch to being periodic whenever it encounters patterns with which it was trained. Apart from being quite fascinating, as far as we know, the theoretical and experimental results presented here are both unreported and novel. Indeed, we are not aware of any NN that possesses these properties!	application domain;artificial neural network;benchmark (computing);chaos theory;international association for pattern recognition;lecture notes in computer science;lyapunov fractal;norm (social);quasiperiodicity;springer (tank)	Ke Qin;B. John Oommen	2013	Trans. Computational Collective Intelligence	10.1007/978-3-642-41776-4_2	simulation;engineering;artificial intelligence;communication	ML	15.178871317447518	-22.693131559865616	70700
d59516594b9cbb4cf07f6ce4003697ea986b32f0	finding robust strategies to defeat specific opponents using case-injected coevolution	evolutionary computation;learning artificial intelligence;computer games	Finding robust solutions that are also capable of beating specific opponents presents a challenging problem. This paper investigates solving this problem by using case-injection with a coevolutionary algorithm. Specifically, we recorded winning strategies used by a human player against a coevolved strategy and then injected the player's strategies into the coevolutionary teachset. We compare the strategies produced by case-injected coevolution to strategies produced by a genetic algorithm that only evaluated against the player's strategies. In this paper, our results show that genetic algorithms do not work well against sufficiently difficult opponents. However, coevolution eventually learns to defeat these opponents by first bootstrapping strategies that work well in general, which drives the population closer to strategies that can defeat the challenging opponent. This work informs our research on finding robust real-time strategy game players that also defeat specific opponents.	bootstrapping (compilers);genetic algorithm;institute for operations research and the management sciences;real-time computing;real-time locating system	Christopher A. Ballinger;Sushil J. Louis	2013	2013 IEEE Conference on Computational Inteligence in Games (CIG)	10.1109/CIG.2013.6633656	simulation;computer science;artificial intelligence;machine learning;evolutionary computation	AI	18.055727637444996	-17.731659220892936	70824
876ed0d045089ff57c5c9a43968544f26012af7d	inference methods for detecting the root cause of alarm floods in causal models		Driven by the oil and chemical industry and amplified by the digitization and automation of the industry, the issue of alarm management has been gaining more and more importance. In highly automated and complex industrial systems, on the one hand, a large number of messages and alarms arise and, on the other hand fewer and fewer employees must be able to handle them. This amount of alarms is called alarm flood and it is a huge safety risk in facilities such as refineries. Therefore, it is necessary to reduce these alarm floods, thus reducing downtime, supporting the operator and preventing catastrophes. A novel approach to reducing alarm floods is concerned with learning the causal relationships between the alarms. The learned interrelations of the alarms are represented by a causal model. Based on these causal model, a root cause analysis is carried out to find out the cause of an alarm flood. This makes it possible to dramatically reduce the number of alarms and messages by displaying only the potential root causes. Therefore, we validate the approach of identifying the root cause of an alarm flood by a given causal model. The three most common inference methods are investigated and their suitability for practical application is evaluated on two demonstrators from SmartFactoryOWL.	catastrophe theory;causal model;causality;downtime;flood	Paul Wunderlich;Oliver Niggemann	2018	2018 23rd International Conference on Methods & Models in Automation & Robotics (MMAR)	10.1109/MMAR.2018.8485945	reliability engineering;control engineering;causal model;automation;computer science;alarm;root cause;inference;alarm management;downtime;root cause analysis	Robotics	12.605640469107515	-13.431848830106734	71064
d684da8e7462e0bbbc44e59e7c80b6702e7da412	following newton direction in policy gradient with parameter exploration	complexity theory;complex dynamical quadrotor system newton direction policy gradient parameter exploration markov decision process mdp model free reinforcement learning method sample based estimation normal distribution variance reduction technique finite sample analysis instructional linear quadratic regulator;normal distribution gradient methods learning artificial intelligence markov processes	This paper investigates the use of second-order methods to solve Markov Decision Processes (MDPs). Despite the popularity of second-order methods in optimization literature, so far little attention has been paid to the extension of such techniques to face sequential decision problems. Here we provide a model-free Reinforcement Learning method that estimates the Newton direction by sampling directly in the parameter space. In order to compute the Newton direction we provide the formulation of the Hessian of the expected return, a technique for variance reduction in the sample-based estimation and a finite sample analysis in the case of Normal distribution. Beside discussing the theoretical properties, we empirically evaluate the method on an instructional linear-quadratic regulator and on a complex dynamical quadrotor system.	algorithm;baseline (configuration management);decision problem;experiment;gradient;hessian;information geometry;iteration;markov chain;markov decision process;mathematical optimization;newton;newton's method;rl (complexity);reinforcement learning;robust optimization;sampling (signal processing);variance reduction	Giorgio Manganini;Matteo Pirotta;Marcello Restelli;Luca Bascetta	2015	2015 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2015.7280673	econometrics;mathematical optimization;machine learning;mathematics	ML	23.85696847886087	-18.929114998391547	71093
e596a5b42359247d086f0c3ef6770123783daf42	arnold: an autonomous agent to play fps games		Advances in deep reinforcement learning have allowed autonomous agents to perform well on Atari games, often outperforming humans, using only raw pixels to make their decisions. However, most of these games take place in 2D environments that are fully observable to the agent. In this paper, we present Arnold, a completely autonomous agent to play First-Person Shooter Games using only screen pixel data and demonstrate its effectiveness on Doom, a classical firstperson shooter game. Arnold is trained with deep reinforcement learning using a recent Action-Navigation architecture, which uses separate deep neural networks for exploring the map and fighting enemies. Furthermore, it utilizes a lot of techniques such as augmenting high-level game features, reward shaping and sequential updates for efficient training and effective performance. Arnold outperforms average humans as well as in-built game bots on different variations of the deathmatch. It also obtained the highest kill-to-death ratio in both the tracks of the Visual Doom AI Competition and placed second in terms of the number of frags.	arnold;artificial neural network;atari;autonomous agent;autonomous robot;deep learning;doom;floating point systems;high- and low-level;noise shaping;observable;pixel;reinforcement learning	Devendra Singh Chaplot;Guillaume Lample	2017			autonomous agent;simulation;computer science	AI	18.587661076914465	-19.65729458182539	71309
a4c0547cdd774734c364048ce2f7f5572dcca793	neural net based prognostics for an industrial semiconductor fabrication system	proof of principle experiment;neural networks;neural nets;soft computing;maintenance engineering;industrial semiconductor fabrication system semiconductor fabrication machinery health data soft computing neural network proof of principle experiment prognostics;neural networks prognostics soft computing;neural net;industrial semiconductor fabrication system;semiconductor device manufacture;neural networks textile industry fabrication data engineering machinery job shop scheduling processor scheduling computer networks design engineering lead compounds;semiconductor fabrication machinery;process engineering;semiconductor device manufacture maintenance engineering neural nets;health data;prognostics;proof of principle;neural network	Modern semiconductor fabrication machinery has the capability to generate huge volumes of health data, well beyond the capability of the typical process engineer to discern the subtle clues it contains. This data holds the key to performing periodic maintenance on an as-needed basis, rather than on a schedule. Soft computing techniques such as neural networks can allow the engineer to use this data to detect the need for maintenance. This paper discusses useful tools to accomplish the above goal and describes the results of proof-of-principle experiments, which prior to the receipt of actual data, which will eventually lead to prototype testing on the actual semiconductor fabrication systems	artificial neural network;experiment;prototype;schedule (computer science);semiconductor device fabrication;semiconductor fabrication plant;soft computing	Victor M. Stone;Mehrdad Jamshidi	2005	2005 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2005.1571361	computer science;machine learning;proof of concept;artificial neural network;prognostics	Robotics	13.715857635535773	-16.469541786245923	71472
0f9226513ef3a6bba1e53e46a70ef6f021ccfb7e	safe cell, safe battery? battery fire investigation using fmea, fta and practical experiments		Incidents of electrical vehicle catching fire forced on a root cause analysis. Failure mode and effects analysis (FMEA) and fault tree analysis (FTA) approaches were used for failure analysis and to design experiments on the battery system level. Analysis focused on the behaviour of an internal short circuit of a cell and its effect on the battery system and the vehicle. An internal short circuit of a stand-alone cell leads to venting and the release of dense smoke, however no fire or explosion occurred which complies with manufacturer declaration and hazard assessments according to battery safety standards. When such cell venting was triggered in the battery system it could be demonstrated that electric sparks on the carbonizing cell battery management print ignite the smoke and eventually lead to a fire of the complete vehicle. It has been shown that the use of comparatively safe Lithium-Iron-Phosphate cells does not entail a safe battery. The identification of the fire root cause enabled to develop and successfully test a mitigation method preventing fire caused by this failure mode.	experiment;failure mode and effects analysis;fault tree analysis	Marcel Held;R. Brönnimann	2016	Microelectronics Reliability	10.1016/j.microrel.2016.07.051	structural engineering;engineering;forensic engineering;waste management	Robotics	12.152348075215786	-11.015806803066177	71553
4b2e56841a9fcd9a3a6aee570dc1c7891800e6ca	bayesian changepoint detection for generic adaptive simulation algorithms	bayesian statistics;component based simulation software;adaptive simulation algorithms;changepoint detection	Adaptive simulation algorithms are used to deal with changing computational demands of simulations due to state changes of the model and the environment. If such an algorithm is developed in a generic manner, i.e., it is not equipped by the developer with a function which decides how to switch its configuration, sophisticated techniques like machine learning need to be exploited. Since adaptations can be costly, it is not practicable to adapt after each simulation step. Consequently, a fundamental challenge of generic adaptive simulation algorithms is to decide when to execute adaptations. For this, we present a dynamic algorithm based on Bayesian online changepoint detection. By observing performance values regularly, this algorithm decides whether adaptations should be executed or not. We evaluate our approach based on a benchmark model defined in PDEVS and a model used in simulation studies defined in ML-Rules. Both modeling formalisms exhibit different dynamics and different requirements for adaptation and thus underline the generality of the adaptation strategy. Altogether, we present how the proposed Bayesian changepoint detection strategy helps balancing the effort required for adaptation, possible speed-up by this adaption, and the effectiveness of the machine learning algorithm.	algorithm;simulation	Tobias Helms;Oliver Reinhardt;Adelinde M. Uhrmacher	2015			simulation;computer science;artificial intelligence;machine learning	ML	19.723245677442737	-16.247941791918855	71623
498ca63cfc80341b93773610f5e62699fe109edd	combining stochastic and greedy search in hybrid estimation	hybrid dynamical system;approximate algorithm;stochastic method;search method;state estimation;constraint satisfaction;rao blackwellised particle filter;posterior distribution;stochastic search	Techniques for robot monitoring and diagnosis have been developed that perform state estimation using probabilistic hybrid discrete/continuous models. Exact inference in hybrid dynamic systems is, in general, intractable. Approximate algorithms are based on either 1) greedy search, as in the case of k-best enumeration or 2) stochastic search, as in the case of Rao-Blackwellised Particle Filtering (RBPF). In this paper we propose a new method for hybrid state estimation. The key insight is that stochastic and greedy search methods, taken together, are often particularly effective in practice. The new method combines the stochastic methods of RBPF with the greedy search of k-best in order to create a method that is effective for a wider range of estimation problems than the individual methods alone. We demonstrate this robustness on a simulated acrobatic robot, and show that this benefit comes at only a small performance penalty.	approximation algorithm;dynamical system;greedy algorithm;particle filter;robot;stochastic optimization;stochastic process	Lars Blackmore;Stanislav Funiak;Brian C. Williams	2005			greedy randomized adaptive search procedure;mathematical optimization;constraint satisfaction;machine learning;posterior probability;statistics	Robotics	23.798447857597058	-15.262662106952973	71753
ae1bcbb34271cd9dcf3612ab8053daea7deff4d5	short-term load forecasting of lssvm based on improved pso algorithm		Based on the empirical, the precision of the forecasting will directly affect the reliability, economy and quality of power supply in power system. An improved particle swarm optimizer (IPSO) is proposed to be used on the least squares support vector machine (LSSVM) algorithm, which optimized the initialization parameters and improved the accuracy of short-term load forecasting. This thesis use the historical data of a certain grid to set up the short-term load forecasting model based on the optimization algorithm. While the data had comprehensive consideration the meteorology, weather, date, type and other factors which influencing the load. Compare with the LSSVM algorithm and the standard PSO-LSSVM, the empirical results show that IPSO-LSSVM model is more applicable in terms of convergence effect, accurate prediction and fast speed. The IPSO not only improves the accuracy of load forecasting, but also prevents LSSVM from great reliance on empirical results and random selection.	algorithm;particle swarm optimization	Qianhui Gong;Wenjun Lu;Wenlong Gong;Xueting Wang	2014		10.1007/978-3-662-45646-0_7	grid;mathematical optimization;electric power system;initialization;least squares support vector machine;convergence (routing);computer science;particle swarm optimization	Robotics	10.195481684339647	-17.552911282675968	72219
f6e3efaf45e2a044d23ecdf30debd6e9f57d637f	artificial neural networks for the prediction of thermo physical properties of diacetone alcohol mixtures	physical properties;artificial neural network	A predictive method based on Artificial networks has been developed for the thermophysical properties of binary liquid mixtures of diacetone alcohol with benzene, chlorobenzene and bromobenzene at (303.15,313.15 and 323.15) K. In method 1, a committee ANN was trained using 5 physical properties combined with absolute temperature as its input to predict thermo physical properties of liquid mixtures. Using these data we found out the predicted data for intermediate mole fraction of different systems without conducting experiments. ANN with back-propagation algorithm is proposed, for Multi-pass Turning Operation and developed in MATLAB. Compared to other prediction techniques, the proposed ANN approach is highly accurate and error is <1%.	algorithm;artificial neural network;backpropagation;experiment;matlab;neural networks;software propagation	T. R. Kubendran;R. Baskaran;M. Balakrishna	2008	Computer and Information Science		computer science;machine learning;physical property;artificial neural network	ML	12.598583743654833	-20.58309166132465	72493
b7f22251bef9c4d29ee20aac7da3860a0a3190bd	a generic solution to multi-armed bernoulli bandit problems based on random sampling from sibling conjugate priors	random sampling;conjugate prior;general solution	The Multi-Armed Bernoulli Bandit (MABB) problem is a classical optimization problem where an agent sequentially pulls one of multiple arms attached to a gambling machine, with each pull resulting in a random reward. The reward distributions are unknown, and thus, one must balance between exploiting existing knowledge about the arms, and obtaining new information. Although poised in an abstract framework, the applications of the MABB are numerous (Gelly and Wang, 2006; Kocsis and Szepesvari, 2006; Granmo et al., 2007; Granmo and Bouhmala, 2007) . On the other hand, while Bayesian methods are generally computationally intractable, they have been shown to provide a standard for optimal decision making. This paper proposes a novel MABB solution scheme that is inherently Bayesian in nature, and which yet avoids the computational intractability by relying simply on updating the hyperparametersof the sibling conjugate distributions, and on simultaneously sampling randomly from the respective posteriors. Although, in principle, our solution is generic, to be concise, we present here the strategy for Bernoulli distributed rewards. Extensive experiments demonstrate that our scheme outperforms recently proposed bandit playing algorithms. We thus believe that our methodology opens avenues for obtaining improved novel solutions.	algorithm;algorithmic efficiency;automaton;bernoulli polynomials;bernoulli scheme;coat of arms;computational complexity theory;euler–bernoulli beam theory;experiment;exploit (computer security);game theory;gaussian (software);mathematical optimization;monte carlo method;multi-agent system;multi-armed bandit;multinomial logistic regression;optimization problem;randomness;regret (decision theory);sampling (signal processing);stationary process;word lists by frequency	Thomas Norheim;Terje Brådland;Ole-Christoffer Granmo;B. John Oommen	2010			sampling;mathematical optimization;computer science;conjugate prior	AI	23.282069964609914	-17.752770036158793	72631
d3b45d73e57a6d2a2e8ca8deef00416b34ce1f61	on the deployment and noise filtering of vehicular radar application for detection enhancement in roads and tunnels	noise filtering;radar installation;radar sensor;roadside and tunnel	Recently, radar technology has attracted attention for the realization of an intelligent transportation system (ITS) to monitor, track, and manage vehicle traffic on the roads as well as adaptive cruise control (ACC) and automatic emergency braking (AEB) for driving assistance of vehicles. However, when radar is installed on roads or in tunnels, the detection performance is significantly dependent on the deployment conditions and environment around the radar. In particular, in the case of tunnels, the detection accuracy for a moving vehicle drops sharply owing to the diffuse reflection of radio frequency (RF) signals. In this paper, we propose an optimal deployment condition based on height and tilt angle as well as a noise-filtering scheme for RF signals so that the performance of vehicle detection can be robust against external conditions on roads and in tunnels. To this end, first, we gather and analyze the misrecognition patterns of the radar by tracking a number of randomly selected vehicles on real roads. In order to overcome the limitations, we implement a novel road watch module (RWM) that is easily integrated into a conventional radar system such as Delphi ESR. The proposed system is able to perform real-time distributed data processing of the target vehicles by providing independent queues for each object of information that is incoming from the radar RF. Based on experiments with real roads and tunnels, the proposed scheme shows better performance than the conventional method with respect to the detection accuracy and delay time. The implemented system also provides a user-friendly interface to monitor and manage all traffic on roads and in tunnels. This will accelerate the popularization of future ITS services.	analog expansion bus;cns disorder;delphi technique;deploy;diffuse reflection;distributed computing;drug vehicle;emergency medical service;experiment;interface device component;radar;radio frequency;randomness;real-time clock;usability	Young-Duk Kim;Guk-Jin Son;Chan-Ho Song;Heekang Kim	2018		10.3390/s18030837	radar engineering details;software deployment;engineering;radar;real-time computing;electronic engineering;radio frequency;filter (signal processing);intelligent transportation system;data processing;cruise control	Mobile	15.43916860678687	-11.716192742255037	73049
7f3f20f7946a1dd42ae6714c7a036572e39ce6ef	towards flexible teamwork in persistent teams: extended report	long period;multi agent system;generic model;persistence;real time;model based approach;search trees;multi agent systems;decision theoretic;communicative action;markov decision process;markov decision processes;teamwork	Teamwork is a critical capability in multi-agent environments. Many such environments mandate that the agents and agent-teams must be persistent i.e., exist over long periods of time. Agents in such persistent teams are bound together by their long-term common interests and goals. This paper focuses on flexible teamwork in such persistent teams. Unfortunately, while previous work has investigated flexible teamwork, persistent teams remain unexplored. For flexible teamwork, one promising approach that has emerged is model-based, i.e., providing agents with general models of teamwork that explicitly specify their commitments in teamwork. Such models enable agents to autonomously reason about coordination. Unfortunately, for persistent teams, such models may lead to coordination and communication actions that while locally optimal, are highly problematic for the team's long-term goals. We present a decision-theoretic technique based on Markov decision processes to enable persistent teams to overcome such limitations of the model-based approach. In particular, agents reason about expected team utilities of future team states that are projected to result from actions recommended by the teamwork model, as well as lower-cost (or higher-cost) variations on these actions. To accommodate real-time constraints, this reasoning is done in an any-time fashion. Implemented examples from an analytic search tree and some real-world domains are presented.	autonomous robot;local optimum;markov chain;markov decision process;multi-agent system;persistence (computer science);real-time locating system;search tree;theory;tiger team	Milind Tambe;Weixiong Zhang	2000	Autonomous Agents and Multi-Agent Systems	10.1023/A:1010026728246	markov decision process;simulation;computer science;knowledge management;artificial intelligence;multi-agent system	AI	20.026832258628282	-15.723920272012382	73192
1ad3e120630499f1203a5f84b61fb4ba3e3a11e9	epsilon focusing--a strategy for active example selection	computer vision;learning from examples;concept learning;face detection	In most classical formulations of learning from examples, a passive learner is presented with examples randomly drawn. Here we discuss an-focusing strategy that actively choose examples for concept learning. We describe the local focused property that functions must have for such a strategy to work. Finally, we develop an example selection heuristic, motivated by-focusing, for training a computer vision system to perform a human face detection task.	computer vision;concept learning;face detection;heuristic;randomness;sample complexity	Partha Niyogi;Kah Kay Sung	1998	Knowl.-Based Syst.	10.1016/S0950-7051(98)00039-2	face detection;simulation;concept learning;computer science;artificial intelligence;machine learning	ML	22.191470482690963	-21.311221344072276	73466
9c48d5ce478cb2545b9a8fb2a9cf2b6f95351168	wave height forecasting using cascade correlation neural network	learning rate;activation function;convergence rate;multi layer perceptron;training algorithm;neural network	Forecasting of wave height is necessary in a large number of ocean coastal activities. Recently, neural networks are used for prediction and approximation of wave heights in sea and ocean due to their great convergence rate. In this paper a cascade correlation neural network is used for prediction of wave heights at given times due to the useful capability of this network for prediction and approximation. Results of different prediction for 500 data points in cascade correlation neural network are compared with those of the M.L.P. (Multi-layer Perceptron) neural network. These results show that cascade correlation network has larger convergence rate compared with M.L.P. network. Also various simulations show that the cascade correlation network has better performance with α=0.005 (Learning-rate), sigmoid activation function for hidden units and linear activation function for output units.	activation function;approximation;artificial neural network;data point;multilayer perceptron;rate of convergence;sigmoid function;simulation	Hamidreza Rashidy Kanan;Karim Faez	2004			probabilistic neural network;computer science;artificial intelligence;machine learning;rate of convergence;multilayer perceptron;activation function;artificial neural network	ML	10.090141550259021	-21.243682907806832	73473
d3d99c189ed530cb07a2119af854dedd66827a5a	voltage sag source location from extracted rules using subgroup discovery	voltage sag dip source location;voltage sag;subgroup discovery;machine learning;power quality monitoring;cn2 sd;fault location	This work presents a set of rules to determine the voltage sag source location in electric power systems. The rule set is extracted using subgroup discovery (SD). The SD objective is to discover characteristics of subgroups with respect to a specific property of interest. Our interest is to obtain the origin of sag events, upstream or downstream from the measurement point. Voltage sag features registered in electric substations are used as input data to SD algorithm. The SD algorithm used is CN2-SD to learn descriptive rules. Results show the rules extracted can be easily interpreted by a domain expert, allowing the formulation of heuristic classification rules with high accuracy.		Víctor Barrera;Beatriz López;Joaquím Meléndez;Jorge Sánchez	2008		10.3233/978-1-58603-925-7-225	engineering;operations management;forensic engineering;engineering drawing	ML	11.269339525007007	-13.734987281535759	73660
cfbb7dff305125ce0f5fcabb0e7168b55e858044	development of quantum local potential function networks based on quantum assimilation and subspace division	subspace division local potential function lpf network structure adaptation quantum assimilation schrodinger equation;computational modeling mathematical model adaptation models quantum computing data models quantum mechanics training data	The centers and radii of radial basis functions (RBFs) greatly affect the approximation capability of RBF networks (RBFNs). Traditional statistics-based approaches are widely used, but they may lack adaptivity to different data structures. Quantum clustering (QC), derived from quantum mechanics and the Schrödinger equation, demonstrates excellent capability in finding the structure and conformity toward data distribution. In this paper, a novel neural networks model called quantum local potential function networks (QLPFNs) is proposed. The QLPFN inherits the outstanding properties of QC by constructing the waves and the potential functions, and the level of data concentration can be discovered to obtain the inherent structures of the given data set. The local potential functions form the basic components of the QLPFN structure, which are automatically generated from the subsets of training data following specific subspace division procedures. Therefore, the QLPFN model in fact incorporates the level of data concentration as a computation technique, which is different from the classical RBFN model that exhibits radial symmetry toward specific centers. Some application examples are given in this paper to show the effectiveness of the QLPFN model.	approximation;artificial neural network;benchmark (computing);cluster analysis;computation (action);conformity;data assimilation;data structure;exhibits as topic;general linear model;maxima and minima;network model;neural network simulation;quantum mechanics;radial (radio);radial basis function network;schrödinger;test set;time series;verification of theories;negative regulation of skeletal muscle acetylcholine-gated channel clustering;statistical cluster	Yiqian Cui;Junyou Shi;Zili Wang	2018	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2016.2614840	quantum operation;quantum probability;computer science;theoretical computer science;mathematics;quantum statistical mechanics;quantum algorithm;quantum phase estimation algorithm	ML	10.416987557768717	-21.757479687756792	74178
1dfd7c09c50a793e56ab5449221e0b2b00e1663c	co-evolution in the successful learning of backgammon strategy	feedforward neural network;evaluation function;reinforcement;backpropagation;coevolution;self learning;backgammon;temporal difference learning	Following Tesauro's work on TD-Gammon, we used a 4,000 parameter feedforward neural network to develop a competitive backgammon evaluation function. Play proceeds by a roll of the dice, application of the network to all legal moves, and selection of the position with the highest evaluation. However, no backpropagation, reinforcement or temporal difference learning methods were employed. Instead we apply simple hillclimbing in a relative fitness environment. We start with an initial champion of all zero weights and proceed simply by playing the current champion network against a slightly mutated challenger and changing weights if the challenger wins. Surprisingly, this worked rather well. We investigate how the peculiar dynamics of this domain enabled a previously discarded weak method to succeed, by preventing suboptimal equilibria in a “meta-game” of self-learning.	artificial neural network;backpropagation;evaluation function;feedforward neural network;td-gammon;temporal difference learning	Jordan B. Pollack;Alan D. Blair	1998	Machine Learning	10.1023/A:1007417214905	temporal difference learning;reinforcement;feedforward neural network;simulation;coevolution;computer science;artificial intelligence;backpropagation;machine learning;evaluation function	ML	17.95488206819504	-20.783013852378275	74418
ad4536ee02356bc1613e768a229edcb2318052e5	forecast of pv power generation based on residual correction of markov chain	forecasting;markov chain pv power generation prediction model gray neural network;neural networks;predictive models power generation neural networks forecasting mathematical model meteorology markov processes;mathematical model;power generation;predictive models;markov processes;meteorology	With the increase of the capacity of photovoltaic (PV) systems, how to alleviate the problem caused by the random output power of PV system becomes significant. This paper uses Markov model to correct prediction results of power generation for grid-connected PV system based on gray neural network model. Using the hourly data of PV system output power under similar climate conditions, gray model of the output power is established in real-time. Then, the output of the gray model, the temperature, irradiance and measured values are used to build the prediction model with neural network, and the residual is corrected by Markov chain. The accuracy of model is researched under three typical weather conditions. The results show that this model gains the high precision, and the efficiency is comparatively better in sunny and cloudy condition than low irradiance. The proposed method reflects the actual trend of the PV generations, which can be successfully applied to engineering and scientific research.	artificial neural network;markov chain;markov model;network model;page view;real-time clock;real-time computing	Kun Ding;Li Feng;Xiuli Wang;Siyu Qin;Jing Mao	2015	2015 International Conference on Control, Automation and Information Sciences (ICCAIS)	10.1109/ICCAIS.2015.7338692	electricity generation;econometrics;simulation;forecasting;computer science;engineering;mathematical model;mathematics;predictive modelling;markov process;artificial neural network;statistics	Robotics	10.061229689766968	-18.305414406057515	74489
d6dd9ce35d06d5a45ebff81b3bbeb8c9f06352a0	temporal convolutional memory networks for remaining useful life estimation of industrial machinery		Accurately estimating the remaining useful life (RUL) of industrial machinery is beneficial in many real-world applications. Estimation techniques have mainly utilized linear models or neural network based approaches with a focus on short term time dependencies. This paper, introduces a system model that incorporates temporal convolutions with both long term and short term time dependencies. The proposed network learns salient features and complex temporal variations in sensor values, and predicts the RUL. A data augmentation method is used for increased accuracy. The proposed method is compared with several state-of-the-art algorithms on publicly available datasets. It demonstrates promising results, with superior results for datasets obtained from complex environments.		Lahiru Jayasinghe;Tharaka Samarasinghe;Chau Yuen;Shuzhi Sam Ge	2018	CoRR		estimation;machine learning;artificial intelligence;artificial neural network;term (time);linear model;mathematics;system model	ML	14.51777501740096	-16.429868101554852	74666
ebca11cfd9aeb148541805ce12e64f0a144d59c5	experiments with online reinforcement learning in real-time strategy games	reinforcement learning;real time strategy;computational complexity;state space;computer game	Real-Time Strategy (RTS) games provide a challenging platform to implement online reinforcement learning (RL) techniques in a real application. Computer as one player monitors opponents’ (human or other computers) strategies and then updates its own policy using RL methods. In this paper, we firstly examine the suitability of applying the online RL in various computer games. RL application depends much on both RL complexity and the game features. We then propose a multi-layer framework for implementing online RL in an RTS game. The framework significantly reduces RL computational complexity by decomposing the state space in a hierarchical manner. We implement an RTS game Tank General, and perform a thorough test on the proposed framework. We consider three typical profiles of RTS game players and compare two basic RL techniques applied in the game. The results show the effectiveness of our proposed framework and shed light on relevant issues on using online RL in RTS games.	computational complexity theory;computer;experiment;interaction;layer (electronics);pc game;profiling (computer programming);rl (complexity);real-time transcription;reinforcement learning;state space	Kresten Toftgaard Andersen;Yifeng Zeng;Dennis Dahl Christensen;Dung Tran	2009	Applied Artificial Intelligence	10.1080/08839510903246526	simulation;computer science;state space;artificial intelligence;machine learning;computational complexity theory;reinforcement learning	AI	18.990423364629358	-16.858753198958645	74778
f232600fd40beee605366165c6c64655222718d3	artificial neural network application of modeling failure rate for boeing 737 tires	neural networks;weibull regression model;failure rate;reliability analysis;modeling;back propagation;artificial neural network	Abstract#R##N##R##N#This paper presents an application of artificial neural network (ANN) technique for conducting the reliability analysis of Boeing 737 tires. For this purpose, an ANN model utilizing the feed-forward back-propagation algorithm as a learning rule is developed. The inputs to the neural network are the flight operational time and the number of landings as independent variables and the output is the failure rate of the tires. Two years of data are used for failure rate prediction model and validation. Model validation, which reflects the suitability of the model for future predictions, is performed by comparing the predictions of the model with that of Weibull regression model. The results show that the failure rate predicted by the ANN is closer in agreement with the actual data than the failure rate predicted by the Weibull model. The present work also identifies some of the common tire failures and presents representative results based on the established model for the most frequently occurring tire failure. Copyright © 2010 John Wiley & Sons, Ltd.	artificial neural network;failure rate	Ahmed Z. Al-Garni;Ahmad Jamal	2011	Quality and Reliability Eng. Int.	10.1002/qre.1114	systems modeling;engineering;artificial intelligence;backpropagation;failure rate;forensic engineering;operations research;artificial neural network	NLP	12.742756473359007	-18.089597007108615	75245
6a5a112504e324ccffb118b4c249ee5847330973	design of online water quality monitoring system and prediction based on probabilistic neural network	online monitoring;dust pollutants;soa;chemical oxygen demand;water quality;environmental protection;scalable systems;ph;light intensity;humidity;probabilistic neural networks;embedded linux;arm processor;rain drainage;cod;water pollution;temperature;water flow;china;service oriented architecture;operating systems	Online water quality monitoring systems have many significant benefits in fields such as source water protection, water treatment, and wastewater discharge, and in accidental or deliberate event of water contamination. It is also used to provide proofs and early warning for companies that discharge industrial wastewater. A typical online water quality monitoring system can collect data about specified factors automatically and continuously, analyse data, present data, store data and transfer data. This paper introduces the authors’ application in BASF Shanghai Coatings Co., Ltd, a scalable online water quality monitoring system that focuses on rain drainage. The hardware platform of this system is based on an ARM processor and embedded Linux operating system; the software platform of this system is SOA (Service-Oriented Architecture). Owing to the generic designed hardware and software platform structure, this system is also competent for other environment protection monitoring applications if the user modifies the software settings as he needs. Meanwhile, this paper suggests a method using a probabilistic neural network to predict COD (Chemical Oxygen Demand) value. pH (Hydrogen Ion Concentration), temperature, water drainage traffic flow, humidity and light intensity were used as five input variables, while COD was used as the output variable.	arm architecture;artificial neural network;client (computing);computer data storage;discharger;embedded system;error-tolerant design;hydrogen;industrial robot;kerrison predictor;linux on embedded systems;operating system;predictor–corrector method;probabilistic neural network;remote terminal unit;scalability;server (computing);service-oriented architecture;service-oriented device architecture;user interface	Lu Dai;Xiong Chen	2016	IJWMC	10.1504/IJWMC.2016.078219	real-time computing;simulation;telecommunications;computer science;operating system;service-oriented architecture;computer security	ML	15.363693224860514	-12.880309605255999	75430
c5b98b48a260c8c7bd654e669d7dc533bcd98587	ace-rl-checkers: decision-making adaptability through integration of automatic case elicitation, reinforcement learning, and sequential pattern mining	artificial intelligence;machine learning;reinforcement learning;case-based reasoning;automatic case elicitation;sequential pattern mining;consecutive binary subsequences	In agents that operate in environments where decision-making needs to take into account, not only the environment, but also the minimizing actions of an opponent (as in games), it is fundamental that the agent is endowed with the ability of progressively tracing the profile of its adversaries, in such a manner that this profile aids in the process of selecting appropriate actions. However, it would be unsuitable to construct an agent with a decision-making system based only on the elaboration of such a profile, as this would prevent the agent from having its “own identity,” which would leave the agent at the mercy of its opponent. Following this direction, this study proposes an automatic Checkers player, called ACE-RL-Checkers, equipped with a dynamic decision-making module, which adapts to the profile of the opponent over the course of the game. In such a system, the action selection process is conducted through a composition of multilayer perceptron neural network and case library. In this case, the neural network represents the “identity” of the agent, i.e., it is an already trained static decision-making module. On the other hand, the case library represents the dynamic decision-making module of the agent, which is generated by the Automatic Case Elicitation technique. This technique has a pseudo-random exploratory behavior, which allows the dynamic decision-making of the agent to be directed either by the opponent’s game profile or randomly. In order to avoid a high occurrence of pseudo-random decision-making in the game initial phases—in which the agent counts on very little information about its opponent—this work proposes a new module based on sequential pattern mining for generating a base of experience rules extracted from human expert’s game records. This module will improve the agent’s move selection in the game initial phases. Experiments carried out in tournaments involving ACE-RL-Checkers and other agents correlated to this work, confirm the superiority of the dynamic architecture proposed herein.	ace;action selection;artificial neural network;data mining;multilayer perceptron;pseudorandomness;randomness;reinforcement learning;sequential pattern mining;tracing (software)	Henrique Castro Neto;Rita Maria da Silva Julia	2018	Knowledge and Information Systems	10.1007/s10115-018-1175-0	machine learning;adaptability;artificial neural network;reinforcement learning;artificial intelligence;architecture;elicitation technique;action selection;multilayer perceptron;elaboration;computer science	AI	17.92518101823159	-19.991111601878337	75493
3ac84fcf8b6d9c54ea469e76849ae9cf4638f04e	reinforcement learning in the game of othello: learning against a fixed opponent and learning from self-play	game theory;self play learning;multilayer perceptrons;training;sarsa algorithm;testing;reinforcement learning algorithms;multilayer perceptrons reinforcement learning algorithms othello game artificial agent self play learning q learning algorithm sarsa algorithm td learning algorithm;artificial neural networks;multi agent systems;heuristic algorithms;games;multilayer perceptrons computer games game theory learning artificial intelligence multi agent systems;games training learning artificial intelligence artificial neural networks heuristic algorithms testing;learning artificial intelligence;computer games;othello game;q learning algorithm;td learning algorithm;artificial agent	This paper compares three strategies in using reinforcement learning algorithms to let an artificial agent learn to play the game of Othello. The three strategies that are compared are: Learning by self-play, learning from playing against a fixed opponent, and learning from playing against a fixed opponent while learning from the opponent's moves as well. These issues are considered for the algorithms Q-learning, Sarsa and TD-learning. These three reinforcement learning algorithms are combined with multi-layer perceptrons and trained and tested against three fixed opponents. It is found that the best strategy of learning differs per algorithm. Q-learning and Sarsa perform best when trained against the fixed opponent they are also tested against, whereas TD-learning performs best when trained through self-play. Surprisingly, Q-learning and Sarsa outperform TD-learning against the stronger fixed opponents, when all methods use their best strategy. Learning from the opponent's moves as well leads to worse results compared to learning only from the learning agent's own moves.	algorithm;intelligent agent;machine learning;multilayer perceptron;q-learning;reinforcement learning;reversi;state-action-reward-state-action;temporal difference learning	Michiel van der Ree;Marco Wiering	2013	2013 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)	10.1109/ADPRL.2013.6614996	simulation;computer science;artificial intelligence;machine learning;fictitious play	ML	17.980259987653493	-20.888223383747153	75513
75a760c6bd5ae15e0fc489a074bc42bc1fc4e697	safe, multi-agent, reinforcement learning for autonomous driving.		Autonomous driving is a multi-agent setting where the host vehicle must apply sophisticated negotiation skills with other road users when overtaking, giving way, merging, taking left and right turns and while pushing ahead in unstructured urban roadways. Since there are many possible scenarios, manually tackling all possible cases will likely yield a too simplistic policy. Moreover, one must balance between unexpected behavior of other drivers/pedestrians and at the same time not to be too defensive so that normal traffic flow is maintained. In this paper we apply deep reinforcement learning to the problem of forming long term driving strategies. We note that there are two major challenges that make autonomous driving different from other robotic tasks. First, is the necessity for ensuring functional safety — something that machine learning has difficulty with given that performance is optimized at the level of an expectation over many instances. Second, the Markov Decision Process model often used in robotics is problematic in our case because of unpredictable behavior of other agents in this multi-agent scenario. We make three contributions in our work. First, we show how policy gradient iterations can be used, and the variance of the gradient estimation using stochastic gradient ascent can be minimized, without Markovian assumptions. Second, we decompose the problem into a composition of a Policy for Desires (which is to be learned) and trajectory planning with hard constraints (which is not learned). The goal of Desires is to enable comfort of driving, while hard constraints guarantees the safety of driving. Third, we introduce a hierarchical temporal abstraction we call an “Option Graph” with a gating mechanism that significantly reduces the effective horizon and thereby reducing the variance of the gradient estimation even further. The Option Graph plays a similar role to “structured prediction” in supervised learning, thereby reducing sample complexity, while also playing a similar role to LSTM gating mechanisms used in supervised deep networks.	autonomous car;autonomous robot;driving simulator;gradient descent;iteration;long short-term memory;machine learning;markov chain;markov decision process;motion planning;multi-agent system;reinforcement learning;robotics;sample complexity;structured prediction;supervised learning;times ascent	Shai Shalev-Shwartz;Shaked Shammah;Amnon Shashua	2016	CoRR		computer science;machine learning;artificial intelligence;traffic flow;reinforcement learning;simulation;overtaking;markov decision process;abstraction;negotiation;functional safety;markov process	AI	20.038293859826094	-18.549142505544996	75644
0307f64de30354f5e0f0169c18d6aa7d4f95410e	neural modelling of mooney viscosity of polybutadiene rubber	quality assurance;grnn;polybutadiene rubber;computacion informatica;neural networks;mooney viscosity;data collection;reliability modeling;grupo de excelencia;input output;general regression neural network;process parameters;ciencias basicas y experimentales;quimica;product quality;fluid viscosity;artificial neural network;neural network	Mooney viscosity is one of the important quality properties of polybutadiene rubber (PBR). It is important to implement appropriate measures to maintain and guarantee a uniform product quality required by the rubber processing industries. One major step towards quality assurance is the on line quality prediction of the product from the process parameters. This can be accomplished by developing a reliable model that predicts product quality as a function of process parameters. Artificial neural networks (ANN), which are capable of mapping highly complex and non-linear dependencies, have been adapted to develop models to predict Mooney and solution viscosity of PBR from process v ity (FV) f r networks. T d with new d ©	artificial neural network;farmville;nonlinear system;pbr theorem;rubber-hose cryptanalysis	G. Padmavathi;M. G. Mandan;S. P. Mitra;K. K. Chaudhuri	2005	Computers & Chemical Engineering	10.1016/j.compchemeng.2005.02.028	input/output;computer science;engineering;artificial intelligence;machine learning;forensic engineering;artificial neural network;data collection	ML	13.11814418861842	-19.29028479159671	75662
00f0537813045b01ca33c3b67fe45c5c41774595	neural modeling of vapor compression refrigeration cycle with extreme learning machine	support vector regression;swinburne;vapor compression refrigeration cycle;radial basis function;extreme learning machine;modeling;back propagation	In this paper, a single-hidden layer feed-forward neural network (SLFN) is used to model the dynamics of the vapor compression cycle in refrigeration and air-conditioning systems, based on the extreme learning machine (ELM). It is shown that the assignment of the random input weights of the SLFN can greatly reduce the training time, and the regularization based optimization of the output weights of the SLFN ensures the high accuracy of the modeling of the dynamics of vapor compression cycle and the robustness of the SLFN against high frequency disturbances. The new SLFN model is tested with the real experimental data and compared with the ones trained with the back propagation (BP), the support vector regression (SVR) and the radial basis function neural network (RBF), respectively, with the results that the high degree of prediction accuracy and strongest robustness against the input disturbances are achieved.		Lei Zhao;Wen-Jian Cai;Zhi-Hong Man	2014	Neurocomputing	10.1016/j.neucom.2013.03.058	support vector machine;radial basis function;systems modeling;vapor-compression refrigeration;computer science;artificial intelligence;backpropagation;machine learning	ML	12.198294512303544	-20.317924191752052	75834
bef9e828bc0e242830f99ac22365c6930f67b163	time series forecasting by evolving artificial neural networks using shuffle, cross-validation and ensembles	forecasting;time series forecasting;evolutionary computation;evolutionary neural network;time series;engineering system;artificial neural networks;ensembles;genetic algorithm;genetic algorithms;cross validation;evolutionary process;artificial neural network;evolutionary computing	Accurate time series forecasting are important for several business, research, and application of engineering systems. Evolutionary Neural Networks are particularly appealing because of their ability to design, in an automatic way, a model (an Artificial Neural Network) for an unspecified nonlinear relationship for time series values. This paper evaluates two methods to obtain the pattern sets that will be used by the artificial neural network in the evolutionary process, one called ”shuffle” and another one carried out with cross-validation and ensembles. A study using these two methods will be shown with the aim to evaluate the effect of both methods in the accurateness of the final forecasting.	artificial neural network;cross-validation (statistics);evolutionary algorithm;mit engineering systems division;neural networks;nonlinear system;time series	Juan Peralta;Germán Gutiérrez;Araceli Sanchis	2010		10.1007/978-3-642-15819-3_7	evolutionary programming;stochastic neural network;nervous system network models;genetic algorithm;computer science;artificial intelligence;machine learning;evolutionary acquisition of neural topologies;time series;data mining;time delay neural network;evolutionary robotics;artificial neural network;intelligent control;evolutionary computation	ML	12.254562115210943	-23.44035492623556	75976
4e4fb2aca19a0ea8df46099e23a11118671efd06	optimization of temporal processes: a model predictive control approach	tratamiento datos;modelo dinamico;extraction information;modelizacion;regressors;dynamique processus;predictive control;temporal processes;optimisation;industrial case study;evolutionary computation;tiempo diferido;optimizacion;analisis datos;information extraction;control horizons;nonlinear control systems;input variables;time delays;dynamic model;knowledge extraction;data processing;delay effects;traitement donnee;control modelo predicativo;predictive models predictive control data mining delay effects combustion mechanical variables control evolutionary computation upper bound input variables optimal control;dinamica proceso;algoritmo genetico;data mining;time delay;sustainability;preparacion serie fabricacion;model predictive control;upper bound;optimal control;optimization problem;modelisation;data analysis;process control combustion data mining delays evolutionary computation nonlinear control systems predictive control;delayed time;optimization data mining evolutionary strategy model predictive control nonlinear temporal process;estudio caso;fouille donnee;mathematical programming;commande mpc;data mining algorithm;modele dynamique;dynamic equation;process control;etude cas;algorithme genetique;evolutionary strategy;data mining algorithms;algorithme evolutionniste;temporal processing;analyse donnee;genetic algorithm;predictive models;algoritmo evolucionista;optimization;temps retard;combustion process temporal processes model predictive control nonlinear process evolutionary computation data mining algorithms regressors time delays prediction control horizons industrial case;nonlinear process;process planning;delay time;evolutionary algorithm;process dynamics;preparation gamme fabrication;modeling;programmation mathematique;tiempo retardo;prediction;busca dato;programacion matematica;combustion process;extraccion informacion;industrial case;combustion;temps differe;optimization model;delays;mechanical variables control;evolutionary computing	A dynamic predictive-control model of a nonlinear and temporal process is considered. Evolutionary computation and data mining algorithms are integrated for solving the model. Data-mining algorithms learn dynamic equations from process data. Evolutionary algorithms are then applied to solve the optimization problem guided by the knowledge extracted by data-mining algorithms. Several properties of the optimization model are shown in detail, in particular, a selection of regressors, time delays, prediction and control horizons, and weights. The concepts proposed in this paper are illustrated with an industrial case study in combustion process.	data mining;evolutionary algorithm;evolutionary computation;mathematical optimization;nonlinear system;optimization problem;program optimization;propagation delay;time-scale calculus	Zhe Song;Andrew Kusiak	2009	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2008.920680	quality control and genetic algorithms;mathematical optimization;simulation;computer science;artificial intelligence;machine learning;model predictive control;evolutionary computation	ML	16.028513620769086	-18.65625783917586	76469
8ca7436fe3463c132425f8c8f68efbcf888eb735	multilayer perceptron with particle swarm optimization for well log data inversion	multilayer perceptrons;well logging;well logging learning artificial intelligence multilayer perceptrons particle swarm optimisation radial basis function networks;radial basis function networks;multilayer perceptron mlp;particle swarm optimization with mutation mpso;rbf networks multilayer perceptron well log data inversion measured apparent conductivity true formation conductivity nonlinear input output mapping particle swarm optimization with mutation algorithm mpso algorithm real data application mlp network radial basis function networks;proceedings paper;training vectors testing particle swarm optimization approximation algorithms multilayer perceptrons;particle swarm optimization with mutation mpso apparent conductivity c a true formation conductivity c t multilayer perceptron mlp;true formation conductivity c t;learning artificial intelligence;apparent conductivity c a;particle swarm optimisation	A nonlinear mapping exists between the measured apparent conductivity (Ca) and the true formation conductivity (Ct). We adopt the multilayer perceptron (MLP) to approximate the nonlinear input-output mapping and propose the use of particle swarm optimization with mutation (MPSO) algorithm to adjust the weights in MLP. In the supervised training step, the input of the network is the measured Ca and the desired output is the Ct. MLP with optimal size 10-9-10 is chosen as the model. We have experiments in simulation and real data application. In simulation, there are 31 sets of simulated well log data, where 25 sets are used for training, and 6 sets are used for testing. After training the MLP network, input Ca, then Ct' can be inverted in testing process. Compared with radial basis function (RBF) networks and particle swarm optimization (PSO) method, the error of MPSO is the smallest. Also we apply it to the inversion of real field well log data. The result is acceptable. It shows that the proposed MPSO algorithm in MLP weight adjustments can perform the well log data inversion.	approximation algorithm;experiment;mathematical optimization;memory-level parallelism;multilayer perceptron;nonlinear system;particle swarm optimization;quad flat no-leads package;radial (radio);radial basis function network;simulation;whole earth 'lectronic link	Kou-Yuan Huang;Kai-Ju Chen;Ming-Che Huang;Liang-Chi Shen	2012	2012 IEEE International Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2012.6352214	well logging;mathematical optimization;multi-swarm optimization;geology;computer science;artificial intelligence;machine learning;multilayer perceptron	Robotics	13.447925719322395	-23.53604817361372	76534
153ec556c1c4d8b4c48c063f104bfe958fb57318	partial pathfinding using map abstraction and refinement	optimal solution;learning process;search algorithm;real time strategy	Classical search algorithms such as A* or IDA* are useful for computing optimal solutions in a single pass, which can then be executed. But in many domains agents either do not have the time to compute complete plans before acting, or should not spend the time to do so, due to the dynamic nature of the environment. Extensions to A* such as LRTA* address this problem by gradually learning an exact heurist ic function, but the learning process is quite slow. In this paper we introduce Partial–Refinement A* (PRA*), which can fully interleave planning and acting through path abstract ion and refinement. We demonstrate the effectiveness of PRA* in the domain of real–time strategy (RTS) games. In maps taken from popular RTS games, we show that PRA* is not only able to cleanly interleave planning and execution, but it is also able to do so with only minimal losses of optimality. Introduction and Related Work Consider the problem of driving a car from Los Angeles to New York. A human approaching this task would likely begin by first answering high-level questions, such as which states to drive through. But low-level decisions such as which lane on the highway to drive in will not even be considered until moments before it is necessary. Furthermore, if we take a short detour around traffic in Tulsa, we will not have to revise any computed plans about what to do after leaving Tusla. Similarly, if we change our final destination in New York, we do not have to re-plan our entire route; just the last few steps. In fact, we do not even have to consider these details until we arrive in New York. This planning involves several levels of reasoning. First, it requir es an abstract model of the world, so we can reason at both low levels (what lane to drive in) as well as high levels (what cities to visit en route). It also involves planning and executing partial plans or paths through the world. It would be unreasonable to consider planning every lane change for the entire trip before setting out. Yet, this is exactly how trad itional search algorithms have approached the task, buildin g a complete plan before starting. In this paper, we introduce the Path-Refinement A* (PRA*) algorithm which can build high-level plans about the world, and progressively refine Copyright c © 2005, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. them into low-level actions as needed. Partial-path refinement means building paths in a manner that interleaves acting and planning, and thus spreading cost of path computation more evenly over the path execution time. This is a highly desirable property, providing robustness in the fac e of a dynamic environment and minimizing the amount of recomputation that needs to be done when the world changes. One application we are particularly interested in is realtime strategy (RTS) games. RTS games make up a significant portion of the computer game market; titles such as Starcraft and Warcraft by Blizzard Entertainment have sold millions of copies. RTS players are assisted by the computer in tasks such as pathfinding, yet pathfinding also tends to be one of the most criticized parts of many games, because existing pathfinding systems can easily be confused. Addition ally, the real-time graphics and simulation demands of RTS games leave only a small portion of the CPU for AI tasks, meaning that pathfinding must be extremely efficient. RTS games can also be viewed as abstract simulations in which robots move around and interact. Therefore, robot navigation can also benefit from pathfinding algorithms which can interleave pathplanning and plan execution.	a* search algorithm;artificial intelligence;best, worst and average case;central processing unit;computation;forward error correction;graphics;high- and low-level;pc game;pathfinding;physical review a;real-time computing;real-time transcription;refinement (computing);robot;robotic mapping;run time (program lifecycle phase);simulation;starcraft	Nathan R. Sturtevant;Michael Buro	2005			simulation;computer science;artificial intelligence;machine learning;algorithm;search algorithm	AI	19.657421349746382	-13.626588010392267	76624
157ecac588239fe07795086e306991d53046bd50	application of improved neuro-fuzzy gmdh to predict scour depth at sluice gates	journal article;drntu engineering civil engineering water resources	An improved neuro-fuzzy based group method of data handling using the particle swarm optimization (NF-GMDH-PSO) is developed as an adaptive learning network to predict the localized scour downstream of a sluice gate with an apron. The input characteristic parameters affecting the scour depth are the sediment size and its gradation, apron length, sluice gate opening, and the flow conditions upstream and downstream of the sluice gate. Six non-dimensional parameters were yielded to define a functional relationship between the input and output variables. The training and testing of the NF-GMDH network are performed using published scour data from the literature. The efficiency of the training stages for the NF-GMDH-PSO is investigated. The testing results for the NF-GMDH network are compared with the traditional approaches based on regression method. A sensitivity analysis is carried out to assign the most significant parameter for the scour prediction. The results showed that the NF-GMDH-PSO network produced lower error in scour prediction than all other models.	database normalization;downstream (software development);evolutionary algorithm;expanded memory;group method of data handling;input/output;iterative and incremental development;mathematical optimization;neuro-fuzzy;particle swarm optimization;phase-shift oscillator;scour inc.;self-organization;soft computing	Mohammad Najafzadeh;Siow Yong Lim	2015	Earth Science Informatics	10.1007/s12145-014-0144-8	hydrology;computer science;geotechnical engineering	Graphics	12.232494923602514	-20.44094240486682	76757
691acb5247976c1785e9de2e5011698809ae7efa	stubborn sets pruning for privacy preserving planning		We adapt a partial order reduction technique based on stubborn sets to the setting of privacy-preserving multiagent planning. We prove that the presented approach preserves optimality and show experimentally that it can significantly improve search performance on some	agent-based model;experiment;heuristic (computer science);partial order reduction;privacy	Tim Schulte	2018			data mining;pruning;computer science	AI	18.367423861075547	-14.908881526332861	76820
3e4f6f726e3133b6e88c4c6ac197eff4fdc9d900	feature extraction-based method for voltage sag source location in the context of smart grids		The location of the voltage sag sources corresponds to an important task for the Power Quality area. However, this is not a trivial task due to the need of many monitoring devices. Therefore, with the data management from smart meters installed in distribution feeders, decision support tools that solve this problem become viable. Thus, this paper proposes an algorithm that determines the area where the voltage sag source is located. For this purpose, it was necessary to extract features from smart meters’ voltage signals. In the sequence, we analyze the relevance of each feature to establish the most significant of them. In this way, the smart meter could extract these features and send them to the utility. At the utility side, the proposed algorithm will estimate the region where the voltage sag source is located. The location procedure is performed by cross checking the most relevant features and the network topology.	algorithm;decision support system;electric power quality;feature extraction;machine learning;network topology;relevance;sensor;smart tv;smart meter	Fábbio A. S. Borges;Ivan Nunes da Silva;Ricardo A. S. Fernandes	2017		10.1007/978-3-319-62410-5_9	real-time computing;voltage;decision support system;smart grid;computer science;network topology;feature extraction;smart meter;voltage sag;data management	AI	11.251687906885817	-13.720546209573008	76862
111f5fed83602fd9b4c906d61b87fb414a3b5c4c	evaluating the usefulness of functional distance measures when calibrating journey-to-crime distance decay functions	modelizacion;journey to crime model;meurtre;luisiana;criminalite;murder;pedestrian safety;travel time;homicidio;north america;distribucion geografica;perfil;distance measure;america del norte;poison control;amerique du nord;amerique;analisis espacial;predictive value;injury prevention;safety literature;profile;travel;result;etats unis;traffic safety;injury control;estados unidos;methode calcul;home safety;metodo calculo;modelisation;viaje;injury research;safety abstracts;human factors;estudio caso;research evaluation;occupational safety;safety;distance metric;etude cas;distancia;resultado;safety research;repartition geographique;accident prevention;criminalidad;violence prevention;resultat;bicycle safety;criminal geographic profile;spatial analysis;serial offender;america;voyage;distance decay model;poisoning prevention;modeling;falls;ergonomics;louisiana;suicide prevention;analyse spatiale;computing method;distance;geographic distribution;criminality;profil;louisiane;functional distance	This research evaluates the usefulness of applying functional distance measures to criminal geographic profiles using mathematically calibrated distance decay models. Both the travelpath (i.e., shortest distance) and temporally optimized (i.e., quickest travel time) functional distance measures were calculated based on the impedance attributes stored within a linearly referenced transportation data layer of several parishes in Louisiana. Two different journey-tocrime distance decay functions (i.e., negative exponential, and truncated negative exponential) were mathematically calibrated for ‘‘best fit’’, based on the distribution of distances between homicide crime locations and offender s residences. Using the calibrated distance decay functions, geographic profiles were created for a localized serial killer from Baton Rouge, Louisiana. A probability score was calculated for every point within the study area to indicate the likelihood that it contained the serial offender s residence. A comparison between the predicted 0198-9715/$ see front matter 2004 Elsevier Ltd. All rights reserved. doi:10.1016/j.compenvurbsys.2004.10.002 * Corresponding author. Tel.: +1 225 578 2963; fax: +1 225 578 4420. E-mail addresses: jkent4@lsu.edu (J. Kent), mleitne@lsu.edu (M. Leitner), acurti1@lsu.edu (A. Curtis). 1 Tel.: +1 225 578 3476; fax: +1 225 578 7289. 2 Tel.: +1 225 578 6198; fax: +1 225 578 4420. 182 J. Kent et al. / Comput., Environ. and Urban Systems 30 (2006) 181–200 (highest probability score) and the actual residence of the serial offender determined the predictive value and procedural validity of functional distance metrics. 2004 Elsevier Ltd. All rights reserved.	baton;characteristic impedance;curve fitting;fax;like button;rouge (metric);temporal logic;time complexity	Josh Kent;Michael Leitner;Andrew Curtis	2006	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2004.10.002	systems modeling;metric;geography;suicide prevention;human factors and ergonomics;injury prevention;total variation distance of probability measures;mathematics;spatial analysis;forensic engineering;distance;computer security;cartography;statistics	Vision	13.762520150039837	-11.134108555077377	76905
a7ba65a2687d54ed44aaee76ebc0d5c1b97f6cbf	prediction of creep curve of hp40nb steel using artificial neural network		Simulation of creep curves using data obtained from a limited number of short-time creep tests is helpful for predicting the long-time creep life of materials by extrapolation techniques. The present paper demonstrates the application of artificial neural network (ANN) for the prediction of creep curves for HP40Nb micro-alloyed steel. The network consists of stress, temperature and time as the input parameters and the creep strain as the output parameter. The data used are taken from accelerated creep tests carried out at constant temperatures in the range 650–1050 °C and constant stresses 47–120 MPa. The network was trained using a three-layer feed-forward back-propagation network, having a 15-neuron hidden layer, using the Levenberg–Marquardt optimization algorithm. After successful network training, the model was subjected to several tests to demonstrate consistent prediction capability. 98% of the creep strain data could be predicted within an error of ±10% deviation from the experimental values. An additional experiment carried out to check the prediction capability of the model confirms very good prediction capability, with a correlation coefficient of 0.994, by ANN modeling.	artificial neural network;backpropagation;coefficient;extrapolation;feature creep;instruction creep;levenberg–marquardt algorithm;mathematical optimization;multitier architecture;parameter (computer programming);simulation;software propagation	Jeferson Panche;P. S. Robi	2017	Neural Computing and Applications	10.1007/s00521-017-2851-9	econometrics	ML	12.313125583813092	-20.042664329518022	77048
16ad03ac85e24432b05d485570ae721460610f5a	wi-fi/marg integration for indoor pedestrian localization	indoor pedestrian localization;pdr;ekpf;marg;wi fi	With the wide deployment of Wi-Fi networks, Wi-Fi based indoor localization systems that are deployed without any special hardware have caught significant attention and have become a currently practical technology. At the same time, the Magnetic, Angular Rate, and Gravity (MARG) sensors installed in commercial mobile devices can achieve highly-accurate localization in short time. Based on this, we design a novel indoor localization system by using built-in MARG sensors and a Wi-Fi module. The innovative contributions of this paper include the enhanced Pedestrian Dead Reckoning (PDR) and Wi-Fi localization approaches, and an Extended Kalman Particle Filter (EKPF) based fusion algorithm. A new Wi-Fi/MARG indoor localization system, including an Android based mobile client, a Web page for remote control, and a location server, is developed for real-time indoor pedestrian localization. The extensive experimental results show that the proposed system is featured with better localization performance, with the average error 0.85 m, than the one achieved by using the Wi-Fi module or MARG sensors solely.	affinity propagation;algorithm;android;artificial neural network;biological neural networks;built-in self-test;cluster analysis;course (navigation);dna integration;dead reckoning;deploy;design review (u.s. government);extended kalman filter;indoor positioning system;internationalization and localization;mobile device;particle filter;processor affinity;real-time clock;remote control;server (computer);server (computing);software propagation;velocity (software development);web page;sensor (device);statistical cluster	Zengshan Tian;Yue Jin;Mu Zhou;Zipeng Wu;Ze Li	2016		10.3390/s16122100	embedded system;simulation;telecommunications;engineering	Mobile	15.408533604965967	-11.577392270466387	77075
f420022058810907876d5f1245d4215c35e33358	improving reinforcement learning with interactive feedback and affordances	robots learning artificial intelligence training equations convergence cleaning green products;affordances reinforcement learning interactive feedback inter agent training knowledge transfer agent knowledge action space pruning;multi agent systems learning artificial intelligence	Interactive reinforcement learning constitutes an alternative for improving convergence speed in reinforcement learning methods. In this work, we investigate inter-agent training and present an approach for knowledge transfer in a domestic scenario where a first agent is trained by reinforcement learning and afterwards transfers selected knowledge to a second agent by instructions to achieve more efficient training. We combine this approach with action-space pruning by using knowledge on affordances and show that it significantly improves convergence speed in both classic and interactive reinforcement learning scenarios.	feedback;humanoid robot;iteration;reinforcement learning;simulation	Francisco Cruz;Sven Magg;Cornelius Weber;Stefan Wermter	2014	4th International Conference on Development and Learning and on Epigenetic Robotics	10.1109/DEVLRN.2014.6982975	error-driven learning;computer science;knowledge management;artificial intelligence;machine learning;hyper-heuristic	Robotics	18.963354973539104	-20.68643203291761	77156
c1c1494dfd44c15a72fe0652e8d3597c026f26e9	on reinforcement learning for full-length game of starcraft		StarCraft II poses a grand challenge for reinforcement learning. The main difficulties of it include huge state and action space and a long-time horizon. In this paper, we investigate a hierarchical reinforcement learning approach for StarCraft II. The hierarchy involves two levels of abstraction. One is the macro-action automatically extracted from expert’s trajectories, which reduces the action space in an order of magnitude yet remains effective. The other is a two-layer hierarchical architecture which is modular and easy to scale, enabling a curriculum transferring from simpler tasks to more complex tasks. The reinforcement training algorithm for this architecture is also investigated. On a 64x64 map and using restrictive units, we achieve a winning rate of more than 99% against the difficulty level-1 built-in AI. Through the curriculum transfer learning algorithm and a mixture of combat model, we can achieve over 93% winning rate of Protoss against the most difficult non-cheating builtin AI (level-7) of Terran, training within two days using a single machine with only 48 CPU cores and 8 K40 GPUs. It also shows strong generalization performance, when tested against never seen opponents including cheating levels built-in AI and all levels of Zerg and Protoss built-in AI. We hope this study could shed some light on the future research of large-scale reinforcement learning.	algorithm;built-in self-test;canonical account;central processing unit;grand challenges;graphics processing unit;principle of abstraction;reinforcement learning;starcraft	Zhen-Jia Pang;Ruo-Ze Liu;Zhou-Yu Meng;Yi Zhang;Yang Yu;Tong Lu	2018	CoRR		machine learning;transfer of learning;architecture;reinforcement learning;deep learning;multi-core processor;mathematics;modular design;hierarchy;artificial intelligence;reinforcement	AI	20.266884463698304	-22.109121098136225	77386
1326fc02038b157b26d0eadbe84e658dda3b7186	an approach to spacecraft anomaly detection problem using kernel feature space	high dimensionality;behavior modeling;von mises fisher;anomaly detection;kernel feature space;kernel function;international space station;time series;feature space;von mises fisher distribution;multi dimensional;a priori knowledge;principal component analysis;normal operator;time series data;qualitative reasoning;spacecraft;probabilistic reasoning;principal component;expert system	"""Development of advanced anomaly detection and failure diagnosis technologies for spacecraft is a quite significant issue in the space industry, because the space environment is harsh, distant and uncertain. While several modern approaches based on qualitative reasoning, expert systems, and probabilistic reasoning have been developed recently for this purpose, any of them has a common difficulty in obtaining accurate and complete a priori knowledge on the space systems from human experts. A reasonable alternative to this conventional anomaly detection method is to reuse a vast amount of telemetry data which is multi-dimensional time-series continuously produced from a number of system components in the spacecraft.This paper proposes a novel """"knowledge-free"""" anomaly detection method for spacecraft based on Kernel Feature Space and directional distribution, which constructs a system behavior model from the past normal telemetry data from a set of telemetry data in normal operation and monitors the current system status by checking incoming data with the model.In this method, we regard anomaly phenomena as unexpected changes of causal associations in the spacecraft system, and hypothesize that the significant causal associations inside the system will appear in the form of principal component directions in a high-dimensional non-linear feature space which is constructed by a kernel function and a set of data.We have confirmed the effectiveness of the proposed anomaly detection method by applying it to the telemetry data obtained from a simulator of an orbital transfer vehicle designed to make a rendezvous maneuver with the International Space Station."""	anomaly detection;behavior model;causal filter;expert system;feature vector;kernel (operating system);molecular orbital;nonlinear system;principal component analysis;probabilistic turing machine;simulation;time series	Ryohei Fujimaki;Takehisa Yairi;Kazuo Machida	2005		10.1145/1081870.1081917	anomaly detection;computer science;artificial intelligence;machine learning;time series;data mining;mathematics;expert system;statistics;principal component analysis	AI	14.538208687297507	-17.612394994914293	77479
e1128eba389cca88edfc14ea8890310d6f3625a9	decision-making on flow control under fuzzy conditions in the mechanical transport system		The article deals with the problem of moving flows in mechanical transport systems suitable for prevention or greatly decreasing the probability of emergency situations. The solution is based on minimizing costs during transportation. Routing methods considering the specifics of the MTS are analyzed. It’s developed routing algorithm with protective correction of flows with fuzzy temporal variability of adaptation. The algorithm consists in definition and establishment of high value of transportation cost on the particular segment of network on a fuzzy time interval. Methods for determining the parameters of protective correction of flows are studied. A structural diagram of the MTS, considering the protective correction, is presented. The diagram is implemented by introduction an intelligent module into the structure. Module operation feature is the use of case-based reasoning. The example of the implementation of protective correction of flows is given.	flow control (data)	Stanislav L. Belyakov;Marina Savelyeva;Dmitry Kiyashko;Anna Lashchenkova	2017		10.1007/978-3-319-66830-7_16	fuzzy logic;diagram;adaptive routing;control engineering;computer science;flow control (data)	Robotics	10.772651121850664	-9.896155505219607	77480
082b1f5c791cadef18c4920ecc1396615a3fe7cb	continual learning in reinforcement environments	learning;incremental learning	Continual learning is the constant development of complex behaviors with no nal end in mind. It is the process of learning ever more complicated skills by building on those skills already developed. In order for learning at one stage of development to serve as the foundation for later learning, a continual-learning agent should learn hierarchically. CHILD, an agent capable of Continual, Hierarchical, Incremental Learning and Development is proposed, described, tested, and evaluated in this dissertation. CHILD accumulates useful behaviors in reinforcement environments by using the Temporal Transition Hierarchies learning algorithm, also derived in the dissertation. This constructive algorithm generates a hierarchical, higher-order neural network that can be used for predicting context-dependent temporal sequences and can learn sequential-task benchmarks more than two orders of magnitude faster than competing neural-network systems. Consequently, CHILD can quickly solve complicated non-Markovian reinforcement-learning tasks and can then transfer its skills to similar but even more complicated tasks, learning these faster still. This continual-learning approach is made possible by the unique properties of Temporal Transition Hierarchies, which allow existing skills to be amended and augmented in precisely the same way that they were constructed in the rst place. Table of	algorithm;artificial neural network;context-sensitive language;reinforcement learning	Mark B. Ring	1995			semi-supervised learning;robot learning;multi-task learning;instance-based learning;error-driven learning;simulation;sequence learning;computer science;artificial intelligence;machine learning;stability;competitive learning;active learning;synchronous learning	ML	19.600417587991902	-21.47476095280573	77622
17eb1562a0fe7d170fde5c2d31c0f3480c507f5c	use of neural network algorithms in prediction of xlpe hv insulation properties under thermal aging		Some Artificial neural network algorithms have been used to predict properties of high voltage electrical insulation under thermal aging in term to reduce the aging experiment time. In this work we present a short comparison of the obtained results in the case of Cross-linked Polyethylene (XLPE). The theoretical and the experimental results are concordant. As a neural network application, we propose a new method based on Radial Basis Function Gaussian network (RBFG) trained by two algorithms: Random Optimization Method (ROM) and Back-propagation (BP).	algorithm;artificial neural network	Boukezzi Larbi;Boubakeur Ahmed	2013		10.1007/978-3-319-00945-2_5	insulator (electricity);high voltage;artificial neural network;random optimization;materials science;algorithm	ML	13.547695059497498	-19.636260498864598	78106
e4eb8ca73ebc863915d46e17af8f2411211a51fc	mines: mutual information neuro-evolutionary system	ucl;discovery;theses;conference proceedings;digital web resources;ucl discovery;open access;ucl library;book chapters;open access repository;ucl research	Mutual information neuro-evolutionary system (MINES) presents a novel self-governing approach to determine the optimal quantity and connectivity of the hidden layer of a three layer feed-forward neural network founded on theoretical and practical basis. The system is a combination of a feed-forward neural network, back-propagation algorithm, genetic algorithm, mutual information and clustering. Backpropagation is used for parameter learning to reduce the system’s error; while mutual information aides back-propagation to follow an effective path in the weight space. A genetic algorithm changes the incoming synaptic connections of the hidden nodes, based on the fitness provided by the mutual information from the error space to the hidden layer, to perform structural learning. Mutual information determines the appropriate synapses, connecting the hidden nodes to the input layer; however, in effect it also links the back-propagation to the genetic algorithm. Weight clustering is applied to reduce hidden nodes having similar functionality; i.e. those possessing same connectivity patterns and close Euclidean angle in the weight space. Finally, the performance of the system is assessed on two theoretical and one empirical problems. A nonlinear polynomial regression problem and the well known two-spiral classification task are used to evaluate the theoretical performance of the system. Forecasting daily crude oil prices are conducted to observe the performance of MINES on a real world application.	artificial neural network;backpropagation;cluster analysis;feedforward neural network;genetic algorithm;multitier architecture;mutual information;nonlinear system;polynomial;software propagation;synaptic package manager;whole earth 'lectronic link	Behzad Behzadan	2011			computer science;artificial intelligence;machine learning;data mining	ML	11.162256287145572	-23.061027320062212	78145
beb1490e958ea5d847aeda15714c44a29225d4cd	prediction of heating parameters based on support vector machine	district heating;neural networks;support vector machines;nonlinear;mathematical modelling;svm;parameter prediction;heating parameters	Considering the questions of complex non-linearity, large thermal inertia, retardance of a district heating system, it is very difficult to establish accurate mathematical models of heating parameters prediction for the heating system. Correlation analysis of influence factors is used to obtain the major factors influencing heating parameters through analysing operational data of a heating system; these factors serve as input parameters of the predicting model. This paper describes a prediction method that combines Support Vector Machine (SVM) with neural network. The method creates a network structure between heating parameters and its influence factors. Evaluation indexes of relative error and correlation coefficients are given to analyse the feasibility of the method within the scope of engineering applications through using the network model to regress and predict the heating parameters and compare them with testing data. It turned out that the prediction technique provides powerful guidance for operation of the district heating system.	approximation error;artificial neural network;coefficient;evaluation function;hybrid algorithm;mathematical model;network model;nonlinear system;simulation;support vector machine	Meiping Wang;Qi Tian	2015	IJWMC	10.1504/IJWMC.2015.069391	support vector machine;nonlinear system;computer science;artificial intelligence;machine learning;data mining;artificial neural network	ML	10.258273158239028	-19.622857206340846	78331
8593cb983d247fae6fa3695dfe0ec74b54b333a7	a near-optimal poly-time algorithm for learning a class of stochastic games	near-optimal poly-time algorithm;stochastic games;markov decision process;reinforcement learning;polynomial time;repeated game	We present a new algorithm for polynomial time learning of near optimal behavior in stochastic games. This algorithm incorporates and integrates important recent results of Kearns and Singh [ 1998] in reinforcement learning and of Monderer and Tennenholtz [1997] in repeated games. In stochastic games we face an exploration vs. exploitation dilemma more complex than in Markov decision processes. Namely, given information about particular parts of a game matrix, how much effort should the agent invest in learning its unknown parts. We explain and address these issues within the class of single controller stochastic games. This solution can be extended to stochastic games in general.	algorithm;markov chain;markov decision process;reinforcement learning;time complexity	Ronen I. Brafman;Moshe Tennenholtz	1999				AI	20.398384004002832	-17.38560400336793	78418
3fc37bed49e344ee775db960c7151f391b83eca2	convergence of the q-ae learning under deterministic mdps and its efficiency under the stochastic environment	dynamic programming;dynamic programming principle;reinforcement learning;optimal policy;decision theory;markov processes;markov decision process;learning artificial intelligence;dynamic programming learning artificial intelligence decision theory markov processes;convergence stochastic processes sun acceleration dynamic programming analytical models state space methods probability distribution time factors;simulation q ae learning stochastic markov decision processes reinforcement learning deterministic markov decision processes optimal policy dynamic programming convergence	Reinforcement learning (RL) is an efficient method for solving Markov decision processes (MDPs) without any priori knowledge about an environment. Q-learning is a representative RL. Though it is guaranteed to derive the optimal policy, Q-learning needs numerous trials to learn the optimal policy. By the use of the feature of Q value, this paper presents an accelerated RL method, the Q-ae learning. Further, utilizing the dynamic programming principle, this paper proves the convergence to the optimal policy of the Q-ae learning under deterministic MDPs. The analytical and simulation results illustrate the efficiencies of the Q-ae learning under deterministic and stochastic MDPs.		Gang Zhao;Ruoying Sun;Shoji Tatsumi	2000		10.1109/ICSMC.2000.884985	temporal difference learning;markov decision process;mathematical optimization;partially observable markov decision process;decision theory;computer science;artificial intelligence;machine learning;dynamic programming;markov process;markov model;reinforcement learning;q-learning;statistics;variable-order markov model	ML	21.08666558537489	-18.299074962284244	78457
20ccb8593d4981353de680814e7a60dd630689c8	kf-lax: kronecker-factored curvature estimation for control variate optimization in reinforcement learning		A key challenge for gradient based optimization methods in model-free reinforcement learning is to develop an approach that is sample efficient and has low variance. In this work, we apply Kronecker-factored curvature estimation technique (KFAC) to a recently proposed gradient estimator for control variate optimization, RELAX, to increase the sample efficiency of using this gradient estimation method in reinforcement learning. The performance of the proposed method is demonstrated on a synthetic problem and a set of three discrete control task Atari games.		Mohammad Firouzi	2018	CoRR			ML	24.322751139791645	-18.76191165824491	78528
417ed2405c04afa0dee56b8812b8ddd9e850177f	problem structure in the presence of perturbations	challenge problem;structured mathematical problem;search strategy;hard random problem distribution;problem structure;search control mechanism;interesting search problem;reasoning procedure;computationally hard problem instance;random problem instance;realistic problem instance	Recent progress on search and reasoning procedures has been driven by experimentation on computation-ally hard problem instances. Hard random problem distributions are an important source of such instances. Challenge problems from the area of nite algebra have also stimulated research on search and reasoning procedures. Nevertheless, the relation of such problems to practical applications is somewhat unclear. Realistic problem instances clearly have more structure than the random problem instances, but, on the other hand, they are not as regular as the structured mathematical problems. We propose a new benchmark domain that bridges the gap between the purely random instances and the highly structured problems, by introducing perturbations into a struc-tured domain. We will show how to obtain interesting search problems in this manner, and how such problems can be used to study the robustness of search control mechanisms. Our experiments demonstrate that the performance of search strategies designed to mimic direct constructive methods degrade surprisingly quickly in the presence of even minor perturbations .	benchmark (computing);computation;control system;experiment;perturbation theory;robustness (computer science)	Carla P. Gomes;Bart Selman	1997			mathematical optimization;machine learning;algorithm	AI	20.22005765770743	-13.352951383871341	78573
62903185fb8c527bc9e00c3374ce8a7b3cf625de	the implementation of neural network for semiconductor pecvd process	back propagation neural network;plasma enhanced chemical vapor deposition pecvd;monitoring system;turnover rate;process parameters;quality predictor;process control;refractive index;product quality;film thickness;silicon dioxide films;taguchi method;plasma enhanced chemical vapor deposited;historical data;neural network;semiconductor manufacturing	"""In semiconductor manufacturing, the monitoring system has been developed very excellently and can be used for comprehensively collecting the historical data of process information and quality characteristics of equipment. However, due to the high turnover rate of personnel and the great variance in manufacturing process, the previous control technique by using intuition and experience of engineers for manufacturing process parameter settings to achieve good product quality is no longer appropriate. Therefore, this research establishes a quality predictor for analyzing the relationship between manufacturing process parameter setting and final product quality in the plasma-enhanced chemical vapor deposition (PECVD) of semiconductor manufacturing by applying the back-propagation neural network (BPNN) algorithm and Taguchi method. The experimental data are categorized into 500 pieces of training data and 150 pieces of verifying data. The proposed analysis method for using in the PECVD process of semiconductor manufacturing is verified by comparing the predicted film thickness of SiO""""2 and the predicted refractive index of silicon dioxide films with the measured data. According to the comparison result, the proposed model has an excellent prediction capability of final product quality and can be applied in process control for related manufacturing fields."""	artificial neural network;plasma-enhanced chemical vapor deposition;semiconductor	Wen-Chin Chen;Amy Hsin-I Lee;Wei-Jaw Deng;Kan-Yuang Liu	2007	Expert Syst. Appl.	10.1016/j.eswa.2006.02.013	taguchi methods;computer science;machine learning;process control;turnover;refractive index;semiconductor device fabrication;artificial neural network	ML	13.403208188969687	-18.956198001184305	78630
513983409194130dec9f6356044edd992465f4c8	point-based policy generation for decentralized pomdps	benchmark problem;multi agent planning;decision theoretic planning;teamwork;decentralized pomdps;coordination	Memory-bounded techniques have shown great promise in solving complex multi-agent planning problems modeled as DEC-POMDPs. Much of the performance gains can be attributed to pruning techniques that alleviate the complexity of the exhaustive backup step of the original MBDP algorithm. Despite these improvements, state-of-the-art algorithms can still handle a relative small pool of candidate policies, which limits the quality of the solution in some benchmark problems. We present a new algorithm, PointBased Policy Generation, which avoids altogether searching the entire joint policy space. The key observation is that the best joint policy for each reachable belief state can be constructed directly, instead of producing first a large set of candidates. We also provide an efficient approximate implementation of this operation. The experimental results show that our solution technique improves the performance significantly in terms of both runtime and solution quality.	approximation algorithm;backup;benchmark (computing);dec alpha;multi-agent system	Feng Wu;Shlomo Zilberstein;Xiaoping Chen	2010		10.1145/1838206.1838377	mathematical optimization;simulation;teamwork;computer science;artificial intelligence	AI	19.760256518198936	-15.389873157249891	78765
346bc4eaad1a89e84aa8cda08b623973ec0a2fb7	application of reinforcement learning to the card game wizard	reinforcement learning approach forecasting behavior playing strategy improvement multiplayer perceptron player hand card evaluator rl approach forecasting decision imperfection grade trick playing game phase forecasting game phase partially observable competitive multiplayer game winning strategy computer player wizard card game;multilayer perceptrons;multilayer perceptrons computer games learning artificial intelligence;games color learning artificial intelligence feature extraction computers training forecasting;learning artificial intelligence;computer games;incomplete information multi agent reinforcement learning competitive game	This article proposes an application using a reinforcement learning (RL) approach to the card game Wizard. The aim is to create a computer player that is able to learn a winning strategy for the game by himself. Wizard is a partially observable competitive multiplayer game that consists of two game phases, forecasting and trick playing. The biggest challenges in creating a strong player are dealing with multiple rounds which have a different grade of imperfection and the decision on the forecast at the beginning of every game round. We introduce an RL approach to the problem by adopting an existing RL algorithm to the playing phase of the game and by implementing an evaluator of the player's hand card using a Multi-Player-Perceptron to conduct the forecast. The results of our experiments show that the player is able to improve his playing strategy through learning. At the beginning the performance of the learning agent is very bad due to the bad forecasting behavior, but he is able to improve his performance over a few training episodes from 0% won games to approximately 25.68% won games in an experiment with 4 players. Therefore he plays equally strong as his opponents and even outperforms one of them.	algorithm;effective method;experiment;interpreter (computing);logic programming;partially observable system;perceptron;reinforcement learning	Jana Cathrin Backhus;Hidetoshi Nonaka;Takeshi Yoshikawa;Masanori Sugimoto	2013	2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2013.6664846	non-cooperative game;video game design;combinatorial game theory;game design;bayesian game;simulation;simultaneous game;computer science;win-win game;artificial intelligence;game mechanics;machine learning;metagaming;repeated game;game developer;strategy;screening game;simulations and games in economics education;sequential game	AI	18.39031655005552	-18.545956432594313	78800
7ecf4ca08ca7f85b050478c2546297e8ac9a267b	learning a dft-based sequence with reinforcement learning: a nao implementation	computer vision and robotics autonomous systems;datorseende och robotik autonoma system	The implementation of sequence learning in robotic platforms o ers several challenges. Deciding when to stop one action and continue to the next requires a balance between stability of sensory information and, of course, the knowledge about what action is required next. The work presented here proposes a starting point for the successful execution and learning of dynamic sequences. Making use of the NAO humanoid platform we propose a mathematical model based on dynamic field theory and reinforcement learning methods for obtaining and performing a sequence of elementary motor behaviors. Results from the comparison of two reinforcement learning methods applied to sequence generation, for both simulation and implementation, are provided.	algorithm;dynamical systems theory;emergence;hebbian theory;humanoid robot;initial condition;machine learning;mathematical model;mixed model;mobile robot;nao (robot);ordinal data;quantum field theory;rl (complexity);reinforcement learning;simulation;state space;supervised learning;unsupervised learning	Boris Durán;Gauss Lee;Robert Lowe	2012	Paladyn	10.2478/s13230-013-0109-5	robot learning;error-driven learning;simulation;computer science;artificial intelligence;machine learning;reinforcement learning	Robotics	20.14451902567961	-20.496855498574348	78991
72df90d383921951cb6b7ab944677a2bf6028c5a	yamones: a computational architecture for molecular network simulation	model generation;environmental conditions;network simulator;kinetic parameter;computer architecture;large scale simulation;single cell;path dependence;stochastic model;distributed architecture	One of the most important challenges for Bioinformatics is the simulation of a single cell, even if we restrict ourselves to simple models of the molecular networks responsible for the behavior of organisms. The challenge involves not only the development of experimental techniques to obtain kinetic parameters that characterize the myriad reactions occurring inside cells, but also computational approaches able to simulate and test the complex models generated. These systems have stochastic behavior; they can take different paths depending on environmental conditions. We can describe them using stochastic models that have a high computational cost, but the simulations can be performed efficiently on distributed architectures like grids and clusters of computers. In this work we describe an implementation of a computational architecture to execute this kind of large scale simulation using a grid infrastructure. We validate the proposed architecture using experiments in order to estimate its performance. IV BSB 16 Favor ver os Anais do Simpósio em Springer Verlag, Lecture Notes in Bioinformatics (LNBI número 3594) para este trabalho. Please see the Symposium Proceedings in Lecture Notes in Bioinformatics (LNBI nr. 3594), Springer Verlag, for this paper.	algorithmic efficiency;back-side bus;bioinformatics;computation;computer cluster;design of experiments;experiment;grid computing;lecture notes in computer science;simulation;springer (tank);stochastic process;ver (command)	Guilherme Balestieri Bedin;Ney Lemke	2005		10.1007/11532323_12	computational science;simulation;computer science;stochastic modelling;theoretical computer science;network simulation	HPC	15.95922649889475	-10.364588942434901	79082
fbe99c7440a0bb5c96611548c5934c117db98fa1	developing 3-step modeling strategy exploiting knowledge based techniques	computer aided design;knowledge based system;neural nets cad knowledge based systems;neural networks;integrated circuit;neural nets;cad;training;branin function modeling 3 step modeling strategy knowledge based technique engineering design artificial neural networks prior knowledge input;data model;knowledge based modeling;computer aided design modeling neural networks knowledge based modeling;artificial neural networks;integrated circuit modeling;mathematical model;mathematical model artificial neural networks data models integrated circuit modeling knowledge based systems training microwave theory and techniques;microwave theory and techniques;modeling;knowledge based systems;artificial neural network;data models;neural network;knowledge base	Artificial neural networks have been used as an important technique in modeling and optimization for engineering design. In this work, 3-step modeling strategy based on knowledge based techniques is proposed to develop new efficient modeling instead of conventional artificial neural network (ANN) modeling. The knowledge based artificial neural networks are constructed by incorporating the existing knowledge such as empirical formulas, equivalent circuit models and semi-analytical equations in neural network structures. In this new technique, required knowledge is created in the first step and used in the second step as a coarse model. Therefore each model shows better performance than former. In this strategy, conventional ANN, prior knowledge input and prior knowledge input with difference techniques are utilized not only to improve modeling accuracy but also to reduce time consumption during modeling. The advantages of using 3-step modeling are demonstrated on Branin function modeling application.	artificial neural network;engineering design process;equivalent circuit;function model;mathematical model;mathematical optimization;semiconductor industry	Murat Simsek	2011	2011 20th European Conference on Circuit Theory and Design (ECCTD)	10.1109/ECCTD.2011.6043618	data modeling;systems modeling;data model;computer science;artificial intelligence;integrated circuit;machine learning;mathematical model;data mining;cad;artificial neural network	EDA	13.846415854974781	-20.790668289847744	79363
da2bf7e438bfdddfa2c9f0ca675391960c9abd0d	short paper: design of a dielectrophoresis-based portable device for monitoring pollution in water deposits	water pollution system on chip prototypes fluids real time systems microfluidics;fluids;prototypes;electrophoresis;water pollution measurement;water resources;real time data center dielectrophoresis based portable device design pollution monitoring water deposit pollution dep particle manipulation portable programmable device pollutant particles electrical stimulation microfluidic device particle detection subsystem data transmitter fluid samples web based data center;pollution particle manipulation dielctrophoresis;system on chip;particle manipulation;microfluidics;water pollution;dielctrophoresis;portable instruments;hydrological techniques;real time systems;water resources electrophoresis hydrological techniques portable instruments water pollution measurement;pollution	Pollution in water deposits is a great health issue. Portable devices installed in water deposits to form a real time, pollution monitoring system would be of great help. Research has demonstrated the use of dielectrophoresis (DEP) where particle manipulation is required. A portable, programmable device for manipulating pollutant particles has been developed, so data or images of samples can be analyzed, transmitted and stored. The system has a signal generator for electrical stimulation, a microfluidic device, a particle detection sub-system, and a data transmitter. It can be programmed to manipulate a specific type of particles and transmit resulting data or image. A portable prototype is achieved, which can be installed in any water deposit and programmed to perform regular fluid samples and analysis, to maintain a web-based, real time data center.	data center;executable space protection;functional electrical stimulation;mobile device;prototype;transmitter;web application	Martha Salome Lopez de la Fuente	2014	2014 IEEE World Forum on Internet of Things (WF-IoT)	10.1109/WF-IoT.2014.6803151	system on a chip;water resources;microfluidics;electrophoresis;pollution;computer science;prototype;water pollution;fluid mechanics	Mobile	15.66014919648085	-12.738003365509668	79492
658b88cfec30f9036fff6bd7d22005d3b50ce4fa	balancing guidance range and strength optimizes self-organization by silicon growth cones	signal strength;guidage;growth cone;metodo formal;methode formelle;intelligence artificielle;guiado;topographic map;formal method;cone;autoorganizacion;guidance;artificial intelligence;self organization;self organized map;inteligencia artificial;hardware implementation;autoorganisation;cono	We characterize the first hardware implementation of a self-organizing map algorithm based on axon migration. A population of silicon growth cones automatically wires a topographic mapping by migrating toward sources of a diffusible guidance signal that is released by postsynaptic activity. We varied the diffusion radius of this signal, trading strength for range. Best performance is achieved by balancing signal strength against signal range. Comments Postprint version. Published in Lecture Notes in Computer Science, Volume 3697, Artificial Neural Networks: Formal Models and Their Applications-ICANN 2005, 2005, pages 1027-1034. Publisher URL: http://dx.doi.org/10.1007/11550907 This conference paper is available at ScholarlyCommons: http://repository.upenn.edu/be_papers/71 Balancing Guidance Range and Strength Optimizes Self-Organization by Silicon Growth Cones Brian Taba and Kwabena Boahen University of Pennsylvania, Philadelphia PA 19104, USA, {btaba, boahen}@seas.upenn.edu, WWW home page: http://www.neuroengineering.upenn.edu/boahen Abstract. We characterize the first hardware implementation of a selforganizing map algorithm based on axon migration. A population of silicon growth cones automatically wires a topographic mapping by migrating toward sources of a diffusible guidance signal that is released by postsynaptic activity. We varied the diffusion radius of this signal, trading strength for range. Best performance is achieved by balancing signal strength against signal range. We characterize the first hardware implementation of a selforganizing map algorithm based on axon migration. A population of silicon growth cones automatically wires a topographic mapping by migrating toward sources of a diffusible guidance signal that is released by postsynaptic activity. We varied the diffusion radius of this signal, trading strength for range. Best performance is achieved by balancing signal strength against signal range.	algorithm;artificial neural network;brian;home page;lecture notes in computer science;neural networks;organizing (structure);population;self-organization;self-organizing map;topography;www	Brian Taba;Kwabena Boahen	2005		10.1007/11550907_162	signal strength;topographic map;self-organization;simulation;formal methods;cone;computer science;artificial intelligence;growth cone	ML	17.04199665011997	-15.031608852803286	79495
1eafc64d68b7a571e8158e8d6ff78841ff35e95e	reinforcement learning transfer using a sparse coded inter-task mapping	novel transfer;sparse projection learning;sparse coding;novel combination;near-optimal policy;successful transfer;inter-task mapping;transfer learning;fixed number;sparse pseudo-input gaussian process	Reinforcement learning agents can successfully learn in a variety of difficult tasks. A fundamental problem is that they learn slowly in complex environments, inspiring the development of speedup methods such as transfer learning. Transfer improves learning by reusing learned behaviors in similar tasks, usually via an inter-task mapping, which defines how a pair of tasks are related. This paper proposes a novel transfer learning technique to autonomously construct an inter-task mapping by using a novel combinations of sparse coding, sparse projection learning, and sparse pseudo-inputs gaussian processes. Experiments show successful transfer of information between two very different domains: the mountain car and the pole swing-up task. This paper empirically shows that the learned inter-task mapping can be successfully used to (1) improve the performance of a learned policy on a fixed number of samples, (2) reduce the learning times needed by the algorithms to converge to a policy on a fixed number of samples, and (3) converge faster to a near-optimal policy given a large amount of samples.	algorithm;approximation;converge;experiment;framing (world wide web);gaussian process;mountain car;neural coding;rl (complexity);reinforcement learning;similarity measure;sparse matrix;speedup;supervised learning	Haitham Bou-Ammar;Matthew E. Taylor;Karl Tuyls;Gerhard Weiss	2011		10.1007/978-3-642-34799-3_1	multi-task learning;simulation;computer science;artificial intelligence;machine learning;inductive transfer;learning classifier system	ML	20.20850432652027	-22.058105620257404	79554
6bc39fba7983997f1f7dd48979fda8c6f1a34636	characterizing an unknown pollution source in groundwater resources systems using psvm and pnn	non dominated sorting genetic algorithm ii nsga ii;real time;multi objective optimization;water quality;source identification;relative error;non dominated sorting genetic algorithm;groundwater quality;pollution source identification;probabilistic neural networks pnns;groundwater quality monitoring;groundwater pollution;probability mass function;support vector machine;probabilistic neural network;probabilistic support vector machines psvms;simulation model	This paper presents a new methodology for estimating location and amount of leakage from an unknown pollution source using groundwater quality monitoring data. The proposed methodology includes a multi-objective optimization model, namely Non-dominated Sorting Genetic Algorithm-II (NSGA-II) which is linked with MODFLOW and MT3D groundwater quantity and quality simulation models. The main characteristics of an unknown groundwater pollution source are estimated using two probabilistic simulation models, namely Probabilistic Support Vector Machines (PSVMs) and Probabilistic Neural Networks (PNNs). In real-time groundwater monitoring, these trained probabilistic simulation models can present the probability mass function of an unknown pollution source location and the relative error in estimating the amount of leakage based on the observed concentrations of water quality indicator at the monitoring wells. The efficiency of the proposed methodology is demonstrated through a real-world case study.		Seyyed Nasser Bashi-Azghadi;Reza Kerachian;Mohammad Reza Bazargan-Lari;Kazem Solouki	2010	Expert Syst. Appl.	10.1016/j.eswa.2010.04.019	support vector machine;approximation error;probability mass function;probabilistic neural network;computer science;multi-objective optimization;machine learning;simulation modeling	NLP	11.52834817095895	-17.006587386615433	79599
bb8489b322716b115e12a5858fe44afa152cfc86	hybridftw: hybrid computation of dynamic time warping distances		In this paper, we propose an efficient approach that computes the dynamic time warping (DTW) distance in time-series similarity search. The DTW distance is known to offer the high accuracy in similarity search, but it has difficulty in supporting the large database due to its high computational complexity. Recently, FastDTW and FTW have been proposed for efficient computation of DTW distances, but they have still performance limitations. In this paper, we propose a hybrid approach, called HybridFTW, which combines the advantages of both FastDTW and FTW. First, HybridFTW takes the advantage of FastDTW that provides fast computation through the limitation of allowable ranges. We call these allowable ranges dynamic (warping) bands, which reduce the computation spaces on the fly, and we reanalyze previous FastDTW and FTW in the viewpoint of static and dynamic bands. Second, HybridFTW also takes the advantage of FTW that exploits the early abandon effect by using the segment-based tight lower bound. To maximize the synergy of combining two methods, we obtain the dynamic band of FastDTW during the process of computing the lower bound in FTW. Using HybridFTW, we next propose range search and  $k$ -NN search algorithms and prove their correctness through formal theorems. Experimental results on real and synthetic data sets show that HybridFTW improves the search performance by up to 38 times over FastDTW and by up to 12 times over FTW.	computation;computational complexity theory;correctness (computer science);dynamic time warping;for the win;image warping;on the fly;range searching;search algorithm;similarity search;synergy;synthetic data;time series	Minwoo Lee;Sanghun Lee;Mi-Jung Choi;Yang-Sae Moon;Hyo-Sang Lim	2018	IEEE Access	10.1109/ACCESS.2017.2781464	mathematical optimization;time complexity;correctness;distributed computing;dynamic time warping;computer science;image warping;computational complexity theory;dynamic programming;nearest neighbor search;search algorithm	DB	17.05793359684384	-10.085439655093035	79986
b9056c807faf8ba40cd67ddfb508b6006a1354b8	more adaptive algorithms for adversarial bandits		We develop a novel and generic algorithm for the adversarial multi-armed bandit problem (or more generally the combinatorial semi-bandit problem). When instantiated differently, our algorithm achieves various new data-dependent regret bounds improving previous work. Examples include: 1) a regret bound depending on the variance of only the best arm; 2) a regret bound depending on the first-order path-length of only the best arm; 3) a regret bound depending on the sum of the first-order path-lengths of all arms as well as an important negative term, which together lead to faster convergence rates for some normal form games with partial feedback; 4) a regret bound that simultaneously implies small regret when the best arm has small loss and logarithmic regret when there exists an arm whose expected loss is always smaller than those of other arms by a fixed gap (e.g. the classic i.i.d. setting). In some cases, such as the last two results, our algorithm is completely parameter-free. The main idea of our algorithm is to apply the optimism and adaptivity techniques to the wellknown Online Mirror Descent framework with a special log-barrier regularizer. The challenges are to come up with appropriate optimistic predictions and correction terms in this framework. Some of our results also crucially rely on using a sophisticated increasing learning rate schedule.	algorithm;coat of arms;data dependency;descent;first-order predicate;generic programming;multi-armed bandit;regret (decision theory);semiconductor industry	Chen-Yu Wei;Haipeng Luo	2018			adversarial system;mathematical optimization;artificial intelligence;machine learning;genetic algorithm;logarithm;regret;mathematics;existential quantification;algorithm;expected loss;convergence (routing)	ML	23.4501168575832	-17.405220862673037	79995
4348b9ef03be405381fb3a705472084aa907221e	operation space design of microbial fuel cells combined anaerobic-anoxic-oxic process based on support vector regression inverse model		Abstract Microbial Fuel Cells (MFCs) can produce power at the same time of wastewater treatment, which is a new technique for environmental protection and new energy. An appropriate space design of operation variables is very important to improve the performance of MFC process. This paper presents a space design method based on data-driven model but not the traditional mechanism model, which is easy to accomplish in a fast and cost-effective mode. The support vector regression (SVR) forward and inverse model are deduced with the quadratic kernel function, in which the quadratic kernel function is suitable for the mathematical formula in the inversion stage. And the space design of operation variables are proposed to calculate directly from the inverse model with the effect of confidence interval when the model prediction uncertainty are considered. The proposed design method is verified in the real MFC-A 2 /O equipment. It is shown that the designated operation space is a narrow and effective region of the knowledge space which brackets the entire fraction of the MFC experiment space. And in general terms, the possible product quality from the designated operation space is more densely concentrated on the desired value compared to the tradition forward model design method.	support vector machine	Jing Wang;Qilun Wang;Jinglin Zhou;Xiaohui Wang;Long Cheng	2018	Eng. Appl. of AI	10.1016/j.engappai.2018.04.005	mathematical optimization;support vector machine;microbial fuel cell;kernel (statistics);computer science;inverse;confidence interval;knowledge space	AI	12.03038398333335	-19.397692216588574	80128
3ea2765cebff819cf9f0cd61d0142a9217ab6e4a	behavior hierarchy learning in a behavior-based system using reinforcement learning	reinforcement learning;decomposition method;multi agent systems;intelligent agent;learning artificial intelligence multi agent systems;value function;multi robot object lifting task behavior hierarchy learning behavior system reinforcement learning architecture learning intelligent agents;learning robotics and automation intelligent agent design methodology testing multiagent systems state space methods process control control systems intelligent control;learning artificial intelligence	Hand-design of an intelligent agent's behaviors and their hierarchy is a very hard task. One of the most important steps toward creating intelligent agents is providing them with capability to learn the required behaviors and their architecture. Architecture learning in a behavior-based agent with subsumption architecture is considered in this paper. Overall value function is decomposed into easily calculate-able parts in order to learn the behavior hierarchy. Using probabilistic formulations, two different decomposition methods are discussed: storing the estimated value of each behavior in each layer, and storing the ordering of behaviors in the architecture. Using defined decompositions, two appropriate credit assignment methods are designed. Finally, the proposed methods are tested in a multi-robot object-lifting task that results in satisfactory performance.	assignment (computer science);bellman equation;computer simulation;distributed object;feudalism;intelligent agent;lifting scheme;q-learning;reinforcement learning;robot;subsumption architecture	Amir Massoud Farahmand;Majid Nili Ahmadabadi;Babak Nadjar Araabi	2007	2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566)	10.1109/IROS.2004.1389699	agent architecture;robot learning;error-driven learning;simulation;decomposition method;computer science;artificial intelligence;machine learning;multi-agent system;bellman equation;learning classifier system;reinforcement learning;intelligent agent	Robotics	18.078749744444345	-19.951334101524616	80372
2b2cb853da9c9edeebdc5bcb836dac96419b9d34	structural design of optimized polynomial radial basis function neural networks	cluster algorithm;polynomial radial basis function neural networks prbfnn;machine learning data;optimal method;c means;kernel function;power plant;gas turbine;particle swarm optimizer;machine learning;radial basis function neural network;least squares estimate;particle swarm optimization algorithm;structural design	In this paper, we introduce optimization methods of Polynomial Radial Basis Function Neural Network (pRBFNN) The connection weight of proposed pRBFNN is represented as four kinds of polynomials, unlike in most conventional RBFNN constructed with constant as connection weight Input space in partitioned with the aid of kernel functions and each kernel function is used Gaussian type Least Square Estimation (LSE) is used to estimate the coefficients of polynomial Also, in order to design the optimized pRBFNN model, center value of each kernel function is determined based on C-Means clustering algorithm, the width of the RBF, the polynomial type in the each node, input variables are identified through Particle Swarm Optimization (PSO) algorithm The performances of the NOx emission process of gas turbine power plant data and Automobile Miles per Gallon (MPG) data was applied to evaluate proposed model We analyzed approximation and generalization of model.	neural networks;polynomial;radial (radio);radial basis function	Young-Hoon Kim;Hyun-Ki Kim;Sung-Kwun Oh	2010		10.1007/978-3-642-13278-0_32	kernel;power station;mathematical optimization;radial basis function;radial basis function kernel;computer science;machine learning;mathematics;radial basis function network;polynomial kernel	EDA	12.308238488767957	-22.589758684194635	80529
8554250f4f24c4c194ac3caa42c0a7f31921cd4b	efficient on-line generation of the correlation structure of f-arima processes	f arima processes;stochastic process;self similar process;network performance;long range correlation;simulation study;correlation;m g process;traffic measurement;synthetic efficient on line generation	Several traffic measurement studies have shown the presence of persistent correlations in modern networks. The use of stochastic processes able to capture this kind of correlations, as self-similar processes, has opened new research fields in network performance analysis, mainly in simulation studies, where the efficient synthetic generation of samples is one of the main topics. Although F-ARIMA processes are very flexible to capture both short- and long-range correlations in a parsimonious way, only off-line methods for synthesizing traces are efficient enough to be of practical use. In order to overcome this disadvantage, in this paper we propose a M/G/***-based efficient and on-line generator of the correlation structure of F-ARIMA processes.	autoregressive integrated moving average	Maria Estrella Sousa Vieira;Andrés Suárez-González;José C. López-Ardao;Cándido López-García	2009		10.1007/978-3-642-02205-0_10	stochastic process;econometrics;simulation;mathematics;network performance;self-similar process;correlation;statistics	AI	23.91169410972618	-21.529371961782665	80541
ad1088b0071652c768a914719c549a6051137f0f	towards self-reflecting machines: two-minds in one robot	self modeling;evolutionary robotics;machine learning;self reflection	We introduce a technique that allows a robot to increase its resiliency and learning skills by exploiting a process akin to self-reflection. A robot contains two controllers: A pure reactive innate controller, and a reflective controller that can observe, model and control the innate controller. The reflective controller adapts the innate controller without access to the innate controller’s internal state or architecture; Instead, it models it and then synthesizes filters that exploit its existing capabilities for new situations. In this paper we explore a number of scenarios where the innate controller is a recurrent neural network. We demonstrate significant adaptation ability with relatively few physical trials.	artificial neural network;ibm notes;random neural network;recurrent neural network;robot;self-reflection;self-replication	Juan Cristóbal Zagal;Hod Lipson	2009		10.1007/978-3-642-21283-3_20	simulation;computer science;artificial intelligence;machine learning;evolutionary robotics	Robotics	18.91199677148717	-22.56129663297366	80565
01ffb73041e6a6e4bc7d378bb67b8bc5ed20a8de	transfer learning by prototype generation in continuous spaces	gaussian processes;reinforcement learning;transfer learning;prototype generation	In machine learning, learning a task is expensive (many training samples are needed) and it is therefore of general interest to be able to reuse knowledge across tasks. This is the case in aerial robotics applications, where an autonomous aerial robot cannot interact with the environment hazard free. Prototype generation is a well known technique commonly used in supervised learning to help reduce the number of samples needed to learn a task. However, little is known about how such techniques can be used in a reinforcement learning task. In this work we propose an algorithm that, in order to learn a new (target) task, first generates new samples—prototypes—based on samples acquired previously in a known (source) task. The proposed approach uses Gaussian processes to learn a continuous multidimensional transition function, rendering the method capable of reasoning directly in continuous (states and actions) domains. We base the prototype generation on a careful selection of a subset of samples from the source task (based on known filtering techniques) and transforming such samples using the (little) knowledge acquired in the target task. Our experimental evidence gathered in known reinforcement learning benchmark tasks, as well as a challenging quadcopter to helicopter transfer task, suggests that prototype generation is feasible and, furthermore, that the filtering technique used is not as important as a correct transformation model.	aerial photography;aerobot;algorithm;autonomous robot;benchmark (computing);experiment;gaussian process;machine learning;negative feedback;probably approximately correct learning;prototype;reinforcement learning;robotics;state (computer science);supervised learning;transform, clipping, and lighting	Enrique Munoz de Cote;Esteban O. Garcia;Eduardo F. Morales	2016	Adaptive Behaviour	10.1177/1059712316664570	unsupervised learning;robot learning;multi-task learning;error-driven learning;simulation;transfer of learning;computer science;artificial intelligence;machine learning;task analysis;gaussian process;reinforcement learning	AI	20.42380696326872	-21.55589350515125	80895
90f3e3135e2df674c38fe3a941d6208b75f155fb	remaining useful life prediction of rotating machinery using hierarchical deep neural network		This paper presents a novel approach for remaining useful life (RUL) prediction of rotating machinery using hierarchical deep neural networks (DNN). The different health stages are classified by a DNN-based health stage classifier trained by segmented degradation signal. This method builds several RUL predictors based on the health stages of the degradation process. Instead of modeling the entire degradation process (typically including various stages with dramatically different properties) with a single model, the proposed approach builds RUL model for each health stage where more accurate fitting can be obtained. A smoothing operator is applied to obtain the final RUL prediction. The experimental results show that the proposed method can achieve more accurate RUL prediction.	artificial neural network;deep learning;elegant degradation;gene prediction;smoothing	Min Xia;Teng Li;Lizhi Liu;Lin Xu;Shujun Gao;Clarence W. de Silva	2017	2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2017.8123047	artificial intelligence;artificial neural network;machine learning;operator (computer programming);smoothing;computer science;training set	Robotics	14.413396368878278	-17.015516179122987	81103
13828a8b398fa41fd5734a44e74fae0a01476cbf	identifying and exploiting weak-information inducing actions in solving pomdps	partial observability;approximation	We present a method for identifying actions that lead to observations which are only weakly informative in the context of partially observable Markov decision processes (POMDP). We call such actions as weak(inclusive of zero-) information inducing. Policy subtrees rooted at these actions may be computed more efficiently. While zero-information inducing actions may be exploited without error, the quicker backup for weak but non-zero information inducing actions may introduce error. We empirically demonstrate the substantial computational savings that exploiting such actions may bring to exact and approximate solutions of POMDPs while maintaining the solution quality.	approximation algorithm;backup;information;markov chain;partially observable markov decision process;partially observable system;tree (data structure)	Ekhlas Sonu;Prashant Doshi	2011			mathematical optimization;computer science;machine learning;approximation	AI	20.73066173677721	-14.625797981231678	81182
472c0bcb9c2fe5e6653deb8b20c0888c7368ed01	the application of control chart for defects and defect clustering in ic manufacturing based on fuzzy theory	fuzzy theory;integrated circuit;defect clustering;control chart;article;integrated circuits ic	c-Chart was frequently used to monitor wafer defects during IC manufacturing. The clustering degree of defect on a wafer will increase along with the area of wafer gradually enlarging. The defect clustering causes the Poisson-based c-chart to exhibit many false alarms. Although several revised control charts have been developed to reduce the number of false alarms, those control charts still have some disadvantages in practical use. This study proposes a control chart that applies fuzzy theory and engineering experience to monitor wafer defects with the consideration of defect clustering. The proposed control chart is simpler and more rational than those revised c-charts. Finally, a case study of an IC company, owing to the HsinChu Scientific part at Taiwan, is used to demonstrate and verify the rationality and effectiveness. 2006 Elsevier Ltd. All rights reserved.	chart;cluster analysis;fuzzy logic;integrated circuit;rationality;software bug;wafer (electronics)	Kun-Lin Hsieh;Lee-Ing Tong;Min-Chia Wang	2007	Expert Syst. Appl.	10.1016/j.eswa.2006.01.050	control chart;computer science;integrated circuit	AI	13.04082842002902	-17.1285165252392	81232
3b09d49e3bde3f97e87dfe62a6d47b48b9fb68da	rao*: an algorithm for chance-constrained pomdp's		Autonomous agents operating in partially observable stochastic environments often face the problem of optimizing expected performance while bounding the risk of violating safety constraints. Such problems can be modeled as chance-constrained POMDP’s (CCPOMDP’s). Our first contribution is a systematic derivation of execution risk in POMDP domains, which improves upon how chance constraints are handled in the constrained POMDP literature. Second, we present RAO∗, a heuristic forward search algorithm producing optimal, deterministic, finite-horizon policies for CCPOMDP’s. In addition to the utility heuristic, RAO∗ leverages an admissible execution risk heuristic to quickly detect and prune overly-risky policy branches. Third, we demonstrate the usefulness of RAO∗ in two challenging domains of practical interest: power supply restoration and autonomous science agents.	autonomous agent;autonomous robot;circuit restoration;comment (computer programming);heuristic;partially observable markov decision process;partially observable system;power supply;search algorithm;software propagation;temporal logic;the australian	Pedro Henrique de Rodrigues Quemel e Assis Santana;Sylvie Thiébaux;Brian Charles Williams	2016			mathematical optimization;artificial intelligence;machine learning	AI	20.744769480657066	-15.388927356794959	81422
4d1dc74591fd25cb591fc933b2c61eeec34effd8	learning to kick the ball using back to reality	optimal solution;engineering design;automatic generation;evolutionary robotics;motor coordination;evolutionary learning;high power;legged robot;reaction time	Kicking the ball with high power, short reaction time and accuracy are fundamental requirements for any soccer player. Human players acquire these fine low-level sensory motor coordination abilities trough extended training periods that might last for years. In RoboCup the problem has been addressed by engineering design and acceptable, probably sub-optimal, solutions have been found. To our knowledge the automatic development of these abilities has not been yet employed. Certainly no one is willing to damage a robot during an extended, and probably violent, evolutionary learning process in a real environment. In this work we present an approach for the automatic generation (from scratch) of ball-kick behaviors for legged robots. The approach relies on the use of UCHILSIM, a dynamically accurate simulator, and the Back to Reality paradigm to evolutionary robotics, a recently proposed method for narrowing the difference between simulation and reality during robot behavior execution. After eight hours of simulations successful ball-kick behaviors emerged, being directly transferable to the real robot.	engineering design process;euclidean distance;evolutionary robotics;fitness function;high- and low-level;programming paradigm;requirement;robot;simulation;triune continuum paradigm	Juan Cristóbal Zagal;Javier Ruiz-del-Solar	2004		10.1007/978-3-540-32256-6_27	mental chronometry;robot learning;simulation;computer science;artificial intelligence;social robot;motor coordination;evolutionary robotics;engineering design process	Robotics	17.114797263517794	-18.8806590837196	81556
3923ee53f2667d33f517e7f239bac3d67fbfcc7a	free-flight and en route air safety: a first-order analysis	transportation safety aviation collision risk modeling;reliability;failure models aviation collision risk;first order;safety aviation collision risk modeling;transportation;reliability failure models aviation collision risk	"""Under present arrangements, U.S. commercial planes do not travel """"as the crow flies"""" from origin to destination; rather, they are generally restricted to paths within a grid. New technologies, however, raise the possibility of moving to a """"free-flight"""" regime under which planes could fly directly from point to point. Striving for general insight rather than definitive conclusions, we use geometrical probability to assess how free-flight could affect the safety and efficiency of en route air traffic operations. We work with two air traffic control sectors: one hypothetical and the other based on actual traffic patterns over Albany, New York. Though tentative, the results suggest that--so long as certain operational constraints are retained--the changed geometry of flight paths after a transition to free-flight might tend in itself to diminish mid-air collision risk. Much depends, however, on whether the human/technological capabilities of future air traffic control can match the extraordinary effectiveness of the existing system."""	advanced tactical center;advanced transportation controller;continuation;crossing number (graph theory);experiment;fo (complexity);first-order predicate;risk aversion;simulation;throughput	Arnold Barnett	2000	Operations Research	10.1287/opre.48.6.833.12394	transport;simulation;computer science;first-order logic;reliability;mathematics;statistics	Logic	10.253471818430919	-10.200784346236604	81580
2c4f319b108c5da620580dcc0a53722faa707c12	single- and multi-objective particle swarm optimization of reservoir structure in echo state network	optimal reservoir architectures single objective particle swarm optimization echo state network esn recurrent networks black box modeling dynamic nonlinear problems recurrent hidden infrastructure dynamic reservoir reservoir structure parameters selection neurons connectivity rate optimal reservoir topology mono objective particle swarm optimizations multiobjective particle swarm optimizations;reservoirs optimization neurons mathematical model particle swarm optimization complexity theory periodic structures;topology particle swarm optimisation recurrent neural nets;particle swarm optimization echo state network reservoir evolutionary learning mono objective multi objective	Echo State Networks ESNs are specific kind of recurrent networks providing a black box modeling of dynamic non-linear problems. Their architecture is distinguished by a randomly recurrent hidden infra-structure called dynamic reservoir. Coming up with an efficient reservoir structure depends mainly on selecting the right parameters including the number of neurons and connectivity rate within it. Despite expertise and repeatedly tests, the optimal reservoir topology is hard to be determined in advance. Topology evolving can provide a potential way to define a suitable reservoir according to the problem to be modeled. This last can be mono- or multi-constrained. Throughout this paper, a mono-objective as well as a multi-objective particle swarm optimizations are applied to ESN to provide a set of optimal reservoir architectures. Both accuracy and complexity of the network are considered as objectives to be optimized during the evolution process. These approaches are tested on various benchmarks such as NARMA and Lorenz time series.	artificial neural network;benchmark (computing);black box;box modeling;british informatics olympiad;echo state network;mathematical optimization;memory management;network architecture;network topology;neural networks;nonlinear system;pareto efficiency;particle filter;particle swarm optimization;performance;randomness;recurrent neural network;time series	Naima Chouikhi;Raja Fdhila;Boudour Ammar;Nizar Rokbani;Adel M. Alimi	2016	2016 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2016.7727232	mathematical optimization;multi-swarm optimization;artificial intelligence;machine learning;metaheuristic	ML	14.067871786670034	-23.360870873412992	81678
4ec75b1160e67387d8e684dd5cb4a06b707b2b93	simulation of artificial ant's behavior in a digital environment.	simulation software;evolutionary computing	Ants present a very good natural metaphor to evolutionary computation. While each individual’s computational power is small compared to more evolved species, it is the power of their colonies that inspire computer scientists. This paper presents “Ant Box Simulator”, a software that allows the simulation of ants in a restricted environment. The simulator demonstrates how digital ants make use of an autocatalytic behavior in order to collectively find a solution for a posed problem in reasonable time. We also show that while pheromones play an important role on biological ant’s navigation, it is not the only sense they rely on.	computer scientist;digital environment;evolutionary computation;simulation	Paulo E. Merloti;Joseph Lewis	2005			simulation;theoretical computer science;computer engineering	ECom	22.14418700238093	-10.645733358553933	82059
40cc7cdffa0a861cb557410518246d97d1678642	benchmarking reinforcement learning algorithms on real-world robots		Through many recent successes in simulation, model-free reinforcement learning has emerged as a promising approach to solving continuous control robotic tasks. The research community is now able to reproduce, analyze and build quickly on these results due to open source implementations of learning algorithms and simulated benchmark tasks. To carry forward these successes to real-world applications, it is crucial to withhold utilizing the unique advantages of simulations that do not transfer to the real world and experiment directly with physical robots. However, reinforcement learning research with physical robots faces substantial resistance due to the lack of benchmark tasks and supporting source code. In this work, we introduce several reinforcement learning tasks with multiple commercially available robots that present varying levels of learning difficulty, setup, and repeatability. On these tasks, we test the learning performance of off-the-shelf implementations of four reinforcement learning algorithms and analyze sensitivity to their hyper-parameters to determine their readiness for applications in various real-world tasks. Our results show that with a careful setup of the task interface and computations, some of these implementations can be readily applicable to physical robots. We find that state-of-the-art learning algorithms are highly sensitive to their hyper-parameters and their relative ordering does not transfer across tasks, indicating the necessity of re-tuning them for each task for best performance. On the other hand, the best hyper-parameter configuration from one task may often result in effective learning on held-out tasks even with different robots, providing a reasonable default. We make the benchmark tasks publicly available to enhance reproducibility in real-world reinforcement learning1.	algorithm;benchmark (computing);computation;machine learning;open-source software;reinforcement learning;repeatability;robot;simulation	A. Rupam Mahmood;Dmytro Korenkevych;Gautham Vasan;William Ma;James Bergstra	2018			implementation;machine learning;computation;source code;benchmarking;robot;reinforcement learning;algorithm;artificial intelligence;mathematics;learning disability	AI	21.257533062872806	-21.658628065693126	82120
29ff843db919fcf54c6b4b0c08a6db71444d0326	modeling of traffic excitation for system identification of bridge structures	modelizacion;carga trafico;construccion arquitectura tecnologia ambiental;computacion informatica;arma auto regressive moving average model;analisis estructural;charge trafic;grupo de excelencia;bridges;response;excitacion;diagnostic construction;identificacion sistema;modelisation;monitoring;civil engineering;system identification;ciencias basicas y experimentales;vibration;puente;construction diagnostic;traffic load;pont;reponse;monitorage;respuesta;computer science;analyse structurale;tecnologias;monitoreo;structural analysis;modeling;identification systeme;traffic loads;excitation;diagnostico construccion	In long-term health monitoring of bridge structures, system identification is often performed based only on the system output (bridge vibration responses) because the system input (traffic excitation) is difficult to measure. To facilitate the identification of the bridge properties, traffic excitation is commonly modeled as spatially uncorrelated white noise. A physical model of a stationary stream of vehicles (moving loads) arriving in accordance with a Poisson process, traversing an elastic beam, shows that the traffic excitation is spatially correlated. Employing the dynamic nodal loading approach, this spatial correlation results in a frequency-dependent excitation spectrum density matrix, and shifts the response spectra obtained from those excited by spatially uncorrelated white noise. It is shown that the application of system identification techniques based on the conventional excitation model may result in misleading structural properties. Hence, this study further proposes an output-only gray-box identification technique for bridge structures, in which knowledge about the nature of the traffic excitation, such as its spatial correlation, is implanted into an autoregressive-movingaverage (ARMA) model. The identifiability of the ARMA model so constructed is assured and the feasibility of the proposed identification technique is demonstrated by a	autoregressive model;density matrix;stationary process;system identification;white noise	Yangbo Chen;Maria Q. Feng;Chin-An Tan	2006	Comp.-Aided Civil and Infrastruct. Engineering	10.1111/j.1467-8667.2005.00416.x	systems modeling;excitation;system identification;telecommunications;engineering;civil engineering;vibration;structural analysis	AI	13.562792076337722	-10.573687007171943	82194
106ef39339826be448a054b5ba9ebaf6ccfbafb3	ga based fcmac-byy model for bank solvency analysis	bank failure;belief networks;optimal solution;early warning system;pattern clustering;banking;fuzzy set;financial management;bank failure classification bank solvency analysis adverse financial repercussion early warning system high risk banks financial distress bank solvency fuzzy cerebellar model arithmetic controller bayesian ying yang network fuzzy clusters sets genetic algorithm fitness functions;fuzzy set theory;financial distress;evolutionary computation demand forecasting genetic algorithms cybernetics;fuzzy clustering;statistical analysis;pattern classification;genetic algorithm;genetic algorithms;global optimization;statistical analysis banking belief networks financial management fuzzy set theory genetic algorithms pattern classification pattern clustering;bayesian ying yang;fitness function;high risk	Since the collapse or failure of a bank could trigger an adverse financial repercussion and generate negative impacts, it is desirable to have an early warning system (EWS) that identifies potential bank failures or high-risk banks through the traits of financial distress. This research is aimed to construct a novel GA-FCMAC-BYY model as an alternative to analyze bank solvency. The proposed model attempts to advance our previous work which uses fuzzy cerebellar model arithmetic controller-Bayesian Ying-Yang (FCMAC-BYY) network. Inspired by the ancient Chinese Ying Yang philosophy, FCMAC-BYY obtains optimal solution by achieving harmony between inputs and fuzzy clusters sets. However, it optimizes the fuzzy sets in the individual dimensions, resulting in the lost of relative binding data and global optimization may not be achieved. Genetic algorithm (GA) is introduced here to look into the issue. GA operates on a population of potential solutions based on the principle of survival of the fittest to produce better approximations to a solution. Populations of candidate solutions are evaluated using fitness functions to determine the best solution. Thereafter, chromosomes would be evolved to produces new genes in the search of the optimal solution. The performance of the proposed GA-FCMAC-BYY model as a bank failure classification and early warning system is very encouraging.	approximation;distress (novel);fitness function;fuzzy set;genetic algorithm;global optimization;maid-droid;mathematical optimization;population;software release life cycle;yang	Kok Siong Lum;Minh Nhut Nguyen;Duan Shi	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424609	mathematical optimization;genetic algorithm;actuarial science;computer science;artificial intelligence;machine learning;data mining;fuzzy set;global optimization	AI	12.912493319963199	-22.680768503008554	82254
f0ff20d6299e77cb7dcd43a2fa31c1a8f43ec18d	simulation modeling of the probability of automobile-pedestrian accident for various driving types	various pedestrian;simulation modeling;specialized controller;automobile-pedestrian accident;simulation model;traffic area;various driving type;accident probability calculation;automobile speed;accident probability;road situation	The paper describes a simulation model of a moving automobile and a pedestrian run out to the traffic area with the accident probability calculation. A set of curves showing the accident probability vs. automobile speed for various pedestrian's walking paces is obtained. A method is offered, which allows to decrease accident probability by using a specialized controller analyzing the changing road situation. A set of curves describing the accident probability vs. automobile speed while using the controller is also obtained.	simulation	Alexander Varnavsky;N. V. Chekan	2014	Automation and Remote Control	10.1134/S0005117914040183	simulation;engineering;automotive engineering;forensic engineering	Robotics	10.221511135842938	-10.149529589254946	82339
29fba35b72eaa0a8d4566949e23965b540cc27e2	a new evolutionary learning model for handwritten character prototyping	handwriting recognition;prototypes power system modeling genetics learning systems evolutionary computation handwriting recognition proposals engines phase measurement;iterative methods;performance evolutionary learning model handwritten character prototyping handwriting recognition search breeder genetic algorithm interaction iterative strategy;genetic algorithms;search problems;evolutionary algorithm;learning artificial intelligence;iterative methods handwriting recognition genetic algorithms search problems learning artificial intelligence;evolutionary learning;breeder genetic algorithm;neural network	The work reported in this paper is aimed to exploit evolutionary learning algorithms for producing the set of prototypes to be used by a handwriting recognition system. In this paper we propose a new evolutionary learning model that combines the power of search of a classical evolutionary algorithm, namely a breeder genetic algorithm, with a novel mechanism for implementing the interaction between the evolving population and the environment. The proposed model allows the system to search for the prototypes by means of a simple iterative strategy rather than through a parallel and adaptive search, as it generally happens in evolutionary learning. Experimental results on handwritten digits have shown that the performance of the proposed algorithm is similar to those exhibited by more complex evolutionary learning algorithms, and better than the one provided by a Neural	artificial neural network;evolutionary algorithm;genetic algorithm;handwriting recognition;iteration;machine learning;map;prototype;spatial variability;test set	Luigi P. Cordella;Claudio De Stefano;Antonio Della Cioppa;Angelo Marcelli	1999		10.1109/ICIAP.1999.797698	evolutionary programming;genetic programming;evolutionary music;genetic algorithm;interactive evolutionary computation;human-based evolutionary computation;cultural algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm;evolutionary acquisition of neural topologies;genetic representation;pattern recognition;iterative method;handwriting recognition;stability;evolutionary robotics;memetic algorithm;population-based incremental learning	AI	14.407717262512644	-23.803572810329538	82432
179a91e2304a37d8f14b6062a696945f39e06a36	rival rewarded and randomly rewarded rival competitive learning	prototypes investments australia neurons neural networks stability equations;neural nets unsupervised learning;unsupervised learning;neural nets;competitive learning;neural nets rival rewarded competitive learning randomly rewarded rival competitive learning rival penalised competitive learning	This paper introduces two new competitive learning paradigms, namely rival rewarded and randomly rewarded rival competitive learning. In both cases, the winner is rewarded as in the classical competitive learning. In the rival rewarded case, the nearest rival can be rewarded in a number of ways. In the second case, the rival is randomly rewarded or penalised by a number of ways. For both paradigms, it is shown experimentally that they behave similarly to the rival penalised competitive learning.	competitive learning;randomness	Andrew Luk;Sandra Lien	1999		10.1109/IJCNN.1999.831154	unsupervised learning;computer science;artificial intelligence;machine learning;pattern recognition;competitive learning;artificial neural network	NLP	17.84249356651792	-21.356975518947944	82569
da0fff6bf3027d8cbd1bd50828e9afa262000948	deep episodic value iteration for model-based meta-reinforcement learning		We present a new deep meta reinforcement learner, which we call Deep Episodic Value Iteration (DEVI). DEVI uses a deep neural network to learn a similarity metric for a non-parametric model-based reinforcement learning algorithm. Our model is trained end-to-end via back-propagation. Despite being trained using the model-free Q-learning objective, we show that DEVI’s model-based internal structure provides ‘one-shot’ transfer to changes in reward and transition structure, even for tasks with very high-dimensional state spaces.	algorithm;artificial neural network;backpropagation;deep learning;end-to-end principle;iteration;markov decision process;parametric model;q-learning;reinforcement learning;software propagation	Steven Stenberg Hansen	2017	CoRR		artificial intelligence;theoretical computer science;machine learning	ML	19.969007373130164	-20.8784785644709	82591
5bf9099e58cf7a8e7692833b0eebb8ad41e54492	a geostatistical approach to modelling positional errors in vector data	vector data	As part of the theoretical development and practical applications of GISs, error issues are receiving increasing attention. This paper contributes to the debate in GIS error issues by exploring the applications of geostatistics in vector data, where positional errors are of major concern. A review is provided of the methods for handling positional errors in GIS vector data comprising points and lines. This is followed by a description of a stochastic simulation approach to modelling positional errors, which is remarkable for its ability to accommodate the spatial correlation characteristics of spatial data and their errors. Results from an experiment using photogrammetric data confirm the effectiveness of the proposed approach for modelling positional errors. The simulation approach is also examined with respect to other methods where due consideration is not given to the spatial correlation that is intrinsic to positional errors. Stochastic simulationbased modelling of uncertain vector data via raster structures represents a valuable extension and contribution of geostatistical approaches to integrated handling of errors in heterogeneous spatial data.	fuzzy set;geographic information system;graph (discrete mathematics);photogrammetry;raster data;raster graphics;simulation;vector graphics	J. Zhang;Roger P. Kirby	2000	Trans. GIS	10.1111/1467-9671.00044	econometrics;computer science;data mining;statistics	Robotics	24.453409342358526	-21.599418872679976	82618
587d4e9b2b3fe35d1eb067035ed417ce8828b88d	traffic signal optimization through discrete and continuous reinforcement learning with robustness analysis in downtown tehran		Abstract Traffic signal control plays a pivotal role in reducing traffic congestion. Traffic signals cannot be adequately controlled with conventional methods due to the high variations and complexity in traffic environments. In recent years, reinforcement learning (RL) has shown great potential for traffic signal control because of its high adaptability, flexibility, and scalability. However, designing RL-embedded traffic signal controllers (RLTSCs) for traffic systems with a high degree of realism is faced with several challenges, among others system disturbances and large state-action spaces are considered in this research. The contribution of the present work is founded on three features: (a) evaluating the robustness of different RLTSCs against system disturbances including incidents, jaywalking, and sensor noise, (b) handling a high-dimensional state-action space by both employing different continuous state RL algorithms and reducing the state-action space in order to improve the performance and learning speed of the system, and (c) presenting a detailed empirical study of traffic signals control of downtown Tehran through seven RL algorithms: discrete state Q-learning( λ ), SARSA( λ ), actor-critic( λ ), continuous state Q-learning( λ ), SARSA( λ ), actor-critic( λ ), and residual actor-critic( λ ). In this research, first a real-world microscopic traffic simulation of downtown Tehran is carried out, then four experiments are performed in order to find the best RLTSC with convincing robustness and strong performance. The results reveal that the RLTSC based on continuous state actor-critic( λ ) has the best performance. In addition, it is found that the best RLTSC leads to saving average travel time by 22% (at the presence of high system disturbances) when it is compared with an optimized fixed-time controller.		Mohammad Reza Aslani;Stefan Seipel;Mohammad Saadi Mesgari;Marco Wiering	2018	Advanced Engineering Informatics	10.1016/j.aei.2018.08.002	data mining;residual;engineering;control theory;adaptability;scalability;robustness (computer science);reinforcement learning;control theory;traffic congestion;traffic simulation	ML	15.361860009729948	-16.118621371857206	82958
dcadbdf3d8c213ed578d886e8e639aefbee03790	meta-gradient reinforcement learning		The goal of reinforcement learning algorithms is to estimate and/or optimise the value function. However, unlike supervised learning, no teacher or oracle is available to provide the true value function. Instead, the majority of reinforcement learning algorithms estimate and/or optimise a proxy for the value function. This proxy is typically based on a sampled and bootstrapped approximation to the true value function, known as a return. The particular choice of return is one of the chief components determining the nature of the algorithm: the rate at which future rewards are discounted; when and how values should be bootstrapped; or even the nature of the rewards themselves. It is well-known that these decisions are crucial to the overall success of RL algorithms. We discuss a gradient-based meta-learning algorithm that is able to adapt the nature of the return, online, whilst interacting and learning from the environment. When applied to 57 games on the Atari 2600 environment over 200 million frames, our algorithm achieved a new state-of-the-art performance. The central goal of reinforcement learning (RL) is to optimise the agent’s return (cumulative reward); this is typically achieved by a combination of prediction and control. The prediction subtask is to estimate the value function – the expected return from any given state. Ideally, this would be achieved by updating an approximate value function towards the true value function. The control subtask is to optimise the agent’s policy for selecting actions, so as to maximise the value function. Ideally, the policy would simply be updated in the direction that increases the true value function. However, the true value function is unknown and therefore, for both prediction and control, a sampled return is instead used as a proxy. A large family of RL algorithms [Sutton, 1988, Rummery and Niranjan, 1994, van Seijen et al., 2009, Sutton and Barto, 2018], including several state-of-the-art deep RL algorithms [Mnih et al., 2015, van Hasselt et al., 2016, Harutyunyan et al., 2016, Hessel et al., 2018, Espeholt et al., 2018], are characterised by different choices of the return. The discount factor γ determines the time-scale of the return. A discount factor close to γ = 1 provides a long-sighted goal that accumulates rewards far into the future, while a discount factor close to γ = 0 provides a short-sighted goal that prioritises short-term rewards. Even in problems where long-sightedness is clearly desired, it is frequently observed that discounts γ < 1 achieve better results [Prokhorov and Wunsch, 1997], especially during early learning. It is known that many algorithms converge faster with lower discounts [Bertsekas and Tsitsiklis, 1996], but of course too low a discount can lead to highly sub-optimal policies that are too myopic. In practice it can be better to first optimise for a myopic horizon, e.g., with γ = 0 at first, and then to repeatedly increase the discount only after learning is somewhat successful [Prokhorov and Wunsch, 1997]. The return may also be bootstrapped at different time horizons. An n-step return accumulates rewards over n time-steps and then adds the value function at the nth time-step. The λ-return [Sutton, 1988, Sutton and Barto, 2018] is a geometrically weighted combination of n-step returns. In either case, the meta-parameter n or λ can be important to the performance of the algorithm, trading off bias and variance. Many researchers have sought to automate the selection of these parameters [Kearns and Singh, 2000, Downey and Sanner, 2010, Konidaris et al., 2011, White and White, 2016]. 32nd Conference on Neural Information Processing Systems (NIPS 2018), Montréal, Canada. There are potentially many other design choices that may be represented in the return, including off-policy corrections [Espeholt et al., 2018, Munos et al., 2016], target networks [Mnih et al., 2015], emphasis on certain states [Sutton et al., 2016], reward clipping [Mnih et al., 2013], or even the nature of the rewards themselves [Randløv and Alstrøm, 1998, Singh et al., 2005, Zheng et al., 2018]. In this work, we are interested in one of the fundamental problems in reinforcement learning: what would be the best form of return for the agent to maximise? Specifically, we propose to learn the return function by treating it as a parametric function with tunable meta-parameters η, for instance including the discount factor γ, or the bootstrapping parameter λ [Sutton, 1988]. The meta-parameters η are adjusted online during the agent’s interaction with the environment, allowing the return to both adapt to the specific problem, and also to dynamically adapt over time to the changing context of learning. We derive a practical gradient-based meta-learning algorithm and show that this can significantly improve performance on large-scale deep reinforcement learning applications. 1 Meta-Gradient Reinforcement Learning Algorithms In deep reinforcement learning, the value function and policy are approximated by a neural network with parameters θ, denoted by vθ(S) and πθ(A|S) respectively. At the core of the algorithm is an update function, θ′ = θ + f(τ, θ, η) , (1) that adjusts parameters from a sequence of experience τt = {St, At, Rt+1, . . .} consisting of states S, actions A and rewards R. The nature of the function is determined by meta-parameters η. Our meta-gradient RL approach is based on the principle of online cross-validation [Sutton, 1992], using successive samples of experience. The underlying RL algorithm is applied to the first sample (or samples), and its performance is measured in a subsequent sample. Specifically, the algorithm starts with parameters θ, and applies the update function to the first sample(s), resulting in new parameters θ′. The gradient dθ′/dη of these updates indicates how the meta-parameters affected these new parameters. The algorithm then measures the performance of the new parameters θ′ on a second sample τ ′. For instance, when learning online τ ′ could be the next time-step immediately following τ . Performance is measured by a differentiable meta-objective J̄(τ ′, θ′, η̄) that uses a fixed meta-parameter η̄. The gradient of the meta-objective with respect to the meta-parameters η is obtained by applying the chain rule: ∂J̄(τ ′, θ′, η̄) ∂η = ∂J̄(τ ′, θ′, η̄) ∂θ′ dθ′ dη . (2) To compute the gradient of the updates, dθ′/dη, we note that the parameters form an additive sequence, and the gradient can therefore be accumulated online [Williams and Zipser, 1989], dθ′ dη = dθ dη + ∂f(τ, θ, η) ∂η + ∂f(τ, θ, η) ∂θ dθ dη = ( I + ∂f(τ, θ, η) ∂θ ) dθ dη + ∂f(τ, θ, η) ∂η (3) This update has the form z′ = Az + ∂f(τ, θ, η) ∂η , where z = dθ/dη or z ≈ dθ/dη. The exact gradient is given by A = I + ∂f(τ, θ, η)/∂θ. In practice, the gradient ∂f(τ, θ, η)/∂θ is large and challenging to compute — it is a n × n matrix, where n is the number of parameters in θ. One possibility is to use an alternate update A = I + ˆ ∂f(τ, θ, η)/∂θ using a cheap approximate derivative ˆ ∂f(τ, θ, η)/∂θ ≈ ∂f(τ, θ, η)/∂θ, for instance using a diagonal approximation [Sutton, 1992, Schraudolph, 1999]. Furthermore, the gradient accumulation defined above assumes that the meta-parameters η are held fixed throughout training. In practice, we are updating η and therefore it may be desirable to decay the trace into the past [Schraudolph, 1999], A = μ(I + ∂f(τ, θ, η)/∂θ), using decay rate μ ∈ [0, 1]. The simplest approximation is to use A = 0 (or equivalently μ = 0), which means that we only consider the effect of the meta-parameters η on a single update; this approximation is especially cheap to compute.	andrew barto;approximation algorithm;artificial neural network;atari;bellman equation;bootstrapping (compilers);converge;cross-validation (statistics);deep learning;experience;gradient;harley's humongous adventure;horizon effect;hyper-heuristic;hyper-threading;information processing;interaction;nips;proxy server;reinforcement learning;rod downey;sampling (signal processing);supervised learning;tree accumulation;utility functions on indivisible goods;while	Zhongwen Xu;Hado van Hasselt;David Silver	2018			supervised learning;computer science;artificial intelligence;machine learning;reinforcement learning;oracle;bootstrapping;bellman equation	ML	22.682291858938893	-19.026371845875506	83227
3daf6886fcff66dff38f7caa38d221cce000824d	creating large numbers of game ais by learning behavior for cooperating units	evolutionary computation;games tiles learning artificial intelligence decision making learning systems computer architecture;learning artificial intelligence;computer games;learning artificial intelligence computer games decision making evolutionary computation;scenario maps game ai creation learning behavior cooperating units hybrid learning method shout ahead architecture battle for wesnoth decision making rule sets reinforcement learning evolutionary learning terrain knowledge	We present two improvements to the hybrid learning method for the shout-ahead architecture for units in the game Battle for Wesnoth. The shout-ahead architecture allows for units to perform decision making in two stages, first determining an action without knowledge of the intentions of other units, then, after communicating the intended action and likewise receiving the intentions of the other units, taking these intentions into account for the final decision on the next action. The decision making uses two rule sets and reinforcement learning is used to learn rule weights (that influence decision making), while evolutionary learning is used to evolve good rule sets. Our improvements add knowledge about terrain to the learning and also evaluate unit behaviors on several scenario maps to learn more general rules. The use of terrain knowledge resulted in improvements in the win percentage of evolved teams between 3 and 14 percentage points for different maps, while using several maps to learn from resulted in nearly similar win percentages on maps not learned from as on the maps learned from.	artificial intelligence (video games);map;reinforcement learning	Stephen Wiens;Jörg Denzinger;Sanjeev Paskaradevan	2013	2013 IEEE Conference on Computational Inteligence in Games (CIG)	10.1109/CIG.2013.6633608	error-driven learning;simulation;computer science;artificial intelligence;machine learning;learning classifier system;competitive learning;evolutionary computation	AI	18.2096447547053	-21.19925814458323	83764
cd7523c404e78e9bd4e1b73d77000e65bf51deee	learning gated bayesian networks for algorithmic trading	datavetenskap datalogi;computer science	Abstract. Gated Bayesian networks (GBNs) are a recently introduced extension of Bayesian networks that aims to model dynamical systems consisting of several distinct phases. In this paper, we present an algorithm for semi-automatic learning of GBNs. We use the algorithm to learn GBNs that output buy and sell decisions for use in algorithmic trading systems. We show how using the learnt GBNs can substantially lower risks towards invested capital, while at the same time generating similar or better rewards, compared to the benchmark investment strategy buy-and-hold.	algorithm;algorithmic trading;bayesian network;benchmark (computing);concave function;dynamical system;go-back-n arq;influence diagram;machine learning;semiconductor industry	Marcus Bendtsen;José M. Peña	2014		10.1007/978-3-319-11433-0_4	simulation;actuarial science;computer science;machine learning;management science	ML	21.135347460958364	-17.751711882623567	83787
3efeb86e40ef1accba2aeaf831dc263b856cc77d	the evolution of variable learning rates	learning rate;neural plasticity;critical period;natural selection	Neural plasticity in humans is well known to be age dependent, with `critical periods' for the learning of many tasks. It is reasonable to hypothesise that this has some intrinsic advantage over constant plasticity, and that it has arisen as the result of evolution by natural selection. If this is true, then it may also prove useful for building more eÆcient arti cial systems that are required to learn how to perform appropriately. In this paper I explore these ideas with a series of explicit evolutionary simulations of some simpli ed control systems.	control system;norm (social);simulation	John A. Bullinaria	2002			neuroplasticity;natural selection;artificial intelligence;machine learning;critical period	ML	16.962942288279976	-22.39342046033749	83797
0fd4fad7c485e39f44cf8bbe7469f8bf40fe33da	tight policy regret bounds for improving and decaying bandits		We consider a variant of the well-studied multiarmed bandit problem in which the reward from each action evolves monotonically in the number of times the decision maker chooses to take that action. We are motivated by settings in which we must give a series of homogeneous tasks to a finite set of arms (workers) whose performance may improve (due to learning) or decay (due to loss of interest) with repeated trials. We assume that the arm-dependent rates at which the rewards change are unknown to the decision maker, and propose algorithms with provably optimal policy regret bounds, a much stronger notion than the often-studied external regret. For the case where the rewards are increasing and concave, we give an algorithm whose policy regret is sublinear and has a (provably necessary) dependence on the time required to distinguish the optimal arm from the rest. We illustrate the behavior and performance of this algorithm via simulations. For the decreasing case, we present a simple greedy approach and show that the policy regret of this algorithm is constant and upper bounded by the number of arms.	coat of arms;concave function;greedy algorithm;multi-armed bandit;regret (decision theory);simulation;whole earth 'lectronic link	Hoda Heidari;Michael Kearns;Aaron Roth	2016			mathematical optimization;machine learning;mathematics;mathematical economics;regret	AI	23.224333999340143	-17.167224523263748	83832
c24c199b948a2c4fdba4e248823ee97d287375f7	on learning navigation behaviors for small mobile robots with reservoir computing architectures	reservoirs;robot sensing systems;goal directed navigation behavior mobile robot reservoir computing architecture rc learning framework recurrent neural network training sensory motor sequence nonlinear space;training;biological system modeling;mobile robots;navigation;reservoirs navigation robot sensing systems mobile robots training biological system modeling;sensory motor coupling echo state network esn goal directed navigation recurrent neural networks rnns reinforcement learning rl reservoir computing rc robot navigation;recurrent neural nets control engineering computing learning artificial intelligence mobile robots neurocontrollers nonlinear control systems path planning	This paper proposes a general reservoir computing (RC) learning framework that can be used to learn navigation behaviors for mobile robots in simple and complex unknown partially observable environments. RC provides an efficient way to train recurrent neural networks by letting the recurrent part of the network (called reservoir) be fixed while only a linear readout output layer is trained. The proposed RC framework builds upon the notion of navigation attractor or behavior that can be embedded in the high-dimensional space of the reservoir after learning. The learning of multiple behaviors is possible because the dynamic robot behavior, consisting of a sensory-motor sequence, can be linearly discriminated in the high-dimensional nonlinear space of the dynamic reservoir. Three learning approaches for navigation behaviors are shown in this paper. The first approach learns multiple behaviors based on the examples of navigation behaviors generated by a supervisor, while the second approach learns goal-directed navigation behaviors based only on rewards. The third approach learns complex goal-directed behaviors, in a supervised way, using a hierarchical architecture whose internal predictions of contextual switches guide the sequence of basic navigation behaviors toward the goal.	architecture as topic;artificial neural network;assumed;behavior;bellman equation;cognition disorders;cognitive science;computation (action);dynamical system;embedded system;embedding;execution;experience;large;linear discriminant analysis;merge;mobile robot;network switch;neural network simulation;nonlinear system;partially observable system;rc circuit;random neural network;recurrent neural network;reservoir device component;reservoir computing;rewards;robot (device);robotics;small;spatial navigation;supervised learning;switch device component;tree network;unsupervised learning;weight;biologic segmentation;replication compartment;sensor (device)	Eric A. Antonelo;Benjamin Schrauwen	2015	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2014.2323247	mobile robot;navigation;simulation;computer science;artificial intelligence;machine learning;mobile robot navigation;reservoir	Robotics	18.913950428910486	-22.82611414288342	84013
85abc327db3c00af1a1610c866fa78d4a3252c78	neural-network- based modeling of electric discharge machining process		The purpose of this article is to present the application of neural network for modeling electric discharge machining process. This article highlights the various aspects of neural network modeling with specific regard to EDM process. Experimental data has been used to train the neural network by back-propagation. Prediction ability of the trained model has been verified experimentally and the reported results indicate that proposed neural network model can successfully predict the output for a given set of input.	artificial neural network;discharger	Pushpendrai Singh Bharti;Sachin Maheshwari;Chitra Sharma	2011		10.1007/978-3-642-19644-7_11	computer science;machine learning;artificial intelligence;experimental data;surface roughness;artificial neural network;electrical discharge machining	Robotics	12.844492783626999	-19.664556741872953	84015
39899216191eb16c306fc9f25a8233192048c0cd	value propagation networks		We present Value Propagation (VProp), a parameter-efficient differentiable planning module built on Value Iteration which can successfully be trained using reinforcement learning to solve unseen tasks, has the capability to generalize to larger map sizes, and can learn to navigate in dynamic environments. Furthermore, we show that the module enables learning to plan when the environment also includes stochastic elements, providing a cost-efficient learning system to build low-level size-invariant planners for a variety of interactive navigation problems. We evaluate on static and dynamic configurations of MazeBase grid-worlds, with randomly generated environments of several different sizes, and on a StarCraft navigation scenario, with more complex dynamics, and pixels as input.		Nantas Nardelli;Gabriel Synnaeve;Zeming Lin;Pushmeet Kohli;Philip H. S. Torr;Nicolas Usunier	2018	CoRR		machine learning;differentiable function;artificial intelligence;computer science;present value;markov decision process;reinforcement learning	ML	20.157693645549788	-20.687923210929004	84037
f0f266b87a4860da36f622f50a8faba70d0374db	search reduction in hierarchical problem solving	problem solving	It has long been recognized that hierarchical problem solving can be used to reduce search. Yet, there has been little analysis of the problemsolving method and few experimental results. This paper provides the rst comprehensive analytical and empirical demonstrations of the e ectiveness of hierarchical problem solving. First, the paper shows analytically that hierarchical problem solving can reduce the size of the search space from exponential to linear in the solution length and identi es a su cient set of assumptions for such reductions in search. Second, it presents empirical results both in a domain that meets all of these assumptions as well as in domains in which these assumptions do not strictly hold. Third, the paper explores the conditions under which hierarchical problem solving will be e ective in practice.	problem solving;time complexity	Craig A. Knoblock	1991			mathematical optimization;computer science;general group problem solving (ggps) model;algorithm	AI	18.36011836898669	-11.308317285366972	84144
3c79204e90b3b57c8efcc3c75eaeb4c21550cb00	automatically finding the control variables for complex system behavior	national aeronautics and space administration;computer systems design;optimization technique;computer systems simulation;optimal method;simulation;search based software engineering;numerical optimization;large scale system;simulated annealing;data mining;software engineering;contrast set learning;computer programming;critical system;machine learning;complex system;systems analysis;monte carlo method;computerized simulation;monte carlo filtering;complex systems;artificial intelligence;ames research center;optimization;software reliability	Testing large-scale systems is expensive in terms of both time and money. Running simulations early in the process is a proven method of finding the design faults likely to lead to critical system failures, but determining the exact cause of those errors is still time-consuming and requires access to a limited number of domain experts. It is desirable to find an automated method that explores the large number of combinations and is able to isolate likely fault points. Treatment learning is a subset of minimal contrast-set learning that, rather than classifying data into distinct categories, focuses on finding the unique factors that lead to a particular classification. That is, they find the smallest change to the data that causes the largest change in the class distribution. These treatments, when imposed, are able to identify the factors most likely to cause a mission-critical failure. The goal of this research is to comparatively assess treatment learning against state-of-the-art numerical optimization techniques. To achieve this, this paper benchmarks the TAR3 and TAR4.1 treatment learners against optimization techniques across three complex systems, including two projects from the Robust Software Engineering (RSE) group within the National Aeronautics and Space Administration (NASA) Ames Research Center. The results clearly show that treatment learning is both faster and more accurate than traditional optimization methods.	algorithm;complex system;complex systems;contrast set learning;critical system;dataspaces;discretization;dynamical system;failure cause;gigabyte;heuristic (computer science);machine learning;markov chain;markov model;mathematical optimization;mission critical;newton's method;precision and recall;quasi-newton method;recursion;reliability engineering;robustness (computer science);simulated annealing;simulation;software engineering;sorting;statistical classification	Gregory Gay;Tim Menzies;Misty Davies;Karen Gundy-Burlet	2010	Automated Software Engineering	10.1007/s10515-010-0072-x	systems analysis;complex systems;simulation;contrast set learning;simulated annealing;computer science;engineering;artificial intelligence;software engineering;machine learning;computer programming;monte carlo method	SE	16.09467289991744	-14.841238392035136	84208
d70eee1b6c8bcd11a4b2e16bcd3fbc75d927eebc	development of smart gas sensor system to classify binary gas mixtures		Solvents are used in a large number of industries especially in cleaning and cosmetic. Solvents are known to be harmful to human health. Classification of solvent in a product is important to determine the level of hazard that can people faced. In this study, three different solvents, methanol, acetone, and chloroform, are used to obtain binary gas mixtures in a laboratory environment. A gas sensor system that has 9 QCM sensors is used to obtain binary gas mixtures data. The developed system uses artificial neural network trained by artificial bee colony algorithm. This hybrid algorithm is used to classify binary gas mixtures. Too many scenarios are tested and it is observed that classifying binary gas mixtures by ANN-ABC hybrid method gives successful results and increased the classification performance of test data by 71.43%.	artificial bee colony algorithm;artificial neural network;hazard (computer architecture);hybrid algorithm;sensor;sputter cleaning;test data	M. Fatih Adak;Nejat Yumusak	2017	IEEE EUROCON 2017 -17th International Conference on Smart Technologies	10.1109/EUROCON.2017.8011191	artificial bee colony algorithm;genetic algorithm;hybrid algorithm;artificial neural network;artificial intelligence;test data;machine learning;binary number;solvent;engineering	Robotics	13.249391025066336	-18.20360721616717	84301
8d6fd213206dbd6cd2060378bb365f47b2b14931	nonparametric regression-based failure rate model for electric power equipment using lifecycle data	maintenance engineering data models prognostics and health management power grids inspection hazards;regression analysis asset management data acquisition hazards maintenance engineering power apparatus power grids power transformers product life cycle management;proportional hazards model phm asset management data mining failure rate health index hi lifecycle data nonparametric regression;power grid electric power equipment nonparametric regression failure rate model stratified proportional hazards model phm hierarchy process equipment health condition multitype recurrent events single health cycle recurrent inspecting events martingale process event specific failure function potential risk power transformers asymptotic property graphical method analytical method lifecycle data acquisition asset management system health prognosis maintenance optimization	In order to analyze the fault trends more accurately, a failure rate model appropriate for general electric power equipment is established based on a nonparametric regression method, improved from stratified proportional hazards model (PHM), which can make maximum use of equipment lifecycle data as the covariates, including manufacturer, service age, location, maintainer, health index, etc. All of covariates are represented in the hierarchy process of equipment health condition, which is beneficial for processing and classifying the lifecycle data into multitype recurrent events quantitatively. On this occasion, more inspecting events can be utilized in a complete cycle to predict potential risk and assess equipment health condition. Then, stratified nonparametric PHM is employed to build the multitype recurrent events-specific failure model appropriate for competing risk problem toward interval censored. Lastly, the example in terms of transformers demonstrates the modeling procedure. Results show the well asymptotic property and goodness-of-fit tested by both of graphical and analytical methods. Compared with existing failure models, such as age-based or CBF model, this improved nonparametric regression model can mine lifecycle data acquisition from asset management system, depict the failure trend accurately considering both individual and group features, and lay the foundation for health prognosis, maintenance optimization, and asset management in power grid.	censoring (statistics);data acquisition;failure rate;graphical user interface;mathematical optimization;proportional hazards model;transformers;whole earth 'lectronic link	Jian Qiu;Huifang Wang;Dongyang Lin;Benteng He;Wanfang Zhao;Wei Xu	2015	2016 IEEE/PES Transmission and Distribution Conference and Exposition (T&D)	10.1109/TSG.2015.2388784	reliability engineering;engineering;operations management;data mining	ML	12.06547972565509	-12.891838313104776	84558
917e3b24448d5f44af8d7b52789b3282b9512f30	a distributed optimal strategy for rendezvous of multi-robots with random node failures	stochastic systems control system synthesis distributed control multi robot systems optimal control probability;algorithm design and analysis vectors robot sensing systems convergence indexes optimal control;probability distribution distributed optimal strategy random node failures multi robot systems constraint set finite time point convergence distributed stochastic optimal control	In this paper, we consider the problem of designing distributed control algorithms to solve the rendezvous problem for multi-robot systems with limited sensing, for situation in which random nodes may fail during execution. We first formulate a distributed solution based upon averaging algorithms that have been reported in the consensus literature. In this case, at each stage of execution a 1-step sequential optimal control (i.e., naïve greedy algorithm) is used. We show that by choosing an appropriate constraint set, finite-time point convergence is guaranteed. We then propose a distributed stochastic optimal control algorithm that minimizes a mean-variance cost function for each stage, given that the probability distribution for possible node failures is known a priori. We show via simulation results that our algorithm provides competitive rendezvous task performance in comparison to that of the classical circumcenter algorithm for cases in which there are no node failures. Then we show, via examples with multiple node failures, that our proposed algorithm provides better rendezvous task performance than contemporary algorithms in cases for which failures occur. Additionally, we generate and compare a spectrum of results by varying the probabilities of node failures, or varying the weight value for the variance term in the cost functional. The results suggest that by choosing the design parameters appropriately, one may adjust the degree of soft constraints of the controller as well.	distributed control system;greedy algorithm;loss function;mathematical optimization;norm (social);optimal control;robot;simulation	Hyongju Park;Seth Hutchinson	2014	2014 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2014.6942703	mathematical optimization;computer science;control theory;distributed computing	Robotics	22.296189303443587	-14.480189211783777	84809
1f8c9c98fbeed5d1b8893119ff02384f79c29e90	intrinsically motivated model learning for developing curious robots	developmental learning;reinforcement learning;intrinsic motivation;robots;exploration	Reinforcement Learning (RL) agents are typically deployed to learn a specific, concrete task based on a pre-defined reward function. However, in some cases an agent may be able to gain experience in the domain prior to being given a task. In such cases, intrinsic motivation can be used to enable the agent to learn a useful model of the environment that is likely to help it learn its eventual tasks more efficiently. This paradigm fits robots particularly well, as they need to learn about their own dynamics and affordances which can be applied to many different tasks. This article presents the  texplore  with Variance-And-Novelty-Intrinsic-Rewards algorithm ( texplore-vanir ), an intrinsically motivated model-based RL algorithm. The algorithm learns models of the transition dynamics of a domain using random forests. It calculates two different intrinsic motivations from this model: one to explore where the model is uncertain, and one to acquire novel experiences that the model has not yet been trained on. This article presents experiments demonstrating that the combination of these two intrinsic rewards enables the algorithm to learn an accurate model of a domain with no external rewards and that the learned model can be used afterward to perform tasks in the domain. While learning the model, the agent explores the domain in a developing and curious way, progressively learning more complex skills. In addition, the experiments show that combining the agent's intrinsic rewards with external task rewards enables the agent to learn faster than using external rewards alone. We also present results demonstrating the applicability of this approach to learning on robots.	action selection;algorithm;automated planning and scheduling;autonomous robot;experience;experiment;humanoid robot;hypertext transfer protocol;nao (robot);open-source software;random forest;robot;robot operating system;sampling (signal processing);simulation;state space;pkg-config	Todd Hester;Peter Stone	2017	Artif. Intell.	10.1016/j.artint.2015.05.002	robot;error-driven learning;simulation;motivation;exploration;computer science;artificial intelligence;machine learning;reinforcement learning	AI	20.370196601090893	-20.698593330029656	85068
aaef9a4f51fd8473cafa3fe537b47a9c13c200b2	survival by continuous learning in a dynamic multiple task environment	dynamic change;artificial neural networks learning systems humans testing games computer science intelligent agent propulsion computational intelligence input variables;computational intelligence;continuous learning;learning mechanism continuous learning dynamic multiple task environment machine learning method;multi agent systems learning artificial intelligence;data mining;cloning;artificial neural networks;multi agent systems;machine learning;heuristic algorithms;learning mechanism;games;machine learning method;dynamic multiple task environment;learning artificial intelligence;fires	The ability to adapt or not when challenged with a dynamic, changing environment is what differentiates between survival and extinction of species. In this paper we present a machine learning method that allows agents in an environment with changing tasks to adapt and modify their behavior thus ensuring their survival. These agents do not get explicit information about the change in tasks. The learning mechanism ensures the presence of enough diversity in the agents so that they can restart learning if the previous learning stops to be effective and enough continuity in the system so that the agents can keep on learning if their task has not changed.	machine learning;scott continuity	Hasan Mujtaba;Abdul Rauf Baig	2008	2008 IEEE Symposium On Computational Intelligence and Games	10.1109/CIG.2008.5035654	games;multi-task learning;error-driven learning;simulation;computer science;artificial intelligence;machine learning;computational intelligence;cloning;artificial neural network	AI	18.144132825548148	-21.180140120701466	85494
6c1ea7992b0d724213a940020b6eb1805c00dbfb	novelty detection for the identification of abnormalities	prediction error;novelty detection;feature space;statistical model;temperature profile;spatial correlation;fault detection;normal operator;neural network	The principle of novelty detection offers an approach to the problem of fault detection which only requires the normal class to be defined. A model of normality is learnt by including normal examples only in the training data; abnormalities are then identified by testing for novelty against this description. In this paper, we review our work on statistical models of normality in feature space and we explain how we have used novelty detection to identify unusual vibration signatures in jet engines. The main aim of the paper, however, is to introduce the concept of a neural network predictor as a model of normality. The neural network is trained to predict an output value given a set of input patterns, all of which are acquired during normal operation. In the application under consideration, we make use of the spatial correlations in the temperature profile of the exhaust gas from a turbine to predict a thermocouple reading given another part of the temperature profile and the engine speed. Abnormalities in...	novelty detection	Lionel Tarassenko;Alexandre Nairac;Neil W. Townsend;Iain L O Buxton;Peter Cowley	2000	Int. J. Systems Science	10.1080/00207720050197802	statistical model;spatial correlation;feature vector;artificial intelligence;machine learning;mean squared prediction error;pattern recognition;mathematics;normal operator;artificial neural network;fault detection and isolation;statistics	Logic	14.687711836232278	-17.867237843069752	85499
7148e3792e50619a13f70c1e62d85b77125cca1c	load forecasting framework of electricity consumptions for an intelligent energy management system in the user-side	forecasting;anfis;genetic algorithm;intelligent ems	0957-4174/$ see front matter 2011 Elsevier Ltd. A doi:10.1016/j.eswa.2011.11.062 ⇑ Corresponding author. Tel.: +34 937 398 772; fax E-mail address: juan.jose.cardenas@mcia.upc.edu ( This work presents an electricity consumption-forecasting framework configured automatically and based on an Adaptative Neural Network Inference System (ANFIS). This framework is aimed to be implemented in industrial plants, such as automotive factories, with the objective of giving support to an Intelligent Energy Management System (IEMS). The forecasting purpose is to support the decision-making (i.e. scheduling workdays, on–off production lines, shift power loads to avoid load peaks, etc.) to optimize and improve economical, environmental and electrical key performance indicators. The base structure algorithm, the ANFIS algorithm, was configured by means of a Multi Objective Genetic Algorithm (MOGA), with the aim of getting an automatic-configuration system modelling. This system was implemented in an independent section of an automotive factory, which was selected for the high randomness of its main loads. The time resolution for forecasting was the quarter hour. Under these challenging conditions, the autonomous configuration, system learning and prognosis were tested with success. 2011 Elsevier Ltd. All rights reserved.	adaptive neuro fuzzy inference system;artificial neural network;autonomous robot;crew scheduling;fax;genetic algorithm;knowledge-based configuration;management system;physical plant;powera;randomness;scheduling (computing)	Juan J. Cárdenas;Luis Romeral;Antonio Garcia Espinosa;Fabio Andrade	2012	Expert Syst. Appl.	10.1016/j.eswa.2011.11.062	simulation;genetic algorithm;adaptive neuro fuzzy inference system;forecasting;computer science;artificial intelligence	AI	10.353542369193093	-16.820465145754643	85524
d2df6969b185a4017048f996d0e7cd1859c24e67	output range analysis for deep feedforward neural networks		Given a neural network (NN) and a set of possible inputs to the network described by polyhedral constraints, we aim to compute a safe over-approximation of the set of possible output values. This operation is a fundamental primitive enabling the formal analysis of neural networks that are extensively used in a variety of machine learning tasks such as perception and control of autonomous systems. Increasingly, they are deployed in high-assurance applications, leading to a compelling use case for formal verification approaches. In this paper, we present an efficient range estimation algorithm that iterates between an expensive global combinatorial search using mixed-integer linear programming problems, and a relatively inexpensive local optimization that repeatedly seeks a local optimum of the function represented by the NN. We implement our approach and compare it with Reluplex, a recently proposed solver for deep neural networks. We demonstrate applications of our approach to computing flowpipes for neural network-based feedback controllers. We show that the use of local search in conjunction with mixed-integer linear programming solvers effectively reduces the combinatorial search over possible combinations of active neurons in the network by pruning away suboptimal nodes.	algorithm;approximation;artificial neural network;autonomous robot;autonomous system (internet);combinatorial search;control system;deep learning;feedforward neural network;formal verification;integer programming;linear programming;local optimum;local search (optimization);machine learning;mathematical optimization;neural networks;polyhedron;rectifier (neural networks);recurrent neural network;reinforcement learning;solver	Souradeep Dutta;Susmit Jha;Sriram Sankaranarayanan;Ashish Tiwari	2018		10.1007/978-3-319-77935-5_9	combinatorial search;feedforward neural network;local optimum;local search (optimization);artificial neural network;machine learning;linear programming;formal verification;solver;artificial intelligence;computer science	ML	21.468437070880068	-22.56445143973407	85885
f7f27fc78579e5c3fa7b03905740f8ff69dcde93	performance of a finite-state machine implementation of iterative cluster labeling on desktop and mobile computing platforms	computer modeling;pattern clustering finite state machines iterative methods mobile computing;nearest eight neighborhood rule;modelizacion;distributed system;iterative method;environmental factors;pattern clustering;diseno circuito;systeme reparti;informatique mobile;algorithm analysis;ecologia;iterative algorithms;paysage;application software;competitividad;maquina estado finito;percolation analysis;computer model;palm mobile computing device;circuit design;percolacion;biological system modeling;tipo dato;ecologie;paisaje;mobile computer;testing;data type;ecology;hoshen kopelman cluster identification algorithm;computer applications;palm device cluster identification finite state machine hoshen kopelman landscape ecology;metodo iterativo;landscape ecology;palm mobile computing device finite state machine iterative cluster labeling mobile computing platform desktop platform hoshen kopelman cluster identification algorithm nearest eight neighborhood rule computer modeling landscape ecology percolation analysis;identificacion sistema;modelisation;iterative methods;finite state machines;iterative cluster labeling;sistema repartido;percolation;system identification;mobile computing platform;methode iterative;competitiveness;cluster identification;clustering algorithms;land cover mapping;hardware design;analyse algorithme;conception circuit;landscape;type donnee;mobile computing;machine etat fini;competitivite;modeling;hoshen kopelman;algorithm design and analysis;finite state machine;identification systeme;analisis algoritmo;desktop platform;labeling;labeling mobile computing clustering algorithms iterative algorithms application software computer applications biological system modeling environmental factors testing algorithm design and analysis;palm device	In this paper, we present an efficient finite-state machine implementation of the Hoshen-Kopelman cluster identification algorithm using the nearest-eight neighborhood rule suitable to applications such as computer modeling for landscape ecology. The implementation presented in this study was tested using both actual land cover maps, as well as randomly generated data similar to those in the original presentation of the Hoshen-Kopelman algorithm for percolation analysis. The finite-state machine implementation clearly outperformed a straightforward adaptation of the original Hoshen-Kopelman algorithm on either data type. Research was also conducted to explore the finite-state machine's performance on a palm mobile computing device, and while it was competitive, it did not exceed the performance of the straightforward Hoshen-Kopelman implementation. However, a discussion of why this was the case is provided along with a possible remedy for future hardware designs.	cpu cache;computer simulation;finite-state machine;hoshen–kopelman algorithm;landscape ecology;low-power fsm synthesis;map;mathematical optimization;mobile computing;percolation;procedural generation;randomness;sparse matrix;testbed;uncanny valley;workstation;xfig	M. L. Aldridge;Michael W. Berry	2009	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2009.19	simulation;computer science;artificial intelligence;theoretical computer science;machine learning;data mining;database;iterative method;mobile computing;world wide web;algorithm	DB	16.86210859650008	-10.60583609609972	86179
47bc678553c42bfa9ce8a3b4c6f65414f7e9573a	maturation and the evolution of imitative learning in artificial organisms	baldwin effect;learning organization;body size;simulation experiment;life history;age at maturity;genetic algorithm;imitation learning;field study;genetic assimilation;neural network	The traditional explanation of delayed maturation age, as part of an evolved life history, focuses on the increased costs of juvenile mortality due to early maturation. Prior quantitative models of these trade-offs, however, have addressed only morphological phenotypic traits, such as body size. We argue that the development of behavioral skills prior to reproductive maturity also constitutes an advantage of delayed maturation and thus should be included among the factors determining the trade-off for optimal age at maturity. Empirical support for this hypothesis from animal field studies is abundant. This paper provides further evidence drawn from simulation experiments. “Latent Energy Environments” (LEE) are a class of tightly controlled environments in which learning organisms are modeled by neural networks and evolved according to a type of genetic algorithm. An advantage of this artificial world is that it becomes possible to discount all non-behavioral costs of early maturity in order to focus on exclusively behavioral consequences. In spite of large selective costs imposed on parental fitness due to prolonged immaturity, the optimal age at maturity is shown to be significantly delayed when offspring are allowed to learn from their parents' behavior via imitation.	artificial neural network;capability maturity model;experiment;genetic algorithm;simulation	Federico Cecconi;Filippo Menczer;Richard K. Belew	1995	Adaptive Behaviour	10.1177/105971239500400103	genetic assimilation;psychology;genetic algorithm;developmental psychology;learning organization;computer science;artificial intelligence;machine learning;baldwin effect;communication;artificial neural network;field research;life history theory	AI	16.85907878363488	-22.343293491355134	86452
e36bbf193fb8a4bd83a913e0badbf8ba4ddc951d	quantitative testing of micro-cracks by the mfl technique based on ga-bp neural network		Magnetic flux leakage (MFL) testing is one of the traditional electromagnetic non-destructive test (NDT) techniques, and the focus of the MFL technique is to predict the sizes of defects, particularly micro-cracks. In this paper, parameters identification of artificial rectangular micro-cracks ranging between 0.1-0.3 mm by the MFL technique is investigated with a BP neural network improved by a genetic algorithm (GA-BP neural network). In order to predict the sizes of artificial rectangular micro-cracks ranging between 0.1-0.3 mm, a MFL system based on anisotropic magneto-resistive (AMR) sensors is developed, and parameters identification is implemented with a GABP neural network. The results show that parameters identification of artificial rectangular micro-cracks can be implemented effectively with the developed MFL system and a GA-BP neural network, which provides a basis for predicting the sizes of the natural cracks. [Received 19 July 2016; Accepted 16 November 2016]	artificial neural network;message format language;software release life cycle	Zhongchao Qiu;Ruilei Zhang;Weimin Zhang	2017	IJMR	10.1504/IJMR.2017.10005448	systems engineering;magnetic flux leakage;engineering;nondestructive testing;artificial neural network;electronic engineering;ranging	ML	12.954703117781778	-20.02479369397399	86507
3ba659c62e93021a54500fd20089fe4c0d2060fb	planning and acting under uncertainty: a new model for spoken dialogue systems	spoken dialogue system	Uncertainty plays a central role in spoken dialogue systems. Some stochastic models like the Markov decision process (MDP) are used to model the dialogue manager. But the partially observable system state and user intentions hinder the natural representation of the dialogue state. A MDP-based system degrades quickly when uncertainty about a user's intention increases. We propose a novel dialogue model based on the partially observable Markov decision process (POMDP). We use hidden system states and user intentions as the state set, parser results and low-level information as the observation set, and domain actions and dialogue repair actions as the action set. Here, low-level information is extracted from different input modalities, including speech, keyboard, mouse, etc., using Bayesian networks. Because of the limitation of the exact algorithms, we focus on heuristic approximation algorithms and their applicability in POMDP for dialogue management. We also propose two methods for grid point selection in grid-based algorithms.	approximation algorithm;bayesian network;bellman equation;computer keyboard;computer mouse;correctness (computer science);dialog system;heuristic;high- and low-level;machine learning;markov chain;optimization problem;partially observable markov decision process;partially observable system;simulation;spoken dialog systems;state space;stochastic process;usability testing	Bo Zhang;Qingsheng Cai;Jianfeng Mao;Baining Guo	2001			natural language processing;speech recognition;partially observable markov decision process;computer science;artificial intelligence;machine learning	AI	20.428208233510365	-15.584438687113808	86607
98ff34d9821ba23d7c7bec4d97c92ae988f9f9ee	integrating partial model knowledge in model free rl algorithms		In reinforcement learning an agent uses online feedback from the environment and prior knowledge in order to adaptively select an effective policy. Model free approaches address this task by directly mapping external and internal states to actions, while model based methods attempt to construct a model of the environment, followed by a selection of optimal actions based on that model. Given the complementary advantages of both approaches, we suggest a novel algorithm which combines them into a single algorithm, which switches between a model based and a model free mode, depending on the current environmental state and on the status of the agent’s knowledge. We prove that such an approach leads to improved performance whenever environmental knowledge is available, without compromising performance when such knowledge is absent. Numerical simulations demonstrate the effectiveness of the approach and suggest its efficacy in boosting policy gradient learning.	algorithm;gradient;network switch;numerical linear algebra;reinforcement learning;simulation	Aviv Tamar;Dotan Di Castro;Ron Meir	2011			artificial intelligence;machine learning;algorithm	ML	20.036353888773498	-19.068540377435397	86735
8074d851e9d755c6c03bf2b9b2f5ee83ecbb3a57	design of a traffic junction controller using classifier systems and fuzzy logic	systeme intelligent;systeme apprentissage;sistema inteligente;classifier system;trafic urbain;traffic control;urban traffic;fuzzy logic;trafico urbano;learning systems;intelligent system;sistema difuso;systeme flou;regulation trafic;regulacion trafico;fuzzy system	Traffic control in laige cities is a difficult and non-trivial optimization problem. Most of the automated urban traffic control systems aie based on deterministic algorithms and have a multi-level architecture; to achieve global optimality, hierarchical control algorithms are generally employed. However, these algorithms are often slow to react to varying conditions, and it has been recognized that incorporating computational intelligence into the lower levels can remove some burdens of algorithm calculation and decision making from higher levels. An alternative approach is to use a fully distributed architecture in which there is effectively only one (low) level of control. Such systems are aimed at increasing the response time of the controller and, again, these often incorporate computational intelligence techniques. This paper presents preliminary work into designing an intelligent local controller primarily for distributed traffic control systems. The idea is to use a classifier system with a fuzzy rule representation to determine useful junction control rules within the dynamic environment.	algorithm;computation;computational intelligence;control system;disk controller;distributed computing;fuzzy logic;fuzzy rule;learning classifier system;mathematical optimization;multi-agent system;optimization problem;problem solving;reinforcement learning;response time (technology);weatherstar	Y. J. Cao;N. Ireson;Larry Bull;R. Miles	1999		10.1007/3-540-48774-3_40	fuzzy logic;simulation;computer science;artificial intelligence;fuzzy control system	AI	15.852976074084703	-16.776537103959487	86755
062dfc0c50c854cf14ee2cb82bfb354ca4216d08	fuzzy cognitive maps learning through swarm intelligence	minimisation;cognitive map;minimization;swarm intelligence;carte cognitive;logique floue;logica difusa;minimizacion;intelligence artificielle;fonction objectif;fuzzy logic;objective function;commande industrielle;control proceso;mapa cognitiva;optimizacion enjambre particula;industrial control;process control;optimisation essaim particule;artificial intelligence;funcion objetivo;fuzzy cognitive map;inteligencia artificial;particle swarm optimization algorithm;commande processus	A technique for Fuzzy Cognitive Maps learning, which is based on the minimization of a properly defined objective function using the Particle Swarm Optimization algorithm, is presented. The workings of the technique are illustrated on an industrial process control problem. The obtained results support the claim that swarm intelligence algorithms can be a valuable tool for Fuzzy Cognitive Maps learning, alleviating deficiencies of Fuzzy Cognitive Maps, and controlling the system’s convergence.	algorithm;cognitive map;loss function;optimization problem;particle swarm optimization;swarm intelligence	Elpiniki I. Papageorgiou;Konstantinos E. Parsopoulos;Peter P. Groumpos;Michael N. Vrahatis	2004		10.1007/978-3-540-24844-6_49	fuzzy logic;minimisation;fuzzy cognitive map;cognitive map;swarm intelligence;computer science;artificial intelligence;machine learning;process control;algorithm	AI	15.759547816783307	-20.080935841948513	86966
ba17c681aa45efa7fbd421324a9e8a3a77be40d8	applying the policy gradient method to behavior learning in multiagent systems: the pursuit problem	policy gradient method;good policy;behavior determination method;minimization problem;pursuit problem;independent learning problem;multiagent system;objective function;probabilistic policy;action determination problem;reinforcement learning;gradient method	In the field of multiagent systems, some methods use the policy gradient method for behavior learning. In these methods, the learning problem in the multiagent system is reduced to each agent's independent learning problem by adopting an autonomous distributed behavior determination method. That is, a probabilistic policy that contains parameters is used as the policy of each agent, and the parameters are updated while calculating the maximum gradient so as to maximize the expectation value of the reward. In this paper, first, recognizing the action determination problem at each time step to be a minimization problem for some objective function, the Boltzmann distribution, in which this objective function is the energy function, was adopted as the probabilistic policy. Next, we showed that this objective function can be expressed by such terms as the value of the state, the state action rule, and the potential. Further, as a result of an experiment applying this method to a pursuit problem, good policy was obtained and this method was found to be flexible so that it can be adapted to use of heuristics and to modification of behavioral constraint and objective in the policy. © 2006 Wiley Periodicals, Inc. Syst Comp Jpn, 37(10): 101–109, 2006; Published online in Wiley InterScience (). DOI 10.1002&sol;scj.20248	agent-based model;gradient method;multi-agent system;pursuit-evasion	Seiji Ishihara;Harukazu Igarashi	2006	Systems and Computers in Japan	10.1002/scj.20248	mathematical optimization;computer science;gradient method;artificial intelligence;machine learning;operations research;reinforcement learning;q-learning	AI	20.126401055272606	-18.69800671283516	87088
528afa138e6bb98eb31dbfadb80494ab37942a3b	learning and evolving combat game controllers	evolutionary computation;games vectors sociology statistics radiation detectors learning algorithm design and analysis;learning;radiation detectors;software agents;learning systems;iterative methods;qa75 electronic computers computer science;vectors;control system synthesis;games;statistics;software agents computer games control system synthesis evolutionary computation iterative methods learning artificial intelligence learning systems;learning condition combat game controller evolution agent control mechanism design video game game design game agent agent controller hard coding learning technique hybrid algorithm werewolf weresarsa evolutionary technique reinforcement learning controller iterative process one on one combat simulator game mechanics arcade game;learning artificial intelligence;computer games;algorithm design and analysis;sociology	The design of the control mechanisms for the agents in modern video games is one of the main tasks involved in the game design process. Designing controllers grows in complexity as either the number of different game agents or the number of possible actions increase. An alternative mechanism to hard-coding agent controllers is the use of learning techniques. This paper introduces two new variants of a hybrid algorithm, named WEREWoLF and WERESARSA, that combine evolutionary techniques with reinforcement learning. Both new algorithms allow a group of different reinforcement learning controllers to be recombined in an iterative process that uses both evolution and learning. These new algorithms have been tested against different instances of predefined controllers on a one-on-one combat simulator, with underlying game mechanics similar to classic arcade games of this kind. The results have been compared with other reinforcement learning controllers, showing that WEREWoLF outperforms the other algorithms for a series of different learning conditions.	arcade game;computation;computational intelligence;control system;environment variable;evolutionary algorithm;game controller;game mechanics;hard coding;hybrid algorithm;iteration;machine learning;reinforcement learning;state space;two-hybrid screening	Luis Peña;Sascha Ossowski;José María Peña Sánchez;Simon M. Lucas	2012	2012 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2012.6374156	games;algorithm design;error-driven learning;simulation;computer science;artificial intelligence;software agent;machine learning;iterative method;learning classifier system;particle detector;evolutionary robotics;reinforcement learning;evolutionary computation	AI	24.231558930467962	-11.586991178246745	87221
69cef9140782855a3454630f1e980c57351929e1	learning what information to give in partially observed domains		In many robotic applications, an autonomous agent must act within and explore a partially observed environment that is unobserved by its human teammate. We consider such a setting in which the agent can, while acting, transmit declarative information to the human that helps them understand aspects of this unseen environment. In this work, we address the algorithmic question of how the agent should plan out what actions to take and what information to transmit. Naturally, one would expect the human to have preferences, which we model information-theoretically by scoring transmitted information based on the change it induces in weighted entropy of the human’s belief state. We formulate this setting as a belief MDP and give a tractable algorithm for solving it approximately. Then, we give an algorithm that allows the agent to learn the human’s preferences online, through exploration. We validate our approach experimentally in simulated discrete and continuous partially observed search-and-recover domains. Visit http://tinyurl.com/chitnis-corl-18 for a supplementary video.	algorithm;autonomous agent;autonomous robot;cobham's thesis;declarative programming;entropy (information theory);experiment;information gain in decision trees;kullback–leibler divergence;visit;weight function	Rohan Chitnis;Leslie Pack Kaelbling;Tomás Lozano-Pérez	2018			autonomous agent;computer science;machine learning;artificial intelligence	AI	20.364370788899528	-16.50094492969387	87290
3efd8510178f6b924794aa89a37800d7e6b808a3	efficient bayes-adaptive reinforcement learning using sample-based search	ucl;discovery;theses;conference proceedings;digital web resources;ucl discovery;open access;ucl library;book chapters;open access repository;ucl research	Bayesian model-based reinforcement learning is a formally elegant approach to learning optimal behaviour under model uncertainty. In this setting, a Bayes-optimal policy captures the ideal trade-off between exploration and exploitation. Unfortunately, finding Bayesoptimal policies is notoriously taxing due to the enormous search space in the augmented belief-state MDP. In this paper we exploit recent advances in sample-based planning, based on Monte-Carlo tree search, to introduce a tractable method for approximate Bayes-optimal planning. Unlike prior work in this area, we avoid expensive applications of Bayes rule within the search tree, by lazily sampling models from the current beliefs. Our approach outperformed prior Bayesian model-based RL algorithms by a significant margin on several well-known benchmark problems.	approximation algorithm;bayesian network;benchmark (computing);business architecture;cobham's thesis;lazy evaluation;monte carlo tree search;reinforcement learning;sampling (signal processing);search tree;simulation;state space	Arthur Guez;David Silver;Peter Dayan	2012			computer science;artificial intelligence;data science;machine learning;data mining;mathematics	AI	21.552903924044116	-16.647286876003328	87719
2228aee1cecdd0106dcee1e3174afa04923de1bf	on-line reinforcement learning using incremental kernel-based stochastic factorization		Kernel-based stochastic factorization (KBSF) is an algorithm for solving reinforcement learning tasks with continuous state spaces which builds a Markov decision process (MDP) based on a set of sample transitions. What sets KBSF apart from other kernel-based approaches is the fact that the size of its MDP is independent of the number of transitions, which makes it possible to control the trade-off between the quality of the resulting approximation and the associated computational cost. However, KBSF’s memory usage grows linearly with the number of transitions, precluding its application in scenarios where a large amount of data must be processed. In this paper we show that it is possible to construct KBSF’s MDP in a fully incremental way, thus freeing the space complexity of this algorithm from its dependence on the number of sample transitions. The incremental version of KBSF is able to process an arbitrary amount of data, which results in a model-based reinforcement learning algorithm that can be used to solve continuous MDPs in both off-line and on-line regimes. We present theoretical results showing that KBSF can approximate the value function that would be computed by conventional kernel-based learning with arbitrary precision. We empirically demonstrate the effectiveness of the proposed algorithm in the challenging threepole balancing task, in which the ability to process a large number of transitions is crucial for success.	algorithmic efficiency;approximation algorithm;arbitrary-precision arithmetic;bellman equation;dspace;kernel (operating system);load balancing (computing);markov chain;markov decision process;online and offline;online machine learning;rl (complexity);reinforcement learning	André da Motta Salles Barreto;Doina Precup;Joelle Pineau	2012			mathematical optimization;discrete mathematics;machine learning;mathematics;q-learning;statistics	ML	22.55930698269022	-19.517639804048226	87856
3a81cd40c916e686381074b13440993756bb0050	using an improved bemd method to analyse the characteristic scale of aeromagnetic data in the gejiu region of yunnan, china	metallogenic prediction;hht;intrinsic mode function;characteristic scale;empirical mode decomposition	The geological and metallogenic process is a typical non-stationary multifactor and multi-scale random process. Multiple measurement data assess the performance of the integrated process, and the combined data set is usually large and complex, among other characteristics. When different metallogenic prediction targets exist, the data must be decomposed on different scales in space. The study of the scale interval in which the object features are located can eliminate useless information and retrieve useful scale data that are needed for metallogenic prediction. Thus, the model that the specific deposit presents will be rapidly and accurately identified to enhance the efficiency of the prediction and analysis models. This paper employs an improved bidimensional empirical decomposition method to decompose aeromagnetic survey data and expresses and decomposes the spatial distribution of deposits with a mixed Gaussian model. By comparing the decomposition results on various sampling data scales with the distribution function for the deposit, the characteristic scale interval that contains the measurement information that exhibits the greatest similarity to the distribution of the deposits can be identified. This method was employed to analyse a Yunnan Gejiu tin–copper polymetallic deposit using aeromagnetic sampling data to calculate suitable decomposition-scale parameters. This approach provides valuable parameters for metallogenic prediction in other areas with aeromagnetic data.		Jie Zhao;Pengda Zhao;Yongqing Chen	2016	Computers & Geosciences	10.1016/j.cageo.2015.12.016	econometrics;hilbert–huang transform;data mining	HCI	24.097146234081407	-22.294235329228233	87904
0990a77bd8c8bb6079fc31686db4caa6f1d2f26a	a genetic algorithm with a multi-layered genotype-phenotype mapping	genetic algorithm	In this paper we investigate the introduction of a multiple-layer genotype-phenotype mapping to a Genetic Algorithm (GA) which attempts to mimic more closely, the effects of nature. The motivation for introducing multiple-layers into the genotype-phenotype mapping is to create a many-to-one genotype-phenotype mapping. The paper compares a traditional GA with a GA containing a multi-layered genotype-phenotype mapping using a number of well understood problems in an attempt to illustrate the potential benefits of including the multilayered mapping. Initial findings suggest that the multi-layered mapping between the genotype-phenotype used in conjunction with a binary representation outperforms existing traditional GA approaches on well known problems, while still allowing the use well understood genetic operators.	binary number;genetic algorithm;genetic operator;one-to-many (data model);software release life cycle	Seamus Hill;Colm O'Riordan	2010			meta-optimization;genetic representation;population-based incremental learning	AI	15.58280232458819	-23.7986746267103	87931
2b6296b7b5fbdee88fb753c7018fc114a54de166	agent-based coding ga and application to combat modeling and simulation	combat simulation;genetic operator;modeling and simulation;agent based;agent coding;simple genetic algorithm;genetic algorithm	Agent-based coding genetic algorithms (AGA) is proposed by combining agent basic theory and encoding methods with agent attribute because simple genetic algorithms (SGA) cannot solve complex problem with good result or without reasonable solution. AGA algorithm is based on individual structure description. In the paper, AGA environment structure and agent structure and genetic operator target function are defined, and verified AGA with a test function and applied it to model combat situation and implement its simulation.		Youming Yu;Guoying Zhang;Jiandong Liu	2007		10.1007/978-3-540-74581-5_21	simulation;computer science;artificial intelligence;algorithm	Robotics	23.050345074812334	-11.093866493772733	88032
c75fc21c6a9e575346be258970187953fcb8d8fa	on the impact of sensor maintenance policies on stochastic-based accuracy	data reconciliation;preventive maintenance;computer aided process engineering;instrumentation network;linear system;chemical engineering;value of accuracy	The concept of stochastic-based accuracy and its calculation procedure for the case of corrective maintenance in data reconciliation-based systems were recently presented [Bagajewicz, M. (2005b). On a new definition of a stochastic-based accuracy concept of data reconciliation-based estimators. In: Proceedings of the 15th European symposium on computer-aided process engineering; Bagajewicz, M., & Nguyen, D. (2008). Stochastic-based accuracy of data reconciliation estimators for linear systems. Computers and Chemical Engineering, 32(6), 1257–1269]. This paper discusses the effect of preventive maintenance policies in chemical plants on stochastic-based accuracy. We show and evaluate a few practical solutions to the problem. The extent to which an effective maintenance policy helps to improve accuracy is shown and the economic justification is provided. Two examples are provided. © 2009 Elsevier Ltd. All rights reserved.	linear system;rendering (computer graphics);sensor	DuyQuang Nguyen;Miguel J. Bagajewicz	2009	Computers & Chemical Engineering	10.1016/j.compchemeng.2009.05.006	reliability engineering;preventive maintenance;simulation;computer science;engineering;artificial intelligence;machine learning;data mining;control theory;linear system;statistics	Embedded	15.164551230052849	-14.565644793509183	88237
17f9df5c41dad28cbbb63f0dd9f8eb1ba84af9a9	graph coloring using fuzzy controlled neural networks	fuzzy controlled neural network;neural networks;graph coloring;neurofuzzy k coloring algorithms	-Graph coloring is an important example of a class of combinatorial optimization problems, which are characterized by their large number of interacting degrees of freedom. Neural Networks (NN) and especially a variation of the Hopfield one constitutes a very popular approach to the solution of problems in this class. The algorithm presented here is based on the idea of improving the convergence performance of such a NN, with the use of a simple fuzzy controller. The algorithm is explained and applied to two graphs of different size. The simulation results are presented and described in detail.	algorithm;combinatorial optimization;graph coloring;hopfield network;interaction;mathematical optimization;neural networks;simulation	Paraskevas Dalianis;Yiannis Kitsios;Spyros G. Tzafestas	1998	Intelligent Automation & Soft Computing	10.1080/10798587.1998.10750738	computer science;artificial intelligence;neuro-fuzzy;machine learning;graph coloring;artificial neural network	ML	21.403066650356497	-11.38482838454661	88243
e116e8c422ba6e4d1a05d621d8916a4e7d7ec2d0	benchmarking the psa-cma-es on the bbob noiseless testbed		We evaluate the CMA-ES with population size adaptation mechanism (PSA-CMA-ES) on the BBOB noiseless testbed. On one hand, the PSA-CMA-ES with a simple restart strategy shows performance competitive with the best 2009 portfolio on most well-structured multimodal functions. On the other hand, it is not effective on weakly-structured multimodal functions. Moreover, on most uni-modal functions, the scale-up of performance measure w.r.t. the dimension tends to be worse than the default CMA-ES, implying that the population size is adapted greater than needed on the unimodal functions. To improve performance on unimodal functions and weakly-structured multimodal functions, we additionally propose a restart strategy for the PSA-CMA-ES. The proposed strategy consists of three search regimes. The resulted restart strategy shows improved performance on unimodal functions and weakly-structured multimodal functions with a little compromise in the performance on well-structured multimodal functions. The overall performance is competitive to the BIPOP-CMA-ES.	cma-es;interlacing (bitmaps);modal logic;multimodal interaction;polar surface area;testbed	Kouhei Nishida;Youhei Akimoto	2018		10.1145/3205651.3208297	machine learning;computer science;benchmarking;mathematical optimization;artificial intelligence;cma-es;testbed;compromise;portfolio	NLP	23.624420578549536	-16.701764294291568	88251
9ed208d5996d619aae6e6657a3108ca069eb573b	wildland fire growth prediction method based on multiple overlapping solution	prediction method;high performance computing;forest fire prediction;forest fire;statistical system;high performance computer;parameter uncertainty;wildfire;wildland fire;dynamic behavior	Several Data-Driven Methods have been developed to try to solve the input parameters uncertainty when considering problems like Wildfires Prediction. In general, these methods operate over a large number of input parameters, and consider the most recent known behavior of wildfires. The purpose of the methods is to find the parameter set that best describes the real situation under consideration. Therefore, it is presumed that the same set of values could be used to predict the immediate future.#R##N##R##N#However, because this kind of prediction is based on a single set of parameters, for those parameters that present a dynamic behavior (e.g. wind direction and speed), the new optimized values are not adequate to make a prediction.#R##N##R##N#In this paper we propose an alternative method developed in a new branch of Data-Driven Prediction, which we called Multiple Overlapping Solution. This method combines statistical concepts and HPC (High Performance Computing) to obtain a higher quality prediction.		Germán Bianchini;Mónica Denham;Ana Carolina Castro Côrtes;Tomàs Margalef;Emilio Luque	2010	J. Comput. Science	10.1016/j.jocs.2010.07.005	supercomputer;parallel computing;simulation;computer science;operating system;operations research	Robotics	10.798909690634776	-15.736688171609595	88254
1a7fd7b566697c9b69e64b27b68db4384314d925	portfolio allocation for bayesian optimization	portfolio allocation;bayesian method;objective function;machine learning;science learning;gaussian process;multi armed bandit	Bayesian optimization with Gaussian processes has become an increasingly popular tool in the machine learning community. It is efficient and can be used when very little is known about the objective function, making it popular in expensive black-box optimization scenarios. It uses Bayesian methods to sample the objective efficiently using an acquisition function which incorporates the model’s estimate of the objective and the uncertainty at any given point. However, there are several different parameterized acquisition functions in the literature, and it is often unclear which one to use. Instead of using a single acquisition function, we adopt a portfolio of acquisition functions governed by an online multi-armed bandit strategy. We propose several portfolio strategies, the best of which we call GP-Hedge, and show that this method outperforms the best individual acquisition function. We also provide a theoretical bound on the algorithm’s performance.	algorithm;bayesian optimization;black box;computer performance;gaussian process;loss function;machine learning;mathematical optimization;microsoft office project portfolio server;monte carlo method;multi-armed bandit;optimization problem;program optimization	Matthew D. Hoffman;Eric Brochu;Nando de Freitas	2011			mathematical optimization;multi-armed bandit;bayesian probability;computer science;artificial intelligence;machine learning;gaussian process;mathematics;statistics	ML	24.24409537280198	-17.54559436429	88264
14ea1e061d2ac59f610be1e394906ff23927ef1e	monte carlo methods for the game kingdomino		Kingdomino is introduced as an interesting game for studying game playing: the game is multiplayer (4 independent players per game); it has a limited game depth (13 moves per player); and it has limited but not insignificant interaction among players. Several strategies based on locally greedy players, Monte Carlo Evaluation (MCE), and Monte Carlo Tree Search (MCTS) are presented with variants. We examine a variation of UCT called progressive win bias and a playout policy (Player-greedy) focused on selecting good moves for the player. A thorough evaluation is done showing how the strategies perform and how to choose parameters given specific time constraints. The evaluation shows that surprisingly MCE is stronger than MCTS for a game like Kingdomino. All experiments use a cloud-native design, with a game server in a Docker container, and agents communicating using a REST-style JSON protocol. This enables a multi-language approach to separating the game state, the strategy implementations, and the coordination layer.	docker;expectation–maximization algorithm;experiment;game server;graph (discrete mathematics);greedy algorithm;heuristic evaluation;interpreter (computing);json;magic number (programming);monte carlo method;monte carlo tree search;online and offline;playout;reinforcement learning;server (computing);tinymce;video game developer	Magnus Gedda;Mikael Z. Lagerkvist;Martin Butler	2018	2018 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2018.8490419	game theory;machine learning;implementation;computer science;artificial intelligence;monte carlo tree search;monte carlo method;json;server	AI	20.16274526774326	-17.050323495759724	88656
c3e89885f27a7ceaca972841ba15e3ee4fc9ec63	application of soft computing to predict blast-induced ground vibration	blast vibration;feed forward;conventional vibration predictors;soft computing;ppv;back propagation neural network;mean absolute error;andhra pradesh;coefficient of determination;back propagation;artificial neural network;coal mining	In this study, an attempt has been made to evaluate and predict the blast-induced ground vibration by incorporating explosive charge per delay and distance from the blast face to the monitoring point using artificial neural network (ANN) technique. A three-layer feed-forward back-propagation neural network with 2-5-1 architecture was trained and tested using 130 experimental and monitored blast records from the surface coal mines of Singareni Collieries Company Limited, Kothagudem, Andhra Pradesh, India. Twenty new blast data sets were used for the validation and comparison of the peak particle velocity (PPV) by ANN and conventional vibration predictors. Results were compared based on coefficient of determination and mean absolute error between monitored and predicted values of PPV.	approximation error;artificial neural network;blast;backpropagation;coefficient of determination;kerrison predictor;multitier architecture;overfitting;population;soft computing;software propagation;test set;velocity (software development)	Manoj Khandelwal;D. Lalit Kumar;Mohan Yellishetty	2009	Engineering with Computers	10.1007/s00366-009-0157-y	structural engineering;computer science;engineering;backpropagation;machine learning;coal mining;soft computing;forensic engineering;coefficient of determination;feed forward;artificial neural network;mean absolute error	ML	10.938665981646057	-19.47390675807406	88668
220b7f1b97dcf6f7a0648f31c78f05fed9f63272	statistical downscaling of watershed precipitation using gene expression programming (gep)	precipitation;gene expression programming;watershed;statistical downscaling;data driven	Investigation of hydrological impacts of climate change at the regional scale requires the use of a downscaling technique. Significant progress has already been made in the development of new statistical downscaling techniques. Statistical downscaling techniques involve the development of relationships between the large scale climatic parameters and local variables. When the local parameter is precipitation, these relationships are often very complex and may not be handled efficiently using linear regression. For this reason, a number of non-linear regression techniques and the use of Artificial Neural Networks (ANNs) was introduced. But due to the complexity and issues related to finding a global solution using ANN-based techniques, the Genetic Programming (GP) based techniques have surfaced as a potential better alternative. Compared to ANNs, GP based techniques can provide simpler and more efficient solutions but they have been rarely used for precipitation downscaling. This paper presents the results of statistical downscaling of precipitation data from the Clutha Watershed in New Zealand using a non-linear regression model developed by the authors using Gene Expression Programming (GEP), a variant of GP. The results show that GEP-based downscaling models can offer very simple and efficient solutions in the case of precipitation downscaling. 2011 Elsevier Ltd. All rights reserved.	artificial neural network;benchmark (computing);binary expression tree;crc-based framing;computer program;d-subminiature;downscaling;gene expression programming;genetic programming;kerrison predictor;local variable;neural networks;nonlinear system;numerical analysis;probability of precipitation;soft computing;symbolic regression;the daily wtf;time complexity;time series;watershed (image processing);xfig	Muhammad Z. Hashmi;Asaad Y. Shamseldin;Bruce W. Melville	2011	Environmental Modelling and Software	10.1016/j.envsoft.2011.07.007	meteorology;precipitation;watershed;hydrology;computer science;machine learning;data mining;gene expression programming	AI	10.286682084472998	-20.1819825322791	88713
1cbf11d46767823b035da6fa7c9c15f9ef006707	estimating reference evapotranspiration using data mining prediction models and feature selection		Since the irrigated agriculture is the most water-consuming sector in Brazil, it is a challenge to use water in a sustainable way. Evapotranspiration is the combination process of transferring moisture from the earth to the atmosphere by evaporation and transpiration from plants. By estimating this rate of loss, farmers can efficiently manage the crop water requirement and how much water is available. In this work, we propose prediction models, which can estimate the evapotranspiration based on climatic data collected by an automatic meteorological station. Climatic data are multidimensional, therefore by reducing the data dimensionality, then irrelevant, redundant or non-significant data can be removed from the results. In this way, we consider in the proposed solution to apply feature selection techniques before generating the prediction model. Thus, we can estimate the reference evapotranspiration according to the collected climatic variables. The experiments results concluded that models with high accuracy can be generated by M5’ algorithm with feature selection techniques.	algorithm;data mining;evaporation;experiment;feature selection;predictive modelling;random search;relevance	Hinessa Dantas Caminha;Ticiana L. Coelho da Silva;Atslands Rego da Rocha;Sílvio Carlos R. Vieira Lima	2017		10.5220/0006327202720279	machine learning;pattern recognition;data mining	ML	10.087904432326853	-19.285100921158854	88891
25a181533b65a559a0dd00bee85f62e50bc8c90f	pareto-based multi-output metamodeling with active learning	networks;technology and engineering;multiobjective optimization	When dealing with computationally expensive simulation codes or process measurement data, global surrogate modeling methods are firmly established as facilitators for design space exploration, sensitivity analysis, visualization and optimization. Popular surrogate model types include neural networks, support vector machines, and splines. In addition, the cost of each simulation mandates the use of active learning strategies where data points (simulations) are selected intelligently and incrementally. When applying surrogate models to multi-output systems, the hyperparameter optimization problem is typically formulated in a single objective way. The different response outputs are modeled separately by independent models. Instead, a multi-objective approach would benefit the domain expert by giving information about output correlation, facilitate the generation of diverse ensembles, and enable automatic model type selection for each output on the fly. This paper outlines a multi-objective approach to surrogate model generation including its application to two problems.	algorithmic efficiency;analysis of algorithms;artificial intelligence;artificial neural network;code;computation;data point;design space exploration;iteration;mathematical optimization;metamodeling;multi-objective optimization;network topology;on the fly;optimization problem;pareto efficiency;regular expression;simulation;spline (mathematics);subject-matter expert;support vector machine;surrogate model	Dirk Gorissen;Ivo Couckuyt;Eric Laermans;Tom Dhaene	2009		10.1007/978-3-642-03969-0_36	mathematical optimization;engineering;machine learning;surrogate model;data mining	AI	22.223540272634132	-23.16645030056319	88997
4f6ea4cfff066ac22c3fec5ebebd1c0a36c337ef	empirical evaluation of the cycle reservoir with regular jumps for time series forecasting: a comparison study		The cycle reservoir with regular jumps (CRJ) is a recent deterministic reservoir model with a very simple structure and highly constrained weight values. CRJ was proposed as an alternative to the randomized Echo State Network (ESN) reservoir. In this work, we empirically evaluate the performance of CRJ for time series forecasting problems, and compare it to ESN and Auto-Regressive with eXogenous inputs (NARX) models. The comparison is conducted based on seven time series datasets that represent different real world cases. Simulation results show that CRJ outperforms ESN and NARX models. The results also demonstrate the effectiveness of CRJ when applied for different time series forecasting problems	comparison sort;time series	Mais Haj Qasem;Hossam Faris;Ali Rodan;Alaa F. Sheta	2017		10.1007/978-3-319-57261-1_12	time series;econometrics;reservoir computing;nonlinear autoregressive exogenous model;recurrent neural network;computer science;echo state network	HCI	22.64976411353118	-19.874875910539547	89335
19dd71f6e8da4fba3502db27a37dfd6d408867f9	towards alarm flood reduction		Alarm systems play critically important role for the safe and efficient operation of modern industrial plants. However, most existing industrial alarm systems suffer from poor performance due to too many alarms needing to be handled by operators in control rooms. This paper proposes a method to reduce the alarm flood by detecting redundant alarms so that they can be filtered later before being transmitted to operators. To do that, an approach based on pattern mining is selected. That method is then applied on an actual dataset coming from a General Electric power plant. The results show that removing redundant alarms allow significantly reducing alarm flood, without loss of efficiency nor safety.	data mining;flood;sensor	Y. Laumonier;Jean-Marc Faure;Jean-Jacques Lesage;H. Sabot	2017	2017 22nd IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)	10.1109/ETFA.2017.8247625	real-time computing;flood myth;operator (computer programming);alarm;power station;engineering	EDA	12.055629978418226	-14.297376075320438	89395
959d7939e1e023b8210a29e13021e6318fed8174	clever pac-man		In this paper we show how combining fuzzy sets and reinforcement learning a winning agent can be created for the popular Pac-man game. Key elements are the classification of the state into a few fuzzy classes that makes the problem manageable. Pac-man policy is defined in terms of fuzzy actions that are defuzzified to produce the actual Pac-man move. A few heuristics allow making the Pac-man strategy very similar to the Human one. Ghosts agents, on their side, are endowed also with fuzzy behavior inspired by original design strategy. Performance of this Pac-man is shown to be superior to those of other AI-based Pac-man described in the literature.	artificial intelligence;defuzzification;fuzzy set;game engine;heuristic (computer science);inference engine;q-learning;reinforcement learning;state space;the mythical man-month	Nicole Alicia Rossini;Christian Quadri;N. Alberto Borghese	2011		10.3233/978-1-60750-972-1-11	artificial intelligence;computer science;machine learning	AI	21.43840068579308	-12.040061822224756	89517
b3cc396315eeaf43cafae4f69059fed22bc80845	using supervised training signals of observable state dynamics to speed-up and improve reinforcement learning	artificial neural networks data models training learning artificial intelligence heuristic algorithms supervised learning computational modeling;state space methods learning artificial intelligence neural nets;rl performance improvement supervised training signals observable state dynamics reinforcement learning value function learning continuous state spaces rl solution improvement feature reuse pretraining phase state change prediction state action pair model free q learning approach model based rl approach	A common complaint about reinforcement learning (RL) is that it is too slow to learn a value function which gives good performance. This issue is exacerbated in continuous state spaces. This paper presents a straight-forward approach to speeding-up and even improving RL solutions by reusing features learned during a pre-training phase prior to Q-learning. During pre-training, the agent is taught to predict state change given a state/action pair. The effect of pre-training is examined using the model-free Q-learning approach but could readily be applied to a number of RL approaches including model-based RL. The analysis of the results provides ample evidence that the features learned during pre-training is the reason behind the improved RL performance.	action potential;bellman equation;observable;q-learning;reinforcement learning;supervised learning	Daniel L. Elliott;Charles W. Anderson	2014	2014 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)	10.1109/ADPRL.2014.7010640	error-driven learning;computer science;artificial intelligence;machine learning;pattern recognition	ML	19.781653024154036	-21.682326401162786	89859
85d1b4fdf921e6bb05ec1b62b80b4732edcd4abd	strategy-planned q-learning approach for multi-robot task allocation	strategy planned distributed q learning;multi robot task allocation;robot kinematics resource management system performance multi robot systems equations learning artificial intelligence;q learning;multi agent q learning;strategy planned distributed q learning multi robot task allocation q learning multi agent q learning	In market-based task allocation mechanism, a robot bids for the announced task if it has the ability to perform the task and is not busy with another task. Sometimes a high-priority task may not be performed because all the robots are occupied with low-priority tasks. If the robots have an expectation about future task sequence based-on their past experiences, they may not bid for the low-priority tasks and wait for the high-priority tasks. In this study, a Q-learning-based approach is proposed to estimate the time-interval between high-priority tasks in a multi-robot multi-type task allocation problem. Depending on this estimate, robots decide to bid for a low-priority task or wait for a high-priority task. Application of traditional Q-learning for multi-robot systems is problematic due to non-stationary nature of working environment. In this paper, a new approach, Strategy-Planned Distributed Q-Learning algorithm which combines the advantages of centralized and distributed Q-learning approaches in literature is proposed. The effectiveness of the proposed algorithm is demonstrated by simulations on task allocation problem in a heterogeneous multi-robot system.	algorithm;algorithmic learning theory;centralized computing;experience;minimal recursion semantics;multi-agent system;q-learning;robot;simulation;stationary process;task manager	H. Hilal Ezercan Kayir;Osman Parlaktuna	2014	2014 11th International Conference on Informatics in Control, Automation and Robotics (ICINCO)	10.5220/0005052504100416	multi-task learning;simulation;computer science;artificial intelligence;machine learning;task analysis;q-learning	Robotics	19.397207557245885	-18.971102777995874	89977
5527816b32ac50097ce923241ff0fff692a83435	pruning algorithms for multi-model adversary search	opponent modeling;pruning;adversary search	Abstract   The multi-model search framework generalizes minimax to allow exploitation of recursive opponent models. In this work we consider adding pruning to the multi-model search. We prove a sufficient condition that enables pruning and describe two pruning algorithms,   αβ     ∗    and   αβ     1p      ∗   . We prove correctness and optimality of the algorithms and provide an experimental study of their pruning power. We show that for opponent models that are not radically different from the player's strategy, the pruning power of these algorithms is significant.	adversary (cryptography);pruning (morphology)	David Carmel;Shaul Markovitch	1998	Artif. Intell.	10.1016/S0004-3702(97)00074-X	null-move heuristic;computer science;theoretical computer science;pruning;machine learning;principal variation search;pattern recognition;killer heuristic;negamax	Theory	19.10169051069125	-16.413573208226726	90240
8d710bfb541fa847d6ccb4ebd8624c6d5a09b1fd	suggestion of probabilistic reward-independent knowledge for dynamic environment in reinforcement learning	probability;learning robots equations probabilistic logic mathematical model probability humans;learning;reinforcement learning;dynamic environment;maze problem probabilistic reward independent knowledge dynamic environment reinforcement learning learning technique actual robot environmental transition;robots;mathematical model;humans;probabilistic logic;learning artificial intelligence;robots learning artificial intelligence	Recently, reinforcement learning attracts attention as the learning technique that is often used on actual robot. As one of problems of reinforcement learning, it is difficult for reinforcement learning to cope with changing purpose, because reinforcement learning depend on reward. Until now, we suggested that we learned to use information does not depend on reward for solving the problem. This information is environmental transition. We defined this information as “Reward-Independent Knowledge (RIK)”. A robot gets RIK and predicts route from initial state to purpose state by using RIK. Reinforcement learning can cope with changing purpose by using RIK. However, it is difficult for RIK to cope with dynamic environment, because RIK is one to one correspondence between state-action pair and next state. Therefore, we suggest that RIK has multiple next state and probability of each possible next state. In this paper, we perform an experiment by simulation. We show that suggested knowledge copes with changing purpose and dynamic environment. In this experiment, we adopt a maze problem which a goal change and changing structure of maze. By this, we will show that suggested knowledge can cope with changing purpose and dynamic environment.	markov chain;q-learning;reinforcement learning;robot;simulation	Nodoka Shibuya;Yoshiki Miyazaki;Kentarou Kurashige	2011	2011 International Symposium on Micro-NanoMechatronics and Human Science	10.1109/MHS.2011.6102175	temporal difference learning;unsupervised learning;robot learning;error-driven learning;simulation;computer science;artificial intelligence;machine learning;learning classifier system;reinforcement learning	ML	20.192148528715023	-19.555594596566635	90640
1354101b9485773af56fd6f1022c2525e3c2d8db	overview: generalizations of multi-agent path finding to real-world scenarios		Multi-agent path finding (MAPF) is well-studied in artificial intelligence, robotics, theoretical computer science and operations research. We discuss issues that arise when generalizing MAPF methods to real-world scenarios and four research directions that address them. We emphasize the importance of addressing these issues as opposed to developing faster methods for the standard formulation of the MAPF problem.	artificial intelligence;operations research;pathfinding;robotics;theoretical computer science	Hang Ma;Sven Koenig;Nora Ayanian;Liron Cohen;Wolfgang Hönig;T. K. Satish Kumar;Tansel Uras;Hong Xu;Craig A. Tovey;Guni Sharon	2016	CoRR		computer science;machine learning;generalization;robotics;artificial intelligence	AI	18.915492674665323	-15.495658270723238	90643
d7b99164f1b199a34f2ade173cce5439156312e2	cma evolution strategy assisted by kriging model and approximate ranking	cma-es;kriging model;evolution control;approximate ranking procedure	The covariance matrix adaptation evolution strategy (CMA-ES) is a competitive evolutionary algorithm (EA) for difficult continuous optimization problems. However, expensive function evaluation of many real-world optimization problems poses a serious challenge to the application of CMA-ES (and other EAs) to these problems. To address this challenge, surrogate-assisted EAs has attracted increasing attention and become popular. In this paper, a new surrogate-assisted CMA-ES algorithm in which Kriging model is used to enhance CMA-ES via approximate ranking procedure is proposed. In the proposed algorithm, the approximate ranking procedure which estimates the rank of current population by using Kriging model and the exact fitness function together is adopted. In addition, the confidence interval method of training set selection is introduced for surrogate model construction. An initial sampling is performed before entering the evolution loop. In each iteration (generation), after the population sampling, the approximate ranking procedure is called instead of the original fitness evaluation, then, parameters of the sampling distribution are updated. This iterative search process continues until the target fitness is reached or the computational budget is exhausted. The proposed algorithm and confidence interval method of training set selection are analyzed through experimental study. The results demonstrate that the confidence interval method works well in Kriging-assisted CMA-ES, and that the proposed algorithm significantly reduces the number of function evaluations of CMA-ES and outperforms the Kriging-assisted CMA-ES using pre-selection and generation-based control on the tested problems.	approximation algorithm;cma-es;computation;computer-assisted translation;continuous optimization;evolution strategy;evolutionary algorithm;experiment;fitness function;iteration;kriging;mathematical optimization;sampling (signal processing);surrogate model;test set	Changwu Huang;Bouchaib Radi;Abdelkhalak El Hami;Hao Bai	2018	Applied Intelligence	10.1007/s10489-018-1193-3	continuous optimization;artificial intelligence;computer science;machine learning;cma-es;mathematical optimization;evolutionary algorithm;surrogate model;kriging;evolution strategy;ranking;fitness function	AI	24.3900854898871	-15.068044009184531	91184
8bdbe0566c44707b048f3f0458f647e8f1f60f5d	continuous action reinforcement learning automata - performance and convergence		Abstract: Reinforcement Learning is a powerful technique for agents to solve unknown Markovian Decision Processes, from the possibly delayed signals that they receive. Most RL work, in particular for multi-agent settings, assume a discrete action set. Learning automata are reinforcement learners, belonging to the category of policy iterators, that exhibit nice convergence properties in discrete action settings. Unfortunately, most applications assume continuous actions. A formulation for a continuous action reinforcement learning automaton already exists, but there is no convergence guarantee to optimal decisions. An improve of the performance of the method is proposed in this paper as well as the proof for the local convergence.	automata theory;automaton;converge;iterator;learning automata;local convergence;markov decision process;multi-agent system;nash equilibrium;numerical analysis;numerical integration;reinforcement learning	Abdel Rodríguez;Ricardo del Corazón Grau-Ábalo;Ann Nowé	2011			artificial intelligence;machine learning;distributed computing	ML	21.079910560158293	-18.628384507517477	91277
2253fe32bc3a216b6911bb1304b5237b86af6320	optimal inversion of open boundary conditions using bpnn data-driven model	optimal inversion;model combination;data driven model;tidal current;inverse method;open boundary conditions;artificial neural network;open boundary condition	One of major difficulties with numerical tidal models is accurate inversion of open boundary conditions. A data-driven model based on artificial neural network is developed to retrieve open boundary values. All training data are calculated by numerical tidal model, so the tidal physics are not disturbed. The basic idea is to find out the relationship between open boundary values and the values of interior tidal stations. Case testes are carried out with a real ocean bay named Liaodong Bay, part of the Bohai Sea, China. One of major tidal constituents, M2 is considered. Case studies show that the inversion method for open boundary conditions can make a more satisfactory inversion for a practical problem. Keywords-Data-driven model, Open boundary conditions, Optimal inversion, Tidal current.	artificial neural network;inverse transform sampling;numerical analysis	Mingchang Li;Guangyu Zhang;Bin Zhou;Shuxiu Liang;Zhaochen Sun	2009	2009 International Workshop on Intelligent Systems and Applications	10.1007/978-3-642-01507-6_1	computer science;machine learning;artificial neural network	Robotics	10.675414833089498	-19.721089388269498	91487
74f0142b4ef581101ac0d98cc941a5326b5dc3da	utility decomposition with deep corrections for scalable planning under uncertainty		Decomposition methods have been proposed in the past to approximate solutions to large sequential decision making problems. In contexts where an agent interacts with multiple entities, utility decomposition can be used where each individual entity is considered independently. The individual utility functions are then combined in real time to solve the global problem. Although these techniques can perform well empirically, they sacrifice optimality. This paper proposes an approach inspired from multi-fidelity optimization to learn a correction term with a neural network representation. Learning this correction can significantly improve performance. We demonstrate this approach on a pedestrian avoidance problem for autonomous driving. By leveraging strategies to avoid a single pedestrian, the decomposition method can scale to avoid multiple pedestrians. We verify empirically that the proposed correction method leads to a significant improvement over the decomposition method alone and outperforms a policy trained on the full scale problem without utility decomposition.	algorithmic efficiency;approximation algorithm;artificial neural network;autonomous car;bellman equation;entity;experiment;full scale;interaction;mathematical optimization;maxima and minima;online and offline;partially observable markov decision process;q-learning;solver;utility functions on indivisible goods	Maxime Bouton;Kyle Julian;Alireza Nakhaei;Kikuo Fujimura;Mykel J. Kochenderfer	2018			decomposition method (constraint satisfaction);computer science;machine learning;artificial intelligence;scalability;full scale;artificial neural network	AI	19.513734022795582	-16.039450415852237	91504
9bd4544f259d8ad8df105f125a4977cc45fdb702	variable metric reinforcement learning methods applied to the noisy mountain car problem	covariance matrix adaptation;reinforcement learning;evolution strategy	Two variable metric reinforcement learning methods, the natural actor-critic algorithm and the covariance matrix adaptation evolution strategy, are compared on a conceptual level and analysed experimentally on the mountain car benchmark task with and without noise.	algorithm;benchmark (computing);cma-es;evolution strategy;experiment;gradient;image noise;mountain car;phil bernstein;reinforcement learning	Verena Heidrich-Meisner;Christian Igel	2008		10.1007/978-3-540-89722-4_11	unsupervised learning;mathematical optimization;cma-es;artificial intelligence;machine learning;mathematics;learning classifier system	ML	20.967313782096117	-23.23548420098931	91523
597ebf76df37438d00a32446292cf02ba05bffe6	a reinforcement learning method for continuous domains using artificial hydrocarbon networks		Reinforcement learning in continuous states and actions has been limitedly studied in ocassions given difficulties in the determination of the transition function, lack of performance in continuous-to-discrete relaxation problems, among others. For instance, real-world problems, e.g. robotics, require these methods for learning complex tasks. Thus, in this paper, we propose a method for reinforcement learning with continuous states and actions using a model-based approach learned with artificial hydrocarbon networks (AHN). The proposed method considers modeling the dynamics of the continuous task with the supervised AHN method. Initial random rollouts and posterior data collection from policy evaluation improve the training of the AHN-based dynamics model. Preliminary results over the well-known mountain car task showed that artificial hydrocarbon networks can contribute to model-based approaches in continuous RL problems in both estimation efficiency (0.0012 in root mean squared-error) and sub-optimal policy convergence (reached in 357 steps), in just 5 trials over a parameter space $\theta \in \mathbb {R}^{86}$. Data from experimental results are available at: http://sites.google.com/up.edu.mx/reinforcement-learning/http://sites.google.com/up.edu.mx/reinforcement-learning/.	artificial neural network;linear programming relaxation;mountain car;rl (complexity);reinforcement learning;robot;robotics;whole earth 'lectronic link	Hiram Ponce;G. Galatola Teka;María de Lourdes Martínez-Villaseñor	2018	2018 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2018.8489088	task analysis;data collection;parameter space;machine learning;reinforcement learning;pattern recognition;artificial intelligence;convergence (routing);computer science;robotics	Robotics	22.520743115411527	-19.617097000178784	91566
9e689a47753d434bdabaa87f61f267fa86d843cf	incremental rbf network models for nonlinear approximation and classification	approximation algorithms;radial basis function networks;birds;particle swarm optimization;optimization radial basis function networks approximation methods predictive models birds approximation algorithms particle swarm optimization;classification multistep incremental model radial basis function network particle swarm oprimization nonlinear approximation;predictive models;optimization;approximation methods	In this paper a multistep learning algorithm for creating a novel incremental Radial Basis Function Network (RBFN) Model is presented and analyzed. The proposed incremental RBFN model has a composite structure that consists of one initial linear sub-model and a number of incremental sub-models, each of them being able to gradually decrease the overall approximation error of the model, until a desired accuracy is achieved. The identification of the entire incremental RBFN model is divided into a series of identifications steps applied to smaller size sub-models. At each identification step the Particle Swarm Optimization algorithm (PSO) with constraints is used to optimize the small number of parameters of the respective sub-model. A synthetic nonlinear test example is used in the paper to analyze the performance of the proposed multistep learning algorithm for the incremental RBFN model. A real wine quality data set is also used to illustrate the usage of the proposed incremental model for solving nonlinear classification problems. A brief comparison with the classical single RBFN model with large number of parameters is conducted in the paper and shows the merits of the incremental RBFN model in terms of efficiency and accuracy.	algorithm;approximation error;nonlinear system;particle swarm optimization;radial basis function network;synthetic intelligence	Gancho Vachkov;Valentin Stoyanov;Nikolinka Christova	2015	2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2015.7338093	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;predictive modelling;particle swarm optimization;approximation algorithm	Robotics	12.261729753502397	-21.7423983007995	91581
411cd6dc6e738ca35e944501a80dd88015f6eb2c	scaling up reinforcement learning through targeted exploration		Recent Reinforcement Learning (RL) algorithms, such as RMAX, make (with high probability) only a small number of poor decisions. In practice, these algorithms do not scale well as the number of states grows because the algorithms spend too much effort exploring. We introduce an RL algorithm State TArgeted R-MAX (STAR-MAX) that explores a subset of the state space, called the exploration envelope ξ. When ξ equals the total state space, STAR-MAX behaves identically to R-MAX. When ξ is a subset of the state space, to keep exploration within ξ, a recovery rule β is needed. We compared existing algorithms with our algorithm employing various exploration envelopes. With an appropriate choice of ξ, STAR-MAX scales far better than existing RL algorithms as the number of states increases. A possible drawback of our algorithm is its dependence on a good choice of ξ and β. However, we show that an effective recovery rule β can be learned on-line and ξ can be learned from demonstrations. We also find that even randomly sampled exploration envelopes can improve cumulative rewards compared to R-MAX. We expect these results to lead to more efficient methods for RL in large-scale problems.	algorithm;max;online and offline;randomness;reinforcement learning;state space;with high probability	Timothy Arthur Mann;Yoonsuck Choe	2011			simulation;artificial intelligence;machine learning;statistics	AI	22.379434411225144	-18.578605925780355	91699
742961299cfb3c786fc47acd5e7cbdd60b73b319	react: real-time algorithm configuration through tournaments	real time;algorithm configuration;combinatorial auctions	The success or failure of a solver is oftentimes closely tied to the proper configuration of the solver’s parameters. However, tuning such parameters by hand requires expert knowledge, is time consuming, and is error-prone. In recent years, automatic algorithm configuration tools have made significant advances and can nearly always find better parameters than those found through hand tuning. However, current approaches require significant offline computational resources, and follow a train-once methodology that is unable to later adapt to changes in the type of problem solved. To this end, this paper presents Real-time Algorithm Configuration through Tournaments (ReACT), a method that does not require any offline training to perform algorithm configuration. ReACT exploits the multi-core infrastructure available on most modern machines to create a system that continuously searches for improving parameterizations, while guaranteeing a particular level of performance. The experimental results show that, despite the simplicity of the approach, ReACT quickly finds a set of parameters that is better than the default parameters and is competitive with state-of-the-art algorithm configurators.	algorithm;cognitive dimensions of notations;computation;computational resource;computer;decision support system;experiment;intel core (microarchitecture);multi-core processor;newman's lemma;on the fly;online and offline;randomness;real-time transcription;sid meier's alpha centauri;solver;terminate (software)	Tadhg Fitzgerald;Yuri Malitsky;Barry O'Sullivan;Kevin Tierney	2014			simulation;computer science;distributed computing;algorithm	NLP	19.71833469366365	-11.353936138619622	92363
8ff3b7809e2bc3199d87debe67aaf2c464b83f0b	automatic synthesis of associative memories through genetic programming: a first co-evolutionary approach	genetic program;automatic generation;pattern recognition;associative memory	Associative Memories (AMs) are mathematical structures specially designed to associate input patterns with output patterns within a single stage. Since the last fifty years all reported AMs have been manually designed. The paper describes a Genetic Programming based methodology able to create a process for the automatic synthesis of AMs. It paves a new area of research that permits for the first time to propose new AMs for solving specific problems. In order to test our methodology we study the application of AMs for real value patterns. The results illustrate that it is possible to automatically generate AMs that achieve good recall performance for problems commonly used in pattern recognition research.		Juan Villegas-Cortez;Gustavo Olague;Carlos Avilés-Cruz;Juan Humberto Sossa Azuela;Andrés Ferreyra	2010		10.1007/978-3-642-12239-2_36	computer science;artificial intelligence;algorithm	AI	15.528763445339889	-22.571061634350933	92458
97ed604cc1acbced9102395e750e08e6872d09c1	over-subscription planning with numeric goals	soft constraints	By relaxing the hard-goal constraints from classical planning and associating them with reward values, over-subscription planning allows users to concentrate on presenting what they want and leaves the task of deciding the best goals to achieve to the planner. In this paper, we extend the over-subscription planning problem and its limited goal specification to allow numeric goals with continuous utility values and goals with mixed hard and soft constraints. Together they considerably extend the modeling power of goal specification and allow the user to express goal constraints that were not possible before. To handle these new goal constraints, we extend the Sapa planner’s planning graph based techniques to help it choose the best beneficial subset of goals that can include both hard or soft logical and numeric goals. We also provide empirical results in several benchmark domains to demonstrate that our technique helps return quality plans.	benchmark (computing);heuristic (computer science);partial-order planning	J. Benton;Minh Binh Do;Subbarao Kambhampati	2005			soft goal;simulation;computer science;management science	AI	18.782924892875076	-10.402910140246236	92637
b25545f444a89447b95f43def445da028accf244	multiscale finite impulse response modeling	ridge regression;cross correlation function;estimation method;principal component regression;multiscale representation;data filtering;finite impulse response model;input output;multiple scales;finite impulse response;regression;ordinary least square;empirical process;multiscale	Multiscale representation of data has shown great shrinkage abilities when used in data filtering. This paper shows that multiscale representation has similar advantages when used in empirical process modeling. One advantage is that it helps separate noise from important features, which helps improve the accuracy of estimated models. Another advantage is the fact that the number of significant cross-correlation function (CCF) coefficients relating the scaled signal approximations of the input and output data shrinks in half (i.e., decreases dyadically) at every subsequent coarser scale. This advantage is very important in FIR modeling because it means that smaller FIR models are needed at coarse scales. This advantage is exploited to develop a Multiscale Finite Impulse Response (MSFIR) modeling algorithm that helps deal with the collinearity problem often encountered in FIR models. The idea is to decompose the input–output data at multiple scales, and using the scaled signals at each scale, construct smaller FIR models with less collinearity, and then select among all scales the optimum estimated model. The developed MSFIR modeling algorithm is finally shown to outperform some of the existing FIR model estimation methods, such as Ordinary Least Squares (OLS) regression, Ridge Regression (RR), and Principal Component Regression (PCR). A key reason for the advantage of MSFIR over RR is that MSFIR shrinks the statistically insignificant CCF coefficients and noise wavelet coefficients (which are statistically zero) towards zero, while RR shrinks the FIR coefficients towards zero, while they are not. r 2005 Elsevier Ltd. All rights reserved.	algorithm;approximation;coefficient;cross-correlation;finite impulse response;input/output;microsoft customer care framework;ordinary least squares;principal component regression;process modeling;rapid refresh;wavelet	Mohamed N. Nounou	2006	Eng. Appl. of AI	10.1016/j.engappai.2005.09.007	principal component regression;input/output;mathematical optimization;regression;ordinary least squares;computer science;cross-correlation;machine learning;finite impulse response;empirical process;tikhonov regularization;statistics	AI	23.493743235116447	-23.60838782518184	92669
4c5ab7c983453f31c25bfc2069a40cb35c3e36f4	heuristics for numeric planning via subgoaling		The paper presents a new relaxation for hybrid planning with continuous numeric and propositional state variables based on subgoaling, generalising the subgoaling principle underlying the h and h heuristics to such problems. Our relaxation improves on existing interval-based relaxations by taking into account some negative interactions between effects when achieving a subgoal, resulting in better estimates. We show conditions on the planning model ensuring that this new relaxation leads to tractable, and, for the h version, admissible, heuristics. The new relaxation can be combined with the interval-based relaxation, to derive heuristics applicable to general numeric planning, while still providing more informed estimates for the subgoals that meet these conditions. Experiments show the effectiveness of its inadmissible and admissible version on satisficing and optimal numeric planning, respectively. As far as we know, this is the first admissible heuristic enabling cost-optimal numeric planning.	admissible heuristic;automated planning and scheduling;cobham's thesis;cost efficiency;directed acyclic graph;experiment;forward error correction;heuristic (computer science);interaction;lambda lifting;linear programming relaxation;the australian	Enrico Scala;Patrik Haslum;Sylvie Thiébaux	2016			mathematical optimization;combinatorics;discrete mathematics;mathematics	AI	20.843200346435477	-13.892631982676779	92820
422b4dd2990f91c5a19a376704ad0712bfd926d7	performance analysis of modeling framework for prediction in wind farms employing artificial neural networks	artificial neural networks;wind speed prediction;radial basis function network;back propagation network;wind farms	This paper introduces the concept and practice of Neural Network architectures for wind speed prediction in wind farms. The wind speed prediction method has been analyzed by using back propagation network and radial basis function network. Artificial neural network is used to develop suitable architecture for predicting wind speed in wind farms. The key of wind speed prediction is rational selection of forecasting model and effective optimization of model performance. To verify the effectiveness of neural network architecture, simulations were conducted on real time wind data with different heights of wind mill. Due to fluctuation and nonlinearity of wind speed, accurate wind speed prediction plays a major role in the operational control of wind farms. The key advantages of Radial Basis Function Network include higher accuracy, reduction of training time and minimal error. The experimental results show that compared to existing approaches, proposed radial basis function network performs better in terms of minimization of errors.	artificial neural network;profiling (computer programming)	K. Gnana Sheela;S. N. Deepa	2014	Soft Comput.	10.1007/s00500-013-1084-9	simulation;computer science;machine learning;radial basis function network;artificial neural network	ML	10.393990422848727	-18.997669528067895	93378
9df37b9c63fefa7343ab9d33986600b1c5cbfda8	an evolutionary approach to damage recovery of robot motion with muscles	metodo adaptativo;interdisciplinary applications;cybernetics;adaptability;muscle activity;adaptabilite;technology;adaptive control;endommagement;methode adaptative;robotics;alliage memoire forme;algoritmo genetico;deterioracion;adaptabilidad;shape memory alloy;vie artificielle;restauracion propiedad;science technology;adaptive method;algorithme genetique;robotica;artificial intelligence;algorithme evolutionniste;genetic algorithm;restauration propriete;algoritmo evolucionista;science fiction;robotique;computer science;evolutionary algorithm;damaging;aleacion memoria forma;artificial life;recovery properties	Robots that can recover from damage did not exist outside science fiction. Here we describe a self-adaptive snake robot that uses shape memory alloy as muscles and an evolutionary algorithm as a method of adaptive control. Experiments demonstrate that if some of the robot’s muscles are deliberately damaged, evolution is able to find new sequences of muscle activations that compensate, thus enabling the robot to recover its ability to move.	evolutionary algorithm;experiment;robot;sara (computer);testbed	Siavash Haroun Mahdavi;Peter J. Bentley	2003		10.1007/978-3-540-39432-7_27	adaptability;simulation;genetic algorithm;cybernetics;adaptive control;computer science;artificial intelligence;evolutionary algorithm;robotics;algorithm;artificial life;technology	Robotics	23.964813537679976	-12.976926606981824	93410
401da4c465a36b879b44071eb857b3e95ca52314	methodology for short-term performance prognostic of gas turbine using recurrent neural network	training;maintenance engineering;engines;predictive models;recurrent neural networks;turbines;data models	The issue of performance prognosis has been a topic of considerable interest in industrial condition monitoring applications. An innovative data driven prognostic methodology has been introduced in the current study by utilizing artificial recurrent neural network (RNN) approach which intends to improve the capability of equipment performance prediction within a specified short time bound even with limited available data. The ability of the approach is demonstrated using condition monitoring parameters collected from a 20 MW industrial gas turbine. An appropriate selection and fusion of measured variables has been employed to feed RNN with the most influential performance information. The analysis demonstrated that the developed prognostic approach has a great potential to provide an accurate short term forecast of equipment performance which can be invaluable for maintenance strategy and planning.	artificial neural network;microwave;performance prediction;random neural network;recurrent neural network	Masdi Muhammad;Tahan B. Mohammadreza;Z. A. Abdul Karim	2015	2015 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)	10.1109/IEEM.2015.7385755	maintenance engineering;data modeling;simulation;computer science;engineering;recurrent neural network;machine learning;data mining;predictive modelling	Robotics	10.792591219773003	-18.566453087242408	93558
ae754e955666132d9eab3a2dd8555672ba1c082c	heuristic search and computer game playing	heuristic search;computer game		a* search algorithm;pc game	Ken Chen	2000	Inf. Sci.	10.1016/S0020-0255(99)00092-4	combinatorial game theory;null-move heuristic;simulation;computer science;artificial intelligence;machine learning;monte carlo tree search;sequential game;similarity heuristic	AI	18.734832001334212	-17.762526771664586	93622
89a10321b67c8e6280e99a7ecde28781dd16c262	an intelligent platform for green forecasting optimization	forecasting;total green cost intelligent platform green forecasting optimization technical platform forecast algorithms green supply chain management gscm forecast efficiency grey genetic algorithm gga controller adaptive exponential grey models aegm mutation rate controller ga parameter optimization gm background value optimization optimal solution forecast precision inventory level;gm test beds green prediction model grey genetic algorithms;prediction algorithms;green prediction model;supply chain management genetic algorithms;predictive models forecasting accuracy integrated circuit modeling optimization algorithm design and analysis prediction algorithms;accuracy;integrated circuit modeling;gm test beds;predictive models;genetic algorithms;optimization;grey genetic algorithms;algorithm design and analysis;supply chain management	In this research, a technical platform has been proposed to modify the traditional algorithms by two new forecast algorithms for green supply chain management (GSCM). This platform also designed a dynamic predicting controller to improve the forecast efficiency of GSCM. This grey genetic algorithm (GGA) controller can optimize the parameters of adaptive exponential grey models (AEGM) to find the better solution for their prediction efficiencies. The contributions of this GGA are essentially from the two features: (1) the crossover and mutation rate controller of GA parameter optimization. (2) the variable controller of GM background value optimization. This research is simulated and verified by a GGA to reach an optimal solution by the 5 research cases and 2 industrial cases of GM experiments. The experimental results are also revealed that the better forecast precision will reduce the inventory level and total green cost of GSCM.	density functional theory;experiment;genetic algorithm;mathematical optimization;time complexity	Chen-Fang Tsai;Shin-Li Lu	2013	2013 IEEE 10th International Conference on e-Business Engineering	10.1109/ICEBE.2013.22	algorithm design;supply chain management;simulation;genetic algorithm;prediction;forecasting;computer science;accuracy and precision;predictive modelling;operations research;statistics	Robotics	10.836094362790107	-17.708386518393997	94182
f766135219cbe28f9e60a16ff1e9d65fae368b29	modeling and prediction of machining quality in cnc turning process using intelligent hybrid decision making tools	response surface methodology;cnc turning;surface roughness;particle swarm optimization;genetic algorithm;power consumption;taguchi method;neural network	Decision-making process in manufacturing environment is increasingly difficult due to the rapid changes in design and demand of quality products. To make decision making process (selection of machining parameters) online, effective and efficient artificial intelligent tools like neural networks are being attempted. This paper proposes the development of neural network models for prediction of machining parameters in CNC turning process. Experiments are designed based on Taguchi's Design of Experiments (DoE) and conducted with cutting speed, feed rate, depth of cut and nose radius as the process parameters and surface roughness and power consumption as objectives. Results from experiments are used to train the developed neuro based hybrid models. Among the developed models, performance of neural network model trained with particle swarm optimization model is superior in terms of computational speed and accuracy. Developed models are validated and reported. Signal-to-noise (S/N) ratios of responses are calculated to identify the influences of process parameters using analysis of variance (ANOVA) analysis. The developed model can be used in automotive industries for deciding the machining parameters to attain quality with minimum power consumption and hence maximum productivity.		C. Ahilan;Somasundaram Kumanan;N. Sivakumaran;John Edwin Raja Dhas	2013	Appl. Soft Comput.	10.1016/j.asoc.2012.03.071	response surface methodology;taguchi methods;genetic algorithm;surface roughness;computer science;machine learning;particle swarm optimization;artificial neural network	Robotics	12.703792772902615	-19.147928267246197	94221
1b3a95b14c76df86d8fef35623b042118b1a48c9	evolutionary statistics: using a genetic algorithm and model reduction to isolate alternate statistical hypotheses of experimental data	genetic algorithm		genetic algorithm	David Rogers	1997			genetic algorithm;experimental data;machine learning;statistics;artificial intelligence;mathematics	ML	12.724006938261608	-23.3880373234457	94242
54268f3c323e0d609dc110e1d698cbd065ceb3c2	multiple linear regression modelling of on-farm direct water and electricity consumption on pasture based dairy farms		Abstract An analysis into the impact of milk production, stock numbers, infrastructural equipment, managerial procedures and environmental conditions on dairy farm electricity and water consumption using multiple linear regression (MLR) modelling was carried out. Electricity and water consumption data were attained through the utilisation of a remote monitoring system installed on a study sample of 58 pasture-based, Irish commercial dairy farms between 2014 and 2016. In total, 15 and 20 dairy farm variables were analysed on their ability to predict monthly electricity and water consumption, respectively. The subsets of variables that had the greatest prediction accuracy on unseen electricity and water consumption data were selected by applying a univariate variable selection technique, all subsets regression and 10-fold cross validation. Overall, electricity consumption was more accurately predicted than water consumption with relative prediction error values of 26% and 49% for electricity and water, respectively. Milk production and the total number of dairy cows had the largest impact on electricity consumption while milk production, automatic parlour washing and whether winter building troughs were reported to be leaking had the largest impact on water consumption. A standardised regression analysis found that utilising ground water for pre-cooling milk increased electricity consumption by 0.11 standard deviations, while increasing water consumption by 0.06 standard deviations when recycled in an open loop system. Milk production had a large influence on model overprediction with large negative correlations of −0.90 and −0.82 between milk production and mean percentage error for electricity and water prediction, respectively. This suggested that overprediction was inflated when milk production was low and vice versa. Governing bodies, farmers and/or policy makers may use the developed MLR models to calculate the impact of Irish dairy farming on natural resources or as decision support tools to calculate potential impacts of on-farm mitigation practises.		P. Shine;T. Scully;John Upton;Michael D. Murphy	2018	Computers and Electronics in Agriculture	10.1016/j.compag.2018.02.020	control engineering;water resource management;regression analysis;pasture;cross-validation;mean squared prediction error;electricity;mean percentage error;engineering;linear regression;dairy farming	AI	11.319365282611981	-18.352593890705442	94361
de217c7e8826e47854c5cc7cfa6bfcae7a606a0b	a fuzzy rule-based algorithm to improve the performance of statistical process control in quality systems	statistical process control;fuzzy rule base;quality system	Statistical process control (SPC) is an important part of quality control systems in industrial applications. It is widely used to monitor parameters in production processes and detect abnormal parameter values that indicate a fault in the process. Measurements of controlled parameters commonly exhibit random variations that arise from either environmental changes or random variations in the measuring instrument itself. SPC uses control charts to determine whether variations in measurements are due only to random changes within the range expected or whether they indicate a real process fault. Inevitably, traditional control charts sometimes generate Type I errors (false alarms), indicating a process fault when none actually exists, and causing an unnecessary stoppage of the plant. In other cases, Type II errors are generated, where real faults are either not detected at all, or are detected only after some time delay during which product quality has been impaired. This paper describes an investigation into the use of fuzzy logic to modify SPC rules, with the aim of reducing the generation of false alarms and also improving the detection and detection-speed of real faults.	algorithm;fuzzy rule;logic programming	Shendy M. El-Shal;Alan S. Morris	2000	Journal of Intelligent and Fuzzy Systems		real-time computing;quality management system;statistical process control;statistics	Robotics	14.378872251145783	-14.25131993538667	94735
a012eed480c457ab69be23a7239b468fd3f7701e	anfis-based prediction of the compressive strength of geopolymers with seeded fly ash and rice husk–bark ash		In the present work, compressive strength of geopolymers made from seeded fly ash and rice husk–bark ash has been predicted by adaptive network-based fuzzy inference systems (ANFIS). Different specimens, made from a mixture of fly ash and rice husk–bark ash in fine and coarse forms and a mixture of water glass and NaOH mixture as alkali activator, were subjected to compressive strength tests at 7 and 28 days of curing. The curing regimes were different: one set of the specimens were cured in water at room temperature until 7 and 28 days and the other sets were oven-cured for 36 h at the range of 40–90°C and then cured at room temperature until 7 and 28 days. A model based on ANFIS for predicting the compressive strength of the specimens has been presented. To build the model, training and testing using experimental results from 120 specimens were conducted. The used data as the inputs of ANFIS models are arranged in a format of six parameters that cover the percentage of fine fly ash in the ashes mixture, the percentage of coarse fly ash in the ashes mixture, the percentage of fine rice husk–bark ash in the ashes mixture, the percentage of coarse rice husk–bark ash in the ashes mixture, the temperature of curing, and the time of water curing. According to these input parameters in the ANFIS models, the compressive strength of each specimen was predicted. The training and testing results in ANFIS models showed a strong potential for predicting the compressive strength of the geopolymeric specimens.	adaptive neuro fuzzy inference system;biological specimen;fuzzy logic	Ali Nazari;Gholamreza Khalaj;Shadi Riahi	2011	Neural Computing and Applications	10.1007/s00521-011-0751-y	mathematical optimization;compressive strength;adaptive neuro fuzzy inference system;geopolymer;fly ash;mathematics;husk;composite material	NLP	12.210908964537111	-19.729141417035642	94947
17545ee99effb973e5d0e20699a3e6fb6b74917d	system dynamic reliability assessment and failure prognostics	dependent degradation;ae;failure prognostics;mc simulation;reliability assessment;rul;recursive bayesian method;pdf;monte carlo simulation;multiple component;pdmp	Traditionally, equipment reliability assessment is based on failure data from a population of similar equipment, somewhat giving an average description of the reliability performance of an equipment, not capturing the specificity of the individual equipment. Monitored degradation data of the equipment can be used to specify its behavior, rendering dynamic the reliability assessment and the failure prognostics of the equipment, as shown in some recent literature. In this paper, dynamic reliability assessment and failure prognostics with noisy monitored data are developed for a system composed of dependent components. Parallel Monte Carlo simulation and recursive Bayesian method are integrated in the proposed modelling framework to assess the reliability and to predict the Remaining Useful Life (RUL) of the system. The main contribution of the paper is to propose a framework to estimate the degradation state of a system composed of dependent degradation components whose conditions are monitored (even without knowing the initial system degradation state) and to dynamically assess the system risk and RUL. As case study, a subsystem of the residual heat removal system of a nuclear power plant is considered. The results shows the significance of the proposed method for tailored reliability assessment and failure prognostics.	c date and time functions;discretization;elegant degradation;local interconnect network;monte carlo method;pseudocode;recursion;recursion (computer science);sensitivity and specificity;simulation;stochastic process;system time	Jie Liu;Enrico Zio	2017	Rel. Eng. & Sys. Safety	10.1016/j.ress.2016.12.003	reliability engineering;engineering;mathematics;forensic engineering;statistics;prognostics;monte carlo method	Robotics	14.689016805318195	-14.910596484207833	94995
3b687253376f07e27a42f4a46ad2d3190a5698b5	generalized compatible function approximation for policy gradient search		Reinforcement learning aims at solving stochastic sequential decision making problems through direct trial-and-error interactions with the learning environment. In this paper, we will develop generalized compatible features to approximate value functions for reliable Reinforcement Learning. Further guided by an Actor-Critic Reinforcement Learning paradigm, we will also develop a generalized updating rule for policy gradient search in order to constantly improve learning performance. Our new updating rule has been examined on several benchmark learning problems. The experimental results on two problems will be reported specifically in this paper. Our results show that, under suitable generalization of the updating rule, the learning performance and reliability can be noticeably improved.	approximation;gradient	Yiming Peng;Gang Chen;Mengjie Zhang;Shaoning Pang	2016		10.1007/978-3-319-46687-3_68	gradient descent;mathematical optimization;mathematical analysis;mathematics;mathematical economics	ML	20.509045714309533	-19.901647081793573	95049
7b99c40ffc65eb15bf179738e99a7efc4121209f	situated planning for execution under temporal constraints		One of the original motivations for domain-independent planning was to generate plans that would then be executed in the environment. However, most existing planners ignore the passage of time during planning. While this can work well when absolute time does not play a role, this approach can lead to plans failing when there are external timing constraints, such as deadlines. In this paper, we describe a new approach for time-sensitive temporal planning. Our planner is aware of the fact that plan execution will start only once planning finishes, and incorporates this information into its decision making, in order to focus the search on branches that are more likely to lead to plans that will be feasible when the planner finishes.	advance directive - proxy;algorithm;automated planning and scheduling;baseline (configuration management);decision making;estimated;european union;execution;failure;heuristic;heuristics;lexm gene;mathematical optimization;mathematics;motivation;node - plant part;optimization problem;partial-order planning;proxy server;run time (program lifecycle phase);search tree;situated;slack variable;streptonigrin;super-twisted nematic display;tree (data structure)	Michael Cashmore;Andrew Coles;Bence Cserna	2018			planner;operations research;mathematical optimization;computer science;absolute time and space;situated	AI	17.973443941490945	-10.56666937162277	95073
49e353073c035dfa11e7a4dd1edac961517d90f2	design of artificial neural network models optimized with sequential quadratic programming to study the dynamics of nonlinear troesch’s problem arising in plasma physics		In this study, a computational intelligence technique based on three different designs of artificial neural networks (ANNs) is presented to solve the nonlinear Troesch’s boundary value problem arising in plasma physics. The structure of three ANN models is formulated by incorporating log-sigmoid (ANN-LS), radial-base (ANN-RB) and tan-sigmoid (ANN-TS) kernel functions in the hidden layers. Mathematical modeling of the problem is constructed for all three feed-forward ANN models by defining an error function in an unsupervised manner. Sequential quadratic programming method is employed for the learning of unknown parameters for all three ANN-LS, ANN-RB and ANN-TS schemes. The proposed models are applied to solve variants of Troesch’s problems by taking the small and large values of critical parameter in the system. A comparison of the proposed solution obtained from these models has been made with the standard numerical results of Adams method. The accuracy and convergence of the proposed models are investigated through results of statistical analysis in terms of performance indices based on the mean absolute deviation, root-mean-square error and variance account for.	artificial neural network;complexity index;computational complexity theory;computational intelligence;fireworks algorithm;iteration;least squares;linear multistep method;local search (optimization);mathematical model;mathematical optimization;mexican hat wavelet;nonlinear system;numerical analysis;os-tan;particle swarm optimization;plasma active;radial (radio);sequential quadratic programming;sigmoid function;significant figures;simulation;unsupervised learning	Raja Muhammad Asif Zahoor;Fiaz Hussain Shah;Muhammad Tariq;Iftikhar Ahmad;Siraj-ul-Islam Ahmad	2016	Neural Computing and Applications	10.1007/s00521-016-2530-2	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;statistics	ML	13.127596431168302	-21.60363050169473	95190
4e868a7db848262dccfdc131b6ba69cc13291afb	a comparison between deep q-networks and deep symbolic reinforcement learning		Deep Reinforcement Learning (DRL) has had several breakthroughs, from helicopter controlling and Atari games to the Alpha-Go success. Despite their success, DRL still lacks several important features of human intelligence, such as transfer learning, planning and interpretability. We compare two DRL approaches at learning and generalization: Deep Q-Networks and Deep Symbolic Reinforcement Learning. We implement simplified versions of these algorithms and propose two simple problems. Results indicate that although the symbolic approach is promising at generalizing and faster learning in one of the problems, it can fail systematically in the other, very similar problem.	algorithm;atari;automated planning and scheduling;driven right leg circuit;reinforcement learning	Aimore R. R. Dutra;Artur S. d'Avila Garcez	2017			machine learning;artificial intelligence;reinforcement learning;computer science	ML	19.283904580857797	-19.8202055928243	95204
8670abb386c018e338b332689b8fd64227c2eaba	d++: structural credit assignment in tightly coupled multiagent domains	robot sensing systems;neural networks;reinforcement learning;training;robotics;learning based control;multi robot systems;thesis dissertation;multiagent systems;environmental monitoring;robot kinematics	Autonomous multi-robot teams can be used in complex coordinated exploration tasks to improve exploration performance in terms of both speed and effectiveness. However, use of multi-robot systems presents additional challenges. Specifically, in domains where the robots' actions are tightly coupled, coordinating multiple robots to achieve cooperative behavior at the group level is difficult. In this paper, we demonstrate that reward shaping can greatly benefit learning in multi-robot exploration tasks. We propose a novel reward framework based on the idea of counterfactuals to tackle the coordination problem in tightly coupled domains. We show that the proposed algorithm provides superior performance (166% performance improvement and a quadruple convergence speed up) compared to policies learned using either the global reward or the difference reward [1].	agent-based model;algorithm;autonomous robot;counterfactual conditional;noise shaping;quadruple-precision floating-point format;speedup	Aida Rahmattalabi;Jen Jen Chung;Mitchell K. Colby;Kagan Tumer	2016	2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2016.7759651	simulation;computer science;engineering;artificial intelligence;machine learning;control theory;environmental monitoring;robotics;reinforcement learning;robot kinematics	Robotics	18.668729608372924	-19.43557964533827	95382
892dd68f43a3e2c72ea83733fe20b10190be3658	active incremental learning of robot movement primitives		Robots that can learn over time by interacting with non-technical users must be capable of acquiring new motor skills, incrementally. The problem then is deciding when to teach the robot a new skill or when to rely on the robot generalizing its actions. This decision can be made by the robot if it is provided with means to quantify the suitability of its own skill given an unseen task. To this end, we present an algorithm that allows a robot to make active requests to incrementally learn movement primitives. A movement primitive is learned on a trajectory output by a Gaussian Process. The latter is used as a library of demonstrations that can be extrapolated with confidence margins. This combination not only allows the robot to generalize using as few as a single demonstration but more importantly, to indicate when such generalization can be executed with confidence or not. In experiments, a real robot arm indicates to the user which demonstrations should be provided to increase its repertoire of reaching skills. Experiments will also show that the robot becomes confident in reaching objects for whose demonstrations were never provided, by incrementally learning from the neighboring demonstrations.	algorithm;encode;experiment;extrapolation;gaussian process;interaction;robot;robotic arm;test set	Guilherme Maeda;Marco Ewerton;Takayuki Osa;Baptiste Busch;Jan Peters	2017			repertoire;machine learning;motor skill;active learning;robot;robotic arm;gaussian process;generalization;computer science;trajectory;artificial intelligence	Robotics	20.35327889236456	-20.777484030590628	95407
333126b154ac00565a0a2994f151c6752a983062	an evolutionary algorithm that constructs recurrent neural networks	topology;optimisation;methode empirique;neural networks;metodo empirico;gnarl evolutionary algorithm recurrent neural networks genetic algorithms evolutionary programming population based search methods;topologie;empirical method;evolutionary programming;search method;algoritmo genetico;reseaux neuronaux;recurrent network;algorithme genetique;population dynamics;genetic algorithm;recurrent neural nets;optimisation recurrent neural nets;recurrent neural network;methode induction;evolutionary algorithm;network structure;dynamique population;evolutionary computation recurrent neural networks network topology computer architecture genetic algorithms genetic programming search methods induction generators ash artificial intelligence;metodo induccion;evolutionary computing;induction method	Standard methods for simultaneously inducing the structure and weights of recurrent neural networks limit every task to an assumed class of architectures. Such a simplification is necessary since the interactions between network structure and function are not well understood. Evolutionary computations, which include genetic algorithms and evolutionary programming, are population-based search methods that have shown promise in many similarly complex tasks. This paper argues that genetic algorithms are inappropriate for network acquisition and describes an evolutionary program, called GNARL, that simultaneously acquires both the structure and weights for recurrent networks. GNARL's empirical acquisition method allows for the emergence of complex behaviors and topologies that are potentially excluded by the artificial architectural constraints imposed in standard network induction methods.	architecture as topic;artificial neural network;assumed;behavior;computation;emergence;evolutionary algorithm;evolutionary programming;exclusion;gnat;genetic algorithm;interaction;neural network simulation;recurrent neural network;text simplification;weight	Peter J. Angeline;Gregory M. Saunders;Jordan B. Pollack	1994	IEEE transactions on neural networks	10.1109/72.265960	evolutionary programming;evolutionary music;genetic algorithm;computer science;artificial intelligence;recurrent neural network;machine learning;evolutionary algorithm;evolutionary acquisition of neural topologies;population dynamics;empirical research;artificial neural network;algorithm	ML	15.642265640288052	-23.691299641725514	95419
c176ec48d2b9b0af30e69a3ccd2c66fafc410ab6	study of hybrid strategy for ambulatory ecg waveform clustering	ambulatory electrocardiogram;artificial neural networks;clustering algorithm;k-means;simulated annealing algorithm;k means	A hybrid strategy has been proposed to reduce the wrong clustering on Ambulatory ECG (electrocardiogram). Since Ambulatory ECG is usually composed by 24 hours data, the number of individual ECG waveform can reach to 100,000, the request for accurate clustering result is highly required. The proposed strategy adopted some intelligent algorithms to solve the above problem. It clusters ECG waveform sample (selected from Ambulatory ECG) synchronously by Max-Min distance clustering algorithm, K-means algorithm and Simulated annealing algorithm first. And then, it adopted all three outputs from the above three algorithms as input on Back Propagation Artificial Neural Network (BP ANN). In the end, we got more accurate clustering result from the output of ANN. For testing the results, data of MIT/BIH arrhythmia database were used for experiments. After the controlled trial on MIT/BIH data, it can be safely concluded that the clustering result achieved by improved strategy can got more accurate than that by the traditional clustering algorithm. An average accuracy ratio is about 94.6%, 1.6% higher than k-means algorithm averagely and 1.3% higher than Simulated Annealing algorithm averagely.		Gang Zheng;Tian Yu	2011	JSW		simulated annealing;computer science;artificial intelligence;machine learning;data mining;cluster analysis;artificial neural network;k-means clustering	AI	12.241138790324712	-23.754475703239866	95520
ce90afb4be3be88f8a98c97caa8f66d9ba57f987	a new evolutionary method for time series forecasting	forecasting;time series forecasting;statistical test;time series;phase space;time delay;hybrid model;genetic algorithm;genetic algorithms;time series prediction;artificial neural network;neural network	This paper presents a new method --- the Time-delay Added Evolutionary Forecasting (TAEF) method --- for time series prediction which performs an evolutionary search of the minimum necessary number of dimensions embedded in the problem for determining the characteristic phase space of the time series. The method proposed is inspired in F. Takens theorem and consists of an intelligent hybrid model composed of an artificial neural network (ANN) combined with a modified genetic algorithm (GA). Initially, the TAEF method finds the most fitted predictor model for representing the series and then performs a behavioral statistical test in order to adjust time phase distortions.	artificial neural network;distortion;embedded system;genetic algorithm;kerrison predictor;software release life cycle;time series	Tiago Alessandro Espínola Ferreira;Germano C. Vasconcelos;Paulo J. L. Adeodato	2005		10.1145/1068009.1068384	econometrics;computer science;artificial intelligence;machine learning;time series;artificial neural network;statistics	AI	12.549710891989069	-23.18475143611515	95537
27fe475a77ed501635ee85cf9acc3b482f7108f3	action translation in extensive-form games with large action spaces: axioms, paradoxes, and the pseudo-harmonic mapping	suboptimal action;pseudo-harmonic mapping;optimal action;large action space;action abstraction;action translation mapping;prior mapping;prior action translation mapping;new mapping;significant abstraction;low exploitability;extensive-form game	When solving extensive-form games with large action spaces, typically significant abstraction is needed to make the problem manageable from a modeling or computational perspective. When this occurs, a procedure is needed to interpret actions of the opponent that fall outside of our abstraction (by mapping them to actions in our abstraction). This is called an action translation mapping. Prior action translation mappings have been based on heuristics without theoretical justification. We show that the prior mappings are highly exploitable and that most of them violate certain natural desiderata. We present a new mapping that satisfies these desiderata and has significantly lower exploitability than the prior mappings. Furthermore, we observe that the cost of this worst-case performance benefit (low exploitability) is not high in practice; our mapping performs competitively with the prior mappings against no-limit Texas Hold’em agents submitted to the 2012 Annual Computer Poker Competition. We also observe several paradoxes that can arise when performing action abstraction and translation; for example, we show that it is possible to improve performance by including suboptimal actions in our abstraction and excluding optimal actions.	best, worst and average case;heuristic (computer science);spaces;statistical machine translation	Sam Ganzfried;Tuomas Sandholm	2013			artificial intelligence;machine learning;algorithm	AI	19.968791496500735	-14.006653214201783	95795
003108431c632b7bd79b07da57256d25db5d7088	modeling research on the sorption kinetics of pentachlorophenol (pcp) to sediments based on neural networks and neuro-fuzzy systems	lake sediment;sediments;pentachlorophenol pcp;pentachlorophenol;second law;radial basis function neural network;neuro fuzzy system;adaptive neuro fuzzy inference system anfis;radial basis function neural network rbfn;kinetics;adaptive neuro fuzzy inference system;neural network;sorption kinetics	The sorption kinetics of pentachlorophenol (PCP) to sediments (from 8 different lakes, south of China) was studied in batch experiments. The comparison of a radial basis function neural network (RBFN) and an adaptive neuro-fuzzy inference system (ANFIS) applied for modeling the sorption behaviors was presented. Although the physical and chemical characteristics were different, the modeling results showed that the sorption behaviors of 8 different sediments were similar. Both RBFN and ANFIS could model the sorption behaviors and make predictions in high accuracy, which illustrated that the two models reflected the internal principle of the sorption better than the traditional model Fick’s second law (FSL). Especially, RBFN held the promise of being able to work under noisy conditions to obtain high accuracy. In conclusion, RBFN was the valid options for modeling the sorption kinetics of PCP to the lake sediments. The individual changes of the three different inputs (the concentration of PCP in the aqueous phase, the reversible fraction and the irreversible fraction) affected the modeling results to the similar extent, from which we could infer that the sorption kinetics of PCP to these sediments were affected by all the three factors rather than only by the concentration of PCP in the aqueous phase. r 2006 Elsevier Ltd. All rights reserved.	adaptive neuro fuzzy inference system;artificial neural network;experiment;fmrib software library (fsl);fuzzy control system;inference engine;kinetics internet protocol;neuro-fuzzy;radial (radio);radial basis function	Xiao-kang Su;Guangming Zeng;Guo-he Huang;Jian-bing Li;Jie Liang;Ling-ling Wang;Chun-yan Du	2007	Eng. Appl. of AI	10.1016/j.engappai.2006.06.016	adaptive neuro fuzzy inference system;computer science;artificial intelligence;machine learning;sediment;artificial neural network;kinetics	AI	11.718555612382163	-20.284583670133227	95812
e17511e875e49ddd6b7ed14428771513a4c6155a	ordering-based search: a simple and effective algorithm for learning bayesian networks	bayesian network;search space;heuristic search;learning problems;hill climbing;network structure;order selection	One of the basic tasks for Bayesian networks (BNs) is that of learning a network structure from data. The BN-learning problem is NPhard, so the standard solution is heuristic search. Many approaches have been proposed for this task, but only a very small number outperform the baseline of greedy hill-climbing with tabu lists; moreover, many of the proposed algorithms are quite complex and hard to implement. In this paper, we propose a very simple and easy-toimplement method for addressing this task. Our approach is based on the well-known fact that the best network (of bounded in-degree) consistent with a given node ordering can be found very efficiently. We therefore propose a search not over the space of structures, but over the space of orderings, selecting for each ordering the best network consistent with it. This search space is much smaller, makes more global search steps, has a lower branching factor, and avoids costly acyclicity checks. We present results for this algorithm on both synthetic and real data sets, evaluating both the score of the network found and in the running time. We show that orderingbased search outperforms the standard baseline, and is competitive with recent algorithms that are much harder to implement.	baseline (configuration management);bayesian network;branching factor;directed graph;greedy algorithm;heuristic;hill climbing;synthetic data;tabu search;time complexity;whole earth 'lectronic link	Marc Teyssier;Daphne Koller	2005			interpolation search;beam search;mathematical optimization;bidirectional search;heuristic;computer science;artificial intelligence;hill climbing;machine learning;bayesian network;jump search;mathematics;incremental heuristic search;iterative deepening depth-first search;best-first search;combinatorial search	AI	21.342054284844405	-13.017404271024121	95990
e59198d0ba7f86bcd1e0b3e02fb0dc07e0108e3d	a comparison between two architectures for searching and learning in maze problems	agent based;classifier system;adaptive heuristic critic;2 dimensional;levels of abstraction;radial basis function neural network;genetic algorithm;on line learning	We present two architectures, each designed to search 2-Dimensional mazes in order to locate a goal position, both of which perform on-line learning as the search proceeds. The first architecture is a form of Adaptive Heuristic Critic which uses a Genetic Algorithm to determine the Action Policy and a Radial Basis Function Neural Network to store the acquired knowledge of the Critic. The second is a stimulus-response Classifier System (CS) which uses a Genetic Algorithm, applied Michigan style, for rule generation and the Bucket Brigade algorithm for rule reinforcement. Experiments conducted using agents based upon each architectural model lead us to a comparison of performance, and some observations on the nature and relative levels of abstraction in the acquired knowledge.		Anthony G. Pipe;Brian Carse	1994		10.1007/3-540-58483-8_18	two-dimensional space;genetic algorithm;computer science;artificial intelligence;machine learning;learning classifier system;algorithm	ML	18.256691047213483	-21.63061148188237	96082
bc26553864137413f3e008009b6cef5feab88735	agile tuning method in successive steps for a river flow simulator		Scientists and engineers continuously build models to interpret axiomatic theories or explain the reality of the universe of interest to reduce the gap between formal theory and observation in practice. We focus our work on dealing with the uncertainty of the input data of the model to improve the quality of the simulation. To reduce this error, scientist and engineering implement techniques for model tuning and they look for ways to reduce their high computational cost. This article proposes a methodology for adjusting a simulator of a complex dynamic system that models the wave translation along rivers channels, with emphasis on the reduction of computation resources. We propose a simulator calibration by using a methodology based on successive adjustment steps of the model. We based our process in a parametric simulation. The input scenarios used to run the simulator at every step were obtained in an agile way, achieving a model improvement up to 50% in the reduction of the simulated data error. These results encouraged us to extend the adjustment process over a larger domain region.	agile software development;algorithmic efficiency;computation;dynamical system;internationalized domain name;simulation;theory	Mariano Trigila;Adriana Gaudiani;Emilio Luque	2018		10.1007/978-3-319-93713-7_60	simulation;dynamical systems theory;calibration;theory;axiom;computation;parametric statistics;agile software development;computer science;communication channel	SE	16.840135601284402	-14.611761492709459	96123
2d2d99a341dab36345b8e77469ae493d989e18b1	implementing parametric reinforcement learning in robocup rescue simulation	temporal difference;real time;reinforcement learning;artificial intelligent;dynamic environment;function approximation;decision making process;state space;multi agent coordination;value function	Decision making in complex, multi agent and dynamic environments such as Rescue Simulation is a challenging problem in Artificial Intelligence. Uncertainty, noisy input data and stochastic behavior which is a common difficulty of real time environment makes decision making more complicated in such environments. Our approach to solve the bottleneck of dynamicity and variety of conditions in such situations is reinforcement learning. Classic reinforcement learning methods usually work with state and action value functions and temporal difference updates. Using function approximation is an alternative method to hold state and action value functions directly. Many Reinforcement learning methods in continuous action and state spaces implement function approximation and TD updates such as TD, LSTD, iLSTD, etc. A new approach to online reinforcement learning in continuous action or state spaces is presented in this paper which doesn't work with TD updates. We have named it Parametric Reinforcement Learning. This method is utilized in Robocup Rescue Simulation / Police Force agent's decision making process and the perfect results of this utilization have been shown in this paper. Our simulation results show that this method increases the speed of learning and simplicity of use. It has also very low memory usage and very low costing computation time.	reinforcement learning;simulation	Omid Aghazadeh;Maziar Ahmad Sharbafi;Abolfazl Toroghi Haghighat	2007		10.1007/978-3-540-68847-1_42	temporal difference learning;decision-making;error-driven learning;simulation;function approximation;computer science;state space;artificial intelligence;machine learning;bellman equation;reinforcement learning;q-learning	ML	20.8063845213945	-19.58991259990973	96202
4dc59a1082097e4aa3ed23368cb9897559434191	speeding up planning through minimal generalizations of partially ordered plans	common generalized core;search space exploration;minimal joint generalization;minimal generalization;substantial speed-up;novel strategy;existing plan;new similar planning task	We present a novel strategy enabling to exploit existing plans in solving new similar planning tasks by finding a common generalized core of the existing plans. For this purpose we develop an operator yielding a minimal joint generalization of two partially ordered plans. In three planning domains we show a substantial speed-up of planning achieved when the planner starts its search space exploration from the learned common generalized core, rather than from scratch.	experiment;initial condition;randomness;speedup	Radomír Cernoch;Filip Zelezný	2010		10.1007/978-3-642-21295-6_29	mathematical optimization;simulation;mathematics	AI	19.116799914804886	-10.538507766272573	96461
dd0ae4c834ae5fda4daeb44cc2cda7a486102a79	quantification of margins and uncertainties using multiple gates and conditional probabilities	turboreacteur;combustion chamber;evaluation performance;fiabilidad;reliability;puerta logica;flujo hipersonico;performance evaluation;securite;probabilidad condicional;uncertainty;operating conditions;etude experimentale;evaluacion prestacion;camara combustion;probabilite conditionnelle;shock tube;metric;probabilistic approach;hypersonic flow;chambre combustion;porte logique;ecoulement hypersonique;systeme incertain;condition operatoire;turbojet;hypersonics;enfoque probabilista;approche probabiliste;fiabilite;safety;turboreactor;metrico;tubo de choque;sistema incierto;condicion operatoria;seguridad;conditional probability;logic gate;estudio experimental;uncertain system;safety margins;metrique;tube choc	A methodology to perform the Quantification of Margins and Uncertainties (QMU) is introduced to enable the assessment of the safety associated with the operating conditions of complex engineering devices consisting of multiple subcomponents or coupled multi-physics processes. One of the key components of the approach is the possibility of decomposing the system into subcomponents characterized by critical metrics—gates—that collectively describe the reliability of the whole system. In the present study we formalize the process of constructing conditional probabilities for system performance and illustrate it with two applications: the evaluation of the test-time in a shock-tube experimental facility and the assessment of the unstart limit in the combustion chamber of a supersonic propulsion engine. In both cases, multiple uncertainties are considered and the gates are used as a mechanism to reduce the complexity of the resulting stochastic problem.	quantification of margins and uncertainties	Gianluca Iaccarino;David H. Sharp;James Glimm	2013	Rel. Eng. & Sys. Safety	10.1016/j.ress.2012.11.026	combustion chamber;simulation;hypersonic speed;shock tube;uncertainty;conditional probability;logic gate;metric;engineering;reliability;mathematics;forensic engineering;statistics	ML	13.385234556242075	-10.49539063131263	96736
033f3eab55b78bfb76e9ec3dd4725cd02c0b03eb	coevolving robust build-order iterative lists for real-time strategy games	computers;games robustness genetic algorithms real time systems buildings computers;games;real time strategy computer games genetic algorithms;robustness;genetic algorithms;buildings;real time systems	We investigate and develop a coevolutionary approach to finding strong, robust build orders for real-time strategy games. Which units to produce and the order in which to produce them is one important aspect of real-time strategy gameplay. In real-time strategy games, creating plans to address unit production problems are called “build orders.” Our research compares build orders produced from a coevolutionary algorithm, genetic algorithm (GA), and hill climber (HC) to exhaustive search. GAs find the strongest build orders, while coevolution produces more robust build orders than a genetic algorithm or HC. Case injection into the coevolutionary teachset and population can be used to bias coevolution into producing build orders that beat specific opponents or play like specific players, while maintaining robustness. Finally, in this paper, we extend our representation by adding branching and iteration to the build-action sequence and show that this more complex representation enables coevolution to find stronger build orders. We believe this study is a start toward a promising approach for creating strong, robust build orders for RTS games.	brute-force search;climber (beam);genetic algorithm;hill climbing;iteration;real-time computing;real-time locating system;real-time transcription;selection bias	Christopher A. Ballinger;Sushil J. Louis;Siming Liu	2016	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2016.2544817	games;simulation;genetic algorithm;computer science;artificial intelligence;machine learning;robustness	AI	17.878470494299563	-17.59729082581503	97234
2ff0512247aeca4229f369c66655b00b0088fe04	fuzzy estimation of a yeast fermentation parameters		The dynamics of fermentation processes are very complex and not completely known. Some state variables are nonmeasurable, and the process parameters are strongly time dependent. Recently, there are some control methods like fuzzy learning and neural networks, which are promising in dealing with non-linearity, complexity, and uncertainly of these processes. These methods are suitable for the modelling of these systems, which are difficult to describe mathematically. The fuzzy learning methods are useful for the modelling, they are less demanding on the mathematical model and a priori knowledge about the processes. Different techniques for estimating the state variables (that are non-measurable) in the fermentation process have been investigated. A non-linear auto-regressive with exogenous input (NARX) model was developed using process data from a pilot bioreactor. The fermentation process is splitted into three phases, where each phase was treated separately. Generally, fuzzy models have a capability of dividing an input space into several subspaces (fuzzy clustering), where each subspace is supposed to give a local linear model. In our work, we used global learning where the local models are less interpretable, but the global model accuracy is satisfying, and the fuzzy partition matrix is obtained by applying the Gustafson-Kessel algorithm. The fermentation parameters are estimated for a batch and a fed-batch culture. The number of inputs to our fuzzy model are three for a first simulation. We used four inputs for a second simulation, in order to detect some correlations among inputs. The results show that estimated parameters are close to the measured (or calculated) ones. The parameters used in the computation are identified using batch experiments.	algorithm;algorithmic efficiency;approximation;artificial neural network;batch processing;cluster analysis;computation;error detection and correction;experiment;fuzzy clustering;fuzzy concept;gustafson's law;linear model;mathematical model;nonlinear autoregressive exogenous model;nonlinear system;sensor;simulation;state (computer science)	Mahmoud Taibi;Chabbi Charef;Nicole Vincent	2005	Int. Arab J. Inf. Technol.		fuzzy number;machine learning	ML	11.653451126577362	-21.519319061768687	97334
44d10c47abe15dcba7907e82edb78d99e66e7a47	structure optimization of neural networks for evolutionary design optimization	structure optimization;neural networks;approximation error;evolutionary design;design optimization;evolutionary algorithms;fitness approximation;neural network model;neural network	We study the use of neural networks (NN) as approximate models for fitness evaluation in evolutionary computation. To improve the quality of the NN models, structure optimization of these NNs is applied with respect to two different criteria: One is the commonly used approximation error, and the other is the ability of the NNs to learn different problems of a common class of problems. Simulation results from turbine blade optimization using the structurally optimized NN models are presented to show that the performance of the model can be improved significantly through structure optimization. Published in: A. M. Barry (editor), GECCO 2002: Proceedings of the Bird of a Feather Workshops, Genetic and Evolutionary Computation Conference, pp. 13-16, AAAI, Menlo Park, CA, USA, 2002	approximation algorithm;approximation error;artificial neural network;certificate authority;continuous design;experiment;fitness approximation;genetic and evolutionary computation conference;mathematical optimization;simulation	Michael Hüsken;Yaochu Jin;Bernhard Sendhoff	2005	Soft Comput.	10.1007/s00500-003-0330-y	stochastic neural network;probabilistic-based design optimization;mathematical optimization;approximation error;multidisciplinary design optimization;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;machine learning;evolutionary acquisition of neural topologies;deep learning;fitness approximation;artificial neural network	AI	13.239271875930568	-23.352147297203718	97630
08d653e3b3bcd8dd57293be1dfd6ab37d1e14fd0	alarm management via temporal pattern learning		Industrial plant safety involves integrated management of all the factors that may cause accidents. Process alarm management can be formulated as a pattern recognition problem in which temporal patterns are used to characterize different typical situations, particularly at startup and shutdown stages. In this paper we propose a new approach of alarm management based on a diagnosis process. Assuming the alarms and the actions of the standard operating procedure as discrete events, the diagnosis step relies on situation recognition to provide the operators with relevant information on the failures inducing the alarm flows. The situation recognition is based on chronicle recognition where we propose to use the hybrid causal model of the system and simulations to generate the representative event sequences from which the chronicles are learned using the Heuristic Chronicle Discovery Algorithm Modified (HCDAM). An extension of this algorithm is presented in this article where the expertise knowledge is included as temporal restrictions which are a new input to HCDAM . An illustrative example in the field of petrochemical plants is presented.		J. W. Vasquez Capacho;Audine Subias;Louise Travé-Massuyès;F. Jimenez	2017	Eng. Appl. of AI	10.1016/j.engappai.2017.07.008	computer science;causal model;operator (computer programming);machine learning;artificial intelligence;standard operating procedure;heuristic;alarm management	AI	11.902566604586104	-14.117467323754111	97751
ffbdcd2fe0aafb40bd9e70b6d575174f066fc182	hardware module design of a real-time multi-sensor fire detection and notification system using fuzzy logic	multi sensors data fusion fire detection fuzzy logic microcontroller based;fires fuzzy logic temperature sensors microcontrollers fuzzy sets gsm smoke detectors;fire status determination hardware module design real time multisensor fire detection and notification system fire safety campaigns fire outbreaks alarming rate engineered solution system firefighting effort multisensor fire detection algorithms fire detection device sensitivity nuisance alarms microcontroller mq2 smoke sensor tmp102 temperature sensor dfrobot flame sensor fuzzy logic algorithm;temperature sensors alarm systems fires flames fuzzy logic microcontrollers real time systems safety systems sensor fusion	Notwithstanding massive fire safety campaigns being carried out, incidents of fire outbreaks continue to increase annually. The alarming rate of these fire outbreaks requires an engineered solution system that detects fire in its early stages and contributes to the firefighting effort. Current research efforts have been directed towards the development of multi-sensor fire detection algorithms to increase the sensitivity of fire detection devices and reduce nuisance alarms. This paper presents the design and implementation of a multi-sensor fire detection and notification system using fuzzy logic. The microcontroller processes data from an MQ2 smoke sensor, a TMP102 temperature sensor and a DFRobot flame sensor using a fuzzy logic algorithm to determine the fire status.	algorithm;fuzzy logic;microcontroller;notification system;real-time clock;sensor	Robert Sowah;Abdul R. Ofoli;Selase Krakani;Seth Fiawoo	2014	2014 IEEE Industry Application Society Annual Meeting	10.1109/IAS.2014.6978415	electronic engineering;simulation;engineering;computer security	Mobile	15.977340936210412	-13.272452794950523	97774
86ecec0b3a94fc5d62375c79d03fc8042b7e5d01	integration of evolution with a robot action selection model	modelizacion;model selection;behavioral analysis;intelligence artificielle;robotics;selection modele;algoritmo genetico;action selection;modelisation;seleccion modelo;analyse comportementale;algorithme genetique;robotica;artificial intelligence;algorithme evolutionniste;genetic algorithm;analisis conductual;algoritmo evolucionista;robotique;inteligencia artificial;evolutionary algorithm;robot;modeling	The development of an effective central model of action selection has already been reviewed in previous work. The central model has been set to resolve a foraging task with the use of heterogeneous behavioral modules. In contrast to collecting/depositing modules that have been hand-coded, modules related to exploring follow an evolutionary approach. However, in this paper we focus on the use of genetic algorithms for evolving the weights related to calculating the urgency for a behavior to be selected. Therefore, we aim to reduce the number of decisions made by a human designer when developing the neural substratum of a central selection mechanism.		Fernando Montes-Gonzalez;José Santos Reyes;Homero V. Ríos-Figueroa	2006		10.1007/11925231_111	robot;simulation;systems modeling;genetic algorithm;action selection;computer science;artificial intelligence;evolutionary algorithm;robotics;operations research;model selection	Robotics	23.572834785826316	-12.743387208703691	97840
122a1f751b3476a00af5a4f75d6be71ee09734f3	an autonomous explore/exploit strategy	reinforcement learning;learning classifier systems;learning classifier system;goal setting;genetics based machine learning;explore exploit strategy	In reinforcement learning problems it has been considered that neither exploitation nor exploration can be pursued exclusively without failing at the task. The optimal balance between exploring and exploiting changes as the training progresses due to the increasing amount of learnt knowledge. This shift in balance is not known a priori so an autonomous online adjustment is sought. Human beings manage this balance through logic and explorations based on feedback from the environment. The XCS learning classifier system uses a fixed explore/exploit balance, but does keep multiple statistics about its performance and interaction in an environment. Utilising these statistics in a non-linear manner, autonomous adjustment of the explore/exploit balance was achieved. This resulted in reduced exploration in simple environments, which could increase with the complexity of the problem domain. It also prevented unsuccessful 'loop' exploit trials and suggests a method of dynamic choice in goal setting.	autonomous robot;color balance;failure;feedback;learning classifier system;nonlinear system;problem domain;reinforcement learning	Alex McMahon;Dan Scott;William N. L. Browne	2005		10.1145/1102256.1102280	error-driven learning;simulation;computer science;artificial intelligence;machine learning;learning classifier system;reinforcement learning	Robotics	18.937057491478225	-20.45522205951522	97913
7542ebe84af3312743044743333a84f0f91672e6	degradation based long-term reliability assessment for electronic components in submarine applications	reliability assessment		elegant degradation	V. Lista;P. Garbossa;T. Tomasi;Mattia Borgarino;Fausto Fantini;L. Gherardi;A. Righetti;M. Villa	2002	Microelectronics Reliability	10.1016/S0026-2714(02)00156-7	reliability engineering;intra-rater reliability;engineering;physics	OS	12.622702940582336	-11.672806086658092	97996
325413859d5bf180dd08352b07a09fd714ec3db9	online task assignment in crowdsourcing markets		We explore the problem of assigning heterogeneous tasks to workers with different, unknown skill sets in crowdsourcing markets such as Amazon Mechanical Turk. We first formalize theonline task assignment problem , in which a requester has a fixed set of tasks and a budget that specifies how many times he would like each task completed. Workers arrive one at a time (with the same worker potentially arriving multiple times), and must be assigned to a task upon arrival. The goal is to allocate workers to tasks in a way that maximizes the total benefit that the requester obtains from the completed work. Inspired by recent research on the online adwords problem, we present a two-phase exploration-exploitation assignment algorithm and prove that it is competitive with respect to the optimal offline algorithm which has access to the unknown skill levels of each worker. We empirically evaluate this algorithm using data collected on Mechanical Turk and show that it performs better than random assignment or greedy algorithms. To our knowledge, this is the first work to extend the online primal-dual technique used in the online adwords problem to a scenario with unknown parameters, and the first to offer an empirical validation of an online primal-dual algorithm.	activity selection problem;amazon mechanical turk;assignment problem;crowdsourcing;diffusing update algorithm;google adwords;greedy algorithm;online algorithm;online and offline;the turk;two-phase commit protocol	Chien-Ju Ho;Jennifer Wortman Vaughan	2012			simulation;computer science;artificial intelligence;machine learning;data mining	AI	18.736437342282038	-14.463472725675038	98096
6885106fdb3b7f2581a5919c4102b689ade50d40	prediction of performance and emission characteristics in a biodiesel engine using wco ester: a comparative study of neural networks	emissions;transesterification;multilayer perception;waste cooking oil;radial basis function	In this study, the applicability of Artificial Neural Networks (ANNs) has been investigated for predicting the performance and emission characteristics of a diesel engine fuelled with Waste cooking oil (WCO). ANN modeling was done using multilayer perception (MLP) and radial basis functions (RBF). In the radial basis functions, centers were initialized by two different methods namely random selection method and using clustering algorithm. In the clustering method, center initialization was done using FCM (Fuzzy$$c$$cmeans) and CDWFCM (cluster dependent weighted fuzzy$$c$$cmeans) algorithms. The networks were trained using the experimental data, wherein load percentage, compression ratio, blend percentage, injection timing and injection pressure were taken as the input parameters and brake thermal efficiency, brake specific energy consumption, exhaust gas temperature and engine emissions were used as the output parameters. The investigation showed that ANN predicted results matched well with the experimental results over a wide range of operating conditions for both models. A comparison was made between ANN models and regression models. ANN performed better than the regression models. Similarly a comparison of MLP and RBF indicated that RBF with CDWFCM performed better than MLP networks with lower Mean Relative Error (MRE) and higher accuracy of prediction.	artificial neural network	Shiva Kumar;P. Srinivasa Pai;B. R. Shrinivasa Rao;G. S. Vijay	2016	Soft Comput.	10.1007/s00500-015-1666-9	radial basis function;simulation;computer science;machine learning	Arch	11.45749682558768	-19.815332246194327	98270
7b515066e82a8108424f0238fb2c20c0c5ac7ca7	an event-driven based multiple scenario approach for dynamic and uncertain uav mission planning		In this paper, a Dynamic and Uncertain Unmanned Aerial Vehicle Mission Planning(DUUMP) is considered. New targets reveal stochastically during the mission execution and the surveillance benefit of each target is a random variable. To deal with this problem, an Event-driven based Multiple Scenario Approach(MSA) is developed. Experiment studies show that the Event-driven based MSA can solve the DUUMP effectively and efficiently with quick system responsiveness and high quality solution, which shows its practical value for real world applications.	event-driven programming;scenario optimization;unmanned aerial vehicle	Ke Shang;Liangjun Ke;Zuren Feng;Stephen Karungaru	2015		10.1007/978-3-319-20472-7_33	mathematical optimization	Robotics	22.285208504019923	-14.15270880399733	98558
627fdb995b528d128ee5685f08e3db523205caf4	a fuzzy-nets-based in-process surface roughness prediction system in turning operations	fuzzy-nets-based in-process;roughness prediction system;surface roughness	A Fuzzy-Nets-based in-process surface roughness prediction (FISRP) system was developed to predict surface roughness in turning operations in a real time fashion. The input variables of the FISRP system were machining parameters, such as feed rate, spindle speed, depth of cut, and machining vibration per revolution. An accelerometer was employed to gather real-time vibration signals. Two groups of data were collected for two cutter bits with nose radii of 0.016 and 0.031 inches, respectively. Fuzzy nets theory was implemented to use the experimental data in developing the system for real-time prediction. The fuzzy nets theory is a five-step learning procedure for developing a knowledge base to predict surface roughness in real time. This FISRP system was tested to have an average prediction accuracy of 95.70%.		L. H. Huang;J. C. Chen	2004	KES Journal		surface roughness;computer science	Crypto	13.245751686900372	-19.143665084866193	98639
0919c25dddd4bf9ffab4594ec2d7e092bbe6f033	multi-resolution corrective demonstration for efficient task execution and refinement	complementary corrective demonstration;learning from human demonstration;multi resolution task execution	Computationally efficient task execution is very important for autonomous mobile robots endowed with limited on-board computational resources. Most robot control approaches assume a fixed state and action representation, and use a single algorithm to map states to actions. However, not all situations in a given task require equally complex algorithms and equally detailed state and action representations. The main motivation for this work is a desire to reduce the computational footprint of performing a task by allowing the robot to run simpler algorithms whenever possible, and resort to a more complex algorithm only when needed. We contribute the Multi-Resolution Task Execution (MRTE) algorithm that utilizes human feedback to learn a mapping from a given state to an appropriate detail resolution consisting of a state and action representation, and an algorithm providing a mapping from states to actions at that resolution. The robot learns a policy from human demonstration to switch between different detail resolutions as needed while favoring lower detail resolutions to reduce computational cost of task execution. We then present the Model Plus Correction (M+C) algorithm to improve the performance of an algorithm using corrective human feedback without modifying the algorithm itself. Finally, we introduce the MultiResolution Model Plus Correction (MRM+C) algorithm as Ç. Meriçli Computer Science Department Carnegie Mellon University E-mail: cetin@cmu.edu M. Veloso Computer Science Department Carnegie Mellon University E-mail: veloso@cmu.edu H. L. Akın Department of Computer Engineering Boğaziçi University E-mail: akin@boun.edu.tr a combination of MRTE and M+C. MRM+C learns how to select an appropriate detail resolution to operate at in a given state from human demonstration. Furthermore, it allows the teacher to provide corrective demonstration at different detail resolutions to improve overall task execution performance. We provide formal definitions of MRTE, M+C, and MRM+C algorithms, and show how they relate to general robot control problem and Learning from Demonstration (LfD) approach. We present experimental results demonstrating the effectiveness of proposed methods on a goaldirected humanoid obstacle avoidance task.	algorithm;autonomous robot;computation;computational complexity theory;computational resource;computer engineering;computer science;humanoid robot;mobile robot;obstacle avoidance;on-board data handling;refinement (computing);robot control;speculative execution	Çetin Meriçli;Manuela M. Veloso;H. Levent Akin	2012	I. J. Social Robotics	10.1007/s12369-012-0159-6	real-time computing;simulation;computer science;artificial intelligence	Robotics	17.997205960512083	-19.276770928828025	98644
43e6a281953718b22b5c19229587af704e353a00	modified radial basis function neural network integrated with multiple regression analysis and its application in the chemical industry processes	correlation pruning algorithm;soft sensor;radial basis function neural network;least squares regression	The construct of a radial basis function neural network (RBFNN) plays an important role in predicting performance. However, determining the optimal construct is difficult. A modified RBFNN integrated with correlation pruning algorithm-least squares regression (CPA-LSR) was proposed to optimize the number of hidden neurons as well as the weights and bias. First, an initial RBFNN was built by superposing each center to a training set point. This RBFNN was then trained. Next, CPA-LSR was applied to eliminate the redundant information of the initial network and to improve the predicting performance by optimizing the structure as well as the weights and bias. Finally, the developed naphtha dry point soft sensor and the industrial oxidation of p-xylene to terephthalic acid were employed to illustrate the performances of the modified RBFNNs. The result reveals an improvement in the predicting performances of the RBFNNs integrated with CPA-LSR. Conclusively, RBFNNs integrated with CPA-LSR are recommended because ...	artificial neural network;radial (radio);radial basis function	Yang Wang;Chao Chen;Xuefeng Yan	2013	Intelligent Automation & Soft Computing	10.1080/10798587.2013.805547	soft sensor;computer science;artificial intelligence;machine learning;pattern recognition;least squares	Robotics	12.433306940925052	-20.628891241064128	98730
b23fbe5d3093e611a4a430dd5e37b13032c3be1f	a simple two-module problem to exemplify building-block assembly under crossover	parallelisme;fitness landscape;paysage;building block;paisaje;algoritmo genetico;resolucion problema;parallelism;paralelismo;biomimetique;algorithme genetique;genetic algorithm;landscape;problem solving;resolution probleme;biomimetics	Theoretically and empirically it is clear that a genetic algorithm with crossover will outperform a genetic algorithm without crossover in some fitness landscapes, and vice versa in other landscapes. Despite an extensive literature on the subject, and recent proofs of a principled distinction in the abilities of crossover and non-crossover algorithms for a particular theoretical landscape, building general intuitions about when and why crossover performs well when it does is a different matter. In particular, the proposal that crossover might enable the assembly of good building-blocks has been difficult to verify despite many attempts at idealized building-block landscapes. Here we show the first example of a two-module problem that shows a principled advantage for crossover. This allows us to understand building-block assembly under crossover quite straightforwardly and build intuition about more general landscape classes favoring crossover or disfavoring it.	climber (beam);crossover (genetic algorithm);exemplification;genetic algorithm;simulation;transcription (software);while	Richard A. Watson	2004		10.1007/978-3-540-30217-9_17	biomimetics;genetic algorithm;fitness landscape;computer science;artificial intelligence;mathematics;landscape;algorithm	ML	23.091906221588623	-11.756752943447005	98884
22f3061e1f4a1a4f6e1b1ebd074fa7eb2a01bf3c	inverse reinforcement learning from failure	social navigation;inverse reinforcement learning;robotics;learning from demonstration;machine learning	In this paper, we approach the problem of Inverse Reinforcement Learning (IRL) from a rather different perspective. Instead of trying to only mimic an expert as in traditional IRL, we present a method that can also utilise failed or bad demonstrations of a task. In particular, we propose a new IRL algorithm that extends the state-of-the-art method of Maximum Causal Entropy Inverse Reinforcement Learning to exploit such failed demonstrations. Furthermore, we present experimental results showing that our method can learn faster and better than its original counterpart.	algorithm;causal filter;reinforcement learning	Kyriacos Shiarlis;João V. Messias;Shimon Whiteson	2016			simulation;computer science;artificial intelligence;machine learning;robotics	AI	19.875252215041453	-20.178799606818494	98986
4a725d6da0afd8d8592cdacfd3d929a2fc3e237e	neuro-guided genetic programming: prioritizing evolutionary search with neural networks		When search operators in genetic programming (GP) insert new instructions into programs, they usually draw them uniformly from the available instruction set. Prefering some instructions to others would require additional domain knowledge, which is typically unavailable. However, it has been recently demonstrated that the likelihoods of instructions' occurrence in a program can be reasonably well estimated from its input-output behavior using a neural network. We exploit this idea to bias the choice of instructions used by search operators in GP. Given a large sample of programs and their input-output behaviors, a neural network is trained to predict the presence of individual instructions. When applied to a new program synthesis task, the network is first queried on the set of examples that define the task, and the obtained probabilities determine the frequencies of using instructions in initialization and mutation operators. This priming leads to significant improvements of the odds of successful synthesis on a range of benchmarks.	artificial neural network;benchmark (computing);evolutionary programming;fitness function;genetic programming;mutation (genetic algorithm);program synthesis	Pawel Liskowski;Iwo Bladek;Krzysztof Krawiec	2018		10.1145/3205455.3205629	program synthesis;priming (psychology);operator (computer programming);machine learning;domain knowledge;artificial neural network;initialization;artificial intelligence;genetic programming;computer science;instruction set	ML	20.345216459362486	-10.204067009140562	99008
598c2489acebfcdfa7d7e1506e04b0b80327bcdf	achieving multiagent coordination through cala-rfmq learning in continuous action space		In cooperative multiagent systems, an agent often needs to coordinate with other agents to optimize both individual and system-level payoffs. A lot of multiagent learning approaches have been proposed to address coordination problems in discrete-action cooperative environments. However, it becomes more challenging when faced with continuous action spaces, e.g., slow convergence rate and convergence to suboptimal policy. In this paper, we propose a novel algorithm called CALA-rFMQ (Continuous Action Learning Automata with recursive Frequency Maximum Q-Value) that ensures robust and efficient coordination among multiple agents in continuous action spaces. Experimental results show that CALA-rFMQ facilitates efficient coordination, and outperforms previous works.	agent-based model	Wanshu Liu;Chengwei Zhang;Tianpei Yang;Jianye Hao;Xiaohong Li;Zhijie Bao	2018		10.1007/978-3-319-97310-4_15	computer science;machine learning;rate of convergence;artificial intelligence;recursion;action learning;coordination game;convergence (routing);multi-agent system	AI	19.431170764733643	-18.68209596483387	99016
8fd4af2eded0b3b854517c06e363a51431602933	an optimizer of grey-genetic algorithms to improve the prediction efficiency for taiwan import and export pollution	prediction theory forecasting theory genetic algorithms grey systems international trade optimal control pollution;optimal control;forecasting theory;prediction theory;predictive models accuracy mathematical model forecasting biological system modeling data models industries;grey systems;genetic algorithms;genetic algorithms forecasting model grey theory;grey genetic algorithms gga model gm models taiwan import manufacturers taiwan export manufacturers short lifecycle product prediction system grey theory models optimal controller taiwan export pollution taiwan import pollution prediction efficiency;international trade;pollution	This study proposes an optimal controller of Grey-Genetic Algorithms (GGA) to improve the prediction efficiency of grey theory models (GM). In this research, we design the different experimental schemes for the improving efficiency of the prediction models. The simple model (GM(1, 1)) and multiple model (GM(1,N)) are applied in the short-lifecycle product prediction system that was presented and evaluated on their performances. These models GM(1,1); GM(1, N); RGM(1, 1); and RGM(1,N) are selected and simulated with those of the import and export data from Taiwan's import & export manufacturers. The experimental results show that the optimal controller can improve the prediction accuracy of GM models. This controller mechanism of GGA's model also offers the more effective simulation alternatives for increasing prediction accuracy by this proposed controller.	genetic algorithm;grey relational analysis;long short-term memory;mathematical optimization;optimal control;performance;simulation	Chen-Fang Tsai	2013	Proceedings of the 2013 IEEE 17th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2013.6581033	genetic algorithm;optimal control;pollution;computer science;operations research	Robotics	10.62114397344955	-17.913171516705873	99025
5117b4bbc1e82e74c408eb42eb483fb88f364ee9	automated hierarchy discovery for planning in partially observable environments	non convex optimization;prior knowledge;non linear approximation;optimization problem;scenario planning;partial observation;policy iteration	Planning in partially observable domains is a notoriously difficult problem. However, in many real-world scenarios, planning can be simplified by decomposing the task into a hierarchy of smaller planning problems. Several approaches have been proposed to optimize a policy that decomposes according to a hierarchy specified a priori. In this paper, we investigate the problem of automatically discovering the hierarchy. More precisely, we frame the optimization of a hierarchical policy as a non-convex optimization problem that can be solved with general non-linear solvers, a mixed-integer non-linear approximation or a form of bounded hierarchical policy iteration. By encoding the hierarchical structure as variables of the optimization problem, we can automatically discover a hierarchy. Our method is flexible enough to allow any parts of the hierarchy to be specified based on prior knowledge while letting the optimization discover the unknown parts. It can also discover hierarchical policies, including recursivepolicies, that are more compact (potentially infinitely fewer parameters) and often easier to understand given the decomposition induced by the hierarchy.	approximation algorithm;automated planning and scheduling;convex optimization;dialog system;encode;experiment;iteration;language model;linear approximation;mathematical optimization;natural language generation;nonlinear system;optimization problem;partially observable markov decision process;partially observable system;recursion (computer science);recursive acronym;snopt;scalability;solver;webserver directory index	Laurent Charlin;Pascal Poupart;Romy Shioda	2006			optimization problem;mathematical optimization;combinatorics;scenario planning;machine learning;mathematics	ML	21.078315358994093	-16.728135941000392	99192
8b7125f9ea05632eb7efb723d9b5ed35207eecb1	vulnerability of industrial facilities to attacks with improvised explosive devices aimed at triggering domino scenarios	improvised explosives;anfo;domino effect;security management;overpressure;tatp	Process- and chemical plants may constitute a critical target for a terrorist attack. In the present study, the analysis of industrial accidents induced by intentional acts of interference is carried out focusing on accident chains triggered by attacks with home-made (improvised) explosives. The effects of blast waves caused by improvised explosive devices are compared with those expected from a net equivalent charge of TNT by using a specific methodology for the assessment of stand-off distances. It is demonstrated that a home-made explosive device has a TNT efficiency comprised between 0.2 and 0.5. The model was applied to a case study, demonstrating the potentiality of improvised explosives in causing accident escalation sequences and severe effects on population and assets. The analysis of the case-study also allowed obtaining suggestions for an adequate security management.		Gabriele Landucci;Genserik L. L. Reniers;Valerio Cozzani;Ernesto Salzano	2015	Rel. Eng. & Sys. Safety	10.1016/j.ress.2015.03.004	security management;simulation;computer science;engineering;overpressure;domino effect;anfo;forensic engineering;computer security	SE	12.294114238007731	-10.9304679333917	99263
37088dec26231bc5a4937054ebc862bb83a3db4d	neural episodic control.		A method includes maintaining respective episodic memory data for each of multiple actions; receiving a current observation characterizing a current state of an environment being interacted with by an agent; processing the current observation using an embedding neural network in accordance with current values of parameters of the embedding neural network to generate a current key embedding for the current observation; for each action of the plurality of actions: determining the p nearest key embeddings in the episodic memory data for the action to the current key embedding according to a distance measure, and determining a Q value for the action from the return estimates mapped to by the p nearest key embeddings in the episodic memory data for the action; and selecting, using the Q values for the actions, an action from the multiple actions as the action to be performed by the agent.	bellman equation;computer performance;experience;human reliability;reinforcement learning;semiconductor industry;table (information)	Alexander Pritzel;Benigno Uria;Sriram Srinivasan;Adrià Puigdomènech Badia;Oriol Vinyals;Demis Hassabis;Daan Wierstra;Charles Blundell	2017			artificial neural network;machine learning;computer science;episodic memory;embedding;artificial intelligence	ML	19.602838951054945	-23.120160275893344	99515
2d5de5d1cd9355283a840799e739014847ce16be	vulnerability analysis of ais-based intrusion detection systems via genetic and particle swarm red teams	genetique;particle swarm;computer crime genetic algorithms artificial life;swarm intelligence;artificial immune system;genetica;sistema inmunitario;vulnerability analysis;securite informatique;genetic swarms artificial immune system ais based intrusion detection systems vulnerability analysis ids genetic hacker evolutionary hackers particle swarm optimization pso constriction coefficient;computer crime;intelligence artificielle;vulnerability;genetics;computer security;vulnerabilite;vulnerabilidad;particle swarm optimizer;internet;optimizacion enjambre particula;biomimetique;seguridad informatica;immune system;intrusion detection systems;optimisation essaim particule;artificial intelligence;algorithme evolutionniste;genetic algorithms;algoritmo evolucionista;inteligencia artificial;evolutionary algorithm;reseau neuronal;delinquency;delinquance;intrusion detection genetics particle swarm optimization detectors computer hacking telecommunication traffic computer science artificial immune systems software statistical analysis;red neuronal;systeme detection intrusion;artificial life;systeme immunitaire;intrusion detection system;biomimetics;neural network;delincuencia	Artificial immune systems (AISs) are biologically inspired problem solvers that have been used successfully as intrusion detection systems (IDSs). In this paper we compare a genetic hacker with 12 evolutionary hackers based on particle swarm optimization (PSO) that have been effectively used as vulnerability analyzers (red teams) for AIS-based IDSs. Our results show that the PSO-based red teams that use Clerc's constriction coefficient outperform those that do not. Our results also show that the three types of red teams (genetic, basic PSO, and PSO with the constriction coefficient) have distinct search behaviors that are complimentary. This result suggests that red teams based on genetic swarms may hold the most promise.	artificial immune system;genetic algorithm;intrusion detection system;mathematical optimization;matthews correlation coefficient;particle swarm optimization	Gerry V. Dozier;Douglas Brown;John Hurley;Krystal Cain	2004	Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753)	10.1109/CEC.2004.1330845	intrusion detection system;simulation;swarm intelligence;computer science;artificial intelligence;machine learning;evolutionary algorithm;operations research	Embedded	23.65194578114907	-12.113961081886934	99596
ece09dcbccc4431449d7ff6a4726a1501c917441	neuro-swarm hybridization for protein tertiary structure prediction	energy function;protein tertiary structure prediction;particle swarm optimization technique;ab-initio approach;neuro-swarm hybridization;classical technique;layered artificial neural network;charmm energy function;new approach;artificial neural network;particle swarm optimization algorithm;main chain dihedral angle;swarm intelligence;soft computing;evolutionary algorithm;bioinformatics;molecular biology	This paper describes a new approach for predicting tertiary structure of protein using artificial neural network and particle swarm optimization technique. The paper is concetrated around the well known Ab-initio approach for global minimisation of energy function. It predicts the native structure of protein by finding the main chain dihedral angles; through the optimization of CHARMM energy function, using particle swarm optimization algorithm. Side chain dihedral angle are predicted using three layered artificial neural network, realised with back propagation algorithm. This approach has merit as it reduces the dimensionality of the search space and computationally outperforms all other classical technique in atleast 80% cases.	swarm	Ayan Datta;Veera Talukdar;Amit Konar;Lakhmi C. Jain	2008	Int. J. Hybrid Intell. Syst.		multi-swarm optimization;swarm intelligence;computer science;bioinformatics;artificial intelligence;machine learning;evolutionary algorithm;soft computing;artificial neural network	NLP	23.771809477815196	-11.906325672740056	99721
09ac448b857b2f2f0939f16266e3bf14f4ca997f	robust vis-nirs models for rapid assessment of soil organic carbon and nitrogen in feralsols haplic soils from different tillage management practices		Abstract Application of spectroscopy for assessment of soil nutrition in the field may be affected by the depth at which the radiation spreads to, the analysed nutrient, the nutrient level or management practices such as tillage systems. In this study, the use of visible to near infrared spectroscopy (Vis-NIRS) was explored as a technique to predict soil organic carbon (SOC) and soil organic nitrogen (SON) in different tillage management practices, varying rates of nitrogen and different depth distribution. The tillage treatments were no-till (NT), rotational tillage (RT) and conventional tillage (CT) and nitrogen was applied at a rate of 0, 100 and 200 kg/ha as lime ammonium nitrate. The reflectance spectra of samples from 0 to 10, 10 to 20 and 20 to 30 cm depths were acquired from all tillage treatments using a laboratory bench-top monochromator NIR Systems Model XDS spectrometer. Partial least square regression (PLSR) models were developed using leave-one-out cross validation method. The models were then tested on independent test samples (54) randomly selected from the total 324 samples. Principal component analysis (PCA) was used to differentiate SOC in different tillage treatments and different rates of nitrogen. The best prediction model was observed for SOC with the coefficient of determination (R 2 ) = 0.993, root mean square error of prediction (RMSEP) = 0.157% and residual predictive deviation (RPD) = 2.55 compared with R 2  = 0.661, RMSEP = 0.019%, RPD = 2.11 for SON. PCA was able to cluster soil samples according to the rates of applied nitrogen but not the tillage systems and depths. This study demonstrated the application of Vis-NIRS for analysis of SOC and SON from soils with varying levels of the nutrients. The robustness of developed models was associated with analysing samples from different depths and combining them during calibrations. Therefore, models developed in this manner were recommended for technicians in the field since they would warrant the assessment of soil in different tillage systems and in the entire rooting zone of crops.		Nkanyiso J. Sithole;Khayelihle Ncama;Lembe S. Magwaza	2018	Computers and Electronics in Agriculture	10.1016/j.compag.2018.08.036	soil science;control engineering;coefficient of determination;radiation;soil carbon;conventional tillage;soil water;nitrogen;soil test;engineering;tillage	HCI	11.950339846467976	-19.2875291601068	99971
836b23783c40cf9b18678a62ab432f7eba0b6a65	scalable algorithms for sequential decision making under uncertainty in multiagent systems	multiagent planning under uncertainty;interactive partially observable markov decision process;dissertation;artificial intelligence;scalable algorithms;rational decision making;interactive decision theory	Decision making or planning is a crucial part of AI research. In recent times, deploying autonomous agents – such as search and rescue robots, autonomous unmanned vehicles, planetary rovers, and many others – has been proposed as a feasible approach in many realworld scenarios where sending humans is deemed either too risky or too expensive. Many times, these agents are required to operate under uncertainty, which may arise either due to the dynamics of the environment or due to the inaccuracies inherent in the sensors and actuators of the autonomous agent. In order to accomplish its goal most efficiently, the autonomous agent must compute an optimal plan for itself. Decision making in partially observable stochastic settings is formalized by partially observable Markov decision processes (POMDPs) [35]. Interactive partially observable Markov decision processes (I-POMDPs) [20] generalize POMDPs to multiagent settings where the goal is to compute the optimal policy for an individual agent operating in the presence of other agents whose goals and preferences may not align with that of the subject agent. The solution to the problem of multiagent decision making under uncertainty suffers from several sources of intractability. These sources of intractability arise due to the uncertainty inherent in the environment, such as the stochastic state transitions, noisy or partial observations, and uncertainty about the goals, capabilities, and beliefs of the other interacting agents. While POMDP allows an agent to act rationally in single agent settings and most POMDP approximation algorithms are generalizable to multiagent contexts such as I-POMDPs, additional effort must be made to tackle problems specific to multiagent settings. In my dissertation, I propose several techniques that target various sources of intractability that plague multiagent decision making problems formalized by I-POMDPs. The first approach is a simple enhancement to existing POMDP algorithms that limits the observation space in certain contexts for quicker solution. The next approach is a generalized policy iteration technique that restricts the exponential growth of the model space, thereby speeding up the computation of a locally optimal policy. Third, I propose an online bimodal approach that in which the agent behaves as a POMDP treating other agents as a static noise under higher uncertainty but once it has received sufficient information regarding the current physical state of the environment, switches to full I-POMDP mode. This asymptotically leads to better runtime. Finally, I target the problem of exponentially growing complexity of I-POMDP solution with the number of interacting agents. This source of intractability is overcome by exploiting commonly found problem structures such as anonymity [58] and context-specific independence [7]. Exploiting these problem structures enables solution of problems involving thousands of interacting agents in under six hours. Index words: Artificial intelligence, rational decision making, interactive decision theory, multiagent planning under uncertainty, interactive partially observable Markov decision process, scalable algorithms Scalable Algorithms for Sequential Decision Making Under Uncertainty in Multiagent Systems	as-interface;agent-based model;align (company);approximation algorithm;artificial intelligence;autonomous agent;autonomous robot;capacitor plague;computation;decision theory;interaction;iteration;local optimum;markov chain;multi-agent system;network switch;partially observable markov decision process;partially observable system;planetary scanner;rationality;scalability;time complexity;unmanned aerial vehicle	Ekhlas Shaikh Sonu	2015			r-cast;optimal decision;influence diagram;partially observable markov decision process;decision analysis;decision engineering;computer science;knowledge management;machine learning;decision rule;management science;business decision mapping	AI	19.907857591250426	-15.524249819010226	100101
3b9ebd25a89c5c09ee258abad59c723b616ea221	learning policies for battery usage optimization in electric vehicles	reinforcement learning;computational sustainability;regression	The high cost, limited capacity, and long recharge time of batteries pose a number of obstacles for the widespread adoption of electric vehicles. Multi-battery systems that combine a standard battery with supercapacitors are currently one of the most promising ways to increase battery lifespan and reduce operating costs. However, their performance crucially depends on how they are designed and operated. In this paper, we formalize the problem of optimizing real-time energy management of multi-battery systems as a stochastic planning problem, and we propose a novel solution based on a combination of optimization, machine learning and data-mining techniques. We evaluate the performance of our intelligent energy management system on various large datasets of commuter trips crowdsourced in the United States. We show that our policy significantly outperforms the leading algorithms that were previously proposed as part of an open algorithmic challenge. Further, we show how to extend our approach to an incremental learning setting, where the policy is capable of improving and adapting as new data is being collected over time.	algorithm;crowdsourcing;data mining;data point;discretization;dynamic programming;glossary of computer graphics;ibm notes;iteration;machine learning;markov chain;markov decision process;mathematical optimization;real-time clock;rechargeable battery;simulation;supervised learning;test set	Stefano Ermon;Yexiang Xue;Carla P. Gomes;Bart Selman	2012	Machine Learning	10.1007/s10994-013-5378-z	simulation;regression;computer science;artificial intelligence;machine learning;reinforcement learning	AI	17.588212216026736	-15.718882036657257	100133
164f97f8b8561391de9326b1d6c8cae7f6b9164c	heuristic search when time matters	heuristic search;provably optimal solution;natural utility function;utility function;time pressure;weighting search time;solution cost;search time;search algorithm;optimizing utility function;time matter;linearly trade-off search time	In many applications of shortest-path algorithms, it is impractical to find a provably optimal solution; one can only hope to achieve an appropriate balance between search time and solution cost that respects the user’s preferences. Preferences come in many forms; we consider utility functions that linearly trade-off search time and solution cost. Many natural utility functions can be expressed in this form. For example, when solution cost represents the makespan of a plan, equally weighting search time and plan makespan minimizes the time from the arrival of a goal until it is achieved. Current state-of-theart approaches to optimizing utility functions rely on anytime algorithms, and the use of extensive training data to compute a termination policy. We propose a more direct approach, called Bugsy, that incorporates the utility function directly into the search, obviating the need for a separate termination policy. We describe a new method based on off-line parameter tuning and a novel benchmark domain for planning under time pressure based on platform-style video games. We then present what we believe to be the first empirical study of applying anytime monitoring to heuristic search, and we compare it with our proposals. Our results suggest that the parameter tuning technique can give the best performance if a representative set of training instances is available. If not, thenBugsy is the algorithm of choice, as it performs well and does not require any off-line training. This work extends the tradition of research on metareasoning for search by illustrating the benefits of embedding lightweight reasoning about time into the search algorithm itself.	anytime algorithm;benchmark (computing);heuristic;makespan;online and offline;performance tuning;search algorithm;shortest path problem;utility	Ethan Burns;Wheeler Ruml;Minh Binh Do	2013	J. Artif. Intell. Res.	10.1613/jair.4047	beam search;mathematical optimization;simulation;beam stack search;computer science;artificial intelligence;machine learning;incremental heuristic search	AI	19.207033986506776	-10.92976899945943	100361
27b6ad1bca3c30d96c2e000703e40df0b1a97174	control scaling factor of cuckoo search algorithm using learning automata	learning automata;scaling factor;cuckoo search;linear reward penalty	In this study, we seek an optimal scaling factor of cuckoo search algorithm by using learning automata. In the presented method, the same learning automaton is built for each individual, and a set of actions of each learning automaton are set to several constant scaling factors. Moreover, the linear reward-penalty learning algorithm is used in learning automaton to select the optimal scaling factor of each individual. Extensive experiments on 20 benchmark functions demonstrate better effectiveness and efficiency of controlling scaling factor of cuckoo search by using learning automata.	automata theory;cuckoo search;image scaling;learning automata;search algorithm	Yaohua Lin;Lijin Wang;Yiwen Zhong;Cuiping Zhang	2016	IJCSM	10.1504/IJCSM.2016.10000973	scale factor;mathematical optimization;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;cuckoo search	Robotics	21.36754207997112	-18.060097565239563	100388
09800895a7ae3f6c5c3fb128ac7ecb3942624fdc	the application of bp neural network in coal analysis	processing element;nonlinear mapping;neural nets;statistical method;backpropagation;data model;on line analysis coal analysis neural network the calorific;power plant;power plants;boilers;complex system;coal fired utility boilers bp neural network coal power plant boiler combustion system calorific value coal quality analysis elemental analysis data ann methods coal fired industrial analysis;solid modeling;relational model;power plants backpropagation boilers coal neural nets;coal;training coal data models biological neural networks analytical models solid modeling artificial neural networks;neural network model;nonlinear system;analytical model;artificial neural network;nonlinear regression;neural network;nonlinear model	Coal analysis is of great significance to Coal power plant boiler combustion system in the diagnosis and optimization, and Calorific value of coal is an important indicator of coal quality analysis. So the research of the relation among Coal analysis data, elemental analysis data and the calorific is of great significance. Based on powerful approximating ability of neural network, the paper uses the daily common BP neural network model. The result shows that the relationship model of this method has a high precision, which makes ANN methods in coal heat power audit, Coal Quality and off-line analysis great practical significance. In addition, the paper established the relational model of coal-fired industrial analysis of data, low heat and elemental analysis data. It offers a good guide to the operation of coal-fired utility boilers.	artificial neural network;elemental;mathematical optimization;network model;online and offline;relational model	Wan-Ye Yao;Ling Su;Shi Yin	2011	2011 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2011.6016755	power station;computer science;machine learning;artificial neural network	DB	11.943297085732885	-18.862690955552875	100569
96b7b3917444e3bd252a81edf10215906510e031	eco-grammars to model biological systems: adding probabilities to agents	game theory;evolutionary stable strategy;teoria juego;theorie jeu;probabilistic approach;dinamica poblacion;ecosysteme;ecosistema;evolutionary biology;agent intelligent;intelligent agent;population dynamics;biological systems;algorithme evolutionniste;algoritmo evolucionista;agente inteligente;evolutionary algorithm;dynamique population;ecosystem	The aim of this paper is to define probabilistic Ecogrammar systems and some of their applications in the field of evolutionary biology. A probabilistic Eco-grammar system is composed of agents that select the rules of internal growth as well as the action rules according to distributions of probability. The environment is 0L probabilistic. Our interest is centered in the study of the normalized populations of symbols obtained along a derivation. In this paper we show that the probabilistic approach applied to Eco-grammar systems allows to model the evolutionary stable strategies of Maynard Smith.	biological system	Sergio O. Anchorena;Blanca Cases	2001		10.1007/3-540-44811-X_6	game theory;probabilistic analysis of algorithms;ecosystem;simulation;probabilistic ctl;probabilistic relevance model;computer science;probabilistic database;artificial intelligence;evolutionary algorithm;evolutionarily stable strategy;population dynamics;probabilistic logic;probabilistic argumentation;intelligent agent;divergence-from-randomness model	Logic	23.116591633472652	-13.216183779153999	100579
5138d6571f5256a88b88416c30ef22980e83c364	an approach for predicting latent infrastructure facility deterioration	damage;forecast;forecasting;carga trafico;evaluation performance;metodo estadistico;modelo prevision;performance evaluation;indicateur;pavement;maintenance;road traffic;evaluacion prestacion;data collection;charge trafic;infraestructura transporte;mesure in situ;statistical method;infrastructure transport;deterioracion;pavements;forecast model;chaussee;pavement conditions;trafic routier;mathematical models;pavement serviceability;methode statistique;traffic load;mantenimiento;deterioration;medicion en sitio;calzada;trafico carretera;evaluation;variable latente;methodology;transportation infrastructure;models;measurement in situ;pavement performance;infrastructure;modele prevision	A pavement deterioration model predicts the performance of a pavement over time as a function of traffic, pavement characteristics and environmental factors. The most important performance characteristics of a pavement are its ability to bear traffic loads and its ability to provide a smooth ride. However, there is no unambiguous approach to directly measure these performance characteristics. Therefore, we consider pavement performance to be unobservable. The problem of designing pavement deterioration models is the problem of defining the above unobservable characteristics in terms of what is observed, i.e., in terms of measured extents and severities of different damage components. The methodology presented in this paper describes a statistical technique to estimate latent pavement performance from observed pavement damage. No constraints are placed on the number or type of measurements required, so the methodology is flexible enough to include different measurement techniques and data collection strategies. The estimation procedure simultaneously fits a deterioration model and a performance index calibration model to data, thereby producing much better fits to data than traditional deterioration models. The methodology presented in this paper will be useful for deriving more realistic predictive models of pavement deterioration and for defining better data collection strategies.		Moshe E. Ben-Akiva;Rohit Ramaswamy	1993	Transportation Science	10.1287/trsc.27.2.174	simulation;forecasting;engineering;evaluation;mathematical model;methodology;mathematics;transport engineering;forensic engineering;statistics;data collection	AI	13.57797838695601	-10.77573354268841	100810
3935c29c1b45bf44930c457f2cb42fa0c6891824	collision avoidance at intersections: a probabilistic threat-assessment and decision-making system for safety interventions	vehicles prediction algorithms probabilistic logic safety acceleration collision avoidance decision making;examensarbeten;threat assessment;intersections;simulation;head on collisions;crash avoidance systems;decision making algorithms;uppsatser;collision avoidance systems;road traffic control collision avoidance decision making emergency management kalman filters nonlinear filters probability road safety;emergency intervention collision avoidance decision making system safety interventions road intersections accident prone elements modern traffic networks road users active safety system frontal collisions detection probabilistic motion prediction algorithm unscented kalman filter probabilistic threat assessment method reachability based decision making protocol;exjobb;collision avoidance;active safety systems;high risk locations;frontal crashes;studentarbeten	Road intersections are among the most complex and accident-prone elements of modern traffic networks. Thus, new safety systems have to cope with highly complex traffic scenarios where the behavior of the different road users is difficult to predict. Sensing the surrounding environment and assessing possible threats therefore remain challenging problems. This paper provides a novel, efficient active-safety system for frontal collisions detection and prevention/mitigation. More precisely, we provide: (i) a probabilistic motion prediction algorithm based on an unscented Kalman filter; (ii) a probabilistic threat assessment method based on vectors defined by reference points on the vehicles' structure; (iii) a reachability-based decision-making protocol enabling an emergency intervention. Simulation results, based on realistic data obtained specifically for this scenario, are also presented showing the efficiency and the potential of the proposed solution.	algorithm;collision detection;iteration;kalman filter;reachability;real-time computing;sensor;simulation;threat (computer)	Gabriel Rodrigues de Campos;Adam H. Runarsson;Fredrik Granum;Paolo Falcone;Klas Alenljung	2014	17th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2014.6957763	simulation;engineering;transport engineering;computer security	Robotics	10.795533863656257	-11.653351966110291	101133
931dadbb8d4ec332711649e99462fe35fe421439	the simplest evolution/learning hybrid: lem with knn	optimisation;evolutionary computation;pediatrics;learnable evolution model;distance measure;neural nets;prediction algorithms;evolution biology;learning systems;gallium pediatrics evolution biology next generation networking learning systems evolutionary computation prediction algorithms;large scale optimization tasks;optimisation evolutionary computation learning artificial intelligence neural nets;learning mechanism;application specific demand;k nearest neighbour;learning artificial intelligence;large scale optimization tasks learnable evolution model k nearest neighbour learning mechanism evolution learning interface learning based intervention application specific demand;learning based intervention;evolution learning interface;next generation networking;large scale optimization;gallium	The learnable evolution model (LEM) was introduced by Michalski in 2000, and involves interleaved bouts of evolution and learning. Here we investigate LEM in (we think) its simplest form, using k-nearest neighbour as the dasialearningpsila mechanism. The essence of the hybridisation is that candidate children are filtered, before evaluation, based on predictions from the learning mechanism (which learns based on previous populations). We test the resulting dasiaKNNGApsila on the same set of problems that were used in the original LEM paper. We find that KNNGA provides very significant advantages in both solution speed and quality over the unadorned GA. This is in keeping with the original LEM paperpsilas results, in which the learning mechanism was AQ and the evolution/learning interface was more sophisticated. It is surprising and interesting to see such beneficial improvement in the GA after such a simple learning-based intervention. Since the only application-specific demand of KNN is a suitable distance measure (in that way it is more generally applicable than many other learning mechanisms), LEM methods using KNN are clearly recommended to explore for large-scale optimization tasks in which savings in evaluation time are necessary.	k-nearest neighbors algorithm;learnable evolution model;mathematical optimization;oracle advanced queuing;population;software release life cycle	Guleng Sheri;David W. Corne	2008	2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)	10.1109/CEC.2008.4631237	mathematical optimization;simulation;prediction;computer science;artificial intelligence;machine learning;gallium;learnable evolution model;evolutionary computation	Vision	15.154271936673997	-23.798569964011502	101343
0f34a93558ae9ca748309c53d3d5676b44a7f8fe	cooperative multi-agent reinforcement learning based on online heuristic extraction	policy iteration multi agent reinforcement learning heuristic policy cooperative;learning process;approximate algorithm;multi agent system;multi agent reinforcement learning;reinforcement learning;curse of dimensionality;prior knowledge;approximation algorithms learning systems heuristic algorithms learning joints robots convergence;iterative methods;learning system;control problem;heuristic policy cooperative multiagent reinforcement learning algorithm adaptive decision making online heuristic extraction method;multi agent systems;multi agent systems iterative methods learning artificial intelligence;intelligent system;policy iteration;learning artificial intelligence;cooperative learning;extraction method;acceleration techniques;heuristic algorithm	Reinforcement learning has been an important technique for adaptive decision-making of multi-agent systems in uncertain environments. However, the curse of dimensionality in multi-agent reinforcement learning usually causes the slow learning convergence or even failure. In this paper, a novel Online Heuristics Extraction method, which can integrate the prior heuristic policy with a learned heuristic policy, is presented. The new method can be incorporated into a tabular or approximate cooperative multi-agent reinforcement learning algorithm so as to speed up the learning process. Simulation results on a cooperative learning task show that, with the new method, a much better learning convergence can be achieved.	approximation algorithm;curse of dimensionality;heuristic;multi-agent system;reinforcement learning;simulation;table (information)	Jun Wu;Xin Xu;Zhenping Sun;Yan Huang	2011	2011 Seventh International Conference on Natural Computation	10.1109/ICNC.2011.6022301	temporal difference learning;semi-supervised learning;unsupervised learning;proactive learning;multi-task learning;instance-based learning;mathematical optimization;error-driven learning;algorithmic learning theory;computer science;artificial intelligence;online machine learning;machine learning;learning classifier system;stability;reinforcement learning;active learning;hyper-heuristic;q-learning;generalization error	ML	18.859949857103054	-20.317972652264782	101439
881a8ad4c51c5f6b4a3c30310ef74c1a24a9b415	impact of driving behavior on traffic delay at a congested signalized intersection	signalized traffic intersections timed petri nets cell transmission model driving behavior traffic delay;vehicles delays petri nets roads safety microscopy vehicle dynamics	This paper proposes a methodology to categorize drivers’ behaviors at a congested signalized intersection. As a discrete event system model, timed Petri nets (TPNs) are used in this paper to formally define two kinds of behaviors: non-jam-induced driving behavior and jam-induced one. In order to systematically assess the performances of both behaviors, a new urban traffic network model is built: a cell transmission model is used to depict the road link traffic that is consistent with the kinematic property of traffic flow, and TPNs are used to model the behaviors and the conflicting traffic flow at the intersection. Some simulation results are given to evaluate the impact of driving behavior on the traffic delay.	categorization;formal language;jam;network model;performance;petri net;simulation	Liang Qi;Mengchu Zhou;Wenjing Luan	2017	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2016.2613598	simulation;computer science;automotive engineering;transport engineering	Embedded	10.757156639786945	-11.101739465458158	101560
f7252c83dc95439664160f1186920b4d68a3eecd	multivariate statistical process control using enhanced bottleneck neural network	benchmark simulation model no 1 bsm1;adaptive confidence limit acl;multivariate statistical process control mspc;gaussian mixture model gmm;bottleneck neural network bnn;wastewater treatment plant wwtp	Abstract: Monitoring process upsets and malfunctions as early as possible and then finding and removing the factors causing the respective events is of great importance for safe operation and improved productivity. Conventional process monitoring using principal component analysis (PCA) often supposes that process data follow a Gaussian distribution. However, this kind of constraint cannot be satisfied in practice because many industrial processes frequently span multiple operating states. To overcome this difficulty, PCA can be combined with nonparametric control charts for which there is no assumption need on the distribution. However, this approach still uses a constant confidence limit where a relatively high rate of false alarms are generated. Although nonlinear PCA (NLPCA) using autoassociative bottle-neck neural networks plays an important role in the monitoring of industrial processes, it is difficult to design correct monitoring statistics and confidence limits that check new performance. In this work, a new monitoring strategy using an enhanced bottleneck neural network (EBNN) with an adaptive confidence limit for non Gaussian data is proposed. The basic idea behind it is to extract internally homogeneous segments from the historical normal data sets by filling a Gaussian mixture model (GMM). Based on the assumption that process data follow a Gaussian distribution within an operating mode, a local confidence limit can be established. The EBNN is used to reconstruct input data and estimate probabilities of belonging to the various local operating regimes, as modelled by GMM. An abnormal event for an input measurement vector is detected if the squared prediction error (SPE) is too large, or above a certain threshold which is made adaptive. Moreover, the sensor validity index (SVI) is employed successfully to identify the detected faulty variable. The results demonstrate that, compared with NLPCA, the proposed approach can effectively reduce the number of false alarms, and is hence expected to better monitor many practical processes.	artificial neural network;chart;google map maker;mixture model;nonlinear system;principal component analysis	Khaled Bouzenad;Messaoud Ramdani	2017	Algorithms	10.3390/a10020049	econometrics;mathematical optimization;machine learning;algorithm;statistics	ML	14.032893025520144	-15.957555635824667	101845
ca3368ef42c9b27ba598739b139d7d05d313bc08	application of regression and artificial neural network analysis in modelling of tool-chip interface temperature in machining	machining;levenberg marquardt;lms algorithm;predictive value;temperature prediction;temperature dependence;chip;coefficient of determination;regression analysis;machine tool;tool chip interface temperature;artificial neural network	In this paper, the regression analysis (RA) and artificial neural network (ANN) are presented for the prediction of tool-chip interface temperature depends on cutting parameters in machining. The RA and ANN model for prediction tool-chip interface temperature are developed and mathematical equations derived for tool-chip interface temperature prediction are obtained. The tool-chip interface temperature results obtained from mathematical equations with RA and ANN model and the experimental results available in the literature obtained by using AISI 1117 steel work piece with embedded K type thermocouple into the uncoated cutting tool (Korkut, Boy, Karacan, & Seker, 2007) are compared. The coefficient of determination (R^2) both training and testing data for temperature prediction in the ANN model are determined as 0.999791289 and 0.997889303 whereas; R^2 for both training and testing data in the RA model are computed as 0.999063 and 0.999427, respectively. The correlation obtained by the training ANN model are better than the one obtained by training RA model. The training ANN model with the Levenberg-Marquardt (LM) algorithm provides more accurate prediction and is quite useful in the calculation of tool-chip interface temperature when compared with the trained RA method in machining. On the other hand, prediction values obtained the testing RA model is slightly better performance than the testing ANN model. The results show that the tool-chip interface temperature equation derived from RA and ANN model can be used for prediction.	artificial neural network	Ihsan Korkut;Adem Acir;Mehmet Boy	2011	Expert Syst. Appl.	10.1016/j.eswa.2011.03.044	chip;levenberg–marquardt algorithm;least mean squares filter;machining;computer science;artificial intelligence;machine tool;machine learning;coefficient of determination;artificial neural network;regression analysis	AI	12.628583257150863	-20.020002581355453	101906
44fe9e7f22f8986d48e3753543792d28b0494db0	eligibility traces for off-policy policy evaluation	temporal difference;data stream;policy evaluation;monte carlo method;statistical techniques;importance sampling;monte carlo	Eligibility traces have been shown to speed reinforcement learning, to make it more robust to hidden states, and to provide a link between Monte Carlo and temporal-difference methods. Here we generalize eligibility traces to off-policy learning, in which one learns about a policy different from the policy that generates the data. Off-policy methods can greatly multiply learning, as many policies can be learned about from the same data stream, and have been identified as particularly useful for learning about subgoals and temporally extended macro-actions. In this paper we consider the off-policy version of the policy evaluation problem, for which only one eligibility trace algorithm is known, a Monte Carlo method. We analyze and compare this and four new eligibility trace algorithms, emphasizing their relationships to the classical statistical technique known asimportance sampling . Our main results are 1) to establish the consistency and bias properties of the new methods and 2) to empirically rank the new methods, showing improvement over one-step and Monte Carlo methods. Our results are restricted to model-free, table-lookup methods and to offline updating (at the end of each episode) although several of the algorithms could be applied more generally.	algorithm;lookup table;monte carlo method;nyquist–shannon sampling theorem;online and offline;reinforcement learning;sampling (signal processing);tracing (software)	Doina Precup;Richard S. Sutton;Satinder P. Singh	2000			temporal difference learning;monte carlo method in statistical physics;econometrics;computer science;data mining;mathematics;statistics;monte carlo method	ML	23.349045650966104	-19.67403845551017	101911
45b7ce42faf726554e73cc35cad14216365f3ea6	application of game tree searching techniques to sequential pattern recognition	dynamic programming;optimal solution;dynamic program;branch and bound approach;miniaverage backing up procedure;game tree searching;sequential pattern recognition;game against nature;game tree search;sequential pattern;gamma procedure;game playing;branch and bound;computer simulation;character recognition;medical diagnosis	A sequential pattern recognition (SPR) procedure does not test all the features of a pattern at once. Instead, it selects a feature to be tested. After receiving the result of that test, the procedure either classifies the unknown pattern or selects another feature to be tested, etc. Medical diagnosis is an example of SPR. In this paper the authors suggest that SPR be viewed as a one-person game played against nature (chance). Virtually all the powerful techniques developed for searching two-person, strictly competitive game trees can easily be incorporated either directly or by analogy into SPR procedures. In particular, one can incorporate the “miniaverage backing-up procedure” and the “gamma procedure,” which are the analogues of the “minimax backing-up procedure” and the “alpha-beta procedure,” respectively. Some computer simulated experiments in character recognition are presented. The results indicate that the approach is promising.	branch and bound;computer simulation;dynamic programming;experiment;heuristic;minimax;optical character recognition;pattern recognition;tree rearrangement	James R. Slagle;Richard C. T. Lee	1971	Commun. ACM	10.1145/362515.362562	computer simulation;computer science;artificial intelligence;machine learning;dynamic programming;medical diagnosis;branch and bound;algorithm	Vision	18.682704794565595	-12.726602665903341	102257
33485f34e27c82d83f6698e6ff9894453999057c	a novel support vector regression method for online reliability prediction under multi-state varying operating conditions		Abstract Modeling the evolution of system reliability in the presence of Condition Monitoring (CM) signals is an important issue for improved reliability assessment and system lifetime prediction. In practice, during its lifetime, a system usually works under varying operating conditions due to internal or external factors such as the ambient environments, operational profiles or workloads. In this context, the system reliability can show varying evolution behaviors (follow changing underlying trajectories), which presents new challenges to describe precisely the dynamics of system reliability. Thus, this paper proposes a novel data-driven approach to address the problems including the identification of varying operating conditions, the construction and dynamical updating of evolution model, and finally the online prediction of system reliability, focusing on systems under one common and typical case of varying operating conditions, the multi-state operating condition. Experiments based on artificial data and some widely studied real reliability cases reveal that the proposed method has superior performance compared with some existing benchmark approaches, in the case under consideration. This improved reliability prediction provides fundamental basis for advanced prognostics such as the Remaining Useful Life (RUL) estimation.	support vector machine	Tao Tao;Enrico Zio;Wei Zhao	2018	Rel. Eng. & Sys. Safety	10.1016/j.ress.2018.04.027	engineering;support vector machine;reliability engineering;condition monitoring;prognostics;particle filter	ML	14.510831898325636	-15.251278908574033	102755
2cc879d90236743ad227b0e88a1f5f52a6603909	tree-based batch mode reinforcement learning	regression tree;ensemble method;supervised learning;random tree;reinforcement learning;value iteration;optimal control;fitted q iteration;ensemble of regression trees;fitted value iteration;batch mode reinforcement learning	Reinforcement learning aims to determine an optimal contro l policy from interaction with a system or from observations gathered from a system. In batch mode, i t can be achieved by approximating the so-calledQ-function based on a set of four-tuples (xt ,ut , rt ,xt+1) wherext denotes the system state at timet, ut the control action taken, rt the instantaneous reward obtained and xt+1 the successor state of the system, and by determining the contro l policy from this Q-function. The Q-function approximation may be obtained from the limit of a s equence of (batch mode) supervised learning problems. Within this framework we describe the use of several classical tree-based supervised learning methods (CART, Kd-tree, tree bagging) a d two newly proposed ensemble algorithms, namelyextremelyandtotally randomized trees. We study their performances on several examples and find that the ensemble methods based on regressi on trees perform well in extracting relevant information about the optimal control policy from sets of four-tuples. In particular, the totally randomized trees give good results while ensuring the convergence of the sequence, whereas by relaxing the convergence constraint even better accurac y results are provided by the extremely randomized trees.	approximation;batch processing;decision tree learning;ensemble learning;optimal control;performance;randomized algorithm;reinforcement learning;supervised learning	Damien Ernst;Pierre Geurts;Louis Wehenkel	2005	Journal of Machine Learning Research		markov decision process;mathematical optimization;optimal control;computer science;machine learning;decision tree;pattern recognition;ensemble learning;supervised learning;reinforcement learning;statistics	ML	22.261343048952252	-18.300817702164125	102869
d7efdd18dfe266d013e816bf303e9d218cc12a59	a cellular automata model for adaptive sympatric speciation	modelizacion;metodo adaptativo;paysage;paisaje;methode adaptative;biology;biologia;modelisation;habitat;evolutionary biology;habitat structure;automate cellulaire;adaptive method;algorithme evolutionniste;algoritmo evolucionista;sympatric speciation;evolutionary algorithm;landscape;cellular automata;modeling;cellular automaton;biologie;new specie;automata celular	The emergence of new species is one of the trickiest issues of evolutionary biology. We propose a cellular automata model to investigate the possibility that speciation proceeds in sympatry, focusing on the importance of the structure of the landscape on the likelihood of speciation. The conditions for speciation are shown to be limited whatever the landscape being considered, although habitat structure best favours the emergence of new species.	automata theory;cellular automaton;emergence;habitat	Samira El Yacoubi;Sébastien Gourbière	2006		10.1007/11861201_34	cellular automaton;systems modeling;habitat;computer science;incipient speciation;landscape;sympatric speciation;heteropatric speciation;algorithm;ecological speciation	AI	23.068832868327288	-12.106765407943941	103069
9aecc1b6e85eed674389102172bf694d2638d7f3	reinforcement learning to train ms. pac-man using higher-order action-relative inputs	arcade video game ms pac man train ms pac man higher order action relative inputs reinforcement learning algorithms open research question dynamic environments smart feature extraction algorithms game state q learning neural network;neural nets;games learning artificial intelligence biological neural networks neurons heuristic algorithms training;feature extraction;neural nets computer games feature extraction learning artificial intelligence;learning artificial intelligence;computer games	Reinforcement learning algorithms enable an agent to optimize its behavior from interacting with a specific environment. Although some very successful applications of reinforcement learning algorithms have been developed, it is still an open research question how to scale up to large dynamic environments. In this paper we will study the use of reinforcement learning on the popular arcade video game Ms. Pac-Man. In order to let Ms. Pac-Man quickly learn, we designed particular smart feature extraction algorithms that produce higher-order inputs from the game-state. These inputs are then given to a neural network that is trained using Q-learning. We constructed higher-order features which are relative to the action of Ms. Pac-Man. These relative inputs are then given to a single neural network which sequentially propagates the action-relative inputs to obtain the different Q-values of different actions. The experimental results show that this approach allows the use of only 7 input units in the neural network, while still quickly obtaining very good playing behavior. Furthermore, the experiments show that our approach enables Ms. Pac-Man to successfully transfer its learned policy to a different maze on which it was not trained before.	algorithm;arcade game;artificial neural network;experiment;feature extraction;interaction;machine learning;open research;q-learning;reinforcement learning	Luuk Bom;Ruud Henken;Marco Wiering	2013	2013 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)	10.1109/ADPRL.2013.6615002	error-driven learning;simulation;computer science;artificial intelligence;machine learning;learning classifier system;reinforcement learning;artificial neural network;q-learning	ML	18.23601679346684	-20.680172918381448	103192
e87587f1818988d20ac97153da3b90dd7c8b841a	assessment of probabilistic parameters of alarm security detectors taking uncertain noise into account	false alarm;detectors;noise alarm systems detectors estimation fuzzy sets optimization;optimization alarm system detectors false alarm fuzzy logic;sensors;measurement uncertainty;fuzzy sets probabilistic parameter alarm security detector uncertain noise assessment detector false alarm;fuzzy set theory;fuzzy sets;alarm system;fuzzy logic;estimation;optimization;alarm systems;measurement errors;sensors alarm systems fuzzy set theory measurement errors measurement uncertainty;noise	A method for assessment detector's false alarm and fault was developed. It includes the assessments of noise intensity barriers and detector's vulnerability to them using fuzzy sets and their defuzzification. It allows considering different environmental influences that may cause improper functioning of the alarm systems.	defuzzification;fuzzy set;pareto efficiency;sensor;vulnerability (computing)	Pavlo E. Bykovy;Yuriy Pigovsky;Volodymyr Kochan;Nadiya Vasylkiv;Andriy F. Karachka	2011	Proceedings of the 6th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems	10.1109/IDAACS.2011.6072864	computer science;machine learning;pattern recognition;data mining;mathematics;fuzzy set;statistics	Robotics	14.728554706176961	-13.908616271897289	103312
0920d9704cfecc5f101a85072fa79acad4558011	rul prediction based on a new similarity-instance based approach	similarity measures prognostics rul prediction instance based learning;remaining life assessment condition monitoring failure analysis fault diagnosis jet engines learning artificial intelligence maintenance engineering mechanical engineering computing reliability;turbofan data set rul prediction rul estimation remaining useful life similarity instance based approach condition based maintenance cbm prognostics approach instance based learning ibl degradation behavior run to failure data history;trajectory degradation data models libraries engines maintenance engineering mathematical model	Prognostics is a major activity of Condition-Based Maintenance (CBM) in many industrial domains where safety, reliability and cost reduction are of high importance. The main objective of prognostics is to provide an estimation of the Remaining Useful Life (RUL) of a degrading component/ system, i.e. to predict the time after which a component/system will no longer be able to meet its operating requirements. This RUL prediction is a challenging task that requires special attention when modeling the prognostics approach. In this paper, we proposes a RUL prediction approach based on Instance Based Learning (IBL) with an emphasis on the retrieval step of the latter. The method is divided into two steps: an offline and an online step. The purpose of the offline phase is to learn a model that represents the degradation behavior of a critical component using a history of run-to-failure data. This modeling step enables us to construct a library of health indicators (HI's) from run-to-failure data which are then used online to estimate the RUL of components at an early stage of life, by comparing their HI's to the ones of the library built in the offline phase. Our approach makes use of a new similarity measure between HIs. The proposed approach was tested on real turbofan data set and showed good performance compared to other existing approaches.	algorithm;complexity;elegant degradation;nonlinear system;online and offline;preprocessor;requirement;similarity measure	Racha Khelif;Simon Malinowski;Brigitte Chebel-Morello;Noureddine Zerhouni	2014	2014 IEEE 23rd International Symposium on Industrial Electronics (ISIE)	10.1109/ISIE.2014.6865006	reliability engineering;engineering;data science;data mining	Robotics	14.315382875314947	-15.732980165063564	103540
ef09cf3a0342d9b618e07d2e5e885e01b566b24e	cyclic reproduction scheme in genetic algorithm for evolutionary game	teleenseignement;game theory;search space;divertissement;teoria juego;theorie jeu;algoritmo genetico;evolutionary game;algorithme genetique;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;teleensenanza;evolutionary algorithm;remote teaching;entertainment	This paper describes how Genetic Algorithm can be used to control the level of difficulty in a game based on a user's skill. An algorithm is proposed to control the difficulty of a game according to user's propensity in our previous work [1], [2]. But the searching spaces are very narrow and convergence of chromosomes is also slow because the game progresses step-by-step and chromosomes are evaluated simultaneously while playing the game. Thus, a method is presented to expand the searching spaces and converge quickly on the Genetic Algorithm in the domain of sequential progress.	genetic algorithm	Sang-Won Um;Suk-Han Lee;TaeYong Kim;Jong-Soo Choi	2006		10.1007/11736639_76	game theory;entertainment;simulation;genetic algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm;advertising;normal-form game;algorithmic game theory;sequential game;game complexity;algorithm	AI	24.13378964853313	-11.32519065260177	103559
a0f6628c444606502e4081ad8df15974d966eb2d	learning all optimal policies with multiple criteria	reinforcement learning;multiple criteria;optimal policy;value iteration;proof of correctness	We describe an algorithm for learning in the presence of multiple criteria. Our technique generalizes previous approaches in that it can learn optimal policies for all linear preference assignments over the multiple reward criteria at once. The algorithm can be viewed as an extension to standard reinforcement learning for MDPs where instead of repeatedly backing up maximal expected rewards, we back up the set of expected rewards that are maximal for some set of linear preferences (given by a weight vector, w). We present the algorithm along with a proof of correctness showing that our solution gives the optimal policy for any linear preference function. The solution reduces to the standard value iteration algorithm for a specific weight vector, w.	algorithm;backup;correctness (computer science);iteration;iterative method;markov decision process;maximal set;reinforcement learning	Leon Barrett;Srini Narayanan	2008		10.1145/1390156.1390162	markov decision process;mathematical optimization;discrete mathematics;computer science;artificial intelligence;machine learning;mathematics;reinforcement learning;q-learning	ML	22.01207636998225	-16.53840304585202	103597
f4eea8d540c37173a5ec24a2d28601f4409e5019	software design of intelligent solar drying system for agricultural and sideline products	computers;algorithm design solar drying software design monitoring system;storage tanks;monitoring;humidity;artificial intelligence;temperature measurement;man machine interface software design intelligent solar drying system agricultural products sideline products solar energy computer measurement control subsystem binary table lookup algorithm tank water temperature detection program flow host computer monitoring subsystem system database communication mechanism host computer communication module;temperature distribution;temperature control agricultural products control engineering computing drying power engineering computing solar power table lookup;computers temperature measurement humidity storage tanks monitoring artificial intelligence temperature distribution	Solar energy is renewable energy which can be used in the drying of agricultural and sideline products. The lower computer measurement and control subsystem is designed and the improved binary table lookup algorithm is designed to realize the tank water temperature detection. The main program flow is demonstrated, furthermore, the host computer monitoring subsystem is constructed, in which the system database and communication mechanism are designed, and the algorithm design of host computer communication module is demonstrated. The man-machine interface is quite friendly for the user. Using this solar dring system, some drying experiments for longan and red pepper are done. Experiments show that the drying system can run reliably, therefore, software design of the intelligent solar drying system is effective.	algorithm design;computer and network surveillance;control flow;entry point;experiment;host (network);lookup table;software design;user interface	Sijie Ouyang;Jianping Chen;Qijun Xiao;Shun Cheng	2014	2014 13th International Conference on Control Automation Robotics & Vision (ICARCV)	10.1109/ICARCV.2014.7064354	control engineering;embedded system;storage tank;simulation;temperature measurement;engineering;artificial intelligence;humidity	Robotics	15.465848837519443	-12.841428456409373	103743
0c0e6577d5c646a78c1f0ed31b131913dcb81d0a	signal processing for a laser based air data system in commercial aircrafts	real time data;design and implementation;signal processing;weather condition	A systematic approach for the design and implementation of an efficient and reliable signal processing unit able to provide vital flight parameters to the cockpit of an aircraft using a properly built LIDAR equipment is presented in this paper. Taking into account the specific characteristics of a signal coming out from such an optical device we define all the necessary steps for the real-time data acquisition and processing in order to extract accurate information about the true air speed (TAS) of the aircraft and other useful flight parameters. Simulation results using properly modeled signals verified the effectiveness of the suggested methodology. The proposed scheme is being developed in the framework of the EU funded NESLIE research project and aims to be finally flight tested in order to demonstrate the availability of accurate measurements in all weather conditions and in any phase of flight.	algorithm;data acquisition;data system;real-time clock;real-time data;signal processing;simulation;thermal-assisted switching	Theodoros Katsibas;Theodoros Semertzidis;Xavier Lacondemine;Nikolaos Grammalidis	2008	2008 16th European Signal Processing Conference		embedded system;real-time computing;simulation;engineering	Robotics	15.53978163843949	-11.738879987037883	103944
3d54bc83ae0592692b48d554abba36612d119d60	an evolutionary behavior tool for reactive multi-agent systems	dynamic change;distributed system;multiagent system;systeme reparti;multi agent system;autonomous system;sistema autonomo;sistema reactivo;sistema repartido;autonomous agent;distributed artificial intelligence;systeme autonome;reactive system;systeme reactif;algorithme evolutionniste;algoritmo evolucionista;evolutionary algorithm;sistema multiagente;artificial life;simulation environment;systeme multiagent	Multi-agent Systems (MAS) are a sub-area of Distributed Artificial Intelligence which focus on the study of autonomous agents and their actions in an environment. This paper presents a simulation environment for Reactive Multi-agent Systems called Simula++, where an evolutionary algorithm can modify the set of behavior rules of each agent. Our major goal is to define and develop a model to dynamically change the agents' behavior in order to adapt the agents to their environment. In the Simula++ environment, an user can define a Reactive MAS where the predefined rules set of each agent can be modified to create new rules during simulation. That would happen through the precepts of Artificial Life and Evolutionary Algorithms.	multi-agent system	Andre Zanki Cordenonsi;Luis Otávio Alvares	2002		10.1007/3-540-36127-8_32	simulation;reactive system;computer science;autonomous system;artificial intelligence;autonomous agent;evolutionary algorithm;multi-agent system;artificial life	Robotics	23.10644865372148	-11.204789163049687	103972
7fde44d28015abb385fd42d1822b892cef3325a9	research and application of summer high temperature prediction model based on cart algorithm		In this paper, the average summer high temperature effective accumulated for many years is used as a judge of the extent of the hot summer temperatures of standards. Based on data mining, the CART algorithm is applied to analyze the relationship between high temperature and some climatic factors such as the East Asian summer monsoon index, summer India Burma trough, the summer North Atlantic Oscillation (NAO), Equatorial Pacific sea surface temperature and so on. The high-temperature forecasting model is established with the setup of the high temperature prediction rules. The data of summer maximum temperature in summer in Zhangzhou, Fujian Province from 1955 to 2012 are selected to calculate the summer hot temperature of 58a. Then, multiple climatic factor data of the same period is given to the input variable, and 46 years of data is randomly selected to get 10 classifications of rule sets, resulting in the achievement of the accuracy rate to 91.49%. With the remaining data of 12a test, the accuracy rate reaches 91.67%. In general, the results of this paper validate the feasibility and validity of the high temperature prediction model, and provide a new idea for the study of the catastrophic weather model.	algorithm;decision tree learning	Yujie Guan;Wei Wang;Fengchang Xue;Shoudong Liu	2017		10.1007/978-3-319-72823-0_30	algorithm;environmental science;hot temperature;trough (meteorology);monsoon;sea surface temperature;north atlantic oscillation;cart	NLP	10.363034592922714	-19.00676248104299	103981
cc82b74a6f8eb35e10646dafa9507805d333ccc0	cooperative and competitive reinforcement and imitation learning for a mixture of heterogeneous learning modules	entropy-regularization;imitation learning;modular architecture;multiple importance sampling;parallel learning;reinforcement learning	This paper proposes Cooperative and competitive Reinforcement And Imitation Learning (CRAIL) for selecting an appropriate policy from a set of multiple heterogeneous modules and training all of them in parallel. Each learning module has its own network architecture and improves the policy based on an off-policy reinforcement learning algorithm and behavior cloning from samples collected by a behavior policy that is constructed by a combination of all the policies. Since the mixing weights are determined by the performance of the module, a better policy is automatically selected based on the learning progress. Experimental results on a benchmark control task show that CRAIL successfully achieves fast learning by allowing modules with complicated network structures to exploit task-relevant samples for training.	algorithm;benchmark (computing);genetic heterogeneity;learning disorders;network architecture;policy;reinforcement learning;weight	Eiji Uchibe	2018		10.3389/fnbot.2018.00061	machine learning;artificial intelligence;computer science;imitation;reinforcement	ML	19.01069777221146	-21.257573439891036	104037
fcfd4386bfee79258c82a5579efe1e079cb0bd1e	learning to compose fuzzy behaviors for autonomous agents	reinforcement learning;fuzzy control;fuzzy logic controller;autonomous agent;evolutionary algorithm	In this paper, we present SELF , an evolutionary algorithm that we have developed to learn the context of activation of fuzzy logic controllers implementing fuzzy behaviors for autonomous agent. SELF learns context metarules that are used to coordinate basic behaviors in order to perform complex tasks in a partially and imprecisely known environment. Context metarules are expressed in terms of positive and negated fuzzy predicates. We also show how SELF can learn robust and portable behaviors, thus reducing the time and eeort to design behavior-based agents .	autonomous agent;autonomous robot;evolutionary algorithm;fuzzy logic;self	Andrea Bonarini;Filippo Basso	1997	Int. J. Approx. Reasoning	10.1016/S0888-613X(97)00002-9	computer science;artificial intelligence;autonomous agent;neuro-fuzzy;machine learning;evolutionary algorithm;reinforcement learning;fuzzy control system	AI	22.620104700691996	-12.85068455567633	104302
92b1d3ea1198c07cf624bac6aef7df93e7e45765	experience generalization for concurrent reinforcement learners: the minimax-qs algorithm	rate of convergence;learning algorithm;minimax q;reinforcement learning;state dependence;optimal control;markov games;experience generalization;convergence to equilibrium;robot soccer	This paper investigates the use of experience generalization on concurrent and on-line policy learning in multi-agent scenarios, using reinforcement learning algorithms. Agents learning concurrently implies in a non-stationary scenario, since the reward received by one agent (for applying an action in a state) depends on the behavior of the other agents. Non-stationary scenarios can be viewed as a two-player game in which an agent and the other player (which represents the other agents and the environment) select actions from the available actions in the current state; these actions define the possible next state. An RL algorithm that can be applied to such a scenario is the Minimax-Q algorithm, which is known to guarantee convergence to equilibrium in the limit. However, finding optimal control policies using any RL algorithm Minimax-Q included) can be very time consuming. We investigate the use of experience generalization for increasing the rate of convergence of RL algorithms, and contribute a new learning algorithm, Minimax-QS, which incorporates experience generalization to the Minimax-Q algorithm. We also prove its convergence to Minimax-Q values under suitable conditions.	algorithm;machine learning;minimax;multi-agent system;online and offline;optimal control;rate of convergence;reinforcement learning;stationary process	Carlos H. C. Ribeiro;Renê Pegoraro;Anna Helena Reali Costa	2002		10.1145/545056.545106	mathematical optimization;error-driven learning;optimal control;computer science;artificial intelligence;machine learning;rate of convergence;reinforcement learning;generalization error	AI	20.838088369803017	-18.915998644339385	104380
41af63634d1d092a0275bc499931199c6cfa4385	autonomous reinforcement of behavioral sequences in neural dynamics	continuous systems;robot learning autonomous reinforcement behavioral sequence dn sarsa λ model computational learning algorithm continuous neural dynamical model autonomous learning continuous environment dynamic environment learning problem discretized space sensory motor dynamics;robots continuous systems learning artificial intelligence learning systems neurocontrollers;artificial intelligence not elsewhere classified;learning systems;robots;neurocontrollers;learning artificial intelligence;robot sensing systems image color analysis computational modeling learning vehicles cameras	The DN-SARSA(λ) model provides a framework which shows how computational learning algorithms can be incorporated into a continuous neural-dynamical model. This enables autonomous learning and acting in continuous and dynamic environments, a challenge that is easily overlooked when formalizing the learning problem in discretized spaces without accounting for their coupling to sensory-motor dynamics.	action selection;algorithm;autonomous robot;computation;discretization;machine learning;organizing (structure)	Sohrob Kazerounian;Matthew D. Luciw;Mathis Richter;Yulia Sandamirskaya	2012	2012 IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL)	10.1109/DevLrn.2012.6400831	unsupervised learning;robot;robot learning;instance-based learning;error-driven learning;simulation;wake-sleep algorithm;computer science;artificial intelligence;machine learning;learning classifier system;competitive learning;computational learning theory;reinforcement learning;active learning;hyper-heuristic;artificial neural network	Robotics	18.926589341971145	-22.72161545345755	104403
3125a3bebe53535e7893440caa7cb77b01acf257	structure learning methods for bayesian networks to reduce alarm floods by identifying the root cause		In times of increasing connectivity, complexity and automation safety is also becoming more demanding. As a result of these developments, the number of alarms for the individual operator increases and leads to mental overload. This overload caused by alarm floods is an enormous safety risk. By reducing this risk, it is not only possible to increase the safety for humans and machines, but also to correct the failure at an early stage. This saves money and reduces outage time. In this paper we present an approach using a Bayesian network to identify the root cause of an alarm flood. The root cause is responsible for a sequence of alarms. The causal dependencies between the alarms are represented with a Bayesian network, which serves as a causal model. Based on this causal model the root cause of an alarm flood can be determined using inference. There exist different methods to learn the structure of a Bayesian network. To investigate which method suites the best for the purpose of alarm flood reduction, one algorithm from each method is selected. We evaluated these algorithms with a dataset, which is recorded from a demonstrator of a manufacturing plant in the SmartFactoryOWL.	algorithm;bayesian network;care-of address;causal filter;causal model;computation;downtime;flood;multiple-alarm fire;time complexity;transfer entropy	Paul Wunderlich;Oliver Niggemann	2017	2017 22nd IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)	10.1109/ETFA.2017.8247692	real-time computing;automation;causal model;operator (computer programming);reliability engineering;alarm;bayesian network;engineering;root cause;inference	Robotics	12.587076335993919	-13.473357011678088	104538
af3103a750ab88d4903bcfe264aaf7d74090f8ed	evolving behaviour trees for the mario ai competition using grammatical evolution	genetic program;conference publication;mario;dynamic game;evolutionary programming;dynamic system;artificial intelligent;ai competition;grammatical evolution;behaviour trees;type system	This paper investigates the applicability of Genetic Programming type systems to dynamic game environments. Grammatical Evolution was used to evolve Behaviour Trees, in order to create controllers for the Mario AI Benchmark. The results obtained reinforce the applicability of evolutionary programming systems to the development of artificial intelligence in games, and in dynamic systems in general, illustrating their viability as an alternative to more standard AI techniques.	algorithm;and–or tree;artificial intelligence;benchmark (computing);crossover (genetic algorithm);dynamical system;evolutionary programming;genetic programming;grammatical evolution;high- and low-level;hybrid system;iterative and incremental development;motion planning;obstacle avoidance;type system	Diego Perez Liebana;Miguel Nicolau;Michael O'Neill;Anthony Brabazon	2011		10.1007/978-3-642-20525-5_13	simulation;computer science;artificial intelligence;algorithm	AI	23.058923044674188	-10.24434301817449	104635
34c5ee99ad2dedb64a712e26195c65a07a4f28e6	bilateral lstm: a two-dimensional long short-term memory model with multiply memory units for short-term cycle time forecasting in re-entrant manufacturing systems		Forecasting short-term cycle time (CT) of wafer lots is crucial for production planning and control in the wafer manufacturing. A novel recurrent neural network called “bilateral long short-term memory (bilateral LSTM)” is proposed to model a short-term cycle time forecasting (CTF) of each re-entrant period of a wafer lot. First, a two-dimensional (2-D) architecture is designed to transmit the wafer and layer correlations by using wafer and layer connections. Subsequently, aiming to store various error signals caused by the diverse CT data, a multiply memory structure is presented to extend the capacity of constant error carousel (CEC) in the LSTM model. The experiment results indicate that the proposed model outperforms conventional models in the accuracy and stability for the short-term CTF. Further comparative experiments reveal that the 2-D architecture can enhance the prediction accuracy and the multi-CEC structure can improve the forecasting stability for the short-term CTF of wafer lots.	artificial neural network;bilateral filter;charge trap flash;experiment;long short-term memory;magnetic-core memory;recurrent neural network;wafer (electronics)	Junliang Wang;Jie Zhang;Xiaoxi Wang	2018	IEEE Transactions on Industrial Informatics	10.1109/TII.2017.2754641	data modeling;real-time computing;long short term memory;computer science;architecture;semiconductor device modeling;wafer;recurrent neural network	Robotics	13.484621035514026	-18.75551024589846	104823
54d029fb6b85160623f20b5aba5dfc214c067027	on error measures in wind forecasting evaluations	wind power;forecasting theory;wind forecasting forecasting wind power generation measurement uncertainty wind speed predictive models biological system modeling;wind power forecasting theory power grids;power grids;wind power forecasting forecasting error measures timing error;error assessment error measures wind power forecasting evaluations environmentally friendly source wind speed large scale wind power integration grid challenging	Wind power is utilized as an environmentally friendly source of bulk electricity. However, large variations of wind speed and subsequently wind power, makes large-scale wind power integration into the grid challenging. Forecasting wind power generation is one of the methods to cope with this issue. Hence, a large variety of different forecasting models are developed in the literature. Since all of forecasts have inherent errors, the procedure of error assessment of forecasting models is important. In this paper, we discuss recent wind forecasting works with a focus on their error assessment criteria. A review of the literature is provided and most common error measures are studied.		Hamid Shaker;Hamidreza Zareipour;David Wood	2013	2013 26th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2013.6567687	wind power;probabilistic forecasting;simulation;engineering	Visualization	10.075228666783707	-17.099612002515972	104902
2a20dcfa9cc905b0dd944715b4a35f4fc5c088ee	nonlinear multi-input multi-output system identification using neuro-evolutionary methods for a quadcopter		This research focuses on studying the effect of using evolutionary algorithms in improving neural network capabilities in identification of non-linear multi-input and multi-output dynamic systems such as a quadcopter. In addition, comparison of the different neural network based approaches is carried out in order to reveal the variations among the different methods. The results show that using evolutionary algorithms in training a neural network enhanced the system identification accuracy. Furthermore, the results show that differential evolution neural networks have promising potential to be used in multi-input multi-output system identification.	artificial neural network;differential evolution;dynamical system;evolutionary algorithm;nonlinear system;system identification	Ahmad Jobran Al-Mahasneh;S. G. Anavatu;Matthew A. Garratt	2017	2017 Ninth International Conference on Advanced Computational Intelligence (ICACI)	10.1109/ICACI.2017.7974512	genetic algorithm;differential evolution;artificial neural network;evolutionary algorithm;nonlinear system;system identification;machine learning;artificial intelligence;computer science;quadcopter	Robotics	13.633000531756757	-23.475525210739114	105161
a9d3a8bb801026e5b8090e549e817e6744ed3052	anomaly detection and predictive maintenance for photovoltaic systems		We present a learning approach designed to detect possible anomalies in photovoltaic (PV) systems in order to let an operator to plan predictive maintenance interventions. The anomaly detection algorithm presented is based on the comparison between the measured and the predicted values of the AC power production. The model designed to predict the AC power production is based on an Artificial Neural Network (ANN), that is capable of estimating the AC power production using solar irradiance and PV panel temperature measurements, and that is trained using a dataset previously gathered from the plant to be monitored. Live trend data coming from the PV system are then compared with the output of the model and the vector of residuals is analyzed to detect anomalies and generate daily predictive maintenance alerts; there residuals are aggregated over 1-day and processed to detect out-of-threshold samples and system degradation trends; these trends are extracted by computing the Triangular Moving Average (TMA) where the window size is automatically determined. The paper also reports experimental data results revealing that the model leads to a good anomaly detection rate, which is measured as a positive predictive detection rate greater than 90%. Moreover, the algorithm is able to recognize trends of system’s deviations from normal operation behavior and generate predictive maintenance alerts as a decision support system for operatives, with the aim of avoiding possible incoming failures. © 2018 Elsevier B.V. All rights reserved.	algorithm;anomaly detection;artificial neural network;decision support system;elegant degradation;tower mounted amplifier	Massimiliano De Benedetti;Fabio Leonardi;Fabrizio Messina;Corrado Santoro;Athanasios V. Vasilakos	2018	Neurocomputing	10.1016/j.neucom.2018.05.017	anomaly detection;solar irradiance;experimental data;predictive maintenance;artificial intelligence;moving average;artificial neural network;ac power;pattern recognition;mathematics;photovoltaic system	AI	11.990737961366394	-15.490848715783912	105413
9b86c41b35dc494f96459127e458e58590065476	oil pvt characterisation using ensemble systems	reservoirs;support vector machines;prediction algorithms;oils;civil engineering;predictive models;correlation;regression tree analysis	In reservoir engineering, there is always a need to estimate crude oil Pressure, Volume and Temperature (PVT) properties for many critical calculations and decisions such as reserve estimate, material balance design and oil recovery strategy, among others. Empirical correlation are often used instead of costly laboratory experiments to estimate these properties. However, these correlations do not always give sufficient accuracy. This paper develops ensemble support vector regression and ensemble regression tree models to predict two important crude oil PVT properties: bubblepoint pressure and oil formation volume factor at bubblepoint. The developed ensemble models are compared with standalone support vector machine (SVM) and regression tree models, and commonly used empirical correlations. The ensemble models give better accuracy when compared to correlations from the literature and more consistent results than the standalone SVM and regression tree models.		Munirudeen A. Oloso;Mohamed G. Hassan;James Buick;Mohamed Bader-El-Den	2016	2016 International Conference on Machine Learning and Cybernetics (ICMLC)	10.1109/ICMLC.2016.7860878	support vector machine;econometrics;prediction;computer science;machine learning;data mining;predictive modelling;correlation;reservoir	ML	11.670216480512343	-19.06235716448944	105505
596ad8a627ca59a2022e1091263b10db347c97b6	optimal minimax strategy in a dice game	game theory;markov decision process;stochastic games	Each of two players, by turns, rolls a dice several times accumulating the successive scores until he decides to stop, or he rolls an ace. When stopping, the accumulated turn score is added to the player account and the dice is given to his opponent. If he rolls an ace, the dice is given to the opponent without adding any point. In this paper we formulate this game in the framework of competitive Markov decision processes (also known as stochastic games), show that the game has a value, provide an algorithm to compute the optimal minimax strategy, and present results of this algorithm in three different variants of the game.	algorithm;automatic computing engine;bellman equation;markov chain;markov decision process;minimax;optimal stopping;stationary process	Fabian Crocce;Ernesto Mordecki	2009	CoRR		non-cooperative game;markov decision process;game theory;minimax;example of a game without a value;game tree;simultaneous game;expectiminimax tree;repeated game;mathematics;stochastic game;strategy;screening game;mathematical economics;sequential game	ML	21.269495472092384	-17.21320144072672	105728
e57e00b441a2891501bb3b965b19bae0ca18517d	transfer of deep reactive policies for mdp planning		Domain-independent probabilistic planners input an MDP description in a factored representation language such as PPDDL or RDDL, and exploit the specifics of the representation for faster planning. Traditional algorithms operate on each problem instance independently, and good methods for transferring experience from policies of other instances of a domain to a new instance do not exist. Recently, researchers have begun exploring the use of deep reactive policies, trained via deep reinforcement learning (RL), for MDP planning domains. One advantage of deep reactive policies is that they are more amenable to transfer learning. In this paper, we present the first domain-independent transfer algorithm for MDP planning domains expressed in an RDDL representation. Our architecture exploits the symbolic state configuration and transition function of the domain (available via RDDL) to learn a shared embedding space for states and state-action pairs for all problem instances of a domain. We then learn an RL agent in the embedding space, making a near zero-shot transfer possible, i.e., without much training on the new instance, and without using the domain simulator at all. Experiments on three different benchmark domains underscore the value of our transfer algorithm. Compared against planning from scratch, and a state-of-the-art RL transfer algorithm, our transfer solution has significantly superior learning curves.	alan v. oppenheim;algorithm;benchmark (computing);bloomberg terminal;computational resource;encoder;experiment;integrated information theory;microsoft azure;planning domain definition language;reinforcement learning;resource directory description language;simulation	Masataka Kawanabe;Daniele Benotti;Mausam	2018			computer science;transfer of learning;artificial intelligence;scratch;architecture;machine learning;probabilistic logic;reinforcement learning;embedding;learning curve;exploit	AI	21.299664703380426	-21.93541241442971	105929
832ebc9095d74f740598f444add6eb4843805869	pirat - a system for quantitative sewer pipe assessment	measurement system;maintenance cost;artificial intelligent;early warning;condition assessment;sewer inspection robot;sewer condition assessment;neural network	Sewers are aging, expensive assets that attract public attention only when they fail. Sewer operators are under increasing pressure to minimise their maintenance costs, while preventing sewer failures. Inspection can give early warning of failures and allow economical repair under noncrisis conditions. Current inspection techniques are subjective and detect only gross defects reliably. They cannot provide the data needed to confidently plan long-term maintenance. This paper describes PIRAT, a quantitative technique for sewer inspection. PIRAT measures the internal geometry of the sewer and then analyses these data to detect, classify, and rate defects automatically using artificial intelligence techniques. We describe the measuring system and present and discuss geometry results for different types of sewers. The defect analysis techniques are outlined and a sample defect report presented. PIRAT’s defect reports are compared with reports from the conventional technique and the discrepancies discussed. We relate PIRAT to other work in sewer robotics. KEY WORDS—sewer inspection robot, sewer condition assessment, neural network	artificial intelligence;artificial neural network;robotics;software bug	Robin Kirkham;Patrick D. Kearney;Kevin J. Rogers;John Mashford	2000	I. J. Robotics Res.	10.1177/02783640022067959	computer science;engineering;artificial intelligence;civil engineering;system of measurement;warning system;forensic engineering;artificial neural network	AI	12.359566487520084	-15.183383231234663	105968
90d3109558ab9ff2bb58a26cb4c831f9f5c7744a	simultaneous monitoring of mean vector and covariance matrix shifts in bivariate manufacturing processes using hybrid ensemble learning-based model	support vector regression;statistical process control;control charts;support vector machine;bivariate manufacturing processes;artificial neural network	Many manufacturing processes are multivariate in nature because the quality of a given product is determined by several interrelated quality characteristics. Recently, various machine learning techniques (e.g., artificial neural network, support vector machine, support vector regression or decision tree) have been used as an effective tool to monitor process mean vector and covariance matrix shifts. However, most of these machine learning techniques-based approaches for process mean vector and covariance matrix have been developed separately in literature with the other parameter assumed to be under control. Little attention has been given to simultaneous monitoring of process mean vector and covariance matrix shifts. In addition, these approaches cannot provide more detailed shift information, for example the shift magnitude, which would be greatly useful for quality practitioners to search the assignable causes that give rise to the out-of-control situation. This study presents a hybrid ensemble learning-based model for simultaneous monitoring of process mean vector and covariance matrix shifts. The numerical results indicate that the proposed model can effectively detect and recognize not only mean vector or covariance matrix shifts but also mixed situations where mean vector and covariance matrix shifts exist concurrently. Meanwhile, the magnitude of the shift of each of the shifted quality characteristics can be accurately quantified. Empirical comparisons also show that the proposed model performs better than other existing approaches in detecting mean vector and covariance matrix shifts, while also providing the capability of recognition of shift types and quantification of shift magnitudes. A demonstrative example is provided. W.-A. Yang (B) School of Mechanical and Electrical Engineering, Nanjing University of Aeronautics and Astronautics, Nanjing 210016, People’s Republic of China e-mail: dreamflow@nuaa.edu.cn	artificial neural network;bivariate data;decision tree;electrical engineering;email;ensemble learning;machine learning;numerical analysis;sensor;shift jis;support vector machine;yang	Wen-An Yang	2016	J. Intelligent Manufacturing	10.1007/s10845-014-0920-9	estimation of covariance matrices;support vector machine;kernel method;covariance matrix;computer science;engineering;covariance;machine learning;data mining;relevance vector machine;artificial neural network;statistics;covariance function	ML	13.972667158363087	-17.556669052678277	106354
1744151a1374627cc03479ab767e56d54a66dafd	fault tolerant measurement system based on takagi-sugeno fuzzy models for a gas turbine in a combined cycle power plant	modelo dinamico;software;combined cycle power plant;q test;fault tolerant measurement systems;takagi sugeno fuzzy model;fuzzy set;procesamiento informacion;parity relations;fault tolerant;neural model;logiciel;combined cycle;fuzzy models;real time;dynamic model;espace etat;measurement system;ajustement;conjunto difuso;ensemble flou;fitting;power plant;gas turbine;structural testing;fault tolerant system;state space method;methode espace etat;principal component analysis;state space;temps reel;modele dynamique;information processing;sistema tolerando faltas;tiempo real;logicial;systeme tolerant les pannes;sistema difuso;systeme flou;ajuste;espacio estado;traitement information;pca;fault detection and diagnosis;fuzzy system;fuzzy model;fault diagnosis;metodo espacio estado	A fault tolerant measurement system for a gas turbine in a combined cycle power plant, based on dynamic models, principal component analysis (PCA) and Q test, is presented. The proposed scheme makes use of a model-based symptom generator, which delivers fault signals obtained by using direct identification of parity relations and structured residuals. Symptoms are then analyzed in a statistical module achieving fault diagnosis and reconstruction of the faulty signals. The scheme presents as main advantage the ability of detecting faults in both input and output sensors due to its particular structure. Tests carried out on the gas turbine of the San Isidro combined cycle power plant in the V Region, Chile, show that Takagi-Sugeno fuzzy models present the best fitting performance and an acceptable computational cost in comparison with autoregressive exogenous, state space, and neural models. Real time software based on this scheme has been developed and connected to Osisoft PI System^(TM). The software is running at Endesa Monitoring and Diagnosis Center in Santiago, Chile.	system of measurement	Rodrigo Berrios;Felipe Núñez;Aldo Cipriano	2011	Fuzzy Sets and Systems	10.1016/j.fss.2011.02.011	fault tolerance;simulation;combined cycle;information processing;computer science;artificial intelligence;machine learning;control theory;fuzzy control system;principal component analysis	EDA	13.388483077782702	-15.443063424261638	106617
39ecb53b6bee6ccd96196620c045856a646a3a5e	an adaptive neuro-fuzzy inference system modeling for material removal rate in stationary ultrasonic drilling of sillimanite ceramic	model combination;anfis;neural networks;modeling and simulation;ultrasonic drilling;χ 2 test;depth of penetration;fuzzy inference;sillimanite ceramic;adaptive neuro fuzzy inference system;material removal rate;artificial neural network;neural network	Ultrasonic drilling of hard and brittle ceramic materials is a mechanical material removal process which is complex in nature and generally characterised by comparatively slow material removal rates. A precise modeling approach is required to simulate the material removal of ceramics by ultrasonic drilling to recompense the affect of sluggish material removal rates. The present paper uses Adaptive Neuro-Fuzzy Inference System (ANFIS) technique to model and simulate the material removal rate in stationary ultrasonic drilling of sillimanite ceramic. Depth of penetration, time for penetration and penetration rate were taken as model’s input features. The model combined modeling function of fuzzy inference with the learning ability of artificial neural network; and a set of rules has been generated directly from experimental data. The proposed modeling approach is verified by comparing the predicted results with the actual practical results obtained by conducting the confirmation experiments. The application of v-test shows that the values of material removal rate predicted by proposed model are well in agreement with the experimental values at 0.1% level of significance. 2010 Elsevier Ltd. All rights reserved.	adaptive neuro fuzzy inference system;artificial neural network;data drilling;experiment;fuzzy logic;intelligent control;mathematical optimization;neuro-fuzzy;online and offline;penetration test;simulation;stationary process;system analysis	Simranpreet Singh Gill;Jagdev Singh	2010	Expert Syst. Appl.	10.1016/j.eswa.2010.02.054	simulation;adaptive neuro fuzzy inference system;computer science;artificial intelligence;machine learning;artificial neural network	Robotics	11.881280476626126	-20.329614193831688	106714
2ef7e0f281928dda6e4083a547cdcc9236d7a6f9	fuzzy petri net based dynamic risk analysis of complex system considering protection layers	protection layers;dynamic risk analysis;accidents risk analysis petri nets yttrium fires complex systems degradation;fuzzy petri net fpn;complex system;dynamic risk transition paths fuzzy petri net protection layers complex process system production loss catastrophic accidents risk transition process fpn based risk analysis methods dynamic degradation dynamic risk analysis model fpnpl;petri nets fuzzy set theory;dynamic risk analysis complex system fuzzy petri net fpn protection layers	It is well known that in the complex process system, component's failure often leads to a chain reaction, which may result in significant production loss and catastrophic accidents. Fuzzy Petri net is able to model the risk transition process and represent uncertain knowledge. However, traditional FPN-based risk analysis methods are insufficient to take into account the protection layers and the dynamic degradation of system, which may lead to data missing and inaccurate results. In this paper, a fuzzy Petri net based dynamic risk analysis model considering protection layers (FPNPL) is proposed to address the problems mentioned above. The dynamic risk transition paths and dynamic risk of accidents can be calculated. The feasibility, effectiveness and accuracy of the proposed approach are illustrated in the case study.	catastrophic interference;complex system;elegant degradation;filtered-popping recursive transition network;fixed-pattern noise;it risk management;mathematical optimization;petri net;process architecture;simulation;stateflow	Jinqiu Hu;Yaqin Cao	2015	2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2015.7381959	complex systems;stochastic petri net;data mining	Robotics	12.548453183729093	-12.818522707235921	106914
542d7b5ef664eba479ababb2c61e0bed8f49e0a7	counter example for q-bucket-brigade under prediction problem	convergence;reinforcement learning;learning classifier systems;learning classifier system;function approximation;genetics based machine learning;genetic based machine learning	Aiming to clarify the convergence or divergence conditions for Learning Classifier System (LCS), this paper explores: (1) an extreme condition where the reinforcement process of LCS diverges; and (2) methods to avoid such divergence. Based on our previous work that showed equivalence between LCS's reinforcement process and Reinforcement Learning (RL) with Function approximation (FA) method, we present a counter-example for LCS with Q-bucket-brigade based on the 11-state star problem, a counter-example originally proposed to show the divergence of Q-learning with linear FA. Furthermore, the empirical results applying the counter-example to LCS verified the results predicted from the theory: (1) LCS with Q-bucket-brigade diverged under the prediction problem, where the action selection policy was fixed; and (2) such divergence was avoided by using implicit-bucket-brigade or applying residual gradient algorithm to Q-bucket-brigade.	action selection;algorithm;approximation;bucket-brigade device;gradient;learning classifier system;q-learning;reinforcement learning;turing completeness	Atsushi Wada;Keiki Takadama;Katsunori Shimohara	2005		10.1145/1102256.1102278	convergence;function approximation;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;learning classifier system;reinforcement learning	ML	17.82815000012031	-23.178096139225712	106919
7a3e0518e20fb01dc409523d275c3837b7eae00d	motorway ramp-metering control with queuing consideration using q-learning	road traffic computerised instrumentation learning artificial intelligence queueing theory;traffic queuing;road traffic;queueing theory;reinforcement learning;q learning;road traffic motorway ramp metering control queuing consideration q learning standard reinforcement learning algorithms traffic control local ramp metering controller maximum permissible queue length multicriterion control approach learning speed;ramp metering;mathematical model learning equations modeling throughput algorithm design and analysis stochastic processes;algorithms;computerised instrumentation;learning artificial intelligence	The standard reinforcement learning algorithms have proven to be effective tools for letting an agent learn from its experiences generated by its interaction with an environment. Among others, reinforcement learning algorithms are of interest because they require no explicit model of the environment beforehand and learning happens through trial and error. This property makes them suitable for real control problems like traffic control. Especially when considering the performance of a network where for instance a local ramp-metering controller needs to consider the performance of the network, since limitations needs to be considered, like the maximum permissible queue length, reinforcement learning algorithms are of interest. Here, a local ramp-metering control problem with queuing consideration is taken up and the performance of standard Q-learning algorithm as well as a newly proposed multi-criterion reinforcement learning algorithm is investigated. The experimental analysis confirms that the proposed multi-criterion control approach has the capability to decrease the state-space size and increase the learning speed of controller while improving the quality of solution.	algorithm;archive;benchmark (computing);control theory;experiment;information;machine learning;multi-agent system;probability matching;q-learning;ramp simulation software for modelling reliability, availability and maintainability;reinforcement learning;simulated annealing;state space;state-action-reward-state-action	Mohsen Davarynejad;Andreas Hegyi;Jos L. M. Vrancken;Jan van den Berg	2011	2011 14th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2011.6082976	control engineering;simulation;computer science;operations management;computational learning theory;reinforcement learning;active learning	Robotics	16.018875807637432	-16.911018896296227	107130
b57c4d28d548dde3970546e05151e355a6e68b3b	planning time to think: metareasoning for on-line planning with durative actions		When minimizing makespan during off-line planning, the fastest action sequence to reach a particular state is, by definition, preferred. When trying to reach a goal quickly in on-line planning, previous work has inherited that assumption: the faster of two paths that both reach the same state is usually considered to dominate the slower one. In this short paper, we point out that, when planning happens concurrently with execution, selecting a slower action can allow additional time for planning, leading to better plans. We present Slo’RTS, a metareasoning planning algorithm that estimates whether the expected improvement in future decision-making from this increased planning time is enough to make up for the increased duration of the selected action. Using simple benchmarks, we show that Slo’RTS can yield shorter time-to-goal than a conventional planner. This generalizes previous work on metareasoning in on-line planning and highlights the inherent uncertainty present in an on-line setting.	algorithm;automated planning and scheduling;benchmark (computing);dylan;fastest;ibm notes;makespan;online and offline	Bence Cserna;Wheeler Ruml;Jeremy Frank	2017			mathematical optimization;planner;job shop scheduling;computer science	AI	19.003951444405757	-11.540588005555005	107187
d8567c3083160e87b83856f298a547a093de3231	move-pruning techniques for monte-carlo go	estensibilidad;modelizacion;metodo monte carlo;analisis estadistico;methode monte carlo;probabilistic approach;scaling up;modelisation;statistical analysis;enfoque probabilista;approche probabiliste;monte carlo method;analyse statistique;ensemble aleatoire;extensibilite;scalability;jeu ordinateur;monte carlo;computer games;modeling;random set;conjunto aleatorio	Progressive Pruning (PP) is used in the Monte-Carlo go playing program Indigo. For each candidate move, PP launches random games starting with this move. PP gathers statistics on moves, and it prunes moves statistically inferior to the best one [5]. This papers yields two new pruning techniques: Miai Pruning (MP) and Set Pruning (SP). In MP the second move of the random games is selected at random among the set of candidate moves. SP consists in gathering statistics about two sets of moves, GOOD and BAD, and it prunes the latter when statistically inferior to the former. Both enhancements clearly speed up the process on 9 × 9 boards, and MP improves slightly the playing level. Scaling up MP to 19×19 boards results in a 30% speed-up enhancement and in a four-point improvement on average.	alpha–beta pruning;branching factor;candidate move;experiment;game of the amazons;heuristic (computer science);monte carlo method;scalability;search algorithm;speedup;tree traversal;weak value	Bruno Bouzy	2006		10.1007/11922155_8	simulation;computer science;artificial intelligence;mathematics;algorithm;statistics;monte carlo method	AI	20.001902946491647	-12.33080636232266	107749
1edde46f697ba3a2931ac39aa1dbf0e8c675d3e5	adaptability enhancement of multiple robots in dynamical enviroment	condition dependence;robot kinematics intelligent robots decision making intelligent sensors uncertainty intelligent agent predictive models statistical analysis hardware data communication;mobile robots time series statistical analysis intelligent control knowledge based systems inference mechanisms probability;probability;decision making adaptability enhancement multiple robots dynamical environment prediction model reasoning conditionally dependent behavior pattern conventional statistical analysis;conventional statistical analysis;intelligent robots;dynamical environment;uncertainty;inference mechanisms;mobile robots;time series;intelligent control;data communication;conditionally dependent behavior pattern;dynamic environment;statistical analysis;adaptability enhancement;intelligent agent;multiple robots;predictive models;prediction model;reasoning;knowledge based systems;intelligent sensors;robot kinematics;hardware	This paper describes a scheme to enhance adaptability of the multiple robot system using prediction result. The main purpose of this paper is attempt to construct a prediction model, which actively incorporates knowledge of the environmeizt and reflects reasoning results of the conditionally dependent behavior pattern, not only based on the conventional statistical analysis. The presented method will meet the demand and contribute to more eficient decision making in the dynamical environment. Also, some remaining problems are mentioned finallj.	robot	Kousuke Sekiyama;Toshio Fukuda	1995		10.1109/ROBOT.1995.525512	simulation;computer science;artificial intelligence;machine learning;control theory;predictive modelling;intelligent agent;statistics;intelligent control	Robotics	16.88152733599213	-19.782446657857303	107764
c0dd07d04bb500ba3d9f48f5507d3af84c3e6c5d	global solar irradiation prediction using a multi-gene genetic programming approach	neural nets;backpropagation;solar power stations;fuzzy logic;numerical analysis;genetic algorithms;regression analysis	In this paper, a nonlinear symbolic regression technique using an evolutionary algorithm known as multi-gene genetic programming (MGGP) is applied for a data-driven modelling between the dependent and the independent variables. The technique is applied for modelling the measured global solar irradiation and validated through numerical simulations. The proposed modelling technique shows improved results over the fuzzy logic and artificial neural network (ANN) based approaches as attempted by contemporary researchers. The method proposed here results in nonlinear analytical expressions, unlike those with neural networks which is essentially a black box modelling approach. This additional flexibility is an advantage from the modelling perspective and helps to discern the important variables which affect the prediction. Due to the evolutionary nature of the algorithm, it is able to get out of local minima and converge to a global optimum unlike the back-propagation (BP) algorithm used for training neural networks. This results in a better percentage fit than the ones obtained using neural networks by contemporary researchers. Also a hold-out cross validation is done on the obtained genetic programming (GP) results which show that the results generalize well to new data and do not over-fit the training samples. The multi-gene GP results are compared with those, obtained using its single-gene version and also the same with four classical regression models in order to show the effectiveness of the adopted approach.	artificial neural network;backpropagation;black box;box modeling;computer simulation;converge;cross-validation (statistics);evolutionary algorithm;fuzzy logic;genetic programming;global optimization;maxima and minima;modeling perspective;neural networks;nonlinear system;numerical analysis;software bloat;software propagation;symbolic regression	Indranil Pan;Daya Shankar Pandey;Saptarshi Das	2014	CoRR	10.1063/1.4850495	fuzzy logic;genetic algorithm;numerical analysis;backpropagation;artificial neural network;regression analysis;statistics	AI	12.840327035328086	-22.599035254032202	107833
cfb29ee2e339591d33e8b9d90bb3ef3c8aac1a5f	on case base formation in real-time heuristic search	video game pathfinding;artificial intelligence;real time heuristic search	Real-time heuristic search algorithms obey a constant limit on planning time per move. Agents using these algorithms can execute each move as it is computed, suggesting a strong potential for application to real-time video-game AI. Recently, a breakthrough in real-time heuristic search performance was achieved through the use of case-based reasoning. In this framework, the agent optimally solves a set of problems and stores their solutions in a case base. Then, given any new problem, it seeks a similar case in the case base and uses its solution as an aid to solve the problem at hand. A number of ad hoc approaches to the case base formation problem have been proposed and empirically shown to perform well. In this paper, we investigate a theoretically driven approach to solving the problem. We mathematically relate properties of a case base to the suboptimality of the solutions it produces and subsequently develop an algorithm that addresses these properties directly. An empirical evaluation shows our new algorithm outperforms the existing state of the art on contemporary video-game pathfinding benchmarks.	a* search algorithm;approximation algorithm;artificial intelligence (video games);case-based reasoning;digital curation;discrete optimization;domain-specific language;heuristic;hoc (programming language);kerrison predictor;mathematical optimization;optimization problem;pathfinding;performance;real-time clock;real-time locating system;real-time transcription;universal quantification	Vadim Bulitko;D. Chris Rayner;Ramon Lawrence	2012			consistent heuristic;simulation;computer science;artificial intelligence;machine learning;incremental heuristic search	AI	19.242364558674197	-10.798030999528915	107851
25d5119d762f0a85ef6514e27943f16f376e47e0	bayesian network-based distress estimation using image features in road structure assessment	road structural damage degree bayesian network based distress estimation image features road structure assessment inspection data;inspection bayes methods roads accuracy estimation bridges structural beams;bayes methods;bridges;structural engineering belief networks condition monitoring inspection roads;inspection;accuracy;estimation;structural beams;roads	This paper presents a Bayesian network-based method for estimating a distress of road structures from inspection data. The distress is represented by a damage of road structures and its degree. In the previous work, the distress was estimated by utilizing Bayesian network based on categories of road structures, details of road structures and damaged parts. However, inspection data include not only the above items but also images of the distress. Therefore, by introducing the use of the images to the previous work, improvement of the distress estimation accuracy can be expected. The proposed method calculates Bayesian network from inspection items and their corresponding images to perform the distress estimation. Experimental results show the effectiveness of the proposed method.	bayesian network;distress (novel);inventory	Keisuke Maeda;Sho Takahashi;Takahiro Ogawa;Miki Haseyama	2014	2014 IEEE 3rd Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2014.7031198	structural engineering;computer vision;engineering;forensic engineering	Robotics	13.018807651735798	-14.880132268973806	107957
0837518723a072d8398414fa79754127eddcae3a	learning mazes with aliasing states: an lcs algorithm with associative perception	aliasing;reinforcement learning;learning classifier systems;associative perception;learning classifier system;agents;real world application;modeling of learning;markov decision problem;self organization;maze	Maze problems represent a simplified virtual model of real environments that can be used for developing core algorithms of many real-world application related to the problem of navigation. However, the best achievements of Learning Classifier Systems (LCS) in maze problems are still mostly bounded to non-aliasing environments, while LCS complexity seems to obstruct a proper analysis of the reasons of failure. Also, despite the fact that the maze environment problem has a long history of usage in research into learning, there has been little analysis on the complexity of maze problems. To overcome these restrictions we try to improve our understanding of the nature and structure of maze environments. We analyze mazes used in research for the last two decades, introduce a set of maze complexity characteristics and develop a set of new maze environments. We then construct a new LCS agent so that it has a simpler and more transparent performance mechanism, and still could solve mazes better than existing algorithms. We use the structure of a predictive LCS model, strip out the evolutionary mechanism, simplify the reinforcement learning procedure and equip the agent with the ability of associative perception, adopted from psychology. We then run our new LCS with associative perception through the old and new aliasing mazes, which represent partially observable Markov decision problems (POMDP) and demonstrate that it performs at least as well, and in some cases better than other published results. Running Head: Learning Mazes with Aliasing States	3d modeling;algorithm;aliasing;decision problem;markov chain;partially observable markov decision process;partially observable system;reinforcement learning	Zhanna V. Zatuchna;Anthony J. Bagnall	2009	Adaptive Behaviour	10.1177/1059712308099230	aliasing;self-organization;computer science;artificial intelligence;software agent;machine learning;learning classifier system;reinforcement learning;algorithm	AI	17.664749593524427	-21.71884032094751	107996
0657b044f6d0c63de1c6c905b21a4e9ca3e74b69	kaizen programming	linear regression;genetic programming;collaborative problem solving;symbolic regression;evolutionary algorithm;curve fitting	This paper presents Kaizen Programming, an evolutionary tool based on the concepts of Continuous Improvement from Kaizen Japanese methodology. One may see Kaizen Programming as a new paradigm since, as opposed to classical evolutionary algorithms where individuals are complete solutions, in Kaizen Programming each expert proposes an idea to solve part of the problem, thus a solution is composed of all ideas together. Consequently, evolution becomes a collaborative approach instead of an egocentric one. An idea's quality (analog to an individual's fitness) is not how good it fits the data, but a measurement of its contribution to the solution, which improves the knowledge about the problem. Differently from evolutionary algorithms that simply perform trial-and-error search, one can determine, exactly, parts of the solution that should be removed or improved. That property results in the reduction in bloat, number of function evaluations, and computing time. Even more important, the Kaizen Programming tool, proposed to solve symbolic regression problems, builds the solutions as linear regression models - not linear in the variables, but linear in the parameters, thus all properties and characteristics of such statistical tool are valid. Experiments on benchmark functions proposed in the literature show that Kaizen Programming easily outperforms Genetic Programming and other methods, providing high quality solutions for both training and testing sets while requiring a small number of function evaluations.	analog signal;benchmark (computing);display resolution;evolutionary algorithm;experiment;fits;genetic programming;programming paradigm;programming tool;software bloat;symbolic regression	Vinicius Veloso de Melo	2014		10.1145/2576768.2598264	evolutionary programming;genetic programming;mathematical optimization;simulation;computer science;linear regression;artificial intelligence;machine learning;evolutionary algorithm;mathematics;curve fitting	ML	20.726769356651598	-9.90056736975428	108114
a90f4821f848b2a56ebfbc81037e70d31d9dcf96	transfer with model features in reinforcement learning		A key question in Reinforcement Learning is which representation an agent can learn to efficiently reuse knowledge between different tasks. Recently the Successor Representation was shown to have empirical benefits for transferring knowledge between tasks with shared transition dynamics. This paper presents Model Features: a feature representation that clusters behaviourally equivalent states and that is equivalent to a ModelReduction. Further, we present a Successor Feature model which shows that learning Successor Features is equivalent to learning a ModelReduction. A novel optimization objective is developed and we provide bounds showing that minimizing this objective results in an increasingly improved approximation of a Model-Reduction. Further, we provide transfer experiments on randomly generated MDPs which vary in their transition and reward functions but approximately preserve behavioural equivalence between states. These results demonstrate that Model Features are suitable for transfer between tasks with varying transition and reward functions. In Reinforcement Learning (RL) (Sutton & Barto, 1998; Kaelbling et al., 1996) one considers interactions between an intelligent agent and an environment. These interactions consists of the agent choosing an action from a set of actions, which then triggers a transition in the environment’s state. For each transition the agent is provided with a single scalar reward. The agent’s objective is to compute an action-selection strategy, also called a policy, that maximizes overall rewards. Transfer experiments in RL (Taylor & Stone, 2009) can provide insight into which information or representation an agent should retain from a task in order to solve a different task more efficiently. Recently, the Successor Representation (Dayan, 1993), which predicts the visitation frequency of future states, was shown to have emComputer Science Department, Brown University, Providence, RI, United States. Correspondence to: Lucas Lehnert <lucas lehnert@brown.edu>. pirical benefits in transfer experiments (Barreto et al., 2017; Zhang et al., 2016; Lehnert et al., 2017) and it was shown to be a representation humans are likely to use when transferring knowledge between different tasks (Momennejad et al., 2017). The Successor Representation can be viewed as an intermediate between model-free and model-based RL (Momennejad et al., 2017). In model-free RL, the intelligent agent only learns a value function which predicts the future return of a single policy. In model-based RL, the intelligent agent learns a model of its environment which is sufficient to make predictions about individual future reward outcomes, given any arbitrary action sequence (Sutton, 1990). In comparison, Successor Representations (SRs) predict future state visitation frequencies under a particular policy. By associating a feature vector with each state, SRs can be generalized to Successor Features (SFs), which predict the discounted sum of future state features (Barreto et al., 2017). Because the value function of any policy can be written as the dotproduct between the SF of a specific state as well as the reward model, transfer between tasks with different reward models is efficient (Lehnert et al., 2017). However, Lehnert et al. (2017) have also shown that SFs are tied to the transition function and a particular policy, making SFs unsuitable for transfer between tasks where more than the reward function changes. In this paper we introduce Model Features, a feature representation that provably assigns identical features to behaviourally equivalent states (Givan et al., 2003) (Section 1). Model Features can be viewed as a form of Model-Reduction which compresses the state space such that future reward outcomes can be predicted using only the compressed representation. Further, we present a modification of the architecture presented by Barreto et al. and show that this architecture can be used to learn Model Features (Section 2 and 3). Hence, the presented SF architecture is not restricted for transfer between tasks with common transition functions (Section 4).	action selection;andrew barto;approximation;bellman equation;dfa minimization;experiment;feature model;feature vector;intelligent agent;interaction;mathematical optimization;model checking;procedural generation;rl (complexity);reinforcement learning;state space;turing completeness;universal quantification;word lists by frequency	Lucas Lehnert;Michael L. Littman	2018	CoRR		machine learning;feature model;equivalence (measure theory);mathematics;reinforcement learning;successor cardinal;reuse;artificial intelligence	AI	21.59489076446893	-15.52770001672034	108257
ab4e482635af8aee43c6e7a0c367da15e059ff18	system for electromotive force standards comparison based on virtual instrument	databases;graphical programming language;measurement uncertainty virtual instrument based automated measuring system electromotive force standards emf standards comparisons graphical programming language labview reliable measurement functions data acquisition real time graphical display statistical processing database management low cost comparisons user friendly comparisons system optimization;computer languages;virtual instrumentation;instruments;statistical processing;time measurement;electromotive force standards;particle measurements;real time;real time graphical display;measurement system;virtual instrument;measurement uncertainty;database management;virtual instrument based automated measuring system;graphical programming;instruments force measurement measurement standards measurement uncertainty computer languages data acquisition displays databases time measurement particle measurements;graphical user interfaces;design and implementation;displays;user friendly comparisons;cost efficiency;force measurement;emf standards comparisons;electric potential;reliable measurement functions;measurement standards;data acquisition;low cost comparisons;voltage measurement;data acquisition electric potential voltage measurement measurement standards virtual instrumentation real time systems graphical user interfaces measurement uncertainty;system optimization;labview;real time systems	This paper presents the design and implementation of a virtual instrument (VI) based automated measuring system for electromotive force (EMF) standards comparisons. The VI is designed in the graphical programming language LabVIEW and enables fast and reliable measurement functions, including data acquisition, real-time graphical display, statistical processing, measurement result archiving, and database management. The VI provides low-cost, efficient, and user-friendly comparisons of EMF standards. The emphasis is given to the system optimization in order to minimize measurement uncertainty, and measurement time consumption. Particular attention was paid to the uncertainty consideration on the part of the measurement system itself. Regular application of the automated system for EMF standard cell comparisons accelerated the measurement procedure by more than ten times, and improved significantly the whole measurement process, compared with the previously used one. In addition, type A standard uncertainty is reduced by more than ten times. The Type B standard uncertainty of the EMF standard is estimated.	virtual instrumentation	Jelena Pantelic-Babic;Vanja Jankovic;Petar Bosnjakovic	2002	IEEE Trans. Instrumentation and Measurement	10.1109/TIM.2002.808017	embedded system;real-time computing;simulation;computer science;visual programming language;physics;quantum mechanics	Embedded	16.575750281677557	-12.423350125065696	108632
f1386eed2d7bf6a7b85bf709c840edfb698ccf47	classifier systems and the animat problem	classifier systems;incremental learning;disjunctive concepts;payoff;animal learning;genetic algorithm	This paper characterizes and investigates, from the perspective of machine learning and, particularly, classifier systems, the learning problem faced by animals and autonomous robots (here collectively termed animats). We suggest that, to survive in their environments, animats must in effect learn multiple disjunctive concepts incrementally under payoff (needs-satisfying) feedback. A review of machine learning techniques indicates that most relax at least one of these constraints. In theory, classifier systems satisfy the constraints, but tests have been limited. We show how the standard classifier system model applies to the animat learning problem. Then, in the experimental part of the paper, we specialize the model and test it in a problem environment satisfying the constraints and consisting of a difficult, disjunctive Boolean function drawn from the machine learning literature. Results include: learning the function in significantly fewer trials than a neural-network method; learning under payoff regimes that include both noisy payoff and partial reward for suboptimal performance; demonstration, in a classifier system, of a theoretically predicted property of genetic algorithms: the superiority of crossovers to point mutations; and automatic control of variation (search) rate based on system entropy. We conclude that the results support the classifier system approach to the animat problem, but suggest work aimed at the emergence of behavioral hierarchies of classifiers to offset slower learning rates in larger problems.	animat;artificial neural network;automatic control;autonomous robot;disjunctive normal form;emergence;genetic algorithm;learning classifier system;machine learning	Stewart W. Wilson	1987	Machine Learning	10.1007/BF00058679	point mutation;margin;genetic algorithm;computer science;artificial intelligence;machine learning;automatic control;mathematics;learning classifier system;boolean function;stability;artificial neural network;algorithm;satisfiability	AI	17.168928133971686	-21.75799791997626	108798
5013ebaa2f19671f53ad99d36433bbee3b83d8c6	correlated multiarmed bandit problem: bayesian algorithms and regret analysis		We consider the correlated multiarmed bandit (MAB) problem in which the rewards associated with each arm are modeled by a multivariate Gaussian random variable, and we investigate the influence of the assumptions in the Bayesian prior on the performance of the upper credible limit (UCL) algorithm and a new correlated UCL algorithm. We rigorously characterize the influence of accuracy, confidence, and correlation scale in the prior on the decision-making performance of the algorithms. Our results show how priors and correlation structure can be leveraged to improve performance.	algorithm;multi-armed bandit	Vaibhav Srivastava;Paul Reverdy;Naomi Ehrich Leonard	2015	CoRR		econometrics;machine learning;mathematics;statistics	ML	24.54526602251444	-19.384521826771547	108897
0f38fe5164829479499ef938e46b3dc5641d901a	parameter estimation of fuzzy controller using genetic optimization and neurofuzzy networks	genetique;modelizacion;optimisation;nonlinear mapping;fuzzy controller;comparative analysis;control difusa;sintesis control;optimizacion;genetica;computational intelligence;fuzzy control;inversed pendulum;intelligence artificielle;algoritmo genetico;genetics;preparacion serie fabricacion;identificacion sistema;modelisation;system identification;synthese commande;scale factor;estimacion parametro;algorithme genetique;artificial intelligence;genetic algorithm;optimization;inverted pendulum;inteligencia artificial;process planning;parameter estimation;estimation parametre;nonlinear system;preparation gamme fabrication;modeling;facteur echelle;factor escala;identification systeme;control synthesis;pendule inverse;commande floue;design methodology;pendulo inverso	In this study, we introduce a noble neurogenetic approach to the design of fuzzy controller. The design procedure dwells on the use of Computational Intelligence (CI), namely genetic algorithms and neurofuzzy networks (NFN). The crux of the design methodology is based on the selection and determination of optimal values of the scaling factors of the fuzzy controllers, which are essential to the entire optimization process. First, the tuning of the scaling factors of the fuzzy controller is carried out, and then the development of a nonlinear mapping for the scaling factors is realized by using GA based NFN. The developed approach is applied to a nonlinear system such as an inverted pendulum where we show the results of comprehensive numerical studies and carry out a detailed comparative analysis.	estimation theory	Sung-Kwun Oh;Seok-Beom Roh;Tae-Chon Ahn	2005		10.1007/11427469_16	scale factor;qualitative comparative analysis;inverted pendulum;systems modeling;genetic algorithm;design methods;system identification;nonlinear system;computer science;artificial intelligence;computational intelligence;control theory;estimation theory	Robotics	15.515249977003641	-20.411023147287487	108965
23abcee09f5c82a946a13f2e2e25ef9e2de6e454	bayesian role discovery for multi-agent reinforcement learning	multi agent reinforcement learning;reinforcement learning	In this paper we develop a Bayesian policy search approach for Multi-Agent RL (MARL), which is model-free and allows for priors on policy parameters. We present a novel optimization algorithm based on hybrid MCMC, which leverages both the prior and gradient information estimated from trajectories. Our experiments demonstrate the automatic discovery of roles through reinforcement learning in a real-time strategy game.	algorithm;experiment;gradient descent;markov chain monte carlo;mathematical optimization;multi-agent system;real-time locating system;reinforcement learning	Aaron Wilson;Alan Fern;Prasad Tadepalli	2010		10.1145/1838206.1838494	temporal difference learning;unsupervised learning;error-driven learning;computer science;artificial intelligence;machine learning;pattern recognition;learning classifier system;reinforcement learning	AI	20.276281077798775	-19.61977674211089	108980
3587d548d54d366db3be958f62c406dd8596d1e9	using active relocation to aid reinforcement learning	reinforcement learning	We propose a new framework for aiding a reinforcement learner by allowing it to relocate, or move, to a state it selects so as to decrease the number of steps it needs to take in order to develop an effective policy. The framework requires a minimal amount of human involvement or expertise and assumes a cost for each relocation. Several methods for taking advantage of the ability to relocate are proposed, and their effectiveness is tested in two commonly-used domains.	andrew barto;reinforcement learning;relocation (computing);sutton's law;value (computer science)	Lilyana Mihalkova;Raymond J. Mooney	2006			error-driven learning;simulation;computer science;artificial intelligence;machine learning;reinforcement learning	ML	18.72821132135265	-21.19601121724814	109254
1454e8f580368a6b72c2d4c313bfe0f1f026a8ab	forecasting sedimentation of constructions based on bp network	analytical models;sedimentation;forecast bp algorithm;building;deformation forcasting model;neural nets;bp neural networks;building bp network forecasting sedimentation constructions deformation forcasting model economic development safe operation back propagation neural network deformation observation;training;forecast bp algorithm bp neural networks sedimentation;biological system modeling;deformable models;forecasting model;biological neural networks deformable models algorithm design and analysis predictive models filtration artificial neural networks backpropagation signal processing neurons technology forecasting;backpropagation;back propagation neural network;deformation observation;constructions;structural engineering computing backpropagation construction deformation neural nets safety sedimentation;safe operation;artificial neural networks;deformation;structural engineering computing;bp network;safety;information processing;timing analysis;economic development;dynamic characteristic;neural network model;forecasting sedimentation;construction;biological neural networks;buildings;neural network	If sedimentation of constructions exceeds the prescribed limits, it would give rise to huge losses for community and people, so it is significant to establish the effective and practical deformation forecasting model for the safe operation and economic development. With the unique non-linear, non-convexity, non-locality, non-steadiness, adaptability and powerful ability of calculation and information process, BP (Back Propagation) neural network can adapt to the complicated and changeable dynamic characteristics of buildings,that has broad application foreground in deformation prediction. In this paper, on the basis of deformation observation data, a basic algorithm about establishing BP neural network model in sedimentation prediction is presented.at the same time, analysis of examples are given so that the application of neural network for deformation forecasting is studied comprehensively and systemically, the results show that neural network is very effective for Sedimentation prediction and can serve society and people in the future.	algorithm;artificial neural network;backpropagation;locality of reference;network model;nonlinear system;software propagation	Ting-chen Jiang	2009	2009 International Conference on Environmental Science and Information Application Technology	10.1109/ESIAT.2009.52	simulation;construction;computer science;engineering;artificial intelligence;backpropagation;machine learning;sedimentation;building;static timing analysis;deformation;artificial neural network	Robotics	10.110412216469433	-20.92664344058594	109289
ffab82aeb12e632715c85268c53afe44b6d9f636	effect of fitness for the evolution of autonomous robots in an open-environment	navegacion;robot movil;fitness;evolution artificielle;robotics;navigation;robot mobile;robotica;robotique;evolutionary process;adecuacion;robot dynamics;artificial evolution;autonomous robot;moving robot;fitness function	The choice of a fittness function in artificial evolution has strong consequences on the evolvability of robots, dynamics of the evolutionary process, and ultimately on the outcome of the evolutionary process. In this paper, the effect of fitness functions for the evolution of autonomous robots to navigate in an open-environment by avoiding obstacles is studied. It is found that both the number and description of components of a fitness function affect the convergence of the evolutionary process. However, the performance of evolved robots in an unknown environment is greatly dependent on the description of components of a fitness function.	robot	Md. Monirul Islam;S. Terao;Kazuyuki Murase	2001		10.1007/3-540-45443-8_15	navigation;simulation;computer science;artificial intelligence;evolutionary algorithm;artificial creation;robotics;evolutionary robotics;fitness function	Robotics	24.251070235112625	-12.417662937487552	109366
8932684d1f1a54494f6466dc8e180634a169f395	an integrated methodology for the dynamic performance and reliability evaluation of fault-tolerant systems	artefacto;modele comportement;tolerancia falta;modelizacion;analyse risque;behavior model;avion combate;evaluation performance;dynamic probabilistic risk assessment;proceso concepcion;concepcion ingenieria;fiabilidad;reliability;metric system;engineering design;chaine markov;design process;cadena markov;stochastic process;performance evaluation;analisis sistema;sintesis control;fault tolerant;system configuration;behavioral analysis;proceso markov;porcentaje falla;risk analysis;lateral;system dynamics;conception ingenierie;behavior modeling;evaluacion prestacion;modelo comportamiento;performance;reliability modeling;behavioral model;flight;taux defaillance;control engineering;aeronef;failure mode;probabilistic approach;aeronave;artefact;preparacion serie fabricacion;performance metric;dynamical system;systeme metrique;probabilistic risk assessment;modelisation;systeme dynamique;analisis riesgo;fight aircraft;vol;electrical engineering and computer science;control system;system evaluation;fault tolerant system;thesis;diagnostic panne;system design;enfoque probabilista;approche probabiliste;processus markov;synthese commande;fiabilite;fault diagnostic;fault tolerance;analyse comportementale;rupture;diagnostico pana;defaillance;performance analysis;markov process;processus stochastique;sistema tolerando faltas;system analysis;risk assessment;failure rate;systeme tolerant les pannes;analisis conductual;avion combat;analyse systeme;failures;process planning;stochastic model;sistema dinamico;proceso estocastico;behavior;preparation gamme fabrication;modeling;vuelo;modelo estocastico;fallo;ruptura;flight control;markov reliability modeling;modele stochastique;tolerance faute;sistema metrico;control synthesis;aircraft;evaluation risque;processus conception;markov chain;dynamic behavior	We propose an integrated methodology for the reliability and dynamic performance analysis of fault-tolerant systems. This methodology uses a behavioral model of the system dynamics, similar to the ones used by control engineers to design the control system, but also incorporates artifacts to model the failure behavior of each component. These artifacts include component failure modes (and associated failure rates) and how those failure modes affect the dynamic behavior of the component. The methodology bases the system evaluation on the analysis of the dynamics of the different configurations the system can reach after component failures occur. For each of the possible system configurations, a performance evaluation of its dynamic behavior is carried out to check whether its properties, e.g., accuracy, overshoot, or settling time, which are called performance metrics, meet system requirements. Markov chains are used to model the stochastic process associated with the different configurations that a system can adopt when failures occur. This methodology not only enables an integrated framework for evaluating dynamic performance and reliability of fault-tolerant systems, but also enables a method for guiding the system Preprint submitted to Elsevier 9 January 2008 design process, and further optimization. To illustrate the methodology, we present a case-study of a lateral-directional flight control system for a fighter aircraft.	behavioral modeling;control system;failure cause;fault tolerance;lateral computing;lateral thinking;markov chain;mathematical optimization;overshoot (signal);performance evaluation;requirement;settling time;stochastic process;system dynamics;system requirements	Alejandro D. Domínguez-García;John G. Kassakian;Joel E. Schindall;Jeffrey J. Zinchuk	2008	Rel. Eng. & Sys. Safety	10.1016/j.ress.2008.01.007	behavioral modeling;reliability engineering;stochastic process;fault tolerance;simulation;engineering;control system;artificial intelligence;probabilistic risk assessment;statistics	Embedded	13.062017478541428	-10.351533469438483	109385
663c7d77b1ec47d918c7de7cba7b9633ce4cf7ab	a level-1 probabilistic risk assessment to blackout hazard in transmission power systems	probabilistic risk analysis;blackout;power system reliability;power system stability;monte carlo methods;power system security	The blackout risk in power systems is difficult to estimate by actual probabilistic methods because they usually neglect, or do not properly consider, the dependencies between failures and the dynamic evolution of the grid in the course of a transient. Our purpose is therefore to develop an integrated probabilistic approach to blackout analysis, capable of handling the coupling between events in cascading failure, and the dynamic response of the grid to stochastic initiating perturbations. This approach is adapted from dynamic reliability methodologies. This paper focuses on the modeling adopted for the first phase of a blackout, ruled by thermal transients. The goal is to identify dangerous cascading scenarios and better calculate their frequency. A Monte Carlo code specifically developed for this purpose is validated on a test grid. Some dangerous scenarios are presented and their frequency calculated by this method is compared with a more classical estimation neglecting thermal effects, showing significant differences. In particular, our method can reveal dangerous scenarios neglected or underestimated by the more classical method because they do not take into account the increase of failure rates in stress conditions.	cascading failure;ibm power systems;monte carlo method;risk assessment;transient (computer programming)	Pierre Henneaux;Pierre-Etienne Labeau;Jean-Claude Maun	2012	Rel. Eng. & Sys. Safety	10.1016/j.ress.2012.02.007	reliability engineering;simulation;engineering;mathematics;forensic engineering;probabilistic risk assessment;statistics;monte carlo method	HPC	12.614402186690429	-10.29494809153604	109648
53d409e94f23de634a8bfc302fb38a8e9b7b897e	efficient and scalable pareto optimization by evolutionary local selection algorithms	graph search;distributed application;elsa;premature convergence;fitness sharing;agent based;efficiency;pareto front;efficiency evolutionary algorithms local selection elsa agent based search cover multicriterion optimization pareto front scalability;local selection;evolutionary algorithms;parallel implementation;scalability;evolutionary algorithm;cover;agent based search;pareto optimality;multicriterion optimization;fitness function;evolutionary computing	Local selection is a simple selection scheme in evolutionary computation. Individual fitnesses are accumulated over time and compared to a fixed threshold, rather than to each other, to decide who gets to reproduce. Local selection, coupled with fitness functions stemming from the consumption of finite shared environmental resources, maintains diversity in a way similar to fitness sharing. However, it is more efficient than fitness sharing and lends itself to parallel implementations for distributed tasks. While local selection is not prone to premature convergence, it applies minimal selection pressure to the population. Local selection is, therefore, particularly suited to Pareto optimization or problem classes where diverse solutions must be covered. This paper introduces ELSA, an evolutionary algorithm employing local selection and outlines three experiments in which ELSA is applied to multiobjective problems: a multimodal graph search problem, and two Pareto optimization problems. In all these experiments, ELSA significantly outperforms other well-known evolutionary algorithms. The paper also discusses scalability, parameter dependence, and the potential distributed applications of the algorithm.	agent-based model;analysis of algorithms;class;computation (action);distributed computing;ecosystem model;evolutionary algorithm;evolutionary computation;experiment;fitness function;genetic selection;graph traversal;mathematical optimization;multi-objective optimization;multimodal interaction;optimization problem;outlines (document);pareto efficiency;population parameter;premature convergence;scalability;search problem;solutions;stemming	Filippo Menczer;Melania Degeratu;William Nick Street	2000	Evolutionary Computation	10.1162/106365600568185	mathematical optimization;scalability;fitness proportionate selection;computer science;artificial intelligence;cover;multi-objective optimization;machine learning;evolutionary algorithm;mathematics;efficiency;fitness function;premature convergence	ML	23.293995324885504	-10.121708508800737	109894
f1f191a253c4ace92ece93aab1685c8ab4d13fc1	time series forecasting using nonlinear dynamic methods and identification of deterministic chaos	forecasting;nonlinear dynamics;logistic map;unscented kalman filter	Abstract   The study is devoted to the application of nonlinear dynamic methods to explore and model chaotic processes. The criteria of deterministic chaos and the general stages of modeling time series are presented in the work. It is proposed to improve the forecast accuracy by the identification of the chaotic component of the time process using deterministic nonlinear dynamic systems with chaotic solutions in terms of small number of available observations and one process implementation. Decomposition in the system of chaotic processes described by the logistic map is used as a model of chaotic signal. Moreover the parameter of the logistic map and the state of the system of each previous step are known inaccurately and are estimated using the unscented Kalman filter (UKF). Divergence process due to rounding estimations of the parameters of the systems is analyzed in the research.	chaos theory;time series	Elena I. Malyutina;Vladimir I. Shiryaev	2014		10.1016/j.procs.2014.05.355	econometrics;computer science;control theory	Robotics	15.00376017888605	-21.016581596025503	109917
a844e8e82484a225ffde4f18e16d99b338d839fd	model-based fault detection and diagnosis optimization for process control rig	process control fault detection and diagnosis fuzzy logic genetic algorithms neural network;multilayer ann multilayer artificial neural network model based fault detection fault diagnosis optimization process control rig fuzzy logic based model genetic algorithm membership function optimization residual signals system faults multilayer artificial neural networks fault classification technique fuzzy model optimized fuzzy ga model fuzzy logic model;fuzzy control;signal classification fault diagnosis fuzzy control fuzzy logic fuzzy set theory genetic algorithms neurocontrollers process control;fuzzy set theory;fuzzy logic;signal classification;process control;genetic algorithms;neurocontrollers;fault detection water heating artificial neural networks mathematical model accuracy heat transfer;fault detection and diagnosis;fault diagnosis;neural network	One of the challenges research on model based fault detection and diagnosis of a system is finding the accurate models. In this paper, fuzzy logic based model using genetic algorithm for optimizing the membership function is used in the development of fault detection and diagnosis of a process control rig. The model is used to generate various residual signals, which relate to the faults of the system. These residual signals are used by artificial neural networks to classify the respective faults and finally to determine the faults of the system. Comparisons of the fault classification technique are done for two different models of the process control rig that are the conventional fuzzy model and the optimized fuzzy-GA model. The results show that the fuzzy-GA model gives more accurate fault classifications as compared to the conventional fuzzy logic model.	artificial neural network;fault detection and isolation;fuzzy logic;genetic algorithm;mathematical optimization;software release life cycle	Ribhan Zafira Abdul Rahman;Rubiyah Yusof;Fatimah Sham Ismail	2013	2013 9th Asian Control Conference (ASCC)	10.1109/ASCC.2013.6606106	control engineering;adaptive neuro fuzzy inference system;engineering;artificial intelligence;neuro-fuzzy;machine learning;fuzzy set operations;fuzzy control system;intelligent control	AI	12.658695357863225	-21.58118844264358	110235
19f8d892464e33b60f69f5ccd9166c517226f1aa	convergence results for single-step on-policy reinforcement-learning algorithms	convergence;reinforcement learning;optimal policy;control problem;on policy;markov decision process;markov decision processes	An important application of reinforcement learning (RL) is to finite-state control problems and one of the most difficult problems in learning for control is balancing the exploration/exploitation tradeoff. Existing theoretical results for RL give very little guidance on reasonable ways to perform exploration. In this paper, we examine the convergence of single-step on-policy RL algorithms for control. On-policy algorithms cannot separate exploration from learning and therefore must confront the exploration problem directly. We prove convergence results for several related on-policy algorithms with both decaying exploration and persistent exploration. We also provide examples of exploration strategies that can be followed during learning that result in convergence to both optimal values and optimal policies.	algorithm;exploration problem;reinforcement learning	Satinder P. Singh;Tommi S. Jaakkola;Michael L. Littman;Csaba Szepesvári	2000	Machine Learning	10.1023/A:1007678930559	markov decision process;mathematical optimization;simulation;computer science;artificial intelligence;machine learning;reinforcement learning	ML	21.457583300545636	-19.18342561478101	110422
9928da4363419788b2f589e75722882ba2d72900	learning-based planning		Automated Planning (AP) studies the generation of action sequences for problem solving. A problem in AP is defined by a state-transition function describing the dynamics of the world, the initial state of the world and the goals to be achieved. According to this definition, AP problems seem to be easily tackled by searching for a path in a graph, which is a well-studied problem. However, the graphs resulting from AP problems are so large that explicitly specifying them is not feasible. Thus, different approaches have been tried to address AP problems. Since the mid 90’s, new planning algorithms have enabled the solution of practical-size AP problems. Nevertheless, domain-independent planners still fail in solving complex AP problems, as solving planning tasks is a PSPACE-Complete problem (Bylander, 94). How do humans cope with this planning-inherent complexity? One answer is that our experience allows us to solve problems more quickly; we are endowed with learning skills that help us plan when problems are selected from a stable population. Inspire by this idea, the field of learning-based planning studies the development of AP systems able to modify their performance according to previous experiences. Since the first days, Artificial Intelligence (AI) has been concerned with the problem of Machine Learning (ML). As early as 1959, Arthur L. Samuel developed a prominent program that learned to improve its play in the game of checkers (Samuel, 1959). It is hardly surprising that ML has often been used to make changes in systems that perform tasks associated with AI, such as perception, robot control or AP. This article analyses the diverse ways ML can be used to improve AP processes. First, we review the major AP concepts and summarize the main research done in learning-based planning. Second, we describe current trends in applying ML to AP. Finally, we comment on the next avenues for combining AP and ML and conclude.	algorithm;artificial intelligence;automated planning and scheduling;complete (complexity);complexity;finite-state machine;machine learning;pspace-complete;population;problem solving;robot control;state transition table	Sergio Jiménez Celorrio;Tomás de la Rosa Turbides	2009			site plan	AI	19.076973004846494	-13.63790814041073	110627
b26444661a67feb1ddc0571a72e2deeff2b06607	feedforward neural network and adaptive network-based fuzzy inference system in study of power lines	feedforward neural network;power line;adaptive network based fuzzy inference system;electromagnetic fields;electromagnetic field;power transmission line;power lines;extremely low frequency;electric and magnetic fields;adaptive network based fuzzy inference systems	Over the past several decades, concerns have been raised over the possibility that the exposure to extremely low frequency electromagnetic fields from power lines may have harmful effects on human and living organisms. This paper presents novel approach based on the use of both feedforward neural network (FNN) and adaptive network-based fuzzy inference system (ANFIS) to estimate electric and magnetic fields around an overhead power transmission lines. An FNN and ANFIS used to simulate this problem were trained using the results derived from the previous research. It is shown that proposed approach ensures satisfactory accuracy and can be a very efficient tool and useful alternative for such investigations.	adaptive neuro fuzzy inference system;artificial neural network;feedforward neural network;inference engine	Jasna Radulovic;Vesna Rankovic	2010	Expert Syst. Appl.	10.1016/j.eswa.2009.05.008	electromagnetic field;adaptive neuro fuzzy inference system;artificial intelligence;machine learning	ML	13.66951952035487	-21.423528096370074	110732
1293b87306f01cb5b0717c0ccff88c256167e1cd	escaping heuristic hollows in real-time search without learning	real time pathfinding real time search heuristic search;real time pathfinding;rta algorithm;software agents search problems;search space;real time;benchmark problem;search algorithm;look ahead;runtime;software agents;heuristic search;path realtime a algorithm realtime search lrta algorithm rta algorithm;heuristic algorithms;games;planning;search problems;realtime search;path realtime a algorithm;real time search;algorithm design and analysis;lrta algorithm;real time systems games search problems heuristic algorithms planning algorithm design and analysis runtime;real time systems	Real-time search is a standard approach to solving search problems in which agents have limited sensing capabilities and must act quickly. It is well known that real-time search algorithms like LRTA* and RTA* perform poorly in regions of the search space in which the heuristic function is very imprecise. Approaches that use look ahead or learning are used to overcome this drawback. They perform more computation in the planning phase compared to LRTA* andRTA* . In this paper we propose Path Real-Time A* (PRTA* ), an algorithm that, like LRTA*, performs little computation in the planning phase, but that, unlike LRTA*, terminates even if the problem does not have a solution. We show that our algorithm outperforms LRTA* and RTA* in standard real-time benchmark problems. Furthermore, we show that in some cases, PRTA* may also outperform lookahead-orlearning-enabled algorithms but carrying out significantly less computation.	a* search algorithm;benchmark (computing);carry-lookahead adder;computation;experiment;heuristic (computer science);item unique identification;parsing;real-time search;real-time clock;real-time transcription;search problem	Carlos Hernández;Jorge A. Baier	2010	2010 XXIX International Conference of the Chilean Computer Science Society	10.1109/SCCC.2010.16	mathematical optimization;real-time computing;simulation;computer science	AI	19.656159396196816	-11.535408292091052	110770
061f7f41c22d30ebb535421e98ace084c161cb60	interaction aware trajectory planning for merge scenarios in congested traffic situations	control engineering;robotics;acceleration;trajectory;reglerteknik;roads;robotteknik och automation;merging;predictive models;planning;vehicles	In many traffic situations there are times where interaction with other drivers is necessary and unavoidable in order to safely progress towards an intended destination. This is especially true for merge manoeuvres into dense traffic, where drivers sometimes must be somewhat aggressive and show the intention of merging in order to interact with the other driver and make the driver open the gap needed to execute the manoeuvre safely. Many motion planning frameworks for autonomous vehicles adopt a reactive approach where simple models of other traffic participants are used and therefore need to adhere to large margins in order to behave safely. However, the large margins needed can sometimes get the system stuck in congested traffic where time gaps between vehicles are too small. In other situations, such as a highway merge, it can be significantly more dangerous to stop on the entrance ramp if the gaps are found to be too small than to make a slightly more aggressive manoeuvre and let the driver behind open the gap needed. To remedy this problem, this work uses the Intelligent Driver Model (IDM) to explicitly model the interaction of other drivers and evaluates the risk by their required deceleration in a similar manner as the Minimum Overall Breaking Induced by Lane change (MOBIL) model that has been used in large scale traffic simulations before. This allows the algorithm to evaluate the effect on other drivers depending on our own trajectory plans by simulating the nearby traffic situation. Finding a globally optimal solution is often intractable in these situations so instead a large set of candidate trajectories are generated that are evaluated against the traffic scene by forward simulations of other traffic participants. By discretization and using an efficient trajectory generator together with efficient modelling of the traffic scene real-time demands can be met.	automated planning and scheduling;autonomous robot;autonomous system (internet);baseline (configuration management);discretization;experiment;forward secrecy;loss function;maxima and minima;merge sort;motion planning;ramp simulation software for modelling reliability, availability and maintainability;randomized algorithm;real-time transcription;vehicle-to-vehicle;velocity (software development)	Niclas Evestedt;Erik Ward;John Folkesson;Daniel Axehill	2016	2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2016.7795596	simulation;engineering;operations management;transport engineering	Robotics	19.933509062347536	-18.277227634839306	111048
34d63706543e87b9071eb64d3405ea6fdd5da386	symbolic heuristic search for factored markov decision processes	dynamic programming;convergence;learning;very large scale integration;latent class models;state estimation;heuristic search;heuristic methods;state space;decision theory;local dependence;decision theoretic planning;algorithms;markov processes;markov decision process;symbolic model checking;forward search;symbols;model based clustering;bayesian networks	We describe a plnning algorithm that integrates two approaches to solving Markov decision processes with large state spaces. State abstraction is used to avoid evaluating states individually. Forward search from a start state, guided by an admissible heuristic, is used to avoid evaluating all states. We combine these two approaches in a novel way that exploits symbolic model-checking techniques and demonstrates their usefulness for decision-theoretic planning.	admissible heuristic;algorithm;computation;finite-state machine;markov chain;markov decision process;model checking;state space;theory	Zhengzhu Feng;Eric A. Hansen	2002			markov decision process;mathematical optimization;heuristic;convergence;decision theory;computer science;state space;artificial intelligence;machine learning;dynamic programming;pattern recognition;bayesian network;symbol;very-large-scale integration;markov process;statistics	AI	21.213987510380797	-15.309586855732324	111254
59b08f3a02eb352dcb91950bf1d29068cd540098	approximate value iteration with temporally extended actions (extended abstract)		The options framework provides a concrete way to implement and reason about temporally extended actions. Existing literature has demonstrated the value of planning with options empirically, but there is a lack of theoretical analysis formalizing when planning with options is more efficient than planning with primitive actions. We provide a general analysis of the convergence rate of a popular Approximate Value Iteration (AVI) algorithm called Fitted Value Iteration (FVI) with options. Our analysis reveals that longer duration options and a pessimistic estimate of the value function both lead to faster convergence. Furthermore, options can improve convergence even when they are suboptimal and sparsely distributed throughout the state space. Next we consider generating useful options for planning based on a subset of landmark states. This suggests a new algorithm, Landmarkbased AVI (LAVI), that represents the value function only at landmark states. We analyze OFVI and LAVI using the proposed landmark-based options and compare the two algorithms. Our theoretical and experimental results demonstrate that options can play an important role in AVI by decreasing approximation error and inducing fast convergence.	algorithm;approximation error;bellman equation;iteration;markov decision process;rate of convergence;state space;temporal logic	Timothy Arthur Mann;Shie Mannor;Doina Precup	2017		10.24963/ijcai.2017/717	artificial intelligence;discrete mathematics;machine learning;markov decision process;mathematical optimization;mathematics	ML	21.922405526222526	-16.46995269874369	111350
3c894f0724e381900fd8a6c09a982e55ebe36bf9	undesired state-action prediction in multi-agent reinforcement learning for linked multi-component robotic system control	multi agent reinforcement learning;multi robot systems;distributed q learning;hose transportation	The paper deals with the problem of learning the control of Multi-Component Robotic Systems (MCRSs) applying Multi-Agent Reinforcement Learning (MARL) algorithms. Modeling Linked MCRS usually leads to over-constrained environments, posing great difficulties for efficient learning with conventional single and multi-agent reinforcement algorithms. In this paper, we propose a hybrid learning algorithm composed of a modified Q-Learning algorithm embedding an Undesired State-Action Prediction (USAP) module trained by a supervised learning approach which learns a model predicting undesired transitions to states breaking physical constraints. The USAP module’s output is used by the Q-Learning algorithm to prevent these undesired transitions, therefore boosting learning efficiency. This hybrid approach is extended to the multi-agent case embedding the USAP module in Distributed Round-Robin Q-Learning (D-RR-QL), which requires very little communications among agents. We present results of computational experiments conducted in the classical multi-agent taxi scheduling task and a hose transportation task. Results show a considerable learning gain both in time and accuracy, compared to the state-of-the-art Distributed Q-Learning approach in the deterministic taxi scheduling task. In the hose transportation task, USAP module introduces a significant improvement in learning convergence speed. 2013 Elsevier Inc. All rights reserved.	algorithm;algorithmic learning theory;computation;experiment;multi-agent system;q-learning;rapid refresh;reinforcement learning;robot;round-robin scheduling;scheduling (computing);supervised learning	Borja Fernández-Gauna;Ion Marqués;Manuel Graña	2013	Inf. Sci.	10.1016/j.ins.2012.12.021	unsupervised learning;robot learning;error-driven learning;simulation;artificial intelligence;machine learning;learning classifier system;generalization error	AI	19.58022707842595	-19.89016732555432	111351
4b69669db26d1fbcbf54dfc6d1a35d48b58bc34f	the adwords problem: online keyword matching with budgeted bidders under random permutations	search engine;learning;pac learning;adwords;matching;random permutation;online;competitive ratio	We consider the problem of a search engine trying to assign a sequence of search keywords to a set of competing bidders, each with a daily spending limit. The goal is to maximize the revenue generated by these keyword sales, bearing in mind that, as some bidders may eventually exceed their budget, not all keywords should be sold to the highest bidder. We assume that the sequence of keywords (or equivalently, of bids) is revealed on-line. Our concern will be the competitive ratio for this problem versus the off-line optimum.  We extend the current literature on this problem by considering the setting where the keywords arrive in a random order. In this setting we are able to achieve a competitive ratio of 1-ε under some mild, but necessary, assumptions. In contrast, it is already known that when the keywords arrive in an adversarial order, the best competitive ratio is bounded away from 1. Our algorithm is motivated by PAC learning, and proceeds in two parts: a training phase, and an exploitation phase.	algorithm;competitive analysis (online algorithm);google adwords;mind;online and offline;probably approximately correct learning;web search engine	Nikhil R. Devanur;Thomas P. Hayes	2009		10.1145/1566374.1566384	matching;competitive analysis;mathematical optimization;random permutation;computer science;artificial intelligence;operations management;machine learning;data mining;mathematics;mathematical economics;world wide web;probably approximately correct learning;algorithm;search engine;statistics	ECom	23.219617509463355	-16.69111358828949	111676
effc7145f3b220903980eec77150ed25002a0db2	knowledge discovery of concrete material using genetic operation trees	high performance concrete;genetic operator;operation tree;compressive strength;material;self organization;genetic algorithm;genetic algorithms;neural network model;nonlinear regression;concrete;neural network;knowledge discovery	This study proposed a novel knowledge discovery method, Genetic Operation Tree (GOT), which is composed of operation tree (OT) and genetic algorithm (GA), to automatically produce self-organized formulas to predict compressive strength of High-Performance Concrete. In GOT, OT plays the architecture to represent an explicit formula, and GA plays the optimization mechanism to optimize the OT to fit experimental data. Experimental data from several different sources were used to evaluate the method. The results showed that GOT can produce formulas which are more accurate than nonlinear regression formulas but less accurate than neural network models. However, neural networks are black box models, while GOT can produce explicit formulas, which is an important advantage in practical applications.	artificial neural network;file binder;network model;nonlinear system;romp;self-organization	I-Cheng Yeh;Li-Chuan Lien	2009	Expert Syst. Appl.	10.1016/j.eswa.2008.07.004	genetic algorithm;computer science;artificial intelligence;machine learning;artificial neural network;algorithm	NLP	12.81829100191162	-20.881016855441118	111717
6e6ce5a4e6b055e444b3c38208ba96644ac2383e	qualitative possibilistic mixed-observable mdps	intelligence artificielle;logique en informatique;apprentissage;informatique et langage	Possibilistic and qualitative POMDPs (πPOMDPs) are counterparts of POMDPs used to model situations where the agent’s initial belief or observation probabilities are imprecise due to lack of past experiences or insufficient data collection. However, like probabilistic POMDPs, optimally solving πPOMDPs is intractable: the finite belief state space exponentially grows with the number of system’s states. In this paper, a possibilistic version of Mixed-Observable MDPs is presented to get around this issue: the complexity of solving π-POMDPs, some state variables of which are fully observable, can be then dramatically reduced. A value iteration algorithm for this new formulation under infinite horizon is next proposed and the optimality of the returned policy (for a specified criterion) is shown assuming the existence of a ”stay” action in some goal states. Experimental work finally shows that this possibilistic model outperforms probabilistic POMDPs commonly used in robotics, for a target recognition problem where the agent’s observations are imprecise.	algorithm;iteration;iterative method;markov decision process;observable;robotics;state space	Nicolas Drougard;Florent Teichteil-Königsbuch;Jean-Loup Farges;Didier Dubois	2013	CoRR		artificial intelligence;machine learning;mathematics;algorithm	AI	21.358808469154987	-16.789160357636835	111953
8f1ff791532d31b8e795c841a9cb34cd73a1e2c6	heath monitoring of capacitors and supercapacitors using the neo-fuzzy neural approach		Despite their great improvements, reliability and availability of power electronic devices always remain a focus. In safety-critical equipment, where the occurrence of faults can generate catastrophic losses, health monitoring of most critical components is absolutely needed to avoid and prevent breakdowns. In this paper, a noninvasive health monitoring method is proposed. It is based on fuzzy logic and the neural network to estimate and predict the equivalent series resistance (ESR) and the capacitance (C) of capacitors and supercapacitors (SCs). This method, based on the neo-fuzzy neuron model, performs a real-time processing (time series prediction) of the measured device impedance and the degradation data provided by accelerated ageing tests. To prove the efficiency of the proposed method, two experiments are performed. The first one is dedicated to the estimation of the ESR and C for a set of 8 polymer film capacitors, while the second one is dedicated to the prediction of the ESR and C for a set of 18 SCs. The obtained results show that combining fuzzy logic and the neural network is an accurate approach for the health monitoring of capacitors and SCs.	artificial neural network;biological neuron model;characteristic impedance;elegant degradation;experiment;fuzzy logic;polymer;real-time clock;series and parallel circuits;software bug;thin-film transistor;time series	Abdenour Soualhi;Maawad Makdessi;Ronan German;Francklin Rivas Echeverr&#x00ED;a;Hubert Razik;Ali Sari;Pascal Venet;Guy Clerc	2018	IEEE Transactions on Industrial Informatics	10.1109/TII.2017.2701823	computer science;electronics;control engineering;fuzzy logic;capacitor;film capacitor;equivalent series resistance;artificial neural network;supercapacitor;electronic engineering;capacitance	SE	13.832259262646021	-16.985355889535068	111960
786f5c15b36c9e5dfa2bf3975ca5426db736d199	modeling time series of climatic parameters with probabilistic finite automata	continuous time;kolmogorov smirnov;adaptive testing;cumulative distribution function;sample size;learning algorithm;time series;machine learning;finite automata;modeling climatic data;generating series	A model to characterize and predict continuous time series from machine-learning techniques is proposed. This model includes the following three steps: dynamic discretization of continuous values, construction of probabilistic finite automata and prediction of new series with randomness. The first problem in most models from machine learning is that they are developed for discrete values; however, most phenomena in nature are continuous. To convert these continuous values into discrete values a dynamic discretization method has been used. With the obtained discrete series, we have built probabilistic finite automata which include all the representative information which the series contain. The learning algorithm to build these automata is polynomial in the sample size. An algorithm to predict new series has been proposed. This algorithm incorporates the randomness in nature. After finishing the three steps of the model, the similarity between the predicted series and the real ones has been checked. For this, a new adaptable test based on the classical KolmogoroveSmirnov two-sample test has been done. The cumulative distribution function of observed and generated series has been compared using the concept of indistinguishable values. Finally, the proposed model has been applied in several practical cases of time series of climatic parameters. 2004 Elsevier Ltd. All rights reserved.	algorithm;automata theory;discretization;finite-state machine;machine learning;mathematical model;polynomial;predictive failure analysis;probabilistic automaton;randomness;stationary process;time series	Llanos Mora López;Juan Mora;Rafael Morales Bueno;Mariano Sidrach de Cardona	2005	Environmental Modelling and Software	10.1016/j.envsoft.2004.04.007	kolmogorov–smirnov test;sample size determination;discrete mathematics;quantum finite automata;cumulative distribution function;computer science;machine learning;time series;mathematics;finite-state machine;computerized adaptive testing;statistics	AI	15.075948978242366	-20.737891181176277	112017
8e883e6537e1c71000fb40b31a5f7904ca0e29ad	polynomial genetic programming for response surface modeling			genetic programming;polynomial;response surface methodology	Kyung Ho Lee;Yun Seog Yeun;W. S. Ruy;Young Soon Yang	2002			genetic program;genetic programming;artificial intelligence;machine learning;polynomial;mathematical optimization;mathematics	Robotics	12.992589216699704	-23.182927307672497	112038
344cd7fa697cf5b7d56e526c64adba5ea3f467fd	prediction of composite suitability index for physical habitat simulations using the anfis method	zacco platypus;watershed monitoring data;composite suitability index;habitat suitability index;adaptive neuro fuzzy inference system anfis;physical habitat simulation	Conventional methods of physical habitat simulation use the habitat suitability index models.However, the habitat suitability index model can easily be affected by the subjective opinion of the expert.To overcome this weakness, this study introduces the ANFIS method for predicting the composite suitability index for use in physical habitat simulations. A physical habitat simulation is a useful tool for assessing the impact of river development or restoration on river ecosystem. Conventional methods of physical habitat simulation use the habitat suitability index models and their success depends largely on how well the model reflects monitoring data. One of preferred habitat suitability index models is habitat suitability curves, which are normally constructed based on monitoring data. However, these curves can easily be affected by the subjective opinion of the expert. This study introduces the ANFIS method for predicting the composite suitability index for use in physical habitat simulations. The ANFIS method is a hybrid type of artificial intelligence technique that combines the artificial neural network and fuzzy logic. The method is known to be a powerful approach especially for developing nonlinear relationships between input and output datasets.In this study, the ANFIS method was used to predict the composite suitability index for the physical habitat simulation of a 2.5km long reach of the Dal River in Korea. Zacco platypus was chosen as the target fish of the study area. A 2D hydraulic simulation was performed, and the hydraulic model was validated by comparing the measured and predicted water surface elevations. The distribution of the composite suitability index predicted by the ANFIS model was compared with that using the habitat suitability curves. The comparisons reveal that the two distributions are similar for various flows. In addition, the distribution of the composite suitability index of the Dal River is computed by the ANFIS method using monitoring data for the other watersheds, namely the Hongcheon River, the Geum River, and the Chogang Stream. The monitoring data for the Chogang Stream, correlation pattern of which was the most similar to that of the Dal River, yielded the distribution of the composite suitability index, which was very close to that obtained using data for the Dal River. This is also supported by the mean absolute percentage error for the difference in the weighted usable areas.	adaptive neuro fuzzy inference system;habitat;simulation	Sang Hwa Jung;Sung-Uk Choi	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.05.028	artificial intelligence;statistics;mathematics;machine learning;adaptive neuro fuzzy inference system;mean absolute percentage error;habitat;composite number	NLP	10.837248035359474	-19.87673313218096	112154
ce4a78056874f4137cbe9376b4c2689fbae863be	an improved gm(1, 1) model of integrated optimizing its background value and initial condition	prediction.;1 model;background value;initial condition;gm 1	  Although GM(1,1) model has been successfully adopted in various fields and demonstrated promising results, its predicting performance  still could be improved. Up to the present, the literatures show that whether the structure method of background value or  the selection of initial condition is logical or not, it affects the simulation and prediction precision directly. However,  most optimized models developed recently are optimized with one side. Based on the idea that we have above reasoned, an improved  GM(1,1) model of integrated optimizing its background value and initial condition is proposed in this paper, which applies a  more logical calculating formula of background value based on Newton interpolation and a relatively ingenious algorithm of  initial condition by adding an arbitrary constant. Furthermore, the LCD TV annual output of China is used as a case study  to examine the model reliability and accuracy. By comparisons of simulation and prediction data, a higher precision is found.    	initial condition;optimizing compiler	Yu-zhe Zhao;Chun-you Wu	2010		10.1007/978-3-642-14880-4_76		DB	11.42047216081718	-17.709328076925658	112299
3483f36900532ebdd39d3eb213593a4e37d9f930	evaluation of artificial intelligence models for actual crop evapotranspiration modeling in mulched and non-mulched maize croplands		Abstract Although many studies have demonstrated the good performances of artificial intelligence (AI) approaches for reference evapotranspiration modeling, the applicability of AI approaches for actual crop evapotranspiration (ET) modeling still remains uncertain, especially in plastic mulched croplands. The objective of the present study was to evaluate the applicability of two different artificial intelligence approaches, including support vector machine (SVM) and artificial neural network optimized by genetic algorithm (GANN), in modeling actual ET in a rainfed maize field under non-mulching (CK) and partial plastic film mulching (MFR). A field experiment was conducted for continuous measurements of ET, meteorological variables, leaf area index (LAI) and plant heights ( h c ) under both CK and MFR during maize seasons of 2011–2013. The meteorological data containing minimum, maximum, mean air temperature, minimum, maximum, mean relative humidity, solar radiation, wind speed and crop data including LAI and h c during maize growing seasons of 2011–2012 were used to trained the SVM and GANN models by using two different input combination, and data of 2013 were used to validate the performances of the models. The results indicated that SVM1 and GANN1 models with meteorological and crop data as input could accurately estimate maize ET, which confirmed the good performances of SVM and GANN models for maize ET estimation. The performances of SVM2 and GANN2 models only with meteorological data as input were relatively poorer than those of SVM1 and GANN1 models, but the estimated results were acceptable when only meteorological data were available. Due to the optimizing of the genetic algorithm, the GANN models performed a slightly better than the SVM models under both CK and MFR, and can be highly recommended to model ET.	artificial intelligence	Dahua Tang;Yu Feng;Daozhi Gong;Weiping Hao;Ningbo Cui	2018	Computers and Electronics in Agriculture	10.1016/j.compag.2018.07.029	evapotranspiration;support vector machine;leaf area index;field experiment;engineering;radiation;artificial intelligence	AI	11.254805584029754	-19.441306987160534	112783
de7b9f1f00ccb5079d9932592171399b033fe096	non-classical planning for robotic applications		For my dissertation I am focusing on non-classical planning for robotic applications. Much classical planning research relies on assumptions that do not hold in real world robotics applications. In many cases the entire world state is not known in advance and the events that occur in the future can not be known with certainty. Robots operating in the real world also need to be responsive and react to dynamic obstacles and events. I am currently a sixth year PhD student at the University of New Hampshire. I am focusing my research on non-classical planning for robotics applications. A lot of my research has been driven from the applications side of things and highlighted some of the shortcomings of traditional planning techniques. Specifically there many assumption of classical planning do not hold when performing planning for robotics. Very rarely is the initial state fully specified or known with much certainty. Events very often do happen outside of the control of the planning agent. Actions can fail and do not always take the same amount of time for repeated execution. Robots that take long periods to plan an entire solution on the order of minutes are much less practical in an environment with dynamic obstacles. Traditionally planning algorithms find a full solution from the current state all the way to the goal, but in many cases this can take too long. Real-Time Search is a promising area that aims to limit the amount of planning that is done before actions are executed. By doing this, obstacles that are moving toward the agent can be avoided. Lastly, providing heuristics to guide task and motion planning is another area that I am doing research in to help speed up solving times and improve the overall quality of solutions. This summary is criminally scarce on citations and I apologize. I hope that it is okay to refer the reader to my cited works for related work. Open Worlds and Temporal Uncertainty In this portion of my dissertation I have investigated two interesting classes of problems. The first revolves around the idea of Open World Planning. This is a type of planning Copyright c © 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. where the entire world state is not known a priori, but instead is slowly discovered over time. As the agent moves around the world and interacts with it through its sensor data it is able to develop a more accurate picture of the world state. In the 2013 ICAPS PlanRob paper (Kiesel et al. 2013), we examined a few domains that exhibit open worlds, but the most significant was the Search and Rescue domain. In this domain, a robot is tasked with finding injured victims inside of a building. To make this more difficult, the robot does not know the layout of the building and it also does not know the locations of any victims. The robot must balance exploration of the building and discovery of victims against an approaching temporal deadline to return to its home base. In this work we wanted to show that while overly complicated techniques are the norm, simpler techniques also can perform quite well. We implemented a form of Hindsight Optimization for our robot to use to search the building looking for victims. In our implementation of Hindsight Optimization, we would generate possible worlds that could exist given our current knowledge of the world. For example, we would have some concrete knowledge of the building layout given the history of our sensor data and given a very rough idea of what any building might look like we could generate random topological building layouts. Inside that topological building layout we would randomly distribute victims, or if an expected distribution was known, we would bias toward that. Given these possible worlds, we then used a very simple domain specific solver to try to maximize reward in each world. From that, we could then rank the next action the robot could execute based on the expectation of reward that would follow. The action would then be executed, new sensor data would arrive, new world samples would be generated, planning would happen again and finally a new next action would be selected. To show how versatile this approach is, in the 2014 ICAPS PlanRob paper (Kiesel and Ruml 2014), we shifted the focus from Open Worlds to Temporal Uncertainty. In this work we considered a simple robot assistant which could be given a variety of pick and place tasks around the house. The difficulty in this problem, was however, that there was uncertainty in the objects’ locations, the duration of each action executed, the success of an action execution and also exogenous events that occurred at uncertain time points. Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence	algorithm;artificial intelligence;automated planning and scheduling;heuristic (computer science);hindsight optimization;mobile manipulator;motion planning;open world;possible world;randomness;real-time search;real-time transcription;robot;robotics;smt placement equipment;solver	Scott Kiesel	2015			simulation;artificial intelligence	AI	19.554542919368735	-13.557439305681898	112986
27cd8ad5104d7dcaace793d95fdd2d52386bd1c6	ga with wisdom of artificial crowds for solving mastermind satisfiability problem			boolean satisfiability problem;mastermind;software release life cycle	Amine Ben Khalifa;Roman V. Yampolskiy	2011	Int. J. Intell. Games & Simulation			AI	22.310388846182168	-10.012912848442767	113358
f0e0fd7fa8dd46051dfc527e4e59812d254d630b	parameter inversion of constitutive model of soil using neural networks	neural network;parameter identification;soil constitutive model;tangent modulus of soil	Neural network models are developed for estimating model parameters of conditioned soils in EBP shield. The parameter identification of nonlinear constitutive model of soil mass is based on an inverse analysis procedure, which consists of minimizing the objective function representing the difference between the experimental data and the calculated data of the mechanical model. The models are found to have good predictive ability and are expected to be very useful for estimating model parameters of conditioned soils in EBP shield. © 2011 Springer-Verlag Berlin Heidelberg.	neural networks	Jizhe Wang;Shouju Li;Juan Cui;Lintao Man	2011		10.1007/978-3-642-23756-0_67	experimental data;constitutive equation;artificial neural network;nonlinear system;mathematical optimization;mathematics;inversion (meteorology)	ML	12.3555834547968	-20.086301567394376	113679
4f8fb88dc93e18572aeb9e3a196821cd7f32deb4	traditional wisdom and monte carlo tree search face-to-face in the card game scopone		We present the design of a competitive artificial intelligence for Scopone, a popular Italian card game. We compare rule-based players using the most established strategies (one for beginners and two for advanced players) against players using Monte Carlo Tree Search (MCTS) and Information Set Monte Carlo Tree Search (ISMCTS) with different reward functions and simulation strategies. MCTS requires complete information about the game state and thus implements a cheating player, whereas ISMCTS can deal with incomplete information and thus implements a fair player. Our results show that, as expected, the cheating MCTS outperforms all the other strategies; ISMCTS is stronger than all the rule-based players implementing well-known and most advanced strategies and it also turns out to be a challenging opponent for human players.	artificial intelligence;logic programming;monte carlo method;monte carlo tree search;simulation;tree traversal	Marcos Norio Watanabe;Pier Luca Lanzi	2018	IEEE Transactions on Games	10.1109/TG.2018.2834618	machine learning;computer science;task analysis;complete information;cheating;artificial intelligence;decision tree;monte carlo method;monte carlo tree search;information set;face-to-face	AI	18.63816536097281	-18.183515009146724	113804
4b145e5f34da4f939f76681fb3cffd5bbad9de1b	skill combination for reinforcement learning	reinforcement learning	Recently researchers have introduced methods to develop reusable knowledge in reinforcement learning (RL). In this paper, we define simple principles to combine skills in reinforcement learning. We present a skill combination method that uses trained skills to solve different tasks in a RL domain. Through this combination method, composite skills can be used to express tasks at a high level and they can also be re-used with different tasks in the context of the same problem domains. The method generates an abstract task representation based upon normal reinforcement learning which decreases the information coupling of states thus improving an agent’s learning. The experimental results demonstrate that the skills combination method can effectively reduce the learning space, and so accelerate the learning speed of the RL agent. We also show in the examples that different tasks can be solved by combining simple reusable skills.	high-level programming language;knowledge representation and reasoning;problem domain;reinforcement learning	Zhihui Luo;David A. Bell;Barry McCollum	2007		10.1007/978-3-540-77226-2_10	semi-supervised learning;unsupervised learning;robot learning;multi-task learning;error-driven learning;simulation;computer science;artificial intelligence;machine learning;learning classifier system	AI	19.735114773073285	-21.46517663362435	113839
d4f9d751f71201449d787fabe83d7cd43bed4960	load balancing for multi-threaded pdes of stochastic reaction-diffusion in neurons	load balancing;multi-threaded pdes;q-learning;simulated annealing;stochastic neuronal simulation;window control	Chemical reactions and molecular diffusion in a neuron play an important role in the transmission of signals within a neuron. Discrete event stochastic simulation of the chemical reactions and diffusion provides a more detailed view of the molecular dynamics within a neuron than continuous simulation. As part of the NEURON project we developed a multi-threaded optimistic PDES simulator, Neuron Time Warp-Multi Thread, for these reaction-diffusion models. We used NTW-MT to simulate a calcium wave model due to its importance to the neuroscience community and representativeness of the types of reaction-diffusion problems which need to be solved in neuroscience. During the course of our experiments we observed a decided need for load balancing and window control to achieve large-scale runs. In this paper, we improved the Q-Learning and Simulated Annealing load balancing algorithm according to characteristics of reaction and diffusion model to address both of these issues. We evaluated the algorithms by various parameters in various scales, and our results showed that (1) the algorithm improves the execution time for small simulations by up to 31% (using Q-Learning) and 19% (using SA) and (2) the SA approach is more suitable for larger models, decreasing the execution time by 41%.	algorithm;calcium;equilibrium;large;load balancing (computing);molecular dynamics;neuron;numerous;population;q-learning;run time (program lifecycle phase);simulated annealing;simulation;sulfanilamide;thread (computing)	Zhongwei Lin;Carl Tropper;Yiping Yao;Robert A. McDougal;Mohammand Nazrul Ishlam Patoary;William W. Lytton;Michael L. Hines	2017	Journal of simulation : JOS	10.1057/s41273-016-0033-x	simulation;q-learning;continuous simulation;computer science;reaction–diffusion system;simulated annealing;load balancing (computing);thread (computing);diffusion (business);stochastic simulation	Metrics	15.534034232125054	-10.580024290821163	113867
e6bb90d9584aa59df2e995b4a5ca8aa6bb11b471	decentralised channel allocation and information sharing for teams of cooperative agents	agile teaming;decentralised control;incentive engineering;multi agent learning;communication;applications;teamwork	In a wide range of emerging applications, from disaster management to intelligent sensor networks, teams of software agents can be deployed to effectively solve complex distributed problems. To achieve this, agents typically need to communicate locally sensed information to each other. However, in many settings, there are heavy constraints on the communication infrastructure, making it infeasible for every agent to broadcast all relevant information to everyone else. To address this challenge, we investigate how agents can make good local decisions about what information to send to a set of communication channels with limited bandwidths such that the overall system utility is maximised. Specifically, to solve this problem efficiently in large-scale systems with hundreds or thousands of agents, we develop a novel decentralised algorithm. This combines multi-agent learning techniques with fast decisiontheoretic reasoning mechanisms that predict the impact a single agent has on the entire system. We show empirically that our algorithm consistently achieves 85% of a hypothetical centralised optimal strategy with full information, and that it significantly outperforms a number of baseline benchmarks (by up to 600%).	algorithm;baseline (configuration management);benchmark (computing);centralisation;cobham's thesis;cognitive radio;converge;multi-agent system;nash equilibrium;network congestion;reinforcement learning;software agent;theory	Sebastian Stein;Simon Andrew Williamson;Nicholas R. Jennings	2012			simulation;teamwork;knowledge management;information technology	AI	19.56944347524408	-15.202462522665279	113982
5b74c56ff7f1379907bf6657ab0138b4870e1c2f	predictive model based on artificial neural network for assessing beef cattle thermal stress using weather and physiological variables		Abstract The performance of feedlot cattle is adversely affected by thermal stress but the approach to assess the status of animal stress can be laborious, invasive, and/or stressful. To overcome these constraints, the present study proposes a model based on an artificial neural network (neural model), for individual assessment of the level of thermal stress in feedlot finishing cattle considering both weather and animal factors. An experiment was performed using two different groups of Nellore cattle. Physiological and weather data were collected during both experiments including surface temperatures for four selected spots, using infrared thermography (IRT). The data were analyzed (in terms of Pearson’s correlation) to determine the best correlation between the weather and physiological measurements and the IRT measurements for defining the best body location and physiological variable to support the neural model. The neural model had a feed-forward and multi-layered architecture, was trained by supervised learning, and accepted IRT, dry bulb temperature, and wet bulb temperature as inputs to estimate the rectal temperature (RT). A regression model was built for comparison, and the predicted and measured RTs were classified on levels of thermal stress for comparing with the classification based on the traditional temperature–humidity index (THI). The results suggested that the neural model has a good predictive ability, with an R 2 of 0.72, while the regression model yielded R 2 of 0.57. The thermal stress predicted by the neural model was strongly correlated with the measured RT (94.35%), and this performance was much better than that of the THI method. In addition, the neural model demonstrated good performance on previously unseen data (ability to generalize), and allowed the individual assessment of the animal thermal stress conditions during the same period of day.	artificial neural network	Rafael Vieira de Sousa;Alex Vinicius da Silva Rodrigues;Mariana Gomes de Abreu;Rubens Andre Tabile;Luciane Silva Martello	2018	Computers and Electronics in Agriculture	10.1016/j.compag.2017.11.033	regression analysis;computer vision;artificial neural network;artificial intelligence;statistics;beef cattle;supervised learning;dry-bulb temperature;wet-bulb temperature;engineering;thermography;feedlot	NLP	12.010393037827404	-19.57633777414345	114106
2e402e57655728b5775a51f5659e75e94ddbd82c	time series forecasting by evolving artificial neural networks with genetic algorithms, differential evolution and estimation of distribution algorithm	forecasting;differential evolution;evolutionary computation;time series;artificial neural networks;estimation of distribution algorithm;genetic algorithms	Time series forecasting is an important tool to support both individual and organizational decisions (e.g. planning production resources). In recent years, a large literature has evolved on the use of evolutionary artificial neural networks (EANN) in many forecasting applications. Evolving neural networks are particularly appealing because of their ability to model an unspecified nonlinear relationship between time series variables. In this work, two new approaches of a previous system, automatic design of artificial neural networks (ADANN) applied to forecast time series, are tackled. In ADANN, the automatic process to design artificial neural networks was carried out by a genetic algorithm (GA). This paper evaluates three methods to evolve neural networks architectures, one carried out with genetic algorithm, a second one carried out with differential evolution algorithm (DE) and the last one using estimation of distribution algorithms (EDA). A comparative study among these three methods with a set of referenced time series will be shown. In this paper, we also compare ADANN forecasting ability against a forecasting tool called Forecast Pro® (FP) software, using five benchmark time series. The object of this study is to try to improve the final forecasting getting an accurate system.	artificial neural network;benchmark (computing);differential evolution;estimation of distribution algorithm;experiment;feasible region;genetic algorithm;hurricane weather research and forecasting model;hybrid system;mimic;maxima and minima;nonlinear system;software release life cycle;time series	Juan Peralta;Xiaodong Li;Germán Gutiérrez;Araceli Sanchis	2011	Neural Computing and Applications	10.1007/s00521-011-0741-0	differential evolution;genetic algorithm;estimation of distribution algorithm;forecasting;computer science;artificial intelligence;machine learning;time series;data mining;artificial neural network;statistics;evolutionary computation	ML	12.798331734630295	-22.992626347217165	114350
2c89ae5383c7bbd7e84bbd9335102434e18d3002	estimating the predictability and the linearity of a process by kernels	kernel;linearity;nonlinear character process predictability estimation process linearity estimation discrete time process data system identification time series prediction statistical estimation theory;jamming;estimation;predictive models;kernel predictive models estimation reactive power jamming linearity data models;time series prediction theory signal classification;data models;reactive power	"""On the basis of discrete-time process data for system identification (or time-series prediction), it would be very desirable to determine a priori how unpredictable and how nonlinear a process is. Showing how this can be done by adopting the framework of statistical estimation theory is the purpose of this paper. Inferring the predictability of a process is important for estimating in advance which prediction performance can be realistically expected from a model. The """"degree"""" of nonlinearity of the underlying process should also be assessed before the design of a suitable model is undertaken. If the data do not reveal a markedly nonlinear character, the irrelevance of nonlinear models will be noticed in advance, thereby saving time which would otherwise be lost on an unnecessary search."""	degree (graph theory);estimation theory;nonlinear programming;nonlinear system;relevance;system identification;time series	Andreas Poncet;George S. Moschytz	1998	9th European Signal Processing Conference (EUSIPCO 1998)		econometrics;computer science;machine learning;statistics	Vision	23.931442713947146	-23.179358033248228	114770
3dd5116d96882498b1ba277707c03a58d8413df4	average run length when monitoring capability indices using ewma	capability chart;average run length;capability indices;ewma	Abstract#R##N##R##N#In order to monitor unstable but capable processes Castagliola and Vannman have recently suggested a procedure based on an EWMA approach, called EWMA capability chart, for monitoring Vannman's Cp(u,v)-family of capability indices and showed how their proposed approach efficiently monitors capable processes by detecting a decrease or increase in the capability level. The goal of this paper is to investigate the efficiency of this capability chart in terms of ARL. The procedure used for computing this ARL is presented and simple guidelines for obtaining approximations to the optimal EWMA parameters are proposed. Copyright © 2008 John Wiley & Sons, Ltd.	run-length encoding	Philippe Castagliola;Kerstin Vännman	2008	Quality and Reliability Eng. Int.	10.1002/qre.940	ewma chart;reliability engineering;engineering;operations management;operations research	NLP	14.450585613118536	-13.42826295526717	114790
96a1675298df10d2c01db55eec3d794f43d0c2e2	anomalies detection in the behavior of processes using the sensor validation theory		Behavior can be defined as combination of variable’s values according to external inputs or environmental changes. This definition can be applied to persons, equipment, social systems or industrial processes. This paper proposes a probabilistic mechanism to represent the behavior of industrial equipment and an algorithm to identify deviations to this behavior. The anomaly detection mechanisms, together with the sensor validation theory are combined to propose an efficient manner to diagnose industrial equipment. A case study is presented with the failure identification of a wind turbine. The diagnosis is conducted when detecting deviations to the turbine normal behavior.	anomaly detection;dynamic bayesian network;experiment;fast software encryption;randomized algorithm;sensor;social system	Pablo H. Ibargüengoytia;Uriel A. García;Alberto Reyes;Mónica Borunda	2016		10.1007/978-3-319-47955-2_2	anomaly detection;wind power;reliability engineering;turbine;probabilistic logic;bayesian network;computer science	AI	12.94628755163066	-14.266439283348038	114855
dc484ce55a4cf5b1891c93ec45c0d984039f4ea4	prediction of compressive strength of self-compacting concrete by anfis models		Abstract Many studies predict the compressive strength of conventional concrete from hardened characteristics; however, in the case of self-compacting concrete, these investigations are very rare. There is no study to predict the compressive strength of self-compacting concrete from mixture proportions and slump flow. This paper designs ANFIS models to establish relationship between the compressive strength as output, and slump flow and mixture proportions as input in eighteen combinations of input parameters. The applied dada is taken from 55 previously conducted experimental studies. Effect of each parameter on the compressive strength and its importance level in the developed model has been investigated. Based on the error size in each combination analysis, weighting factor and importance level of each parameter is evaluated to apply the correction factors to get the most optimized relationship. Obtained results indicate that the model including all input data (slump flow and mixture proportions) gives the best prediction of the compressive strength. Excluding the slump flow from combinations affects the prediction of compressive strength, considerably. However itu0027s not as much as the effect of the maximum aggregate size and aggregate volume in the mixture design. In addition, different values of powder volume, aggregate volume and paste content in the mixture reveal different ascending and descending effects on the compressive strength.	adaptive neuro fuzzy inference system	Behnam Vakhshouri;Shami Nejadi	2018	Neurocomputing	10.1016/j.neucom.2017.09.099	adaptive neuro fuzzy inference system;artificial intelligence;compressive strength;mathematics;pattern recognition;slump;weighting;composite material	Crypto	12.031120551400448	-19.675384169194785	115113
688215185a426922f47505ec7a589141132e21d2	local models for data-driven learning of control policies for complex systems	data driven control;nadaraya watson models;local learning	0957-4174/$ see front matter 2012 Elsevier Ltd. A http://dx.doi.org/10.1016/j.eswa.2012.05.063 ⇑ Corresponding author. Tel.: +39 0106475835; fax E-mail addresses: ddmach@ge.issia.cnr.it (D. Mac (C. Cervellera). An approach based on local learning, relying on Nadaraya–Watson models (NWMs), is introduced for the problem of deriving an automatic controller able to exploit data collected during the operation of some complex plant or system by a reference teacher (e.g., a human operator). Such learning approach is particularly useful when the system is too complex to be modeled accurately and/or the task cannot be easily formalized by a cost function, a situation which rules out classic approaches based, e.g., on dynamic programming. Here it is proved that local models are a suitable solution for a real-time employment, since they allow to incorporate new information directly and efficiently without the need of offline training, and new data immediately reflect in improvement of performance. To this purpose, convergence analysis of the method is provided, also considering the case where the reference controller introduces random variations in the training data. Finally, a simulation test, concerning the control of a mechanical system, is provided to showcase the use of local models in an applicative scenario. 2012 Elsevier Ltd. All rights reserved.	applicative programming language;complex systems;dynamic programming;fax;loss function;online and offline;real-time clock;real-time computing;simulation	Danilo Macciò;Cristiano Cervellera	2012	Expert Syst. Appl.	10.1016/j.eswa.2012.05.063	simulation;computer science;artificial intelligence;machine learning;mathematics	ML	21.821510116577837	-23.129677361320116	115627
4dfc6033bbd34b60bcc03ba3b528aa0fb564790b	heterogeneous double populations based hybrid genetic algorithm design for training feedforward neural networks	feedforward neural network;feedforward neural networks;least squares approximations;measurement noise heterogeneous double populations based hybrid genetic algorithm feedforward neural network training gradient based leaning method nn neuron context dependence problem genetic representation permutation problem hybrid ga design least squares estimator neuron optimization hidden neuron parameter approximation generalization capability;training;least squares feedforward neural network training permutation problem genetic algorithm;neurons artificial neural networks training genetic algorithms genetics optimization feedforward neural networks;genetics;least squares;artificial neural networks;least squares approximations feedforward neural nets generalisation artificial intelligence genetic algorithms gradient methods learning artificial intelligence;gradient methods;permutation problem;genetic algorithm;genetic algorithms;optimization;feedforward neural nets;neurons;generalisation artificial intelligence;learning artificial intelligence	Genetic algorithms (GA) has been extensively applied to address the shortcomings of gradient based leaning methods in training feedforward neural networks (NN). However, the complicated properties of NN training, such as context dependence problem between neurons and permutation problem of genetic representation, will cause difficulties in efficiently implementing conventional GAs. In the present study, a novel hybrid GA design is proposed to overcome these problems. First, for the sake of eliminating the context dependence, the new method adopts GA and least squares estimator to separately optimize the neurons in hidden and output layers. Second, in order to completely avoid the permutation problem, the proposed GA design employs two heterogeneous populations that evolve in company but respectively learn the optimal combinations and parameters of hidden neuron. Finally, experimental studies encouragingly show that, in comparison with five well-known conventional approaches, the new training method displays a much better approximation and generalization capabilities in nonlinear static and dynamic modeling, especially for the observed signals corrupted with large measurement noises.	algorithm design;approximation;artificial neural network;experiment;feed forward (control);feedforward neural network;genetic algorithm;genetic representation;gradient;least squares;mathematical optimization;memetic algorithm;neuron;nonlinear system;population;software release life cycle;teaching method;utility functions on indivisible goods	Li Feng Zhang;Rong He;Meng Ling Yan	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6252929	feedforward neural network;mathematical optimization;genetic algorithm;computer science;artificial intelligence;machine learning;artificial neural network	ML	13.998123803977457	-23.85718574184491	115902
66ddb5d1ada89b1fb050843ae31399f01a7e336e	dynamic control of data measurement intervals in a networked sensing system using neurocomputing	networked sensing system artificial neural network dynamic measurement interval intelligent transportation;transportation networks;networked sensing system;neurocomputing;low energy;neural nets;environmental parameter;dynamic control;transport system;wireless sensor networks containers data handling energy consumption food safety neural nets transportation;wireless sensor network;intelligent transportation;energy consumption;food safety;transportation process;transport process;transportation;humidity measurement;area measurement;data measurement interval;food quality;food quality supervision;data handling;power consumption;data approximation;wireless sensor networks;simulation environment;dynamic measurement interval;power consumption dynamic control data measurement interval networked sensing system neurocomputing wireless sensor network food quality supervision transportation process artificial neural network data approximation;containers;artificial neural network;humidity measurement area measurement	A new algorithm for dynamic controlling of data measurement intervals in a networked sensing system (NSS) is presented in this paper. The method is developed on a wireless sensor network (WSN) for food quality supervision during the transportation process using containers. The artificial neural network (ANN) is used for data approximation due to its learning capability and high flexibility. At each instance, the measurement interval is changed dynamically depending on the stability of the environmental parameters in the container. The wireless sensor network is able to detect the possible unstable situations automatically with low energy consumption. Firstly, the performance of the dynamic control mechanism is tested in a simulation environment. Later, the developed algorithm is implemented to adjust the measurement intervals in a real transportation system. The new developed technique could be applied to decrease the power consumption in various applications of the networked sensing systems.	algorithm;approximation;artificial neural network;backpropagation;computational neuroscience;control theory;maxima and minima;sampling (signal processing);simulation	Xinwei Wang;Amir Sheikh Jabbari;Rainer Laur;Walter Lang	2010	2010 Seventh International Conference on Networked Sensing Systems (INSS)	10.1109/INSS.2010.5573671	control engineering;embedded system;real-time computing;engineering	Robotics	12.118529650556416	-16.885841589851903	116277
4d92df4a844c94fbb31b95157488e4b562b4f681	the optimal reward baseline for gradient-based reinforcement learning	system modeling;reinforcement learning;conference paper;learning system;gradient estimate;partial observation	There exist a number of reinforcement learning algorithms which learn by climbing the gradient of expected reward. Their long-run convergence has been proved, even in partially observable environments with non-deterministic actions, and without the need for a system model. However, the variance of the gradient estimator has been found to be a significant practical problem. Recent approaches have discounted future rewards, introducing a bias-variance trade-off into the gradient estimate. We incorporate a reward baseline into the learning system, and show that it affects variance without introducing further bias. In particular, as we approach the zerobias, high-variance parameterization, the optimal (or variance minimizing) constant reward baseline is equal to the long-term average expected reward. Modified policy-gradient algorithms are presented, and a number of experiments demonstrate their improvement over previous work.	algorithm;baseline (configuration management);experiment;gradient;machine learning;partially observable system;reinforcement learning;state space;three-state logic;variance reduction	Lex Weaver;Nigel Tao	2001			mathematical optimization;simulation;systems modeling;reward-based selection;computer science;machine learning;mathematics;reinforcement learning;q-learning	ML	21.896060259557935	-18.511567263931852	116479
63ff27ebb969044436b2e4270ed05d55d1a692e0	multiple relaxations in temporal planning	planning and scheduling;temporal information;electronic computers computer science	CRIKEY is a planner that separates out the scheduling from the classical parts of temporal planning. This can be seen as a relaxation of the temporal information during the classical planning phase. Relaxations in planning are used to guide the search. However, the quality of the relaxation greatly affects the performance of the planner, and in some cases can lead the search into a dead end. This can happen whilst separating out the planning and scheduling problems, leading to the production of an unschedulable plan. CRIKEY can detect these cases and change the relaxation accordingly.	automated planning and scheduling;linear programming relaxation;scheduling (computing);while	Keith Halsey;Derek Long;Maria Fox	2004			mathematical optimization;simulation;computer science	AI	18.098831383361812	-10.439697217094892	116504
ddd7eb5827761063ce8281b97522fe27667ccc6c	modular neural network and classical reinforcement learning for autonomous robot navigation: inhibiting undesirable behaviors	neural networks;path planning;autonomous robot navigation;reinforcement learning;inner triggered reinforcement modular neural network reinforcement learning autonomous robot navigation intelligent autonomous system mobile robot navigation;neural networks learning navigation neurons robot sensing systems intelligent systems competitive intelligence mobile robots scholarships trajectory;mobile robots;autonomic system;engineering and technology;teknik och teknologier;technology and engineering;mobile robot navigation;path planning mobile robots neurocontrollers;neurocontrollers;modular neural network;neuronal activity;autonomous robot	Classical reinforcement learning mechanisms and a modular neural network are unified for conceiving an intelligent autonomous system for mobile robot navigation. The conception aims at inhibiting two common navigation deficiencies: generation of unsuitable cyclic trajectories and ineffectiveness in risky configurations. Distinct design apparatuses are considered for tackling these navigation difficulties, for instance: 1) neuron parameter for memorizing neuron activities (also functioning as a learning factor), 2) reinforcement learning mechanisms for adjusting neuron parameters (not only synapse weights), and 3) a inner-triggered reinforcement. Simulation results show that the proposed system circumvents difficulties caused by specific environment configurations, improving the relation between collisions and captures.	artificial neural network;autonomous robot;autonomous system (internet);computation;experiment;mobile robot;modular neural network;neuron;reinforcement learning;robotic mapping;simulation;synapse;synaptic weight	Eric A. Antonelo;Albert-Jan Baerveldt;Thorsteinn S. Rögnvaldsson;Mauricio Figueiredo	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.246723	mobile robot;error-driven learning;simulation;computer science;artificial intelligence;motion planning;reinforcement learning;mobile robot navigation;artificial neural network;premovement neuronal activity	Robotics	17.966574636669154	-22.004022488417554	116667
fbaa847e76dc5eeaf9a7a6ea8fe0cb693ace0d8f	adding expert knowledge and exploration in monte-carlo tree search	computer go;monte carlo tree search;uct;expert knowledge;monte carlo simulation	We present a new exploration term, more efficient than classical UCT-like exploration terms and combining efficiently expert rules, patterns extracted from datasets, All-Moves-As-First values and classical online values. As this improved bandit formula does not solve several important situations (semeais, nakade) in computer Go, we present three other important improvements which are central in the recent progress of our program MoGo: – We show an expert-based improvement of Monte-Carlo simulations for nakade situations; we also emphasize some limitations of this modification. – We show a technique which preserves diversity in the Monte-Carlo simulation, which greatly improves the results in 19x19. – Whereas the UCB-based exploration term is not efficient in MoGo, we show a new exploration term which is highly efficient in MoGo. MoGo recently won a game with handicap 7 against a 9Dan Pro player, Zhou JunXun, winner of the LG Cup 2007, and a game with handicap 6 against a 1Dan pro player, Li-Chen Chien. 1	computer go;entity–relationship model;monte carlo method;monte carlo tree search;simulation	Guillaume Chaslot;Christophe Fiter;Jean-Baptiste Hoock;Arpad Rimmel;Olivier Teytaud	2009		10.1007/978-3-642-12993-3_1	simulation;computer science;artificial intelligence;machine learning;mathematics;monte carlo tree search;algorithm;statistics;monte carlo method	ML	19.577637984205577	-17.673779572484268	116731
6bd8427718fbe866a9ba2f45ba71c256d9b762ac	learning coordination strategies for multiple robots	game theory;multirobot systems;robot kinematics design engineering systems engineering and theory convergence scalability air traffic control parallel robots fault tolerant systems process design delay;cooperative predator prey games coordination strategy learning multiple robots multirobot systems convergence problems credit assignment problems scalability problems noncooperative prisoners dilemma;cooperative systems;multi robot systems;learning artificial intelligence;game theory multi robot systems cooperative systems learning artificial intelligence	The central issue in the design of multi-robot systems is the coordination of the robots’ behaviors. Daditionally, this has been done b y hand-coding complex strategies. Recent work has focussed on how strategies can be learned, but many of these systems suffer from convergence, credit assignment and scalability problems. This paper proposes a new approach for learning multi-robot coordination strategies that addresses these concerns. The effectiveness of the technique is demonstrated using the non-cooperative prisoners ’ dilemma and the cooperative predator and prey domains.	hand coding;prey;robot;scalability;vergence	Fenton Ho;Mohamed S. Kamel	1998		10.1109/IROS.1998.724632	game theory;simulation;engineering;artificial intelligence;distributed computing	Robotics	17.95944860301997	-19.42583941080577	116841
39c440d23424e14556016748947f9eff045ca557	space-time continuous models of swarm robotic systems - supporting global-to-local programming		This work was done within the “Research Training Group” GRK 1194 “Self-organizing Sensor-Actuator Networks” in the subproject I2 “Decentral Task Processing by Cooperation and Interaction”. A generic model in as far as possible mathematical closed-form was developed that predicts the behavior of large self-organizing robot groups (robot swarms) based on their control algorithm. In addition, an extensive subsumption of the relatively young and distinctive interdisciplinary research field of swarm robotics is emphasized. The connection to many related fields is highlighted and the concepts and methods borrowed from these fields are described shortly. Large groups of small robots, mostly of limited equipment are applied in swarm robotics forming a decentral system. All robots are autonomous and act on the basis of locally available information. The development of the control algorithm, that is to be executed locally on each robot, has proven to be difficult. This development of the local control algorithm is defined and constrained by the global task (global-to-local programming, or also micro-macro problem). The classical reductionistic approach is of limited use here (problem of designing emergence). For example, the resulting behavior of the robot swarm often contradicts the intuition of the program developer due to effects of the many robot–robot interactions that cannot be anticipated. The support of the swarm algorithm developer by models is an approach that has already been discussed in the literature several times. The quickly available predictions of the model are supposed to support the development early before the implementation on the robots. Even complete parameter intervals can be scanned for optimal values. Furthermore, the development and the application of models can result in a better understanding of the effective processes in swarms concerning both the general understanding and in a particular application. The modeling approach proposed in this work is particularly distinguished by the explicit representation of space and the, at least partially existent, formal connection between the microand the macro level. The basic model of the robot positions is motivated by Brownian motion and consists of a pair of corresponding equations. While the Langevin equation (a stochastic differential equation) gives a local (microscopic) description of concrete trajectories, the Fokker–Planck equation (also Kolmogorov forward equation, a partial differential equation), that can be analytically derived from the Langevin equation, gives a global (macroscopic) description by means of probability densities. This physical model was extended to a generic model of communicating robot groups based on heuristic arguments. This model approach has a variety of applications, however, the adaptation to a specific control algorithm is a demanding modeling step. The proposed model is validated against several swarm robotic scenarios applying real robots and simulations: collision-based adaptive aggregation, collective perception, collective phototaxis, foraging with virtual pheromones, and tree-like aggregation. The required adaptation of the model to the according situation is exemplified (modeling state transitions, parameter selection, measurement etc.). The achieved accuracy of the model predictions is good and sufficient to be a support in the algorithm development phase.	algorithm;autonomous robot;brownian motion;collective intelligence;emergence;heuristic;interaction;kolmogorov equations;organizing (structure);reductionism;self-organization;simulation;subsumption architecture;swarm robotics	Heiko Hamann	2010		10.1007/978-3-642-13377-0	swarm robotics	Robotics	17.434054870992817	-19.86021965922088	117139
039df729edbc7c20085fda50599241ea626d20f0	detecting adversarial attacks on neural network policies with visual foresight		Deep reinforcement learning has shown promising results in learning control policies for complex sequential decision-making tasks. However, these neural network-based policies are known to be vulnerable to adversarial examples. This vulnerability poses a potentially serious threat to safety-critical systems such as autonomous vehicles. In this paper, we propose a defense mechanism to defend reinforcement learning agents from adversarial attacks by leveraging an actionconditioned frame prediction module. Our core idea is that the adversarial examples targeting at a neural network-based policy are not effective for the frame prediction model. By comparing the action distribution produced by a policy from processing the current observed frame to the action distribution produced by the same policy from processing the predicted frame from the action-conditioned frame prediction module, we can detect the presence of adversarial examples. Beyond detecting the presences of adversarial examples, our method allows the agent to continue performing the task using the predicted frame when the agent is under attack. We evaluate the performance of our algorithm using five games in Atari 2600. Our results demonstrate that the proposed defense mechanism achieves favorable performance against baseline algorithms in detecting adversarial examples and in earning rewards when the agents are under attack.	adversary (cryptography);algorithm;artificial neural network;atari;autonomous robot;baseline (configuration management);numerical weather prediction;reinforcement learning;sensor	Yen-Chen Lin;Ming-Yu Liu;Min Sun;Jia-Bin Huang	2017	CoRR		machine learning;artificial intelligence;futures studies;adversarial system;computer science;artificial neural network;reinforcement learning;vulnerability	AI	18.151130879889045	-19.72819624305293	117214
b62efc4466cd7b26fed182f980462f10f77fbf7b	learning to win process-control games watching game-masters	metodo matematico;mathematical method;learning;aprendizaje probabilidades;aprendizaje;control proceso;apprentissage;winning strategy;process control;methode mathematique;apprentissage probabilites;one player immortality game;commande processus;probability learning	The present paper focuses on some interesting classes of process-control games, where winning essentially means successfully controlling the process. A master for one of these games is an agent who plays a winning-strategy. Learners try to nd programs for winning strategies for such games from a program for (or model of) the process to be controlled and by watching masters play winning strategies. Studied are successful learning from arbitrary masters and from hopefully pedagogically useful selected masters. It is shown that selected masters are strictly more helpful for learning than are arbitrary masters. Both for learning from arbitrary masters and for learning from selected masters, though, there are cases where one can learn programs for winning strategies from masters but not if one is required to learn a program for the master's strategy itself! Both for learning from arbitrary masters and for learning from selected masters, surprisingly, one can learn strictly more watching m + 1 masters than one can learn watching only m. Lastly a simulation result is presented where the presence of a selected master reduces the complexity from innnitely many semantic mind changes to nitely many syntactic ones.	simulation	John Case;Matthias Ott;Arun Sharma;Frank Stephan	2002	Inf. Comput.	10.1006/inco.2000.2946	simulation;computer science;artificial intelligence;process control;mathematics;operations research;algorithm	AI	18.44035534436688	-12.78186866988738	117401
53b7fa5d62f6735672c86cb17c03a4f479a35819	implementation of vlsi model as a tool in diagnostics of slowly varying process parameters which affect the performance of steam turbine	modelsim;verilog;steam turbine;on line diagnostic analyser	There is a global challenge in demand and need of electricity. Whenever a serious fault occurs, it affects the productivity of any power plant. So many indicators have been identified in real-time fault diagnosis of steam turbine which is extremely important in a functioning power plant. Detection of fault and early rectification requires a real time intelligent fault diagnostic system. This paper considers seven types of very slowly happening and accumulating physical phenomena which will ultimately lead to deterioration in turbine performance. Based on the acquired domain knowledge, an online intelligent diagnostic analyzer for turbine performance degradation is designed in this paper by using a VLSI based team turbine n-line diagnostic analyser erilog odelsim methodology written in Verilog code and simulated using a simulator (Modelsim Altera 6.4a). This system can be easily implemented on to FPGA which enables the identification of the root causes for turbine performance degradation. The simulation results show that the developed real-time fault diagnostic system is accurate, high percentile with less time consuming, cost effective, and easy to apply and user friendly. © 2014 Elsevier B.V. All rights reserved.	elegant degradation;field-programmable gate array;real-time clock;real-time operating system;rectifier;simulation;usability;verilog;very-large-scale integration	L. Sivakumar;S. Devi	2014	Appl. Soft Comput.	10.1016/j.asoc.2014.08.015	embedded system;simulation;steam turbine	Robotics	12.380390092572872	-15.571540195468593	117704
801ba2f60e96f9b8d7ebac2d57a7e407586758ac	increasing behavioral complexity for evolved virtual creatures with the esp method		Since their introduction in 1994 [26], evolved virtual creatures (EVCs) have employed the coevolution of morphology and control to produce high-impact work in multiple fields, including graphics, evolutionary computation, robotics, and artificial life. However, in contrast to fixed-morphology creatures, there has been no clear increase in the behavioral complexity of EVCs in those two decades. This paper describes a method for moving beyond this limit, making use of high-level human input in the form of a syllabus of intermediate learning tasks—along with mechanisms for preservation, reuse, and combination of previously learned tasks. This method—named ESP for its three components: encapsulation, syllabus, and pandemonium—is presented in two complementary versions: Fast ESP, which constrains later morphological changes to achieve linear growth in computation time as behavioral complexity is added, and General ESP, which allows this restriction to be removed when sufficient computational resources are available. Experiments demonstrate that the ESP method allows evolved virtual creatures to reach new levels of behavioral complexity in the co-evolution of morphology and control, approximately doubling the previous state of the art.	artificial life;cognitive complexity;computational resource;creatures;esp game;encapsulation (networking);evolutionary computation;experiment;galaxy morphological classification;graphics;high- and low-level;horner's method;linear function;mathematical morphology;monte carlo method;pandemonium!;period-doubling bifurcation;robotics;time complexity	Dan Lessin;Don Fussell;Risto Miikkulainen;Sebastian Risi	2015	CoRR		simulation;computer science;artificial intelligence;machine learning	Graphics	17.14955005838197	-18.713868229080145	117853
7ca72db3558e1ec67e23f6eb2a3b9e3a5449e284	a probabilistic long term prediction approach for highway scenarios	acceleration mechanics;driving;vehicles acceleration predictive models prediction algorithms measurement uncertainty computational modeling trajectory;risk assessment;road traffic control automobiles gaussian distribution gaussian processes intelligent transportation systems mixture models;behavior;constant velocity assumption probabilistic long term prediction approach highway scenarios traffic situation safe autonomous driving systems uncertain risk estimation computation traffic participant behavior comfort aspects fuel consumption reduction lane change maneuvers gaussian mixtures conditional distribution position uncertainty quantification position uncertainty prediction situation dependent probabilistic output constant acceleration assumption traffic dependent predictions;autonomous intelligent cruise control;lane changing;autonomous land vehicles	Risk estimation for the current traffic situation is crucial for safe autonomous driving systems. The computation of risk estimates however is always uncertain, especially if the behavior of traffic participants has to be taken into account. Besides risk estimation, knowledge about the future behavior of other traffic participants can be used for Adaptive Cruise Control Applications, helping to choose a driving strategy with more foresight, which is not only desirable under comfort aspects, but can also be used to reduce fuel consumption. In this publication we focus on highway scenarios, where possible behaviors consist of changes in acceleration and lane-change maneuvers. Based on this insight we present a novel approach for the prediction of future positions in highway scenarios.	autonomous car;computation;lateral thinking;risk assessment	Julian Schlechtriemen;Andreas Wedel;Gabi Breuel;Klaus-Dieter Kuhnert	2014	17th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2014.6957776	control engineering;simulation;engineering;transport engineering	Visualization	10.489412462781328	-11.829485387705466	117891
3174e8acd9713a3f6395d61ece9c125816c95553	downscaling temperature and precipitation using support vector regression with evolutionary strategy	forecasting;atmospheric precipitation;downscaling;evolutionary computation;support vector machines;neural nets;forecasting support vector regression evolutionary strategy hyper parameter optimization downscaling;support vector regression;physics computing;support vector machines atmospheric precipitation evolutionary computation learning artificial intelligence neural nets physics computing regression analysis;evolutionary strategy;predictive models artificial neural networks data models training support vector machines linear regression benchmark testing;regression analysis;learning artificial intelligence;hyper parameter search downscaling temperature downscaling precipitation support vector regression evolutionary strategy downscaling forecast problems wcci 2006 contest surface air temperature multiple linear regression machine learning bootstrap aggregated ensemble artificial neural network cherkassky ma estimate random forest stepwise linear regression;hyper parameter optimization	In this work, we propose a hybrid algorithm combining support vector regression with evolutionary strategy (SVR-ES) in order to build successful predictive models for downscaling problems. SVR-ES uses uncorrelated mutation with p step sizes to find the optimal SVR hyper-parameters. Two downscaling forecast problems used in the WCCI-2006 contest - surface air temperature and precipitation - were tested. We used multiple linear regression (MLR) as benchmark and a variety of machine learning techniques including bootstrap-aggregated ensemble artificial neural network (ANN), SVR with hyper-parameters given by the Cherkassky-Ma estimate and random forest (RF). We also tested all techniques with using stepwise linear regression (SLR) first to screen out irrelevant predictors. We concluded that SVR-ES is an attractive approach because it tends to outperform the other techniques and can also be implemented in an almost automatic way. The Cherkassky-Ma estimate is a useful approach to minimizing the MAE error and also saves computational time related to the hyper-parameter search. The ANN and RF are also good options to outperform multiple linear regression (MLR). Finally, the use of SLR for predictor selection can dramatically reduce computational time and often help to enhance accuracy.	algorithmic efficiency;artificial neural network;benchmark (computing);best practice;cma-es;computation;downscaling;evolution strategy;hybrid algorithm;kerrison predictor;learning to rank;machine learning;nonlinear system;parallel computing;predictive modelling;principle of good enough;radio frequency;random forest;relevance;stepwise regression;support vector machine;time complexity	Aranildo R. Lima;Alex J. Cannon;William W. Hsieh	2012	The 2012 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2012.6252383	support vector machine;econometrics;computer science;machine learning;data mining;artificial neural network;evolutionary computation	ML	10.363787074947288	-22.33673862306028	117961
884165f56b814e53477fa25ed636458de6eecf4a	a mobile application for controlling domestic gas cylinders remotely		The domestic gas cylinders or cooking gas are considered as the source of energy commonly used at homes but, the potential for a serious accident such as gas leak from organizations or flow valves if the gas cylinder or its attachments are not treated properly or simply if the user forgot to close the gas before leaving home. The current project aims to develop a mobile application in order to control the gas cylinder remotely by mobile application in an effective way. The system consists of two parts. A specially designed controller connected to the gas cylinder organizer and an android mobile application to control the cylinder remotely through it. The main functions of this application are, controlling one or more domestic gas cylinder remotely, sending an audio alarm to the user if he leave while the gas cylinder opened and close it, providing an alarm if there is a gas leakage and close it and finally if the system fail to close it due to any reason it call the civil defense.	mobile app	Wafaa M. Shalash;Salha Al-Behairi;Nada Al-Qahtani;Mashael Al-Muzaini;Bayan Sharahili;Aisha Alawi	2014		10.1007/978-3-319-07635-5_34	control engineering;environmental engineering;hydrology;engineering	HCI	15.999549629875228	-13.671042081918563	118100
18927b6b59b12c1be024549f8ad37092f28d7260	automated driving in uncertain environments: planning with interaction and uncertain maneuver prediction		Automated driving requires decision making in dynamic and uncertain environments. The uncertainty from the prediction originates from the noisy sensor data and from the fact that the intention of human drivers cannot be directly measured. This problem is formulated as a partially observable Markov decision process (POMDP) with the intended route of the other vehicles as hidden variables. The solution of the POMDP is a policy determining the optimal acceleration of the ego vehicle along a preplanned path. Therefore, the policy is optimized for the most likely future scenarios resulting from an interactive, probabilistic motion model for the other vehicles. Considering possible future measurements of the surrounding cars allows the autonomous car to incorporate the estimated change in future prediction accuracy in the optimal policy. A compact representation results in a low-dimensional state-space. Thus, the problem can be solved online for varying road layouts and number of vehicles. This is done with a point-based solver in an anytime fashion on a continuous state-space. Our evaluation is threefold: At first, the convergence of the algorithm is evaluated and it is shown how the convergence can be improved with an additional search heuristic. Second, we show various planning scenarios to demonstrate how the introduction of different considered uncertainties results in more conservative planning. At the end, we show online simulations for the crossing of complex (unsignalized) intersections. We can demonstrate that our approach performs nearly as good as with full prior information about the intentions of the other vehicles and clearly outperforms reactive approaches.	anytime algorithm;autonomous car;heuristic;hidden variable theory;markov chain;partially observable markov decision process;partially observable system;solver;state space;web-based simulation	Constantin Hubmann;Jens Schulz;Marvin Becker;Daniel Althoff;Christoph Stiller	2018	IEEE Transactions on Intelligent Vehicles	10.1109/TIV.2017.2788208	mathematical optimization;acceleration;probabilistic logic;trajectory;partially observable markov decision process;heuristic;convergence (routing);solver;computer science	Robotics	19.933312066317267	-15.452228320307977	118167
617267091be6a00bb612647108dd47cae7cbf341	case-based multi-task pathfinding algorithm	manhattan distance pathfinding multi task a ida hpa km a haa lpa cbr;abstracts;case based reasoning;computer games;computer games case based reasoning;search time case based multitask pathfinding algorithm computer games case based reasoning method a algorithm memory based pathfinding	Pathfinding is an important task in computer games, where the algorithm efficiency is the key issue. In this paper, we introduce case-based reasoning method in the process of A* algorithm in multi-task pathfinding. Firstly, we save some typical paths as cases. When a new task is coming, it no longer uses A* to find a path from scratch, but firstly computes the similarity of the new task and the stored cases to decide whether to go along the previous found paths or not. A solution to the new task will be obtained after adapting to the found similar case(s). Obviously, this memory-based pathfinding can reduce the search time at the cost of using more memory to store found paths as cases. Through experimental results, it is demonstrated that, as the number of stored paths is increasing, fewer nodes are needed to be searched during the pathfinding process.	a* search algorithm;algorithmic efficiency;case-based reasoning;computer multitasking;pc game;pathfinding	Yan Li;Lan-Ming Su;Qiang He	2012	2012 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2012.6358976	case-based reasoning;simulation;computer science;pathfinding;artificial intelligence;machine learning	AI	17.569159091773084	-12.15120775346078	118248
31e8a123acc3984ee49080afb05592fb258af82f	application of lssvm-pso to load identification in frequency domain	pso;particle swarm optimizer;inverse problem;load identification;frequency domain;lssvm;least squares support vector machine;numerical simulation;random vibration	It is important to identify loads on aircraft to facilitate the designing of aircraft and ground environmental experiments. A new approach of load identification in frequency domain based on least squares support vector machine (LSSVM) and particle swarm optimization (PSO) was proposed. The principle of load identification using LSSVM was derived and the corresponding model of relationship between loads and responses was constructed using LSSVM. To get better performance of identification, PSO was adopted to find optimal hyper-parameters of LSSVM with the best generalization ability of the identification model. The results of numerical simulation and random vibration experiments of simplified aircraft show that the proposed approach can identify not only singlesource load, but also multisource loads effectively with high precision, which demonstrate the proposed approach is greatly applicable to engineering project.	particle swarm optimization	Dike Hu;Wentao Mao;Jinwei Zhao;Guirong Yan	2009		10.1007/978-3-642-05253-8_26	computer simulation;random vibration;least squares support vector machine;mathematical optimization;computer science;inverse problem;machine learning;frequency domain	EDA	13.10309921944348	-21.64041969821859	118714
9512602d1cfedd604b5b8335df3339ffc460d0f0	bp neural network based on pso algorithm for temperature characteristics of gas nanosensor	pso;temperature characteristics;gas nanosensor;neural network	To comprehensively understand the characteristics of gas nanosensor between temperature and sensitivity, this paper has developed a Backward Propagation (BP) neural network based on Particle Swarm Optimization (PSO), which is applied to fitting the temperature-sensitivity characteristic of the SnO2 gas nanosensor mixed with benzene. The simulation results show the PSO can well optimize the structure of the BP network, and the fitting accuracy of the temperature of nanosensor using the acquired BP model is improved greatly and the optimized BP network has better generalization performance than the traditional BP network, and the acquired curve is both smooth and accurate, so the study shows that BP-PSO neural network is effective for fitting the temperature characteristics of gas nanosensor.	algorithm;artificial neural network;effective method;network model;particle swarm optimization;phase-shift oscillator;simulation;struct (c programming language);tin dioxide	Weiguo Zhao	2012	JCP	10.4304/jcp.7.9.2318-2323	computer science;artificial intelligence;machine learning;artificial neural network	Vision	12.864572610878806	-20.75858039997452	118730
49a121cd87d6f5eadbc064b90d30014e804d4033	active learning for efficient sampling of control models of collectives	cost function;decision forests active learning efficient sampling control models collectives large scale systems organizational structure problem decomposition hierarchical control systems hierarchical task networks coalition formation coalition reconfiguration autonomous virtual power plants sampled data points high level optimization;smart power grids hierarchical systems large scale systems learning artificial intelligence optimisation organisational aspects power plants power system control sampled data systems sampling methods;power generation production cost function schedules robots switches;robots;schedules;production;power generation;switches	Many large-scale systems benefit from an organizational structure to provide for problem decomposition. A pivotal problem solving setting is given by hierarchical control systems familiar from hierarchical task networks. If these structures can be modified autonomously by, e.g., Coalition formation and reconfiguration, adequate decisions on higher levels require a faithful abstracted model of a collective of agents. An illustrative example is found in calculating schedules for a set of power plants organized in a hierarchy of Autonomous Virtual Power Plants. Functional dependencies over the combinatorial domain, such as the joint costs or rates of change of power production, are approximated by repeatedly sampling input-output pairs and substituting the actual functions by piecewise linear functions. However, if the sampled data points are weakly informative, the resulting abstracted high-level optimization introduces severe errors. Furthermore, obtaining additional point labels amounts to solving computationally hard optimization problems. Building on prior work, we propose to apply techniques from active learning to maximize the information gained by each additional point. Our results show that significantly better allocations in terms of cost-efficiency (up to 33.7 % reduction in costs in our case study) can be found with fewer but carefully selected sampling points using Decision Forests.	active learning (machine learning);approximation algorithm;control system;data point;discrete optimization;emoticon;functional dependency;hierarchical task network;high- and low-level;intelligent agent;linear function;linear model;machine learning;mathematical optimization;metaheuristic;mutual information;nonlinear system;piecewise linear continuation;problem solving;reduced cost;relational operator;relative intensity noise;run time (program lifecycle phase);sampling (signal processing);tracing (software);type class	Alexander Schiendorfer;Christoph Lassner;Gerrit Anders;Wolfgang Reif;Rainer Lienhart	2015	2015 IEEE 9th International Conference on Self-Adaptive and Self-Organizing Systems	10.1109/SASO.2015.13	robot;electricity generation;simulation;network switch;schedule;computer science;artificial intelligence;machine learning	Robotics	17.931305232504624	-15.178218611389248	118794
3b6016dafaf21046eb0dadb125167cc653b69de8	opponent modeling and exploitation in poker using evolved recurrent neural networks		As a classic example of imperfect information games, Heads-Up No-limit Texas Holdem (HUNL) has been studied extensively in recent years. While state-of-the-art approaches based on Nash equilibrium have been successful, they lack the ability to model and exploit opponents effectively. This paper presents an evolutionary approach to discover opponent models based on recurrent neural networks (LSTM) and Pattern Recognition Trees. Experimental results showed that poker agents built in this method can adapt to opponents they have never seen in training and exploit weak strategies far more effectively than Slumbot 2017, one of the cutting-edge Nash-equilibrium-based poker agents. In addition, agents evolved through playing against relatively weak rule-based opponents tied statistically with Slumbot in heads-up matches. Thus, the proposed approach is a promising new direction for building high-performance adaptive agents in HUNL and other imperfect information games.	intelligent agent;iterative and incremental development;logic programming;long short-term memory;nash equilibrium;neural networks;pattern recognition;recurrent neural network	Xun Li;Risto Miikkulainen	2018		10.1145/3205455.3205589	machine learning;genetic algorithm;artificial intelligence;adversary;computer science;artificial neural network;recurrent neural network;nash equilibrium;perfect information;exploit	AI	18.71626395563347	-18.0745956681881	118855
ceaf6a9af0f4660fa5c3cdf245bb5f7e7f6c5fc9	achieving a more robust neural network model for control of a mr damper by signal sensitivity analysis	activation function;control problem;control system;mlp neural network;sensitivity analysis;output error;neural network model;neural network	Most neural network models can work accurately on their trained samples, but when encountering noise, there could be significant errors if the trained neural network is not robust enough to resist the noise. Sensitivity to perturbation in the control signal due to noise is very important for the prediction of an output signal. The goal of this paper is to provide a methodology of signal sensitivity analysis in order to enable the selection of an ideal MultiLayer Perception (MLP) neural network model from a group of MLP models with different parameters, i.e. to get a highly accurate and robust model for control problems. This paper proposes a signal sensitivity which depends upon the variance of the output error due to noise in the input signals of a single output MLP with differentiable activation functions. On the assumption that noise arises from additive/multiplicative perturbations, the signal sensitivity of the MLP model can be easily calculated, and a method of lowering the sensitivity of the MLP model is proposed. A control system of a magnetorheological (MR) fluid damper, which is a relatively new type of device that shows the future promise for the control of vibration, is modelled by MLP. A large number of simulations on the MR damper’s MLP model show that a much better model is selected using the proposed method.	activation function;artificial neural network;control system;memory-level parallelism;multilayer perceptron;network model;simulation;utility functions on indivisible goods	Xiaotong Wang;Chih-Chen Chang;Fang Du	2002	Neural Computing & Applications	10.1007/s005210200005	probabilistic neural network;computer science;recurrent neural network;machine learning;control theory;time delay neural network;multilayer perceptron;activation function;sensitivity analysis;artificial neural network	AI	14.756713447896933	-21.74551074563177	119137
2a21d7863ce63022fd24cb1ca7dafdecdd690036	improving hearthstone ai by learning high-level rollout policies and bucketing chance node events		Modern board, card, and video games are challenging domains for AI research due to their complex game mechanics and large state and action spaces. For instance, in Hearthstone — a popular collectible card (CC) (video) game developed by Blizzard Entertainment — two players first construct their own card decks from over 1,000 different cards and then draw and play cards to cast spells, select weapons, and combat minions and the opponent's hero. Players' turns are often comprised of multiple actions, including drawing new cards, which leads to enormous branching factors that pose a problem for state-of- the-art heuristic search methods. In this paper we first present two ideas to tackle this problem, namely by reducing chance node branching factors by bucketing events with similar outcomes, and using high-level policy net­works for guiding Monte Carlo Tree Search rollouts. We then apply these ideas to the game of Hearthstone and show significant improvements over a state-of-the-art AI system for this game.	algorithm;artificial neural network;branching factor;deep learning;evaluation function;experiment;game mechanics;heuristic;heuristic (computer science);high- and low-level;influence diagram;machine learning;monte carlo method;monte carlo tree search;randomness;recurrent neural network;reinforcement learning;sampling (signal processing);simulation;state (computer science)	Shuyi Zhang;Michael Buro	2017	2017 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2017.8080452	simulation;collectable;machine learning;entertainment;hero;artificial intelligence;computer science;branching (version control);adversary;monte carlo tree search;heuristic;game mechanics	AI	19.461669004471407	-17.648202597345637	119177
351aa15979794fcb4450f4a3d265935f355ac1f4	reinforcement programming for function approximation	learning artificial intelligence function approximation genetic algorithms;genetic programming learning mathematical model equations programming profession function approximation;function approximation;genetic programming reinforcement programming function approximation reinforcement learning computational intelligence;genetic algorithms;learning artificial intelligence	Reinforcement learning is one of the major strands of current computational intelligence: it is used to enable an agent to explore an environment in order to ascertain the best actions in that environment. Genetic programming is a method to evolve programs and given the similarity between genetic algorithms and reinforcement learning, it is perhaps surprising that so little attention has been given to using reinforcement learning to identify useful programs. This paper makes a start on this task by investigating using reinforcement learning methods for function approximation.	approximation;computational intelligence;genetic algorithm;genetic programming;local optimum;operand;q-learning;reinforcement learning;softmax function;state-action-reward-state-action	Salah Rana;Malcolm K. Crowe;Colin Fyfe	2012	2012 12th UK Workshop on Computational Intelligence (UKCI)	10.1109/UKCI.2012.6335777	temporal difference learning;unsupervised learning;genetic programming;mathematical optimization;error-driven learning;computer science;artificial intelligence;machine learning;learning classifier system;inductive programming;reinforcement learning;hyper-heuristic	AI	17.66242847486254	-21.641544521474927	119315
9616ffe99a910f247c413013e8fd20f47be56353	composite importance measures for multi-state systems with multi-state components	system reliability;user needs;reliability theory;monte carlo simulation multi state system reliability composite importance measures;computer integrated manufacturing power system reliability systems engineering and theory degradation monte carlo methods computational modeling current measurement engineering profession research and development management state space methods;monte carlo methods reliability theory;monte carlo;monte carlo methods	This paper presents & evaluates composite importance measures (CIM) for multi-state systems with multi-state components (MSMC). Importance measures are important tools to evaluate & rank the impact of individual components within a system. For multi-state systems, previously developed measures do not meet all user needs. The major focus of the study is to distinguish between two types of importance measures which can be used for evaluating the criticality of components in MSMC with respect to multi-state system reliability. This paper presents Type 1 importance measures that are involved in measuring how a specific component affects multi-state system reliability. A Monte Carlo (MC) simulation methodology for estimating the reliability of a MSMC is used for computing the proposed CIM metrics. Previous approaches (Type 2) have focused on investigating how a particular component state or set of states affects multi-state system reliability. For some systems, it is not clear how to prioritize system component importance, collectively considering all of its states, using the previously developed importance measures. That detracts from those measures. Experimental results show that the proposed CIM can be used as an effective tool to assess component criticality for MSMC. Examples are used to illustrate & compare the proposed CIM with previous multi-state importance measures.	algorithmic efficiency;approximation algorithm;chomsky hierarchy;complex systems;computation;computer-integrated manufacturing;criticality matrix;monte carlo method;nsa product types;self-organized criticality;simulation;subroutine	Jose Emmanuel Ramirez-Marquez;David W. Coit	2005	IEEE Transactions on Reliability	10.1109/TR.2005.853444	reliability engineering;simulation;systems engineering;engineering;mathematics;statistics;monte carlo method	SE	13.702108641867392	-11.766094006020504	119517
a8ba88cdd0b01dbdb14b7d65e054f59e99415a4c	transformations and multi-scale optimisation in biological adaptive networks		The natural energy minimisation behaviour of a dynamical system can be interpreted as a simple optimisation process, finding a locally optimal resolution of constraints between system variables. In human problem solving, high-dimensional problems are often made much easier by inferring a low-dimensional model of the system in which search is more effective. But this is an approach that seems to require top-down domain knowledge; not one amenable to the spontaneous energy minimisation behaviour of a natural dynamical system. However, in recent work we investigated the ability of distributed dynamical systems to improve their constraint resolution ability over time by self-organisation. Using a ‘self-modelling’ Hopfield network with a particular type of associative connection we illustrated how slowly changing relationships between system components results in a transformation into a new system, a low-dimensional caricature of the original system, in which the energy minimisation behaviour is significantly more effective at globally resolving system constraints. This uses only very simple and fully-distributed positive feedback mechanisms that are relevant to other ‘active linking’ and adaptive networks. Here we overview the implications of this neural network model for understanding transformations and emergent collective behaviour in various non-neural adaptive networks such as social, genetic and in particular, ecological networks.	artificial neural network;dynamical system;emergence;hopfield network;local optimum;mathematical optimization;network model;positive feedback;problem solving;self-organization;spontaneous order;top-down and bottom-up design	Richard A. Watson;Rob Mills;Christopher L. Buckley	2011			ecological network;dynamical systems theory;machine learning;positive feedback;domain knowledge;artificial intelligence;computer science;hopfield network;dynamical system;artificial neural network;associative property	AI	17.070440600734024	-22.479231569537752	119535
4582a36c40656ccfd2d746a5e5caab8daa4a492c	monitoring and data recording system for the underground		Abstract   This paper gives a short report on a new generation of monitoring and data recording systems used in underground trains. The system function, its hardware and software, including diagnostics are described.		Zdenek Blazek	1993	Microprocessing and Microprogramming	10.1016/0165-6074(93)90106-U	embedded system;computer hardware;electrical engineering	ML	16.035185078192224	-13.050114960439627	119795
c9df19b66764158493904fdb652eaae0aecb1731	sliding window symbolic regression for predictive maintenance using model ensembles		Predictive Maintenance (PdM) is among the trending topics in the current Industry 4.0 movement and hence, intensively investigated. It aims at sophisticated scheduling of maintenance, mostly in the area of industrial production plants. The idea behind PdM is that, instead of following fixed intervals, service actions could be planned based upon the monitored system condition in order to prevent outages, which leads to less redundant maintenance procedures and less necessary overhauls. In this work we will present a method to analyze a continuous stream of data, which describes a system’s condition progressively. Therefore, we motivate the employment of symbolic regression ensemble models and introduce a sliding-window based algorithm for their evaluation and the detection of stable and changing system states.	symbolic regression	Jan Zenisek;Michael Affenzeller;Josef Wolfartsberger;Mathias Silmbroth;Christoph Sievi;Aziz Huskic;Herbert Jodlbauer	2017		10.1007/978-3-319-74718-7_58	artificial intelligence;predictive maintenance;computer science;sliding window protocol;machine learning;symbolic regression;scheduling (computing);industrial production;ensemble forecasting	Robotics	14.09446096093567	-14.873758745688818	119949
4e80fe93542b2913f0a4b784e5443e76b8dd7c89	data driven modeling for ugi gasification process via a variable structure genetic bp neural network	enhanced genetic algorithm data driven modeling ugi gasifier neural networks with link switches;artificial neural networks temperature measurement biological cells genetic algorithms mathematical model encoding;lm algorithm data driven modeling ugi gasification process variable structure genetic bp neural network backpropagation link switches ega vrbpnn enhanced genetic bp neural network gas temperature enhanced genetic algorithm ega levenberg marquardt algorithm;production engineering computing backpropagation data handling fuel gasification genetic algorithms neural nets	An enhanced genetic BP neural network with link switches (EGA-VRBPNN) is proposed in this work to address the data-driven modeling problem for the gasification process inside a UGI gasifier. During gasification processes, the online measured gas temperature is crucial but difficult to model its' dynamics via first principles because of the tremendous complexity of the gasification process, which is mainly reflected from severe changes of the gas temperature versus infrequent and small manipulations of parts of the input variables. EGA-VRBPNN, which incorporates a neural networks with link switches (NN-LS) with an enhanced genetic algorithm (EGA) and the Levenberg-Marquardt (LM) algorithm, can not only learn the relationships between control inputs and system outputs from historical data with the help of optimized network structure through combination of the EGA and NN-LS, but also overcome the drawbacks of gradient-based method and make full use of the network's gradient information to achieve a satisfactory accuracy. A set of data collected from the practical fields are applied to modeling via the EGA-VRBPNN, by which the effectiveness of the EGA-VRBPNN is verified.	artificial neural network;dynamical system;enhanced graphics adapter;genetic algorithm;gradient descent;hopfield network;levenberg–marquardt algorithm;mimo;network switch;nonlinear system	Shida Liu;Zhongsheng Hou;Chenkun Yin	2014	2014 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2014.6889652	artificial intelligence;machine learning	Robotics	11.142354068259857	-22.126675366744635	119981
61ae8c12849564817ea941186610a0cac37c1460	autonomous agent learning using an actor-critic algorithm and behavior models	behavior model;behavior modeling;reinforcement learning;actor critic;autonomous agent	We introdu e a Supervised Reinfor ement Learning (SRL) algorithm for autonomous learning problems where an agent is required to deal with high dimensional spa es. In our learning algorithm, behavior models learned from a set of examples, are used to dynami ally redu e the set of relevant a tions at ea h state of the environment en ountered by the agent. Su h subsets of a tions are used to guide the agent through promising parts of the a tion spa e, avoiding the sele tion of useless a tions. The algorithm handles ontinuous states and a tions. Our experimental work with a di ult robot learning task shows learly how this approa h an signi antly speed up the learning pro ess and improve the nal performan e.	actor model;algorithm;autonomous agent;autonomous robot;robot learning	Victor Uc Cetina	2008		10.1145/1402821.1402870	behavioral modeling;unsupervised learning;robot learning;error-driven learning;simulation;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;learning classifier system;stability;action learning;reinforcement learning;active learning	ML	19.371364030964212	-21.372548705987043	120319
36abaea1ae4b336cffd3d87f33d7d359144c26ef	proactive fault detection schema for enterprise information system using statistical process control	statistical approach;six sigma;proactive fault detection;statistical process control;false alarm rate;control chart;fault detection;enterprise information system;prediction model;information system;ewma;system management;early detection	This paper proposes a proactive fault detection schema using adaptive statistical approaches in order to enhance system availability and reliability in the heterogeneous & complicated information system environment. The proposed system applies Six Sigma SPC (Statistical Process Control) techniques already validated in industries in order to monitor the application system in the information system. This makes it possible to reduce false alarm rates for system faults and accurately detect faults by creating a control chart based on past performance data and controlling the distribution of performance based on the chart. The early detection of faults is also enabled through a fault prediction model. Therefore, the aforementioned system not only detect unknown or unseen faults but also resolve potential problems for system administrator by detecting abnormal behaviors before faults occur. In the experiment we show the superiority of our proposed model and the possibility to early detect system faults.	enterprise information system;fault detection and isolation	Chihoon Lee;Doohyung Lee;Jahwan Koo;Jin-Wook Chung	2009		10.1007/978-3-642-02556-3_13	reliability engineering;real-time computing;engineering;computer security	DB	13.937232514274427	-13.813803362509168	121130
7ddec06374cdce2effe6862c0d343701fe906220	simulating dynamic covariance structures for testing the adaptive behavior of variable selection algorithms (invited paper)	input variables;testing input variables computational modeling computer simulation educational institutions costs context modeling engines algorithm design and analysis stochastic processes;testing;covariance simulation;adaptive behavior;variable selection;computational modeling;engines;stochastic processes;missing data;covariance simulation exploration exploitation variable selection missing data;context modeling;computer simulation;covariance structure;algorithm design and analysis;exploration exploitation	Variable selection for regression is a classical statistical problem, motivated by concerns that too large a number of covariates may bring about overfitting and unnecessarily high measurement costs. Novel difficulties arise in streaming contexts, where the correlation structure of the process may be drifting, in which case it must be constantly tracked so that selections may be revised accordingly. A particularly interesting phenomenon is that non-selected covariates become missing variables, inducing bias on subsequent decisions. This raises an intricate exploration-exploitation tradeoff, whose dependence on the covariance tracking algorithm and the choice of variable selection scheme is too complex to be dealt with analytically. We hence capitalise on the strength of simulations to explore this problem, taking the opportunity to tackle the difficult task of simulating dynamic correlation structures.	action selection;adaptive behavior;expectation propagation;feature selection;greedy algorithm;information system;overfitting;reinforcement learning;simulation;streaming media	Christoforos Anagnostopoulos;Niall M. Adams	2008	Tenth International Conference on Computer Modeling and Simulation (uksim 2008)	10.1109/UKSIM.2008.92	computer simulation;algorithm design;econometrics;simulation;missing data;computer science;artificial intelligence;adaptive behavior;machine learning;software testing;context model;computational model;statistics	Robotics	21.485871829398558	-17.263954309673363	121201
cef57c37aef0f19367b9f80966c56813494b988c	application of artificial neural network for predicting crack growth direction in multiple cracks geometry	crack offset distance;multiple cracks;crack inclination;artificial neural network	The objective of this study is to design an efficient artificial neural network (ANN) architecture in order to predict the crack growth direction in multiple crack geometry. Nonlinear logistic (sigmoid and tangent hyperbolic) and linear activation functions have been used through the oneand two-hidden layer ANN. 85 tests were conducted on aluminium alloys under different crack positions, defined by crack tip distance, crack offset distance, crack size, and crack inclination with loading axis. The experimental data	apache axis;artificial neural network;sigmoid function	Deepayan Gope;Prakash Chandra Gope;Aruna Thakur;Abhishek Yadav	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.02.003	computer science;machine learning;artificial neural network	ML	13.067870056017455	-20.182561373891325	121299
773ae063e3880008647af089cf1bc53cf369bcf7	generalized emphatic temporal difference learning: bias-variance analysis		We consider the off-policy evaluation problem in Markov decision processes with function approximation. We propose a generalization of the recently introduced emphatic temporal differences (ETD) algorithm (Sutton, Mahmood, and White, 2015), which encompasses the original ETD(λ), as well as several other off-policy evaluation algorithms as special cases. We call this framework ETD(λ, β), where our introduced parameter β controls the decay rate of an importance-sampling term. We study conditions under which the projected fixed-point equation underlying ETD(λ, β) involves a contraction operator , allowing us to present the first asymptotic error bounds (bias) for ETD(λ, β). Our results show that the original ETD algorithm always involves a contraction operator, and its bias is bounded. Moreover, by controlling β, our proposed generalization allows trading-off bias for variance reduction, thereby achieving a lower total error.	algorithm;approximation;importance sampling;lazy evaluation;markov chain;markov decision process;sampling (signal processing);temporal difference learning;variance reduction	Assaf Hallak;Aviv Tamar;Rémi Munos;Shie Mannor	2016			mathematical optimization;machine learning;mathematics;statistics	AI	22.81401844170804	-18.454124975508496	121344
a75fba05d5fe67affcd05c532e2d444fae3bd0c5	fault isolation using modified contribution plots	contribution plots;principal component analysis;fault isolation;missing data analysis	Investigating the root causes of abnormal events is a crucial task for an industrial process. When process faults are detected, isolating the faulty variables provides additional information for investigating the root causes of the faults. Numerous data-driven approaches require the datasets of known faults, which may not exist for some industrial processes, to isolate the faulty variables. The contribution plot is a popular tool to isolate faulty variables without a priori knowledge. However, it is well known that this approach suffers from the smearing effect, which may mislead the faulty variables of the detected faults. In the presented work, a contribution plot without the smearing effect to non-faulty variables was derived. A continuous stirred tank reactor (CSTR) example and the industrial application were provided to demonstrate that the proposed approach is not only capable of locating different faulty variables when the fault was propagated by the controllers, but also capable of identifying the variables responsible for the multiple sensor faults.		Jialin Liu;Ding-Sou Chen	2014	Computers & Chemical Engineering	10.1016/j.compchemeng.2013.10.004	econometrics;computer science;engineering;machine learning;mathematics;forensic engineering;fault detection and isolation;statistics;principal component analysis	DB	13.534447454886886	-14.510828500925085	121393
3b8f12c1e24bf81c9b1343cf7b7909a94c4046e3	toward reducing failure risk in an integrated vehicle health maintenance system: a fuzzy multi-sensor data fusion kalman filter approach for ivhms	failure risk;fault detection and isolation;product and process innovation;multi sensor data fusion;fuzzy kalman filter approach	Highlights? Factor analysis identified four sub-systems: gear, engine, fuel and electrical. ? Fuzzy multi-sensor data fusion Kalman model developed. ? Fault detection and risk reduction in maintenance decision support system. ? Fuzzy Kalman filter approach reduced time and improved control of systems. This paper reports on a new integrated vehicle health maintenance system (IVHMS) based on fault detection and feedback. A fuzzy multi-sensor data fusion Kalman model was used to help reduce IVHMS failure risk. The IVHMS was tested, and sensors with and without faults were identified. The results demonstrate that multi-sensor data fusion based on fault detection and fuzzy Kalman feedback is an effective method of reducing risk in an IVHMS. Use of the fuzzy Kalman filter approach reduced the time needed to perform complex matrix manipulations to control higher order systems in the IVHMS. Moreover, the approach was able to capture the nonlinearity of engine operations under the influence of various anomalies.	kalman filter	James A. Rodger	2012	Expert Syst. Appl.	10.1016/j.eswa.2012.02.171	computer science;control theory;fault detection and isolation	Robotics	12.709240877693349	-14.102774632432624	121446
511e0970d6ba2cfb0c810e2ac8adf067b420234d	application of an artificial immune system-based fuzzy neural network to a rfid-based positioning system	fuzzy neural network fnn;genetic algorithms gas;radio frequency identification rfid;artificial immune system ais	Due to the rapid development of globalization, which makes supply chain management more complicated, more companies are applying radio frequency identification (RFID), in warehouse management. The obvious advantages of RFID are its ability to scan at high-speed, its penetration and memory. In addition to recycling, use of a RFID system can also reduce business costs, by indentifying the position of goods and picking carts. This study proposes an artificial immune system (AIS)-based fuzzy neural network (FNN), to learn the relationship between the RFID signals and the picking cart's position. Since the proposed network has the merits of both AIS and FNN, it is able to avoid falling into the local optimum and possesses a learning capability. The results of the evaluation of the model show that the proposed AIS-based FNN really can predict the picking cart position more precisely than conventional FNN and, unlike an artificial neural network, it is much easier to interpret the training results, since they are in the form of fuzzy IF-THEN rules.	artificial immune system;artificial neural network;neuro-fuzzy;positioning system	Ren-Jieh Kuo;W. L. Tseng;F. C. Tien;T. Warren Liao	2012	Computers & Industrial Engineering	10.1016/j.cie.2012.06.006	simulation;engineering;artificial intelligence;operations management	Robotics	11.048694668446283	-22.38062256980562	121569
c098e9d5040f1159bf3d7635c5e0c75da2ee145b	acting and bayesian reinforcement structure learning of partially observable environment		This article shows how to learn both the structure and the parameters of partially observable environment simultaneously while also online performing near-optimal sequence of actions taking into account exploration-exploitation tradeoff. It combines two results of recent research: The former extends model-based Bayesian reinforcement learning of fully observable environment to bigger domains by learning the structure. The latter shows how a known structure can be exploited to model-based Bayesian reinforcement learning of partially observable domains. This article shows that merging both approaches is possible without too excessive increase in computational complexity.	algorithm;computational complexity theory;dynamic bayesian network;markov chain;partially observable markov decision process;partially observable system;particle filter;reinforcement learning	Robert Brunetto;Marta Vomlelová	2014			simulation;artificial intelligence;machine learning;mathematics	AI	20.56411015149224	-19.135979762928585	121604
9c3c60532ad27158f435ccbebf45c965f16881c5	an efficient algorithm for finding the m most probable configurationsin probabilistic expert systems	conditional independence;bayesian network;charge;flow;maximization;efficient algorithm;belief revision;graphical representation;probability distribution;junction tree;most probable explanation;local computation;evidence;potential function;divide and conquer;propagation;marginalization;expert system	A probabilistic expert system provides a graphical representation of a j oint probability distribution which enables local computations of probabi lities. Dawid (1992) provided a ‘flow-propagation’ algorithm for finding the mo st probable configuration of the joint distribution in such a system. This paper analyses that algorithm in detail, and shows how it can be combined with a clever partiti oning scheme to formulate an efficient method for finding the M most probable configurations. The algorithm is a divide and conquer technique, that it er ively identifies theM most probable configurations. The algorithm has been implemented into the experimental shell XBAIES, which is an extension of BAI ES (Cowell, 1992).	algorithm;computation;expert system	D. Nilsson	1998	Statistics and Computing	10.1023/A:1008990218483	probability distribution;divide and conquer algorithms;flow;social exclusion;conditional independence;charge;theoretical computer science;machine learning;bayesian network;mathematics;belief revision;expert system;statistics	ML	21.2529746978166	-14.891533939570966	122075
ce792d2d483457325a53d81bb953c103a72659fb	analysis of frequent episodes in sequences of incidents collected in power distribution systems	power distribution system;incipient faults;incipient faults power system faults sequence of incidents;power distribution planning;electronic mail;management system;customer services;circuit faults;power quality;electrical network;power distribution faults;association rules;set theory;customer service;power distribution;power system faults;pattern discovery;power distribution planning power distribution faults;computer aided software engineering;circuit faults customer services computer aided software engineering association rules electronic mail power quality;association rule;power system;power distribution planning frequent episodes power distribution systems electric utility customer service centers incident management systems normal operation failure analysis pattern discovery algorithm electrical networks;normal operator;electric utilities;sequence of incidents;historical data	Power distribution incidents collected by the electric utility through their customer service centers and incident management systems are analyzed systematically in this work. An incident is defined by the actions carried out by the utility to return the system to its normal operation when a failure occurrs. A sequence of incidents is a set of dated incidents recorded in a region or a network during a period of time, but only some subsets of them are of interest, either because they present similar features or because they are related in a way that allows them to be considered together (timing, periodicity, etc.). These subsets of significant incidents in a sequence are called episodes and are instances of possible patterns that define the behaviour of the system. The analysis is oriented to extract useful information from sequences of historical data to recognize relevant episodes that show a pattern of behaviour which could be useful to forecast future incidents or assist planning and operation. With this goal, the authors evaluate the use of a pattern discovery algorithm in sequences of incidents gathered in a network as part of the case study. Since the incidents can occur by random factors not all the frequent episodes that can be found are relevant. Then, it is proposed a methodology based on set theory to choose the relevant episodes which are especially useful to recognize outstanding episodes in sequences that have high randomness, which is the case of sequences of incidents in electrical networks.	algorithm;incident management;quasiperiodicity;randomness;relevance;set theory	Oscar Quiroga;Joaquím Meléndez;Sergio Herraiz;Alvaro Ferreira;Alfredo Munoz	2011	2011 2nd IEEE PES International Conference and Exhibition on Innovative Smart Grid Technologies	10.1109/ISGTEurope.2011.6162727	reliability engineering;engineering;operations management;data mining	Robotics	11.36307884855408	-13.735594897636773	122134
fe92e9eb0a77f7afadddc911bbcd5da8b0a08541	analyzing the dynamics of the simultaneous feature and parameter optimization of an evolving spiking neural network	biology computing;optimisation;brain;bioelectric potentials;neural encoding technique;neural nets;data mining;mammalian brain parameter optimization quantum inspired spiking neural network feature selection feature classification machine learning knowledge discovery neural encoding technique;mammalian brain;spiking neural network;machine learning;quantum inspired spiking neural network;optimisation bioelectric potentials biology computing brain data mining learning artificial intelligence neural nets neurophysiology;feature selection;neurons;neurophysiology;practice guideline;learning artificial intelligence;parameter optimization;feature classification;knowledge discovery	This study investigates the characteristics of the Quantum-inspired Spiking Neural Network (QiSNN) feature selection and classification framework. The self-adapting nature of QiSNN due to the simultaneous optimization of network parameters and feature subsets represents a highly desirable characteristic in the context of machine learning and knowledge discovery. In this paper, the evolution of the parameters and feature subsets is studied in detail. The goal of this analysis is a comprehensive understanding of all parameters involved in QiSNN and some practical guidelines for using the method in future research and applications. We also highlight the role of the employed neural encoding technique along with its impact on the classification abilities of QiSNN.	feature selection;machine learning;mathematical optimization;neural coding;quantum;spiking neural network	Stefan Schliebs;Michael Defoin-Platel;Nikola K. Kasabov	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596548	computer science;artificial intelligence;machine learning;pattern recognition;feature selection;neurophysiology;artificial neural network;spiking neural network	ML	15.596194404572444	-23.903137762844768	122247
6b6824d5fa84bd8955c2f7792ec011c5957d7ed3	reinforced concrete bridge deck reliability model incorporating temporal and spatial variations of probabilistic corrosion rate sensor data	modelizacion;environmental factors;reinforced concrete;variabilidad;fiabilidad;reliability;multisensor;system approach;duree service;facteur environnement;corrosion rate;metodo monte carlo;methode empirique;securite;temporal variability;surveillance;teoria sistema;metodo empirico;reliability modeling;environmental conditions;empirical method;methode monte carlo;spatial variation;bridges;duracion servicio;efecto medio;systeme integre;sistema integrado;probabilistic approach;environmental effect;efecto medio ambiente;health monitoring;spatial variability;modelisation;factor medio;systeme incertain;vigilancia;correlation spatiale;spatial correlation;correlacion espacial;sante;facteur milieu;monitoring;systems theory;spatial and temporal variation;medium effect;enfoque probabilista;approche probabiliste;theorie systeme;fiabilite;monte carlo method;puente;safety;pont;beton arme;invariante;steel structure;monitorage;health;bridge deck;variability;salud;monitoreo;monte carlo simulation;sistema incierto;critical section;effet environnement;variabilite;integrated system;seguridad;modeling;corrosion;uncertain system;capteur multiple;invariant;effet milieu;service life;environmental factor;hormigon armado	The reliability of reinforced concrete (RC) bridge decks depends significantly on the rate of corrosion of the reinforcing steel. Structural health monitoring (SHM) techniques, including embedded corrosion rate sensors, can greatly improve the quantification of the steel corrosion rate, which can lead to improved estimates of structural safety and serviceability. Due to uncertainties in concrete properties, environmental conditions, and other factors, the rate of corrosion of reinforcing steel can be highly variable, both within a given structural component and over time. By placing multiple corrosion rate sensors throughout a structural component, such as a bridge deck, these spatial and temporal variabilities can be monitored and as such better predicted, for use in a reliability model. The objective of this investigation is to present a reliability model for a RC bridge deck incorporating both spatial and temporal variations of probabilistic corrosion rate sensor data. This objective is accomplished using a computational reliability model and Monte Carlo simulation. Corrosion rate sensor data is assumed for multiple critical sections throughout a RC bridge deck over time by applying empirical spatial and temporal relationships. This data is then used to improve an existing spatially invariant reliability model. The improved reliability model incorporates several sub-models to determine the changes in load effects on and resistance of a RC bridge deck slab over time, as well as spatial correlation of corrosion and a system approach to account for spatial variability. The improved reliability model incorporating both spatial and temporal variations in corrosion rate data provides a better estimate of the service life of a RC bridge deck slab.		Philip S. Marsh;Dan M. Frangopol	2008	Rel. Eng. & Sys. Safety	10.1016/j.ress.2006.12.011	structural engineering;spatial variability;engineering;mathematics;forensic engineering;statistics;monte carlo method	DB	13.447807486572607	-10.632060364330538	122352
5253e0ba205ac526dfa276a3c1dd5ff989474e9c	simulating competing alife organisms by constructive compound neural networks	arquitectura red;learning algorithm;fuzzy neural nets;realite virtuelle;realidad virtual;supervised learning;reinforcement learning;virtual reality;reseau neuronal flou;algorithme apprentissage;online learning;architecture reseau;apprentissage renforce;food availability;network architecture;aprendizaje reforzado;algoritmo aprendizaje;neural network	We have developed a new efficient neural network-based algorithm for Alife application in a competitive world whereby the effects of interactions between organisms are evaluated in a weak form by exploiting the position of nearest food elements into consideration but not the positions of the other competing organisms. Two online learning algorithms, an instructive ASL (adaptive supervised learning) and an evaluative feedback-oriented RL (reinforcement learning) algorithm developed have been tested in simulating Alife environments with various neural network algorithms. Adopting an adaptively selected best sequence of feedback action period Δα which we have found to be a decisive parameter in improving the network efficiency, the ASL-guided FuzGa had an improved performance as compared with ASL-guided CasCor and RL-guided FuzGa. We confirm that the present solution successfully evaluates the effect of interactions at a larger FA (food availability), reducing to an isolated solution at a lower value of FA.	artificial neural network;neural network software	Jianjun Yan;Naoyuki Tokuda;Juichi Miyamichi	2000		10.1007/3-540-45486-1_22	simulation;network architecture;computer science;artificial intelligence;machine learning;virtual reality;supervised learning;reinforcement learning;artificial neural network	Robotics	17.831632927607913	-21.140786921942073	122359
0141d8a97e101cccae88733504de3b093c67ebb9	an intelligent perturbative approach for the time series forecasting problem	performance measure;forecasting;prediction method;time series forecasting;taef method;perturbation theory;perturbation techniques;time series;intelligent perturbative approach;cost accounting;forecasting theory;time series forecasting theory perturbation techniques;perturbative taef;approximation scheme;robustness;robustness intelligent perturbative approach time series forecasting problem predictive method perturbation theory taef method p taef perturbative taef;p taef;time series forecasting problem;predictive method;forecasting cost accounting	In this paper it is introduced a new perturbative approach for time series forecasting. The model uses the error of the series, that is the difference between real value of the series and the output of a predictive method, to improve the series forecasting. The methodology proposed is inspired in the Perturbation Theory, that consists in a set of approximation schemes used to describe a complicated problem in terms of simpler ones. For an experimental investigation, this theory, is combined with the TAEF method, that has interesting results when compared with the literature. This combination is called P-TAEF (Perturbative TAEF). Its results over some time series are discussed and compared with previous results found in the literature. It was used several performance measures that showed the robustness of the perturbative approach.	approximation;approximation algorithm;artificial neural network;computational complexity theory;genetic algorithm;hybrid system;perturbation theory (quantum mechanics);program evaluation and review technique;time series	Paulo S. G. de Mattos Neto;Aranildo R. Lima;Tiago Alessandro Espínola Ferreira;George D. C. Cavalcanti	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596700	econometrics;mathematical optimization;machine learning;time series;mathematics;statistics	DB	14.836061663038665	-21.043371164599463	122434
4df463923533128c24e95d51ccee0fe3e1a781e5	real-time search for autonomous agents and multiagent systems	multiagent system;real time;adaptive control;autonomous agent;autonomous agents;real time search;problem solving;multiagent systems	Since real-time search provides an attractive framework for resource-bounded problem solving, this paper extends the framework for autonomous agents and for a multiagent world. To adaptively control search processes, we propose ε-search which allows suboptimal solutions with ε error, and δ-search which balances the tradeoff between exploration and exploitation. We then consider search in uncertain situations, where the goal may change during the course of the search, and propose a moving target search (MTS) algorithm. We also investigate real-time bidirectional search (RTBS) algorithms, where two problem solvers cooperatively achieve a shared goal. Finally, we introduce a new problem solving paradigm, called organizational problem solving, for multiagent systems.	agent-based model;algorithm;autonomous agents and multi-agent systems;autonomous robot;baseline (configuration management);bidirectional search;centralized computing;enterprise resource planning;experiment;exploit (computer security);multi-agent system;problem domain;problem solving;procedural generation;programming paradigm;randomness;real-time search;real-time clock;real-time locating system;real-time transcription;real-time web;search algorithm;testbed	Toru Ishida	1998	Autonomous Agents and Multi-Agent Systems	10.1023/A:1026449201026	simulation;adaptive control;computer science;artificial intelligence;autonomous agent;multi-agent system;distributed computing	AI	18.99819637047918	-16.139766661186787	122455
11410745902e35439ac79e64ff186754ae1feab1	the self organization of context for learning in multiagent games	high dimensionality;reinforcement learning;curse of dimensionality;linear functionals;domain knowledge;machine learning;state space;reinforce ment learning;self organization;self organized map	Reinforcement learning is an effective machine learning paradigm in domains represented by compact and discrete state-action spaces. In highdimensional and continuous domains, tile coding with linear function approximation has been widely used to circumvent the curse of dimensionality, but it suffers from the drawback that human-guided identification of features is required to create effective tilings. The challenge is to find tilings that preserve the context necessary to evaluate the value of a state-action pair while limiting memory requirements. The technique presented in this paper addresses the difficulty of identifying context in high-dimensional domains. We have chosen RoboCup simulated soccer as a domain because its 90-dimensional continuous state space makes it a formidable challenge for reinforcement learning algorithms. Using self-organizing maps and reinforcement learning in a two-pass process, our technique scales to large state spaces without requiring a large amount of domain knowledge to automatically form abstractions over the state space. Results show that our algorithm learns to play the game of soccer better than contemporary learned and handcoded opponents.	algorithm;approximation;curse of dimensionality;linear function;machine learning;organizing (structure);programming paradigm;reinforcement learning;requirement;self-organization;self-organizing map;state space	Christopher D. White;Dave Brogan	2006			semi-supervised learning;unsupervised learning;error-driven learning;self-organization;simulation;curse of dimensionality;computer science;state space;artificial intelligence;machine learning;reinforcement learning;domain knowledge	ML	19.641991593360515	-21.48260300921418	122790
51fcaaea80b7b635bf67b1ee32c8c64c616e2242	an introduction to computational intelligence techniques for robot control	neural nets;computational intelligence;logique floue;control design;logica difusa;robotics;robot industriel;fuzzy logic;commande industrielle;real world application;neural net;robot control;industrial robots;industrial control;robot industrial;robotica;algorithme evolutionniste;algoritmo evolucionista;robotique;evolutionary algorithm;reseau neuronal;red neuronal;neural network;evolutionary computing;industrial robot	The application of computational intelligence techniques to the field of industrial robot control is discussed. The core ideas behind using neural computation, evolutionary computation, and fuzzy logic techniques are presented, along with a selection of specific real-world applications. Their practical advantages and disadvantages relative to more traditional approaches are made clear.	artificial neural network;computational intelligence;control system;evolutionary computation;fuzzy logic;industrial robot;robot control	John A. Bullinaria;Xiaoli Li	2007	Industrial Robot	10.1108/01439910710749618	fuzzy logic;control engineering;simulation;computer science;engineering;artificial intelligence;computational intelligence;robot control;artificial neural network	Robotics	15.432916417511704	-20.22857956030387	122932
6ecd97cf3f2149b04f88c96513be7f6a2d29b5a5	a committee machine with empirical formulas for permeability prediction	computadora;tratamiento datos;computers;reservoirs;roche sedimentaire;drill cores;prevision;oligocene;carotte;fanerozoico;porosite;neural networks;oligoceno;case studies;well log;ordinateur;gres;committee machine;permeabilite;sandstone;far east;diagraphie;data processing;tertiary;traitement donnee;testing;testigo;roca clastica;well logging;diagrafia;cenozoique;algorithme;modelo;taiwan;asie;estudio caso;roca sedimentaria;paleogene;clastic rocks;etude cas;log forage;paleogeno;algorithms;genetic algorithm;extreme orient;permeabilidad;permeability;modele;extremo oriente;empirical formulas;parallel architecture;reseau neuronal;well logs;tertiaire;phanerozoic;porosity;experimentation;porosidad;sedimentary rocks;prediction;averaging method;cenozoico;models;terciario;phanerozoique;red neuronal;reservoir;roche clastique;asia;neural network;algoritmo;cenozoic	This study integrates log-derived empirical formulas and the concept of the committee machine to develop an improved model for predicting permeability. A set of three empirical formulas, such as the Wyllie–Rose, Coates–Dumanoir, and porosity models to correlate reservoir well-logging information with measured core permeability, are used as expert members in a committee machine. A committee machine, a new type of neural network, has a parallel architecture that fuses knowledge by combining the individual outputs of its experts to arrive at an overall output. In this study, an ensemble-based committee machine with empirical formulas (CMEF) is used. This machine combines three individual formulas, each of which performs the same evaluation task. The overall output of each ensemble member is then computed according to the coefficients (weights) of the ensemble averaging method that reflects the contribution of each formula. The optimal combination of weights for prediction is also investigated using a genetic algorithm. We illustrate the method using a case study. Eighty-two data sets composed of well log data and core data were clustered into 41 training sets to construct the model and 41 testing sets to validate the model’s predictive ability. A comparison of prediction results from the CMEF model and from three individual empirical formulas showed that the proposed CMEF model for permeability prediction provided the best generalization and performance for validation. This indicated that the CMEF model was more accurate than any one of the individual empirical formulas performing alone. r 2005 Elsevier Ltd. All rights reserved.	artificial neural network;coefficient;committee machine;core data;ensemble averaging (machine learning);entity–relationship model;genetic algorithm;parallel computing;software release life cycle	Chang-Hsu Chen;Zsay-Shing Lin	2006	Computers & Geosciences	10.1016/j.cageo.2005.08.003	well logging;geology;computer science;artificial intelligence;paleontology;artificial neural network;statistics	AI	10.062267207708071	-23.908838463740796	123016
e349d06245eda4e0da5e28b18052a9dbf9ba8598	lightweight multi car dynamic simulator for reinforcement learning		With improvements in reinforcement learning algorithms, and the demand to implement these algorithms on real systems, the use of a simulator as an intermediate stage is essential to save time, material and financial resources. The lack of particular features in a unified simulator for applications to autonomous cars and robotics, encouraged this research, which produced a simulator capable of simulating multiple car like objects, in either one or several arenas (environments). Being a lightweight application, multiple instances of the simulator can run at the same time, only constrained by the available computational resources.	algorithm;autonomous car;autonomous robot;computation;computational resource;machine learning;partially observable system;prototype;reinforcement learning;robotics;simulation	Abhijit Majumdar;Patrick Benavidez;Mo M. Jamshidi	2018	2018 World Automation Congress (WAC)	10.23919/WAC.2018.8430473	simulation;engineering;reinforcement learning;multi-agent system;artificial intelligence;robotics	Robotics	19.456056360149358	-20.020744170641283	123090
9495bfb57c0c1a88ee48ac27b52e6c4b664988d6	a model recognition approach for solving interactive dynamic influence diagrams		The interactive dynamic influence diagrams provides a way to model and solve multi-agent decision-making problems from the perspective of the subject agent. The subject agent usually optimizes its own decisions by predicting the behavior of other agents. The exponential increase in the model of other agents over time bring great difficulties to the decision. In this paper, we propose a learning algorithm based on dynamic Bayesian network, and utilize standard Bayesian learning to update the likelihood of each candidate model given the observation histories. By excluding unrelated or weakly related models, the model space is fundamentally compressed. The experimental results show the advantages of the algorithm: on the one hand, the method successfully determines the real model of other agents to predict their behavior; on the other hand, compared with other methods, the method gets a higher return.	algorithm;data compression;decision making;dynamic bayesian network;influence diagram;multi-agent system;numerous;exponential	Le Tian;Huayi Yin	2017	IECON 2017 - 43rd Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2017.8216935	control engineering;machine learning;artificial neural network;dynamic bayesian network;engineering;influence diagram;exponential function;artificial intelligence;bayesian inference	AI	20.569080650349694	-19.275912815626565	123653
4fc3ef61563bd6a79d426d5ebc4e3a325a01d88d	exploring selection mechanisms for an agent-based distributed evolutionary algorithm	multi agent system;agent based;adaptive genetic algorithm;agent based model;population size;self adaptation;performance analysis;parallelization;genetic algorithms;evolutionary algorithm;multi agents systems	In this paper we propose an agent-based model of evolutionary algorithms (EAs) which extends seamlessly from concurrent single-host to distributed multi-host installations. Since the model is based on locally executable selection, we focus on the comparison of two selection mechanisms which accomplish with such a restriction: the classical tournament method and a new one called autonomous selection. Using the latter method the population size changes during runtime, hence it is not only interesting as a new selection mechanism, but also from the perspective of scalable networks.	agent-based model;autonomous robot;evolutionary algorithm;executable;scalability;social network	A. E. Eiben;Marc Schoenauer;Juan Luis Jiménez Laredo;Pedro Ángel Castillo Valdivieso;Antonio Mora García;Juan Julián Merelo Guervós	2007		10.1145/1274000.1274086	population size;simulation;genetic algorithm;computer science;artificial intelligence;machine learning;evolutionary algorithm	AI	23.048198496239564	-10.436336122923828	123818
a4f7585fe6c0e4e638167e738a034480bf97e556	task oriented machine-learning and review	path.;knowledge;task;optimization;machine-learning;machine learning;path finding	We propose an optimization algorithm to execute a previously unlearned task-oriented command in an intelligent machine. We show that a well-defined, physically bounded, task-oriented problem can be solved if a machine has knowledge of the goal of the task, is capable of determining the advantage of a decision, has knowledge of itself, has knowledge of the perimeters of the problem space, and is provided the basic physical skills to execute the task. The algorithm proposed operates on a cycle composed of learning, reviewing, and optimization. We use the classic robot path finding problem in an initially unknown environment to illustrate the algorithm.	algorithm;artificial intelligence;machine learning;mathematical optimization;pathfinding;problem domain	Pierre Abdelmalek;Howard E. Michel	2004			active learning (machine learning);generalization error;theoretical computer science;machine learning;computer science;wake-sleep algorithm;artificial intelligence	AI	18.772164758324955	-21.38657553859622	123898
c16b1dc8c66e0fcd5abf3a3a399ba4a83d3105c1	predicting gas emissions in a cement kiln plant using hard and soft modeling strategies	environmental factors;nitrogen compounds;least mean squares methods;so 2 emission abatement elm extreme learning machine polynomial function pmls parsimonious multivariate least squares soft modeling strategy hard modeling strategy cement kiln plant gas emission no 2;predictive models input variables kilns data models correlation computational modeling cyclones;cements building materials;sulphur compounds cements building materials environmental factors environmental science computing learning artificial intelligence least mean squares methods nitrogen compounds polynomials;polynomials;environmental science computing;learning artificial intelligence;sulphur compounds	In this work, two alternative methodologies for modeling and predicting gas emissions of NO, NO2 and SO2 are presented. The first method involves hard modeling strategies with Parsimonious Multivariate Least Squares (PMLS) assuming simple polynomial functions as base model. The second is a soft modeling approach using Extreme Learning Machine (ELM). In this work we found that both methods have similar capabilities for data description, providing an in depth analysis of the system under study. Results also reveal further insights in predicting gas emissions and enlighten on which of the factors can be useful for prediction, and consequently for system characterization and emission abatement.	interdependence;kerrison predictor;least squares;maxima and minima;occam's razor;polynomial	Dulce Gabriel;Tiago Matias;J. Costa Pereira;Rui Araújo	2013	2013 IEEE 18th Conference on Emerging Technologies & Factory Automation (ETFA)	10.1109/ETFA.2013.6648036	computer science;engineering;artificial intelligence;forensic engineering;polynomial;mechanical engineering	Robotics	12.311612434474704	-19.91187235025768	123915
77929db77f7f11584081187c0b33147f0aa5646f	a hybrid forecast of exchange rate based on arfima,discrete grey-markov, and fractal kalman model		We propose a hybrid forecast based on extended discrete grey Markov and variable dimension Kalman model and show that our hybrid model can improve much more the performance of forecast than traditional grey Markov and Kalman models. Our simulation results are given to demonstrate that our hybrid forecast method combined with degree of grey incidence are better than grey Markov and ARFIMA model or Kalman methods.	autoregressive fractionally integrated moving average;fractal dimension;genetic genealogy;incidence matrix;kalman filter;markov chain;simulation	Gol Kim;Ri Suk Yun	2012	CoRR		econometrics;statistics	AI	23.254795874289908	-22.361109291475998	124029
3f638b68c008cd1cd9ca407521ac1bce46978a40	multi-timescale, gradient descent, temporal difference learning with linear options		Deliberating on large or continuous state spaces have been long standing challenges in reinforcement learning. Temporal Abstraction have somewhat made this possible, but efficiently planing using temporal abstraction still remains an issue. Moreover using spatial abstractions to learn policies for various situations at once while using temporal abstraction models is an open problem. We propose here an efficient algorithm which is convergent under linear function approximation while planning using temporally abstract actions. We show how this algorithm can be used along with randomly generated option models over multiple time scales to plan agents which need to act real time. Using these randomly generated option models over multiple time scales are shown to reduce number of decision epochs required to solve the given task, hence effectively reducing the time needed for deliberation. ar X iv :1 70 3. 06 47 1v 1 [ cs .A I] 1 9 M ar 2 01 7	ap computer science a;approximation algorithm;gradient descent;linear function;planning;procedural generation;recursion;reinforcement learning;temporal difference learning;time complexity;tracing (software)	Peeyush Kumar;Doina Precup	2017	CoRR		mathematical optimization;simulation;artificial intelligence;machine learning;mathematics	ML	21.281745002146362	-19.150043188908306	124053
ce4eb6d998e0722bf1dd240e3b533d0481c50c09	a wireless sensor network-based portable vehicle detector evaluation system	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;wsn;uk phd theses thesis;vehicle detection system;life sciences;vds;traffic monitoring;uk research reports;medical journals;reference instrument;wireless sensor networks;europe pmc;biomedical research;bioinformatics	In an upcoming smart transportation environment, performance evaluations of existing Vehicle Detection Systems are crucial to maintain their accuracy. The existing evaluation method for Vehicle Detection Systems is based on a wired Vehicle Detection System reference and a video recorder, which must be operated and analyzed by capable traffic experts. However, this conventional evaluation system has many disadvantages. It is inconvenient to deploy, the evaluation takes a long time, and it lacks scalability and objectivity. To improve the evaluation procedure, this paper proposes a Portable Vehicle Detector Evaluation System based on wireless sensor networks. We describe both the architecture and design of a Vehicle Detector Evaluation System and the implementation results, focusing on the wireless sensor networks and methods for traffic information measurement. With the help of wireless sensor networks and automated analysis, our Vehicle Detector Evaluation System can evaluate a Vehicle Detection System conveniently and objectively. The extensive evaluations of our Vehicle Detector Evaluation System show that it can measure the traffic information such as volume counts and speed with over 98% accuracy.	algorithm;cable;customize;detector device component;detectors;digital video recorder;evaluation;lasers;limewire;network architecture;network packet;ninety nine;objectivity/db;packetized elementary stream;percent mass per mass;physiologic monitoring recorder;piezoelectricity;potential energy surface;routing;scalability;sexually transmitted diseases;systems architecture	Seongeun Yoo	2013		10.3390/s130101160	embedded system;simulation;wireless sensor network;telecommunications;vehicle tracking system;computer science;bioinformatics;engineering;electrical engineering;computer security	Mobile	16.00921563749882	-13.2061026611901	124092
1587f01d5c5f7f1d849ddd3bea11d785f7e4fbc8	a new surface reconstruction method in reverse engineering	learning algorithm;surface reconstruction arithmetic backpropagation production engineering computing reverse engineering simulated annealing;rbfnn;training;backpropagation;simulated annealing;surface reconstruction;points cloud surface reconstruction method;production engineering computing;surface reconstruction radial basis function neural network simulated annealing arithmetic matlab;radial basis function networks;artificial neural networks;nonlinear function;simulated annealing arithmetic;radial basis function neural network;solid modeling;arithmetic;backpropagation learning algorithm network;point cloud;nonlinear function reverse engineering points cloud surface reconstruction method radial basis function neural network rbfnn simulated annealing arithmetic matlab program backpropagation learning algorithm network;surface reconstruction reconstruction algorithms reverse engineering arithmetic clouds iterative algorithms radial basis function networks simulated annealing matlab algorithm design and analysis;back propagation;meteorology;matlab;matlab program;reverse engineering	Points cloud surface reconstruction method in reverse engineering was proposed, Radial basis function neural network (RBFNN) was designed, and simulated annealing arithmetic was adopted to adjust the network weights. MATLAB program was compiled, experiments on points cloud data have been done employing the program. All experiments have shown that the arithmetic can efficiently approach the surface with 10-4 mm error precision, also the learning speed is quick and reconstruction surface is smooth. Trainings have been done with other networks in comparison. The sum squared error is 4.6802×10-8mm using the algorithmic proposed in this paper, the one is 1.1014×10-6mm under the same parameters employing RBFNN only. Back-propagation learning algorithm network does not converge until 3500 iterative procedure, and exactness design RBFNN is time-consuming. The arithmetic can approach nonlinear function by arbitrary precision, and also keep the network from getting into partial minimum.		Xue-mei Wu;Gui-xian Li;De-bin Shan;Wei-min Zhao	2009		10.1109/ICNC.2009.327	computer science;artificial intelligence;theoretical computer science;machine learning	Vision	13.263320359435923	-23.32747922281816	124149
5559f15e3ed0cdd29715509d01022cb98c4f351a	the role of sensory-motor coordination - identifying environmental motion dynamics with dynamic neural networks	motor coordination	We describe three recurrent neural architectures inspired by the proprioceptive system found in mammals; Exo-sensing, Ego-sensing, and Composite. Through the use of Particle Swarm Optimisation the robot controllers are adapted to perform the task of identifying motion dynamics within their environment. We highlight the effect of sensory-motor coordination on the performance in the task when applied to each of the three neural architectures.	integrated project support environment;mathematical optimization;mobile robot;neural networks;particle filter;particle swarm optimization;recurrent neural network	Stephen Paul McKibbin;Bala P. Amavasai;Arul N. Selvan;Fabio Caparrelli;W. A. F. W. Othman	2008				Robotics	18.795649026776584	-23.196837101004544	124523
2f05be9cf95e1aed7a08fa158cc2dde31261452f	feature selection with a grouping genetic algorithm - extreme learning machine approach for wind power prediction			feature selection;genetic algorithm	Laura Cornejo-Bueno;Carlos Camacho-Gómez;Adrián Aybar-Ruíz;Luis Prieto;Sancho Salcedo-Sanz	2016		10.1007/978-3-319-44636-3_35	machine learning;pattern recognition;data mining;population-based incremental learning	ML	11.135249115285923	-23.89669413567975	124708
c8c3c9d05f6d2c47751b1d8010d95a55c6653de0	using an induced relational decision tree for rule injection in a learning classifier system	learning process;structural model;decision tree;learning;search space;rule based system;reinforcement learning;relational reinforcement learning;prediction algorithms;learning rule based system induced relational decision tree rule injection learning classifier system learning transfer systems adaptive rule based systems relational learning xcs first order relational decission tree;learning classifier system;adaptive rule based systems;xcs;induced relational decision tree;accuracy;first order;estimation;pattern classification decision trees knowledge based systems learning artificial intelligence;complex i;first order relational decission tree;relational model;markov process;pattern classification;hybrid system;estimation learning prediction algorithms regression tree analysis accuracy markov processes adaptation models;learning rule based system;transfer learning;rule injection;decision process;markov processes;learning artificial intelligence;adaptation models;decision trees;learning transfer systems;relational learning;knowledge based systems;regression tree analysis;generalization capability	Transfer learning, using systems with rich and general representations, to improve adaptive rule based systems designed to efficiently react in changing environments is the idea behind the problem studied in this paper. In this framework, the aim of this research is studying the benefits of using relational learning in combination with an evolutionary propositional learning system as XCS. The proposed method starts by learning a first order relational decission tree using a set of simplified instances of a problem. The learned relational model is then used to help a learning classifier system to deal with a more complex instance of the task. The researched strategy is based on injecting rules derived from the relational model in the discovering subsystem of the XCS. Results show that this method can be used to automatically adapt the behaviour of a learning rule based system when the environment increases its complexity.	algorithm;decision tree;experiment;intelligent agent;learning classifier system;learning rule;relational model;rich representation language;rule-based system	J. I. Estévez;Pedro A. Toledo;Silvia Alayón	2011	2011 IEEE Congress of Evolutionary Computation (CEC)	10.1109/CEC.2011.5949680	semi-supervised learning;multi-task learning;instance-based learning;error-driven learning;statistical relational learning;computer science;artificial intelligence;machine learning;decision tree;pattern recognition;markov process;learning classifier system;reinforcement learning;statistics	AI	19.610205118790592	-21.956261033993552	124785
78147fed4bd451989c0b9a0a318810810158ee4a	the expected value of hierarchical problem-solving	abstraction hierarchy;model development;problem solving	In the best case using an abstraction hierarchy in problem solving can yield an exponential speed up in search e ciency Such a speed up is predicted by var ious analytical models developed in the literature and e ciency gains of this order have been con rmed empir ically However these models assume that the Down ward Re nement Property DRP holds When this property holds backtracking never need occur across abstraction levels When it fails search may have to consider many di erent abstract solutions before nd ing one that can be re ned to a concrete solution In this paper we provide an analysis of the expected search complexity without assuming the DRP We nd that our model predicts a phase boundary where abstraction provides no bene t if the probability that an abstract solution can be re ned is very low or very high search with abstraction yields signi cant speed up However in the phase boundary area where the probability takes on an intermediate value search e ciency is not nec essarily improved The phenomenon of a phase bound ary where search is hardest agrees with recent empirical studies of Cheeseman et al CKT	backtracking;best, worst and average case;disaster recovery plan;hereditary property;naruto shippuden: clash of ninja revolution 3;problem solving;speedup;time complexity	Fahiem Bacchus;Qiang Yang	1992			artificial intelligence;machine learning;algorithm;statistics	AI	19.68014045558028	-12.486852988496544	125103
64ba9f4b1b0869dc69a2ac8d1e0bb3691775ea0b	multi-thresholded approach to demonstration selection for interactive robot learning	robot learning;automated multithreshold approach multithresholded approach demonstration selection interactive robot learning complex robot behaviors interactive approach informative states single threshold value action confidence multiple confidence threshold multithreshold selection confidence based selection single fixed threshold manual data selection;human robot interaction;learning from demonstration;learning by example;robots;robots learning by example;robot sensing systems training learning systems support vector machines uncertainty training data;learning from demonstration human robot interaction	Effective learning from demonstration techniques enable complex robot behaviors to be taught from a small number of demonstrations. A number of recent works have explored interactive approaches to demonstration, in which both the robot and the teacher are able to select training examples. In this paper, we focus on a demonstration selection algorithm used by the robot to identify informative states for demonstration. Existing automated approaches for demonstration selection typically rely on a single threshold value, which is applied to a measure of action confidence. We highlight the limitations of using a single fixed threshold for a specific subset of algorithms, and contribute a method for automatically setting multiple confidence thresholds designed to target domain states with the greatest uncertainty. We present a comparison of our multi-threshold selection method to confidence-based selection using a single fixed threshold, and to manual data selection by a human teacher. Our results indicate that the automated multi-threshold approach significantly reduces the number of demonstrations required to learn the task.	information;reinforcement learning;robot learning;selection algorithm	Sonia Chernova;Manuela M. Veloso	2008	2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/1349822.1349852	human–robot interaction;robot;robot learning;simulation;computer science;artificial intelligence;machine learning	Robotics	20.376009635389284	-20.946914341865064	125122
b851f7190b85fdbea779c6846f1b241065986e6b	a hybrid algorithm for coalition structure generation	agile teaming;qa75 electronic computers computer science;mechanism design	The current state-of-the-art algorithm for optimal coalition structure generation is IDP-IP—an algorithm that combines IDP (a dynamic programming algorithm due to Rahwan and Jennings, 2008b) with IP (a tree-search algorithm due to Rahwan et al., 2009). In this paper we analyse IDP-IP, highlight its limitations, and then develop a new approach for combining IDP with IP that overcomes these limitations.	anomaly detection at multiple scales;anytime algorithm;best, worst and average case;dynamic programming;hybrid algorithm;search algorithm;tree traversal;worst-case complexity	Talal Rahwan;Tomasz P. Michalak;Nicholas R. Jennings	2012			mechanism design;simulation;artificial intelligence;machine learning;distributed computing	AI	18.953007643445734	-16.054989525499412	125267
6754f3e1c204a14795977b587109db77d5f86c2c	adaptive online prediction method based on ls-svr and its application in an electronic system	yang ming guo cong bao ran xiao lei li jie zhong ma 在线预测 电子系统 自适应 应用 支持向量回归机 计算时间 预测模型 预测精度 adaptive online prediction method based on ls svr and its application in an electronic system	Health trend prediction has become an effective way to ensure the safe operation of highly reliable systems, and online prediction is always necessary in many real applications. To simultaneously obtain better or acceptable online prediction accuracy and shorter computing time, we propose a new adaptive online method based on least squares support vector regression (LS-SVR). This method adopts two approaches. One approach is that we delete certain support vectors by judging the linear correlation among the samples to increase the sparseness of the prediction model. This approach can control the loss of useful information in sample data, improve the generalization capability of the prediction model, and reduce the prediction time. The other approach is that we reduce the number of traditional LS-SVR parameters and establish a modified simple prediction model. This approach can reduce the calculation time in the process of adaptive online training. Simulation and a certain electric system application indicate preliminarily that the proposed method is an effective prediction approach for its good prediction accuracy and low computing time.	least squares;neural coding;protein structure prediction;simulation;support vector machine	Yang-ming Guo;Cong-bao Ran;Xiao-lei Li;Jie-zhong Ma	2012	Journal of Zhejiang University SCIENCE C	10.1631/jzus.C1200156	speech recognition;computer science;artificial intelligence;data mining	ML	12.142814485284875	-18.30095678921952	125491
9b5c8966157d8fc2f3807ce48e127b7e8b8a9a0b	fault diagnosis of pneumatic systems with artificial neural network algorithms	production system;pneumatic;back propagation bp;modular production system;normal modes;adaptive resonance theory2 art2;adaptive resonance theory 2;estimation error;synthetic data;back propagation;artificial neural network;fault diagnosis	Pneumatic systems repeat the identical programmed sequence during their operation. The data was collected when the pneumatic system worked perfectly and had some faults including empty magazine, zero vacuum, inappropriate material, no pressure, closed manual pressure valve, missing drilling stroke, poorly located material, not vacuuming the material and low air pressure. The signals of eight sensors were collected during the entire sequence and the 24 most descriptive features of the data were encoded to present to the ANNs. A synthetic data generation process was proposed to train and test the ANNs better when signals are extremely repetitive from one sequence to other. Two artificial neural networks (ANN) were used for interpretation of the encoded signals. The tested ANNs were Adaptive Resonance Theory 2 (ART2), and Back propagation (Bp). ART2 correctly distinguished the perfect and faulty operations at all the tested vigilance values. It classified 11 faulty and 1 normal modes in seven or eight categories at the best vigilance values. Bp also distinguished perfect and faulty operations without even the slightest uncertainty. In less than 10 cases, it had difficulty identifying the 11 types of possible faults. The average estimation error of the Bp was better than 2.1% of the output range on the test data which was created by deviating the encoded values. The ART2 and Bp performance was found excellent with the proposed encoding and synthetic data generation procedures for extremely repetitive sequential data. 2009 Elsevier Ltd. All rights reserved.	adaptive resonance theory;algorithm;artificial neural network;normal mode;sensor;software propagation;synthetic data;test data	Mustafa Demetgül;Ibrahim N. Tansel;S. Taskin	2009	Expert Syst. Appl.	10.1016/j.eswa.2009.01.028	normal mode;computer science;artificial intelligence;backpropagation;machine learning;production system;artificial neural network;synthetic data	AI	14.024514251166233	-17.888092269536184	125688
5ffdc6b4129b6db44dfc28ed5fa0136e07996b51	verification of markov decision processes using learning algorithms	verification;reinforcement learning;machine learning;statisticalmodel checking;stochastic systems	We present a general framework for applying machine-learning algorithms to the verification of Markov decision processes (MDPs). The primary goal of these techniques is to improve performance by avoiding an exhaustive exploration of the state space. Our framework focuses on probabilistic reachability, which is a core property for verification, and is illustrated through two distinct instantiations. The first assumes that full knowledge of the MDP is available, and performs a heuristic-driven partial exploration of the model, yielding precise lower and upper bounds on the required probability. The second tackles the case where we may only sample the MDP, and yields probabilistic guarantees, again in terms of both the lower and upper bounds, which provides efficient stopping criteria for the approximation. The latter is the first extension of statistical model checking for unbounded properties in MDPs. In contrast with other related techniques, our approach is not restricted to time-bounded (finite-horizon) or discounted properties, nor does it assume any particular properties of the MDP. We also show how our methods extend to LTL objectives. We present experimental results showing the performance of our framework on several examples.	algorithm;approximation;formal verification;heuristic;machine learning;markov chain;markov decision process;model checking;reachability;state space;statistical model;verification and validation	Tomás Brázdil;Krishnendu Chatterjee;Martin Chmelik;Vojtech Forejt;Jan Kretínský;Marta Z. Kwiatkowska;David Parker;Mateusz Ujma	2014		10.1007/978-3-319-11936-6_8	mathematical optimization;verification;computer science;artificial intelligence;theoretical computer science;machine learning;reinforcement learning;algorithm	Logic	21.997189795191442	-15.809765150881933	125794
0bd5f0e635beec62ec068329a7d179d18e311154	an improved method to calculate the time-to-collision of two vehicles		In order to improve vehicle safety, a interaction phase between primary and secondary safety systems has been defined. These systems use information provided by the primary safety systems to achieve both the primary and the secondary systems’ objectives. It is essential to discriminate whether a collision is avoidable or not and to calculate the time available before the crash happens. This paper shows a method that improves on other simplifiedmethods to calculate the time-to-collision (TTC) to provide a more accurate result that could be used in a collision avoidance system.		Felipe Jiménez;José Eugenio Naranjo;Fernando García	2013	Int. J. Intelligent Transportation Systems Research	10.1007/s13177-012-0054-4	reliability engineering;simulation;engineering;forensic engineering	Robotics	11.064342513139167	-11.05660922437573	125927
24fcbd94628cd0e3c9e7175738b7712022f4efad	kinetic morphogenesis of a multilayer perceptron		We introduce a morphogenesis paradigm for a neural network where neurons are allowed to move autonomously in a topological space to reach suitable reciprocal positions under an informative perspective. To this end, a neuron is attracted by the mates which are most informative and repelled by those which are most similar to it. We manage the neuron motion with a Newtonian dynamics in a subspace of a framework where topological coordinates match with those reckoning the neuron connection weights. As a result, we have a synergistic plasticity of the network which is ruled by an extended Lagrangian where physics components merge with the common error terms. With the focus on a multilayer perceptron, this plasticity is operated by an extension of the standard back-propagation algorithm which proves robust even in the case of deep architectures. We use two classic benchmarks to gain some insights on the morphology and plasticity we are proposing.	algorithm;artificial neural network;backpropagation;benchmark (computing);boltzmann machine;coefficient;emulator;galaxy morphological classification;granular computing;ground state;information;multilayer perceptron;neuron;programming paradigm;social network;software propagation;synergy	Bruno Apolloni;Simone Bassis;Lorenzo Valerio	2011			pattern recognition;artificial intelligence;machine learning;computer science;multilayer perceptron;morphogenesis	ML	16.201819685879766	-23.578468040776453	126132
0e554198a6e3cdce1821d579a454b79702e32d9f	evolutionary search for cellular automata logic gates with collision-based computing		We aim to search for cellular automata candidates using an automatic system for the demonstration of collision-based universality. Some of these candidates are able to simulate Turing machines in their space-time dynamics using gliders and glider guns. In this paper, we present an evolutionary algorithm that searches for the simulation of a logic gate by cellular automata. Different parameters are tried and other search techniques are also presented to provide a benchmark. Results show how a large number of simulations of logic gates were found.	automata theory;benchmark (computing);cellular automaton;evolutionary algorithm;glider (conway's life);gun (cellular automaton);logic gate;simulation;universal turing machine	Emmanuel Sapin;Larry Bull	2008	Complex Systems		computer science;artificial intelligence;theoretical computer science;machine learning;mobile automaton;algorithm	Embedded	22.190528407965395	-10.54829253345997	126183
727297f40bb91641eeb5db7720862cd70856686d	autonomous discovery of motor constraints in an intrinsically motivated vocal learner		This paper introduces new results on the modeling of early vocal development using artificial intelligent cognitive architectures and a simulated vocal tract. The problem is addressed using intrinsically motivated learning algorithms for autonomous sensorimotor exploration, a kind of algorithm belonging to the active learning architectures family. The artificial agent is able to autonomously select goals to explore its own sensorimotor system in regions, where its competence to execute intended goals is improved. We propose to include a somatosensory system to provide a proprioceptive feedback signal to reinforce learning through the autonomous discovery of motor constraints. Constraints are represented by a somatosensory model which is unknown beforehand to the learner. Both the sensorimotor and somatosensory system are modeled using Gaussian mixture models. We argue that using an architecture which includes a somatosensory model would reduce redundancy in the sensorimotor model and drive the learning process more efficiently than algorithms taking into account only auditory feedback. The role of this proposed system is to predict whether an undesired collision within the vocal tract under a certain motor configuration is likely to occur. Thus, compromised motor configurations are rejected, guaranteeing that the agent is less prone to violate its own constraints.		Juan Manuel Acevedo-Valle;Cecilio Angulo;Cl&#x00E9;ment Moulin-Frier	2018	IEEE Transactions on Cognitive and Developmental Systems	10.1109/TCDS.2017.2699578	redundancy (engineering);mixture model;machine learning;architecture;active learning;somatosensory system;computer science;artificial intelligence;auditory feedback;vocal tract;cognition	ML	18.721949996908325	-21.77582066803724	126522
024a44012c9d4235e4b5c4e5e7f52307f8e0220d	parameter estimation of a demand forecasting function associated with the behavior of weed using genetic algorithm	estimation of parameters;weed;genetic algorithm	This paper presents a computational method used to estimate the parameters of a demand forecasting equation, and its semantic interpretation, that describes the behavior of a generation of weeds in an agricultural field. Its implementation was made witha genetic algorithm (GA) structured by evolutionary logic, which uses the technique of identification of the function parameters from the seeds density of weed on an experimental field. In order to evaluate and validate the developed technique, a seeds density of weed database was generated from the application of originalparameters of the weed Abutilon theophrasti which can be found in a maize crop (Zea mays) area. This database was used, and the GA demonstrated a high efficacy. In 38% of the analyzed cases, the fitness was below 5 for 100 realized experiments. This associated variable, i.e, for each analyzed individual, is related to the mean square error (MSE), which has its existence in thedomain 0 ≤ MSE	computation;estimation theory;experiment;fitness function;genetic algorithm;mean squared error;mike lesser;premature convergence;seeds (cellular automaton);semantic interpretation;software release life cycle;the 100;time complexity	Marinna S. Sterzo;Paulo Estevão Cruvinel	2017	2017 IEEE 11th International Conference on Semantic Computing (ICSC)	10.1109/ICSC.2017.43	genetic algorithm;computer science;artificial intelligence;machine learning	Robotics	12.683186467795647	-22.607022740046624	126838
9be877a9fb8ed1d1ec69e71d6a61a4832ceb65a1	the problem of a mouse in a maze	problem solving method	In a broader research work about problem-solving methods and techniques, the problem of a mouse in a maze appears to be a fairly good problem to deal with. In fact, it is complex to be described in detail, easily understandable as regards its main features and well-known in order to have other instances of solution a new one can be compared to.	problem solving	Luca Majocchi;Giacomo R. Sechi	1984	SIGART Newsletter	10.1145/1056648.1056652	toy problem;computer science;artificial intelligence;machine learning;algorithm	DB	18.582783916711165	-11.803449253430525	126917
95ee75c3ae63099f0191a2d0a277cac8cff15d0a	realtime online solving of quantified csps	arc consistency;success rate;quantified constraint satisfaction problem	We define Realtime Online solving of Quantified Constraint Satisfaction Problems (QCSPs) as a model for realtime online CSP solving. We use a combination of propagation, lookahead and heuristics and show how all three improve performance. For adversarial opponents we show that we can achieve promising results through good lookahead and heuristics and that a version of alpha beta pruning performs strongly. For random opponents, we show that we can frequently achieve solutions even on problems which lack a winning strategy and that we can improve our success rate by using Existential Quantified Generalised Arc Consistency, a lower level of consistency than SQGAC, to maximise pruning without removing solutions. We also consider the power of the universal opponent and show that through good heuristic selection we can generate a significantly stronger player than a static heuristic provides.	alpha–beta pruning;bin packing problem;consistency model;constraint satisfaction;cryptographic service provider;heuristic (computer science);local consistency;online algorithm;overhead (computing);parsing;problem solving;sampling (signal processing);set packing;software propagation;solver	David Stynes;Kenneth N. Brown	2009		10.1007/978-3-642-04244-7_60	mathematical optimization;computer science;machine learning;mathematics;algorithm;local consistency	AI	19.71648613682064	-11.553210246534192	127029
838060bcd75efd8aabc890d04ce60ce2c9d7de2b	incremental evolution of robot controllers for a highly integrated task	robot movil;iterative method;realite virtuelle;sintesis control;realidad virtual;behavioral analysis;mobile robot;virtual reality;robotics;animal;metodo iterativo;refinement method;robot mobile;methode iterative;synthese commande;analyse comportementale;evolutionary strategy;robotica;algorithme evolutionniste;analisis conductual;algoritmo evolucionista;robotique;evolutionary algorithm;methode raffinement;reseau neuronal;metodo afinamiento;red neuronal;control synthesis;moving robot;neural network	In this paper we apply incremental evolution for automatic synthesis of neural network controllers for a group of physically connected mobile robots called s-bots. The robots should be able to safely and cooperatively perform phototaxis in an arena containing holes. We experiment with two approaches to incremental evolution, namely behavioral decomposition and environmental complexity increase. Our results are compared with results obtained in a previous study where several non-incremental evolutionary algorithms were tested and in which the evolved controllers were shown to transfer successfully to real robots. Surprisingly, none of the incremental evolutionary strategies performs any better than the non-incremental approach. We discuss the main reasons for this and why it can be difficult to apply incremental evolution successfully in highly integrated tasks.	artificial neural network;evolution;evolutionary algorithm;mobile robot	Anders Lyhne Christensen;Marco Dorigo	2006		10.1007/11840541_39	mobile robot;simulation;computer science;artificial intelligence;evolutionary algorithm;virtual reality;iterative method;evolution strategy;robotics;artificial neural network;algorithm	Robotics	23.776690332822884	-12.412714990639593	127285
eb603ddf4b40a7facae3d303fb2193b5b52bb4bc	machine learning based models for fault detection in automatic meter reading systems		Recently, research has focused on the area of fault detection in Automatic Meter Reading (AMR) systems. The manufacturers and users of AMR systems are now keen to include diagnostic features in the systems to improve salability and reliability. However, traditional manual fault detection methods are time-consuming and inaccurate. automatic fast fault detection methods are urgently needed. In this paper, we propose several machine learning based fault detection models to meet this requirement. Furthermore, we use novel boosting strategy to fuse multiple models to leverage multi-aspect information in AMR systems. The experimental results on simulated data show that the proposed models are accurate and robust, and fusion strategy indeed improve the performance on fault detection.	adaptive multi-rate audio codec;fault detection and isolation;machine learning;optimizing compiler	Yinggang Kou;Gaoying Cui;Jie Fan;Xiao Chen;Wei Li	2017	2017 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)	10.1109/SPAC.2017.8304362	automatic meter reading;boosting (machine learning);decision tree;recurrent neural network;data modeling;machine learning;multiple models;fault detection and isolation;server;artificial intelligence;computer science	Robotics	14.351927600790194	-16.991248242444232	127335
e7d4e4452c7192e7fc0c1b37fe173bbd4f9d7e5f	fault prognostic and prediction based on the importance degree of test point	loss measurement;test points;reliability engineering;partial derivatives;untrusted rate signal flow model phm undetected rate partial derivatives false alarm rate;degree of test point;prognostics and health management;signal flow model;mechanical engineering computing;testability metrics;prognostics and health management loss measurement reliability engineering fault detection fault diagnosis;fault prediction;system testability;false alarm rate;signal processing failure analysis fault diagnosis mechanical engineering computing;fault prognostic;failure analysis;signal processing;fault detection;undetected rate;untrusted rate;phm;testability metrics fault prognostic fault prediction degree of test point prognostics and health management test points signal flow model system testability false alarm rate;fault diagnosis	Prognostics and Health Management (PHM) is a technology to monitor the equipment status and predict impending faults. It is used to predict the potential fault and provide fault information and track trends of system degradation by capturing characteristics signals. So how to detect characteristics signals is very important. The select of test point plays a very important role in detecting characteristics signal. Traditionally, we use dependency model to select the test point containing the most detecting information. But, facing the large complicated system, the dependency model is not built so easily sometimes. And the greater trouble is how to calculate the matrix. Rely on this premise, the paper provide a highly effective method to select test point without dependency model. Because Signal flow model is a diagnosis model based on failure mode, which focuses on system's failure mode and the dependency relationship between the test points and faults. In the signal flow model, a fault information can flow from the beginning to the end. According to the signal flow model, we can find out location and structure information of every test point and module. We break the signal flow model up into serial and parallel parts to obtain the final relationship function between the system's testability or prediction metrics and test points. Further, through the partial derivatives operation, we can obtain every test point's importance degree in determining the testability metrics, such as undetected rate, false alarm rate, untrusted rate. This contributes to installing the test point according to the real requirement and also provides a solid foundation for the Prognostics and Health Management. According to the real effect of the practical engineering application, the method is very efficient.	effective method;elegant degradation;failure cause;sensor;software testability;test point;the matrix	Wenkui Hou;Junfeng Yan	2015	2015 IEEE Conference on Prognostics and Health Management (PHM)	10.1109/ICPHM.2015.7245025	reliability engineering;real-time computing;engineering;automatic test pattern generation;forensic engineering	EDA	12.28251730424783	-13.274297094222202	127398
6d06d5c3378d7f2191e858778f4f5dba10246983	generalizing over uncertain dynamics for online trajectory generation		We present an algorithm which learns an online trajectory generator that can generalize over varying and uncertain dynamics. When the dynamics is certain, the algorithm generalizes across model parameters. When the dynamics is partially observable, the algorithm generalizes across different observations. To do this, we employ recent advances in supervised imitation learning to learn a trajectory generator from a set of example trajectories computed by a trajectory optimizer. In experiments in two simulated domains, it finds solutions that are nearly as good as, and sometimes better than, those obtained by calling the trajectory optimizer on line. The online execution time is dramatically decreased, and the off-line training time is reasonable.	algorithm;experiment;mathematical optimization;online and offline;partially observable system;run time (program lifecycle phase);simulated annealing;simulation;supervised learning	Beomjoon Kim;Albert Kim;Hongkai Dai;Leslie Pack Kaelbling;Tomás Lozano-Pérez	2015		10.1007/978-3-319-60916-4_3	mathematical optimization;machine learning;control theory	ML	20.78659947857272	-18.61880626671505	127418
e305cdc5915590e470534ebb4b6bebb1969f2cea	empirical sensitivity analysis of discretization parameters for fault pattern extraction from multivariate time series data	market research;probability density function;discretization;time series;time series analysis;sensitivity analysis;feature extraction;fault detection;time series discretization fault detection pattern extraction sensitivity analysis;article;pattern extraction;time series analysis sensitivity analysis market research fault detection data models probability density function feature extraction;data models	It has been a challenge to find patterns in a time series of sensor data for fault detection in a system. Since it is usually not straightforward to discover meaningful features and rules directly from complex time series, data discretization has been popularly employed to reduce data size while preserving meaningful features from the original data, for which the choice of appropriate discretization parameters is crucial. We thus present a systematic discretization procedure of multivariate time series data that includes: 1) label definition in consideration of the estimated distribution functions of sensor signals and the trends of signal’s short-term variation and 2) label specification to a set of time segments in order to describe the state of a given system for the time segment as a discretized state vector. Formal definitions of fault patterns and discretization problems are made to conduct empirical sensitivity analysis of discretization parameters in finding the most informative fault patterns. We then investigate the relationship between the parameters and the key characteristic indicators of sensor signals. The computational results with the ten real-world data sets provide a practical advice to select appropriate parameters.	code;discretization;fault detection and isolation;http 404;information;overlap zone;pattern recognition;population parameter;rule (guideline);sensor;specification;time series	Sujeong Baek;Duck Young Kim	2017	IEEE Transactions on Cybernetics	10.1109/TCYB.2016.2540657	market research;discretization error;computer science;machine learning;time series;discretization;data mining;mathematics;discretization of continuous features;statistics	ML	24.42079045488246	-22.46335857524135	127541
0f60a604399a701cbff62e956f39bd28bb62f75d	utilizing anfis for prediction water absorption of lightweight geopolymers produced from waste materials		In the present work, water absorption of lightweight geopolymers produced by fine fly ash and rice husk–bark ash together with palm oil clinker (POC) aggregates has been investigated experimentally and modeled by adaptive network-based fuzzy inference systems (ANFIS). Different specimens made from a mixture of fine fly ash and rice husk–bark ash with and without POC were subjected to water absorption tests at 2, 7, and 28 days of curing. The specimens were oven cured for 36 h at 80 °C and then cured at room temperature until 2, 7, and 28 days. The results showed that high amount of POC particles improve the percentage of water absorption at the early age of curing. In addition, the ratio of “the percentage of water absorption” to “weight” of the POC-contained specimens at all ages of curing was much higher than that of POC-free specimens, which make them suitable for lightweight applications. To build the model, training, validating, and testing using experimental results from 144 specimens were conducted. The used data in the ANFIS models are arranged in a format of six input parameters that cover the quantity of fine POC particles, the quantity of coarse POC particles, the quantity of FA + RHBA mixture, the ratio of alkali activator to ashes mixture, the age of curing, and the test trial number. According to these input parameters, the water absorption of each specimen was predicted. The training, validating, and testing results in the ANFIS models showed a strong potential for predicting the water absorption of the geopolymer specimens.	adaptive neuro fuzzy inference system;biological specimen;experiment;fuzzy logic;palm os	Ali Nazari	2012	Neural Computing and Applications	10.1007/s00521-012-0934-1	mathematical optimization;absorption of water;geopolymer;clinker (cement);adaptive neuro fuzzy inference system;fly ash;mathematics;composite material	NLP	12.245149156194381	-19.685996335255393	127775
25699c369eb4f64c03453bde6def0db9e4d02599	faster probabilistic planning through more efficient stochastic satisfiability problem encodings	satisfiability;finite horizon;partial observation	The propositional contingent planner ZANDER solves finitehorizon, partially observable, probabilistic planning problems at state-of-the-art-speeds by converting the planning problem to a stochastic satisfiability (SSAT) problem and solving that problem instead (Majercik 2000). ZANDER obtains these results using a relatively inefficient SSAT encoding of the problem (a linear action encoding with classical frame axioms). We describe and analyze three alternative SSAT encodings for probabilistic planning problems: a linear action encoding with simple explanatory frame axioms, a linear action encoding with complex explanatory frame axioms, and a parallel action encoding. Results on a suite of test problems indicate that linear action encodings with simple explanatory frame axioms and parallel action encodings show particular promise, improving ZANDER’s efficiency by as much as three orders of magnitude.	boolean satisfiability problem;church encoding;contingency (philosophy);partially observable system;stochastic optimization	Stephen M. Majercik;Andrew P. Rusczek	2002			combinatorics;discrete mathematics;mathematics;algorithm	AI	20.961122716820466	-14.27580893934515	128458
894ac148cfea4adc2a4ce0fea8dd8c8eb45d76e9	a rop prediction approach based on improved bp neural network	neural networks instruction sets welding;neural networks;welding;rop equations rop prediction bp neural network bp improvement;china rop prediction approach bp neural network rate of penetration prediction well drilling process regression analysis drilling practices geology data drilling logs well logs bp training algorithm dynamical learning rate yuanba;well logging backpropagation drilling geotechnical neural nets regression analysis;instruction sets	Effective prediction of ROP (Rate of Penetration) is a crucial part of successful well drilling process. Due to the penetration complexities and the formation heterogeneity, traditional way such as ROP equations and regression analysis are confined by their limitations in the drilling practices. With the accumulation of the geology data and drilling logs, data-based modelling methods like ANN become powerful tools in modern drilling engineering. This paper proposed a ROP prediction approach based on improved BP neural network technologies. The main idea is to build prediction model of target well from well logs through the improved BP neural network modelling method. During the training process, the traditional BP training algorithm is improved by introducing momentum factor and the dynamical learning rate, which are able to notably increase the speed of converging and obtain better generalization performance. We collect and analyze the well log of the No.104 well in Yuanba, China. The experiment results show that the proposed approach is able to effectively utilize the engineering data, and provide accurate ROP prediction in the areas which have certain amount of data collection.	algorithm;artificial neural network;modem;network performance;penetration test;tree accumulation;whole earth 'lectronic link	Jinan Duan;Jinhai Zhao;Li Xiao;Chuanshu Yang;Huinian Chen	2014	2014 IEEE 3rd International Conference on Cloud Computing and Intelligence Systems	10.1109/CCIS.2014.7175818	simulation;computer science;artificial intelligence;operating system;machine learning;instruction set;artificial neural network;welding	ML	10.152590427554673	-21.244576566448572	128462
a74c7fccae2400d974421db57ad5a9804aaed041	smp and cluster architectures for retrieval of images in digital libraries	digital library;image retrieval;template matching;feature extraction	This paper presents an overview over parallel architectures for the efficient realisation of digital libraries by considering image databases as an example. The state of the art approach for image retrieval uses a priori extracted features and limits the applicability of the retrieval techniques, as a detail search for objects and for other important elements can't be performed. Well-suited algorithms for dynamic feature extraction and comparison are not often applied, as they require huge computational and memory resources. Integration of parallel methods and architectures enables the use of these alternative approaches for improved classification and retrieval of documents in digital libraries. Therefore implemented prototypes on a symmetric multiprocessor (SMP) and on cluster architecture are introduced in the paper. Performance measurements with a wavelet-based template matching method resulted into a reasonable speedup.	algorithm;computation;computer cluster;database;digital library;feature extraction;image processing;image retrieval;library (computing);personal computer;scheduling (computing);speedup;symmetric multiprocessing;template matching;wavelet	Odej Kao	2000			visual word;automatic image annotation;digital image processing;feature extraction;computer vision;theoretical computer science;architecture;speedup;template matching;image retrieval;artificial intelligence;computer science	Vision	16.782393859647193	-15.809585758369654	128827
23a8215d1f1eb73dba880cb76019ede9724fa514	self-taught decision theoretic planning with first order decision diagrams	decision diagram;first order;machine learning;planning under uncertainty;decision theoretic planning;markov decision processes	We present a new paradigm for planning by learning, where the planner is given a model of the world and a small set of states of interest, but no indication of optimal actions in these states. The additional information can help focus the planner on regions of the state space that are of interest and lead to improved performance. We demonstrate this idea by introducing novel model-checking reduction operations for First Order Decision Diagrams (FODD), a representation that has been used to implement decision-theoretic planning with Relational Markov Decision Processes (RMDP). Intuitively, these reductions modify the construction of the value function by removing any complex specifications that are irrelevant to the set of training examples, thereby focusing on the region of interest. We show that such training examples can be constructed on the fly from a description of the planning problem thus we can bootstrap to get a self-taught planning system. Additionally, we provide a new heuristic to embed universal and conjunctive goals within the framework of RMDP planners, expanding the scope and applicability of such systems. We show that these ideas lead to significant improvements in performance in terms of both speed and coverage of the planner, yielding state of the art planning performance on problems from the International Planning Competition.	bellman equation;diagram;heuristic;markov chain;markov decision process;model checking;on the fly;programming paradigm;region of interest;relevance;state space;theory	Saket Joshi;Kristian Kersting;Roni Khardon	2010			markov decision process;mathematical optimization;optimal decision;influence diagram;partially observable markov decision process;computer science;knowledge management;artificial intelligence;machine learning;first-order logic;management science	AI	21.35957880659082	-15.715947646069042	129141
30bb1a3a1579aac8990d8dabd5135a766c176137	the predictions of optoelectronic attributes of led by neural network	epitaxial growth;neural model;and forward;issn 0957 4174;light emitting diode;chip;optoelectronic attributes;expert systems with applications;process engineering;prediction;neural network	In this paper, the predictions of optoelectronic attributes of Light-Emitting Diode (LED) chip, including luminous intensity, wavelength and forward voltage by using neural network were presented. The simulated data was measured by Electrical Luminescence (EL) technique. The well-trained neural models were used to predict the optoelectronic attributes of LED chip in its epitaxy growth stage in advance. These predicted results could provide the necessary information for the process engineer to adjust the control parameters of epitaxy growth accurately and then ensure the LED chip to be in conformance with the requested quality.	artificial neural network	Pin-Hsuan Weng;Yu-Ju Chen;Shuming T. Wang;Rey-Chue Hwang	2010	Expert Syst. Appl.	10.1016/j.eswa.2010.02.094	chip;epitaxy;prediction;computer science;machine learning;artificial neural network;statistics;light-emitting diode	ML	13.636228924833016	-18.975191430708946	129289
127f464c2dc8d85b7612a6924495f79e5458710f	move evaluation in go using deep convolutional neural networks		The game of Go is more challenging than other board games, due to the difficulty of constructing a position or move evaluation function. In this paper we investigate whether deep convolutional networks can be used to directly represent and learn this knowledge. We train a large 12-layer convolutional neural network by supervised learning from a database of human professional games. The network correctly predicts the expert move in 55% of positions, equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional-search program GnuGo in 97% of games, and matched the performance of a state-of-the-art Monte-Carlo tree search that simulates two million positions per move.	artificial neural network;convolutional neural network;evaluation function;gnu go;monte carlo tree search;supervised learning	Chris J. Maddison;Aja Huang;Ilya Sutskever;David Silver	2015	CoRR		simulation;computer science;artificial intelligence;machine learning	AI	19.110019222873767	-19.32201446709832	129427
0d3edba9b76451876926eea95eab509ff15278d7	design of neural networks	pre processing;neural networks;benchmark problem;parameter tuning;problem oriented design;training algorithm;neural network	The paper offers a critical analysis of the procedure observed in many applications of neural networks. Given a problem to be solved, a favorite NN-architecture is chosen and its parameters tuned with some standard training algorithm, but without taking in consideration relevant features of the problem or possibly its interdisciplinary nature. Three relevant benchmark problems are discussed to illustrate the thesis that “brute force solving is not the same as	algorithm;benchmark (computing);brute-force search;neural networks	Claudio Moraga	2007		10.1007/978-3-540-74819-9_4	computer science;artificial intelligence;machine learning;data mining;time delay neural network	ML	15.055056162802169	-22.924114275200555	130083
2ea8e7f9f6511776b6257ff8b703622a36817b0f	research on wind speed vertical extrapolation based on extreme learning machine		In engineering, the method of wind speed vertical extrapolation is based on the actual wind data of the wind tower, and the wind shear index is used to calculate the wind speed at any height in the near ground. The wind shear index is only considered in the neutral state of the atmosphere, without considering the impact of atmospheric stability on the wind shear index, which has some limitations. At the same time, the calculation of the wind shear index is a rather complicated task when considering the atmospheric stability. In order to solve these problems, this paper puts forward to use extreme learning machine for fitting the relationship between wind speed at different heights. Extreme learning machine has the advantages of fast learning speed, good generalization ability and so on. In this paper, the results obtained by the extreme learning machine and traditional methods are compared with the measured values. The results show that the extreme learning machine has a better application prospect in the vertical wind speed extrapolation.	extrapolation	Hui Lv;Guochu Chen	2017		10.1007/978-981-10-6364-0_1	atmospheric sciences;atmospheric instability;extrapolation;wind speed;extreme learning machine;atmosphere;wind shear;meteorology;engineering	ML	10.841315189982383	-19.63340169763019	130138
10e7a96ff8f06f94f7708118932f40dab0da0bf1	application of reinforcement learning with continuous state space to ramp metering in real-world conditions	detectors;state space methods;convergence;travel time;learning;road traffic;state space methods automated highways convergence learning artificial intelligence pattern classification regression analysis road traffic;automated highways;traffic control;toronto canada;system performance;ramp metering;transportation;pattern classification;algorithms;regression analysis;learning artificial intelligence;network travel time reinforcement learning continuous state space real world conditions freeway ramp metering real life experiments rl methods discrete state representation slow convergence continuous representation learning speed large scale complex problems local regression k nearest neighbors temporal difference alinea controller microsimulation testbed paramics knn td method;algorithm design and analysis;traffic control convergence algorithm design and analysis detectors learning transportation system performance	In this paper we introduce a new approach to Freeway Ramp Metering (RM) based on Reinforcement Learning (RL) with focus on real-life experiments in a case study in the City of Toronto. Typical RL methods consider discrete state representation that lead to slow convergence in complex problems. Continuous representation of state space has the potential to significantly improve the learning speed and therefore enables tackling large-scale complex problems. A robust approach based on local regression, named k nearest neighbors temporal difference (kNN-TD), is employed to represent state space continuously in the RL environment. The performance of the new algorithm is compared against the ALINEA controller and typical RL methods using a micro-simulation testbed in Paramics. The results show that RM using the kNN-TD method can reduce total network travel time by 44% compared to the do-nothing case (without RM) and by 17% compared to ALINEA.	closed-loop transfer function;control system;control theory;experiment;freeway;k-nearest neighbors algorithm;ramp simulation software for modelling reliability, availability and maintainability;real life;reinforcement learning;sensor;software deployment;software metering;state space;temporal difference learning;testbed	Kasra Rezaee;Baher Abdulhai;Hossam Abdelgawad	2012	2012 15th International IEEE Conference on Intelligent Transportation Systems	10.1109/ITSC.2012.6338837	simulation;engineering;artificial intelligence;machine learning	Robotics	15.522550723683812	-16.90086222699183	130157
c71aad2ea881bf2bf4050a364b535b093fcc0f16	inexpensive cost-optimized measurement proposal for sequential model-based diagnosis		In this work we present strategies for (optimal) measurement selection in model-based sequential diagnosis. In particular, assuming a set of leading diagnoses being given, we show how queries (sets of measurements) can be computed and optimized along two dimensions: expected number of queries and cost per query. By means of a suitable decoupling of two optimizations and a clever search space reduction the computations are done without any inference engine calls. For the full search space, we give a method requiring only a polynomial number of inferences and guaranteeing query properties existing methods cannot provide. Evaluation results using real-world problems indicate that the new method computes (virtually) optimal queries instantly independently of the size and complexity of the considered diagnosis problems.	approximation;computation;coupling (computer programming);inference engine;maxima and minima;polynomial;precomputation;selection algorithm;time complexity	Patrick Rodler;Wolfgang Schmid;Konstantin Schekotihin	2017			decoupling (cosmology);artificial intelligence;computer science;machine learning;computation;expected value;sequential model;inference engine;polynomial	DB	24.457098310384758	-15.384655119208315	130702
a518704c64fc94d11725f1ca5f562b61ebbe94ec	data-driven modeling for fixed-bed intermittent gasification processes by enhanced lazy learning incorporated with relevance vector machine	support vector machines temperature measurement cost function vectors mathematical model training mimo;support vector machines belief networks coal gasification learning artificial intelligence production engineering computing;relevance vector machine data driven modeling ugi gasifier enhanced lazy learning;bayesian learning framework data driven modeling fixed bed intermittent gasification processes enhanced lazy learning with relevance vector machine ell rvm ugi gasifiers online measured temperature produced crude gas gasifier temperature ugi gasification process infrequent gasifier manipulation weighted neighbour selection method online modeling algorithm	An enhanced lazy learning approach incorporated with relevance vector machine (ELL-RVM) is proposed for modeling of the fixed-bed intermittent gasification processes inside UGI gasifiers. The online measured temperature of produced crude gas plays a dominant role during gasification processes. However, it is difficult to formulate the dynamics of gasifier's temperature via first principles due to the complexity of UGI gasification process, especially severe changes in the temperature versus infrequent manipulation of the gasifier and noise in the temperature data collected from practical fields. Noticing that the changes of some input variables of UGI gasification process are small but impactful, a novel weighted-neighbour selection method, which is based on minimizing dynamic cost functions for different outputs coordinately, is adopted to enhance the lazy learning approach. The sparseness and short test time of RVM is fully utilized in design and implementation of the proposed online modeling algorithm under the Bayesian learning framework. The effectiveness of ELL-RVM for modeling UGI gasification processes is verified by a series of experiments based on the data collected from practical fields.	algorithm;dynamical system;existential quantification;experiment;lazy evaluation;lazy learning;loss function;mimo;neural coding;nonlinear system;relevance vector machine;selection (genetic algorithm)	Shida Liu;Zhongsheng Hou;Chenkun Yin	2014	11th IEEE International Conference on Control & Automation (ICCA)	10.1109/ICCA.2014.6871060	simulation;engineering;artificial intelligence;machine learning	Robotics	12.783251083873587	-18.599051479365166	130889
0c17c91d248b40c5fcc629722727e71a8195b6e6	deep sequential models for sampling-based planning		We demonstrate how a sequence model and a sampling-based planner can influence each other to produce efficient plans and how such a model can automatically learn to take advantage of observations of the environment. Sampling-based planners such as RRT generally know nothing of their environments even if they have traversed similar spaces many times. A sequence model, such as an HMM or LSTM, guides the search for good paths. The resulting model, called DeRRT*, observes the state of the planner and the local environment to bias the next move and next planner state. The neural-network-based models avoid manual feature engineering by co-training a convolutional network which processes map features and observations from sensors. We incorporate this sequence model in a manner that combines its likelihood with the existing bias for searching large unexplored Voronoi regions. This leads to more efficient trajectories with fewer rejected samples even in difficult domains such as when escaping bug traps. This model can also be used for dimensionality reduction in multi-agent environments with dynamic obstacles. Instead of planning in a high-dimensional space that includes the configurations of the other agents, we plan in a low-dimensional subspace relying on the sequence model to bias samples using the observed behavior of the other agents. The techniques presented here are general, include both graphical models and deep learning approaches, and can be adapted to a range of planners.		Yen-Ling Kuo;Andrei Barbu;Boris Katz	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8593947	voronoi diagram;computer vision;computer science;dimensionality reduction;sampling (statistics);deep learning;subspace topology;machine learning;feature engineering;hidden markov model;artificial intelligence;graphical model	Robotics	20.727466869859988	-20.623331896928246	130968
30e9c0c64eb858acd8b453c2d47b6fc1dfa695eb	an evolutionary algorithm for error-driven learning via reinforcement		Although different learning systems are coordinated to afford complex behavior, little is known about how this occurs. This article describes a theoretical framework that specifies how complex behaviors that might be thought to require error-driven learning might instead be acquired through simple reinforcement. This framework includes specific assumptions about the mechanisms that contribute to the evolution of (artificial) neural networks to generate topologies that allow the networks to learn large-scale complex problems using only information about the quality of their performance. The practical and theoretical implications of the framework are discussed, as are possible biological analogs of the approach.	error-driven learning;evolutionary algorithm	Yanping Liu;Erik D. Reichle	2015	CoRR		error-driven learning;artificial intelligence;machine learning	ML	17.243420273755568	-22.3484926912842	131077
be4dafe57ad915dcd8e1034f8141f08faa7f3ab1	multi-vehicle flocking control with deep deterministic policy gradient method		Flocking control has been studied extensively along with the wide application of multi-vehicle systems. In this paper the Multi-vehicles System (MVS) flocking control with collision avoidance and communication preserving is considered based on the deep reinforcement learning framework. Specifically the deep deterministic policy gradient (DDPG) with centralized training and distributed execution process is implemented to obtain the flocking control policy. First, to avoid the dynamically changed observation of state, a three layers tensor based representation of the observation is used so that the state remains constant although the observation dimension is changing. A reward function is designed to guide the way-points tracking, collision avoidance and communication preserving. The reward function is augmented by introducing the local reward function of neighbors. Finally, a centralized training process which trains the shared policy based on common training set among all agents. The proposed method is tested under simulated scenarios with different setup.	centralized computing;experiment;flocking (behavior);gradient method;multi-agent system;reinforcement learning;test set	Zhao Xu;Yang Lyu;Quan Pan;Jinwen Hu;Chunhui Zhao;Shuai Liu	2018	2018 IEEE 14th International Conference on Control and Automation (ICCA)	10.1109/ICCA.2018.8444355	control engineering;flocking (texture);tensor;collision;engineering;gradient method;machine learning;reinforcement learning;training set;artificial intelligence	Robotics	19.94861650154174	-18.786279371678507	131306
b64a11ac25cb7c6b55bc600b3cd144e4dfa8c1ef	evolutionary multivariate adaptive regression splines for estimating shear strength in reinforced-concrete deep beams	reinforce concrete;artificial bee colony;shear strength;deep beams;artificial intelligence;multivariate adaptive regression splines	This study proposes a novel artificial intelligence (AI) model to estimate the shear strength of reinforcedconcrete (RC) deep beams. The proposed evolutionary multivariate adaptive regression splines (EMARS) model is a hybrid of multivariate adaptive regression splines (MARS) and artificial bee colony (ABC). In EMARS, MARS addresses learning and curve fitting and ABC implements optimization to determine the optimal parameter settings with minimal estimation errors. The proposed model was constructed using 106 experimental datasets from the literature. EMARS performance was compared with three other data-mining techniques, including back-propagation neural network (BPNN), radial basis function neural network (RBFNN), and support vector machine (SVM). EMARS estimation accuracy was benchmarked against four prevalent mathematical methods, including ACI-318 (2011), CSA, CEB-FIP MC90, and Tang’s Method. Benchmark results identified EMARS as the best model and, thus, an efficient alternative approach to estimating RC deep beam shear strength. & 2013 Elsevier Ltd. All rights reserved.	artificial bee colony algorithm;artificial intelligence;artificial neural network;backpropagation;benchmark (computing);curve fitting;data mining;experiment;factory instrumentation protocol;global optimization;imax;iteration;map;mathematical optimization;multivariate adaptive regression splines;radial (radio);radial basis function;ssi ceb;smoothing spline;software propagation;support vector machine	Min-Yuan Cheng;Minh-Tu Cao	2014	Eng. Appl. of AI	10.1016/j.engappai.2013.11.001	multivariate adaptive regression splines;computer science;artificial intelligence;machine learning;shear strength	AI	12.539656706991726	-21.086656385723952	132139
503fa3d18ad3ca1ab4ffe9222a1e302d27adccfb	emergent organisation in colonies of simple automata	distributed system;multiagent system;systeme reparti;qa 76 software;automaton;computer programming;automata;qa75 electronic computers computer science;sistema repartido;automate;autoorganizacion;algorithme evolutionniste;self organization;algoritmo evolucionista;evolutionary algorithm;sistema multiagente;autoorganisation;systeme multiagent	We have simulated a colony of approx 3000 simple automata, with interaction behaviours that attempt to emulate those observed in stromatolite building microbes. The colony is able to maintain a diverse genome that can metabolise large quantities of up to 100 different nutrient molecules simultaneously. Group organisations that process short lived molecules more rapidly than others readily emerge under the correct conditions. We have applied the lessons to the control and management of a distributed communications system.	algorithm;automata theory;automaton;distributed computing;emergence;emergent;emergentism;load balancing (computing);quality of service;self-organization;simulation	Ian W. Marshall;Chris M. Roadknight	2001		10.1007/3-540-44811-X_37	simulation;computer science;artificial intelligence;evolutionary algorithm;distributed computing;automaton;algorithm	Networks	22.80754125262628	-11.873213275620046	132482
9b1d98c77583beb33f4e80f08ca7b7e8d5b63a5e	railway traffic conflict detection via a state transition prediction approach	rail transportation delays real time systems tracking safety mathematical model analytical models;analytical models;rail transportation;safety;mathematical model;dynamic environment conflict detection railway traffic management state transition map traffic prediction;tracking;delays;real time systems	Conflict detection and resolution is one of the most important tasks in daily railway traffic management, although it is still difficult to solve all its aspects. In fact, the aspect of conflict detection has not been amply studied. In this paper, an approach of traffic state prediction and conflict detection, based on proper state transition maps (STMaps) and corresponding relation matrices, is proposed. First, the traffic state sequences, which mainly concern infrastructure status and train movement information, are studied. These state sequences are expressed as segment and route state vectors and kept in corresponding state-domain tables (SDTables). The empirical state transitions are then applied to detect irregular states in a dynamic traffic environment. Furthermore, the structural constraints of infrastructure topology and route compatibilities are represented in matrices to aid the calculation and prediction of potential conflicting situations. Scenarios such as train delay and infrastructure failure are designed to test the proposed approach. The test results show that irregular states can be efficiently detected and potential conflicts can be further identified, and the detailed conflict information is also approachable.	file synchronization;map;state transition table	Taomei Zhu;Jose Manuel Mera	2017	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2016.2603441	simulation;computer science;engineering;traffic conflict;mathematical model;mathematics;transport engineering;tracking;computer security;statistics	SE	10.821463986158784	-11.402126173183532	132651
fcf0fef7cedc2525dbfdab32e25ed93f5d45d140	analysis of hebbian models with lateral weight connections	continuous time;discrete time;signal processing;principal component analysis;comparative study;correlation matrix;artificial neural network;eigenvectors;neural network;dynamic behavior	In this paper, the behavior of some hebbian artificial neural networks with lateral weights is analyzed. Hebbian neural networks are employed in communications and signal processing applications for implementing on-line Principal Component Analysis (PCA). Different improvements over the original Oja model have been developed in the last two decades. Among them, models with lateral weights have been designed to directly provide the eigenvectors of the correlation matrix [1,5,6,9]. The behavior of hebbian models has been traditionally studied by resorting to an associated continuous-time formulation under some questionable assumptions which are not guaranteed in real implementations. In this paper we employ the alternative deterministic discrete-time (DDT) formulation that characterizes the average evolution of these nets and gathers the influence of the learning gains time evolution [12]. The dynamic behavior of some of these hebbian models is analytically characterized in this context and several simulations complement this comparative study.		Pedro J. Zufiria;José Andrés Berzal	2007		10.1007/978-3-540-73007-1_6	econometrics;covariance matrix;discrete time and continuous time;eigenvalues and eigenvectors;computer science;artificial intelligence;machine learning;comparative research;leabra;generalized hebbian algorithm;artificial neural network;principal component analysis	Vision	15.481412168600198	-21.527782432220892	132671
8b58d59d961f8827f9f69faee8f08888f72ca440	multidisciplinary design optimization under uncertainties based on bliss and pma	optimisation;reliability;performance evaluation;pma sensitivity analysis system analysis slmra single loop multidisciplinary reliability analysis method sequential optimization and reliability evaluation framework performance measurement approach bi level integrated system synthesis bliss sora triple layered nested optimization loops rbmdo reliability based multidisciplinary design optimization;design engineering;reliability engineering vectors design optimization gears probabilistic logic;sensitivity analysis design engineering optimisation performance evaluation reliability;multidisciplianry reliability analysis multidisciplianry design optimization bi level integrated system synthesis performance measure approach sequential optimization and reliability assessment;sensitivity analysis	Reliability-based multidisciplinary design optimization (RBMDO) is a powerful tool to implement MDO considering uncertainties. However, integrating the reliability-based design with MDO directly will cause the triple-layered nested optimization loops. Therefore, an efficient method (BLISS-SORA) for RBMDO integrates bi-level integrated system synthesis (BLISS) and the performance measurement approach (PMA) is proposed under the sequential optimization and reliability evaluation framework (SORA). The multidisciplinary reliability analysis is decoupled from the multidisciplinary design optimization. A single-loop multidisciplinary reliability analysis method (SLMRA) is proposed based on the BLISS and PMA. The system analysis, sensitivity analysis and reliability analysis are decoupled and executed in a single loop so that the repeated iterations of the overall reliability analysis can be avoided. The procedures of the proposed method are addressed in detail. Finally, one design example is demonstrated to verify the efficiency and accuracy of the proposed method.	bliss;black and burst;iteration;mathematical optimization;multidisciplinary design optimization;reliability engineering;system analysis;phpmyadmin	Jun Zhang;Bing Zhang	2013	Proceedings of the 2013 IEEE 17th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2013.6580948	probabilistic-based design optimization;multidisciplinary design optimization;reliability;sensitivity analysis	EDA	13.217359416055237	-11.77369435647815	132938
87098fab733ec04b10155c5734a985729f8cdaf4	online learning with erdos-renyi side-observation graphs		We consider adversarial multi-armed bandit problems where the learner is allowed to observe losses of a number of arms beside the arm that it actually chose. We study the case where all non-chosen arms reveal their loss with an unknown probability rt, independently of each other and the action of the learner. Moreover, we allow rt to change in every round t, which rules out the possibility of estimating rt by a well-concentrated sample average. We propose an algorithm which operates under the assumption that rt is large enough to warrant at least one side observation with high probability. We show that after T rounds in a bandit problem with N arms, the expected regret of our algorithm is of order O (√∑T t=1(1/rt) logN ) , given that rt ≥ log T/(2N − 2) for all t. All our bounds are within logarithmic factors of the best achievable performance of any algorithm that is even allowed to know exact values of rt.	algorithm;coat of arms;multi-armed bandit;regret (decision theory);with high probability	Tomás Kocák;Gergely Neu;Michal Valko	2016				ML	23.202448692853324	-17.38675995590778	133219
44170922ffdb84f7a44e9ea4912b7b02f7af460a	autoregressive dynamic mechanism for urban area microscopic traffic flow models		To study traffic congestion, city routing, intersection control, emergency cases, or other types of scenarios it is necessary to have an accurate traffic flow model. Traffic models are comprised of different mechanisms that give it its realism. In this work two basic mechanisms are studied: the dynamic movement of the vehicle and a cautious car-following behavior. The dynamic movement of the vehicle is dependent on an autoregressive acceleration algorithm, which gives the vehicle an innate fluid motion. The model also considers a cautious car-following mechanism, where the vehicle decelerates if a safe distance threshold is crossed and the lagging vehicle is traveling faster. Additionally, using the described model, we performed a study to observe the impact of the standard deviation of the velocity on the overall average velocity. This deviation is caused by human reaction times, tiredness, distractions, etc. Therefore, these results reflect the human-driving efficiency.	algorithm;autoregressive model;network congestion;quantifier (logic);routing;velocity (software development)	Felipe Tejada;Claudio Estevez;Aleksejs Zacepins;Vitalijs Komasilovs	2016	2016 IEEE International Smart Cities Conference (ISC2)	10.1109/ISC2.2016.7580858	simulation;engineering;transport engineering;forensic engineering	Robotics	10.06464317128641	-10.224239560752192	133501
ba6ee25c760873387fb6c583c96fdeb9400a2b60	towards possibilistic reinforcement learning algorithms	dynamic programming;learning algorithm;learning;uncertainty;reinforcement learning;large hadron collider;sequential decision problems;possibilistic reinforcement learning algorithms;dynamic program;uncertainty handling;decision problem;computational modeling;dynamic programming possibilistic reinforcement learning algorithms sequential decision problems uncertainty markov decision processes indirect methods;indirect methods;stochastic processes;decision theory;possibility theory;learning stochastic processes uncertainty large hadron collider decision making utility theory possibility theory computational modeling;markov processes;markov decision process;learning artificial intelligence;markov decision processes;possibility theory learning artificial intelligence markov processes decision theory dynamic programming uncertainty handling;utility theory	Monday (3/12/2001) 8:00 Registration Venue: Copland Theatre Foyer, Economics and Commerce 8:30 Opening Venue: Economics and Commerce, Copland Theatre 9:00 Plenary 1, Lotfi Zadeh Venue: Economics and Commerce, Copland Theatre 10:00 Tea/Coffee, Copland Theatre Foyer 10:30 T1a: Pattern recognition and image processing Venue: Old Arts, Theatre A Chairs: J Keller, X Zhao T2a: Electronic and robotic systems Venue: Zoology, Agar Theatre Chairs: L Reznik, C-L Chen T3a: Soft computing and hybrid systems Venue: Old Arts, Theatre C Chairs: N Kasabov, P Mastorocostas T4a: Control systems Venue: Old Arts, Theatre D Chairs: J Kacprzyk, J Q Yi T5a: Mathematics Venue: Old Arts, Theatre E Chiars: A Ramer, J Li PS1: Poster Session 1, papers in T1 and T3 Venue: North Dining Room, Union House	copland (operating system);entity–relationship model;hybrid system;image processing;pattern recognition;reinforcement learning;robot;soft computing;venue (sound system)	Régis Sabbadin	2001		10.1109/FUZZ.2001.1007334	markov decision process;mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;reinforcement learning;statistics	Robotics	23.09678748569587	-15.449526985328339	133554
7ad8742a5cc69b0caa37fd226ce3c07e7f42deb8	application of teaching learning based optimization procedure for the development of svm learned edm process and its pseudo pareto optimization	support vector machine svm;teaching learning based optimization tlbo;electrical discharge machining edm	Two-stage soft computing ((SVM-TLBO)-(PLM-TLBO-pseudo PARETO)) based virtual system of manufacturing process - EDM is developed.Virtual data generator of EDM process learned by support vector machine (SVM) with internal parameters (C, ? and ?) tuned by teaching learning based optimization (TLBO) is reported.Modifications namely population based termination criteria, initialize population with high dispersion and way of choosing teacher in case of multiple best learners performing same score, over standard TLBO are suggested. Further, a comparison between performances of TLBO and PSO in model development is studied.A simple procedure for pseudo Pareto front development by modified TLBO is proposed.Inverse solution procedure for selection of optimum available machine parameter setting corresponding to specific output combination is elaborated. Manufacturing processes could be well characterized by both the quantitative and the qualitative measurements of their performances. In case of conflicting type performance measures, it is necessary to get possible optimum values of all performances simultaneously, like higher material removal rate (MRR) with lower average surface roughness (ASR) in electric discharge machining (EDM) process. EDM itself is a stochastic process and predictions of responses - MRR and ASR are still difficult. Advanced structural risk minimization based learning system - support vector machine (SVM) is, therefore, applied to capture the random variations in EDM responses in a robust way. Internal parameters of SVM - C, ? and ? are tuned by modified teaching learning based optimization (TLBO) procedure. Subsequently, using the developed SVM model as a virtual data generator of EDM process, responses are generated at the different points in the experimental space and power law models are fitted to the estimated data. Varying the weight factors, different weighted combinations of the inverse of MRR and the ASR are minimized by modified TLBO. Pseudo Pareto front passing through the optimum results, thus obtained, gives a guideline for selection of optimum achievable value of ASR for a specific demand of MRR. Further, inverse solution procedure is elaborated to find the near-optimum setting of process parameters in EDM machine to obtain the specific need based MRR-ASR combination.	mathematical optimization;optimization problem;pareto efficiency	Ushasta Aich;Simul Banerjee	2016	Appl. Soft Comput.	10.1016/j.asoc.2015.11.002	artificial intelligence;machine learning	AI	14.790589344981699	-12.187897708220484	133569
00c95c5192bfa72d55471efccbb27a4a9347fc93	bayesian action-graph games		Games of incomplete information, or Bayesian games, are an important gametheoretic model and have many applications in economics. We propose Bayesian action-graph games (BAGGs), a novel graphical representation for Bayesian games. BAGGs can represent arbitrary Bayesian games, and furthermore can compactly express Bayesian games exhibiting commonly encountered types of structure including symmetry, actionand type-specific utility independence, and probabilistic independence of type distributions. We provide an algorithm for computing expected utility in BAGGs, and discuss conditions under which the algorithm runs in polynomial time. Bayes-Nash equilibria of BAGGs can be computed by adapting existing algorithms for complete-information normal form games and leveraging our expected utility algorithm. We show both theoretically and empirically that our approaches improve significantly on the state of the art.	algorithm;expected utility hypothesis;naive bayes classifier;nash equilibrium;time complexity	Albert Xin Jiang;Kevin Leyton-Brown	2010			econometrics;simulation;machine learning;mathematics;statistics	ML	23.789084025737388	-19.605278009366398	133976
6cc0472053f0ec7dc2fa16af7b0b22d6457be014	model-based exploration in continuous state spaces	reinforcement learning;benchmark problem;domain knowledge;discrete model;state space	Modern reinforcement learning algorithms effectively exploit experience data sampled from an unknown controlled dynamical system to compute a good control policy, but to obtain the necessary data they typically rely on naive exploration mechansisms or human domain knowledge. Approaches that first learn a model offer improved exploration in finite problems, but discrete model representations do not extend directly to continuous problems. This paper develops a method for approximating continuous models by fitting data to a finite sample of states, leading to finite representations compatible with existing model-based exploration mechanisms. Experiments with the resulting family of fitted-model reinforcement learning algorithms reveals the critical importance of how the continuous model is generalized from finite data. This paper demonstrates instantiations of fitted-model algorithms that lead to faster learning on benchmark problems than contemporary model-free RL algorithms that only apply generalization in estimating action values. Finally, the paper concludes that in continuous problems, the exploration-exploitation tradeoff is better construed as a balance between exploration and generalization.	algorithm;bellman equation;benchmark (computing);continuous integration;dynamical system;machine learning;optimization problem;reinforcement learning;spaces	Nicholas K. Jong;Peter Stone	2007		10.1007/978-3-540-73580-9_21	mathematical optimization;computer science;state space;artificial intelligence;machine learning;mathematics;reinforcement learning;domain knowledge;algorithm	ML	22.323736998467638	-19.51152535016462	134012
efd2bb9e4a493e28e9098dbf82cdb0ea1d6dfab4	predictive performance of clustered feature-weighting case-based reasoning	case base reasoning;back propagation neural network;machine learning;process parameters;feature weighting;hybrid system;self organized map;neural network;semiconductor manufacturing	Because many factors are complexly involved in the production of semiconductors, semiconductor manufacturers can hardly manage yield precisely. We present a hybrid machine learning system, i.e., a clustered feature-weighting case-based reasoning, to detect high-yield or low-yield lots in semiconductor manufacturing. The system uses self-organizing map neural networks to identify similar patterns in the process parameters. The trained back-propagation neural networks determine feature weights of case-based reasoning. Based on the clustered feature-weighting case-based reasoning, the hybrid system predicts the yield level of a new manufacturing lot. To validate the effectiveness of our approach, we apply the hybrid system to real data of a semiconductor company.	case-based reasoning	Sung Ho Ha;Jong Sik Jin;Jeong Won Yang	2008		10.1007/978-3-540-88192-6_45	computer science;artificial intelligence;machine learning;data mining;semiconductor device fabrication;artificial neural network;hybrid system	AI	13.314245619373187	-18.990866424383732	134178
b7e9b3870d9a1679010984eb53021ddcaa172424	sensorless estimation of wind speed by soft computing methodologies: a comparative study		This paper shows a few novel calculations for wind speed estimation, which is focused around soft computing. The inputs of to the estimators are picked as the wind turbine power coefficient, rotational rate and blade pitch angle. Polynomial and radial basis function (RBF) are applied as the kernel function of Support Vector Regression (SVR) technique to estimate the wind speed in this study. Instead of minimizing the observed training error, SVR_poly and SVR_rbf attempt to minimize the generalization error bound so as to achieve generalized performance. The results are compared with the adaptive neuro-fuzzy (ANFIS) results.	adaptive neuro fuzzy inference system;algorithm;coefficient;generalization error;mean squared error;neuro-fuzzy;pitch (music);polynomial;r.o.t.o.r.;radial (radio);radial basis function;soft computing;standard business reporting;support vector machine;system identification	Dalibor Petkovic;Muhammad Arif;Shahaboddin Shamshirband;Ehab Hussein Bani-Hani;Davood Kiakojoori	2015	Informatica, Lith. Acad. Sci.		simulation;control theory	ML	10.96870528444677	-20.384063243475246	134179
b741a591819f17014ae61c9727cf52f606ca3f0f	introducing convex layers to the traveling salesman problem		In this paper, we will propose convex layers to the Traveling Salesman Problem (TSP). Firstly, we will focus on human performance on the TSP. Experimental data shows that untrained humans appear to have the ability to perform well in the TSP. On the other hand, experimental data also supports the hypothesis of convex hull i.e. human relies on convex hull to search for the optimal tour for the TSP. Secondly, from the paper published by Bonabeau, Dorigo and Theraulaz, social insect behavior would be able to help in some of the optimizing problems, especially the TSP. Thus, we propose convex layers to the TSP based on the argument that, by the analogy to the social insect behavior, untrained humans’ cognition should be able to help in the TSP. Lastly, we will use Tour Improvement algorithms on convex layers to search for an optimal tour for a 13-cities problem to demonstrate the idea.	algorithm;cognition;convex hull;eusociality;human reliability;travelling salesman problem	Sing Liew	2012	CoRR		mathematical optimization;simulation;artificial intelligence;mathematics	ML	21.247774001715154	-10.549581694237757	134234
f4ffc5492d18a2e782669a5ffd2bd5b6624b02a1	complementary computing: policies for transferring callers from dialog systems to human receptionists	human machine systems;complementary computing;spoken dialog system;spoken dialog systems;probabilistic model;machine learning;probabilistic user modeling;generalized expectation;problem solving;user model	We describe a study of the use of decision-theoretic policies for optimally joining human and automated problem-solving efforts. We focus specifically on the challenge of determining when it is best to transfer callers from an automated dialog system to human receptionists. We demonstrate the sensitivities of transfer actions to both the inferred competency of the spoken-dialog models and the current sensed load on human receptionists. The policies draw upon probabilistic models constructed via machine learning from cases that were logged by a call routing service deployed at our organization. We describe the learning of models that predict outcomes and interaction times and show how these models can be used to generate expected-utility policies that identify when it is best to transfer callers to human operators. We explore the behavior of the policies with simulations constructed from real-world call data.	dialog system;expected utility hypothesis;machine learning;problem solving;routing;simulation;theory	Eric Horvitz;Tim Paek	2006	User Modeling and User-Adapted Interaction	10.1007/s11257-006-9026-1	statistical model;user modeling;computer science;artificial intelligence;machine learning;data mining;dialog system;world wide web	AI	20.442643265581992	-16.637959650555953	134741
e43573be7f96fbf3c667cbe20ab2db283813e4a8	on adversarial policy switching with experiments in real-time strategy games		Given a Markov game, it is often possible to hand-code or learn a set of policies that capture a diversity of possible strategies. It is also often possible to hand-code or learn an abstract simulator of the game that can estimate the outcome of playing two strategies against one another from any state.simulator of the game that can estimate the outcome of playing two strategies against one another from any state. We consider how to use such policy sets and simulators to make decisions in large Markov games such as real-time strategy (RTS) games. Prior work has considered the problem using an approach we call minimax policy switching. At each decision epoch, all policy pairs are simulated against each other from the current state, and the minimax policy is chosen and used to select actions until the next decision epoch. While intuitively appealing, our first contribution is to show that this switching policy can have arbitrarily poor worst case performance. Our second contribution is to describe a simple modification, whose worst case performance is provably no worse than the minimax fixed policy in the set. Our final contribution is to conduct experiments with these algorithms in the domain of RTS games using both an abstract game engine that we can exactly simulate and a real game engine that we can only approximately simulate. The results show the effectiveness of policy switching when the simulator is accurate, and highlight challenges in the face of inaccurate simulations.	algorithm;best, worst and average case;existential quantification;experiment;game engine;local optimum;markov chain;mathematical optimization;minimax;optimality criterion;policy-based design;real-time transcription;simulation;monotone	Brian King;Alan Fern;Jesse Hostetler	2013			minimax;mathematical optimization;example of a game without a value;simulation;computer science;artificial intelligence;machine learning;management science;algorithm	AI	20.325636152339158	-17.171540571818003	134790
e43801048d3aec0b0a26495adfd2ff6898c8fac4	the prediction of heating energy consumption in a model house by using artificial neural networks in denizli-turkey	energy efficient;predictive value;root mean square error;heating;large scale;natural gas;mean absolute percentage error;energy consumption;degree hour method;renewable energy resource;environmental problem;energy saving;artificial neural network	0965-9978/$ see front matter 2009 Elsevier Ltd. A doi:10.1016/j.advengsoft.2009.09.012 * Tel.: +90 258 2963320; fax: +90 258 2963262. E-mail address: adombayci@pamukkale.edu.tr Turkey does not have petrol and natural gas reserves on a large scale. National energy resources are lignite and hydropower. Together with increasing environmental problems and diminishing fossil resources, studies focusing on energy reduction as well as usage of renewable energy resources have accelerated. However, taking the technological and economical impossibilities into account, the most logical solution is energy saving by providing energy efficiency in households. In this study, an artificial neural network (ANN) model is developed in order to predict hourly heating energy consumption of a model house designed in Denizli which is located in Central Aegean Region of Turkey. Hourly heating energy consumption of the model house is calculated by degree-hour method. ANN model is trained with heating energy consumption values of years 2004–2007 and tested with heating energy consumption values of year 2008. The training and test figures were depicted for February month of these years. Best estimate is found with 29 neurons and a good coherence is observed between calculated and predicted values. According to the results obtained, root-mean-squared error (RMSE), absolute fraction (R) and mean absolute percentage error (MAPE) values are 1.2575, 0.9907, and 0.2091 for training phase and 1.2125, 0.9880, and 0.2081 for testing phase respectively. 2009 Elsevier Ltd. All rights reserved.		Ö. Altan Dombayci	2010	Advances in Engineering Software	10.1016/j.advengsoft.2009.09.012	renewable energy;natural gas;simulation;mean absolute percentage error;computer science;engineering;machine learning;mathematics;mean squared error;efficient energy use;artificial neural network;statistics	AI	10.176338495208986	-17.967281222290584	134958
7c9bbce333de6f7f552920d4f649a737b6a0d55b	is reduction in task space a condition for accelerated learning?	robot learning;learning behavior;robot sensing systems;machine learning algorithms;learning process;search space reduction;state space methods;robot learning scenario;biasing scheme;neural networks;search space;reinforcement learning;q learning;space exploration;task space reduction;sub optimal learning;orbital robotics;acceleration;search problems learning artificial intelligence;learning systems;learning system;time factors;machine learning;sub optimal learning task space reduction accelerated learning biasing scheme robot learning scenario unique task characteristics learning behavior reinforcement learning q learning maximal search space collapse search space reduction;unique task characteristics;acceleration orbital robotics learning systems neural networks state space methods space exploration robot sensing systems machine learning machine learning algorithms time factors;search problems;learning artificial intelligence;point of view;maximal search space collapse;accelerated learning	"""Biasing, once regarded as """"cheating"""" in the machine learning community, is now understood and accepted as a necessary part of learning. However, despite its wide acceptance and recognition, biasing has never been studied as a separate research issue, except by Hailu & Sommer (1999), who made an attempt to shed light on the relationship between the quality of the bias and learning trials. So far, the general view held in biasing a learning system is to look for a bias that maximally collapses the search space. It is well-known, however, that reckless reduction of the search space often leads to sub-optimal learning. Regardless of the final level of optimality, this paper challenges this broadily accepted biasing scheme from the point of view of accelerating the learning process itself. Is a large search space a definitive indication of slow learning? We give a non-affirmative answer to this dogma by presenting a typical robot learning scenario. Experiments clearly indicate that, in spite of its large search space, a bias that is derived from the unique characteristics of the task shows better learning behavior than a bias that reduces the search space aggressively."""		G. Hailu;Chandrasekhar Nataraj;Hashem Ashrafiuon	2001		10.1109/ICSMC.2001.969922	acceleration;robot learning;multi-task learning;simulation;computer science;artificial intelligence;space exploration;machine learning;reinforcement learning;artificial neural network;q-learning	ML	17.838221354791294	-20.857383793987804	135118
2b1db2913ff83219a01d3ae1c2c581a5b57603aa	decision support using deterministic equivalents of probabilistic game trees	game simulation;decision support;decision support tool;certainty equivalents;game theory;nash equilibrium;system configuration;risk aversion;pattern generation;biological system modeling;risk aversion decision support repeated game theory certainty equivalents game simulation;mission planning;certainty equivalence;repeated game;games game theory probabilistic logic biological system modeling decision support systems educational institutions algorithm design and analysis;games;decision support systems;repeated game theory;probabilistic logic;algorithm design and analysis	We have developed a game-theory driven decision-support tool that builds probabilistic game trees automatically from user-defined actions, rules, and states. The result of evaluating the paths in the game tree is a series of decisions which forms a decision-path representing an epsilon-Nash-Equilibrium. The algorithm uses certainty-equivalents to handle trade-offs between expected rewards and risks, effectively modeling the probabilistic game tree as deterministic. The resulting decision-paths correspond to player actions in the scenario. These sets of actions can be used as search patterns against a real-world database. A match to one of these patterns indicates an instance of novel behavior patterns generated by the game-theory driven decision support tool. This particular paradigm could be applied in any domain that requires anticipating and responding to adversarial agents with uncertainty, from mission planning to emergency responders to systems configuration.	algorithm;decision support system;game theory;nash equilibrium;programming paradigm	Michael L. Valenzuela;Liana Suantak;Jerzy W. Rozenblit	2012	2012 IEEE 19th International Conference and Workshops on Engineering of Computer-Based Systems	10.1109/ECBS.2012.22	games;algorithm design;simulation;risk aversion;decision support system;computer science;artificial intelligence;machine learning;repeated game;probabilistic logic;sequential game;nash equilibrium	Robotics	20.213617428529638	-16.173688272063696	135157
af2448705f92859af23ee28ef68adea83ce28622	the modularity in freeform evolving neural networks	evolutionary computation;neural networks;retina neurons artificial neural networks evolution biology evolutionary computation pixel computational modeling;neural nets;computer model;evolving neural networks;evolution biology;artificial neural networks;evolutionary computation modularity neural networks;computational modeling;retina;pixel;modularity;neurons;artificial evolution;modular neural network;artificial tracer method freeform artificial evolution modularity freeform neural networks;artificial neural network;neural network;evolutionary computing;neural nets evolutionary computation	In this paper, we validate whether the network modularity can emerge, and the evolution performance can be improved by varying the environment or evolution process under a more freeform artificial evolution. Previous studies have demonstrated that the modular structure naturally arisen as a response of the variations on environment and selection process, however, since the models they used were relatively simple and with some biasing constraints, the results may lack of generality. In contrast, we evolve more freeform neural networks to address this issue, and an artificial tracer method was employed to quantify the modularity. A series of varying scenarios have been experimented, the results show that the evolution performance have been improved in most cases, however, the modularity never appeared among those scenarios. A further experiment shows that our method has the potentials to produce modular networks but the more advanced methods are still needed to encourage the emergence of modularity on the complex questions.	artificial neural network;biasing;emergence;evolutionary algorithm;experiment;fitness function;modular programming;modularity (networks);pattern recognition;teaching method	Shuguang Li;Jianping Yuan	2011	2011 IEEE Congress of Evolutionary Computation (CEC)	10.1109/CEC.2011.5949943	computer science;bioinformatics;artificial intelligence;modularity;machine learning;modularity;computational model;artificial neural network;pixel	AI	15.557739202391698	-23.026942456242907	135385
9856032465b52b6fc302abad1f3893c27424c0e9	application of system ncf method to ice flood prediction of the yellow river	artificial neural network;fuzzy set theory;genetic algorithm	Combined forecasts is a well-established procedure for improving forecasting accuracy which takes advantage of the availability of both multiple information and computing resources for data-intensive forecasting. Therefore, based on the combination of engineering fuzzy set theory and artificial neural network theory as well as genetic algorithms and combined forecast theory, the system Non-linear Combined Forecast (NCF) method is established for accuracy enhancement of prediction, especially of ice flood prediction. The NCF values from single forecast model for Inner Mongolia Reach of the Yellow River are given. The case shows that the method has clear physical meanings and precise consequences. Compared with any single model, the system NCF method is more rational, effective and accurate.		Yu Guo;Wen-long Chen;Shouyu Chen	2008		10.1007/978-3-540-88914-4_51	genetic algorithm;computer science;machine learning;fuzzy set;artificial neural network	Robotics	10.219177177622246	-19.693360338596566	135499
b3512d47b1ca6fc5822353d4ee7d3bd6db359caf	neural network ensembles in reinforcement learning	reinforcement learning with function approximation;large environments;neural network ensemble;learning from unstable estimations of value functions	The integration of function approximation methods into reinforcement learning models allows for learning state- and state-action values in large state spaces. Model-free methods, like temporal-difference or SARSA, yield good results for problems where the Markov property holds. However, methods based on a temporal-difference are known to be unstable estimators of the value functions, when used with function approximation. Such unstable behavior depends on the Markov chain, the discounting value and the chosen function approximator. In this paper, we propose a meta-algorithm to learn state- or state-action values in a neural network ensemble, formed by a committee of multiple agents. The agents learn from joint decisions. It is shown that the committee benefits from the diversity on the estimation of the values. We empirically evaluate our algorithm on a generalized maze problem and on SZ-Tetris. The empirical evaluations confirm our analytical results.	algorithm;approximation;artificial neural network;control theory;error message;markov chain;markov property;metaheuristic;reinforcement learning;tetris	Stefan Faußer;Friedhelm Schwenker	2013	Neural Processing Letters	10.1007/s11063-013-9334-5	mathematical optimization;artificial intelligence;machine learning;mathematics;learning classifier system;q-learning;statistics	ML	21.58366622248045	-19.049497732389504	135550
90e8fbcb0af1043b257938976fa7df6979c7496e	no-regret algorithms for online convex programs	shortest path;convex programming;machine learning	Online convex programming has recently emerged as a powerful primitive for designing machine learning algorithms. For example, OCP can be used for learning a linear classifier, dynamically rebalancing a binary search tree, finding the shortest path in a graph with unknown edge lengths, solving a structured classification problem, or finding a good strategy in an extensive-form game. Several researchers have designed no-regret algorithms for OCP. But, compared to algorithms for special cases of OCP such as learning from expert advice, these algorithms are not very numerous or flexible. In learning from expert advice, one tool which has proved particularly valuable is the correspondence between no-regret algorithms and convex potential functions: by reasoning about these potential functions, researchers have designed algorithms with a wide variety of useful guarantees such as good performance when the target hypothesis is sparse. Until now, there has been no such recipe for the more general OCP problem, and therefore no ability to tune OCP algorithms to take advantage of properties of the problem or data. In this paper we derive a new class of no-regret learning algorithms for OCP. These Lagrangian Hedgingalgorithms are based on a general class of potential functions, and are a direct generalization of known learning rules like weighted majority and external-regret matching. In addition to proving regret bounds, we demonstrate our algorithms learning to play one-card poker.	algorithm;convex optimization;linear classifier;machine learning;open core protocol;regret (decision theory);search tree;shortest path problem;sparse matrix	Geoffrey J. Gordon	2006			mathematical optimization;convex optimization;computer science;theoretical computer science;machine learning;mathematics;shortest path problem	ML	23.70170957659127	-17.37880532858236	135568
6b967403346842e8819e17fab5ace22d72fe4ccc	hosting capacity of low-voltage grids for distributed generation: classification by means of machine learning techniques		Abstract A high amount of installed distributed generators (DG) in low-voltage grids, e.g. photovoltaic generators (PV), may cause serious problems due to overloading of electrical equipment and violation of voltage limits. The assessment of low-voltage grids regarding their hosting capacity for the installation of DG is a difficult task, because grid structures may be diverse and complex. In this article, we classify grids by means of machine learning techniques, in particular support vector machines (SVM). SVM learn to assess grids by means of sample data, that is, grids represented by characteristic features that were assessed by human domain experts (i.e., distribution system operators (DSO) staff). We show that this approach can significantly better reflect domain expert assessments compared to a technique we proposed earlier which is based on a stochastic load flow simulation procedure and a subsequent parametric stochastic model estimation. One key result of this article is that SVM with grid based features significantly outperform SVM using features from load flow simulations regarding the classification accuracy if both are trained with data that were assessed (labeled) by DSO staff. Experiments are based on data for 300 real rural and suburban low-voltage grids.	machine learning	Sebastian Breker;Jan S. Rentmeister;Bernhard Sick;Martin Oberkönig	2018	Appl. Soft Comput.	10.1016/j.asoc.2018.05.007	support vector machine;machine learning;stochastic modelling;subject-matter expert;artificial intelligence;grid;electrical equipment;mathematics;low voltage;parametric statistics;photovoltaic system	Metrics	10.559455005823754	-13.548066030333066	135707
2a1e78e76bed1c7044c0e556cef06cb78b6ef67b	optimal and approximate q-value functions for decentralized pomdps	sequential decision making;benchmark problem;dynamic program;optimal policy;universiteitsbibliotheek;artificial intelligent;upper bound;decision theoretic planning;value function;experimental evaluation	Decision-theoretic planning is a popular approach to sequential decision making problems, because it treats uncertainty in sensing and acting in a principled way. In single-agent frameworks like MDPs and POMDPs, planning can be carried out by resorting to Q-value functions: an optimal Q-value function Q is computed in a recursive manner by dynamic programming, and then an optimal policy is extracted from Q. In this paper we study whether similar Q-value functions can be defined for decentralized POMDP models (DecPOMDPs), and how policies can be extracted from such value functions. We define two forms of the optimal Q-value function for Dec-POMDPs: one that gives a normative description as the Q-value function of an optimal pure joint policy and another one that is sequentially rational and thus gives a recipe for computation. This computation, however, is infeasible for all but the smallest problems. Therefore, we analyze various approximate Q-value functions that allow for efficient computation. We describe how they relate, and we prove that they all provide an upper bound to the optimal Q-value function Q. Finally, unifying some previous approaches for solving Dec-POMDPs, we describe a family of algorithms for extracting policies from such Q-value functions, and perform an experimental evaluation on existing test problems, including a new firefighting benchmark problem.	approximation algorithm;bellman equation;benchmark (computing);computable function;computation;dynamic programming;partially observable markov decision process;recursion;theory	Frans A. Oliehoek;Matthijs T. J. Spaan;Nikos A. Vlassis	2008	J. Artif. Intell. Res.	10.1613/jair.2447	mathematical optimization;computer science;artificial intelligence;machine learning;management science;bellman equation;upper and lower bounds	ML	21.85024924542381	-16.499566870489105	136026
559ba251a40b3522e91f81e37c9073c7ebd83b2c	architecture of behavior-based function approximator for adaptive control	learning process;supervised learning;behavior based control;adaptive control;hybrid approach;function approximation;control strategy	This paper proposes the use of behavior-based control architecture and investigates on some techniques inspired by Nature- a combination of reinforcement and supervised learning algorithms to accomplish the sub-goals of a mission of building adaptive controller. The approach iteratively improves its control strategies by exploiting only relevant parts of action and is able to learn completely in on-line mode. To illustrate this, it has been applied to non-linear, non-stationary control task: Cart-Pole balancing. The results demonstrate that our hybrid approach is adaptable and can significantly improve the performance of TD methods while speed up learning process.		Hassab Elgawi Osman	2008		10.1007/978-3-642-03040-6_13	unsupervised learning;adaptive control;function approximation;computer science;artificial intelligence;machine learning;supervised learning	Robotics	19.285947288337475	-20.48452336217011	136105
fea92d50fc55b63c52c2e1c04339db23251d4b21	application of artificial neural network for determination of standard time in machining	neural net;sensitivity analysis;machine model;artificial neural network;neural network	The purpose of this article is to present the application of neural network for time per unit determination in small lot production in machining. A set of features considered as input vector and time consumption in manufacturing process was presented and treated as output of the neural net. A neural network was used as a machining model. Sensitivity analysis was made and proper topology of neural network was determined.	artificial neural network	Izabela Kutschenreiter-Praszkiewicz	2008	J. Intelligent Manufacturing	10.1007/s10845-008-0076-6	control engineering;probabilistic neural network;computer science;engineering;artificial intelligence;machine learning;time delay neural network;sensitivity analysis;artificial neural network	AI	13.225765797458555	-19.498860373451265	136454
fc38eb91506c6bf4b607b5e3c0ba2387287f498d	using genetic algorithm based variable selection to improve neural network models for real-world systems	feature selection;genetic algorithm;optimization;/ neural network;variable selection;operating system;genetics;neural network model;neural network;prediction model;system modeling	"""Real-world systems are often modeled by sampling sensor data taken during system operation. System states may not be all known or measurable, sensor data may be biased or noisy, and it is not often known which sensor data may be useful for predictive modeling. Neural network models generated from this data must therefore rely on how effectively the chosen sensor data represents the system. Genetic algorithms may help to address this problem by determining a near optimal subset of sensor variables most appropriate to produce good models. This paper describes the use of genetic algorithms to optimize variable selection to determine inputs into a neural network system model. The use of this technique for modeling a typical industrial application, a liquid fed ceramic melter, and the results of the genetic search to optimize the neural network model for this application, are described. Keywords/ neural network, genetic algorithm, optimization, variable selection, feature selection 1 This research was supported by the Office of Naval Research work requests N0001402WR20090 and N0001402WX20003. 0ntroduction When modeling a complex system (such as a chemical reactor), it is not generally known a priori which system states are necessary to develop a good model, or which states are observable based upon available sensor technology (although it is often known that many system states are not observable). In addition, there is a greater problem in identifying useful data. Complex dynamic systems such as the chemical reactor may be instrumented with tens, hundreds or even thousands of sensors. The problem with so much sensor information is that most of it will be irrelevant. Worse still, unfiltered incorporation of irrelevant data will adulterate a model, eroding its predictive capabilities. A key data pretreatment problem is sensor redundancy. It is well known that smaller models are often better models [5], [4]. This translates to fewer inputs and fewer hidden layer nodes. While it may be nice to have highly redundant data from a large number of sensors, in reality we may only need a few key sensors in order to produce a good model. The problem is in determining which few sensors to choose, and ignoring most of the remaining sensors. This is confounded by the fact that due to differing sensor response characteristics and noise, in the aggregate there is a considerable amount of noise and bias in the data. In this study modeling of a liquid fed ceramic melter (LFCM) process was undertaken in order to predict the surface level. The melt chamber was instrumented with 20 thermocouple sensors placed at different sites within the chamber. Each sensor may have a slightly different characteristic response curve due to differences in manufacturing, usage history, etc. Each sensor also is susceptible to some level of noise. A time history of data is taken from all 20 sensors and stored in a database used to train a neural network model. Some sensors, such as those near the surface in the reactor vessel, may offer fairly high-variance data throughout the process, but be largely irrelevant to accurately predicting final product quality. We would like to select a near-optimal set of sensor variables in order to train a neural network model with the greatest predictive accuracy 5ariable Selection 8sing :As Variable selection (or feature selection) may be performed in an automated way using genetic algorithms (GAs). The genes need to be defined for a given application such that finding a better or more optimal set of genes means finding a better solution to the problem. A GA may perform variable selection if each gene in a chromosome represents an available sensor variable. Fitness is judged for each chromosome by determining how good the models are (accuracy, robustness) generated by that combination of variables. An initial population of chromosomes is generated by choosing a string length (# of genes) and randomly assigning a variable to each gene. The GA search is then set in motion and the chromosomes compete, reproduce, and die off as they are replaced by more fit chromosomes. It is usually desirable to maintain a fixed-size population in order to make sure that the fitter chromosomes quickly replace the less fit ones. An occasional mutation is introduced to make sure that certain genes (variables) which may be really useful aren't quickly eliminated (possibly because they are randomly combined with really noisy variables early on) and then never incorporated again. This is referred to as a population in danger due to lack of genetic variation, and to avoid this situation a mutation rate is predetermined and mutated chromosomes are introduced into the population at regular intervals during GA search. As these parameters are application dependent, it is not possible to know beforehand which values will work best. The GA process is implemented with automatic sequence selection, model building and discarding, and evaluation of accuracy and robustness of the models (scoring). Successive generations will inherit the best characteristics from the previous generation, while eliminating the less valuable characteristics. :A ;epresentation = >perators Genetic algorithms are often thought of, discussed and implemented using binary strings, or bit strings. Each gene or bit represents the expression of a state. If the bit is turned on, then the gene corresponding to that bit can be said to be """"expressed"""". In this application a bit represents the state of either a variable being included (“1”) or not included (“0”) in the final solution. Genetic algorithms sometimes require the use of special operators in order to simulate the evolutionary processes which they emulate. The most common operators are crossover and mutation. The crossover operator takes two parent chromosomes (in this application, each parent chromosome represents a group of input variables used to build a neural network model), and combines them to produce an offspring. A common form of crossover operator is uniform crossover [6]. In uniform crossover, if a specific gene is turned on in both parents, then it will be turned on in the offspring. If a gene is turned on in only one of the parents, then it may be turned on (with a predetermined probability, usually 0.5) in the offspring. Uniform crossover was used in this project. The mutation operator is applied independently but immediately following the crossover operator. A mutation is a random change of a gene in a chromosome, and is applied according to a preset mutation rate (usually quite low, e.g. 0.001). An elitist policy, or survival rate, that determines what percentage of the population (the fittest members) would survive into the next generation was employed. Because the computational cost of building and training neural network models from scratch can be high, another feature employed in this work was to guarantee that when a new offspring is generated it does not duplicate any chromosome currently in the population or which has been previously built and tested. A graveyard was used to store old chromosomes which represent models which have been built, tested, and then discarded. Each new offspring is compared with chromosomes in the graveyard to make sure that it hasn't been tested before in a previous generation. Since we assume that all of the neural network models use the same superset of data (same output data, input data includes sensor streams for all possible input variables), then the process of choosing variables for a particular model is deterministic, so there is never a need to retest a chromosome once its corresponding model has been built and scored. This promotes better crossover by preventing the generation of chromosomes which are already represented or have been generated and tested in prior generations. Chromosomes which are carried from one generation to the next are stored along with their scores, but are not retested since this would unnecessarily duplicate computations."""	aggregate data;algorithmic efficiency;artificial neural network;automatic sequence;complex system;computation;crossover (genetic algorithm);dynamical system;feature selection;fitness function;genetic algorithm;mathematical optimization;multilayer perceptron;mutation (genetic algorithm);network model;next-generation network;observable;predictive modelling;randomness;reactor (software);redundancy (engineering);relevance;sampling (signal processing);sensor;simulation;software release life cycle;string (computer science);the offspring;type system;world-system	Donald Sofge	2002			computer science;pattern recognition;artificial intelligence;genetic algorithm;machine learning;systems modeling;system model;feature selection;sampling (statistics);artificial neural network;time delay neural network	AI	14.37133466460749	-18.384398267711656	136752
df81de1ad8397d48c65536cded1df3cfd627e2f6	task scheduling and merging in space and time		Every day, robots are being deployed in more challenging environments, where they are required to perform complex tasks. In order to achieve these tasks, robots rely on intelligent deliberation algorithms. In this thesis, we study two deliberation approaches – task scheduling and task planning. We extend these approaches in order to not only deal with temporal and spatial constraints imposed by the environment, but also exploit them to be more efficient than the state-ofthe-art approaches. Our first main contribution is a scheduler that exploits a heuristic based on Allen’s interval algebra to prune the search space to be traversed by a mixed integer program. We empirically show that the proposed scheduler outperforms the state of the art by at least one order of magnitude. Furthermore, the scheduler has been deployed on several mobile robots in long-term autonomy scenarios. Our second main contribution is the POPMERX algorithm, which is based on merging of partially ordered temporal plans. POPMERX first reasons with the spatial and temporal structure of separately generated plans. Then, it merges these plans into a single final plan, while optimising the makespan of the merged plan. We empirically show that POPMERX produces better plans that the-stateof-the-art planners on temporal domains with time windows. Note that the results presented in this thesis have been significantly improved. Please refer to our journal paper. To girls and women around the world, who are told that they cannot follow their dreams.		Lenka Mudrová	2017			merge (version control);spacetime;job shop scheduling;scheduling (computing);mobile robot;real-time computing;heuristic;exploit;deliberation;computer science	AI	18.164307769405657	-10.443503996962669	137116
a2444cbd4683c53ec8ea9ed130006f760f76e8f4	adaptive learning mechanisms for ordering actions using random races	metodo adaptativo;optimisation;medio ambiente;modele mathematique;optimizacion;learning;learning model;interaction;relacion orden;ordering;methode adaptative;modelo matematico;course aleatoire;action;aprendizaje;learning systems;learning system;relation ordre;apprentissage;learning systems clustering algorithms ultrasonic transducers welding pattern recognition classification algorithms inspection pattern classification ultrasonic variables measurement measurement standards;random walk;environment;adaptive method;adaptive learning;mathematical model;a priori information;environnement;optimization;interaccion;marcha aleatoria;accion;optimisation learning systems;learning strategies;marche aleatoire;permutationally epsilon optimal model adaptive learning mechanisms action ordering random races learning multiple race track model learning single race track model overtaking rules;random environment;random race	Consider a learning machine (LM) interacting with an environment epsilon . The environment offers the machine M actions. Traditionally, learning systems endeavor to compute the best action that the environment offers, and this is done without any estimation procedure. In this paper, we consider the problem of the LM computing not only the optimal action offered but also the ordering of the actions in terms of their optimality. The problem is posed in its generality and various norms of learning in this setting are formalized. Also various learning strategies are presented that use a new mathematical model called the random race. In this model the learning is modeled using M racers that are running toward a goal. At each instant, racer R/sub i/ moves toward the goal with a probability of s/sub i/ and stays where he is with a probability of (1-s/sub i/). In the simplest learning model, the learning multiple race track (LMRT) model, the racers run on multiple tracks, and in this scenario, each racer has his own track, thus disallowing interference between the racers. However, in a more general setting, the learning single race track (LSRT) model, the racers run on a single track, and in this case, interferences between racers are specified in terms of overtaking rules. In this paper, we first examine the learning multiple race track (LMRT) model, and we have shown that in the absence of a priori information the LMRT is permutationally epsilon -optimal in all suggestive random environments. Other results are proven or conjectured. >		David T. H. Ng;B. John Oommen;E. R. Hansen	1993	IEEE Trans. Systems, Man, and Cybernetics	10.1109/21.260677	interaction;simulation;order theory;artificial intelligence;machine learning;mathematical model;mathematics;natural environment;adaptive learning;random walk;statistics	Embedded	22.386018537955923	-21.45054792542331	137233
1c7aa38ef6a249d1f7677cd07d591dada785662b	stochastic self-monitoring of autonomous systems	assignment;dynamic programming;robot movil;asignacion;programacion dinamica;autonomous system;assignation;loi conditionnelle;credit;ley condicional;sistema autonomo;autonomic system;robot mobile;credito;systeme autonome;inferencia;programmation dynamique;directed markov field;conditional distribution;inference;moving robot;auotmonitorage;planification stochastique	A probabilistic method is presented for high level task planning of autonomous, mobile systems under partial observability of states and partial knowledge of transition laws. Partial state observability is addressed by directed Markov fields which support the detection of relationships between pairs of observed variables in competition to other such pairs.	autonomous system (internet)	Thomas Kämpke	1999	Computers and Artificial Intelligence		conditional probability distribution;observability;simulation;computer science;autonomous system;artificial intelligence;dynamic programming;assignment;control theory;mathematics;programming language	AI	23.31069078274853	-14.439047568459706	137275
6ddaf7ef913c12013561c7f8e22af59649fe43b3	combining deep reinforcement learning and safety based control for autonomous driving		With the development of state-of-art deep reinforcement learning, we can efficiently tackle continuous control problems. But the deep reinforcement learning method for continuous control is based on historical data, which would make unpredicted decisions in unfamiliar scenarios. Combining deep reinforcement learning and safety based control can get good performance for self-driving and collision avoidance. In this passage, we use the Deep Deterministic Policy Gradient algorithm to implement autonomous driving without vehicles around. The vehicle can learn the driving policy in a stable and familiar environment, which is efficient and reliable. Then we use the artificial potential field to design collision avoidance algorithm with vehicles around. The path tracking method is also taken into consideration. The combination of deep reinforcement learning and safety based control performs well in most scenarios.	algorithm;autonomous car;gradient;reinforcement learning	Xi Xiong;Jianqiang Wang;Fang Zhang;Keqiang Li	2016	CoRR		error-driven learning;simulation;engineering;artificial intelligence;machine learning	Robotics	19.72860526011461	-18.80154016657844	137317
61e72a00859cf36b827468a300cf6f8fc9c349ca	selecting robust strategies based on abstracted game models		Game theory is a tool for modeling multi-agent decision problems and has been used successfully in problems such as poker, security, and trading agents. However, many real games are extremely large[4]. One approach for solving large games is to use abstraction techniques to shrink the game to a form that can be solved by removing detail and translating a solution back to the original. However, abstraction introduces error into the model. We study ways to analyze games that are robust to errors in the model of the game, including abstracted games. We empirically evaluate several solution methods to evaluate how robust they are for abstracted games.	decision problem;game theory;multi-agent system	Oscar Veliz;Christopher Kiekintveld	2015			combinatorial game theory;game theory;minimax;simulation;computer science;artificial intelligence;theoretical computer science;mathematical game;abstraction;screening game;normal-form game;simulations and games in economics education;algorithmic game theory;sequential game	AI	19.764682005098347	-17.329707146865577	137380
4ef7d14d9ecb0b43195766807e3b224190b15903	dynamics of a 2d piecewise linear braess paradox model: effect of the third partition	piecewise smooth maps;braess paradox;modeling and simulation;discontinuous maps;engineering all;border collision bifurcations;multidisciplinary;applied mathematics	In this work, we investigate the dynamics of a piecewise linear 2D discontinuous map modeling a simple network showing the Braess paradox. This paradox represents an example in which adding a new route to a specific congested transportation network makes all the travelers worse off in terms of their individual travel time. In the particular case in which the modeled network corresponds to a binary choice situation, the map is defined on two partitions and its dynamics has already been described. In the general case corresponding to a ternary choice, a third partition appears leading to significantly more complex bifurcation structures formed by border collision bifurcations of stable cycles with points located in all three partitions. Considering a map taking a constant value on one of the partitions, we provide a first systematic description of possible dynamics for this case.		Viktor Avrutin;Christoph Dibak;Arianna Dal Forno;Ugo Merlone	2015	I. J. Bifurcation and Chaos	10.1142/S0218127415300311	mathematical optimization;combinatorics;calculus;control theory;modeling and simulation;mathematics;multidisciplinary approach	NLP	10.170543678401577	-10.315075589637527	137588
38f8b219f399ab24938da88303d0cc551bc3d4a6	on the run-time dynamics of a peer-to-peer evolutionary algorithm	population size;p2p;waiting time;evolutionary algorithm;peer to peer	In this paper we propose an improvement on a fully distributed Peer-to-Peer (P2P) Evolutionary Algorithm (EA) based on autonomous selection. Autonomous selection means that individuals decide on their own state of reproduction and survival without any central control, using instead estimations about the global population state for decision making. The population size varies at run-time as a consequence of such a decentralized reproduction and death of individuals. In order to keep it stable, we propose a self-adjusting mechanism which has been shown successful in three different search landscapes. Key are the estimations about fitness and size of the population as provided by a gossiping algorithm. Such an algorithm requires several rounds to collect the information while the individuals have to wait for synchronization. As an improvement, we propose a completely asynchronous EA which does not need waiting times. The results show that our approach outperforms qualitatively the execution time of the synchronous version.	autonomous robot;evolutionary algorithm;peer-to-peer;run time (program lifecycle phase)	Juan Luis Jiménez Laredo;A. E. Eiben;Maarten van Steen;Juan Julián Merelo Guervós	2008		10.1007/978-3-540-87700-4_24	population size;simulation;computer science;artificial intelligence;evolutionary algorithm;peer-to-peer	EDA	22.95239681304687	-10.686693753514714	137603
140ed89b9ab6a128e9869996ff325023a49dce08	a ludo cellular automata model for microscopic traffic flow	traffic flow;stochastic;discrete model;cellular automata;microscopic	The Ludo Cellular Automata (LCA) concept proposed in this paper, harnesses a stochastic approach for vehicle acceleration at microscopic level. Inspired by the traditional Ludo board game, a die roll in LCA coupled with a set of Ludo rules and biases have the potential to improve the stochasticity of traffic flow speed. Hence, LCA increases vehicle acceleration and deceleration accuracy. Furthermore, the model defines spaces with multiple-state, which can accommodate multiple constraints. Each space in a lane contains a speed value, which allows vehicles to react accordingly. The LCA model aims at providing a robust and flexible algorithm that enhances traffic flow accuracy and computation efficiency.	cellular automaton	Kelvin N. S. Heeroo;Oomesh Gukhool;Dristesh Hoorpah	2016	J. Comput. Science	10.1016/j.jocs.2016.04.015	cellular automaton;simulation;traffic flow;mathematics;stochastic;statistics	Theory	10.79822988087134	-10.244645096471878	137911
e9c6edc5f51998435982adfb4555655ff12cffd4	large-scale traffic grid signal control with regional reinforcement learning	approximation algorithms;roads;feature extraction;aerospace electronics;self adjusting systems approximation theory centralised control control engineering computing learning artificial intelligence optimal control optimisation road traffic control;approximation algorithms real time systems adaptation models feature extraction learning artificial intelligence aerospace electronics roads;approximate q learning traffic grid signal control reinforcement learning rl heuristic self organizing algorithm centralized control optimal control policy;learning artificial intelligence;adaptation models;real time systems	Reinforcement learning (RL) based traffic signal control for large-scale traffic grids is challenging due to the curse of dimensionality. Most particularly, searching for an optimal policy in a huge action space is impractical, even with approximate Q-functions. On the other hand, heuristic self-organizing algorithms could achieve efficient decentralized control, but most of them have few effort on optimizing the real-time traffic. This paper proposes a new regional RL algorithm that could form local cooperation regions adaptively, and then learn the optimal control policy for each region separately. In particular, we maintain a set of learning parameters to capture the control patterns in regions at different scales. At each time step, we first decompose the large-scale traffic grid into disjoint sub-regions, depending on the real-time traffic condition. Next, we apply approximate Q-learning to learn the centralized control policy within each sub-region, by updating the corresponding learning parameters upon traffic observations. The numerical experiments demonstrate that our regional RL algorithm is computationally efficient and functionally adaptive, and it outperforms typical heuristic decentralized algorithms.	algorithmic efficiency;approximation algorithm;centralized computing;curse of dimensionality;distributed control system;experiment;feature extraction;heuristic;message passing;numerical analysis;optimal control;organizing (structure);q-learning;real-time clock;reinforcement learning;self-organization;subnetwork	Tianshu Chu;Shuhui Qu;Jie Wang	2016	2016 American Control Conference (ACC)	10.1109/ACC.2016.7525014	simulation;feature extraction;computer science;artificial intelligence;machine learning;control theory;reinforcement learning;approximation algorithm	ML	19.454426442916315	-18.8170089778732	138099
225d58437c4691ad5be8d766e02274de15fd5d7c	dynamic clustering using particle swarm optimization with application in image segmentation	particle swarm;clustering validation;unsupervised clustering;analyse amas;swarm intelligence;algoritmo busqueda;image segmentation;image processing;partition donnee;algorithme k moyenne;classification non supervisee;algorithme recherche;search algorithm;recherche aleatoire;data partition;procesamiento imagen;natural images;algoritmo genetico;traitement image;dynamic clustering;cluster analysis;particle swarm optimizer;optimizacion enjambre particula;particle swarm optimization;clasificacion no supervisada;segmentation image;initial condition;number of clusters;algorithme genetique;optimisation essaim particule;investigacion aleatoria;unsupervised classification;algorithme evolutionniste;algoritmo k media;genetic algorithm;k means algorithm;analisis cluster;algoritmo evolucionista;cluster validity;evolutionary algorithm;reseau neuronal;random search;red neuronal;k means clustering;particion dato;neural network	A new dynamic clustering approach (DCPSO), based on particle swarm optimization, is proposed. This approach is applied to image segmentation. The proposed approach automatically determines the “optimum” number of clusters and simultaneously clusters the data set with minimal user interference. The algorithm starts by partitioning the data set into a relatively large number of clusters to reduce the effects of initial conditions. Using binary particle swarm optimization the “best” number of clusters is selected. The centers of the chosen clusters is then refined via the K-means clustering algorithm. The proposed approach was applied on both synthetic and natural images. The experiments conducted show that the proposed approach generally found the “optimum” number of clusters on the tested images. A genetic algorithm and random search version of dynamic clustering is presented and compared to the particle swarm version.	artificial immune system;artificial neural network;cluster analysis;color image;color quantization;computational intelligence;computer engineering;computer science;computer vision;data mining;differential evolution;e-commerce payment system;evolutionary computation;experiment;fuzzy cognitive map;genetic algorithm;image segmentation;initial condition;interference (communication);k-means clustering;kepler engelbrecht;lenna;machine learning;mathematical optimization;multi-objective optimization;particle swarm optimization;quantization (image processing);random search;resultant;software release life cycle;swarm intelligence;swarm robotics;synthetic intelligence;turi;web mining	Mahamed G. H. Omran;Ayed A. Salman;Andries Petrus Engelbrecht	2005	Pattern Analysis and Applications	10.1007/s10044-005-0015-5	correlation clustering;multi-swarm optimization;determining the number of clusters in a data set;fuzzy clustering;image processing;swarm intelligence;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;single-linkage clustering;particle swarm optimization;algorithm;affinity propagation;k-means clustering	AI	23.689525004779277	-12.098824027245287	138324
9239d88fa2786ae833825883614380f6112526b9	a garch modeling approach for constant speed drive residual life predicting of aircraft generator	garch;time varying;generators;garch model;aircraft generator;time varying variance;time series;state estimation;residual life;residual life prediction garch modeling approach constant speed drive residual life aircraft generator time series data monitoring time varying variance generalized autoregressive conditional heteroscedasticity model state estimation constant speed generator drive;simulation experiment;petroleum;csd;autoregressive processes;time series aircraft power systems autoregressive processes electric generators;garch modeling approach;garch time series csd residual life prediction;generalized autoregressive conditional heteroscedasticity model;mathematical model;aircraft power systems;time series data;life prediction;predictive models;time series data monitoring;atmospheric modeling;constant speed generator drive;predictive models aircraft autoregressive processes state estimation life estimation time series analysis synchronous generators petroleum equations parameter estimation;prediction;electric generators;conditional heteroscedasticity;time series prediction;aircraft;residual life prediction;data models;constant speed drive residual life;time series model	The estimation of devices states and the prediction of condition developments are always utilized in projects by monitoring time-series data. For solving the problems of non-stationary and time-varying variance in practical data, generalized autoregressive conditional heteroscedasticity (GARCH) model is discussed, compared with traditional time-series model, in this paper in order to gain a better estimation and a greater predicting effect. In the paper GRACH model is applied to state estimation of constant speed generator drive (CSD) of aircraft for the residual life prediction. Finally the suitability of the proposed method is examined by simulating experiment data. And it is necessary in practical projects to analyze the relations among sample data, prediction period and precision. The simulation results show that the residual life prediction error of CSD lies within 10% as expected.	autoregressive model;cambridge structural database;conditional entropy;simulation;stationary process;time series	Xiaofei Du;Yuanjun Zhou	2008	2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2008.90	econometrics;time series;statistics	Robotics	10.075453815110661	-14.623771915489902	138703
06fef0b1453988d2f798a328eaed14fd26d50c19	towards automatic experimentation of educational knowledge	datamining;games	We present a general automatic experimentation and hypothesis generation framework that utilizes a large set of users to explore the effects of different parts of an intervention parameter space on any objective function. We also incorporate importance sampling, allowing us to run these automatic experiments even if we cannot give out the exact intervention distributions that we want. To show the utility of this framework, we present an implementation in the domain of fractions and numberlines, using an online educational game as the source of players. Our system is able to automatically explore the parameter space and generate hypotheses about what types of numberlines lead to maximal short-term transfer; testing on a separate dataset shows the most promising hypotheses are valid. We briefly discuss our results in the context of the wider educational literature, showing that one of our results is not explained by current research on multiple fraction representations, thus proving our ability to generate potentially interesting hypotheses to test.	experiment;importance sampling;loss function;maximal set;optimization problem;sampling (signal processing)	Yun-En Liu;Travis Mandel;Emma Brunskill;Zoran Popovic	2014		10.1145/2556288.2557392	games;simulation;computer science;artificial intelligence;algorithm	HCI	22.279015253136656	-21.533709203564754	138747
6cd9307ea86945f6ec555efcd1a81fd71a86082e	virtual spectrum analyzer based on data acquisition card	packaging machines;add on boards;digital signal processing;signal generators;data acquisition card;virtual instrumentation;instruments;software measurement;virtual instrument data acquisition card virtual spectrum analyser dsp integrated programming package labview;virtual instrument;integrated programming package;spectrum;digital signal processing chips data acquisition spectral analysers software packages virtual instrumentation;speed;accuracy;data analysis;data analysis data acquisition instruments hardware software design microcomputers signal generators digital signal processing packaging machines software measurement;virtual spectrum analyser;add on boards virtual instrumentation spectral analysers data acquisition;virtual spectrum analyzer;digital signal processing chips;spectral analysis;software design;data acquisition;data acquisition card virtual spectrum analyzer accuracy speed dsp integrated programming package labview;microcomputers;software packages;dsp;hardware;labview;spectral analysers;spectral analysis data acquisition instruments software design hardware signal generators software packages packaging machines software measurement costs	A virtual spectrum analyzer based on a data acquisition card is presented. The implemented functions are described. The properties of the device were examined. Such features as accuracy and speed are considered. The virtual analyzer and an instrument equipped with a DSP are compared. The integrated programming package LabView was used to design the analyzer.	data acquisition;digital signal processor;labview;spectrum analyzer	Piotr Bilski;Wieslaw Winiecki	2002	IEEE Trans. Instrumentation and Measurement	10.1109/19.989906	embedded system;computer hardware;computer science;engineering;operating system;digital signal processing;physics;quantum mechanics;statistics	Visualization	16.48298571945054	-12.343130537966232	138816
6ba80f6366bcf7a8513cc4aa8c6486af0df6a6c2	problem solving with reinforcement learning	high dimensionality;reinforcement learning;problem solving	This thesis is concerned with practical issues surrounding the application of reinforcement learning techniques to tasks that take place in high dimensional continuous state-space environments. In particular, the extension of on-line updating methods is considered, where the term implies systems that learn as each experience arrives, rather than storing the experiences for use in a separate oo-line learning phase. Firstly, the use of alternative update rules in place of standard Q-learning (Watkins 1989) is examined to provide faster convergence rates. Secondly, the use of multi-layer perceptron (MLP) neural networks (Rumelhart, Hinton and Williams 1986) is investigated to provide suitable generalising function approximators. Finally, consideration is given to the combination of Adaptive Heuristic Critic (AHC) methods and Q-learning to produce systems combining the beneets of real-valued actions and discrete switching. The diierent update rules examined are based on Q-learning combined with the TD() algorithm (Sutton 1988). Several new algorithms, including Modiied Q-Learning and Summation Q-Learning, are examined, as well as alternatives such as Q() (Peng and Williams 1994). In addition, algorithms are presented for applying these Q-learning updates to train MLPs on-line during trials, as opposed to the backward-replay method used by Lin (1993b) that requires waiting until the end of each trial before updating can occur. The performance of the update rules is compared on the Race Track problem of Barto, Bradtke and Singh (1993) using a lookup table representation for the Q-function. Some of the methods are found to perform almost as well as Real-Time Dynamic Programming, despite the fact that the latter has the advantage of a full world model. The performance of the connectionist algorithms is compared on a larger and more complex robot navigation problem. Here a simulated mobile robot is trained to guide itself to a goal position in the presence of obstacles. The robot must rely on limited sensory feedback from its surroundings and make decisions that can be generalised to arbitrary layouts of obstacles. These simulations show that the performance of on-line learning algorithms is less sensitive to the choice of training parameters than backward-replay, and that the alternative Q-learning rules of Modiied Q-Learning and Q() are more robust than standard Q-learning updates. Finally, a combination of real-valued AHC and Q-learning, called Q-AHC learning, is presented, and various architectures are compared in performance on the robot problem. The resulting reinforcement learning system has the properties of providing on-line training, parallel computation, generalising function …	algorithm;andrew barto;artificial neural network;computation;connectionism;dynamic programming;experience;feedback;heuristic;layer (electronics);lookup table;memory-level parallelism;mobile robot;motion planning;multilayer perceptron;online and offline;online machine learning;parallel computing;problem solving;q-learning;real-time transcription;reinforcement learning;robotic mapping;simulation;state space	Gavin Adrian Rummery	1995			machine learning;reinforcement learning	ML	18.814843079727286	-21.79600926776156	138884
120b4423e340735ba3dcc1b03c498be4d91b0186	on genetic programming of fuzzy rule-based systems for intelligent control	fuzzy rule based system;genetic program;mobile robot;fuzzy control;syntactic constraints;mobile robots;fuzzy logic controller;genetic programming;intelligent control;fuzzy logic;control system;rule base discovery;evolutionary computing	Fuzzy logic and evolutionary computation have proven to be convenient tools for handling real-world uncertainty and designing control systems, respectively. An approach is presented that combines attributes of these paradigms for the purpose of developing intelligent control systems. The potential of the genetic programming paradigm (GP) for learning rules for use in fuzzy logic controllers (FLCs) is evaluated by focussing on the problem of discovering a controller for mobile robot path tracking. Performance results of incomplete rule-bases compare favorably to those of a complete FLC designed by the usual trial-and-error approach. A constrained syntactic representation supported by structure-preserving genetic operators is also introduced.	control system;evolutionary computation;fuzzy logic;fuzzy rule;genetic operator;genetic programming;intelligent control;mobile robot;programming paradigm;rule-based system	Edward Tunstel;Mo M. Jamshidi	1996	Intelligent Automation & Soft Computing	10.1080/10798587.1996.10750674	mobile robot;fuzzy electronics;defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;computer science;control system;artificial intelligence;neuro-fuzzy;machine learning;genetic representation;fuzzy associative matrix;fuzzy set operations;fuzzy control language;fuzzy control system;intelligent control	Robotics	22.495531428058563	-12.850473899172233	138893
065510ee1e07dab577d80d237e895feacd9bc251	evolving neural networks to play go	evolution methods;computer go;evolving neural networks;scaling up;game playing;approaches to learning	Go is a difficult game for computers to master, and the best go programs are still weaker than the average human player. Since the traditional game playing techniques have proven inadequate, new approaches to computer go need to be studied. This paper presents a new approach to learning to play go. The SANE (Symbiotic, Adaptive Neuro-Evolution) method was used to evolve networks capable of playing go on small boards with no pre-programmed go knowledge. On a 9 × 9 go board, networks that were able to defeat a simple computer opponent were evolved within a few hundred generations. Most significantly, the networks exhibited several aspects of general go playing, which suggests the approach could scale up well.	artificial intelligence;artificial neural network;computer go;ibm notes;neuroevolution;pattern recognition;sane;scalability;traditional game	Norman Richards;David E. Moriarty;Paul McQuesten;Risto Miikkulainen	1997	Applied Intelligence	10.1023/A:1008224732364	simulation;computer science;artificial intelligence;machine learning	AI	18.81959890337694	-19.954123414484357	139249
b5fdbacc37f1d5e1a72c292ac2107c06c7bd6d4f	learning to learn without gradient descent by gradient descent		We learn recurrent neural network optimizers trained on simple synthetic functions by gradient descent. We show that these learned optimizers exhibit a remarkable degree of transfer in that they can be used to efficiently optimize a broad range of derivative-free black-box functions, including Gaussian process bandits, simple control objectives, global optimization benchmarks and hyper-parameter tuning tasks. Up to the training horizon, the learned optimizers learn to tradeoff exploration and exploitation, and compare favourably with heavily engineered Bayesian optimization packages for hyper-parameter tuning.	algorithm;artificial neural network;bayesian optimization;black box;ethernet over twisted pair;experiment;flow network;gaussian process;global optimization;gradient descent;heuristic (computer science);hyper-heuristic;mathematical optimization;network architecture;procedural parameter;random neural network;recurrent neural network;serialization;sid meier's alpha centauri;synthetic intelligence;word lists by frequency	Yutian Chen;Matthew W. Hoffman;Sergio Gomez Colmenarejo;Misha Denil;Timothy P. Lillicrap;Matthew Botvinick;Nando de Freitas	2017			machine learning;mathematical optimization;bayesian optimization;global optimization;artificial intelligence;computer science;gradient descent;recurrent neural network;gaussian process	ML	21.162737351415657	-22.119282296583	139352
3b2dc7f4fb26130c3d88ad97e7795fe1154debba	parametric model-based anomaly detection for locomotive subsystems	locomotive subsystem;railway engineering;parametric model;locomotives;parametric statistics electromechanical systems monitoring electric variables control control systems electromechanical sensors fault detection neural networks statistical analysis support vector machines;support vector machines;neural nets;gaussian processes;anomaly detection;statistical test;reasoning module;inference mechanisms;maintenance engineering;support vector machine parametric model based anomaly detection locomotive subsystem complex electromechanical system locomotive health condition monitoring cost effective maintenance strategy neural network model reasoning module statistical testing gaussian mixture model;cost effective maintenance strategy;lead time;input output;control system;gaussian mixture model;condition monitoring;health indicator;support vector machines condition monitoring fault diagnosis gaussian processes inference mechanisms locomotives maintenance engineering neural nets railway engineering statistical testing;parametric model based anomaly detection;normal operator;complex electromechanical system;cost effectiveness;statistical testing;support vector machine;neural network model;locomotive health condition monitoring;fault diagnosis	Locomotives are complex electromechanical systems. Continuously monitoring the health state of locomotives is critical in modern cost-effective maintenance strategy. A typical locomotive is equipped with the capability to generate fault messages or incidents based on logical rules in the control system. In the mean time, sensor readings and operational state variables are also collected. The goal is to detect faults early to provide lead-time for maintenance actions and trip planning based on the collected fault log and parametric data. In this paper, we present a model-based anomaly detection strategy. In this method, the inputs-outputs relationship of a locomotive subsystem is modeled using a neural network model based on normal operational data. The residuals between measurements and model outputs are calculated. A reasoning module based on these multiple residuals is used to generate an overall health indicator of the subsystem at each instance of times, which is further used to determine whether the subsystem is abnormal. Statistical testing, Gaussian mixture model and support vector machine are used to generate this healthy index and their performances are compared. We demonstrate the effectiveness of the anomaly detection strategy using real-world operational data from locomotives.	anomaly detection;artificial neural network;control system;encode;evolutionary algorithm;failure cause;mixture model;network model;nonlinear system;parametric model;performance;predictive modelling;sampling (signal processing);scalability;semantic reasoner;support vector machine;test bench;wrapper library	Feng Xue;Weizhong Yan	2007	2007 International Joint Conference on Neural Networks	10.1109/IJCNN.2007.4371451	support vector machine;statistical hypothesis testing;computer science;machine learning;artificial neural network	ML	12.830714532205151	-14.911248389761736	139395
ce1799d7a1f8726ba14ea27f7505b281e8f6caaa	trajectory generation for redundant manipulator using virus-evolutionary genetic algorithm with subpopulations	tragectory generation;trajectory generation;redundant manipulater;evolutionary genetics;virus evolutionary genetic algorithm		genetic algorithm	Takemasa Arakawa;Toshio Fukuda;Naoyuki Kubota	1997	JACIII	10.20965/jaciii.1997.p0155	evolutionary programming;bioinformatics;genetic representation;human evolutionary genetics	Robotics	24.090662100986357	-10.262225422695654	139443
7b2582909dff50584672dc125e02aecffe727a60	from nature to maths: improving forecasting performance in subspace-based methods using genetics colonial theory	forecasting;colonial theory;nature inspired algorithm;genetics;subspace methods	Many scientific fields consider accurate and reliable forecasting methods as important decision-making tools in the modern age amidst increasing volatility and uncertainty. As such there exists an opportune demand for theoretical developments which can result in more accurate forecasts. Inspired by Colonial Theory, this paper seeks to bring about considerable improvements to the field of time series analysis and forecasting by identifying certain core characteristics of Colonial Theory which are subsequently exploited in introducing a novel approach for the grouping step of subspace based methods. The proposed algorithm shows promising results in terms of improved performances in noise filtering and forecasting of time series. The reliability and validity of the proposed algorithm is evaluated and compared with popular forecasting models with the results being thoroughly evaluated for statistical significance and thereby adding more confidence and value to the findings of this research.		Hossein Hassani;Zara Ghodsi;Emmanuel Sirimal Silva;Saeed Heravi	2016	Digital Signal Processing	10.1016/j.dsp.2016.01.002	econometrics;forecasting;computer science;artificial intelligence;machine learning;mathematics;operations research;statistics	HPC	17.368922001723547	-14.394222264991923	139529
370dc14fcf306bedbab2eb62920e571b17a6c574	transfer learning for continuous state and action spaces	continuous actions;gaussian processes;reinforcement learning;continuous states;transfer learning	Transfer learning focuses on developing methods to reuse information gathered from a source task in order to improve the learning performance in a related task. In this work, we present a novel approach to transfer knowledge between tasks in a reinforcement learning (RL) framework with continuous states and actions, where the transition and policy functions are approximated by Gaussian processes. The novelty in the proposed approach lies in the idea of transferring information about the hyper-parameters of the state transition function from the source task, which represents qualitative knowledge about the type of transition function that the target task might have, constraining the search space and accelerating the learning process. We performed experiments on relevant tasks for RL, which show a clear improvement in the overall performance when compared to state-of-the-art reinforcement learning and transfer learning algorithms for continuous state and action spaces.	approximation algorithm;bayesian approaches to brain function;bayesian programming;experiment;finite-state machine;function model;gaussian process;hyper-heuristic;machine learning;reinforcement learning;spaces;state transition table;transform, clipping, and lighting	Esteban O. Garcia;Enrique Munoz de Cote;Eduardo F. Morales	2014	IJPRAI	10.1142/S0218001414600076	temporal difference learning;semi-supervised learning;unsupervised learning;multi-task learning;instance-based learning;error-driven learning;simulation;transfer of learning;computer science;artificial intelligence;machine learning;gaussian process;inductive transfer;action learning;reinforcement learning;active learning;q-learning;statistics	AI	20.223902801499364	-21.95009340260899	139701
20166f92c41b78fc6ba6d3af5beb917c583d96b3	one-shot learning of manipulation skills with online dynamics adaptation and neural network priors	neural networks;system dynamics;computational modeling;heuristic algorithms;robots;learning artificial intelligence;adaptation models	One of the key challenges in applying reinforcement learning to complex robotic control tasks is the need to gather large amounts of experience in order to find an effective policy for the task at hand. Model-based reinforcement learning can achieve good sample efficiency, but requires the ability to learn a model of the dynamics that is good enough to learn an effective policy. In this work, we develop a model-based reinforcement learning algorithm that combines prior knowledge from previous tasks with online adaptation of the dynamics model. These two ingredients enable highly sample-efficient learning even in regimes where estimating the true dynamics is very difficult, since the online model adaptation allows the method to locally compensate for unmodeled variation in the dynamics. We encode the prior experience into a neural network dynamics model, adapt it online by progressively refitting a local linear model of the dynamics, and use model predictive control to plan under these dynamics. Our experimental results show that this approach can be used to solve a variety of complex robotic manipulation tasks in just a single attempt, using prior data from other manipulation behaviors.	algorithm;artificial neural network;encode;linear model;one-shot learning;principle of good enough;reinforcement learning;robot	Justin Fu;Sergey Levine;Pieter Abbeel	2016	2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2016.7759592	robot;simulation;computer science;artificial intelligence;machine learning;system dynamics;computational model;artificial neural network	Robotics	20.50955213156067	-20.503552702629268	139967
3a20130ad5bf2bd071a7151a84bf273a4345d6e5	latent goal analysis for dimension reduction in reinforcement learning		Reinforcement learning is a paradigm that is both very general and widely applied for interacting agents. Despite tremendous progress on both model-based and model-free algorithms, reinforcement learning does however still requires a substantial amount of manual task design. One of the major burdens for a truly autonomous operation of RL agents is the design of task-appropriate features [Kober and Peters, 2012] of state and action. These features need to be comprehensive for RL to perform effectively, yet compact in terms of dimension to perform efficiently.	algorithm;autonomous robot;dimensionality reduction;interaction;programming paradigm;rl (complexity);reinforcement learning	Matthias Rolf;Minoru Asada	2015			machine learning;artificial intelligence;reinforcement learning;dimensionality reduction;job design;pattern recognition;computer science	AI	19.604290181043275	-20.69725251565005	140093
b6eebfd0d299272c161af80e6388721bce552c68	improved long-term temperature prediction by chaining of neural networks	neural networks;system theory;nonlinear;stability;system identification;time series analysis;non linear;sista;neural network	When an artificial neural network (ANN) is trained to predict signals p steps ahead, the quality of the prediction typically decreases for large values of p. In this paper, we compare two methods for prediction with ANNs: the classical recursion of one-step ahead predictors and a new kind of chain structure. When applying both techniques to the prediction of the temperature at the end of a blast furnace, we conclude that the chaining approach leads to an improved prediction of the temperature and avoidance of instabilities, since the chained networks gradually take the prediction of their predecessors in the chain as an extra input. It is observed that instabilities might occur in the iterative case, which does not happen with the chaining approach. To select relevant inputs and decrease the number of weights in this approach, Automatic Relevance Determination (ARD) for multilayer perceptrons is applied.		Michel Duhoux;Johan A. K. Suykens;Bart De Moor;Joos Vandewalle	2001	International journal of neural systems	10.1142/S012906570100045X	stability;system identification;nonlinear system;computer science;artificial intelligence;machine learning;time series;data mining;systems theory;artificial neural network	ML	10.67514186745507	-21.596331586483398	140147
55e50ce0291e9e38b6777348f63e51daf8345b33	sampling frequency influence at fault locations using algorithms based on artificial neural networks	neural nets;signal sampling;power transmission faults;voltage 230 kv fault locations sampling frequency evaluation chained artificial neural network structure alternative transient program software atp software ann validation ann testing ann training phase quantities zero sequence voltage current waveform data fault condition simulation transmission line standard format file batch mode fault type classification digital fault recorders;program verification;oscillographs;power engineering computing;program testing;signal sampling fault location learning artificial intelligence neural nets oscillographs power engineering computing power transmission faults power transmission lines program testing program verification;fault location digital fault recorders sampling frequency;learning artificial intelligence;power transmission lines;artificial neural networks fault location databases training power transmission lines;fault location	A sampling frequency evaluation used in digital fault recorders for fault locations was implemented. A chained structure of artificial neural networks (ANN) was adopted to locate the faults. The ATP (Alternative Transient Program) software was used in the building of the database for training, testing and validation of the ANN, with different sampling frequencies. The input to the ANN are phase quantities and zero sequence voltage and current waveform data. The fault conditions were simulated for a 230 kV transmission line. The database used was generated automatically from a standard format file, and run in batch mode. For the fault location, the transmission line was divided into 8 zones. Previous to location, classification of the fault type is performed by training the ANN with the full line data. For the location, eight ANN were trained for each fault type, each one with the data of each zone.	algorithm;artificial neural network;batch processing;database;sampling (signal processing);transmission line;vii;waveform	J. A. C. B. Silva;Kleber Melo Silva;W. L. A. Neves;Benemar Alencar Souza;Flavio Bezerra Costa	2012	2012 Fourth World Congress on Nature and Biologically Inspired Computing (NaBIC)	10.1109/NaBIC.2012.6402233	embedded system;real-time computing;fault coverage;fault indicator;computer science;artificial intelligence;stuck-at fault;machine learning;electric power transmission;artificial neural network	DB	10.810364225681383	-16.870816878876944	140259
f6039c770b07ebc2153ca906df65926bff244731	the potential application of particle swarm optimization algorithm for forecasting the air-overpressure induced by mine blasting		In tunneling projects and open-pit mines, drilling and blasting is a common method for fragmenting the rock masses. Although fragmentation is the main aim of blasting, the adverse effects such as air-overpressure (AOp) and ground vibration are unavoidable. Among these unwanted effects, AOp is considered as one of the most important effects which can cause damage to nearby structures. Therefore, precise estimation of AOp is required for minimizing the environmental problems. This article proposes three new models for predicting blast-induced AOp at Shur river dam area, Iran, optimized by particle swarm optimization (PSO). For this aim, 80 blasting events were investigated and the requirement parameters such as maximum charge per delay, distance from the blast-face and rock mass rating were measured. To evaluate the acceptability and reliability of the proposed PSO models, artificial neural network (ANN) has also been performed. After modeling, the capability of the constructed predictors has been evaluated using the statistical criteria such as coefficient of determination (R 2) and mean square error (MSE). Eventually, it was found that the PSO-linear model (with R 2 = 0.960 and MSE = 4.33) possessed superior predictive ability than the PSO-power model (with R 2 = 0.923 and MSE = 8.89), PSO-quadratic model (with R 2 = 0.926 and MSE = 10.14), ANN model (with R 2 = 0.897 and MSE = 9.98) and USBM model (with R 2 = 0.872 and MSE = 16.28).	adobe air;algorithm;artificial neural network;blast;coefficient of determination;d programming language;fragmentation (computing);ip fragmentation;linear model;mathematical optimization;mean squared error;michael shur;particle swarm optimization;phase-shift oscillator;quadratic equation;quadratic function;tunneling protocol	Amir AminShokravi;Hajar Eskandar;Ali Mahmodi Derakhsh;Hima Nikafshan Rad;Ali Ghanadi	2017	Engineering with Computers	10.1007/s00366-017-0539-5	artificial neural network;rock mass rating;mathematics;mathematical optimization;rock blasting;coefficient of determination;drilling and blasting;mean squared error;particle swarm optimization	AI	11.385924517611189	-19.3468130915814	140307
b614bddcc2775e360e6903741f6c0850c6731128	matrix-based system reliability method and applications to bridge networks	bayes estimation;transportation network;transportation networks;fragility curve;system reliability;fiabilite systeme;red transporte;sismo;fonction masse;analisis estadistico;probabilidad condicional;modelo determinista;informacion incompleta;importance measure;seisme;funcion masa;probabilite conditionnelle;bridges;bridge network;sistema complejo;modele deterministe;probabilistic approach;earthquakes;bayesian method;sistema reactivo;fiabilidad sistema;reliability bounds;incomplete information;methode matricielle;graph connectivity;systeme incertain;estimacion bayes;structure reseau;programacion lineal;statistical analysis;systeme complexe;complex system;enfoque probabilista;approche probabiliste;puente;analyse statistique;conectividad grafo;information incomplete;matrix method;connectivity analysis;pont;mass function;linear programming;reactive system;metodo matriz;systeme reactif;programmation lineaire;linear program;modele donnee;probability mass function;network structure;sistema incierto;deterministic model;conditional probability;connectivite graphe;uncertain system;failure probability;data models;estimation bayes;reseau transport	Using a matrix-based system reliability (MSR) method, one can estimate the probabilities of complex system events by simple matrix calculations. Unlike existing system reliability methods whose complexity depends highly on that of the system event, the MSR method describes any general system event in a simple matrix form and therefore provides a more convenient way of handling the system event and estimating its probability. Even in the case where one has incomplete information on the component probabilities and/or the statistical dependence thereof, the matrix-based framework enables us to estimate the narrowest bounds on the system failure probability by linear programming. This paper presents the MSR method and applies it to a transportation network consisting of bridge structures. The seismic failure probabilities of bridges are estimated by use of the predictive fragility curves developed by a Bayesian methodology based on experimental data and existing deterministic models of the seismic capacity and demand. Using the MSR method, the probability of disconnection between each city/county and a critical facility is estimated. The probability mass function of the number of failed bridges is computed as well. In order to quantify the relative importance of bridges, the MSR method is used to compute the conditional probabilities of bridge failures given that there is at least one city disconnected from the critical facility. The bounds on the probability of disconnection are also obtained for cases with incomplete information. r 2008 Elsevier Ltd. All rights reserved.	bridging (networking);complex system;failure cause;linear programming;the matrix	Won-Hee Kang;Junho Song;Paolo Gardoni	2008	Rel. Eng. & Sys. Safety	10.1016/j.ress.2008.02.011	matrix method;data modeling;probability mass function;conditional probability;bridging;bayesian probability;fragility;reactive system;linear programming;connectivity;deterministic system;mathematics;complete information;algorithm;statistics	AI	13.606346991346577	-10.116380353004743	140476
0750b115d73b5447ab5af8a8789a5db692b80f01	using racing to automatically configure algorithms for scaling performance		Automated algorithm configuration has been proven to be an effective approach for achieving improved performance of solvers for many computationally hard problems. Following our previous work, we consider the challenging situation where the kind of problem instances for which we desire optimised performance are too difficult to be used during the configuration process. In this work, we propose a novel combination of racing techniques with existing algorithm configurators to meet this challenge. We demonstrate that the resulting algorithm configuration protocol achieves better results than previous approaches and in many cases closely matches the bound on performance obtained using an oracle selector. An extended version of this paper can be found at www.cs.ubc.ca/labs/beta/Projects/Config4Scaling.	algorithm;local search (optimization);resampling (statistics);sid meier's alpha centauri;ti-nspire series;test engineer	James Styles;Holger H. Hoos	2013		10.1007/978-3-642-44973-4_41	mathematical optimization;simulation;computer science;artificial intelligence;machine learning;algorithm	AI	20.149901460483733	-10.862534446936488	140528
2cbf724c64348d4b494b4a6789d98bd0fcf9d753	log-linear dialog manager	dialog manager log linear model pomdp;production planning grammar belief propagation probabilistic logic optimization probability distribution;pomdp log linear dialog manager log linear probabilistic model dialog management task full policy optimization online estimation belief propagation inference particle belief propagation rule based system partially observable markov decision process;speech processing belief maintenance inference mechanisms knowledge based systems markov processes	We design a log-linear probabilistic model for solving the dialog management task. In both planning and learning we optimize the same objective function: the expected reward. Rather than performing full policy optimization, we perform on-line estimation of the optimal action as a belief-propagation inference step. We employ context-free grammars to describe our variable spaces, which enables us to define rich features. To scale our approach to large variable spaces, we use particle belief propagation. Experiments show that the model is able to choose system actions that yield a high expected reward, outperforming its POMDP-like log-linear counterpart and a hand-crafted rule-based system.	belief propagation;context-free grammar;context-free language;dialog manager;experiment;log-linear model;loss function;mathematical optimization;online and offline;optimization problem;partially observable markov decision process;rule-based system;software propagation;statistical model	Hao Tang;Shinji Watanabe;Tim K. Marks;John R. Hershey	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6854371	computer science;machine learning;pattern recognition;data mining	Robotics	21.572637886915057	-17.928509973725305	140779
ccedd98390487ac8a3c0927b3b9bf1dd5eebf3c1	the repetitive optimization design strategy using neural network and hybrid algorithm	levenberg marquardt;feedforward neural networks;feed forward;response surface methodology;evolutionary computation;aerospace engineering;neural networks;design engineering;robust evolutionary search;bayes methods;bayesian methods;backpropagation levenberg marquardt algorithm;backpropagation;design optimization;design space;missiles;feedforward artificial neural networks;artificial neural networks;air intercept missile aim optimization design;metamodel;repetitive optimization design strategy;aerospace computing;bayesian learning;missiles aerospace computing backpropagation bayes methods evolutionary computation feedforward neural nets genetic algorithms gradient methods;local gradient based method;air intercept missile aim design optimization problem;optimal design;gradient methods;air intercept missile aim design optimization problem repetitive optimization design strategy neural network hybrid algorithm bayesian learning technique feedforward artificial neural networks backpropagation levenberg marquardt algorithm metamodel genetic algorithm local gradient based method robust evolutionary search;local search method;genetic algorithm;genetic algorithms;feedforward neural nets;optimization design;bayesian learning technique;artificial neural network ann;local search;back propagation;air intercept missile aim optimization design optimization design artificial neural network ann genetic algorithm ga local search method;algorithm design and analysis;hybrid algorithm;meta model;artificial neural network;genetic algorithm ga;neural network	In this paper, a Bayesian learning technique, mapped into feed-forward artificial neural networks, is considered as a system approximation, which, for training, highly non-linear and implicit complex functions. This process is integrated with a hybrid algorithm (HA) in the proposed design optimization strategy. The combination of the back-propagation Levenberg-Marquardt (BPLM) algorithm and the Bayesian learning technique shows good and accurate generalization, which creates the meta-model, considered as the fitness and constraints function in the hybrid algorithm. Here, a genetic algorithm (GA), hybridized with a local gradient-based method, performs the effective and robust evolutionary search and reduces the computation cost. D-optimality is used to select the appropriate points in the design space, to obtain the significant responses. A numerical example, the design of a two-member frame and air intercept missile-AIM design optimization problem are presented to demonstrate the accuracy and feasibility of the process.	aim alliance;approximation;artificial neural network;backpropagation;complex systems;computation;genetic algorithm;gradient;hybrid algorithm;levenberg–marquardt algorithm;linear function;mathematical optimization;metamodeling;nonlinear system;numerical analysis;optimization problem;response surface methodology;software propagation;software release life cycle;time complexity;visual intercept	Nhu-Van Nguyen;Kwon-Su Jeon;Jae-Woo Lee;Yung-Hwan Byun	2008	2008 IEEE International Conference on Research, Innovation and Vision for the Future in Computing and Communication Technologies	10.1109/RIVF.2008.4586331	algorithm design;mathematical optimization;meta-optimization;wake-sleep algorithm;engineering;artificial intelligence;machine learning;population-based incremental learning	Robotics	14.428312155755677	-23.433743569595112	140850
4ad8de93bbda83533cee65eba58480f390afc418	hybrid self-adaptive learning based particle swarm optimization and support vector regression model for grade estimation	ore grade estimation;support vector regression;self adaptive learning based particle swarm optimization	Ore grade estimation is one of the key stages and the most complicated aspects in mining. Its complexity originates from scientific uncertainty. In this paper, a novel hybrid SLPSO–SVR model that hybridized the self-adaptive learning based particle swarm optimization (SLPSO) and support vector regression (SVR) is proposed for ore grade estimation. This hybrid SLPSO–SVR model searches for SVR's optimal parameters parameters to construct the SVR models. The SVR uses the ‘Max-Margin’ idea to search for an optimum hyperplane, and adopts the ε-insensitive loss function for minimizing the training error between the training data and identified function. The hybrid SLPSO–SVR grade estimation method has been tested on a number of real ore deposits. The result shows that method has advantages of rapid training, generality and accuracy grade estimation approach. It can provide with a very fast and robust alternative to the existing time-consuming methodologies for ore grade estimation. Crown Copyright & 2013 Published by Elsevier B.V. All rights reserved.	complexity;crown group;loss function;mathematical optimization;particle swarm optimization;support vector machine	Xiaoli Li;Li-hong Li;Bao-lin Zhang;Qianjin Guo	2013	Neurocomputing	10.1016/j.neucom.2013.03.002	support vector machine;mathematical optimization;multi-swarm optimization;computer science;artificial intelligence;machine learning	AI	12.240277062388198	-21.834043831462015	140899
a6248c2ad19dea859621064c4959af38534fd3d1	switching q-learning in partially observable markovian environments	automatic control;observability;hierarchical structure;hierarchical structure learning automaton reinforcement learning sq learning memoryless system partially observable environments;learning;communication switching educational institutions communications technology observability state estimation automatic control embedded computing learning autonomous agents service robots;reinforcement learning;hierarchical systems;service robots;partially observable environments;optimal policy;learning automata;state estimation;learning systems;sq learning;hierarchical structure learning automaton;memoryless systems learning artificial intelligence learning systems learning automata hierarchical systems;communications technology;partial observation;communication switching;learning artificial intelligence;autonomous agents;memoryless systems;memoryless system;embedded computing	"""Recent research on hidden-state reinforcement learning (RL) problems has been concentrated in overcoming partial observability by using memory to estimate states. Switching Q-learning (SQ-learning) is a novel memoryless approach for RL in partially observable environments. The basic idea of SQ-learning is that """"non-Markovian"""" tasks can be automatically decomposed into subtasks solvable by memoryless policies, without any other information leading to """"good"""" subgoals. To deal with such decomposition, SQ-learning employs ordered sequences of Q-modules in which each module discovers a local control policy. Furthermore, a hierarchical structure learning automaton is used which finds appropriate subgoal sequences. We apply SQ-learning to three partially observable maze problems. The results of extensive simulations demonstrate that SQ-learning has the ability to quickly learn optimal or near-optimal policies without huge computational burden."""	partially observable system;q-learning	Hiroyuki Kamaya;Haeyeon Lee;Kenichi Abe	2000		10.1109/IROS.2000.893160	information and communications technology;observability;simulation;computer science;artificial intelligence;autonomous agent;machine learning;automatic control;control theory;system analysis;reinforcement learning	Robotics	19.486412404292093	-19.210314708075295	141149
a7e9b58d73d9d7135dcc240a08021af7af20c0cf	multiagent coordination by extended markov tracking	multiagent system;markovian environment;system dynamics;information transfer;control architecture;planning;control;multiagent systems;coordination;extended markov tracking	We present here Extended Markov Tracking (EMT), a computationally tractable method for the online estimation of Markovian system dynamics, along with experimental support for its successful contribution to a specific control architecture. The control architecture leverages EMT to simultaneously track and correct system dynamics.Using a widespread extension of the Markovian environment model to multiagent systems, we provide an application of EMT-based control to multiagent coordination. The resulting coordinated action algorithm, in contrast to alternative approaches, does not eliminate interference among agents, but rather exploits it for purposes of synchronization and implicit information transfer. This information transfer enables the algorithm to be computationally tractable. Experiments are presented that demonstrate the effectiveness of EMT-based control for multiagent coordination in stochastic environments.	agent-based model;algorithm;cobham's thesis;interference (communication);markov chain;multi-agent system;system dynamics	Zinovi Rabinovich;Jeffrey S. Rosenschein	2005		10.1145/1082473.1082539	planning;simulation;information transfer;computer science;artificial intelligence;multi-agent system;distributed computing;system dynamics;scientific control	AI	18.06444024790043	-15.94122593882099	141255
485571f237e9e836e9b957333b3b15b7a031d31c	design of online soft sensors based on combined adaptive pca and rbf neural networks	chemical process monitoring;distillation columns;chemical process control;sensors;nonlinear distillation column benchmark problem online soft sensors adaptive principal component analysis rbf neural networks chemical process monitoring chemical process control time delay radial basis functions artificial neural network inherent feature extraction;benchmark problem;sensors delays distillation equipment feature extraction neurocontrollers principal component analysis radial basis function networks;rbf neural networks;data mining;time delay;neural network soft sensor industrial distillation column pca;inherent feature extraction;radial basis function networks;soft sensor;artificial neural networks;radial basis function;monitoring;adaptive systems;adaptive principal component analysis;feature extraction;rbf neural network;principal component analysis;principal component analysis neural networks chemical sensors artificial neural networks feature extraction monitoring process control chemical processes costs testing;online soft sensors;neurocontrollers;distillation equipment;high dimension;pca;radial basis functions artificial neural network;sliding window;delays;artificial neural network;industrial distillation column;neural network;nonlinear distillation column benchmark problem	An accurate on-line measurement of important quality variables is essential for successful monitoring and controlling of chemical processes. However, these variables are usually difficult to measure on-line due to the practical limitations such as the time-delay, high cost and reliability considerations. To overcome this problem, two online soft sensors are proposed based upon a combined adaptive principal component analysis (PCA) and a radial basis functions (RBF) artificial neural network. For this purpose, a recursive PCA and a PCA based on a sliding window scheme are presented to adaptively extract the inherent features inside the measurements with high dimensions. The extracted low-dimension features are then used recursively as the main inputs to the RBF neural network. The developed online soft sensors are finally tested on a highly nonlinear distillation column benchmark problem to illustrate their effective performances. The simulation results demonstrate the superiority of the proposed soft sensor based on the combined recursive PCA and the RBF neural network.	artificial neural network;benchmark (computing);nonlinear system;online and offline;performance;principal component analysis;radial (radio);radial basis function;recursion;sensor;simulation	Karim Salahshoor;Mojtaba Kordestani;Majid Soleimani Khoshro	2009	2009 IEEE Symposium on Computational Intelligence in Control and Automation	10.1109/CICA.2009.4982788	control engineering;engineering;artificial intelligence;machine learning	AI	13.058719869118477	-21.674530851726256	141342
cc0385f0194907cf5209fcfdff3ff8f70147a513	probabilistic long-term prediction for autonomous vehicles		Long-term prediction of traffic participants is crucial to enable autonomous driving on public roads. The quality of the prediction directly affects the frequency of trajectory planning. With a poor estimation of the future development, more computational effort has to be put in re-planning, and a safe vehicle state at the end of the planning horizon is not guaranteed. A holistic probabilistic prediction, considering inputs, results and parameters as random variables, highly reduces the problem. A time frame of several seconds requires a probabilistic description of the scene evolution, where uncertainty or accuracy is represented by the trajectory distribution. Following this strategy, a novel evaluation method is needed, coping with the fact, that the future evolution of a scene is also uncertain. We present a method to evaluate the probabilistic prediction of real traffic scenes with varying start conditions. The proposed prediction is based on a particle filter, estimating behavior describing parameters of a microscopic traffic model. Experiments on real traffic data with random leading vehicles show the applicability in terms of convergence, enabling long-term prediction using forward propagation.		Stefan Hörmann;Daniel Stumper;Klaus C. J. Dietmayer	2017	2017 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2017.7995726	control engineering;automotive engineering	Robotics	10.515749483603264	-11.863470423816048	141694
bef82a442d5ce9bd920c22f44313e5f360d6b667	an integrated health management process for automotive cyber-physical systems	automotive cyber physical systems;regenerative braking automotive electronics embedded systems energy storage fault diagnosis hybrid electric vehicles;fault modeling;test design automotive cyber physical systems fault diagnosis and prognosis fault modeling inference algorithms;circuit faults automotive engineering vehicles fault diagnosis software sensors feature extraction;fault diagnosis and prognosis;inference algorithms;epgs integrated health management process automotive cyber physical systems distributed cyber physical systems automotive vehicles failure modes advanced diagnosis prognosis technology fault detection fault isolation network embedded automotive systems vehicle availability regenerative braking system hybrid electric vehicles electric power generation and storage system;test design	Automobile is one of the most widely distributed cyber-physical systems. Over the last few years, the electronic explosion in automotive vehicles has significantly increased the complexity, heterogeneity and interconnectedness of embedded systems. Although designed to sustain long life, systems degrade in performance due to gradual development of anomalies eventually leading to faults. In addition, system usage and operating conditions (e.g., weather, road surfaces, and environment) may lead to different failure modes that can affect the performance of vehicles. Advanced diagnosis and prognosis technologies are needed to quickly detect and isolate faults in network-embedded automotive systems so that proactive corrective maintenance actions can be taken to avoid failures and improve vehicle availability. This paper discusses an integrated diagnostic and prognostic framework, and applies it to two automotive systems, viz., a Regenerative Braking System (RBS) in hybrid electric vehicles and an Electric Power Generation and Storage (EPGS) system.	.net framework;algorithm;cyber-physical system;elegant degradation;embedded system;failure cause;fault tolerance;interconnectedness;online and offline;viz: the computer game	Chaitanya Sankavaram;Anuradha Kodali;Krishna R. Pattipati	2013	2013 International Conference on Computing, Networking and Communications (ICNC)	10.1109/ICCNC.2013.6504058	control engineering;embedded system;engineering;automotive engineering	Embedded	12.776756649294441	-13.070002063163779	141701
4f870ed2a6da19d8bdea4a8a751e8f218aeedc79	software reliability prediction using multi-objective genetic algorithm	software;software reliability genetic algorithms software systems predictive models reliability engineering software testing uncertainty computational intelligence parameter estimation stochastic processes;software testing;optimization technique;articulo;software reliability prediction using multi objective genetic algorithm;multi objective genetic algorithm;multiple objectives;software reliability prediction;program testing;machine learning;software development;software reliability genetic algorithms learning artificial intelligence parameter estimation program testing;mathematical model;multiple model;genetic algorithm;predictive models;genetic algorithms;optimization;parameter estimation;learning artificial intelligence;software reliability;parameter estimation software reliability prediction multiobjective genetic algorithm probability estimation software fail software development software testing machine learning optimization;software fail;growth model;probability estimation;gallium;data models;multiobjective genetic algorithm	Software reliability models are very useful to estimate the probability of the software fail along the time. Several different models have been proposed to predict the software reliability growth (SRGM); however, none of them has proven to perform well considering different project characteristics. The ability to predict the number of faults in the software during development and testing processes. In this paper, we explore Genetic Algorithms (GA) as an alternative approach to derive these models. GA is a powerful machine learning technique and optimization techniques to estimate the parameters of well known reliably growth models. Moreover, machine learning algorithms, proposed the solution overcome the uncertainties in the modeling by combining multiple models using multiple objective function to achieve the best generalization performance where. The objectives are conflicting and no design exists which can be considered best with respect to all objectives. In this paper, experiments were conducted to confirm these hypotheses. Then evaluating the predictive capability of the ensemble of models optimized using multi-objective GA has been calculated. Finally, the results were compared with traditional models.	experiment;genetic algorithm;list of software reliability models;loss function;machine learning;mathematical optimization;optimization problem;software quality;software release life cycle;software reliability testing	Sultan H. Aljahdali;Mohammed E. El-Telbany	2009	2009 IEEE/ACS International Conference on Computer Systems and Applications	10.1109/AICCSA.2009.5069339	genetic algorithm;computer science;machine learning;data mining	SE	16.139524073310493	-14.82826365040851	141784
e69f3d2a104bfb1ea56b22bc0b432dd3801d43d5	a robust, distributed task allocation algorithm for time-critical, multi agent systems operating in uncertain environments	robustness to uncertainty;auction based scheduling;meetings and proceedings;conference contribution;multi agent systems;distributed task allocation	The aim of this work is to produce and test a robust, distributed, multi-agent task allocation algorithm, as these are scarce and not well-documented in the literature. The vehicle used to create the robust system is the Performance Impact algorithm (PI), as it has previously shown good performance. Three different variants of PI are designed to improve its robustness, each using Monte Carlo sampling to approximate Gaussian distributions. Variant A uses the expected value of the task completion times, variant B uses the worst-case scenario metric and variant C is a hybrid that implements a combination of these. The paper shows that, in simulated trials, baseline PI does not handle uncertainty well; the task-allocation success rate tends to decrease linearly as degree of uncertainty increases. Variant B demonstrates a worse performance and variant A improves the failure rate only slightly. However, in comparison, the hybrid variant C exhibits a very low failure rate, even under high uncertainty. Furthermore, it demonstrates a significantly better mean objective function value than the baseline.		Amanda Whitbrook;Qinggang Meng;Paul W. H. Chung	2017		10.1007/978-3-319-60045-1_8	robustness (computer science);expected value;pi;failure rate;monte carlo method;distributed computing;multi-agent system;computer science;algorithm;gaussian	AI	22.16827897549127	-14.136063686737888	142250
b08dd315594cd69e35621d3b0cf150fe9ba39ab1	accurate ambient noise assessment using smartphones	crowdsensing;dynamic range;smartphone;noise sensing	Nowadays, smartphones have become ubiquitous and one of the main communication resources for human beings. Their widespread adoption was due to the huge technological progress and to the development of multiple useful applications. Their characteristics have also experienced a substantial improvement as they now integrate multiple sensors able to convert the smartphone into a flexible and multi-purpose sensing unit. The combined use of multiple smartphones endowed with several types of sensors gives the possibility to monitor a certain area with fine spatial and temporal granularity, a procedure typically known as crowdsensing. In this paper, we propose using smartphones as environmental noise-sensing units. For this purpose, we focus our study on the sound capture and processing procedure, analyzing the impact of different noise calculation algorithms, as well as in determining their accuracy when compared to a professional noise measurement unit. We analyze different candidate algorithms using different types of smartphones, and we study the most adequate time period and sampling strategy to optimize the data-gathering process. In addition, we perform an experimental study comparing our approach with the results obtained using a professional device. Experimental results show that, if the smartphone application is well tuned, it is possible to measure noise levels with a accuracy degree comparable to professional devices for the entire dynamic range typically supported by microphones embedded in smartphones, i.e., 35-95 dB.	algorithm;best practice;block size (cryptography);buffers;crowdsensing;dynamic range;embedded system;embedding;experiment;global positioning system;linear iga bullous dermatosis;map;microphone device component;mobile app;mobile phone;multi-purpose viewer;noise (electronics);numerous;overhead (computing);sampling (signal processing);sampling - surgical action;smartphone;the sims;accelerometers;sensor (device)	Willian Zamora;Carlos Miguel Tavares Calafate;Juan-Carlos Cano;Pietro Manzoni	2017		10.3390/s17040917	embedded system;dynamic range;real-time computing;simulation;computer science;engineering	HCI	16.70634869046619	-11.386528848636988	142433
408b41ff98c07daeca71dcf2c9830f8f9c341add	modeling hardness of nb-microalloyed steels using fuzzy logic	fuzzy logic;microalloyed steel;low carbon nb steel;continuous cooling	The paper presents some results of the research connected with the development of new approach based on the fuzzy logic of predicting the Vickers microhardness of the phase constituents occurring in five steels after continuous cooling. The independent variables in the model are chemical compositions, initial austenite grain size, and cooling rate over the temperature range of the occurrence of phase transformations. For purpose of constructing these models, 114 different experimental data were gathered from the literature. The data used in the fuzzy logic model are arranged in a format of twelve input parameters that cover the chemical compositions, initial austenite grain size, and cooling rate, and output parameter which is Vickers microhardness. In this model, the training and testing results in the fuzzy logic systems have shown strong potential for prediction of effects of chemical compositions and heat treatments on hardness of microalloyed steels.	computer cooling;formal system;fuzzy logic;luc steels;parameter (computer programming);vickers range clock;whole earth 'lectronic link	Gholamreza Khalaj;Hossein Yoozbashizadeh;Alireza Khodabandeh;Ali Nazari	2011	Neural Computing and Applications	10.1007/s00521-011-0802-4	fuzzy logic;computer science	AI	12.311343816791688	-19.698911663835904	142436
401691bfe933f111c96a41ba8fdde94ded096283	probably approximately correct (pac) exploration in reinforcement learning		OF THE DISSERTATION Probably Approximately Correct (PAC) Exploration in Reinforcement Learning by Alexander L. Strehl Dissertation Director: Michael Littman Reinforcement Learning (RL) in finite state and action Markov Decision Processes is studied with an emphasis on the well-studied exploration problem. We provide a general RL framework that applies to all results in this thesis and to other results in RL that generalize the finite MDP assumption. We present two new versions of the Model-Based Interval Estimation (MBIE) algorithm and prove that they are both PAC-MDP. These algorithms are provably more efficient any than previously studied RL algorithms. We prove that many model-based algorithms (including R-MAX and MBIE) can be modified so that their worst-case per-step computational complexity is vastly improved without sacrificing their attractive theoretical guarantees. We show that it is possible to obtain PAC-MDP bounds with a model-free algorithm called Delayed Q-learning.	algorithm;best, worst and average case;computation;computational complexity theory;exploration problem;markov chain;markov decision process;max;probably approximately correct learning;q-learning;reinforcement learning;whole earth 'lectronic link	Alexander L. Strehl	2008			markov decision process;mathematical optimization;computer science;artificial intelligence;machine learning;probably approximately correct learning;q-learning	ML	21.895376012633882	-17.503069681693223	142568
9dd57e0bc6c7a980b43a50ef0f69f679cc259b62	wind speed extrapolation using machine learning methods and lidar measurements		Accurate wind energy assessments require wind speed (WS) at the hub height. The cost of WS measurements grows enormously with height. This paper utilizes deep neural network (DNN) algorithm for the extrapolation of the WS to higher heights based on measured values at lower heights. LiDAR measurements at lower heights are used for training the system and at higher heights for performance analysis. These measurements are made at 10,  $20,\ldots $ , and 120 m heights. First, the measured WS values at 10–40 m were used to extrapolate values up to 120 m. In the second scenario, the WS at 10–50 m were used to extrapolate values up to 120 m. This continued until the last scenario, in which the WS at 10–100 m were used to estimate values at 110 and 120 m. A relationship between heights of measurements and the accuracy of the WS estimation at hub height is presented. The WS extrapolated using the present approach is compared with the measured values and with local wind shear exponent (LWSE)-based extrapolated WS. Furthermore, to analyze the performance of the DNN relative to other machine learning methods, we compared its performance with that of classical feedforward artificial neural networks trained using a genetic algorithm to find the initial weights and the Levemberg–Marquardt (LM) method (GANN) for training. The mean absolute percent error between measured and extrapolated WS at height 120 m based on measurements between 10–50 m using DNN, GANN, and LWSE are 9.65%, 12.77%, and 9.79%, respectively.		Mohamed A. Mohandes;Sakhi Rehman	2018	IEEE Access	10.1109/ACCESS.2018.2883677	wind power;extrapolation;artificial neural network;wind speed;computer science;machine learning;mean absolute percentage error;wind shear;lidar;artificial intelligence	ML	10.583509528209483	-19.423018714552196	142746
e795a373fd3cc8537a518709d9ba43e1638f3c30	making right decisions based on wrong opinions		We revisit the classic problem of designing voting rules that aggregate objective opinions, in a setting where voters have noisy estimates of a true ranking of the alternatives. Previous work has replaced structural assumptions on the noise with a worst-case approach that aims to choose an outcome that minimizes the maximum error with respect to any feasible true ranking. This approach underlies algorithms that have recently been deployed on the social choice website RoboVote.org. We take a less conservative viewpoint by minimizing the average error with respect to the set of feasible ground truth rankings. We derive (mostly sharp) analytical bounds on the expected error and establish the practical benefits of our approach through experiments.	aggregate data;algorithm;best, worst and average case;experiment;ground truth;worst-case complexity	Gerdus Benade;Anson Kahng;Ariel D. Procaccia	2017		10.1145/3033274.3085108	mathematical optimization;voting;ground truth;computational social choice;management science;mathematics;welfare economics;social choice theory;ranking	ECom	17.39037228079889	-15.289712152474712	142830
45a2f064fd263bb7df22bed25ef1cdde4014cd41	processus décisionnels de markov décomposés et factorisés pour l'optimisation de stratégies d'exploration	navegacion;dynamic programming;planning technique;optimisation;matrix factorization;programacion dinamica;tecnica planeamiento;decomposition;optimizacion;proceso markov;autonomous system;espace etat;decision markov;programmation stochastique;robotics;probabilistic approach;sistema autonomo;factorisation matricielle;factorization;navigation;systeme incertain;planificacion;dynamic programming markov decisional processes;state space method;methode espace etat;enfoque probabilista;approche probabiliste;processus markov;state space;systeme autonome;programmation dynamique;markov process;robotica;planning;markov decision;optimization;robotique;stochastic planning;planification;espacio estado;stochastic programming;sistema incierto;factorizacion matricial;autonomous robotics;uncertain system;programacion estocastica;metodo espacio estado;technique planning	Autonomous exploration systems require planning under uncertainty. Markov Decision Processes provide a classical framework based on an enumerated and unstructured state space representation. Recent works propose more compact and structured approaches in probabilistic planning. We present and discuss factorization techniques using state variables, and then decomposition techniques using sub-regions. A novel hybrid approach combining both is proposed that is well-fitted to probabilistic exploration-like planning: we use decomposition techniques to generate navigation local policies that are then included in a factored MDP. We discuss results obtained on the basis of probabilistic exploration-like planning problems.	markov chain	Florent Teichteil-Königsbuch;Patrick Fabiani	2006	Revue d'Intelligence Artificielle	10.3166/ria.20.133-180	planning;stochastic programming;navigation;state space;autonomous system;artificial intelligence;dynamic programming;calculus;mathematics;markov process;decomposition;robotics;matrix decomposition;factorization;algorithm	Logic	23.302602242562262	-14.47723180119092	142879
a22fc113e41ec81029141cf61068d39a6888c66b	reliability assessment of automated substation and functional integration	reliability;functional integration;substation automation;event tree	Due to importance of control functions in high voltage substations as the nodes entering into the industrial power system, this paper investigate a comprehensive technique to quantitatively evaluate the reliability of automation system in substations. This approach is based on reduced event tree methodology. The method has been tested extensively by applying to different substation automation configurations. Furthermore, the model of functions which are involved in operation of breaker and disconnector are discussed and the proposed method is employed to quantitatively assess the effects of functional integration in the bay level. The results validate that well judged integration can lead to better reliability achievement and cost reduction.	control function (econometrics);event tree;functional integration;traction substation	Farshid Salehi;Azade Brahman;Reza Keypour;Wei-Jen Lee	2016	2016 IEEE Industry Applications Society Annual Meeting	10.1109/IAS.2016.7731952	reliability engineering;electronic engineering;systems engineering;engineering	EDA	12.535866551924176	-11.99245673998344	142894
ddbe1e4ff00ad1c6bf6d51d713390258dd9fc8b7	electromechanical equipment state forecasting based on genetic algorithm - support vector regression	support vector regression;forecasting model;gas turbine;industrial smokes and gas turbine;electromechanical equipments;genetic algorithm;support vector machine;prediction	Prediction of electromechanical equipments state nonlinear and non-stationary condition effectively is significant to forecast the lifetime of electromechanical equipments. In order to forecast electromechanical equipments state exactly, support vector regression optimized by genetic algorithm is proposed to forecast electromechanical equipments state. In the model, genetic algorithm is employed to choose the training parameters of support vector machine, and the SVR forecasting model of electromechanical equipments state with good forecasting ability is obtained. The proposed forecasting model is applied to the state forecasting for industrial smokes and gas turbine. The experimental results demonstrate that the proposed GA-SVR model provides better prediction capability. Therefore, the method is considered as a promising alternative method for forecasting electromechanical equipments state.	genetic algorithm;support vector machine	Ji Huang;Yucheng Bo;Huiyuan Wang	2011	Expert Syst. Appl.	10.1016/j.eswa.2011.01.033	support vector machine;simulation;computer science;machine learning	ML	12.592757744400547	-18.07076960678752	143022
6b8b4071c5d261fe5e57443ba65f9fdcc22cffee	stochastic planning in large search spaces		Multi-agent planning approaches are employed for many problems including task allocation, surveillance and video games. In the first part of my thesis, we study two multi-robot planning problems, i.e. patrolling and task allocation. For the patrolling problem, we present a novel stochastic search technique, Monte Carlo Tree Search with Useful Cycles, that can generate optimal cyclic patrol policies with theoretical convergence guarantees. For the multi-robot task allocation problem, we propose an Monte Carlo Tree Search based satisficing method using branch and bound paradigm along with a novel search parallelization technique. In the second part of my thesis, we develop a stochastic multi-agent narrative planner employing MCTS along with new heuristic and pruning methods applicable for other planning domains as well.	branch and bound;heuristic;monte carlo method;monte carlo tree search;multi-agent system;parallel computing;programming paradigm;robot;spaces;stochastic optimization	Bilal Kartal	2016			patrolling;artificial intelligence;machine learning;branch and bound;computer science;heuristic;mathematical optimization;satisficing;monte carlo tree search;convergence (routing)	AI	19.09386774591342	-15.930689227221144	143265
f48bd6355cf81045a2a845eaabb5483c0a2be7ce	a self-improving fuzzy cerebellar model articulation controller with stochastic action generation	cerebellar model articulation controller	A modified fuzzy cerebellar model articulation controller (FCMAC) with reinforcement learning capability is introduced in this article. This model utilizes the likelihood scheme to predict the evaluation of successive actions. Based on an approximating evaluation model, the proper output (action) is always selected. The structure of the proposed FCMAC consists of three parts: a fuzzy quantizer, which is used to represent the associative mapping function from the receptive field to the actual memory; an action evaluation module, which models and produces the expected evaluation signal and an action selection unit that generates an action with the expectation of better performance using a probability distribution function that estimates an optimal action selection policy. To demonstrate its excellent performance, the proposed self-improving model is implemented as a neural network controller for the swing control of a pendulum system. The results from both the simulation and experiment demonstrates better p...	biconnected component;cerebellar model articulation controller	Kao-Shing Hwang;Yuan-Pao Hsu	2002	Cybernetics and Systems	10.1080/019697202753435890	computer science;artificial intelligence;machine learning;control theory;mathematics	AI	19.61495397271362	-23.147177919821246	143779
eeca1331da89695309411e87b755fa7f434f8ab0	assessing the effects of zero abundance data on habitat preference modelling using a genetic takagi-sugeno fuzzy model	software;fish habitat;genetic takagi sugeno fuzzy model;takagi sugeno fuzzy model;marine animals;fuzzy reasoning;full abundance data;data models marine animals vegetation biological system modeling genetic algorithms accuracy predictive models;uncertainty genetic fuzzy systems species distribution habitat model model error;fuzzy habitat preference model;uncertainty;theoretical computer science;biological system modeling;model performance;aquaculture;generalization ability;genetics;data model;vegetation;accuracy;model error;genetic fuzzy systems;zero abundance data;fish habitat modelling;habitat preference;artificial intelligence;genetic algorithm;agriculture;predictive models;genetic algorithms;habitat preference curves;prediction model;generalisation artificial intelligence;applied mathematics;presence only abundance data;genetic fuzzy system;agricultural canal;habitat preference modelling;generalization ability zero abundance data habitat preference modelling genetic takagi sugeno fuzzy model fish habitat modelling habitat preference curves model performance agricultural canal full abundance data presence only abundance data fuzzy habitat preference model;fuzzy system;species distribution;habitat model;generalisation artificial intelligence agriculture aquaculture fuzzy reasoning;data models	In this paper, the effects of zero abundance data on fish habitat modelling using a genetic Takagi-Sugeno fuzzy system were assessed with specific focus on habitat preference curves (HPCs) and model performance. Three independent data sets were prepared from a series of fish habitat surveys conducted in an agricultural canal in Japan. To quantify the effects of zero abundance data, two kinds of data (full abundance data and presence-only abundance data) were used, from which a fuzzy habitat preference model (FHPM) were developed. As a result, the HPCs obtained using presence-only abundance data resulted in similar HPCs across the different data sets used, while those obtained using full abundance data differed by the data sets. Because the model performance with regard to generalization ability was higher, the present study concluded that the use of presence-only abundance data can better capture the habitat preference of the target species.	fuzzy control system;habitat	Shinji Fukuda	2011	2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011)	10.1109/FUZZY.2011.6007723	genetic algorithm;computer science;artificial intelligence;machine learning;data mining;predictive modelling;fuzzy control system	Robotics	10.541802611891383	-19.64150213379926	144012
3cff51d3f43316dfb44e9f9c0c9a550035cba123	run-time improvement of point-based pomdp policies	on-line planning;additional belief point;run-time improvement;whole optimal policy;belief point;resulting policy;point-based pomdp policy;belief state;plan repair;off-line plan creation;on-line plan repair;on-line plan repair approach	The most successful recent approaches to partially observable Markov decision problem (POMDP) solving have largely been point-based approximation algorithms. These work by selecting a finite number of belief points, computing alpha-vectors for those points, and using the resulting policy everywhere. However, if during execution the belief state is far from the points, there is no guarantee that the policy will be good. This case occurs either when the points are chosen poorly or there are too few points to capture the whole optimal policy, for example in domains where there are many low probability transitions, such as faults or exogenous events. In this paper we explore the use of an on-line plan repair approach to overcome this difficulty. The idea is to split computation between off-line plan creation and, if necessary, on-line plan repair. We evaluate a variety of heuristics used to determine when plan repair might be useful, and then repair the plan by sampling a small number of additional belief points and recomputing the policy. We show in several domains that the approach is more effective than either off-line planning alone even with much more computation time, or a purely on-line planning based on forward search. We also show that the overhead of checking the heuristics is very small when replanning is unnecessary.	approximation algorithm;computation;decision problem;experiment;heuristic (computer science);markov chain;online and offline;overhead (computing);partially observable markov decision process;partially observable system;sampling (signal processing);time complexity	Minlue Wang;Richard Dearden	2013			mathematical optimization;simulation;artificial intelligence;machine learning;mathematics	AI	20.68810837270418	-15.596490976085022	144204
7779a1ea7a9c0a72e6aad4471ebd95675cdc3233	bayesian action decoder for deep multi-agent reinforcement learning		When observing the actions of others, humans carry out inferences about why the others acted as they did, and what this implies about their view of the world. Humans also use the fact that their actions will be interpreted in this manner when observed by others, allowing them to act informatively and thereby communicate efficiently with others. Although learning algorithms have recently achieved superhuman performance in a number of two-player, zero-sum games, scalable multi-agent reinforcement learning algorithms that can discover effective strategies and conventions in complex, partially observable settings have proven elusive. We present the Bayesian action decoder (BAD), a new multiagent learning method that uses an approximate Bayesian update to obtain a public belief that conditions on the actions taken by all agents in the environment. Together with the public belief, this Bayesian update effectively defines a new Markov decision process, the public belief MDP, in which the action space consists of deterministic partial policies, parameterised by deep neural networks, that can be sampled for a given public state. It exploits the fact that an agent acting only on this public belief state can still learn to use its private information if the action space is augmented to be over partial policies mapping private information into environment actions. The Bayesian update is also closely related to the theory of mind reasoning that humans carry out when observing others’ actions. We first validate BAD on a proof-of-principle two-step matrix game, where it outperforms traditional policy gradient methods. We then evaluate BAD on the challenging, cooperative partial-information card game Hanabi, where in the two-player setting the method Equal contribution University of Oxford, UK DeepMind, London, UK. Correspondence to: Jakob Foerster <jakob.foerster@cs.ox.ac.uk>, Francis Song <songf@google.com>. surpasses all previously published learning and hand-coded approaches.	agent-based model;approximation algorithm;artificial neural network;deep learning;francis;gradient;humans;information card;machine learning;markov chain;markov decision process;multi-agent system;partially observable system;personally identifiable information;reinforcement learning;scalability	Jakob N. Foerster;Francis Song;Edward Hughes;Neil Burch;Iain Dunning;Shimon Whiteson;Matthew Botvinick;Michael Bowling	2018	CoRR		machine learning;scalability;artificial neural network;artificial intelligence;reinforcement learning;markov decision process;private information retrieval;exploit;bayesian probability;computer science;theory of mind	AI	19.862191834474707	-16.059683235172596	144429
39475f9ec1f7c30efd6035cc31c3e34f2e656cf9	near-optimal machine teaching via explanatory teaching sets		Modern applications of machine teaching for humans often involve domain-specific, nontrivial target hypothesis classes. To facilitate understanding of the target hypothesis, it is crucial for the teaching algorithm to use examples which are interpretable to the human learner. In this paper, we propose NOTES, a principled framework for constructing interpretable teaching sets, utilizing explanations to accelerate the teaching process. Our algorithm is built upon a natural stochastic model of learners and a novel submodular surrogate objective function which greedily selects interpretable teaching examples. We prove that NOTES is competitive with the optimal explanation-based teaching strategy. We further instantiate NOTES with a specific hypothesis class, which can be viewed as an interpretable approximation of any hypothesis class, allowing us to handle complex hypothesis in practice. We demonstrate the effectiveness of NOTES on several image classification tasks, for both simulated and real human learners. Our experimental results suggest that by leveraging explanations, one can significantly speed up teaching.	approximation;computer vision;experiment;greedy algorithm;information;loss function;optimization problem;simulation;submodular set function	Yuxin Chen;Oisin Mac Aodha;Shihan Su;Pietro Perona;Yisong Yue	2018			machine learning;stochastic modelling;submodular set function;speedup;artificial intelligence;computer science;contextual image classification	ML	22.10139340064063	-21.473320855136308	144450
23e8c92835bf0d3ec32ed9ba43fee1e104a7e062	learning conflicts from experience		Multi-agent path finding has been proven to be a PSPACE-hard problem. Generating such a centralised multi-agent plan can be avoided, by allowing agents to plan their paths separately. However, this results in an increased number of collisions and agents must replan frequently. In this paper we present a framework for multi-agent path planning, which allows agents to plan independently and solve conflicts locally when they occur. The framework is a generalisation of the CQ-learning algorithm which learns sparse interactions between agents in a multi-agent reinforcement learning setting. 1	algorithm;centralisation;conjunctive query;interaction;motion planning;multi-agent system;pspace;pathfinding;reinforcement learning;sparse matrix	Yann-Michaël De Hauwere;Ann Nowé	2012			artificial intelligence;machine learning;computer science	AI	19.010488499522822	-15.752071942086644	144845
9ca25d0158c50b8972e5363dcf5c670148e8b6e8	time-inconsistent planning: a computational problem in behavioral economics	behavioral economics;time inconsistency;present bias	In many settings, people exhibit behavior that is inconsistent across time ' we allocate a block of time to get work done and then procrastinate, or put effort into a project and then later fail to complete it. An active line of research in behavioral economics and related fields has developed and analyzed models for this type of time-inconsistent behavior.  Here we propose a graph-theoretic model of tasks and goals, in which dependencies among actions are represented by a directed graph, and a time-inconsistent agent constructs a path through this graph. We first show how instances of this path-finding problem on different input graphs can reconstruct a wide range of qualitative phenomena observed in the literature on time-inconsistency, including procrastination, abandonment of long-range tasks, and the benefits of reduced sets of choices. We then explore a set of analyses that quantify over the set of all graphs; among other results, we find that in any graph, there can be only polynomially many distinct forms of time-inconsistent behavior; and any graph in which a time-inconsistent agent incurs significantly more cost than an optimal agent must contain a large 'procrastination' structure as a minor. Finally, we use this graph-theoretic model to explore ways in which tasks can be designed to help motivate agents to reach designated goals.	algorithm;computational problem;directed graph;goal node (computer science);graph (discrete mathematics);graph minor;graph theory;induced subgraph;shortest path problem;traverse;tree traversal	Jon M. Kleinberg;Sigal Oren	2014		10.1145/2600057.2602890	mathematical optimization;simulation;computer science;artificial intelligence;machine learning;dynamic inconsistency;mathematics;microeconomics;mathematical economics;behavioral economics;algorithm	ECom	17.6435796597035	-10.857982221473291	144912
645fef410716f9c206e1c17a90beeb7c2403b03f	finding best k policies	time complexity;dynamic program;optimal policy;markov decision process	An optimal probabilistic-planning algorithm solves a problem, usually modeled by a Markov decision process, by finding its optimal policy. In this paper, we study the k best policies problem. The problem is to find the k best policies. The k best policies, k > 1, cannot be found directly using dynamic programming. Näıvely, finding the k-th best policy can be Turing reduced to the optimal planning problem, but the number of problems queried in the näıve algorithm is exponential in k. We show empirically that solving k best policy problem by using this reduction requires unreasonable amounts of time even when k = 3. We then provide a new algorithm, based on our theoretical contribution to prove that the k-th best policy differs from the i-th policy, for some i < k, on exactly one state. We show that the time complexity of the algorithm is quadratic in k, but the number of optimal planning problems it solves is linear in k. We demonstrate empirically that the new algorithm has good scalability.	algorithm;automated planning and scheduling;best practice;brute-force search;computation;dynamic programming;markov chain;markov decision process;scalability;time complexity;turing	Peng Dai;Judy Goldsmith	2009		10.1007/978-3-642-04428-1_13	markov decision process;time complexity;mathematical optimization;computer science;mathematics;management science;algorithm	ML	21.715494001811617	-16.09172698788757	144925
7bd5735a1a2304313a2fdc181b1fc43f62686733	a self-organizing multi-agent system for adaptive continuous unsupervised learning in complex uncertain environments	multi agent system;self organization;unsupervised learning	Introduction. Continuous learning and online decisionmaking in complex dynamic environments under conditions of uncertainty and limited computational recourses represent one of the most challenging problems for developing robust intelligent systems. The existing task of unsupervised clustering in statistical learning requires the maximizing (or minimizing) of a certain similarity-based objective function defining an optimal segmentation of the input data set into clusters, which is an NP-hard optimization problem for general metric spaces and is computationally intractable for real-world problems of practical interest (Davidson and Ravi 2005). The task of continuous online learning in complex dynamic environments assumes near real-time mining of streaming data continually arriving at the system, which imposes additional requirements for continuous clustering algorithms. This paper describes the developed computationally efficient adaptive multi-agent approach to continuous online clustering of streaming data in complex uncertain environments and a knowledge-based self-organizing multi-agent system for implementing it. A multi-agent approach to adaptive continuous learning. We address the problem of continuous online learning in changing environments by developing a hybrid learning approach to be both intelligible and computationally efficient that combines multiagent distributed resource allocation and model-based reinforcement learning of POMDPs. The developed multi-agent approach to adaptive online unsupervised learning of streaming data is based on an asynchronous message-passing method of continuous agglomerative hierarchical clustering and a knowledge-based competitive multi-agent system for implementing it. The proposed computationally efficient multi-agent algorithm for online agglomerative hierarchical clustering of streaming data is different from conventional unsupervised learning methods by being distributed, dynamic, and continuous. Distributed clustering process provides the ability to perform efficient run-time learning from both centralized and decentralized data sources without an additional centralized algorithm of aggregating partial mining results. Both the input dataset of decentralized sources and decision criteria for learning (e.g. similarity matrices and expert knowledge) are not fixed and can be changed at runtime during execution of the dynamic algorithm. The con-	agent-based model;algorithm;algorithmic efficiency;centralized computing;cluster analysis;computation;computational complexity theory;dynamic problem (algorithms);experiment;hierarchical clustering;logic programming;machine learning;markov chain;mathematical optimization;maxima and minima;message passing;multi-agent system;np-hardness;optimization problem;organizing (structure);partially observable markov decision process;partially observable system;prototype;real-time computing;real-time locating system;reinforcement learning;requirement;run time (program lifecycle phase);self-organization;semi-supervised learning;stream (computing);streaming media;synthetic intelligence;unsupervised learning	Igor Kiselev;Reda Alhajj	2008				ML	19.370999682544905	-19.314885706619776	144936
af902680ad18ed175d1707d4d1c5cbb8cf090608	root cause reasoning based on fuzzy fault petri net for petroleum engineering systems	petroleum engineering systems root cause fault propagation path fuzzy fault petri net;cognition accidents petroleum petroleum industry safety fault diagnosis petri nets;petroleum industry accident prevention failure analysis fault diagnosis fuzzy set theory gears inference mechanisms maintenance engineering petri nets;flue gas turbine gearbox root cause reasoning fuzzy fault petri net petroleum engineering systems petroleum industry fault mode probability fault propagation paths proactive maintenance strategy emergency plan accident prevention	In petroleum industry, engineering systems are becoming increasingly large-scale, high speed, automatic and intelligent. They are closely linked with the exploitation and transportation processes of oil and gas, making up an open complex system. Its failure often causes a chain reaction, which will further lead to serious or even catastrophic accidents with significant economic losses. Fault coupling and cascading are the “the real ultimate causes” of system breakdown, due to the complexity of its structure and behavior, as well as the high correlation and strong interaction among subsystems, system and environment. A new approach for root cause reasoning based on fault fuzzy Petri net is proposed considering the characteristics of cascading faults. The probability of each fault mode can be calculated and the fault propagation paths are ratiocinated. In this way, the proactive maintenance strategy or emergency plan can be made in advance to prevent accident. The effectiveness and accuracy of the proposed method is validated in the application of gearbox of the flue gas turbine used in refining system. The results reported in this paper could be useful for the petroleum engineering system designers and safety management personal.	algorithm;backward chaining;catastrophic interference;complex system;mit engineering systems division;petri net;software propagation	Jinqiu Hu;Laibin Zhang;Wenqiang Li;Wenhui Tian	2014	2014 11th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2014.6980812	fault model	Robotics	12.618470625112536	-12.959443041644601	144958
4add8f7acf5167fb2a4c17cd95258abff0d62016	prediction of fatigue crack growth rate in aircraft aluminum alloys using radial basis function neural network		Fatigue crack propagation in aircraft structures is a critical problem as life risk is involved besides financial loss. The relationship between stress intensity factor, ΔΚ and fatigue crack growth rate, da/dN is non-linear even in Paris region (region II). Analytical techniques are not much flexible to handle non-linearity. Accurate prediction of crack growth rate developed as a result of fatigue is important to evaluate fatigue life of engineering structures. Machine learning algorithms cater for non-linarites satisfactorily because of their excellent learning capability and flexible nature. This paper presents MLA based technique for prediction of crack growth rate using Radial Basis Function Neural Network (RBF-NN). The proposed technique is tested on different aluminum alloys used for aircraft structures. The minimum predicted MSE was achieved as 1.1315 × 10−9 for 7055-T7511 Aluminum Alloy. The results show an excellent agreement to experimental data.	algorithm;artificial neural network;machine learning;nonlinear system;radial (radio);radial basis function;software propagation	Hassaan Bin Younis;Khurram Kamal;Muhammad Fahad Sheikh;Amir Hamza;Tayyab Zafar	2018	2018 Tenth International Conference on Advanced Computational Intelligence (ICACI)	10.1109/ICACI.2018.8377568	experimental data;stress intensity factor;paris' law;artificial neural network;fracture mechanics;control theory;radial basis function;materials science	ML	11.998486304106077	-20.3022723198067	144964
98fbd642e2fd89e687b26ba8952d075f666ba918	modified fast pca algorithm on gpu architecture	principal component analysis face recognition graphics processing units;kernel;approximation algorithms;principal component analysis graphics processing units computer architecture approximation algorithms algorithm design and analysis face recognition kernel;computer architecture;face recognition;principal component analysis;graphics processing units;algorithm design and analysis;face recognition task principal component analysis gpu architecture image data parallel computation modified version of fast pca algorithm mfpca algorithm	Recognition task is a hard problem due to the high dimension of input image data. The principal component analysis (PCA) is the one of the most popular algorithms for reducing the dimensionality. The main constraint of PCA is the execution time in terms of updating when new data is included; therefore, parallel computation is needed. Opening the GPU architectures to general purpose computation allows performing parallel computation on a powerful platform. In this paper the modified version of fast PCA (MFPCA) algorithm is presented on the GPU architecture and also the suitability of the algorithm for face recognition task is discussed. The performance and efficiency of MFPCA algorithm is studied on large-scale datasets. Experimental results show a decrease of the MFPCA algorithm execution time while preserving the quality of the results.	algorithm;computation;facial recognition system;graphics processing unit;parallel computing;principal component analysis;run time (program lifecycle phase)	Vazgen Sh. Melikyan;Hasmik Osipyan	2014	Proceedings of IEEE East-West Design & Test Symposium (EWDTS 2014)	10.1109/EWDTS.2014.7027099	computer science;theoretical computer science;machine learning;pattern recognition	EDA	16.72499003149049	-16.602364567669877	145192
18aec6e4dd84c0617856704c89b6ab27b197192c	adapting to a changing environment: the brownian restless bandits	online game;machine learning;average cost;random walk;steady state analysis;multi armed bandit	In the multi-armed bandit (MAB) problem there are k distributions associated with the rewards of playing each of k strategies (slot machine arms). The reward distributions are initially unknown to the player. The player iteratively plays one strategy per round, observes the associated reward, and decides on the strategy for the next iteration. The goal is to maximize the reward by balancing exploitation: the use of acquired information, with exploration: learning new information. We introduce and study a dynamic MAB problem in which the reward functions stochastically and gradually change in time. Specifically, the expected reward of each arm follows a Brownian motion, a discrete random walk, or similar processes. In this setting a player has to continuously keep exploring in order to adapt to the changing environment. Our formulation is (roughly) a special case of the notoriously intractable restless MAB problem. Our goal here is to characterize the cost of learning and adapting to the changing environment, in terms of the stochastic rate of the change. We consider an infinite time horizon, and strive to minimize the average cost per step which we define with respect to a hypothetical algorithm that at every step plays the arm with the maximum expected reward at this step. A related line of work on the adversarial MAB problem used a significantly weaker benchmark, the best time-invariant policy. The dynamic MAB problem models a variety of practical online, game-againstnature type optimization settings. While building on prior work, algorithms and steady-state analysis for the dynamic setting require a novel approach based on different stochastic tools. ∗Microsoft Research, Mountain View CA. E-mail: slivkins at microsoft.com. Parts of this work has been completed while A. Slivkins was a postdoc at Brown University. †Computer Science Department, Brown University, Providence RI. E-mail: eli at cs.brown.edu. Supported in part by NSF awards CCR-0121154 and DMI-0600384, and ONR Award N000140610607.	algorithm;benchmark (computing);brownian motion;coat of arms;computer science;ibm notes;iteration;mathematical optimization;multi-armed bandit;steady state;time-invariant system	Aleksandrs Slivkins;Eli Upfal	2008			simulation;multi-armed bandit;computer science;artificial intelligence;machine learning;mathematics;steady state;random walk	ML	22.16362051204644	-17.469283236381916	145260
76200bda5126626fed275ec1724bf493614defcf	learning to detect local overheating of the high-power microwave heating process with deep learning		As a new kind of heating technology, microwave heating could replace traditional heating methods, because it has the advantages of high efficiency, no secondary pollution, and rapid heating. But the microwave heating process, which involves complex coupling between time-varying electromagnetic field and thermal field, is extremely complicated. At this point, the heated medium may produce local overheating. Worse, it may cause unexpected safety accidents, such as burning and even explosion. However, the temperature variation during the period of microwave heating could barely be obtained. In order to solve the problem of local overheating, this paper proposes a deep learning algorithm based on multi-dimensional data to construct an anomaly detection model for detecting local overheating. The algorithm consists of convolutional neural networks (CNNs) and unsupervised learning method named isolation forest algorithm (IFA). First, CNNs is utilized to extract features of the data collected from a WXD15S microwave heating system. Then, IFA detects the local overheating. Compared with the algorithm with common model, experiment results show that the proposed algorithm owns better measurement performance and higher precision.	algorithm;anomaly detection;artificial neural network;convolutional neural network;deep learning;microwave;optical disc authoring;sensor;unsupervised learning	Kai Wang;Longkun Ma;Qingyu Xiong;Shan Liang;Guotan Sun;Xing Yu;Zheng Yao;Tong Liu	2018	IEEE Access	10.1109/ACCESS.2018.2810266	overheating (economics);heating system;convolutional neural network;unsupervised learning;feature extraction;deep learning;anomaly detection;computer science;electronic engineering;distributed computing;artificial intelligence;microwave	SE	11.6981871560531	-16.068213889663554	145482
b77a4322060a2ba621394b83ae1c5d400c3b8641	the descended dimension method of parameter-estimation of bp neural network based on item response theory	software;parameter estimation backpropagation neural nets;backpropagation neural network;neural nets;guess rate;training;item parameter estimation;field test;descended dimension method;guess rate descended dimension method parameter estimation bp neural network backpropagation neural network item response theory response theory model scoring matrices scoring rate passing rate correlation coefficient;psychology;backpropagation;back propagation neural network;scoring rate;artificial neural networks;neural networks parameter estimation educational institutions computer science education psychology statistical analysis libraries computer science software engineering estimation theory;estimation;response theory model;item parameter estimation descended dimension method bp neural network;bp neural network;parameter estimation;correlation;correlation coefficient;item response theory;passing rate;scoring matrices;neural network	Parameters and individual ability in Dichotomously Scored of Response Theory model are estimated with Back-Propagation Neural Network. The dimension of Scoring matrixes X is descended by using scoring rate or passing rate or coefficient of correlation or guess rate when estimating those item parameters. The method is simulated in computer, and the results show that the item parameters estimation is more precise than the current international popular software, such as BILOG,PARSCALE etc. The well-trained Neural Network can output the estimate value in field test and need fewer examinees and items. The difference between estimate values and true values is very small.	algorithm;artificial neural network;backpropagation;coefficient;estimation theory;item response theory;network model;polytomy;whole earth 'lectronic link	Yunlan Tan;Shuliang Ding	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.604	item response theory;estimation;computer science;artificial intelligence;backpropagation;machine learning;estimation theory;correlation;artificial neural network;statistics	Robotics	10.861646905310298	-21.02930636636086	145575
cbafe23518e036e95cd253bd3fdf162515d7bbbd	advances in intelligent computing for diagnostics, prognostics, and system health management		This special issue of the Journal of Intelligent & Fuzzy Systems on intelligent computing for diagnostics, prognostics, and system health management is edited from a selection of papers which were originally presented at SDPC 2017 – the 2017 International Conference on Sensing, Diagnosis, and Control, held in Shanghai, China, in August 2017. The guest editors have accepted 41 papers with the special issue. By diagnosis, prognostics and system health management we mean a set of activities including: fault detection, fault classification, fault prognosis, and system modeling. Informally, fault detection refers to the real-time signal processing required to know whether or not a given system is in its healthy normal operating state. Fault classification refers to determination of the type of fault an unhealthy system is suffering from and is a pattern recognition task. Fault prognosis refers to the forecast of the remaining useful life of a system and is based on dynamic modeling. In general, these activities require a sequence of operations such as data acquisition and conditioning, feature extraction, feature selection, and a final	data acquisition;fault detection and isolation;feature extraction;feature selection;fuzzy control system;pattern recognition;real-time clock;signal processing;systems modeling;unix signal	Chuan Li;José Valente de Oliveira	2018	Journal of Intelligent and Fuzzy Systems	10.3233/JIFS-169520	machine learning;artificial intelligence;mathematics;prognostics;systems engineering;health management system	Robotics	13.466952651382476	-15.529344394006273	145864
37d4d89d00c9e821f4cf6b4b4ef36d885eefb0b9	controlling wall following robot navigation based on gravitational search and feed forward neural network	navigation;scitos;wall following;gravitational search;robot;neural network	Automated control of mobile robot navigation is a challenging area in the field of robotics research. In this work, an attempt is made to use a new neural network training algorithm based on gravitational search (GS) and feed forward neural network (FFNN) for automatic robot navigation of wall following mobile robots. The GS strategy is used for setting the optimal weight set of the FFNN so as to increase the performance of the neural network. The algorithm is tested with three large datasets obtained from UCI machine learning repository, containing a sequence of sensor readings where sensors are arranged around the waist of the SCITOS G5 robot. The proposed method shows promising results for all the datasets.	algorithm;artificial neural network;machine learning;mobile robot;robotic mapping;robotics;roland gs;sensor	Tirtharaj Dash;Tanistha Nayak;Rakesh Ranjan Swain	2015		10.1145/2708463.2709070	simulation;engineering;artificial intelligence;machine learning	Robotics	17.82909330115459	-22.817039474601103	146113
757cb069775e07913f4d7db122bcdd382930c847	saffron: an adaptive algorithm for online control of the false discovery rate		In the online false discovery rate (FDR) problem, one observes a possibly infinite sequence of pvalues P1, P2, . . . , each testing a different null hypothesis, and an algorithm must pick a sequence of rejection thresholds α1, α2, . . . in an online fashion, effectively rejecting the k-th null hypothesis whenever Pk ≤ αk. Importantly, αk must be a function of the past, and cannot depend on Pk or any of the later unseen p-values, and must be chosen to guarantee that for any time t, the FDR up to time t is less than some pre-determined quantity α ∈ (0, 1). In this work, we present a powerful new framework for online FDR control that we refer to as “SAFFRON”. Like older alphainvesting algorithms, SAFFRON starts off with an error budget (called alpha-wealth) that it intelligently allocates to different tests over time, earning back some alpha-wealth whenever it makes a new discovery. However, unlike older methods, SAFFRON’s threshold sequence is based on a novel estimate of the alpha fraction that it allocates to true null hypotheses. In the offline setting, algorithms that employ an estimate of the proportion of true nulls are called “adaptive”, hence SAFFRON can be seen as an online analogue of the offline Storey-BH adaptive procedure. Just as Storey-BH is typically more powerful than the Benjamini-Hochberg (BH) procedure under independence, we demonstrate that SAFFRON is also more powerful than its non-adaptive counterparts such as LORD. Departments of Statistics and Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, USA Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, Berkeley, USA. Correspondence to: Aaditya Ramdas <aramdas@eecs.berkeley.edu>, Tijana Zrnic <tijana@eecs.berkeley.edu>, Martin J. Wainwright <wainwrig@eecs.berkeley.edu>, Michael I. Jordan <jordan@eecs.berkeley.edu>. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).	adaptive algorithm;bsd;c date and time functions;computer science;electrical engineering;international conference on machine learning;itai benjamini;online and offline;rejection sampling;x86	Aaditya Ramdas;Tijana Zrnic;Martin J. Wainwright;Michael I. Jordan	2018			mathematics;sequence;false discovery rate;adaptive algorithm;monotone polygon;null hypothesis;artificial intelligence;special case;pattern recognition;derivation	ML	22.895466741079296	-19.06478982594753	146462
5ce340535e8daf08da9dcf5d1065c2f3f5519d03	optimized real-time soft analyzer for chemical process using artificial intelligence	delay effects process control algorithm design and analysis delays biological system modeling training estimation;multilayer perceptrons;optimized real time soft analyzer industrial process identification neural network model hierarchical level responsible strategy forward selection lipschitz number method mlp multilayer perceptron optimized classical neural network estimation models product information chemical process instruments artificial intelligence;multilayer perceptrons artificial intelligence chemical engineering;chemical engineering;artificial intelligence;tennessee eastman process tep multi layer perceptron soft analyzer lipschitz number	This paper concerns application of data-derived approaches for analyzing and monitoring chemical process instruments, extracting product information, and designing estimation models for primary process variables, or difficult to measure in real-time variables. Modeling of process with an optimized classical neural network, the multi-layer perceptron (MLP) is discussed. Tennessee Eastman Process, a well-known plant wide process benchmark, is applied to validate the proposed approach. Investigations and several algorithms as step response test, Lipschitz number method and forward selection are used. The main advancement introduced here is that a hierarchical level responsible strategy is applied for selection of input variables and respective efficient time delays to attain the highest possible prediction accuracy of the neural network model for industrial process identification.	algorithm;artificial intelligence;artificial neural network;benchmark (computing);layer (electronics);mathematical model;memory-level parallelism;multilayer perceptron;network model;real-time clock;step response;stepwise regression	Mohammad Mahdi Karimi;Alireza Fatehi;Reza Ebrahimpour;Ali Shamsaddinlou	2013	2013 9th Asian Control Conference (ASCC)	10.1109/ASCC.2013.6606356	control engineering;computer science;artificial intelligence;machine learning	AI	12.72929677485565	-21.67497570237929	146650
0dd7a8da88eddb9b502de9b80f37a80db79fddee	multi-agent planning with quantitative capability	multi agent planning;capability;pddl	In the recent years, there has been a lot of research in multi-agent planning (MAP). Multi-agent planning applications include search and exploration, robotics, and logistics etc. Existing works show that agents have different capabilities if the agents have different action sets. However, agents may have different capabilities even if the action sets are same. In this paper, we present an approach for multi-agent planning problem, where capabilities of the agents are represented in a quantitative manner. The proposed approach translates such MAP problem into classical planning problem. The resultant classical planning problem is solved by an existing state-of-the-art classical planner. Experiments were performed on some benchmark planning domains and the results are quite promising.	automated planning and scheduling;benchmark (computing);complex adaptive system;experiment;logistics;multi-agent system;resultant;robotics	Satyendra Singh Chouhan;Rajdeep Niyogi	2016	2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2016.7732112	planning domain definition language;capability;simulation;computer science;engineering;artificial intelligence;reactive planning	AI	18.93304267836337	-15.808369519011116	146784
1435493c917e5beb255a658a3204a18e5ee5277d	robust rendezvous for multi-robot system with random node failures: an optimization approach		In this paper, we consider the problem of designing distributed control algorithms to solve the rendezvous problem for multi-robot systems with limited sensing, for situations in which random nodes may fail during execution. We first formulate a distributed solution based upon averaging algorithms that have been reported in the consensus literature. In this case, at each stage of execution a one-step sequential optimal control (i.e., naive greedy algorithm) is used. We propose a distributed stochastic optimal control algorithm that minimizes a mean–variance cost function for each stage, given that the probability distribution for possible node failures is known a priori, as well as a minimax version of the problem when the prior probability distribution is not known. We demonstrate via extensive numerical simulations that our proposed algorithm provides statistically better rendezvous task performance than contemporary algorithms in cases for which failures occur.	mathematical optimization;robot	Hyongju Park;Seth Hutchinson	2018	Auton. Robots	10.1007/s10514-018-9715-8	simulation;probability distribution;computer science;mathematical optimization;rendezvous problem;robust optimization;rendezvous;minimax;stochastic control;optimal control;greedy algorithm	Robotics	22.23915117728412	-14.525213120850168	146862
e460aeb261cad8fb667de17f5d249a9a77bcf946	determination of octane number of gasoline by double ann algorithm combined with multidimensional gas chromatography	analytical models;gasoline octane number;gasoline double ann multidimensional gc octane number;least squares approximations;partial least square regression model;double ann;neural nets;partial least square;ann regression model;hydrocarbon analysis;training;research octane number;gas chromatography;regression model;multidimensional gas chromatography;ron;inspection;refinery gasoline octane number double ann algorithm multidimensional gas chromatography artificial neural network multidimensional resolution column hydrocarbon analysis research octane number ron ann regression model partial least square regression model pls regression model;artificial neural networks;petroleum;pls regression model;hydrocarbons;multidimensional gc;gasoline;multidimensional resolution column;regression analysis;octane number;double ann algorithm;refinery;chromatography;artificial neural networks hydrocarbons training inspection gas chromatography analytical models;artificial neural network;regression analysis chromatography least squares approximations neural nets petroleum	In this paper, a double artificial neural network (ANN) algorithm has been established for calculating the octane number (ON) of gasoline from the results of multidimensional gas chromatography analysis. Multidimensional resolution column was applied to obtain the results of the detailed hydrocarbon analysis. The double ANN regression model has been established between the results of the detailed hydrocarbon analysis and the actually determined research octane number (RON). When the method was applied to determine RON of export gasoline samples, the deviation of results was about 0.5 RON compared with the standard method. The result of double ANN regression model was better than the result of partial least square (PLS) regression model. This method was easy to manipulate, and the modelling process was fast and easy to achieve. It was suitable for measuring the ON of the gasoline samples from the refinery and the export inspection.	algorithm;artificial neural network	Ming-yang Liu;Peng Zhou;Ping Kong;Chun-guang Yang;Gang Li;Ming-ren Mu	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5583775	chromatography;econometrics;chemistry;analytical chemistry	Robotics	12.158540587878038	-19.810843720235713	146891
f18aba7d54b34f6c96a1c78371714678af9f6a4a	captain jack: new variable selection heuristics in local search for sat	new variable selection heuristics;random instance;captain jack;uniform random k-sat;rich design space;well-known sls-based sat solvers;parameter space;previous sls solvers;design space;sat instance;best-performing solvers;local search	Stochastic local search (SLS) methods are well known for their ability to find models of randomly generated instances of the propositional satisfiability problem (SAT) very effectively. Two well-known SLS-based SAT solvers are SPARROW, one of the best-performing solvers for random 3-SAT instances, and VE-SAMPLER, which achieved significant performance improvements over previous SLS solvers on SAT-encoded software verification problems. Here, we introduce a new highly parametric algorithm, CAPTAIN JACK, which extends the parameter space of SPARROW to incorporate elements from VE-SAMPLER and introduces new variable selection heuristics. CAPTAIN JACK has a rich design space and can be configured automatically to perform well on various types of SAT instances. We demonstrate that the design space of CAPTAIN JACK is easy to interpret and thus facilitates valuable insight into the configurations automatically optimized for different instance sets. We provide evidence that CAPTAIN JACK can outperform well-known SLS-based SAT solvers on uniform random k-SAT and ‘industrial-like’ random instances.	algorithm;boolean satisfiability problem;feature selection;heuristic (computer science);jack audio connection kit;local search (constraint satisfaction);local search (optimization);procedural generation;software verification;standard sea level	Dave A. D. Tompkins;Adrian Balint;Holger H. Hoos	2011		10.1007/978-3-642-21581-0_24	mathematical optimization;computer science;artificial intelligence;machine learning;algorithm	AI	20.339669614985983	-10.456500365728191	147230
8e569ed84486ec26263bb4f78837e465f41fbce1	fetal weight prediction models: standard techniques or computational intelligence methods?	ultrasound;standard deviation;computational intelligence;root mean square error;non linear model;automatic generation;prediction model;collective model;nonlinear regression	An accurate model of ultrasound estimation of fetal weight (EFW) can help in decision if the cesarean childbirth is necessary. We collected models from various sources and compared their accuracy. These models were mostly obtained by standard techniques such as linear and nonlinear regression. The aim of the comparison was to recommend a model best fitting to data measured for Czech population. Alternatively, we generated several linear and non-linear models by using our method GAME from the computational intelligence domain. GAME models can be serialized into simple equations that are understandable by domain experts. In this contribution, we show that automatically generated GAME models are at least as accurate (in terms of root mean squared error and standard deviations of predictions) as the best model computed by means of (time and expert skills demanding) standard techniques.	computation;computational intelligence	Tomás Siegl;Pavel Kordík;Miroslav Snorek;Pavel Calda	2008		10.1007/978-3-540-87536-9_48	econometrics;computer science;artificial intelligence;machine learning;computational intelligence;ultrasound;mean squared error;predictive modelling;standard deviation;nonlinear regression;statistics	AI	15.067224222349292	-18.75065917834987	147266
6c1c0d0be3e50e650a48b22653fa3c2b8ee767f8	supervised neural network learning with an environment adapted supervision based on motivation learning factors		This paper introduces an innovative approach for supervised learning systems in cases when we do not have initially defined training data sets, but we need to develop them gradually during training process on the basis of the motivation factors that come from the given environment. We suppose to gradually develop and update knowledge about the environment and use it for supervision of training MLP. In the beginning, the gradually gained knowledge does not have to be correct, but it allows to adapt a neural network still better and more efficiently in time. It is illustrated on the problem of acquiring the ability to return to the starting position optimally by a virtual robot from anywhere in an initially unknown and gradually explored maze. The proposed approach focuses on the attempt to reflect human cognitive abilities and motivation factors in an introduced model using artificial neural networks. This article presents a new approach in which the decision-making method arises from the supervised learning process controlled by the knowledge gained during maze exploration. This paper presents a model of maze exploration and knowledge-based adaptation of the neural network. The experimental results of the classical supervised learning approach and the proposed modified approach will be compared to demonstrate significant improvements.	artificial neural network	Maciej Janowski;Adrian Horzyk	2018		10.1007/978-3-319-91253-0_8	pattern recognition;supervised learning;machine learning;computer science;artificial intelligence;artificial neural network;cognition;training set	ML	18.58802733197507	-21.454478726805714	147295
fa5fb29765e9175766415450eebaec6c43086d81	generalized adaptive a	shortest paths;d lite;heuristic search;a;moving target search;incremental search	Agents often have to solve series of similar search problems. Adaptive A* is a recent incremental heuristic search algorithm that solves series of similar search problems faster than A* because it updates the h-values using information from previous searches. It basically transforms consistent hvalues into more informed consistent h-values. This allows it to find shortest paths in state spaces where the action costs can increase over time since consistent h-values remain consistent after action cost increases. However, it is not guaranteed to find shortest paths in state spaces where the action costs can decrease over time because consistent h-values do not necessarily remain consistent after action cost decreases. Thus, the h-values need to get corrected after action cost decreases. In this paper, we show how to do that, resulting in Generalized Adaptive A* (GAA*) that finds shortest paths in state spaces where the action costs can increase or decrease over time. Our experiments demonstrate that Generalized Adaptive A* outperforms breadth-first search, A* and D* Lite for moving-target search, where D* Lite is an alternative state-of-the-art incremental heuristic search algorithm that finds shortest paths in state spaces where the action costs can increase or decrease over time.	a* search algorithm;adobe flash lite;breadth-first search;experiment;incremental heuristic search;search problem;shortest path problem	Xiaoxun Sun;Sven Koenig;William Yeoh	2008		10.1145/1402383.1402451	consistent heuristic;beam search;mathematical optimization;bidirectional search;heuristic;computer science;artificial intelligence;machine learning;incremental heuristic search;algorithm	AI	19.75114502085024	-11.617460926811809	147306
35de5fd96c17a8f832970e329fa1d85a2e610fca	a method for analysing the reliability of a transmission grid	arbre graphe;modelizacion;minimal cut;arbol defecto;fault tree;factor riesgo;fiabilidad;reliability;substation;analisis estadistico;failure;analisis sistema;corte minima;reseau electrique;tree graph;risk factor;securite;emergency system;electrical network;probabilistic method;transmission;ligne transmission;systeme urgence;red electrica;sistema urgencia;power system dynamics;probabilistic approach;facteur risque;analisis programa;dynamical system;grid;modelisation;systeme dynamique;protection;failure reliability;statistical analysis;puesto electrico;arbre defaut;rejilla;power system;enfoque probabilista;approche probabiliste;poste electrique;linea transmision;fiabilite;rupture;safety;analyse statistique;defaillance;grille;system analysis;analyse systeme;program analysis;failures;circuit breakers;sistema dinamico;analyse programme;arbol grafo;seguridad;modeling;importance;fallo;ruptura;grid security;power system security;dynamic analysis;coupure minimale;transmission line	The paper describes a probabilistic method for transmission grid security evaluation. Power system security is the ability of the power system to withstand sudden disturbances such as short circuits. The method presented here uses event and fault trees and combines them with power system dynamic simulations. Event trees model the substation protection and trip operations after line faults. Different event tree end states (fault duration, circuit breaker trips) are simulated with power system dynamic analysis program. The dynamic analysis results (power system post-fault states) are then classified into secure, alert, emergency and system breakdown. The probabilities, minimal cut sets and grid level importance measures (Fussell-Vesely, risk increase and decrease factors) are calculated for the total and partial system breakdown. In this way, the relative importance of the substation devices regarding to the system breakdown can be reached. Also the more and less likely contributing factors to system breakdown are received. With this method, an existing 400 kV transmission grid with its line fault and device failure statistics is analysed. r 2007 Elsevier Ltd. All rights reserved.	event tree;fault tree analysis;max-flow min-cut theorem;simulation;system dynamics;traction substation	Liisa Haarla;Urho Pulkkinen;Mikko Koskinen;Jussi Jyrinsalo	2008	Rel. Eng. & Sys. Safety	10.1016/j.ress.2006.10.025	program analysis;electrical network;simulation;systems modeling;fault tree analysis;telecommunications;transmission;engineering;probabilistic method;dynamical system;transmission line;reliability;circuit breaker;mathematics;dynamic program analysis;system analysis;electric power system;grid;risk factor;tree;statistics	EDA	12.703803791079574	-10.062623502864465	147459
277a1f5fa81f4655c83d39de2c27976746d3cb53	policy gradients in linearly-solvable mdps		We present policy gradient results within the framework of linearly-solvable MDPs. For the first time, compatible function approximators and natural policy gradients are obtained by estimating the cost-to-go function, rather than the (much larger) state-action advantage function as is necessary in traditional MDPs. We also develop the first compatible function approximators and natural policy gradients for continuous-time stochastic systems.	approximation;bellman equation;decision problem;dynamic programming;gauss–newton algorithm;gradient;gradient method;heuristic;iteration;markov decision process;newton's method;optimal control;reinforcement learning;sampling (signal processing);stochastic process	Emanuel Todorov	2010			mathematical optimization;machine learning;data mining;mathematics	ML	22.49339357764194	-18.215579471721902	147470
4672156639c066fe67480f1128510d0dc605dd09	hierarchical method based on artificial neural networks for power output prediction of a combined cycle power plant			artificial neural network;neural networks	Rafik Fainti;Antonia Nasiakou;Miltiadis Alamaniotis;Lefteri H. Tsoukalas	2016	IJMSTR	10.4018/IJMSTR.2016100102	control engineering;machine learning;control theory	EDA	11.293026608935756	-23.199147306619366	147493
1b062f0c23ac07d6cb6ad8dca3a6298081fdfb89	a self-adaptive multi-engine solver for quantified boolean formulas	aqme;metodo adaptativo;quantization;logica booleana;ing inf 05 sistemi di elaborazione delle informazioni;adaptability;adaptabilite;cuantificacion;mise a jour;methode empirique;commande modele interne;principio modelo interno;apprentissage inductif;quantified boolean formulas;metodo empirico;quantified boolean formula;empirical method;methode adaptative;quantification;adaptabilidad;actualizacion;analyse syntaxique;aprendizaje por induccion;inductive reasoning;control modelo interno;analisis sintaxico;internal model control;syntactic analysis;adaptive method;inductive learning;principe modele interne;self adaptive multi engine solver;logique booleenne;internal model principle;boolean logic;domain specificity;updating;internal model	In this paper we study the problem of engineering a robust solver for quantified Boolean formulas (QBFs), i.e., a tool that can efficiently solve formulas across different problem domains without the need for domain-specific tuning. The paper presents two main empirical results along this line of research. Our first result is the development of a multi-engine solver, i.e., a tool that selects among its reasoning engines the one which is more likely to yield optimal results. In particular, we show that syntactic QBF features can be correlated to the performances of existing QBF engines across a variety of domains. We also show how a multi-engine solver can be obtained by carefully picking state-of-the-art QBF solvers as basic engines, and by harnessing inductive reasoning techniques to learn engine-selection policies. Our second result is the improvement of our multi-engine solver with the capability of updating the learned policies when they fail to give good predictions. In this way the solver becomes also self-adaptive, i.e., able to adjust its internal models when the usage scenario changes substantially. The rewarding results obtained in our experiments show that our solver AQME—Adaptive QBF Multi-Engine—can be more robust and efficient than state-of-the-art single-engine solvers, even when it is confronted with previously uncharted formulas and competitors.	boolean satisfiability problem;domain-specific language;experiment;inductive reasoning;inference engine;performance;problem domain;solver;true quantified boolean formula	Luca Pulina;Armando Tacchella	2008	Constraints	10.1007/s10601-008-9051-2	adaptability;internal model;quantization;computer science;artificial intelligence;inductive reasoning;mathematics;algorithm	AI	20.871513303531323	-13.067568022533747	147554
0c5a443569c695cc3bc5cfa2ec37f666aea22598	efficient average reward reinforcement learning using constant shifting values	reinforcement learning;average reward;constant shifting value	There are two classes of average reward reinforcement learning (RL) algorithms: model-based ones that explicitly maintain MDP models and model-free ones that do not learn such models. Though model-free algorithms are known to be more efficient, they often cannot converge to optimal policies due to the perturbation of parameters. In this paper, a novel model-free algorithm is proposed, which makes use of constant shifting values (CSVs) estimated from prior knowledge. To encourage exploration during the learning process, the algorithm constantly subtracts the CSV from the rewards. A terminating condition is proposed to handle the unboundedness of Q-values caused by such substraction. The convergence of the proposed algorithm is proved under very mild assumptions. Furthermore, linear function approximation is investigated to generalize our method to handle large-scale tasks. Extensive experiments on representative MDPs and the popular game Tetris show that the proposed algorithms significantly outperform the state-of-the-art ones. Introduction Reinforcement learning (RL) is an effective learning technique for solving sequential decision-making problems. An RL agent tries to maximize its cumulative reward by interacting with the environment, which is usually modeled as a Markov decision process (MDP) (Kaelbling, Littman, and Moore 1996). Average reward MDPs are natural models of many non-terminating tasks, such as the call admission control and routing problem (Marbach, Mihatsch, and Tsitsiklis 2000) and the automatic guided vehicle routing problem (Ghavamzadeh and Mahadevan 2007). Average reward RL has received much attention in the recent years (Ortner 2013; Mahadevan 2014; Nguyen et al. 2014). There are mainly two classes of average reward RL algorithms (Tadepalli 2010). The first class is model-based algorithms such as UCRL (Ortner and Auer 2007), UCRL2 (Jaksch, Ortner, and Auer 2010), and PSRL (Osband, Russo, and van Roy 2013). They achieve efficient exploration by Copyright c © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. estimating the environment model of an MDP. It often takes a very long time to obtain an accurate model though, especially when the state-action space is large. The second class is model-free algorithms which do not explicitly maintain MDP models, including R-learning (Schwartz 1993; Singh 1994), SMART (Das et al. 1999), RVI Q-learning (Abounadi, Bertsekas, and Borkar 2001; Li 2012), and GRlearning (Gosavi 2004), etc. They all use an adaptive shifting value to approximate the optimal average reward to avoid the unboundedness of Q-values. Their learning processes are however typically sensitive to input parameters and may often result in long execution time or even non-convergence. For example, R-learning can be easily perturbed by the learning rates (Mahadevan 1996) and choosing a proper reference state for RVI Q-learning can be difficult when the state space is large (Abounadi, Bertsekas, and Borkar 2001). To overcome the instability and improve scalability of average reward RL, this paper proposes a novel model-free stochastic approximation algorithm which takes advantage of constant shifting values (CSVs) when such values can be inferred from prior knowledge. A main feature of our method (named CSV-LEARNING), is that it encourages a more precise and accurate exploration until a stable policy is reached. As will be discussed later, a CSV usually leads to unboundedness of Q-values during the learning process. Nonetheless, we have derived a terminating condition to secure the convergence of policy, and proved that such a convergence could be towards the optimal policy if CSVs are wisely chosen (i.e., with good prior knowledge). Linear function approximation is also considered in this paper to handle large scale tasks. We compare our method with other existing algorithms using representative MDPs and the popular game Tetris. Experiment results show that CSV-LEARNING converges to the optimal policy significantly faster than existing algorithms. Preliminaries and Related Work In this section, we first introduce the average reward MDP, and then briefly present some related work in this area. An average reward MDP is a tuple 〈S,A,R, P 〉, where S Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI-16)	approximation algorithm;artificial intelligence;british undergraduate degree classification;certified server validation;computerized system validation;converge;divergence (computer science);experiment;first-class function;instability;interaction;linear function;markov chain;markov decision process;newman's lemma;q-learning;reinforcement learning;run time (program lifecycle phase);smart;scalability;second level address translation;state space;stochastic approximation;terminate (software);tetris;unbounded nondeterminism;vehicle routing problem;word lists by frequency	Shangdong Yang;Yang Gao;Bo An;Hao Wang;Xingguo Chen	2016			mathematical optimization;computer science;artificial intelligence;machine learning;reinforcement learning	AI	22.584199568988105	-18.989867233153362	147769
5bf6b9b96d2d83176e6d88d8ca35b95e458687c0	design and application of water displacing oil physical simulation system based on radial basic function network	least squares approximations;water displacing oil;oil production water displacing oil physical simulation system radial basic function network training strobe circuit constant current source k nearest neighbor algorithm least square method;least square method;radial basis function networks;radial basis function networks digital simulation learning artificial intelligence least squares approximations oil technology;k nearest neighbor;oil technology;radial basic function network water displacing oil physical simulation design and application;learning artificial intelligence;design and application;radial basic function network;digital simulation;physical simulation;petroleum conductivity electrical resistance measurement water resources data acquisition electrodes sensor arrays circuit simulation production hydrocarbon reservoirs	The water displacing oil physical simulation system and modeling method based on radial basic function network is presented in this paper. The 512 routes strobe circuit and the constant current source which can adjust the range intelligently are designed in this simulation system. According to the approximate linear relationship between the resistance rate value and the water saturation, the resistivity is measured using four wire method. The radial basic function network was used to establish the water displacing remaining oil model. We construct the structure of radial basic function network, and adopt the K-Nearest Neighbor algorithm and least square method to train the network. The experimental results show that this simulation system and modeling method is feasible and effective.	approximation algorithm;artificial intelligence;constant current;current source;dynamical simulation;k-nearest neighbors algorithm;nearest-neighbor interpolation;radial (radio)	Jingwen Tian;Erhong Lu;Meijuan Gao	2009	2009 Second International Workshop on Knowledge Discovery and Data Mining	10.1109/WKDD.2009.213	simulation;computer science;artificial intelligence;machine learning;least squares;k-nearest neighbors algorithm	AI	13.12238777604254	-20.76200203395591	147916
d373200b3cad763895a4fbe66c2bc29506ad4b88	automating the strategy selection for parallel heuristic search	artificial intelligent;heuristic search;machine learning;parallel processing;problem solving	Many Artificial Intelligence (AI) programs attempt, to apply some form of intelligence to problem solving. Problem solving may include planning the moves of a robot, parsing and interpreting a sentence, or playing the opponent in a game of chess. All of these include some form of search where a set of alternatives are evaluated and the most appropriate alternative is selected that could eventually lead to a solution. The search process often requires a great deal of processor time which can seriously affect the program’s performance. For time critical applications the use of the fastest processor often does not produce timely results. Even parallel processing does not necessarily reduce the processing time especially if the wrong approach is taken for a problem. With each problem having a different structure it is impossible to use the same approach for all problems. This research has examined a method for automating the selection of a strategy for parallel search. Machine learning, and the C4.5 machine learning system in particular, is used to choose the best strategy based on a problem’s structure.	artificial intelligence;c4.5 algorithm;fastest;heuristic;machine learning;parallel computing;parsing;problem solving	R. Craig Varnell	1998		10.1145/275295.275319	heuristic;beam search;null-move heuristic;mathematical optimization;computer science;theoretical computer science;machine learning;incremental heuristic search;hyper-heuristic	AI	18.778379862422515	-12.626164489257858	148160
34eb5d1d0a851b9be92a9da96c4723efaac556bd	determining possible avenues of approach using ants	ant colony optimization;functional form;urban planning;data fusion;risk assessment;swarm intelligence	Threat assessment is an important part of level 3 data fusion. Here we study a subproblem of this, worstcase risk assessment. Inspired by agent-based models used for simulation of trail formation for urban planning, we use ant colony optimization (ANTS) to determine possible avenues of approach for the enemy, given a situation picture. One way of determining such avenues would be to calculate the “potential field” caused by placing sources at possible goals for the enemy. This requires postulating a functional form for the potential, and also takes long time. Here we instead seek a method for quickly obtaining an effective potential. ANTS, which has previously been used to obtain approximate solutions to various optimization problems, is well suited for this. The output of our method describes possible avenues of approach for the enemy, i.e, areas where we should be prepared for attack. (The algorithm can also be run “reversed” to instead get areas of opportunity for our forces to exploit.) Using real geographical data, we found that our method gives a fast and reliable way of determining such avenues. Our method can be used in a computer-based command and control system to replace the first step of human intelligence	agent-based model;algorithmic number theory symposium;ant colony optimization algorithms;approximation algorithm;best, worst and average case;control system;discounted maximum loss;higher-order function;mathematical optimization;real-time transcription;risk assessment;sensor;simulation;unmanned aerial vehicle	Pontus Svenson;Hedvig Kjellström	2003	CoRR		risk assessment;algorithm design;ant colony optimization algorithms;simulation;risk analysis;risk management;swarm intelligence;computer science;artificial intelligence;urban planning;sensor fusion;software testing;particle swarm optimization;higher-order function	AI	19.23734312988458	-13.02246845286729	148232
dca653b30b05116a9ba2725a6c2e13333c4f7907	how behavior trees generalize the teleo-reactive paradigm and and-or-trees	computers;control systems;service robots;industries;engineering and technology;teknik och teknologier;batteries;problem solving	Behavior Trees (BTs) is a way of organizing the switching structure of a control system, that was originally developed in the computer gaming industry but is now also being used in robotics. The Teleo-Reactive programs (TRs) is a highly cited reactive hierarchical robot control approach suggested by Nilsson and And-Or-Trees are trees used for heuristic problems solving. In this paper, we show that BTs generalize TRs as well as And-Or-Trees, even though the two concepts are quite different. And-Or-Trees are trees of conditions, and we show that they transform into a feedback execution plan when written as a BT. TRs are hierarchical control structures, and we show how every TR can be written as a BT. Furthermore, we show that so-called Universal TRs, guaranteeing that the goal will be reached, are a special case of so-called Finite Time Successful BTs. This implies that many designs and theoretical results developed for TRs can be applied to BTs.	behavior tree;control flow;control system;heuristic;organizing (structure);pc game;programming paradigm;query plan;robot control;robotics	Michele Colledanchise;Petter Ögren	2016	2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2016.7759089	simulation;computer science;engineering;control system;artificial intelligence;control theory;mathematics	Robotics	22.773503634422713	-10.600798885143266	148408
4c286604cfce93f59fdcd86ec0ef062d938287b1	consideration of multiple objectives in neural learning classifier systems	robot movil;multiobjective programming;programmation multiobjectif;systeme apprentissage;autonomous system;educational software program;learning classifier system;didacticiel;sistema autonomo;learning systems;nivel energia;energy levels;multiple objectives;robot mobile;systeme autonome;energy level;programa didactico;reseau neuronal;red neuronal;autonomous robot;moving robot;artificial neural network;neural network;niveau energie;programacion multiobjetivo	For effective use in a number of problem domains Learning Classifier Systems must be able to manage multiple objectives. This paper explicitly considers the case of developing the controller for a simulated mobile autonomous robot which must achieve a given task whilst maintaining sufficient battery power. A form of Learning Classifier System in which each rule is represented by an artificial neural network is used. Results are presented which show it is possible to solve both objectives when the energy level is presented as an input along with sensor data. A more realistic, and hence more complex, version of the basic scenario is then investigated.		Larry Bull;Matthew Studley	2002		10.1007/3-540-45712-7_53	margin;simulation;computer science;energy level;artificial intelligence;machine learning;learning classifier system;artificial neural network	ML	16.37152484246266	-20.621185372097113	148584
922d569d94abbb2ebca4896bf3bf7db2bd850688	higher level application of adp: a next phase for the control field?	dynamic programming;online algorithm;control systems;artificial intelligence ai;learning control;learning algorithm;learning;reinforcement learning;higher level application;adaptive control;artificial intelligence biomimetics feedback humans learning programming linear systems theory;reinforcement learning rl;artificial intelligent;approximate dynamic programming adp;optimal control;learning systems;artificial neural networks;system identification;humans optimal control learning dynamic programming artificial intelligence control systems algorithm design and analysis system identification adaptive control artificial neural networks;learning systems adaptive control dynamic programming learning artificial intelligence;dynamic programming higher level application humanlike control context discernment adaptive control learning control individual controllers reinforcement learning;artificial intelligence;approximate dynamic programming;experience based identification and control ebic;neural networks nns;humans;system identification sid approximate dynamic programming adp artificial intelligence ai context context discernment experience based identification and control ebic neural networks nns optimal control reinforcement learning rl;individual controllers;learning artificial intelligence;system identification sid;experience base;context;algorithm design and analysis;humanlike control;neural network;context discernment	Two distinguishing features of humanlike control vis-a-vis current technological control are the ability to make use of experience while selecting a control policy for distinct situations and the ability to do so faster and faster as more experience is gained (in contrast to current technological implementations that slow down as more knowledge is stored). The notions of context and context discernment are important to understanding this human ability. Whereas methods known as adaptive control and learning control focus on modifying the design of a controller as changes in context occur, experience-based (EB) control entails selecting a previously designed controller that is appropriate to the current situation. Developing the EB approach entails a shift of the technologist's focus ldquoup a levelrdquo away from designing individual (optimal) controllers to that of developing online algorithms that efficiently and effectively select designs from a repository of existing controller solutions. A key component of the notions presented here is that of higher level learning algorithm. This is a new application of reinforcement learning and, in particular, approximate dynamic programming, with its focus shifted to the posited higher level, and is employed, with very promising results. The author's hope for this paper is to inspire and guide future work in this promising area.	adenosine diphosphate;approximation algorithm;cardiovascular technologist;controllers;dynamic programming;gain;online algorithm;reinforcement learning;solutions;usb on-the-go;visual instruction set	George G. Lendaris	2008	IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)	10.1109/TSMCB.2008.918073	algorithm design;online algorithm;optimal control;system identification;computer science;artificial intelligence;machine learning;dynamic programming;control theory;artificial neural network	Robotics	18.74334597807788	-20.229166524649404	148681
7468f6b69ae9284240b49613751218d1ca30c3b5	using domain knowledge to improve monte-carlo tree search performance in parameterized poker squares		Poker Squares is a single-player card game played on a 5 x 5 grid, in which a player attempts to create as many high-scoring Poker hands as possible. As a stochastic single-player game with an extremely large state space, this game offers an interesting area of application for Monte-Carlo Tree Search (MCTS). This paper describes enhancements made to the MCTS algorithm to improve computer play, including pruning in the selection stage and a greedy simulation algorithm. These enhancements make extensive use of domain knowledge in the form of a state evaluation heuristic. Experimental results demonstrate both the general efficacy of these enhancements and their ideal parameter settings.	monte carlo tree search	Robert Arrington;Clay Langley;Steven Bogaerts	2016			grid;machine learning;parameterized complexity;artificial intelligence;state space;domain knowledge;theoretical computer science;heuristic;monte carlo tree search;computer science	ML	19.363733728508315	-17.312681769892205	148970
13fbf15dce48e9a4e00654b8d4e6f42718f75062	mini-buckets: a general scheme for bounded inference	bayesian network;constraint propagation;approximate algorithm;approximation algorithms;search space;forward checking;probabilistic inference;backtrack search;optimization problem;approximate solution;most probable explanation;approximation scheme;accuracy complexity trade off;combinatorial optimization;medical diagnosis;bayesian networks	This article presents a class of approximation algorithms that extend the idea of bounded-complexity inference, inspired by successful constraint propagation algorithms, to probabilistic inference and combinatorial optimization. The idea is to bound the dimensionality of dependencies created by inference algorithms. This yields a parameterized scheme, called mini-buckets, that offers adjustable trade-off between accuracy and efficiency. The mini-bucket approach to optimization problems, such as finding the most probable explanation (MPE) in Bayesian networks, generates both an approximate solution and bounds on the solution quality. We present empirical results demonstrating successful performance of the proposed approximation scheme for the MPE task, both on randomly generated problems and on realistic domains such as medical diagnosis and probabilistic decoding.	approximation algorithm;bayesian network;combinatorial optimization;local consistency;mathematical optimization;procedural generation;schema (genetic algorithms)	Rina Dechter;Irina Rish	2003	J. ACM	10.1145/636865.636866	mathematical optimization;combinatorics;combinatorial optimization;computer science;theoretical computer science;machine learning;bayesian network;mathematics;statistics	AI	21.594194318076173	-13.025520299642224	148995
72393b1b49a1e2debb03ae114b082bf87679d6f9	simulation of oil spill using ann and ca models	rivers;information science;deepspill cellular automata ca artificial neural network ann simulation of oil spill;neural nets cellular automata digital simulation geographic information systems;physics;ann oil spill ca model oil spill simulation artificial neural network kappa coefficient neurons number cellular automata model;neurons information science rivers physics;neurons	In this paper, the artificial neural network (ANN) used to obtain transition rules in oil spill CA model. Model parameters are difficult to obtain in many traditional oil spill models, as they cannot meet the requirements of rapid response for oil spills. Therefore, a new oil spill model - ANN oil spill CA model was established in this paper. This model can simulate the change process of oil spill by setting initial image, verification image, and impact factors. Experimental results show that the simulation results have a good performance with overall accuracy of 96.6% and Kappa coefficient of 0.826. It was also found that the consistency of simulation results is proportional to the ratio of training sample. However, the higher the ratio of the training sample, the more computation is need in the ANN training. We also studied the effect of neurons number in the hidden layer. Studies show that the consistency of simulation results becomes better with the increase of neurons number in the initial stage for good fitting rate of training sample. However, the consistency of simulation results get worse for over-fitting of training sample in following stage.	artificial neural network;captcha;coefficient;computation;kappa calculus;overfitting;production (computer science);requirement;simulation	Yihan Zhang;Jigang Qiao;Bingqi Wu;Weiqi Jiang;Xiaocong Xu;Guohua Hu	2015	2015 23rd International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2015.7378560	simulation;engineering;artificial intelligence;operations research	Robotics	11.467266132302827	-19.49121676708549	149035
12bbda7f62763edb02aec7ad89b8de49b1522ac1	adaptive dynamic programming approach to experience-based systems identification and control	aptitud;contraste;vitesse;dynamic programming;velocity;control optimo;metodo adaptativo;systeme commande;aptitude;evaluation performance;sistema control;programacion dinamica;case history;learning algorithm;performance evaluation;sintesis control;neural networks;modalite traitement;implementation;evaluacion prestacion;reinforcement learning;connaissance;hombre;adaptive dynamics;programmation generique;methode adaptative;velocidad;intelligence artificielle;conocimiento;algorithme apprentissage;lenguaje algebraico;experience based identification and control;approximate dynamic programming adp;identificacion sistema;optimal control;knowledge;control system;contrast;apprentissage renforce;historique;system identification;synthese commande;commande optimale;contexto;adaptive method;human;programmation dynamique;contexte;modalidad tratamiento;artificial intelligence;langage algebrique;application method;approximate dynamic programming;inteligencia artificial;ability;implementacion;programacion generica;aprendizaje reforzado;processing speed;algoritmo aprendizaje;experience base;on line algorithm;algebraic language;context;identification systeme;control synthesis;generic programming;homme;neural network;context discernment;systems identification;estudio historico	"""Humans have the ability to make use of experience while selecting their control actions for distinct and changing situations, and their process speeds up and have enhanced effectiveness as more experience is gained. In contrast, current technological implementations slow down as more knowledge is stored. A novel way of employing Approximate (or Adaptive) Dynamic Programming (ADP) is described that shifts the underlying Adaptive Critic type of Reinforcement Learning method """"up a level"""", away from designing individual (optimal) controllers to that of developing on-line algorithms that efficiently and effectively select designs from a repository of existing controller solutions (perhaps previously developed via application of ADP methods). The resulting approach is called Higher-Level Learning Algorithm. The approach and its rationale are described and some examples of its application are given. The notions of context and context discernment are important to understanding the human abilities noted above. These are first defined, in a manner appropriate to controls and system-identification, and as a foundation relating to the application arena, a historical view of the various phases during development of the controls field is given, organized by how the notion 'context' was, or was not, involved in each phase."""	adenosine diphosphate;algorithm;algorithmic learning theory;artificial intelligence;artificial neural network;care-of address;carroll morgan (computer scientist);concurrent versions system;control engineering;controllers;design rationale;dynamic programming;entity name part qualifier - adopted;experience;experiment;fill;gain;goto;humans;ibm notes;indexes;lars gene;lars bak (computer programmer);mantle;nephrogenic systemic fibrosis;network interface controller;online and offline;otherkin;reinforcement learning;roberto busa;rule (guideline);shannon (unit);solutions;stevens-johnson syndrome;system identification;usb on-the-go;version;care of - addressparttype	George G. Lendaris	2009	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2009.06.021	simulation;optimal control;aptitude;system identification;contrast;computer science;artificial intelligence;machine learning;dynamic programming;knowledge;velocity;generic programming;implementation;artificial neural network;algorithm	Robotics	15.946149742836665	-20.537929009161793	149059
8bae165187ea22eb34a47c48277dd524bc27dc98	an accelerated approach to decentralized reinforcement learning of the ball-dribbling behavior			reinforcement learning	David Leonardo Leottau;Javier Ruiz-del-Solar	2015			artificial intelligence;machine learning;reinforcement learning;computer science	Robotics	19.39577063371777	-20.221889948337232	149181
d7f8e8e2b7fd7c0e4cac35f8a120405b9b014458	integrating grammatical inference into robotic planning		This paper presents a method for the control synthesis of robotic systems in an unknown, dynamic, and adversarial environments. We (1) incorporate a grammatical inference module that identifies the governing dynamics of the adversarial environment and (2) utilize game theory to compute a motion plan for a system given a task specification. The framework is flexible and modular since different games can be formulated for different system objectives and different grammatical inference algorithms can be utilized depending on the abstract nature of the dynamic environment.	acceptor (semiconductors);algorithm;computation;finite-state machine;game theory;grammar induction;logic programming;motion planning;nash equilibrium;requirement;robot;semiautomaton	Jane Chandlee;Jie Fu;Konstantinos Karydis;Cesar Koirala;Jeffrey Heinz;Herbert G. Tanner	2012			simulation;computer science;artificial intelligence;machine learning	Robotics	18.187853871702476	-16.313185281171908	149307
a2a6420f420419020e8ca32be3c8591194686dea	machine learning-based novelty detection for faulty wafer detection in semiconductor manufacturing	novelty detection;dimensionality reduction;virtual metrology;faulty wafer detection;semiconductor manufacturing	Since semiconductor manufacturing consists of hundreds of processes, a faulty wafer detection system, which allows for earlier detection of faulty wafers, is required. statistical process control (SPC) and virtual metrology (VM) have been used to detect faulty wafers. However, there are some limitations in that SPC requires linear, unimodal and single variable data and VM underestimates the deviations of predictors. In this paper, seven different machine learning-based novelty detection methods were employed to detect faulty wafers. The models were trained with Fault Detection and Classification (FDC) data to detect wafers having faulty metrology values. The real world semiconductor manufacturing data collected from a semiconductor fab were tested. Since the real world data have more than 150 input variables, we employed three different dimensionality reduction methods. The experimental results showed a high True Positive Rate (TPR). These results are promising enough to warrant further study.	machine learning;novelty detection;semiconductor device fabrication;wafer (electronics)	Dongil Kim;Pilsung Kang;Sungzoon Cho;Hyoungjoo Lee;Seungyong Doh	2012	Expert Syst. Appl.	10.1016/j.eswa.2011.09.088	embedded system;real-time computing;computer science;machine learning;semiconductor device fabrication;dimensionality reduction	ML	13.212611565075715	-16.102636784695772	149464
27a915fbbd76431950df79034b36264826d4ee00	optimal modularity and memory capacity of neural networks		The neural network is a powerful computing framework that has been exploited by biological evolution and by humans for solving diverse problems. Although the computational capabilities of neural networks are determined by their structure, the current understanding of the relationships between a neural network’s architecture and function is still primitive. Here we reveal that neural network’s modular architecture plays a vital role in determining the neural dynamics and memory performance of the network. In particular, we demonstrate that there exists an optimal modularity for memory performance, where a balance between local cohesion and global connectivity is established, allowing optimally modular networks to remember longer. Our results suggest that insights from dynamical analysis of neural networks and information spreading processes can be leveraged to better design neural networks and may shed light on the brain’s modular organization.	artificial neural network;computation;dynamical system;evolution;modular programming	Nathaniel Rodriguez;Eduardo Izquierdo-Torres;Yong-Yeol Ahn	2017	CoRR		machine learning;artificial neural network;modularity;artificial intelligence;modularity (networks);computer science	ML	15.840999492343546	-23.79744867252183	149599
6c36584167123e1cb36dbe2868eb1b9632689741	monte-carlo tree search for simulated car racing		Monte Carlo Tree Search (MCTS) has recently seen considerable success in playing certain types of games, most of which are discrete, fully observable zero-sum games. Consequently there is currently considerable interest within the research community in investigating what other games this algorithm might play well, and how it can be modified to achieve this. In this paper, we investigate the application of MCTS to simulated car racing, in particular the open-source racing game TORCS. The presented approach is based on the development of an efficient forward model and the discretization of the action space. This combination allows the controller to effectively search the tree of potential future states. Results show that it is indeed possible to implement a competent MCTS-based racing controller. The controller generalizes to most road tracks as long as a warm-up period is provided.	algorithm;controller (computing);discretization;monte carlo method;monte carlo tree search;observable;open-source software;torcs;tree traversal	Jacob Fischer;Nikolaj Falsted;Mathias Vielwerth;Julian Togelius;Sebastian Risi	2015			simulation;computer science;monte carlo tree search	ML	20.414567892471624	-17.67025480127722	149649
84cf51f4fdce3cecf87bbf3eab9a49feef6ba5b7	artificial intelligence based green technology retrofit for misfire detection in old engines	green technology;signal processing;rule based models;misfire;ic engine;emission control;engine condition monitoring	The core theme of the paper is misfire detection using random forest algorithm and decision tree based machine learning models for emission minimization in gasoline passenger vehicles. The engine block vibration signals are used for misfire detection. The signal is a combination of all vibration emissions of various engine components and also contains the vibration signature due to misfire. The quantum of information available at a given instant is enormous and hence suitable techniques are adopted to reduce the computational load due to redundant information. The random forest algorithm based model and the decision tree model are found to have a consistent high classification accuracy of around 89.7% and 89.3% respectively. From the results obtained the authors conclude that the combination of statistical features and random forest algorithm is suitable for detection of misfire in spark ignition engines and hence contributing to emission minimization in vehicles. DOI: 10.4018/jgc.2012010104 44 International Journal of Green Computing, 3(1), 43-55, January-June 2012 Copyright © 2012, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. 1993). Engine misfire is defined as, “lack of combustion in the cylinder due to absence of spark, poor fuel metering, poor compression, or any other cause” (California Air Resources Board, 1991). Misfire detection in an internal combustion engine is very crucial to maintain optimum performance throughout its service life and to reduce emissions.	algorithm;artificial intelligence;computation;cylinder seal;decision tree model;machine learning;random forest	S. Babu Devasenapati;K. I. Ramachandran	2012	IJGC	10.4018/jgc.2012010104	embedded system;engineering;automotive engineering;forensic engineering	AI	13.230801272477619	-17.10143274202481	149691
d095115e8e10041d512fe32a8a133ddfe6d2cbab	impact electric component of the electromagnetic field on electronic security and steering systems in personal rapid transit		Transport safety systems and electronic security system Personal Rapid Transit (PRT) steering systems constitute a spatially formed set of elements that operate together in order to achieve the assumed level of security at a railway station or during the performance of transportation operations. Occurring intended or unintended electromagnetic interferences in the process of exploitation electronic systems may cause the occurrence of catastrophic damages or can be the reason of a reduction of the work quality of these systems. Small frequency range electromagnetic interference (up to 100 kHz) that occurs in an extensive “railway” area should be considered separately, i.e. the electric and magnetic components of this field should be distinguished. Because of measurements and legal regulations concerning the impact of this interference on elements, devices and electronic systems. Any disruption of the primary functions of the steering system can be the cause of the occurrence of human life and health hazards. The present article discusses the impact of electromagnetic interference: the electric component of the field on the process of the operation of the PRT steering and security system.		Jacek Pas;Wlodzimierz Choromanski	2014		10.1007/978-3-662-45317-9_27	embedded system;electronic engineering;engineering;electrical engineering	HCI	12.325572852609284	-11.073147827728612	149714
fd7817c4cdb926bbd7acf74c33f48ce2a65f1e99	identification and predictive control of spray tower system using artificial neural network and differential evolution algorithm	poles and towers;training;prediction algorithms;recurrent neural nets air pollution control autoregressive processes evolutionary computation identification industrial control minimisation neurocontrollers optimal control predictive control;poles and towers training optimization prediction algorithms artificial neural networks mathematical model liquids;liquids;qa75 electronic computers computer science;artificial neural networks;mathematical model;who spray tower system identification artificial neural network differential evolution algorithm environmental protection measures particulate matter emission pm emission industrial productions nonlinear characteristics intelligent control technique ann based predictive control strategy de optimization algorithm optimal control signal liquid droplet size cost function minimization pm concentration recurrent neural network rnn nonlinear autoregressive with exogenous input model narx model dynamic model empirical model input pm concentration output pm concentration matlab code de best 1 bin de rand 1 bin control parameter tuning prediction horizon weight factor control horizon control response;optimization;qd chemistry;differential evolution algorithm system identification predictive control spray tower system artificial neural network	Increasing demands for high precision environmental protection measures regarding particulate matter (PM) emission from industrial productions and non-linear characteristics of spray tower system lead to the application of an intelligent control technique to adequately deal with these complexities. This includes the use of an artificial neural network (ANN) based predictive control strategy and differential evolution (DE) optimization algorithm to determines the optimal control signal, uk (liquid droplet size, dD) by minimizing the cost function such that the output is set below the allowable PM concentration. A recurrent neural network (RNN) based on non-linear autoregressive with exogenous inputs (NARX) model has been used to develop the dynamic model of the system. The data for the training was obtained from empirical model of a spray tower system which involved 500 data sets representing the process input and the output PM concentration. The control process was implemented using MATLAB code by considering two DE optimization strategies; DE/best/1/bin and DE/rand/1/bin. The effectiveness of the controllers was demonstrated for different iterations by tuning the control parameters such as the prediction horizon, weight factor and control horizon. From the control response, it can be seen that the controller for the DE/rand/1/bin does a very good job of controlling the PM below the WHO allowable emission rate of 20g/μm3.	algorithm;artificial neural network;autoregressive model;control theory;differential evolution;intelligent control;iteration;kerrison predictor;loss function;matlab;mathematical model;mathematical optimization;mean squared error;nonlinear autoregressive exogenous model;nonlinear system;optimal control;random neural network;recurrent neural network;system identification	Bashir A. Danzomo;Momoh-Jimoh E. Salami;Md. Raisuddin Khan	2015	2015 10th Asian Control Conference (ASCC)	10.1109/ASCC.2015.7244417	control engineering;engineering;artificial intelligence;machine learning	Robotics	11.802295238502023	-21.71138483752021	149825
b13d91e4f44b6fbd4d7f2b62ead62db752271016	learning and exploration in autonomous agents: adaptive and active prospect		Place learning and exploration in autonomous agents is important for understanding and building intelligent agents. Experimental and computational studies from the areas of psychology, computer science and neuroscience have achieved great successes. This thesis provides a theoretical investigation into three major problems in place learning and exploration, namely, localization, mapping, and action selection. Two benchmark models are introduced to analyze the basic aspects of place learning and exploration. The checkerboard maze is a stochastic grid-type environment. Exploration performance of an agent is evaluated by the sensory prediction capability of the agent. The evaluation does not require the knowledge of the internal representation of the agent. Furthermore, the checkerboard maze is reduced to the classical multi-armed bandit model in order to analyze the action selection problem in detail. The exploration performance in the multi-armed bandit is quantified by the estimation error of the reward means. Place learning and exploration is modelled as a Partially ObservableMarkovDecision Process (POMDP), and is implemented by a Bayesian network with internal dynamics. The map of the environment is represented by the observation probability of the POMDP, and is stored in the weights of a generative model. The belief state is tracked by Bayes filtering. The distribution of the sensory input is predicted by the generative model. Through the minimization of prediction errors by an on-line adaptive multiplicative gradient descent rule, the mapping between locations and sensory inputs is learned. In the n-armed bandit, the optimal exploration policy in the sense of total mean squared error is proved to be gain-maximization exploration. The sample complexity of the proposed ideal gain-maximization exploration policy can beO(n) as small as the counter-based and the error-based policies, both in the sense of total mean squared error and expected 0/1 loss. For realistic situations where the reward variances are unknown, a realistic gain-maximization exploration policy is derived using upper confidence limits of the reward variances. Gain-maximization is a general principle unifying a wide range of exploration strategies including counter-based and error-based policies. By generalizing the total mean squared error, the counter-based and error-based exploration policies are shown to result from the gainmaximization principle with respect to different variants of the general objective measure. Formulating the exploration in reward maximization as the learning of the differences between the reward means, we derive gain-maximization selection policies both in the ideal case and for realistic situations. Through a simple linear trade-off, gain-based rewardmaximization policies achieve smaller regret on fixed data sets, as compared to classical strategies like interval estimation methods, -greedy strategy, and upper confidence bound policy. The action selection in the full place learning problem is implemented by a network maximizing the agent’s intrinsic rewards. Action values are learned in a similar way asQ-learning. Based on the results of local gain adaptation and multi-armed bandit,two gain functions are defined as the agent’s curiosity. Moreover, an estimation of a global exploration performance measure is found to model competence motivation. Active exploration directed by the proposed intrinsic reward functions not only outperforms random exploration, but also produces curiosity behavior which is observed in natural agents. Acknowledgments The results presented in this thesis were conducted during my work at the Institute for Theoretical Neurophysics in the University of Bremen. It is my honer and pleasure to work with my colleagues, who are so friendly and supportive to help me all the time. First of all, I would thank Klaus Pawelzik to open the exciting research field for me. He is always thought provoking, insightful, and guiding me to explore scientific questions. His generous support, kind encouragement, and warmhearted friendship through all these years make my pursuit of science possible to be realized. I am also grateful to Prof. Schwegler, Prof. Bornholdt and Prof. Jaeger for their insightful comments and discussions. I especially thank Prof. Burgard for reviewing my thesis. I feel very thankful to Michael Herrmann for his constructive cooperation and discussions during these years. He is always ready to provide full strength help. I own many thanks to Agnes Janssen, who creates an amazingly friendly working atmosphere for us. I feel gratitude to Udo Ernst and David Rotermund, who maintain the computation facilities available anytime. I would thank my colleagues Matthias Bethge, Christian Eurich, Axel Etzold, Nadja Schinkel, Erich Schulzke, Onno Boehler, Juan Ochoa, Stefan Braunewell, Maria Davidich, Joerg Reichardt, Roland Rothenstein, Hedinn Steingrimsson, Andreas Thiel, Frank Emmert-Streib, Jens Otterpohl, Ronald Bormann, and Klaus Franke. Last but not least, I want to thank my whole family for their constant love, support and encouragement. I will never thank them enough.	action selection;anytime algorithm;autonomous agent;autonomous robot;bayesian network;benchmark (computing);computation;computer science;expectation–maximization algorithm;generative model;gradient descent;herbert w. franke;internationalization and localization;klaus samelson;mean squared error;memory dependence prediction;multi-armed bandit;online and offline;partially observable markov decision process;regret (decision theory);sample complexity;selection algorithm;udo of aachen	Bailu Si	2007			autonomous agent;active learning;reinforcement learning;computer science;artificial intelligence	ML	22.42512897526977	-18.478793916294098	150079
2ecbb6e3030a6c6b25c8a75307716aeb08f5afd5	an anytime multistep anticipatory algorithm for online stochastic combinatorial optimization	online algorithm;discrete optimization;search algorithm;combinatorial problems;endogenous uncertainty;artificial intelligent;stochastic optimization;decision under uncertainty;scheduling;project scheduling;markov decision process;sample average approximation;pharmaceutical industry;combinatorial optimization;stochastic programming;time constraint	The one-step anticipatory algorithms (1s-AA) is an online algorithm making decisions under uncertainty by ignoring the non-anticipativity constraints in the future. It was shown to make near-optimal decisions on a variety of online stochastic combinatorial problems in dynamic fleet management and reservation systems. Here we consider applications in which 1s-AA is not as close to the optimum and propose Amsaa, an anytime multi-step anticipatory algorithm. Amsaa combines techniques from three different fields to make decisions online. It uses the sampling average approximation method from stochastic programming, search algorithms for Markov decision processes from artificial intelligence, and discrete optimization algorithms. Amsaa was evaluated on a stochastic project scheduling application from the pharmaceutical industry featuring endogenous observations of the uncertainty. The experimental results show that Amsaa significantly outperforms state-of-the-art algorithms on this application under various time constraints.	anytime algorithm;approximation;approximation algorithm;artificial intelligence;combinatorial optimization;converge;discrete optimization;dynamic programming;emoticon;experiment;gibbs sampling;heuristic;importance sampling;linear programming relaxation;markov chain;markov decision process;markov property;mathematical induction;mathematical optimization;monte carlo method;multidimensional digital pre-distortion;multistage amplifier;online algorithm;online and offline;randomness;refinement (computing);sampling (signal processing);scheduling (computing);search algorithm;search tree;stochastic optimization;stochastic programming	Luc Mercier;Pascal Van Hentenryck	2011	Annals OR	10.1007/s10479-010-0798-7	markov decision process;stochastic programming;discrete optimization;online algorithm;mathematical optimization;combinatorial optimization;computer science;stochastic optimization;machine learning;mathematics;management science;scheduling;schedule;search algorithm	AI	21.394125823162074	-16.21012608240464	150248
6c38af9aa378e5ae997be98cc9af2b4d013dde47	augmenting sampling based controllers with machine learning		Efficient learning of 3D character control still remains an open problem despite of the remarkable recent advances in the field. We propose a new algorithm that combines planning by a sampling-based model-predictive controller and learning from the planned control, which is very noisy. We combine two methods of learning: 1) immediate but imprecise nearest-neighbor learning, and 2) slower but more precise neural net-work learning. The nearest neighbor learning allows to rapidly latch on to new experiences whilst the neural net-work learns more gradually and develops a stable representation of the data. Our experiments indicate that the learners augment each other, and allow rapid discovery and refinement of complex skills such as 3D bipedal locomotion. We demonstrate this in locomotion of 1-, 2- and 4-legged 3D characters under disturbances such as heavy projectile hits and abruptly changing target direction. When augmented with the learners, the sampling based model predictive controller can produce these stable gaits in under a minute on a 4-core CPU. During training the system runs real-time or at interactive frame rates depending on the character complexity.	academy;algorithm;artificial neural network;central processing unit;experience;experiment;feedback;game controller;iteration;machine learning;precomputation;real-time transcription;refinement (computing);sampling (signal processing);simulation;while	Joose Rajamäki;Perttu Hämäläinen	2017		10.1145/3099564.3099579	robot learning;instance-based learning;online machine learning;semi-supervised learning;active learning (machine learning);machine learning;wake-sleep algorithm;stability (learning theory);multi-task learning;artificial intelligence;computer science	ML	19.805538671945122	-21.076442125704062	150451
b9e49932a515b38db8c3093ab43066b2fc79181e	gain-based exploration: from multi-armed bandits to partially observable environments	gain maximization exploration policy;optimal exploration asymptotically;active learning;error based exploration;counter based exploration;knowledge acquisition multi armed bandits partially observable environments gain maximization exploration policy error based exploration counter based exploration optimal exploration asymptotically;partially observable environments;prior knowledge;upper bound;knowledge acquisition;multi armed bandits;partial observation;learning artificial intelligence;learning artificial intelligence decision making knowledge acquisition;learning estimation error gain measurement decision making upper bound testing redundancy entropy knowledge acquisition robots;multi armed bandit	We introduce gain-based policies for exploration in active learning problems. For exploration in multi-armed bandits with the knowledge of reward variances, an ideal gain-maximization exploration policy is described in a unified framework which also includes error-based and counter-based exploration. For realistic situations without prior knowledge of reward variances, we establish an upper bound on the gain function, resulting in a realistic gain- maximization exploration policy which achieves the optimal exploration asymptotically. Finally, we extend the gain- maximization exploration scheme towards partially observable environments. Approximating the environment by a set of local bandits, the agent actively selects its actions by maximizing discounted gain in learning local bandits. The resulting gain-based exploration not only outperforms random exploration, but also produces curiosity-driven behavior which is observed in natural agents.	active learning (machine learning);expectation–maximization algorithm;multi-armed bandit;partially observable system;unified framework	Bailu Si;J. Michael Herrmann;Klaus Pawelzik	2007	Third International Conference on Natural Computation (ICNC 2007)	10.1109/ICNC.2007.395	mathematical optimization;engineering;artificial intelligence;machine learning	ML	21.712851735694063	-18.219303916046403	150457
b12a59b2472a706590119cec8c1f157ec1d4e627	soft-computing models for soot-blowing optimization in coal-fired utility boilers	predictive control;intelligent soot blowing;theoretical model;performance indicator;soft computing;probabilistic model;artificial neural networks;monitoring system;statistical analysis;feedback loop;coal fired boilers;heat flux;anfis model;adaptive neuro fuzzy inference system;artificial neural network;expert system	Fouling and slagging are classical difficulties in pulverized fuel utility boilers, which cause important degradation and dramatic reduction of efficiency. Current cleaning devices, traditionally based on prefixed soot-blowing manoeuvres, mitigate the problem only partially and offers clear optimization possibilities. But the development of predictive control is far from easy: soot-blowing represents a significant fraction of efficiency, the effectiveness has an intrinsic level of randomness and the fouling dynamics involves nonlinear feedback loops. The complexity of the phenomenon makes not applicable theoretical models or statistical analysis. The problem requires the application of alternative methodologies as expert systems or soft-computing based techniques. The present paper aims to develop a probabilisntelligent soot-blowing oal-fired boilers tic model to predict the effectiveness of soot-blowing based in Artificial Neural Networks and Adaptive Neuro-Fuzzy Inference Systems. The validity of the model has been illustrated in a real case-study boiler, a 350 MWe Spanish power station. Training and test data for these models are provided by a monitoring system based on heat-flux measurements in the furnace water-walls. For evaluation and comparison purposes, the quality of prediction obtained for the mentioned algorithms is analyzed in terms of performance indices. The connection weight approach reveals the relative importance of input variables in each soft-computing model. Finally, the integration of these models into an advisory tool is discussed.	algorithm;artificial neural network;elegant degradation;expert system;feedback;fuzzy logic;mathematical optimization;neural network software;neuro-fuzzy;nonlinear system;randomness;soft computing;sputter cleaning;test data	B. Peña;E. Teruel;L. I. Díez	2011	Appl. Soft Comput.	10.1016/j.asoc.2010.04.023	statistical model;simulation;adaptive neuro fuzzy inference system;computer science;artificial intelligence;performance indicator;machine learning;heat flux;feedback loop;pulverized coal-fired boiler;model predictive control;artificial neural network	ML	11.213422719669905	-20.768373089463715	150689
a481ef233939b74448d18fb342f251def5db12f5	recurrent transition hierarchies for continual learning: a general overview		Continual learning is the unending process of learning new things on top of what has already been learned (Ring 1994). Temporal Transition Hierarchies (TTHs) were developed to allow prediction of Markov-k sequences in a way that was consistent with the needs of a continual-learning agent (Ring 1993). However, the algorithm could not learn arbitrary temporal contingencies. This paper describes Recurrent Transition Hierarchies (RTH), a learning method that combines several properties desirable for agents that must learn as they go. In particular, it learns online and incrementally, autonomously discovering new features as learning progresses. It requires no reset or episodes. It has a simple learning rule with update complexity linear in the number of parameters.	algorithm;learning rule;markov chain	Mark Ring	2011			error-driven learning;artificial intelligence;machine learning;algorithm	ML	19.761447998219484	-22.796603450117306	150715
151284f4ad85cd31aabeabcfa3b6a84cbb13c7e0	a learning approach to the database selection problem in the presence of dynamic user interests and database contents		Database Selection is the problem of choosing, from a finite number of databases, the one that contains the most relevant information pertaining to a query. Previous approaches to this problem consisted of deterministic search techniques in conjunction with efficient pruning of search spaces, based on vector space model and ranking. In this article, we propose a new probabilistic search method, based on a reinforcement learning algorithm, to solve the database selection problem, where an agent learns to map situations to action by means of receiving reward and penalties for the action taken and trying to maximize its rewards. We use reinforcement algorithm with user feedback to learn a policy, which maps a particular topic or particular interest to a set of databases. Reinforcement learning is an attractive approach to this problem due to its ability to generate optimal solutions for both stationary and non-stationaryldynamically changing environments(queries). Experiments with simple queries show that reinforcement learning has potential to be considered as an efficient approach for database selection.	database;experiment;map;reinforcement learning;selection algorithm;stationary process	Pooja Bajracharya;Snehasis Mukhopadhyay	2004		10.1002/meet.1450410128	error-driven learning;computer science;theoretical computer science;machine learning;data mining;information retrieval	ML	22.230160272478116	-18.28249383709823	150776
285b55bb58ed28584196f2daf2e9ceae3949ed8e	robust insulin estimation under glycemic variability using bayesian filtering and gaussian process models		Abstract The ultimate goal of an artificial pancreas (AP) is finding the optimal insulin rates that can effectively reduce high blood glucose (BG) levels in type 1 diabetic patients. To achieve this, most autonomous closed-loop strategies continuously compute the optimal insulin bolus to be administrated on the basis of the estimated plasma concentrations for glucose and insulin. Unlike subcutaneous glucose levels which can be measured in real-time, unavailability of insulin sensors makes it essential the use of mathematical models so as to fully estimate plasma insulin concentrations. For model-based estimation, GP-Bayesian filters have been recently proposed to incorporate probabilistic non-parametric Gaussian process (GP) models of dynamic systems into Kalman filtering techniques. As a result, model uncertainty can explicitly be incorporated into the prediction step and in the filtering processes, which is usually not the case for more traditional filtering strategies that resort to parametric models for state estimation. More specifically, the question arises as to whether glycemic variability is properly taken into account in model formulations and whether it would compromise proper estimation of plasma insulin concentration. To tackle this, a stochastic glycemic model including variability was incorporated into different parametric and nonparametric filtering techniques to provide an estimate of the plasma insulin levels. In particular, we compared density representation against using knowledge about the parameterization of the transition dynamics and the observation function. We found that, as glycemic variability increases, filtering techniques based on parametric models rapidly degrades their performance as a consequence of large nonlinearities. Results show that Bayes’ filtering techniques increase predictability of the patient state, and thus, boost safety and performance in the AP control and monitoring tasks.	gaussian process;spatial variability	Luis Omar Ávila;Mariano De Paula;Ernesto C. Martínez;Marcelo Luis Errecalde	2018	Biomed. Signal Proc. and Control	10.1016/j.bspc.2018.01.019	artificial pancreas;parametric model;pattern recognition;kalman filter;artificial intelligence;filter (signal processing);mathematics;nonparametric statistics;parametric statistics;gaussian process;glycemic;control theory	ML	14.848842087850793	-15.346019343889145	150921
f34ffc6bbe4ee7a4d3f7698c7a345cf8c00fde85	an adaptive machine learning decision system for flexible predictive maintenance	ion beams;semiconductor manufacturing feature extraction industrial modeling optical emission spectroscopy predictive maintenance sparse principal component analysis regularization methods;predictive maintenance;feature extraction;principal component analysis;manufacturing;semiconductor industry cost reduction decision support systems etching flexible manufacturing systems ion beam applications learning artificial intelligence maintenance engineering process monitoring regression analysis remaining life assessment scheduling;etching;ion beam etching process adaptive machine learning decision system flexible predictive maintenance process monitoring manufacturing environments maintenance cost reduction downtime reduction data intensive industries semiconductor manufacturing adaptive pdm based flexible maintenance scheduling decision support system opportunity costs risk costs regularized regression methods remaining useful life estimation industrial dataset;manufacturing principal component analysis feature extraction ion beams etching predictive maintenance	Process monitoring and Predictive Maintenance (PdM) are gaining increasing attention in most manufacturing environments as a means of reducing maintenance related costs and downtime. This is especially true in industries that are data intensive such as semiconductor manufacturing. In this paper an adaptive PdM based flexible maintenance scheduling decision support system, which pays particular attention to associated opportunity and risk costs, is presented. The proposed system, which employs Machine Learning and regularized regression methods, exploits new information as it becomes available from newly processed components to refine remaining useful life estimates and associated costs and risks. The system has been validated on a real industrial dataset related to an Ion Beam Etching process for semiconductor manufacturing.	data-intensive computing;decision boundary;decision support system;downtime;dynamic time warping;exploit (computer security);fragmented object;ion beam;machine learning;scheduling (computing);semiconductor device fabrication;simulation;support vector machine;time series	Gian Antonio Susto;Jian Wan;Simone Pampuri;Mattia Zanon;Adrian B. Johnston;Paul G. O'Hara;Se&#x00E1;n McLoone	2014	2014 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2014.6899418	reliability engineering;engineering;operations management;manufacturing engineering	Robotics	13.139145551649486	-12.425330576967406	150978
08b57648ea807417fe9bf905bf664de6118bb84e	stochastic hybrid models for predicting the behavior of drivers facing the yellow-light-dilemma	road traffic gaussian processes monte carlo methods probability;upper bound;computational modeling;trajectory;stochastic processes;mathematical model;vehicles stochastic processes upper bound mathematical model trajectory computational modeling adaptation models;warning systems stochastic hybrid models driver behavior prediction yellow light dilemma gaussian process estimation monte carlo simulations probability red light violations;vehicles;adaptation models	We address the problem of predicting whether a driver facing the yellow-light-dilemma will cross the intersection with the red light. Based on driving simulator data, we propose a stochastic hybrid system model for driver behavior. Using this model combined with Gaussian process estimation and Monte Carlo simulations, we obtain an upper bound for the probability of crossing with the red light. This upper bound has a prescribed confidence level and can be calculated quickly on-line in a recursive fashion as more data become available. Calculating also a lower bound we can show that the upper bound is on average less than 3% higher than the true probability. Moreover, tests on driving simulator data show that 99% of the actual red light violations, are predicted to cross on red with probability greater than 0.95 while less than 5% of the compliant trajectories are predicted to have an equally high probability of crossing. Determining the probability of crossing with the red light will be important for the development of warning systems that prevent red light violations.	algorithm;driving simulator;experiment;gaussian process;hybrid system;line level;monte carlo method;online and offline;recursion;simulation	Daniel Hoehener;Patrick A Green;Domitilla Del Vecchio	2015	2015 American Control Conference (ACC)	10.1109/ACC.2015.7171849	stochastic process;econometrics;simulation;computer science;trajectory;mathematical model;mathematics;upper and lower bounds;computational model;statistics	Robotics	10.056107797919655	-11.706405428443965	150979
2004c0947ac31cbfbd279585db0a09daabf2629d	a robust reinforcement based self constructing neural network	topology;control systems;evolutionary computation;value function robust reinforcement based self constructing neural network high skilled human resources sophisticated control systems control system automatic generation evolutionary methods reinforcement methods;robust reinforcement based self constructing neural network;learning;sophisticated control systems;neural nets;conference;neural nets evolutionary computation learning artificial intelligence;automatic generation;action selection;network topology;neurons artificial neural networks robots learning network topology topology control systems;artificial neural networks;control system;human resource;robots;high skilled human resources;control system automatic generation;evolutionary methods;value function;neurons;learning artificial intelligence;neural network;reinforcement methods	Usually, many high-skilled human resources are required to create sophisticated control systems. Automatic generation of control systems can overcome these requirements. Because of their versatility and flexibility neural networks gained an important role for this task. While evolutionary methods have been relatively successful in generating neural networks, they have some limitations, in addition to being computationally expensive, because they rely on adapting populations instead of individuals. Reinforcement methods on the other hand can improve and adapt the behaviour of an individual; the reinforcement methods that are presented in this paper can grow a neural network during operation. We show that neural networks can be created for various domains without changing any parameters. Additionally, our neural network can learn the action selection policy and the value function locally within the neurons. These features make our neural network highly flexible and distinguish it from other reinforcement based constructive neural networks.	action selection;analysis of algorithms;artificial neural network;bellman equation;computer cluster;control system;evolutionary algorithm;population;radial basis function;reinforcement learning;requirement;spiking neural network	Andreas Huemer;Mario A. Góngora;David A. Elizondo	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596762	robot;stochastic neural network;action selection;computer science;artificial intelligence;machine learning;evolutionary acquisition of neural topologies;bellman equation;artificial neural network;network topology	ML	16.528527742885764	-23.291729115252558	151242
3f6c97fe2b3b3cb495d4da15583a8823297e5d76	realization of task intelligence for service robots in an unstructured environment	task intelligence;episodic memory;deep art network;motion planning;task planner	In order to perform various tasks using a robot in a real environment, it is necessary to learn the tasks based on recognition, to be able to derive a task sequence suitable for the situation, and to be able to generate a behavior adaptively. To deal with this issue, this paper proposes a system for realizing task intelligence having a memory module motivated by human episodic memory, and a task planning module to resolve the current situation. In addition, this paper proposes a technique that can modify demonstrated trajectories according to current robot states and recognized target positions in order to perform the determined task sequence, as well as a technique that can generate the modified trajectory without collisions with surrounding obstacles. The effectiveness and applicability of the task intelligence are demonstrated through experiments with Mybot, a humanoid robot developed in the Robot Intelligence Technology Laboratory at KAIST.	robot	Deok-Hwa Kim;Gyeong-Moon Park;Yong-Ho Yoo;Si-Jung Ryu;In-Bae Jeong;Jong-Hwan Kim	2017	Annual Reviews in Control	10.1016/j.arcontrol.2017.09.013	memory module;control engineering;task analysis;hierarchical task network;humanoid robot;machine learning;simulation;robot;motion planning;episodic memory;artificial intelligence;cognitive robotics;computer science	Robotics	18.466424354996434	-21.532883574575777	151582
e56160766014d6d664255837eb0dceeef67a29a4	detection of water safety conditions in distribution systems based on artificial neural network and support vector machine		This study presents the development of artificial neural network (ANN) and support vector machine (SVM) classification models for predicting the safety conditions of water in distribution pipes. The study was based on 504 monthly records of water quality parameters; pH, turbidity, color and bacteria counts taken from nine different locations across the water distribution network in the city of Alesund, Norway. The models predicted the safety conditions of the water samples in the pipes with 98% accuracy and 94% respectively during testing. The high accuracy achieved in the model results indicate that contamination events in distribution systems that result in unsafe values of the water quality parameters can be detected using these classification models. This can provide water utility managers with real time information about the safety conditions of treated water at different locations of distribution pipes before water reaches consumers.	artificial neural network;support vector machine	Hadi Mohammed;Ibrahim A. Hameed;Razak Seidu	2018		10.1007/978-3-319-99010-1_52	water safety;support vector machine;turbidity;artificial neural network;water quality;artificial intelligence;environmental science;pattern recognition	ML	10.519286736895285	-18.498269133701513	151923
8ea2321b5d7c1413279d8b6e697eecd7c95955de	results uncertainty of solid waste generation forecasting by hybrid of wavelet transform-anfis and wavelet transform-neural network	wavelet transform-anfis;input variable;ann model;wt-anfis model;artificial neural network;wt-ann model;weekly wg;uncertainity;model calculation;input variables preprocessing;wavelet transform;solid waste generation forecasting;municipal solid waste management;wavelet transform-neural network;accurate prediction;adaptive neuro-fuzzy inference system;results uncertainty;dynamic mswms;neural network;adaptive neuro fuzzy inference system;solid waste	Both planning and design of municipal solid waste management systems (MSWMS) require accurate prediction of waste generation (WG). In this study, the hybrid of wavelet transform-adaptive neuro-fuzzy inference system (WT-ANFIS) and wavelet transform-artificial neural network (WT-ANN) is used to predict the weekly WG in Tehran, concerning complexity and dynamic MSWMS. In order to input variables preprocessing is done by WT and then new variables entered to ANFIS and ANN models. Consequently, output uncertainty of WT-ANFIS and WT-ANN models is done. The results achieved in this research indicate the positive effect of input variables preprocessing by WT in the prediction of weekly WG in Tehran, and it has led to noticeable increase in the accuracy of two model calculations. However, WT-ANFIS model had better results than WT-ANN model, because of the smaller uncertainty than WT-ANN model. 2009 Published by Elsevier Ltd.	adaptive neuro fuzzy inference system;artificial neural network;inference engine;neuro-fuzzy;preprocessor;two-hybrid screening;uncertainty principle;waste;wavelet transform	Roohollah Noori;Mohammad Ali Abdoli;Ashkan Farokhnia;Maryam Abbasi	2009	Expert Syst. Appl.	10.1016/j.eswa.2008.12.035		AI	11.364039365322741	-18.490818683101693	152009
3dbd7b66e0b8aee2a131bfdd27b1b5b70f5d150b	evolution of neural controllers for competitive game playing with teams of mobile robots	mobile robot;close coupling;mobile robots;behavioral robotics;evolutionary robotics;evolutionary neural computing;evolutionary process;game playing;robot colonies;simulation environment;training algorithm;artificial neural network	In this work, we describe the evolutionary training of artificial neural network controllers for competitive team game playing behaviors by teams of real mobile robots. This research emphasized the development of methods to automate the production of behavioral robot controllers. We seek methods that do not require a human designer to define specific intermediate behaviors for a complex robot task. The work made use of a real mobile robot colony (EVolutionary roBOTs) and a closely coupled computer-based simulated training environment. The acquisition of behavior in an evolutionary robotics system was demonstrated using a robotic version of the game Capture the Flag. In this game, played by two teams of competing robots, each team tries to defend its own goal while trying to ‘attack’ another goal defended by the other team. Robot neural controllers relied entirely on processed video data for sensing of their environment. Robot controllers were evolved in a simulated environment using evolutionary training algorithms. In the evolutionary process, each generation consisted of a competitive tournament of games played between the controllers in an evolving population. Robot controllers were selected based on whether they won or lost games in the course of a tournament. Following a tournament, the neural controllers were ranked competitively according to how many games they won and the population was propagated using a mutation and replacement strategy. After several hundred generations, the best performing controllers were transferred to teams of real mobile robots, where they exhibited behaviors similar to those seen in simulation including basic navigation, the ability to distinguish between different types of objects, and goal tending behaviors. © 2004 Elsevier B.V. All rights reserved.	algorithm;artificial neural network;benchmark (computing);capture the flag;erdős–rényi model;evaluation function;evolutionary computation;evolutionary robotics;fitness function;mobile robot;performance evaluation;simulation;testbed;virtual reality	Andrew L. Nelson;Edward Grant;Thomas C. Henderson	2004	Robotics and Autonomous Systems	10.1016/j.robot.2004.01.001	mobile robot;simulation;computer science;artificial intelligence;social robot;evolutionary robotics;artificial neural network	Robotics	17.815271996822187	-19.106255355305393	152089
d712b6a8a938dfdc24e7c5fea458c521ee6ad64c	hierarchical modeling of systems with similar components: a framework for adaptive monitoring and control	hierarchical bayesian modeling;markov chain monte carlo;markov decision process;adaptive monitoring and control	System management includes the selection of maintenance actions depending on the available observations: when a system is made up by components known to be similar, data collected on one is also relevant for the management of others. This is typically the case of wind farms, which are made up by similar turbines. Optimal management of wind farms is an important task due to high cost of turbines' operation and maintenance: in this context, we recently proposed a method for planning and learning at system-level, called PLUS, built upon the Partially Observable Markov Decision Process (POMDP) framework, which treats transition and emission probabilities as random variables, and is therefore suitable for including model uncertainty. PLUS models the components as independent or identical. In this paper, we extend that formulation, allowing for a weaker similarity among components. The proposed approach, called Multiple Uncertain POMDP (MU-POMDP), models the components as POMDPs, and assumes the corresponding parameters as dependent random variables. Through this framework, we can calibrate specific degradation and emission models for each component while, at the same time, process observations at system-level. We compare the performance of the proposed MU-POMDP with PLUS, and discuss its potential and computational complexity. & 2016 Elsevier Ltd. All rights reserved.	computational complexity theory;content management system;elegant degradation;markov chain;partially observable markov decision process	Milad Memarzadeh;Matteo Pozzi;J. Zico Kolter	2016	Rel. Eng. & Sys. Safety	10.1016/j.ress.2016.04.016	markov decision process;simulation;partially observable markov decision process;markov chain monte carlo;engineering;machine learning;mathematics;statistics	AI	14.361989894590264	-11.480618677352622	152213
844a95f55f1d3f2483c543c8f82ade3810542de9	application of bio-inspired data processing in intelligent transportation systems	bio inspired data processing;autonomous evaluation;knowledge based soft computing technique;least squares approximations;sensors;intelligent transportation systems;soft computing;distributed processing;intelligent transportation system;distributed computing;automated highways;data processing;least squares approximation;immune system feature;combinational architecture;intelligent transportation systems bioinformatics least squares approximation data processing intelligent sensors immune system computer networks distributed computing condition monitoring wireless sensor networks;computer networks;wireless sensor network;radial basis function networks;artificial neural networks;monitoring system;sensory record reliability;least squares mechanism;condition monitoring;radial basis function network;feature extraction;global data prediction;transportation;immune system;pattern classification;knowledge based data classification mechanism;bio inspired data processing soft computing wireless sensor network intelligent transportation system;computerised monitoring;distributed data processing;wireless sensor networks artificial immune systems automated highways computerised monitoring distributed processing feature extraction knowledge based systems least squares approximations pattern classification radial basis function networks transportation;probabilistic neural network;bioinspired data processing;artificial immune systems;wireless sensor networks;knowledge based systems;intelligent sensors;immunological center selection;bioinformatics	There has been a growing interest in using the soft computing techniques for distributed data processing in monitoring systems during last years; wireless sensor network is an example which can be utilized to record and process the environmental conditions in transportation systems. In this paper, by using knowledge based soft computing techniques, the reliability of the sensory records is evaluated autonomously in an intelligent transportation system; for this purpose, a new combinational architecture is applied including a bio-inspired local/global data approximation as well as a knowledge based data classification mechanism. The approximation mechanism is established on a least squares mechanism for global data prediction and a radial basis function network including immunological center selection to perform the local data approximations. To classify the records, a new probabilistic neural network including immune system features is developed. The proposed data processing technique is applicable for various intelligent data processing purposes.	algorithm;approximation;artificial neural network;british informatics olympiad;combinational logic;distributed computing;least squares;probabilistic neural network;radial (radio);radial basis function network;soft computing	Amir Sheikh Jabbari;Hans-Jörg Kreowski;Walter Lang	2010	2010 5th IEEE International Conference Intelligent Systems	10.1109/IS.2010.5548366	computer science;artificial intelligence;machine learning;data mining	Robotics	15.700307505569215	-19.21221487352395	152489
174a03c3c6c8c3c432a40e7df00cc708136dc65f	swarm intelligence - from natural to artificial systems			naruto shippuden: clash of ninja revolution 3;swarm intelligence	Eric Bonabeau;Marco Dorigo;Guy Theraulaz	1999				AI	22.314351170306384	-10.096530220414202	152529
efe72409a40acedad7b5ba86b82e951c6cfcd317	learning battles in vizdoom via deep reinforcement learning		First-person shooter (FPS) video games play an important role in game artificial intelligence (AI). In this paper, we present an effective deep reinforcement learning (DRL) method to learn battles in ViZDoom. Our approach utilizes the actor-critic with Kronecker-factored trust region (ACKTR), a sample-efficient and computationally inexpensive DRL method. We train our ACKTR agents in two battle scenarios, and compare with the advantage actor-critic (A2C) baseline agent. The experimental results demonstrate that DRL methods successfully teach agents to battle in these scenarios. In addition, the ACKTR agents significantly outperform the A2C agents in terms of all the metrics by a significant margin.	artificial intelligence (video games);baseline (configuration management);driven right leg circuit;first-person (video games);floating point systems;reinforcement learning;trust region	Kun Shao;Dongbin Zhao;Nannan Li;Yuanheng Zhu	2018	2018 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2018.8490423	simulation;battle;machine learning;task analysis;artificial intelligence;reinforcement learning;visualization;computer science;trust region	AI	19.531590805291497	-20.05912525200235	152665
18a0fc21a409bdbc3a7c43333d9a1b00e41f8eb3	stochastic local search for pomdp controllers	partially observed markov decision process;dynamic program;decision problem;large scale;stochastic local search	The search for finite-state controllers for partially observable Markov decision processes (POMDPs) is often based on approaches like gradient ascent, attractive because of their relatively low computational cost. In this paper, we illustrate a basic problem with gradient-based methods applied to POMDPs, where the sequential nature of the decision problem is at issue, and propose a new stochastic local search method as an alternative. The heuristics used in our procedure mimic the sequential reasoning inherent in optimal dynamic programming (DP) approaches. We show that our algorithm consistently finds higher quality controllers than gradient ascent, and is competitive with (and, for some problems, superior to) other state-of-the-art controller and DP-based algorithms on large-scale POMDPs.	algorithm;computational complexity theory;decision problem;dynamic programming;gradient descent;heuristic (computer science);local search (optimization);markov chain;partially observable markov decision process;partially observable system;times ascent	Darius Braziunas;Craig Boutilier	2004			mathematical optimization;partially observable markov decision process;computer science;artificial intelligence;machine learning;decision problem	AI	21.19345729906716	-16.63842202982919	152706
64a0a2be3c643aa729ea47c5755145b4b360b5ce	a decision heuristic for monte carlo tree search doppelkopf agents		This work builds up on previous research by Sievers and Helmert, who developed an Monte Carlo Tree Search based doppelkopf agent. This four player card game features a larger state space than skat due to the unknown cards of the contestants. Additionally, players face the unique problem of not knowing their teammates at the start of the game. Figuring out the player parties is a key feature of this card game and demands differing play styles depending on the current knowledge of the game state. In this work we enhance the Monte Carlo Tree Search agent created by Sievers and Helmert with a decision heuristic. Our goal is to improve the quality of playouts, by suggesting high quality moves and predicting enemy moves based on a neural network classifier. This classifier is trained on an extensive history of expert player moves recorded during official doppelkopf tournaments. Different network architectures are discussed and evaluated based on their prediction accuracy. The best performing network was tested in a direct comparison with the previous Monte Carlo Tree Search agent by Sievers and Helmert. We show that high quality predictions increase the quality of playouts. Overall, our simulations show that adding the decision heuristic increased the strength of play under comparable computational effort.	algorithm;artificial neural network;computational intelligence;database;display resolution;dropout (neural networks);heuristic;long short-term memory;monte carlo method;monte carlo tree search;network architecture;recurrent neural network;reinforcement learning;simulation;state space	Alexander Dockhorn;Christoph Doell;Matthias Hewelt;Rudolf Kruse	2017	2017 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2017.8285181	network architecture;adversary;state space;artificial neural network;machine learning;heuristic;monte carlo tree search;artificial intelligence;computer science	AI	18.58748627557268	-18.544193354072863	153080
6b0b81bb9a2b52150ffb3c5afb6ea91fe10715b6	experimental evaluation of straight line programs for hydrological modelling with exogenous variables		The estimation of the future streamflows is one of the main research topics in hydrology and a very important task for water resources management. The aim of this work is to use symbolic regression in order to model the hydrological balance. Specifically, we use genetic programming to solve the symbolic regression problem. Nevertheless, in this work we use Straight Line Programs instead of trees to encode algebraic expression. Results shows that this representation for algebraic expressions could improve the results in both accuracy and computational time.		Ramón Rueda Delgado;Luis G. Baca Ruiz;Patricia Jimeno-Sáez;Manuel P. Cuéllar;David Pulido-Velazquez;Mara del Carmen Pegalajar	2017		10.1007/978-3-319-59650-1_38	machine learning;symbolic regression;line (geometry);artificial intelligence;genetic programming;the symbolic;computer science;hydrological modelling;algebraic expression	Theory	10.167691160638284	-20.44667197013066	153211
583b1300c6faaca5d80c78c203fa1eefe3c55131	schema co-evolutionary algorithm (scea)	tecnologia electronica telecomunicaciones;simple genetic algorithm sga;robotics and systems;walsh schema transform;institute of control;schema theorem building block hypothesis;schema co evolutionary algorithm scea;제2회 로보틱스 및 응용연구회 지능시스템연구회 합동학술발표대회;제어로봇시스템학회;kwee bo sim;tecnologias;grupo a		evolutionary algorithm	Kwee-Bo Sim;Dong-Wook Lee	2004	IEICE Transactions		computer science;artificial intelligence;algorithm	Visualization	22.12048908198521	-10.206945714003261	153701
48cce5ee49facf75eeb12832c387452424b645dd	a bayesian framework for reinforcement learning	bayesian framework;learning process;reinforcement learning;dynamic program;optimal policy;bayesian method;posterior distribution;stationary process	The reinforcement learning problem can be decomposed into two parallel types of inference: (i) estimating the parameters of a model for the underlying process; (ii) determining behavior which maximizes return under the estimated model. Following Dearden, Friedman and Andre (1999), it is proposed that the learning process estimates online the full posterior distribution over models. To determine behavior, a hypothesis is sampled from this distribution and the greedy policy with respect to the hypothesis is obtained by dynamic programming. By using a different hypothesis for each trial appropriate exploratory and exploitative behavior is obtained. This Bayesian method always converges to the optimal policy for a stationary process with discrete states.	dynamic programming;greedy algorithm;nat friedman;reinforcement learning;stationary process	Malcolm J. A. Strens	2000			temporal difference learning;unsupervised learning;stationary process;econometrics;variable-order bayesian network;wake-sleep algorithm;bayesian probability;machine learning;pattern recognition;mathematics;posterior probability;learning classifier system;reinforcement learning;statistics	ML	22.249520182029304	-18.68130781739244	153877
9e5be523621e4636fa7ac2c7087d288324d9d451	aero-engine exhaust gas temperature prognostic model based on gated recurrent unit network		Exhaust gas temperature (EGT), a key gas path parameter, is regarded as the performance indication parameter of the aero-engine. In engineering, the EGT prognostic model provides supports for aero-engine performance assessment, maintenance plan optimization and operation schedule determination. The EGT parameters are regarded as the time series with nonlinear characteristics, which should be considered in the prognostic model. To address these issues, an EGT prognostic model based on the gated recurrent unit (GRU) network was proposed in this paper. The time series and nonlinear characteristics could be addressed by the GRU network simultaneously. For better prediction accuracy, the architecture of the GRU layer was determined by contrast experiments, in which the GRU stacked layer number, look-back timestamps and output dimension were determined. The proposed prognostic model was validated by the real-valued EGT data of a turbofan aero-engine. Five conventional machine learning prognostic models were regarded as the comparison models. The comparison experiments showed that the proposed EGT prognostic model had advantages in prediction accuracy and stability. The proposed EGT prognostic model could provide supports for aero-engine prognostic and health management in engineering.	elm;evolutionary governance theory;experiment;machine learning;mathematical optimization;nonlinear system;radio frequency;time series;windows aero	Shisheng Zhong;Zhen Li;Lin Lin;Yongjian Zhang	2018	2018 IEEE International Conference on Prognostics and Health Management (ICPHM)	10.1109/ICPHM.2018.8448857	architecture;time series;reliability engineering;prognostics;data modeling;exhaust gas;logic gate;computer science	SE	12.978363461364685	-17.7975269371331	153976
84cd3385be9e755558a4855662a1ce4b3b97e8e7	drama, a connectionist architecture for control and learning in autonomous robots	hebbian learning;unsupervised dynamical learning;neural nets;robotics;time series;time delay recurrent neural network;dynamic control;time delay;autonomous robots;sensors and actuators;associative memory;artificial intelligence;recurrent neural network;autonomous robot;real time computing;spatio temporal associations;on line learning;numerical simulation	Adaptation to their environment is a fundamental capability for living agents, from which autonomous robots could also benefit. This work proposes a connectionist architecture, DRAMA, for dynamic control and learning of autonomous robots. DRAMA stands for dynamical recurrent associative memory architecture. It is a time-delay recurrent neural network, using Hebbian update rules. It allows learning of spatio-temporal regularities and time series in discrete sequences of inputs, in the face of an important amount of noise. The first part of this paper gives the mathematical description of the architecture and analyses theoretically and through numerical simulations its performance. The second part of this paper reports on the implementation of DRAMA in simulated and physical robotic experiments. Training and rehearsal of the DRAMA architecture is computationally fast and inexpensive, which makes the model particularly suitable for controlling computationally-challenged robots. In the experiments, we use a basic hardware system with very limited computational capability and show that our robot can carry out real time computation and on-line learning of relatively complex cognitive tasks. In these experiments, two autonomous robots wander randomly in a fixed environment, collecting information about its elements. By mutually associating information of their sensors and actuators, they learn about physical regularities underlying their experience of varying stimuli. The agents learn also from their mutual interactions. We use a teacher-learner scenario, based on mutual following of the two agents, to enable transmission of a vocabulary from one robot to the other.	as-interface;artificial neural network;autonomous robot;computation;connectionism;content-addressable memory;experiment;hebbian theory;interaction;numerical analysis;online and offline;online machine learning;randomness;recurrent neural network;simulation;time series;vocabulary	Aude Billard;Gillian Hayes	1999	Adaptive Behaviour	10.1177/105971239900700103	simulation;hebbian theory;computer science;artificial intelligence;recurrent neural network;machine learning;time series;robotics;artificial neural network	Robotics	19.18781583829778	-23.260809786077036	154158
f2f2f657624a4348cc5f340049ff8555519601d5	adaptive profit sharing reinforcement learning method for dynamic environment	partial observable markov process adaptive forgettable profit sharing reinforcement learning method dynamic environment nonmarkov property;profit sharing;reinforcement learning;forgetting;informing science;markov property;rational theorem reinforcement learning forgetting;learning system;dynamic environment;markov processes incentive schemes learning artificial intelligence;markov process;learning educational institutions learning systems markov processes robustness information science;incentive schemes;markov processes;learning artificial intelligence;environmental change;rational theorem;effective action	In this paper, an Adaptive Forgettable Profit Sharing reinforcement learning method is introduced. This method enables agents to adapt the environmental changes very quickly. It can be used to learn the robust and effective actions in the uncertain environments which have the non-markov property, especially the partial observable markov process (POMDP). Profit Sharing learns rational policy that is easy to be learned and results in good behavior in POMDP. However, the policy becomes worse in the dynamic and huge environment that changes frequently and require the lots of actions to achieve the goal. In order to handle such kind of environment, the forgetting, which gives the adaptability and rationality to Profit Sharing, is implemented. This method allows the agent to forget past experiences that reduce the rationality of its policy. The usefulness of the proposed algorithm is demonstrated through the numerical examples.	algorithm;experience;markov chain;markov property;numerical analysis;numerical method;partially observable markov decision process;rationality;reinforcement learning	Sadamori Koujaku;Kota Watanabe;Hajime Igarashi	2011	2011 10th International Conference on Machine Learning and Applications and Workshops	10.1109/ICMLA.2011.25	computer science;knowledge management;artificial intelligence;machine learning;markov process;reinforcement learning;statistics	Robotics	20.22884886883269	-19.294035158932	154444
e5936841bbe746bae0d27486e9203f49337faa28	fuzzy and tile coding function approximation in agent coevolution	reinforcement learning;coevolution;fuzzy logic;function approximation;tile coding	Reinforcement learning (RL) is a machine learning technique for sequential decision making. This approach is well proven in many small-scale domains. The true potential of this technique cannot be fully realised until it can adequately deal with the large domain sizes that typically describe real world problems. RL with function approximation is one method of dealing with the domain size problem. This paper investigates two different function approximation approaches to RL: Fuzzy Sarsa and gradient-descent Sarsa(λ) with tile coding. It presents detailed experiments in two different simulation environments on the effectiveness of the two approaches. Initial experiments indicated that the tile coding approach had greater modelling capabilities in both testbed domains. However, experimentation in a coevolutionary scenario has indicated that Fuzzy Sarsa has greater flexibility.	algorithm;approximation;cooperative coevolution;data compression;experiment;fuzzy logic;gradient descent;machine learning;newton's method;reinforcement learning;simulation;state-action-reward-state-action;testbed	Laurissa N. Tokarchuk;John Bigham;Laurie G. Cuthbert	2006			simulation;artificial intelligence;machine learning;mathematics	ML	15.714561159169094	-21.932938985710724	154849
e7ce1ce2fbced0eef2ee1062c9d673a71b4fb617	cyclone performance prediction using linear regression techniques		A wide range of industrial fields utilize cyclone separators and so, evaluating their performance according to different materials and varying operating conditions could contribute useful information and could also save these industries significant amounts of capital. This study models cyclone performance using linear regression techniques and low errors were obtained in comparison with the values obtained from real experiments. Linear regression and generalized linear regression techniques, simple and enhanced with Gradient Boosting techniques, were used to create linear models with low errors of approximately 0.83 % in cyclone performance.	cyclone;performance prediction	Marina Corral Bobadilla;Roberto Fernández-Martínez;Rubén Lostado-Lorza;Fátima Somovilla Gomez;Eliseo P. Vergara González	2016		10.1007/978-3-319-47364-2_6	performance prediction;statistics;gradient boosting;linear model;linear regression;generalized linear model;cyclone;mathematics	ML	11.241637379568827	-18.717310659894242	154911
6c8beaf077d5820d3f1c177301b9b22f6d860454	a wide area synchrophasor based ann transient stability predictor for the egyptian power system	phasor measurements units;egyptian power system wide area synchrophasor ann transient stability artificial neural networks phaser measurements units;phase measurement;transient stability prediction;generators;wide area applications artificial neural networks egyptian power system phasor measurements units synchrophasor transient stability prediction;rate of change;neural nets;real time;phasor measurement unit;power system dynamics;transient stability;synchrophasor;wide area applications;transient analysis;power system transient stability neural nets phase measurement;artificial neural networks;generators artificial neural networks power system stability phasor measurement units power system dynamics transient analysis;power system;power system transient stability;power system stability;egyptian power system;phasor measurement units;artificial neural network	This paper proposes an Artificial Neural Networks (ANN) based technique for transient stability prediction. The ANN makes use of the advent of Phasor Measurements Units (PMU) for real-time prediction. Rate of change of bus voltages and angles is used to train a two layers ANN. Potential of the proposed approach is tested using the Egyptian Power System (EPS) as a study system.	artificial neural network;kerrison predictor;neural networks;phasor;power management unit;real-time clock	Fahd Hashiesh;Hossam E. Mostafa;Ibrahim Helal;Mohamed M. Mansour	2010	2010 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT Europe)	10.1109/ISGTEUROPE.2010.5638923	control engineering;electronic engineering;engineering;electrical engineering	Robotics	10.589456202107929	-17.400271629551096	155581
5aad60330120090a261f59090e4283ea5aefbd7a	developing a repeated multi-agent constant-sum game algorithm using human computation	constant sum games;tenspotter;tournament play multiagent constant sum game algorithm human computation multiagent constant sum games tens potter easy to use publicly available game human players play strategy collusion strategy tournament format multiagent algorithms learning techniques multiagent machine algorithms;multi agent systems computer games learning artificial intelligence;multi agent games;intelligent agents;android based games intelligent agents multi agent games constant sum games tenspotter human computation;human computation;android based games	In repeated multi-agent constant-sum games, each player's objective is to maximize control over a finite set of resources. We introduce Tens potter, an easy-to-use publicly-available game designed to allow human players to compete as agents against a machine algorithm. The algorithm learns play strategies from humans, reduces them to nine basic strategies, and uses this knowledge to build and adapt its collusion strategy. We use a tournament format to test our algorithm against human players as well as against other established multi-agent algorithms taken from the literature. Through these tournament experiments, we demonstrate how learning techniques adapted using human computation--information obtained from both human and machine inputs--can contribute to the development of an algorithm able to defeat two well-established multi-agent machine algorithms in tournament play.	algorithm;experiment;human-based computation;multi-agent system	Christopher G. Harris	2012	2012 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2012.175	combinatorial game theory;simulation;turns, rounds and time-keeping systems in games;computer science;artificial intelligence;theoretical computer science;game mechanics;machine learning;intelligent agent	AI	19.28848906761554	-17.753116732931762	155850
d1bdfe1a60c0578c26a1fe1128bc1549c20c6ff3	decentralized dynamic task allocation for uavs with limited communication range		We present the Limited-range Online Routing Problem (LORP), which involves a team of Unmanned Aerial Vehicles (UAVs) with limited communication range that must autonomously coordinate to service task requests. We first show a general approach to cast this dynamic problem as a sequence of decentralized task allocation problems. Then we present two solutions both based on modeling the allocation task as a Markov Random Field to subsequently assess decisions by means of the decentralized Max-Sum algorithm. Our first solution assumes independence between requests, whereas our second solution also considers the UAVs’ workloads. A thorough empirical evaluation shows that our workloadbased solution consistently outperforms current state-of-the-art methods in a wide range of scenarios, lowering the average service time up to 16%. In the bestcase scenario there is no gap between our decentralized solution and centralized techniques. In the worst-case scenario we manage to reduce by 25% the gap between current decentralized and centralized techniques. Thus, our solution becomes the method of choice for our problem.	aerial photography;algorithm;belief propagation;centralized computing;computation;dynamic problem (algorithms);loss function;markov chain;markov random field;relevance;requirement;routing;server side includes;unmanned aerial vehicle;worst-case scenario	Marc Pujol-Gonzalez;Jesús Cerquides;Pedro Meseguer;Juan A. Rodríguez-Aguilar;Milind Tambe	2018	CoRR		markov random field;workload;dynamic problem;distributed computing;computer science	Robotics	19.407102664530015	-14.73102121930571	156031
2e91dbbb2c5be47bfd3963672fcb4597a8c71f39	rolling horizon methods for games with continuous states and actions	evolutionary algorithm rolling horizon methods game continuous states game action game continuous dynamics agent learning t holop algorithm truncated hierarchical open loop planning algorithm evolutionary planning inverted pendulum problem double integrator problem lunar lander arcade game optimisation algorithm;qa75 electronic computers computer science;artificial neural networks;planning artificial intelligence computer games evolutionary computation learning artificial intelligence;artificial neural networks benchmark testing optimization;optimization;benchmark testing	It is often the case that games have continuous dynamics and allow for continuous actions, possibly with with some added noise. For larger games with complicated dynamics, having agents learn offline behaviours in such a setting is a daunting task. On the other hand, provided a generative model is available, one might try to spread the cost of search/learning in a rolling horizon fashion (e.g. as in Monte Carlo Tree Search). In this paper we compare T-HOLOP (Truncated Hierarchical Open Loop Planning), an open loop planning algorithm at least partially inspired by MCTS, with a version of evolutionary planning that uses CMA-ES (which we call EVO-P) in two planning benchmark problems (Inverted Pendulum and the Double Integrator) and in Lunar Lander, a classic arcade game. We show that EVO-P outperforms T-HOLOP in the classic benchmarks, while T-HOLOP is unable to find a solution using the same heuristics. We conclude that off-the-shelf evolutionary algorithms can be used successfully in a rolling horizon setting, and that a different type of heuristics might be needed under different optimisation algorithms.	actor model;arcade game;automated planning and scheduling;benchmark (computing);cma-es;evolutionary algorithm;expectation propagation;experiment;generative model;heuristic (computer science);inverted pendulum;lunar lander (video game series);mathematical optimization;monte carlo method;monte carlo tree search;online and offline;requirement	Spyridon Samothrakis;Samuel A. Roberts;Diego Perez Liebana;Simon M. Lucas	2014	2014 IEEE Conference on Computational Intelligence and Games	10.1109/CIG.2014.6932888	benchmark;simulation;computer science;artificial intelligence;machine learning;artificial neural network	AI	19.91577085051515	-18.071103007815946	156314
224aed8592fc922d3d14859aa2775196418d3886	anytime intention recognition via incremental bayesian network reconstruction	anytime inference algorithm;bayesian network construction;bayesian networks;intention recognition	This paper presents an anytime algorithm for incremental intention recognition in a changing world. The algorithm is performed by dynamically constructing the intention recognition model on top of a prior domain knowledge base. The model is occasionally reconfigured by situating itself in the changing world and removing newly found out irrelevant intentions. We also discuss some approaches to knowledge base representation for supporting situation-dependent model construction. Reconfigurable Bayesian Networks are employed to produce the intention recognition model.	anytime algorithm;bayesian network;knowledge base;relevance	Han The Anh;Luís Moniz Pereira	2010			computer science;artificial intelligence;machine learning;bayesian network;data mining	AI	20.4855806177931	-21.023592577765136	156477
631ab4abdb88e3525afae7b69f3aaa9468a4fa89	an immune algorithm based fuzzy predictive modeling mechanism using variable length coding and multi-objective optimization allied to engineering materials processing	cluster algorithm;optimisation;evolutionary computation;materials processing;momentum terms;transparent fuzzy model;immune algorithm;fuzzy predictive modeling;variable length code;multi objective optimization;g700 artificial intelligence;backpropagation;fuzzy sets;accuracy;multiobjective optimization algorithm;fuzzy rule base;backpropagation algorithm;steel industry;steel industry backpropagation evolutionary computation fuzzy systems optimisation;engineering materials processing;back propagation algorithm;clustering algorithms;optimization;prediction model;optimization fuzzy sets modeling clustering algorithms encoding accuracy data models;variable length coding;encoding;modeling;transparent fuzzy model immune algorithm fuzzy predictive modeling variable length coding engineering materials processing multiobjective fuzzy modeling evolutionary based clustering algorithm fuzzy rule base backpropagation algorithm momentum terms multiobjective optimization algorithm steel industry;fuzzy systems;fuzzy model;multiobjective fuzzy modeling;evolutionary based clustering algorithm;data models	In this paper, a systematic multi-objective fuzzy modeling approach is proposed, which can be regarded as a three-stage modeling procedure. In the first stage, an evolutionary based clustering algorithm is developed to extract an initial fuzzy rule base from the data. Based on this model, a back-propagation algorithm with momentum terms is used to refine the initial fuzzy model. The refined model is then used to seed the initial population of an immune inspired multi-objective optimization algorithm in the third stage to obtain a set of fuzzy models with improved transparency. To tackle the problem of simultaneously optimizing the structure and parameters, a variable length coding scheme is adopted to improve the efficiency of the search. The proposed modeling approach is applied to a real data set from the steel industry. Results show that the proposed approach is capable of eliciting not only accurate but also transparent fuzzy models.	algorithm;backpropagation;cluster analysis;fuzzy concept;fuzzy rule;mathematical optimization;multi-objective optimization;pareto efficiency;predictive modelling;rule-based system;software propagation;variable-length code	Jun Chen;Mahdi Mahfouf	2008	2008 IEEE International Conference on Granular Computing	10.1109/GRC.2008.4664729	mathematical optimization;defuzzification;fuzzy transportation;computer science;artificial intelligence;fuzzy number;backpropagation;neuro-fuzzy;machine learning;fuzzy set operations;evolutionary computation	Robotics	10.830629348852112	-23.11014754139552	156486
82a59f8adea47fd4b71694fa3faf34e3e5530266	automatic generation of fuzzy rules using the fuzzy behaviorist approach: the case of sensor-based robot navigation	fuzzy behaviors;fuzzy control;automated fuzzy rules generation;sensorbased navigation;autonomous robot	ABSTRACTA system for automatic generation of fuzzy rules is proposed which is based on a new approach, called “Fuzzy Behaviorist,” and on its associated formalism for rule base development in behavior-based robot control systems. The automated generator of fuzzy rules automatically constructs the membership functions of fuzzy rules that implement reasoning schemes that have been expressed in qualitative terms. The system also checks for completeness of the rule base and independence and/or redundancy of the rules to ensure that the requirements of the formalism are satisfied. Examples of the automatic generation of fuzzy rules for cases involving suppression and/or inhibition of fuzzy behaviors are given and discussed. Experimental results obtained with the automated fuzzy rule generator applied to the domain of sensor-based navigation in a priori unknown environments using one of our autonomous test-bed robots and a real car in outdoor environments are then presented and discussed to illustrate the feasi...	robotic mapping	François G. Pin;Yutaka Watanabe	1995	Intelligent Automation & Soft Computing	10.1080/10798587.1995.10750627	fuzzy logic;fuzzy electronics;fuzzy cognitive map;defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;fuzzy associative matrix;fuzzy set operations;fuzzy control system	Robotics	22.450526402190825	-12.9038167508526	156592
d8bc2e2537cecbe6e751d4791837251a249cd06d	assessing tracking performance in complex scenarios using mean time between failures	tracking performance solution quality mean time between failures dummy algorithm tracking algorithms complex scenarios;standards;time measurement;prediction algorithms;standards target tracking time measurement prediction algorithms object tracking measurement uncertainty aggregates;measurement uncertainty;aggregates;object tracking;object tracking large scale systems;target tracking	Existing measures for evaluating the performance of tracking algorithms are difficult to interpret, which makes it hard to identify the best approach for a particular situation. As we show, a dummy algorithm which does not actually track scores well under most existing measures. Although some measures characterize specific error sources quite well, combining them into a single aggregate measure for comparing approaches or tuning parameters is not straightforward. In this work we propose `mean time between failures' as a viable summary of solution quality - especially when the goal is to follow objects for as long as possible. In addition to being sensitive to all tracking errors, the performance numbers are directly interpretable: how long can an algorithm operate before a mistake has likely occurred (the object is lost, its identity is confused, etc.)? We illustrate the merits of this measure by assessing solutions from different algorithms on a challenging dataset.	aggregate data;algorithm;cross-validation (statistics);dummy variable (statistics);loss function;mean squared error;mean time between failures;network switch;xfig	Peter Carr;Robert T. Collins	2016	2016 IEEE Winter Conference on Applications of Computer Vision (WACV)	10.1109/WACV.2016.7477617	computer vision;simulation;prediction;computer science;video tracking;data mining;statistics;measurement uncertainty;time	Vision	24.463342423488843	-20.885896294974483	156659
a85627fc51f132e855a1ae811a5480764a1ffdaa	optimization of graph sub-structures using intelligent swarm agents			particle swarm optimization	Sherin M. Youssef	2004				Robotics	22.503370948783953	-9.979798206546292	156766
db48845ad5ab5776c5c292d5cee9c1b7b6e70f27	degradations analysis and aging modeling for health assessment and prognostics of pemfc	proton exchange membrane fuel cell pemfc;critical components;health assessment;aging model;prognostics	Applying prognostics to Proton Exchange Membrane Fuel Cell (PEMFC) stacks is a good solution to help taking actions extending their lifetime. However, it requires a great understanding of the degradation mechanisms and failures occurring within the stack. This task is not simple when applied to a PEMFC due to the different levels (stack - cells - components), the different scales and the multiple causes that lead to degradation. To overcome this problem, this work proposes a methodology dedicated to the setting of a framework and a modeling of the aging for prognostics. This methodology is based on a deep literature review and degradation analyses of PEMFC stacks. This analysis allows defining a proper vocabulary dedicated to PEMFC׳s prognostics and health management and a clear limited framework to perform prognostics. Then the degradations review is used to select critical components within the stack, and to define their critical failure mechanisms thanks the proposal of new fault trees. The impact of these critical components and mechanisms on the power loss during aging is included to the model for prognostics. This model is finally validated on four datasets with different mission profiles both for health assessment and prognostics.		Marine Jouin;Rafael Gouriveau;Daniel Hissel;Marie-Cécile Péra;Noureddine Zerhouni	2016	Rel. Eng. & Sys. Safety	10.1016/j.ress.2015.12.003	reliability engineering;engineering;forensic engineering;prognostics	SE	12.541350893189009	-12.383841554175916	156777
7906dec6c58f6fdedb10b7ceb4104dfc70a6ce93	synthesis of neural tree models by improved breeder genetic programming	improved breeder genetic programming;time series;gaussian mutation;neural tree model;noisy fitness evaluation	Neural tree model has been successfully applied to solving a variety of interesting problems. In most previous studies, optimization of the neural tree model was divided into two steps: first structure optimization, then parameter optimization. One major problem in the evolution of structure without parameter information was noisy fitness evaluation. In this paper, an improved breeder genetic programming algorithm is proposed to the synthesis of neural tree model. The effectiveness and performance of the method are evaluated on time series prediction problems and compared with those of related methods. Simulation results show that the proposed algorithm is a potential method with better performance and effectiveness.	algorithm;genetic programming;mathematical optimization;non-deterministic turing machine;potential method;simulation;time series	Feng Qi;Xiyu Liu;Yinghong Ma	2010	Neural Computing and Applications	10.1007/s00521-010-0451-z	mathematical optimization;computer science;artificial intelligence;machine learning;time series;statistics	AI	13.659916047780218	-23.384970997389583	156790
81cee0e83c2667af1b1eeee03e2a6ddc23c3c487	railway track circuit fault diagnosis using recurrent neural networks	degradation;rail transportation;circuit faults;neural networks;railway track circuit fault identification railway track circuit fault diagnosis railway network safety railway network availability long short term memory recurrent neural network spatial dependences temporal dependences lstm recurrent neural network test input sequences t distributed stochastic neighbor embedding method t sne method railway track circuit fault detection;insulation life;stochastic processes fault diagnosis learning artificial intelligence neural net architecture railway safety recurrent neural nets;circuit faults rail transportation fault diagnosis degradation insulation life neural networks integrated circuit modeling;integrated circuit modeling;track circuit fault diagnosis long short term memory lstm recurrent neural network rnn;fault diagnosis	Timely detection and identification of faults in railway track circuits are crucial for the safety and availability of railway networks. In this paper, the use of the long-short-term memory (LSTM) recurrent neural network is proposed to accomplish these tasks based on the commonly available measurement signals. By considering the signals from multiple track circuits in a geographic area, faults are diagnosed from their spatial and temporal dependences. A generative model is used to show that the LSTM network can learn these dependences directly from the data. The network correctly classifies 99.7% of the test input sequences, with no false positive fault detections. In addition, the t-Distributed Stochastic Neighbor Embedding (t-SNE) method is used to examine the resulting network, further showing that it has learned the relevant dependences in the data. Finally, we compare our LSTM network with a convolutional network trained on the same task. From this comparison, we conclude that the LSTM network architecture is better suited for the railway track circuit fault detection and identification tasks than the convolutional network.	artificial neural network;biological neural networks;fault detection and isolation;leigh disease;network architecture;neural tube defects;recurrent neural network;sensor;t-distributed stochastic neighbor embedding	Tim de Bruin;Kim Verbert;Robert Babu&#x0161;ka	2017	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2016.2551940	embedded system;real-time computing;degradation;computer science;machine learning;artificial neural network	ML	15.276481002026477	-17.49452515215663	156949
c5e9e079bf16c146626d2b567ecd5d0b1f1656df	extending particle swarm optimisation via genetic programming	genetique;modelizacion;fitness landscape;swarm intelligence;genetic program;paysage;genetica;paisaje;algoritmo genetico;genetics;modelisation;commande force;optimizacion enjambre particula;algorithme genetique;optimisation essaim particule;algorithme evolutionniste;control fuerza;genetic algorithm;algoritmo evolucionista;evolutionary algorithm;landscape;reseau neuronal;modeling;particle swarm optimisation;red neuronal;neural network;force control	Particle Swarm Optimisers (PSOs) search using a set of interacting particles flying over the fitness landscape. These are typically controlled by forces that encourage each particle to fly back both towards the best point sampled by it and towards the swarm’s best. Here we explore the possibility of evolving optimal force generating equations to control the particles in a PSO using genetic programming.	artificial intelligence;genetic programming;interaction;mathematical optimization;particle filter;particle swarm optimization;problem domain;sampling (signal processing);search algorithm	Riccardo Poli;William B. Langdon;Owen Holland	2005		10.1007/978-3-540-31989-4_26	simulation;systems modeling;genetic algorithm;fitness landscape;swarm intelligence;computer science;artificial intelligence;machine learning;evolutionary algorithm;landscape;particle swarm optimization;artificial neural network;algorithm	Robotics	23.693636512020838	-12.066445748733639	156979
55ba8912b7e6701d324a4a23c7beea45e752c425	water fixture identification in smart housing: a domain knowledge based case study	water resources;monitoring;feature extraction;smart meters;intelligent sensors;water conservation	In current practice, smart housing environments often over-install smart sensors on every fixture and log data from them at high sampling rates, resulting in more data being collected than is necessary. Fixture identification offers a possible alternative to reduce the number of sensors installed and the amount of data collected in smart housing. Fixture identification applies classifiers to label utility consumption data aggregated at the apartment level by the specific fixture that actually contributes the data, such as the shower or the kitchen sink. Successful fixture identification can be used to educate tenants, optimize the resource supply strategy, and offer a smart solution for detecting abnormal usage activities. In this paper, we report a case study of water fixture identification by using support vector machines (SVMs) to perform fixture classification. We use the Smart Housing Dataset from Clarkson University, which comprises of one academic year of tenant activities from 12 student apartments. Our results show that the proposed approach achieves an average accuracy between 78% to 87.8% for identifying hot water fixtures including kitchen sink, bathroom sink and shower. As a result, the number of smart meters per apartment is reduced from 7 to 3, one for hot water, one for cold water, and the third for toilet. The novelty of our study lies in the feature selection process, which is guided by our domain knowledge of water fixture characteristics and the correlation between water fixture usage and other user behavior in the apartments. We describe our proposed features, their rationale, and their effect on classification performance.	design rationale;feature selection;kitchen sink regression;sampling (signal processing);sensor;smart meter;statistical classification;sudarsky's gas giant classification;support vector machine;test fixture	Yan Gao;Daqing Hou;Natasha Banerjee;Sean Banerjee	2016	2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)	10.1109/ICMLA.2016.0162	water conservation;water resources;simulation;feature extraction;computer science;intelligent sensor	Mobile	11.414411504954106	-15.95346934445131	156999
46f60c551221ae172b741af1048b6678a2b19f63	a new approach for manufacturing forecast problems with insufficient data: the case of tft-lcds	forecasting;small data set;k means;bpnn;tft lcds	Manufacturing forecast problems have been widely discussed in recent years, where more accurate predictions could reduce the overall manufacturing costs. This study uses the case of ensuring the heights of thin film transistor–liquid crystal display photo-spacers. It is a small sample size prediction problem, because the data available for analysis is limited on the manufacturing lines. A new approach is developed to deal with this problem, which involves three steps. The first step is using K-means clustering to separate data into K clusters, while the second step is to compute the possibility through the fuzzy membership function in each cluster for attribute extension. The last step is to put the data with new generate attributes into a backpropagation neural network (BPNN) machine learning algorithm. Two performance evaluation methods, cross-validation and data specification testing, are selected to compare the proposed method with three popular prediction models: linear regression, support vector machine for regression (SVR), and BPNN. The results show that the proposed method outperforms the others with regard to the total errors, mean square error, and standard deviation.	algorithm;artificial neural network;backpropagation;cluster analysis;cross-validation (statistics);k-means clustering;machine learning;mean squared error;performance evaluation;support vector machine;thin-film transistor;thin-film-transistor liquid-crystal display	Der-Chiang Li;Chih-Chieh Chang;Chiao-Wen Liu;Wen-Chih Chen	2013	J. Intelligent Manufacturing	10.1007/s10845-011-0577-6	mathematical optimization;forecasting;computer science;artificial intelligence;marketing;machine learning;data mining;statistics;k-means clustering	ML	12.173984012724652	-18.386950798415366	157066
a3097515095041373241ce4228555d5ba5c5cf17	bp neural network integration model research for hydraulic metal structure health diagnosing	integration model;health diagnosing;bagging technology;bp neural network;hydraulic metal structure	Several potential network structures are chosen to do a large number of experimental analysis, historical data is divided into training sample and testing sample, and the corresponding neural network model is established with BP learning algorithm. After checking the testing sample, a superior network integration model which can be applied for hydraulic metal structure health grade diagnosing is determined. By plenty of experimental tests and verification analysis, it is concluded that the two-hidden-layer neural network model suits hydraulic metal structure health diagnosing better. As for the gate health diagnosing, based on Bagging technology, the BP neural network integration model for hydraulic metal structure health diagnosing is researched and constructed. The analysis of the sample showed that its accuracy rate (78%) is obviously better than the single neural network model(67%). The BP neural network integration model will work together with the FAHP model the author studied, that can make the diagnosis results more reasonable and reliable.	algorithm;artificial neural network;cognition;engineering sample;fault tolerance;human factors and ergonomics;interference (communication);network model;neural network software;parallel computing;tree accumulation;verification and validation	Guangming Yang;Chongshi Gu;Yong Huang;Kun Yang	2014	Int. J. Comput. Intell. Syst.	10.1080/18756891.2014.966999	artificial intelligence;operations research	AI	12.884735305736074	-17.687316892590843	157074
611540fb218ef989fd689fb854f4d2ca90f28bec	prognostics by interacting multiple model estimator	prognostics techniques failure model modeling failing models remaining useful life interacting multiple model estimator filtering technique information fusion ability built in probabilistic metric failure model tracking system health health index degradation rate confidence interval imm based rul estimation constant degradation rate data generation;multiple failure models;indexes degradation mathematical model acceleration data models fatigue load modeling;remaining life assessment condition monitoring estimation theory failure mechanical failure analysis fault diagnosis probability;benchmark data prognostics multiple failure models interacting multiple model estimator;interacting multiple model estimator;prognostics;benchmark data	In prognostics, the modeling of the failure models is complicated even for a single component, such as fatigue crack growth. For a complex system, there are a large number of components, and hence the failing models can be even more complicated due to diverse sub-systems and their components. The remaining useful life (RUL) of the system, as a whole, depends on many factors and there are often sudden changes in its progression pattern. The interacting multiple model (IMM) estimator is a filtering technique that tracks multiple models and reports the probability of each model. The information fusion ability of IMM with a built-in probabilistic metric is highly desirable in failure model tracking and higher level fusion. A general framework is proposed to describe the system health by a health index, then the RUL can be evaluated as the current health value divided by the degradation rate of the health index at that moment. Within the general framework of a health index, an IMM estimator is proposed to identify the failure models and evaluate both the values and the confidence interval of the RUL. Simulations on various health degradation models are carried out to illustrate the effectiveness of the IMM based RUL estimation. Specifically, the RUL sub-models can be with nearly constant degradation rate, with accelerated growing degradation rate, or some drastic break-down due to environmental changes such as a hard failure. In simulations, the truth is known, and hence the performance of the RUL estimator can be precisely assessed. This paper has not only proposed a fusion scheme to handle various failure models, but also presented the data generation procedure of health index in various situations. Such data sets can be used as benchmarks to compare various prognostics techniques.	benchmark (computing);canonical account;color gradient;complex system;computer simulation;elegant degradation;failure;interaction;radar tracker	Yanjun Yan;Mahendra Mallick;James Z. Zhang;Jie Liu	2016	2016 IEEE International Conference on Prognostics and Health Management (ICPHM)	10.1109/ICPHM.2016.7542822	reliability engineering;engineering;forensic engineering;statistics	SE	14.631385166451834	-15.087585184068642	157269
7671abbe85c2059971395cb96fd1e61c8e51407e	combining reward shaping and curriculum learning for training agents with high dimensional continuous action spaces		The needs for training agent with high dimensional continuous action spaces will increase as the robot hardware such as robotic arms and humanoid robots are becoming more and more sophisticated. However, it is difficult and time-consuming task. To tackle the problem, we combine reward shaping and curriculum learning. More specifically, the rewards are provided to the agent for every step it takes and the difficulty of the problem gradually increases depending on the agent learning. Both reward function and curriculum are designed to make the agent achieve its objective. The simulation results demonstrate that the proposed scheme outperforms the comparisons.	coat of arms;humanoid robot;multi-agent system;noise shaping;performance;reinforcement learning;simulation;spaces;traffic shaping;whole earth 'lectronic link	Sooyoung Jang;Mikyong Han	2018	2018 International Conference on Information and Communication Technology Convergence (ICTC)	10.1109/ICTC.2018.8539438	robot;curriculum;humanoid robot;machine learning;robotic arm;linear programming;computer science;artificial intelligence	Robotics	19.13463833011235	-20.461365818809217	157394
f0b437975f7b0b81ff57b47426889d8373d0b98f	a new method for adaptive model-based control of non-linear dynamic plants using a neuro-fuzzy-fractal approach	computer program;soft computing;fuzzy logic;fractal dimension;food industry;neuro fuzzy;model based control;mathematical model;neural network;non linear dynamics	We describe in this paper a new method for adaptive model-based control of non-linear dynamic plants using Neural Networks, Fuzzy Logic and Fractal Theory. The new neuro-fuzzy-fractal method combines Soft Computing (SC) techniques with the concept of the fractal dimension for the domain of Non-Linear Dynamic Plant Control. The new method for adaptive model-based control has been implemented as a computer program to show that our neuro-fuzzy-fractal approach is a good alternative for controlling non-linear dynamic plants. We illustrate in this paper our new methodology with the case of controlling biochemical reactors in the food industry. For this case, we use mathematical models for the simulation of bacteria growth for several types of food. The goal of constructing these models is to capture the dynamics of bacteria population in food, so as to have a way of controlling this dynamics for industrial purposes.	fractal;neuro-fuzzy;nonlinear system	Patricia Melin;Oscar Castillo	2001	Soft Comput.	10.1007/s005000000069	fuzzy logic;food industry;computer science;artificial intelligence;neuro-fuzzy;machine learning;mathematical model;soft computing;fractal dimension;artificial neural network	Robotics	12.289779019050457	-23.01243549562068	157504
a21cbe9614ba2fb3f61cfe134777310b61b40cd7	multi-timescale nexting in a reinforcement learning robot	general form;arbitrary function;nexting prediction;linear function approximation;sensory input signal;substantial accuracy;value function;multi-timescale nexting;simple timescales;general nexting;discount rate	The term 'nexting' has been used by psychologists to refer to the propensity of people and many other animals to continually predict what will happen next in an immediate, local, and personal sense. The ability to 'next' constitutes a basic kind of awareness and knowledge of one's environment. In this paper we present results with a robot that learns to next in real time, making thousands of predictions about sensory input signals at timescales from 0.1 to 8 seconds. Our predictions are formulated as a generalization of the value functions commonly used in reinforcement learning, where now an arbitrary function of the sensory input signals is used as a pseudo reward, and the discount rate determines the timescale. We show that six thousand predictions, each computed as a function of six thousand features of the state, can be learned and updated online ten times per second on a laptop computer, using the standard temporal-difference(脦禄) algorithm with linear function approximation. This approach is sufficiently computationally efficient to be used for real-time learning on the robot and sufficiently data efficient to achieve substantial accuracy within 30 minutes. Moreover, a single tile-coded feature representation suffices to accurately predict many different signals over a significant range of timescales. We also extend nexting beyond simple timescales by letting the discount rate be a function of the state and show that nexting predictions of this more general form can also be learned with substantial accuracy. General nexting provides a simple yet powerful mechanism for a robot to acquire predictive knowledge of the dynamics of its environment.	reinforcement learning;robot	Joseph Modayil;Adam White;Richard S. Sutton	2012		10.1007/978-3-642-33093-3_30	robot learning;error-driven learning	Robotics	19.736749912019558	-23.51263699806044	157521
a9096ad8421627edcfcf849964eddd853f1303c5	model-based adversarial imitation learning.		Generative adversarial learning is a popular new approach to training generative models which has been proven successful for other related problems as well. The general idea is to maintain an oracle D that discriminates between the expert’s data distribution and that of the generative model G. The generative model is trained to capture the expert’s distribution by maximizing the probability of D misclassifying the data it generates. Overall, the system is differentiable end-toend and is trained using basic backpropagation. This type of learning was successfully applied to the problem of policy imitation in a model-free setup. However, a model-free approach does not allow the system to be differentiable, which requires the use of high-variance gradient estimations. In this paper we introduce the Model based Adversarial Imitation Learning (MAIL) algorithm. A model-based approach for the problem of adversarial imitation learning. We show how to use a forward model to make the system fully differentiable, which enables us to train policies using the (stochastic) gradient of D. Moreover, our approach requires relatively few environment interactions, and fewer hyper-parameters to tune. We test our method on the MuJoCo physics simulator and report initial results that surpass the current state-of-the-art.	algorithm;backpropagation;generative model;gradient descent;interaction;simulation	Nir Baram;Oron Anschel;Shie Mannor	2016	CoRR		generative grammar;machine learning;artificial intelligence;differentiable function;generative model;adversarial system;oracle;backpropagation;imitation;computer science	ML	21.277749222830636	-21.547714969202055	157532
f92c337417edbc931cd073bdc8ce0e80d199b066	automatic and accurate evaluation of the parameters of a magnetic hysteresis model	backpropagation;electrical engineering computing;feedforward neural nets;magnetic cores;magnetic domain walls;magnetic hysteresis;modelling;optimisation;parameter estimation;jiles-atherton model;pspice;artificial neural networks;automatic accurate evaluation;backpropagation;data acquisition;domain wall motion;domain wall pinning;feedforward network;hysteresis loop;learning phase;magnetic core;magnetic hysteresis model;magnetic induction;magnetic material under test;model parameters evaluation;multidimensional optimization;parameter accuracy improvement	This paper presents a method based on both artificial neural networks (ANNs) and on a multidimensional optimization procedure in order to significantly reduce the time taken and to improve the accuracy in evaluating parameters of the Jiles-Atherton model of magnetic hysteresis. The main steps of the method are (1) data acquisition of the experimental hysteresis loop of the magnetic material under test, (2) evaluation of the model's parameters by means of ANN, and (3) parameter accuracy improvement by means of a multidimensional optimization procedure. In order to highlight the method's effectiveness, the results of numerical and experimental tests are also given	hysteresis	Domenico Grimaldi;Linus Michaeli;Arrigo Palumbo	2000	IEEE Trans. Instrumentation and Measurement	10.1109/19.836327		Embedded	13.192736532363883	-20.150016362351252	157816
9dd5264a4ce28cfb4acaf52ac0e4f7ec27c1d561	a probabilistic-based airframe integrity management model	bayes estimation;largo fisura;modelizacion;rotura fatiga;crack;crack closure effect;ajustamiento modelo;fatigue life prediction;methode semiempirique;fatigue;duree vie fatigue;propriete physique;fiabilidad;reliability;physics of failure;modele empirique;envejecimiento;rupture fatigue;fatigue fracture;fissure;dommage cumulatif;bayesian updating;data collection;lognormal distribution;prior distribution;integrated management;efecto ciere fisura;loi lognormale;aeronef;probabilistic approach;fisura;cumulative damage;fatigue life;aeronave;health management;dano cumulativo;ajustement modele;modelisation;modelo cierre;systeme incertain;estimacion bayes;ley lognormal;propagation fissure;crack propagation;propiedad fisica;enfoque probabilista;approche probabiliste;fiabilite;model matching;metodo semiempirico;ageing;distributed models;empirical model;vieillissement;life prediction;modelo empirico;longevidad fatiga;crack growth;effet fermeture fissure;sistema incierto;aging aircraft;semiempirical method;modeling;uncertain system;prognostics;longueur fissure;physical properties;modele fermeture;propagacion fisura;aircraft;estimation bayes;airframe reliability;closure model;crack length	This paper proposes a lognormal distribution model to relate crack-length distribution to fatigue damage accumulated in aging airframes. The fatigue damage is expressed as fatigue life expended (FLE) and is calculated using the strain-life method and Miner's rule. A two-stage Bayesian updating procedure is constructed to determine the unknown parameters in the proposed semi-empirical model of crack length versus FLE. At the first stage of the Bayesian updating, the crack closure model is used to simulate the crack growth based upon generic but uncertain physical properties. The simulated crack-growth results are then used as data to update the uninformative prior distributions of the unknown parameters of the proposed semi-empirical model. At the second stage of the Bayesian updating, the crack-length data collected from field inspections are used as evidence to further update the posteriors from the first stage of the Bayesian updating. Two approaches are proposed to build the crack-length distribution for the fleet based on individual posterior crack distribution of each aircraft. The proposed distribution model of the crack length can be used to analyze the reliability of aging airframes by predicting, for instance, the probability that a crack will reach an unacceptable length after additional flight hours.		Xinhua Wang;Masoud Rabiei;J. Hurtado;Mohammad Modarres;P. Hoffman	2009	Rel. Eng. & Sys. Safety	10.1016/j.ress.2008.10.010	ageing;fracture mechanics;simulation;systems modeling;prior probability;engineering;reliability;log-normal distribution;health management system;mathematics;forensic engineering;bayesian inference;physical property;empirical modelling;statistics;prognostics;data collection	DB	13.466084453860041	-10.616036049012484	158055
3643dbd9666041e28700f7f39645c46dc70c1937	id* lite: improved d* lite algorithm	robot navigation;aspect oriented programming;design patterns;adaptive replication control	Robot navigation has been of great importance especially under unknown or keep-changing environment. In order to solve this kind of problems, many algorithms have been brought up. D* Lite is generally considered as one of the most functional ones. The better performance of D* Lite largely depends on relatively less updating rather than recalculating terrain cost from scratch between robot movements. However, D* Lite still needs updating, i.e. recalculation, every time a terrain change is discovered. In this paper, we give an efficient method to check out when such recalculation can be fully or partially avoided. Experimental results show that it speeds up to 5 times for a variety of benchmarks including a novel and realistic benchmark. Our idea results in an improved version of D* Lite which we call ID* Lite. Moreover, it can be easily embedded into D* Lite variants such as DD* Lite and anytime D* etc.	adobe flash lite;anytime algorithm;benchmark (computing);embedded system;robot;robotic mapping;shortest path problem	Weiya Yue;John Franco;Weiwei Cao;Hongwei Yue	2011		10.1145/1982185.1982483	software design pattern;simulation;aspect-oriented programming;computer science;data mining;database;programming language;world wide web	AI	23.490617773032977	-10.73207752642901	158154
b7518e19695840b3110dbebc24f6b9da53263b7f	bounds for multistage stochastic programs using supervised learning strategies	multistage stochastic programming;supervised learning;upper bound;general methods;machine learning;stochastic programming	We propose a generic method for obtaining quickly good upper bounds on the minimal value of a multistage stochastic program. The method is based on the simulation of a feasible decision policy, synthesized by a strategy relying on any scenario tree approximation from stochastic programming and on supervised learning techniques from machine learning.	algorithm;approximation;machine learning;model selection;multistage amplifier;optimization problem;simulation;statistical learning theory;stochastic programming;supervised learning	Boris Defourny;Damien Ernst;Louis Wehenkel	2009		10.1007/978-3-642-04944-6_6	semi-supervised learning;unsupervised learning;mathematical optimization;computer science;online machine learning;machine learning;pattern recognition;generalization error	AI	21.546717586829793	-17.879648845933865	158366
46d3f24b468059bcc31b2d751fec8e2678b4773d	a hybrid pso optimized svm-based model for predicting a successful growth cycle of the spirulina platensis from raceway experiments data	computacion informatica;particle swarm optimization pso;ciencias basicas y experimentales;matematicas;grupo a;spirulina platensis;hyperparameter selection;support vector machines svms;chlorophyll a monitoring	In this research work, a practical new hybrid model to predict the successful growth cycle of Spirulina platensis was proposed. The model was based on Particle Swarm Optimization (PSO) in combination with support vector machines (SVMs). This optimization mechanism involved kernel parameter setting in the SVM training procedure, which significantly influences the regression accuracy. PSO-SVM-based models, which are based on the statistical learning theory, were successfully used here to predict the Chlorophyll a (Chl-a) concentration (output variable) as a function of the following input variables: pH, optical density, oxygen concentration, nitrate concentration, phosphate concentration, salinity, water temperature and irradiance. Regression with three different kernels (linear, quadratic and RBF) was performed and determination coefficients of 0.94 , 0.97 , and 0.99 , respectively, were obtained. The PSO-SVM-based model goodness of fit to experimental data (Chl-a concentration) confirmed the good performance of this model. Indeed, it is well-known that Chl-a is an extremely important biomolecule, critical in photosynthesis, which allows plants to obtain energy from light and it is one of the most often used algal biomass estimator. The model also allowed to know the most influent parameters in the growth of the S. platensis. Finally, conclusions of this study are exposed. A hybrid PSO-SVM-based model is built as a predictive model of the S. platensis growth cycle.Chlorophyll a is a relevant parameter used to estimate the biomass production.The remaining physical-chemical variables in this process are studied in depth.The obtained regression accuracy of the hybrid PSO-SVM-RBF-based model is about 99%.The results show that PSO-SVM-based models can assist in the diagnosis of the S. platensis presence.	experiment;particle swarm optimization;support vector machine	P. J. García Nieto;E. García-Gonzalo;J. R. Alonso Fernández;C. Díaz Muñiz	2016	J. Computational Applied Mathematics	10.1016/j.cam.2015.01.009	econometrics	NLP	11.821412777050313	-19.234335780401988	158546
24fd0fd0f32912c490cddc999a66e11eacb67c49	cardiovascular signal reconstruction based on shape modelling and non-stationary temporal modelling	arma models;reconstruction;temporal modelling;signal detection;stochastic process modelling cardiovascular signal reconstruction shape modelling nonstationary temporal modelling physiological signals cardiovascular function degradation sources acquisition process signal modelling statistical similarity;shape modelling;statistical analysis;stochastic processes;electrocardiography autoregressive processes shape biological system modeling principal component analysis computational modeling vectors;signal reconstruction;cardiovascular system;stochastic processes cardiovascular system medical signal processing signal detection signal reconstruction statistical analysis;arma models cardiovascular signal reconstruction shape modelling pca temporal modelling;pca;medical signal processing;cardiovascular signal	Physiological signals, specially those related to cardiovascular function, are usually corrupted due to the number of degradation sources appearing in the acquisition process (noise, movements, etc.). If the power of these artifacts is close to the power of the signal, they cannot be removed and the affected epoch must be set aside. In this paper, we propose a novel methodology for reconstructing corrupted pieces based on signal modelling. The method consists of two stages: 1) estimation of the model parameters from the largest uncorrupted signal and 2) simulation of the model to achieve a new piece able to replace the corrupted one. Results on real data show that reconstructed pieces are valid in terms of statistical similarity, yielding anomaly-free realizations of the stochastic process modelling the acquired signal.	anomaly detection;elegant degradation;epoch (reference date);process modeling;signal reconstruction;simulation;stationary process;stochastic process	Diego Martín-Martínez;Pablo Casaseca-de-la-Higuera;Marcos Martín-Fernández;Carlos Alberola-López	2012	2012 Proceedings of the 20th European Signal Processing Conference (EUSIPCO)		econometrics;computer science;machine learning;statistics	Robotics	23.892353321502114	-23.13177889021846	158621
a971de469f7406787d5ff4bd974ae3df42a88b8c	evolutionary functional link interval type-2 fuzzy neural system for exchange rate prediction	differential evolution;ga;de;exchange rate;genetic algorithm;eflit2fns;back propagation	Abstract: This paper proposes a hybrid evolutionary functional link and interval type-2 fuzzy neural system (EFLIT2FNS) to predict the currency exchange rate data for six different time horizons starting from one day to one year. The antecedent part of each fuzzy rule of EFLIT2FNS model is an interval type-2 fuzzy set and the fuzzy rules are of the Takagi-Sugano-Kang (TSK) and the consequent part comprises a functional link artificial neural network (FLANN). The parameters of both the antecedent and consequent part of the fuzzy rules are optimised by the gradient descent algorithm. Further, to overcome the limitations of the above said algorithm, two evolutionary algorithms, i.e., genetic algorithm (GA) and differential evolution (DE) are used to optimise all the parameters used in the model. Five different currency exchange time series data are considered for evaluating the performance of the proposed algorithm. The simulation results reveal that the prediction accuracy of the EFLIT2FNS model is significantly better than other models used for comparison.	artificial neural network;blancmange curve;differential evolution;evolutionary algorithm;fuzzy rule;fuzzy set;genetic algorithm;gradient descent;simulation;time series	Sreejit Chakravarty;Pradipta Kishore Dash	2012	IJDMMM	10.1504/IJDMMM.2012.049882	differential evolution;genetic algorithm;adaptive neuro fuzzy inference system;computer science;artificial intelligence;fuzzy number;backpropagation;neuro-fuzzy;machine learning;algorithm	AI	10.726637946183898	-22.967798184889308	158629
f9bb30eec4aa2853e290a171e3b94ccdd5d18212	swarm reinforcement learning method for a multi-robot formation problem	swarm intelligence;formation control;formation control reinforcement learning swarm intelligence;reinforcement learning;multi robot systems learning artificial intelligence mobile robots;mobile robots;swarm reinforcement learning method optimal policy optimal route multiple robots multirobot formation problem;robot kinematics learning artificial intelligence learning systems equations information exchange mathematical model;multi robot systems;learning artificial intelligence	In this paper, we treat a multi-robot formation problem in which each of multiple robots selects one of goal positions adequately and finds the optimal route to the goal position, and we propose a swarm reinforcement learning method for acquiring the optimal policy in the problem. In the proposed method, multiple sets of the robots and an environment, which are called learning worlds, are prepared and the robots in each learning world learn not only by performing a usual reinforcement learning method but also by exchanging information among learning worlds. The performance of the proposed method is evaluated through numerical experiments.	experiment;multi-agent system;numerical analysis;q-learning;reinforcement learning;robot;swarm;value (computer science)	Hitoshi Iima;Yasuaki Kuroe	2013	2013 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/SMC.2013.393	mobile robot;robot learning;swarm robotics;error-driven learning;simulation;swarm intelligence;computer science;artificial intelligence;machine learning;learning classifier system;reinforcement learning;active learning;hyper-heuristic	Robotics	18.639819204096806	-21.219665008899277	158787
76b5baf5ba4a82a068ce9d32c391ab991e423c90	evolving adaptive poker players for effective opponent exploitation				Xun Li;Risto Miikkulainen	2017			machine learning;artificial intelligence;adversary;computer science	AI	18.988511244051526	-17.79972032259423	158892
f018db76c994c0d41cce0f572b4d8a93462973fb	understanding rare safety and reliability events using transition path sampling		Abstract In the chemical and process industries, processes and their control systems are typically well-designed to mitigate abnormal events having potential adverse consequences to human health, environment, and/or property. Strong motivation exists to understand how these events develop and propagate. These events occur so rarely that statistical analyses of their occurrences alone are incapable of describing and characterizing them − especially when they have not yet occurred. Moreover, the use of process models to understand such rare events is hampered by the orders of magnitude separating the frequencies with which reliability and safety events (years to decades) occur and the duration over which they occur (minutes to hours). To address these challenges, we adapt a Monte-Carlo based, rare-event sampling technique, Transition Path Sampling (TPS), which was developed by the molecular simulation community. Important modifications to the TPS technique are needed to apply it to process dynamics, and are discussed herein.	sampling (signal processing);transition path sampling	Ian H. Moskowitz;Warren D. Seider;Amish J. Patel;Jeffrey E. Arbogast;Ulku G. Oktem	2018	Computers & Chemical Engineering	10.1016/j.compchemeng.2017.06.016	control engineering;sampling (statistics);reliability engineering;data mining;mathematics;transition path sampling;rare events;process modeling;control system	SE	13.454813861353138	-14.259420359234959	158932
30c61ec0b8bdc9a95a9de09cbb9499692d9bad5d	foot plantar pressure estimation using artificial neural networks		In this paper, we present a novel approach to estimate the maximum pressure over the foot plantar surface exerted by a two-layer shoe sole for three distinct phases of the gait cycle. The proposed method is based on Artificial Neural Networks and can be utilized for the determination of the comfort that is related to the sole construction. Input parameters to the proposed neural network are the material properties and the thicknesses of the sole layers (insole and outsole). A set of simulation experiments has been conducted using analytic finite elements analysis in order to compile the necessary dataset for the training and validation of the neural network. Extensive experiments have shown that the developed method is able to provide an accurate alternative (more than 96 %) compared to the highly expensive, with respect to computational and human resources, approaches based on finite element analysis.	artificial neural network;neural networks;pedobarography	Elias K. Xidias;Zoi Koutkalaki;Panagiotis Papagiannis;Paraskevas Papanikos;Philippe N. Azariadis	2015		10.1007/978-3-319-33111-9_3	artificial neural network;plantar surface;artificial intelligence;gait;finite element method;material properties;pattern recognition;computer science	Robotics	12.796512998516189	-19.895202276308456	159019
6315059fe97941e20ff57360dbe38d1abaf0ada3	morphological algorithm design for binary images using genetic programming	mathematical morphology;genetic program;binary image;genetic programming;image analysis;algorithm design;fitness function	This paper presents a Genetic Programming (GP) approach to the design of Mathematical Morphology (MM) algorithms for binary images. The algorithms are constructed using logic operators and the basic MM operators, i.e. erosion and dilation, with a variety of structuring elements. GP is used to evolve MM algorithms that convert a binary image into another containing just a particular feature of interest. In the study we have tested three fitness functions, training sets with different numbers of elements, training images of different sizes, and 7 different features in two different kinds of applications. The results obtained show that it is possible to evolve good MM algorithms using GP.	algorithm design;binary image;dilation (morphology);erosion (morphology);fitness function;genetic programming;mathematical morphology	Marcos I. Quintana;Riccardo Poli;Ela Claridge	2006	Genetic Programming and Evolvable Machines	10.1007/s10710-006-7012-3	genetic programming;algorithm design;image analysis;mathematical morphology;binary image;computer science;theoretical computer science;machine learning;fitness function;algorithm	Robotics	15.706183094205988	-22.220017625555766	159569
635ffc4efa56cced3148932eb52bc2275255960e	optimal query selection using multi-armed bandits		Query selection for latent variable estimation is conventionally performed by opting for observations with low noise or optimizing information-theoretic objectives related to reducing the level of estimated uncertainty based on the current best estimate. In these approaches, typically, the system makes a decision by leveraging the current available information about the state. However, trusting the current best estimate results in poor query selection when truth is far from the current estimate, and this negatively impacts the speed and accuracy of the latent variable estimation procedure. We introduce a novel sequential adaptive action value function for query selection using the multi-armed bandit framework, which allows us to find a tractable solution. For this adaptive-sequential query selection method, we analytically show: 1) performance improvement in the query selection for a dynamical system; and 2) the conditions where the model outperforms competitors. We also present favorable empirical assessments of the performance for this method, compared to alternative methods, both using Monte Carlo simulations and human-in-the-loop experiments with a brain–computer interface typing system, where the language model provides the prior information.	bellman equation;brain–computer interface;cobham's thesis;dynamical system;experiment;information theory;language model;latent variable;monte carlo method;multi-armed bandit;simulation;trust (emotion)	Aziz Ko&#x00E7;anao&#x011F;ullar&imath;;Yeganeh M. Marghi;Murat Akcakaya;Deniz Erdogmus	2018	IEEE Signal Processing Letters	10.1109/LSP.2018.2878066	artificial intelligence;mathematics;task analysis;competitor analysis;performance improvement;mutual information;language model;monte carlo method;pattern recognition;bellman equation;latent variable	ML	22.3671341352284	-19.990618137254085	159576
0815542ab9f0b1658ac126a74fe010077aa43a11	distributed gibbs: a memory-bounded sampling-based dcop algorithm	dcop;sampling;gibbs	Researchers have used distributed constraint optimization problems (DCOPs) to model various multi-agent coordination and resource allocation problems. Very recently, Ottens et al. proposed a promising new approach to solve DCOPs that is based on confidence bounds via their Distributed UCT (DUCT) sampling-based algorithm. Unfortunately, its memory requirement per agent is exponential in the number of agents in the problem, which prohibits it from scaling up to large problems. Thus, in this paper, we introduce a new sampling-based DCOP algorithm called Distributed Gibbs, whose memory requirements per agent is linear in the number of agents in the problem. Additionally, we show empirically that our algorithm is able to find solutions that are better than DUCT; and computationally, our algorithm runs faster than DUCT as well as solve some large problems that DUCT failed to solve due to memory limitations.	algorithm;constrained optimization;dcop;distributed constraint optimization;image scaling;mathematical optimization;multi-agent system;requirement;sampling (signal processing);time complexity	Duc Thien Nguyen;William Yeoh;Hoong Chuin Lau	2013			sampling;mathematical optimization;computer science;artificial intelligence;theoretical computer science;machine learning	AI	20.42895363161415	-15.837336797875915	159596
4e8d789354b5dcaca1239763e77d63c6151d2b37	a new approach to model financial markets	xie habin wang shouyang 金融市场 模拟 granger因果关系 分解技术 信息模型 自回归模型 场问题 var a new approach to model financial markets	This paper deals with the problem of how to take full use of prices information to model financial markets. A range decomposition technique is proposed to decompose the returns into two components. It is proved theoretically that these two components are bi-directional Granger causality, which makes it convenient to establish a vector autoregressive model (VAR). Both simulations and empirical studies are performed, and the results are consistent with the theoretical ones. The range decomposition approach presented in this paper is more efficient in information employment and suggests a new framework to model financial markets.		Habin Xie;Shouyang Wang	2013	J. Systems Science & Complexity	10.1007/s11424-013-1196-4	mathematics	Logic	24.380849766860912	-23.664751161666178	159658
b42ec0b8d6fffa17be77b7833dd117eb3649a26c	on the complexity of solving polytree-shaped limited memory influence diagrams with binary variables	computer sciences;decision networks;computational complexity;decision theory;influence diagrams;probabilistic planning	Influence diagrams are intuitive and concise representations of structured decision problems. When the problem is non-Markovian, an optimal strategy can be exponentially large in the size of the diagram. We can avoid the inherent intractability by constraining the size of admissible strategies, giving rise to limited memory influence diagrams. A valuable question is then how small do strategies need to be to enable efficient optimal planning. Arguably, the smallest strategies one can conceive simply prescribe an action for each time step, without considering past decisions or observations. Previous work has shown that finding such optimal strategies even for polytree-shaped diagrams with ternary variables and a single value node is NP-hard, but the case of binary variables was left open. In this paper we address such a case, by first noting that optimal strategies can be obtained in polynomial time for polytree-shaped diagrams with binary variables and a single value node. We then show that the same problem is NP-hard if the diagram has multiple value nodes. These two results close the fixed-parameter complexity analysis of optimal strategy selection in influence diagrams parametrized by the shape of the diagram, the number of value nodes and the maximum variable cardinality.	analysis of algorithms;automated planning and scheduling;decision problem;directed graph;influence diagram;marginal model;np-hardness;partition problem;polynomial;selection algorithm;time complexity	Denis Deratani Mauá;Cassio Polpo de Campos;Marco Zaffalon	2013	Artif. Intell.	10.1016/j.artint.2013.10.002	mathematical optimization;combinatorics;influence diagram;decision theory;computer science;artificial intelligence;mathematics;computational complexity theory;algorithm	AI	21.436815710992864	-15.379035706088326	159701
26a1a965f39892a09635ef9ac1e62baa6d3f06ab	a fuzzy logic approach for sensor validation in real time expert	fuzzy logic approach;sensor validation;real time expert;fuzzy logic;real time	Data validation of the information coming from sensors is a fundamental problem when developing on-line real-time expert systems. In this paper an approach using fuzzy logic methods is presented. This approach has been originated during the development of the MIP project, a real-time expert system for assistance to petrochemical processes that is described in [1]. The MIP expert system is deployed and in production in a petrochemical plant of INH-REPSOL in Tarragona, Spain. The method presented in this paper complements the MIP expert system by preprocessing the incoming data and assigning confidence values to each measurement from the sensors. These confidence values can be used subsequently to enrich the conclusions obtained by the MIP system. The method is currently in field test in the plant.	fuzzy logic	Juan A. Aguilar-Crespo;Erik de Pablo;Xavier Alamán	1992		10.1007/3-540-56735-6_71	fuzzy electronics;data mining;control theory;fuzzy control system	AI	12.430408326027653	-15.92729968206248	159774
768ebf7b7e8c55ec603da5dc4619cdcf16b58bc5	machining activity extraction and energy attributes inheritance method to support intelligent energy estimation of machining process	nc program;energy attribute inheritance;energy attribute;machining activity;activity extraction;intelligent energy estimation	An energy-efficient intelligent manufacturing system could significantly save energy compared to traditional intelligent manufacturing systems that do not consider energy issues. Intelligent energy estimation of machining processes is the foundation of the energy-efficient intelligent manufacturing system. This paper proposes a method for machining activity extraction and energy attributes inheritance to support the intelligent energy estimation of machining processes. Fifteen machining activities and their energy attributes are defined according to their operating and energy consumption characteristics. Activities and energy attributes are extracted mainly from NC program supplemented with blank dimensional information. An effective extraction method of activities and energy attributes is the basis for the intelligent energy calculating of machining process. Based on an investigation on the extraction procedure of activities and energy attributes, energy attributes inheritance method is further discussed. Four types of energy attribute inheritance rules are summarized according to the different inheritance characteristics. Based on these four types of inheritance rules, the energy attributes can be transmitted from activity to Therblig as effective inputs of Therblig-based energy model of machining processes. The proposed methodology is finally demonstrated through two machining cases.	activity recognition;discharger;energy modeling;lazy inheritance	Shun Jia;Renzhong Tang;Jingxiang Lv	2016	J. Intelligent Manufacturing	10.1007/s10845-014-0894-7	reliability engineering;engineering;engineering drawing	AI	11.34871341098819	-12.459425407534566	159891
104945806d600aa7fd9d95f3f3f8a8b7ca1eb8c2	a gpr-pso incremental regression framework on gps/ins integration for vehicle localization under urban environment	gauss process regression;gps outage;global positioning system;particle swarm optimization;vehicle localization;inertial navigation system	Land vehicle localization and navigation mainly relies on the Global Positioning System (GPS)/Inertial Navigation System (INS) integration. In this paper, we propose a unified incremental regression framework that enables vehicle localization with high accuracy in urban environment. Within the framework, we propose a nonlinear Gauss Process Regression (GPR) approach to perform vehicle position prediction during GPS outages. By mapping nonlinear data into high-dimensional space by kernel function, the proposed GPR based approach is able to deal with the nonlinearity issue in GPS denied environment. We design a Particle Swarm Optimization (PSO) based algorithm to optimize GPR hyper-parameters, which are tuned with high time efficiency for vehicular position prediction. By real-world road experiments, the proposed method is evaluated against Artificial Neural Network (ANN), Support Vector Machine Regression (SVR) and Partial Least Squares Regression (PLSR). The results reveal that the proposed outperforms the others by 22.8%-65.2% improvement in the positional accuracy.	algorithm;artificial neural network;downtime;experiment;gps signals;global positioning system;inertial navigation system;kriging;nonlinear system;partial least squares regression;particle swarm optimization;receiver autonomous integrity monitoring;support vector machine	Zhu Xiao;Sui Zhan;Zhiyang Xiang;Dong Wang;Wenjie Chen	2016	2016 IEEE 27th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)	10.1109/PIMRC.2016.7794744	gps/ins;simulation;global positioning system;computer science;control theory;inertial navigation system;particle swarm optimization	Robotics	12.024598416779632	-16.736938349724724	160082
1f26c41f9d637f1e056355341d06472ad65a9a44	why did td-gammon work?	evaluation function;feed forward;machine learning;hill climbing;temporal difference learning;back propagation	Although TD-Gammon is one of the major successes in machine learning, it has not led to similar impressive breakthroughs in temporal difference learning for other applications or even other games. We were able to replicate some of the success of TD-Gammon, developing a competitive evaluation function on a 4000 parameter feed-forward neural network, without using back-propagation, reinforcement or temporal difference learning methods. Instead we apply simple hill-climbing in a relative fitness environment. These results and further analysis suggest that the surprising success of Tesauro’s program had more to do with the co-evolutionary structure of the learning task and the dynamics of the backgammon game itself.	artificial neural network;backpropagation;evaluation function;feedforward neural network;hill climbing;machine learning;self-replicating machine;software propagation;td-gammon;weatherstar	Jordan B. Pollack;Alan D. Blair	1996			temporal difference learning;simulation;computer science;artificial intelligence;backpropagation;hill climbing;machine learning;evaluation function;stability;feed forward;q-learning	ML	18.107569334360623	-20.86589003561838	160233
7117b948dda2081c7dcd8f8a7850a8f1de7aaa8c	fusion of multiple behaviors using layered reinforcement learning	similar state grouping;robot sensing systems;multiple behavior fusion;learning algorithm;state space methods;decision tree;state space methods decision trees intelligent robots learning by example;tree induction;intelligent robots;bismuth;behavior based control;reinforcement learning;dynamic environment;reinforcement learning behavior based control intelligent robots;learning by example;state space;aggregated state space learning;control policy;learning robot;aerospace electronics;decision trees robot sensing systems bismuth humans aerospace electronics robot kinematics;state action data;humans;complex behavior learning multiple behavior fusion layered reinforcement learning learning robot human demonstrations state action data aggregated state space learning decision tree similar state grouping tree induction control policy q learning algorithm motor level;layered reinforcement learning;human demonstrations;complex behavior learning;decision trees;q learning algorithm;robot kinematics;motor level	This study introduces a method to enable a robot to learn how to perform new tasks through human demonstration and independent practice. The proposed process consists of two interconnected phases; in the first phase, state-action data are obtained from human demonstrations, and an aggregated state space is learned in terms of a decision tree that groups similar states together through reinforcement learning. Without the postprocess of trimming, in tree induction, the tree encodes a control policy that can be used to control the robot by means of repeatedly improving itself. Once a variety of behaviors is learned, more elaborate behaviors can be generated by selectively organizing several behaviors using another Q-learning algorithm. The composed outputs of the organized basic behaviors on the motor level are weighted using the policy learned through Q-learning. This approach uses three diverse Q-learning algorithms to learn complex behaviors. The experimental results show that the learned complicated behaviors, organized according to individual basic behaviors by the three Q-learning algorithms on different levels, can function more adaptively in a dynamic environment.	algorithm;decision tree;machine learning;organizing (structure);q-learning;reinforcement learning;robot;state space	Kao-Shing Hwang;Yu-Jen Chen;Chun-Ju Wu	2012	IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans	10.1109/TSMCA.2012.2183349	simulation;computer science;artificial intelligence;machine learning;decision tree;reinforcement learning	ML	19.012080066249535	-22.691365159571134	160461
3feb7fa48f2f2d6122b28bf7540c59a4237b7bce	prediction of burning rate of htpb propellant by using support vector regression	of hydroxyl;mechanical engineering computing;support vector machines;neural nets;support vector regression;additives;nanostructured materials;burning rate;particle swarm optimizer;support vector machines additives catalysts combustion synthesis mechanical engineering computing nanostructured materials neural nets particle swarm optimisation propellants regression analysis;htbp propellant;combustion synthesis;catalysts;regression analysis;regression analysis htbp propellant nano catalyst burning rate support vector regression;artificial neural networks propulsion support vector machines kernel training predictive models solids;particle swarm optimisation;ann model htpb propellant support vector regression burning rate prediction hydroxyl terminated poly butadiene propellant nanostructure catalysts svr method particle swarm optimization pso additives artificial neural network model;nano catalyst;artificial neural network;propellants	The performance of Hydroxyl-Terminated Polybutadiene (HTBP) propellants will be changed by filling with nano-structure catalysts. In this study, a novel regression approach, the support vector regression (SVR) approach combined with particle swarm optimization (PSO) was introduced to investigate the influence of the additives on burning-rate of HTBP. The SVR model was trained and tested with an experimental dataset of RDX/AP/Al/HTPB propellants containing nano-structure ns-Fe2O3 catalyst. The prediction performance of SVR model was compared with that of artificial neural network (ANN) model. The results demonstrate that the prediction ability of SVR is superior to that of ANN. This investigation indicates that SVR-based modeling is a practically useful tool in prediction of the burning-rate of HTPB affected by three different factors (mass fraction of ns-Fe2O3, mass fraction of HTPB and pressure).	artificial neural network;gnu nano;mathematical optimization;particle swarm optimization;support vector machine	J. L. Tang;C. Z. Cai;S. Zhao;G. L. Wang	2011	2011 6th IEEE International Conference on Nano/Micro Engineered and Molecular Systems	10.1109/NEMS.2011.6017463	materials science;support vector machine;forensic engineering;artificial neural network	Robotics	12.149528814696723	-19.723947522994862	160634
598137e1e41539c271d9f5498c9d5d11d8a59f8d	biologically based neural network for mobile robot navigation	delivery system;neural networks;mobile robot;surveillance;mobile robots;robotics;autonomous mobile robot;emerging technology;neuroscience;action selection;evolutionary robotics;mobile robot navigation;cost effectiveness;neural network	ABSTRACT The new tendency in mobile robots is to create non-Cartesian systems based on reactions to their environment. This emergingtechnology is known as Evolutionary Robotics, which is combined with the Biorobotic field. This new approach brings cost-effective solutions, flexibility, robustness, and dynamism into the design ofmobile robots. It also provides fast reactions to thesensory inputs, and new interpretation ofthe environment or surroundings ofthe mobile robot. The Subsumption Architecture(SA) and the action selection dynamics developed by Brooks and Maes, respectively, have successfully obtained autonomousmobile robots initiating this new trend ofthe Evolutionary Robotics. Their design keeps the mobile robot control simple. Thiswork presents a biologically inspired modification ofthese schemes. The hippocampal-CA3 (a special type of neuron)-basedneural network (HCA3) developed by Williams Levy is used to implement the SA, while the action selection dynamics emergefrom iterations of the levels of competence implemented with the HCA3. This replacement by the HCA3 results in a closerbiological model than the SA, combining the Behavior-based intelligence theory with neuroscience. The design is kept simple,and it is implemented in the Khepera Miniature Mobile Robot. The used control scheme obtains an autonomous mobile robotthat can be used to execute a mail delivery system and surveillance task inside a building floor.Keywords: mobile robots, Khepera, HCA3 neural networks, Subsumption Architecture, evolutionary robotics	artificial neural network;mobile robot;robotic mapping	Raul E. Torres Muniz	1998		10.1117/12.335708	mobile robot;computer vision;simulation;subsumption architecture;engineering;artificial intelligence;social robot;robot control;mobile robot navigation	Robotics	16.811367311781243	-21.828000376370003	160637
6c61aed1e8bf85dd7989a6c1447b19f7bd4a2e05	eg-grids: context-free grammatical inference from positive examples using genetic search	inference grammaticale;process selection;search space;frase;seleccion proceso;context free;search strategy;intelligence artificielle;algoritmo genetico;choix procede;genetics;inferencia gramatical;grid;grammaire cf;sentence;rejilla;context free grammar;minimum description length;gramatica independiente;strategie recherche;algorithme genetique;grille;artificial intelligence;algorithme evolutionniste;genetic algorithm;grammatical inference;algoritmo evolucionista;phrase;inteligencia artificial;evolutionary algorithm;estrategia investigacion	In this paper we present eg-GRIDS, an algorithm for inducing context-free grammars that is able to learn from positive sample sentences. The presented algorithm, similar to its GRIDS predecessors, uses simplicity as a criterion for directing inference, and a set of operators for exploring the search space. In addition to the basic beam search strategy of GRIDS, eg-GRIDS incorporates an evolutionary grammar selection process, aiming to explore a larger part of the search space. Evaluation results are presented on artificially generated data, comparing the performance of beam search and genetic search. These results show that genetic search performs better than beam search while being significantly more efficient computationally.	beam search;context-free grammar;context-free language;evolutionary algorithm;genetic algorithm;grammar induction	Georgios Petasis;Georgios Paliouras;Constantine D. Spyropoulos;Constantin Halatsis	2004		10.1007/978-3-540-30195-0_20	linear search;interpolation search;beam search;bidirectional search;genetic algorithm;minimum description length;beam stack search;computer science;artificial intelligence;machine learning;evolutionary algorithm;mathematics;incremental heuristic search;iterative deepening depth-first search;best-first search;combinatorial search;context-free grammar;grid;algorithm;fringe search;state space search;binary search algorithm;search algorithm	AI	20.48927386099008	-12.049588273383423	160646
eb8aba5f113095c50fae4fb980d9aca8a538e606	model-based condition monitoring for wind turbines	mechanical engineering computing;neural nets;transfer functions;wind turbines;maintenance engineering;wind turbines condition monitoring fault diagnosis inspection maintenance engineering mechanical engineering computing neural nets transfer functions;inspection;condition monitoring;state dependent parameter model wind turbines condition monitoring artificial neural network;early warning system model based condition monitoring wind turbines routine inspection maintenance diagnostics wind farms fault detection linear models artificial neural networks operational turbines nonlinear state dependent pseudo transfer functions nonlinear controllers;wind turbines data models wind speed generators artificial neural networks transfer functions wind farms;fault diagnosis	It is common for wind turbines to be installed in remote locations on land or offshore, leading to difficulties in routine inspection and maintenance. In addition, wind turbines in these locations are often subject to harsh operating conditions. These challenges mean there is a requirement for a high degree of maintenance. Consequently, monitoring and diagnostics of wind turbines play an increasingly important role in the competitive operation of wind farms. The data generated by monitoring systems can be used to obtain models of wind turbines operating under different conditions, and hence predict output signals based on known inputs. By comparing output data obtained from operational turbines with those predicted by the models, it is possible to detect changes that may be due to the presence of faults. This paper discusses model-based condition monitoring methods for wind turbines, in which the relationships between measured variables are modelled using linear models and artificial neural networks identified from data acquired from operational turbines. The relationships between variables are also modelled using non-linear state dependent `pseudo' transfer functions. Although these state dependent parameter models have been used extensively as the basis of non-linear controllers, the research described here represents the first occasion for which they have been employed for a condition monitoring system. It is found that artificial neural network-based models outperform state dependent parameter models; however, the computing power required for the latter is considerably less. Finally, the monitoring data are used to develop adaptive threshold rules for critical output signals, forming the basis of an early warning system.	artificial neural network;field-programmability;field-programmable gate array;linear model;nonlinear system;online and offline;parameter (computer programming);pareto efficiency;real-time clock;requirement;sampling (signal processing);software bug;transfer function	Philip Cross;Xiandong Ma	2013	2013 19th International Conference on Automation and Computing		wind power;maintenance engineering;inspection;machine learning;transfer function	SE	12.290318879795358	-15.78756310963137	160892
b3e8ee1a1dda23f6948fe8e28ed7c8608ff6098d	application of hierarchical neural fuzzy models to modeling and control of a bioprocess	hierarchical structure;large scale system;model based control;ethanol production;fuzzy system;fuzzy model;neural network;model predictive controller	Hierarchical structures have been introduced in the litera ture to deal with the dimensionality problem which is the main drawback to the application of neural networks and f uzzy models to modeling and control of largescale systems. In the present work, hierarchical neural fuz zy (HNF) models are reviewed focusing on the modelbased control of a biotechnological process. The model cons idered here consists of a set of neural fuzzy systems connected in cascade and is used in the modeling of an industr ial plant for ethyl alcohol (ethanol) production. Based on the HNF model of the process, a nonlinear model predictive ontroller (HNF-MPC) is designed and applied to control the process. The performance of the HNF-MPC is illus trated within servo and regulatory scenarios.	algorithm;artificial neural network;beta normal form;carrier-to-noise ratio;computer simulation;exptime;emoticon;fuzzy control system;fuzzy set;mpc-mlq;nonlinear system;optimal control;physical plant;radial basis function;sampling (signal processing);sequential quadratic programming;servo;weight function	Luiz Augusto da Cruz Meleiro;Ricardo J. G. B. Campello;Rubens Maciel Filho;Wagner Caradori do Amaral	2006	Applied Artificial Intelligence	10.1080/08839510600941379	adaptive neuro fuzzy inference system;computer science;neuro-fuzzy;machine learning;ethanol fuel;artificial neural network;fuzzy control system	AI	11.283107696540528	-23.544961252702155	160935
9a14ef8fc1911057331151b6bc7c2c24d1052af7	supervised and reinforcement evolutionary learning for wavelet-based neuro-fuzzy networks	tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;learning algorithm;model combination;reinforcement learning;wavelet neural network;sequential search;symbiotic evolution;real world application;identification;neuro fuzzy;takagi sugeno kang;genetic algorithm;genetic algorithms;control;tecnologias;grupo a;evolutionary learning;computer simulation;fuzzy model;support function;neuro fuzzy networks;wavelet networks	This study presents a wavelet-based neuro-fuzzy network (WNFN). The proposed WNFN model combines the traditional Takagi–Sugeno–Kang (TSK) fuzzy model and the wavelet neural networks (WNN). This study adopts the non-orthogonal and compactly supported functions as wavelet neural network bases. A novel supervised evolutionary learning, called WNFN-S, is proposed to tune the adjustable parameters of the WNFN model. The proposed WNFN-S learning scheme is based on dynamic symbiotic evolution (DSE). The proposed DSE uses the sequential-search-based dynamic evolutionary (SSDE) method. In some real-world applications, exact training data may be expensive or even impossible to obtain. To solve this problem, the reinforcement evolutionary learning, called WNFN-R, is proposed. Computer simulations have been conducted to illustrate the performance and applicability of the proposed WNFN-S and WNFN-R learning algorithms.	algorithm;artificial neural network;complex systems;computer simulation;evolution;fitness function;fuzzy control system;fuzzy rule;linear search;machine learning;mathematical optimization;multi-objective optimization;national supercomputer centre in sweden;neuro-fuzzy;randomness;system identification;wavelet	Cheng-Jian Lin;Yong-Cheng Liu;Chi-Yung Lee	2008	Journal of Intelligent and Robotic Systems	10.1007/s10846-008-9214-9	computer simulation;simulation;genetic algorithm;computer science;engineering;artificial intelligence;machine learning;reinforcement learning	AI	14.030600904762078	-23.347533664885873	160974
8f73187f5ebddfe9c085e42190f6ccff2033e003	a system for evolving neural architectures	multiplication operator;search space;simulation;proof of concept;genetic algorithm;brain function;neural network;evolution	Significant emphasis has been placed on the use of genetic algorithms for evolving solutions to otherwise intractable problems but they also offer an opportunity to explore the process of evolution itself. Brains represent complex circuits that have arisen in an astronomically large search space of possibilities to solve a variety of problem types, most of them quite complex. To expedite the investigation of the evolution of neural circuitry, we introduce a system that makes it possible to (1) explore the constraints under which various brain functions might have evolved, (2) demonstrate (as a proof of concept) that such evolution is possible, and (3) that lays the foundation for tracking paths from simpler to more complex architectures. The system we present uses a highly flexible genome encoding scheme in conjunction with a sophisticated genetic algorithm (employing multiple operators) and a flexible neural network simulation program. We show preliminary results for a basic neural circuit and discuss implications for subsequent work.	artificial neural network;electronic circuit;genetic algorithm;line code;simulation	Steve Donaldson;Chris Walling	2012		10.1145/2184512.2184567	computer science;artificial intelligence;machine learning;algorithm	ML	16.009455829752007	-23.643198286128193	161336
f3f8b9dd9d83fdcfd2434b830d67c0b4c363c902	abnormal condition diagnosis for process industry based on virtual sensing technology		Both process changes and sensor faults can result in the unexpected deviation of the sensor reading from its anticipated values. When the anomaly of sensor measurement occurs, in order to take appropriate actions to diminish or eliminate related dangerous factors, identifying the source of abnormal conditions is a very crucial step. To reach that, an abnormal condition diagnosis method based on virtual sensing technology is proposed. Once the abnormal situation of sensor measurement is detected, the virtual sensor is constructed based on the Gauss Process Regression and Moving Windows algorithm. Through analyzing prediction residual, the task of differentiating between sensor and system faults can be performed. In order to verify the performance of this proposal, a case study is carried out on CSTH platform, where both scenarios of sensor faults and process changes are considered. The simulation results show the effectiveness of this method.	algorithm;anomaly detection;microsoft windows;simulation	Jinqiu Hu;Xiaoxiao Hao;Laibin Zhang	2017	2017 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)	10.1109/FSKD.2017.8393035	knowledge extraction;residual;artificial intelligence;control engineering;machine learning;computer science;fuzzy control system	Robotics	12.535245558862364	-14.53270267866747	161342
7cecea78982c4ac4bdd0e18c9737dde812d06da1	evolving spiking neural networks of artificial creatures using genetic algorithm	neurons biological cells delays sociology statistics biological neural networks computational modeling;neural nets genetic algorithms;single complex creature evolving spiking neural networks artificial creatures genetic algorithm based evolution framework ga snn virtual environment randomly connected izhikevich spiking reservoir neural networks biological neurons neuronal connections axonal conduction delays evolutionary algorithm colony approach	This paper presents a Genetic Algorithm (GA) based evolution framework in which Spiking Neural Network (SNN) of single or a colony of artificial creatures are evolved for higher chance of survival in a virtual environment. The artificial creatures are composed of randomly connected Izhikevich spiking reservoir neural networks. Inspired by biological neurons, the neuronal connections are considered with different axonal conduction delays. Simulation results prove that the evolutionary algorithm has the capability to find or synthesis artificial creatures which can survive in the environment successfully and also simulations verify that colony approach has a better performance in comparison with a single complex creature.	action potential;biological neuron model;evolutionary algorithm;genetic algorithm;neural networks;randomness;simulation;spiking neural network;virtual reality	Elahe Eskandari;Arash Ahmadi;Shaghayegh Gomar;Majid Ahmadi;Mehrdad Saif	2016	2016 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2016.7727228	types of artificial neural networks;computer science;artificial intelligence;machine learning;spiking neural network	AI	15.888790491602366	-23.233711100719695	161441
ca9b84606ad586f26f8b28b38c2291b7f7011e71	evaluation of citrus gummosis disease dynamics and predictions with weather and inversion based leaf optical model		Abstract One of the major threats for crops around the world due to pest and diseases, which can impact the health, economy, environment, and society at large. In general, several issues related to crop yield improvement arises due to insufficient and inadequate knowledge. Therefore, there is a need to develop viable models that incorporate various weather-soil-plant factors, which can give better understanding of the crop and enable timely interventions for yield improvement. To overcome Citrus Gummosis disease related issues and increase the Citrus productivity, seven different datasets Temperature (T), Humidity (R h ), Rainfall (R), Soil Moisture (SM), Soil Temperature (ST), Leaf Area Index (LAI) and Chlorophyll (C ab ) were used. Considering various plant, soil and environmental factors, the Citrus Gummosis prediction model has been developed with the multi-source datasets from June 2014 to November 2016 using Support vector regression (SVR) and multilinear regression (MLR). The research is carried out for healthy (5–10 Yrs. and 11–15 Yrs.) and unhealthy (5–10 Yrs. and 11–15 Yrs.) age group of plants. Inverse PROSAIL model has been simulated for retrieving citrus C ab and LAI values. These values were validated with the actual field data. Both the weather and soils based disease prediction models has been developed and validated with MLR and SVR. Further, the influence of Gummosis disease on plant parameters was also studies with the new contribution of Biophysical variables (LAI and C ab ) based statistical prediction model. The SVR model gave fairly good performance as compared to MLR. In addition to the separate models a the combined scenario approach (Integrated Gummosis Disease Forecast Model: IGDFM) is designed to understand the interconnectivity of the parametric conditions (weather-soil- plant parameters) with disease physiology with respect to different age group of the plants. The RMSE of proposed approach for higher age group plants (i.e. 11–15 years) in the combined scenario was 0.9061 and 0.8518 for SVR and MLR methods, respectively. It is envisaged that this study could enable farmers to recognize and predict the timing and severity of the Gummosis disease in Citrus and thereby achieve yield improvement.		Mrunalini R. Badnakhe;Surya S. Durbha;J. Adinarayana;Rajendra M. Gade	2018	Computers and Electronics in Agriculture	10.1016/j.compag.2018.10.009	statistics;control engineering;predictive modelling;gummosis;crop yield;leaf area index;parametric statistics;engineering	Vision	11.472847104519808	-18.658741133822488	161624
87e003eb21fa1cfc8c31a922eabeb4a083a95bc2	two fpga-oriented high-speed irradiance virtual sensors for photovoltaic plants	information systems;neural networks;piecewise linear techniques;electrical and electronic engineering;training;temperature sensors;computer architecture;artificial neural networks;computer architecture temperature measurement training temperature sensors field programmable gate arrays artificial neural networks;solar radiation;temperature measurement;piecewise linear techniques photovoltaic power systems programmable gate arrays neural networks solar radiation;photovoltaic power systems;field programmable gate arrays;computer science applications1707 computer vision and pattern recognition;control and systems engineering	Knowing solar irradiance value allows an optimized management of photovoltaic (PV) power plants in terms of produced energy. Unfortunately, although sensing temperature is easy, the measurement of solar irradiance is expensive. In this paper, two circuit architectures for the estimation of the solar irradiance based on simple measurements are proposed. They are thought to be part of a centralized system implemented on field programmable gate array (FPGA) for sensing and monitoring of solar irradiance in a whole PV plant. The FPGA centralized architecture could allow for a real-time irradiance mapping by exploiting information coming from several low-cost measuring circuits suitably allocated on the PV modules. Validations on real irradiance data collected by the U.S. Department of Energy’s National Renewable Energy Laboratory are presented.	centralized computing;computation;field-programmable gate array;performance;real-time clock	Alberto Oliveri;Luca Cassottana;Antonino Laudani;Francesco Riganti Fulginei;Gabriele Maria Lozito;Alessandro Salvini;Marco Storace	2017	IEEE Transactions on Industrial Informatics	10.1109/TII.2015.2462293	control engineering;embedded system;electronic engineering;temperature measurement;computer science;engineering;electrical engineering;sunlight;photovoltaic system;machine learning;information system;artificial neural network;field-programmable gate array	EDA	15.367622799622957	-12.905882707189512	161815
683b88e35b95b01801ea4a9ff961052f7d31c4cc	controlling non-conformities propagation in manufacturing. case study in an electromechanical assembly plant	statistical process control assembling control charts production control quality control;non conformities propagation;layers of control;production system;statistical process control;nonconformities propagation control manufacturing electromechanical assembly plant control methods quality performance production system value stream associated control chart low volumes industry energy field;control charts production systems process control industries control systems risk analysis;control chart;production control;control charts;assembling;layers of control statistical quality control statistical process control non conformities propagation;statistical quality control;quality control;control method	The purpose of this paper is to control the propagation of non-conformities. The control methods implemented to ensure the quality performance of a production system present weaknesses, inherent to their constitution, which can let non-conformities propagate along the value stream. This propagation cannot be avoided, but it can be mastered. This paper presents a method to master non-conformities propagation in a production system by building the associated control chart. In order to calibrate the proposition, a case study on non-conformities propagation in a low-volumes industry in the energy field is presented. The simulation of the proposed plan shows the benefits of controlling this indicator.	assembly language;production system (computer science);simulation;software propagation	Valerie Fiegenwald;Samuel Bassetto;Michel Tollenaere	2011	2011 IEEE International Conference on Industrial Engineering and Engineering Management	10.1109/IEEM.2011.6118162	control engineering;reliability engineering;control chart;economics;engineering;operations management;instrumentation and control engineering;statistical process control	Robotics	13.971750357283018	-12.625467202506366	162343
71ffc95e672a2df87ecaad657008f2d13381de16	a novel soft sensor method detecting completion of transition for industrial polymer processes		Soft sensors are widely used to estimate values of process variables that are difficult to measure online, for example, polymer quality variables. Industrial polymer processes generally produce many grades of products. In order to reduce quantity of off-grade material and produce a consistent product, values of polymer quality variables should be estimated with high accuracy by using soft sensor models. However, the predictive accuracy during grade transition can be low because a state in a polymer reactor is unsteady in transition. Values of process variables in the unsteady state can differ from those which is used to construct a regression model. It is desired to know the time on which the polymer quality meets product specifications. Thus, we propose to construct a model which detects completion of transition in order to assure predicted values of the polymer quality variables after the transition. By using the model and constructing regression models for each grade of a product, values of the objective variables can be predicted with high accuracy, selecting a regression model appropriately. We analyzed real industrial data as application of the proposed method. The proposed method achieved higher predictive accuracy than traditional ones.	discriminant;k-nearest neighbors algorithm;model selection;norm (social);polymer;reactor (software);sensor;support vector machine;time series	Hiromasa Kaneko;Masamoto Arakawa;Kimito Funatsu	2009		10.3182/20090921-3-TR-3005.00095	simulation	AI	12.666590871688154	-18.142432816676656	162576
96e8219e033a921ed0e4660da8f1aa316e7b6a1c	preferring properly: increasing coverage while maintaining quality in anytime temporal planning		Temporal Fast Downward (TFD) is a successful temporal planning system that is capable of dealing with numerical values. Rather than decoupling action selection from scheduling, it searches directly in the space of time-stamped states, an approach that has shown to produce plans of high quality at the price of coverage. To increase coverage, TFD incorporates deferred evaluation and preferred operators, two search techniques that usually decrease the number of heuristic calculations by a large amount. However, the current definition of preferred operators offers only limited guidance in problems where heuristic estimates are weak or where subgoals require the execution of mutex operators. In this paper, we present novel methods for refinement of this definition and show how to combine the diverse strengths of different sets of preferred operators using a restarting procedure incorporated into a multi-queue best-first search. These techniques improve TFD’s coverage drastically and preserve the average solution quality, leading to a system that solves more problems than each of the competitors of the temporal satisficing track of IPC 2011 and clearly outperforms all of them in terms of IPC score.	action selection;anytime algorithm;best-first search;coupling (computer programming);display resolution;heuristic;numerical analysis;refinement (computing);scheduling (computing)	Patrick Eyerich	2012		10.3233/978-1-61499-098-7-312	simulation;artificial intelligence;data mining	AI	18.537809620857015	-10.199114690842832	162610
c95e961c3e574ae9ef427b6810c9ec34fe04b11a	partial abductive inference in bayesian belief networks using a genetic algorithm	approximation method;bayesian belief networks;bayesian belief network;exact computation;most probable explanation;genetic algorithm;genetic algorithms;abductive inference;probabilistic reasoning	Abductive inference in Bayesian belief networks is the process of generating the K most probable con®gurations given an observed evidence. When we are only interested in a subset of the network's variables, this problem is called partial abductive inference. Both problems are NP-hard, and so exact computation is not always possible. This paper describes an approximate method based on genetic algorithms to perform partial abductive inference. We have tested the algorithm using the alarm network and from the experimental results we can conclude that the algorithm presented here is a good tool to perform this kind of probabilistic reasoning. Ó 1999 Elsevier Science B.V. All rights reserved.	abductive reasoning;approximation algorithm;bayesian network;computation;genetic algorithm;np-hardness;naruto shippuden: clash of ninja revolution 3	Luis M. de Campos;José A. Gámez;Serafín Moral	1999	Pattern Recognition Letters	10.1016/S0167-8655(99)00088-4	genetic algorithm;frequentist inference;computer science;artificial intelligence;non-monotonic logic;machine learning;pattern recognition;bayesian network;bayesian statistics;abductive logic programming	AI	20.961985023812865	-12.4741148376948	162677
964516b22c0f82e8a9ed135fbbc25eea9fe3b8d4	inducing grammars from sparse data sets: a survey of algorithms and results	inducing grammar;sparse data set;comprehensive survey;finite state automata;occam's razor;a bbadingo one learning competition;grammar induction;sparse example set;occam s razor;sparse data	This paper provides a comprehensive survey of the field of grammar induction applied to randomly generated languages using sparse example sets.	algorithm;grammar induction;procedural generation;sparse matrix	Orlando Cicchello;Stefan C. Kremer	2003	Journal of Machine Learning Research		natural language processing;sparse matrix;grammar induction;computer science;occam's razor;machine learning;sparse language;finite-state machine;adaptive grammar;mildly context-sensitive grammar formalism;algorithm	ML	17.661415746531404	-13.678568624956439	162784
b9ddcb056e00c6c6c4a48cd1c4147393f763e4ff	interval quantile regression models based on swarm intelligence		Abstract This paper presents quantile regression models for classical data and interval symbolic data using algorithms based on swarm intelligence to estimate the parameters aiming to improve the model performance. Also, these methods are compared with methods of estimation based on linear programming widely used in the literature. Applications using real and simulated data are considered. The prediction quality is assessed by the mean magnitude of relative error calculated from test data. The growth of symbolic data nature of alerts to the need of the new statistical methodologies development for the treatment of this type of information. The results show that the proposed models are effective alternatives for optimizing the choice of parameters of the quantile regression, providing greater precision and robustness than models based on linear programming.	interval arithmetic;swarm intelligence	Yanne Micaele Gomes Soares;Roberta Andrade de Araújo Fagundes	2018	Appl. Soft Comput.	10.1016/j.asoc.2018.04.061	artificial intelligence;robustness (computer science);machine learning;swarm intelligence;mathematics;magnitude (mathematics);quantile regression;approximation error;test data;linear programming	AI	15.271194853845087	-18.583360811532287	162885
25238cb0825924e891e0f724c993941ddc52ccb9	spectrum-based sequential diagnosis		We present a spectrum-based, sequential software debugging approach coined SEQUOIA, that greedily selects tests out of a suite of tests to narrow down the set of diagnostic candidates with a minimum number of tests. SEQUOIA handles multiple faults, that can be intermittent, at polynomial time and space complexity, due to a novel, approximate diagnostic entropy estimation approach, which considers the subset of diagnoses that cover almost all Bayesian posterior probability mass. Synthetic experiments show that SEQUOIA achieves much better diagnostic uncertainty reduction compared to random test sequencing. Real programs, taken from the Software Infrastructure Repository, confirm SEQUOIA’s better performance, with a test reduction up to 80% compared to random test sequences.	approximation algorithm;computation;dspace;debugging;embedded system;entropy estimation;experiment;fault detection and isolation;fractal;greedy algorithm;heuristic;ibm sequoia;icse;information gain in decision trees;information theory;intelligent control;intermittent fault;john d. wiley;journal of artificial intelligence research;p (complexity);pervasive informatics;polynomial;regression testing;stochastic optimization;synthetic data;test case;time complexity;top-down and bottom-up design	Alberto González-Sanchez;Rui Abreu;Hans-Gerhard Groß;Arjan J. C. van Gemund	2011			simulation;algorithm;statistics	AI	24.497644768223182	-16.13107114014265	162988
4f93a8e55ac45247f4feb420eeed32f781f6dab7	lightclockv2 - a motivation for teaching scalable digital hardware design		Learning embedded design can be achieved with simple standard applications and microcontrollers but to spark interest in the topic, to pursue digital hardware design, motivation of students is a key factor demanding new approaches. One of which is presented in this paper as the LightClockV2, a fancy LED-based visualization gadget, built from 60 RGB color LEDs mounted on a circular PCB board to generate radial light beams. For focusing beams, we used laser pointer lenses which are mounted and adjusted in 3D printed holders. A main challenge of the project was the generation of 180 individually controllable pulse width modulation (PWM) signals. Characteristics as a 100 kHz PWM frequency, expandability for other visualization applications and a full single chip solution tighten the project requirements. In an implementation perspective a FPGA based solution efficiently provides an appropriate computational unit (finite state machine) generating light patterns, and 180 PWM peripheral modules. However, the FPGA implementation is a powerful and high-performance realization of this application and faces significant advantages in contrast to a classical microcontroller-based solution.	3d printing;digital electronics;embedded system;field-programmable gate array;finite-state machine;microcontroller;peripheral;pointer (computer programming);pulse-width modulation;radial (radio);requirement	Michael Rathmair;Friedrich Bauer;Marcus Meisel	2018	2018 IEEE 27th International Symposium on Industrial Electronics (ISIE)	10.1109/ISIE.2018.8433817	computer hardware;peripheral;microcontroller;field-programmable gate array;chip;finite-state machine;rgb color model;engineering;visualization;pulse-width modulation	EDA	14.704252702458957	-9.89156867771791	163040
5d6222dd49c6229eed9b9ba991c5aa0d9ad410fd	diversity-driven extensible hierarchical reinforcement learning		Hierarchical reinforcement learning (HRL) has recently shown promising advances on speeding up learning, improving the exploration, and discovering intertask transferable skills. Most recent works focus on HRL with two levels, i.e., a master policy manipulates subpolicies, which in turn manipulate primitive actions. However, HRL with multiple levels is usually needed in many real-world scenarios, whose ultimate goals are highly abstract, while their actions are very primitive. Therefore, in this paper, we propose a diversity-driven extensible HRL (DEHRL), where an extensible and scalable framework is built and learned levelwise to realize HRL with multiple levels. DEHRL follows a popular assumption: diverse subpolicies are useful, i.e., subpolicies are believed to be more useful if they are more diverse. However, existing implementations of this diversity assumption usually have their own drawbacks, which makes them inapplicable to HRL with multiple levels. Consequently, we further propose a novel diversity-driven solution to achieve this assumption in DEHRL. Experimental studies evaluate DEHRL with five baselines from four perspectives in two domains; the results show that DEHRL outperforms the state-of-the-art baselines in all four aspects.	baseline (configuration management);reinforcement learning;scalability	Yuhang Song;Jianyi Wang;Thomas Lukasiewicz;Zhenghua Xu;Mai Xu	2018	CoRR		artificial intelligence;implementation;machine learning;reinforcement learning;scalability;computer science;extensibility;transferable skills analysis	AI	21.04205696979449	-21.945688321394464	163164
07069f4b928a21a0f8793c9336dbdd3633e03335	large datasets: a mixed method to adapt and improve their learning by neural networks used in regression contexts		The purpose of this work is to further study the relevance of accelerating the Monte-Carlo calculations for the gamma rays external radiotherapy through feed-forward neural networks. We have previously presented a parallel incremental algorithm that builds neural networks of reduced size, while providing high quality approximations of the dose deposit [4]. Our parallel algorithm consists in an optimized decomposition of the initial learning dataset (also called learning domain) in as much subsets as available processors. However, although that decomposition provides subsets of similar signal complexities, their sizes may be quite different, still implying potential differences in their learning times. This paper presents an efficient data extraction allowing a good and balanced training without any loss of signal information. As will be shown, the resulting irregular decomposition permits an important improvement in the learning time of the global network.	3d computer graphics;advanced power management;approximation;central processing unit;display resolution;dynamical simulation;experiment;feedforward neural network;global network;monte carlo method;neural networks;parallel algorithm;relevance	Marc Sauget;Julien Henriet;Michel Salomon;Sylvain Contassot-Vivier	2011		10.1007/978-3-642-23957-1_21	computer science;artificial intelligence;machine learning;data mining	ML	23.08653762691278	-20.701312352068122	163249
06b9cae470d7ce879d39548957fc9681c6bf3d17	multi-response variable optimization in sensor drift monitoring system using support vector regression	svr;sensor calibration;response surface methodology;in yong seo bok nam ha won nam koong 支持向量回归 传感器漂移 变量优化 监控系统 传感器信号 灵敏度 正常运行 安全操作 multi response variable optimization in sensor drift monitoring system using support vector regression;optimal method;support vector regression;performance index;npp;monitoring system;multi response;nuclear power plant;rsm;pca;principal component	In a nuclear power plant (NPP), periodic sensor calibrations are required to assure sensors are operating correctly. However, only a few faulty sensors are found to be calibrated. For the safe operation of an NPP and the reduction of unnecessary calibration, on-line calibration monitoring is needed. Most researches have been focused on improving only the accuracy of the system although sensitivity is another important performance index. This paper presents multi-response optimization for an on-line sensor drift monitoring system to detect drift and estimate sensor signal effectively. Accuracy and sensitivity of the principal component-based auto-associative support vector regression (PCSVR) were optimized at the same time by desirability function approach. Response surface methodology (RSM) is employed to efficiently determine the optimal values of SVR hyperparameters. The proposed optimization method was confirmed with actual plant data of Kori NPP Unit 3. The results show the trade-off between the accuracy and sensitivity of the model as we expected.		In-Yong Seo;Bok-Nam Ha;Min-Ho Park	2011		10.1007/978-3-642-20042-7_3	simulation;computer science;machine learning;data mining;principal component analysis	Robotics	12.997259880936793	-16.05685610218083	163301
dbcad7dc7c15734e60d325e924ab9363ba86bbb0	tburton: a divide and conquer temporal planner	episode;history;timeline;timed concurrent automata;temporal planning;automata;regression;planning temporal planner;temporal network;timed automata;simple temporal network	Planning for and controlling a network of interacting devices requires a planner that accounts for the automatic timed transitions of devices, while meeting deadlines and achieving durative goals. Consider a planner for an imaging satellite with a camera that cannot tolerate exhaust. The planner would need to determine that opening a valve causes a chain reaction that ignites the engine, and thus needs to shield the camera. While planners exist that support deadlines and durative goals, currently, no planners can handle automatic timed transitions. We present tBurton, a temporal planner that supports these features, while additionally producing a temporally least-commitment plan. tBurton uses a divide and conquer approach: dividing the problem using causal-graph decomposition and conquering each factor with heuristic forward search. The ‘sub-plans’ from each factor are then unified in a conflict directed search, guided by the causal graph structure. We describe why this approach is fast and efficient, and demonstrate its ability to improve the performance of existing planners on factorable problems through benchmarks from the International Planning Competition.	causal filter;causal graph;heuristic;interaction	David Wang;Brian Charles Williams	2015			timeline;real-time computing;simulation;regression;computer science;artificial intelligence;automaton	AI	17.91407858329314	-10.559539414896392	163703
000ae3191a681b1d80f59426b9e65b1f1669100e	artificial neural network method to construct potential energy surfaces for transition metal nanoparticles: pt, au, and ag	molecular dynamics simulations;feedforward neural network;transition metal nanoparticle;ag;transition metal nanoparticle artificial neural network potential energy surface modeling prediction feedforward;nanoparticles;feedforward neural networks;platinum;feedforward;training;silver feedforward neural nets gold materials science computing molecular dynamics method nanoparticles platinum potential energy surfaces;molecular dynamic simulation;ag artificial neural network method potential energy surfaces transition metal nanoparticles feedforward neural networks nonlinear relationship binding energy density functional theory calculations molecular dynamics simulations pt au;transition metal;molecular dynamics method;artificial neural networks;density functional theory calculations;pt;gold;artificial neural networks potential energy nanoparticles gold neurons chemistry neural networks feedforward neural networks shape control surface fitting;density function theory;silver;materials science computing;nonlinear relationship;feedforward neural nets;potential energy surfaces;potential energy surface;neurons;potential energy;local minima;modeling;prediction;transition metal nanoparticles;binding energy;artificial neural network;au;artificial neural network method	Potential energy surfaces (PESs) for transition metal nanoparticles of Pt, Au, and Ag were derived using the artificial neural network (ANN) method. Three feedforward neural networks were constructed to fit the nonlinear relationship between the binding energy and the nanoparticle information, i.e. size and atomic coordinates, based on the data obtained from density functional theory calculations. The test results demonstrated that the newly derived ANN PESs can successfully predict the binding energy at the local minima of the global potential energy surfaces. More promisingly, the ANN PESs may be used in the molecular dynamics simulations for studying transition metal nanoparticles that are larger in size than those being studied here.	artificial neural network;density functional theory;feedforward neural network;functional theories of grammar;maxima and minima;molecular dynamics;nonlinear system;simulation	Zhe Xu;Xiajing Shi;Jianbo Li;Susan Lu;Lichang Wang	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.243	materials science;machine learning;computational chemistry;nanotechnology	Robotics	13.04979342438892	-20.415100784450754	164009
1fdf0319b4a1db62c611980351e5f4c2f08958cd	gep-pg: decoupling exploration and exploitation in deep reinforcement learning algorithms		In continuous action domains, standard deep reinforcement learning algorithms like DDPG suffer from inefficient exploration when facing sparse or deceptive reward problems. Conversely, evolutionary and developmental methods focusing on exploration like Novelty Search, QualityDiversity or Goal Exploration Processes explore more robustly but are less efficient at fine-tuning policies using gradient-descent. In this paper, we present the GEP-PG approach, taking the best of both worlds by sequentially combining a Goal Exploration Process and two variants of DDPG. We study the learning performance of these components and their combination on a low dimensional deceptive reward problem and on the larger Half-Cheetah benchmark. We show that DDPG fails on the former and that GEP-PG improves over the best DDPG variant in both environments. Supplementary videos and discussion can be found at frama.link/gep_pg, the code at github.com/flowersteam/geppg.	algorithm;benchmark (computing);coupling (computer programming);gene expression programming;gradient descent;reinforcement learning;sparse matrix	Cédric Colas;Olivier Sigaud;Pierre-Yves Oudeyer	2018			decoupling (cosmology);machine learning;novelty;pattern recognition;artificial intelligence;computer science;reinforcement learning;algorithm	ML	20.71807623870554	-20.331993387533096	164335
3345bf0066863fab82862b3203adf185a841e310	learning options in multiobjective reinforcement learning		Reinforcement Learning (RL) is a successful technique to train autonomous agents. However, the classical RL methods take a long time to learn how to solve tasks. Option-based solutions can be used to accelerate learning and transfer learned behaviors across tasks by encapsulating a partial policy into an action. However, the literature report only single-agent and single-objective option-based methods, but many RL tasks, especially real-world problems, are better described through multiple objectives. We here propose a method to learn options in Multiobjective Reinforcement Learning domains in order to accelerate learning and reuse knowledge across tasks. Our initial experiments in the Goldmine Domain show that our proposal learn useful options that accelerate learning in multiobjective domains. Our next steps are to use the learned options to transfer knowledge across tasks and evaluate this method with stochastic policies.	autonomous robot;experiment;reinforcement learning;stochastic process	Rodrigo Cesar Bonini;Felipe Leno da Silva;Anna Helena Reali Costa	2017			artificial intelligence;error-driven learning;machine learning;computer science;reinforcement learning	AI	20.105582457644438	-19.91951258933706	164391
4e5d6aaed1a31620135f8446c0137e3913bec5c2	a new learning algorithm for the hierarchical structure learning automata operating in the nonstationary s-model random environment	learning algorithm relative reward strength algorithm convergence optimal path nonstationary environment hierarchical structure learning automata nonstationary s model random environment;hierarchical structure;nonstationary environment;learning algorithm;relative reward strength algorithm;indexing terms;learning automata;learning artificial intelligence learning automata;learning artificial intelligence;hierarchical structure learning automata hsla;article;computer simulation;random environment;learning automata computer simulation intelligent systems information science pursuit algorithms hierarchical systems convergence power engineering and energy cities and towns	An extended algorithm of the relative reward strength algorithm is proposed. It is shown that the proposed algorithm ensures the convergence with probability I to the optimal path under the certain type of nonstationary environment. Several computer simulation results confirm the effectiveness of the proposed algorithm.	algorithm;automata theory;computer simulation;convergence (action);learning automata	Norio Baba;Yoshio Mogami	2002	IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society	10.1109/TSMCB.2002.1049609	computer simulation;unsupervised learning;mathematical optimization;index term;wake-sleep algorithm;computer science;artificial intelligence;theoretical computer science;machine learning;stability;active learning;population-based incremental learning;generalization error	Robotics	18.370962622687227	-22.694615307460435	164520
621dbe0c863c330660675d806029f86960796eb2	submodular learning and covering with response-dependent costs		We consider interactive learning and covering problems, in a setting where actions may incur different costs, depending on the outcomes of the action. Fo r instance, in a clinical trial, selecting a patient for treatment might result in improved health o r adverse effects for this patients, and these two outcomes have different costs. We consider a se tting where these costs can be inferred from observable responses to the actions. We gener alize previous analyses of interactive learning and covering to consistency aware submodular objectives, and propose a natural greedy algorithm for the setting of response-dependent costs. We b ound the approximation factor of this greedy algorithm, for general submodular functions, as wel l as specifically forlearning objectives, and show that a different property of the cost function cont rols the approximation factor in each of these scenarios. We further show that in both setting s, the approximation factor of this greedy algorithm is near-optimal in the class of greedy algo rithms. Experiments demonstrate the advantages of the proposed algorithm in the response-depen nt cost setting.	approximation;covering problems;fo (complexity);greedy algorithm;loss function;observable;submodular set function	Sivan Sabato	2018	Theor. Comput. Sci.	10.1016/j.tcs.2017.12.033	submodular set function;artificial intelligence;computer science;machine learning;active learning;covering problems;interactive learning;mathematical optimization;greedy algorithm	ML	21.459143918618164	-13.892744218849256	164547
ffaf6d5cf16fcdce85086e77046047cb0dbfb778	knowledge discovery and pavement performance: intelligent data mining	bituminous pavements;computer program;water management;bituminous pavement;decision tree;raveling;support vector machines;rough set theory;data collection;rule based;data mining;research method;genetics;pavements;porous asphalt concrete;artificial intelligent;variable selection;data analysis;deformation;machine learning;stiffness;linear elasticity;mathematical models;cement treated bases;cracking;dense asphalt concrete;artificial intelligence;rutting;support vector machine;asphalt concrete;decision trees;pavement technology;pavement performance;artificial neural network;neural network;base layer;knowledge discovery	The main goal of the study was to discover knowledge from data about asphalt road pavement problems to achieve a better understanding of the behavior of them and via this understanding improve pavement quality and enhance its lifespan. Four pavement problems were chosen to be investigated; raveling of Porous Asphalt Concrete (PAC), cracking of Dense Asphalt Concrete (DAC), rutting of dense asphalt concrete, and determination of the stiffness of Cement Treated Bases (CTBs). At the moment, almost 75% of the Dutch motorways network has a PAC top layer. Raveling is the most dominant type of damage of PAC top layers. The DAC top layers which are mainly applied to the secondary roads in the Netherlands are the most commonly used top layers worldwide. The two main damage types of this top layer are cracking and rutting. Determination of the stiffness of the cement treated base layer stiffness is not an easy task. Therefore, a tool which can accurately calculate the stiffness of such base layers is desirable. Concerning data, the SHRP-NL databases provided the data for the three surface damages, being ravelling of PAC, cracking and rutting of DAC. The data for climate and traffic were obtained from databases of the Royal Dutch Meteorological Institute (KNMI), the Ministry of Transport and Water Management, and different provinces of the Netherlands. The data for the stiffness of CTBs was simulated using the multilayer linear-elastic computer program BISAR. During preparation of the data, the determination of outliers was a challenging task. Due to the low number of data points available for raveling, cracking, and rutting (in one case around 70 data points), an extensive variable selection was performed using eight different methods: decision trees, genetic polynomial, artificial neural network, rough set theory, correlation based variable selection with bidirectional and genetic search, wrappers of neural network with genetic search, and relief ranking filter. For development of models (data mining) from the mentioned data, four machine learning based techniques were employed. Two were prediction techniques; artificial neural networks and support vector machines. The other two were rule based techniques; decision trees and rough set theory. This study resulted in 20 intelligent models for the mentioned four problems		Maryam Miradi	2009			structural engineering;engineering;civil engineering;forensic engineering	ML	10.095771495820749	-20.100597579957782	164645
0e67c7f538cda8e02a51f72fde53de676e60f1ed	on the hybrid neural network model for solving optimization problems	traveling salesman problem;hybrid network;satisfiability;optimization problem;general solution;neural network model;neural network	A recent model of neural networks, named the Hybrid Neural Network Model (HN), for solving optimization problems appeared in [3]. In [3], the main algorithm called the Hybrid Network Updating Algorithm (HNUA) is used to drive the HN model. The best thing about the HNUA is that it reaches a feasible solution very quickly. Our argument here is that while the HNUA is very quick to satisfy the constraints, it guarantees very little in terms of the quality of the generated solution. In this paper we rewrite one of the steps in the HNUA so that the goal function is better served. we demonstrate our work using the traveling salesman problem as an example.	hybrid neural network;network model	Fouad B. Chedid	1995		10.1007/3-540-61576-8_82	stochastic neural network;2-opt;mathematical optimization;artificial intelligence;recurrent neural network;machine learning;3-opt;bottleneck traveling salesman problem	AI	21.301432275885354	-11.285125370227705	164654
eea1d303b4e78c86a2675880fa20ff35cf1fe6cb	prediction of bearing remaining useful life with deep convolution neural network		Cyber-physical-social system (CPSS) has drawn tremendous attention in industrial applications such as industrial Internet of Things (IIoT). As the fundamental component of IIoT, bearings play an increasingly important role in CPSS for IIoT. Better understanding of bearing working conditions and degradation patterns so as to more accurately predict the remaining useful life (RUL), becomes an urgent demand for industrial prognostics in IIoT. The data-driven approach has indicated good potential, but the prediction accuracy is still not satisfactory. This paper proposes a new method for the prediction of bearing RUL based on deep convolution neural network (CNN). A new feature extraction method is presented to obtain the eigenvector, named the spectrum-principal-energy-vector. The eigenvector is suitable for deep CNN. In the prediction phase, we propose a smoothing method to deal with the discontinuity problem found in the prediction results. To the best of our knowledge, we are the first to propose such a smoothing method for bearing RUL prediction. Experiments show that our method can significantly improve the prediction accuracy of bearing RUL.	artificial neural network;convolution;elegant degradation;feature extraction;internet of things;reflections of signals on conducting lines;smoothing;social system	Lei Ren;Yaqiang Sun;Hao Wang;Lin Zhang	2018	IEEE Access	10.1109/ACCESS.2018.2804930	convolutional neural network;artificial neural network;machine learning;smoothing;prognostics;industrial internet;feature extraction;computer science;distributed computing;bearing (mechanical);artificial intelligence	ML	14.425200677547943	-17.14897349330183	164727
53f7aed2a851c00ea4225aa182c6564403cacd58	an artificial neural network for classification a quality of a coal fuel in combustion chambers using fpaa	feedforward ann neural network fpaa;field programmable analog arrays;combustion field programmable analog arrays artificial neural networks neurons coal process control;gradient algorithm coal fuel quality classification combustion chambers fpaa feedforward artificial neural network matlab polak riberie formula ann;artificial neural networks;coal;process control;quality control coal combustion combustion equipment feedforward neural nets gradient methods mathematics computing production engineering computing;neurons;combustion	A hardware artificial neural network for classification a quality of a coal fuel in combustion chambers is presented in the paper. Proposed method is based on an analysis of measured combustion process parameters in the chamber by the feedforward artificial neural network. Measured parameters have been used to train neural network weights with a help of MATLAB program. The preconditioned conjugate gradient algorithm with the Polak-Riberie formula has been used to weights training process. Calculated weights have been used to determine the quality of the coal fuel loaded into the chamber. The ANN has been tested by the MATLAB program and the FPAA implemented network. Obtained results are presented and discussed.	algorithm;artificial neural network;conjugate gradient method;feedforward neural network;field-programmable analog array;matlab	Robert Suszynski;Jacek Marciniak;Krzysztof Wawryn	2016	2016 MIXDES - 23rd International Conference Mixed Design of Integrated Circuits and Systems	10.1109/MIXDES.2016.7529723	control engineering;electronic engineering;engineering;electrical engineering	EDA	13.154536762465852	-20.313546528775866	164789
3fc6f0e8f598e613db46e1b643b85e11459ea79f	traffic safety region estimation based on sfs-pca-lssvm: an application to highway crash risk evaluation		Accurate real-time crash risk evaluation is essential for making prevention strategy in order to proactively improve traffic safety. Quite a number of models have been developed to evaluate traffic crash risk, by using real-time surveillance data. In this paper, the basic idea of traffic safety region is introduced into highway crash risk evaluation. Traffic safety region aims to describe the safe condition for highway, which means highway is under low risk of crash condition. Sequential forward selection (SFS), principal components analysis (PCA) and least squares support vector machine (LSSVM) are used comprehensively for traffic safety region estimation and classifying the traffic states (safe condition and unsafe condition). The method works by first extracting state variables from the observed traffic variables. Two statistics T and SPE are calculated by SFS-PCA and used as the final state variables for traffic state space. Next, LSSVM is used to estimate the boundary of traffic safety region and identify the traffic states. To demonstrate the advantage of the proposed method, this study develops two crash risk evaluation models, namely SFS-LSSVM model and PCA-LSSVM model, based on crash data and non-crash data collected on freeway I-880N in Alameda. Validation results show that the method is of reasonably high accuracy for identifying traffic states. Keywords— Traffic safety region, Crash risk evaluation, SFS, PCA, LSSVM	clustered file system;freeway;least squares support vector machine;principal component analysis;real-time clock;real-time transcription;state space;stepwise regression	Yanfang Yang;Yong Qin;Limin Jia;Honghui Dong	2016	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194016400179	crash test;automotive engineering;transport engineering	Security	11.944406262356642	-14.276245639581436	164872
f60013093f497ba82ea68898e9ace6368a27db52	breakout prediction for continuous casting using genetic algorithm-based back propagation neural network model	manufacturing defect;modelizacion;medida temperatura;gas;installation coulee continue;continuous casting;etude experimentale;efficiency;thermocouple;en continu;en continuo;algoritmo genetico;propagation erreur;termopar;feasibility;modelisation;continuous casting machine;eficacia;casting;colada continua;backpropagation algorithm;bp neural network;instalacion colada continua;defaut fabrication;algorithme genetique;efficacite;breakout prediction;algorithme retropropagation;genetic algorithm;genetic algorithms;temperature measurement;propagacion error;growth of error;reseau neuronal;coulee continue;modeling;estudio experimental;coulee en moule;red neuronal;practicabilidad;faisabilite;continuous process;defecto fabricacion;neural network;colada molde;mesure temperature;algoritmo retropropagacion	In this paper, the effectiveness of the genetic algorithm-based back propagation (GABP) neural network model and its application to the breakout prediction in the continuous casting process are investigated. The formation of the sticking-type breakouts and the prediction principle of thermocouple thermometry method are analysed firstly. Then the genetic algorithm-based back propagation neural network model is proposed by fusing genetic algorithm (GA), and error back propagation neural network to offset the demerits of one paradigm by the merits of another. Finally, the GABP neural network model is applied to the breakout prediction in the continuous casting process; and the feasibility of the model is verified by the testing result with the accuracy rate of 97.56% and the prediction rate of 100%.	artificial neural network;backpropagation;breakout box;genetic algorithm;genetic operator;global optimization;kiva;mathematical optimization;network model;nonlinear system;premature convergence;programming paradigm;software propagation	Benguo Zhang;Ruizhong Zhang;Ge Wang;Lifeng Sun;Zhike Zhang;Qiang Li	2012	IJMIC	10.1504/IJMIC.2012.047727	feasibility study;genetic algorithm;computer science;engineering;artificial intelligence;machine learning;engineering drawing;artificial neural network;algorithm	AI	14.843184126554808	-19.996770484566863	165142
d7c870912e29fdfb89cb467b35561906ec29b226	novelty and habituation: the driving forces in early stage learning for developmental robotics	genetique;modelizacion;structure topologique;learning process;biologically inspired robots;driving force;long period;consolidacion;capteur tactile;nouveaute;genetica;tactile sensor;sensor tactil;novelty;topological structure;novedad;intelligence artificielle;sensory feedback;robotics;apprentissage moteur;psychology;development process;developmental psychology;developmental robotics;habituacion;genetics;recovery rate;modelisation;consolidation;dk atira pure researchoutput researchoutputtypes contributiontoconference paper;biomimetique;robotica;artificial intelligence;coordinacion;psychologie;robotique;inteligencia artificial;reseau neuronal;motor learning;habituation;modeling;estructura topologica;red neuronal;psicologia;aprendizaje motor;coordination;biomimetics;neural network;approaches to learning;dk atira pure researchoutput researchoutputtypes contributiontobookanthology chapter	Biologically inspired robotics offers the promise of future autonomous devices that can perform significant tasks while coping with noisy, real-world environments. In order to survive for long periods we believe a developmental approach to learning is required and we are investigating the design of such systems inspired by results from developmental psychology. Developmental learning takes place in the context of an epigenetic framework that allows environmental and internal constraints to shape increasing competence and the gradual consolidation of control, coordination and skill. In this paper we describe the use of novelty and habituation as the motivation mechanism for a sensory-motor learning process. In our system, a biologically plausible habituation model is utilized and the effect of parameters such as habituation rate and recovery rate on the learning/development process is studied. We concentrate on the very early stages of development in this work. The learning process is based on a topological mapping structure which has several attractive features for sensory-motor learning. The motivation model was implemented and tested through a series of experiments on a working robot system with proprioceptive and contact sensing. Stimulated by novelty, the robot explored its egocentric space and learned to coordinate motor acts with sensory feedback. Experimental results and analysis are given for different parameter configurations, proprioceptive encoding schemes, and stimulus habituation schedules.	developmental robotics	Qinggang Meng;Mark H. Lee	2005		10.1007/11521082_19	consolidation;biomimetics;robot learning;computer vision;systems modeling;motor learning;computer science;artificial intelligence;machine learning;robotics;developmental robotics;software development process;habituation;artificial neural network;tactile sensor	Robotics	23.82375631902813	-13.081798499678287	165429
b9f2e8aac1ca1ef4fd492baf63e7ac2d14e6d9ef	the optimal parameter design of aerospace aluminum alloy weldment via soft computing	silicon;decision making optimal parameter design aerospace aluminum alloy weldment soft computing economic design method effective experimental design method parameter design problem topsis technique for order preference by similarity to ideal solution ann artificial neural network sc simulated anneal sa genetic algorithm ga product quality welding efficiency welding industries tig welding parameters;arc welding;electric shock;aerospace engineering;simulated annealing aerospace engineering aerospace materials aluminium alloys arc welding genetic algorithms neural nets production engineering computing;neural nets;aluminum alloys;welding artificial neural networks genetic algorithms silicon aluminum alloys electric shock markov processes;soft computing;welding;simulated anneal;simulated annealing;production engineering computing;aerospace materials;aluminum alloy;artificial neural networks;tig;aerospace aluminum alloy;aluminium alloys;markov process;genetic algorithm;genetic algorithms;markov processes;artificial neural network;simulated anneal aerospace aluminum alloy tig soft computing artificial neural network genetic algorithm	This research proposes an economic and effective experimental design method of multiple characteristics to deal with the parameter design problem with many continuous parameters and levels. It uses TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) and ANN (Artificial Neural Network) to train the optimal function framework of parameter design. It combines SC (Soft Computing) of SA (Simulated Anneal) and GA (Genetic Algorithm) to search the optimal parameters combination for the optimal parameter of aerospace aluminum alloy weldment. To improve previous experimental methods for multiple characteristics, this research method employs SA to search the optimal parameter such that the potential parameter can be evaluated more completely and objectively. Additionally, the model can learn the relationship between the welding parameters and the quality responses of different aluminum alloy materials to facilitate the future applications in the decision-making of parameter settings for automatic welding equipment. The research results can be presented to the industries as a reference, and improve the product quality and welding efficiency to relevant welding industries.	artificial neural network;design of experiments;genetic algorithm;robot welding;soft computing	Jhy-Ping Jhang	2011	2011 Seventh International Conference on Natural Computation	10.1109/ICNC.2011.6022158	engineering;engineering drawing;metallurgy;manufacturing engineering	Robotics	14.332333896174818	-12.440311228873085	165470
a7ec161c59ed27f2940eaaed0765bca48b35ecc4	modelling of suspended sediment - in nile river using ann	suspended sediment	Artificial neural network (ANN) prediction models can be considered as an efficient tool in predictions once they are trained from examples or patterns. These types of ANN models need large amount of data which should be at hand before thinking to develop such models. In this paper, the capability of ANN model to predict suspended sediment in 2-D flow field is investigated. The data used for training the network are generated from a pre-verified 2-D hydrodynamic and a 2-D suspended sediment models which were recently developed by the authors. About two-thirds of the data are used for training the network while the rest of the data are used for validating and testing the developed ANN model. Field data measured by hydraulic research Institute are used to compare the results of the ANN model. The conjugate gradient learning algorithm is adopted. The results of the developed ANN model proved that the technique is reliable in such field compared to both the results of the previously developed models and the field data provided that the trained network is used to generate prediction within the range of training data.	algorithm;artificial neural network;computation;conjugate gradient method;feedforward neural network;mathematical model;multilayer perceptron;numerical analysis;verification and validation	Abdelazim M. Negm;M. M. Elfiky;T. M. Owais;M. H. Nassar	2007			computer science	ML	11.417739694059634	-20.445118312575648	165844
1b1b60d964277fcb037398e7a04959264b84cc66	efficient reinforcement learning via probabilistic trajectory optimization		We present a trajectory optimization approach to reinforcement learning in continuous state and action spaces, called probabilistic differential dynamic programming (PDDP). Our method represents systems dynamics using Gaussian processes (GPs), and performs local dynamic programming iteratively around a nominal trajectory in Gaussian belief spaces. Different from model-based policy search methods, PDDP does not require a policy parameterization and learns a time-varying control policy via successive forward-backward sweeps. A convergence analysis of the iterative scheme is given, showing that our algorithm converges to a stationary point globally under certain conditions. We show that prior model knowledge can be incorporated into the proposed framework to speed up learning, and a generalized optimization criterion based on the predicted cost distribution can be employed to enable risk-sensitive learning. We demonstrate the effectiveness and efficiency of the proposed algorithm using nontrivial tasks. Compared with a state-of-the-art GP-based policy search method, PDDP offers a superior combination of learning speed, data efficiency, and applicability.	algorithm;convergence (action);differential dynamic programming;gaussian process;iteration;iterative method;mathematical optimization;normal statistical distribution;program optimization;reinforcement learning;stationary process;system dynamics;trajectory optimization	Gökçe Can Gür;George I. Boutselis;Evangelos Theodorou	2018	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2017.2764499	machine learning;probabilistic logic;trajectory optimization;artificial intelligence;dynamic programming;reinforcement learning;data efficiency;differential dynamic programming;computer science;gaussian process;optimal control	ML	21.49771050101585	-18.78228335435271	166110
58b40fc89c3d2740e3e62447b46ae09341ef163d	unusual condition detection of bearing vibration in hydroelectric power plants for risk management	risk management;power plant;pattern detection;electric power;support vector machine	Kyushu Electric Power Co., Inc. collects different sensor data and weather information to maintain the safety of hydroelectric power plants while the plants are running. In order to maintain the safety of hydroelectric power plants, it is very important to measure and collect the sensor data of abnormal condition and trouble condition. However, it is very hard to measure and collect them. Because it is very rare to occur abnormal condition and trouble condition in the hydroelectric power equipment. In this situation, we have to find abnormal condition sign as a risk management from the many sensor data of normal condition. In this paper, we consider that the abnormal condition sign may be unusual condition. This paper shows results of unusual condition patterns detection of bearing vibration. The unusual condition patterns are detected from the collected different sensor data and weather information by using one class support vector machine. The result shows that our approach may be useful for unusual condition patterns detection in bearing vibration and maintaining hydroelectric power plants. Therefore, the proposed method is one method of risk management for hydroelectric power plants.	risk management	Takashi Onoda;Norihiko Ito;Kenji Shimizu	2006		10.1007/978-3-540-69902-6_28	control engineering;engineering;operations management;forensic engineering	EDA	12.228008126149055	-15.043331334615766	166369
efc92d09b84af1dacd213df8bfc1ffcb1e2b64c0	operation network modeling with degenerate causal strengths for missile defense systems	missiles tin analytical models stochastic processes delay effects indexes;operation process evaluation degenerate causal strengths missile defense system mds operation network model	A hybrid operation network model is proposed to describe and evaluate a missile defense system. More specifically, the network model provides a formal modeling approach based on the concept of the Combat Network Model. It represents uncertain information of the combat space with probabilities and the causal strengths (CAST) logic. Besides, the degenerate value of CAST parameter is discussed, and a complete conflict situation is discovered which the existing CAST algorithm cannot handle it. Furthermore, a novel modeling framework is proposed with the degenerate CAST parameters and virtual actionable nodes. The framework characterizes the missile defense process considering such factors as time delay, location, capability, and operation scope of weapons. The feasibility of the proposed model is demonstrated using a simulated example along with a sensitivity analysis. The results show the advantage of the joint control and command, identify the sensitive events/activities regarding the efficiency improvement, and suggest an optimal expected operation time window.	algorithm;broadcast delay;cast tool;cast-256;causal filter;causality;network model;operation time	Jianbin Sun;Bingfeng Ge;Jichao Li;Kewei Yang	2018	IEEE Systems Journal	10.1109/JSYST.2016.2570519	computer science;real-time computing;control engineering;missile defense;degenerate energy levels;network model;stochastic process;control theory	AI	11.140933973164506	-11.342636201177543	166507
68061754df2928009fe48983b46eaad4511a4a5c	model-based contextual policy search for data-efficient generalization of robot skills	model based policy search;contextual policy search;gaussian processes;reinforcement learning;robotics;journal article;abt scholkopf;robot table tennis;robot hockey;robot skill generalization;abt schaal;movement primitives	In robotics, lower-level controllers are typically used to make the robot solve a specific task in a fixed context. For example, the lower-level controller can encode a hitting movement while the context defines the target coordinates to hit. However, in many learning problems the context may change between task executions. To adapt the policy to a new context, we utilize a hierarchical approach by learning an upper-level policy that generalizes the lower-level controllers to new contexts. A common approach to learn such upper-level policies is to use policy search. However, the majority of current contextual policy search approaches are model-free and require a high number of interactions with the robot and its environment. Model-based approaches are known to significantly reduce the amount of robot experiments, however, current model-based techniques cannot be applied straightforwardly to the problem of learning contextual upper-level policies. They rely on specific parametrizations of the policy and the reward function, which are often unrealistic in the contextual policy search formulation. In this paper, we propose a novel model-based contextual policy search algorithm that is able to generalize lower-level controllers, and is data-efficient. Our approach is based on learned probabilistic forward models and information theoretic policy search. Unlike current algorithms, our method does not require any assumption on the parametrization of the policy or the reward function. We show on complex simulated robotic tasks and in a real robot experiment that the proposed learning framework speeds up the learning process by up to two orders of magnitude in comparison to existing methods, while learning high quality policies.	approximation algorithm;constrained optimization;constraint (mathematics);data point;display resolution;duality (optimization);encode;exptime;experiment;gradient;information theory;interaction;interior point method;lagrangian (field theory);lagrangian relaxation;mathematical optimization;optimization problem;reinforcement learning;robot;robotics;sampling (signal processing);search algorithm;solver	Andras Gabor Kupcsik;Marc Peter Deisenroth;Jan Peters;Ai Poh Loh;Prahlad Vadakkepat;Gerhard Neumann	2017	Artif. Intell.	10.1016/j.artint.2014.11.005	robot learning;simulation;computer science;artificial intelligence;machine learning;gaussian process;robotics;reinforcement learning	AI	21.40769120464364	-19.283784313389738	166693
32825161c161270f4e305fab0e53b517109b65ac	evolving neural networks	neural networks;value function;evolutionary computing;neural network;artificial neural network;pattern matching;artificial life;evolutionary computation;neuroevolution;network topology;reinforcement learning	Neuroevolution, i.e. evolution of artificial neural networks, has recently emerged as a powerful technique for solving challenging reinforcement learning problems. Compared to traditional (e.g. value-function based) methods, neuroevolution is especially strong in domains where the state of the world is not fully known: the state can be disambiguated through recurrency, and novel situations handled through pattern matching. In this tutorial, we will review (1) neuroevolution methods that evolve fixed-topology networks, network topologies, and network construction processes, (2) ways of combining traditional neural network learning algorithms with evolutionary methods, and (3) applications of neuroevolution to game playing, robot control, resource optimization, and cognitive science.	artificial neural network;cognitive science;evolutionary algorithm;machine learning;mathematical optimization;network topology;neuroevolution;pattern matching;reinforcement learning;robot control	Risto Miikkulainen;Kenneth O. Stanley	2009		10.1145/1570256.1570410	evolutionary computation;machine learning;artificial neural network;artificial life;reinforcement learning;neuroevolution;computer science;neuroevolution of augmenting topologies;artificial intelligence;hyperneat;evolutionary acquisition of neural topologies	AI	16.80876683781595	-23.040641127425335	167116
403948155a0bb9c35a4816e19465fce9633e70b5	prediction of water temperature in prawn cultures based on a mechanism model optimized by an improved artificial bee colony		Abstract To reduce aquaculture risk and optimize water quality management in prawn culture ponds, this paper uses mechanistic and statistical analytic methods to propose a hybrid water temperature forecasting model based on the water temperature mechanism model (WTMM) with optimal parameters selected by an improved artificial bee colony (IABC) algorithm. Because of existing problems with using an artificial bee colony algorithm in modeling, an improved ABC with a dynamically adjusted inertia weight based on the fitness function value was implemented to improve local and global search abilities. Then, IABC was employed to adaptively search for the optimal combinatorial parameters needed in the WTMM model, which overcomes the blindness of and limits to parameter selection for the traditional WTMM model. We adopted an IABC-WTMM algorithm to construct a non-linear mechanical prediction model. The IABC-WTMM was tested and compared to other algorithms by applying it to the prediction of water temperature in prawn culture ponds. Experimental results show that the proposed IABC-WTMM could increase prediction accuracy and execute generalization performance better than the original water temperature mechanism model (O-WTMM) and back-propagation neural network (BP-NN), but was inferior to the standard LSSVR model. Overall, it is a suitable and effective method for predicting water temperature in intensive aquacultures.	artificial bee colony algorithm	Longqin Xu;Shuangyin Liu;Daoliang Li	2017	Computers and Electronics in Agriculture	10.1016/j.compag.2017.05.034	engineering;mathematical optimization;control engineering;artificial bee colony algorithm;artificial neural network;effective method;blindness;artificial intelligence;fitness function	AI	11.273612461882307	-17.864248753890852	167254
735ad7d9e861fac100cf218eb1086714d32722e9	a decision-theoretic approach to collaboration: principal description methods and efficient heuristic approximations	universiteitsbibliotheek;decision problem;dynamic environment;approximate solution;decision theoretic;information system;crisis management;compact model	This chapter gives an overview of the state of the art in decision-theoretic models to describe cooperation between multiple agents in a dynamic environment. Making (near-) optimal decisions in such settings gets harder when the number of agents grows or the uncertainty about the environment increases. It is essential to have compact models, because otherwise just representing the decision problem becomes intractable. Several such model descriptions and approximate solution methods, studied in the Interactive Collaborative Information Systems project, are presented and illustrated in the context of crisis management.	approximation algorithm;decision problem;heuristic;information system;theory	Frans A. Oliehoek;Arnoud Visser	2010		10.1007/978-3-642-11688-9_4	simulation;computer science;knowledge management;management science	AI	19.214517038575885	-15.324487701748803	167534
e6edcbae40b513b76d959f4cb5ed0d2c51336870	hard and soft computing techniques for non-linear modeling and control with industrial applications			nonlinear system;soft computing	Majeed Soufian	2002				Robotics	11.989953813803911	-23.15606096422888	167538
397b6beba1efcd69a765412ae842d5f1eb15ffef	a go-flow and dynamic bayesian network combination approach for reliability evaluation with uncertainty: a case study on a nuclear power plant		Uncertainty analyses have been considered critical analysis methods for identifying the risks in reliability evaluations. However, with multi-phase, multi-state, and repairable features, this method cannot effectively and precisely display the reliability evaluation results with uncertainty for dynamic and complex systems. In this paper, uncertainty analysis has been conducted in the evaluation of safety-related risk analysis for a nuclear power plant (NPP). A GO-FLOW and dynamic Bayesian network (DBN) combination approach for the reliability evaluation with uncertainty is proposed in this paper. Based on the unified rules, the various operators can be mapped into the DBN even with the multi-phase, multi-state, and repairable characteristics. As the framework of the DBN, utilizing sensitivity analysis, this approach can provide information on those inputs that are contributing the most to the uncertainty. Next, the DBN algorithm and the Monte Carlo simulation are used to quantify the uncertainty in terms of appropriate estimates for the analysis results. Finally, the auxiliary power supply system of the pressurized water reactor in the NPP is analyzed as an example to illustrate the approach. The results of this paper show that uncertainty analysis makes the reliability evaluation more accurate compared with the results without the uncertainty analysis. Moreover, the GO-FLOW methodology can be applied easily for uncertainty analysis with its modified functions and algorithms.	algorithm;complex systems;dynamic bayesian network;entropic uncertainty;monte carlo method;power supply;reactor (software);reliability engineering;simulation	Yi Ming Ren;Dongming Fan;Xinrui Ma;Zili Wang;Qiang Feng;Dezhen Yang	2018	IEEE Access	10.1109/ACCESS.2017.2775743	distributed computing;computer science;reliability engineering;operator (computer programming);nuclear power plant;econometrics;dynamic bayesian network;uncertainty analysis;monte carlo method;algorithm design;risk analysis (business)	SE	13.12928056076703	-11.897585713223734	167787
4fa3a3f2baf82033ccb322e236bf21925f1a8204	research on data fusion system of fire detection based on neural-network	flaming fire;fires neural networks production chemical processes temperature data engineering chemical products combustion circuits delay;chemical processes;fuzzy neural nets;fuzzy reasoning;neural networks;fire signal data;temperature sensors;intelligent control fire detection neural network fuzzy reasoning data fusion;scattering;heating;data fusion;data engineering;typical smoldering fire;intelligent control;fire data fitting characteristic;simulation experiment;artificial neural networks;fire experiential characteristic;fire detection;chemical products;fuzzy inference system;production;circuits;temperature measurement;sensor fusion;sensor fusion fires fuzzy neural nets fuzzy reasoning;temperature;fires;data fitting;typical smoldering fire data fusion system fire detection neural network fire experiential characteristic fire data fitting characteristic fire signal data fuzzy inference system flaming fire;data fusion system;combustion;neural network	There are some serious problems in traditional fire detection methods and technology, such as lower grade intelligence, high mis-warming rate, delay-warming etc. In this paper, multi-information parameter in the early fire was regarded as early information of fire. This information was trained by neural network technology. Result would be gain with data fusion technology. And the result of data fusion could be confirmed as bases of fire and apply in the fire detection. A 3-layers data fusion structure is used in the neural network. In this fire detecting system, the fire experiential characteristic and the fire data-fitting characteristics of fire signal data are used by the fuzzy inference system to get the last fire probability. Finally simulation experiments are done for typical flaming fire, typical smoldering fire and the fire under typical disturbance signals' in environment. And satisfactory results are obtained.	artificial neural network;curve fitting;experiment;flaming (internet);fuzzy control system;fuzzy logic;inference engine;neural network software;sensor;simulation;total correlation	Yanan Pei;Fangcheng Gan	2009	2009 Pacific-Asia Conference on Circuits, Communications and Systems	10.1109/PACCS.2009.134	simulation;architectural engineering;computer science;engineering;machine learning;sensor fusion;forensic engineering;artificial neural network	Robotics	12.339827547092513	-17.657537546953346	167905
fe4a504cab0cb0e3e5b5f3003d899d62b3c3f695	suspended sediment concentration prediction by geno-kalman filtering	kalman filtering;water resource;gas;mre;suspended sediment concentration;gkf;ce;pkf;mean square;kalman filter;least square method;lsm;transition matrix;lsmkf;discharge;relative error;mae;mississippi river;genetic algorithm;genetic algorithms;regression analysis;prediction;dynamic linear model	More accurate prediction of suspended sediment concentration will likely lead to more economic hydraulic construction and provide a valuable basis for the optimum operation of water resources. The majority of past models have relied on simple regression analysis relating discharge to concentration. A new adaptive prediction approach termed Geno-Kalman filtering (GKF), combining Genetic Algorithm and Kalman filtering techniques is proposed. The model is formed in three steps. Firstly, discharge and suspended sediment concentration are related by using dynamic linear model. Secondly, an optimum transition matrix relating these two state variables is obtained by Genetic Algorithms (GAs), and an optimum Kalman gain is calculated. Thirdly, Kalman filtering is used to predict the suspended sediment concentration from discharge measurement. The proposed method is applied to measurements at the Mississippi River basin in St. Louis, Missouri, and is found to result in smaller absolute, mean square, relative errors compared to perceptron Kalman filtering. Furthermore, Geno-Kalman filtering method outperforms the perceptron Kalman filtering and least square methods in terms of coefficient of efficiency. 2010 Elsevier Ltd. All rights reserved.	coefficient;discharger;estimation theory;genetic algorithm;graphical user interface;kalman filter;linear model;mean squared error;newton's method;numerical analysis;numerical error;perceptron;stochastic matrix	Abdüsselam Altunkaynak	2010	Expert Syst. Appl.	10.1016/j.eswa.2010.06.002	kalman filter;genetic algorithm;computer science;machine learning;control theory;statistics	AI	11.803422669469263	-19.036590959966027	167972
92638bc75aaac21968b18fc56241fe9a5131c405	the pressure control on non-negative pressure water supply based on the fuzzy pid control	automatic control;nonnegative pressure water supply;digital pid control;control systems;hydraulic pressure control;fuzzy pid control;expert systems;probability density function;fuzzy control;pressure control;niobium;adaptive control;programmable control;water supply;data mining;water storage;fuzzy sets;anti jamming;error analysis;accuracy;non negative water supply;three term control;error correction;pid control;anti jamming pressure control nonnegative pressure water supply fuzzy pid control digital pid control;hydraulic pressure control fuzzy control non negative water supply fuzzy pid;pressure control fuzzy control three term control control systems automatic control adaptive control programmable control error correction water storage expert systems;fuzzy pid;water supply fuzzy control pressure control three term control;control method	A new method is emerging in the field of high-rise building in recent years. That is water supply of non-negative pressure. For the reasons of used quantity of water cannot be predicted and non-equilibrium and other reasons, the water pressure is changed notable, it cannot meet the requirements of users by water pressure. The digital PID control is the common control method in the process of manufacture. It has extensive used in the field of machine, metallurgy, chemical etc. But it has shortage in the aspect of control precision and capability of anti-jamming. It has been discussed in this paper that fuzzy PID control use in the process of water supply and it also contrast with the ordinary PID control.	electronic counter-countermeasure;pid;radio jamming;requirement	Ding-lei Wang;Ai-Min Wang	2009	2009 International Joint Conference on Artificial Intelligence	10.1109/JCAI.2009.57	pid controller;niobium;probability density function;error detection and correction;adaptive control;computer science;artificial intelligence;automatic control;control theory;accuracy and precision;fuzzy set;water supply;statistics	Robotics	12.413788135114562	-17.543315718440596	168176
7fb0fad692376dd94f6de5a8435e92d082aa8f09	a historical population in a coevolutionary system	coevolutionary system;evolutionary computation;game theory;adaptive memory;tempo game;tempo;computational intelligence;tempo computational intelligence adaptive memory;continuous learning;history computational intelligence computer science military computing australia counting circuits fuzzy systems humans system testing intelligent systems;adaptive memory historical population coevolutionary system memory population continuous learning winning individual tempo game computational intelligence;memory population;learning artificial intelligence;learning artificial intelligence evolutionary computation game theory;historical population;winning individual	The use of memory in coevolutionary systems is considered an important mechanism to counter the Red Queen effect. Our research involves incorporating a memory population that the coevolving populations compete against to obtain a fitness that is influenced by past generations. This long term fitness then allows the population to have continuous learning that awards individuals that do well against the current populations, as well as previous winning individuals. By allowing continued learning, the individuals in the populations increase their overall ability to play the game of TEMPO, not just to play a single round with the current opposition.	algorithm;categorization;information overload;knowledge base;population;self-replicating machine;sorting	Phillipa M. Avery;Zbigniew Michalewicz;Martin Schmidt	2007	2007 IEEE Symposium on Computational Intelligence and Games	10.1109/CIG.2007.368085	game theory;simulation;computer science;artificial intelligence;machine learning;computational intelligence;adaptive memory;evolutionary computation	Security	17.54990315871656	-17.711011634602887	168238
15ae006a13075205dab3d9da8426e98ebef60f82	neural network modeling of the cellgap process for liquid crystal display fabricated on plastic substrates	d optimal design;error back propagation;neural networks;liquid crystal display;cellgap;latin hypercube sampling;flexible lcd;neural network model;neural network	In this paper, a neural network model is presented to characterize the thickness and the uniformity of the cellgap process for flexible liquid crystal display (LCD). Input factors are explored via a D-optimal design with 15 runs and used as training data in the neural network. In order to verify the fitness of the model, three more runs are added as test data. Latin hypercube sampling and error back-propagation algorithm are used to build the model. Latin hypercube sampling is used to generate initial weights and biases of the network. The thickness of cellgap is measured at five points: one at the center and four at the edges. The average thickness is used as cellgap thickness, and the uniformity is obtained by comparing the thickness at the center and edge points. 2007 Elsevier Ltd. All rights reserved.	algorithm;artificial neural network;backpropagation;circuit complexity;liquid-crystal display;network model;optimal design;sampling (signal processing);semiconductor device fabrication;software propagation;test data;thickness (graph theory)	Jung Hwan Lee;Dong-Hun Kang;Young-Don Ko;Jaejin Jang;Dae-Shik Seo;Ilgu Yun	2008	Expert Syst. Appl.	10.1016/j.eswa.2007.08.027	simulation;latin hypercube sampling;computer science;artificial intelligence;optimal design;backpropagation;machine learning;liquid-crystal display;artificial neural network	AI	13.269561615838398	-20.181886032582327	168460
1536acecd01a31b468eed007e40ef07e859005ca	a systemic computation platform for the modelling and analysis of processes with natural characteristics	novel computation;virtual machine;ucl;programming language;travelling salesman problem;discovery;theses;conference proceedings;computer architecture;bio inspired computation;digital web resources;interactive system;ucl discovery;open access;genetic algorithm;ucl library;book chapters;open access repository;ucl research;systemic computation	Computation in biology and in conventional computer architectures seem to share some features, yet many of their important characteristics are very different. To address this, [1] introduced systemic computation, a model of interacting systems with natural characteristics. Following this work, here we introduce the first platform implementing such computation, including programming language, compiler and virtual machine. To investigate their use we then provide an implementation of a genetic algorithm applied to the travelling salesman problem and also explore how SC enables self-adaptation with the minimum of additional code.	biological computation;biological system;coherence (physics);compiler;complex system;computer architecture;genetic algorithm;interaction;model of computation;parallel computing;programming language;semantics (computer science);travelling salesman problem;virtual machine;von neumann architecture	Erwan Le Martelot;Peter J. Bentley;R. Beau Lotto	2007		10.1145/1274000.1274037	computational science;genetic algorithm;computer science;virtual machine;artificial intelligence;theoretical computer science;machine learning;mathematics;travelling salesman problem	PL	15.542893719518334	-10.383454957369816	168548
43c7b4eed8a10ec748e4149fc1ebdd7b6e561ab1	active forgetting in machine learning and its application to financial problems	machine learning investments portfolios mathematics pattern classification mathematical programming radial basis function networks potential well testing;investment;machine learning;pattern classification;learning artificial intelligence;stock portfolio problems financial investment problems machine learning forgetting active forgetting;investment learning artificial intelligence	One of main features in financial investment problems is that the situation changes very often over time. Under this circumstance, in particular, it has been observed that additional learning plays an effective role. However, since the rule for classification becomes more and more complex with only additional learning, some appropriate forgetting is also necessary. It seems natural that many data are forgotten as the time elapses. On the other hand, it is expected more effective to forget unnecessary data actively. In this paper, several methods for active forgetting are suggested. The effectiveness of active forgetting is shown by examples in stock portfolio problems.	machine learning	Hirotaka Nakayama;Kengo Yoshii	2000		10.1109/IJCNN.2000.861445	error-driven learning;investment;computer science;artificial intelligence;online machine learning;machine learning;active learning;hyper-heuristic	ML	16.827468600043904	-20.840554742981887	168614
a9c348941a677f3ee8869f25138679b3b54270c9	a sequential perspective on searching for static targets	or in military;sequential analysis;applied probability;applied probability or in military sequential analysis	0377-2217/$ see front matter Published by Elsevier doi:10.1016/j.ejor.2011.05.045 ⇑ Corresponding author. Tel.: +1 831 656 3311. E-mail addresses: kurt.e.wilson@afghan.swa. rszechtm@nps.edu (R. Szechtman), mpatkins@nps.edu We present a sequential approach to detect static targets with imperfect sensors, which range from tower-mounted cameras to satellites. The scenario is operationally relevant to many military, homeland security, search and rescue, environmental engineering, counter-narcotics, and law enforcement applications. The idea is to stop the search as soon as there is enough probabilistic evidence about the targets’ locations, given an operator-prescribed error tolerance, knowledge of the sensors’ parameters, and a sequence of detection signals from the sensors. By stopping the search as soon as possible, we promote efficiency by freeing up sensors and operators to perform other tasks. The model we develop has the added benefits of decreasing operator workload and providing negative information as a search progresses. Published by Elsevier B.V.	error-tolerant design;like button;quantum information;sensor	Kurt E. Wilson;Roberto Szechtman;Michael P. Atkinson	2011	European Journal of Operational Research	10.1016/j.ejor.2011.05.045	simulation;sequential analysis;data mining;mathematics;applied probability;computer security;statistics	ML	17.75414731651461	-14.044332196100866	168710
83a4e55e1dec71382e741e14ff13ee85a18031e7	bayesian multi-task reinforcement learning	reinforcement learning	We consider the problem of multi-task reinforcement learni ng where the learner is provided with a set of tasks, for which only a small number o f samples can be generated for any given policy. As the number of samples may n ot be enough to learn an accurate evaluation of the policy, it would be neces sary to identify classes of tasks with similar structure and to learn them jointly. We consider the case where the tasks share structure in their value functions, an d model this by assuming that the value functions are all sampled from a common pri or. We adopt the Gaussian process temporal-difference value function mode l and use a hierarchical Bayesian approach to model the distribution over the value f unctions. We study two cases, where all the value functions belong to the same cl ass and where they belong to an undefined number of classes. For each case, we pre sent a hierarchical Bayesian model, and derive inference algorithms for (i) joint learning of the value functions, and (ii) efficient transfer of the informat ion gained in (i) to assist learning the value function of a newly observed task.	algorithm;bayesian network;bellman equation;computer multitasking;gaussian process;reinforcement learning;undefined behavior	Alessandro Lazaric;Mohammad Ghavamzadeh	2010			computer science;artificial intelligence;machine learning;pattern recognition;mathematics;reinforcement learning;q-learning	ML	22.225054160755153	-18.899735838793802	168775
c4da522a1211aeb2e7a49dfe12b2f1d516508399	confidence based quality evaluation for total manufacturing process using comprehensive process capability	machining;uncertainty;会议论文;inspection;confidence interval confidence based quality evaluation manufacturing process comprehensive process capability multivariate process capability comprehensive evaluation approach quality characteristics procurement process machining process assembling process delivery inspection process test process feedback process correction process structure equation model sem;indexes manufacturing processes mathematical model uncertainty inspection machining;indexes;manufacturing processes;mathematical model;statistical analysis assembling inspection machining process capability analysis procurement quality control;confidence interval manufacturing process quality evaluation uncertainty sem	In view of the uncertainty in the quality evaluation for manufacturing process and multivariate process capability, a comprehensive evaluation approach is proposed by extending classic process capability index with considering variations of key quality characteristics among the whole manufacturing process, which includes the procurement, machining, assembling and delivery inspection processes. Meanwhile, to avoid the influence of uncertainties, the test, feedback and correction processes for the evaluation approach are added based on the Structure Equation Model (SEM). Then, after the evaluation result is calculated according to the evaluation approach, a method to monitor the deviations of the evaluation results is introduced based on the confidence interval. At last, the quality level of total manufacturing process is evaluated by combing the evaluation results and their confidence interval. Finally, a case study is carried out to verify the proposed method.	monte carlo method;procurement;simulation;trusted computer system evaluation criteria	Kongjun Gao;Yihai He;Linbo Wang	2015	2015 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)	10.1109/IEEM.2015.7385875	reliability engineering;database index;process performance index;process capability;uncertainty;inspection;machining;process capability index;engineering;operations management;mathematical model;mathematics;statistics;manufacturing engineering	Robotics	14.117453568577695	-12.470926389717318	168813
c6f9799bedf9f661cc2f9ff1bfe05b053f6d3c32	data mining for the chemical process industry	data mining	Advancements in sensors and database technologies have resulted in the collection of huge amounts of process data from chemical plants. A number of process quantities such as temperature, pressure, flow rates, level, composition, and pH can be easily measured. Chemical processes are dynamic systems and are equipped with hundreds or thousands of sensors that generate readings at regular intervals (typically seconds). In addition, derived quantities that are functions of the sensor measurements as well as alerts and alarms are generated regularly. Several commercial data warehouses, referred to as plant historians in chemical plants, such as the DeltaV Continuous Historian (from Emerson Process Management), InfoPlus.21TM (from AspenTech), Uniformance® PHD (from Honeywell), and Industrial SQL (from Wonderware) are in common use today around the world. These historians store large amount (weeks) of historical process operation data at their original resolution and an almost limitless amount (years) in compressed form. This data is available for mining, analysis and decision support – both real-time and offline. Process measurements can be classified based on their nature as binary (on/off) or continuous. However, both are stored in discrete form in the historians. Measurements can also be classified based on their role during operation as controlled, manipulated, and non-control related variables. Controlled variables are directly or indirectly related to the plant’s quality, production, or safety objectives and are maintained at specified setpoints, even in the face of disturbances, by analog or digital controllers. This regulation is achieved by altering manipulated variables such as flow-rates. Chemical plants are typically well-integrated – a change in one variable would propagate across many others. Non-control related variables do not have any role in plant control, but provide information to plant personnel regarding the state of the process. In general, a plant can operate in a number of states which can be broadly classified into steady-states and transitions (Srinivasan et al., 2005b). Large scale plants such as refineries typically run for long periods in steady-states but undergo transition if there is a change in feedstock or product grades. Transitions also result due to large process disturbances, maintenance activities, and abnormal events. During steady-states, the process variables vary within a narrow range. In contrast, transitions correspond to large changes / discontinuities in the plant operations; i.e., change of set points, turning on or idling of equipments, valve manipulations, etc. A number of decisions are needed on the part of the plant personnel to keep the plant running safely and efficiently during steady states as well as transitions. Data mining and analysis tools that facilitate humans to uncover information, knowledge, patterns, trends, and relationships from the historical data are therefore crucial.	analog signal;binary file;data mining;database;decision support system;dynamical system;online and offline;ph (complexity);physical plant;real-time clock;sql;sensor;steady state	Yew Seng Ng;Rajagopalan Srinivasan	2009			engineering;industrial engineering;process engineering;biochemical engineering	AI	12.205316332006499	-14.942821291951162	168891
34891ff0df7b392afd1b392b1b8704a8c6a274a1	optimizing two-sequence functionals in competitive analysis		The efficiency of an on-line motion planning strategy often is measured by a constant competitive factor C. Competitivity means that the cost of a C-competitive on-line strategy with incomplete information is only C times worse than the optimal offline solution under full information. If a strategy is represented by an infinite sequence X=f 1,f 2,… of steps or values, the problem of finding a strategy with minimal C often results in minimizing functionals F k in X. For example $F_{k}(f_{1},f_{2},\ldots):=\frac{\sum_{i=1}^{k+1}f_{i}}{f_{k}}$ represents a functional for the 2-ray search problem. There are two main paradigms for finding an optimal sequence f 1,f 2,… that minimizes F k for all k. Namely, optimality of the exponential function and equality approach. If the strategy has to be defined by more than one interacting sequence both approaches may fail. In this paper we show that for such more sophisticated situations a combination of the paradigms is a good choice. As an example we consider an extension of the 2-ray search problem that can be formalized by two sequences.	competitive analysis (online algorithm);interaction;iteration;motion planning;online and offline;optimizing compiler;search problem;time complexity	Elmar Langetepe	2011	Computer Science - Research and Development	10.1007/s00450-011-0151-7	mathematical optimization;algorithm	AI	19.20178759789711	-10.979927701714026	168917
699d3449b82a635d4fbdf3b0946d31b4d78f0cea	learning to factor policies and action-value functions: factored action space representations for deep reinforcement learning		Deep Reinforcement Learning (DRL) methods have performed well in an increasing numbering of high-dimensional visual decision making domains. Among all such visual decision making problems, those with discrete action spaces often tend to have underlying compositional structure in the said action space. Such action spaces often contain actions such as go left, go up as well as go diagonally up and left (which is a composition of the former two actions). The representations of control policies in such domains have traditionally been modeled without exploiting this inherent compositional structure in the action spaces. We propose a new learning paradigm, Factored Action space Representations (FAR) wherein we decompose a control policy learned using a Deep Reinforcement Learning Algorithm into independent components, analogous to decomposing a vector in terms of some orthogonal basis vectors. This architectural modification of the control policy representation allows the agent to learn about multiple actions simultaneously, while executing only one of them. We demonstrate that FAR yields considerable improvements on top of two DRL algorithms in Atari 2600: FARA3C outperforms A3C (Asynchronous Advantage Actor Critic) in 9 out of 14 tasks and FARAQL outperforms AQL (Asynchronous n-step Q-Learning) in 9 out of 13 tasks.	algorithm;algorithmic learning theory;atari;basis (linear algebra);driven right leg circuit;programming paradigm;q-learning;reinforcement learning	Sahil Sharma;Aravind Suresh;Rahul Ramesh;Balaraman Ravindran	2017	CoRR		error-driven learning;artificial intelligence;machine learning;pattern recognition;mathematics;action learning	AI	19.20893960690762	-21.45044311967431	169517
4dad31c570bc437078949863f93e7eb41614a6d0	generating diverse opponents with multiobjective evolution	genetic program;evolutionary computation;believable agents;sensors;probability density function;pareto front;computational intelligence;game play learning;data mining;multiobjective evolutionary algorithm;qa75 electronic computers computer science;multi agent systems computer games evolutionary computation learning artificial intelligence;multi agent systems;artificial intelligence computational intelligence collaboration automatic control evolutionary computation humans genetics length measurement time measurement testing;nonplayer character;non player character;games;diverse opponent generation;game play learning diverse opponent generation multiobjective evolutionary algorithm computational intelligence ai game agent nonplayer character;reinforcement learn ing;driver circuits;artificial intelligence;humans;learning artificial intelligence;ai game agent;computer games;computer game	For computational intelligence to be useful in creating game agent AI, we need to focus on creating interesting and believable agents rather than just learn to play the games well. To this end, we propose a way to use multiobjective evolutionary algorithms to automatically create populations of non-player characters (NPCs), such as opponents and collaborators, that are interestingly diverse in behaviour space. Experiments are presented where a number of partially conflicting objectives are defined for racing game competitors, and multiobjective evolution of Genetic Programming-based controllers yield pareto fronts of interesting controllers.	artificial neural network;computational intelligence;evolutionary algorithm;experiment;genetic programming;inscriptiones graecae;interaction;pareto efficiency;population	Alexandros Agapitos;Julian Togelius;Simon M. Lucas;Jürgen Schmidhuber;Andreas Konstantinidis	2008	2008 IEEE Symposium On Computational Intelligence and Games	10.1109/CIG.2008.5035632	games;probability density function;simulation;computer science;sensor;artificial intelligence;multi-objective optimization;machine learning;computational intelligence;evolutionary computation	AI	17.71316535374918	-17.700750107214926	169579
5ca8d9fefbe84af9a3a3c47ea32ec82334be3c77	a computational theory of adaptive behavior based on an evolutionary reinforcement mechanism	computability theory;reinforcement learning;adaptive agents;credit assignment;adaptive behavior;associative learning;response to selection;rescorla wagner rule;delay reduction theory;evolutionary algorithms;evolutionary algorithm;matching theory;stimulus control;conditioned reinforcement;equilibrium theory	Two mathematical and two computational theories from the field of human and animal learning are combined to produce a more general theory of adaptive behavior. The cornerstone of this theory is an evolutionary algorithm for reinforcement learning that instantiates the idea that behavior evolves in response to selection pressure from the environment in the form of reinforcement. The evolutionary reinforcement algorithm, along with its associated equilibrium theory, are combined with a mathematical theory of conditioned reinforcement and a computational theory of associative learning that together solve the problem of credit assignment in a biologically plausible way. The result is a biologically-inspired computational theory that enables an artificial organism to adapt continuously to changing environmental conditions and to generate adaptive state-action sequences.	adaptive behavior;artificial life;emoticon;evolutionary algorithm;experiment;reinforcement learning;schedule (computer science);steady state;theory of computation;usability testing	J. J. McDowell;Paul L. Soto;Jesse Dallery;Saule Kulubekova	2006		10.1145/1143997.1144028	mathematical optimization;algorithmic learning theory;computability theory;computer science;artificial intelligence;adaptive behavior;stimulus control;machine learning;evolutionary algorithm;mathematics;learning classifier system;computational learning theory;reinforcement learning	ML	17.54106261610747	-18.397831852494665	169880
2f789917e9deeab518b69c862c1938df24153e1c	sensitivity analysis for complex ecological models - a new approach	bottom up;recursive partitioning;regression tree;lake kinneret;model calibration;model analysis;data collection;dynamic model;global sensitivity analysis;aquatic ecosystem;ecosystem model;machine learning;sensitivity analysis;reservoir simulation;ecological model;general linear model;organic material;global sensitivity;dyresm caedym	A strategy for global sensitivity analysis of a multi-parameter ecological model was developed and used for the hydrodynamic-ecological model (DYRESMeCAEDYM, DYnamic REservoir Simulation ModelComputational Aquatic Ecosystem Dynamics Model) applied to Lake Kinneret (Israel). Two different methods of sensitivity analysis, RPART (Recursive Partitioning And Regression Trees) and GLM (General Linear Model) were applied in order to screen a subset of significant parameters. All the parameters which were found significant by at least one of these methods were entered as input to a GBM (Generalized Boosted Modeling) analysis in order to provide a quantitative measure of the sensitivity of the model variables to these parameters. Although the GBM is a general and powerful machine learning algorithm, it has substantial computational costs in both storage requirements and CPU time. Employing the screening stage reduces this cost. The results of the analysis highlighted the role of particulate organic material in the lake ecosystem and its impact on the over all lake nutrient budget. The GBM analysis established, for example, that parameters such as particulate organic material diameter and density were particularly important to the model outcomes. The results were further explored by lumping together output variables that are associated with sub-components of the ecosystem. The variable lumping approach suggested that the phytoplankton group is most sensitive to parameters associated with the dominant phytoplankton group, dinoflagellates, and with nanoplankton (Chlorophyta), supporting the view of Lake Kinneret as a bottomeup system. The study demonstrates the effectiveness of such procedures for extracting useful information for model calibration and guiding further data collection. 2010 Elsevier Ltd. All rights reserved.	algorithm;aquatic ecosystem;central processing unit;ecosystem model;general linear model;generalized linear model;lumpers and splitters;machine learning;mesa;recursion (computer science);requirement;simulation	Vardit Makler-Pick;Gideon Gal;Malka Gorfine;Matthew R. Hipsey;Yohay Carmel	2011	Environmental Modelling and Software	10.1016/j.envsoft.2010.06.010	biology;ecosystem model;environmental engineering;organic matter;hydrology;computer science;machine learning;decision tree;top-down and bottom-up design;aquatic ecosystem;ecology;sensitivity analysis;statistics;social ecological model;general linear model;recursive partitioning;data collection	AI	16.536951121694013	-15.439012270491647	170018
e4546ab6dda0ae93b7598272e3f70184166aff2e	surface roughness prediction in machining using soft computing	machining;genetic program;computational intelligence;soft computing;surface roughness;surface texture;fuzzy logic;process monitoring;membership function;average roughness;end milling;genetic algorithm;adaptive neuro fuzzy inference system;artificial neural network	A study is presented to model surface roughness in end milling using adaptive neuro-fuzzy inference system (ANFIS) and genetic algorithms (GAs). The machining parameters, namely, the spindle speed, feed rate, depth of cut and the workpiece-tool vibration amplitude have been used as inputs to model the workpiece surface roughness. The number and the parameters of membership functions used in ANFIS along with the most suitable inputs are selected using GAs maximising the modelling accuracy. The ANFIS with GAs (GA-ANFIS) are trained with a subset of the experimental data. The trained GA-ANFIS are tested using the set of validation data. The procedure is illustrated using the experimental data of a CNC vertical machining centre in end-milling of 6061 aluminum. Results are compared with other soft computing techniques like genetic programming (GP) and artificial neural network (ANN). The results show the effectiveness of the proposed approach in modelling the surface roughness.	soft computing	B. Samanta	2009	Int. J. Computer Integrated Manufacturing	10.1080/09511920802287138	fuzzy logic;surface finish;genetic algorithm;membership function;surface roughness;machining;adaptive neuro fuzzy inference system;computer science;engineering;artificial intelligence;machine learning;computational intelligence;soft computing;engineering drawing;artificial neural network	Robotics	12.823659354863574	-19.799322191966457	170076
593ee4c9fad06d817ad7a0ed2d677c911c5d83fe	on the performance of deterministic sampling in probabilistic roadmap planning		Probabilistic Roadmap approaches (PRMs) have been successfully applied in motion planning of robots with many degrees of freedom. In recent years, the community has proposed deterministic sampling as a way to improve the performance in these planners. However, our recent results show that the choice of the sampling source - pseudo-random or deterministic- has small impact on a PRM planner's performance. We used two single-query PRM planners for this comparative study. The advantage of the deterministic sampling on the pseudorandom sampling is only observable in low dimension problems. The results were surprising in the sense that deterministic sampling performed differently than claimed by the designers.	probabilistic roadmap	Abraham Sánchez López;G. Juarez RobertoJuarez;María Auxilio Osorio Lama	2007		10.1007/978-3-540-76631-5_104	mathematical optimization;simulation;computer science	Robotics	23.80687289544087	-18.158143346291933	170146
fc75667c40ce1620ad0b3b83905ae3b71365cb0b	on using discretized cohen-grossberg node dynamics for model-free actor-critic neural learning in non-markovian domains	neural model;neural nets;neuro dynamic programming;reinforcement learning;markov property;neural networks learning recurrent neural networks history dynamic programming neurons signal processing computer science computer networks state space methods;decision problem;decision making neural nets learning artificial intelligence markov processes;markov processes;learning artificial intelligence;optimal sequence of action discretized cohen grossberg node dynamics model free actor critic neural learning nonmarkovian domains neural networks small scale nonmarkovian deterministic path problem;neural network	We describe how multi-stage non-Markovian decision problems can be solved using actor-critic reinforcement learning by assuming that a discrete version of CohenGrossberg node dynamics describes the node-activation computations of a neural network (NN). Our NN (i.e., agent) is capable of rendering the process Markovian implicitly and automatically in a totally model-free fashion without learning by how much the state space must be augmented so that the Markov property holds. This serves as an alternative to using Elman or Jordantype recurrent neural networks, whose context units function as a history memory in order to develop sensitivity to non-Markovian dependencies. We shall demonstrate our concept using a small-scale non-Markovian deterministic path problem, in which our actor-critic NN finds an optimal sequence of actions (but learns neither transitional dynamics nor associated rewards), although it needs many iterations due to the nature of neural model-free learning. This is, in spirit, a neurodynamic programming approach.	artificial neural network;computation;decision problem;discretization;iteration;markov chain;markov property;recurrent neural network;reinforcement learning;state space	Eiji Mizutani;Stuart E. Dreyfus	2003		10.1109/CIRA.2003.1222053	feedforward neural network;types of artificial neural networks;markov property;computer science;artificial intelligence;recurrent neural network;theoretical computer science;machine learning;decision problem;time delay neural network;deep learning;markov process;competitive learning;artificial neural network;q-learning	ML	19.14762989436361	-23.82130747850886	170182
2b404cade9833135c62832e0c9ebd2495259b840	biological engineering applications of feedforward neural networks designed and parameterized by genetic algorithms	feedforward neural network;training parameterization;evolutionary computation;neural networks;learning;detection panne;activation function;search space;automatic neural network design;failure detection;parameterization;calcul evolutionniste;biology;biologia;algoritmo genetico;parametrizacion;biological engineering;aprendizaje;network topology;apprentissage;a priori knowledge;reseau neuronal non boucle;backpropagation algorithm;fault detection;algorithme genetique;genetic algorithm;genetic algorithms;feedforward neural nets;network architecture;prediction model;evolutionary process;deteccion falla;parametrisation;biologie;neural network	Two neural network (NN) applications in the field of biological engineering are developed, designed and parameterized by an evolutionary method based on the evolutionary process of genetic algorithms. The developed systems are a fault detection NN model and a predictive modeling NN system. An indirect or 'weak specification' representation was used for the encoding of NN topologies and training parameters into genes of the genetic algorithm (GA). Some a priori knowledge of the demands in network topology for specific application cases is required by this approach, so that the infinite search space of the problem is limited to some reasonable degree. Both one-hidden-layer and two-hidden-layer network architectures were explored by the GA. Except for the network architecture, each gene of the GA also encoded the type of activation functions in both hidden and output nodes of the NN and the type of minimization algorithm that was used by the backpropagation algorithm for the training of the NN. Both models achieved satisfactory performance, while the GA system proved to be a powerful tool that can successfully replace the problematic trial-and-error approach that is usually used for these tasks.	activation function;anatomy, regional;architecture as topic;artificial neural network;backpropagation;bart selman;bioengineering;biological science disciplines;cns disorder;computer science;crossover (genetic algorithm);environmental illness;fault detection and isolation;feedforward neural network;genetic algorithm;heuristic;heuristics;iterative and incremental development;mathematical model;mathematical optimization;maxima and minima;mutation (genetic algorithm);network architecture;network planning and design;network topology;neural network simulation;predictive modelling;principle of good enough;probability;software release life cycle;specification;tnfsf13b wt allele;user experience	Konstantinos P. Ferentinos	2005	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2005.03.010	genetic algorithm;computer science;artificial intelligence;machine learning;artificial neural network;algorithm	ML	15.622688885202408	-23.778201166830787	170280
a93128778c731f21c2193695bfc0e6bccb45f1bc	predicting moisture content of agricultural products using artificial neural networks	agricultural production;bean;moisture content;fluidized bed drying;artificial intelligent;mean absolute error;fluidized bed;artificial neural networks ann;relative error;back propagation algorithm;hazelnut;chickpea;artificial neural network	Drying of agricultural products is a significant process to store and use them for various purposes. There are few drying methods in agricultural industry, among them fluidized bed drying is widely employed due to its several advantages over the other methods. The prediction of drying characteristics with a small number of experiments is rather efficient since because of the fact that the drying experiments is time consuming and requires tedious work for a single agricultural product. Therefore, several methods such as deterministic, stochastic, artificial intelligence have been developed in order to predict the drying characteristics based on the experimental data obtained from the lab-scale fluidized bed drying system. In this paper, the artificial neural networks (ANN) method was used to predict the drying characteristics of agricultural products such as hazelnut, bean and chickpea. The ANN was trained using experimental data for three different products through the back propagation algorithm containing double input and single output parameters. The results showed fairly good agreement between predicted results by using ANN and the measured data taken under the same modeling conditions. The mean relative error (MRE) and mean absolute error (MAE) obtained when unknown data were applied to the networks was 3.92 and 0.033, respectively, which is very satisfactory.	artificial neural network	Adnan Topuz	2010	Advances in Engineering Software	10.1016/j.advengsoft.2009.10.003	approximation error;environmental engineering;water content;computer science;engineering;machine learning;fluidized bed;agricultural productivity;waste management;artificial neural network;mean absolute error	ML	11.722955111055034	-19.73582271073882	170340
1f08598381af9146d0fd9a61b30d0e51a7331689	distributed prioritized experience replay		We propose a distributed architecture for deep reinforcement learning at scale, that enables agents to learn effectively from orders of magnitude more data than previously possible. The algorithm decouples acting from learning: the actors interact with their own instances of the environment by selecting actions according to a shared neural network, and accumulate the resulting experience in a shared experience replay memory; the learner replays samples of experience and updates the neural network. The architecture relies on prioritized experience replay to focus only on the most significant data generated by the actors. Our architecture substantially improves the state of the art on the Arcade Learning Environment, achieving better final performance in a fraction of the wall-clock training time.		Dan Horgan;John Quan;David Budden;Gabriel Barth-Maron;Matteo Hessel;Hado van Hasselt;David Silver	2018	CoRR		fold (higher-order function);artificial intelligence;machine learning;computer science;architecture;deep learning;artificial neural network;reinforcement learning;learning environment	ML	20.17142514817404	-21.834111208589032	170518
45afb6878467d4ca8a4c2aafeee1a7cbc4ed10e5	artificial neural network application for modeling the rail rolling process	rail rolling;hot rolling;artificial neural network	Rail rolling process is one of the most complicated hot rolling processes. Evaluating the effects of parametric values on this complex process is only possible through modeling. In this study, the production parameters of different types of rails in the rail rolling processes were modeled with an artificial neural network (ANN), and it was aimed to obtain optimum parameter values for a different type of rail. For this purpose, the data from the Rail and Profile Rolling Mill in Kardemir Iron & Steel Works Co. (Karabuk, Turkey) were used. BD1, BD2, and Tandem are three main parts of the rolling mill, and in order to obtain the force values of the 49kg/m rail in each pass for the BD1 and BD2 sections, the force and torque values for the Tandem section, parameter values of 60, 54, 46, and 33kg/m type rails were used. Comparing the results obtained from the ANN model and the actual field data demonstrated that force and torque values were obtained with acceptable error rates. The results of the present study demonstrated that ANN is an effective and reliable method to acquire data required for producing a new rail, and concerning the rail production process, it provides a productive way for accurate and fast decision making.	artificial neural network	Hüseyin Altinkaya;Ilhami M. Orak;Ismail Esen	2014	Expert Syst. Appl.	10.1016/j.eswa.2014.06.014	computer science;machine learning;artificial neural network	ML	13.027697611878429	-18.953815841576358	170835
a287e6671824e1853ad0dc3261961328b09bfdf2	estimation of parameters for the free-form machining with deep neural network		Predictive Analytics is a crucial part of a Big Data application. Lately, developers have turned their attention to deep learning models due to their huge success in various implementations. Meanwhile, there is lack of deep learning implementations in manufacturing applications due to insufficient data. This phenomenon has been slowly shifting due to the application of IoT and Industry 4.0 concept within the manufacturing industry. Streaming and batch data producing sources are becoming more and more common in the machining industry. In this paper, we propose a deep learning predictive analytics model based on the data generated by a particular machining process. The results indicate that using such a model can make very accurate predictions and can be used as part of a real-time decision-making process in the manufacturing industry. In this study, the prediction models of three crucial metrics of machining such as quality, performance and energy consumption have been developed by utilizing artificial neural networks and deep learning methods. Specific measures of quality, performance and energy consumption refer to material removal rate (MRR), surface roughness (Ra) and specific energy consumption (SEC) respectively. The control parameters of machining are selected as stepover (ae), depth of cut (ap), feed per tooth (fz) and cutting speed (Vc). In addition, variance analysis (ANOVA) has been used to examine the effects of the input parameters on the output parameters.	artificial neural network;big data;deep learning;industry 4.0;real-time clock;real-time computing;software analytics;streaming media	Gokberk Serin;M. Ugur Gudelek;Ahmet Murat Ozbayoglu;Hakki Özgür Ünver	2017	2017 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2017.8258158	artificial intelligence;machining;specific energy;artificial neural network;reliability engineering;predictive analytics;machine learning;big data;deep learning;computer science;machine tool;phenomenon	Robotics	13.432822254485941	-18.90593180154163	170904
939f303aa92c78f43e411c6b392856ef9b331939	heuristically accelerated reinforcement learning: theoretical and experimental results		Since finding control policies using Reinforcement Learning (RL) can be very time consuming, in recent years several authors have investigated how to speed up RL algorithms by making improved action selections based on heuristics. In this work we present new theoretical results – convergence and a superior limit for value estimation errors – for the class that encompasses all heuristicsbased algorithms, called Heuristically Accelerated Reinforcement Learning. We also expand this new class by proposing three new algorithms, the Heuristically Accelerated Q(λ), SARSA(λ) and TD(λ), the first algorithms that uses both heuristics and eligibility traces. Empirical evaluations were conducted in traditional control problems and results show that using heuristics significantly enhances the performance of the learning process.	algorithm;bellman equation;heuristic (computer science);mountain car;reinforcement learning;tracing (software)	Reinaldo A. C. Bianchi;Carlos H. C. Ribeiro;Anna Helena Reali Costa	2012		10.3233/978-1-61499-098-7-169	mathematical optimization;computer science;artificial intelligence;machine learning	ML	24.304342734743184	-15.229700043711913	171332
8de28da515a54506b33050754e59b1666816fd00	using robust generalized fuzzy modeling and enhanced symbolic regression to model tribological systems		Abstract Tribological systems are mechanical systems that rely on friction to transmit forces. The design and dimensioning of such systems requires prediction of various characteristic, such as the coefficient of friction. The core contribution of this paper is the analysis of two data-based modeling techniques which can be used to produce accurate and at the same time interpretable models for friction systems. We focus on two methods for building interpretable and potentially non-linear regression models: (i) robust fuzzy modeling with batch processing and an enhanced regularized learning scheme, and (ii) enhanced symbolic regression using genetic programming. We compare our results of both methods with state-of-the-art methods and found that linear models are insufficient for predicting the coefficient of friction, temperature, wear, and noise-vibration-harshness rating of the tribological systems, while the proposed robust fuzzy modeling and the enhanced symbolic regression approaches, as well as the state-of-the-art regression techniques, are able to generate satisfactory models. However, robust fuzzy modeling and enhanced symbolic regression lead to simpler models with fewer parameters that can be interpreted by domain experts.	symbolic regression	Gabriel Kronberger;Michael Kommenda;Edwin Lughofer;Susanne Saminger-Platz;Andreas Promberger;Falk Nickel;Stephan M. Winkler;Michael Affenzeller	2018	Appl. Soft Comput.	10.1016/j.asoc.2018.04.048	linear model;symbolic regression;regression analysis;mathematical optimization;machine learning;mathematics;fuzzy logic;artificial intelligence;batch processing;genetic programming;dimensioning	Logic	12.49264224154208	-18.793650943183707	171610
3b0f4bb63048b0a9f4bdcd3e037e1ddfd50a6b7d	safe and efficient off-policy reinforcement learning		In this work, we take a fresh look at some old and new algorithms for off-policy, return-based reinforcement learning. Expressing these in a common form, we derive a novel algorithm, Retrace(λ), with three desired properties: (1) it has low variance; (2) it safely uses samples collected from any behaviour policy, whatever its degree of “off-policyness”; and (3) it is efficient as it makes the best use of samples collected from near on-policy behaviour policies. We analyze the contractive nature of the related operator under both off-policy policy evaluation and control settings and derive online sample-based algorithms. We believe this is the first return-based off-policy control algorithm converging a.s. to Q∗ without the GLIE assumption (Greedy in the Limit with Infinite Exploration). As a corollary, we prove the convergence of Watkins’ Q(λ), which was an open problem since 1989. We illustrate the benefits of Retrace(λ) on a standard suite of Atari 2600 games. One fundamental trade-off in reinforcement learning lies in the definition of the update target: should one estimate Monte Carlo returns or bootstrap from an existing Q-function? Return-based methods (where return refers to the sum of discounted rewards � t γ rt) offer some advantages over value bootstrap methods: they are better behaved when combined with function approximation, and quickly propagate the fruits of exploration (Sutton, 1996). On the other hand, value bootstrap methods are more readily applied to off-policy data, a common use case. In this paper we show that learning from returns need not be at cross-purposes with off-policy learning. We start from the recent work of Harutyunyan et al. (2016), who show that naive off-policy policy evaluation, without correcting for the “off-policyness” of a trajectory, still converges to the desired Q value function provided the behavior μ and target π policies are not too far apart (the maximum allowed distance depends on the λ parameter). Their Q(λ) algorithm learns from trajectories generated by μ simply by summing discounted off-policy corrected rewards at each time step. Unfortunately, the assumption that μ and π are close is restrictive, as well as difficult to uphold in the control case, where the target policy is greedy with respect to the current Q-function. In that sense this algorithm is not safe: it does not handle the case of arbitrary “off-policyness”. Alternatively, the Tree-backup (TB(λ)) algorithm (Precup et al., 2000) tolerates arbitrary target/behavior discrepancies by scaling information (here called traces) from future temporal differences by the product of target policy probabilities. TB(λ) is not efficient in the “near on-policy” case (similar μ and π), though, as traces may be cut prematurely, blocking learning from full returns. In this work, we express several off-policy, return-based algorithms in a common form. From this we derive an improved algorithm, Retrace(λ), which is both safe and efficient, enjoying convergence guarantees for off-policy policy evaluation and – more importantly – for the control setting. 30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain. Retrace(λ) can learn from full returns retrieved from past policy data, as in the context of experience replay (Lin, 1993), which has returned to favour with advances in deep reinforcement learning (Mnih et al., 2015; Schaul et al., 2016). Off-policy learning is also desirable for exploration, since it allows the agent to deviate from the target policy currently under evaluation. To the best of our knowledge, this is the first online return-based off-policy control algorithm which does not require the GLIE (Greedy in the Limit with Infinite Exploration) assumption (Singh et al., 2000). In addition, we provide as a corollary the first proof of convergence of Watkins’ Q(λ) (see, e.g., Watkins, 1989; Sutton and Barto, 1998). Finally, we illustrate the significance of Retrace(λ) in a deep learning setting by applying it to the suite of Atari 2600 games provided by the Arcade Learning Environment (Bellemare et al., 2013).	andrew barto;approximation;arcade game;atari;backup;bellman equation;blocking (computing);deep learning;greedy algorithm;image scaling;information processing;monte carlo method;nips;reinforcement learning;resampling (statistics);tracing (software);word lists by frequency	Rémi Munos;Tom Stepleton;Anna Harutyunyan;Marc G. Bellemare	2016			simulation;computer science;artificial intelligence;machine learning;mathematics;algorithm;statistics	ML	22.662002165694272	-19.078308417901567	171896
8a56db96244162ed42860d32d421d5fb9dba8d53	solving multiple instances at once: the role of search and adaptation	learning process;multiple instance	Having in mind the idea that the computational effort and knowledge gained while solving a problem’s instance should be used to solve other ones, we present a new strategy that allows to take advantage of both aspects. The strategy is based on a set of operators and a basic learning process that is fed up with the information obtained while solving several instances. The output of the learning process is an adjustment of the operators. The instances can be managed sequentially or simultaneously by the strategy, thus varying the information available for the learning process. The method has been tested on different SAT instance classes and the results confirm that (a) the usefulness of the learning process and (b) that embedding problem specific algorithms into our strategy, instances can be solved faster than applying these algorithms instance by instance.		Antonio D. Masegosa;David A. Pelta;Juan Ramón González	2011	Soft Comput.	10.1007/s00500-010-0564-4	instance-based learning;mathematical optimization;computer science;artificial intelligence;machine learning;mathematics	NLP	17.040970781830488	-20.57121170827496	171916
7b581c9ce200b031451f592478c7c34b5fc47898	task-based end-to-end model learning in stochastic optimization		With the increasing popularity of machine learning techniques, it has become common to see prediction algorithms operating within some larger process. However, the criteria by which we train these algorithms often differ from the ultimate criteria on which we evaluate them. This paper proposes an end-to-end approach for learning probabilistic machine learning models in a manner that directly captures the ultimate task-based objective for which they will be used, within the context of stochastic programming. We present three experimental evaluations of the proposed approach: a classical inventory stock problem, a real-world electrical grid scheduling task, and a real-world energy storage arbitrage task. We show that the proposed approach can outperform both traditional modeling and purely black-box policy optimization approaches in these applications.	algorithm;black box;end-to-end principle;experiment;machine learning;mathematical optimization;reinforcement learning;scheduling (computing);stochastic optimization;stochastic process;stochastic programming	Priya L. Donti;J. Zico Kolter;Brandon Amos	2017			online machine learning;stochastic optimization;artificial intelligence;computer science;machine learning;stochastic programming;scheduling (computing);probabilistic logic;electrical grid;end-to-end principle;arbitrage	ML	21.06551554091996	-17.33435073058507	172095
c6db932468004bd6ae7fe30813fcd3ddb2680c21	adaptive submodularity with varying query sets: an application to active multi-label learning		Adaptive submodular optimization, where a sequence of items is selected adaptively to optimize a submodular function, has been found to have many applications from sensor placement to active learning. In the current paper, we extend this work to the setting of multiple queries at each time step, where the set of available queries is randomly constrained. A primary contribution of this paper is to prove the first near optimal approximation bound for a greedy policy in this setting. A natural application of this framework is to crowd-sourced active learning problem where the set of available experts and examples might vary randomly. We instantiate the new framework for multi-label learning and evaluate it in multiple benchmark domains with promising results.	active learning (machine learning);approximation;benchmark (computing);crowdsourcing;greedy algorithm;mathematical optimization;multi-label classification;randomness;submodular set function	Alan Fern;Robby Goetschalckx;Mandana Hamidi-Haines;Prasad Tadepalli	2017			artificial intelligence;machine learning;computer science	ML	23.386477431906087	-16.112975789728427	172212
1edbdab64c7948fd016b28fb53aa65774ba70349	exploiting system hierarchy to compute repair plans in probabilistic model-based diagnosis	hierarchical repair algorithm;computes optimal sequence;anomalous system behavior;cost-effective repair action;optimal approach;exploiting system hierarchy;compact system;model-based diagnosis;repair algorithm;optimal repair strategy;probabilistic model-based diagnosis;optimal repair policy;repair plan;cost effectiveness;probabilistic model	The goal of model-based diagnosis is to isolate causes of anomalous system behavior and recommend cost-e ective repair actions. In general, precomputing optimal repair policies is intractable. To date, investigators addressing this problem have explored approximations that either impose restrictions on the system model, such as a single fault assumption, or that compute an immediate best action with limited lookahead. In this paper, we develop a formulation of repair in model-based diagnosis and a repair algorithm that computes optimal sequences of actions. This optimal approach is costly but can be applied to precompute an optimal repair strategy for compact systems. We show how we can exploit a hierarchical system speci cation to make this approach tractable for larger systems. When introducing hierarchy, we also consider the tradeo between simply replacing a component and decomposing it to repair its subcomponents. The hierarchical repair algorithm is suitable for o -line precomputation of an optimal repair strategy. A modi cation of the algorithm takes advantage of an iterative-deepening scheme to trade o inference time and the quality of the computed strategy.	algorithm;approximation;cobham's thesis;iterative deepening depth-first search;iterative method;parsing;precomputation;statistical model	Sampath Srinivas;Eric Horvitz	1995			statistical model;simulation;cost-effectiveness analysis;artificial intelligence;machine learning;mathematics;algorithm;statistics	AI	20.681476602494122	-15.329473722055054	172528
5f9ea0c3ac73a5415c9286c6d3e3e07312c64eb6	b-spline neural network design using improved differential evolution for identification of an experimental nonlinear process	differential evolution;motion control;chaotic sequences;premature convergence;optimal method;logistic map;random sequence;nonlinear identification;b spline;local minima;stochastic search;neural network;evolutionary computing	B-Spline Neural Network (BSNN), a type of basis function neural network, is trained by gradient-based methods which may fall into local minima during the learning procedure. To overcome the limitations encountered by gradient-based optimization methods, we propose differential evolution (DE) – an evolutionary computation methodology – which can provide a stochastic search to adjust the control points of a BSNN. In this paper, we propose six DE approaches using chaotic sequences based on logistic mapping to train a BSNN. Chaos describes the complex behavior of a nonlinear deterministic system. The application of chaotic sequences instead of random sequences in DE is a powerful strategy to diversify the DE population and improve the DE’s performance in preventing premature convergence to local minima. The numerical results presented here indicate that chaotic DE was effective for building a good BSNN model for the nonlinear identification of an experimental nonlinear yo–yo motion control system. # 2007 Published by Elsevier B.V. www.elsevier.com/locate/asoc Available online at www.sciencedirect.com Applied Soft Computing 8 (2008) 1513–1522	artificial neural network;b-spline;basis function;chaos theory;coefficient of determination;control system;differential evolution;evolutionary algorithm;evolutionary computation;fuzzy control system;gradient;gradient descent;initial condition;kalman filter;levenberg–marquardt algorithm;logistic map;mathematical optimization;maxima and minima;network planning and design;newton;nonlinear system;numerical analysis;performance;premature convergence;requirement;simulation;soft computing;stochastic optimization;systems design;systems theory	Leandro dos Santos Coelho;Fabio Alessandro Guerra	2008	Appl. Soft Comput.	10.1016/j.asoc.2007.10.015	differential evolution;b-spline;motion control;mathematical optimization;logistic map;computer science;artificial intelligence;random sequence;machine learning;maxima and minima;mathematics;artificial neural network;statistics;premature convergence;evolutionary computation	Robotics	14.174491538297081	-23.432463595987254	172607
dd1f9f3d690c4ab1be896fbca391fc7e8be7b7ea	using bayesian networks for convergence analysis of intelligent dynamic spectrum access algorithms	analytical models;belief networks;convergence;rl convergence properties analysis;bayes methods;cellular radio;bayesian network model;cellular system;telecommunication computing;joints;interference;telecommunication computing bayes methods belief networks cellular radio convergence learning artificial intelligence markov processes monte carlo methods radio spectrum management;distributed q learning dsa algorithm;joint policy transitions;cellular system intelligent dynamic spectrum access algorithm convergence analysis reinforcement learning convergence properties analysis rl convergence properties analysis distributed q learning dsa algorithm monte carlo simulation probabilistic analysis joint policy transitions markov chain bayesian network model;bayes methods algorithm design and analysis analytical models convergence joints interference heuristic algorithms;distributed reinforcement learning;probabilistic analysis;heuristic algorithms;radio spectrum management;markov processes;learning artificial intelligence;reinforcement learning convergence properties analysis;dynamic spectrum access distributed reinforcement learning bayesian networks;monte carlo simulation;algorithm design and analysis;dynamic spectrum access;monte carlo methods;bayesian networks;markov chain;intelligent dynamic spectrum access algorithm convergence analysis	In this paper we propose a novel Bayesian network based model for analysing convergence properties of reinforcement learning (RL) based dynamic spectrum access (DSA) algorithms. It uses a minimum complexity DSA problem for probabilistic analysis of the joint policy transitions of RL algorithms. A Monte Carlo simulation of a distributed Q-learning DSA algorithm shows that the proposed approach exhibits remarkable accuracy of predicting convergence behaviour of such algorithms. Furthermore, their behaviour can also be expressed in the form of an absorbing Markov chain, derived from the novel Bayesian network model. This representation enables further theoretical analysis of convergence properties of RL based DSA algorithms. The main benefit of the analysis tool presented in this paper is that it enables the design and theoretical evaluation of novel DSA schemes by extending the proposed Bayesian network model.	absorbing markov chain;algorithm;bayesian network;monte carlo method;network model;probabilistic analysis of algorithms;q-learning;reinforcement learning;simulation;statistical model	Nils Morozs;Tim Clarke;David Grace	2015	2015 IEEE International Conference on Communication Workshop (ICCW)	10.1109/ICCW.2015.7247387	computer science;artificial intelligence;theoretical computer science;machine learning;statistics;monte carlo method	Robotics	20.977667760885286	-18.280719448951565	172841
0b07ea05dcbb75dc4a194e62c0ea371eab37522d	model-based learning of interaction strategies in multi-agent systems	multi agent system;repeated game;model based learning	Agents that operate in a multi-agent system need an efficient strategy to handle their encounters with other agents involved. Searching for an optimal interaction strategy is a hard problem because it depends mostly on the behavior of the others. One way to deal with this problem is to endow the agents with the ability to adapt their strategies based on their interaction experience. This work views interaction as a repeated game and presents a general architecture for a model-based agent that learns models of the rival agents for exploitation in future encounters. First, we describe a method for inferring an optimal strategy against a given model of another agent. Second, we present an unsupervised algorithm that infers a model of the opponent’s strategy from its interaction behavior in the past. We then present a method for incorporating exploration strategies into modelbased learning. We report experimental results demonstrating the superiority of the model-based learning agent over non-adaptive agents and over reinforcement-learning agents.	adversary (cryptography);agent-based model;algorithm;automata theory;automaton;best, worst and average case;converge;dfa minimization;experiment;game theory;interpupillary distance;microsoft windows;multi-agent system;online and offline;procedural generation;production (computer science);recursion;reinforcement learning;stationary process;time complexity;unsupervised learning;utility	David Carmel;Shaul Markovitch	1998	J. Exp. Theor. Artif. Intell.	10.1080/095281398146789	simulation;computer science;artificial intelligence;machine learning;multi-agent system;repeated game	AI	19.8594966371237	-17.506502626277683	172936
b15a7fe9d98f853ec82eb5845f1100d9c1fa2d45	learning where you are going and from whence you came: h- and g-cost learning in real-time heuristic search	poor performance;style approach;numerous variant;f-cost learning real-time a;real-time heuristic search;start state;goal state;new algorithm;different approach;g-cost learning;empirical evaluation;real-time agent-centric algorithm	Real-time agent-centric algorithms have been used for learning and solving problems since the introduction of the LRTA* algorithm in 1990. In this time period, numerous variants have been produced, however, they have generally followed the same approach in varying parameters to learn a heuristic which estimates the remaining cost to arrive at a goal state. Recently, a different approach, RIBS, was suggested which, instead of learning costs to the goal, learns costs from the start state. RIBS can solve some problems faster, but in other problems has poor performance. We present a new algorithm, f -cost Learning RealTime A* (f -LRTA*), which combines both approaches, simultaneously learning distances from the start and heuristics to the goal. An empirical evaluation demonstrates that f -LRTA* outperforms both RIBS and LRTA*-style approaches in a range of scenarios.	algorithm;finite-state machine;heuristic (computer science);map;pathfinding;real-time computing;real-time locating system;real-time transcription;reinforcement learning	Nathan R. Sturtevant;Vadim Bulitko	2011		10.5591/978-1-57735-516-8/IJCAI11-070	mathematical optimization;artificial intelligence;machine learning	AI	19.054138455677847	-11.597505225265412	173133
a04709ea59a93a9040d616921d1beabff89a7e25	toward open-ended evolutionary robotics: evolving elementary robotic units able to self-assemble and self-reproduce	robotique evolutionniste;open ended evolution;intelligence artificielle;body brain co evolution;evolutionary robotics;obstacle avoidance;self assembling;artificial intelligence;inteligencia artificial;evolutionary process;self replication;reseau neuronal;58a25;62p12;robot;red neuronal;neural network	In this paper we discuss the limitations of current evolutionary robotics models and we propose a new framework that might solve some of these problems and lead to an open-ended evolutionary process in hardware. More specifically, the paper describes a novel approach, where the usual concepts of population, generations and fitness are made implicit in the system. Individuals co-evolve embedded in their environment. Exploiting the self-assembling capabilities of the (simulated) robots, the genotype of a successful individual can spread in the population. In this way, interesting behaviours spontaneously emerge, resulting in chasing and evading other individuals, collective obstacle avoidance, coordinated motion of self-assembled structures.	autonomous robot;centralized computing;coherence (physics);collective intelligence;control system;encode;embedded system;emergence;emoticon;evolution;evolutionary algorithm;evolutionary robotics;experiment;first draft of a report on the edvac;fitness function;galaxy morphological classification;interaction;nonlinear gameplay;obstacle avoidance;population;self-assembly;self-replicating machine;simulation;sorting;spontaneous order;swarm;switzerland;tom gruber	Raffaele Bianco;Stefano Nolfi	2004	Connect. Sci.	10.1080/09540090412331314759	robot;simulation;computer science;artificial intelligence;machine learning;self-replication;obstacle avoidance;evolutionary robotics;artificial neural network	Robotics	23.955543234898965	-13.014076425555125	173225
1f3f3ad0da854b827c6cb76821239d61e69029c6	multi-disciplinary trends in artificial intelligence		Graphical models, including constraint networks, Bayesian networks, Markov random fields and influence diagrams, have become a central paradigm for knowledge representation and reasoning in Artificial Intelligence, and provide powerful tools for solving problems in a variety of application domains, including coding and information theory, signal and image processing, data mining, learning, computational biology, and computer vision. Although past decades have seen considerable progress in algorithms in graphical models, many real-world problems are of such size and complexity that they remain out of reach. Advances in exact and approximate inference methods are thus crucial to address these important problems with potential impact across many computational disciplines. Exact inference is typically NP-hard, motivating the development of approximate and anytime techniques. Existing algorithms typically take one of two approaches: Inference, expressed as message-passing schemes, or search and conditioning methods. In the past decade, my research group has developed several very successful algorithms for reasoning in graphical models based on combining heuristic search with message passing approximations. These algorithms are state-of-theart. For example, in the past two approximate inference competitions (The Probabilistic Inference Challenge in UAI, 2012 and 2014) our algorithms were evaluated as leading at either first or second place. My plan is to describe the main principles underlying these developments. In this talk I will describe the unifying framework of AND/OR search spaces for graphical models and show how they can facilitate problem decomposition and allow avoiding redundant specification (and computation) by exploiting the conditional independencies of the graphical model. The AND/OR search space size is bounded exponentially by the graphical models treewidth, making them comparable to inference algorithms such as variable-elimination or join/junction-tree decompositions. Yet, as search schemes they can facilitate many of the ideas developed within Heuristic Search and Operations Research communities, for all queries (e.g., satisfiability, optimization, weighted counting and their combinations) while enjoying the treewidth bound, automatically. Most significantly, they can allow trading off memory for time and time for accuracy, leading to anytime solvers. I will subsequently show how approximate inference can be used for generating heuristic information for guiding the AND/OR search. This can be accomplished using the two ideas of mini-bucket partitioning schemes which relaxes the input problem by node duplication only, combined with linear programming relaxations ideas which optimize cost-shifting re-parameterization, to yield tight bounding heuristic information within systematic, anytime search. AND/OR search guided by such inference-based heuristics has yielded some of the best state-of-the-art solvers for combinatorial optimization. Current research centers on extending these ideas beyond pure optimization, to weighted counting and to hybrid queries (i.e., max-product or min-sum queries such as marginal map and maximizing expected utilities in influence diagrams), aiming for anytime behavior that generates not only an approximation, but also upper and lower bounds which become tighter with more time. XVIII R. Dechter	a* search algorithm;anytime algorithm;approximation algorithm;artificial intelligence;bayesian network;combinatorial optimization;computation;computational biology;computer vision;data mining;graphical model;heuristic (computer science);image processing;influence diagram;information theory;knowledge representation and reasoning;linear programming;marginal model;markov chain;markov random field;mathematical optimization;maxima and minima;message passing;operations research;programming paradigm;tree decomposition;treewidth;variable elimination	Fangzhen Lin;Abhaya Nayak	2016		10.1007/978-3-319-49397-8	data science;discipline;computer science	AI	21.583919454553985	-15.991616921841253	173241
6489ea2c26e14b87a7baae3a033f4a737f0c0ef0	modeling and optimization for microstructural properties of al/sic nanocomposite by artificial neural network and genetic algorithm	feed forward neural network;mechanical alloying;metal matrix nanocomposites;genetic algorithm;microstructures	Mechanical alloying process for synthesizing of Al/SiC nanocomposite powders was modeled by artificial neural network and then optimized by genetic algorithm. The feed-forward back propagation neural network model was used for predicting of the characteristics of the nanocomposite. These characteristics were the crystallite size, and the lattice strain of Al matrix. The aim of the optimization was to specify the maximum lattice strain and the minimum crystallite size of aluminum matrix that could be acquired by adjusting the process variables. Process variables included milling time, milling speed, balls to powders weight ratio that they were given as the input of the neural network model. Both modeling and optimization achieved satisfactory performance, and the genetic algorithm system proved to be a powerful tool that can suitably optimize process parameters. A comparison was made with an already carried out work; the model showed 37.6% improvement in error percentage of the crystallite size and 18.7% improvement in error percentage of the lattice strain of aluminum matrix.	artificial neural network;backpropagation;genetic algorithm;mathematical optimization;nanocomposite;network model;software propagation	R. Esmaeili;M. R. Dashtbayazi	2014	Expert Syst. Appl.	10.1016/j.eswa.2014.03.038	feedforward neural network;genetic algorithm;microstructure;computer science;machine learning	AI	12.68314018797435	-20.066280298783354	173362
f2581c11fe103e7c3ca6b312a85744178ac44d2b	parallel reinforcement learning using multiple reward signals	neural networks;reinforcement learning;learning methods;datavetenskap datalogi;modularity;computer science;artificial neural network;neural network	Reinforcement learning is a quite general learning paradigm that can be used to solve a large set of problems. For complex problems it has been shown that by using task decomposition it may be possible for the system to learn faster. One common approach is to construct systems with multiple modules, where each module learns a sub-task. We present a parallel learning method for agents with an actor–critic architecture based on artificial neural networks. The agents have multiple modules, where the modules can learn in parallel to further increase learning speed. Each module solves a sub-problem and receives its own separate reward signal with all modules trained concurrently. We use the method on a grid world navigation task and show that parallel learning can significantly reduce learning time.	reinforcement learning	Peter Raicevic	2006	Neurocomputing	10.1016/j.neucom.2005.07.008	temporal difference learning;semi-supervised learning;unsupervised learning;robot learning;feature learning;multi-task learning;instance-based learning;error-driven learning;types of artificial neural networks;wake-sleep algorithm;computer science;artificial intelligence;theoretical computer science;online machine learning;machine learning;modularity;learning classifier system;stability;competitive learning;reinforcement learning;active learning;artificial neural network	Robotics	19.20757866934875	-21.422954034131614	173420
db25feb8dfd86b17b2ba605cce129cb5f28b88ea	a note on minimizing absolute percentage error in combined forecasts	combining forecast;mean absolute percentage error;combined forecasts;linear program;goal programming	In this note, two new approaches of combined forecasts are proposed. One approach minimizes mean absolute percentage error while the other approach minimizes the maximum absolute percentage error. A goal programming model is used to obtain the weights to combine different forecasts to minimize the mean absolute percentage error. This formulation can be solved readily by any linear programming computer code. The other approach, minimizing the maximum absolute percentage error, can also be formulated as a goal programming model. Scope and purposeMean absolute percentage error has been widely used as a performance measure in forecasting. One of the major reasons for its popularity is that it is easy to interpret and understand and it becomes a good alternative to mean squared error. Our proposed linear programming models can provide solutions of the minimum mean absolute percentage error and the minimum of the maximum absolute percentage error in combined forecasts. The models we proposed could be solved readily by any linear programming computer code.	approximation error	Kim Fung Lam;H. W. Mui;H. K. Yuen	2001	Computers & OR	10.1016/S0305-0548(00)00026-5	mean percentage error;econometrics;mathematical optimization;mean absolute percentage error;mean absolute scaled error;forecast error;linear programming;goal programming;mathematics;mean absolute error;statistics	NLP	15.30546240002222	-18.50660949467061	173424
0934af15c9a1e4f34f40e2588c07804ca5174682	multi-armed bandit problems with history		In this paper we consider the stochastic multi-armed bandit problem. However, unlike in the conventional version of this problem, we do not assume that the algorithm starts from scratch. Many applications offer observations of (some of) the arms even before the algorithm starts. We propose three novel multi-armed bandit algorithms that can exploit this data. An upper bound on the regret is derived in each case. The results show that a logarithmic amount of historic data can reduce regret from logarithmic to constant. The effectiveness of the proposed algorithms are demonstrated on a large-scale malicious URL detection problem.	algorithm;coat of arms;experiment;multi-armed bandit;regret (decision theory);triune continuum paradigm	Pannagadatta K. Shivaswamy;Thorsten Joachims	2012			mathematical optimization;computer science;artificial intelligence;machine learning	ML	23.114035687109673	-17.669716538437328	173434
4aa103211434969cc4d7efd3244d218ac218db0b	a discrete event traffic model explaining the traffic phases of the train dynamics on a linear metro line with demand-dependent control		In this paper we present a mathematical model of the train dynamics in a linear metro line system with demand-dependent run and dwell times. On every segment of the line, we consider two main constraints. The first constraint is on the travel time, which is the sum of run and dwell time. The second one is on the safe separation time, modeling the signaling system, so that only one train can occupy a segment at a time. The dwell and the run times are modeled dynamically, with two control laws. The one on the dwell time makes sure that all the passengers can debark from and embark into the train. The one on the run time ensures train time-headway regularity in the case where perturbations do not exceed a run time margin. We use a Max-plus algebra approach which allows to derive analytic formulas for the train time-headway and frequency depending on the number of trains and on the passenger demand. The analytic formulas, illustrated by 3D figures, permit to understand the phases of the train dynamics of a linear metro line being operated as a transport on demand system.	3d printing;control theory;mathematical model;run time (program lifecycle phase);signalling system no. 7;time complexity	Florian Schanzenbacher;Nadir Farhi;Fabien Leurent;Gerard Gabriel	2018	2018 Annual American Control Conference (ACC)	10.23919/ACC.2018.8431921	control theory;traffic model;train;mathematics;vehicle dynamics;dwell time	Robotics	10.164033333422232	-10.624840945612643	173458
bd0181faf365cea4135fb953a2fe9d2ea40a4e9b	including electromagnetic interference (emi) in functional safety risk assessments		EMI is a potential cause of malfunctions and failures in all electronic technologies. A safety-related system must therefore take EMI into account in its risk assessment. This paper discusses some of the major issues associated with including EMI in an IEC 61508 functional safety risk assessment.	emi;interference (communication);risk assessment	Keith Armstrong	2012		10.1007/978-1-4471-2494-8_9	iec 61508;reliability engineering;electromagnetic compatibility;electromagnetic interference;engineering;risk assessment;functional safety;emi	Security	12.36105340024587	-11.291507005072901	173653
4752a930609d26193f0f5eb0fd2ab873a4d0f919	claspfolio 2: advances in algorithm selection for answer set programming		Building on the award-winning, portfolio-based ASP solver claspfolio, we presentclaspfolio 2, a modular and open solver architecture that integrates sever al different portfolio-based algorithm selection approaches and techniques. The claspfolio 2 solver framework supports various feature generators, so lver selection approaches, solver portfolios, as well as solver -schedule-based pre-solving techniques. The default configuration ofclaspfolio 2 relies on a light-weight version of the ASP solver clasp to generate static and dynamic instance features. The flexible open design of claspfolio 2 is a distinguishing factor even beyond ASP. As such, it provides a unique framework for compari ng and combining existing portfolio-based algorithm selection approaches and techniques in a single, unified framework. Taking advantage of this, we conducted an extensive experimental study to assess the i mpact of different feature sets, selection approaches and base solver portfolios. In addition to gaining substantial insights into the utility of the various approaches and techniques, we identified a default configura tion of claspfolio 2 that achieves substantial performance gains not only over clasp’s default configuration and the earlier version of claspfolio, but also over manually tuned configurations of clasp.	algorithm selection;answer set programming;experiment;open design;solver;unified framework	Holger H. Hoos;Marius Thomas Lindauer;Torsten Schaub	2014	TPLP	10.1017/S1471068414000210	mathematical optimization;computer science;artificial intelligence;machine learning;data mining	AI	20.246037724637045	-10.40807487976066	173912
1fb6581cae9134840a026331c0842a38e6a68e5d	bandwidth synchronization under progression time uncertainty	bandwidth synchronization uncertainty vehicles optimization reliability engineering;road traffic;vissim bandwidth synchronization progression time uncertainty deterministic progression time bandwidth optimization models deterministic value maxband model optimal solutions monte carlo method random progression time simulation microscopic traffic simulation;synchronisation;bandwidth traffic signals;progression mathematics;monte carlo method;progression time variation bandwidth model monte carlo method multiple optimal solutions;optimization;traffic signal control systems;microsimulation;monte carlo methods;traffic signal timing;synchronisation monte carlo methods road traffic	Deterministic progression time is generally assumed in bandwidth optimization models. However, progression time is cycle-by-cycle time varying and generally longer than the deterministic value. Progression time uncertainty has a considerable impact on the bandwidth that is obtained with deterministic data. In addition, we prove that there exist infinite optimal solutions in the MAXBAND model if a known optimal solution holds some properties. Different optimal solutions may have different sensitivities to progression time uncertainty. In this paper, we develop a two-phase approach. In the first phase we solve the MAXBAND models with perturbation controlled by a parameter and generate a number of optimal or suboptimal plans, and in the second phase we apply the Monte Carlo method to simulate random progression time, evaluate the generated plans, and rank them by the reliability. We also conduct extensive microscopic traffic simulation using VISSIM to evaluate delays and stops for certain optimal plans. Some observations are made.	color gradient;existential quantification;mathematical optimization;monte carlo method;simulation;two-phase commit protocol;vissim	Jing-Quan Li	2014	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2013.2286098	econometrics;real-time computing;simulation;computer science;mathematics;statistics;monte carlo method	DB	10.731608230508233	-9.95578095934969	173969
94e9d4c63268abdebcff529c452a30b272221b5c	logarithmic online regret bounds for undiscounted reinforcement learning	multi armed bandit problem;reinforcement learning	We present a learning algorithm for undiscounted reinforcement learning. Our interest lies in bounds for the algorithm’s online performance after some finite number of steps. In the spirit of similar methods already successfully applied for the exploration-exploitation tradeoff in multi-armed bandit problems, we use upper confidence bounds to show that our UCRL algorithm achieves logarithmic online regret in the number of steps taken with respect to an optimal policy.	algorithm;approximation;bellman equation;fastest;machine learning;microsoft outlook for mac;multi-armed bandit;regret (decision theory);reinforcement learning	Peter Auer;Ronald Ortner	2006			mathematical optimization;multi-armed bandit;computer science;artificial intelligence;machine learning;mathematics;reinforcement learning	ML	22.287760097532956	-17.833454983435626	174105
4d2a6c31ff196e6b40072ea7b6604cec2507e41d	controller for torcs created by imitation	hand coded controller;feed forward neural network;neural nets;sensors;backpropagation algorithm torcs game controller wcci 2008 simulated car racing competition hand coded controller feed forward neural network;backpropagation;acceleration;artificial neural networks;gears;backpropagation algorithm;games;game controller;neural nets backpropagation computer games computer interfaces;artificial intelligence;humans;computer games;humans games artificial intelligence computational modeling computer simulation artificial neural networks backpropagation algorithms internet feeds neural networks;wcci 2008 simulated car racing competition;computer interfaces;torcs	This paper is an initial approach to create a controller for the game TORCS by learning how another controller or humans play the game. We used data obtained from two controllers and from one human player. The first controller is the winner of the WCCI 2008 Simulated Car Racing Competition, and the second one is a hand coded controller that performs a complete lap in all tracks. First, each kind of controller is imitated separately, then a mix of the data is used to create new controllers. The imitation is performed by means of training a feed forward neural network with the data, using the backpropagation algorithm for learning.	algorithm;artificial neural network;backpropagation;torcs	Jorge Muñoz;Germán Gutiérrez;Araceli Sanchis	2009	2009 IEEE Symposium on Computational Intelligence and Games	10.1109/CIG.2009.5286464	simulation;computer science;artificial intelligence;backpropagation;machine learning;artificial neural network	Logic	17.677212536842614	-20.461724034149878	174251
11462817417247ebb6c0dadfabd5d836590e66ad	a safe, accurate intravenous infusion control system	control systems;hardware software codesign;control systems fluid flow control medical control systems hardware optical control gravity feeds process control current measurement fluid flow measurement;cost control;integrated design;medical computing;control system;fault tolerant system;rate constant;flow rate;fault tolerant system intravenous infusion control system fluid volume gravity controlled infusion systems pish integrated design of software and hardware;fault tolerance;fpgas;patient treatment;computerised instrumentation;computerised instrumentation patient treatment medical computing;optical sensor	Medical facilities use conventional intravenous (IV) infusion systems in cases where the patient needs some kind of programmed medicine or nutrition. Gravity controls the simplest and cheapest system. In this kind of system, however, the flow rate varies with the bottle's fluid volume and the hose's pressure. Adjusting the drip feed keeps the rate constant. This article details our development of a control system for conventional gravity-controlled infusion systems that guarantees a safe and accurate infusion process. The control system measures the current flow rate through an optical sensor in the drop window and controls it by compressing or decompressing the hose with a motor. We wanted the system to control conventional IV infusion systems with hardware and software. This kind of implementation creates a low-cost control system that resists software faults. Providing this kind of safety becomes crucial if the microcomputer is also used for other purposes. To analyze the various implementation possibilities, we used the PISH (integrated design of software and hardware) codesign methodology developed by our research group. This fault-tolerant system implemented in hardware and software and partitioned with a codesign methodology revolutionizes traditional IV infusion control systems.	control system	Edna Barros;Marcus Vinicius Duarte dos Santos	1998	IEEE Micro	10.1109/40.735940	embedded system;fault tolerance;parallel computing;real-time computing;computer science;control system;operating system	Embedded	16.496784320352052	-12.397483190546927	174298
b232884375869a3003efbc1b041e91c9f93281e6	approximation of centroid end-points and switch points for replacing type reduction algorithms	type reduction;type 2 fuzzy logic system;technology;computer science artificial intelligence;fuzzy logic systems;time series;accuracy;science technology;controllers;model;design;optimization;computer science;sets;prediction;defuzzification	Despite several years of research, type reduction (TR) operation in interval type-2 fuzzy logic system (IT2FLS) cannot perform as fast as a type-1 defuzzifier. In particular, widely used Karnik-Mendel (KM) TR algorithm is computationally much more demanding than alternative TR approaches. In this work, a data driven framework is proposed to quickly, yet accurately, estimate the output of the KM TR algorithm using simple regression models. Comprehensive simulation performed in this study shows that the centroid end-points of KM algorithm can be approximated with a mean absolute percentage error as low as 0.4%. Also, switch point prediction accuracy can be as high as 100%. In conjunction with the fact that simple regression model can be trained with data generated using exhaustive defuzzification method, this work shows the potential of proposed method to provide highly accurate, yet extremely fast, TR approximation method. Speed of the proposed method should theoretically outperform all available TR methods while keeping the uncertainty information intact in the process.	approximation algorithm;approximation error;communication endpoint;defuzzification;emoticon;farthest-first traversal;free library of springfield township;fuzzy control system;fuzzy logic;hungarian algorithm;in the beginning... was the command line;run time (program lifecycle phase);simulation;time complexity;transistor;type-1 owa operators	Syed Moshfeq Salaken;Abbas Khosravi;Saeid Nahavandi;Dongrui Wu	2015	Int. J. Approx. Reasoning	10.1016/j.ijar.2015.07.010	design;prediction;defuzzification;artificial intelligence;machine learning;time series;mathematics;algorithm;statistics;technology	AI	24.450679868487775	-15.342016811275524	174308
81208ddc7c3849838704b675161f5846ce2f8bfe	estimation of software project effort with support vector regression	software effort estimation;support vector regression;linear regression;regression;radial basis function neural network;comparative study;rbf network	This paper provides a comparative study on support vector regression (SVR), radial basis functions neural networks (RBFNs) and linear regression for estimation of software project effort. We have considered SVR with linear as well as RBF kernels. The experiments were carried out using a dataset of software projects from NASA and the results have shown that SVR significantly outperforms RBFNs and linear regression in this task.	software project management;support vector machine	Adriano Lorena Inácio de Oliveira	2006	Neurocomputing	10.1016/j.neucom.2005.12.119	support vector machine;proper linear model;regression;computer science;linear regression;machine learning;comparative research;bayesian multivariate linear regression;pattern recognition;data mining	SE	10.77816608959499	-20.58520816470872	174450
08b10f70d7fa1b0cd9ed8ee47044d5e402cfa2b8	investigations into controllers for adaptive autonomous agents based on artificial neural networks		R. MARK RYLATT INVESTIGATIONS INTO CONTROLLERS FOR ADAPTIVE AUTONOMOUS AGENTS BASED ON ARTIFICIAL NEURAL NETWORKS (2001). This thesis reports the development and study of novel architectures for the simulation of adaptive behaviour based on artificial neural networks. There are two distinct levels of enquiry. At the primary level, the initial aim was to design and implement a unified architecture integrating sensorimotor learning and overall control. This was intended to overcome shortcomings of typical behaviour-based approaches in reactive control settings. It was achieved in two stages. Initially, feedforward neural networks were used at the sensorimotor level of a modular architecture and overall control was provided by an algorithm. The algorithm was then replaced by a recurrent neural network. For training, a form of reinforcement learning was used. This posed an intriguing composite of the well-known action selection and credit assignment problems. The solution was demonstrated in two sets of simulation studies involving variants of each architecture. These studies also showed: firstly that the expected advantages over the standard behaviour-based approach were realised, and secondly that the new integrated architecture preserved these advantages, with the added value of a unified control approach. The secondary level of enquiry addressed the more foundational question of whether the choice of processing mechanism is critical if the simulation of adaptive behaviour is to progress much beyond the reactive stage in more than a trivial sense. It proceeded by way of a critique of the standard behaviourbased approach to make a positive assessment of the potential for recurrent neural networks to fill such a role. The findings were used to inform further investigations at the primary level of enquiry. These were based on a framework for the simulation of delayed response learning using supervised learning techniques. A further new architecture, based on a second-order recurrent neural network, was designed for this set of studies. It was then compared with existing architectures. Some interesting results are presented to indicate the appropriateness of the design and the potential of the approach, though limitations in the long run are not discounted.		R. Mark Rylatt	2001			autonomous agent;artificial neural network;computer science;evolutionary robotics;artificial intelligence	AI	18.46648820240693	-21.154148460934966	174810
896d00a104e0d91787b1c88616d8b3cbfd01859b	searching for an alternative plan	cost function;generic algorithm;search algorithm;search;agents;intelligent agent;distance metric;a;alternative plan	Suppose that an intelligent agent accepts as input a complete plan, i.e., a sequence of states (or operators) that should be followed in order to achieve a goal. For some reason, the given plan cannot be followed by the agent, and thus an alternative plan needs to be found --- but we would like the alternative plan to be as close as possible to the original. To achieve this, we define a number of distance metrics between paths or plans, and characterize these functions and their respective attributes and advantages. We then develop a general algorithm based on best-first search that helps an agent find the most suitable alternative plan efficiently, and propose a number of heuristics for the cost function of this best-first search algorithm. We then experimentally show that our algorithm is efficient in finding an alternative plan.	best-first search;distance-vector routing protocol;experiment;fastest;heuristic (computer science);intelligent agent;loss function;randomness;search algorithm;shortest path problem	Ariel Felner;Alex Pomeransky;Jeffrey S. Rosenschein	2003		10.1145/860575.860582	mathematical optimization;genetic algorithm;metric;computer science;artificial intelligence;software agent;data mining;intelligent agent;search algorithm	AI	20.67770526116788	-12.079400941376479	174841
18c785e5ed391108bca15a8f3f218e42d1c6ea1b	modelling dengue epidemics with autoregressive switching markov models (ar-hmm)	time series;markov model;time lag;dengue fever;control strategy	In this work, autoregressive switching-Markov models (ARHMM) are applied to the dengue fever epidemics (DF) in La Havana (Cuba). This technique allows to model time series which are controlled by some unobserved process and finite time lags. A first experiment with real data of dengue is performed in order to obtain the characterization of different stages of the epidemics. The aim of this work is to present a method which can give valuable information about how an efficient control strategy can be performed.	autoregressive model;control theory;direction finding;hidden markov model;linear algebra;markov chain;time series;vii	Madalina Olteanu;Esther García-Garaluz;Miguel A. Atencia Ruiz;Gonzalo Joya Caparrós	2009		10.1007/978-3-642-02478-8_111	simulation;computer science;time series;dengue fever;markov model;operations research;statistics	ML	23.289497488077068	-22.374274746206204	175248
6ae300813f2badaca08927798636232b9b06c8cc	an incremental-evolutionary approach for learning deterministic finite automata	evolutionary computation;training set learning deterministic finite automata incremental learning evolutionary algorithms;learning automata doped fiber amplifiers evolutionary computation noise level machine learning neural networks training data merging voting systems engineering and theory;incremental learning;deterministic finite automata;finite automata;learning artificial intelligence evolutionary computation finite automata;evolutionary algorithm;learning artificial intelligence	This work proposes an approach for learning deterministic finite automata (DFA) that combines incremental learning and evolutionary algorithms. First, the training set is sorted according to the sequence length (from the shortest sequence to the longest one). Then, the training set is divided into a suitable number of groups (M). Next, a DFA population is evolved by using a block of the training set (initially the first group). This process is repeated M times by taken the previously evolved DFA population as initial population and by adding the next sequences group to the previously used block. Finally, an evolutionary algorithm tunes the previously evolved DFA population by using the full training set and the remaining running time. Experiments show that our approach performs well regardless the level of noise present in the training set.	automata theory;deterministic finite automaton;evolutionary algorithm;experiment;finite-state machine;image noise;test set;time complexity	Jonatan Gómez	2006	2006 IEEE International Conference on Evolutionary Computation	10.1109/CEC.2006.1688331	mathematical optimization;quantum finite automata;computer science;artificial intelligence;theoretical computer science;deterministic finite automaton;machine learning;evolutionary algorithm;automata theory;dfa minimization;stability;evolutionary robotics;evolutionary computation	Vision	17.303495121748195	-21.165527427180248	175283
9498db49bdc2d4a2f3719736090e4ff7837ab791	prediction of soil deformation in tunnelling using artificial neural networks		In the past few decades, as a new tool for analysis of the tough geotechnical problems, artificial neural networks (ANNs) have been successfully applied to address a number of engineering problems, including deformation due to tunnelling in various types of rock mass. Unlike the classical regression methods in which a certain form for the approximation function must be presumed, ANNs do not require the complex constitutive models. Additionally, it is traced that the ANN prediction system is one of the most effective ways to predict the rock mass deformation. Furthermore, it could be envisaged that ANNs would be more feasible for the dynamic prediction of displacements in tunnelling in the future, especially if ANN models are combined with other research methods. In this paper, we summarized the state-of-the-art and future research challenges of ANNs on the tunnel deformation prediction. And the application cases as well as the improvement of ANN models were also presented. The presented ANN models can serve as a benchmark for effective prediction of the tunnel deformation with characters of nonlinearity, high parallelism, fault tolerance, learning, and generalization capability.	approximation;artificial neural network;benchmark (computing);carpal tunnel syndrome;consistency model;fault tolerance;generalization (psychology);neural networks;nonlinear system;parallel computing;personality character	Jinxing Lai;Junling Qiu;Zhihua Feng;Jianxun Chen;Haobo Fan	2016		10.1155/2016/6708183	artificial intelligence;machine learning	AI	11.249763685270112	-22.410640473462212	175431
a36b08788c9d68ebdf2aaa8d555858a6128a7f02	r-rtrl based on recurrent neural network with k-fold cross-validation for multi-step-ahead prediction landslide displacement		The reinforced real-time recurrent learning (R-RTRL) algorithm with K-fold cross-validation for recurrent neural networks (RNNs) are applied to forecast multi-step-ahead landslide displacement (K-R-RTRL). The proposed novel method is implemented to make two-and four-ahead forecasts in Liangshuijing landslide monitoring point ZJG24 in Three Gorges Reservoir area. Based on comparison purpose, two comparative neural networks are performed, one is RTRL, the other is back propagation through time neural network (BPTT). The proposed algorithm K-R-RTRL gets superior performance to comparative networks in the final numerical and experimental results.	displacement mapping;recurrent neural network	Jiejie Chen;Ping Jiang;Zhigang Zeng;Boshan Chen	2018		10.1007/978-3-319-92537-0_54	cross-validation;machine learning;artificial neural network;artificial intelligence;pattern recognition;computer science;recurrent neural network;backpropagation;landslide	ML	10.209808362692112	-20.727984818524522	175533
689b834830ae4a6fe5c54980b40997e4f60f3ca2	maze exploration behaviors using an integrated evolutionary robotics environment	tactile sensor;mobile robot;wireless network;evolutionary neural network;test bed;time delay;proof of concept;evolutionary robotics;computer application;physical environment;simulation environment;artificial neural network;distributed robotics	This paper presents results generated with a new evolutionary robotics (ER) simulation environment and its complementary real mobile robot colony research test-bed. Neural controllers producing mobile robot maze searching and exploration behaviors using binary tactile sensors as inputs were evolved in a simulated environment and subsequently transferred to and tested on real robots in a physical environment. There has been a considerable amount of proof-of-concept and demonstration research done in the field of ER control in recent years, most of which has focused on elementary behaviors such as object avoidance and homing. Artificial neural networks (ANN) are the most commonly used evolvable controller paradigm found in current ER literature. Much of the research reported to date has been restricted to the implementation of very simple behaviors using small ANN controllers. In order to move beyond the proof-of-concept stage our ER research was designed to train larger more complicated ANN controllers, and to implement those controllers on real robots quickly and efficiently. To achieve this a physical robot test-bed that includes a colony of eight real robots with advanced computing and communication abilities was designed and built. The real robot platform has been coupled to a simulation environment that facilitates the direct wireless transfer of evolved neural controllers from simulation to real robots (and vice versa). We believe that it is the simultaneous development of ER computing systems in both the simulated and the physical worlds that will produce advances in mobile robot colony research. Our simulation and training environment development focuses on the definition and training of our new class of ANNs, networks that include multiple hidden layers, and time-delayed and recurrent connections. Our physical mobile robot design focuses on maximizing computing and communications power while minimizing robot size, weight, and energy usage. The simulation and ANN-evolution environment was developed using MATLAB. To allow for efficient control software portability our physical evolutionary robots (EvBots) are equipped with a PC-104-based computer running a custom distribution of Linux and connected to the Internet via a wireless network connection. In addition to other high-level computing applications, the mobile robots run a condensed version of MATLAB, enabling ANN controllers evolved in simulation to be transferred directly onto physical robots without any alteration to the code. This is the first paper in a series to be published cataloging our results in this field. © 2004 Elsevier B.V. All rights reserved.	aliasing;artificial life;artificial neural network;autonomous robot;erdős–rényi model;evolutionary robotics;game controller;high- and low-level;linux;matlab;mobile robot;multiple homing;population;programming paradigm;sensor;simulation;software portability;testbed;virtual reality	Andrew L. Nelson;Edward Grant;John M. Galeotti;Stacey Rhody	2004	Robotics and Autonomous Systems	10.1016/j.robot.2003.11.002	mobile robot;simulation;computer science;artificial intelligence;social robot;wireless network;machine learning;evolutionary robotics;proof of concept;artificial neural network;tactile sensor;testbed	Robotics	16.401699008049697	-22.077463478404074	175599
46915dc92902bb3ac3a19f09ef099b78a7d1513a	multivariate state estimation technique for remaining useful life prediction of electronic products		This paper investigates the use of Multivariate State Estimation Techniques as input in predicting the remaining useful life prediction of electronic products. A prognostics approach combining the Multivariate State Estimation Technique with life cycle damage prediction is then presented, along with a case study. The challenges of the approach are also discussed.	elegant degradation;sensor	Shunfeng Cheng;Michael G. Pecht	2007				HCI	14.296688572790059	-15.24801473922721	175608
2897b921f734bc7083f263717ba2217257d3e661	a neuroevolution approach to general atari game playing	topology;evolutionary computation;neural networks;network topology;artificial neural networks;neuroevolution approach higher dimensional representation raw game screen temporal difference learning td learning state spaces sparse reward gradient general video game playing gvgp indirect encoding method compact state representation object representation state representations hyperneat indirect network encoding neuroevolution of augmenting topology cma es covariance matrix adaptation evolution strategy conventional neuroevolution weight evolution algorithmic sophistication neuroevolution agents neuroevolution algorithm general atari 2600 game playing domain specific knowledge video games;games;neural networks algorithms artificial neural networks genetic algorithms evolutionary computation;algorithms;genetic algorithms;games artificial neural networks network topology topology encoding algorithm design and analysis;encoding;neural nets computer games covariance matrices genetic algorithms learning artificial intelligence multi agent systems;algorithm design and analysis	This paper addresses the challenge of learning to play many different video games with little domain-specific knowledge. Specifically, it introduces a neuroevolution approach to general Atari 2600 game playing. Four neuroevolution algorithms were paired with three different state representations and evaluated on a set of 61 Atari games. The neuroevolution agents represent different points along the spectrum of algorithmic sophistication - including weight evolution on topologically fixed neural networks (conventional neuroevolution), covariance matrix adaptation evolution strategy (CMA-ES), neuroevolution of augmenting topologies (NEAT), and indirect network encoding (HyperNEAT). State representations include an object representation of the game screen, the raw pixels of the game screen, and seeded noise (a comparative baseline). Results indicate that direct-encoding methods work best on compact state representations while indirect-encoding methods (i.e., HyperNEAT) allow scaling to higher dimensional representations (i.e., the raw game screen). Previous approaches based on temporal-difference (TD) learning had trouble dealing with the large state spaces and sparse reward gradients often found in Atari games. Neuroevolution ameliorates these problems and evolved policies achieve state-of-the-art results, even surpassing human high scores on three games. These results suggest that neuroevolution is a promising approach to general video game playing (GVGP).	algorithm;artificial neural network;atari;baseline (configuration management);cma-es;domain-specific language;evolution strategy;feature engineering;general game playing;general video game playing;gradient;hyperneat;image processing;image scaling;neuroevolution of augmenting topologies;pixel;polystation;sparse matrix;temporal difference learning	Matthew J. Hausknecht;Joel Lehman;Risto Miikkulainen;Peter Stone	2014	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2013.2294713	games;algorithm design;simulation;genetic algorithm;neuroevolution of augmenting topologies;computer science;artificial intelligence;machine learning;evolutionary acquisition of neural topologies;artificial neural network;network topology;encoding	ML	16.79774913553951	-22.917861791890157	175725
1488f39315cd6ee27460472acbeb0f0ae6795fca	optimistic planning for sparsely stochastic systems	stochastic systems decision theory markov processes planning predictive control;hiv infection;predictive control;model predictive control;stochastic system;upper bound;optimistic planning;online planning;planning markov processes stochastic systems upper bound computational modeling prediction algorithms;stochastic drug effectiveness optimistic planning online planning algorithm sparsely stochastic markov decision process random state transition planning tree active selection method model predictive control receding horizon control online control simulated hiv infection;decision theory;planning;inverted pendulum;markov processes;markov decision process;stochastic systems;model predictive control online planning optimistic planning markov decision processes stochastic systems;markov decision processes;state transition	We propose an online planning algorithm for finite-action, sparsely stochastic Markov decision processes, in which the random state transitions can only end up in a small number of possible next states. The algorithm builds a planning tree by iteratively expanding states, where each expansion exploits sparsity to add all possible successor states. Each state to expand is actively chosen to improve the knowledge about action quality, and this allows the algorithm to return a good action after a strictly limited number of expansions. More specifically, the active selection method is optimistic in that it chooses the most promising states first, so the novel algorithm is called optimistic planning for sparsely stochastic systems. We note that the new algorithm can also be seen as model-predictive (receding-horizon) control. The algorithm obtains promising numerical results, including the successful online control of a simulated HIV infection with stochastic drug effectiveness.	approximation algorithm;automated planning and scheduling;computation;iteration;markov chain;markov decision process;numerical analysis;regret (decision theory);sparse matrix;stochastic process;tree (data structure)	Lucian Busoniu;Rémi Munos;Bart De Schutter;Robert Babuska	2011	2011 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)	10.1109/ADPRL.2011.5967375	mathematical optimization;simulation;computer science;machine learning	AI	21.131457775234356	-18.33301956682561	175730
cc2cd7b310a72bf70a9cb4fd78fc44e9eafcac33	boiler efficiency estimation from hydrogen content in fuel	software;thermal power stations boilers flue gases hydrogen regression analysis;hydrogen;temperature sensors;gross calorific value boiler efficiency estimation hydrogen content fuel thermal power plant heat energy chemical composition electricity production boiler loss dasy lab software suite akaike information criterion aic linear regression method flue gas;akaike information criterion boiler loss due to hydrogen in fuel dasy lab efficiency estimation linear regression;boilers;fuels;mathematical model;predictive models;boilers fuels hydrogen predictive models mathematical model software temperature sensors	More than 45 % of world's electricity is generated from thermal power plants by utilizing coal as a fuel. Boilers and turbines are the most basic components in thermal power plants. Efficient utilization of heat energy produced from chemical composition of fuel assures enhanced electricity production. Performance degradation of boiler is mainly due to boiler losses. This paper presents innovative method to predict boiler efficiency using DASY Lab software suite. The prediction of boiler efficiency is based on the coefficient of correlation between boiler efficiency, the boiler loss due to hydrogen content of fuel and Akaike Information Criterion (AIC). Linear regression method is used to obtain the line of best fit. Loss due to hydrogen content in fuel has a strong correlation with the boiler efficiency. Hence, this method uses loss due to hydrogen content in fuel and simplifies the steps in finding boiler efficiency. The hydrogen content of fuel, temperature of flue gas, ambient temperature, and gross calorific value of fuel are used for finding the efficiency of boiler. The maximum error in predicting the boiler efficiency is 1.82 %, which signifies the authenticity of the proposed method. The predicted boiler efficiency is validated using data from an industry.	akaike information criterion;coefficient;curve fitting;elegant degradation;hydrogen;line fitting;power supply;software suite	L. C. ChayalakshmiC.;D. S. Jangamshetti;Savita Sonoli	2015	2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2015.7275758	hydrogen;environmental engineering;computer science;engineering;machine learning;mathematical model;mathematics;predictive modelling;forensic engineering;waste management;statistics	Robotics	11.43673186430632	-17.57464832057648	176071
679b227df74916e2df4331a4aa64dba70cf21c0c	benchmarking for bayesian reinforcement learning	bayesian reinforcement learning;bbrl library;offline learning	In the Bayesian Reinforcement Learning (BRL) setting, agents try to maximise the collected rewards while interacting with their environment while using some prior knowledge that is accessed beforehand. Many BRL algorithms have already been proposed, but the benchmarks used to compare them are only relevant for specific cases. The paper addresses this problem, and provides a new BRL comparison methodology along with the corresponding open source library. In this methodology, a comparison criterion that measures the performance of algorithms on large sets of Markov Decision Processes (MDPs) drawn from some probability distributions is defined. In order to enable the comparison of non-anytime algorithms, our methodology also includes a detailed analysis of the computation time requirement of each algorithm. Our library is released with all source code and documentation: it includes three test problems, each of which has two different prior distributions, and seven state-of-the-art RL algorithms. Finally, our library is illustrated by comparing all the available algorithms and the results are discussed.	anytime algorithm;approximation algorithm;computation;documentation;interaction;learning disorders;markov chain;markov decision process;open-source software;rl (complexity);reinforcement learning;rewards;source code;time complexity	Michael Castronovo;Damien Ernst;Adrien Couëtoux;Raphaël Fonteneau	2016		10.1371/journal.pone.0157088	documentation;machine learning;reinforcement learning;benchmarking;markov decision process;bayes' theorem;offline learning;markov chain;bayesian probability;computer science;artificial intelligence	AI	23.631864279460682	-18.706782841050533	176106
8b125898c6e7ab3e73d1d9adb0b7b9c873c26c30	machine condition prognosis based on sequential monte carlo method	methane;sequential importance sampling and resampling sirs;posterior probability density function;sequential monte carlo method;dynamic system;time series;working conditions;predictive maintenance;machine condition prognosis;condition monitoring;complex system;particle filter;sequential importance sampling;nonlinear system;condition based maintenance	Machine condition prognosis is an important part of the decision-making in condition-based maintenance. By predicting the degradation of working conditions of machinery, it can organize a predictive maintenance program and prevent production loss. For complex systems, the trending data of the performance degradation is nonlinear over time known as a time series. This paper proposes a prognosis algorithm applied in a real dynamic system. Sequential Monte Carlo method, also known as a particle filter, can be used in nonlinear systems without any assumption of linearity. It is based on the sequential important sampling and resampling algorithm, which represents the posterior probability density function by a set of randomly drawn samples (called particles) and their associated weights. The prediction estimations are computed based on those samples and their weights. The real trending data of low methane compressors acquired from condition monitoring routines is employed for evaluating the proposed method. The results show that the proposed method offers a potential to predict the trending data in real systems of machine condition prognosis.	monte carlo method	Wahyu Caesarendra;Gang Niu;Bo-Suk Yang	2010	Expert Syst. Appl.	10.1016/j.eswa.2009.07.014	econometrics;mathematical optimization;methane;particle filter;nonlinear system;dynamical system;time series;predictive maintenance;statistics	ML	14.204031943959961	-15.207153527414007	176185
525a3837e1a2b0394484597746e29bdb347e4fc6	neuron time warp	monte carlo methods;biology computing;brain;differential equations;stochastic processes;mpi;brain parts;chemical reaction;dendrite branch;differential equation;ions diffusion;multicore machine;multiscale simulation model;neuron time warp;neuronal membrane;next subvolume method;shared memory;stochastic monte carlo algorithm	Detailed simulation of chemical reactions and the diffusion of ions through a neuronal membrane presents challenges due to the multiple scales at which this occurs, scales that require development and consolidation of a number of different simulation methodologies. In this paper, we describe Neuron Time Warp (NTW), a part of the NEURON project for development of multi-scale tools for simulations of brain parts and brains. NTW relies upon the Next Subvolume Method, a stochastic Monte Carlo algorithm used to simulate chemical reactions within the membrane of a neuron. We make use of a model of a dendrite branch on which to evaluate NTW's performance using MPI and shared memory on a multi-core machine. This work is a first step towards the development of multi-scale simulation models which are capable of portraying the behavior of a neuron with greater fidelity then is possible with differential equation based models alone.	message passing interface;monte carlo algorithm;monte carlo method;multi-core processor;neuron;semiconductor consolidation;shared memory;simulation	Mohammand Nazrul Ishlam Patoary;Carl Tropper;Zhongwei Lin;Robert A. McDougal;William W. Lytton	2014	Proceedings of the Winter Simulation Conference 2014		simulation;computer science;artificial intelligence;theoretical computer science	HPC	15.532848829990066	-10.579918254147113	176195
69332e874da533547eebf0de374d0495d2f86822	sidekick agents for sequential planning problems	electrical engineering and computer science;thesis	Effective Al sidekicks must solve the interlinked problems of understanding what their human collaborator's intentions are and planning actions to support them. This thesis explores a range of approximate but tractable approaches to planning for AI sidekicks based on decision-theoretic methods that reason about how the sidekick's actions will effect their beliefs about unobservable states of the world, including their collaborator's intentions. In doing so we extend an existing body of work on decisiontheoretic models of assistance to support information gathering and communication actions. We also apply Monte Carlo tree search methods for partially observable domains to the problem and introduce an ensemble-based parallelization strategy. These planning techniques are demonstrated across a range of video game domains. Thesis Supervisor: Leslie Pack Kaelbling Title: Professor Thesis Supervisor: Tomis Lozano-Perez Title: Professor	approximation algorithm;cobham's thesis;effective method;leslie speaker;monte carlo method;monte carlo tree search;parallel computing;partially observable system;theory	Owen Macindoe	2013			simulation;computer science;artificial intelligence;algorithm	AI	19.41601891431617	-15.482810362277036	176268
9ee479dbefa3f17f4c784cf54137016b3b1d6699	multi-agent reinforcement learning with bidding for automatic segmentation of action sequences	learning automatic control boltzmann distribution costs subcontracting sun stochastic systems;multi agent reinforcement learning;automatic segmentation;reinforcement learning;multi agent systems learning artificial intelligence;task execution multi agent reinforcement learning bidding action sequence segmentation modular agent coalition;multi agent systems;a priori knowledge;learning artificial intelligence	This paper presents an approach for developing multiagent reinforcement learning systems that are made up of a coalition of modular agents. We focus on learning to segment action sequences to create modular structures in reinforcement learning, through adding an additional a bidding process that is based on reinforcements received during task execution. The approach segments sequences and distributes them among agents) to facilitate the learning of the overall task. Notably, our approach does not rely on a priori knowledge or a priori structures. Initial experiments demonstrated the basic promise of the approach. This work shows how bidding and reinforcement learning can be usefully combined, thus pointing to a new and promising approach.	agent-based model;experiment;reinforcement learning	Ron Sun	2000		10.1109/ICMAS.2000.858517	semi-supervised learning;unsupervised learning;robot learning;error-driven learning;simulation;engineering;artificial intelligence;machine learning;learning classifier system;reinforcement learning;active learning	AI	18.99642806433538	-20.516845796126997	176568
121279da37c0a339524daf7d8b4063e380e21508	interpolation in the extended classifier system: an architectural perspective		Machine Learning techniques constitute a key factor to make Organic Computing (OC) systems selfadaptive and self-reconfigurable at runtime. OC systems are therefore equipped with a so-called selflearning property enabling them to react appropriately when the environmental demands change and the system is faced possibly unforeseen situations. The eXtended Classifier System (XCS) is a rule-based evolutionary online learning system that has gained plenty attention in the research field of Genetic-based Machine Learning in general and within the OC initiative in particular. In this article, the XCS system is structurally extended to incorporate numerical interpolation. With the presented approaches we pursue the overall goal to overcome the challenge of sparsely distributed samples in the problem space resulting from e.g., non-uniform data distributions. A novel Interpolation Component (IC) is introduced and two architectural integration approaches are discussed. We elaborate on three strategies to integrate interpolated values into various algorithmic steps of XCS. The potential of incorporating interpolation techniques is underpinned by an evaluation on a rather challenging theoretical classification task, called the checker-	interpolation;learning classifier system;logic programming;machine learning;norm (social);numerical analysis;organic computing;problem domain;run time (program lifecycle phase);self-reconfiguring modular robot	Anthony Stein;Dominik Rauh;Sven Tomforde;Jörg Hähner	2017	Journal of Systems Architecture - Embedded Systems Design	10.1016/j.sysarc.2017.01.010	embedded system;simulation;computer science;artificial intelligence;machine learning;distributed computing;algorithm;statistics	Graphics	16.192683363054403	-21.4762157810041	176579
f1096bac43e8bfba476ada488fac33a636dc1aaf	reinforcement-driven shaping of sequence learning in neural dynamics		We present here a simulated model of a mobile Kuka Youbot which makes use of Dynamic Field Theory for its underlying perceptual and motor control systems, while learning behavioral sequences through Reinforcement Learning. Although dynamic neural fields have previously been used for robust control in robotics, high-level behavior has generally been pre-programmed by hand. In the present work we extend a recent framework for integrating reinforcement learning and dynamic neural fields, by using the principle of shaping, in order to reduce the search space of the learning agent.	control system;high- and low-level;noise shaping;reinforcement learning;robotics;robust control	Matthew D. Luciw;Sohrob Kazerounian;Yulia Sandamirskaya;Gregor Schöner;Jürgen Schmidhuber	2014		10.1007/978-3-319-08864-8_19	machine learning	ML	18.790133899671645	-23.075647114966205	176901
ab5ad7809b01cca51f8e394a626e26ca579b8d29	q-learning and enhanced policy iteration in discounted dynamic programming	dynamic programming;minimization;temporal difference;optimal stopping problem;learning algorithm;convergence;linear system of equations;approximation algorithms;dynamic program;decision problem;simulation based temporal difference q learning policy iteration dynamic programming finite state discounted markovian decision problem optimal q factors optimal stopping problem lookup table representation feature based q factor approximations stochastic iterative implementations large scale problems linear basis function approximations;learning systems;iterative methods;function approximation;policy evaluation;table lookup dynamic programming function approximation iterative methods learning systems markov processes q factor;approximation algorithms approximation methods table lookup context convergence equations minimization;lookup table;approximation methods;policy iteration;technical report;markov processes;table lookup;context;large scale problem;q factor	We consider the classical finite-state discounted Markovian decision problem, and we introduce a new policy iteration-like algorithm for finding the optimal Q-factors. Instead of policy evaluation by solving a linear system of equations, our algorithm involves (possibly inexact) solution of an optimal stopping problem. This problem can be solved with simple Q-learning iterations, in the case where a lookup table representation is used; it can also be solved with the Q-learning algorithm of Tsitsiklis and Van Roy [TsV99], in the case where feature-based Q-factor approximations are used. In exact/lookup table representation form, our algorithm admits asynchronous and stochastic iterative implementations, in the spirit of asynchronous/modified policy iteration, with lower overhead advantages over existing Q-learning schemes. Furthermore, for large-scale problems, where linear basis function approximations and simulation-based temporal difference implementations are used, our algorithm resolves effectively the inherent difficulties of existing schemes due to inadequate exploration.	dynamic programming;iteration;markov decision process;q-learning	Dimitri P. Bertsekas;Huizhen Yu	2010		10.1109/CDC.2010.5717930	temporal difference learning;system of linear equations;mathematical optimization;discrete mathematics;convergence;optimal stopping;lookup table;function approximation;computer science;technical report;theoretical computer science;dynamic programming;decision problem;mathematics;iterative method;markov process;q factor;approximation algorithm	ML	22.312920508346917	-15.986708967068207	176927
63c4280d0f9dd5d9442e6156b2ad88f0a817298a	prediction of medical equipment failure rate: a case study		Medical equipment is one of the important inputs required for the provision of efficient healthcare services. Following maintenance programs will make the equipment last longer, work more efficiently and reduces the likelihood of equipment failure during critical processing operations. Prediction of these failures affects the efficiency and enlarges the uptime of medical equipment, minimizes sudden failures and even can prevent it. Therefore, time series analysis using autoregressive model (AR) has been used to analyze failure rate data. AR model uses the past behavior of the system output to predict its behavior in the future. The mean squared error (MSE) between model output and real-life data was less than 0.1 %. Moreover, it succeeded to predict duration of next failures.	failure rate	Rasha S. Aboul-Yazeed;Ahmed El-Bialy;Abdalla S. A. Mohamed	2016		10.1007/978-3-319-48308-5_62	reliability engineering	NLP	12.427535006090652	-13.601706281076767	177585
4527f6402f6c62630067f0f35373d664928b3ea8	a neural network to solve quadratic programming problems with fuzzy parameters	quadratic programming problem with fuzzy parametersneural network modelfuzzy mappingbi objective problemweighting problem	In this paper, a representation of a recurrent neural network to solve quadratic programming problems with fuzzy parameters (FQP) is given. The motivation of the paper is to design a new effective one-layer structure neural network model for solving the FQP. As far as we know, there is not a study for the neural network on the FQP. Here, we change the FQP to a bi-objective problem. Furthermore, the bi-objective problem is reduced to a weighting problem and then the Lagrangian dual is constructed. In addition, we consider a neural network model to solve the FQP. Finally, some illustrative examples are given to show the effectiveness of our proposed approach.	artificial neural network;quadratic programming	Amin Mansoori;Sohrab Effati;Mohammad Eshaghnezhad	2018	FO & DM	10.1007/s10700-016-9261-9	mathematical optimization;combinatorics;machine learning;mathematics	ML	21.21447576709304	-11.172525254620213	177685
1a96519d66f12687876892d6afc3ecf0676dddf3	exploring feature-level duplications on imbalanced data using stochastic diffusion search		Swarm intelligence mimics the behaviours of social insects like bees, wasps and ants to offer powerful problem solving metaheuristic which lies in a network of interactions amongst the agents of a multiagent system as well as with their environment. One of the computer algorithms inspired by swarm intelligence is the stochastic diffusion search (SDS). SDS uses some of the processes and techniques found in swarm to solve search and optimisation problems. In this paper, a hybrid approach is proposed to deal with real-world imbalanced data. The proposed model involves oversampling the minority class, undersampling the majority class as well as optimising the parameters of the classifier, Support Vector Machine (SVM). The proposed model uses Synthetic Minority Over-sampling Technique (SMOTE) to perform the oversampling and the agents of a swarm intelligence technique, SDS, to perform an ‘informed’ undersampling on the majority classes. The use of this swarm intelligence technique in conducting the undersampling tasks is investigated and its impact on improving the classification results is demonstrated. In addition to comparing the agents-led undersampling with random undersampling, the results are contrasted against other best known techniques on nine real-world datasets. Additionally, further experiments are designed to explore the behaviour of the SDS agents during the undersampling process.	agent-based model;direct3d;eusociality;experiment;greedy algorithm;interaction;iteration;mathematical optimization;metaheuristic;multi-agent system;oversampling;problem solving;redundancy (engineering);sampling (signal processing);software agent;stochastic diffusion search;support vector machine;swarm intelligence;undersampling	Haya Abdullah Alhakbani;Mohammad Majid al-Rifaie	2016		10.1007/978-3-319-59294-7_25	swarm intelligence;swarm behaviour;support vector machine;oversampling;stochastic diffusion search;undersampling;machine learning;computer science;artificial intelligence	AI	23.771291725603927	-10.27393562645488	177774
ae10baeb0c30de9e4e9981a003be848cdd9277ce	generalizing hyper-heuristics via apprenticeship learning	apprenticeship learning;hyper heuristics;learning by demonstration;generalization	An apprenticeship-learning-based technique is used as a hyperheuristic to generate heuristics for an online combinatorial problem. It observes and learns from the actions of a known-expert heuristic on small instances, but has the advantage of producing a general heuristic that works well on other larger instances. Specifically, we generate heuristic policies for online bin packing problem by using expert near-optimal policies produced by a hyper-heuristic on small instances, where learning is fast. The ”expert” is a policy matrix that defines an index policy, and the apprenticeship learning is based on observation of the action of the expert policy together with a range of features of the bin being considered, and then applying a k-means classification. We show that the generated policy often performs better than the standard best-fit heuristic even when applied to instances much larger than the training set.	apprenticeship learning;best practice;bin packing problem;curve fitting;experiment;feature extraction;feature vector;heuristic (computer science);hyper-heuristic;k-means clustering;problem domain;randomized algorithm;set packing;software release life cycle;test set	Shahriar Asta;Ender Özcan;Andrew J. Parkes;A. Sima Etaner-Uyar	2013		10.1007/978-3-642-37198-1_15	simulation;computer science;artificial intelligence;machine learning	AI	23.385160195153123	-16.00969292555515	177920
2e5d81adb7b9abe7b707807df4075bf7ea7d2508	a machine learning based engine error detection method		Nowadays the fault of automobile engines climb due to the growth of automobiles. Traditional mechanical automobile testing is not efficient enough. In this paper, the Machine Learning based Engine Error Detection method (MLBED) is proposed for the complex nonlinear relation and operation parameters of automobile engine operating parameters such as large scale data, noise, fuzzy nonlinear etc. This method is a fault diagnosis and early warning method designed on the basis of self-organizing neural network, Elman neural network and probabilistic neural network. The experimental results show that MLBED has a great advantage in the current fault detection methods of automobile engine. The method improves the prediction accuracy and efficiency.	error detection and correction;machine learning	Xinsong Cheng;Liang Zhao;Na Lin;Changqing Gong;Ruiqing Wang	2017		10.1007/978-3-319-72823-0_32	fuzzy logic;error detection and correction;artificial neural network;probabilistic neural network;climb;machine learning;fault detection and isolation;automotive engine;artificial intelligence;warning system;computer science	Logic	12.428590044728745	-21.774729033121677	178167
4c6dd347446bcc7559eb8ddee22cfcd8a6a808f5	a bayesian game based adaptive fuzzy controller for multiagent pomdps	optimisation;time complexity bayesian game adaptive fuzzy controller multiagent pomdp fuzzy reinforcement learning rl partially observable markov decision processes fuzzy inference systems fis;joints games markov processes bayesian methods approximation methods learning computational modeling;fuzzy controller;game theory;sequential decision making;partially observed markov decision process;learning;time complexity;bayes methods;reinforcement learning;optimisation adaptive control bayes methods decision making fuzzy control game theory inference mechanisms learning artificial intelligence markov processes;fuzzy control;adaptive control;fuzzy inference systems;bayesian methods;inference mechanisms;joints;optimal policy;scaling up;fuzzy reinforcement learning;computational modeling;partially observable markov decision processes;games;fuzzy inference system;rl;infinite horizon;approximation methods;markov processes;learning artificial intelligence;multiagent pomdp;fis;empirical evaluation;adaptive fuzzy controller;bayesian game	This paper develops a novel fuzzy reinforcement learning (RL) based controller for multiagent partially observable Markov decision processes (POMDPs) modeled as a sequence of Bayesian games. Multiagent POMDPs have emerged as a powerful framework for modeling and optimizing multiagent sequential decision making problems under uncertainty, but finding optimal policies is computationally very challenging. Our aim here is twin fold, (i) introduction of a learning paradigm in infinite horizon multiagent POMDPs and (ii) scaling up multiagent POMDP solution approaches by introduction of fuzzy inference systems (FIS) based generalization. We introduce what may be called fuzzy multiagent POMDPs to overcome space and time complexity issues involved in finding optimal policies for multiagent POMDPs. The proposed FIS based RL controller approximates optimal policies for multiagent POMDPs modeled as a sequence of Bayesian games. We empirically evaluate the proposed fuzzy multiagent POMDP controller on the standard benchmark multiagent tiger problem and compare its performance against other state-of-the-art multiagent POMDP solution approaches. Results showcase the effectiveness of the proposed approach and validate the feasibility of employing Bayesian game based RL (in conjunction with FIS approximation) for addressing the intractability of multiagent POMDPs.	agent-based model;approximation;benchmark (computing);dspace;display resolution;dynamical system;fuzzy logic;game theory;markov chain;partially observable markov decision process;partially observable system;problem domain;programming paradigm;reinforcement learning;robot;scalability;serial ata;time complexity	Rajneesh Sharma;Matthijs T. J. Spaan	2010	International Conference on Fuzzy Systems	10.1109/FUZZY.2010.5584614	time complexity;bayesian game;games;game theory;mathematical optimization;adaptive control;bayesian probability;computer science;artificial intelligence;machine learning;markov process;computational model;reinforcement learning;fuzzy control system	AI	19.961706450191635	-16.922966201843668	178495
309735867a81360b0bfe116a94f5074c874026ac	application of neural network on solid boronizing	mathematics model;solid boronizing;neural network	This paper discusses an application of neural network system on the performance prediction of solid boronizing. To build the mathematics model between the solid boronizing and the prediction of boronizing performance, a neural network approach is adopted. This approach overcomes a lot of problems in the traditional approaches and provides a stable and effective approach.	artificial neural network;coefficient;performance prediction;solid-state drive	Yuxi Liu;Zhifeng Zhang	2011		10.1007/978-3-642-24553-4_1	computer science;artificial intelligence;machine learning;operations research;artificial neural network	ML	11.615534921010086	-22.69280741820507	178543
ed79f593ad7572a2e838bf140913d4de4cd83d18	state-of-health monitoring and prediction of lithium-ion battery using probabilistic indication and state-space model	degradation;bayes methods;health propagation state of health monitoring lithium ion battery state space model ssm battery health prognostics system bayesian inference probabilistic indication bip indication logistic regression particle filtering generative topographic mapping multisensor data fault patterns battery state of health health degradation state;state space model ssm battery health prognostics bayesian inference generative topographic mapping gtm remaining useful life rul prediction;sensor fusion battery testers bayes methods inference mechanisms particle filtering numerical methods power system measurement regression analysis secondary cells;monitoring;batteries;batteries bayes methods degradation prognostics and health management battery charge measurement state space methods probabilistic logic;predictive models;battery charge measurement;voltage measurement	In this paper, a battery health prognostics system is developed based on Bayesian-inference probabilistic (BIP) indication and state-space model (SSM) that integrates logistic regression (LR) and particle filtering (PF). In this system, generative topographic mapping is constructed to model distribution of multisensor data from healthy battery under an assumption that predictable fault patterns are not available. BIP is developed as a quantification indication of battery state-of-health. BIP is capable of offering failure probability for the monitored batteries, which has intuitionist explanation related to health degradation state. SSM is used for modeling health propagation of battery on the time flow, where LR and PF are integrated to predict remaining useful life of the battery. The experimental results on a lithium-ion battery testbed illustrate the potential applications of the proposed system as an effective tool for battery health prognostics.	distribution (mathematics);elegant degradation;gene prediction;generative topographic map;lr parser;linear programming;logistic regression;model-driven architecture;multimodal interaction;particle filter;series and parallel circuits;software propagation;state of health;state space;test data;testbed;topography;turing test;unsupervised learning	Jianbo Yu	2015	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2015.2444237	reliability engineering;degradation;computer science;engineering;data mining;predictive modelling;forensic engineering	Robotics	12.970503209155833	-14.15366595260396	178625
64dbf26f9a6b422a6e60986cda65f8adf357ed74	autonomous growing neural gas for applications with time constraint: optimal parameter estimation	school of no longer in use;electronics and computer science;delaunay triangulation;growing neural gas;temporal constraint;self organizing models;topology preservation	This paper aims to address the ability of self-organizing neural network models to manage real-time applications. Specifically, we introduce fAGNG (fast Autonomous Growing Neural Gas), a modified learning algorithm for the incremental model Growing Neural Gas (GNG) network. The Growing Neural Gas network with its attributes of growth, flexibility, rapid adaptation, and excellent quality of representation of the input space makes it a suitable model for real time applications. However, under time constraints GNG fails to produce the optimal topological map for any input data set. In contrast to existing algorithms, the proposed fAGNG algorithm introduces multiple neurons per iteration. The number of neurons inserted and input data generated is controlled autonomous and dynamically based on a priory or online learnt model. A detailed study of the topological preservation and quality of representation depending on the neural network parameter selection has been developed to find the best alternatives to represent different linear and non-linear input spaces under time restrictions or specific quality of representation requirements.		José García Rodríguez;Anastassia Angelopoulou;Juan Manuel García Chamizo;Alexandra Psarrou;Sergio Orts;Vicente Morell	2012	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2012.02.032	simulation;delaunay triangulation;computer science;artificial intelligence;machine learning;time delay neural network;mathematics	ML	16.785873927203827	-23.599511149418664	178686
38cb2a8a2b1b9c9895c2195183f5f135fe3065cc	can machine learning learn a decision oracle for np problems? a test on sat	np;satisfiability;sat;ml;machine learning;heuristics	This note describes our experiments aiming to empirically test the ability of machine learning models to act as decision oracles for NP problems. Focusing on satisfiability testing problems, we have generated random 3-SAT instances and found out that the correct branch prediction accuracy reached levels in excess of 99%. The branching in a simple backtracking-based SAT solver has been reduced in more than 90% of the tested cases, and the average number of branching steps has reduced to between 1/5 and 1/3 of the one without the machine learning model. The percentage of SAT instances where the machine learned heuristic-enhanced algorithm solved SAT in a single pass reached levels of 80-90%, depending on the set of features used.	machine learning	Cristian Grozea;Marius Popescu	2014	Fundam. Inform.	10.3233/FI-2014-1024	np;computer science;theoretical computer science;heuristics;machine learning;mathematics;algorithm;satisfiability	Theory	19.60041614510275	-12.39263045839869	178892
d117c4ed7344a41b3cb73ad837b6b833889f3606	temperature mode recognition of metallurgical slag based on kpca and nn		As fusion and crystallization temperature is an important physical and chemical characteristic of metallurgical slag, an efficient  way of soft computation is presented in the paper to recognize temperature mode in order to replace complicated hardware measurement  device. First, in terms of sample data of image information in nonlinear correlation, kernel principal component analysis  is adopted to get characteristics that adversely rule out nonlinear correlation information. Then, neural network is adopted  to recognize fusion and crystallization temperature of metallurgical slag with help of unrelated sample data. Finally, the  method is proved efficient after it is inspected in practical application of metallurgical slag’s temperature recognition.  		Debiao Wang;Taifu Li;Yingying Su;Ji-bin Chang	2009		10.1007/978-3-642-03664-4_96	machine learning;artificial intelligence;kernel principal component analysis;crystallization;slag;computation;artificial neural network;nonlinear system;metallurgy;computer science	Robotics	13.595156551419507	-18.81666552830526	179382
01fabd9c1c9c703a45fe0cc564437b79b59b1646	optimizing memory-bounded controllers for decentralized pomdps	selected works;bepress	We present a memory-bounded optimization approach for solving infinite-horizon decentralized POMDPs. Policies for each agent are represented by stochastic finite state controllers. We formulate the problem of optimizing these policies as a nonlinear program, leveraging powerful existing nonlinear optimization techniques for solving the problem. While existing solvers only guarantee locally optimal solutions, we show that our formulation produces higher quality controllers than the state-of-the-art approach. We also incorporate a shared source of randomness in the form of a correlation device to further increase solution quality with only a limited increase in space and time. Our experimental results show that nonlinear optimization can be used to provide high quality, concise solutions to decentralized decision problems under uncertainty.	algorithm;dec alpha;decision problem;display resolution;experiment;finite-state machine;local optimum;mathematical optimization;natural language processing;nonlinear programming;nonlinear system;optimization problem;optimizing compiler;partially observable markov decision process;randomness;scalability;solver	Christopher Amato;Daniel S. Bernstein;Shlomo Zilberstein	2007			mathematical optimization;computer science;mathematics;management science	AI	21.07282654767459	-16.678386759185546	179419
4d205d846c5de9ad3699047f86355085c4ecc467	consensus-based evaluation for fault isolation and on-line evolutionary regeneration	developpement logiciel;field programmable gate array;diseno circuito;fault detection and isolation;consensus;multiplier;reconfigurable architectures;circuit design;evolvable hardware;red puerta programable;algoritmo genetico;reseau porte programmable;multiplicateur;detection defaut;biomimetique;consenso;desarrollo logicial;software development;algorithme genetique;reparation;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;conception circuit;evolutionary algorithm;evolutionary process;reparacion;fault isolation;deteccion imperfeccion;architecture reconfigurable;multiplicador;repair;fitness function;defect detection;biomimetics	While the fault repair capability of Evolvable Hardware (EH) approaches have been previously demonstrated, further improvements to fault handling capability can be achieved by exploiting population diversity during all phases of the fault handling process. A new paradigm for online EH regeneration using Genetic Algorithms (GAs) called Consensus Based Evaluation (CBE) is developed where the performance of individuals is assessed based on broad consensus of the population instead of a conventional fitness function. Adoption of CBE enables information contained in the population to not only enrich the evolutionary process, but also support fault detection and isolation. On-line regeneration of functionality is achieved without additional test vectors by using the results of competitions between individuals in the population. Relative fitness measures support adaptation of the fitness evaluation procedure to support graceful degredation even in the presence of unpredictable changes in the operational environment, inputs, or the FPGA application. Application of CBE to FPGA-based multipliers demonstrates 100% isolation of randomly injected stuck-at faults and evolution of a complete regeneration within 135 repair iterations while precluding the propagation of any discrepant output. The throughput of the system is maintained at 85.35% throughout the repair process.	autonomy;cobham's thesis;evolvable hardware;exception handling;exponential hierarchy;fault detection and isolation;field-programmable gate array;fitness function;genetic algorithm;isolation (database systems);iteration;online and offline;population;programming paradigm;randomness;run time (program lifecycle phase);software propagation;throughput	Kening Zhang;Ronald F. DeMara;Carthik A. Sharma	2005		10.1007/11549703_2	simulation;computer science;artificial intelligence;evolutionary algorithm;fault detection and isolation;algorithm	Robotics	23.509994109532602	-10.767503021212828	179427
1315a50c35d71a2a0f31f708a1206adc7c23edd6	a new hybrid neural-genetic methodology for improving learning	fitness function hybrid neural genetic methodology learning optimization genetic algorithms neural network training;neural networks;learning;hybrid neural genetic methodology;neural nets;biological cells genetic algorithms neural networks evolution biology genetic mutations computer science intelligent networks optimization methods acceleration computer networks;genetics;acceleration;computer networks;neural network training;evolution biology;neural system;biological cells;genetic algorithm;genetic algorithms;optimization;intelligent networks;genetic mutations;computer science;learning artificial intelligence;learning artificial intelligence neural nets genetic algorithms;fitness function;neural network;optimization methods	A new hybrid neural-generic methodology is presented that exploits the optimization advantages of genetic algorithms for the purpose of accelerating neural network training. The choice of fitness function is addressed and experimental findings are shown where neural network training is improved through the proposed approach. The results suggest that genetic algorithms can be a powerful tool for improving learning in neural networks.		A. Likartsis;I. Vlachavas;Lefteri H. Tsoukalas	1997		10.1109/TAI.1997.632233	genetic algorithm;computer science;bioinformatics;artificial intelligence;machine learning;artificial neural network	Vision	15.123102323566348	-23.888030449886518	179611
b909ac959df9268d9c3ea336bca1214fe4eb2cf1	reliable, distributed scheduling and rescheduling for time-critical, multiagent systems	auction based scheduling;adaptive systems auction based scheduling distributed task allocation multiagent systems;multi agent systems;adaptive systems;distributed task allocation;article;heuristic algorithms resource management job shop scheduling time factors multi agent systems manufacturing robustness	This paper addresses two main problems with many heuristic task allocation approaches—solution trapping in local minima and static structure. The existing distributed task allocation algorithm known as performance impact (PI) is used as the vehicle for developing solutions to these problems as it has been shown to outperform the state-of-the-art consensus-based bundle algorithm for time-critical problems with tight deadlines, but is both static and suboptimal with a tendency toward trapping in local minima. This paper describes two additional modules that are easily integrated with PI. The first extends the algorithm to permit dynamic online rescheduling in real time, and the second boosts performance by introducing an additional soft-max action-selection procedure that increases the algorithm’s exploratory properties. This paper demonstrates the effectiveness of the dynamic rescheduling module and shows that the average time taken to perform tasks can be reduced by up to 9% when the soft-max module is used. In addition, the solution of some problems that baseline PI cannot handle is enabled by the second module. These developments represent a significant advance in the state of the art for multiagent, time-critical task assignment.Note to Practitioners—This work was motivated by the limitations of current agent-to-task allocation algorithms that do not use a central server for communication. In previously published work, the current state-of-the-art consensus-based bundle algorithm has demonstrated poor performance when applied to model task allocation problems with critical time limits, often failing to assign all of the tasks, especially when the deadlines are tight. The performance impact (PI) algorithm has a much better success rate with these model problems but would be flawed when applied to real missions because it has no mechanism for online replanning when new information becomes available. In addition, it is somewhat restricted in the way it searches for a problem solution, meaning that more efficient plans are often available but are not discovered. This paper tackles both of these shortcomings. The PI algorithm is extended to include a module that permits rescheduling when necessary, and a further module is introduced that widens the scope of the solution search. A third module that is able to offer robust plans, even for large-scaled missions involving many agents and tasks, has also been developed, although it is not discussed here. Implementation and testing of a version of PI that incorporates all three of these modules are the final goal of this research.		Amanda Whitbrook;Qinggang Meng;Paul W. H. Chung	2018	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2017.2679278	mathematical optimization;computer science;job shop scheduling;adaptive system;robustness (computer science);real-time computing;scheduling (computing);pi;bundle;multi-agent system;heuristic;distributed computing	AI	19.3699104050739	-14.129832083376472	179744
293ca1551ed147faa11cdaf895af84ebfaaa5205	a new condition indicator for slow-rotating roller chains based on the angle and torque of the driving motor		Heavy-duty slow-rotating roller chains are expensive and time-consuming to replace. Inspections to assess the wear on a chain can only be carried out periodically and usually lead to a standstill of production, which comes with a loss of earnings. Therefore, the incentive to maintain them only when needed, and to use them as long as possible is high. Thus, the use of condition monitoring for roller chains is justified. It can continuously determine the remaining wear margin of the chain so that maintenance can be scheduled when necessary and production holds can be minimized. For slow-rotating roller chains the usual frequency-based approaches are not applicable. We propose the average torque of the driving motor for the roll-in of each chain link as a meaningful condition indicator. The angle and torque can be read out from the motor drive and encoder, respectively, and the average torque can easily be calculated. On data from a highly worn chain of a demonstrator, the roll-in of certain chain links lead to a 25% increased average torque of the driving motor. We expect the average torque to gradually increase with less remaining wear margin.		Manfred Smieschek;Timo Hinrichs;André Stollenwerk;Stefan Kowalewski;Rudiger Preub	2018	2018 IEEE 14th International Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2018.8560542		Robotics	11.919420864444234	-12.331336829215426	179751
3df1e5e04c1d18ed6e0c2ac54b3ed403b67bedb4	réseaux bayésiens dynamiques génériques et hiérarchiques pour la décision en environnement incertain	search problem;modelizacion;distributed system;hierarchical system;planning technique;disaster;rotor helicoptere;systeme reparti;tecnica planeamiento;descomposicion grafo;rotor helicoptero;sauvetage;proceso markov;localization;systeme hierarchise;espace etat;helicopter rotor;decision markov;salvamento;localizacion;robotics;interpretacion abstracta;problema investigacion;dynamic bayesian networks;modelisation;reseau bayes;sistema jerarquizado;systeme incertain;planificacion;hierarchical classification;sistema repartido;localisation;state space method;methode espace etat;red bayes;sinistre;processus markov;state space;markov process;bayes network;classification hierarchique;robotica;planning;markov decision;robotique;planification;interpretation abstraite;espacio estado;abstract interpretation;sistema incierto;probleme recherche;robot;modeling;clasificacion jerarquizada;uncertain system;markov decision processes;rescue;graph decomposition;metodo espacio estado;siniestro;decomposition graphe;technique planning	Planning under uncertainty techniques are hard to apply to autonomous robotics problems: they require a tedious modeling effort when dealing with large state spaces. Factored representations, using state variables, are more compact, but they cannot cope very efficiently with variables that can take a large number of values, e.g. the robot localization variables. Search and rescue problems combine these with mission variables. We propose a generic hierarchical abstract model in order to simplify the modeling stage for robotics planning problems with action uncertainties. An algorithm automatically instanciates our abstract model, which is shown and assessed on several instances of search and rescue autonomous rotorcraft problems.	linear algebra	Florent Teichteil-Königsbuch;Patrick Fabiani	2007	Revue d'Intelligence Artificielle	10.3166/ria.21.391-418	planning;markov decision process;robot;helicopter rotor;disaster;simulation;systems modeling;internationalization and localization;search problem;computer science;state space;artificial intelligence;bayesian network;hierarchical control system;markov process;robotics;dynamic bayesian network	NLP	23.307541768876103	-14.471251466695989	180020
9a201f5996b28a4470996cb18f1bbc07952554df	intelligent fault recognition and diagnosis for rotating machines using neural networks	vibration analysis;intelligent fault recognition;artificial neural networks;industrial applications;data acquisition;remote machine condition monitoring	Monitoring industrial machine health in real-time is not only in high demand, it is also complicated and difficult. Possible reasons for this include: (a) access to the machines on site is sometimes impracticable, and (b) the environment in which they operate is usually not human-friendly due to pollution, noise, hazardous wastes, etc. Despite theoretically sound findings on developing intelligent solutions for machine condition-based monitoring, few commercial tools exist in the market that can be readily used. This paper examines the development of an intelligent fault recognition and monitoring system (Melvin I), which detects and diagnoses rotating machine conditions according to changes in fault frequency indicators. The signals and data are remotely collected from designated sections of machines via data acquisition cards. They are processed by a signal processor to extract characteristic vibration signals of ten key performance indicators (KPIs). A 3-layer neural network is designed to recognize and classify faults based on a pre-determined set of KPIs. The system implemented in the laboratory and applied in the field can also incorporate new experiences into the knowledge base without overwriting previous training. Results show that Melvin I is a smart tool for both system vibration analysts and industrial machine operators. DOI: 10.4018/978-1-4666-2651-5.ch012	artificial neural network;data acquisition;emoticon;experience;knowledge base;overwriting (computer science);real-time clock;real-time computing;signal processing	Cyprian F. Ngolah;Ed Morden;Yingxu Wang	2011	IJSSCI	10.4018/jssci.2011100105	embedded system;computer science;artificial intelligence;machine learning;vibration;data acquisition;artificial neural network	ML	12.374456151044381	-15.365970040343976	180109
dfd91e739bd979c08485a75fd11c501a6ec05118	build order optimization in starcraft	resrouce allocation;real time strategy game;scheduling	In recent years, real-time strategy (RTS) games have gained interest in the AI research community for their multitude of challenging subproblems — such as collaborative pathfinding, effective resource allocation and unit targeting, to name a few. In this paper we consider the build order problem in RTS games in which we need to find concurrent action sequences that, constrained by unit dependencies and resource availability, create a certain number of units and structures in the shortest possible time span. We present abstractions and heuristics that speed up the search for approximative solutions considerably in the game of StarCraft, and show the efficacy of our method by comparing its real-time performance with that of professional StarCraft players.	action selection;fast forward;hard coding;heuristic (computer science);pathfinding;real-time clock;real-time locating system;real-time transcription;search algorithm;selection algorithm;simulation;starcraft	David Churchill;Michael Buro	2011			real-time computing;simulation;computer science;artificial intelligence;machine learning;scheduling	AI	19.144947761091853	-16.805269785929664	180266
a3e366b3e76d2b9d98798906e43ee2824a93f943	application of ensemble classification method for power transformers condition assessment	oil insulation;power transformer insulation;monitoring;condition monitoring;training;indexes	The increase in the amount of data acquired from the monitoring of power system components has motivated utilities to employ effective strategies for processing the information collected. Hence, salient features can be identified and efficient decisions is made. An important component of any power system is power transformers, which have the single highest value of the equipment installed in high-voltage substations. For this reason, significant attention has been devoted to transformer monitoring and diagnostic techniques, resulting in huge volumes of raw data, especially related to the detection of any abnormal transformer behavior. The application of many monitoring tests is therefore not always useful, creating a critical need for a rational method of minimizing the number of monitoring tests without losing essential information about the actual condition of the transformer. This paper presents a statistical approach for evaluating the state of the transformer using machine learning technique. Demonstration of the use of classifier ensemble to predict transformer condition was also made.	machine learning;naive bayes classifier;transformer;transformers	Ayman Othman;Monsef Tahir;Ramadan El Shatshat;Khaled Bashir Shaban	2017	2017 IEEE 30th Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2017.7946774	control engineering;electric power system;electronic engineering;raw data;computer science;condition monitoring;transformer	SE	11.732455162900532	-15.272112039095916	180341
c96bfd70182f8dbc7526f05060a781d638025af3	wind turbine blade breakage monitoring with deep autoencoders	wind turbine blade breakages condition monitoring deep autoencoders statistical process control;blades wind turbines monitoring sensors wind farms condition monitoring temperature	Monitoring wind turbine blade breakages based on supervisory control and data acquisition (SCADA) data is investigated in this research. A preliminary data analysis is performed to demonstrate that existing SCADA features are unable to present irregular patterns prior to occurrences of blade breakages. A deep autoencoder (DA) model is introduced to derive an indicator of impending blade breakages, the reconstruction error (RE), from SCADA data. The DA model is a neural network of multiple hidden layers organized symmetrically. In training DA models, the restricted Boltzmann machine is applied to initialize weights and biases. The back-propagation method is subsequently employed to further optimize the network structure. Through examining SCADA data, we observe that the trend of RE will shift by the blade breakage. To effectively detect RE shifts through online monitoring, the exponentially weighted moving average control chart is deployed. The effectiveness of the proposed monitoring approach is validated by blade breakage cases collected from wind farms located in China. The computational results prove the capability of the proposed monitoring approach in identifying impending blade breakages.	algorithm;artificial neural network;autoencoder;backpropagation;chart;computation;data acquisition;restricted boltzmann machine;software propagation	Long Wang;Zijun Zhang;Jia Xu;Ruihua Liu	2018	IEEE Transactions on Smart Grid	10.1109/TSG.2016.2621135	computer science;marine engineering	ML	11.878544193869109	-16.472977648280878	180474
13a2d21a1c0831bac997df6dae48143166651067	solution of the augmenting sequence of linear programming problems as a tool for the intellectual home environment's self-training	intelligent control;augmenting self training;linear programming;smart home environment;intelligent decision making	This work presents the solution based on the augmenting sequence of linear programming problems (LPP) as a tool for intellectualizing home environment. The proposed solution empowers the intelligent decision making procedure which can be applied to various intelligent control applications. The augmenting self-training procedure based on LPP approach is presented as well, which allows making reasonable decisions having only limited data about the controlled environment. The method permits retraining the decision making system when new data is available. As a proof of concept, this solution is applied to intelligent light control application. The obtained simulation results show the method’s capability in making reasonable decisions according to users preferences.  DOI:  http://dx.doi.org/10.5755/j01.itc.44.2.10235	linear programming	Andrius Dmuchovskis;Raimundas Jasinevicius;Vaidas Jukavicius;Egidijus Kazanavicius;Laura Kizauskiene;Agnius Liutkevicius	2015	ITC	10.5755/j01.itc.44.2.10235	mathematical optimization;simulation;computer science;linear programming;artificial intelligence;machine learning;computer security;algorithm;intelligent control	Logic	16.730779213310548	-20.182152299930745	180539
1966eb24630e03667d41191db00578b2df8ab31c	modeling and analysis of transportation networks using batches petri nets with controllable batch speed	transportation network;transportation networks;real time control;real time;dynamic model;traffic flow;continuous flow;batches petri nets;variable speed limit;hybrid petri net;petri net;control strategy;modeling and analysis	In road transportation networks, such as freeways, motorways or highways, variable speed limit (VSL) control is one of the most efficient strategies to substantially improve traffic flow and solve or reduce the congestion problem. One way to design control strategies applicable in real time is to represent the vehicle flows with a hybrid dynamic model. In this context, Batches Petri Nets (BPN) and their extensions, are well adapted for the modeling of such systems as they intend to model variable delays on continuous flows by adding special nodes, called batch nodes, to the continuous and hybrid Petri nets. Using BPN with controllable batch speed, this paper studies a portion of the A12 highway in The Netherlands. This hybrid representation leads to the evaluation of several real time VSL control laws in accordance with the accumulation front of vehicles.	petri net	Isabel Demongodin	2009		10.1007/978-3-642-02424-5_13	real-time computing;simulation;real-time control system;stochastic petri net;computer science;traffic flow;petri net	Robotics	10.290787619825958	-10.21706926563575	180567
12136f2efd2340e0c49822d4f54d40f24f14384f	old resolution meets modern sls	csp domains;perforation;institute for integrated and intelligent systems;benchmark problem;stochastic local search sls;conference paper;faculty of engineering and information technology;resolution enhancement;random processes;learning problems;280213;stochastic local search;markov processes;keywords learning systems;local minima;local search;other artificial intelligence	Recent work on Stochastic Local Search (SLS) for the SAT and CSP domains has shown the importance of a dynamic (non-markovian) strategy for weighting clauses in order to escape from local minima. In this paper, we improve the performance of two best contemprorary clause weighting solvers, PAWS and SAPS, by integrating a propositional resolution procedure. We also extend the work to AdaptNovelty , the best non-weighting SLS solver in the GSAT/WalkSAT series. One outcome is that our systems can solve some highly structured problems such as quasigroup existence and parity learning problems which were previously thought unsuitable for local search and which are completely out of reach of traditional solvers such as GSAT. Here we present empirical results showing that for a range of random and realworld benchmark problems, resolution-enhanced SLS solvers clearly outperform the alternatives.	benchmark (computing);local search (optimization);maxima and minima;parity learning;randomness;solver;standard sea level;walksat	Anbulagan;Duc Nghia Pham;John K. Slaney;Abdul Sattar	2005			stochastic process;mathematical optimization;computer science;artificial intelligence;local search;machine learning;maxima and minima;markov process;statistics	AI	21.105315419748912	-13.512780311187576	180644
1af1cdfebaa9be9bd2404b05bf0c85731b46e97c	the instant model for a dis road traffic simulation system	road traffic;simulation;vehicle dynamics;autonomous land vehicles	In this paper, the authors present an instant simulation model of a vehicle for a distributed interactive simulation (DIS) road traffic simulation system. The model is useful in predicting remote vehicles by replacing the primitive DIS dead reckoning for an improved and longer prediction in particularly predictable circumstances and scenarios. The instant vehicle states such as acceleration deceleration, and steady run, are used in cooperation with vehicle signals and a map database.	simulation	Pichaya Tandayya;Richard N. Zobel	2000			simulation;vehicle information and communication system;engineering;automotive engineering;transport engineering	EDA	10.59056538158583	-10.376902689351498	180938
38423dba0b1e69b59c72925fe317b365fd43f455	fixed structure automata in a multi-teacher environment	convergence;pediatrics;selected works;speed of convergence;learning automata;power engineering and energy;performance gain;bepress;learning automata convergence power engineering and energy pediatrics performance gain	The concept of an automaton operating in a multi-teacher environment is introduced, and several interesting questions that arise in this context are examined. In particular, we concentrate on the consequences of adding a new teacher to an existing n-teacher set as it affects the choice of a switching strategy. The effect of this choice on expediency and speed of convergence is presented for a specific automaton structure.	automaton;rate of convergence	Daniel E. Koditschek;Kumpati S. Narendra	1977	IEEE Transactions on Systems, Man, and Cybernetics	10.1109/TSMC.1977.4309788	simulation;convergence;computer science;artificial intelligence;theoretical computer science;machine learning;ω-automaton;mathematics	Embedded	16.83255510405514	-13.68200366703974	181186
250239b3096ff27831a2b35658f8fce92652fc7b	a model for compressing probabilities in belief networks	fuzzy reasoning;encode technology;compressibility of information;probabilistic reasoning;belief network	Probabilistic reasoning with belief (Bayesian) networks is based on conditional probability matrices. Thus it suffers from NP-hard implementations. In particular, the amount of probabilistic information necessary for the computations is often overwhelming. So, compressing the conditional probability table is one of the most important issues faced by the probabilistic reasoning community. Santos suggested an approach (called linear potential functions) for compressing the information from a combinatorial amount to roughly linear in the number of random variable assignments. However, much of the information in Bayesian networks, in which there are no linear potential functions, would be fitted by polynomial approximating functions rather than by reluctantly linear functions. For this reason, we construct a polynomial method to compress the conditional probability table in this paper. We evaluated the proposed technique, and our experimental results demonstrate that the approach is efficient and promising.	bayesian network	Shichao Zhang;Chengqi Zhang	2001	Informatica (Slovenia)		computer science;artificial intelligence;theoretical computer science;machine learning;bayesian network;probabilistic logic;algorithm;statistics	ML	21.687106162306442	-13.1914723994536	181235
5a24dd4224f0ff3f41b7523c8ad92e0d1fee3a07	constructing temporally extended actions through incremental community detection		Hierarchical reinforcement learning works on temporally extended actions or skills to facilitate learning. How to automatically form such abstraction is challenging, and many efforts tackle this issue in the options framework. While various approaches exist to construct options from different perspectives, few of them concentrate on options' adaptability during learning. This paper presents an algorithm to create options and enhance their quality online. Both aspects operate on detected communities of the learning environment's state transition graph. We first construct options from initial samples as the basis of online learning. Then a rule-based community revision algorithm is proposed to update graph partitions, based on which existing options can be continuously tuned. Experimental results in two problems indicate that options from initial samples may perform poorly in more complex environments, and our presented strategy can effectively improve options and get better results compared with flat reinforcement learning.	algorithm;community;increment;logic programming;online machine learning;regular expression;reinforcement learning;state diagram;state transition;surgical revision;temporal logic	Xiao Xu;Mei Yang;Ge Li	2018		10.1155/2018/2085721	artificial intelligence;machine learning;adaptability;computer science;reinforcement learning;learning environment;abstraction;graph	AI	20.125873522663298	-21.016755173532115	181472
915c95d935a8bd5fb7a06b08de0da4c0f654d459	optimizing weight and threshold of bp neural network using sfla: applications to nonlinear function fitting	optimisation;nonlinear function fitting sfla bp network;mathematics computing;neural networks;sfla;nonlinear function fitting;neural nets;training;prediction algorithms;backpropagation;fitting;nonlinear functions;bp network;statistics;fitting sociology statistics neural networks algorithm design and analysis prediction algorithms training;optimisation backpropagation mathematics computing neural nets nonlinear functions;bp neural network threshold sfla nonlinear function fitting shuffled frog leaping algorithm pseudocode flow chart bp neural network optimizing weight;algorithm design and analysis;sociology	The shuffled frog-leaping algorithm (SFLA) is presented along with a pseudocode and flow chart to facilitate its implementation. And then we use SFLA to optimize the weight and the threshold value of BP network. Based on the experiments, we show that SFLA performs better than Genetic Algorithms (GAs) in the optimization of BP network's weight and threshold value, which are used in the nonlinear function fitting.	artificial neural network;curve fitting;experiment;flowchart;genetic algorithm;mathematical optimization;nonlinear system;optimizing compiler;pseudocode;tau-leaping	Hongwei Ye;Linfang Yang;Xiaozhang Liu	2013	2013 Fourth International Conference on Emerging Intelligent Data and Web Technologies	10.1109/EIDWT.2013.41	computer science;artificial intelligence;machine learning;algorithm	Robotics	13.091906426331816	-23.214888935607025	181499
8198654db71d9d386d8a34e38536bf774b99c5f0	aggregating optimistic planning trees for solving markov decision processes	reinforcement learning;on line planning;markov decision processes	This paper addresses the problem of online planning in Markov decision processes using a generative model and under a budget constraint. We propose a new algorithm, ASOP, which is based on the construction of a forest of single successor state planning trees, where each tree corresponds to a random realization of the stochastic environment. The trees are explored using a “safe” optimistic planning strategy which combines the optimistic principle (in order to explore the most promising part of the search space first) and a safety principle (which guarantees a certain amount of uniform exploration). In the decision-making step of the algorithm, the individual trees are aggregated and an immediate action is recommended. We provide a finite-sample analysis and discuss the trade-off between the principles of optimism and safety. We report numerical results on a benchmark problem showing that ASOP performs as well as state-of-the-art optimistic planning algorithms.	aggregate data;algorithm;benchmark (computing);generative model;markov chain;markov decision process;numerical analysis	Gunnar Kedenburg;Raphaël Fonteneau;Rémi Munos	2013			markov decision process;mathematical optimization;computer science;machine learning;management science;reinforcement learning	AI	20.979176818356937	-16.15283199025879	181801
5f96de7993116225501a7accd0aedbcf869686e8	multi-fidelity robotic behaviors: acting with variable state information	real time;costs and benefits;robot soccer;legged robot	Our work is driven by one of the core purposes of artificial intelligence: to develop real robotic agents that achi eve complex high-level goals in real-time environments. Robot ic behaviors select actions as a function of the state of the robot and of the world. Designing robust and appropriate robotic behaviors is a difficult because of noise, uncertain ty and the cost of acquiring the necessary state information. We addressed this challenge within the concrete domain of robotic soccer with fully autonomous legged robots provide d by Sony. In this paper, we present one of the outcomes of this research: the introduction of multi-fidelity behaviorsto explicitly adapt to different levels of state information acc uracy. The paper motivates and introduces our general approach and then reports on our concrete work with the Sony robots. The multi-fidelity behaviors we developed allow the robots to su ccessfully achieve their goals in a dynamic and adversarial e nvironment. A robot acts according to a set of behaviors that aggressively balance the cost of acquiring state informati on with the value of that information to the robot’s ability to achieve its high-level goals. The paper includes empirical experiments which support our method of balancing the cost and benefit of the incrementally-accurate state informatio n.	artificial intelligence;autonomous robot;eve;experiment;high- and low-level;real-time transcription	Elly Winner;Manuela M. Veloso	2000			simulation;computer science;cost–benefit analysis;artificial intelligence;social robot	AI	18.015393682835658	-19.346058210104772	181812
099cdb087f240352a02286bf9a3e7810c7ebb02b	metacontrol for adaptive imagination-based optimization		Many machine learning systems are built to solve the hardest examples of a particular task, which often makes them large and expensive to run—especially with respect to the easier examples, which might require much less computation. For an agent with a limited computational budget, this “one-size-fits-all” approach may result in the agent wasting valuable computation on easy examples, while not spending enough on hard examples. Rather than learning a single, fixed policy for solving all instances of a task, we introduce a metacontroller which learns to optimize a sequence of “imagined” internal simulations over predictive models of the world in order to construct a more informed, and more economical, solution. The metacontroller component is a model-free reinforcement learning agent, which decides both how many iterations of the optimization procedure to run, as well as which model to consult on each iteration. The models (which we call “experts”) can be state transition models, action-value functions, or any other mechanism that provides information useful for solving the task, and can be learned on-policy or off-policy in parallel with the metacontroller. When the metacontroller, controller, and experts were trained with “interaction networks” (Battaglia et al., 2016) as expert models, our approach was able to solve a challenging decision-making problem under complex non-linear dynamics. The metacontroller learned to adapt the amount of computation it performed to the difficulty of the task, and learned how to choose which experts to consult by factoring in both their reliability and individual computational resource costs. This allowed the metacontroller to achieve a lower overall cost (task loss plus computational cost) than more traditional fixed policy approaches. These results demonstrate that our approach is a powerful framework for using rich forward models for efficient model-based reinforcement learning.	algorithmic efficiency;computation;computational resource;dynamical system;fits;integer factorization;iteration;machine learning;mathematical optimization;predictive modelling;reinforcement learning;simulation;state transition table	Jessica B. Hamrick;Andrew J. Ballard;Razvan Pascanu;Oriol Vinyals;Nicolas Heess;Peter W. Battaglia	2017	CoRR		simulation;computer science;artificial intelligence;machine learning;mathematics	AI	20.993371038164344	-19.96652740526661	182040
b3e83a8953d078e5f027fc626ad1eb6c52227176	estimating reference crop evapotranspiration using hga-lssvm	levenberg marquardt;least squares approximations;support vector machines;support vector;transpiration;parameter selection;lssvm regression reference crop evapotranspiration estimation hga lssvm model crop irrigation computing least squares support vector machines hybrid genetic algorithm levenberg marquardt optimization algorithm meteorological factor;evaporation;crops;transpiration crops evaporation genetic algorithms least squares approximations regression analysis support vector machines;genetic algorithms;regression analysis;prediction model;evapotranspiration;optimal algorithm;prediction model least square support vector hybrid genetic algorithm reference crop evapotranspiration;optimization agriculture support vector machines predictive models meteorology temperature distribution;hybrid genetic algorithm;least squares support vector machine	Reference crop evapotranspiration (ETo) is the basis for estimating crop evapotranspiration and for computing crop irrigation requirements. In recent years, Least squares support vector machines (LSSVM) have been applied to forecasting in many areas of engineering. In this paper, a novel hyper-parameter selection for LSSVM regression is presented based on hybrid genetic algorithm (HGA). The HGA not only has the advantage of global searching of GA, but also the advantage of local optimization ability of Levenberg-Marquardt optimization algorithm. The LSSVM is applied to the forecasting of reference crop evapotranspiration (ETo). Three ETo prediction models of different meteorological factor input were established based on HGA-LSSVM. These models were verified by measured meteorological data. The ETo computational results by three models were in accordance with the measured results. It also indicated that three ETo prediction models based on LSSVM had the strong predictive ability. And three models predictive ability was 5 factor input LSSVM-ETo-1> 4 factor input LSSVM-ETo-2>3 factor LSSVM-ETo-3 in turn. So HGA-based hyper-parameter selection for LSSVM regression and LSSVM applied to ETo forecast are feasible.	computation;genetic algorithm;hercules graphics card;least squares support vector machine;levenberg–marquardt algorithm;local search (optimization);mathematical optimization;memetic algorithm;requirement;software release life cycle	Xianghong Guo;Xihuan Sun;Juanjuan Ma	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5584576	hydrology;engineering;machine learning;data mining	Visualization	10.843862314140154	-17.812152093574454	182445
a1b68955f33761c38d1f7260e5219e0f6c933cf6	application on the rate of lightning trip based on the grey model	analytical models;reliability;grey theory trip out rate power system catastrophe forecast model reliability;power supply reliability lightning trip grey model power system trip out rate forecast grey theory catastrophe prediction model trip out rate threshold;integrated circuit modeling;lightning;lightning predictive models data models power transmission lines integrated circuit modeling reliability analytical models;predictive models;power transmission reliability grey systems lightning power transmission lines;power transmission lines;data models	Trip-out rate plays a very important role in the research of stable operation of power system, so trip-out rate forecast has become an urgent problem. combining with the characteristics of the grey theory, a catastrophe prediction model about trip-out rate was set up based on the original data. A trip-out rate threshold was established and the data exceeding it was considered abnormal. The time when the trip-out rate would appear abnormal was predicted through the original data and the model. The exception value was accurately predicted by one instance at last. It proves the validity of the prediction method. From another perspective, the gray model can improve the power supply reliability.	catastrophe theory;gene prediction;lightning (connector);power supply	Hua Li;Xunjun Sun;Lingling Li;Fan Wu	2013	2013 10th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2013.6816245	lightning;data modeling;computer science;machine learning;reliability;predictive modelling;electric power transmission;statistics	Mobile	11.50378399671242	-13.249479427803418	182501
b257838333b2fc6ef676fe4521d9b2bc15f75a00	learning intelligent behavior in a non-stationary and partially observable environment	learning process;multi agent system;reinforcement learning;q learning;learning activities;agent learning;multi agent systems;individual learning;partial observation;point of view	Individual learning in an environment where more than one agent exist is a chal-lengingtask. In this paper, a single learning agent situated in an environment where multipleagents exist is modeled based on reinforcement learning. The environment is non-stationaryand partially accessible from an agents' point of view. Therefore, learning activities of anagent is influenced by actions of other cooperative or competitive agents in the environment.A prey-hunter capture game that has the above characteristics is defined and experimentedto simulate the learning process of individual agents. Experimental results show that thereare no strict rules for reinforcement learning. We suggest two new methods to improve theperformance of agents. These methods decrease the number of states while keeping as muchstate as necessary.	partially observable system;prey;reinforcement learning;simulation;situated;stationary process	Selguk Senkul;Faruk Polat	2002	Artificial Intelligence Review	10.1023/A:1019935502139	robot learning;proactive learning;multi-task learning;error-driven learning;computer science;knowledge management;artificial intelligence;machine learning;multi-agent system;competitive learning;action learning;reinforcement learning;active learning;q-learning	AI	20.262723022416345	-19.14249682520253	182609
073efa4fcd174c9629803bdb04758f0ff378fbd7	issues for design of information system for supervision and control of dynamic systems	information system;sequential nonlinear mapping.;identification of states;dynamic system	A new method for a creation of the information system for sequential identification of states of technological processes or other dynamic systems for their supervision and control is considered. The states of dynamic system can be unknown and can change themselves abruptly or slowly. The method is based on a sequential nonlinear mapping of many-dimensional vectors of parameters (collection of which describes the present state of dynamic systems) into two-dimensional vectors in order to reflect the states and their changes on the PC screen and to observe the situation by means of computer. The mapping error function is chosen and expressions for sequential nonlinear mapping are obtained. The mapping preserves the inner structure of distances among the vectors. Examples are given.	cluster analysis;dynamical system;information system;nonlinear system;statistical classification;stochastic process	Algirdas Mykolas Montvilas	1999	Informatica, Lith. Acad. Sci.		simulation;computer science;artificial intelligence;dynamical system;control theory;information system	EDA	16.035616490059155	-15.699584456519004	182701
f99e94ce6f1c3f4002bf1fd22a77e4bc0f3a8ee1	alphazero for a non-deterministic game		The AlphaZero algorithm, developed by DeepMind, achieved superhuman levels of play in the games of chess, shogi, and Go, by learning without domain-specific knowledge except game rules. This paper investigates whether the algorithm can also learn theoretical values and optimal plays for non-deterministic games. Since the theoretical values of such games are expected win rates, not a simple win, loss, or draw, it is worthy investigating the ability of the AlphaZero algorithm to approximate expected win rates of positions. This paper also studies how the algorithm is influenced by a set of hyper-parameters. The tested non-deterministic game is a reduced and solved version of Chinese dark chess (CDC), called 2×4 CDC. The experiments show that the AlphaZero algorithm converges nearly to the theoretical values and the optimal plays in many of the settings of the hyper-parameters. To our knowledge, this is the first research paper that applies the AlphaZero algorithm to non-deterministic games.		Chu-Hsuan Hsueh;I-Chen Wu;Jr-Chang Chen;Tsan-sheng Hsu	2018	2018 Conference on Technologies and Applications of Artificial Intelligence (TAAI)	10.1109/TAAI.2018.00034		AI	18.928893019031687	-18.337314866779035	182986
954945197c1607a0890276413efef15ba2f91049	the ibmap approach for markov network structure learning	structure learning;independence tests;68t05;edas;markov network;knowledge discovery	In this work we consider the problem of learning the structure of Markov networks from data. We present an approach for tackling this problem called IBMAP, together with an efficient instantiation of the approach: the IBMAP-HC algorithm, designed for avoiding important limitations of existing independence-based algorithms. These algorithms proceed by performing statistical independence tests on data, trusting completely the outcome of each test. In practice tests may be incorrect, resulting in potential cascading errors and the consequent reduction in the quality of the structures learned. IBMAP contemplates this uncertainty in the outcome of the tests through a probabilistic maximum-a-posteriori approach. The approach is instantiated in the IBMAP-HC algorithm, a structure selection strategy that performs a polynomial heuristic local search in the space of possible structures. We present an extensive empirical evaluation on synthetic and real data, showing that our algorithm outperforms significantly the current independence-based algorithms, in terms of data efficiency and quality of learned structures, with equivalent computational complexities. We also show the performance of IBMAP-HC in a real-world application of knowledge discovery: EDAs, which are evolutionary algorithms that use structure learning on each generation for modeling the distribution of populations. The experiments show that when IBMAP-HC is used to learn the structure, EDAs improve the convergence to the optimum.	analysis of algorithms;computation;evolutionary algorithm;experiment;heuristic;local search (optimization);markov chain;markov random field;polynomial;population;synthetic intelligence;trust (emotion);universal instantiation	Federico Schlüter;Facundo Bromberg;Alejandro Edera	2014	Annals of Mathematics and Artificial Intelligence	10.1007/s10472-014-9419-5	mathematical optimization;computer science;artificial intelligence;machine learning;edas;data mining;mathematics;knowledge extraction;algorithm;statistics	AI	21.578996996729092	-13.20702726429471	183193
e773aaa7143f8679460888b1e8729d174fc88b14	reliability analysis regarding product fleets in use phase: multivariate cluster analytics and risk prognosis based on operating data	product fleets complex failure modes cluster analysis product reliability risk prognosis big data;prognostics and health management;reliability;automobiles;automotive case study reliability analysis product fleets multivariate cluster analytics operating data product functionality complexity manufacturing process parameter complexity complex failure modes product life cycle mass production consumer goods damaged products risk probability prognosis risk calculation methods univariate risk probability determination big data risk analysis combined multivariate analysis product failure behaviour customer product usage profile;risk analysis;big data;clustering algorithms;automobiles reliability prognostics and health management big data risk analysis clustering algorithms algorithm design and analysis;risk analysis automobile industry big data customer profiles failure analysis mass production pattern clustering probability product life cycle management production engineering computing reliability;algorithm design and analysis	The increasing complexity of product functionality and manufacturing process parameters often leads to complex failure modes and reliability problems within the product life cycle. Especially in the case of mass production of consumer goods - e.g. automobiles, washing machines, computer - an increasing percentage of damaged products within the product fleet can lead to garage or recall actions. If the manufacturer receives knowledge about the first damage claims based on a field observation, a risk probability prognosis is the base of operations regarding further actions. State of the art concerning risk calculation methods consider the failure behaviour and allow the univariate determination of the risk probability regarding the product fleet. These methods do not consider the load or usage profile of the products based on any life span variable. In fact, current technical complex products save a lot of life data (“Big Data”), which can be additionally used for risk analysis within product fleets. This paper outlines an approach to determine the risk probability in product fleets based on a combined multivariate analysis of the product failure behaviour and the customer product usage profile. The theory and application of the approach is shown with the help of a synthetic data set within an automotive case study, which includes real effects of typical field failure behaviour and usage profiles of an automobile fleet.	big data;failure cause;it risk management;reliability engineering;synthetic data;washing machine	S. Bracke;A. Lucker;S. Sochacki	2016	2016 International Conference on Control, Decision and Information Technologies (CoDIT)	10.1109/CoDIT.2016.7593562	reliability engineering;engineering;operations management;data mining	ML	11.030433136070094	-14.492604619707611	183291
c62677b46ffef31cbea038015a23adc2e0742c2b	verification of uncertain pomdps using barrier certificates		We consider a class of partially observable Markov decision processes (POMDPs) with uncertain transition and/or observation probabilities. The uncertainty takes the form of probability intervals. Such uncertain POMDPs can be used, for example, to model autonomous agents with sensors with limited accuracy, or undergoing a sudden component failure, or structural damage [1]. Given an uncertain POMDP representation of the autonomous agent, our goal is to propose a method for checking whether the system will satisfy an optimal performance, while not violating a safety requirement (e.g. fuel level, velocity, and etc.). To this end, we cast the POMDP problem into a switched system scenario. We then take advantage of this switched system characterization and propose a method based on barrier certificates for optimality and/or safety verification. We then show that the verification task can be carried out computationally by sum-of-squares programming. We illustrate the efficacy of our method by applying it to a Mars rover exploration example.		Mohamadreza Ahmadi;Murat Cubuktepe;Nils Jansen;Ufuk Topcu	2018	CoRR		mars rover;autonomous agent;computer science;mathematical optimization;markov decision process;partially observable markov decision process;observable;markov process	AI	20.61266435761927	-15.121158485308056	183346
4ce30be3bc21bf27ada4fb35dcad6021d634154f	prediction of granular time-series energy consumption for manufacturing jobs from analysis and learning of historical data	libraries;support vector machines;information science;support vector machines job shop scheduling machinery production engineering computing regression analysis;training;time series prediction energy consumption prediction energy usage in manufacturing support vector regression;energy consumption;energy consumption manufacturing training libraries information science mathematical model support vector machines;support vector regression granular time series energy consumption manufacturing jobs jobs scheduling infrastructural perspective financial perspective manufacturing machinery historical energy data machine mechanical condition job energy consumption;manufacturing;mathematical model	In the manufacturing sector, the consideration of energy consumption during the scheduling and execution of jobs can offer significant benefits from an infrastructural and financial perspective. While numerous methods have been proposed for predicting the energy consumption of manufacturing machinery, they typically do not treat them as dynamic pieces of equipment which can lead to issues with long term accuracy. Furthermore, these models produce predictions at a high level of abstraction which can lead to sub-optimal utilization. This paper addresses these shortcomings and presents a new methodology based around the usage and inference of historical energy data. Multiple energy profiles for identical jobs are stored along with information regarding the machines mechanical conditions, allowing the system to compensate for machine-related changes to the energy consumption. Where historical data is lacking, analysis of how the machine's condition affects job energy consumption over time, allows for the use of Support Vector Regression to generate temporary synthetic energy profiles compensated for probable machine conditions.	high-level programming language;job stream;scheduling (computing);support vector machine;synthetic intelligence;time series	Chris Duerden;Lik-Kwan Shark;Geoff Hall;Joe Howe	2016	2016 Annual Conference on Information Science and Systems (CISS)	10.1109/CISS.2016.7460575	support vector machine;simulation;information science;computer science;mathematical model;data mining;manufacturing;statistics	AI	14.307025680958867	-15.91446835034538	183410
5bd2be68e116e582b3d9ee2809804a83ff61d580	landslide displacement prediction with uncertainty based on neural networks with random hidden weights	forecasting;terrain factors;pedestrian safety;poison control;uncertainty;injury prevention;terrain factors artificial neural networks uncertainty training forecasting estimation;training;safety literature;traffic safety;injury control;home safety;artificial neural networks;injury research;safety abstracts;human factors;estimation;prediction interval pi displacement prediction feedforward neural networks landslide;occupational safety;safety;safety research;accident prevention;violence prevention;bicycle safety;poisoning prevention;falls;ergonomics;suicide prevention	In this paper, we propose a new approach to establish a landslide displacement forecasting model based on artificial neural networks (ANNs) with random hidden weights. To quantify the uncertainty associated with the predictions, a framework for probabilistic forecasting of landslide displacement is developed. The aim of this paper is to construct prediction intervals (PIs) instead of deterministic forecasting. A lower-upper bound estimation (LUBE) method is adopted to construct ANN-based PIs, while a new single hidden layer feedforward ANN with random hidden weights for LUBE is proposed. Unlike the original implementation of LUBE, the input weights and hidden biases of the ANN are randomly chosen, and only the output weights need to be adjusted. Combining particle swarm optimization (PSO) and gravitational search algorithm (GSA), a hybrid evolutionary algorithm, PSOGSA, is utilized to optimize the output weights. Furthermore, a new ANN objective function, which combines a modified combinational coverage width-based criterion with one-norm regularization, is proposed. Two benchmark data sets and two real-world landslide data sets are presented to illustrate the capability and merit of our method. Experimental results reveal that the proposed method can construct high-quality PIs.	benchmark (computing);clinical prediction rule;combinational logic;displacement mapping;dynamical system;entity name part qualifier - adopted;evolutionary algorithm;feedforward neural network;gnas wt allele;geology;global storage architecture;interval arithmetic;landslides;loss function;manifold regularization;mathematical optimization;neural networks;optimization problem;particle swarm optimization;projections and predictions;psychologic displacement;randomness;search engine;search algorithm;weight;width	Cheng Lian;Zhigang Zeng;Wei Yao;Huiming Tang;C. L. Philip Chen	2016	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2015.2512283	estimation;simulation;uncertainty;forecasting;computer science;suicide prevention;artificial intelligence;human factors and ergonomics;injury prevention;machine learning;data mining;mathematics;statistics	ML	11.917199474609205	-22.470818276550265	183694
08e3669d2909df378debbd1b0587c90660154d84	dynamic difficulty for checkers and chinese chess	computers;prediction algorithms;materials;heuristic algorithms;games;humans;computer games;synthetic opponent checkers chinese chess sound algorithm computer games partially ordered set master algorithm board games;weapons;games heuristic algorithms prediction algorithms computers humans weapons materials	We investigate the practical effectiveness of a theoretically sound algorithm for dynamic difficulty adjustment in computer games: Firstly, we show how the partially ordered set master (Posm) algorithm [11] can be incorporated in board games, taking checkers and Chinese chess as examples. Secondly, we describe an empirical study of (i) Posm on checkers against synthetic opponents of varying strength, (ii) Posm on chinese chess against synthetic opponents of varying strength, and (iii) Posm on Chinese chess against human opponents of varying strength. Our results indicate that Posm can indeed serve as a flexible and effective subroutine for dynamical difficulty adjustment in computer games.	algorithm;experiment;pc game;randomness;subroutine;synthetic intelligence;vii	Laurentiu Ilici;Jiaojian Wang;Olana Missura;Thomas Gärtner	2012	2012 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2012.6374138	games;simulation;bitboard;prediction;turns, rounds and time-keeping systems in games;computer science;artificial intelligence;machine learning;statistics	Vision	17.58326203317442	-17.569281149678886	183815
23c9cfb66f3972c50a82d5fe4f7cad9eadab6699	structural and parametric evolution of continuous-time recurrent neural networks	topology;evolutionary computation;neuroevolution;neural networks;evolutionary algorithms continuous time recurrent neural networks neuroevolutionary methods neural network topologies;biological system modeling;evolving neural networks;genetic algorithms neuroevolution neural networks;network topology;recurrent neural nets evolutionary computation;artificial neural networks;biological cells;neuroevolutionary methods;continuous time recurrent neural networks;next generation;mathematical model;evolutionary algorithms;recurrent neural networks neurons network topology biological system modeling neural networks biomedical engineering artificial neural networks evolution biology physiology biophysics;genetic algorithm;genetic algorithms;recurrent neural nets;neurons;evolutionary algorithm;neural network topologies;continuous time recurrent neural network;neural network	Neuroevolution comprehends the class of methods responsible for evolving neural network topologies and weights by means of evolutionary algorithms. Despite their good performance in several control tasks, most of these methods use variations of simple sigmoidal neurons. Recent investigations have shown the potential applicability of more realistic neuron models, opening new perspectives for the next generation of neuroevolutionary methods. This work aims to extend a recent method known as NEAT to evolve continuous-time recurrent neural networks (CTRNNs). The proposed model is compared with previous methods on a control benchmark test. Preliminary results reveal some advantages when evolving general CTRNNs over traditional models.	artificial neural network;benchmark (computing);evolutionary algorithm;network topology;neuroevolution of augmenting topologies;neuron;recurrent neural network;sigmoid function	Cesar Gomes Miguel;Carolina Feher da Silva;Márcio Lobo Netto	2008	2008 10th Brazilian Symposium on Neural Networks	10.1109/SBRN.2008.12	genetic algorithm;computer science;bioinformatics;artificial intelligence;machine learning;artificial neural network	ML	15.736810115680605	-23.565499935756588	183833
20b52ca3f80b9e262d5d6af7141b47d12fafb69b	estimating the odds for texas hold'em poker agents	average hand strength computer poker hand probabilities abstraction hand strength;game theory;hand probabilities;risk management;abstraction;software agents computer games game theory risk management;software agents;computer poker;average hand strength;game playing algorithms texas hold em poker agents software agents incomplete information games hidden information risk management opponent gameplay estimation expected hand strength hand potential benchmark tests average rank strength method ars method game abstraction strategy computation;games indexes table lookup heating history artificial intelligence software agents;computer games;hand strength	Developing software agents that play incomplete information games is a demanding task: it is required they incorporate strategies capable of dealing with hidden information and deception and risk management. In Poker, these issues are commonly addressed by estimating opponents' game play using a variety of techniques such as Expected Hand Strength (E[HS]) or Hand Potential. In this paper, we propose criteria which can be applied when assessing such techniques, and we have also run benchmark tests which demonstrate their pertinence. We have, however, been faced with a clear gap in terms of the methods' efficiency. While this is not a problem in theoretical models, when implementing such methods in real world applications, they can prove to be painfully slow. In order to address this issue, we propose the Average Rank Strength (ARS) method. It can calculate the strength of a hand of any size through the hand's rank width negligible error, when compared to the original method. Still, the greatest contribution of this method lies in the speed-up factor of about 1000 times over E[HS]. Since most successful agents in the literature use their game abstraction based on E[HS], this breakthrough will significantly contribute towards a much lighter strategy computation, since this routine must be called billions of times. By saving computation time, we believe that future integration of ARS with current game playing algorithms will allow for creating agents with smaller abstraction levels, thus making room for improvement in their overall performance.	algorithm;benchmark (computing);computation;relevance;risk management;software agent;time complexity	Luís Filipe Teófilo;Luís Paulo Reis;Henrique Lopes Cardoso	2013	2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)	10.1109/WI-IAT.2013.134	simulation;computer science;artificial intelligence;game mechanics;machine learning	AI	18.773725859932835	-17.922136516725743	183915
c713c716c43d08f72c51eb41499fa85e51bead80	a coevolutionary approach to learn animal behavior through controlled interaction	turing test;interaction;science automation;animal behavior;coevolution;evolutionary robotics;artificial life	This paper proposes a method that allows a machine to infer the behavior of an animal in a fully automatic way. In principle, the machine does not need any prior information about the behavior. It is able to modify the environmental conditions and observe the animal; therefore it can learn about the animal through controlled interaction. Using a competitive coevolutionary approach, the machine concurrently evolves animats, that is, models to approximate the animal, as well as classifiers to discriminate between animal and animat. We present a proof-of-concept study conducted in computer simulation that shows the feasibility of the approach. Moreover, we show that the machine learns significantly better through interaction with the animal than through passive observation. We discuss the merits and limitations of the approach and outline potential future directions.	animat;approximation algorithm;computer simulation	Wei Li;Melvin Gauci;Roderich Groß	2013		10.1145/2463372.2465801	turing test;interaction;simulation;coevolution;computer science;artificial intelligence;machine learning;evolutionary robotics;artificial life	AI	17.255915989144647	-21.742631895067795	184038
8b2c530ca4d3d5f265a4446aa8cdd8624fc56a48	prediction of manufacturing plant's electric power using machine learning		In this paper, we apply the data accumulated through E-IOT platform to machine learning method to find significant variables first and predict the electric power generated in manufacturing process by using these variables. Pre-processing such as resampling of data was carried out before the prediction. In order to select the significant variables, 25 variables were derived using Lasso (least absolute shrinkage and selection operator), one of the machine learning techniques. We used Deep Learning's LSTM technique, one of the field of machine learning for the prediction.	deep learning;lasso;least squares;long short-term memory;machine learning;resampling (statistics)	Kyoe-Rae Yeom;Hyo-Sub Choi	2018	2018 Tenth International Conference on Ubiquitous and Future Networks (ICUFN)	10.1109/ICUFN.2018.8436973	operator (computer programming);lasso (statistics);electric power system;deep learning;electric power;feature extraction;linear regression;resampling;computer science;machine learning;artificial intelligence	ML	10.210313402510586	-22.295112114772508	184926
c6388a51994426afc50452e2b3d9065c9c0a3584	classification of disturbance records in power stations based on fuzzy reasoning	fuzzy rules disturbance records classification power stations fuzzy reasoning power generation utilities digital fault recorders dfr fuzzy classification system dfr phasor records fuzzy inference system fuzzyfied input variables;generators;expert systems;fuzzy systems expert systems generators fuzzy logic power generation feature extraction educational institutions;power stations fuzzy reasoning fuzzy set theory pattern classification power engineering computing power generation faults;fuzzy logic;feature extraction;power generation;fuzzy systems	Nowadays, it is a common practice in power generation utilities to monitor the generation units using Digital Fault Recorders (DFRs). In general, the disturbance records are stored at the utility central office or control center, leading to a substantial amount of data that in practice is not analysed in its totality. This paper describes a methodology to deal with this problem by proposing a fuzzy classification system. From the DFR phasor records, currents and voltages sampled signal are extracted. The data is processed in order to calculate some meaningful features that are applied to a fuzzy inference system. The fuzzyfied input variables are processed by fuzzy rules which emulate the engineers reasoning at the control center. The output of the fuzzy system indicate which kind of disturbance occurred and what is its degree of pertinence. The proposed methodology enables an automated pre-classification of the DFR data helping the engineers by focusing their attention to the most relevant occurrences. Related studies show that approximately 95% of the disturbance records can be automatically archived because they result from normal operational procedures. The results obtained by using real disturbance records show that the proposed scheme is able to correctly classify the occurrences and also to generalize the result from situations not directly represented in the rule set.	algorithm;archive;divergence-from-randomness model;fuzzy classification;fuzzy control system;fuzzy logic;fuzzy rule;inference engine;online and offline;phasor;relevance;rule-based system;shutdown (computing)	Miguel Moreto;Dionatan A. G. Cieslak;Jacqueline G. Rolim	2014	2014 Power Systems Computation Conference	10.1109/PSCC.2014.7038367	control engineering;fuzzy electronics;defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;engineering;artificial intelligence;fuzzy number;neuro-fuzzy;data mining;fuzzy set operations;fuzzy control system	AI	11.29696905518021	-14.268544457769899	185033
4faf71b3b8e9fee7fca104fc62ef2ba1291942c8	approaching biomimetics: optimization of resource use in buildings using a system dynamics modeling tool	net zero building;system dynamics;stella;ecomimetics;biomimetics;biomimicry	The biomimetic field in architecture is developing tools for transferring processes and functions from biological systems to buildings. Buildings, like ecosystems, are dynamic and complex systems, thus studying their dynamics from a systems thinking perspective might bring insight to some environmental problems. STELLA®, a software commonly used to model environmental dynamics, was used to identify approaches for energy optimization in the Great River Energy Building. Long-term energy flows and thermal properties of the building were modeled to understand the feedback loops that control the behavior of the building system. The simulation showed that optimization of passive building parameters produced considerable energy savings, but more active strategies would be necessary to make the Great River Energy building a net-zero energy building. This exercise showed how the STELLA® software can represent the dynamic behavior of buildings as well as the dynamic behavior of environmental systems, and the potential of this tool for biomimetic research in architecture.	biomimetics;mathematical optimization;system dynamics	Mercedes Garcia-Holguera;Grant Clark;Aaron Sprecher;Susan Gaskin	2015			structural engineering;simulation;engineering;building science	Robotics	11.981281651302734	-18.06219352831808	185095
239a245b99d62bba7428bb8a40ef0c29d7c3a137	leak localization in water distribution networks using model-based bayesian reasoning	leak localization;model based;bayesian reasoning;water distribution networks;fault diagnosis	This paper presents a new method for leak localization in Water Distribution Networks that uses a model-based approach combined with Bayesian reasoning. Probability density functions in model-based pressure residuals are calibrated off-line for all the possible leak scenarios by using a hydraulic simulator, being leak size uncertainty, demand uncertainty and sensor noise considered. A Bayesian reasoning is applied online to the available residuals to determine the location of leaks present in the Water Distribution Network. A time horizon method combined with the Bayesian reasoning is also proposed to improve the accuracy of the leak localization method. The Hanoi District Metered Area case study is used to illustrate the performance of the proposed approach.	bayesian network;image noise;naive bayes classifier;online and offline;portable document format;simulation	Adria Soldevila;Rosa M. Fernández-Cantí;Joaquim Blesa;Sebastian Tornil-Sin;Vicenç Puig	2016	2016 European Control Conference (ECC)	10.1109/ECC.2016.7810545	simulation;engineering;machine learning;data mining	Robotics	11.732660916421862	-16.687742008874487	185426
ad2c9e92a5e3a2d7ac947a563b93e34105036302	please be an influencer?: contingency-aware influence maximization		Most previous work on influence maximization in social networks assumes that the chosen influencers (or seed nodes) can be influenced with certainty (i.e., with no contingencies). In this paper, we focus on using influence maximization in public health domains for assisting low-resource communities, where contingencies are common. It is very difficult in these domains to ensure that the seed nodes are influenced, as influencing them entails contacting/convincing them to attend training sessions, which may not always be possible. Unfortunately, previous state-of-the-art algorithms for influence maximization are unusable in this setting. This paper tackles this challenge via the following four contributions: (i) we propose the Contingency Aware Influence Maximization problem and analyze it theoretically; (ii) we cast this problem as a Partially Observable Markov Decision Process and propose CAIMS (a novel POMDP planner) to solve it, which leverages a natural action space factorization associated with real-world social networks; and (iii) we provide extensive simulation results to compare CAIMS with existing state-of-the-art influence maximization algorithms. Finally, (iv) we provide results from a real-world feasibility trial conducted to evaluate CAIMS, in which key influencers in homeless youth social networks were influenced in order to spread awareness about HIV. ACM Reference Format: Amulya Yadav∗, Ritesh Noothigattu, Eric Rice, Laura Onasch-Vera, Leandro Soriano Marcolino, and Milind Tambe. 2018. Please be an Influencer? Contingency-Aware Influence Maximization. In Proc. of the 17th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2018), Stockholm, Sweden, July 10–15, 2018, IFAAMAS, 9 pages.	autonomous agents and multi-agent systems;emoticon;entropy maximization;expectation–maximization algorithm;international conference on autonomous agents and multiagent systems;markov chain;partially observable markov decision process;simulation;social network;usability;eric	Amulya Yadav;Ritesh Noothigattu;Eric Rice;Laura Onasch-Vera;Leandro Soriano Marcolino;Milind Tambe	2018			computer science;contingency;machine learning;artificial intelligence;influencer marketing;social network;partially observable markov decision process;maximization	DB	19.188025448000776	-15.441683456870058	185575
5a5bfd03f6c3f576e13cf48e633deb459068e61c	robot coverage control by evolved neuromodulation	evolutionary grn models evolved neuromodulation baldwin effect evolutionary search process reinforcement learning agents robot coverage control problem evolving neuromodulatory gene regulatory networks neuromodulatory grn;proteins robots learning artificial intelligence evolution biology training neurons biological system modeling;evolutionary computation;search problems evolutionary computation learning artificial intelligence mobile robots neurocontrollers;mobile robots;search problems;neurocontrollers;learning artificial intelligence	An important connection between evolution and learning was made over a century ago and is now termed as the Baldwin effect. Learning acts as a guide for an evolutionary search process. In this study reinforcement learning agents are trained to solve the robot coverage control problem. These agents are improved by evolving neuromodulatory gene regulatory networks (GRN) that influence the learning and memory of agents. Agents trained by these neuromodulatory GRNs can consistently generalize better than agents trained with fixed parameter settings. This work introduces evolutionary GRN models into the context of neuromodulation and illustrates some of the benefits that stem from neuromodulatory GRNs.	gene regulatory network;neuromodulation (medicine);reinforcement learning;robot	Kyle Ira Harrington;Emmanuel Awa;Sylvain Cussat-Blanc;Jordan B. Pollack	2013	The 2013 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2013.6706784	mobile robot;simulation;computer science;artificial intelligence;machine learning;evolutionary computation	AI	17.053050599770483	-22.852316074452105	185805
acc09a7a95747c56cd5f4ebd37bee522cfba45e9	comparing two data driven interpolation methods for modeling nitrate distribution in aquifer	performance evaluation;interpolation method;spatial interpolation;nitrate;groundwater;kriging;fuzzy model;fuzzy estimation;pollution	As a soluble compound in water, nitrate could easily pass through soil to the groundwater. In recent decades, nitrate pollution of groundwater has been increased mainly as a result of excessive application of fertilizers in agricultural areas. Appraisal of nitrate distribution in aquifers is not a new problem but it is still unsolved. This paper compares the performances of two modeling approaches such as geostatistical (kriging) and soft (fuzzy) computing in spatial interpolation of nitrate concentration in groundwater. For this purpose, the groundwater samples are collected from springs and wells in Mersin–Tarsus Aquifer to be considered. The estimation models are established based on data driven modeling concept. The results and performance evaluations indicate that the estimation capacity of the fuzzy model is higher than that of the kriging model.	adaptive neuro fuzzy inference system;fuzzy logic;fuzzy rule;interpolation;kriging;logic programming;smoothing;soft computing;sugeno integral	Bülent Tütmez;Zubeyde Hatipoglu	2010	Ecological Informatics	10.1016/j.ecoinf.2009.08.001	pollution;groundwater;mathematics;multivariate interpolation;kriging;statistics	Robotics	10.981699130262788	-19.876911544715018	186041
8216940d1933152f0b71e087a6295d77e2fd9738	genetic learning of fuzzy reactive controllers	robot movil;fuzzy controller;control difusa;learning;autonomous system;fuzzy control;logique floue;logica difusa;robotics;algoritmo genetico;sistema autonomo;genetics;aprendizaje;fuzzy logic;apprentissage;robot mobile;systeme autonome;algorithme genetique;robotica;genetic algorithm;robotique;autonomous robot;moving robot;commande floue	This paper concerns tdae learning of basic behaviors in an autonomous robot. It presents a method to adapt basic reactive behaviors using a genetic algorithm. Behaviors are implemented as fuzzy controllers and the genetic algorithm is used to evolve their rules. These rules will be formulated in a fuzzy way using prefixed linguistic labels. In order to test the rules obtained in each generation of the genetic evolution process, a real robot has been used. Numerical results from the evolution rate of the different experiments, as well as an example of the fuzzy rules obtained, are presented and discussed. © 1998 Elsevier Science B.V. All rights reserved.	artificial life;autonomous robot;computer science;emergence;entropy (information theory);evolutionary computation;experiment;fuzzy concept;fuzzy logic;fuzzy rule;genetic algorithm;high-level programming language;intelligent agent;khepera mobile robot;machine learning;mathematical optimization;numerical method	Vicente Matellán Olivera;Camino Fernández;José M. Molina López	1998	Robotics and Autonomous Systems	10.1016/S0921-8890(98)00035-9	fuzzy logic;genetic algorithm;defuzzification;computer science;autonomous system;artificial intelligence;fuzzy number;neuro-fuzzy;fuzzy associative matrix;robotics;fuzzy set operations	AI	23.101275091710743	-12.6200190148255	186103
2c8a2e1f6b68fc007107b8e41ddc511a005ef10b	condition multi-classification and evaluation of system degradation process using an improved support vector machine		Article history: Received 5 January 2017 Received in revised form 14 March 2017 Accepted 20 March 2017 Available online xxxx Degradation process is a non-negligible phenomenon in system condition monitoring and reliability practices. Traditional binary-state characterization (i.e., normal and failure) on system health condition may not provide accurate information for maintenance scheduling, and the multi-state classification for degradation process is a necessary step to realize cost-effective condition based maintenance. Support vector machine (SVM) is a useful technique for system condition monitoring and fault diagnosis. However, the SVM classification accuracy of deteriorating system is usually poor, because characteristics of different degradation statesmay not be very distinctive. This paper presented an improved support vector machine for system degradation classification and evaluation. The core of the proposed method can be summarized as: an improved voting scheme in oneagainst-one SVM, and an optimization of classification process by utilizing inherent physical property of system state transition. A case study of cooling fan bearing accelerated life time test is conducted to obtain the experimental data, and a comparison before and after optimization shows that the proposedmethod improves the classification accuracy. © 2017 Elsevier Ltd. All rights reserved.	computer cooling;elegant degradation;highly accelerated life test;mathematical optimization;scheduling (computing);support vector machine	Qiang Miao;Xin Zhang;Zhiwen Liu;Heng Zhang	2017	Microelectronics Reliability	10.1016/j.microrel.2017.03.020	reliability engineering;engineering;data mining;forensic engineering	AI	13.12810561334723	-17.27890436244994	186172
89eab8fdca20e1b30fd01a24083b79301a9460b8	recognition of rainstorm field in flood discharge of high dam based on neural network	forecasting;structural engineering dams floods hydroelectric power stations neural nets pattern recognition rain;hydro project rainstorm field;hydroelectric power stations;high dam;flood discharge;neural nets;pattern recognition model;training;dams;rainstorm field pattern recognition neural network high dam atomization;mechanics model;artificial neural networks;atomization range;computational modeling;rainstorm field;structural engineering;mathematical model;atomization;rain;pattern recognition;neural networks floods numerical simulation prototypes pattern recognition artificial intelligence artificial neural networks civil engineering wind forecasting process design;mechanics model flood discharge high dam neural network atomized flow forecasting atomization range hydro project rainstorm field pattern recognition model;floods;neural network model;numerical models;atomized flow;discharges;two phase flow;neural network;numerical simulation	Atomization in flood discharge of high dam is a serious and complicated problem which belongs to the research field of water-air and air-water two phase flow. The motion of atomized flow is restricted by water head, discharge and operation scheme and affected by environmental wind and terrain. Numerical simulation is the main method of forecasting the range of atomization. Neural network as a new method in this study has the identities of distribution and nonlinearity which very adapt to simulate the behavior of atomized flow. In design and operation process of a hydro project rainstorm field of the atomization is the main range ensuring the security of the project. In this paper a pattern recognition model of rainstorm field based on neural network is constructed and trained by prototype data. Finally the rainstorm fields of two hydro projects in designing are computed and the results are in comparison with those of mechanics model. The comparison result shows the neural network model can predict the rainstorm field quickly with acceptable accuracy.	artificial neural network	Fang Liu;Caiyuan Huang	2009		10.1109/JCAI.2009.19	forecasting;computer science;machine learning;mathematical model;two-phase flow;computational model;artificial neural network	ML	11.161924031525034	-20.758112436669666	186376
c7b67d7a11242a958e9a80a62ed527ab6ecb2f36	sunny: a lazy portfolio approach for constraint solving	constraint satisfaction;machine learning;artificial intelligence;algorithms portfolio	*** To appear in Theory and Practice of Logic Programming (TPLP) *** Within the context of constraint solving, a portfolio approach allows one to exploit the synergy between different solvers in order to create a globally better solver. In this paper we present SUNNY: a simple and flexible algorithm that takes advantage of a portfolio of constraint solvers in order to compute — without learning an explicit model — a schedule of them for solving a given Constraint Satisfaction Problem (CSP). Motivated by the performance reached by SUNNY vs. different simulations of other state of the art approaches, we developed sunny-csp, an effective portfolio solver that exploits the underlying SUNNY algorithm in order to solve a given CSP. Empirical tests conducted on exhaustive benchmarks of MiniZinc models show that the actual performance of sunny-csp conforms to the predictions. This is encouraging both for improving the power of CSP portfolio solvers and for trying to export them to fields such as Answer Set Programming and Constraint Logic Programming.	algorithm;answer set programming;association for logic programming;constraint logic programming;constraint programming;constraint satisfaction problem;lazy evaluation;simulation;solver;stable model semantics;synergy	Roberto Amadini;Maurizio Gabbrielli;Jacopo Mauro	2014	TPLP	10.1017/S1471068414000179	constraint logic programming;concurrent constraint logic programming;mathematical optimization;constraint programming;constraint satisfaction;computer science;artificial intelligence;machine learning;algorithm	AI	19.22061386349065	-10.14907731749142	186450
bcaa949af79640fef95fa4a3acfad7f0d3f3a3ac	learning to play pong video game via deep reinforcement learning		We consider deep reinforcement learning algorithms for playing a game based on the video input. We discuss choosing proper hyperparameters in the deep Q-network model and compare with the modelfree episodic control focused on reusing of successful strategies. The evaluation was made based on the Pong video game implemented in Unreal Engine 4.	algorithm;machine learning;network model;reinforcement learning;unreal development kit	Ilya Makarov;Andrej Kashin;Alisa Korinevskaya	2017				AI	19.71862900599978	-20.6243851489521	186568
6aa688178e880c6870e2751922f6215ead82dbc4	bayesian networks approach for a fault detection and isolation case study	bayesian network;fault detection and isolation;performance indicator;dynamic model;multilayer perceptron;working conditions;input output;mlp neural network;dynamic bayesian network;hydraulic actuator	This paper presents a Fault Detection and Isolation (FDI) approach based on the use of Hybrid Dynamic Bayesian Networks (HDBN). The peculiarity of the proposed approach is that an analytical dynamic model of the process to be monitored is not required. Instead it is hypothesized that input/output measures performed on the considered process during different working conditions, including faults, are available. In the paper the proposed FDI approach is described and the performances are evaluated on synthetic and real data supplied by a standard benchmark consisting of an hydraulic actuators available in literature. The goodness of the proposed approach is assessed by using appropriate performance indices. An intercomparison between the BN approach and an other approach, namely a Multilayer Perceptron (MLP) neural network is given. Results show that the BN approach outperforms the MLP approach in some indices but it requires a high design and computational effort.	artificial neural network;benchmark (computing);computation;dhrystone;dynamic bayesian network;fault detection and isolation;input/output;mathematical model;memory-level parallelism;multilayer perceptron;performance;quad flat no-leads package;simulink	Giuseppe Nunnari;Flavio Cannavó;R. Vrânceanu	2004		10.1007/3-540-31662-0_14	control engineering;input/output;probabilistic neural network;hydraulic cylinder;computer science;engineering;performance indicator;machine learning;bayesian network;control theory;multilayer perceptron;fault detection and isolation;dynamic bayesian network	SE	13.245486592735555	-17.77955948019737	187156
0c8c5e91e6ff5ed8df2674f4c63e8896d722fadd	near-optimal regret bounds for reinforcement learning	rein forcement learning;learning algorithm;reinforcement learning;optimal policy;markov decision process;lower bound	For undiscounted reinforcement learning in Markov decisio n processes (MDPs) we consider the total regret of a learning algorithm with respect to an optimal policy. In order to describe the transition structure of an MDP we propose a new parameter: An MDP hasdiameter Dif for any pair of statess,s′ there is a policy which moves froms to s′ in at mostD steps (on average). We present a reinforcement learning algorithm with total re gret Õ(DS √ AT) afterT steps for any unknown MDP withSstates,A actions per state, and diameter D. A corresponding lower bound of Ω( √ DSAT) on the total regret of any learning algorithm is given as well . These results are complemented by a sample complexity bound n the number of suboptimal steps taken by our algorithm. This bound can be used to achiev e a (gap-dependent) regret bound that is logarithmic inT. Finally, we also consider a setting where the MDP is allowed t o change a fixed number of l times. We present a modification of our algorithm that is able to deal with this setting and show a regret bound of Õ(l1/3T2/3DS √ A).	algorithm;markov chain;regret (decision theory);reinforcement learning;sample complexity	Peter Auer;Thomas Jaksch;Ronald Ortner	2008			markov decision process;mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;upper and lower bounds;reinforcement learning;q-learning	ML	22.345194023088027	-17.370245681675765	187192
45ce3fdf5a25944972f7e814d322bdacf2128357	reliability analysis and comparison between automatic and manual load haul dump machines	underground mining;reliability;maintenance;load haul dump lhd machines;automation	Today's trend of replacing manually operated vehicles with automated ones will have an impact not only on machine design, working environment and procedures but also on machine breakdown and maintenance procedures. In the harsh environment of underground mines, the transition from manual to automatic operation is believed to fundamentally change the basis for break downs, maintenance and machine design. In this paper, differences and similarities between manual and automatic underground loading equipment is analysed from a reliability point of view. The analysis is based on a case study performed at a Swedish underground mine. In the contrary of common thoughts, this paper proves that there is a difference between the manual and semi-automatic machines and in particular for the transmission, in favour of the manual one. This paper also shows a path for detailed reliability analysis, and the results may be used for improving maintenance programmes for other types of mobile equipment. Copyright © 2013 John Wiley & Sons, Ltd.	reliability engineering	Anna Gustafson;Håkan Schunnesson;Uday Kumar	2015	Quality and Reliability Eng. Int.	10.1002/qre.1610	underground mining;engineering;operations management;automation;reliability;mathematics;forensic engineering;operations research;engineering drawing;statistics	HPC	11.900548924466193	-11.122393347298	187285
a75f6872cfdab348f35d23179701d1ed02fc1a07	simulating the seismic response of embankments via artificial neural networks	science and technology;design process;soft computing;earthquake engineering;seismic response;finite element method;artificial neural networks;embankments;dynamic response;material nonlinearity;artificial neural network	Geotechnical earthquake engineering may generally be considered as an u0027u0027impreciseu0027u0027 scientific area due to the unavoidable uncertainties and the simplifications adopted during the design process of geostructures. Therefore, relatively accurate predictions using advanced soft computing (SC) techniques can be tolerated rather than solving a problem conventionally. Artificial neural networks (ANNs), being one of the most popular SC techniques, have been used in many fields of science and technology, as well as, into an increasing number of earthquake engineering applications on structures and infrastructures. In this work the implementation of ANNs is focused on the simulation of the seismic response of a typical embankment. The dynamic response of the embankment is evaluated utilizing the finite-element method, where the nonlinear behavior of the geo-materials can be taken into account by an equivalent-linear procedure. In the present study, this extremely time-consuming process is replaced by properly trained ANNs.	algorithmic efficiency;approximation algorithm;artificial neural network;computation;dynamic loading;finite element method;hardware acceleration;mit engineering systems division;marginal model;metamodeling;nonlinear system;pin grid array;simulation;test set	Yiannis Tsompanakis;Nikos D. Lagaros;Prodromos N. Psarropoulos;Evaggelos C. Georgopoulos	2009	Advances in Engineering Software	10.1016/j.advengsoft.2008.11.005	design process;computer science;engineering;artificial intelligence;civil engineering;machine learning;finite element method;geotechnical engineering;artificial neural network;science, technology and society	AI	12.09133677872121	-23.13279510050562	187465
ac0c2d9aa9311012b402875faef15f6a1b14ddba	performance updating of concrete bridges using proactive health monitoring methods	reliability;maintenance and repair;bayesian methods;bayesian method;health monitoring;deterioration;concrete bridges;chlorides	Uncertainties associated with modelling of deteriorating bridges strongly affect management decisions, such as inspection, maintenance and repair actions. These uncertainties can be reduced by the effective use of health monitoring systems, through which information regarding in situ performance can be incorporated in the management of bridges.#R##N##R##N#The objectives of this paper are twofold; first, an improved chloride induced deterioration model for concrete bridges is proposed that can quantify degradation in performance soon after chlorides are deposited on the bridge, rather than when initiation of corrosion at the reinforcement level takes place. As a result, the implications of introducing proactive health monitoring can be assessed using probabilistic durability criteria. Thus, the second objective of the paper is to present a methodology for performance updating of deteriorating concrete bridges fitted with a proactive health monitoring system.#R##N##R##N#This methodology is illustrated via a simple example of a typical bridge element, such as a beam or a part of a slab. The results highlight the benefits from introducing ‘smart’ technology in managing bridges subject to deterioration, and quantify the reduction in uncertainties and their subsequent effect on predictions of future bridge performance.		M. Imran Rafiq;Marios K. Chryssanthopoulos;Toula Onoufriou	2004	Rel. Eng. & Sys. Safety	10.1016/j.ress.2004.01.012	structural engineering;reliability engineering;bayesian probability;engineering;mathematics;forensic engineering;statistics	SE	13.11113477567871	-11.045700558934598	187479
0c316cfd1cfee9ac10c02e20c9c845b9266008f1	application of temperature prediction based on neural network in intrusion detection of iot		The security of network information in the Internet of Things faces enormous challenges. The traditional security defense mechanism is passive and certain loopholes. Intrusion detection can carry out network security monitoring and take corresponding measures actively. The neural network-based intrusion detection technology has specific adaptive capabilities, which can adapt to complex network environments and provide high intrusion detection rate. For the sake of solving the problem that the farmland Internet of Things is very vulnerable to invasion, we use a neural network to construct the farmland Internet of Things intrusion detection system to detect anomalous intrusion. In this study, the temperature of the IoT acquisition system is taken as the research object. It has divided which into different time granularities for feature analysis. We provide the detection standard for the data training detection module by comparing the traditional ARIMA and neural network methods. Its results show that the information on the temperature series is abundant. In addition, the neural network can predict the temperature sequence of varying time granularities better and ensure a small prediction error. It provides the testing standard for the construction of an intrusion detection system of the Internet of Things.		Xuefei Liu;Chao Zhang;Pingzeng Liu;Maoling Yan;Baojia Wang;Jianyong Zhang;Russell Higgs	2018	Security and Communication Networks	10.1155/2018/1635081	computer science;computer network;mean squared prediction error;artificial neural network;network security;complex network;research object;intrusion;intrusion detection system;internet of things	ML	11.879820543160337	-16.52971419394056	187480
af1f3828fe65fc088de551aefd8bda93a7c4266e	deterministic policy optimization by combining pathwise and score function estimators for discrete action spaces		Policy optimization methods have shown great promise in solving complex reinforcement and imitation learning tasks. While model-free methods are broadly applicable, they often require many samples to optimize complex policies. Modelbased methods greatly improve sample-efficiency but at the cost of poor generalization, requiring a carefully handcrafted model of the system dynamics for each task. Recently, hybrid methods have been successful in trading off applicability for improved sample-complexity. However, these have been limited to continuous action spaces. In this work, we present a new hybrid method based on an approximation of the dynamics as an expectation over the next state under the current policy. This relaxation allows us to derive a novel hybrid policy gradient estimator, combining score function and pathwise derivative estimators, that is applicable to discrete action spaces. We show significant gains in sample complexity, ranging between 1.7 and 25×, when learning parameterized policies on Cart Pole, Acrobot, Mountain Car and Hand Mass. Our method is applicable to both discrete and continuous action spaces, when competing pathwise methods are limited to the latter.	action potential;approximation;east pole–west pole divide;gradient;linear programming relaxation;mathematical optimization;mountain car;sample complexity;spaces;system dynamics	Daniel Levy;Stefano Ermon	2018			artificial intelligence;estimator;computer science;machine learning;sample complexity;system dynamics;mathematical optimization;parameterized complexity;score;ranging	AI	22.19833764189074	-18.708930316937053	187789
f472e106e8bcf9458e08925b818a2b1a5af19e08	approximate bayesian computation of the occurrence and size of defects in advanced gas-cooled nuclear reactor boilers	nuclear safety;approximate bayesian computation;size and detection;modelling of crack initiation	A campaign of visual inspections was undertaken in 2014 on a specific component of thirty-two Advanced Gas-cooled nuclear Reactor boilers at Hartlepool and Heysham A power stations, as a consequence of an anomalous reading previously obtained in a routine ultrasonic test. While the presence of a crack in Heysham A boiler 1D1 was confirmed, no further defect was detected; not all components could be inspected in all of their eight sections (octants), however, because of the very unfavourable conditions in which the work had to be performed. The occurrence and size of defects in the uninspected octants are here inferred on the basis of models of crack initiation and growth fitted, by Approximate Bayesian Computation, to the results of the campaign. The probability of failure of one or more components in an extreme seismic event is also inferred.	computation;reactor (software)	Paolo Mason	2016	Rel. Eng. & Sys. Safety	10.1016/j.ress.2015.10.012	econometrics;engineering;forensic engineering;statistics	Logic	12.819028226397378	-14.573403828134445	187944
b27f732cb3fb318afea9aff93b9ca72752870252	shapelet-based remaining useful life estimation	shapelet based remaining useful life estimation machine learning statistical techniques phm training set discriminative patterns test units similarity based approaches discriminative rul shapelet extraction run to failure data shapelet characterization data acquisition critical machinery rul prognostics and health management domain;statistical analysis failure analysis learning artificial intelligence machinery maintenance engineering production engineering computing reliability remaining life assessment;training;time series analysis estimation feature extraction training hidden markov models monitoring equations;hidden markov models;estimation;monitoring;time series analysis;feature extraction	In the Prognostics and Health Management domain, estimating the remaining useful life (RUL) of critical machinery is a challenging task. Various research topics as data acquisition and processing, fusion, diagnostics, prognostivs and decision are involved in this domain. This paper presents an approach for estimating the Remaining Useful Life (RUL) of equipments based on shapelet extraction and characterization. This approach makes use in a first step of an history of run-to-failure data to extract discriminative rul-shapelets, i.e. shapelets that are correlated with the RUL of the considered equipment. A library of rul-shapelets is extracted from this step. Then, in an online step, these rul-shapelets are compared to different test units and the ones that match these units are used to estimate their RULs. This approach is hence different from classical similarity-based approaches that matches the test units with training ones. Here, discriminative patterns from the training set are first extracted and then matched to test units. The performance of our approach is assessed on a data set coming from a previous PHM Challenge. We show that this approach is efficient to estimate the RUL compared to other approaches.	data acquisition;keyword extraction;test set;time series	Simon Malinowski;Brigitte Chebel-Morello;Noureddine Zerhouni	2014	2014 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2014.6899416	engineering;data science;machine learning;data mining	Robotics	14.278398346443232	-15.929963339569932	188125
c532f5c3780b12c03e5804f3fbdef92cfcf46f96	learning policies for resolving demand-capacity imbalances during pre-tactical air traffic management		In this work we propose and investigate the use of collaborative reinforcement learning methods for resolving demand-capacity imbalances during pre-tactical Air Traffic Management. By so doing, we also initiate the study of data-driven techniques for predicting multiple correlated aircraft trajectories; and, as such, respond to a need identified in contemporary research and practice in air-traffic management. Our simulations, designed based on real-world data, confirm the effectiveness of our methods in resolving the demand-capacity problem, even in extremely hard scenarios.	reinforcement learning;simulation	Theocharis Kravaris;George A. Vouros;Christos Spatharis;Konstantinos Blekas;Georgios Chalkiadakis;Jose Manuel Cordero Garcia	2017		10.1007/978-3-319-64798-2_15	computer science;risk analysis (engineering);distributed computing;air traffic management;simulation;extremely hard;reinforcement learning	ML	21.60114721206473	-20.428561685623105	188154
27931d196c6b1c61abb34bb976798adfe19f9429	genetically optimized hybrid fuzzy neural networks based on simplified fuzzy inference rules and polynomial neurons	metodo cuadrado menor;regle inference;methode moindre carre;optimisation;parametric programming;fuzzy neural network;fuzzy neural nets;structure optimization;sistema hibrido;least squares method;optimizacion;polynomial neural network;analisis estructural;programmation parametrique;reseau neuronal flou;least square method;genetics;inference rule;programacion parametrica;fuzzy inference;hybrid system;optimization;parametric optimization;analyse structurale;reseau neuronal;structural analysis;red neuronal;regla inferencia;neural network;systeme hybride;design methodology	We introduce an advanced architecture of genetically optimized Hybrid Fuzzy Neural Networks (gHFNN) and develop a comprehensive design methodology supporting their construction. The gHFNN architecture results from a synergistic usage of the hybrid system generated by combining Fuzzy Neural Networks (FNN) with Polynomial Neural Networks (PNN). As to the consequence part of the gHFNN, the development of the PNN dwells on two general optimization mechanisms: the structural optimization is realized via GAs whereas in case of the parametric optimization we proceed with a standard least square method-based learning.	artificial neural network;polynomial	Sung-Kwun Oh;Byoung-Jun Park;Witold Pedrycz;Tae-Chon Ahn	2005		10.1007/11428831_99	computer science;artificial intelligence;neuro-fuzzy;machine learning;least squares;artificial neural network;algorithm	ML	10.759863908285887	-23.71457544440067	188228
aa239d58c22c345e47ac2e372241ac7aba33c226	a quantified sensitivity measure of radial basis function neural networks to input variation	sensitivity computation quantified sensitivity measure radial basis function neural networks rbfnn numerical integral technique computer simulation;radial basis function neural networks;statistical analysis integral equations learning artificial intelligence radial basis function networks sensitivity analysis;rbfnn;quantified sensitivity measure;integral equations;sensitivity neurons computational modeling artificial neural networks computer architecture function approximation;numerical integral technique;radial basis function networks;computer architecture;sensitivity;artificial neural networks;computational modeling;statistical analysis;function approximation;numerical integration;sensitivity analysis;radial basis function neural network;sensitivity computation;neurons;learning artificial intelligence;computer simulation;neural network	The sensitivity of a neural network's output to its parameter variation is an important issue in both theoretical researches and practical applications of neural networks. This paper proposes a quantified sensitivity measure of the Radial Basis Function Neural Networks (RBFNNs) to input variation. The sensitivity is defined as the mathematical expectation of squared output deviations caused by input variations. In order to quantify the sensitivity, the input is treated as a statistical variable and a numerical integral technique is employed to approximately compute the expectation. Experimental verifications are run and the results show a very good agreement between the proposed sensitivity computation and computer simulation. The quantified sensitivity measure could be helpful as a general tool for evaluating RBFNNs' performance.	computation;computer simulation;neural networks;numerical analysis;radial (radio);radial basis function	Xianming Chen;Xiaoqin Zeng;Rong Chu;Shuiming Zhong	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596949	mathematical optimization;function approximation;sensitivity;numerical integration;computer science;artificial intelligence;machine learning;computational model;sensitivity analysis;integral equation;artificial neural network	EDA	13.386747707088045	-20.835390133173316	188383
3c0da93251e5ce6be27d7381e79fdd53e763faec	eyesee: a machine vision system for inspection of integrated circuit chips	vision system;critical dimension;fabrication;instruments;integrated circuit;machine vision inspection humans instruments testing fabrication microscopy laboratories large scale integration ice;microscopy;testing;very large scale integrated;inspection;chip;large scale integration;machine vision;humans;ice;semiconductor manufacturing	"""A machine vision system for insp&Wg either """"in-process"""" or completed (fully patterndl integratedcircuit (IC) chips hes been demonstrated. Applied to the inspection of a Oarlington IC, the EYESEE system was shown to effeAively r8place a human operator i n performing a fiml inspection task. EYESEE has been extended to inspection of certain Large &le In ation g LSi) and V e r y Large mesurement of line widths and critical dimensions, for measurement of mask ar#8 reticle mlay r8gIstratton accuracy, and for M i o n and i den m o md micro defects. Technical fmsfbility has h for &XJt mat i ng msny icond duct or inspection tesks. A va review of other relevant machine vision techniques used within the semi ambt cr mmufaAuring i n d u s t r y is p r m k l ~ ?YESEE is a trtidmask of SchlumWgw LW. Work performed d Fairchild Lttixratogr for Artificial I n t e l l i g e n c e Research (FLAIR), m Schlumbergw Palo Alto Research Laboratory (SPAR), Palo Alto, GI. * ~ n ~ r ~ ~ u c t ~ ~ n An autamW vision system fur i n s p e c t i o n of pmtially ar been demonstr8ted In tha laboratory. am drerecteri zati on end massuremtmt iticei dimmioras, mask and Mkle registration mrecy, md rmdm and repsting m m (g-oss) or micro (fine) defects. EYESEE im demonstrated, to thesatisfsction of many moillsborators, that wtmatic visual i n s p e c t i o n of t r w s i s b pair IC received . This small scale intsgratlon i ng and l a r g e (several mil) s Corners. """"moets"""", snd anducting analyzed with d i f f m t sets d tests ih ia T h e m tests Ing pads; bridging metel ww junctions; broken moats; and corners. T b multistqe proem allows the system to distinguish between numerw allowable visual m l i e s true defacts. No direct awnparim with an adjmt die GT B die is required In this s y s t e m , although 8 CAQ data base could conceivebly be used in order to more mily @merate the """"map"""" of the die. Inspection of LSI and VLSl &i ces, such 6s a 64K DRAM, required the cbveloppment of addittml image precessing techniques consisting of signs1 segmentation, region p i n g , texture s;lalysis, template matching, autocorrelation, eutomatic fows and illumination control. EYESEE vidso i m q a pramsing technology has reachacl the point where technical fm ib i l i t y has been established for autometing many Sami Mor inspeetion tasks."""	autocorrelation;bridging (networking);database;die (integrated circuit);dynamic random-access memory;integrated circuit;limewire;machine vision;palo;programming in the large and programming in the small;semiconductor industry;template matching;traitorous eight;verification and validation	Michael L. Baird	1985		10.1109/ROBOT.1985.1087249	chip;computer vision;electronic engineering;inspection;machine vision;computer science;engineering;artificial intelligence;integrated circuit;software testing;fabrication;semiconductor device fabrication;engineering drawing;critical dimension;automated optical inspection	Vision	16.607725286211178	-10.177543956457583	188639
0af9178c207c2ecfa5ce48f0f77e4358b0889d2f	partial least-squares algorithm for weights initialization of backpropagation network	feedforward neural network;optimal solution;feedforward neural networks;backpropagation network;partial least square;root mean square error;backpropagation;partial least squares;near infrared;weights initialization	This paper proposes a hybrid scheme to set the weights initialization and the optimal number of hidden nodes of the backpropagation network (BPN) by applying the loading weights and factor numbers of the partial least-squares (PLS) algorithm. The joint PLS and BPN method (PLSBPN) starts with a small residual error, modi6es the latent weight matrices, and obtains a near-global minimum in the calibration phase. Performances of the BPN, PLS, and PLSBPN were compared for the near infrared spectroscopic analysis of glucose concentrations in aqueous matrices. The results showed that the PLSBPN had the smallest root mean square error. The PLSBPN approach signi6cantly solves some conventional problems of the BPN method by providing the good initial weights, reducing the calibration time, obtaining an optimal solution, and easily determining the number of hidden nodes. c © 2002 Elsevier Science B.V. All rights reserved.	algorithm;artificial neural network;backpropagation;business process network;cross-validation (statistics);feedforward neural network;maxima and minima;mean squared error;minimum-weight triangulation;national supercomputer centre in sweden;partial least squares regression;performance	Tzu-Chien Ryan Hsiao;Chii-Wann Lin;Huihua Kenny Chiang	2003	Neurocomputing	10.1016/S0925-2312(01)00708-1	feedforward neural network;mathematical optimization;computer science;artificial intelligence;machine learning;mathematics	AI	12.480302274067599	-20.898840167577585	189228
75741777f159054e5eb0698d800fe11c9cc6cce4	knowledge-inducing interactive genetic algorithms based on multi-agent	modelizacion;fatigue;multiagent system;multi agent system;base de connaissances;fatiga;orientado agente;speed of convergence;intelligence artificielle;oriente agent;algoritmo genetico;calcul analogique;convergence speed;modelisation;agent oriented programming;interactive genetic algorithm;algorithme genetique;velocidad convergencia;evolution strategy;artificial intelligence;algorithme evolutionniste;base conocimiento;genetic algorithm;algoritmo evolucionista;agent oriented;inteligencia artificial;evolutionary algorithm;sistema multiagente;modeling;vitesse convergence;knowledge modeling;systeme multiagent;analog calculus;calculo analogico;knowledge base	Interactive genetic algorithms lack a common model to effectively integrate different assistant evolution strategies including knowledge-based methods and fitness assignment strategies.Aiming at the problems,knowledgebased interactive genetic algorithm based on multi-agent is put forward in the paper combined with the flexibility of multi-agent systems.Five kinds of agents are abstracted based on decomposed-integral strategy of MAS.A novel implicit knowledge model and corresponding inducing strategy are proposed and realized by knowledge-inducing agent.A novel substitution strategy for evaluating fitness by an online model instead of human is proposed and implemented in fitness-estimation agent.State-switch conditions of above agents are given using agent-oriented programming. Taking fashion design system as a testing platform, the rationality of the model and the effective of assistant evolution strategies proposed in the paper are validated. Simulation results indicate this algorithm can effectively alleviate users’ fatigue and improve the speed of convergence.		Yi-Nan Guo;Jian Cheng;Dun-Wei Gong;Ding-quan Yang	2006		10.1007/11881070_101	knowledge base;simulation;systems modeling;genetic algorithm;computer science;artificial intelligence;evolutionary algorithm;evolution strategy;algorithm	AI	23.070844971979398	-11.436646611923997	189305
435cf33cfd9ba5be1f0876d109261217ebf73030	medium and long term power load forecasting using cpso-gm model	power load forecasting;grey model;co evolution;particle swarm optimization	To overcome the low precision of the basic grey model (GM) in forecasting power loads of medium and longterm, a co-evolutionary particle swarm optimization (CPSO) Grey Model (CPSO-GM) is proposed in this paper. This is done by employing the CPSO to optimize the parameters of the grey model based on the modified formula of the background value. They conduct the simulation experiments on the power load data of medium and long-term by applying the CPSO-GM. The experimental results show that the proposed algorithm is superior to the three different grey prediction models and better to forecast power load data of medium and long-term.		Guo Pan;Aijia Ouyang	2014	JNW	10.4304/jnw.9.8.2121-2128	coevolution;computer science;artificial intelligence;particle swarm optimization;operations research	HPC	10.965290916195185	-17.796151837030056	189630
8320565e1134cd67065e4f9c6ff700c5c161812f	qfcs: a fuzzy lcs in continuous multi-step environments with continuous vector actions	optimal solution;learning algorithm;two dimensions;reinforcement learning;tesis de doctorado;learning classifier systems;learning classifier system;fuzzy classifier systems;fuzzy logic;expected value;induction theory;genetic algorithm;fuzzy system;fuzzy classifier	This document presents a doctoral dissertation which is a requirement for the Ph.D. degree in Information Technologies and Communications from Instituto Tecnológico y de Estudios Superiores de Monterrey (ITESM), Campus Monterrey, major in Intelligent Systems in the field of Learning Classifier Systems (LCS). The dissertation introduces a new LCS, called QFCS, that is able to deal with problems defined over continuous variables. These problems are important because real life is modeled in that way. LCSs are systems with a set of rules that compete and that can learn from and adapt to the environment. These properties are very desirable in intelligent systems because they allow the systems to adjust to subtle details. Traditionally, in Artificial Intelligence, designers have to pre-adjust the parameters. This made the developer not to take into account those subtle details and, consequently, deal with them during experimentation. LCSs make use of reinforcement learning and of evolutionary computing to deal with the proper adjustment of those subtleties. But, LCSs in their beginnings have been designed to solve problems that can be defined in a discrete form. Lately, researchers have tried to extend the approach to deal with problems in the continuum. This task has shown to be far away of being solved. Thus, there have been many approaches to adapt these systems to continuous variables. One of them has been the introduction of Fuzzy Logic to model the continuous environment. In this way, little by little LCSs have been extended to tackle more problems in the continuum, increasing, little by little, their related difficulty. Some of the problems solved with this approaches are the learning of continuous functions, the frog problem and navigation tasks. Learning of continuous functions is a problem where some continuous input enters to the system and the corresponding output is obtained, but the system does not know what this output is, all the system knows is the amount of reward it receives for each output made. This problem is of one-step since the system has to place an output once. The frog problem consists of a frog that lives with a fly in a line. The frog has to jump once and catch the fly. Since the frog lives in a line, the environment is continuous. The length the frog jumps is also continuous. This is one-step since the frog jumps once. The frog receives a reward at each time it jumps even if it does not trap the fly. Navigation tasks are more complex problems since they are multi-step. This means the system has to act more than one time to reach the goal. In this case, it moves many times to reach another place. The environment can be discrete but it is more complex if it is continuous. The actions are a set of discrete vectors but, in a more complex form, they could be continuous. The reward is given when the system reaches the goal.	artificial intelligence;campus party;evolutionary computation;fuzzy logic;quantum key distribution;real life;reinforcement learning;triune continuum paradigm	José Abdón Ramírez-Ruiz;Manuel Valenzuela-Rendón;Hugo Terashima-Marín	2008		10.1007/978-3-540-87700-4_29	fuzzy logic;margin classifier;mathematical optimization;two-dimensional space;genetic algorithm;defuzzification;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;mathematics;fuzzy associative matrix;learning classifier system;stability;reinforcement learning;fuzzy set operations;expected value	AI	21.488416649363614	-11.843011977502957	189843
1c0df2879321fa4fcc872c17771282296ba7b941	ai approaches for cutting tool diagnosis in machining processes	machining processes;hidden markov models;pattern recognition;diagnosis;bayesian networks	Monitoring of cutting tool systems are very important in machine tools and manufacturing equipment due to the impact they have in quality products and economy production. The cutting tool condition can be determined by direct or indirect sensing methods. Indirect methods are the only practical approach that offers better results by exploiting data sensor fusion techniques, which help to make a more robust and stable diagnosis. Different successful approaches from the Artificial Intelligence (AI) community are reviewed. A discussion of the implementation and evaluation of two AI techniques is done. Hidden Markov Model (HMM) based and Bayesian Networks based into an industrial machining center are tested. Excellent results demonstrated that HMM-based approach has a potential industrial application.		Rubén Morales-Menéndez;Antonio Vallejo;Luis E. Garza-Castañón;Francisco J. Cantú Ortiz;José Vicente Abellán Nebot	2007			engineering;operations management;machine learning;manufacturing engineering	Logic	12.841651074315184	-16.134226592923696	190030
118750f2bfb2f7e384a5df1cdb1b60374e02bc01	pattern recognition in large-scale data sets: application in integrated circuit manufacturing	signature analysis;mahalanobis distance;neural networks;integrated circuit;failure analysis;markov random fields and spatial signatures;pattern recognition;linear discriminant analysis;back propagation	It is important in semiconductor manufacturing to identify probable root causes, given a signature. The signature is a vector of electrical test parameters measured on a wafer. Linear discriminant analysis and artificial neural networks are used to classify a signature of test electrical measurements of a failed chip to one of several pre-determined root cause categories. An optimal decision rule that assigns a new incoming signature of a chip to a particular root cause category is employed such that the probability of misclassification is minimized. The problem of classifying patterns with missing data, outliers, collinearity, and non-normality are also addressed. The selected similarity metric in linear discriminant analysis, and the network topology, used in neural networks, result in a small number of misclassifications. An alternative classification scheme is based on the locations of failed chips on a wafer and their spatial dependence. In this case, we model the joint distribution of chips by a Markov random field, estimate its canonical parameters and use them as inputs for the artificial neural network that also classifies the patterns by matching them to the probable root causes.	integrated circuit;pattern recognition	Choudur K. Lakshminarayan;Michael I. Baron	2013		10.1007/978-3-319-03689-2_13	machine learning;pattern recognition;data mining;mathematics	ML	14.94128817074989	-17.778299270566087	190125
62429ce23c3d7b7f55069ef5bfe686ded8a4cd58	phenogp: combining programs to avoid code disruption	new building-blocks program;pgp individual;best order;canonical gp;perfect code;code disruption;useful code;best program;new form;simple building-blocks program;good fitness	In conventional Genetic Programming (GP), n programs are simultaneously evaluated and only the best programs will survive from one generation to the next. It is a pity as some programs might contain useful code that might be hidden or not evaluated due to the presence of introns. For example in regression, 0× (perfect code) will unfortunately not be assigned a good fitness and this program might be discarded due to the evolutionary process. In this paper, we develop a new form of GP called PhenoGP (PGP). PGP individuals consist of ordered lists of programs to be executed in which the ultimate goal is to find the best order from simple building-blocks programs. If the fitness remains stalled during the run, new building-blocks programs are generated. PGP seems to compare fairly well with canonical GP.	schema (genetic algorithms)	Cyril Fonlupt;Denis Robilliard	2013		10.1007/978-3-642-37207-0_5	computer science;artificial intelligence;algorithm	Logic	20.365110803196142	-10.1384301044318	190189
f4d46648765d707f8d98a2f2e7dadbd2b1b4e43e	combinatorial multi-armed bandits for real-time strategy games		Games with large branching factors pose a significant challenge for game tree search algorithms. In this paper, we address this problem with a sampling strategy for Monte Carlo Tree Search (MCTS) algorithms called näıve sampling, based on a variant of the Multiarmed Bandit problem called Combinatorial Multi-armed Bandits (CMAB). We analyze the theoretical properties of several variants of näıve sampling, and empirically compare it against the other existing strategies in the literature for CMABs. We then evaluate these strategies in the context of real-time strategy (RTS) games, a genre of computer games characterized by their very large branching factors. Our results show that as the branching factor grows, näıve sampling outperforms the other sampling strategies.	branching factor;monte carlo method;monte carlo tree search;multi-armed bandit;pc game;real-time locating system;sampling (signal processing);search algorithm	Santiago Ontañón	2017	J. Artif. Intell. Res.	10.1613/jair.5398	mathematical optimization;sampling (statistics);branching factor;real-time strategy;branching (version control);game tree;monte carlo tree search;mathematics;search algorithm	AI	19.63255474047754	-16.805766767599845	190283
d184a5af26ab9db9c265b974d79c5a37851ba33a	fuzzy testing and selecting better processes performance	process capability;normal distribution;confidence limit;fuzzy number;approximation;quality requirement;general methods;estimation;indexation;fuzzy inference;membership function;supplier evaluation;supply chain;binomial distribution;taguchi methods;product quality;variance reduction;taguchi method;supplier selection;competitive advantage;design methodology	Purpose – The principal aim of this study was to provide more realistic output data based on imprecise measurements of product quality. The real‐world problems in fuzzy testing and selecting better processes performance are considered.Design/methodology/approach – The Taguchi index, which provides numerical measures on process performance, has been widely used in the industry. In practice, the Taghchi index is estimated by sample data, thus it is of interest to obtain the confidence limits of the estimate Cpm for assessing processes. In addition, it is much more realistic, because in general the output quality characteristics of continuous quantities are more or less imprecise. Using the approach taken by Buckley, with some extensions, a general method is used to combine the vector of fuzzy numbers to produce the membership function of a fuzzy estimator of Cpm for further fuzzy testing and selection of better process performances.Findings – As the rapid advancement of manufacturing technology occurs, curr...		Shuenn-Ren Cheng;Bi-Min Hsu;Ming-Hung Shu	2007	Industrial Management and Data Systems	10.1108/02635570710758761	reliability engineering;econometrics;taguchi methods;defuzzification;engineering;fuzzy number;operations management;statistics	SE	14.383347754126476	-12.647543650552683	190408
abed5459d77f6375d47691cc23e457f37afe863e	a hybrid-forecasting model based on gaussian support vector machine and chaotic particle swarm optimization	power distribution system;gaussian noise;support vector regression;forecasting model;journal;hybrid model;load forecasting;particle swarm optimizer;loss function;particle swarm optimization;embedded;support vector machine;point of view;chaotic mapping	Load forecasting is an important subject for power distribution systems and has been studied from different points of view. This paper aims at the Gaussian noise parts of load series the standard v-support vector regression machine with @e-insensitive loss function that cannot deal with it effectively. The relation between Gaussian noises and loss function is built up. On this basis, a new v-support vector machine (v-SVM) with the Gaussian loss function technique named by g-SVM is proposed. To seek the optimal unknown parameters of g-SVM, a chaotic particle swarm optimization is also proposed. And then, a hybrid-load-forecasting model based on g-SVM and embedded chaotic particle swarm optimization (ECPSO) is put forward. The results of application of load forecasting indicate that the hybrid model is effective and feasible.	mathematical optimization;particle swarm optimization;support vector machine	Qi Wu	2010	Expert Syst. Appl.	10.1016/j.eswa.2009.07.057	support vector machine;mathematical optimization;multi-swarm optimization;computer science;artificial intelligence;machine learning;mathematics;relevance vector machine	ML	12.311795191786024	-22.19790988542811	191072
6446960ccdb74d1a29448cfac3426c25ee053728	a genetic programming based system for the automatic construction of image filters	mathematical morphology;automatic image filtering;image filters;genetic programming	The manual selection of linear and nonlinear operators for producing image filters is not a trivial task in practice, so new proposals that can automatically improve and speed up the process can be of great help. This paper presents a new proposal for constructing image filters using an evolutionary programming approach, which has been implemented as the IFbyGP software. IFbyGP employs a variation of the Genetic Programming algorithm GP and can be applied to binary and gray level image processing. A solution to an image processing problem is represented by IFbyGP as a set of morphological, convolution and logical operators. The method has a wide range of applications, encompassing pattern recognition, emulation filters, edge detection, and image segmentation. The algorithm works with a training set consisting of input images, goal images, and a basic set of instructions supplied by the user, which would be suitable for a given application. By making the choice of operators and operands involved in the process more flexible, IFbyGP searches for the most efficient operator sequence for a given image processing application. Results obtained so far are encouraging and they stress the feasibility of the proposal implemented by IFbyGP. Also, the basic language used by IFbyGP makes its solutions suitable to be directly used for hardware control, in a context of evolutionary hardware. Although the proposal implemented by IFbyGP is general enough for dealing with binary, gray level and color images, only applications using the first two are considered in this paper; as it will become clear in the text, IFbyGP aims at the direct use of induced sequences of operations by hardware devices. Several application examples discussing and comparing IFbyGP results with those obtained by other methods available in the literature are presented and discussed.	composite image filter;genetic programming	Emerson Carlos Pedrino;Valentin Obac Roda;Edilson R. R. Kato;José Hiroki Saito;Mário Luiz Tronco;Roberto H. Tsunaki;Orides Morandin;Maria do Carmo Nicoletti	2013	Integrated Computer-Aided Engineering	10.3233/ICA-130429	genetic programming;computer vision;feature detection;mathematical morphology;computer science;artificial intelligence;theoretical computer science;machine learning;digital image processing;algorithm	EDA	15.631975174550194	-22.326974732235737	191107
b08a98b88dfc2be362be352e29bb2a2a6797e558	sorting network development using cellular automata	optimization technique;evolutionary design;sorting networks;sorting network;comparative study;cellular automata;cellular automaton	The sorting network design represents a task that has often been considered as a benchmark for various applications of evolutionary design and optimization techniques. Although the specific structure of this class of circuits allows to use a simple encoding in combination with additional mechanisms for optimizing the area- and delay-efficiency of designed sorting networks, the design of large sorting networks represents a difficult task. This paper proposes a novel cellular automaton-based approach for the development of specific instances of sorting networks. In order to explore the area of generative cellular automata applied on this specific circuit structures, two different encodings are introduced: (1) an absolute encoding and (2) a relative encoding. The abilities of the both techniques are investigated and a comparative study is provided considering a variety of experimental settings.		Michal Bidlo;Zdenek Vasícek;Karel Slaný	2010		10.1007/978-3-642-15323-5_8	cellular automaton;sorting network;computer science;theoretical computer science;machine learning;algorithm	Robotics	15.837756438092827	-23.696573208568328	191119
2ab08004a96a17cf82db9739ffdab4297c1d8d13	where do we go now?: anytime algorithms for path planning	path planning;potential field;anytime algorithm;artificial intelligent;computer science education;real time strategy;games;multidisciplinary;computer game	Commercial computer games has become one of the largest industries in the area of entertainment. Real Time Strategy (Rts) based games is one of the most important among different types of computer games and is also considered to be a good research platform within Artificial Intelligence (Ai). There exists a number of algorithms that can deal with the Ai related problems of this domain, e.g. the ones of getting as cheap or fast as possible from one point to another (i.e. path planning). However most of the algorithms used in academia are better suited for problems that do not need to be solved within tight time frames. Anytime algorithms (Aa) are algorithms that can be stopped at any point in time and yet come up with a preliminary solution. We believe that by making algorithms anytime, we can optimize their behaviors to better suit the Rts domain. This study will introduce a tool for evaluating path planning algorithms and compare the performances of A*, Recursive Best First Search (Rbfs), Potential Fields (Pf) and their anytime versions for the path planning problem.	a* search algorithm;anytime algorithm;artificial intelligence;best-first search;motion planning;pc game;performance;recursion (computer science)	Rehman Butt;Stefan J. Johansson	2009		10.1145/1536513.1536558	games;simulation;computer science;artificial intelligence;machine learning;motion planning;multidisciplinary approach	AI	18.638764365333863	-11.913126531151319	191434
041fa75b033880b905ab1899007aebfe405d9ec4	perseus: randomized point-based value iteration for pomdps	partially observed markov decision process;point based value iteration;artificial intelligent;large scale;planning under uncertainty	Partially observable Markov decision processes (POMDPs) form an attractive and principled framework for agent planning under uncertainty. Point-based approximate techniques for POMDPs compute a policy based on a finite set of points collected in advance from the agent’s belief space. We present a randomized point-based value iteration algorithm called Perseus. The algorithm performs approximate value backup stages, ensuring that in each backup stage the value of each point in the belief set is improved; the key observation is that a single backup may improve the value of many belief points. Contrary to other point-based methods, Perseus backs up only a (randomly selected) subset of points in the belief set, sufficient for improving the value of each belief point in the set. We show how the same idea can be extended to dealing with continuous action spaces. Experimental results show the potential of Perseus in large scale POMDP problems.	approximation algorithm;backup;iteration;iterative method;markov chain;partially observable markov decision process;randomized algorithm;randomness	Matthijs T. J. Spaan;Nikos A. Vlassis	2005	J. Artif. Intell. Res.	10.1613/jair.1659	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics	AI	20.561644559140532	-15.952977164788669	191453
81cf91bde7767730e5575d3a4711ce7675df8b68	robot reinforcement learning based on learning classifier system	reinforcement learning;learning classifier system	This paper proposed a robot reinforcement learning method based on learning classifier system. A learning Classifier System is a rule-based machine learning system that combines reinforcement learning and genetic algorithms. The reinforcement learning component is responsible for adjusting the strength of rules in the system according to some reward obtained from the environment. The genetic algorithm acts as an innovation discovery component which is responsible for discovering new better learning rules. The advantages of this approach are its rule-based representation, which can easily reduce learning space, improve online learning ability and robustness.		Jie Shao;Jing-yu Yang	2010		10.1007/978-3-642-14831-6_27	semi-supervised learning;unsupervised learning;robot learning;multi-task learning;instance-based learning;error-driven learning;computer science;artificial intelligence;machine learning;learning classifier system;active learning	ML	18.709390509899542	-21.161492989017205	191477
0003a26b0117d632579bde0de6f38a647c0b22f1	modeling and optimal control of batch processes using recurrent neuro-fuzzy networks	neuro fuzzy systems;fuzzy neural nets;optimal control batch processes neural networks neuro fuzzy systems;neural networks;optimal control fuzzy neural networks predictive models neural networks process control manufacturing processes delay effects inductors polymers chemical processes;dynamic model;batch process monitoring optimal control batch process control recurrent neuro fuzzy network nonlinear long range prediction model linear dynamic model;fuzzy set theory;time delay;neurocontrollers optimal control batch processing industrial process control recurrent neural nets fuzzy neural nets process monitoring fuzzy set theory;input output;optimal control;process monitoring;batch processing industrial;neuro fuzzy;network model;neuro fuzzy system;batch process;process control;membership function;prediction model;long range;neurocontrollers;recurrent neural nets;batch processes;product quality;batch reactor;neural network	"""A recurrent neuro-fuzzy network based strategy for batch process modeling and optimal control is presented in this paper. The recurrent neuro-fuzzy network allows the construction of a """"global"""" nonlinear long-range prediction model from the fuzzy conjunction of a number of """"local"""" linear dynamic models. In this recurrent neuro-fuzzy network, the network output is fed back to the network input through one or more time delay units. This particular structure ensures that predictions from a recurrent neuro-fuzzy network are long-range or multi-step-ahead predictions. Long-range predictions are particularly important for batch processes where the interest lies in the product quality and quantity at the end of a batch. To enhance batch process control and monitoring, a model capable of predicting accurately the product quality/quantity at the end of a batch is required. Process knowledge is used to initially partition the process nonlinear characteristics into several local operating regions and to aid in the initialization of the corresponding network weights. Process input output data is then used to train the network. Membership functions of the local regimes are identified and local models are discovered through network training. An advantage of this recurrent neuro-fuzzy network model is that it is easy to interpret. This helps process operators in understanding the process characteristics. The proposed technique is applied to the modeling and optimal control of a fed-batch reactor."""	neuro-fuzzy;optimal control	Jie Zhang	2005	IEEE Trans. Fuzzy Systems	10.1109/TFUZZ.2004.841737	input/output;batch reactor;optimal control;membership function;computer science;neuro-fuzzy;network model;machine learning;control theory;network simulation;predictive modelling;fuzzy set;artificial neural network;batch processing	Embedded	13.676748518831435	-21.877490882192667	191484
6c2c4f0dbce83eaff3a2711fbf1220a879c4e596	rigorous agent evaluation: an adversarial approach to uncover catastrophic failures		This paper addresses the problem of evaluating learning systems in safety critical domains such as autonomous driving, where failures can have catastrophic consequences. We focus on two problems: searching for scenarios when learned agents fail and assessing their probability of failure. The standard method for agent evaluation in reinforcement learning, Vanilla Monte Carlo, can miss failures entirely, leading to the deployment of unsafe agents. We demonstrate this is an issue for current agents, where even matching the compute used for training is sometimes insufficient for evaluation. To address this shortcoming, we draw upon the rare event probability estimation literature and propose an adversarial evaluation approach. Our approach focuses evaluation on adversarially chosen situations, while still providing unbiased estimates of failure probabilities. The key difficulty is in identifying these adversarial situations – since failures are rare there is little signal to drive optimization. To solve this we propose a continuation approach that learns failure modes in related but less robust agents. Our approach also allows reuse of data already collected for training the agent. We demonstrate the efficacy of adversarial evaluation on two standard domains: humanoid control and simulated driving. Experimental results show that our methods can find catastrophic failures and estimate failures rates of agents multiple orders of magnitude faster than standard evaluation schemes, in minutes to hours rather than days.	addresses (publication format);adversary (cryptography);autonomous car;catastrophic illness;catastrophic interference;continuation;deploy;estimated;ethanol 0.62 ml/ml topical gel;experiment;extreme value theory;kerrison predictor;liver failure, acute;monte carlo method;probability;regular expression;reinforcement learning;reuse (action);sparse matrix	Jonathan Uesato;Ananya Kumar;Csaba Szepesvári;Tom Erez;Avraham Ruderman;Keith Anderson;Krishmamurthy Dvijotham;Nicolas Heess;Pushmeet Kohli	2018	CoRR		machine learning;software deployment;reuse;continuation;adversarial system;artificial intelligence;reinforcement learning;monte carlo method;computer science	AI	21.65742389185995	-20.298141904589432	191534
f0321d03d712c3321b9cf933b6476923cb0c60c7	policy iteration for robust nonstationary markov decision processes		Policy iteration is a well-studied algorithm for solving stationary Markov decision processes (MDPs). It was recently extended to robust stationary MDPs. For robust nonstationary MDPs, however, an “as is” execution of this algorithm is not possible because it would call for an infinite amount of computation in each iteration. We therefore present a policy iteration algorithm for robust nonstationary MDPs, which performs finitely implementable approximate variants of policy evaluation and policy improvement in each iteration. We prove that the sequence of costto-go functions produced by this algorithm monotonically converges pointwise to the optimal cost-to-go function; the policies generated converge subsequentially to an optimal policy.		Saumya Sinha;Archis Ghate	2016	Optimization Letters	10.1007/s11590-016-1040-6	mathematical optimization;discrete mathematics;machine learning;mathematics	ML	22.56639122029283	-18.28447909556869	191777
0aaf14bea7c6d466bffa3eca8c392a67bb3e1023	approximate planning	approximate planning	This paper makes two linked contributions. First, we argue that planning systems, instead of being correct (every plan returned achieves the goal) a~Ld complete (all such plans are returned), should bc approximately correct and complete, in that most plans returned achieve the goal and that most such plans are returned. Our first contribution is to formalize this notion. Our second aim is to demonstrate the practical importance of these ideas. We argue that the cached plans used by case-based planners are best thought of as approximate as opposed to exact, and also show that we can use our approach to plan for subgoals gl and g2 separately and to combine the plans generated to produce a plan for the conjoined goal gl A g~. The computational benefits of working with subgoals separately have long been recognized, but attempts to do so using correct and complete planners have failed.	approximation algorithm;computation	Matthew L. Ginsberg	1995	Artif. Intell.	10.1016/0004-3702(94)00077-E		AI	18.72402767179675	-11.216701302848664	191960
90b81ca35fabcc5f1cf762877a4ff6764ab8c458	a new predictive model for the filtered volume and outlet parameters in micro-irrigation sand filters fed with effluents using the hybrid pso-svm-based approach	regatge per degoteig;trickle irrigation;particle swarm optimization pso;info eu repo semantics article;filtres i filtracio;filters and filtration;drip irrigation;regression analysis;clogging;support vector machines svms	Prediction of sand filter outlet values allows assessing drip emitter clogging risk.A hybrid model based on SVMs with the PSO technique was used for this prediction.The developed model predicted satisfactorily sand filter outlet parameters.Performance of the PSO-SVM model was better than with other techniques. Filtration is a key operation in micro-irrigation for removing the particles carried by water that could clog drip emitters. Currently, there are not sufficiently accurate models available to predict the filtered volume and outlet parameters for the sand filters used in micro-irrigation systems. The aim of this study was to obtain a predictive model able to perform an early detection of the filtered volume and sand filter outlet values of dissolved oxygen (DO) and turbidity, both related to emitter clogging risks. This study presents a novel hybrid algorithm, based on support vector machines (SVMs) in combination with the particle swarm optimization (PSO) technique, for predicting the main filtration operation parameters from data corresponding to 769 experimental filtration cycles in a sand filter operating with effluent. This optimization technique involves kernel parameter setting in the SVM training procedure, which significantly influences the regression accuracy. To this end, the most important physical-chemical parameters of this process are monitored and analyzed: effective sand media size, head loss across the filter and filter inlet values of dissolved oxygen (DO), turbidity, electrical conductivity (Ec), pH and water temperature. The results of the present study are two-fold. In the first place, the significance of each physical-chemical variables on the filtration is presented through the model. Secondly, a model for forecasting the filtered volume and sand filter outlet parameters is obtained with success. Indeed, regression with optimal hyperparameters was performed and coefficients of determination equal to 0.74 for outlet turbidity, 0.82 for filtered volume and 0.97 for outlet dissolved oxygen were obtained when this hybrid PSO-SVM-based model was applied to the experimental dataset, respectively. The agreement between experimental data and the model confirmed the good performance of the latter.	phase-shift oscillator;predictive modelling	P. J. García Nieto;E. García-Gonzalo;G. Arbat;M. Duran-Ros;F. Ramírez de Cartagena;J. Puig-Bargués	2016	Computers and Electronics in Agriculture	10.1016/j.compag.2016.04.031	environmental engineering;engineering;drip irrigation	Robotics	11.96296189330931	-19.223307894182163	192192
6cea524d63832020812c4b25f9824d9b3d987fd0	rolling force prediction based on pso optimized support vector regression	forecasting;bp nn algorithm rolling force prediction pso optimized support vector regression hot bar rolling process particle swarm optimization mathematic model;rolling force prediction;support vector machines;neural nets;pso optimized support vector regression;bp nn algorithm;metallurgical industries;prediction algorithms;support vector regression;mathematic model;hot bar rolling process;backpropagation;force;accuracy;particle swarm optimizer;force support vector machines accuracy forecasting prediction algorithms mathematical model predictive models;particle swarm optimization;rolling force prediction bar rolling support vector regression particle swarm optimization;mathematical model;bar rolling;predictive models;regression analysis;support vector machines backpropagation hot rolling metallurgical industries neural nets particle swarm optimisation regression analysis;prediction model;support vector machine;particle swarm optimisation;hot rolling	Rolling force prediction is very important in hot bar rolling process. Aiming at the problem of predicting the bar rolling force accurately, an optimal approach of support vector regression based on improved particle swarm optimization (PSO) is proposed. A mathematic model based on the support vector regression optimized by particle swarm optimization is established, and the optimal parameter of which is searched by PSO. The experiment results shows that the proposed prediction model has better prediction results than the support vector regression algorithm and BP-NN algorithm, increasing the average prediction accuracy from 78.5% to 94.1%.	algorithm;computer simulation;ipso alliance;mathematical optimization;particle swarm optimization;support vector machine	Dongsheng Wu;Qing Yang;Dazhi Wang	2011	2011 Seventh International Conference on Natural Computation	10.1109/ICNC.2011.6022214	mathematical optimization;engineering;artificial intelligence;machine learning	Robotics	10.922340700482303	-17.934798392467858	192580
fda7a0f478b93ea4be392b3c721f0293b6c1fa20	safety margin sensitivity analysis for model selection in nuclear power plant probabilistic safety assessment		The safety assessment of Nuclear Power Plants makes use of Thermal-Hydraulic codes for the quantification of the safety margins with respect to upper/lower safety thresholds, when postulated accidental scenarios occur. To explicitly treat uncertainties in the safety margins estimates within the Risk-Informed Safety Margin Characterization (RISMC) framework, we resort to the concept of Dynamic Probabilistic Safety Margin (DPSM). We propose to add to the framework a sensitivity analysis that calculates how much the Thermal-Hydraulic (TH) code inputs affect the DPSM, in support to the selection of the most proper probabilistic safety assessment method to be used for the problem at hand, between static or dynamic methods (e.g., Event Trees (ETs) or Dynamic ETs (DETs), respectively). Two case studies are considered: firstly a Station Black Out followed by a Seal Loss Of Coolant Accident (LOCA) for a 3-loops Pressurized Water Reactor (PWR), whose dynamics is simulated by a MAAP5 model and, secondly, the accidental scenarios that can occur in a U-Tube Steam Generator, whose dynamics is simulated by a SIMULINK model. The results show that the sensitivity analysis performed on the DPSM points out that an ET-based analysis is sufficient in one case, whereas a DET-based analysis is needed for the other case.	code;computation;detection error tradeoff;dynamical system;error-tolerant design;fault tree analysis;linear system;margin classifier;mixture model;model selection;nonlinear system;onset (audio);operating system;pid;parametric model;quantum fluctuation;reactor (software);sap business one;sensitivity index;simulation;simulink;spatial variability;spectral leakage;statistical model;system safety;thermal grease;water cooling	Francesco Di Maio;Claudia Picoco;Enrico Zio;Valentin Rychkov	2017	Rel. Eng. & Sys. Safety	10.1016/j.ress.2017.01.020	reliability engineering;simulation;engineering;forensic engineering	Embedded	12.695134473182712	-10.831344412547237	192666
42b83e8d7ef27f266bf2f91ed89260340e6d7984	constraint programming and machine learning for interactive soccer analysis		A soccer competition consists of n teams playing against each other in a league or tournament system, according to a single or double round-robin schedule. These competitions offer an excellent opportunity to model interesting problems related to questions that soccer fans frequently ask about their favourite teams. For instance, at some stage of the competition, fans might be interested in determining whether a given team still has chances of winning the competition (i.e., finishing first in a league or being within the first k teams in a tournament to qualify to the playoff). This problem relates to the elimination problem, which is NP-complete for the actual FIFA pointing rule system (0, 1, 3), zero point to a loss, one point to a tie, and three points to a win. In this paper, we combine constraint programming with machine learning to model a general soccer scenario in a real-time application.	cp/m;computation;constraint programming;experiment;jorge urrutia galicia;machine learning;np-completeness;real-time clock;real-time computing;real-time locating system;round-robin scheduling	Robinson Duque;Juan Francisco Díaz;Alejandro Arbelaez	2016		10.1007/978-3-319-50349-3_18	machine learning;inductive programming;artificial intelligence;constraint programming;computer science;ask price;tournament	AI	17.56146974310896	-17.062571474529975	192670
33990e5647162be6b9e909b1146e5f3bbd2fe578	research on temperature rising prediction of distribution transformer by artificial neural networks		In order to predict the temperature rising of the distribution transformer by applying the artificial neural networks (ANNs) method analyze experimental data with the actual measured data and compared with the actual measured value to reach the relative errors investigation. The historical data of the working day are divided into three periods according to the varying loadings trend of load change emotion as the peak period, the general time period and the valley period. In experimental results, The average relative error of the peak period is 2.05%, the average relative error of the general period is 1.69%, the average relative error of the valley period is 1.25 %, and the working day average relative error is 1.60% for a day 24 hours. By Ann’s derivation the result has a very good prediction rate at temperature rising of distribution transformer. © Springer Nature Singapore Pte Ltd. 2018.		Wenxin Zhang;Jeng-Shyang Pan;Yen-Ming Tseng	2017		10.1007/978-981-10-6487-6_18	machine learning;experimental data;distribution transformer;artificial intelligence;artificial neural network;approximation error;computer science	ML	10.080263224782714	-18.761371887305465	192923
004ed694a9013dd239ee65a95741bc317e0e985c	a compact, high-speed, wearable sensor network for biomotion capture and interactive media	biomedical measurement;capacitive sensors;humanities;interactive systems;radio links;sport;wearable computers;wireless sensor networks;athletic training;biomechanical analysis;biomotion capture;bit rate 1 mbit/s;capacitive proximity sensor;compact inertial measurement units;distributed measurement system;frequency 100 hz;high-speed wireless network;interactive dance;interactive media;multipoint human motion;radio link;wearable sensor network;algorithms;design;measurement;performance;theory;wearable sensors;biomechanics;biomotion;dance;high-performance;inertial measurement unit;interactive media;real-time;synchronous motion analysis;wireless	In this paper, we present a wireless sensor platform designed for processing multipoint human motion with low latency and high resolution. One application considered here is interactive dance, in which a choreographer wishes to translate the movements of multiple dancers into real-time audio or video content to accompany the performance. This can only be accomplished using a distributed measurement system capable of responding quickly with enough information to describe the expressive movements of multiple people. Similar requirements exist for biomechanical analysis, especially in the context of athletic training, where high resolution is demanded, and instant feedback is also desirable. Our approach to addressing such aggressive requirements involves a high-speed wireless network of compact inertial measurement units (IMUs) that can be worn at various locations on the body. Each device is equipped with its own 1 Mbps radio link and a full six-axis IMU, as well as a capacitive node-to-node proximity sensor. Currently, the system supports real-time data collection and processing for up to 25 nodes with 100 Hz full state updates, thereby handling much higher data rates than its predecessors. With locally buffered data, sample rates of up to 1 kHz have been achieved successfully. Early results discussed here demonstrate the feasibility of our design through testing with both dancers and professional athletes.	interactive media;wearable computer	Ryan Aylward;Joseph A. Paradiso	2007		10.1109/IPSN.2007.4379698	embedded system;simulation;wireless sensor network;computer science;biomechanics;operating system	HCI	16.70845357018236	-11.442819823709511	192935
03d83145ac5091865595e14400da7ef7309a25dd	cdot: optimizing map queries on trees		Among the graph structures underlying Probabilistic Graphical Models, trees are valuable tools for modeling several interesting problems, such as linguistic parsing, phylogenetic analysis, and music harmony analysis. In this paper we introduce CDoT, a novel exact algorithm for answering Maximum a Posteriori queries on tree structures. We discuss its properties and study its asymptotic complexity; we also provide an empirical assessment of its performances, showing that the proposed algorithm substantially improves over a dynamic programming	computational complexity theory;dynamic programming;exact algorithm;graphical model;optimizing compiler;parsing;performance;phylogenetics;tree structure	Roberto Esposito;Daniele P. Radicioni;Alessia Visconti	2013		10.1007/978-3-319-03524-6_41	theoretical computer science;machine learning;data mining;mathematics	ML	17.844045662614242	-13.65567513783887	193120
79600f2da6c044649e4174d2973522df60cef2d6	neural networks for power systems alarm handling	neural networks;power systems;endnotes;power system;alarm analysis;pubications;computer control;neural network	Ball, N., L. Kiernan, K. Warwick, E. Cahiil, D. Esp and J. Macqueen, Neural networks for power systems alarm handling, Neurocomputing 4 (1992) 5-8. A multi-layered architecture of self-organizing neural networks is being developed as part of an intelligent alarm processor to analyse a stream of power grid fault messages and provide a suggested diagnosis of the fault location. Feedback concerning the accuracy of the diagnosis is provided by an object-oriented grid simulator which acts as an external supervisor to the learning system. The utilization of artificial neural networks within this environment should result in a powerful generic alarm processor which will not require extensive training by a human expert to produce accurate results.	ball project;ibm power systems;neural networks;neurocomputing;organizing (structure);self-organization;simulation	Nigel Ball;Leo Kiernan;Kevin Warwick;Eamonn Cahill;David Esp;John Macqueen	1992	Neurocomputing	10.1016/0925-2312(92)90038-Q	real-time computing;computer science;artificial intelligence;machine learning;time delay neural network;electric power system;artificial neural network	HPC	15.394869315857692	-16.894174815296505	193229
b8de8642ec8f93e04009397440a4a392a27d4580	optimistic planning in markov decision processes using a generative model		We consider the problem of online planning in a Markov decision process with discounted rewards for any given initial state. We consider the PAC sample complexity problem of computing, with probability 1−δ, an -optimal action using the smallest possible number of calls to the generative model (which provides reward and next-state samples). We design an algorithm, called StOP (for StochasticOptimistic Planning), based on the “optimism in the face of uncertainty” principle. StOP can be used in the general setting, requires only a generative model, and enjoys a complexity bound that only depends on the local structure of the MDP.	algorithm;generative model;markov chain;markov decision process;sample complexity;uncertainty principle	Balázs Szörényi;Gunnar Kedenburg;Rémi Munos	2014			mathematical optimization;partially observable markov decision process;artificial intelligence;machine learning;mathematics;generative model	ML	22.05774771980532	-17.479458936182215	193342
52bfe20c265eb18a3c1848cf8152d0477c010982	a new method for constructing spectral emissivity models for measuring the real temperature of targets	data processing;neural networks;mathematical model;temperature measurement;voltage	The main problem in radiation pyrometry is the large error arising from the unknown or varying emissivity of the target surface. In this paper, a combined neural network emissivity model, which allows calculating the true temperature and emissivity of any measurand from the measured data of continuous spectral emissivity, is established by the combined neural network. The proposed single parameter dynamic search algorithm using the hybrid steepest descent and Newton's method is proposed to optimize the training algorithm of the model. This optimization algorithm can quicken the convergence speed of the combined neural network emissivity model (CNNE model). Through theoretical derivation and simulation experiments, we can see that this model is theoretically useful for any target, which calculates the function relationships between wavelength and emissivity. Simulation and experimental results have shown the high accuracy in measurements by using this method.	artificial neural network;experiment;gradient descent;mathematical model;mathematical optimization;newton's method;search algorithm;simulation	Chunling Yang;Dongyang Zhao;Jingming Dai	2005	IEEE Transactions on Instrumentation and Measurement	10.1109/TIM.2005.858108	gradient descent;mathematical optimization;voltage;pyrometer;temperature measurement;computer science;machine learning;mathematical model;mathematics;emissivity;newton's method;artificial neural network;remote sensing;search algorithm	Vision	12.922536987980825	-20.95150038078716	193484
5cd8c5706d58111c62c4c93a530570242fb4ddcd	investigation of long short-term memory networks to temperature prediction for permanent magnet synchronous motors		Monitoring critical temperatures in permanent magnet synchronous motors (PMSMs) is crucial to ensure safe operation and maximum device utilization as well. In this work, the application of recurrent neural networks featuring memory blocks (LSTMs/GRUs) are investigated upon their suitability to accurate temperature time series prediction inside PMSMs or similar motor types, which is the first time in literature to the author's best knowledge. Considered motor components are stator yoke, teeth and winding as well as the rotor's permanent magnets of a highly-utilized PMSM for electric vehicle applications. Having benchmark data available, numerous neural networks are trained and optimized with the aid of the Chainer framework and particle swarm optimization is conducted for finding suitable model hyper-parameters (e.g. number of hidden neurons or layers) on a computing cluster. It is found, that the Euclidean norm performance (in the range of 1–3 K) is similar but the worst-case predication errors (in the range of 9–14 K) are significantly higher compared to established modeling techniques like lumped-parameter thermal networks (LPTNs). This initial investigation motivates future research to increase ANN-based estimation accuracy by taken other ANN topologies, training methods or hyper-parameter optimization approaches into account.	algorithm;artificial neural network;benchmark (computing);best, worst and average case;computation;computer cluster;experiment;global optimization;long short-term memory;mathematical optimization;microsoft outlook for mac;naruto shippuden: clash of ninja revolution 3;particle swarm optimization;r.o.t.o.r.;real-time clock;recurrent neural network;test set;time complexity;time series	Oliver Wallscheid;Wilhelm Kirchgassner;Joachim Böcker	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7966088	synchronous motor;artificial intelligence;time series;machine learning;rotor (electric);artificial neural network;control engineering;network topology;computer science;recurrent neural network;stator;particle swarm optimization	ML	10.231781833358534	-19.851392300981416	193800
ed613810f67829eb02dff6442aba8e091568fa5f	predicting solution summaries to integer linear programs under imperfect information with machine learning		The paper provides a methodological contribution at the intersection of machine learning and operations research. Namely, we propose a methodology to quickly predict solution summaries (i.e., solution descriptions at a given level of detail) to discrete stochastic optimization problems. We approximate the solutions based on supervised learning and the training dataset consists of a large number of deterministic problems that have been solved independently and offline. Uncertainty regarding a missing subset of the inputs is addressed through sampling and aggregation methods. Our motivating application concerns booking decisions of intermodal containers on doublestack trains. Under perfect information, this is the so-called load planning problem and it can be formulated by means of integer linear programming. However, the formulation cannot be used for the application at hand because of the restricted computational budget and unknown container weights. The results show that standard deep learning algorithms allow one to predict descriptions of solutions with high accuracy in very short time (milliseconds or less).	approximation algorithm;computation;deep learning;integer programming;level of detail;linear programming;machine learning;mathematical optimization;object composition;online and offline;operations research;sampling (signal processing);stochastic optimization;supervised learning	Eric Larsen;Sébastien Lachapelle;Yoshua Bengio;Emma Frejinger;Simon Lacoste-Julien;Andrea Lodi	2018	CoRR		supervised learning;machine learning;mathematical optimization;stochastic optimization;deep learning;sampling (statistics);mathematics;perfect information;integer programming;level of detail;integer;artificial intelligence	AI	21.164902436529783	-16.890290993971394	193857
39d18021662376564aee8ea519a765e928e932a8	using markov models and statistics to learn, extract, fuse, and detect patterns in raw data		Many systems are partially stochastic in nature. We have derived datadriven approaches for extracting stochastic state machines (Markov models) directly from observed data. This chapter provides an overview of our approach with numerous practical applications. We have used this approach for inferring shipping patterns, exploiting computer system side-channel information, and detecting botnet activities. For contrast, we include a related data-driven statistical inferencing approach that detects and localizes radiation sources.	botnet;computer;hidden markov model;markov chain;sensor;side-channel attack;signal processing;stochastic process	Richard R. Brooks;Lu Yu;Yu Fu;Guthrie Cordone;Jon Oakley;Xingsi Zhong	2017	CoRR	10.1007/978-3-319-75683-7_20	raw data;computer science;theoretical computer science;finite-state machine;fuse (electrical);botnet;linear regression;radiation;tracking system;markov model	ML	12.794043414637768	-14.609464671883488	193947
66d91b2663c8ddc0427fa5fe3ea142ac5b8d204c	a three-network architecture for on-line learning and optimization based on adaptive dynamic programming	actor critic design;reinforcement learning;multi state optimization;online learning and control;goal representation;three network architecture;adaptive dynamic programming	In this paper, we propose a novel adaptive dynamic programming (ADP) architecture with three networks, an action network, a critic network, and a reference network, to develop internal goalrepresentation for online learning and optimization. Unlike the traditional ADP design normally with an action network and a critic network, our approach integrates the third network, a reference network, into the actor-critic design framework to automatically and adaptively build an internal reinforcement signal to facilitate learning and optimization overtime to accomplish goals. We present the detailed design architecture and its associated learning algorithm to explain how effective learning and optimization can be achieved in this new ADP architecture. Furthermore, we test the performance of our architecture both on the cart-pole balancing task and the triple-link inverted pendulum balancing task, which are the popular benchmarks in the community to demonstrate its learning and control performance over time. & 2011 Elsevier B.V. All rights reserved.	artificial intelligence;backpropagation;benchmark (computing);dynamic programming;inverted pendulum;levenberg–marquardt algorithm;mathematical optimization;network architecture;network planning and design;online and offline;online machine learning;optimization problem;simulation;usb on-the-go	Haibo He;Zhen Ni;Jian Fu	2012	Neurocomputing	10.1016/j.neucom.2011.05.031	error-driven learning;simulation;computer science;artificial intelligence;machine learning;learning classifier system;reinforcement learning	AI	19.811857996334066	-22.545140113563043	194398
080922fe2dc75967390b042d06717cbd51c0db1a	tracking the best disjunction	concept drift;sc winnow;amortized analysis;upper bound;computer experiment;computational learning theory;prediction;lower bound;on line learning	Littlestone developed a simple deterministic on-line learning algorithm for learning k-literal disjunctions. This algorithm (called $${WINNOW}$$ ) keeps one weight for each of then variables and does multiplicative updates to its weights. We develop a randomized version of $${WINNOW} $$ and prove bounds for an adaptation of the algorithm for the case when the disjunction may change over time. In this case a possible target disjunction schedule $${\mathcal{T}} $$ is a sequence of disjunctions (one per trial) and the shift size is the total number of literals that are added/removed from the disjunctions as one progresses through the sequence. We develop an algorithm that predicts nearly as well as the best disjunction schedule for an arbitrary sequence of examples. This algorithm that allows us to track the predictions of the best disjunction is hardly more complex than the original version. However, the amortized analysis needed for obtaining worst-case mistake bounds requires new techniques. In some cases our lower bounds show that the upper bounds of our algorithm have the right constant in front of the leading term in the mistake bound and almost the right constant in front of the second leading term. Computer experiments support our theoretical findings.	amortized analysis;best, worst and average case;computer experiment;literal (mathematical logic);online and offline;online machine learning;randomized algorithm;winnow (algorithm)	Peter Auer;Manfred K. Warmuth	1998	Machine Learning	10.1023/A:1007472513967	winnow;computer science;artificial intelligence;machine learning;mathematics;upper and lower bounds;computational learning theory;algorithm;statistics	Theory	22.7581886059148	-17.21464086057843	194930
c0c9bd0f8bf859a8b38d05c9aa32f731df844b1c	sequence-form and evolutionary dynamics: realization equivalence to agent form and logit dynamics	evolutionary game theory;extensive form games	"""Evolutionary game theory provides the principal tools to model the dynamics of multi-agent learning algorithms. While there is a long-standing literature on evolutionary game theory in strategic-form games, in the case of extensive-form games few results are known and the exponential size of the representations currently adopted makes the evolutionary analysis of such games unaffordable. In this paper, we focus on dynamics for the sequence form of extensive-form games, providing three dynamics: one realization equivalent to the normal-form logit dynamic, one realization equivalent to the agent-form replicator dynamic, and one realization equivalent to the agent-form logit dynamic. All the considered dynamics require polynomial time and space, providing an exponential compression w.r.t. the dynamics currently known and providing thus tools that can be effectively employed in practice. Moreover, we use our tools to compare the agent-form and normal-form dynamics and to provide new """"hybrid"""" dynamics."""	turing completeness	Nicola Gatti;Marcello Restelli	2016			mathematical optimization;evolutionary game theory;simulation;extensive-form game;computer science	AI	17.80538157501822	-16.650005134297324	195022
27f2a960ec99d25235c141a0d6c14c54dbe068b1	a new approach to battery power tracking and predicting for mobile robot transportation using wavelet decomposition and anfis networks	forecasting;mobile robots;transportation;voltage measurement;conferences;automation	An intelligent system named Laboratory Mobile Robot Transportation System (LMRTS) has been developed for the mobile robotic transportation in laboratory automation. In this paper, a new approach is presented to predict and manage the on-board battery voltages of the mobile robots for optimizing the LMRTS system. The LMRTS can select and optimize the best mobile robotic candidate for a transportation task by considering those battery forecasting results. The proposed predictor includes three components: (a) Measuring the online voltages of the robotic on-board batteries; (b) Using the wavelet method to decompose the original measured data into a series of sub-layers; (c) Building the ANFIS for all the decomposed sub-layers and make the predictions; and (d) Integrating the forecasting results of the sub-layers to have the final predictions for the original online voltage signal. Two real experimental results show that the proposed hybrid predictor has both high forecasting accuracy and fast time performance, which can provide a powerful assistance to the real mobile robotic transportation.	adaptive neuro fuzzy inference system;algorithm;artificial intelligence;artificial neural network;computation;control theory;emoticon;experiment;kerrison predictor;laboratory automation;mobile robot;on-board data handling;real-time clock;stationary process;wavelet	Hui Liu;Norbert Stoll;Steffen Junginger;Kerstin Thurow	2014	2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014)	10.1109/ROBIO.2014.7090339	control engineering;mobile robot;embedded system;transport;simulation;forecasting;computer science;engineering;artificial intelligence;automation;statistics	Robotics	10.549886207251918	-17.117086023163775	195578
cc203e8f341bedbbc5d91183651526c711a78b33	parameter estimation of fuzzy controller and its application to inverted pendulum	fuzzy controller;comparative analysis;pid controller;estimation algorithm;estimation algorithms;fuzzy pid pd controller;neuro fuzzy;genetic algorithm;inverted pendulum;hcm hard c means;parameter estimation;neuro fuzzy networks nfn model;evolutionary computing;hcm clustering based regression polynomial	In this paper, a new approach to estimate scaling factors of the fuzzy PID controller is presented. The performance of the fuzzy PID controller is sensitive to the variety of scaling factors. The design procedure dwells on the use of evolutionary computing (more specifically, a genetic algorithm) and estimation algorithm. The tuning of the scaling factors of the fuzzy PID controller is essential to the entire optimization process. And then we estimate scaling factors of the fuzzy PID controller by means of three types of estimation algorithms such as HCM (Hard C-Means) clustering-based regression polynomial, neuro-fuzzy networks, and regression polynomials. Numerical studies are presented in detail along with a detailed comparative analysis.	estimation theory;inverted pendulum	Sung-Kwun Oh;Witold Pedrycz;Seok-Beom Roh;Tae-Chon Ahn	2004	Eng. Appl. of AI	10.1016/j.engappai.2003.12.003	pid controller;qualitative comparative analysis;inverted pendulum;genetic algorithm;computer science;neuro-fuzzy;machine learning;estimation theory;evolutionary computation	AI	15.418281505524263	-20.45475926629518	195847
f6c18a927bd5a44ea345f8f756a7012ba322ba4a	comparison of two methods for predicting aqueous solubility		This study compares the solubility predictions of the two parameter general solubility equation (GSE) of Jain and Yalkowsky with the 171 parameter Klopman group contribution approach. Melting points and partition coefficients were obtained for each of the compounds from Klopman's test set. Using these two variables, the solubility of each compound was calculated by the GSE and compared to the values predicted by Klopman. Both methods give reasonable solubility predictions. The data of Klopman produced an average absolute error (AAE) of 0.71 and a root-mean-square error (RMSE) of 0.86, while the GSE had an AAE of 0.64 and a RMSE of 0.92.	arm accredited engineer;approximation error;coefficient;generic stream encapsulation;mean squared error;plant roots;population parameter;test set;acetylajmaline esterase activity	Debra L. Peterson;Samuel H. Yalkowsky	2001	Journal of chemical information and computer sciences	10.1021/ci010298s	chromatography;econometrics;chemistry;statistics	ML	12.144193656835148	-19.47766861972729	195885
3d7f9b32dcd45acd595fef6f39319eefd295f374	a stochastic bandit algorithm for scratch games		Stochastic multi-armed bandit algorithms are used to solve the exploration and exploitation dilemma in sequential optimization problems. The algorithms based on upper confidence bounds offer strong theoretical guarantees, they are easy to implement and efficient in practice. We considers a new bandit setting, called “scratch-games”, where arm budgets are limited and reward are drawn without replacement. Using Serfling inequality, we propose an upper confidence bound algorithm adapted to this setting. We show that the bound of expectation to play a suboptimal arm is lower than the one of UCB1 policy. We illustrate this result on both synthetic problems and realistic problems (ad-serving and emailing campaigns optimization).	ad serving;algorithm;chernoff bound;definition;dhrystone;experiment;jensen's inequality;mathematical optimization;multi-armed bandit;regret (decision theory);social inequality;synthetic intelligence;unbalanced circuit;web page	Raphaël Féraud;Tanguy Urvoy	2012			mathematical optimization;simulation;computer science;artificial intelligence;machine learning	ML	23.268344152225836	-17.489524948266872	195899
5588ae3e8bb1125133f051547fbf79e38e777f99	learning to play visual doom using model-free episodic control		Recently, the deep reinforcement learning has shown successful outcomes in classic video games (e.g., ATARI) and visual doom competition. Although itu0027s very powerful, it suffers from very long learning time to generalize its performance. For example, it takes about 7~15 days to produce a good controller for ATARI games with state-of-the art GPUs. In this work, we propose to speed up the visual-based learning by introducing episodic control into the Visual Doom platform. The episodic control memorizes agentu0027s experience with random projection and selects the next action based on similarity search on the memory. Because itu0027s a model-free learning, it does not require much time to generalize a model and speeds up learning by exploiting previous experience. This is the first time to apply the episodic control into the visual Doom platform. Experimental results show that it converges to the desirable performance faster than the deep Q network in basic environment.	atari;doom;graphics processing unit;random projection;reinforcement learning;similarity search	Byeong-Jun Min;Kyung-Joong Kim	2017	2017 IEEE Conference on Computational Intelligence and Games (CIG)	10.1109/CIG.2017.8080439	simulation;machine learning;control theory;reinforcement learning;computer science;visualization;speedup;computational intelligence;nearest neighbor search;artificial intelligence;random projection	Vision	19.344550889971917	-20.19483594131354	195941
4b5cfd53bdffe82b778dc2ad38fb3a1f7bb798d9	financial distress prediction study with adaptive genetic fuzzy neural networks on listed corporations of china	reasoning mechanism;optimal solution;financial data processing;fuzzy neural network;black box syndrome;fuzzy neural nets;convergence;fuzzy reasoning;adaptive genetic algorithm;genetic algorithms backpropagation convergence financial data processing fuzzy neural nets fuzzy reasoning;data collection;self learning capability;financial distress adaptive genetic bp algorithm fuzzy neural networks;backpropagation;genetics;financial distress;financial distress prediction;fuzzy rule partition financial distress prediction adaptive genetic fuzzy neural network chinese listed corporation self learning capability black box syndrome convergence back propagation reasoning mechanism;chinese listed corporation;artificial neural networks;adaptation model;adaptive genetic bp algorithm;hybrid system;mathematical model;fuzzy neural networks neural networks predictive models genetic algorithms fuzzy sets input variables adaptive systems fuzzy logic artificial intelligence computer science;predictive models;genetic algorithms;fuzzy neural networks;fuzzy rule partition;back propagation;adaptive genetic fuzzy neural network;data models;neural network	Neural networks (NNs) have been widely used to predict financial distress because of their excellent performances of treating non-linear data with self-learning capability. However, the shortcoming of NNs is also significant due to a ldquoblack boxrdquo syndrome. Moreover, in many situations NNs more or less suffer from the slow convergence and occasionally involve in a local optimal solution, which strongly limited their applications in practice. In this paper, a hybrid system combining fuzzy neural network and adaptive genetic algorithm - adaptive genetic fuzzy neural network (AGFNN) is proposed to overcome NNpsilas drawbacks. Furthermore, the new model has been applied to financial distress analysis based on the data collected from a set of Chinese listed corporations, and the results indicate that the performance of AGFNN model is much better than the ones of BPNN model and FNN model.	carpal tunnel syndrome;distress (novel);genetic algorithm;hybrid system;inventory;neural networks;neuro-fuzzy;nonlinear system;performance	Zhibin Xiong	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.715	computer science;artificial intelligence;backpropagation;machine learning;data mining;artificial neural network	Robotics	10.878516394529978	-22.247310843916026	196296
f779016fea20feda1c8580144e85168e5324f99b	prediction of chaotic time series using ls-svm with automatic parameter selection	genetic engineering;prediction error;support vector machines;information science;chaos;multilayer perceptrons;benchmark problem;chaotic time series;multilayer perceptron;time series;artificial neural networks;prediction methods;parameter selection;chaos least squares methods support vector machines genetic algorithms multilayer perceptrons prediction methods artificial neural networks educational institutions information science genetic engineering;genetic algorithm;genetic algorithms;cross validation;k fold cross validation;least squares methods;least squares support vector machine	Least squares support vector machine (LS-SVM) combined with genetic algorithm (GA) is used to predict chaotic time series. The LS-SVM can overcome some shortcoming in the multilayer perceptron and the GA is used to tune the LS-SVM parameters automatically. A benchmark problem, Hénon map time series, has been used as an example for demonstration. It is showed this approach can escape from the blindness of man-made choice of the LS-SVM parameters. It enhances the efficiency and the capability of prediction. Further, the GA is compared with cross-validation method for tuning LS-SVM parameters. The results reveal that the GA can obtain lower prediction errors than the k-folds cross validation method.	benchmark (computing);cross-validation (statistics);genetic algorithm;hénon map;least squares support vector machine;multilayer perceptron;software release life cycle;time series	Xiaodong Wang;Haoran Zhang;Changjiang Zhang;Xiushan Cai;Zhongjing Wang;Jinshan Wang	2005	Sixth International Conference on Parallel and Distributed Computing Applications and Technologies (PDCAT'05)	10.1109/PDCAT.2005.189	genetic algorithm;information science;computer science;artificial intelligence;machine learning;pattern recognition	Robotics	13.57835255437209	-23.88580686436542	196417
7f7e73ea3c56e545eb83f687cf5f0d7070d9a6a2	improving reinforcement learning agents using genetic algorithms	reinforcement learning;genetic algorithm;evolutionary algorithm	In this paper a new Reinforcement Learning algorithm was proposed. Q learning is a useful algorithm for agent learning in nondeterministic environment but it is a time consuming algorithm. The presented work applies an evolutionary algorithm for improving Reinforcement Learning algorithm.	genetic algorithm;reinforcement learning	Akram Beigi;Hamid Parvin;Nasser Mozayani;Behrouz Minaei-Bidgoli	2010		10.1007/978-3-642-15470-6_34	temporal difference learning;unsupervised learning;instance-based learning;error-driven learning;genetic algorithm;wake-sleep algorithm;cultural algorithm;computer science;artificial intelligence;online machine learning;machine learning;evolutionary algorithm;pattern recognition;leabra;learning classifier system;stability;reinforcement learning;id3 algorithm;active learning;population-based incremental learning;generalization error	AI	18.155296381033207	-21.629441768193406	196535
a27c8ddbf7598711d05a0a6f57df546829f8bb69	application of genetic programming and genetic algorithm in evolving emotion recognition module	training;emotion recognition;emotion recognition feature extraction training genetic programming genetic algorithms accuracy intelligent agents;genetic programming;accuracy;intelligent agents;feature extraction;intelligent agent evolutionary algorithm genetic programming genetic algorithm emotion recognition;genetic algorithms;parallel voting systems genetic programming genetic algorithm evolving emotion recognition module weighted credibility intelligent agent;image classification emotion recognition genetic algorithms	This paper will discuss about implementation of a voting system and weighted credibility to augment evolution process of an emotion recognition module. The evolution process of the emotion recognition module is one part of ongoing research on designing an intelligent agent capable of emotion recognition, interaction, and expression. Genetic programming evolves the classifiers, while genetic algorithm evolves the weighted credibility as a modification of parallel voting systems. The experimental results suggest that the implementation of weighted credibility evolution improves the performance of training, in the form of significantly reduced training time needed.	autonomous robot;computation;converge;credibility thesis;emotion recognition;genetic algorithm;genetic programming;intelligent agent;pareto efficiency	Rahadian Yusuf;Ivan Tanev;Katsunori Shimohara	2015	2015 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2015.7257058	genetic programming;genetic algorithm;feature extraction;computer science;artificial intelligence;machine learning;genetic representation;pattern recognition;accuracy and precision;intelligent agent	AI	14.772273582299558	-22.628585498213628	196571
0f4a784f031c82285e9d0571bbd5fa35aea345b7	a pythagorean-type fuzzy deep denoising autoencoder for industrial accident early warning		Early warning is crucial for preventing industrial accidents and mitigating damage, but current methods are often time-consuming, error-prone, and incompetent to deal with uncertainty. This paper presents a fuzzy deep neural network for early warning of industrial accidents, which equips the classical deep denoising autoencoder (DDAE) model with Pythagorean-type fuzzy parameters in order to enhance the model's representation ability and robustness. To efficiently train the fuzzy deep model, we propose a hybrid algorithm combining Hessian-free optimization and biogeography-based optimization metaheuristic to balance global search and local search. Experiments on datasets from several industrial zones in China show that the proposed Pythagorean-type fuzzy DDAE (PFDDAE) can achieve much higher accuracy of accident risk classification than the classical DDAE and the fuzzy DDAE using regular fuzzy parameters, and the proposed hybrid learning algorithm exhibits significant performance advantage over some other learning algorithms in training PFDDAE. In particular, a test on the 2014 Kunshan aluminum dust explosion accident shows that the deep learning model would be very likely to prevent the accident if it was adopted in advance.	artificial neural network;autoencoder;bayesian network;black bag operation;cognitive dimensions of notations;deep belief network;deep learning;differential evolution;experiment;fuzzy set;genetic algorithm;hessian;hybrid algorithm;hyper-heuristic;local search (optimization);machine learning;mathematical optimization;metaheuristic;noise reduction;restricted boltzmann machine;truncated newton method	Yu-Jun Zheng;Shengyong Chen;Jin-Yun Xue	2017	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2017.2738605	machine learning;mathematics;autoencoder;fuzzy logic;artificial neural network;deep learning;fuzzy set;metaheuristic;local search (optimization);artificial intelligence;warning system	AI	11.211270748637364	-23.486515248866038	196635
f24d5875bb3a6efa6ff0799ee10b5b9d993f4354	state of health prediction of lithium-ion batteries: multiscale logic regression and gaussian process regression ensemble		Abstract State of health (SOH) prediction plays a vital role in battery health prognostics. It is important to estimate the capacity of Lithium-ion battery for future cycle running. In this paper, a novel method is developed based on an integration of multiscale logic regression (LR) and Gaussian process regression (GPR) to tackle SOH estimation and prediction problem of Lithium-ion battery. Empirical mode decomposition is employed to decouple global degradation, local regeneration and various fluctuations in battery capacity time series. An LR model with varying moving window is utilized to fit the residuals (i.e., the global degradation trend). A GPR with the lag vector is developed to recursively estimate local regenerations and fluctuations. This design scheme captures the time-varying degradation behavior and reduces affections of local regeneration phenomenon in Lithium-ion batteries. The experimental results on Lithium-ion battery data from NASA Ames Prognostics Center of Excellence illustrate the potential applications of the proposed method as an effective tool for battery health prognostics.	kriging;state of health	Jianbo Yu	2018	Rel. Eng. & Sys. Safety	10.1016/j.ress.2018.02.022	hilbert–huang transform;reliability engineering;battery (electricity);prognostics;recursion;engineering;state of health;kriging;lag;lithium-ion battery	AI	10.512081012207423	-14.48633731783474	196681
16d70e8af45ca0ae2c1bb73f3be6628518d40b8f	self-organization in a perceptual network	biological models;data transmission;intelligent networks biological information theory circuits biology computing animal structures neuroscience genetics system testing neural networks constraint theory;processing 990210 supercomputers 1987 1989;general and miscellaneous mathematics computing and information science;communications;neural nets;self adjusting systems;data processing;computer networks;computer network;artificial intelligent;adaptive signal processing;single cell;network connectivity;pattern recognition;self adjusting systems information theory neural nets pattern recognition;artificial intelligence;self organization;optimization;network connections self organization neural networks perceptual network feature analyzing function multilayered networks optimization information theory visual system;knowledge representation;information theoretic;information theory	The emergence of a feature-analyzing function from the development rules of simple, multilayered networks is explored. It is shown that even a single developing cell of a layered network exhibits a remarkable set of optimization properties that are closely related to issues in statistics, theoretical physics, adaptive signal processing, the formation of knowledge representation in artificial intelligence, and information theory. The network studied is based on the visual system. These results are used to infer an information-theoretic principle that can be applied to the network as a whole, rather than a single cell. The organizing principle proposed is that the network connections develop in such a way as to maximize the amount of information that is preserved when signals are transformed at each processing stage, subject to certain constraints. The operation of this principle is illustrated for some simple cases.<<ETX>>	artificial intelligence;emergence;information theory;knowledge representation and reasoning;mathematical optimization;organizing (structure);self-organization;signal processing	Ralph Linsker	1988	Computer	10.1109/2.36	adaptive filter;self-organization;data processing;information theory;network formation;computer science;artificial intelligence;theoretical computer science;machine learning;network simulation;data transmission	ML	15.753544594929375	-23.893446475565668	196711
aa360af1e263db69a4a6f17b0bc6eda94759abb1	forecasting of coalbed methane (cbm) productivity based on rough set and least squares support vector machine		Coalbed methane (CBM) productivity is the comprehensive indicator for measuring potential gas production of CBM wells. The productivity directly affects the economic benefits of CBM project. Thus, the development of an effective CBM productivity prediction model presents guiding significance to the exploration and development of CBM Wells. CBM is saved in the coal reservoir, with its productivity determined by many geological factors. Since the complexity of the relationship between many geological factors, it is difficult to establish an accurate mathematical expressions to describe the dynamic process. This paper proposed a mixed model, based on a rough set (RS) and least squares support vector machine (LS-SVM), to predict the CBM productivity. Meanwhile, a coupling simulation annealing (CSA) algorithm has been adopted to optimize the kernel parameter of the LS-SVM and to obtain the most regularized parameter of the Kernel Function.	algorithm;least squares support vector machine;mixed model;rough set;simulated annealing;simulation	Haoming Xia;Yaochen Qin;Lijun Zhang;Yanping Cao;Jiaxing Xu	2017	2017 25th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2017.8090914	coalbed methane;kernel (linear algebra);data mining;kernel (statistics);support vector machine;computer science;mixed model;least squares support vector machine;rough set	Robotics	11.795361147069785	-18.97826256341287	196955
eb442f9e5da6d3379ea1763c25965330572437a4	irregularity detection on low tension electric installations by neural network ensembles	databases;filtering;low tension electric installations;measurement error;neural networks;neural nets;irregularity detection;training;public utilities;neural network ensemble;data mining;companies;inspection;artificial neural networks;power markets;power engineering computing;time series analysis;light s a company;energy consumption;public utilities neural nets power engineering computing power markets;intelligent system;light s a company irregularity detection low tension electric installations neural network ensembles brazilian electric utilities electricity concessionaries intelligent system;energy loss;rough sets;electric utilities;intelligent networks;electricity concessionaries;temperature;brazilian electric utilities;information analysis;neural networks artificial neural networks energy consumption databases intelligent networks filtering rough sets information analysis time series analysis temperature;rio de janeiro;neural network ensembles	The volume of energy loss that Brazilian electric utilities have to deal with has been ever increasing. The electricity concessionaries are suffering significant and increasing loss in the last years, due to theft, measurement errors and many other kinds of irregularities. Therefore, there is a great concern from those companies to identify the profile of irregular customers, in order to reduce the volume of such losses. This paper presents the proposal of an intelligent system, composed of two neural networks ensembles, which intends to increase the level of accuracy in the identification of irregularities among low tension consumers. The data used to test the proposed system are from Light S.A. Company, the Rio de Janeiro concessionary. The results obtained presented a significant increase in the identification of irregular customers when compared to the current methodology employed by the company.	artificial intelligence;artificial neural network;winsock	Cyro Muniz;Karla Figueiredo;Marley M. B. R. Vellasco;Gustavo Chavez;Marco Aurélio Cavalcanti Pacheco	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178985	filter;intelligent network;rough set;inspection;temperature;computer science;artificial intelligence;machine learning;time series;data mining;data analysis;artificial neural network;observational error	EDA	11.350853925327218	-15.48450273999596	196973
e16095f2def23305d5c2ad77edbca1e7d77b1d2a	learning complex dexterous manipulation with deep reinforcement learning and demonstrations		Dexterous multi-fingered hands are extremely versatile and provide a generic way to perform a multitude of tasks in human-centric environments. However, effectively controlling them remains challenging due to their high dimensionality and large number of potential contacts. Deep reinforcement learning (DRL) provides a model-agnostic approach to control complex dynamical systems, but has not been shown to scale to highdimensional dexterous manipulation. Furthermore, deployment of DRL on physical systems remains challenging due to sample inefficiency. Consequently, the success of DRL in robotics has thus far been limited to simpler manipulators and tasks. In this work, we show that model-free DRL can effectively scale up to complex manipulation tasks with a high-dimensional 24-DoF hand, and solve them from scratch in simulated experiments. Furthermore, with the use of a small number of human demonstrations, the sample complexity can be significantly reduced, which enables learning with sample sizes equivalent to a few hours of robot experience. The use of demonstrations result in policies that exhibit very natural movements and, surprisingly, are also substantially more robust. We demonstrate successful policies for object relocation, in-hand manipulation, tool use, and door opening, which are shown in the supplementary video.	algorithm;complex dynamics;driven right leg circuit;dynamical system;experiment;gradient;ibm notes;igor muttik;kohn–sham equations;noise shaping;reinforcement learning;relocation (computing);robotics;robustness (computer science);sample complexity;software deployment	Aravind Rajeswaran;Vikash Kumar;Abhishek Gupta;John Schulman;Emanuel Todorov;Sergey Levine	2018	CoRR	10.15607/RSS.2018.XIV.049	machine learning;artificial intelligence;computer science;relocation;scale-up;curse of dimensionality;robot learning;software deployment;small number;reinforcement learning;robotics	Robotics	21.115202176035588	-21.279340963628	197241
a2eee8ccedd515c2e2a915ba88a02d948ba3bd0f	thermodynamic analysis of variable speed refrigeration system using artificial neural networks	learning algorithm;experimental analysis;neural networks;refrigeration;predictive value;electric motor;backpropagation;system performance;performance model;thermodynamics;variable speed;experimental measurement;artificial neural network;neural network	This study presents thermodynamic performance modeling of an experimental refrigeration system driven by variable speed compressor using artificial neural networks (ANNs) with small data sets. Controlling the rotational speed of compressor with a frequency inverter is one of the best methods to vary the capacity of refrigeration system. For this aim, an experimental refrigeration system was designed with a frequency inverter mounted on compressor electric motor. The experiments were made for different compressor electric motor frequencies. Instead of several experiments, the use of ANNs had been proposed to determine the system performance parameters based on various compressor frequencies and cooling loads using results of experimental analysis. The backpropagation learning algorithm with two different variants was used in the network. In order to train the neural network, limited experimental measurements were used as training and test data. The best fitting training data set was obtained with eight neurons in the hidden layer. The results showed that the statistical error values of training were obviously within acceptable uncertainties. Also the predicted values were very close to actual values.	algorithm;artificial neural network;backpropagation;city of heroes;experiment;sigmoid function;transfer function	Önder Kizilkan	2011	Expert Syst. Appl.	10.1016/j.eswa.2011.03.052	electric motor;computer science;artificial intelligence;backpropagation;machine learning;refrigeration;artificial neural network;experimental analysis of behavior	ML	11.429174333979267	-19.902401884221348	197356
84d9cf32975989a48931e651df13af6d1b7857ca	measuring the distance between finite markov decision processes	reinforcement learning;kantorovich metric;transfer learning;hausdorff metric;markov decision process	Markov decision processes (MDPs) have been studied for many decades. Recent research in using transfer learning methods to solve MDPs has shown that knowledge learned from one MDP may be used to solve a similar MDP better. In this paper, we propose two metrics for measuring the distance between finite MDPs. Our metrics are based on the Hausdorff metric which measures the distance between two subsets of a metric space and the Kantorovich metric for measuring the distance between probabilistic distributions. Our metrics can be used to compute the distance between reinforcement learning tasks that are modeled as MDPs. The second contribution of this paper is that we apply the metrics to direct transfer learning by finding the similar source tasks. Our third contribution is that we propose two knowledge transfer methods which transfer value functions of the selected source tasks to the target task. Extensive experimental results show that our metrics are effective in finding similar tasks and significantly improve the performance of transfer learning with the transfer methods.	hausdorff dimension;markov chain;markov decision process;reinforcement learning	Jinhua Song;Yang Gao;Hao Wang;Bo An	2016			markov decision process;hausdorff distance;mathematical optimization;transfer of learning;computer science;artificial intelligence;machine learning;equivalence of metrics;reinforcement learning	AI	22.542753246809745	-17.77610509585453	197372
14254d3b0a96b91affdb8b834dfa4871539a0e4c	search space analysis of recurrent spiking and continuous-time neural networks	continuous time;neural networks recurrent neural networks stochastic processes chaotic communication neurons biological system modeling evolutionary computation navigation helium visualization;evolutionary computation;search space;nonlinear control systems;dynamic system;continuous time systems;spiking neural network;inverted pendulum recurrent continuous time neural network recurrent spiking neural network np hard problem stochastic search space analysis evolutionary algorithm dynamic system problem henon map;stochastic processes;henon mapping;inverted pendulum;stochastic processes continuous time systems evolutionary computation henon mapping nonlinear control systems pendulums recurrent neural nets search problems;search problems;recurrent neural nets;recurrent neural network;evolutionary algorithm;pendulums;stochastic search;neural network	The problem of designing recurrent continuous-time and spiking neural networks is NP-Hard. A common practice is to utilize stochastic searches, such as evolutionary algorithms, to automatically construct acceptable networks. The outcome of the stochastic search is related to its ability to navigate the search space of neural networks and discover those of high quality. In this paper we investigate the search space associated with designing the above recurrent neural networks in order to differentiate which network should be easier to automatically design via a stochastic search. Our investigation utilizes two popular dynamic systems problems; (1) the Henon map and (2) the inverted pendulum as a benchmark.	artificial neural network;benchmark (computing);display resolution;dynamical system;evolutionary algorithm;experiment;hénon map;information theory;inverted pendulum;james hoe;local search (optimization);recurrent neural network;spiking neural network;stochastic optimization;the spike (1997)	Mario Ventresca;Beatrice M. Ombuki-Berman	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.247076	stochastic neural network;inverted pendulum;pendulum;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;dynamical system;machine learning;evolutionary algorithm;control theory;mathematics;artificial neural network;evolutionary computation;spiking neural network	Robotics	16.06946116649591	-23.541658012575148	197636
