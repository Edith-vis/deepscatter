id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
76cf4564bb51ff4538ddf68412f329ada3b2bb68	automatic induction of a ccg grammar for turkish	word order	This paper presents the results of automatically inducing a Combinatory Categorial Grammar (CCG) lexicon from a Turkish dependency treebank. The fact that Turkish is an agglutinating free wordorder language presents a challenge for language theories. We explored possible ways to obtain a compact lexicon, consistent with CCG principles, from a treebank which is an order of magnitude smaller than Penn WSJ.	combinatory categorial grammar;lexicon;the wall street journal;treebank	Ruken Cakici	2005			word order;natural language processing;speech recognition;computer science;linguistics	NLP	-23.79453253442056	-75.67233979188387	1011
309c47cf61e7c18c9404ee8ddda4b6f765b08181	a multi-agent system for programming robots by human demonstration	task expert;programming expert;gesture-based programming;simple manipulative task;robotic skill;multi-agent system;robotic primitive;programming robot;robotic system;robotic agent;human demonstration;robotic equivalent	This paper e xplores Gesture-Based Programming as a paradigm for programming robotic agents. Gesture-Based Programming is a form of programming by human demonstration that focuses the de velopment of robotic systems on task experts rather than programming experts. The technique relies on the e xistence of pre viously acquired robotic skills (called “sensorimotor primitives”) which are intended to be the robotic equi valent of that which humans acquire through e veryday physical interactions. The interpretation of the human’ s demonstration and subsequent matching to robotic primiti ves is a qualitati ve problem that we approach with a community of skilled agents. A simple manipulati ve task is programmed to demonstrate the system.	fundamental interaction;multi-agent system;programming paradigm;robot	Richard M. Voyles;Pradeep K. Khosla	2001	Integrated Computer-Aided Engineering		computer vision;constraint programming;simulation;programming domain;reactive programming;functional reactive programming;computer science;artificial intelligence;robotic paradigms;programming paradigm;procedural programming;symbolic programming;inductive programming	Robotics	-32.9805635473752	-39.8910822278442	1020
d4f44bcb4b0483849c678fa95bf52628be1261fe	dimension of philosophy of technologies: critical theory and democratization of technologies	critical theory;philosophy of technology;teaching and learning;public policy	Philosophy of technology promises the possibility of an understanding of technology that may be important not only to public policy but also in helping to conceptualise intellectual approaches to the study of technology and, indeed, to shaping new fields of knowledge and research. Philosophy of technology may also have a role to play in relation not only to structuring a largely disparate and inchoate field but also more directly in teaching and learning about technology (Peters, et. al 2008).		Arun Kumar Tripathi	2008	Ubiquity	10.1145/1386858.1386861	public policy;philosophy of technology;management science;technology education;management;philosophy of computer science;critical theory	HCI	-77.26847149575666	-10.400781207184565	1029
ae124c904ac9c3937246db2badc80b458ed27143	bewelcome.org - a non-profit democratic hospex service set up for growth		This paper presents an extensive data-based analysis of the non-profit democratic hospitality exchange serv ice bewelcome.org. We hereby pursuit the goal of determining th e factors influencing its growth. It also provides general insights on internet-based hospitality exchange services. The othe r investigated services are hospitalityclub.org and couchsurfing.o rg. Communities using the three services are interconnected – comp aring their data provides additional information.	internet	Rustam Tagiew	2014	CoRR		hospitality;computer science;the internet;democracy;service set;knowledge management	ML	-67.63537966624669	-12.946638463635297	1030
25967f079722bf0c557c9872e764a94a54fb9611	the semantic interpretation of trust in multiagent interactions	trust;commitments;algorithms	In a multiagent system, a truster keeps estimating and revising its trust for a trustee based on its interactions with trustee. Understanding these interactions and estimating trust from them is an interesting and challenging topic and therefore, several works have been pursued in this direction. Scissors et al. (Scissors et al. 2009) explore the linguistic similarity in chat messages to estimate trust between message senders and receivers. Adalı et al. (Adalı, Sisenda, and Magdon-Ismail 2012) calculate the relationship strength between two users in Twitter based on their different social and behavioral aspects. (DuBois, Golbeck, and Srinivasan 2011) provide an algorithm to compute trust and distrust in a social network. The above approaches are promising but they are limited to numerical heuristics. Such approaches are justifiably criticized for missing the essential intuitive considerations of trust, e.g., regarding the autonomy of the participants and the vulnerability of the truster to decisions by the trustee. The richer approaches, however, have not lent themselves well to computational techniques that could be applied in practice (Castelfranchi and Falcone 2010). Therefore, we seek to bridge the above gap between theory and practice. Specifically, we propose a computational model of trust founded on commitments that supports agents determining their trust for others based on their interactions.	agent-based model;algorithm;computation;computational model;cristiano castelfranchi;distrust;heuristic (computer science);interaction;multi-agent system;numerical analysis;semantic interpretation;social network	Anup K. Kalia	2014			computer science;artificial intelligence;data mining;trustworthy computing	AI	-20.842230348890816	-11.133356864274019	1035
7a29ba9fb737e23bda194a7583bf8dd0c50903d3	morphology generation for swiss german dialects	serveur institutionnel;archive institutionnelle;open access;archive ouverte unige;cybertheses;institutional repository	Most work in natural language processing is geared towards written, standardized language varieties. In this paper, we present a morphology generator that is able to handle continuous linguistic variation, as it is encountered in the dialect landscape of German-speaking Switzerland. The generator derives inflected dialect forms from Standard German input. Besides generation of inflectional affixes, this system also deals with the phonetic adaptation of cognate stems and with lexical substitution of non-cognate stems. Most of its rules are parametrized by probability maps extracted from a dialectological atlas, thereby providing a large dialectal coverage.	mathematical morphology;switzerland	Yves Scherrer	2011		10.1007/978-3-642-23138-4_9	natural language processing;speech recognition;engineering;linguistics	NLP	-30.265453807289976	-75.94059016297713	1037
7bf3fd0f93d5f16490785399c194acc10689c038	voice interactive classroom, a service-oriented software architecture for speech-enabled learning	software;sistema interactivo;channel access;semiconductor optical amplifiers;acceso multiple;teleenseignement;acces multiple;voice interactive learning;learning;logiciel;acoplamiento modo;service orientation;couplage mode;logicial personalizado;classroom;systeme conversationnel;aprendizaje;intergiciel;4260d;software architecture;apprentissage;internet;amplificateur optique semiconducteur;interactive system;ubiquitous learning;aula clase;interactive learning;logicial;service oriented architecture soa;middleware;teleensenanza;remote teaching;multiple access;service oriented architecture;salle cours;mode coupling;architecture logiciel	Software technology is creating a ubiquitous context for human living and learning in which new modes of interaction are gradually being incorporated. Speech-enabled software brings a new way of interacting with the Internet, but auditory access to web resources needs to be more broadly supported by software architectures. This paper introduces ''Voice Interactive Classroom'', a software solution that proposes a middleware approach to provide cross-platform multi-channel access to internet-based learning.	service-oriented device architecture;software architecture	Víctor Manuel Álvarez García;María del Puerto Paule Ruíz;Juan Ramón Pérez Pérez	2010	J. Network and Computer Applications	10.1016/j.jnca.2010.03.005	embedded system;simulation;telecommunications;computer science;artificial intelligence;social software engineering;software framework;component-based software engineering;software development;software design description;operating system;service-oriented architecture;middleware;multimedia;software walkthrough;software analytics;resource-oriented architecture;law;software system	ML	-46.850140788716054	-26.7950187602647	1049
9c0698bf985747cec59555734f45a42f1da472e3	integration of “omics” data and phenotypic data within a unified extensible multimodal framework	hpc;biostatistics;database;genomics;integrative neuroscience;omics analysis;reproducibility;workflow	"""Analysis of """"omics"""" data is often a long and segmented process, encompassing multiple stages from initial data collection to processing, quality control and visualization. The cross-modal nature of recent genomic analyses renders this process challenging to both automate and standardize; consequently, users often resort to manual interventions that compromise data reliability and reproducibility. This in turn can produce multiple versions of datasets across storage systems. As a result, scientists can lose significant time and resources trying to execute and monitor their analytical workflows and encounter difficulties sharing versioned data. In 2015, the Ludmer Centre for Neuroinformatics and Mental Health at McGill University brought together expertise from the Douglas Mental Health University Institute, the Lady Davis Institute and the Montreal Neurological Institute (MNI) to form a genetics/epigenetics working group. The objectives of this working group are to: (i) design an automated and seamless process for (epi)genetic data that consolidates heterogeneous datasets into the LORIS open-source data platform; (ii) streamline data analysis; (iii) integrate results with provenance information; and (iv) facilitate structured and versioned sharing of pipelines for optimized reproducibility using high-performance computing (HPC) environments via the CBRAIN processing portal. This article outlines the resulting generalizable """"omics"""" framework and its benefits, specifically, the ability to: (i) integrate multiple types of biological and multi-modal datasets (imaging, clinical, demographics and behavioral); (ii) automate the process of launching analysis pipelines on HPC platforms; (iii) remove the bioinformatic barriers that are inherent to this process; (iv) ensure standardization and transparent sharing of processing pipelines to improve computational consistency; (v) store results in a queryable web interface; (vi) offer visualization tools to better view the data; and (vii) provide the mechanisms to ensure usability and reproducibility. This framework for workflows facilitates brain research discovery by reducing human error through automation of analysis pipelines and seamless linking of multimodal data, allowing investigators to focus on research instead of data handling."""		Samir Das;Xavier Lecours Boucher;Christine Rogers;Carolina Makowski;François Chouinard-Decorte;Kathleen Oros Klein;Natacha Beck;Pierre Rioux;Shawn T. Brown;Zia Mohaddes;Cole Zweber;Victoria Foing;Marie Forest;Kieran J. O’Donnell;J Clark;Michael J. Meaney;Celia M. T. Greenwood;Alan C. Evans	2018		10.3389/fninf.2018.00091	data mining;extensibility;omics;computer science;bioinformatics	HPC	-49.6363509806919	-64.76239526413757	1052
0d8ca00614ba204a7b739f257d0b1a094dfac448	straw-like user interface (ii): a new method of presenting auditory sensations for a more natural experience	dynamic change;user interface;medical care;virtual reality;tactile display;tactile interface;food texture;virtual reality sound effect;physical model;augmented reality;drinking sensation;natural experiment	We have proposed a new type of audio-tactile interface called the Straw-like User Interface (SUI) that allowed users to virtually experience the sensations of drinking with straw. The sensations were created based on data of pressure, vibration and sound recorded during drinking with a straw. The device enabled us to develop many unique interfaces, facilitating extension of research fields related to tactile displays, from medical care to entertainment. However, with the previous system, the recorded data were replayed at the same speed without reference to the suction power, and so the sensation became unnatural. In this paper we propose a simple technique to preserve naturalness. We dynamically change the play list in accordance with the user’s behavior. We believe that the proposed method provides a simple approach to record-andreplay of audio-tactile information without needing a physical model.	mixed reality;user interface	Yuki Hashimoto;Masahiko Inami;Hiroyuki Kajimoto	2008		10.1007/978-3-540-69057-3_62	simulation;engineering;multimedia;communication	HCI	-45.98825586834058	-38.66056101819256	1059
e2405f442aa03b520672bfc24af5f1a60bad0b17	predicting asthma-related emergency department visits using big data	environmental sensors;google;surveillance data;social networking online big data diseases emergency services medical information systems;market research;emergency department visits;surveillance;asthma;predictive modeling;social media data;twitter diseases surveillance google predictive models media market research;google search interests;chronic conditions;media;targeted patient interventions;big data;medical information systems;asthma related emergency department;targeted patient interventions asthma related emergency department big data chronic conditions surveillance data national asthma disease surveillance systems multiple data sources google search interests environmental sensor data social media data public health surveillance;social networking online;multiple data sources;diseases;predictive modeling asthma big data emergency department visits environmental sensors;predictive models;emergency department ed visits;twitter;social media;public health surveillance;environmental sensor data;emergency services;national asthma disease surveillance systems	Asthma is one of the most prevalent and costly chronic conditions in the United States, which cannot be cured. However, accurate and timely surveillance data could allow for timely and targeted interventions at the community or individual level. Current national asthma disease surveillance systems can have data availability lags of up to two weeks. Rapid progress has been made in gathering nontraditional, digital information to perform disease surveillance. We introduce a novel method of using multiple data sources for predicting the number of asthma-related emergency department (ED) visits in a specific area. Twitter data, Google search interests, and environmental sensor data were collected for this purpose. Our preliminary findings show that our model can predict the number of asthma ED visits based on near-real-time environmental and social media data with approximately 70% precision. The results can be helpful for public health surveillance, ED preparedness, and targeted patient interventions.	accident and emergency department;big data;digital data;erectile dysfunction;google search;patients;real-time clock;real-time computing;social media;interest	Sudha Ram;Wenli Zhang;Max Williams;Yolande Pengetnze	2015	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2015.2404829	market research;predictive analytics;media;big data;social media;medicine;computer science;machine learning;data mining;predictive modelling;medical emergency;computer security	ML	-58.063175197755896	-68.07241152205644	1063
3012f4a925cc7b8fa1731a89b1a07639163c6dc8	contextual information improves oov detection in speech	contextual information	Out-of-vocabulary (OOV) words represent an important source of error in large vocabulary continuous speech recognition (LVCSR) systems. These words cause recognition failures, which propagate through pipeline systems impacting the performance of downstream applications. The detection of OOV regions in the output of a LVCSR system is typically addressed as a binary classification task, where each region is independently classified using local information. In this paper, we show that jointly predicting OOV regions, and including contextual information from each region, leads to substantial improvement in OOV detection. Compared to the state-of-the-art, we reduce the missed OOV rate from 42.6% to 28.4% at 10% false alarm rate.	acoustic cryptanalysis;acoustic model;argument (complex analysis);automated system recovery;baseline (configuration management);binary classification;conditional random field;downstream (software development);exptime;emoticon;finite-state machine;fred (chatterbot);language model;pipeline (computing);principle of maximum entropy;sensor;speech analytics;speech recognition;vocabulary	Carolina Parada;Mark Dredze;Denis Filimonov;Frederick Jelinek	2010			speech recognition;computer science;machine learning;pattern recognition	NLP	-16.785840056924414	-88.85392123447983	1064
8fb9d894185f1b78007e8b2d65dbb3402ab0e31f	unified neutral theory of biodiversity and biogeography	neutral theory;chapter			Egbert G. Leigh;James Rosindell;Rampal S. Etienne	2010	Scholarpedia	10.4249/scholarpedia.8822	neutral theory of molecular evolution;physics	Logic	-40.73579618018723	-11.332537173304239	1070
ce5fcae32dfcec5d17a66508aa9dcc937117bae2	research note: analysis of the characteristics of victims in information security incident damages: the case of japanese internet users		In this article, the authors investigate the attributes of victims in information security incident damages for the purpose of reducing the damages. The Information-Technology Promotion Agency, Japan, in 2010, conducted an Internet survey targeted to Japanese Internet home users entitled, “Survey of awareness toward information security incidents” that is used in this article. Using micro data collected from this survey, they employed multinomial logit regression analysis to show factors affecting the user’s experience of the incidents of damage through particular incidents. They concluded that the overconfidence regarding information security knowledge increased the probability for phishing and spoofing.	information security	Ken-ichi Hanamura;Toshihiko Takemura;Ayako Komatsu	2013	The Review of Socionetwork Strategies	10.1007/s12626-013-0032-6	public relations;advertising;computer security	NLP	-69.73070381276627	-10.145741626193244	1073
a778a7b5940deda0b24fecd1d6625495dd6c3d79	data fusion as source for the generation of useful knowledge in context-aware systems			context-aware pervasive systems	Julio Muñoz;Guillermo Molero-Castillo;Edgard Benítez-Guerrero;Everardo Bárcenas	2018	Journal of Intelligent and Fuzzy Systems	10.3233/JIFS-169500	machine learning;artificial intelligence;mathematics;sensor fusion	Robotics	-37.74675625726689	-12.257576236982818	1076
d6c8b963c233c6e31e41cebb4a2912953fdbb92f	an holistic approach to software quality : the development of a contingent model			contingency (philosophy);holism;software quality	P. Bennetts	2000				SE	-68.38444635099474	2.732888335770502	1082
ac0bc0305761cc28da8f8f3f1a574e6c0da1701a	a qualitative approach to understanding variations in experiences and its relationship to learning: an introduction to phenomenography		Phenomenography has been increasingly used to explore important questions and complex phenomena in engineering education. However, as a relatively new research method (it was introduced in 1981) with unique and nuanced methodological underpinnings, it is not always well understood. In this special session, we will provide an overview of phenomenography methodology. In addition, participants will gain experience in conducting phenomenographic analysis and interacting with real data. Finally, participants will discuss implications of phenomenographic analysis and potential applications in their teaching and research activities.	experience;interaction	Carla B. Zoltowski;Nicholas D. Fila;Emily Dringenberg	2017	2017 IEEE Frontiers in Education Conference (FIE)	10.1109/FIE.2017.8190497	data collection;knowledge management;sociology;phenomenography;engineering education	Visualization	-63.51840583005868	-35.22766623221681	1090
96da3b9694d58db26894ec6306884cb94947ad48	an optimized backout mechanism for sequential updates	data base;management system;key-sorted data base;sequential updates;online data base;db1 data base application;optimized backout mechanism;weizmann institute;backout mechanism;new argument;special characteristic	"""It has been recently show that the technique of periodic updating of a key-sorted data base from a key-sorted """"transaction file"""" may be considered to be used even in online data bases. In this paper, a backout mechanism is described which exploits the special characteristics of this technique thus, adding new arguments to justify the employnent of an option for batch and sequential updates in data bases. A formula is developed to enable the user to tune this backout mechanism according to parameters that characterize his application and his installation. The backout mechanism described here is implemented at the Weizmann Institut in its DB1 data base applications management system (DBAMS)."""	database	Joel Arditi	1979	Fifth International Conference on Very Large Data Bases, 1979.		real-time computing;computer science;data mining;algorithm	DB	-30.60330538681137	2.5560544701397574	1091
6bfc87bf7449e3ed8f4603b955613a5cfa56a6c1	a new control owner switching system for multiple tv viewers via face recognition	detectors;deviceless remote control switching method multiple tv viewers multiuser face recognition head gesture recognition rotation invariant deviceless tv control owner switching system;face recognition face switches face detection tv detectors;face recognition;telecontrol face recognition gesture recognition interactive television;face;tv;face detection;switches	Through the development of pattern recognition methods, many researchers have proposed various systems to control a TV that can be activated automatically without devices. In this paper, we propose a control owner switching system of TV via multi-user face recognition and head gesture recognition. We mainly focus on rotation invariant and wide-range (up to four meters) multi-user face recognition so that the system can be applied to indoor environments. In addition, we propose a deviceless TV control owner switching system using a small behavior of the user. As a method of switching, we suggest switching the TV control ownership by shaking the user's head from left to right for a few times. Experimental result shows that switching system is perfect for transferring control ownership.	facial recognition system;gesture recognition;multi-user;pattern recognition	Jeongwoo Ju;Dongwoon Han;Jiwhan Kim;Injae Lee;Jihun Cha;Junmo Kim	2015	2015 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2015.7066431	facial recognition system;face;computer vision;detector;face detection;network switch;computer science;gesture recognition;multimedia	Robotics	-38.79973056595609	-43.57789014379146	1094
cfd8259caaf7583a86c68b0ff3fc52b12c1342c9	a study of information retrieval on accumulative social descriptions using the generation features	web pages;generation process;information retrieval;social document;anchor text;power law distribution;empirical evaluation;accumulative social descriptions	This paper is concerned with the study of information retrieval (IR) on Accumulative Social Descriptions (ASDs). ASDs refer to Web texts that accumulated by many Web users describing certain Web resources, such as anchor texts, search logs and social annotations. There have been some studies working on leveraging ASDs for improving search performance in both internet and intranet. However, to the best of our knowledge, no prior study has concerned the specific generation features of ASDs, which are the focus point of this paper. Specifically, we consider the generation features from two perspectives, the generation processes and the generated distributions. Further, three probabilistic IR models are derived based on them. The three models are first demonstrated with one toy dataset and then empirically evaluated with two real datasets: an internet dataset consisting of 90,295 Web pages, with 25,845,818 social annotations crawled from Del.icio.us and 31,320,005 pieces of anchor texts crawled through Yahoo! API, and an intranet dataset consisting of 179,835 Web pages with 1,245,522 annotations dumped from the intranet tagging system in IBM, named as Dogear. Extensive experimental results show that the proposed methods, which fully leverage the generation features of ASDs, improve the performance of both internet and intranet search significantly.	application programming interface;information retrieval;intranet;web page;web resource;world wide web	Lichun Yang;Shengliang Xu;Shenghua Bao;Dingyi Han;Zhong Su;Yong Yu	2009		10.1145/1645953.1646045	natural language processing;anchor text;computer science;artificial intelligence;pareto distribution;machine learning;web page;data mining;database;world wide web;information retrieval	Web+IR	-28.463856627712946	-54.61841757839543	1096
7e498019e2b01933c2cdcff884993474d7150a3a	teaching the first programming course with python's turtle graphic library	first programming course;pedagogical tool;motivation;game oriented;specific assignments;teaching	How to keep students interested in a CS1 course is not new to those who teach the subject. This work describes our experience in the use of Python with its Turtle Graphic Library in a game-oriented approach that seeks to increase the interest and motivation of students. We present the assignment for branch, loops and functions: the simulation of a basic game with a spaceship that can shoot a bullet to the enemy. Our experience has shown us that students get engaged and motivate themselves with the graphical component. We have found an improvement in students' grades.	computer graphics;graphical user interface;python;simulation;spaceship (cellular automaton);turtle graphics	Elizabeth Vidal Duarte	2016		10.1145/2899415.2925499	education;simulation;motivation;computer science;software engineering;multimedia;programming language;pedagogy	HCI	-82.61693847346368	-37.29662840450734	1103
d8f4345e7795dab59179b7d5d13d0f234f514210	rethinking schooling - edited by ian westbury & geoffrey milburn				Diana Battersby	2008	BJET	10.1111/j.1467-8535.2008.00908_17.x		Vision	-54.77413661180653	-16.26214592032087	1105
2451a6af4d4a3e332a6f7652e35c01eadcfc7ac1	the flamingo software package on approximate string queries	large data sets;approximate string search;software package;data cleaning;flamingo package;similarity search;open source software	An important operation in data cleaning is similarity search on textual strings. A simple example is “finding actor names similar to schwarzeneger,” given the fact that few people know the exact spelling of our former governor in California. It is challenging to support this operation efficiently on large amounts of data. Despite its importance, the problem did not receive enough attention in the research community a decade ago. In this talk, I will give an overview of recent results on this problem, and describe the development history of the Flamingo package, an open-source software that supports efficient approximate string queries. I will also describe my outreach activities to apply our research results of data cleaning in real applications, which led to a startup called Bimaple that specializes in powerful instant search on large data sets.	approximation algorithm;google search;open-source software;plasma cleaning;similarity search	Chen Li	2011		10.1007/978-3-642-20244-5_45	computer science;theoretical computer science;data mining;database;nearest neighbor search;data cleansing;programming language	DB	-32.83505141784649	-2.0252140405823176	1110
33ff2582bff06988d2684eb4de02b3f13ec6a8f6	semi-supervised training of acoustic models using lattice-free mmi		The lattice-free MMI objective (LF-MMI) has been used in supervised training of state-of-the-art neural network acoustic models for automatic speech recognition (ASR). With large amounts of unsupervised data available, extending this approach to the semi-supervised scenario is of significance. Finite-state transducer (FST) based supervision used with LF-MMI provides a natural way to incorporate uncertainties when dealing with unsupervised data. In this paper, we describe various extensions to standard LF-MMI training to allow the use as supervision of lattices obtained via decoding of unsupervised data. The lattices are rescored with a strong LM. We investigate different methods for splitting the lattices and incorporating frame tolerances into the supervision FST. We report results on different subsets of Fisher English, where we achieve WER recovery of 59-64% using lattice supervision, which is significantly better than using just the best path transcription.	acoustic cryptanalysis;artificial neural network;decoding methods;finite-state transducer;semi-supervised learning;semiconductor industry;speech recognition;transcription (software);unsupervised learning;word error rate	Vimal Manohar;Hossein Hadian;Daniel Povey;Sanjeev Khudanpur	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8462331	artificial intelligence;decoding methods;artificial neural network;lattice (order);pattern recognition;computer science	NLP	-19.185216612357785	-78.65721431536925	1116
66c10af97cc34fe48b3ba950b98d04ea87137799	information seeking motivation scale development: a self-determination perspective		PurposernrnrnrnrnUsing self-determination motivation theory as a theoretical framework, the purpose of this paper is to examine information seeking motivation at the domain level in higher education setting.rnrnrnrnrnDesign/methodology/approachrnrnrnrnrnConfirmatory factor analysis was used to validate the Information Seeking Motivation Scale – College Version (ISMS – C).rnrnrnrnrnFindingsrnrnrnrnrnISMS – C was validated in the information seeking context. Consistent with self-determination theory (SDT), the results imply that students approach research tasks for both controlled and autonomous reasons.rnrnrnrnrnResearch limitations/implicationsrnrnrnrnrnAll constructs representing extrinsic and intrinsic motivation on a continuum were confirmed. However, amotivation proved difficult to define with the current sample. Additional studies need to be conducted in higher education setting in order to confirm its existence.rnrnrnrnrnPractical implicationsrnrnrnrnrnGiven that the situational motivation is contingent on domain-level motivation, the ISMS – C scale can be helpful in promoting lasting intrinsic information seeking motivation at that level.rnrnrnrnrnOriginality/valuernrnrnrnrnConsistent with the subjectivist orientation in information sciences which aims to account for cognitive and affective forces behind information need, ISMS constructed in the current study is one of the first measurement instruments to account for a spectrum of information seeking motivations at the domain level.	information seeking	Ana Dubnjakovic	2017	Journal of Documentation	10.1108/JD-03-2017-0032	computer science;information retrieval;cognitive psychology;confirmatory factor analysis;information needs;cognitive evaluation theory;self-determination theory;social psychology;goal theory;situational ethics;information science;information seeking	Visualization	-75.51402011940469	-41.31544831461653	1124
119f2c43f5f976d434819ef0821f69f32e1ea7cd	kmi, the open university at ntcir-9 crosslink: cross-lingual link discovery in wikipedia using explicit semantic analysis		This paper describes the methods used in the submission of Knowledge Media institute (KMI), The Open University to the NTCIR-9 Cross-Lingual Link Discovery (CLLD) task entitled CrossLink. KMI submitted four runs for link discovery from English to Chinese; however, the developed methods, which utilise Explicit Semantic Analysis (ESA), are applicable also to other language combinations. Three of the runs are based on exploiting the existing cross-lingual mapping between different versions of Wikipedia articles. In the fourth run, we assume information about the mapping is not available. Our methods achieved encouraging results and we describe in detail how their performance can be further improved. Finally, we discuss two important issues in link discovery: the evaluation methodology and the applicability of the developed methods across different textual collections.	bigraph;esa;explicit semantic analysis;semantic similarity;wikipedia	Petr Knoth;Lukás Zilka;Zdenek Zdráhal	2011			computer science;data science;data mining;world wide web	AI	-31.002444838163456	-63.38304906941604	1127
a4e7dcb1bdb7e421039460a0cc2831287003ec7f	an overview of knowledge management research viewed through the web of science (1993-2012)	web of science;knowledge management;information visualization;research work;bibliometric analysis	Purpose – The purpose of this paper is to present a bibliometric analysis of scientific output of the knowledge management (KM), the aim being to offer an overview of research activity in this field and characterize its most significant aspects. In addition, this study aims to quantitatively analyze KM research trends, forecasts, and citations from 1993 to 2012 in Web of Science (WOS). Design/methodology/approach – A total of 12,925 documents related to KM research were collected from following databases: Science Citation Index Expanded, Social Sciences Citation Index, Arts & Humanities Citation Index, Conference Proceedings Citation Index-Science, and Conference Proceedings Citation Index-Social Science & Humanities. These documents were carefully reviewed and subjected to bibliometric data analysis techniques. Findings – A number of research questions pertaining to patterns in scientific outputs, subject categories and major journals, author keywords frequencies, characteristics of the international collaboration, most cited papers and significant papers distribution of KM research were proposed and answered. In addition, there are five research sights on KM research are as follows: management science, computer science, information science, business, and engineering. Based on these findings, many implications emerged that improve one’s understanding of the identity of KM as a distinct multi-discipline scientific field. Research limitations/implications – Comprehensiveness and inclusiveness of the analyzed KM-related data set in WOS because of some KM-centric journals are not indexed by Thomson Reuters. Originality/value – The paper offers an overview and evaluation of research activity into the KM viewed through the WOS during 1993-2012.	bibliometrics;citation analysis;co-citation;computer science;database;embnet.journal;expert system;field research;information management;information science;information system;knowledge base;knowledge management;library science;management science;management system;semantic web;social sciences citation index;web of science	Junping Qiu;Hong Lv	2014	Aslib J. Inf. Manag.	10.1108/AJIM-12-2013-0133	library science;computer science;data science;data mining	DB	-75.39726299169378	-18.731349640565032	1128
fb60aacb59630b72629acd247bd98e70430db5d4	beautiful javascript: how to guide students to create good and elegant code	client side;web application;development of professional competencies in computer science;programming guidelines;module pattern;modularity;javascript;form validation;procedural guidelines;design principles	Programming is a complex task, which should be taught using authentic exercises, with supportive information and procedural information. Within the field of Computer Science, there are few examples of procedural information that guide students in how to proceed while solving a problem. We developed such guidelines for programming tasks in JavaScript, for students who have already learned to program using an object oriented language.  Teaching JavaScript in an academic setting has advantages and disadvantages. The disadvantages are that the language is interpreted so there is no compiler to check for type errors, and that the language allows many 'awful' constructs. The advantage is that, because of those disadvantages, programmers should consciously apply rules for 'good' programs, instead of being able to rely on the errors and warnings that a compiler will raise.  In this article, we show how we guide students to develop elegant code in JavaScript, by giving them a set of guidelines, and by advising a process of repeated refactoring until a program fulfills all requirements. To show that these guidelines work, we describe the development of a generic module for client-side form validation. The process followed and the resulting module both are valuable in an educational setting. As an example, it shows and explains precisely to students how such a module can be developed by following our guidelines, step by step.	client-side;code refactoring;compiler;computer science;consciousness;javascript;procedural programming;programmer;requirement	Harrie Passier;Sylvia Stuurman;Harold Pootjes	2014		10.1145/2691352.2691358	simulation;computer science;programming language	PL	-81.62402722595152	-37.507006669912094	1135
46a905ba5ead0eb75f51fe6a96b9ce3a64076ac4	design and implementation of an emergency environmental response system to protect migrating salmon in the lower san joaquin river, california	emergency response;water resource;decision support;management system;data integrity;dissolved oxygen;real time;dissolved oxygen decision support modeling algae;54 dissolved oxygen decision support modeling algae;web accessibility;data management;pacific ocean;forecasting model;deep water ship channel;design and implementation;san joaquin river;algae;water supply system;modeling;long term survival;data management system;water quality monitoring	In the past decade tens of millions of dollars have been spent by water resource agencies in California to restore the native salmon fishery in the San Joaquin River and its major tributaries. An excavated deep water ship channel (DWSC), through which the river runs on its way to the Bay/Delta and Pacific Ocean, experiences episodes of low dissolved oxygen which acts as a barrier to anadromous fish migration and a threat to the long-term survival of the salmon run. An emergency response management system is under development to forecast these episodes of low dissolved oxygen and to deploy measures that will raise dissolved oxygen concentrations to prevent damage to the fishery resource. The emergency response management system has been designed to interact with a real-time water quality monitoring network and is served by a comprehensive data management and forecasting model toolbox. The Bay/Delta and Tributaries (BDAT) Cooperative Data Management System is a distributed, web accessible database that contains terabytes of information on all aspects of the ecology of the Bay/Delta and upper watersheds. The complexity of the problem dictates data integration from a variety of monitoring programs. A unique data templating system has been constructed to serve the needs of cooperating scientists who wish to share their data and to simplify and streamline data uploading into the master database. In this paper we demonstrate the utility of such a system in providing decision support for management of the San Joaquin River fishery. We discuss how the system might be expanded to have further utility in coping with other emergencies and threats to water supply system serving California's costal communities.	adobe streamline;decision support system;ecology;ecosystem;management system;real-time clock;terabyte;upload	Nigel W. T. Quinn;Karl C. Jacobs	2007	Environmental Modelling and Software	10.1016/j.envsoft.2005.12.009	systems modeling;decision support system;environmental engineering;data management;hydrology;computer science;oxygen saturation;web accessibility;data integrity;management system;ecology;algae	DB	-12.849681981801895	-21.26260866706669	1136
05760c25eefd7d0b0a7b9b1a4c7a25b29f7d2356	developing a climbing maintenance robot for tower and rotor blade service of wind turbines		Today, more than 275.000 wind turbines generate over 400 GW electrical power worldwide [1]. So the demand for maintenance constantly raises. Since September 2014 the University of Applied Sciences Aachen and industrial partners develop SMART (Scanning, Monitoring, Analyzing, Repair and Transportation), a maintenance platform for wind turbines. The research project is funded by the German federal ministry of economic affairs and energy (BMWi), to support the upcoming industrial needs. While the reliability of the mechanical parts, like main bearing, generator, gears and main shaft increased during the recent years, the maintenance and improvement of rotor blades should be improved. A weatherproof cabin for rotor blade maintenance can extend the annual maintenance period from eight to twelve months, a major goal of the SMART development. In addition, a unique climbing mechanism for conical shaped, thin and slippery surfaces is generated and tested. SMART successfully completed the proof-of-concept milestone by demonstrating the climbing process in Decem-	gw-basic;r.o.t.o.r.;robot;smart	Josef Schleupen;Heiko Engemann;Mohsen Bagheri;Stephan Kallweit;Peter Dahmann	2016		10.1007/978-3-319-49058-8_34	automotive engineering;marine engineering;engineering drawing	Robotics	-45.09567243371928	-4.241818556579916	1138
5a5c0fa86ac185ce91f1de9221fa24a505e96dea	generating ordered list of recommended items: a hybrid recommender system of microblog		While Tencent has the biggest microblog user groups, Sina Microblog took a commanding lead with 56.5% of China’s microblogging market based on active users, and 86.6% based on browsing time over its competitors[3]. The existance of fake user group, widely used spammer strategy [4], and weird definition of active users considering those who write(including retweets and comments) or read microblog messages no matter directly on the website or via third-party port or associated platforms as acitve users contribute to the fake prosperity of Tencent Microblog which is far from the public perception. Another problem of Tencent Microblog is the low percentage of accepted item recommendation, less than 9% according to our sampling[5]. The item list doesn’t update in time, and the recommendation often deviates from the preference of users.	recommender system;spamming;tencent qq	Yingzhen Li;Yingjie Zhang	2012	CoRR		computer science;data mining;internet privacy;world wide web;information retrieval	ECom	-22.63164819365551	-50.52772748125008	1148
babb8104139f94a096f0985f3539837e5077bb6f	who talks tcp? - survey of 8 february 83				Dave Smallberg	1983	RFC	10.17487/RFC0843		Mobile	-55.01212177793353	-5.367818275631962	1155
58b09061ff57782e337265c45a3196a45d283cbc	on extensions of the core and the anticore of transferable utility games	maastricht university;transferable utility;anticore;microeconomics;digital archive;core;open access;min prenucleolus;publication;scientific;pareto optimality;institutional repository;core extension;transferable utility game	We consider several related set extensions of the core and the anticore of games with transferable utility. An efficient allocation is undominated if it cannot be improved, in a specific way, by sidepayments changing the allocation or the game. The set of all such allocations is called the undominated set, and we show that it consists of finitely many polytopes with a core-like structure. One of these polytopes is the L1-center, consisting of all efficient allocations that minimize the sum of the absolute values of the excesses. The excess Pareto optimal set contains the allocations that are Pareto optimal in the set obtained by ordering the sums of the absolute values of the excesses of coalitions and the absolute values of the excesses of their complements. The L1-center is contained in the excess Pareto optimal set, which in turn is contained in the undominated set. For three-person games all these sets coincide. These three sets also coincide with the core for balanced games and with the anticore for antibalanced games. We study properties of these sets and provide characterizations in terms of balanced collections of coalitions. We also propose a singlevalued selection from the excess Pareto optimal set, the min-prenucleolus, which is defined as the prenucleolus of the minimum of a game and its dual.	maxima and minima;offset binary;pareto efficiency	Jean Derks;Hans Peters;Peter Sudhölter	2014	Int. J. Game Theory	10.1007/s00182-013-0371-0	core;mathematical optimization;economics;publication;mathematics;microeconomics;transferable utility;mathematical economics;welfare economics	ECom	-5.301116072355761	-2.7787861342507467	1166
06de2bd165569dff89cfcdeb8b4d2e6f48da90c1	an haptic-based immersive environment for shape analysis and modelling	haptic display;computer aided design;design process;haptic device;shape analysis;immersive environment;visual modeling;design environment;production cost;product design;development time;surface analysis;product development	Currently, the design of aesthetic products is a process that requires a set of activities where digital models and physical mockups play a key role. Typically, these are modified (and built) several times before reaching the desired design, increasing the development time and, consequently, the final product cost. In this paper, we present an innovative design environment for computer-aided design (CAD) surface analysis. Our system relies on a direct visuo-haptic display system, which enables users to visualize models using a stereoscopic view, and allows the evaluation of sectional curves using touch. Profile curves are rendered using an haptic device that deforms a plastic strip, thanks to a set of actuators, to reproduce the curvature of the shape co-located with the virtual model. By touching the strip, users are able to evaluate shape characteristics, such as curvature or discontinuities (rendered using sound), and to assess the surface quality. We believe that future computer-aided systems (CAS)/CAD systems based on our approach will contribute in improving the design process at industrial level. Moreover, these will allow companies to reduce the product development time by reducing the number of physical mockups necessary for the product design evaluation and by increasing the quality of the final product, allowing a wider exploration and comparative evaluation of alternatives in the given time.		Bruno Rodrigues De Araújo;Tiago João Vieira Guerreiro;Manuel J. Fonseca;Joaquim A. Jorge;João Madeiras Pereira;Monica Bordegoni;Francesco Ferrise;Mario Covarrubias;Michele Antolini	2009	Journal of Real-Time Image Processing	10.1007/s11554-009-0139-8	embedded system;computer vision;simulation;design process;computer science;surface weather analysis;shape analysis;haptic technology;product design;new product development;product engineering	HCI	-37.19571171897069	-31.6851463868887	1169
33af03476ef87506d049ee5ac6af82768b1be2c2	new trends in neural computation, international workshop on artificial neural networks, iwann '93, sitges, spain, june 9-11, 1993, proceedings	artificial neural network		artificial neural network;computation;neural networks		1993				ML	-53.35151120277831	-10.405676221022786	1176
1c124d7d05eef2ad187ce730d4c7868b949a31e9	a combination of trie-trees and inverted files for the indexing of set-valued attributes	containment queries;hti;stock market;inverted files;data mining;indexation;tries	Set-valued attributes frequently occur in contexts like market-basked analysis and stock market trends. Late research literature has mainly focused on set containment joins and data mining without considering simple queries on set valued attributes. In this paper we address superset, subset and equality queries and we propose a novel indexing scheme for answering them on set-valued attributes. The proposed index superimposes a trie-tree on top of an inverted file that indexes a relation with set-valued data. We show that we can efficiently answer the aforementioned queries by indexing only a subset of the most frequent of the items that occur in the indexed relation. Finally, we show through extensive experiments that our approach outperforms the state of the art mechanisms and scales gracefully as database size grows.	algorithm;auxiliary memory;computer data storage;data mining;database;experiment;inverted index;lazy evaluation;overhead (computing);page cache;scientific literature;trie	Manolis Terrovitis;Spyros Passas;Panos Vassiliadis;Timos K. Sellis	2006		10.1145/1183614.1183718	computer science;trie;data mining;database;information retrieval	DB	-28.75906563206171	3.1947601107083776	1186
404f65a875283451d7ac5f20959cc575d9503910	interaction with sound: explorations beyond the frontiers of 3d virtual auditory environments			interaction	Niklas Röber	2009				ML	-51.22221460537503	-33.7814326980488	1188
9584ca7d57b3b00f45e17831b317e916b5287b85	spatial prediction of landslide hazard using fuzzy k-means and dempster-shafer theory	geociencias medio ambiente;fuzzy k means;dempster shafer theory of evidence;spatial prediction;decision making process;dempster shafer theory;classical logic;geografia;grupo a;forest management	Landslide databases and input parameters used for modeling landslide hazard often contain imprecisions and uncertainties inherent in the decision-making process. Dealing with imprecision and uncertainty requires techniques that go beyond classical logic. In this paper, methods of fuzzy k -means classification were used to assign digital terrain attributes to continuous landform classes whereas the Dempster-Shafer theory of evidence was used to represent and manage imprecise information and to deal with uncertainties. The paper introduces the integration of the fuzzy k -means classification method and the Dempster-Shafer theory of evidence to model landslide hazard in roaded and roadless areas illustrated through a case study in the Clearwater National Forest in central Idaho, USA. Sample probabilistic maps of landslide hazard potential and uncertainties are presented. The probabilistic maps are intended to help decisionmaking in effective forest management and planning.	blackwell (series);database;k-means clustering;map;moral hazard;oracle bpa suite;printing;rapid refresh;test data	Pece V. Gorsevski;Piotr Jankowski;Paul E. Gessler	2005	Trans. GIS	10.1111/j.1467-9671.2005.00229.x	decision-making;classical logic;forest management;dempster–shafer theory;geography;artificial intelligence;machine learning;data mining;mathematics;statistics	ML	-6.657200097107965	-23.5755809648688	1190
7447de04886ad61bf75ac8bdbc7ccb4069a1c143	3rd ieee working conference on software visualization, vissoft 2015, bremen, germany, september 27-28, 2015		It is an honor and a pleasure to present the proceedings of the 3rd IEEE Working Conference on Software Visualization. VISSOFT is the premier conference on software visualization and related theory and practices in software comprehension. VISSOFT 2015 has taken place in Bremen, Germany. This conference is the third in line after the recent merger of the ACM Symposium on Software Visualization and the IEEE International Workshop on Visualizing Software for Understanding and Analysis (VISSOFT). VISSOFT 2015 focuses specifically on visualization techniques that draw on aspects of software maintenance, software evolution, program comprehension, reverse engineering and reengineering. As was the case for the first edition of VISSOFT, we are co-located with the 31th International Conference on Software Maintenance and Evolution (ICSME). VISSOFT 2015 is the result of a long effort undertaken by many people. The organizing committee includes Juergen Doellner (General Chair), Fabian Beck and Alexandre Bergel (Program Co-Chairs), Alexandre Bergel and Anne Etien (Artifact Evaluation), Craig Anslow and Johan Fabry (NIER & Tool Track Co-Chairs), Juraj Kubelka (Web chair). In total, 55 reviewers (excluding the chairs) have participated in selecting submissions and producing high-quality reviews. Every conference depends on the quality of the research it presents. We would like to thank all the authors who submitted their work to VISSOFT 2015. We would like to pay tribute to members of the PC for the care and time they put into producing reviewers of high quality, and doing so in a timely manner. Tudor Gı̂rba kindly accepted to be our keynote speaker. His talk is titled Pervasive software visualizations and argues why IDE has to change radically by making visualization as first class citizens. Doru, as Tudor likes to be called, obtained his PhD in 2005 from the University of Bern, and now works as a consultant and coach. He leads the work on the Moose platform for software and data analysis. In 2014, he won the prestigious Dahl-Nygaard Junior Prize for his work on modeling and visualization of evolution and interplay of large numbers of objects. VISSOFT 2015 is different than previous years as it now features an Artifact Evaluation, a best paper award, a response period for technical papers, and a special journal issue. The award has been sponsored by Object Profile. Object Profile interest is in software visualization and the company welcomed our effort. It is becoming common to have a response period which offers opportunities for authors to answer questions or spot issues in the reviewers evaluation. A response period helps by improving the quality of the reviews, and it increases the interaction between authors and the reviewers. All but four papers had an author response. This year, a selection of the best papers will be invited to submit an extended version for a special section of Information and Software Technology (IST) published by Elsevier.	code refactoring;display resolution;first-class function;moose;organizing (structure);personal computer;pervasive informatics;program comprehension;reverse engineering;software evolution;software maintenance;software visualization		2015				Visualization	-61.68517132633474	-16.850581258902423	1191
1eebed1df7a6b3aadaace8baa92672ace2027d28	coronal specification and licensing in place assimilation	conference paper;optimality theory	Based on unmarkedness of coronal cross-linguistically, coronal has been considered to be underspecified. Also, place assimilation where coronal tends to assimilate to the adjacent labial or velar by a featurefilling rule has been support the underspecification of coronals. I instead argue that coronal should be specified in Optimality Theory despite its unmarkedness, and place assimilation no longer provides evidence of underspecification of coronal. In addition, I maintain that place assimilation is a way of respecting licensing requirements and that a licensing hierarchy with respect to place feature of a coda empirically resolve current issues regarding coronal underspecification and place assimilation.	coda (file system);data assimilation;requirement	Seung-Hoon Shin	1996			simulation;engineering;artificial intelligence;communication	HCI	-21.041855481656576	3.203937676263711	1195
411ccf82d612abf73f08a500e0292fda1c39a7c2	user requirements for interruption management in mobile communications in hospitals		In hospitals, mobile communication devices increase the occurrence of inappropriate interruptions during clinical task performance. These interruptions have been related to decreased quality of clinical care. User requirements were elicited using a scenario based approach. The results present insights into user requirements for an interruption management system for hospitals. Hospital workflow protocols were identified as a major source of interruptions. Many suggestions for managing these interruptions related to improving workflow using IT. We have shown that even though the hospital is an exceptionally demanding environment, the user requirements for interruption management concur with earlier findings in the broader fields of context aware interruption management and computer supported cooperative work.	computer-supported cooperative work;inappropriate adh syndrome;interrupt;interruption science;mobile phone;protocols documentation;requirement;user requirements document	Bernd G. Talsma;Terje Solvoll;Gunnar Hartvigsen	2013	Studies in health technology and informatics	10.3233/978-1-61499-289-9-1095	knowledge management;user requirements document;mobile telephony;computer security;medicine	HCI	-60.084072019588596	-61.98527178778443	1196
7d7c24031d7a733f5cb73af65ee86685ad1ed3fc	designing visual decision making support with the help of eye-tracking		Data visualizations are helpful tools to cognitively access large amounts of data and make complex relationships in data understandable. This paper shows how results from neuro-physiological measurements, more specifically eye-tracking, can support justified design decisions about improving existing data visualizations for exploring process execution data. This is achieved by gaining insight into how visualizations are used for decision-making. The presented examination is embedded in the domain of process modeling behavior analysis, and the analyses are performed on the background of representative analytical questions from the domain of process model behavior analysis. We present initial findings on one out of three visualization types we have examined, which is the Rhythm-Eye visualization.	embedded system;eye tracking;process modeling	Barbara Weber;Jens Gulden;Andrea Burattin	2017			r-cast;management science;decision support system;business decision mapping;decision engineering;eye tracking;computer science	HCI	-63.1404067550361	-48.86695430315388	1203
0de43925ced162831af924e8f1b528a3d7c98a0c	what's the deal with privacy apps?: a comprehensive exploration of user perception and usability	mobile exploration;entity resolution;social media	We explore mobile privacy through a survey and through usability evaluation of three privacy-preserving mobile applications. Our survey explores users' knowledge of privacy risks, as well as their attitudes and motivations to protect their privacy on mobile devices. We found that users have incomplete mental models of privacy risks associated with such devices. And, although participants believe they are primarily responsible for protecting their own privacy, there is a clear gap between their perceived privacy risks and the defenses they employ. For example, only 6% of participants use privacy-preserving applications on their mobile devices, but 83% are concerned about privacy. Our usability studies show that mobile privacy-preserving tools fail to fulfill fundamental usability goals such as learnability and intuitiveness---potential reasons for their low adoption rates. Through a better understanding of users' perception and attitude towards privacy risks, we aim to inform the design of privacy-preserving mobile applications. We look at these tools through users' eyes, and provide recommendations to improve their usability and increase user-acceptance.	learnability;mental model;mobile app;mobile device;privacy;security through obscurity;usability goals	Hala Assal;Stephanie Hurtado;Ahsan Imran;Sonia Chiasson	2015		10.1145/2836041.2836044	usability goals;privacy software;social media;information privacy;name resolution;privacy by design;computer science;internet privacy;world wide web;computer security	HCI	-58.289903458606624	-43.431689004125545	1205
cb0d088f1691569141a9f1d413d62c657bfe4a97	advances in pervasive health	pervasive;journal article;health	Title Advances in pervasive health Authors(s) O'Grady, Michael J.; Caulfield, Brian; O'Hare, G. M. P. (Greg M. P.) Publication date 2012-07 Publication information Journal of Ambient Intelligence and Humanized Computing, (July 2012): Publisher Springer Item record/more information http://hdl.handle.net/10197/4345 Publisher's statement The final publication is available at www.springerlink.com Publisher's version (DOI) 10.1007/s12652-012-0146-7	ambient intelligence;brian;pervasive informatics;springer (tank)	Michael Joseph O'Grady;Brian Caulfield;Gregory M. P. O'Hare	2013	J. Ambient Intelligence and Humanized Computing	10.1007/s12652-012-0146-7	human–computer interaction;computer science;health;ubiquitous computing	AI	-59.74648065632917	-13.848599265102163	1206
0e5089d567c47385ed58e5287736f17822c57654	universense : iot device pairing through heterogeneous sensing signals		Easily establishing pairing between Internet-of-Things (IoT) devices is important for fast deployment in many smart home scenarios. Traditional pairing methods, including passkey, QR code, and RFID, often require specific user interfaces, surface's shape/material, or additional tags/readers. The growing number of low-resource IoT devices without an interface may not meet these requirements, which makes their pairing a challenge. On the other hand, these devices often already have sensors embedded for sensing tasks, such as inertial sensors. These sensors can be used for limited user interaction with the devices, but are not suitable for pairing on their own.  In this paper, we present UniverSense, an alternative pairing method between low-resource IoT devices with an inertial sensor and a more powerful networked device equipped with a camera. To establish pairing between them, the user moves the low-resource IoT device in front of the camera. Both the camera and the on-device sensors capture the physical motion of the low-resource device. UniverSense converts these signals into a common state-space to generate fingerprints for pairing. We conduct real-world experiments to evaluate UniverSense and it achieves an F1 score of 99.9% in experiments carried out by five participants.	embedded system;experiment;f1 score;fingerprint;home automation;ibm notes;modal logic;qr code;requirement;sensor;software deployment;state space;user interface	Shijia Pan;Carlos Ruiz;Jun Han;Adeola Bannis;Patrick Tague;Hae Young Noh;Pei Zhang	2018		10.1145/3177102.3177108	software deployment;home automation;embedded system;inertial measurement unit;internet of things;pairing;user interface;computer science	HCI	-38.068699885951304	-45.80794715963512	1212
ec407a4f9fe5cf88048b43f9ddd112bd84a1b0a3	filtering on the temporal probability sequence in histogram equalization for robust speech recognition	speech speech recognition acoustics robustness noise training histograms;acoustic signal processing;ta filter temporal probability sequence filtering filter based histogram equalization approach fheq approach robust speech recognition acoustic feature sequence representation temporal average filter statistic probability sequence smoothing acoustic feature stream noise robustness aurora 2 tasks aurora 4 tasks ta heq heq ta;smoothing methods;noise robust speech recognition heq fheq feature normalization temporal filter;statistics;speech recognition;statistics acoustic signal processing smoothing methods speech recognition	In this paper, we propose a filter-based histogram equalization (FHEQ) approach for robust speech recognition. The FHEQ approach first represents the original acoustic feature sequence with statistic probability. Then, a temporal average (TA) filter is applied to smooth the statistic probability sequence. Finally, the filtered statistic probability sequence is transformed to form a new acoustic feature stream. Filtering on statistic probability of a feature sequence is a novel concept that can incorporate the advantages of the conventional histogram equalization (HEQ) and temporal filtering techniques for better noise robustness. Our experimental results on the Aurora-2 and Aurora-4 tasks show that FHEQ outperforms the conventional cepstral mean subtraction (CMS), cepstral mean and variance normalization (CMVN), and HEQ. Furthermore, we conducted a comparison test on TA-HEQ and HEQ-TA, which apply a TA filter to smooth acoustic features before and after the HEQ processing, respectively. The test results show that FHEQ outperforms both TA-HEQ and HEQ-TA, suggesting that filtering in probability is more effective than filtering in acoustic feature.	acoustic cryptanalysis;cepstral mean and variance normalization;cepstrum;histogram equalization;least mean squares filter;speech recognition	Syu-Siang Wang;Yu Tsao;Jeih-Weih Hung	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6639042	speech recognition;computer science;machine learning;pattern recognition;mathematics;statistics	Vision	-12.99208982623267	-92.73398712141974	1220
14a1106f7697f9cde46cc17f292ec78684d23e86	indagator: investigating perceived gratifications of an application that blends mobile content sharing with gameplay	mobile communications;social networking;motivation;user generated content	The confluence of mobile content sharing and pervasive gaming yields new opportunities for developing novel applications on mobile devices. Yet, studies on users‟ attitudes and behaviors related to mobile gaming, content sharing and retrieval activities (referred simply as content sharing and gaming) have been lacking. For this reason, the objectives of this paper are three-fold. One, it introduces Indagator, an application which incorporates multiplayer, pervasive gaming elements into mobile content sharing activities. Two, it seeks to uncover the motivations for content sharing within a game-based environment. Three, it aims to identify types of users who are motivated to use Indagator for content sharing. Informed by the uses and gratifications paradigm, a survey was designed and administered to 203 undergraduate and graduate students from two large universities. The findings revealed that perceived gratification factors such as information discovery, entertainment, information quality, socialization, and relationship maintenance, and demographic variables such basic familiarity with features of mobile communication devices, and IT-related backgrounds were significant in predicting intention to use mobile sharing and gaming applications such as Indagator. However, age, gender, and the personal status gratification factor were nonsignificant predictors. This paper concludes by presenting the implications, limitations and future research directions.	collaborative filtering;confluence;coupling (computer programming);diary studies;digital media;experience;information discovery;information quality;mobile device;mobile game;pervasive informatics;pipelines;programming paradigm;socialization;software developer;transaction log;usability;user-generated content;world wide web	Chei Sian Lee;Dion Hoe-Lian Goh;Alton Yeow-Kuan Chua;Rebecca Pei-Hui Ang	2010	JASIST	10.1002/asi.21305	simulation;motivation;computer science;multimedia;user-generated content;world wide web;social network	HCI	-58.740993755579765	-44.22514549742384	1235
37dab00c740e3b5981827024a3497ec6135ac427	summarizing world speak : a preliminary graph based approach				Nikhil Londhe;Rohini K. Srihari	2017		10.26615/978-954-452-049-6_060	natural language processing;machine learning;artificial intelligence;computer science;graph	ML	-33.741264512117986	-78.2296422017736	1236
f276b4d13015b1b8ec797b7cf4af2a99cd385927	p-smart - a virtual system for clothing thermal functional design	thermal functions;human body clothing environment hce;virtual simulation;human body;system development;virtual space;journal magazine article	This paper presents a virtual CAD system developed for clothing thermal functional design and simulation. It allows designers and engineers in virtual space to design and preview the thermal functional performance of clothing and gives feedback to improve the design iteratively. The system provides designers with an effective tool for designing and engineering clothing to achieve superior thermal functional performance.	functional design	Yi Li;Aihua Mao;Ruomei Wang;Xiaonan Luo;Zhong Wang;Wenbang Hou;Liya Zhou;Yubei Lin	2006	Computer-Aided Design	10.1016/j.cad.2006.03.003	human body;simulation;engineering;engineering drawing	EDA	-37.19692557643582	-31.632302174829327	1244
a97d96563893c7a76dc7da2fc1b26b4c7133ef30	when does social network-based prediction work? a large scale analysis of brand and tv audience engagement by twitter users		Social network-based prediction, more specifically targeting friends and contacts of existing customers, has proven successful in various domains like retail banking, telecommunications, and online advertising. However, little is known about for what types of product categories and brands social network-based marketing is especially effective at predicting brand engagement, both in absolute terms and compared to demographic targeting or collaborative filtering. In this work, we compare the performance of a social network-based recommendation engine against a product network-based recommendation engine of the kind used in collaborative filtering. We do so over 700 brands and 223,000 consumers a novel data set collected from Twitter. We compare the performance of the two approaches by product and user features. Preliminary results indicate that the variance in performance within and across methods is related to differences in brand and user popularity as well as brand audience. We believe that this is the first study to compare the effectiveness of social network-based marketing with traditional approaches to predict brand engagement over a large number of brands and product types.	collaborative filtering;computer performance;online advertising;recommender system;social network	Shawndra Hill;Adrian Benton;Christophe Van den Bulte	2013			public relations;marketing;advertising;brand awareness;world wide web	Web+IR	-20.25869953893513	-51.400647985401356	1246
8053a8cb00c4817dbc042354b2a5625c11d7b1b1	adoption of collaboration information technologies in australian and us organizations: a comparative study	electronic meeting system;internet groupware information technology electronic mail teleconferencing;groupware;teleconferencing;collaboration australia collaborative work teleconferencing collaborative software data analysis large scale systems medical services information systems information technology;electronic mail;data collection;information technology;computing and communication sciences;internet;the australian standard research classification 280000 information;comparative study;data analysis collaboration information technologies australian organizations us organizations macro level adoption it clusters task oriented collaboration adoption patterns stand alone e mail systems audio teleconferencing systems videoconferencing web based tools electronic meeting systems	Collaboration to accomplish tasks has taken on a new meaning over the past few years. The majority of organizations are viewing information technology (IT) as a key enabler to transcend time and distance barriers to collaborate efficiently and effectively. Despite this, we know very little about the macro level adoption of IT to support collaboration. This paper assesses the pattern of adoption of seven IT clusters to support task-oriented collaboration in US and Australian organizations. Data collected from one hundred and forty Australian organizations and one hundred and nineteen US organizations is analyzed to compare adoption patterns. Our results suggest that stand-alone e-mail systems, audio teleconferencing systems, and videoconferencing are the most widely adopted technologies to support collaboration in both countries while web-based tools and electronic meeting systems are the least commonly adopted. A further analysis of data suggests that promotion of collaboration, mode of collaboration, and the adoption of some IT clusters are affected by region. Implications of these findings are discussed along with some directions for practice and research.	email;web application	Deepinder S. Bajwa;L. Floyd Lewis;Graham Pervan	2003		10.1109/HICSS.2003.1173661	the internet;teleconference;computer science;knowledge management;marketing;software engineering;comparative research;database;multimedia;law;information technology;world wide web;data collection	HCI	-89.40492905469699	-0.9615119753077979	1249
f2a6e5951c9b117b014c1171472cf03a5c15d56c	modes and orders of market entry: revisiting innovation and imitation strategies	market entry;followers;entry order;first mover;imitation;innovation;entry mode;imitation strategies;market timing;environmental change	This paper focuses on the initial questions of how and when to enter a market from the perspective of a firm. By entry mode is meant a firm’s strategy (innovation or imitation) for entering the market in response to environmental changes. Entry order refers to the related issue of market timing (first-mover or follower). Invention is understood as the conversion of human creativity, time and financial resources into new ideas. Innovation in turn reflects the practical and financial return on such investments. While there is little disagreement about what an innovator strategy is, imitative strategies are more ambiguous. Based on a corporate technology and innovation strategy perspective, the paper reconceptualises and extends existing modes and orders of market entry, and in particular clarifies the ambiguity associated with imitative strategies. Four distinct imitator strategies are identified. The paper closes with a brief discussion of limitations, avenues for future research, and implications for managers and affected policymakers.		John P. Ulhøi	2012	Techn. Analysis & Strat. Manag.	10.1080/09537325.2012.643559	innovation;market timing;imitation;environmental change;economics;marketing;operations management;ecology;management;first-mover advantage	NLP	-80.62668269880054	0.9777329326562307	1250
63d7b56813f5a61027f9e79e4a3330699a95a4ee	an analysis of dematel approaches for criteria interaction handling within anp	criteria interaction;anp;multiple attribute decision making;decision analysis;dematel	Majority of the Multiple-Attribute Decision Making (MADM) methods assume that the criteria are independent of each other, which is not a realistic assumption in many real world problems. Several forms of interactions among criteria might occur in real life situations so that more sophisticated/intelligent techniques are required to deal with particular needs of the problem under consideration. Unfortunately, criteria interaction concept is very little issued in the literature. It is still a very important and critical research subject for intelligent decision making within MADM. The present paper aims to put a step forward to fill this gap by depicting the general picture, which provides a classification of methods related to criteria interaction phenomenon, and discuss/review the Decision-Making Trial and Evaluation Laboratory (DEMATEL) and Analytical Network Process (ANP) hybridizations first time in the literature. DEMATEL and ANP hybridizations grab remarkable attention of decision analysis community in recent years and seem as one of the most promising approaches to handle criteria interactions in a MADM setting. © 2015 Elsevier Ltd. All rights reserved.	decision analysis;interaction;real life	Ilker Gölcük;Adil Baykasoglu	2016	Expert Syst. Appl.	10.1016/j.eswa.2015.10.041	decision analysis;management science;operations research	AI	-5.143611804568139	-18.298802724447846	1255
7e523111263eeaeaa9e6ee5046d754fd86e891c0	talking drums: generating drum grooves with neural networks		Presented is a method of generating a full drum kit part for a provided kick-drum sequence. A sequence to sequence neural network model used in natural language translation was adopted to encode multiple musical styles and an online survey was developed to test different techniques for sampling the output of the softmax function. The strongest results were found using a sampling technique that drew from the three most probable outputs at each subdivision of the drum pattern but the consistency of output was found to be heavily dependent on style.	artificial neural network;drum memory;encode;natural language;network model;sampling (signal processing);softmax function;subdivision surface	P. Hutchings	2017	CoRR		machine learning;sampling (statistics);natural language;drum;artificial neural network;speech recognition;subdivision;engineering;artificial intelligence;softmax function	ML	-18.493759252073545	-79.81834765505344	1257
d57f2202079296a2a830a1ed80028f4d4ea1066e	exploring creative process via improvisation and the design method replay	creativity;design research;design methods;contextual information;improvisation;design method;reflection	RePlay is an exploratory method being developed by the author as a tool to observe creativity in action and how improvisation similar to brainstorming is a useful embodied technique in collaborative and an often inter-disciplinary design process. This paper reflects on a pilot study conducted with a group of improvisation actors to experiment with the method and its development. The contribution of the paper is to explore the value of RePlay as an embodied approach for observing as well as enhancing creativity both as method for observation and developing it as a creative tool. The method involves the use of body storming in the early stages of co-creation on behalf of participants as well as reflection on the activity afterwards. This exploratory method builds upon Dix et al. [7, 21] BadIdeas as well as improvisation techniques and the use of props in collaborative brainstorming. What follows, is an overview of design methods as well as a summary of some of the work that has been done in the area of Human- Computer Interaction and other disciplines regarding the use of improvisation. This paper also includes a summary of the results of a pilot study utilizing RePlay as well and proposed future work and directions for research.	replay attack	Layda Gongora	2010			simulation;human–computer interaction;engineering;multimedia	EDA	-63.193879392716205	-37.69345379293947	1262
43c39956873fb2f13dc117b5671badfb85c7f915	webdiplomat: a web-based interactive machine translation system	third-party correction;speech subsystems;speech recognition;web-based user interface;machine translation output;chat-style machine translation system;online learning;web-based interactive machine translation;underlying client-server architecture;different useful configuration;machine translation;distributed computing;user interface;client server architecture	We have implenlented a.n interactive, Wel)-based, chat-style machine translation system, SUpl)ort;ing speech recognition and synthesis, localor thirdparty correction of speech recognition and machine tra.nslation output, a.nd online learning. The underlying client-server architecture, implemented in .la.va TM, pl:ovides remote, distributed computation for the translation and speech sut)systems. We further describe our Web-based user interthces, whMi can easily produce different uscflfl eonfigllrartions.	client–server model;computation;distributed computing;interactive machine translation;server (computing);speech recognition	Christopher Hogan;Robert E. Frederking	2000			computer-assisted translation;natural language processing;speech recognition;computer science;machine translation;user interface;world wide web;client–server model	NLP	-41.99514975257669	-28.3157482452848	1275
4d1e23d3fa189c2964ccdeb10f8c3db2d9fa7736	understanding online regret experience in facebook use - effects of brand participation, accessibility & problematic use	cross sectional;problematic use;facebook;sns brand participation;adolescents;online regret experience	The past few years have witnessed the emergence of research examining online regret experience. The presence of online regret generates negative use experience and even leads to service switching and discontinuity. However, to date, only limited research has examined the conceptualization of this new yet very important phenomenon in the field of technology use. To address this research gap, the present study has examined the relative influence of SNS brand participation, technology accessibility attributes (including Facebook usage parameters) and problematic Facebook use in predicting regret experience regarding Facebook use. A pen-and-paper cross-sectional survey was administered to 804 adolescent Facebook users (aged 13e18 years). The study results suggest that adolescent users with varying technology accessibility did not differ in their online regret experience, but excessive Facebook users and those actively participating in brand communities tended to experience higher regret. Other findings suggest that two variables, namely parents’ perceptions of problematic Facebook use and conflict with friends due to Facebook use, were significant predictors of online regret experience. This study presents different theoretical and practical implications for both research and practice. © 2016 Elsevier Ltd. All rights reserved.	accessibility;conceptualization (information science);cross-sectional data;emergence;reflections of signals on conducting lines;regret (decision theory)	Amandeep Dhir;Puneet Kaur;Sufen Chen;Kirsti Lonka	2016	Computers in Human Behavior	10.1016/j.chb.2016.02.040	psychology;cross-sectional study;social psychology	HCI	-87.47431923695035	-18.00029562175229	1276
8524e31b679a002e71e2ad27831642ef5f505989	using new media to improve self-help for clients and staff	self help;video podcast;client support;team building;new media	"""One of the most common frustrations for any person looking for technical support is actually finding effective technical support. Even if a solution seems clear, it can be misunderstood if the vernacular is not just right. A large part of a successful support call involves being able to determine the actual problem based on the information the client provides. Help desk analysts must have the ability to translate """"non-tech"""" descriptions to identify a problem in technical terms and then communicate a solution using vernacular the client can understand. This process is always a little different. If we aim to be successful analysts, we must speak different """"languages"""" in order to help our clients. Based on this logic, it stands to reason that our self-help documentation must do the same. Providing a variety of methods to get self-help ensures a message will be received by a wider audience.  In the world of modern media, audiences are presented with many ways to consume information. This ensures the message is heard by the most people in a manner that is the most appealing and the most clear. New methods of consuming information have become possible as the face of mainstream media has become democratized over the last few years. This is thanks largely to the fact that the tools needed to create and distribute content have become affordable and readily available to anyone with a bit of technical skill. Anyone with a laptop, a webcam and a little imagination can and do create content. Considering all of this, we asked ourselves, """"Why shouldn't we?.""""  We have found that creating content in new media is relatively easy and fun. Finding and creating new methods to deliver content positively engages and challenges our help desk team. Thinking about how to best use new media requires help desk analysts to rethink otherwise standardized and mundane processes and create fresh perspectives. The creation and production of new media establishes stronger ownership of procedures and process.  We would like to share the following from our ongoing experiences with new media at our help desk: General issues we see with clients finding help How creating new media creates stronger ownership and morale with staff Expanding the technical skills of help desk staff How using new media improves our client experience Casting a wider net (ensuring a message gets to the most people) How we use new media and what we have done with it How to make your own video podcast in 1,345 easy steps!"""	client (computing);documentation;laptop;new media;podcast;technical support;webcam	Brent James Voyer;Clayton Walter Crane	2010		10.1145/1878335.1878394	public relations;computer science;multimedia;world wide web	HCI	-66.96334075350319	-26.748648822461092	1277
12bbb55ed07c236bd26bd4455ce4d890f09adaf9	interpreted collaboration protocols and their use in groupware prototyping	trellis;process based hypertext hypermedia;formal methods;coordination structure;collaborative system;formal method;structural dynamics;colored petri net;on the fly;protocol specification;group work;moderated meeting;dynamic protocol;group interaction	The correct and timely creation of systems for coordination of group work depends on the ability to express, analyze, and experiment with protocols for managing multiple work threads. We present an evolution of the Trellis model that provides a formal basis for prototyping the coordination structure of a collaboration system. In Trellis, group interaction protocols are represented separately from the interface processes that use them for coordination. Protocols are interpreted (rather than compiled into applications) so group interactions can be changed as a collaborative task progresses. Changes can be made either by a person editing the protocol specification “on the fly” or by a silent “observation” process that participates in an application solely to perform behavioral adaptations. Trellis uniquely mixes hypermedia browsing with collaboration support. We term this combination a hyperprogram, and we say that a hyperprogram integrates the description of a collaborative task with the information required for that task. As illustration, we describe a protocol for a moderated meeting and show a Trellis prototype conference tool controlled by this protocol.	collaborative software;compiler;hypermedia;interaction protocol;on the fly;prototype;trellis quantization	Richard Furuta;P. David Stotts	1994		10.1145/192844.192888	structural dynamics;real-time computing;simulation;formal methods;human–computer interaction;telecommunications;computer science;operating system;communication;world wide web	SE	-39.30113636279651	-27.344381082986125	1285
18c86a3af0bdfd81726fb0ac2864779610669b9c	modeling speech production and perception mechanisms and their applications to synthesis, recognition, and coding	hearing prostheses;hidden markov models speech synthesis speech coding speech analysis noise robustness humans magnetic resonance imaging speech processing acoustic noise automatic speech recognition;spectral dynamics;speech production mechanism;intra speaker variabilities;robust automatic speech recognition;cognitive ability;subband energies;speech synthesis;auditory signal processing;magnetic resonance images;articulatory dynamics;adaptive codes speech synthesis speech recognition speech coding vocoders audio coding biomedical mri hidden markov models modelling;audio coder;hidden markov model;wireless communications modeling speech production mechanism speech perception mechanism speech synthesis speech recognition speech coding cognitive abilities robust automatic speech recognition hearing prostheses magnetic resonance images acoustic recordings electropalatography articulatory database 3d geometry vocal tract epg intra speaker variabilities inter speaker variabilities articulatory dynamics tongue shapes acoustic modeling mri vocal tract normalization schemes auditory signal processing spectral dynamics local peak frequency positions noise dynamic model stochastic hidden markov model auditory modeling audio coder perceptual metrics encoding human listener signal to mask ratio adaptive bit allocation scheme subband energies;variable rate;signal to mask ratio;acoustic modeling;speech processing;speech analysis;dynamic model;perceptual metrics;vocal tract;adaptive bit allocation scheme;speech coding;adaptive codes;speech perception;noise robustness;magnetic resonance image;speech perception mechanism;wireless communication;automatic speech recognition;audio coding;cognitive abilities;mr imaging;inter speaker variabilities;hidden markov models;wireless communications;signal processing;acoustic noise;magnetic resonance imaging;vocoders;mri;stochastic hidden markov model;speech recognition;electropalatography;vocal tract normalization schemes	Summary form only given, as follows. Quantitative models of human speech production and perception mechanisms provide important insights into our cognitive abilities and can lead to high-quality speech synthesis, robust automatic speech recognition and coding schemes, and better speech and hearing prostheses. Some of our research activities in these two areas are described. Our speech production work involved collecting, and analyzing magnetic resonance images (MRI), acoustic recordings, and electropalatography (EPG) data from talkers of American English during speech production. The articulatory database is the largest of its kind in the world and contains the first images of liquids (such as /I/ and /r/) and fricatives (such as /s/ and /sh) for both male and female talkers. MR images are useful for characterizing the 3D geometry of the vocal tract (VT) and for measuring lengths, area functions, and volumes. EPG is used to study inter- and intra-speaker variabilities in the articulatory dynamics, while acoustic recordings are necessary for modeling. Inter- and intra-speaker characteristics of the VT and tongue shapes will be illustrated for various speech sounds, as well as results of acoustic modeling based on the MRI and acoustic data. The implications of our findings on vocal-tract normalization schemes and speech synthesis are also discussed. In the speech perception area, aspects of auditory signal processing and speech perception are parameterized and implemented in a speech recognition system. Our models parameterize the sensitivity to spectral dynamics and local peak frequency positions in the speech signal. These cues remain robust when listening to speech in noise. Recognition evaluations using the dynamic model with a stochastic hidden Markov model (HMM) recognition system showed increased robustness to noise over other state-of-the-art representations. The applications of auditory modeling to speech coding are discussed. We developed an embedded and perceptually-based speech and audio coder. Perceptual metrics are used to ensure that encoding is optimized to the human listener and is based on calculating the signal-to-mask ratio in short-time frames of the input signal. An adaptive bit allocation scheme is employed and the subband energies are then quantized. The coder is variable-rate, noise-robust and suitable for wireless communications.		Abeer Alwan	1999		10.1109/ISSPA.1999.818096	voice activity detection;audio mining;linear predictive coding;speech recognition;cognition;computer science;magnetic resonance imaging;speech coding;speech processing;acoustic model;psqm;wireless	AI	-9.101735338139033	-88.0321712495045	1287
3a5eebbc19edb427b0ba5090a7982c6498931b42	a method for outdoor skateboarding video games	wireless sensor;mobile;real time;gaming;hci;data mining;video game;digital entertainment and sports;sports;new gaming audiences;real time classification;mobile video	Video games aimed at motivating players to exercises have gained popularity over the last few years, but most games are still designed for indoor scenarios. In this paper, we present a platform for a novel game concept: a mobile video game that is controlled by performing tricks on a real skateboard. The platform consists of two parts. A well-protected small wireless sensor module integrated unobtrusively into a skateboard and trick detection software that employs data mining techniques to classify skateboarding tricks from the raw data. We show the feasibility of the approach by presenting Tilt'n'Roll, a prototype skateboarding game application built on this platform.	data mining;mobile game;prototype	Jan Anlauff;Erik Weitnauer;Alexander Lehnhardt;Stefanie Schirmer;Sebastian Zehe;Keywan Tonekaboni	2010		10.1145/1971630.1971642	video game design;game design;video game graphics;simulation;engineering;game mechanics;game art design;game developer;multimedia;advertising;video game development	Mobile	-53.30710766233641	-42.867017394579804	1290
eddde88ee3814e0852d71af83113250a353b3641	an exploratory study of buyers' participation intentions in reputation systems: the relationship quality perspective	conflict handling styles;social conformity;期刊论文;reputation systems;perceived value of knowledge;relationship quality	Drawing upon a relationship quality framework, this study identifies how satisfaction, trust and different styles of handling conflict influence online buyers’ participation intentions in reputation systems associated with a C2C online shopping platform. Furthermore, we investigate how these effects are moderated by social conformity and the perceived value of knowledge. The results of a survey of 269 online buyers indicate that satisfaction, trust and an accommodating conflict handling style positively impact the intention to submit positive ratings, whereas an avoiding conflict handling style negatively affects the intention to submit positive ratings. Implications and suggestions for future research are provided. 2014 Elsevier B.V. All rights reserved.	conformity;online shopping;reputation system	Qian Huang;Robert M. Davison;Hefu Liu	2014	Information & Management	10.1016/j.im.2014.09.003	public relations;conformity;knowledge management;social psychology	AI	-89.80690270199636	-12.801304299139689	1294
496e2de9c69409fdfedf474c21da2b9453ecb8b8	vowel enhancement in early stage spanish esophageal speech using natural glottal flow pulse and vocal tract frequency warping		This paper presents an enhancement system for early stage Spanish Esophageal Speech (ES) vowels. The system decomposes the input ES into neoglottal waveform and vocal tract filter components using Iterative Adaptive Inverse Filtering (IAIF). The neoglottal waveform is further decomposed into fundamental frequency F0, Harmonic to Noise Ratio (HNR), and neoglottal source spectrum. The enhanced neoglottal source signal is constructed using a natural glottal flow pulse computed from real speech. The F0 and HNR are replaced with natural speech F0 and HNR. The vocal tract formant frequencies (spectral peaks) and bandwidths are smoothed, the formants are shifted downward using second order frequency warping polynomial and the bandwidth is increased to make it close to the natural speech. The system is evaluated using subjective listening tests on the Spanish ES vowels /a/, /e/, /i/, /o/, /u/. The Mean Opinion Score (MOS) shows significant improvement in the overall quality (naturalness and intelligibility) of the vowels.	bilinear transform;image warping;intelligibility (philosophy);inverse filter;natural language;polynomial;smoothing;speech enhancement;tract (literature);waveform	Rizwan Ishaq;Dhananjaya N. Gowda;Paavo Alku;Begonya Garcia-Zapirain	2015		10.18653/v1/W15-5110	speech recognition;acoustics;engineering;communication	AI	-9.643086196212646	-87.0062195822254	1295
ae3875b59cd8fd6ffe3a692cfa2c46b8b205ff03	proceedings of the www2009 workshop on linked data on the web, ldow 2009, madrid, spain, april 20, 2009			linked data;world wide web		2009				NLP	-56.55510837594478	-9.005907895524881	1298
b831ea4663bc1fda30fd15a7b83c905ccce387bd	introduction to multimedia and mobile agents	mobile agent		mobile agent	Qing Li;Timothy K. Shih	2003	Inf. Sci.	10.1016/S0020-0255(03)00002-1	computer science;mobile agent	AI	-54.17977821109608	-3.649678356686613	1299
bef7d3f1d2b0788261dc01846de916a1e2aee9ed	teaching security using hands-on exercises (abstract only)	laboratory exercises;network security;information assurance;cybersecurity;security;teaching	"""We see teaching cybersecurity through hands-on, interactive exercises as a way to engage students. Some of the exercises that we have seen require significant preparation on the part of the instructor. Having a community makes it easier to share exercises, knowing what works and what problems students and instructors have encountered. The purpose of this BOF is to bring together instructors who have used hands-on exercises and those who would like to. We recognize that few CS programs can afford new required courses, so we would be discussing ways to integrate security-related exercises into existing ones. This could include networking, OS, computer architecture, programming languages, software engineering and algorithms.  Recent hiring forecasts indicate that there is a tremendous need for skilled information security experts. This was evident at the last National Initiative for Cybersecurity Education (NICE) conference at NIST, and from sponsors of the Collegiate Cybersecurity CCDC. Security will be one of the core areas in the ACM/IEEE COMPUTER SCIENCE 2013 Curricula.  We think that it is particularly important to share stories from the classroom (what worked and what didn't), discuss ethical hacking, and discuss how to teach analytical skills. We also plan to discuss our own experiences, practices and ongoing efforts (e.g., our teaching experiences, the SISMAT program, Security Injections, EDURange and the dissemination of infosec interactive exercises). SISMAT includes a two-week summer intensive program based on the """"Hacker Curriculum"""" and a combination of research and internship in cyberbersecurity for undergraduates."""	algorithm;computer architecture;computer science;computer security;cyber security standards;experience;hacker;hands-on computing;information security;operating system;programming language;software engineering	Richard S. Weiss;Michael E. Locasto;Jens Mache;Blair Taylor;Elizabeth K. Hawthorne	2013		10.1145/2445196.2445490	simulation;computer science;network security;software engineering;multimedia;pedagogy	HCI	-80.5293083521942	-30.568610572762545	1300
e9f11386e9726849eb3e38950d8ef334a8f9ebcd	translating technology in professional practices to optimize infection prevention and control: a case study based on the trip-ant framework		The aim of this study was to explain how the Polymerase Chain Reaction PCR technology was translated into professional practices to prevent and control vancomycin-resistant enterococci outbreaks via an actor-network, based on the integrated framework TRIP-ANT. A single case study was conducted in three purposefully selected sites implementing the PCR-VRE assay. The complete dataset comprised semi-structured interviews with 28 participants and a review of hospital and external documents. A content analysis was conducted. The authors' findings indicate the emergence of four main themes, including illustration of who was involved in the adoption process, attribution of roles and responsibilities, interaction/communication/ collaboration mechanisms, and changes in professional practices. Their findings also address five challenges that arose from each theme. The translation of PCR technology into professional practices relies on the enrolment of an organisational, clinical, managerial and financial support network, and on the evolution of practices, communications, and roles and responsibilities.		Randa Attieh;Marie-Pierre Gagnon;Geneviève Roch;Sarah L. Krein	2016	IJANTTI	10.4018/IJANTTI.2016070103	systems engineering;knowledge management;management science	HCI	-80.14586868578803	-1.5483027539607364	1304
57d9e792392f4384a20f69f59a03c1418f7bed06	towards semi automatic construction of a lexical ontology for persian.		Lexical ontologies and semantic lexicons are important resources in natural language processing. They are used in various tasks and applications, especially where semantic processing is evolved such as question answering, machine translation, text understanding, information retrieval and extraction, content management, text summarization, knowledge acquisition and semantic search engines. Although there are a number of semantic lexicons for English and some other languages, Persian lacks such a complete resource to be used in NLP works. In this paper we introduce an ongoing project on developing a lexical ontology for Persian called FarsNet. We exploited a hybrid semi-automatic approach to acquire lexical and conceptual knowledge from resources such as WordNet, bilingual dictionaries, mono-lingual corpora and morpho-syntactic and semantic templates. FarsNet is an ontology whose elements are lexicalized in Persian. It provides links between various types of words (cross POS relations) and also between words and their corresponding concepts in other ontologies (cross ontologies relations). FarsNet aggregates the power of WordNet on nouns, the power of FrameNet on verbs and the wide range of conceptual relations from ontology community	automatic summarization;bilingual dictionary;framenet;information retrieval;knowledge acquisition;lexicon;machine translation;natural language processing;ontology (information science);point of sale;question answering;semantic search;semiconductor industry;text corpus;web search engine;wordnet	Mehrnoush Shamsfard	2008			natural language processing;speech recognition;information retrieval	AI	-29.287745827270545	-70.86137436947074	1305
b481f0fe69420d3ad18248020e51fbf161db5ff4	exploring goodness of prosody by diverse matching templates	query by humming;speech prosody	In automatic speech grading systems, rare research is followed through addressing the issue of GOR (Goodness Of pRosody). In this paper we propose a novel method by taking the advantage of our QBH (Query By Humming) techniques in 2008 MIREX evaluation task. A set of standard samples related to the top-cream students are initially picked up as templates, a cascade QBH structure is then taken from two metrics: the MOMEL stylization followed by DTW distance; the Fujisaki model followed by EMD distance. Sentence GOR is obtained by the fused confidence between target and each template, and forms a weighted sum as the goodness in the passage level. Experiment results indicate that performance increases with the count of template, and Fujisaki-EMD metric outperforms MOMEL-DTW one in terms of correlation. Their combination can be treated as template based GOR score, compensated with our previous feature based GOR score, the approach can achieve 0.432 in correlation and 17.90% in EER in our corpus.		Shen Huang;Hongyan Li;Shijin Wang;Jiaen Liang;Bo Xu	2010			natural language processing;speech recognition;computer science;machine learning;pattern recognition	AI	-16.456676412724352	-82.82597414401707	1307
e54c452f691d4937179cb3b8c45c56b965b83beb	cliniweb: managing clinical information on the world-wide web	subject headings;indexation;health care;world wide web	The World Wide Web is a powerful new way to deliver on-line clinical information, but several problems limit its value to health care professionals: content is highly distributed and difficult to find, clinical information is not separated from non-clinical information, and the current Web technology is unable to support some advanced retrieval capabilities. A system called CliniWeb has been developed to address these problems. CliniWeb is an index to clinical information on the World Wide Web, providing a browsing and searching interface to clinical content at the level of the health care student or provider. Its database contains a list of clinical information resources on the Web that are indexed by terms from the Medical Subject Headings disease tree and retrieved with the assistance of SAPHIRE. Limitations of the processes used to build the database are discussed, together with directions for future research.		Benoît Thirion;Stéfan Jacques Darmoni	1997	Journal of the American Medical Informatics Association : JAMIA	10.1136/jamia.1997.0040071	web service;web application security;controlled vocabulary;web development;web modeling;data web;web mapping;web design;web accessibility initiative;web standards;computer science;web navigation;social semantic web;data mining;database;web intelligence;web engineering;web 2.0;world wide web;information retrieval;health care	NLP	-53.143405673142794	-62.497624418601525	1308
df9491cc46eacf66bb963a699b73ec1a82aec4eb	learning attributes from the crowdsourced relative labels		"""Finding semantic attributes to describe related concepts is typically a hard problem. The commonly used attributes in most fields are designed by domain experts, which is expensive and time-consuming. In this paper we propose an efficient method to learn human comprehensible attributes with crowdsourcing. We first design an analogical interface to collect relative labels from the crowds. Then we propose a hierarchical Bayesian model, as well as an efficient initialization strategy, to aggregate labels and extract concise attributes. Our experimental results demonstrate promise on discovering diverse and convincing attributes, which significantly improve the performance of the challenging zero-shot learning tasks. Introduction Extracting concise attributes and then drawing a conclusion is a usual pattern when humans make decisions (Hwang and Yoon 1981). For example, when we judge whether a research paper is good or not, instead of making a decision directly, we usually ask whether this paper is novel, possesses good technique quality or has a potential impact to the literature, and then reach a decision based on the answers of these sub-questions. Here novelty, technique quality and potential impact are three attributes extracted from the raw textual data to judge the quality of a paper. They can help us to solve the comprehensive judgment. In the machine learning literature, compared with raw features such as pixel representation of images, attributes are usually more concise and easily interpretable (Farhadi et al. 2009). Moreover, due to the extensive knowledge background of humans, attributes naturally contain cross domain information, some of which cannot be deduced directly from the data themselves. For example, humans can extract behavior attributes of an animal only from static pictures of it. Thus attributes are suitable for transferring knowledge between tasks and classifying objects. The benefits have been shown by works in the zero-shot learning literature (Jayaraman and Grauman 2014; Lampert, Nickisch, and Harmeling 2009; Norouzi et al. 2014; Palatucci et al. 2009; Parikh and Grauman 2011b; RomeraParedes and Torr 2015). In this paper, we ask a new question: can we learn high quality attributes from the crowds? This question arises from Copyright c © 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. practice since finding attributes to describe related concepts is typically a very hard task. Although humans use attributes to make decisions in every minute, it is usually a subconscious process and hard to be characterized. Moreover, due to human perception variations, different people may extract different attributes from a same task, so the responses are inherently diverse. As a result of these difficulties, the commonly used attributes in most fields are designed by experts, which is an expensive and time-consuming process. Fortunately, the rise of crowdsourcing provides a new way to collect information from a group of people fast and cheaply. Systems like Amazon Mechanical Turk and CrowdFlower have been widely used by machine learning researchers to label large-scale datasets (Deng et al. 2009; Welinder et al. 2010; Kovashka et al. 2016), cluster items (Gomes et al. 2011) and even build classifiers (Cheng and Bernstein 2015). To learn attributes by crowdsourcing, we first design an analogical interface to collect human opinions, which is efficient, and can lead people to give expected results. Then the human responses are represented by a collection of relative labels. Next we build a hierarchical Bayesian aggregating model to ensemble the results collected from different people and tasks, which is robust to the crowdsourcing noise. After the above process, we test the efficacy of our method, and the results demonstrate promise on discovering diverse and convincing attributes, whose qualities are further proved by significantly improving zero-shot learning performances compared with the expert-designed attributes. Analogical Encoding of Attributes The first step is to collect information from humans. Suppose we want to collect main visual attributes1 of animals, a naive approach is to directly show pictures of each animal, then ask humans to answer some straightforward questions, such as: """"what is the main visual characteristic of this animal?"""" However, in practice we found this approach often results in a poor response due to several reasons: (1) the question is not well defined, thus it can be interpreted in many different ways and has too many possible answers. Moreover, usually people tend to give apparent attributes. For example, when we show annotators flower pictures, 94% responses focus on the In this work, we define the attributes at the category level, which means items in a same category should share same attribute values. Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17)"""	aggregate data;algorithm;amazon mechanical turk;artificial intelligence;bayesian network;crowdsourcing;display resolution;list of system quality attributes;machine learning;performance;phil bernstein;pixel;subject-matter expert;text corpus;the turk	Tian Tian;Ning Chen;Jun Zhu	2017			computer science;artificial intelligence;machine learning	AI	-13.405683336188819	-66.3681278236779	1326
52d996f8d4fc4ccb7edc5b2f0c7af68ac5ab0c51	a new approach on indexing mobile objects on the plane	spatiotemporal databases;range query;computational geometry;mobile object;indexing;data structures;indexation;experimental evaluation;access method;data structure	We present a set of time-efficient approaches to index objects moving on the plane to efficiently answer range queries about their future positions. Our algorithms are based on previously described solutions as well as on the employment of efficient access methods. Finally, an experimental evaluation is included that shows the performance, scalability and efficiency of our methods. 2008 Elsevier B.V. All rights reserved.	algorithm;range query (data structures);scalability	Spyros Sioutas;Konstantinos Tsakalidis;Kostas Tsichlas;Christos Makris;Yannis Manolopoulos	2008	Data Knowl. Eng.	10.1016/j.datak.2008.06.009	range query;search engine indexing;data structure;computer science;theoretical computer science;data mining;database;programming language;access method	DB	-26.649465684989483	0.9661150749443342	1331
25eaa942f6667a3ea5907fa1574ad62a549fc763	knowledge representation and sense disambiguation for interrogatives in e-hownet	判解;keh jiann chen;interrogatives;semantic representation;法律詞典;論文;大陸法學;法規;月旦法學;法律題庫;裁判時報;月旦知識庫;法學資料庫;tssci;e hownet;教學;shu ling huang;sense disambiguation	In order to train machines to ‘understand’ natural language, we propose a meaning representation mechanism called E-HowNet to encode lexical senses. In this paper, we take interrogatives as examples to demonstrate the mechanisms of semantic representation and composition of interrogative constructions under the framework of E-HowNet. We classify the interrogative words into five classes according to their query types, and represent each type of interrogatives with fine-grained features and operators. The process of semantic composition and the difficulties of representation, such as word sense disambiguation, are addressed. Finally, machine understanding is tested by showing how machines derive the same deep semantic structure for synonymous sentences with different surface structures.	artificial intelligence;encode;knowledge representation and reasoning;natural language;word sense;word-sense disambiguation	Shu-Ling Huang;Keh-Jiann Chen	2008	IJCLCLP	10.30019/IJCLCLP.200809.0001	natural language processing;semeval;computer science;linguistics;communication	AI	-26.21870762110035	-71.12094492310783	1335
a9c5aaa451d1596dfffd5486ba5ffba398a8e4e2	proceedings of the 11th brazilian symposium on multimedia and the web, webmedia 2005, pocos de caldas, minas gerais, brazil, december 5-7, 2005	minas gerais			Renata Pontin de Mattos Fortes	2005			computer science	Logic	-55.85663536447145	-7.793267859113645	1337
630ce28f2ca1d6a95604d08ded370fff32865859	collaborative design of an oceanographic event logger	design process;linked data;information infrastructure;invisible work;field data;interdisciplinary collaboration;collaborative design;oceanographic research	We report on an in-progress project to design a new field instrument used to link data collection and preservation practices across the gaps separating groups of oceanographic scientists engaged in interdisciplinary collaborations. Oceanographic cruises provide an important means for collecting data as an input for specific scientific investigations and for longer term efforts to make a wide range of environmental field data available for future scientific investigators. For both of these tasks, there is the need to perform the invisible work of identifying and resolving potential gaps and consistency issues in the data in order to make the data usable. The event logger system was designed to address these issues by associating every measurement on two organization's scientific cruises with a latitude, longitude, and time stamp. It is the finding of this ethnographic analysis that the event logger system has been successful to the extent that the design process has been able to incorporate a diverse range of voices into an open and collaborative activity.	basic stamp;data logger;keystroke logging	Brian Lindseth;Karen Baker	2012		10.1145/2145204.2145383	information infrastructure;simulation;design process;computer science;data science;linked data;data mining;world wide web	HCI	-71.7464306374365	-18.356944044988367	1338
add99d04f4c4322dc32c81d2071bebe6a49e73c3	a virtual psychiatric ward for orientating patients admitted for the first time	journal magazine article	Misconceptions about psychiatric wards frequently cause newly admitted mental patients to stay away from these wards despite their need for treatment. Although ward orientation is typically conducted by nurses in an attempt to help patients to adapt to the new environment, it is considered time-consuming, and the method of orientation and the explanations given may vary among different nurses. This situation calls for a more effective and standardized approach to orientating mental patients on their first admission. To this end, a computer-based interactive virtual environment was developed based on a real psychiatric ward by using virtual reality (VR) technologies. It enables the patient to navigate around to gain understanding about the ward through a virtual guided tour. The effectiveness of this VR orientation approach was investigated by a randomized controlled trial with consecutive sampling. Fifty-four Chinese participants were randomly assigned to undergo ward orientation by either using the VR-based approach or reading text-based electronic information sheets about the ward with a computer. Subjective and objective measures were obtained respectively using the Chinese version of the State-Trait Anxiety Inventory questionnaire and the heart-rate variability measurement before and after the intervention. In addition, a test on the level of understanding about the ward was administered at the end of the session. The results showed that the VR orientation approach is helpful in reducing patients' anxiety while also improving their level of understanding about the ward.	anxiety disorders;heart rate variability;hospital admission;mental disorders;mentally ill persons;patients;personnameuse - assigned;randomized algorithm;randomness;sampling (signal processing);text-based (computing);vr - veterans rand health survey;virtual reality;ward (environment);wikiwikiweb;explanation	Wai-Chi Lau;Kup-Sze Choi;Wai-Yee Chung	2010	Cyberpsychology, behavior and social networking	10.1089/cyber.2009.0107	psychology;psychiatry;medicine;computer science;pediatrics;psychotherapist	Visualization	-56.978953355484215	-54.225458136674604	1339
476b952e630aa269b9ca82cf5f7f06ce82c2a87b	ethical and privacy issues in the application of learning analytics	educational data mining;surveillance;data ownership;legal rights;presentation;ethics;conference paper;learning analytics;privacy	The large-scale production, collection, aggregation, and processing of information from various learning platforms and online environments have led to ethical and privacy concerns regarding potential harm to individuals and society. In the past, these types of concern have impacted on areas as diverse as computer science, legal studies and surveillance studies. Within a European consortium that brings together the EU project LACE, the SURF SIG Learning Analytics, the Apereo Foundation and the EATEL SIG dataTEL, we aim to understand the issues with greater clarity, and to find ways of overcoming the issues and research challenges related to ethical and privacy aspects of learning analytics practice. This interactive workshop aims to raise awareness of major ethics and privacy issues. It will also be used to develop practical solutions to advance the application of learning analytics technologies.	computer science;privacy	Hendrik Drachsler;Tore Hoel;Maren Scheffel;Gábor Kismihók;Alan Berg;Rebecca Ferguson;Weiqin Chen;Adam Cooper;Jocelyn Manderveld	2015		10.1145/2723576.2723642	public relations;information privacy;privacy by design;data science;political science;data mining	ML	-71.86879278710725	-15.042052127823839	1344
af025c47ffe3c537fd7dcb1ca5fc83871da5802f	using a positivist case research methodology to test three competing theories-in-use of business process redesign	business process redesign;positivist perspective;e commerce;is management;sociotechnical;research methodology;theory in use;business process reengineering	We test three practitioner theories-in-use of business process redesign derived from the business process reengineering (BPR) literature using a positivist case study of a U.S. company that undertook BPR. The evidence refutes the domi-	business process;code refactoring	Suprateek Sarker;Allen S. Lee	2001	J. AIS		e-commerce;economics;business process reengineering;systems engineering;engineering;knowledge management;business process management;process modeling;process management;business process;management;business process modeling	Web+IR	-79.54106599714514	3.5379357807879708	1345
eb2d88fadbe2fb924328a398c88468de4e9ddc79	design of graphical user interfaces to implement new features in an atm system of a financial bank		Actually, many bank customers would like to be able to perform various banking operations from an ATM in such a way that the entire process of long queues is avoided and the waiting time in the transaction process is reduced, which must guarantee the security of the customer’s data. That is why, as part of the human-computer interaction course of the PUCP of the master in informatics, it was decided with the support of the BBVA Continental to develop the design project of new operations for its ATMs. For the development of this project, three meetings were considered. In a first meeting, information was gathered with the bank’s workers, to be clear about how the operations that are to be designed are being carried out. For our second meeting, the evaluation of the prototypes was carried out in the bank’s facilities, for which usability tests were developed. In the last meeting, the improved prototypes were presented according to the breaks recorded in the usability tests. Ultimately, in order to carry out this project, a framework was developed which guaranteed constant interaction with our users and being able to meet all their needs.	atm turbo;graphical user interface	Roy Meléndez;Freddy Paz	2018		10.1007/978-3-319-91803-7_18	real-time computing;usability;informatics;graphical user interface;queue;database transaction;computer science;user-centered design	HCI	-67.39765874597072	-25.269615233667892	1347
57ff1c280a4bd599b444a4cdd1c0167c2a9e6aa8	speech perception in children with speech sound disorder	speech perception	This paper describes preliminary results from an ongoing study designed to characterize acoustic-phonetic traits in children with speech delay (SD) of unknown origin. Here we present data on 13 SD children and their siblings (26 children in all) from two speech perception tasks: a two-alternative forced choice categorical perception (ID) task, and an error monitoring (EM) task. In the ID task, minimally differing words (e.g., cage – gauge) were used to create 9-step synthetic continua. For the EM task, children heard both correctly and incorrectly articulated words and indicated whether the word was correct or not. Some word tokens in this task were produced by the SD children identified as probands in this study. On both tasks, SD children performed more poorly than their non-SD siblings, showing more gradual slopes in their ID functions, and less accuracy in identifying correct versus error productions.	acoustic cryptanalysis;faraday cage;list of http status codes;synthetic intelligence	H. Timothy Bunnell;N. Carolyn Schanen;Linda D. Vallino;Thierry G. Morlet;James B. Polikoff;Jennette D. Driscoll;James T. Mantell	2007			cued speech;speech recognition;motor theory of speech perception;auditory phonetics;speech perception;intelligibility (communication);computer science;speech sound disorder	NLP	-10.132500589471757	-81.97923348076125	1351
d24bb69dab7994a0e9a06b38f7f32e8c9dfd8aa7	brodyn'18: workshop on analysis of broad dynamic topics over social media		Social media streams are flooded with posts related to topics that are broad (i.e., cover several sub-topics) and dynamic (i.e., develop over time) which attract long-standing user interests. Posts about topics like “Brexit” or “UK elections” are hard to miss any day while these topics are “hot”, yet research on identifying and analyzing posts on such type of topics is still in its infancy. The BroDyn workshop aims at building a community interested in developing and exchanging ideas and methods for analyzing social media for broad dynamic topics. It also aims at understanding the limitations of existing techniques in answering emerging information needs for such topics, and proposing new techniques, evaluation methods, and test collections to address these limitations. The workshop is designed to bring together audience at all levels, including researchers from academia and industry as well as potential users, to create a forum for discussing recent advances in this area. The workshop, in its first version, featured three papers that span different aspects of the target research area.	denial-of-service attack;information needs;social media;usability	Tamer Elsayed;Walid Magdy;Mucahid Kutlu;Maram Hasanain;Reem Suwaileh	2018			multimedia;social media;political science	Web+IR	-76.52629579756302	-17.5889720189036	1360
245d6c2e2df3af9e46b08508652d27e13923e7a4	django remote submission		The Django Remote Submission (DRS) is a Django (Django, n.d.) application to manage long running job submission, including starting the job, saving logs, and storing results. It is an independent project available as a standalone pypi package (PyPi, n.d.). It can be easily integrated in any Django project. The source code is freely available as a GitHub repository (django-remote-submission, n.d.).		Tanner C. Hobson;Mathieu Doucet;Ricardo M. Ferraz Leal	2017	J. Open Source Software	10.21105/joss.00366	geology	SE	-43.621930169093034	-3.802084776758363	1361
0fc4a53d823057e0eb117d910a2f6d2de8a7e525	incremental discovery of top-k correlative subgraphs	databases;libraries;database management systems;trees mathematics data mining database management systems;correlation databases algorithm design and analysis data mining informatics educational institutions libraries;correlation mining;trees mathematics;data mining;graph mining;incremental processing;topcor algorithm incremental discovery top k correlative subgraph data mining correlation mining graph database query graph search tree;informatics;correlation;incremental processing graph mining correlation mining;algorithm design and analysis	Although data mining is a research area with important contributions, there is relatively limited work on correlation mining from graph databases. In this paper, we formulate the problem of mining the next most correlated graph in a graph database given the top-k correlated graphs, with respect to a query graph q. In order to solve the above problem, we take advantage of the search tree, produced by the top-k graphs. However, the search tree poses significantly difficulties, due to its size. Mainly relied on the TopCor algorithm, we make use of the algorithm's findings and rules, we derive two termination conditions and we devise a new algorithm to address the above problem, iTopCor. Our experimental results demonstrate the efficiency of the algorithm with respect to TopCor, especially when the data set is large or when many sub graph isomorphism tests are involved.	algorithm;big data;computation;data mining;experiment;graph database;graph isomorphism;input/output;scalability;search tree;subgraph isomorphism problem;time complexity	Georgia S. Latsiou;Apostolos N. Papadopoulos	2011	2011 15th Panhellenic Conference on Informatics	10.1109/PCI.2011.48	spqr tree;algorithm design;wait-for graph;computer science;data science;machine learning;data mining;database;fsa-red algorithm;graph;data stream mining;informatics;correlation;molecule mining;graph database;tree decomposition	DB	-7.1555836730612485	-38.35665694246931	1365
1204e5c70dcc882e008d372e46b88d4fe465d73c	construction of a teaching resources sharing platform based on campus network	campus network;sharing platform;teaching resources			Wenya Tian	2011	JDIM		world wide web;campus network;computer science	ECom	-73.00446456911105	-35.42921184426559	1367
5f6ca855ac89e2db2ad12dbf1ec5ec9df247ed38	heterogeneous multi-robot cooperation	cooperative control;mobile;learning;efficiency;cooperation;selection;robotics;missions;faults;computer architecture;electrical engineering and computer science;thesis;dynamics;awareness;fault tolerance;robots;parameters;control;artificial intelligence laboratory;behavior;global;problem solving;heterogeneity	This report addresses the problem of achieving fault tolerant cooperation within small to medium sized teams of heterogeneous mobile robots I describe a software architec ture I have developed called ALLIANCE that facilitates robust fault tolerant cooperative control and examine numerous issues in cooperative team design ALLIANCE is a fully distributed architecture that utilizes adaptive action selection to achieve cooperative control in robot missions involving loosely coupled largely independent tasks The robots in this architecture possess a variety of high level functions that they can perform during a mission and must at all times select an appropriate action based on the requirements of the mission the activities of other robots the current environmental conditions and their own internal states Since such cooperative teams often work in dynamic and unpredictable environ ments the software architecture allows the team members to respond robustly and reliably to unexpected environmental changes and modi cations in the robot team that may occur due to mechanical failure the learning of new skills or the addition or removal of robots from the team by human intervention In addition an extended version of ALLIANCE called L ALLIANCE incorporates a simple mechanism that allows teams of mobile robots to learn from their previous experiences with other robots allowing them to select their own actions more e ciently on subsequent trials when working with familiar robots on missions composed of independent tasks This mechanism allows a human system designer to easily and quickly group together the appropriate combination of robots for a particular mission since robots need not have a priori knowledge of their teammates The development of ALLIANCE and L ALLIANCE involved research on a number of topics fault tolerant cooperative control adaptive action selection distributed control robot awareness of team member actions improving e ciency through learning inter robot communication action recognition and local versus global control This report describes each of these topics in detail along with experimental results of investigating these issues both in simulated and in physical mobile robot teams I am not aware of any other cooperative control architecture that has exhibited the com bination of fault tolerance reliability adaptivity and e ciency possible with ALLIANCE and L ALLIANCE and which has been successfully demonstrated on physical mobile robot	action selection;artificial consciousness;consensus dynamics;distributed computing;distributed control system;experience;fault tolerance;high-level programming language;loose coupling;mobile robot;requirement;software architecture;structural integrity and failure;systems design	Lynne E. Parker	1994			simulation;engineering;artificial intelligence;operations management	Robotics	-26.58030706776001	-22.086268524749045	1370
9196ae8b315131b149c0f40be606d0d823844163	michael thelwall wins the 2015 derek john de solla price medal		The Editorial Board and the Publishers of Scientometrics are glad to announce that the 2015 Derek John de Solla Price Medal has been awarded to Michael Thelwall for his distinguished contribution to the field of sciento-metrics.	scientometrics	Kayvan Kousha;Jonathan Levitt	2015	Scientometrics	10.1007/s11192-015-1647-x	political economy;law and economics	DB	-58.88870454912885	-14.818337913167907	1371
21d50be08524a0fdc49f83a67e2838272ec1248b	putting control into language learning		PrimaRules = Cat, Conjunction ** { cat CS ; fun useA : A -> AP ; simpleCl : NP -> VP -> Cl ; usePN : PN -> NP ; usePron : Pron -> NP ; useCNdefsg : CN -> NP ; useCNindefsg : CN -> NP ; useCNindefpl : CN -> NP ; complexNP : Det -> CN -> NP ; conjNP : NP -> NP -> ListNP ; extConjNP : ListNP -> NP -> ListNP ; useConjNP : Conj -> ListNP -> NP ; useN : N -> CN ; attribCN : AP -> CN -> CN ; apposCNdefsg : CN -> PN -> NP ; useCl : Cl -> S ; advS : Adv -> S -> S ; intransV : V -> VP ; transV : V2 -> NP -> VP ; complVA : VA -> AP -> VP ; useS : S -> CS ; } abstract PrimaLex = Cat ** { fun copula_VA : VA ; copula_V2 : V2 ; -Vocabulary p11 -More vocabulary p19 imperium_N : N ; puella_N : N ; Romanus_A : A ; laetus_A : A ; magnus_A : A ; amicus_N : N ; imperator_N : N ; anxius_A : A ; habere_V2 : V2 ; vinum_N : N ; tenere_V2 : V2 ; bonus_A : A ; multus_Det : Det ; pater_N : N ; civitas_N : N ; felix_A : A ; externus_A : A ; coniux_N : N ; vincere_V2 : V2 ; sapiens_A : A ; victus_A : A ; numen_N : N ; saepe_Adv : Adv ; ingens_A : A ; provincia_N : N ; -Not in vocabulary list but in text devenire_V2 : V2 ; Augustus_PN : PN ; Gallia_PN : PN ; Caesar_N : N ; Africa_PN : PN ; he_PP : Pron ; Germanus_N : N ; and_Conj : Conj ; hostis_N : N ; dicere_V : V ; } Herbert Lange, Peter Ljunglöf (GU) Language Learning CNL 2018 12 / 17 Properties of the Grammars limited vocabulary small set of syntax rules implicitly defined syntactic complexity Herbert Lange, Peter Ljunglöf (GU) Language Learning CNL 2018 13 / 17 Deterministically interpretable (P4): Fully formalized grammars. Sentence are mapped to finite set of abstract syntax trees Languages with natural sentence (N4): Sentences syntactically correct according to the RGL Languages with short description (S4): Compact grammars with limited access to external resources like the RGL and additional lexica No classification (E−): No formal representation besides the abstract syntax trees (expressivity not relevant for application) Herbert Lange, Peter Ljunglöf (GU) Language Learning CNL 2018 14 / 17	abstract syntax tree;compute node linux;deterministic algorithm;leet;lexicon;peter bernus;r language;vocabulary	Herbert Lange;Peter Ljunglöf	2018		10.3233/978-1-61499-904-1-61	language acquisition;natural language processing;artificial intelligence;computer science	NLP	-30.41287497907481	-80.84772077904414	1378
dc632c820c965cb89a2c6203151e8bf600d39aa6	uta and sics at clef-ip		University of Tampere (UTA) and Swedish Institute of Computer Science (SICS) joined forces in a CLEF-IP experiment where a simple automatic query generation approach was initially tested. For two topics, the extracted query words were compared to query keys selected by three human experts to see whether the automatic key word extraction algorithms seem to be able to extract relevant words from the topics. We participated in the main task with 8 XL runs. Despite the modesty of our results, our best runs placed relatively well compared to the other participants' runs. This suggests that our approach to the automatic query generation could be useful, and should definitely be developed further. The comparison of the queries generated by the patent engineers to those generated by our system showed that typically less than half of the query words selected by the patent engineers were present in the automatically generated queries. For the limited two topics, our automatically generated queries also performed better than the patent engineers' ones, but clearly more user data would be needed before any conclusions can be made in one way or another.	algorithm;swedish institute of computer science	Antti Järvelin;Anni Järvelin;Preben Hansen	2009			speech recognition;clef;computer science	Web+IR	-31.469597436501374	-64.74878344045189	1388
bc6cad80d90b5093b354ee6795920faa6cfef1a8	how fair can you get? image retrieval as a use case to calculate fair metrics		Many providers of research data services officially embrace the FAIR guiding principles for scientific data management and stewardship. To assess the compliance of their services to these principles and to indicate possible improvements, use-case-centric metrics are needed as an addendum to existing approaches. The retrieval of spatially and temporally annotated images can exemplify such a use case. A prototypical benchmark based on that use case indicates that currently no research data repository achieves the full score according to the proposed metric. Suggestions on how to increase the score include automatic annotation based on the metadata inside the image file and support for content negotiation to retrieve the research data. This can lead to an improvement of data integration workflows, resulting in a better and more FAIR approach to manage research data.		Tobias Weber;Dieter Kranzlmüller	2018	2018 IEEE 14th International Conference on e-Science (e-Science)	10.1109/eScience.2018.00027	data integration;data mining;image retrieval;metadata;data management;data as a service;content negotiation;information repository;computer science;annotation	Visualization	-41.70259442548142	1.6951529366220006	1389
adb3fd76419d5961b2bf3826f44f256c460f7cda	a bioportal-based terminology service for health data interoperability	r medicine general	A terminology service makes diverse terminologies/ontologies accessible under a uniform interface. The EUTRANSFoRm project built an online terminology service for European primary care research. The service experienced performance limitations during its operation. Based on community feedback, we evaluated alternative solutions and developed a new version of the service. Based on BioPortal's scalable infrastructure, the new service delivers more features with improved performance and reduced maintenance cost. We plan to extend the service to meet Fast Healthcare Interoperability Resources specifications.	fast healthcare interoperability resources;interface device component;nomenclature;ontology (information science);open biomedical ontologies;primary health care;scalability;specification	Lei Zhao;Sarah N. Lim Choi Keung;Theodoros N. Arvanitis	2016	Studies in health technology and informatics	10.3233/978-1-61499-664-4-143	service level requirement;computer science;knowledge management;service delivery framework;service design;data mining;database	HPC	-54.31938656952603	-62.97172266391124	1392
7c4458cd5b66225774abd8ed65a14638937648f7	a ranking of universities should account for differences in their disciplinary specialization	analyse bibliometrique;filing;europa;production scientifique;disciplinary specialization;universite;gini index;espana;institutional research performance;scientific production;spanish academic system;university rankings;classement;indice gini;bibliometrics;university;espagne;bibliometric analysis;europe;recherche scientifique;universidad;scientific research;clasificacion;investigacion cientifica;analisis bibliometrico;spain;academic systems	A bibliometric analysis of the 50 most frequently publishing Spanish universities shows large differences in the publication activity and citation impact among research disciplines within an institution. Gini Index is a useful measure of an institution’s disciplinary specialization and can roughly categorize universities in terms of general versus specialized. A study of the Spanish academic system reveals that assessment of a university’s research performance must take into account the disciplinary breadth of its publication activity and citation impact. It proposes the use of graphs showing not only a university’s article production and citation impact, but also its disciplinary specialization. Such graphs constitute both a warning and a remedy against one-dimensional approaches to the assessment of institutional research performance.	bibliometrics;categorization;graph (discrete mathematics);partial template specialization	Carmen López-Illescas;Félix de Moya Anegón;Henk F. Moed	2011	Scientometrics	10.1007/s11192-011-0398-6	social science;scientific method;epistemology;bibliometrics;computer science;sociology;management	NLP	-75.73271460667134	-22.40096026224634	1393
40732026d1d7b2587d6aa1dfff0b800b957ee64a	natural language processing	artificial intelligence natural languages;natural language processing artificial intelligence knowledge representation large scale systems statistical analysis machine learning data mining optimization methods genetic algorithms neural networks;optimal method;statistical method;natural languages;data mining;constraint satisfaction;artificial intelligent;large scale;machine learning;artificial intelligence;genetic algorithm;knowledge representation;natural language processing;constraint satisfaction natural language processing artificial intelligence research knowledge representation logical reasoning;neural network	The Natural Language Processing group at the University of Szeged has been involved in human language technology research since 1998, and by now, it has become one of the leading workshops of Hungarian computational linguistics. Both computer scientists and linguists enrich the team with their knowledge, moreover, MSc and PhD students are also involved in research activities. The team has gained expertise in the fields of information extraction, implementing basic language processing toolkits and creating language resources. The Group is primarily engaged in processing Hungarian and English texts and its general objective is to develop language-independent or easily adaptable technologies. With the creation of the manually annotated Szeged Corpus and TreeBank, as well as the Hungarian WordNet, SzegedNE and other corpora it has become possible to apply machine learning based methods for the syntactic and semantic analysis of Hungarian texts, which is one of the strengths of the group. They have also implemented novel solutions for the morphological and syntactic parsing of morphologically rich languages and they have also published seminal papers on computational semantics, i.e. uncertainty detection and multiword expressions. They have developed tools for basic linguistic processing of Hungarian, for named entity recognition and for keyphrase extraction, which can all be easily integrated into large-scale systems and are optimizable for the specific needs of the given application. Currently, the group’s research activities focus on the processing of non-canonical texts (e.g. social media texts) and on the implementation of a syntactic parser for Hungarian, among others.	computational linguistics;computational semantics;computer scientist;information extraction;language technology;language-independent specification;list of toolkits;machine learning;named-entity recognition;natural language processing;parsing;social media;text corpus;treebank;wordnet	Alexander F. Gelbukh	2005		10.1109/ICHIS.2005.79	applications of artificial intelligence;natural language processing;computer science;artificial intelligence;machine learning	NLP	-31.228706258016366	-71.69386759853482	1394
29edfab86511511b149fc6e8691b07aac7a8dc67	computational understanding	computational understanding	"""The problem of computational understanding has often been broken into two sub-problems: how to syntactically analyze a natural language sentence and how to semantically interpret the results of the syntactic analysis. There are many reasons for this subdivision of the task, involving historical influences from American structural linguistics and the early """"knowledge-free"""" approaches to Artificial Intelligence. The sub-division has remained basic to much work in the area because syntactic analysis seems to be much more amenable to computational methods than semantic interpretation does, and thus more workers have been attracted developing syntactic analyzers first."""	artificial intelligence;computation;natural language;parsing;semantic interpretation;subdivision surface	Christopher Riesbeck	1974		10.3115/980190.980199	computer science	AI	-31.356396604292566	-75.55339556325993	1397
5435ae0434fe27af5f5abf122e950ddf255ac467	extracting biomedical events and modifications using subgraph matching with noisy training data		The Genia Event (GE) extraction task of the BioNLP Shared Task addresses the extraction of biomedical events from the natural language text of the published literature. In our submission, we modified an existing system for learning of event patterns via dependency parse subgraphs to utilise a more accurate parser and significantly more, but noisier, training data. We explore the impact of these two aspects of the system and conclude that the change in parser limits recall to an extent that cannot be offset by the large quantities of training data. However, our extensions of the system to extract modification events shows	baseline (configuration management);biomedical text mining;dependency grammar;downstream (software development);experiment;natural language;parsing;subgraph isomorphism problem;test set	Andrew MacKinlay;David Martínez;Antonio Jimeno-Yepes;Haibin Liu;W. John Wilbur;Karin M. Verspoor	2013			computer science;data mining;database;information retrieval	NLP	-24.255964116444346	-70.12208736068511	1401
51fdaa9a057c9341473211cc27adbd341149fe63	facilitating the acquisition of mental models of programming with gil: an integrated planning and debugging learning environment			debugging;mental model	Brian J. Reiser	1995			systems engineering;debugging;learning environment;integrated business planning;computer science	Robotics	-71.12015651443922	-35.961086118382596	1403
e8373331a93e5a6e56cb786a6aca56f9e96753a3	development of an adverse drug reaction corpus from consumer health posts for psychiatric medications		UWM-Adverse Drug Events Corpus (UWM-ADEC) is an annotated corpus that has been developed from consumer drug review posts in social media. In this corpus, we identified four types of Adverse Drug Reactions (ADRs) including physiological, psychological, cognitive, and functional problems. Additionally, we mapped the ADRs to corresponding concepts in Unified medical language Systems (UMLS). The quality of the corpus was measured using well-defined guidelines, double coding, high inter-annotator agreement, and final reviews by pharmacists and clinical terminologists. This corpus is a valuable source for research in the area of text mining and machine learning for ADRs identifications from consumer health posts, specifically for psychiatric medications.	ct scan;entity;find-a-drug;harvard mark iii;inter-rater reliability;machine learning;precision and recall;seamless3d;social media;systematized nomenclature of medicine;text corpus;text mining;vocabulary	Maryam Zolnoori;Timothy B. Patrick;Kin Wah Fung;Paul A. Fontelo;Anthony Faiola;Yi Shuan Shirley Wu;Kelly Xu;Jiaxi Zhu;Christina E. Eldredge	2017			adverse drug reaction;psychiatry;medicine	NLP	-49.380050283076436	-70.04984499114526	1404
f8a1d72cfa347dae2133c839c4cf631cee7ee649	multidimensional emotional appraisal semantic space (meas): evaluating hm affective interactions	human computer interaction;affective interaction;settore m psi 01 psicologia generale;semantic model;emotion;semantic space;m psi 01 psicologia generale;non verbal communication	In this paper we'll present a dimensional semantic model of emotion locating the former in a four axes space in the attempt to quantify emotion considered as constantly changing with time rather than to label it. The Multidimensional Emotional Appraisal Semantic Space (MEAS) is a method according to which the most relevant features to measure emotions are: a dimensional approach to emotion, the multimodality of expressive signals and the embodied nature of the emotional interaction. Four dimensions have been selected: novelty, pleasantness, coping and arousal. The componential organization all these different levels gives birth to multiple and fuzzy emotional experiences that are in part signalled through patterns of non verbal expression and that can change their intensity in relation to the relevance of the event for the individual and in relation to the arousal given by physiological signals.	interaction	Maria Rita Ciceri;Stefania Balzarotti	2007		10.1007/978-3-540-74827-4_50	emotion;emotional expression;artificial intelligence	AI	-51.74221723895426	-47.6323195595225	1406
b5e66b914d10c71a1159dab989bb6444cf2ffd9c	planning and plausible reasoning in artificial intelligence: diagrams, planning, and reasoning	artificial intelligent		artificial intelligence;diagram	Cyrus F. Nourani	1991			opportunistic reasoning;model-based reasoning;procedural reasoning system;psychology of reasoning;artificial intelligence, situated approach;computer science;qualitative reasoning;artificial intelligence;automated reasoning;reasoning system	AI	-27.40918126700328	-7.9987144800907215	1408
66086c667fac2f1ffd7154cb4667c78ede4de03e	"""foreword to the special issue on """"nonstandard applications of computer algebra"""""""	nonstandard application;computer algebra;special issue	nonstandard application;computer algebra;special issue	symbolic computation	Michael J. Wester;Stanly L. Steinberg;Eugenio Roanes-Lozano	2009	Mathematics and Computers in Simulation	10.1016/j.matcom.2008.11.004	applied mathematics;computer science	DB	-50.96152793242404	-15.507999450432838	1409
34f4e09d2de65026d9d65e99b848a544198f6a7e	visual discovery and model-driven explanation of time series patterns	market research;metadata;time series analysis;data visualization;lenses;visual analytics;article	Gatherminer is an interactive visual tool for analysing time series data with two key strengths. First, it facilitates bottom-up analysis, i.e., the detection of trends and patterns whose shapes are not known beforehand. Second, it integrates data mining algorithms to explain such patterns in terms of the time series' metadata attributes - an extremely difficult task if the space of attribute-value combinations is large. To accomplish these aims, Gatherminer automatically rearranges the data to visually expose patterns and clusters, whereupon users can select those groups they deem `interesting.' To explain the selected patterns, the visualisation is tightly coupled with automated classification techniques, such as decision tree learning. We present a brief evaluation with telecommunications experts comparing our tool against their current commercial solution, and conclude that Gatherminer significantly improves both the completeness of analyses as well as analysts' confidence therein.	algorithm;bottom-up proteomics;data mining;decision tree learning;model-driven integration;statistical model;time series;usability testing;vii;visual language	Advait Sarkar;Martin Spott;Alan F. Blackwell;Mateja Jamnik	2016	2016 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)	10.1109/VLHCC.2016.7739668	computer science;data science;data mining;world wide web	DB	-25.78134921678747	-34.18864550453181	1410
c6233e747e167eedab52c9b51fa2dd937c5fd1da	on the interactive visualization of very large image data sets	real time visualization;personal computer;real time;interactive visualization;panoramic images;rendering computer graphics data visualisation image representation;image representation scheme;data visualisation;image representation;data visualization rendering computer graphics real time systems image representation hardware layout cities and towns robustness navigation microcomputers;panoramic images image data set visualization image representation scheme adaptive rendering perspective view generation module;image data set visualization;panoramic image;rendering computer graphics;perspective view generation module;adaptive rendering	This paper presents a system for real-time visualization of very large image data sets using on- demand loading and dynamic view prediction. We use a robust image representation scheme for efficient adaptive rendering and a perspective view generation module to extend the applicability of the system to panoramic images. We demonstrate the effectiveness of the system by applying it both to imagery that does not require perspective correction and to very large panoramic data sets requiring perspective view generation. The system permits smooth, real-time interactive navigation of very large panoramic and non-panoramic image data sets on average personal computers without the use of specialized hardware.	interactive visualization;personal computer;real-time clock;real-time web	Frank Ekpar;Masaaki Yoneda;Hiroyuki Hase	2007	7th IEEE International Conference on Computer and Information Technology (CIT 2007)	10.1109/CIT.2007.80	computer vision;interactive visualization;computer science;multimedia;computer graphics (images)	Vision	-34.526976747854405	-33.733608161076226	1417
870f8222d83933d6b0c35dd9f8597acbce509c1e	development of brand selection model considering customer service		In many companies, customer service becomes one of the critical factors of the brand evaluation. It is important for the companies to know the customer’s utility functions about the customer service and repurchase of the products considering customer service. One of our main aims of this study is to develop brand selection model which considering utility of the customer service in order to propose promotion method for customer service of the company. In this study, we add some types of the customer services to utility in the models, and develop brand selection models. By the use of the questionnaire survey for the real companies, we confirm the adaptability of the proposed model, and we show the importance of the customer service.		Hiroki Kageyama;Fumiaki Saitoh;Syohei Ishizu	2013		10.1007/978-3-642-39473-7_137	customer to customer;voice of the customer;customer equity;customer reference program;brand management;customer delight;customer intelligence;customer retention;brand awareness;service quality;customer advocacy	NLP	-5.127742772338268	-15.262892665061814	1429
049da10d45d6b08701b002777bcdc22cae34ed46	the playful and the serious: an approximation to huizinga's homo ludens			approximation;dr. zeus inc.	Hector Rodriguez	2006	Game Studies			HCI	-54.031529825001954	-16.79477347529124	1435
02bcc2a19af47e579f4622132d0686c51eb9b274	but i wasn't trained on that!: the use and abuse of training tools	search terms;learning style;learning styles;training;troubleshooting;mentoring;knowledgebase;training program;critical thinking;tools;problem solving	"""Is your training program in a funk? Have PowerPoint presentations and PDFs lost their appeal? Are you hearing the line, """"I wasn't trained on that!"""" too often? If so, we have some advice that may help you break the monotony of everyday training.  In 2010, the group responsible for training student consultants at the CITES Help Desk undertook a daunting task. We needed to detail each service and application we supported as well as all of our policies and procedures. Every facet of our business had to be recorded then imparted to a newly re-positioned and non-technical group of Help Desk consultants.  In teaching this information we discovered what we already knew, but could rarely physically demonstrate: a Help Desk consultant can never fully understand the scope of what we truly do. """"I wasn't trained on that,"""" becomes an unavoidable reality. So, our training took a different approach. Instead of focusing on the """"facts"""" of our business as we had relied on heavily in the past, we invested more time in developing critical thinking, effective search habits, troubleshooting and problem solving skills. """"You don't know everything but you can find anything,"""" became an unofficial mantra.  Online coursework, job shadowing, lectures, and training games are just some of the methods that have been used in our training programs. This paper will explore the pros of each tool, but also show how they might be over-used, under-used or simply abused by the teacher or the student."""	job stream;portable document format;problem solving	Nathan Carpenter;Ryan Christopher Tucker	2010		10.1145/1878335.1878348	simulation;engineering;knowledge management;multimedia	HCI	-75.84604815678243	-30.387945002761427	1439
7e54ddbd0045e61a7b6f4642641c649ce399c36c	improving recombination in a linear ebmt system by use of constraints	computerlinguistik;lin ebmt;lin ebmt system;constraint;srilm;beispielbasierte maschinelle ubersetzung;sprachverarbeitung;maschinelle ubersetzung;moses;example based machine translation;natural language processing	(Automatic) machine translation (MT) is one of the most challenging domains in Natural Language Processing (NLP) and plays an important role in ensuring global communication, especially in a multilingual world with access to large amounts of Internet resources. As rule-based MT approaches need manually developed resources, new MT directions have been developed over the last twenty years, such as corpus-based machine translation (CBMT): statistical MT (SMT) and example-based machine translation (EBMT). These new directions are based mainly on the existence of a parallel aligned corpus and, therefore, can be easily employed for lower-resourced languages. In this dissertation we showed how EBMT systems behave when a lower-resourced inflecting language (i.e. Romanian) is involved in the translation process. For this purpose we built an EBMT baseline system based only on surface forms (the Lin-EBMT system). One of our main goal was to investigate the impact of word-order constraints on the translation results: we integrated constraints extracted from generalized examples (i.e. templates) in Lin-EBMT and built an extended system: Lin − EBMTREC+. Although constraints represent a well-known method which is employed quite often in NLP, the use of word-order constraints in an EBMT system is an innovative approach which can open new paths in the domain of example-based MT. We run our experiments for two language-pairs in both directions of translation: Romanian-German and Romanian-English. This aspect raises interesting questions, as Romanian and German present language specific characteristics, which make the translation process even more challenging. Both EBMT systems developed are easily adaptable for other language-pairs. They are platform and languagepair independent, provided that a parallel aligned corpus for the language-pair exists and that the tools used for obtaining the needed intermediate information (e.g. wordalignment) are available. As a side question, we studied how EBMT reacts in comparison to SMT. We compared the EBMT results obtained to results provided by a Moses1-based SMT system and the Google Translate on-line system. To provide a complete view on CBMT, the performance of each MT system was assessed in several experimental settings, using different corpora (type and size), various system settings and additional part-of-speech (POS) information. We evaluated the translation results by means of three automatic evaluation metrics: BLEU, NIST and TER. A subset of the results was manually analyzed for a better overview on the translation quality. Our experiments showed that constraints improve translation results, although a clear www.statmt.org/moses last accessed on June 27th, 2011.	bleu;baseline (configuration management);crossover (genetic algorithm);evaluation of machine translation;example-based machine translation;experiment;google translate;logic programming;nist (metric);natural language processing;online and offline;parallel computing;part-of-speech tagging;statistical machine translation;text corpus;on-line system	Monica Gavrila	2012			engineering;performance art;cartography	NLP	-28.96375695970745	-74.85519181877605	1442
ebd01fcb9f22a90e92ff1f0e112defd247dc96c5	organizational issues in the implementation and adoption of health information technology innovations: an interpretative review	health information technology;implementation;organizational	PURPOSE Implementations of health information technologies are notoriously difficult, which is due to a range of inter-related technical, social and organizational factors that need to be considered. In the light of an apparent lack of empirically based integrated accounts surrounding these issues, this interpretative review aims to provide an overview and extract potentially generalizable findings across settings.   METHODS We conducted a systematic search and critique of the empirical literature published between 1997 and 2010. In doing so, we searched a range of medical databases to identify review papers that related to the implementation and adoption of eHealth applications in organizational settings. We qualitatively synthesized this literature extracting data relating to technologies, contexts, stakeholders, and their inter-relationships.   RESULTS From a total body of 121 systematic reviews, we identified 13 systematic reviews encompassing organizational issues surrounding health information technology implementations. By and large, the evidence indicates that there are a range of technical, social and organizational considerations that need to be deliberated when attempting to ensure that technological innovations are useful for both individuals and organizational processes. However, these dimensions are inter-related, requiring a careful balancing act of strategic implementation decisions in order to ensure that unintended consequences resulting from technology introduction do not pose a threat to patients.   CONCLUSIONS Organizational issues surrounding technology implementations in healthcare settings are crucially important, but have as yet not received adequate research attention. This may in part be due to the subjective nature of factors, but also due to a lack of coordinated efforts toward more theoretically-informed work. Our findings may be used as the basis for the development of best practice guidelines in this area.	best practice;database;diffusion of innovation;equilibrium;information sciences;paper;patients;practice guidelines as topic;review [publication type];scientific publication;systematic review;unintended consequences	Kathrin M. Cresswell;Aziz Sheikh	2013	International journal of medical informatics	10.1016/j.ijmedinf.2012.10.007	organizational learning;computer science;organization;knowledge management;organizational studies;management science;implementation;management;law	HCI	-79.93110795494778	-1.6256533924565157	1444
f457c762d820755347e948310da0a5bc2958b94e	efficient algorithms for simultaneously mining concise representations of sequential patterns based on extended pruning conditions		Abstract The concise representations of sequential patterns, including maximal sequential patterns, closed sequential patterns and sequential generator patterns, play an important role in data mining since they provide several benefits when compared to sequential patterns. One of the most important benefits is that their cardinalities are generally much less than the cardinality of the set of sequential patterns. Therefore, they can be mined more efficiently, use less storage space, and it is easier for users to analyze the information provided by the concise representations. In addition, the set of all maximal sequential patterns can be utilized to recover the complete set of sequential patterns, while closed sequential patterns and sequential generators can be used together to generate non-redundant sequential rules and to quickly recover all sequential patterns and their frequencies. Several algorithms have been proposed to mine the concise representations separately, i.e., each of them has been designed to discover only a type of the concise representation. However, they remain time-consuming and memory intensive tasks. To address this problem, we propose three novel efficient algorithms named FMaxSM, FGenCloSM and MaxGenCloSM to exploit only maximal sequential patterns, to simultaneously mine both the sets of closed sequential patterns and generators, and to discover all three concise representations during the same process. To our knowledge, MaxGenCloSM is the first algorithm for concurrently mining the three concise representations of sequential patterns. The proposed algorithms are based on two novel local pruning strategies called LPMAX and LPMaxGenClo that are designed to prune non-maximal, non-closed and non-generator patterns earlier and more efficiently at two and three successive levels of the prefix tree without subsequence relation checking. Extensive experiments on real-life and synthetic databases show that FMaxSM, FGenCloSM and MaxGenCloSM are up to two orders of magnitude faster than the state-of-the-art algorithms and that the proposed algorithms consume much less memory, especially for low minimum support thresholds and for dense databases.	algorithm	Hai V. Duong;Tin C. Truong;Hoai Bac Le	2018	Eng. Appl. of AI	10.1016/j.engappai.2017.09.024	machine learning;pruning;artificial intelligence;cardinality;trie;computer science;sequential pattern mining;exploit;algorithm	AI	-6.270088827333119	-37.07746283567851	1446
d7b7e60defbba50e59e8e4556d41ac52223aaeef	virtual space co-creation: the perspective of user innovation	user communities;personalization;user toolkits;creative self efficacy;leading edge status;customer knowledge;user innovation;co creation	By integrating theories and findings from prior user innovation literature, the authors examine how to improve a customer's co-creation and personalization performance of virtual products by means of harnessing the complementary effects of user characteristics leading edge status, customer knowledge, and creative self-efficacy and firm supporting factors user toolkits and user communities. They tested an integrated research model using survey data collected from 308 Chinese consumers who personalized their virtual spaces by utilizing the tools and supports provided on a social network service site. The authors find that the integrated model that includes both user factors and firm factors was more powerful in terms of explaining a higher variance in personalization effectiveness. They also find that leading edge status, creative self-efficacy, and user communities had stronger impacts on personalization effectiveness than did customer knowledge and user toolkits. The findings provide a broader review of user factors and firm factors for business practitioners and researchers to understand co-creation and personalization.		Yonggui Wang;Dahui Li	2016	JOEUC	10.4018/JOEUC.2016040106	user modeling;computer user satisfaction;user journey;knowledge management;marketing;personalization;multimedia;law;world wide web	HCI	-88.29211962741546	-11.799043056510275	1448
306a947e12e03b0ec8301577c0c13bddde8bb4cf	the gameplay visualization manifesto: a framework for logging and visualization of online gameplay data	quality assurance;online game;massively multiplayer online game;game design;quests;massively multiplayer online roleplaying games;massively multiplayer online games;gameplay visualization;data acquisition	As massively multiplayer online games gain popularity, there has been a concomitant increase in their size and complexity, both technically and in terms of player usage. Quality assurance for such games takes up a major component of the development budget due to the painstaking work required to ensure the best possible gameplay. This article presents a new framework for the process of visualizing online game-play data. Major components such as an event model and data acquisition infrastructure are derived. Interface and implementation factors are also explored, including in-situ game interface approaches. We also expect that this framework can be modified for all genres of gaming that require an understanding of complex game-play.	complexity;data acquisition;event (computing);expect;massively multiplayer online role-playing game	Simon Joslin;Ross Brown;Penny Drennan	2007	Computers in Entertainment	10.1145/1316511.1316517	video game design;game design;quality assurance;simulation;computer science;emergent gameplay;game mechanics;distributed computing;multimedia;data acquisition;video game development	Visualization	-54.108663604641286	-42.811294208458584	1450
4f5d704ac1cdf2a54ca39699b25cb96a01e062e3	technology-based service encounters using self-service technologies in the healthcare industry	customer satisfaction;indexation;survey data;patient satisfaction	Although there have been studies discussing the influence of technology-based services on the overall service efficiency and quality of organizations in various industries, very little effort has been devoted to investigating this issue in the healthcare industry. Hospital image is considered to be a crucial factor influencing patients' choice of hospitals, but few studies specifically examine its association with technology-based services. By consulting the model of the European Customer Satisfaction Index, a research model for evaluating the impact of the use of technology-based services on hospital image, patient satisfaction, and patient loyalty in the healthcare industry is developed and examined in this study using survey data collected from 738 patients at two medical centers with an online appointment system. The research results confirm the importance of providing quality, technology-based services in enhancing hospital image, patient satisfaction, and patient loyalty. The implications of this re...		Wei-Tsong Wang;Shih-Yu Cheng;Lin-Yo Huang	2013	Int. J. Hum. Comput. Interaction	10.1080/10447318.2012.695728	knowledge management;survey data collection;customer satisfaction	HCI	-61.78623575152879	-63.39516070266404	1457
8bdd9c36e813dcd412c940c4b68c29363da626c2	existing plagiarism detection techniques: a systematic mapping of the scholarly literature	plagiarism;processes;detection;qa75 electronic computers computer science;taxonomy;techniques	Purpose – The purpose of this paper is to analyse the state-of-the-art techniques used to detect plagiarism in terms of their limitations, features, taxonomies and processes. Design/methodology/approach – The method used to execute this study consisted of a comprehensive search for relevant literature via six online database repositories namely; IEEE xplore, ACM Digital Library, ScienceDirect, EI Compendex, Web of Science and Springer using search strings obtained from the subject of discussion. Findings – The findings revealed that existing plagiarism detection techniques require further enhancements as existing techniques are incapable of efficiently detecting plagiarised ideas, figures, tables, formulas and scanned documents. Originality/value – The contribution of this study lies in its ability to have exposed the current trends in plagiarism detection researches and identify areas where further improvements are required so as to complement the performances of existing techniques.		Taiseer Abdalla Elfadil Eisa;Naomie Salim;Salha Alzahrani	2015	Online Information Review	10.1108/OIR-12-2014-0315	computer science;data science;data mining;database;world wide web;information retrieval;taxonomy	HCI	-38.87466473364456	-59.56974912733568	1462
7fc2dd9f1bff23eaff50177ede33c20d084ff97d	query answering to iq test questions using word embedding		This paper presents an improvement over the results of Wang et al. on query answering to IQ test questions using word embedding. The improvement comes from using the Glove method and renormalization of results using the best results of two leading methods. This latter approach combines knowledge coming from different corpuses.	word embedding	Michal Frackowiak;Jakub Dutkiewicz;Czeslaw Jedrzejek;Marek Retinger;Pawel Werda	2016		10.1007/978-3-319-43982-2_25	natural language processing;computer science;linguistics;information retrieval	NLP	-26.82096297707321	-68.1071973542868	1467
11059a93fddf610d2e41a21292dc25d88d7f8827	transfer learning and applications		In machine learning and data mining, we often encounter situations where we have an insufficient amount of high-quality data in a target domain, but we may have plenty of auxiliary data in related domains. Transfer learning aims to exploit these additional data to improve the learning performance in the target domain. In this talk, I will give an overview on some recent advances in transfer learning for challenging data mining problems. I will present some theoretical challenges to transfer learning, survey the solutions to them, and discuss several innovative applications of transfer learning, including learning in heterogeneous cross-media domains and in online recommendation, social media and social network mining.	data mining;machine learning;social media;social network	Qiang Yang	2012		10.1007/978-3-642-32891-6_2	multi-task learning;instance-based learning;computer science;data science;machine learning;data mining;inductive transfer;synchronous learning	ML	-17.661377879777454	-50.27349669422524	1470
0521b301c8e8cc96754cba9346688723fbaa789e	"""a response to """"the museum of errors/horrors in scopus"""" by franceschini et al"""		The Opinion Paper by Franceschini, Maisano, and Mastrogiacomo (2016) entitled “The museum of errors/horrors in copus” highlights some errors in Scopus indexing. Scopus has always strived for 100% accurate representation of indexed tems and 100% matching of cited references to their cited targets, and therefore we are grateful to the Editor of this journal or the opportunity to respond to this paper. Scopus grows daily and today contains more than 61 million documents from over 5,000 publishers. Scopus has also had umerous changes in technology since it was launched 12 years ago. We always appreciate feedback from users and have nvested significantly in making it easy for users and the broader research community to provide the elements we need to e able to act on the feedback, and in streamlining our operational procedures to incorporate feedback quickly. Likewise, we appreciate the open feedback in this Opinion Paper. Several classes of indexing errors are highlighted that esult from occasional data processing errors and are inherent in databases of Scopus’ size and complexity. All of the error ypes mentioned are known to us, but the occurrence of these errors is not always easy to identify automatically, at scale, n the database. We have corrected most of the isolated occurrences identified by the authors; we are investigating the emaining ones and are also assessing their underlying cause(s) to improve our existing procedures for identifying and orrecting these in the future. Most of the errors reported fall into two different categories: The first category is that of citations not being linked. Scopus has strict rules before it matches citations, and we have eighted these rules towards precision, rather than towards recall. If the information of the cited reference as provided by he authors differs too much from the core item (for example, differences in the article title or differences in the metadata) here is no match and the citation link between the citing document and the cited document will not be made. This may hen result in citations to indexed articles being missed in Scopus. If we would follow the route that the authors seem to be uggesting, and weight more heavily towards recall rather than precision, then we may be able to link some of the missing itations correctly but there would be a much higher occurrence of incorrect links. The second category is duplication of items. For some content, we receive the same information from different sources such as content processed by ourselves, and content processed by third parties such as Medline), or we receive different ersions of the same article from the same source (such as the article-in-press and the final version). Scopus de-duplicates nd merges these items based on the metadata of the article. Once again, the matching algorithm is weighted towards recision rather than towards recall. If there are inconsistencies in the metadata between the items, then they will not be dentified as duplicates and both will remain present in the database. If we would be more permissive in the matching, we ay be able to match and remove some additional duplicates correctly but there would be a much higher occurrence of ccidental removal of non-duplicate items. For a database of the size of Scopus, it is constantly necessary to balance precision and recall. Scopus always weights ost heavily towards precision (99.95% precision and 98.5% recall).1 This type of balancing may not be necessary for the maller datasets often used in bibliometric studies, where manual validation and correction are possible, and we hope that his explanation of the trade-offs is valuable to this journal’s readers. We believe that the approach in place for Scopus, of taking the information provided by the authors, via the publishers, as he authoritative information, is the correct one. However, in cases where precise matching is needed for accurate indexing, uch as in citation linking and the removal of duplicates, this means that Scopus relies heavily on the accuracy of publisherrovided information. We do not lightly change this publisher-provided information without validation from the research ommunity; and this is why we have extensive feedback mechanisms in place to make corrections where needed.2 However, e recognize that some structural improvements can be made and therefore we also continue to invest significantly in ngoing initiatives to ensure the quality of Scopus content.	algorithm;bibliometrics;database;medline;precision and recall;scopus	Wim J. N. Meester;Lisa Colledge;Elizabeth E. Dyas	2016	J. Informetrics	10.1016/j.joi.2016.04.011		Web+IR	-33.51288553530095	-58.72002572657363	1472
7af760cd2886bb3b2a21274f7b4e780e926c81aa	sensor based speech production system without use of glottis		The present work proposes a speech production mechanism using source-filter (Vocal tract) model, with the help of sensors placed in the oral cavity to synthesize speech. The speech is produced without involvement of glottis. This is achieved by exciting the articulatory system (Oral cavity) with sensor based input. The proposed system creates a virtual voice for a person who lost his voice due to some disability in vocal tract. The Vocal tract model and articulatory system has been tested with English alphabets (Vowels and consonants) using LabView, which has been validated by perceptual test. The present work mainly focuses on the role of the tongue as speech articulator.	algorithm;graphical user interface;labview;production system (computer science);sensor;signal processing;speech synthesis;tract (literature)	Palli Padmini;Shikha Tripathi;Kaustav Bhowmick	2017	2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2017.8126151	speech recognition;control engineering;glottis;articulatory phonetics;computer science;vocal tract;articulator;tongue;speech production;graphical user interface;perceptual test	HCI	-7.2505480085508145	-84.64630374099997	1477
829aac2a2996c5f451bc0701899ff34274c48fb6	20th ieee international conference on e-health networking, applications and services, healthcom 2018, ostrava, czech republic, september 17-20, 2018					2018				Robotics	-56.24034860145697	-5.587327620170075	1488
7f968a1982b45d6405cb1f6f1d337f062a0db165	evolution of artificial agents in a realistic virtual environment	virtual environments;video game;evolutionary algorithms;evolutionary algorithm;virtual environment;simulation environment;physical simulation;artificial agents	Modern video game software implements very immersive, simulated worlds. These worlds benefit from highly sophisticated graphics and physics simulations provided by the software. The experiments presented here show that these complex simulated environments can provide an attractive research platform for evolutionary algorithms, specifically for the task of artificial agent evolution.	artificial intelligence;basis (linear algebra);constrained optimization;crossover (genetic algorithm);evolutionary algorithm;experiment;graphics;immersion (virtual reality);intelligent agent;many-worlds interpretation;mathematical optimization;simulated reality;simulation;virtual reality	Jonathan R. Hicks;Joseph A. Driscoll	2005		10.1145/1167253.1167340	simulation;human–computer interaction;computer science;multimedia	AI	-27.96912367546668	-24.57465206643287	1494
6a1cd218ffb388167095e7fd6f0631e740357a42	adapting bottom-up, emergent behaviour for character-based ai in games		It is widely acknowledged that there is a demand for alternatives to handcrafted character behaviour in interactive entertainment/video games. This paper investigates a simple agent architecture inspired by the thought experiment “Vehicles: Experiments in Synthetic Psychology” by the cyberneticist and neuroscientist Valentino Braitenberg [1]. It also shows how architectures based on the core principles of bottom-up, sensory driven behaviour controllers can demonstrate emergent behaviour and increase the believability of virtual agents, in particular for application in games.	adobe flash;agent architecture;bottom-up parsing;connectionism;cyberneticist;emergence;experiment;interaction;simulation;synthetic intelligence;top-down and bottom-up design	Micah Rosenkind;Graham Winstanley;Andrew Blake	2012		10.1007/978-1-4471-4739-8_26	simulation;computer science;artificial intelligence;communication	AI	-23.928014755847443	-19.452438554004125	1501
13592c1bef7a0927b6ff672d00e89ac3b656eabf	multi-agent reinforcement learning for planning and scheduling multiple goals	learning hydrogen multiagent systems robots postal services knowledge acquisition state space methods delay;multi agent reinforcement learning;planning artificial intelligence;knowledge acquisition multi agent systems learning artificial intelligence planning artificial intelligence scheduling;planning and scheduling;non mdps multiagent reinforcement learning multiple goal scheduling knowledge acquisition reinforcement learning algorithm complexity multiple agents pre defined structures desirable emergence cooperative behaviors potential cooperative properties profit sharing;multi agent systems;scheduling;knowledge acquisition;state space;learning artificial intelligence	Recently, reinforcement learning has been proposed as an effective method for knowledge acquisition of the multiagent systems. However, most researches on multiagent system applying a reinforcement learning algorithm focus on the method to reduce complexity due to the existence of multiple agents[4] and goals[8]. Though these pre-defined structures succeeded in putting down the undesirable effec t due to the existence of multiple agents, they would also suppress the desirable emergence of cooperative behaviors in the multiagent domain. We show that the potential cooperative properties among the agent are emerged by means of Profit-sharing[2][3] which is robust in the non-MDPs.	agent-based model;algorithm;automated planning and scheduling;effective method;emergence;knowledge acquisition;multi-agent system;reinforcement learning;scheduling (computing)	Sachiyo Arai;Katia P. Sycara;Terry R. Payne	2000		10.1109/ICMAS.2000.858474	error-driven learning;computer science;knowledge management;artificial intelligence;machine learning;hyper-heuristic	AI	-17.019714647529113	-11.154644197109693	1505
b3c747d92eca0af4bb8e7d269b08a675480c4c69	assessing the comparability of news texts		Comparable news texts are frequently proposed as a potential source of alignable sub-sentential fragments for use in statistical machine translation systems. But can we assess just how potentially useful they will be? In this paper we first discuss a scheme for classifying news text pairs according to the degree of relatedness of the events they report and investigate how robust this classification scheme is via a multi-lingual annotation exercise. We then propose an annotation methodology, similar to that used in summarization evaluation, to allow us to identify and quantify shared content at the sub-sentential level in news text pairs and report a preliminary exercise to assess this method. We conclude by discussing how this works fits into a broader programme of assessing the potential utility of comparable news texts for extracting paraphrases/translational equivalents for use in language processing applications.	comparison and contrast of classification schemes in linguistics and metadata;fits;statistical machine translation	Emma Barker;Robert J. Gaizauskas	2012			data science;data mining;information retrieval	NLP	-28.33543371916392	-68.28715933321443	1514
bbd5cf716d3b112feda52f549cae3497239a60f3	big data framework for finding patterns in multi-market trading data		In the United States, multimarket trading is becoming very popular for investors, professionals and high-frequency traders. This research focuses on 13 exchanges and applies data mining algorithm, an unsupervised machine learning technique for discovering the relationships between stock exchanges. In this work, we used an association rule (FP-growth) algorithm for finding trading pattern in exchanges. Thirty days NYSE Trade and Quote (TAQ) data were used for these experiments. We implemented a big data framework of Spark clusters on the top of Hadoop to conduct the experiment. The rules and co-relations found in this work seems promising and can be used by the investors and traders to make a decision.	big data	Daya Ram Budhathoki;Dipankar Dasgupta;Pankaj Jain	2018		10.1007/978-3-319-94301-5_18	machine learning;data mining;unsupervised learning;big data;artificial intelligence;stock exchange;computer science;association rule learning	ML	-8.837176130709802	-30.97583385340948	1524
621a165bb1d7219d9db31f756d20ab5f69ca1b7f	intellectual property and universities: a path forward [point of view]		During the past three decades there has been an increasing focus on the commercialization of technologies developed by academe. Prior to this, research funding by the U.S. Government was skewed toward pure science and mention of commercialization was viewed negatively more often than not. Today’s research funding landscape has reversed the negative view of commercialization, with many Requests for Proposals having specific requirements toward commercialization assessments. This change in mindset has dramatically increased the importance of intellectual property (IP) created by academic research. In fact, most universities have Technology Transfer Offices actively seeking commercialization opportunities for IP created through research activities. The impact of commercialization focus has also affected funding beyond universities. Startup efforts leveraging university IP have become commonplace, with the number of funding mechanisms increasing dramatically. Corporate engagement and interest in university research has evolved as well through the creation of consortia that have expanded the interconnection between industry and academe beyond sponsored research projects. The role of university Technology Transfer Offices has had to evolve to accommodate business engagements at startup and corporate levels, leading to a complex IP landscape that involves universities, startups, and large industrial players. The education of future researchers remains the prime directive of universities, while corporate/startup recruiting is, and will continue to be, a critical component to the relationship between business and academe. Through this Point of View contribution, we provide insight into the cycle of university IP and funding that has evolved through increased commercialization focus for research technologies, highlighting and the resulting relationships between academe, startups, and corporations and offer our opinions on how the future of universities and intellectual property should evolve. Two university IP-based startups from our personal experience are then described to provide examples of possible paths for such efforts.	point of view (computer hardware company)	E. William Cowell;Jeffrey H. Reed	2017	Proceedings of the IEEE	10.1109/JPROC.2017.2706598	prime directive;mindset;request for proposal;intellectual property;commercialization;public relations;funding mechanism;political science;government	Visualization	-74.95585304602196	2.854875741009629	1527
051a6cd4f5064997aaa7b5928dfd42c71711dfb7	historical data as an explicit component of land information systems	spatial information system;temporal data;spatial distribution;unit of analysis;case management;data quality;historical data;land information system	Abstract A variety of geographical and land information systems is increasingly employed to manage and analyse spatial distributions and attributes. However, common to many applications are temporal as well as spatial considerations; data are time- as well as space-specific. Current spatial information systems acknowledge temporal data but neglect to make explicit use of them for historical analysis even though organizations using these systems routinely require this for a variety of procedures for decision making and for the evaluation of data quality. Historical information is examined in the context of three prototype land information systems. Though the primary focus of these systems varies, common themes and problems are discussed. In each case, managing historical information is complicated by changes in the spatial units of analysis as well as in the attributes associated with those units. Several important issues that follow from the historical aspect of land data are identified and categorized in...	land information system	Ric Vrana	1989	International Journal of Geographical Information Science	10.1080/02693798908941494	data quality;geography;computer science;knowledge management;data mining;database;management science;temporal database;information quality;land information system;unit of analysis	HPC	-36.835750125008346	-2.7857124970241447	1530
d381b2dd9c0b7cb2252b170a34cc79a85b1f416b	interactive sensor visualization module for smart manufacturing system				Pradipta Biswas;Swarnaba Roy;Gowdham Prabhakar;J. Rajesh;Somnath Arjun;Manish Arora;B. Gurumoorthy;Amaresh Chakrabarti	2017		10.14236/ewic/HCI2017.99	human–computer interaction;visualization;computer science	Robotics	-49.89311307380085	-32.83784925153442	1533
5e060d13a80b456ba440b3c9d5391e8cedba7740	visual exploration of latent ranking evolutions in time series	time-series;ranking;rank changes;temporal evolutions	Rankings are everywhere in the world and they change constantly. Detecting and analyzing ranking changes in a ranked list is of great importance for recommendation and information retrieval tasks. Common to existing approaches is that the latent correlations and trends of ranked lists are not taken into account. This paper introduces RankEvo, an integration of rank structuring and visualization techniques, for detecting and analyzing latent evolutions in ranking time series. We characterize the ranking changes by computing the similarities among the time series of ranked items and organizing similar items into itemsets, and further forming ranking evolutions. The integrated RankEvo system provides visualization and intuitive interactions for exploring correlated itemsets, concurrent ranking evolutions, as well as outlier items of ranked lists. The system also employs additional information windows on demand for evolution elaboration and verification. Case studies are conducted to demonstrate the effectiveness and usability of the RankEvo system in assisting users to understand ranking changes.	algorithm;cluster analysis;computation;information retrieval;interaction;latent semantic analysis;level of detail;microsoft windows;organizing (structure);sensor;time series;usability	Hui Lei;Jing Xia;Fangzhou Guo;Yaoyao Zou;Wei Chen;Zhen Liu	2016	J. Visualization	10.1007/s12650-016-0349-7	econometrics;machine learning;pattern recognition	Web+IR	-25.804066258007055	-34.092031242168865	1536
134d82398f646d22a633a4ff4f9ea6a215eafbf3	annotation and analysis of extractive summaries for the kyutech corpus		Summarization of multi-party conversation is one of the important tasks in natural language processing. For conversation summarization tasks, corpora have an important role to analyze characteristics of conversations and to construct a method for summary generation. We are developing a freely available Japanese conversation corpus for a decision-making task. We call it the Kyutech corpus. The current version of the Kyutech corpus contains topic tags of each utterance and reference summaries of each conversation. In this paper, we explain an annotation task of extractive summaries. In the annotation task, we annotate an importance tag for each utterance and link utterances with sentences in reference summaries that already exist in the Kyutech corpus. By using the annotated extractive summaries, we can evaluate extractive summarization methods on the Kyutech corpus. In the experiment, we compare some methods based on machine learning techniques with some features.	automatic summarization;british national corpus;image scaling;machine learning;natural language processing;reference implementation;text corpus	Takashi Yamamura;Kazutaka Shimada	2018			natural language processing;artificial intelligence;computer science;annotation	NLP	-24.88632489065059	-69.90118487917758	1547
f9f63a585a28ffd00e1f4d46eac8ce940e450895	johns hopkins or johnny-hopkins: classifying individuals versus organizations on twitter		Twitter accounts include a range of different types of users. While many individuals use Twitter, organizations also have Twitter accounts. Identifying opinions and trends from Twitter requires the accurate differentiation of these two groups. Previous work (McCorriston et al., 2015) presented a method for determining if an account was an individual or organization based on account profile and a collection of tweets. We present a method that relies solely on the account profile, allowing for the classification of individuals versus organizations based on a single tweet. Our method obtains accuracies comparable to methods that rely on much more information by leveraging two improvements: a character-based convolutional neural network, and an automatically-derived corpus an order of magnitude larger than the previously available dataset. We make both the dataset and the resulting tool available1.	artificial neural network;convolutional neural network;short circuit;text-based (computing)	Zach Wood-Doughty;Praateek Mahajan;Mark Dredze	2018				NLP	-20.200274218129966	-68.04024930819286	1548
719c983af00217c02448cad320044b51062e1633	rethinking network connectivity in rural communities in cameroon		To bridge the digital divide between the urban and rural regions, the government of Cameroon has launched the Multipurpose Community Telecentres (MCT). But this project does not seems to sustain the local development. The aim of this study is threefold: to determine the ICT penetration in rural Cameroon and Internet adoption; to evaluate the impact of MCTs in rural region and to provide some recommendations for both the network planning and the development of suitable services. The study considers two rural communities in Cameroon. The results show that despite low incomes, and MCTs that are missing their goal, there is some readiness of local populations to welcome ICT projects in order to improve their daily life and activities. To design sustainable ICT projects for those regions, we provide some recommendations from network design to business strategy.	internet;mobile data terminal;network planning and design;population;strategic management;telecentre	Jean Louis Fendji Kedieng Ebongue	2015	CoRR		environmental resource management;economic growth	HCI	-80.34826098817312	-8.537541006664064	1550
31a4c38eb3a1eae1910b035dbb1e8a651575c9ac	multi-contextuality in boundary-spanning practices	multi contextuality;hd industries land use labor;sensor technology;t technology general;social sciences;boundary spanning;hf commerce;ubiquitous computing environments;innovation;samhallsvetenskap;work practice	The capability to establish boundary spanning practices within and across organizations has for long been recognized as a key strategic resource. As organizations are becoming distributed and dynamic, they will be increasingly populated by multiple functional, geographical, hierarchical, and professional boundaries. The inherent complexity of such settings makes it difficult for organizations to leverage their boundary spanning practices. IT systems have been hailed as a critical enabler of boundary spanning. However, there is little knowledge on how organizations are affected by the introduction of different types of IT systems. Building on an interpretive case study of Swedish transport organizations, this paper explores consequences of sensor technology for boundary spanning. The paper contributes with an understanding of what co-existing use contexts mean for boundary spanning practices. A theoretical implication is that such multi-contextuality requires an integrative view on boundary spanning that combines insights from the organizational innovation and work practice literatures.	electrical engineering;embedded system;european conference on information systems;european journal of information systems;file spanning;it university;informatics;information systems journal;information science;information system;interaction;international federation for information processing;knowledge management;management information systems quarterly;population;situated;software deployment;stationary process;systems management;telematics;ubiquitous computing;websphere optimized local adapters	Rikard Lindgren;Magnus Andersson;Ola Henfridsson	2008	Inf. Syst. J.	10.1111/j.1365-2575.2007.00245.x	innovation;social science;economics;engineering;knowledge management;sensor;operations management;management science;management;boundary spanning	HCI	-76.13882837669713	-3.507473340356962	1552
ebcf80c7a664e86d6d047d75575824485f8930ac	capturing of information about knowledge document and learning resource usage		Definition A Learning Resource is a digital resource used for E-Learning.		Christoph Rensing	2009			data science;computer science;knowledge management	AI	-41.81887486746576	3.8797521476084276	1559
9a517c78754db4299b69aa4f7f6e962ec77a6101	immersive data grasping using the explore table	tangible user interface;interface design;critical reflection;user experience;natural user interface;inspiration;interaction design;physical materials;everyday life;cooperative work;embodied interaction	Accustomed to traditional user experiences with mouse and keyboard, designers are challenged to break free and find new and compelling approaches to interaction design for natural user interfaces. Tangible and embodied interaction works in parallel, is quick, and allows cooperative work. This exploration serves to inspire and provoke critical reflection on interaction design for natural user interfaces based on physical substances that are used in everyday life -- like eggs, soap bubbles, and magnets.	experience;interaction design;natural user interface;table (database)	Marius Brade;Dietrich Kammer;Mandy Keck;Rainer Groh	2010		10.1145/1935701.1935809	user interface design;user;user experience design;simulation;interactive systems engineering;human–computer interaction;engineering;multimedia;natural user interface;interactivity;user interface;interaction technique	HCI	-45.271349975558756	-39.252777428033085	1560
da25dc304ec9961660434952195df252e098a0af	treatment side effect prediction from online user-generated content.		With Health 2.0, patients and caregivers increasingly seek information regarding possible drug side effects during their medical treatments in online health communities. These are helpful platforms for non-professional medical opinions, yet pose risk of being unreliable in quality and insufficient in quantity to cover the wide range of potential drug reactions. Existing approaches which analyze such usergenerated content in online forums heavily rely on feature engineering of both documents and users, and often overlook the relationships between posts within a common discussion thread. Inspired by recent advancements, we propose a neural architecture that models the textual content of user-generated documents and user experiences in online communities to predict side effects during treatment. Experimental results show that our proposed architecture outperforms baseline models.	baseline (configuration management);conversation threading;downstream (software development);encoder;feature engineering;health 2.0;online community;side effect (computer science);user experience;user-generated content	Hoang Nguyen;Kazunari Sugiyama;Min-Yen Kan;Kishaloy Halder	2018			user-generated content;machine learning;artificial intelligence;multimedia;computer science;side effect	Web+IR	-19.71705329806213	-51.49364055975768	1562
19934658ff2ba2940e78256fbbef42a0218a1513	ocular vergence measurement in projected and collimated simulator displays	excentricite;ergonomia;eccentricity;etude experimentale;movimiento ocular;hombre;excentricidad;electrophysiology;ergonomie;percepcion;electrooculographie;simulator;ecran visualisation;pantalla visualizacion;simulador;eye movement;cognition;human;simulateur;cognicion;electrofisiologia;display screen;perception;mouvement oculaire;vision;electrophysiologie;estudio experimental;ergonomics;electrooculography;homme;electrooculografia	The purpose of this study was to investigate electrooculography (EOG) as a measurement of ocular vergence in both collimated and projected simulator environments. The task required participants to shift their gaze between a central fixation point and a target appearing at one of three eccentricities. EOG was effective in recording ocular vergence. The EOG results were similar between collimated and projected displays, except for differences in vergence changes during lateral movement of the eyes, and ocular excursions downward elicited a greater EOG response than the reverse upward movement. The computer-based technique of recording vergence was found to produce measurable traces from a majority of participants. The technique has potential for further development as a tool for measuring ocular vergence in virtual environments where methods that require the wearing of head-mounted apparatus to track ocular structures (e.g., the pupil), which cannot be worn at the same time as a flight or flight-simulator helmet, are unsuitable.	electrooculography;eye;flight simulator;lateral thinking;ocular hypotension;paraneoplastic syndromes, ocular;projections and predictions;pupil;simulation;simulators;tracing (software);vergence;virtual reality	Paul Morahan;James W. Meehan;John Patterson;Philip K. Hughes	1998	Human factors	10.1518/001872098779591359	psychology;cognitive psychology;vision;computer vision;electrophysiology;cognition;human factors and ergonomics;eccentricity;communication;perception;eye movement	HCI	-45.510497180409644	-54.793134407494875	1569
358bb69b6fd511b10e2c34788bb80080edcba78e	malachy eaton: evolutionary humanoid robotics		I had the joy of reading Malachy Eaton’s Evolutionary Humanoid Robotics. It sheds light at the intersection of evolutionary search and robotics, with a special focus on humanoid or human-like robots. It is a skill to hit the right spot between introducing newcomers to a concept while also informing researchers already in the field. Eaton manages to do just that by delivering a nice flowing, quick to read book (with its 151 pages). The reader is given an introduction of the relevant principles and ideas in evolutionary computing and its applications in robotics. I can recommend this book to starting graduate students in the fields of computer science and/or robotics, or researchers looking to get started with evolutionary robotics. With its focus on humanoid robots it might seem like a niche book but the discussion about current evolutionary approaches and their limitations has wider implications. Eaton asks questions that are interesting for the whole area of robotics not just humanoid robots. Such as ‘‘How can we close the reality gap?’’, that is, reduce the difference between simulated robots and real robots. And how can we create, i.e. program, learn or evolve, interesting behaviours for complex robots? And, a question also very important in my research, how can we perform evolution and/or learning on real robots safely? As a researcher in evolutionary humanoid robotics (EHR) I particularly liked these questions and how EHR can make a difference. The book also discusses the different approaches for evolving robotic ‘‘brains’’. I.e. evolving decision making or control systems for a robot, in contrast to evolving the robot’s body. It also explains different approaches for the evolutionary process	computer science;control system;evolutionary computation;evolutionary robotics;humanoid robot;niche blogging	Jürgen Leitner	2015	Genetic Programming and Evolvable Machines	10.1007/s10710-015-9256-2	simulation;artificial intelligence	Robotics	-58.42879754734275	-28.916694975849204	1572
2bc489cf09950261e24bd5a00d9bea78a744a3a6	gaze-enhanced speech recognition	speech recognition speech error analysis visualization noise acoustics interpolation;pointing speech recognition eye gaze;speech recognition mobile handsets;generic language model gaze enhanced speech recognition eye gaze data multimodal interfaces mobile phones tablets large vocabulary speech recognition system	This work demonstrates through simulations and experimental work the potential of eye-gaze data to improve speech-recognition results. Multimodal interfaces, where users see information on a display and use their voice to control an interaction, are of growing importance as mobile phones and tablets grow in popularity. We demonstrate an improvement in speech-recognition performance, as measured by word error rate, by rescoring the output from a large-vocabulary speech-recognition system. We use eye-gaze data as a spotlight and collect bigram word statistics near to where the user looks in time and space. We see a 25% relative reduction in the word-error rate over a generic language model, and approximately a 10% reduction in errors over a strong, page-specific baseline language model.	baseline (configuration management);bigram;dbpedia;language model;mobile phone;multimodal interaction;simulation;speech recognition;vocabulary;word error rate	Malcolm Slaney;Rahul Rajan;Andreas Stolcke;Partha Parthasarathy	2014	2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2014.6854198	voice activity detection;computer vision;speech recognition;word error rate;computer science;acoustic model;speech analytics	Visualization	-24.767190300862342	-87.57998750271021	1577
9304e274fb952ee6ceee4140228e71bbeb90ef26	neural machine transliteration: preliminary results		Machine transliteration is the process of automatically transforming the script of a word from a source language to a target language, while preserving pronunciation. Sequence to sequence learning has recently emerged as a new paradigm in supervised learning. In this paper a character-based encoder-decoder model has been proposed that consists of two Recurrent Neural Networks. The encoder is a Bidirectional recurrent neural network that encodes a sequence of symbols into a fixed-length vector representation, and the decoder generates the target sequence using an attention-based recurrent neural network. The encoder, the decoder and the attention mechanism are jointly trained to maximize the conditional probability of a target sequence given a source sequence. Our experiments on different datasets show that the proposed encoderdecoder model is able to achieve significantly higher transliteration quality over traditional statistical models.	artificial neural network;compiler;encoder;experiment;neural networks;programming paradigm;recurrent neural network;scripting language;statistical model;string (computer science);supervised learning;text-based (computing)	Amir Hossein Jadidinejad	2016	CoRR		natural language processing;speech recognition;computer science;artificial intelligence;machine learning;pattern recognition	NLP	-17.724632119024566	-74.73412705217949	1578
64324463cd40627fb5569c53af4a38451a596db7	critical success factors and outcomes of market knowledge management: a conceptual model and empirical evidence	financial performance;knowledge management;conceptual model;businesses;customer satisfaction;information technology adoption;empirical evidence;critical success factor;market knowledge management	In this paper, the authors examine critical success factors and outcomes of market knowledge management, which is the management of knowledge pertaining to a firm’s customers, competitors, and suppliers. Using data collected from 307 managers in 105 businesses across Canada, the authors show that a firm’s extent of information technology adoption, its analytical capabilities, and market orientation are critical success factors for the firm’s market knowledge management. An important outcome of market knowledge management is the organization’s financial performance, mediated by customer satisfaction and customer loyalty. Results of this study indicate that superior business performance depends not only on the effective management of knowledge, but also on what type of knowledge is managed. Finally, implications of results and avenues for future research are discussed.	knowledge management	Subramanian Sivaramakrishnan;Marjorie Delbaere;David Di Zhang;Edward R. Bruning	2010	IJKM	10.4018/jkm.2010070101	empirical evidence;economics;computer science;knowledge management;conceptual model;marketing;digital firm;customer satisfaction;critical success factor;knowledge value chain;management	AI	-81.82118357810148	3.3815469966719642	1584
c025472b4927512cb953a4bc7f8ef2ce5f96c51f	multiobjective e-commerce recommendations based on hypergraph ranking		Abstract Recommender systems are emerging in e-commerce as important promotion tools to assist customers to discover potentially interesting items. Currently, most of these are single-objective and search for items that fit the overall preference of a particular user. In real applications, such as restaurant recommendations, however, users often have multiple objectives such as group preferences and restaurant ambiance. This paper highlights the need for multi-objective recommendations and provides a solution using hypergraph ranking. A general User-Item-Attribute-Context data model is proposed to summarize different information resources and high-order relationships for the construction of a multipartite hypergraph. This study develops an improved balanced hypergraph ranking method to rank different types of objects in hypergraph data. An overall framework is then proposed as a guideline for the implementation of multi-objective recommender systems. Empirical experiments are conducted with the dataset from a review site Yelp.com, and the outcomes demonstrate that the proposed model performs very well for multi-objective recommendations. The experiments also demonstrate that this framework is still compatible for traditional single-objective recommendations and can improve accuracy significantly. In conclusion, the proposed multi-objective recommendation framework is able to handle complex and changing demands for e-commerce customers.	e-commerce	Mingsong Mao;Jie Lu;Jialin Han;Guangquan Zhang	2019	Inf. Sci.	10.1016/j.ins.2018.07.029	artificial intelligence;recommender system;machine learning;e-commerce;hypergraph;data model;mathematics;guideline;ranking	AI	-21.918672810451866	-47.28725891922954	1589
93f552cf3d60176365ecf861dea238c0b045e0b6	a history of the teragrid science gateway program: a personal view	portals;science gateways;path finding;computational science;requirement analysis;lessons learned;middleware	This paper describes the NSF TeraGrid Science Gateways program, its formation, progress, lessons learned and current contributions over its seven-year life and new directions in the NSF XSEDE program. Early requirements analysis work with path-finding gateways that formed the underpinning of the program are described as are current projects and their unique contributions to the larger program. Future directions both within the XSEDE program and for gateways more generally are discussed.	ibm notes;requirement;requirements analysis;teragrid	Nancy Wilkins-Diehr	2011		10.1145/2110486.2110488	requirements analysis;computer science;pathfinding;operating system;middleware;world wide web	SE	-60.85166180128507	-16.261090337637146	1593
7631c06213e31f83dcd01b9872df3a050e5da4f1	building a formal grammar for a polysynthetic language	language specific;lexical-functional grammar;nlp resource;abstract linguistic representation;polysynthetic language;well-researched western language;formal grammar;formal description;lfg framework;nlp task;computational linguistics;amerindian language	We present the results of a project of building a lexical-functional grammar of Aymara, an Amerindian language. There was almost no research on Aymara in computational linguistics to date. The goal of the project is twofold: First, we want to provide a formal description of the language. Second, NLP resources (lexicon and grammar) are being developed that could be used in machine translation and other NLP tasks. The paper presents formal description of selected properties of Aymara which are uncommon in well-researched Western languages. Furthermore, we present an abstract linguistic representation in the LFG framework which is less language specific than f-structures.		Petr Homola	2011		10.1007/978-3-642-32024-8_15	grammar systems theory;natural language processing;object language;regular grammar;computer science;affix grammar;emergent grammar;linguistics;formal grammar;natural language;attribute grammar;communication	NLP	-29.456786293618432	-76.17104352570558	1597
66207b8551629bff93a89d6807b7d278fea2edd7	a demonstration of vrspinning: exploring the design space of a 1d rotation platform to increase the perception of self-motion in vr		In this demonstration we introduce VRSpinning, a seated locomotion approach based around stimulating the user's vestibular system using a rotational impulse to induce the perception of linear self-motion. Currently, most approaches for locomotion in VR use either concepts like teleportation for traveling longer distances or present a virtual motion that creates a visual-vestibular conflict, which is assumed to cause simulator sickness. With our platform we evaluated two designs for using the rotation of a motorized swivel chair to alleviate this, wiggle and impulse. Our evaluation showed that impulse, using short rotation bursts matched with the visual acceleration, can significantly reduce simulator sickness and increase the perception of self-motion compared to no physical motion.	simulation;wiggle stereoscopy	Thomas Dreja;Michael Rietzler;Teresa Hirzle;Jan Gugenheimer;Julian Frommel;Enrico Rukzio	2018		10.1145/3266037.3271645	simulation;acceleration;human–computer interaction;vestibular system;impulse (physics);simulator sickness;virtual reality;teleportation;perception;computer science	HCI	-45.135780544657216	-48.780509769699165	1610
538555d786a9fa22eb47476a27ba3273606dd7d2	curriculum and course syllabi for a high-school cs program	high school;ministry of education	The authors served on a committee that designed a high-school curriculum in computer science and has been supervising the preparation of a comprehensive study program based on it. The new program is intended for the Israeli high-school system, has been formally approved by the Ministry of Education, and is expected to fully replace the old one in the near future. The program emphasizes the foundations of algorithmics, and teaches programming as a way to get the computer to carry out an algorithm. The purpose of this paper is to describe the program's curriculum and syllabi in detail.		Judith Gal-Ezer;David Harel	1999	Computer Science Education	10.1076/csed.9.2.114.3807	mathematics education;computer science;engineering;software engineering;pedagogy	Theory	-80.4926840568908	-33.79108234790339	1620
865d5bcd93b50934a1539958b4bc7c5c2b35d582	knowledge management governance: the road to continuous benefits realization	information management system;information systems security;mis systems;information systems research;journal of it;jit;teaching cases;information security;case studies;information science;information security systems;information technology;business information technology;security information systems;it journals;information systems management;it teaching cases;operational research society;business model;journal of information technology teaching cases;computer information systems;jit journal;geographic information systems;information technology journal;information management;information systems journals;information systems technology;managing information systems;accounting information systems;information and management;management information systems;define information systems;strategic information systems;business information management;soft system methodology;information system;health information systems;computer information technology;journal of information technology;business information systems;business systems analyst;journal information technology;it journal;management science;journal of information systems;information technology journals	Investment in knowledge management (KM) programmes is often contentious due to the challenge of meeting the need for continuous and sustainable benefits realization. In KM, the word ‘sustainable’ describes how programmes of strategies to leverage organizational knowledge remain productive over time: that they deliver strategic value to the organization. The focus of this paper falls on the constructs of the governance of KM and on its leadership, in KM strategy development and implementation, including risk management, financial controls and transparent evaluation mechanisms for continuous benefits realization. This paper presents a KM governance model and explores its recent validation through six case studies of large, distributed, multinational organizations, and through these introduces the granular constructs of KM governance. Exploration of the impact of KM governance on developing and implementing KM programmes in each case study organization demonstrates that there is a clear nexus between strategic KM governance and benefits realized from those programmes.	knowledge management	Suzanne Zyngier;Frada Burstein	2012	JIT	10.1057/jit.2011.31	public relations;computer science;engineering;knowledge management;electrical engineering;management information systems;management science;information technology;information system	DB	-71.44927601914978	1.442263214107476	1623
14c47cef417620619e3e3c0d02b3a341c3d2a195	satisfaction attainment theory as a model for value creation	it professional;intellectual capital;goal assessment;shift in the yield assessment sya;information systems knowledge management educational institutions technology management management information systems information analysis information science context aware services economic indicators costs;satisfaction attainment theory sat;customer satisfaction;yield assessment;value creation;information system;affective response;causal models;organisational aspects customer satisfaction;yield assessment shift satisfaction attainment theory causal model organizational stakeholder salient goal set;organisational aspects	Organizations exist to create value for their stakeholders that stakeholders cannot create through individual effort. Information systems exist to increase an organization's ability to create value using intellectual capital. A theoretical explanation of value might therefore be useful to increase the likelihood that IS/IT professionals would design and deploy systems in ways that increase value for stakeholders. This paper proposes satisfaction attainment theory (SAT) as causal model of value creation. An organizational stakeholder is a person whose wellbeing might be advanced by an organization. Perceptions of value have reference to some object-of-value. The term, object, in the context of this paper, means anything to which one could ascribe value - e.g. goods, services, states, or outcomes. SAT assumes that people hold multiple, conflicting goals, and so must sacrifice the yield of some goal to attain others. It posits that an individual automatically and subconsciously sets an expectation for some level of utility from attaining a goal and assesses the likelihood that a goal is attained. It also posits that individuals automatically and subconsciously assess yield the yield of a set of salient goals (SSG). Any perceived shift in the yield assessment (SYA) for the salient set of goals is automatically accompanied by an affective arousal proportional to and with a valence in the direction of the perceived SYA. SAT proposes that the value of an object is a positive function of the SYA that occurs when an individual contemplates sacrificing the yield of other goals to obtain the yield that could be derived from the object. Value is therefore created by making an individual aware of an opportunity to attain a positive SYA by sacrificing the yield of one set of goals to attain the yield of another set.	causal model;information system;symbolic stream generator	Robert O. Briggs;Sajda Qureshi;Bruce A. Reinig	2004	37th Annual Hawaii International Conference on System Sciences, 2004. Proceedings of the	10.1109/HICSS.2004.1265063	knowledge management;marketing;management science;customer satisfaction;management;information technology;information system;causal model	HCI	-86.29465229206436	0.9570401455096937	1625
135a567b908ee38b4f3218ef76384f8cb6ad542a	inferring the size of the causal universe: features and fusion of causal attribution networks		Cause-and-effect reasoning, the attribution of effects to causes, is one of the most powerful and unique skills humans possess. Multiple surveys are mapping out causal attributions as networks, but it is unclear how well these efforts can be combined. Further, the total size of the collective causal attribution network held by humans is currently unknown, making it challenging to assess the progress of these surveys. Here we study three causal attribution networks to determine how well they can be combined into a single network. Combining these networks requires dealing with ambiguous nodes, as nodes represent written descriptions of causes and effects and different descriptions may exist for the same concept. We introduce NetFUSES, a method for combining networks with ambiguous nodes. Crucially, treating the different causal attributions networks as independent samples allows us to use their overlap to estimate the total size of the collective causal attribution network. We find that existing surveys capture 5.77% ± 0.781% of the ≈293 000 causes and effects estimated to exist, and 0.198% ± 0.174% of the ≈10 200 000 attributed cause-effect relationships. Keywords— causality; knowledge graphs; graph alignment; natural language processing; word embeddings; capturerecapture estimators Causality and causal reasoning are central questions of statistics, computer science, philosophy, and the cognitive sciences [1, 2, 3, 4]. Recently, our understanding of causality has been revolutionized by new insights and large volumes of data [5, 6]. Large-scale data collection and surveys of large numbers of individuals are now possible at an unprecedented scale. One class of new data enabled by the internet is very large-scale knowledge graphs, annotated semantic networks codifying large numbers of factual statements, events, and interrelationships between concepts [7, 8, 9]. Knowledge graphs allow generalization to new relationships using graph algorithms, and these algorithms have been applied to causal predictions [10]. In this work we study causal relationships encoded into networks. Nodes in these networks represent causes and effects, and directed links indicate cause-effect relationships. Generally, these relationships are gathered by large1 ar X iv :1 81 2. 06 03 8v 1 [ cs .S I] 1 4 D ec 2 01 8 Cause of anxiety Effect of anxiety Other Wikidata IPRnet ConceptNet Figure 1: Causes and effects around ‘anxiety,’ a term common to all three networks studied here. This example illustrates similarities and differences of these networks, in particular the sparse, treelike structure of Wikidata and ConceptNet compared with the denser interlinking present in IPRnet. scale surveying of individuals, often as part of larger efforts to build general-purpose semantic networks [11, 12], although dedicated experiments have also been conducted [13]. As these relationships are contributed by individuals or groups of individuals, we refer to these networks as causal attribution networks. Attribution theory, the study of how individuals perceive causality and attribute causes to effects, has long explored the cognitive biases that affect causal attribution [14, 15, 16]. We study causal attribution networks extracted from three sources, the collaboratively constructed knowledge graph “Wikidata”, the long-running project “ConceptNet,” and “IPRnet,” a network built by members of a crowdsourcing platform to test a network data collection method called “Iterative Pathway Refinement” [13]. Figure 1 shows examples from all three networks, centered on “anxiety” a term common to all three. Wikidata and ConceptNet encode other relationships, but we focus on causal relationships. All three networks represent different efforts to explore the larger causal attribution network, and our goal is to understand similarities and difference between these networks, and whether or not they can be fruitfully combined into a single, larger network. A key challenge when combining these data is resolving ambiguity between entities or concepts: most causes and effects in these networks are originally identified only by short written descriptions, and it is possible to describe the same entity in many different ways. Yet, overcoming this challenge to fuse multiple causal attribution networks together brings multiple benefits: it provides a common network dataset for researchers to study causality and attribution, and by measuring the overlap of different network samples we can estimate the size of the single underlying, incompletely observed causal attribution network. The rest of this paper is organized as follows. Section 1 describes the data collection and network and text analysis procedures, introduces a method called NetFUSES for fusing graphs with potentially ambiguous node identities, and		Daniel Berenberg;James P. Bagrow	2018	CoRR			ML	-21.473027563431742	-42.91394518364428	1631
c7aaee604a2cfbb5d017d6e7d1c4ea9e37022692	an environment for a virtual hypermedia factory	european commission;cultural heritage;information technology;production facilities cultural differences information systems councils computer science cybernetics information technology multimedia systems publishing web and internet services;multimedia systems;hypermedia;internet hypermedia humanities travel industry;internet;humanities;information system;national research council;travel industry;information providers virtual hypermedia factory national research council cybernetics institute cultural heritage european commission tourism publishing internet	"""The Advanced Information System group of the National Research Council (CNR) Computer Science Department at the Cybernetics Institute has become involved in research concerning hypermedia systems in the field of cultural heritage. This activity takes place within the three-year project """"An Environment for a Virtual Hypermedia Factory"""" (VHF). The European Commission funded the project within the 4th RTD Framework, Information Technologies (Multimedia Systems domain). The project aims mainly to develop an integrated environment equipped with services and applications for producing, archiving, and spreading information about cultural heritage, tourism, and publishing through the Internet. This environment encourages content integration by stimulating cooperation among information providers in different but correlated knowledge domains. The paper discusses the Virtual Hypermedia Factory consortium and platform requirements."""	hypermedia	Claudia Di Napoli;Mario Mango Furnari	1999	IEEE MultiMedia	10.1109/93.771376	the internet;human–computer interaction;computer science;knowledge management;cultural heritage;multimedia;tourism;law;information technology;world wide web;information system	Visualization	-70.37327627051981	-27.835600059660507	1632
b40acd18ecc1541e25039e771d12daf16d0a35d4	irrigation water demand forecasting - a data pre-processing and data mining approach based on spatio-temporal data		URLs: Irrigation Water Demand Forecasting A Data Pre-processing and Data Mining Approach Based on Spatiotemporal Data Author(s): Hafeez, M.M. ; Islam, M. ; Khan, M.A. Australasian Data Mining Conference (AusDM) 2011 1-2 December, 2011 Vamplew, P., Stranieri, A., Ong, K.-L., Christen, P. and Kennedy, P. J. 183 194 World population is increasing at a fast rate resulting in huge pressure on limited water resources. Just about 3% of the earth¿s total water is freshwater that can be used for various applications including irrigation. Therefore, an efficient irrigation water management is crucial for the survival of human being. In our study area farmers need to order water based on their requirements. Once a request for water is made it typically takes about 7 days to get it at the farm gate from the upstream ... Location: Ballarat, Australia http://researchoutput.csu.edu.au/R/-?func=dbin-jump-full&object_id=31008&local_base=GEN01-CSU01 PL: FT: Publisher: Australian Computer Society Place of Publication: Sydney, Australia Irrigation Water Demand Forecasting – A Data Pre-Processing and Data Mining Approach based on Spatio-Temporal Data. Mahmood A. Khan 1 , Md. Zahidul Islam 2, 3 , Mohsin Hafeez 1 1 International Centre of Water for Food Security, Charles Sturt University, Wagga Wagga 2678, NSW, Australia 2 School of Computing and Mathematics, Charles Sturt University, Wagga Wagga 2678, NSW, Australia 3 Centre for Research in Complex Systems (CRiCS), Charles Sturt University, Bathurst 2795, NSW, Australia makhan@csu.edu.au, zislam@csu.edu.au, mhafeez@csu.edu.au	data mining;data pre-processing;decision support system;decision tree;freshwater ecosystem;irrigation informatics;pattern recognition;preprocessor;requirement;upstream (software development)	Mahmood A. Khan;Md Zahidul Islam;Mohsin Hafeez	2011				AI	-44.5837893220881	-10.521602758262878	1639
e1ddbe92a396d1ae9cd3ae2116213855b871f761	smarter planet: empower people with information insights	spectrum;decision maker;information integration	We are all now connected economically, technically and socially. Our planet is becoming smarter. Infusing intelligence into the way the world literally works the systems and processes that enable physical goods to be developed, manufactured, bought and sold services to be delivered everything from people and money to oil, water and electrons to move and billions of people to work and live. All these become possible via information integration scattering in many different data sources: from the sensors, on the web, in our personal devices, in documents and in databases, or hidden within application programs. Information is exploding with large amount of data generated every second. It creates many challenges in securely storing, managing, integrating, cleansing, analyzing and governing the massive generated information besides the privacy issue. This can be a difficult or time consuming endeavor. This talk describes some information-intensive tasks, choosing examples from such areas as healthcare, science, the business world and our personal lives. I will discuss the barriers to getting information together, delivering it to the people that need it, in a form they can understand, analyzing the diverse spectrum of information, giving insights to the decision makers. I will review key research on information integration and information interaction, indicate how the combination may enable real progress, and illustrate where research challenges remain.		Josephine M. Cheng	2011		10.1007/978-3-642-20149-3_1	spectrum;decision-making;computer science;knowledge management;information integration;data mining;database;management science	HCI	-37.751447628797365	-8.316549462344502	1646
1fd4b2db3d0c9c9f89ea0e3627ab07d2a9df9395	on using multi-agent systems in playing board games	computer program;multiagent system;multi agent system;multiagent system architecture;diplomacy;area of interest;risk;datavetenskap datalogi;computer science;board games;computer game	Computer programs able to play different kinds of games (aka bots) is a growing area of interest for the computer game industry as the demand for better skilled computerized opponents increase. We propose a general architecture of a Multi-agent System (Mas) based bot able to play complex board games and show that this solution is able to outperform other bots in two quite different games, namely no-press Diplomacy and Risk. Based on these results, we formulate a hypothesis of the applicability of Mas based bots in the domain of board games and identify the need for future investigations in the area.	multi-agent system;pc game	Stefan J. Johansson	2006		10.1145/1160633.1160737	video game design;simulation;turns, rounds and time-keeping systems in games;computer science;artificial intelligence;emergent gameplay;game mechanics;multi-agent system;risk;multimedia;diplomacy	AI	-24.354519298279573	-21.326134575625066	1656
81c682c770e09f166a7e669d479fd6686b1f5071	engineering positive organizational behavior and managing the psychological capital for learning effectiveness	social intelligence;learning effectiveness;emotional intelligence;organizational effectiveness;learning outcome;effective learning outcomes;online course outcomes;psychology educational courses engineering education;psychology;psychology lead organizations resilience cities and towns conferences meteorology;leadership development;resilience;lead;online course outcomes effective learning outcomes effective teaching methods;online courses;psychological ownership questionnaire engineering positive organizational behavior psychological capital learning effectiveness social intelligence emotional intelligence organizational development organizational effectiveness psychological ownership engineering classroom setting organizational behavior course authentic leadership questionnaire psychological capital questionnaire;educational courses;engineering education;cities and towns;organizations;organizational behavior;meteorology;teaching methods;effective teaching methods;organizational development;conferences	Social Intelligence has been a living concept for quite some time as an offshoot of Emotional Intelligence and has been used in engineering. Its usefulness in individual context has found several applications in developing individual effectiveness. Several researchers have expanded the concept to organizational development, and organizational effectiveness using modern concepts of Positive Organizational Behavior (POB). The POB has been derived from Psychological Capital and Psychological Ownership. These have been useful for implementing organizational development. POB and Social Intelligence studies in engineering classroom setting are important to today's engineering leadership development. This paper examines the intended outcomes of an Organizational Behavior (OB) course in shaping Positive Organizational Behavior (POB) using different tools — Authentic Leadership Questionnaire (ALQ), Psychological Capital Questionnaire (PCQ), Psychological Ownership Questionnaire (POQ), which were administered as pre and post semester basis. An analysis of result has been provided that can be directly attributed to the effects of carefully designed interventions in the course.	organizational behavior;traffic shaping	Hamid Khan	2011	2011 Frontiers in Education Conference (FIE)	10.1109/FIE.2011.6142726	organizational engineering;organizational commitment;lead;organizational performance;organizational learning;engineering education;organizational behavior and human resources;emotional intelligence;organization;knowledge management;teaching method;organizational effectiveness;social intelligence;management;pedagogy;organizational behavior	AI	-76.7461715481625	-39.85546515682676	1661
75709b388df993c5f26c64d969c33850e54669a5	knowledge-rich contexts extraction from comparable corpora (identification de contextes riches en connaissances en corpus comparable) [in french]			text corpus	Firas Hmida	2014			artificial intelligence;communication;algorithm	NLP	-27.47389966996261	-76.87569659105756	1662
723d33fcdbc1a4adbf710a4d465e06282f03483a	a community-based web browsing system	information resources;search engine;information retrieval;interactive visualization;search engines visualization web pages world wide web web page design space exploration database systems laboratories data engineering explosives;online front ends;data visualisation;internet community based web browsing system web browsers web sites page oriented search engines interactive visualization system user test world wide web;internet;user testing;data visualisation online front ends internet information resources information retrieval;web browsing	Current forms of web browsers do not adequately reflect the current situation of explosive increase of web space. The user is still forced lo access the web spoce page by page. In this paper we pmpose a web browsing method based on communities. A communiQ is a collection ofweb sires which are related each other Unlike the conventional page-oriented search engines/browsers. the proposed inferactive visualization system enables the user IO see not only the related web sites but also communities in exploring the ever growing web space, This helps him/her lo grasp an overall slrucfure of (he target space. Results o f a user &SI shows that the system is powerful and useful,	browsing;web hosting service;web search engine	Daisuke Toyama;Masumi Kakimoto;Atsuo Yoshitaka;Masahito Hirakawa	2001		10.1109/HCC.2001.995280	web service;web application security;static web page;web development;web modeling;data web;web analytics;web mapping;web-based simulation;web design;web search engine;web accessibility initiative;web standards;computer science;web navigation;web page;multimedia;web intelligence;web 2.0;world wide web;information retrieval;web server	Web+IR	-42.88880477424882	-25.344924622735498	1663
c069c8bd3683fe271c74475fed0b91e6235729ac	ihs_rd: lexical normalization for english tweets		This paper describes the Twitter lexical normalization system submitted by IHS R&D Belarus team for the ACL 2015 workshop on noisy user-generated text. The proposed system consists of two components: a CRFbased approach to identify possible normalization candidates, and a post-processing step in an attempt to normalize words that do not have normalization variants in the lexicon. Evaluation on the test data set showed that our unconstrained system achieved the Fmeasure of 0.8272 (rank 1 out of 5 submissions for the unconstrained mode, rank 2 out of all 11 submissions).	conditional random field;lexicon;test data;user-generated content;video post-processing	Dmitry Supranovich;Viachaslau Patsepnia	2015		10.18653/v1/W15-4311	normalization (statistics);lexicon;test data;pattern recognition;artificial intelligence;computer science	NLP	-22.91280014088291	-70.26478298308037	1680
eabc95827ae258757a8c261b2a2fbaee69bca1f9	computational investigation of early child language acquisition using multimodal neural networks: a review of three models	neural network control;technology;computer model;computer modelling;cognitive process;language acquisition;control system;science technology;artificial intelligence;child language acquisition;computer science;neural network model;computational model;native language;neural network	Current opinion suggests that language is a cognitive process in which different modalities such as perceptual entities, communicative intentions and speech are inextricably linked. As such, the process of child language acquisition is one in which the child learns to decipher this inextricability and to acquire language capabilities starting from gesturing, followed by language dominated by single word utterances, through to full-blown native language capability. In this paper I review three multimodal neural network models of early child language acquisition. Using these models, I show how computational modelling, in conjunction with the availability of empirical data, can contribute towards our understanding of child language acquisition. I conclude this paper by proposing a control theoretic approach towards modelling child language acquisition using neural networks.	artificial neural network;cognition;computation;entity;multimodal interaction;theory	Abel Nyamapfene	2009	Artificial Intelligence Review	10.1007/s10462-009-9125-6	language acquisition;natural language processing;universal networking language;computer science;artificial intelligence;computational linguistics;machine learning;linguistics;modeling language;language technology;computational model;artificial neural network;technology	NLP	-26.12039822588585	-15.73329760353635	1682
575c2be68c5cb8b3af1cc16c5e43a71a68a86039	the design of i-mass as a tool for interacting with cultural heritage	usability evaluation;agent based;cultural heritage;semantic interoperability;requirement analysis	"""This paper gives an overview of the I-Mass system, an application to interact with digital cultural heritage information by way of metadata descriptions, irrespective of the specific storage and access characteristics such as format, location, and language. The paper describes the approach used to solve the so-called problem of """"interoperability of content"""" - or the resolution of syntactic and semantic interoperability, respectively. It further describes the workings of I-Mass guided by the agent-based architecture and the requirements analysis and usability evaluation involved, and presents some first results."""	interaction	Geert de Haan	2003		10.1145/963600.963682	semantic interoperability;engineering;knowledge management;multimedia;world wide web	Logic	-40.503556460708275	-26.578934974426375	1688
76accfded0e528c48c7f3fb064e8028fffe85029	adroit: automatic discourse relation organizer of internet-based text	adroit system;elementary segment;discourse relation;automatic discourse relation organizer;cue-phrase disambiguation;rhetorical structure theory;information rich natural language;present version;internet-based text;noble technique;automatic discourse analysis	The ADROIT system that we are developing allows automatic discourse analysis of information rich natural language texts extracted directly from the web. We use guidelines and relations of Rhetorical Structure Theory (RST) to decompose texts into elementary segments and to perform the discourse parsing between them. In this paper, we present version 1.0 of ADROIT and focus on the noble technique of cue-phrase disambiguation and machine learning for identification and organization of discourse relations.	discourse relation;image organizer;intel matrix raid;machine learning;natural language;parsing;word-sense disambiguation	A. S. M. Mahbub Morshed;Mitsuru Ishizuka	2008			natural language processing;computer science	NLP	-29.62389427344576	-76.83247095243124	1693
a4527e789313eddb70cbe9cb8f2f0ea145199c1a	panel 1 competing reference disciplwes for mis research				Haim Mendelson	1987			knowledge management;computer science;marketing	Theory	-70.40988139211983	-0.791937005484818	1697
628adad42391b8e22886b114638d676c1f72a161	guest editorial: special issue on emerging trends in education - part ii		The first eight papers accepted for the Special Issue on “Emerging Trends in Education” were published previously [1]. Here, we introduces the remaining eight papers, which cover quite a varied set of topics, encompassing online education, adaptive learning, student modeling and analytics, as well as gamification. For example, in “FORGE toolkit: leveraging distributed systems in eLearning platforms” Guillaume Jourjon et al. explore technologies supporting online education. The focus is on the creation of a distributed architecture meant to support large-scale laboratory activities by leveraging experimentation facilities deployed in international initiatives for the development of e-learning resources. In particular, the authors present the design of an ecosystem based on configurable widgets that can be exploited in the e-book authoring process to enable the integration of tools designed for producing teaching and educational materials with services offered by experimentation facilities. The authors tested the proposed framework in the context of network and communication courses offered by both academic and industrial institutions worldwide. In “Tutorials in eLearning: How presentation affects outcomes”, Leana Copeland and Tom Gedeon present a possible application of an emerging human-computer interaction technology like eye tracking in the context of education. More specifically, their goal is to study how different sequences of text and test questions could influence performance in terms of understanding and, ultimately, of learning effectiveness for English language readers. According to the authors, results obtained could be exploited to guide the design of learning materials capable to adapt to users’ behavior. In “Open student models of core competencies at the curriculum level: Using learning analytics for student reflection” Chih-Yueh Chou et al. analyzed the quantity and quality of courses and associated grades to estimate the proficiency level of core competences. Course-competency diagnostic tools, course work performance radar charts and peer-based ranking tables are proposed as a means to enable student reflection by promoting awareness, selfassessment, learning autonomy, planning and positive group interactions. In “Identifying at-risk students for early interventions: A time-series clustering approach” by Jui-Long Hung et al., the authors apply a clustering approach over disaggregated time series data from the logs of a LMS regarding frequency of course material access, frequency of forum reads, number of discussions posted, number of replies posted, demographic information, and student grades to generate more accurate predictions about at-risk students. Experimental results demonstrate that, compared to alternative methods working on aggregate data, the proposed approach supports earlier detection, which allows online instructors to develop suitable interventions via course design or student-teacher interactions. In “Similarity-based grouping to support teachers on collaborative activities in exploratory learning environments” by Sergio Gutierrez-Santosa et al., the focus is shifted primarily on teachers. The authors propose a tool that is meant to help teachers to cope with pragmatic and logistic constraints that are typical of collaborative learning scenarios in a physical class context. The tool supports the formation of groups capable of enacting a profitable learning experience where students engage in productive discussions and reflect on their approaches to a given problem by justifying and critiquing proposed solutions. The designed tool has been tested with young students working with a mathematical learning system designed to develop their algebraic ways of thinking by identifying relationships in figural patterns. The tool first compares approaches towards the solution, in order to identify complementary students. Then, it forms pairs of students by using a heuristic aimed to minimize similarity between approaches for the whole class. Experimental tests showed that the proposed approach can reduce the time needed for performing the allocation, by producing groups that are in line with teachers’ own expectation of good pairing. Related to the topic of group formation, is the relationship between group structure and educational effectiveness. This is explored in “Relation between combination of personal characteristic types and educational effectiveness for controlled project-based learning” by Yusuke Sunaga et al., where a study of the impact of students’ personalities on the knowledge and skills acquired when working on a learning Digital Object Identifier 10.1109/TETC.2017.2667298	aggregate data;cluster analysis;distributed computing;e-book;ecosystem;eye tracking;forge;gamification;heuristic;human–computer interaction;identifier;radar chart;tom;time series	Phillip A. Laplante;Claudio Giovanni Demartini;Fabrizio Lamberti;Colin J. Neill	2017	IEEE Trans. Emerging Topics Comput.	10.1109/TETC.2017.2667298		HCI	-73.36080981316745	-38.95879588397261	1702
6259937b26dbbf0ad93272469705f4f59fd5e1fd	netzmanagement in heterogenen lokalen netzen.				Georg Rößler;Werner Schollenberger	1991	Praxis der Informationsverarbeitung und Kommunikation		computer network;computer science;distributed computing	NLP	-40.688364509411386	-14.136757536250558	1706
a16af208c23f1115a5794aa9c03e2e80695d4cdb	capturing cognitive causal paths in human reliability analysis with bayesian network models		reIn the last decade, Bayesian networks (BNs) have been identified as a powerful tool for human reliability analysis (HRA), with multiple advantages over traditional HRA methods. In this paper we illustrate how BNs can be used to include additional, qualitative causal paths to provide traceability. The proposed framework provides the foundation to resolve several needs frequently expressed by the HRA community. First, the developed extended BN structure reflects the causal paths found in cognitive psychology literature, thereby addressing the need for causal traceability and strong scientific basis in HRA. Secondly, the use of node reduction algorithms allows the BN to be condensed to a level of detail at which quantification is as straightforward as the techniques used in existing HRA. We illustrate the framework by developing a BN version of the critical data misperceived crew failure mode in the IDHEAS HRA method, which is currently under development at the US NRC [45]. We illustrate how the model could be quantified with a combination of expert-probabilities and information from operator performance databases such as SACADA. This paper lays the foundations necessary to expand the cognitive and quantitative foundations of HRA.	bayesian network;causal filter;human reliability;reliability engineering	Kilian Zwirglmaier;Daniel Straub;Katrina M. Groth	2017	Rel. Eng. & Sys. Safety	10.1016/j.ress.2016.10.010	reliability engineering;engineering;artificial intelligence;data mining	AI	-18.274013769528263	0.13797511023638195	1707
70e782e30786131cbafdb8caaa9a4f6f3b718118	on assorted consolidations of belief structures	representacion conocimientos;belief;sistema experto;fuzzy set;loi probabilite;ley probabilidad;incertidumbre;uncertainty;possibilite;sistema informatico;ensemble flou;computer system;intelligence artificielle;imperfect information;probability law;croyance;informacion imperfecta;artificial intelligence;systeme informatique;incertitude;conjunto borroso;inteligencia artificial;information system;systeme expert;creencia;knowledge representation;representation connaissances;systeme information;information imparfaite;sistema informacion;expert system	Abstract   We investigate the aggregation of Dempster-Shafer belief structures under various different situations. We first look at the standard case where we have multiple belief structures in effect; this is the case covered by Dempster's rule. We next look at the case where a probability distribution determines which belief structure is in effect. Our next case involves the situation where a possibility distribution determines the effective belief structure. Finally, we investigate the case where another belief structure is used to guide the selection of the effective belief structure.		Ronald R. Yager	1992	Inf. Sci.	10.1016/0020-0255(92)90075-J	uncertainty;computer science;artificial intelligence;perfect information;belief;fuzzy set;operations research;expert system;information system;algorithm	AI	-20.99345271601179	-2.0102838555753944	1718
2aeaeeed64c7eb8b12cfadaeac1a2d69f1ec76a7	adequacy of representation of the national drug file reference terminology physiologic effects reference hierarchy for commonly prescribed medications		The National Drug File Reference Terminology contains a novel reference hierarchy to describe physiologic effects (PE) of drugs. The PE reference hierarchy contains 1697 concepts arranged into two broad categories; organ specific and generalized systemic effects. This investigation evaluated the appropriateness of the PE concepts for classifying a random selection of commonly prescribed medications. Ten physician reviewers classified the physiologic effects of ten drugs and rated the accuracy of the selected term. Inter reviewer agreement, overall confidence, and concept frequencies were assessed and were correlated with the complexity of the drug's known physiologic effects. In general, agreement between reviewers was fair to moderate (kappa 0.08-0.49). The physiologic effects modeled became more disperse with drugs having and inducing multiple physiologic processes. Complete modeling of all physiologic effects was limited by reviewers focusing on different physiologic processes. The reviewers were generally comfortable with the accuracy of the concepts selected. Overall, the PE reference hierarchy was useful for physician reviewers classifying the physiologic effects of drugs. Ongoing evolution of the PE reference hierarchy as it evolves should take into account the experiences of our reviewers.		S. Trent Rosenbloom;Joseph Awad;Theodore Speroff;Peter L. Elkin;Russell L. Rothman;Anderson Spickard;Josh F. Peterson;Brent A. Bauer;Dietlind Wahner-Roedler;Mark Lee;William M. Gregg;Kevin B. Johnson;Jim Jirjis;Mark Erlbaum;John S. Carter;Michael J. Lincoln;Steven H. Brown	2003	AMIA ... Annual Symposium proceedings. AMIA Symposium		medicine;data mining;communication;social psychology	Comp.	-55.433566335167086	-69.79675063378974	1719
f223f92ce2584a7fdc37173f87b0f470ccf35ecf	holistic approaches to computer science		Computer science curricula has been well defined for many years through the publication of the Computer Science Curricula reports developed jointly by the two major professional societies, the Association for Computing Machinery (ACM) and the IEEE Computer Society. These documents define computer science curricula by providing knowledge areas and course exemplars. The most recent curriculum report, the Computer Science Curricula 2013 (CSC13 [1]), provides 18 knowledge areas (KAs). Though it stresses that KAs do not necessary represent courses, computer science departments have traditionally created courses around the KAs. Indeed, the course exemplars presented in the CSC13 report, for the most part, center around KAs.	computer science;holism	Ali Erkan;John Barr;Valerie Barr;Michael Goldweber;Deepak Kumar	2018		10.1145/3159450.3159614	curriculum;knowledge management;professional association;computer science	Theory	-80.35956603197003	-30.352344829509537	1722
1faf9953a26fc831525439caf47476e85d9ea382	the problem of a common language, especially for scientific numeral work.				Friedrich L. Bauer;Klaus Samelson	1959			arithmetic;natural language processing;computer science;linguistics	NLP	-30.7322392449991	-77.64654763197778	1724
d956e869916ac30adab9843471d75bf7f99b394f	detection of malicious urls based on word vector representation and ngram				Quan Tran Hai;Seong Oun Hwang	2018	Journal of Intelligent and Fuzzy Systems	10.3233/JIFS-169831	machine learning;mathematics;artificial intelligence	ML	-19.638783579452756	-61.340575277262545	1729
ae6acc31ae00b3f41254cd661437ae7986fcdea1	mapping and explaining the formation of beneficiary perceptions in ict4d	qualitative research;t technology general;image formation;za4050 electronic information resources;data collection;conference contribution;interpretivism;ict4d	one of the causes of failure in ICT4D is connected to field research, which is not always capable to understand the reality experienced by beneficiaries in developing nations. Here I present a research method devised specifically to map and explain the perceptions of beneficiaries in ICT4D projects. The method relies on the construct of subjective perception as image, and provides a type of narrative analysis aimed at “writing the history” of how perceptions are formed. Drawing on my research on food security in south India, I present the technique at work in the collection and analysis of data, illustrating its strengths and limitations in mapping the world visions of respondents. The technique is proposed to solve the conundrum of understanding users’ reality in ICT4D research, hence avoiding the “design-reality gaps” that lead to failure.		Silvia Masiero	2016			geography;knowledge management;management science;social psychology	HCI	-78.44397342901135	-12.765887259174805	1732
b22787f701838102f4ab6cac767e6564198c904c	worker perception of quality assurance mechanisms in crowdsourcing and human computation markets	quality assurance;650 management;004 informatik;labor psychology;human computation;majority vote;survey;crowdsourcing;mechanical turk	Many human computation systems utilize crowdsourcing marketplaces to recruit workers. Because of the open nature of these marketplaces, requesters need to use appropriate quality assurance mechanisms to guarantee high quality results. Previous research has mostly focused on the statistical aspects of quality assurance. Instead, we analyze the worker perception of five quality assurance mechanisms (Qualification Test, Qualification Restriction, Gold Standard, Majority Vote, Validating Review) according to subjective (fairness, offense, benefit) and objective (necessity, accuracy, cost) criteria. Based on theory from related areas like labor psychology, we develop a conceptual model and test it with a survey on Mechanical Turk. Our results show big differences in perception, especially with respect to Majority Vote which is rated low by workers. On the basis of these results, we show implications for theory and give requesters on crowdsourcing markets the advice to integrate the worker view when selecting an appropriate quality assurance mechanism.	amazon mechanical turk;crowdsourcing;display resolution;fairness measure;human-based computation;the turk	Thimo Schulze;Dennis Nordheimer;Martin Schader	2013			public relations;engineering;data mining;social psychology	Web+IR	-92.02013848908103	-13.957011270666124	1733
97a4da4139e3251b17536e962faaedbf7bab0949	hiring behavior models for online labor markets	bayesian network;hiring decisions;econometric analysis;online labor markets;ranking	In an online labor marketplace employers post jobs, receive freelancer applications and make hiring decisions. These hiring decisions are based on the freelancer's observed (e.g., education) and latent (e.g., ability) characteristics. Because of the heterogeneity that appears in the observed characteristics, and the existence of latent ones, identifying and hiring the best possible applicant is a very challenging task. In this work we study and model the employer's hiring behavior. We assume that employers are utility maximizers and make rational decisions by hiring the best possible applicant at hand. Based on this premise, we propose a series of probabilistic models that estimate the hiring probability of each applicant. We train and test our models on more than 600,000 job applications obtained by oDesk.com, and we show evidence that the proposed models outperform currently in-use baselines. To get further insights, we conduct an econometric analysis and observe that the attributes that are strongly correlated with the hiring probability are whether or not the freelancer and the employer have previously worked together, the available information on the freelancer's profile, the countries of the employer and the freelancer and the skillset of the freelancer. Finally, we find that the faster a freelancer applies to an opening, the higher is the probability to get the job.	baseline (configuration management);job stream;statistical model;strongly correlated material	Marios Kokkodis;Panagiotis Papadimitriou;Panagiotis G. Ipeirotis	2015		10.1145/2684822.2685299	ranking;computer science;machine learning;bayesian network	Web+IR	-5.866516664903911	-9.860488878468358	1739
383d92af90570e5debbc130db1d41b8b4a9e4dd9	proceedings of the 2nd international workshop on social influence analysis co-located with 25th international joint conference on artificial intelligence (ijcai 2016), new york city, new york, usa, july 9, 2016			international joint conference on artificial intelligence		2016				SE	-53.840600019477215	-10.278035008659476	1745
33d5813c5ba50f61b4fb287602b453b90d0f4e9d	from animation to analysis in introductory computer science	introductory computer science	At educational computer conferences and exhibits, one is overwhelmed by the extensive use of computers as learning tools in almost any subject. However, the one subject which stands out for its limited use of computers is computer science. There is a tendency in computer science education to focus on what goes on in the mind: design and analysis of algorithms, development of data structures, and use of abstraction and modularization in programming. The computer is seen only as the object of study but not as a tool in the educational process. The danger in such an approach to teaching computer science is that the student may become facile in the use of formalism and languages but may fail to deeply grasp what is really going on One important way in which computers have been used in computer science to assist the educational process is by the development of algorithm animations. Algorithm animations have been created by a number of computer science educators including ourselves [2,3,4,5,6,7,8, 10,11, 12], The primary goals of these algorithm animations have been: .	algorithm;analysis of algorithms;computer science;data structure;semantics (computer science)	Richard Rasala;Viera K. Proulx;Harriet J. Fell	1994		10.1145/191029.191057	computational science;computer science	Theory	-83.0180143175122	-37.17889192006601	1754
f621c58c765a3d2a6501a9fbce21681b4d2beb28	assessing the quality of wikipedia pages using edit longevity and contributor centrality		In this paper we address the challenge of assessing the quality of Wikipedia pages using scores derived from edit contribution and contributor authoritativeness measures. The hypothesis is that pages with significant contributions from authoritative contributors are likely to be high-quality pages. Contributions are quantified using edit longevity measures and contributor authoritativeness is scored using centrality metrics in either Wikipedia talk or co-author networks. The results suggest that it is useful to take into account the contributor authoritativeness when assessing the information quality of Wikipedia content. The percentile visualization of the quality scores provides some insights about anomalous articles, and could be used to help Wikipedia editors to identify Start and Stub articles that are of relatively good quality.	centrality;information quality;wikipedia	Xiangju Qin;Padraig Cunningham	2012	CoRR		computer science;data science;data mining;world wide web	Web+IR	-79.41580111558235	-20.678885154591264	1757
d5c5685d1127f9a3295e5fde4970b706cba358b9	a real time presentation method for playing of a hyperpresentation mail on internet	real time		internet	Younghwan Lim	1999			computer science;multimedia;distributed computing;the internet	ECom	-54.94366175657139	-30.90457034545816	1769
bb1a588774dbd5b31b92a1400ea245dbf1d95302	efficient algorithms for incremental all pairs shortest paths, closeness and betweenness in social network analysis	incremental graph algorithms;centrality metrics;apsp;social network analysis	One of the biggest challenges in today’s social network analysis (SNA) is handling dynamic data. Real-world social networks evolve with time, forcing their corresponding graph representations to dynamically update by addition or deletion of edges/nodes. Consequently, a researcher is often interested in fast recomputation of important SNA metrics pertaining to a network. Recomputations of SNA metrics are expensive. Use of dynamic algorithms has been found as a solution to this problem. For calculating closeness and betweenness centrality metrics, computations of all pairs shortest paths (APSP) are needed. Thus, to compute these SNA metrics dynamically, APSP are needed to be computed dynamically. This paper presents fast incremental updating algorithms along with the time complexity results for APSP, closeness centrality and betweenness centrality, considering two distinct cases: edge addition and node addition. The following time complexity results are presented: (1) The incremental APSP algorithm runs in $$O(n^2)$$ O ( n 2 ) time ( $$\Omega (n^2)$$ Ω ( n 2 ) is the theoretical lower bound of the APSP problem), (2) The incremental closeness algorithm that runs in $$O(n^2)$$ O ( n 2 ) time, and (3) The incremental betweenness algorithm runs in $$O(nm + n^2\, {\mathrm{log}} \, n)$$ O ( n m + n 2 log n ) time. Here, $$m$$ m is the number of edges and $$n$$ n is the number of nodes in the network. Though the time complexity of the presented incremental betweenness algorithm is no better than its static counterpart (Brandes, J Math Sociol 25(2):163–177, 2001), the experimental comparisons demonstrate that the former performs better than the latter. All the presented methods are applicable to weighted, directed or undirected graphs with non-negative real-valued edge weights. An alternate version of the incremental APSP algorithm is presented in the Appendix section. It is demonstrated that this version works better on large graphs.	algorithm;betweenness centrality;closeness centrality;computation;dynamic data;dynamic problem (algorithms);graph (discrete mathematics);shortest path problem;social network analysis;time complexity	Sushant S. Khopkar;Rakesh Nagi;Alexander G. Nikolaev;Vaibhav Bhembre	2014	Social Network Analysis and Mining	10.1007/s13278-014-0220-6	combinatorics;discrete mathematics;machine learning;mathematics;betweenness centrality	Theory	-10.966868691522112	-41.298044638499306	1775
7b476ac3cd7d0bb54d8e7ba44ff13525c93b4a06	motion-motif graphs	similar motion;encompassing motion graph;input data;motion compression;motion-motif graph;large datasets;redundant motion;motif length;motion motif;motion capture data;large motion datasets	We present a technique to automatically distill a motion-motif graph from an arbitrary collection of motion capture data. Motion motifs represent clusters of similar motions and together with their encompassing motion graph they lend understandable structure to the contents and connectivity of large motion datasets. They can be used in support of motion compression, the removal of redundant motions, and the creation of blend spaces. This paper develops a string-based motif-finding algorithm which allows for a user-controlled compromise between motif length and the number of motions in a motif. It allows for time warps within motifs and assigns the majority of the input data to relevant motifs. Results are demonstrated for large datasets (more than 100,000 frames) with computation times of tens of minutes.	algorithm;computation;motion capture;motion compensation;sequence motif	Philippe Beaudoin;Stelian Coros;Michiel van de Panne;Pierre Poulin	2008			computer vision;computer science;theoretical computer science;machine learning;motion estimation;geometry;computer graphics (images)	Vision	-28.349806558278235	-35.42103222825063	1777
5092311bdb18b85a1d5488061036a54815795247	quality assurance for segmentation and tagging of chinese novels in the ming and qing dynasties	quality assurance;computer aided analysis;manuals;word processing computer aided analysis iterative methods linguistics literature natural language processing quality assurance quality control text analysis;pragmatics;named entities;semantics;text analysis;literature;iterative methods;word segmentation;novels in the ming and qing dynasties;process control;novels in the ming and qing dynasties quality assurance word segmentation tagging named entities;tagging semantics manuals process control buildings pragmatics educational institutions;quality control;natural language processing;buildings;word processing;tagging;linguistics word segmentation named entity tagging project chinese novels ming dynasty qing dynasty quality assurance modern chinese segmentation mainland china taiwan classic chinese modern chinese iterative refinement process quality control computer aided processing tool chinese literature computer aided manually reviewed method information technology;linguistics	This paper presents a word segmentation and named entity tagging project which annotates Chinese novels in the Ming and Qing dynasties. Computer-aided tools are used to assist the annotation. The focus of this paper will be on the quality assurance measures to ensure precision and consistency. The specification for word segmentation and named entity tagging is formulated based on the standards for modern Chinese segmentation commonly used in Mainland China and in Taiwan as well as the analysis of differences between Chinese classics and modern Chinese. The specification is established through iterative refinements. This refinement process can offer valuable insights into the quality control of computer-aided processing performed on Chinese literature works in the Ming and Qing dynasties and can be applied to those in even earlier periods. The finalized corpus, built in a computer-aided, manually-reviewed method in accordance with the specification, can be used for researches in literature, linguistics, information technology, and teaching of Chinese.	distortion;iteration;manual handling of loads;named entity;refinable function;refinement (computing);text segmentation;video post-processing	Dan Xiong;Qin Lu;Fengju Lo;Dingxu Shi;Tin-Shing Chiu	2012	2012 International Conference on Asian Language Processing	10.1109/IALP.2012.60	natural language processing;text segmentation;quality assurance;quality control;text mining;speech recognition;computer science;process control;semantics;linguistics;iterative method;pragmatics	SE	-30.056283747416984	-73.18004045380522	1778
199fb5ff6f0fdeda53db5ef8ddfebaa2649e4cd9	human dimensions of peer review in information science			information science	Keren Dali;Paul T. Jaeger;Lilith Lee	2017		10.1002/pra2.2017.14505401100	knowledge management;computer science;information science	NLP	-62.62765237441093	-9.749897720087175	1788
c2fa99f947a1870e4786c49614758da7654ecca0	aintec '09, asian internet engineering conference, bangkok, thailand, november 18-20, 2009, proceedings					2009				HPC	-56.40609658047876	-7.473841747616704	1798
c6a8417752e4e9e99dfcb88023ad29d7d9ad3566	prosodic processing in developmental dyslexia: a case study in standard chinese	stress;pragmatics;standards;boundary perception prosodic processing speech production speech perception developmental dyslexia prosodic cues standard chinese nonalphabetic tonal language complex neurobiological mechanism visual picture processing semantic priming prosodic patterns perception prosodic patterns production syntactic structure double object construction native chinese adult impaired perceptual ability sentence accents information structures sentence boundaries;speech;noise measurement;syntax prosody dyslexia speech perception and production information structure;syntactics;production;production syntactics stress speech standards pragmatics noise measurement;speech processing handicapped aids natural language processing	The present case study investigated the speech production and perception of developmental dyslexia through prosodic cues in Standard Chinese. As a non-alphabetic tonal language, there is a complex neurobiological mechanism between visual picture processing and semantic priming, perception and production of prosodic patterns. The experimental materials employed in the study were the syntactic structure of Double Object construction with various information structures. The results show that the dyslexic participant, a native Chinese adult, i.e. M6, had an impaired perceptual ability to discriminate boundaries and sentence accents in different information structures. While on the aspect of production, both sentence accents and boundaries produced by M6 could be perceived by other normal participants, however, every syntactic structure has a consistent pattern in all the focus conditions. The results implied that in normal participants, prosody processing (i.e., sentence accent and boundary perception) was interacted with higher-level information of language, such as syntactic and information structures, however, the dyslexic shows no such interactions.	data structure;focus group;interaction;pitch (music);semantic network;semantic prosody	Yi Yuan;Aijun Li;Yuan Jia;Jianhua Hu;Balazs Surany	2015	2015 International Conference Oriental COCOSDA held jointly with 2015 Conference on Asian Spoken Language Research and Evaluation (O-COCOSDA/CASLRE)	10.1109/ICSDA.2015.7357866	psychology;natural language processing;linguistics;communication	NLP	-10.50075551199112	-80.55146179855991	1800
5102bfe6d8947db9535d66cb5b37adaaaccdca90	fixit: a 3d jigsaw puzzle game using multi-touch gestures		We propose Fixit, a 3D jigsaw puzzle game using touch gestures on Android mobile devices. The system consists of a back-end authoring process and afront-end gaming control. The authoring process generates thepuzzle pieces, which are cut and refined by our algorithms from the input 3D model. The gaming control providesan intuitivegraphical user interface, which utilize touch screen multimodal gestures and allows user to reconstruct the 3Djigsaw puzzle pieces into the original 3D model.	multi-touch	Yi-Hsiang Lo;Che-Chun Hsu;Hsin-Yin Chang;Wen-Yao Kung;Yen-Chun Lee;Ruen-Rone Lee	2014		10.1007/978-3-319-11650-1_5	multimedia	HCI	-43.6375632527921	-38.78800405367985	1801
513bf5630b85b0a3feb95896dd77a8a7cc4e249c	a phoneme recognition system using modular construction of time-delay neural networks	processing element;modular construction neural networks artificial neural networks speech recognition hidden markov models data mining vocabulary biomedical engineering refining computer aided manufacturing;neural nets;speech recognition neural nets;time delay neural network;speaker independent;speech recognition;artificial neural network;male speakers phoneme recognition system time delay neural networks phoneme data artificial neural network continuous speech	The purpose of this research was to investigate altemative approaches of representing phoneme data to be input into an artificial neural network, and alterations that can be made in the network to reduce training time without sacrificing recognition rate. The study used a modularly constructed Time-Delay Neural Network (TDNN) trained to identifi English stop consonant phonemes under speaker-independent, continuous speech conditions. Samples of continuous speech were recorded from ten male speakers and phonemes were manually extracted, passed through a 128-point FFT, and downsampled by a factor of four. Extracted phonemes were less than the maximum input size for the TDNN, so data was shified within the input window to allow recognition of the phonerite regardless of where the phoneme was presented within the input window. The TDNN contained 490 processing elements and over 12,000 connections and was constructed in a modular fashion, allowing fiture expansion. Recognition rates as high as 98.8% were obtained for individual phonemes within modules, and overall recognition rates as high as 79.4% for all stop consonant phonemes were obtained. Deficiencies in the TDNN used are discussed, as well as refinements which should significantly increase overall recognition rates.	artificial neural network;decimation (signal processing);fast fourier transform;information;modular design;modular programming;time delay neural network	Thomas C. Wendell;Kadry Abdelhamied	1992		10.1109/CBMS.1992.245041	neural gas;natural language processing;speech recognition;computer science;recurrent neural network;machine learning;time delay neural network;acoustic model;artificial neural network	ML	-17.8908620764561	-86.60547148047573	1807
ef56a532d1e3257f6f9c6b740a56e7f940565ed1	student and instructor satisfaction with e-learning tools in online learning environments	e learning tools;satisfactions;technology;online learning;student;instructors	"""This study utilized Expectancy Confirmation Theory (ECT) and Technology Acceptance Model (TAM) to examine satisfaction of students and instructors toward online learning tools and resources in online learning environments. The study findings indicate that student expectation was the most important factor that helped the instructors to design and provide appropriate and efficient technology tools and resources to enhance student learning. Further, the instructors were satisfied with the technology tools and resources that were provided, as these helped them to achieve their instructional expectations. These findings could help to stimulate reflections on ways to improve and design useful e-learning tools and resources that could enhance effective teaching and learning in online environments. a computer technology tool that is used for enhancing teaching and learning. E-learning also refers to the use of Internet technologies to deliver information or solutions that enhance knowledge and performance (Rosenberg, 2001). In terms of learner, Sun et al. (2008) argue that satisfaction of learners is the most significant factor for developing online course. Their research study demonstrates a framework of six dimensions that influence satisfactions of online learners. Among them, learners and technology are two dimensions that obviously relate to the development of e-learning tools and resources. DOI: 10.4018/jicte.2012010108 International Journal of Information and Communication Technology Education, 8(1), 76-86, January-March 2012 77 Copyright © 2012, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. These two dimensions contain several factors that are characterized by three significant features: usability, quality, and flexibility. All of these features are of acute importance due to their affect on satisfaction of learners within online learning environments (Sun et al., 2008). Satisfaction of instructors toward e-learning technology is also important for determining success of e-learning tools (Sobero & Sobero, 2009). Further, their research study indicates that confirmation of expectations and perceived usefulness of instructors are significant for explaining their satisfactions with e-learning tools. This theoretical framework is illustrated in Figure 1. Related Theories and Models of Satisfactions Expectancy Confirmation Theory (ECT) Previous research studies show that usability, quality, and flexibility of e-learning tools and resources are significant features that influence satisfactions of online learners. Expectancy Confirmation Theory (ECT) is a theory used for measuring and predicting factors that influence satisfactions of users toward products. Bhattacherjee (2001) applied this theory in a study to examine user’s satisfactions towards continually using information system (IS). The study demonstrates the success of applying ECT to examine satisfactions toward usage of IS. Additionally, Chui at el. (2005) also used ECT in their study to examine usability and quality of online technological materials within online education – factors affecting satisfaction of online users. Therefore, ECT was also used in this to examine satisfactions of learners and instructor toward e-learning tools and resources within online courses, which is the primary purpose of the study. Bhattacherjee (2001) provides a framework and descriptions of five processes of ECT that include expectation, performance, confirmation, satisfaction, intention. This framework is illustrated in Figure 2. Figure 1. Framework of six dimensions that influence satisfactions of e-learners 9 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/student-instructor-satisfactionlearning-tools/61392?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Library Science, Information Studies, and Education. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	amiga reflections;computer;electroconvulsive therapy;ibm tivoli access manager;inferring horizontal gene transfer;information science;information system;librarian;library science;usability;web page	Jared Keengwe;Watsatree Diteeyont;Assion Lawson-Body	2012	IJICTE	10.4018/jicte.2012010108	educational technology;engineering;knowledge management;multimedia;synchronous learning;pedagogy;technology	HCI	-76.10015370124358	-39.91144651952638	1815
d0b170667ebf6c34108e4119c8190821144a31f1	actions that make you change your mind (extended abstract)	extended abstract	In this paper we study the dynamics of belief from an agent-oriented, semantics-based point of view. In a formal framework used to specify and to analyze rational agents, we define actions that model three well-known changes of belief, viz. expansions, contractions and revisions. We define both the opportunity for and the result of these belief-changing actions. To define the semantics of the contraction action we introduce selection functions. These functions pick out a set of states that is to be added to the set of doxastic alternatives of an agent, thereby contracting its set of beliefs. The action that models belief revisions is defined as the sequential composition of a contraction and an expansion in a way suggested by the Levi-identity. We show that these belief-changing actions are defined in an intuitively acceptable, reasonable way by proving that the AGM postulates for belief changes are validated.		Bernd van Linder;Wiebe van der Hoek;John-Jules Ch. Meyer	1995		10.1007/3-540-60343-3_36	lived body	Theory	-11.963753117545307	-1.0517741921313557	1820
0e7ada4eab920d8aab4cfafcc9e228253c457604	a system framework and key techniques of fragments assembly for restoration of historical relics based on grid	grid;restoration of historical relics;assembly of fragments;globus	Computer-aided relic recovery is an important and urgent research in archaeology, especially virtual assembly of historical relic fragments using computer graphics, image processing and virtual reality techniques. In the computer-aided assembly of historical relic fragments, many algorithms cooperate, and heavy load and difficult use of the algorithms further the difficulty of implementation. Grid is used to enable the coordinated use of distributed resources. In this paper, a way is discussed to make algorithms more effectively shared and used, and how to assemble historical relic fragments based on Grid-computing technologies. We first present the framework of grid-based archaeological fragment assembly system, and then discuss the key technologies and implementation details.	algorithm;circuit restoration;computer graphics;grid computing;image processing;virtual reality	Hai Guo;Leiguang Ouyang;Xiangxu Meng;Hui Xiang;Chenglei Yang;RongJiang Pan	2006		10.1145/1128923.1128995	bioinformatics;engineering;world wide web;cartography	Visualization	-35.43063308473823	-32.023870668265054	1823
d1be669cc13598509c0fb4dddabb4fa7e23fcd5d	assessing the suitability of an honest rating mechanism for the collaborative creation of structured knowledge	peer production;incentives;structured knowledge	Creating and maintaining semantic structures such as ontologies continues to be an important issue. The approach investigated here is to let members of an online community create structured knowledge collaboratively and to use ratings to evaluate the data created. Obviously, such ratings have to be of high quality. Honest rating mechanisms (HRMs) known from literature are a promising means to gain such high-quality ratings. However, the design of such mechanisms for collaborative knowledge creation and their effectiveness have not been studied so far. To evaluate the effects of an HRM on rating quality in this context, we have conducted several experiments with online communities. We find that an HRM increases rating quality and “punishes” rating errors. We also find that rating-based rewards increase the quality of the structured knowledge created.	display resolution;experiment;human race machine;online community;ontology (information science)	Conny Kühne;Klemens Böhm	2012	World Wide Web	10.1007/s11280-012-0193-1	incentive;knowledge management;data mining;world wide web	Web+IR	-84.18202352606536	-15.25735048660144	1824
0afe29f90df5527e7ed3a2355292b04670d3704b	study of bilingual teaching reform and practice based on web resources	bilingual teaching;computer simulation;electronic circuit	Analyzing the importance and necessity of the bilingual teaching about “computer simulation for electronic circuit” course, searching from the teaching mode, teaching material selection, teaching methods and means, evaluation methods and so on, analyzing and researching the bilingual teaching of this course by combining the theoretical analysis with the practical course teaching, several teaching modes and methods which are appropriate for our students and the characteristic course are summarized.	web resource	Meihua Gua;Jinyan Haob	2011		10.1007/978-3-642-23357-9_65	mathematics education;computer science;multimedia;pedagogy	HCI	-77.28899259933587	-41.607849664499184	1826
9f9793c196f434f8cd3f29c5eb028ea5e37a87c7	acm president's letter: r for excellence: better education		In this third of a series of letters on my proposed goals for ACM, the focus is on education. For the forseeable future, the computer industry, the computer-related industries , and the application of computers to all sectors of our economy will be people-limited; the pacing elements will be neither technology nor the availability of money. The sources of competent people are keyed to the availability and adequacy of education in computer fundamentals and in information processing techniques. Accordingly, my proposed goal for ACM is twofold: By 1972, ACM should have published recommended curricula for computer-related programs in-secondary schools-technical institutes or trade schools-junior colleges-colleges and universities-professional development courses for credit. By 1980, ACM should have taken direct or indirect action on accreditation of at least 50 percent of the U.S. computer education curricula and programs. When this double-edged goal was first proposed one year ago, it provoked vigorous objection from a number of our senior people in computer science education. I hope that a broader set of ACM members will speak out on this subject this time around. Also, several events during the past year have reinforced my convictions on the attainability of an education goal for ACM. One of the key events has been the consolidation of ACM's education activities under the leadership of a single committee chaired by Bill Atchison. The present structure of his committee's responsibility is shown on this page. Noticeably present in this structure is the Professional Development activity, which is still in a highly experimental stage. As the national trend grows toward credit-giving professional development courses in computer-related technologies, I expect the ACM Education Committee to assume a major overview responsibility in this area. The oldest ACM activity related to this education goal is the formally published ACM curriculum for computer science at the college or university level. During the past year, the continuing review of the adoption of this recommended curriculum has shown v~ide-spread acceptance, but there are enough practical experiences now in hand to point the way toward major revisions to portions of the curriculum. Much work needs to be done to achieve agreement on these revisions, but 1972 should be a good target date for the second edition of the ACM Computer Science Curriculum. George Heller's Committee on Secondary School Education is well on its way toward curriculum recommendations at that level. I expect that their work will receive its first …	computer science;information processing;integrated development environment;money;semiconductor consolidation	Walter M. Carlson	1970	Commun. ACM	10.1145/355598.362770	computer science	Graphics	-65.75913609802045	-20.233973320241272	1830
558367bb6e2644acbfc5870569f9908eed975d77	fast and robust pos tagger for arabic tweets using agreement-based bootstrapping		Part-of-Speech (POS) tagging is a key step in many NLP algorithms. However, tweets are difficult to POS tag because they are short, are not always written maintaining formal grammar and proper spelling, and abbreviations are often used to overcome their restricted lengths. Arabic tweets also show a further range of linguistic phenomena such as usage of different dialects, romanised Arabic and borrowing foreign words. In this paper, we present an evaluation and a detailed error analysis of state-of-the-art POS taggers for Arabic when applied to Arabic tweets. On the basis of this analysis, we combine normalisation and external knowledge to handle the domain noisiness and exploit bootstrapping to construct extra training data in order to improve POS tagging for Arabic tweets. Our results show significant improvements over the performance of a number of well-known taggers for Arabic.	algorithm;brill tagger;error analysis (mathematics);formal grammar;natural language processing;part-of-speech tagging;robustness (computer science)	Fahad Albogamy;Allan Ramsay	2016			arabic;natural language processing;artificial intelligence;speech recognition;bootstrapping;computer science	NLP	-24.89506884308179	-77.15956975617145	1834
f87233120c001b37799e11e6957d36686fab43e6	manufacturing-oriented discrete process modeling approach using the predicate logic	modelizacion;machining formal logic inference mechanisms;regle inference;machining;production efficiency manufacturing oriented discrete process modeling approach first order predicate logic part machining discrete manufacturing process intelligent modeling method process representation inference rule process simulation;discrete process;indice produccion;flexible manufacturing systems;performance evaluation;predicate logic;intelligent modeling method;gollete estrangulamiento;first order predicate logic;routing;logic;model performance;routage;manufacturing processes virtual manufacturing logic object oriented modeling machining production flexible manufacturing systems performance evaluation costs transient analysis;inference mechanisms;manufacturing oriented discrete process modeling approach;transient analysis;production process;inference rule;modelisation;goulot etranglement;manufacturing processes;usinage;first order;logique ordre 1;taux production;process representation;processus fabrication;formal logic;performance simulation discrete process intelligent modeling predicate logic;production;production rate;part machining;process model;discrete manufacturing process;mecanizado;process simulation;modeling;bottleneck;object oriented modeling;virtual manufacturing;first order logic;production efficiency;performance simulation;proceso fabricacion;intelligent modeling;regla inferencia;logica orden 1;enrutamiento	Part machining is a discrete manufacturing process. In order to evaluate the manufacturing process, an intelligent modeling method based on the first-order predicate logic is proposed. First, the basic predicate formula is defined according to the machining method, and the predicate and variables are illustrated in detail. Thus, the process representation is completed. Second, to construct the process model, the modeling element is put forward, which includes three nodes. Components of modeling element are, respectively, discussed, as well as the mapping relationship between modeling element and predicate. After the definition of modeling predicate formula, five basic inference rules are established. Consequently, the manufacturing process model is constructed. Third, on the basis of the process model, the process simulation is carried out to evaluate the manufacturing performances, such as the production efficiency, the utilization rate of machining equipment, the production bottleneck, etc. Finally, a case study is conducted to explain this modeling method.	algorithm;discrete manufacturing;first-order logic;first-order predicate;performance;process modeling;simulation	Wang Zhenwei;Hui Li	2009	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2009.70	process simulation;computer science;artificial intelligence;first-order logic;logic;algorithm	DB	-21.987247215704308	-3.2305277648711055	1835
96b18b8e8d45778f301c99d8fe5f8c6f6fa3161d	a survey of gender issues related to computer music and strategies for change				Mary Simoni	1995			humanities;psychology;social science;multimedia	HCI	-68.49483380936128	-32.87786305517966	1836
213de8480be16a3e840182b6b517456e6ace4510	toward a technology for organizational memories	databases knowledge management memory management information systems expert systems natural languages intelligent systems performance evaluation prototypes production facilities;information retrieval;administrative data processing;knowledge management;business process modeling;organizational memory;administrative data processing knowledge based systems;thesaurus generation;information modeling;task oriented method organizational memory enterprise wide knowledge management knowledge processing intelligent assistant formal knowledge elements nonformal knowledge elements;knowledge based systems	THE RECOGNITION THAT KNOWLedge is one of an enterprise’s most important assets, decisively influencing its competitiveness, has fueled interest in comprehensive approaches to the basic activities of knowledge management : the identification, acquisition, development, dissemination, use, and preservation of the enterprise’s knowledge. Traditionally, enterprises have addressed knowledge management from either a management or a technological point of view. Managers understand that the knowledge their employees possess is one of their company’s most valuable assets. They are concerned with the effective use of personal knowledge and the qualitative and quantitative adaptation of this knowledge toward a changing environment. The technological approach, by contrast, deals with questions about what information technology should be provided to support knowledge management. 1	case preservation;knowledge management	Andreas Abecker;Ansgar Bernardi;Knut Hinkelmann;Otto Kühn;Michael Sintek	1998	IEEE Intelligent Systems	10.1109/5254.683209	knowledge base;organizational learning;knowledge integration;information model;computer science;knowledge management;artificial intelligence;body of knowledge;mathematical knowledge management;knowledge-based systems;knowledge engineering;open knowledge base connectivity;data mining;database;procedural knowledge;knowledge extraction;personal knowledge management;knowledge value chain;business process modeling;domain knowledge	AI	-70.83423160845858	3.795727749971826	1837
39dd5ba808101bb746bcd741e2808b06cded1710	pairwise mergers in bipartite matching games with an application in collaborative logistics		Merging among players in a cooperative game can alter the structure of the core. This paper shows that in bipartite matching games, if pairs of players from di erent sides merge, the structure of the core remains unchanged. This allows us to extend the well-known result regarding the characterization of the core with dual solutions for simple games to their associated pairwise merger games. We introduce the class of vehicle scheduling games as an area of application for our result.		Behzad Hezarkhani	2016	Oper. Res. Lett.	10.1016/j.orl.2016.10.004	combinatorial game theory;simulation;mathematics;distributed computing	ECom	-5.766657134058114	-2.2986810803569546	1843
43ee2158165f870a21e93c26b072bd30ee4f993a	april in paris: signs of artificial life along the seine	art;multimedia systems;artificial intelligence multimedia systems art interactive systems;public space;artificial intelligence;interactive systems;art digital media multiagent environment memory chip artificially intelligent form public places;cities and towns art cameras loudspeakers orbital robotics displays strips bones turning speech;artificial life	The idea of blending art into city life is not new and has been associated with technology from the start. Our paper will consider programmed, generative art works in the context of two art historical antecedents, the Futurists in the 1910s and the art movement Fluxus in the 1960s. We will focus on a selection of installations in the streets of Issy, France, during the “Festival Premier Contact” organized by Le CUBE and curated by its Art Director, Florent Aziosmanoff (April 2005). The artists discussed will be laKitchen, Roland Cahen, Damaris Risch, Vincent Lévy, among others.	alpha compositing;artificial life;futurist	Carol-Ann Braun	2005	IEEE MultiMedia	10.1109/MMUL.2005.42	computer vision;simulation;human–computer interaction;telecommunications;computer science;artificial intelligence;multimedia;world wide web;artificial life	Visualization	-53.4948046592192	-27.549373128171037	1850
2f87bee04646f6aa81ca57c4a09f4f7f6dbd8395	interest rate prediction: a neuro-hybrid approach with data preprocessing	multiple regression analysis;differential evolution based fuzzy clustering;interest rate prediction;and fuzzy inference neural network	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	algorithmic trading;applications of artificial intelligence;artificial neural network;autoregressive model;benchmark (computing);book;cluster analysis;computation;computational intelligence;data mining;data pre-processing;data structure;electrical engineering;francis;fuzzy clustering;fuzzy logic;information systems;information management;least squares;linear model;nl (complexity);network model;nonlinear system;preprocessor;primary source;support vector machine;systems engineering;time complexity	Nijat Mehdiyev;David Enke	2014	Int. J. General Systems	10.1080/03081079.2014.883386	adaptive neuro fuzzy inference system;computer science;machine learning;pattern recognition;mathematics;regression analysis;statistics	Robotics	-14.125287577165707	-5.70755547560541	1856
9b2881975acd3bbb8ad8402f1cbf5f090c716c56	virtual subject innovation platform: a new operational pattern for comprehensive hospital	creativity;hospital;virtual subject	This is a study that describes the prevalence and patterns of constructing virtual subject in hospital in China. It is a high risk for hospital to invest greatly for innovation of hospital disciplines, so we want to establish some new comprehensive platforms which based on some informational systems that involve diseases treatment, medical research, diseases recoveries, prevent diseases and medicine developments. But the virtual subject platform could afford a superior chance for cooperation between interior and exterior medical organizations. This article discusses the subject’s structure, the construction’s principles, cooperation advantages and clarifies that the platform could boost the efficiency of hospital to do some medical research.	high risk acute leukemia;immune system diseases	Huan Xu;Yuxiu Liu;Yi Su;Linming Zhou;Guobin Yang;Xueming Yi	2011	Journal of Medical Systems	10.1007/s10916-011-9699-9	medicine;artificial intelligence;management;computer security	Security	-57.919839849057325	-61.85456979387509	1860
e08a0a3291b9bccde5b469617da78541fb1dd845	massively multiple online role playing games as normative multiagent systems	datorsystem;computer systems	The latest advancements in computer games offer a domain of human and artificial agent behaviour well suited for analysis and development based on normative multi agent systems research. One of the most influential gaming trends today, Massively Multi Online Role Playing Games (MMORPG), poses new questions about the interaction between the players in the game. If we model the players and groups of players in these games as multiagent systems with the possibility to create norms and sanction norm violations we have to create a way to describe the different kind of norms that may appear in these situations. Certain situations in MMORPG are subject to discussions about how norms are created and propagated in a group, one such example involves the sleeper in the game Everquest, from Sony Online Entertainment (SOE). The Sleeper was at first designed to be unkillable, but after some events and some considerations from SOE the sleeper was finally killed. The most interesting aspect of the story about the sleeper is how we can interpret the norms being created in this example. We propose a framework to analyse the norms involved in the interaction between players and groups in MMORPG. We argue that our model adds complexity where we find earlier norm typologies lacking some descriptive power of this phenomenon, and we can even describe and understand the confusing event with the sleeper in Everquest.	agent-based model;biological anthropology;categorization;everquest;glitch;intelligent agent;massively multiplayer online role-playing game;multi-agent system;pc game;school of everything;sleeper;systems theory	Magnus Johansson;Harko Verhagen	2009			simulation;computer science;distributed computing;multimedia	AI	-64.76889972543144	-31.39215446072474	1863
950537374cd9c335de56ac173d35c8c71f5a9cf0	implementation of the grid file: design concepts and experience		"""The grid file is an adaptable, symmetric multikey file structure. It stores highly dynamic sets of multidimensional data in such a way that different types of queries can be performed using few disk accesses. We present the design concepts underlying our implementation of the grid file and describe applications of the oridfile system. 1. I n t r o d u c t i o n . File structures that provide multikey access to records are of interest in various fields of data processing, for example in the physical organization of data base systems or in applications involving large sets of geometric data. In practical applications the most common method for multikey access to data is to construct an inverted file, i.e. an independent access path for each key, by means of a single-key access structure. However, for queries which involve more than one key, e.g. partial match or range queries, it may be necessary to access an inverted file repeatedly and to perform costly intersections in order to obtain the records which satisfy the query. This method also suffers from inherent redundancy due to which insertion or deletion of a single record requires modifying all the access paths. Several multikey file structures have been proposed that avoid the deficiencies of the inverted file by combining all keys into a single access path, so that the same structure handles all keys. Each of these structures partitions the data space into subspaces, down to the """"level of resolution"""" of the implementation of the access method. Some of these multikey file structures perform some tasks better than others, e.g. exact match, partial match, range or nearest neighbor queries. No single structure can, of course, be optimal under all circumstances. Just like single-key file structures, multikey file structures can be classified according to whether they are static or dynamic and whether they are based on comparative search (e.g. by tree structures) or address computation. Examples * This work was carded out while the author was at the lnstitut fiir Informatik, ETH, CH-8092 Zf~ich, Switzerland. Received August 1984. Revised December 1984 and May 1985."""	access structure;computation;database;dataspaces;experience;grid file;i/o controller hub;inverted index;range query (data structures);single-access key;switzerland;tree structure	Klaus H. Hinrichs	1985	BIT		self-certifying file system;grid file;parallel computing;torrent file;indexed file;device file;computer file;computer science;class implementation file;versioning file system;operating system;unix file types;ssh file transfer protocol;journaling file system;database;mathematics;open;data file;file system fragmentation;design rule for camera file system	DB	-28.089051263956254	3.1760720382302403	1869
d2a51c4e7fb385e8f72ec2610d9e4725f266d35e	research hypotheses for gender activities in mobile internet	data gathering;palm sized computer;gender difference;gender activities;structural equation modelling;computer self efficacy;social influence;mobile internet;perceived value;determinants	This study extends the Unified Theory of Acceptance and Use of Technology Model (UTAUT) by adding perceived playfulness, perceived value and palm-sized computer self-efficacy to the UTAUT in order to investigate the factors affecting individual's' m-Internet acceptance and to see if there exists gender differences in the acceptance of m-Internet. Data, gathered from 343 respondents in Taiwan, were tested against the research model using the structural equation modelling approach. The results indicate that that performance expectancy, effort expectancy, social influence, perceived value and palm-sized computer self-efficacy were significant determinants of behavioural intention to use m-Internet.	internet;structural equation modeling	Hsiu-Yuan Wang;Tung-Jung Chan;Ching-Mu Chen;Yung-Fa Huang;Neng-Chung Wang;Yu-Sheng Chang	2010		10.1145/1815396.1815691	structural equation modeling;simulation;determinant;social influence;statistics;data collection	HCI	-89.89073175798524	-9.658372329900363	1873
ba9abc48327189b0524229a7136f92da6db8635c	sonigraphite: drawing sounds as new physical expression	video games;virtual characters;uncanny valley;character design;new physics	A ferrous feedstock for subsequent use in a melting or smelting furnace is produced by casting molten ferrous material continuously onto the surface of an elongate channel-shaped substrate moving continuously past a casting station. The cast material solidifies to form a strip which is separated continuously from the substrate and subsequently fragmented to produce ferrous segments of a size suitable for feeding to a melting or smelting furnace.		Ryoko Kitazawa;Mariko Koizumi;Hiroshi Miyamura;Syugo Suzuki;Naohito Okude	2008		10.1145/1400885.1400924	physics beyond the standard model;computer science;artificial intelligence;uncanny valley;multimedia;computer graphics (images)	HCI	-52.36256566410313	-28.987604104806202	1881
dd47f01022df5836f2990e692a28cd2119d3c8a4	"""corrections to """"on decentralized estimation with active queries"""""""				David A. Castañón;Theodoros Tsiligkaridis;Alfred O. Hero	2017	IEEE Trans. Signal Processing	10.1109/TSP.2017.2721914		EDA	-38.96109510761406	-13.125520692360356	1888
a043f801867de143b4fc53787f4f23211f2336ea	reading as dialogical document work: possibilities for library and information science	information practices;reading;library and information science;information studies;information behaviour;journal article;biblioteks och informationsvetenskap;document theory;dialogism;document work	Purpose – The purpose of this paper is to introduce a dialogically based theory of documentary practices and document work as a promising framework for studying activities that are often conceptualised as information behaviour or information practices within Library and Information Science (LIS). Design/methodology/approach – An empirical example – a lesson on how to read railway timetables – is presented. The lesson stems from a research project including 223 Swedish lessons recorded in Swedish primary schools 1967-1969. It is argued that this lesson, as many empirical situations within LIS research, can fruitfully be regarded as documentary practices which include document work such as reading, rather than instances of information behaviour. Findings – It is found that the theoretical perspective of dialogism could contribute to the theory development within LIS, and function as a bridge between different subfields such as reading studies and documentary practices. Research limitations/implications – Th...	library and information science	Anna Hampson Lundh;Mats Dolatkhah	2015	Journal of Documentation	10.1108/JD-01-2015-0019	library science;social science;computer science;multimedia;sociology;world wide web;information retrieval;reading	NLP	-73.36838978940345	-21.931144716869813	1894
3efed03bbfd95b7abad4e74a5aca5ce68839f4b7	combination of rule-based and textual similarity approaches to match financial entities	text mining;text summarization;financial data mining	Record linkage is a well studied problem [1] with many years of publication history. Nevertheless, there are many challenges remaining to be addressed, such as the topic addressed by FEIII Challenge 2016. Matching financial entities (FEs) is important for many private and governmental organizations. In this paper we describe the problem of matching such FEs across three datasets: FFIEC, LEI and SEC. We were able to achieve an f-measure of 93.78% in the first task, which is comparable to the maximum 97.44%, and 70.44% for the second task, where the maximum is 88.38%.	entity;f1 score;linkage (software)	Ahmad Samiei;Ioannis Koumarelas;Michael Loster;Felix Naumann	2016		10.1145/2951894.2951905	concept mining;text graph;text mining;automatic summarization;pattern recognition;data mining;information retrieval;co-occurrence networks	ML	-25.91465834815744	-67.44146908950214	1895
6f049ec88e324c1ab3916c1b2d3900081707f3b5	erratum to: optimal surveillance network design: a value of information model	simulation and modeling;operation research decision theory;operations research management science;complex systems	Author details 1 School of Public Health, Environmental Health Sciences Division and Public Health Informatics Program, HumNat Lab, University of Minnesota, Minneapolis, MN, USA. 2 Institute on the Environment, University of Minnesota, Minneapolis, MN, USA. 3 Institute for Engineering in Medicine, University of Minnesota, Minneapolis, MN, USA. 4 Academic Health Center, Mayo Memorial Building, Suite 1232 12th fl., MMC807, 420 Delaware St. SE, Minneapolis, MN 55455, USA. Additional file	informatics;information model;network planning and design	Matteo Convertino;Yang Liu;Haejin Hwang	2016	CASM	10.1186/s40294-016-0021-z	simulation;computer science;systems engineering;management science	ML	-44.820830590697426	-9.52177232616584	1917
4f64bbab9a1b315c5a850142efb2ea3457f912cd	a three-dimensional representation for program execution	computer program;programming environments;computer graphics;real time;dynamical processes;three dimensional;user interfaces computer graphics programming environments;displays tree data structures workstations debugging books dynamic programming hardware shape graphics tree graphs;human visual system 3d representation program execution graphical workstations interactive real time manipulation pictorial representation dynamic processes dynamic behavior animation debugging process;human visual system;graphical representation;user interfaces;dynamic behavior	Modern graphical workstations make possible interactive real-time manipulation of three-dimensional objects. While 3D graphics is usually used to model real-world objects, in this paper we explore an abstract three-dimensional pictorial representation of computer programs. Since programs are descriptions of dynamic processes, the focus is on the dynamic behavior of the graphical representation, resulting in an animation of the program's execution. The goal is to aid the debugging process by helping the programmer visualize the dynamic aspects of a program's behavior. 3D representations help make use of the enormous innate power of the human visual system. Shu's book on visual programming [Shu 881 discusses many projects which use pictorial representations for computer programs and their data. Most of the representations that are described in Shu's book and other sources are two-dimensional, and concentrate mainly on the static appearance of program code. The experiments described in this paper are aimed at extending the visual vocabulary for graphical programming, using an abstract three-dimensional representation for computer programs in the context of an interactive dynamic debugger. Three-dimensional representations are now made practical by hardware which automatically performs rendering of solid objects just as easily as displaying a line of text. Other graphical techniques employed in this debugger to provide an integrated view of program execution are: a re-roofing process which keeps a fixed viewpoint while displaying a changing context, graphical objects, a reversible control structure, use of 3D rotation to simultaneously present sequential and time-slice views.. Programming in three dimensions the Of as substitution Of Program elements are represented by colored polyhedra. Each program element is labeled by three-dimensional text attached to a face of the program element. The size, shape, color and position of program elements are significant. The properties of tGe polyhedra changgto reflect the current state of the program. Boxes grow, shrink,	3d computer graphics;color;computer program;control flow;debugger;debugging;experiment;graphical user interface;image;polyhedron;preemption (computing);programmer;real-time transcription;visual programming language;vocabulary;workstation	Henry Lieberman	1989		10.1109/WVL.1989.77051	human–computer interaction;computer science;theoretical computer science;algorithmic program debugging;computer graphics (images)	Graphics	-40.01781987290666	-31.710513074419886	1918
7dbc61a7914066a4df3f2bc9e69cd1d6bcd47754	iq level assessment methodology in robotic intervention with children with autism	pediatrics;atmospheric measurements;particle measurements;autism;service robots;autism humanoid robots service robots atmospheric measurements particle measurements pediatrics;humanoid robots;medical robotics humanoid robots;autism behavior iq level assessment methodology intelligence quotient brain developmental disorder repetitive stereotyped behavior communication difficulties social interaction humanoid form assistive tool child robot intervention program robot interaction sessions robot based intervention program rbip autistic children interaction modules autism characteristic;human robot interaction robotic social assistive therapy autism humanoid robot	This paper presents the assessment methodology to investigate relationship between Intelligence Quotient (IQ) of children with autism and their respective initial response during robotic intervention, compared to normal classroom interaction. Autism is a brain developmental disorder that leads to the irregular behavior in three common aspects; repetitive stereotyped behavior, communication difficulties, and social interaction. This research introduced robot in humanoid form as assistive tool in child-robot intervention program to investigate the relationship between IQ levels with response of the children in the robot interaction sessions. The Robot-Based Intervention Program (RBIP) is introduced to facilitate the experimental process. The autistic children interact with the robot and completing the interaction modules that has been designed and developed for them which is aimed to reduce the present of autism characteristic and behavior.	assistive technology;interaction;robot	Hanafiah Yussof;Syamimi Shamsuddin;Fazah Akhtar Hanapiah;Luthffi Idzhar Ismail;Mohd Azfar Miskam	2015	2015 10th Asian Control Conference (ASCC)	10.1109/ASCC.2015.7244914	psychology;simulation;developmental psychology;communication	Robotics	-55.05825821104185	-50.4305592594636	1919
6f9404ca11541f9a65ed2592af2bcedf123a8f33	how to merge three different methods for information filtering ?		Twitter is now a gold marketing tool for entities concerned with online reputation. To automatically monitor online reputation of entities , systems have to deal with ambiguous entity names, polarity detection and topic detection. We propose three approaches to tackle the first issue: monitoring Twitter in order to find relevant tweets about a given entity. Evaluated within the framework of the RepLab-2013 Filtering task, each of them has been shown competitive with state-of-the-art approaches. Mainly we investigate on how much merging strategies may impact performances on a filtering task according to the evaluation measure.	content-control software;entity;information filtering system;performance;reputation;unbalanced circuit	Jean-Valère Cossu;Ludovic Bonnefoy;Xavier Bost;Marc El-Bèze	2015	CoRR			Web+IR	-21.465967039503347	-56.56387588811559	1923
8b47932852df86232e7476392a52b1ee4e751aee	a novel e-commerce customer continuous purchase recommendation model research based on colony clustering		Customer purchasing behaviour in e-commerce platform has become uncertainty and jump affected by the contexts. Existing personalised recommendation models failed to deal with the problem well and they cause loss of customers constantly. This paper puts forward a novel model based on ant colony clustering algorithm to improve customersu0027 continuous purchase intention, including for customer interest is not drift and interest has already shifting. Firstly, for the research field of e-commerce, it gives definition and structured expression to contexts connotation. Secondly, for the problem that growing data sparseness in recommendation system, it introduces ant colony algorithm to cluster similar users in order to reduce the number of candidate neighbour sets and user similarity computing time. Thus, it can improve the target users of nearest neighbour search accuracy. On this basis, according to customer interest variation characteristics, we put forward the dynamic collaborative filtering recommendation alg...	cluster analysis;e-commerce	Qibei Lu;Feipeng Guo	2016	IJWMC	10.1504/IJWMC.2016.10003273	collaborative filtering;swarm intelligence;recommender system;ant colony optimization algorithms;e-commerce;metaheuristic;data mining;cluster analysis;computer science;purchasing	AI	-21.975010994284535	-47.90340343874716	1924
02233f15732129eaebfb029bba70b772a4426162	impact of the unknown communication channel on automatic speech recognition: a review kn-29	automatic speech recognition;communication channels	This review article summarizes the main difficulties encountered in Automatic Speech Recognition (ASR) when the type of communication channel is not known. This problem is crucial for the development of successful applications in promising domains such as computer telephony and cars. The main technical problems encountered are due to the speaker and the task (e.g. speaking style, Lombard reflex, vocal tract geometry), the use of microphones with different characteristics, the variable quality of the support channels (e.g. telephone channels are noisy and have different characteristics), reverberation and echoes, the variable distance and direction to the microphone introduced by hands-free recognition, and the ambient noise which distorts the input speech signals. This overview characterizes and emphasizes these problems and highlights some promising directions for future research. Finally, it presents an attempt to characterize the sensitivity of a phoneme recognizer as a function of the source of channel distortion, using the TIMIT database and several of its variants (NTIMIT, CTIMIT, FFMTIMIT).	channel (communications);digital single-lens reflex camera;distortion;finite-state machine;microphone;speech recognition;timit;tract (literature)	Jean-Claude Junqua	1997			speech recognition;artificial intelligence;voice activity detection;speaker recognition;acoustic model;distortion;review article;pattern recognition;computer science;speech processing;telephony;communication channel	AI	-13.081284059238728	-85.2640127775858	1925
ec137aa828766c28f353ae6095da427f19ae8c2e	on the genre-fication of music: a percolation approach (long version)	the european physical journal b;hidden variable theory;correlacion;renormalization group;shared memory;group structure;red www;memoria compartida;complex network;musica;condensed matter;percolacion;complex structure;reseau web;teoria variable escondida;acoustique musicale;cartographie;89 75 fb structures and organization in complex systems;journal;musical acoustics;musique;cartografia;phase transition;internet;percolation;64 60 ak renormalization group;complex system;acustica musical;and percolation studies of phase transitions;hidden variables;epj;theorie variable cachee;social organization;fractal;complex systems;cartography;world wide web;subdivision;correlation;89 65 ef social organizations;structure groupe;music;estructura grupo;anthropology;memoire partagee	In this paper, we analyze web-downloaded data on people sharing their music library. By attributing to each music group usual music genres (Rock, Pop...), and analysing correlations between music groups of different genres with percolation-idea based methods, we probe the reality of these subdivisions and construct a music genre cartography, with a tree representation. We also show the diversity of music genres with Shannon entropy arguments, and discuss an alternative objective way to classify music, that is based on the complex structure of the groups audience. Finally, a link is drawn with the theory of hidden variables in complex networks.	cartography;complex network;entropy (information theory);hidden variable theory;percolation;shannon (unit)	Renaud Lambiotte;Marcel Ausloos	2005	CoRR	10.1140/epjb/e2006-00115-0	complex systems;pop music automation;hidden variable theory;physics;quantum mechanics	Web+IR	-5.372131667853396	-31.31663128553344	1933
3b23fc4cca50bb99474aca04ba8ab60c6e51ff9f	developing business analytic capabilities for combating e-commerce identity fraud: a study of trustev's digital verification solution	social fingerprinting;online fraud detection;business analytics capabilities	Given the significant growth in e-commerce, organizations are seeking novel capabilities and technological innovations to deal simultaneously with the volume of data generated and the need to combat potentially damaging fraudulent activity. Although recent studies identify business analytics (BA) as a potential means of combating fraud, significant inroads into the interrelationships between capabilities and the articulation of a pathway to analytical capability have yet to be made. This study presents an investigation of Trustev, a global provider of digital verification technology, and its development of the profile-based social fingerprinting fraud detection solution. Adopting an interpretive structural modeling technique for data analysis, we construct a framework and reveal a road map for organizations to become analytically capable in online fraud detection. Our study adds to the discourse of the application of BA to combat online fraud.	e-commerce	Ter Chian Felix Tan;Zixiu Guo;Michael Cahalane;Daniel Cheng	2016	Information & Management	10.1016/j.im.2016.07.002	public relations;engineering;marketing;management;social psychology;world wide web;computer security	HCI	-79.79407474402389	-0.05029101971340578	1934
10a189136d01bb8b6b3d57303fe4cb0545204c10	what we know about the voynich manuscript	undeciphered document;current knowledge;voynich manuscript;linguistic property;medieval europe	The Voynich Manuscript is an undeciphered document from medieval Europe. We present current knowledge about the manuscriptu0027s text through a series of questions about its linguistic properties.	bigram;computational linguistics;decipherment;mathematical morphology;natural language;voynich manuscript	Sravana Reddy;Kevin Knight	2011			natural language processing;computer science;artificial intelligence	NLP	-31.737568002755623	-77.24971150696774	1939
365253bfd1b57236b1ea50d82869523c9085bab9	conceptual modeling of spatiotemporal database applications: an ontological view	null	Spatiotemporal databases have received much attention since more and more applications such as mobile computing and fleet management have urgent requirements on management of spatiotemporal information. Conceptual data modeling of spatiotemporal applications is used to describe user's cognition of real world phenomena and must support adequate concepts and notations with accurate semantics to allow the developer to capture and present spatiotemporal information. In this paper we propose a conceptual model for spatiotemporal data modeling, which is based on the ontology. The ontology for spatiotemporal changes and spatiotemporal entities are discussed. The conceptual model that we introduce in this paper utilizes Unified Modeling Language (UML) for handling spatiotemporal information, and it can describe spatiotemporal phenomenon effectively.	spatiotemporal database	Yuchang Gong;Lihua Yue;Peiquan Jin	2005			conceptual model;data mining;ontology;computer science;spatiotemporal database	DB	-35.7050929073342	-2.9794610937429464	1942
30fc251eefe47c6ab77b9b75cbfb4c01bcb23e99	lessons learned from a rational reconstruction of minstrel	procedural story generation;interactive storytelling	Scott Turner's 1993 Minstrel system was a high water mark in story generation, harnessing the concept of imaginative recall to generate creative stories. Using case based reasoning and an author level planning system, Minstrel models human creative processes. However, the algorithmic and representational commitments made in Minstrel were never subject to principled and quantitative analysis. By rationally reconstructing Minstrel, we are able to investigate Turner's computational model of creativity and learn new lessons about his architecture. We find that Minstrel's original performance was tied to a well groomed case library, but by modifying several components of the algorithm we can create a more general version which can construct stories using a sparser and less structured case library. Through a rational reconstruction of Minstrel, we both learn new architectural and algorithmic lessons about Minstrel’s computational model of creativity as well as make his architecture available to the contemporary research community for further experimentation.	algorithm;case-based reasoning;computation;computational model	Brandon Robert Tearse;Peter A. Mawhorter;Michael Mateas;Noah Wardrip-Fruin	2012			computer science;artificial intelligence	AI	-57.57568046989207	-30.695187884660587	1957
6978346ba28f5e698d5fd9c4cbb1f5f8e67f57be	an open-source acasi design for social collaborative mhealth	health informatics;collaborative internet;mhealth;androids humanoid robots mobile communication open source software smart phones collaboration informatics;social collaborative internet medical data information and communication technologies icts patient well being improvement social collaborative healthcare solutions mobile devices mhealth audio computer assisted self interview technology tablet touchscreen keypad android platform open source acasi;public domain software android operating system groupware health care internet keyboards mobile computing notebook computers patient care;acasi;cloud computing health informatics acasi mhealth collaborative internet;cloud computing	Trivial access to vast amounts of medical data, together with recent advances in information and communication technologies (ICTs), have collectively made it straightforward to help improve overall patient well-being. This in turn, can provide new and unique opportunities for social collaborative healthcare solutions using mobile devices (mHealth). One prominent example is Audio-Computer Assisted Self Interview (ACASI) technology, allowing respondents to listen to pre-recorded audio questions, while simultaneously reading survey questions, and providing responses using a tablet touchscreen or keypad. Although several ACASI alternatives exist for mHealth, they are proprietary, limited in features, and are not available on the popular Android platform. In this paper, we discuss alternatives for implementing an open-source ACASI solution on Android, and identify key features of ACASI systems for social collaborative Internet, and also outline a model for implementation with four particular alternatives.	android;cloud computing;freedom of information laws by country;informatics;mhealth;mobile device;open-source software;smartphone;tablet computer;touchscreen	Saranya Radhakrishnan;Zachary Stecher;Deger Cenk Erdil	2016	2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)	10.1109/COMPSAC.2016.61	health informatics;human–computer interaction;cloud computing;computer science;operating system;multimedia;world wide web;computer security	HCI	-60.41573620478679	-56.372222187708815	1958
d9e45182f059012ffbe366522bb576bb67998e3c	hermitian based hidden activation functions for adaptation of hybrid hmm/ann models		This work is concerned with speaker adaptation techniques for artificial neural network (ANN) implemented as feed-forward multi-layer perceptrons (MLPs) in the context of large vocabulary continuous speech recognition (LVCSR). Most successful speaker adaptation techniques for MLPs consist of augmenting the neural architecture with a linear transformation network connected to either the input or the output layer. The weights of this additional linear layer are learned during the adaptation phase while all of the other weights are kept frozen in order to avoid over-fitting. In doing so, the structure of the speakerdependent (SD) and speaker-independent (SI) architecture differs and the number of adaptation parameters depends upon the dimension of either the input or output layers. We propose an alternative neural architecture for speaker-adaptation to overcome the limits of current approaches. This neural architecture adopts hidden activation functions that can be learned directly from the adaptation data. This adaptive capability of the hidden activation function is achieved through the use of orthonormal Hermite polynomials. Experimental evidence gathered on the Wall Street Journal Nov92 task demonstrates the viability of the proposed technique.	activation function;artificial neural network;hermite polynomials;hidden markov model;layer (electronics);multilayer perceptron;overfitting;polynomial;speech analytics;speech recognition;the wall street journal;vocabulary	Sabato Marco Siniscalchi;Jinyu Li;Chin-Hui Lee	2012			artificial intelligence;artificial neural network;speech recognition;perceptron;architecture;hermite polynomials;pattern recognition;hidden markov model;linear map;computer science;orthonormal basis;activation function	ML	-17.288294301309787	-89.11134910585334	1965
f136e17e3ca8ea4446ca6b737d0b14745bacf9ef	tensor-train recurrent neural networks for video classification		The Recurrent Neural Networks and their variants have shown promising performances in sequence modeling tasks such as Natural Language Processing. These models, however, turn out to be impractical and difficult to train when exposed to very high-dimensional inputs due to the large input-to-hidden weight matrix. This may have prevented RNNs’ large-scale application in tasks that involve very high input dimensions such as video modeling; current approaches reduce the input dimensions using various feature extractors. To address this challenge, we propose a new, more general and efficient approach by factorizing the input-to-hidden weight matrix using Tensor-Train decomposition which is trained simultaneously with the weights themselves. We test our model on classification tasks using multiple real-world video datasets and achieve competitive performances with state-of-the-art models, even though our model architecture is orders of magnitude less complex. We believe that the proposed approach provides a novel and fundamental building block for modeling highdimensional sequential data with RNN architectures and opens up many possibilities to transfer the expressive and advanced architectures from other domains such as NLP to modeling highdimensional sequential data.	artificial neural network;autoencoder;code;commodity computing;encoder;end-to-end encryption;end-to-end principle;experiment;feature extraction;https;long short-term memory;mobile device;natural language processing;neural networks;performance;pixel;random neural network;recurrent neural network;simulation;unit testing;video clip	Yinchong Yang;Denis Krompass;Volker Tresp	2017			artificial intelligence;tensor;theoretical computer science;architecture;video modeling;machine learning;computer science;pattern recognition;recurrent neural network;matrix (mathematics)	ML	-14.57683404168812	-71.69599234277536	1976
74d6361cebb53002863fd32b161190bd2dd63b11	perceptual properties of current speech recognition technology	speech recognition resonant frequency auditory system feature extraction cavity resonators educational institutions;human auditory system perceptual property speech recognition technology feature extraction procedures automatic speech recognition systems asr systems human auditory processing human auditory perception reverse route engineering techniques;speech recognition auditory perception feature extraction;feature extraction;speech recognition;hearing;speech recognition feature extraction hearing	In recent years, a number of feature extraction procedures for automatic speech recognition (ASR) systems have been based on models of human auditory processing, and one often hears arguments in favor of implementing knowledge of human auditory perception and cognition into machines for ASR. This paper takes a reverse route, and argues that the engineering techniques for automatic recognition of speech that are already in widespread use are often consistent with some well-known properties of the human auditory system.	automatic system recovery;cognition;feature extraction;speech recognition	Hynek Hermansky;Jordan Cohen;Richard M. Stern	2013	Proceedings of the IEEE	10.1109/JPROC.2013.2252316	voice activity detection;speech technology;speech recognition;acoustics;feature extraction;computer science;neurocomputational speech processing;speech processing;computational auditory scene analysis	Security	-11.946778867773668	-86.09899313010023	1980
ac33fc102c98b00629acc23509b5aeb734016f19	kevin mandia, chris prosise - incident response: computer forensics, 2nd ed				Anton Chuvakin	2004	;login:			ECom	-58.38979623758802	-5.249334697604642	1982
d8960606c0eb6dc6d93c0ee658207573b838faa6	making: on being and becoming expert		Making is considered to be democratizing technology design and production. Yet, in many cases, in order to be a successful maker or have a rewarding maker experience, participants/makers need to bring in some form of expertise, creating both implicit and explicit barriers for differentiated publics to take part. We explore the literature and existing scholarship regarding expertise and making, using it to briefly contextualize our own research into maker programs in U.S. Libraries and design-focused fab labs. Both cases illustrate how the acquisition of expertise is also affected by community and learning environment dynamics. Through discussion we critically engage how mundane aspects of infrastructure relate to maker notions of expertise, the Maker Movement’s claims of broad participation toward democratization, and the contextual dimensions of expertise.	fab lab;semiconductor fabrication plant	Yana Boeva;Ellen Foster	2016	IxD&A		systems engineering;political science;becoming	HCI	-64.46173771387339	-34.461445608998574	1983
53882810c39ac014e9aed76cf13809936ec34d35	internet adoption in macao	household income;mass media;internet use;expected value;telephone survey;perceived value;family functioning	Based on the data from a telephone survey of 868 Macao residents conducted in Macao with 330 Internet users and 538 non-users, this paper examines the characteristics of the users and non-users in terms of their demographics, assessments on media credibility, family functioning, media use, and perceived values of the Internet. Drawing from the literature of diffusion, expectancy-value and media substitution theories, it investigates the relations between Internet use and its potential predictors. The results confirmed the conclusions of previous adoption studies that Internet users were more likely to be male, younger, better educated and with higher monthly household income than non-users. The study also found that demographic variables such as education, sex and income, as well as doing exercise were the significant predictors of Internet use. However, no traditional mass media use variables and perceived values of the Internet were found to be significant predictors.	internet;significant figures;theory	Weng Hin Cheong	2002	J. Computer-Mediated Communication	10.1111/j.1083-6101.2002.tb00140.x	sociology;social psychology;expected value;statistics;mass media	HCI	-86.36885784824712	-22.295610901987143	1987
2f02a9d4c9025b6b84d123dcb4e0bd6f4cd9e831	the role of user review on information system project outcomes: a control theory perspective	control theory;information system	The effect of user participation on system success is one of the most studied topics in information systems, yet still yields inconclusive results. Contingency-based concepts attempt to resolve this issue by providing a plausible explanation which indicates that users can only generate expected results when there is a need for users to participate in the development process. As a different approach, this study adopts a mediating perspective and asserts that influence due to the effectiveness of participation determines the final outcomes. Based on control theory, and viewing user participation in reviews as one kind of control, we propose that the influence users can generate through participation determines project outcomes. Data collected from 151 information systems personnel confirms the relationships and that an ability to achieve quality interactions among developers and users heightens the achievement of user influence. DOI: 10.4018/978-1-4666-0930-3.ch013	control theory;information system;interaction;user review	Jack Shih-Chieh Hsu;Houn-Gee Chen;James J. Jiang;Gary Klein	2010	IJITPM	10.4018/jitpm.2010100201	public relations;economics;engineering;management science;management;information system	HCI	-87.20041565922523	-2.0116351580068432	1994
8a292ff11537c97b0a194316fac55509b34628b6	matching recommendation technologies and domains	research and development;recommender system	Recommender systems form an extremely diverse body of technologies and approaches. The chapter aims to assist researchers and developers identify the recommendation technology that are most likely to be applicable to different domains of recommendation. Unlike other taxonomies of recommender systems, our approach is centered on the question of knowledge: what knowledge does a recommender system need in order to function, and where does that knowledge come from? Different recommendation domains (books vs condominiums, for example) provide different opportunities for the gathering and application of knowledge. These considerations give rise to a mapping between domain characteristics and recommendation technologies.	book;google summer of code;intelligent user interface;recommender system;thomas j. watson research center;watson (computer)	Robin D. Burke;Maryam Ramezani	2011		10.1007/978-0-387-85820-3_11	marketing;world wide web;information retrieval	AI	-71.48113102140817	-18.05151220455652	2001
1e7c73ca0430234abbaba074303a1a933257aecc	a semantic approach to build personalized interfaces in the cultural heritage domain	semantic representation;interaction styles;integrable system;interactive interfaces;cultural heritage;user centered design;digital archive;visual querying;human factors;interactive application;interfaces for cultural heritage;panoramic image;visual interfaces;visual interface design;graphical user intervaces	"""In this paper we present a system we have built to disseminate cultural heritage distributed across multiple museums. Our system addresses the requirements of two categories of users: the end users that need to access information according to their interests and interaction preferences, and the domain experts and museum curators that need to develop thematic tours providing end users with a better understanding of the single artefact or collection. In our approach we make use of a semantic representation of the given heritage domain in order to build multiple visual interfaces, called """"Virtual Wings"""" (VWs). Such interfaces allow users to navigate through data available from digital archives and thematic tours and to create their own personalized virtual visits. An interactive application integrating personalized digital guides (using PDAs) and 360 panoramic images is the example of VW presented."""	archive;personal digital assistant;personalization;requirement	Stefano Valtolina;Pietro Mazzoleni;Stefano Franzoni;Elisa Bertino	2006		10.1145/1133265.1133328	integrable system;user-centered design;human–computer interaction;computer science;cultural heritage;human factors and ergonomics;multimedia;world wide web	HCI	-40.49692984430459	-25.66877227138209	2008
a2edcf3446c5bb433fca3d6b8429205e5fd19816	designing, developing, and deploying systems to support human-robot teams in disaster response	human computer interaction;disaster response;collaborative robots;intelligent robots;human robot team;pcs perceptual and cognitive systems;robot assisted disaster response;structure damage assessment;robotics;human robot interaction;elss earth life and social sciences;user centric designs;damage detection;collaborative planning;intelligent buildings;human performances;machine design;user centric design;robots;situation awareness;robot programming;disasters;situational assessment;emergency services	G.J.M. Kruijff, I. Kruijff-Korbayováa∗, S. Keshavdas, B. Larochelle, M. Jańıček F. Colas, M. Liu, F. Pomerleau, R. Siegwart M.A. Neerincx, R. Looije, N.J.J.M Smets, T. Mioch, J. van Diggelen F. Pirri, M. Gianni, F. Ferri, M. Menna R. Worst, T. Linder, V. Tretyakov, H. Surmann T. Svoboda , M. Reinstein , K. Zimmermann , T. Petř́ıček , V. Hlaváč DFKI, Saarbrücken, Germany; ASL, ETH, Zurich, Switzerland; TNO, Soesterberg, The Netherlands; ALCOR, Sapienza University, Rome, Italy; Fraunhofer IAIS, Sankt Augustin, Germany; Department of Cybernetics, CTU, Prague, Czech Republic	alcor;autonomous system (internet);autonomy;biocybernetics;cloud computing;cognitive engineering;cognitive ergonomics;cognitive robotics;cognitive science;computer vision;cybernetics;dialog system;diploma in computer science;embedded system;experiment;francis;freedom of information laws by country;general material designation;german research centre for artificial intelligence;google scholar;human-centered computing;humans;human–robot interaction;linear algebra;machine perception;natural language processing;natural language understanding;omnidirectional camera;persistence (computer science);programming paradigm;real life;robot;scsi initiator and target;sensor;situated;software deployment;software engineering;theory;unmanned aerial vehicle	Geert-Jan M. Kruijff;Ivana Kruijff-Korbayová;Shanker Keshavdas;Benoit Larochelle;Miroslav Janícek;Francis Colas;Ming Liu;François Pomerleau;Roland Siegwart;Mark A. Neerincx;Rosemarijn Looije;Nanja J. J. M. Smets;Tina Mioch;Jurriaan van Diggelen;Fiora Pirri;Mario Gianni;Federico Ferri;Matteo Menna	2014	Advanced Robotics	10.1080/01691864.2014.985335	robot;situation awareness;user-centered design;disaster;simulation;human–computer interaction;computer science;engineering;knowledge management;artificial intelligence;robotics	AI	-48.72440573743589	-10.368281435548335	2009
8bbb1bcb01b8c0f5efce9c058fe169175aab22c5	learning-to-rank and relevance feedback for literature appraisal in empirical medicine		The constantly expanding medical libraries contain immense amounts of information, including evidence from healthcare research. Gathering and interpreting this evidence can be both challenging and time-consuming for researchers conducting systematic reviews. Technologically assisted review (TAR) aims to assist this process by finding as much relevant information as possible with the least effort. Toward this, we present an incremental learning method that ranks documents, previously retrieved, by automating the process of title and abstract screening. Our approach combines a learning-to-rank model trained across multiple reviews with a model focused on the given review, incrementally trained based on relevance feedback. The classifiers use as features several similarity metrics between the documents and the research topic, such as Levensthein distance, cosine similarity and BM25, and vectors derived from word embedding methods such as Word2Vec and Doc2Vec. We test our approach using the dataset provided by the Task II of CLEF eHealth 2017 and we empirically compare it with other approaches participated in the task.	artificial neural network;convolutional neural network;cosine similarity;learning to rank;library (computing);recurrent neural network;relevance feedback;systematic review;word embedding;word2vec	Athanasios Lagopoulos;Antonios Anagnostou;Adamantios Minas;Grigorios Tsoumakas	2018		10.1007/978-3-319-98932-7_5	word2vec;information retrieval;ehealth;learning to rank;word embedding;systematic review;levenshtein distance;relevance feedback;computer science;cosine similarity	NLP	-45.41342857376867	-69.67309743919618	2023
74b41ba1609492bedf17da068ada8a1fb9bd8e6c	the perceived uniqueness of the is profession: the role of gender	bepress selected works;gender;is workforce;professional identity	This research investigated gender differences in the characteristics IS managers perceive to be unique to the IS profession. An interpretivist perspective, qualitative data collection (i.e., focus group interviews) and the revealed causal mapping data analysis method were used to evoke and represent mental models (i.e., cognitive structures) of men and women in the IS field regarding the unique characteristics of their profession. By comparing these mental models we uncovered different strategic views of professional identity within our participants. A lack of consistency in how IS professional identity is conceptualized could lead to a fragmented sense of professional community and disengagement at the individual level.	americas conference on information systems;causal filter;focus group;mental model;type physicalism	Deborah J. Armstrong;Margaret F. Reid;Cynthia K. Riemenschneider;David L. Gomillion	2011			public relations;political science;management;pedagogy	HCI	-82.42005295348007	-2.4702618847511064	2025
e00033f080fa620fe4b14cff7cf78dfd83d16895	conceptualizing a desktop environment for cognitively challenged people	disabilities;human computer interaction;accessibility;cognitively impaired;desktop;open source	In India as well as in different parts of the world, a large section of society suffers from different kinds of disabilities. These difficulties impose certain constraints on people suffering with them in following their routine life as compared to normal persons. Of these difficulties, cognitive disability is one of the most difficult to address. This disability relates to different kinds of problems with brain like amnesia, learning disability, attention problems etc. The type and nature of problem may vary from person to person. Common symptoms like slow grasping, longer response time and distraction in nature have been identified by observing the affected users at various rehabilitation centers. Using ICT based solutions, life can be made better for such persons. Computers can assist them in different ways in rehabilitation and enhancing their quality of life. The aim of this paper is to highlight the issues and challenges faced by cognitively impaired persons in using computers and to propose solution(s) so that computer usage will be easy for them. An accessible desktop environment with relevant features is conceptualized that will help user in smooth interaction with computer without distraction. Specific features of the proposed desktop are focused primarily on memory and attention based issues and provides support for affected users, parents/caretakers and teachers. The proposed solution is validated with and impacts of design have been collected from the relevant stack holders such as end users, caretakers and parents. All enhancements are done on open source operating system environment and are available as open source. This paper discusses the system and the rationale for the various features incorporated.	amnesia: the dark descent;design rationale;desktop computer;environment variable;open-source software;operating system;response time (technology)	Shiv Nath Kumar;Sagun Baijal;Leena Chourey;Aparna Ramamurthy;M. Sasikumar	2012		10.1145/2381716.2381785	psychology;simulation;human–computer interaction;multimedia	HCI	-62.056444557244376	-54.247789975150106	2026
14669beaeab11d860d146e2f19b870237a524589	some brief remarks on information and consciousness.				George L. Farre	1997	Informatica (Slovenia)		cognitive science	NLP	-53.58109993866208	-20.188477164066672	2036
527066de3c38bf42e7ba34f175a53cdec28b221e	a practical application of argumentation in french agrifood chains		Evaluating food quality is a complex process since it relies on numerous criteria historically grouped into four main types: nutritional, sensorial, practical and hygienic qualities. They may be completed by other emerging preoccupations such as the environmental impact, economic phenomena, etc. However, all these aspects of quality and their various components are not always compatible and their simultaneous improvement is a problem that sometimes has no obvious solution, which corresponds to a real issue for decision making. This paper proposes a decision support method guided by the objectives defined for the end products of an agrifood chain. It is materialized by a backward chaining approach based on argumentation.		Madalina Croitoru;Rallou Thomopoulos;Nouredine Tamani	2014		10.1007/978-3-319-08795-5_7	argumentation theory;argumentation framework;management science;reverse engineering;decision support system;food quality;backward chaining;computer science	NLP	-16.99302717154101	-3.0265802090785896	2046
64f39ddbfb0e9ebb5514866b2657a3c0c9c44c13	find, identify, select...socialize?: alternative objectives of library catalogs	history;library catalogs;cataloging	Throughout history, library catalogs have served various purposes, yet most formal statements of catalog objectives focus on inventory and holdings. As contemporary libraries face questions about the continued relevance of the library catalog, these purposes inspire reexamination. This poster presents a historical review of library catalogs with emphasis on purposes, as well as a review of proposals for alternatives to these extant objectives in order to inform future catalog design and library advocacy.	library (computing);relevance;socialization	Rachel Ivy Clarke	2014		10.1002/meet.2014.14505101076	data science;world wide web;library catalog	PL	-65.68801210472407	-11.720146431977932	2048
295059fc46e8ddd18717b2f1b24942450bddff42	a neural model of landmark navigation in insects	neural model;snapshot model;insect navigation;landmark guidance	Central-place foragers like bees use landmark-based infor mation in order to return to important locations. Experiments revealed that the insects s tore a “snapshot image” of the surroundings of the target location and derive a home direct ion by comparing current image and snapshot. A corresponding algorithmic model, the so -called “snapshot model”, was proposed by Cartwright and Collett (1983). Here we present a neural architecture derived from this model that demonstrates how visual landmark navig ation could be implemented in the insect’s brain. The neural model closely resembles th snapshot model on both the functional and the behavioral level.	occam's razor;snapshot (computer storage);xfig	Ralf Möller;Marinus Maris;Dimitrios Lambrinos	1999	Neurocomputing	10.1016/S0925-2312(98)00150-7	computer vision	AI	-8.995452321558904	-52.071685594060106	2050
6b69186caf5b3471355379ba8d31f0bcf8974cf1	student-generated content improves online learning of programming		Quality learning content for online courses is difficult and time-consuming to create, and therefore students are increasingly employed to create learning content for use by their peers. Student-generated content however may be low quality and consequently of uncertain utility. The authors present a successful approach for improving online learning of programming through student-generated content â€“ community tests that help other students in solving programming exercises. In their approach, the tests simplify student work on solving exercises, and the learning system can automatically provide focused help to each struggling student. They evaluated the proposed solution in an existing online learning system for programming in university programming courses. Results indicate that students used the proposed features often, and when examining the impact on learning performance, the active students showed improved performance compared to inactive students. Social awareness in online setting was evaluated using a questionnaire.		Jozef Tvarozek;Peter Jurkovic	2016	IJHCITP	10.4018/IJHCITP.2016100106	cooperative learning;simulation;computer science;multimedia;active learning;active learning;synchronous learning;pedagogy	ML	-77.81224682872366	-41.47131449632228	2051
9f1462f1aab465dd4bb6d861d1650c94f45e6815	exploiting data reliability and fuzzy clustering for journal ranking	dk atira pure researchoutput researchoutputtypes contributiontojournal article;open wireless architecture measurement robustness pragmatics computers computer science;journal ranking;owa;fuzzy clustering;era journal ranking fuzzy clustering aggregation of indicators owa data reliability;data reliability;era;aggregation of indicators	Journal impact indicators are widely accepted as possible measurements of academic journal quality. However, much debate has recently surrounded their use, and alternative journal impact evaluation techniques are desirable. Aggregation of multiple indicators offers a promising method to produce a more robust ranking result, avoiding the possible bias caused by the use of a single impact indicator. In this paper, fuzzy aggregation and fuzzy clustering, especially the ordered weighted averaging (OWA) operators are exploited to aggregate the quality scores of academic journals that are obtained from different impact indicators. Also, a novel method for linguistic term-based fuzzy cluster grouping is proposed to rank academic journals. The paper allows for the construction of distinctive fuzzy clusters of academic journals on the basis of their performance with respect to different journal impact indicators, which may be subsequently combined via the use of the OWA operators. Journals are ranked in relation to their memberships in the resulting combined fuzzy clusters. In particular, the nearest-neighbor guided aggregation operators are adopted to characterize the reliability of the indicators, and the fuzzy clustering mechanism is utilized to enhance the interpretability of the underlying ranking procedure. The ranking results of academic journals from six subjects are systematically compared with the outlet ranking used by the Excellence in Research for Australia, demonstrating the significant potential of the proposed approach.	aggregate data;cluster analysis;data redundancy;fuzzy clustering;fuzzy set;ordered weighted averaging aggregation operator	Pan Su;Changjing Shang;Tianhua Chen;Qiang Shen	2017	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2016.2612265	impact evaluation;artificial intelligence;fuzzy logic;machine learning;robustness (computer science);fuzzy clustering;data mining;journal ranking;ranking;cluster grouping;excellence;computer science	Web+IR	-5.264870884600155	-21.424766936159116	2052
9ac7b520e7b6d0ca3ef8370f3815790b97c8b790	implementing data event triggers with standard-based document exchange to improve timely communication for referring providers			data event	Darren K. Mann;Shan He;Jennifer Nelson;Gary Anderson;Sidney N. Thornton	2017				DB	-60.34607307332983	1.661413743028217	2066
0c093e87ea993bc42d6dde4737be54f45dcb0cba	virtual multimedia libraries built from the web	libraries;virtual library;multimedia;information retrieval;captions;conference paper;audio;indexation;world wide web;video;images;neural network;expert system	We have developed a tool MARIE-4 for building virtual libraries of multimedia (images, video, and audio) by automatically exploring (crawling) a specified subdomain of the World Wide Web to create an index based on caption keywords. Our approach uses carefully-researched criteria to identify and rate caption text, and employs both an expert system and a neural network. We have used it to create a keyword-based interface to nearly all nontrivial captioned publicly-accessible U.S. Navy images (667,573), video (8,290), and audio (2,499), called the Navy Virtual Multimedia Library (NAVMULIB).	artificial neural network;expert system;library (computing);multimedia library;world wide web	Neil C. Rowe	2002		10.1145/544220.544251	video;computer science;multimedia;world wide web;expert system;information retrieval	HCI	-14.03038144702605	-57.2008521433948	2074
c99224aa614d4c4e791105fcf0f6bb7ffe537025	designing a computer game to teach einstein's theory of relativity	serious games;games to teach;interactive game environment;high school students;teaching computer animation computer games courseware physics computing physics education special relativity;physics computing;relativistic visualisation;play mechanics;physics education;einsteins theory of relativity teaching;physics;relativistic visualisation serious games games to teach physics relativity;play mechanics computer game einsteins theory of relativity teaching interactive game environment asteroids styled game high school students graphics animations;special relativity;animations;computer application;high school student;asteroids styled game;game theory physics focusing visualization computational modeling computer applications buildings relativistic effects educational institutions computer graphics;computer animation;computer games;courseware;relativity;serious game;graphics;computer game;teaching	This paper describes an ongoing project to build a computer application that presents Einstein's theory of relativity in an interactive game environment. With the current interest in the use and study of how computer games can help teach and educate, so-called 'serious games', the resulting game is expected to have value for educators in communicating the concepts of relativity to high school students as well as introducing the topic to a wider audience. The focus of this paper is on the initial design and building of an asteroids-styled game and describes features of the physics, graphics and animations, and play mechanics. Directions for future development and studies are discussed.	arcade game;game mechanics;game physics;graphics;numerical relativity;pc game;video game design	David Nicholas Carr;Terry Bossomaier;Ken Lodge	2007	Computer Graphics, Imaging and Visualisation (CGIV 2007)	10.1109/CGIV.2007.35	game design;simulation;applied mathematics;computer science;game mechanics;game art design;multimedia;simulations and games in economics education;game design document	HCI	-85.39357146675684	-38.18334516460471	2077
380cf29ad53935f7f914b2f95cc1cde1b7f28bbc	ontology: its transformation from philosophy to information systems	representation;information systems;ontology of information systems;it adoption;philosophy;information system;description;ontology	It is no secret that the multidisciplinary sphere of informationsystems has borrowed the term 'ontology' from philosophy, andreinterpreted it to be more suitable for information systems.However, there is some disagreement about what thisreinterpretation should be. This paper examines two prominent anddistinct views on what information systems ontology is, andattempts to advance a unified definition that can be understoodinterdisciplinarily. But the goal of this paper is to show thespecific points of variance between information systems ontologyand philosophical ontology in order to shed light on thetransformation of the term 'ontology' in its adoption by theinformation systems community. The relatively new informationsystems ontology is facing great challenges that may be betterconfronted with the insights that can be discovered throughphilosophical ontology.	information system	Gloria L. Zúñiga	2001		10.1145/505168.505187	upper ontology;ontology alignment;ontology components;bibliographic ontology;epistemology;computer science;knowledge management;ontology;ontology;data mining;ontology-based data integration;information retrieval;process ontology;information system;suggested upper merged ontology	AI	-77.76130066271527	-2.134548362009882	2082
99c2ff990d40bcf3dc7a5628295c25cfcf11c554	08471 report - geographic privacy-aware knowledge discovery and delivery				Bart Kuijpers;Dino Pedreschi;Yücel Saygin;Stefano Spaccapietra	2008			knowledge management;knowledge extraction;business	ML	-39.2759589228809	-4.283490821165288	2085
2b7a1937a0e05db038024ba17848a789c6353d44	corporate governance: information security the weakest link?	information security;corporate governance	Information is an important asset of any organisation and the protection of this asset, through information security is equally important. This paper examines the relationship between corporate governance and information security and the fact that top management is responsible for high-quality information security.	corporate governance;information security	Kerry-Lynn Thomson	2002			corporate governance;stakeholder;security convergence;information governance;computer science;information security;corporate security;computer security	Security	-71.22995080995311	-7.0404995184459755	2086
39111b619ff3cfdb886388bd158e62f7e078853f	efficient xml keyword search: from graph model to tree model	graph search;structured queries;graph traversals;labeling techniques;orders of magnitude;graph search methods;xml keyword searches;reference relationships;keyword queries;indexing technique	Keyword search, as opposed to traditional structured query, has been becoming more and more popular on querying XML data in recent years. XML documents usually contain some ID nodes and IDREF nodes to represent reference relationships among the data. An XML document with ID/IDREF is modeled as a graph by existing works, where the keyword query results are computed by graph traversal. As a comparison, if ID/IDREF is not considered, an XML document can be modeled as a tree. Keyword search on XML tree can be much more efficient using tree-based labeling techniques. A nature question is whether we need to abandon the efficient XML tree search methods and invent new, but less efficient search methods for XML graph. To address this problem, we propose a novel method to transform an XML graph to a tree model such that we can exploit existing XML tree search methods. The experimental results show that our solution can outperform the traditional XML graph search methods by orders of magnitude in efficiency while generating a similar set of results as existing XML graph search methods.	efficient xml interchange;graph traversal;search algorithm;tree traversal;xml tree	Yong Zeng;Zhifeng Bao;Tok Wang Ling;Guoliang Li	2013		10.1007/978-3-642-40285-2_5	xml catalog;xml validation;xml namespace;simple api for xml;computer science;document structure description;xml framework;data mining;xml database;xml schema;database;xml signature;orders of magnitude;graph database;information retrieval;efficient xml interchange	DB	-8.87200775435464	-39.89578073094729	2087
9f6336ee2b5113110312d7c61b9cfc6ec08af273	leveraging physical human actions in large interaction spaces	multiuser interaction;data manipulation;wall sized displays	"""Large interaction spaces such as wall-size displays allow users to interact not only with their hands, like traditional desktop environment, but also with their whole body by, e.g. walking or moving their head orientation. While this is particularly suitable for tasks where users need to navigate large amounts of data and manipulate them at the same time, we still lack a deep understanding of the advantages of large displays for such tasks. My dissertation begins with a set of studies to understand the benefits and drawbacks of a high-resolution wall-size display vs. a desktop environments. The results show strong benefits of the former due to the flexibility of """"physical navigation"""" involving the whole body when compared with mouse input. From whole-body interaction to human-to-human interaction, my current work seeks to leverage natural human actions to collaborative contexts and to design interaction techniques that detects gestural interactions between users to support collaborative data exchange."""	computer mouse;desktop computer;image resolution;interaction technique	Can Liu	2014		10.1145/2658779.2661165	simulation;data manipulation language;human–computer interaction;computer science	HCI	-46.0020643245941	-40.54163382010298	2095
37a43b733f0f35aacbc4956a3641c4d1443a3e23	in my ‘mind’s eye’: introspectionism, detectivism, and the basis of authoritative self-knowledge	specious present;humanidades;self knowledge;detectivism;same order view;frist person authority;filosofia etica;introspectionism;constitutivism;authoritative self knowledge;introspection	It is widely accepted that knowledge of certain of one’s own mental states is authoritative in being epistemically more secure than knowledge of the mental states of others, and theories of self-knowledge have largely appealed to one or the other of two sources to explain this special epistemic status. The first, ‘detectivist’, position, appeals to an inner perception-like basis, whereas the second, ‘constitutivist’, one, appeals to the view that the special security awarded to certain self-knowledge is a conceptual matter. I argue that there is a fundamental class of cases of authoritative self-knowledge, ones in which subjects are consciously thinking about their current, conscious intentional states, that is best accounted for in terms of a theory that is, broadly speaking, introspectionist and detectivist. The position developed has an intuitive plausibility that has inspired many who work in the Cartesian tradition, and the potential to yield a single treatment of the basis of authoritative self-knowledge for both intentional states and sensation states.	cartesian closed category;consciousness;introspection;mental state;plausibility structure;theory	Cynthia Macdonald	2014	Synthese	10.1007/s11229-014-0487-1	specious present;introspection;self-knowledge;philosophy;epistemology;mathematics	AI	-25.731993606178456	-12.637948942152494	2108
81b99a0f2667fb598914233e9ec87c5c32dc3d56	symbols, neurons, soap-bubbles and the neural computation underlying cognition	symbolic dynamics;neural network	A wide range of systems appear to perform computation: what common features do they share? I consider three examples, a digital computer, a neural network and an analogue route finding system based on soap-bubbles. The common feature of these systems is that they have autonomous dynamics — their states will change over time without additional external influence. We can take advantage of these dynamics if we understand them well enough to map a problem we want to solve onto them. Programming consists of arranging the starting state of a system so that the effects of the system's dynamics on some of its variables corresponds to the effects of the equations which describe the problem to be solved on their variables. The measured dynamics of a system, and hence the computation it may be performing, depend on the variables of the system we choose to attend to. Although we cannot determine which are the appropriate variables to measure in a system whose computation basis is unknown to us I go on to discuss how grammatical classifications of computational tasks and symbolic machine reconstruction techniques may allow us to rule out some measurements of a system from contributing to computation of particular tasks. Finally I suggest that these arguments and techniques imply that symbolic descriptions of the computation underlying cognition should be stochastic and that symbols in these descriptions may not be atomic but may have contents in alternative descriptions.	artificial neural network;autonomous robot;cognition;computation;computer	Robert W. Kentridge	1994	Minds and Machines	10.1007/BF00974169	symbolic dynamics;symbolic computation;computer science;artificial intelligence;theoretical computer science;machine learning;artificial neural network;algorithm	AI	-23.21005068311679	-17.24617566807457	2110
e5669e89f95b81b96be5164c79e5b6ddc56f2e51	2018 ieee international conference on sensing, communication and networking, secon workshops 2018, hong kong, hong kong, june 11, 2018					2018				Robotics	-55.3313536394698	-5.54561720661188	2113
bae2730d4ae8e7556ab1321972aae78f12630e2f	an investigation of transformation-based learning in discourse	decision tree;confidence measure;monte carlo;transformation based learning;natural language processing	This paper presents results from the first attempt to apply Transformation-Based Learning to a discourse-level Natural Language Processing task. To address two limitations of the standard algorithm, we developed a Monte Carlo version of TransformationBased Learning to make the method tractable for a wider range of problems without degradation in accuracy, and we devised a committee method for assigning confidence measures to tags produced by Transformation-Based Learning. The paper describes these advances, presents experimental evidence that TransformationBased Learning is as effective as alternative approaches (such as Decision Trees and N-Grams) for a discourse task called Dialogue Act Tagging, and argues that Transformation-Based Learning has desirable features that make it particularly appealing for the Dialogue Act Tagging task.	algorithm;cobham's thesis;decision tree;elegant degradation;grams;monte carlo method;natural language processing	Ken Samuel;Sandra Carberry;K. Vijay-Shanker	1998			semi-supervised learning;natural language processing;unsupervised learning;multi-task learning;algorithmic learning theory;computer science;artificial intelligence;machine learning;decision tree;linguistics;id3 algorithm;active learning;statistics;monte carlo method;generalization error	ML	-20.74559750525643	-71.0164559854425	2116
2a36f36f5fc573620ec5b7e578e0883d0c6c515c	extending e-books with annotation, online support and assessment mechanisms to increase efficiency of learning	study design;mark;teaching and learning;annotation;learning support;learning support network;human resource;performance analysis;discussion forum;timing analysis;e book reading;performance prediction	The Internet and web environment allow readers to read online many multimedia books. Readers can annotate, collaborate, and discuss content using efficient reading functions. Reading is migrating from printed books to e-books. This study designs an online reading environment with a wide range of support to increase students' learning performance. Online knowledge and human resources are used to answer directly students' queries. Students' annotating behaviors are analyzed as to help them understand the results of their learning earlier on. Experimental results reveal the extent to which students' reading behaviors shift from the printed book to this system using online reading time analysis. Data and questionnaire results show that students think that the system is conveniently and efficiently for them to annotate and propose query strings to knowledge repository and to discussion forum. In assessing reading performance, analysis of students' annotation results can forecast examination grades with 75.5 accuracy. Such analysis helps teachers and students to increase teaching and learning efficiencies.	book;e-book;internet;printing;query string	Chin-Yeh Wang;Gwo-Dong Chen	2004		10.1145/1007996.1008032	human resources;computer science;data science;multimedia;clinical study design;world wide web;static timing analysis	HCI	-77.86814909496974	-41.681359250117076	2120
548a81512547d6abe2fbc220a5dcf3b2fab5b758	impact &amp; contributions of mbase on software engineering graduate courses	home computing;software engineering education mbase software engineering graduate courses;software systems;computer industry;null;software engineering;software engineering education;computer architecture;computer science education;mbase;software engineering software systems spirals programming computer science education computer architecture computer industry computer science educational technology home computing;software engineering graduate courses;educational courses;spirals;software development;computer science;educational technology;programming;software engineering computer science education educational courses	As the founding Director of the Center for Software Engineering, Professor Barry W. Boehm developed courses that have greatly impacted the education of software engineering students. Through the use of the MBASE framework and complementary tools, students have been able to obtain real-life software development experience without leaving campus. Project team clients and the universities have also benefited. This paper provides evidence on the impact of Dr. Boehm's frameworks on courses at two universities, and identifies major contributions to software engineering education and practice	ampersand;barry boehm;mbase;real life;software development;software engineering	Ricardo Valerdi;Raymond J. Madachy	2006	19th Conference on Software Engineering Education & Training (CSEET'06)	10.1109/CSEET.2006.21	engineering management;personal software process;computer science;social software engineering;software engineering;computer engineering	SE	-82.86899966929548	-33.180244164879255	2125
b94e7f6f07985ffd64e015d45d65de50216a71e3	efficient space utilization for improving navigation in congested environments	human robot spatial interaction;obstacle avoidance	In this paper, we have looked into some two behaviors for 'efficient space utilization' by humans in a congested situation. From observations, we have noticed that 'last minute avoidance' and 'shoulder turning' are two crucial behaviors in achieving efficient navigation in crowded environments. The presented study verifies the shoulder turning behavior and investigates the typical values for these behaviors. These results will form an initial framework for local avoidance planner for future research.		Moondeep C. Shrestha;Hayato Yanagawa;Erika Uno;Shigeki Sugano	2015		10.1145/2701973.2702018	computer vision;simulation;computer science;artificial intelligence;obstacle avoidance	Robotics	-20.386506901439184	-25.914400756443538	2128
f100c3053da33f5eeb8a3cfeeeba5997822dedb4	proceedings of the 2009 workshop on applied textual inference (textinfer)				Chris Callison-Burch;Ido Dagan;Christopher D. Manning;Marco Pennacchiotti;Fabio Massimo Zanzotto	2009			natural language processing;inference;artificial intelligence;computer science	NLP	-55.04676491285011	-11.58643343726382	2131
491eeb1f49796827d1b461fe1ccc9f9189815d6d	"""""""cultures in negotiation"""": teachers' acceptance/resistance attitudes considering the infusion of technology into schools"""	learning community;information technology;country specific developments;resistance to change;media adaptation;technological literacy;learning communities;foreign countries;secondary education;intermode differences;information and communication technology;technology integration;media in education;teacher training;improving classroom teaching;scaffolding teaching technique;teacher attitudes;instructional improvement;school culture	A teachers’ training project, employing teacher-mentored in-school training approach, has been recently initiated in Greek secondary education for the introduction of Information and Communication Technology (ICT) into the classroom. Data resulting from this project indicate that although teachers express considerable interest in learning how to use technology they need consistent support and extensive training in order to consider themselves able for integrating it into their instructional practice. Teachers are interested in using ICT (a) to attain a better professional profile, and (b) to take advantage of any possible learning benefits offered by ICT but always in the context of the school culture. They are willing to explore open and communicative modes of ICT based teaching whenever school objectives permit, otherwise they appear to cautiously adapt the use of ICT to the traditional teacher-centered mode of teaching (strongly connected to the established student examination system). Teachers’ attitude to adapt ICT mode of use is supported by research evidence that emphasize the situational character of knowledge and expertise. Authors employ a model premised on Perceptual Control Theory to interpret available data and discuss the view that introducing ICT into schools can be understood as a “negotiation” process between cultures.	emoticon;perceptual control theory;strongly connected component	Stavros N. Demetriadis;Ana Barbas;A. Molohides;George Palaigeorgiou;D. Psillos;Ioannis P. Vlahavas;Ioannis A. Tsoukalas;Andreas S. Pomportsis	2003	Computers & Education	10.1016/S0360-1315(03)00012-5	psychology;learning community;knowledge management;multimedia;sociology;law;information technology;pedagogy	AI	-75.90859576410551	-37.175117936773745	2140
0589365d6a09a1f5f457d3a47f20d6d4ec3e8d0c	the research of the influence of customer perceived value to customer satisfaction in mobile games		With the popularity of LTE technology, the mobile industry is booming and the market size of the mobile industry is expanding. The major Internet companies have entered the mobile gaming market, resulting in an increasingly competitive market. Under this background, mobile games have then become an emerging market in online game industry in the past few years. The scholars studying mobile games are focused on the technology development level, few studies on consumer behavior. The paper study is behavior intention of mobile games based on Customer Perceived Value. The research results in this paper have practical meaning for mobile game developers and operators. Through the use of Customer Perceived Value, analyze the behavior features of Chinese and Japanese users. Then they can enhance customer satisfaction and customer loyalty by properly managing Customer Perceived Value.		Kailiang Zhang;Yumi Asahi	2015		10.1007/978-3-319-20612-7_64	public relations;customer to customer;voice of the customer;marketing;attitudinal analytics;customer equity;customer reference program;customer delight;customer intelligence;advertising;business;customer satisfaction;customer retention;service quality;relationship marketing;customer advocacy	AI	-86.03985961455152	-11.087438375720401	2143
0efc330759b7ffed965b576ab022b8126f73c5b8	genetic and evolutionary computation conference, gecco 2006, proceedings, seattle, washington, usa, july 8-12, 2006	genetics;evolutionary computing		genetic and evolutionary computation conference		2006			computer science;evolutionary computation	Robotics	-49.791853407443405	-11.865061900553595	2145
590157c32b467f40014727e1a0ff6a37b1cbfa72	an implementation review of occlusion-based interaction in augmented reality environment	libraries;human computer interaction;occlusion based interaction;augmented reality costs computer graphics virtual reality application software software libraries visualization software engineering productivity testing;virtual reality;testing;window manager;data mining;virtual reality human computer interaction;visualization;glut;augmented reality technology;three dimensional displays;windows management occlusion based interaction augmented reality technology virtual reality artoolkit library opengl glut graphics manipulation;opengl;artoolkit library;augmented reality;windows management;graphics manipulation;cameras;occlusion based interaction augmented reality;qa76 computer software	Augmented Reality (AR) technology shows some potential in providing new approach of interaction with computer. It shares similar potential in Virtual Reality (VR) but at lower cost. In this paper, an AR application is developed to explore the capability of the interaction approach called Occlusion Based Interaction using low cost device. The implementation of the application is utilizing the ARToolKit library as the main library to handle the AR part while OpenGL and GLUT to handle the graphics manipulation and windows management respectively.	artoolkit;augmented reality;graphics;microsoft windows;opengl;virtual reality	Mohamad Shahrul Shahidan;Nazrita Ibrahim;Mohd Hazli Mohamed Zabil;Azlan Yusof	2009	2009 Sixth International Conference on Computer Graphics, Imaging and Visualization	10.1109/CGIV.2009.60	human–computer interaction;engineering;multimedia;computer graphics (images)	Visualization	-43.08923963112644	-35.67420663410592	2147
c434e1a7ff20f796a0bad6323e13112d12aa8b54	exploring the influential factors of e-banking satisfaction in rural areas in china		Online banking has become a new and popular business in recent years. What factors influence the success of online banking and how can online banking get a larger development have drawn much research interest of people. This paper mainly focuses on the research of online banking standing at the users’ view. It will explore the factors that influence the satisfaction of customer. Through this paper, we would not only get the new awareness about the factors affecting the users’ satisfaction about online banking, but also gain the profound reflection of the future way regarding the online banking.	online banking	Mengyu Ren;Yan Li;Yu Wang;Zihao Zhao	2014		10.1007/978-3-319-19620-6_42	marketing;rural area;china;business	HCI	-87.39229909797433	-9.478330695219055	2148
26edbd4d229f455429f3eefe885fb13a3214ee81	stringology algorithms	stringology algorithm	Stringology is the study of algorithmic and mathematical aspects of strings and sequences. The first string algorithms were designed for exact string matching. Although new algorithms for this task are still improving complexities somewhat, others, for more complicated tasks, are also being developed. With cheaper DNA sequencing producing huge amounts of data, bioinformatics and data compression play a more and more important role. This special issue contains extended versions of selected papers presented at the Prague Stringology Conference in years 2010 and 2011. The Prague Stringology Conference was founded in 1996 to bring together researchers in stringology and automata theory. As a result of new developments in the area of stringology, other related topics became very important parts of the conference. For example, in the last years algorithms on trees (called arbology) were also introduced as a topic of the conference. The papers in this special issue focus on minimization of finite automata, searching for various repeats and abelian periods in strings, web graph compression, data deduplication, string and tree pattern matching, and inferring strings from an indexing data structure. I would like to express my gratitude to Prof. Endre Boros for dedicating a special issue of Discrete Applied Mathematics to PSC 2010 and 2011, and for his support during the editorial process. We are grateful to Katie D’Agosta, whose efficiency was important in helping us to finish this work. We want to thank also all anonymous referees whose competent and rigorous work has assured the quality of this issue.	automata theory;bioinformatics;data compression;data deduplication;data structure;finite-state machine;multi-function printer;pattern matching;string (computer science);string searching algorithm;www;webgraph	Jan Holub	2014	Discrete Applied Mathematics	10.1016/j.dam.2013.11.009		DB	-14.156506087523487	-2.7082087027178763	2149
7852d7f1c8e974dec08597eca63a7620c149e10e	cloud-based virtual computing laboratories	libraries;educational institutions servers cloud computing virtualization libraries laboratories;virtual instrumentation;virtualization;information assurance virtual computing labaoratories cloud computing;computer aided instruction;virtual instrumentation cloud computing computer aided instruction educational institutions teaching;servers;vlab cloud based virtual computing laboratories universities teaching support research support in house labs;information assurance;virtual computing labaoratories;teaching;cloud computing	Virtual computing laboratories are widely implemented in universities, especially to support teaching and research in areas such as engineering, computer science, and information assurance. Most existing labs that support teaching or a combination of teaching and research are internally implemented and managed. Some universities are considering migrating their in-house labs into the cloud using solutions provided by multiple vendors. This paper explores the practical aspects of such a migration and describes costs, benefits, and challenges.	computer science;information assurance	Stephen D. Burd;Xin Luo;Alessandro F. Seazzu	2013	2013 46th Hawaii International Conference on System Sciences	10.1109/HICSS.2013.131	education;virtualization;human–computer interaction;cloud computing;computer science;operating system;software engineering;utility computing;server	HPC	-54.92597917659488	3.3236992003120402	2159
40dc3985951b332c7d09cb0f9505290558347b4f	historical datum as a basis for a new gis application to support civil protection services in nw italy	geo hydrological hazard;gis;civil protection;italy;historical data	Debris flows and stream floods are common natural processes in alpine regions. Though their occurrence varies significantly in space and time, a sound knowledge basis for assessing the extent and impact of such events can be gained through the use of historical sources. The GIS application described here derives from an analysis of historical accounts of landslide, flood and debris flow events which caused losses in property and lives in Piedmont (Northwestern Italy). The analysis focuses on past geo-hydrological events in small-scale Alpine catchments in such region, but the research method can be exported to any mountain basin.Controlling natural hazards is a national task of paramount importance to ensure maximum safety, through sustainable strategies in the integrated risk management of natural hazard in mountainous watersheds. A specific objective of this project was to define a flood prevention methodology, to jointly with civil protection agencies in order to establish priority actions and rapid response in case of torrential rains. Working together with local civil protection units, the overall aim is to raise awareness of potential flood risks and help residents be prepared for flood events. Debris flows and stream floods are common natural processes in alpine regions.The impact of these processes can be gained through the use of historical sources.In our approach, GIS technology is the tool used to manage this information.WebGIS, portable GIS and GPS devices are the best tools to use these informations.Civil protection agencies, local governments and citizens are the main end-users.		L. Turconi;Guido Nigrelli;R. Conte	2014	Computers & Geosciences	10.1016/j.cageo.2013.12.008	geomatics;hydrology;civil defense;remote sensing	HCI	-12.485529648870125	-21.701542197413794	2160
129ea850c1c54b784bdfb3362453f5045abe0414	research on remote sensing dynamic monitoring of ecological resource environment based on gis	geographic information system;remote sensing;ecological environment;dynamic monitoring;evaluation;data mining	SPOT and ETM+ satellite images are used as the main source of information. The remote sensing image processing software ERDASIMAGINE and the geographic information system software ARCVIEWGIS have been used. The technical method and work flow of remote sensing dynamic monitoring of resources and ecological environment based on GIS are studied. The geometric correction, registration, filtering, fusion and information extraction of remote sensing images have been completed. Data mining and professional maps based on GIS are produced and updated. The key techniques are analyzed and studied. In addition, the natural ecological environment of the region was evaluated.	geographic information system	Xiaofeng Li;Zongyi He;Lili Jiang;Yanjun Ye	2018	Wireless Personal Communications	10.1007/s11277-018-5317-1	image processing;information extraction;computer science;geographic information system;ecology;remote sensing;software	Mobile	-13.135870266603527	-27.58301377780109	2162
b1df9ad31635b1fcc75839445d1cd0655ba91822	massive open online courses: current state and perspectives (dagstuhl perspectives workshop 14112)		The rapid emergence and adoption of Massive Open Online Courses (MOOCs) has raised new questions and rekindled old debates in higher education. Academic leaders are concerned about educational quality, access to content, privacy protection for learner data, production costs and the proper relationship between MOOCs and residential instruction, among other matters. At the same time, these same leaders see opportunities for the scale of MOOCs to support learning: faculty interest in teaching innovation, better learner engagement through personalization, increased understanding of learner behavior through large-scale data analytics, wider access for continuing education learners and other nonresidential learners, and the possibility to enhance revenue or lower educational costs. Two years after “the year of the MOOC”, this report summarizes the state of the art and the future directions of greatest interest as seen by an international group of academic leaders. Eight provocative positions are put forward, in hopes of aiding policymakers, academics, administrators, and learners regarding the potential future of MOOCs in higher education. The recommendations span a variety of topics including financial considerations, pedagogical quality, and the social fabric. Perspectives Workshop March 10–13, 2014 – http://www.dagstuhl.de/14112 1998 ACM Subject Classification K.3 Computers and Education	emergence;massive open online course;personalization	Pierre Dillenbourg;Armando Fox;Claude Kirchner;John C. Mitchell;Martin Wirsing	2014	Dagstuhl Manifestos	10.4230/DagMan.4.1.1		HCI	-74.59281547479242	-28.676937700221533	2168
d565e951fd10c984eb81883afa1d8cd8142e1a9a	digital forensics curriculum development: identification of knowledge domains learning objectives and core concepts	digital forensics	Digital forensics course offerings are being added to various curricula at colleges and universities world-wide at an amazing pace. This is due to significant student interest in the topic and job market demands for such skill sets. However, academia is struggling to establish a firm knowledge base and offer quality digital forensics education to its students. We contend that the identification and community acceptance of digital forensics knowledge domains, learning objectives, and core concepts is imperative to effectively and efficiently educating students in digital forensics. We argue that this goal has yet to be achieved. The purpose of this research and paper is to qualitatively test that presumption, and to methodologically identify and propose a set of digital forensics knowledge domains, supporting learning objectives, and necessary core concepts. Toward that end, we qualitatively analyzed digital forensics syllabi from 42 different colleges and universities and supplemented the analysis with our knowledge and experience. We conclude that our presumption is indeed correct, and thus propose a more structured approach toward digital forensics education and support it by presenting model course syllabi.	imperative programming;knowledge base	Nicole Beebe;Jan Guynes Clark	2006				AI	-77.28374102079752	-27.68498026923867	2169
5e1b2a968d6f79c23589a352fd626b566f649da2	proceedings of the 2016 international conference on supercomputing, ics 2016, istanbul, turkey, june 1-3, 2016			acm/ieee supercomputing conference;supercomputer		2016				Robotics	-51.34190511721303	-4.921908396586731	2171
8eb87d311f17c1f3ec97615b0e439dd7898816aa	guest editors' introduction: wearables, implants, and internet of things	special issues and sections;internet of things;implants;wearable computing	RECENT years have seen an explosion of deeply embedded, smart, and highly connected computing devices in diverse form factors. In particular, wearable and implant technologies, and Internet of Things (IoT) have made significant forays into nearly all aspects of our life, including health, entertainment, fashion, and social behavior. With advances in technology and process miniaturization, design of new and advanced sensors, pervasive connectivity, and the trend in business towards cloud-driven data-centric solutions, the future is projected to see an even higher proliferation of systems comprising of such devices that coordinate through cloud to solve complex, distributed tasks. Commensurate with computing capability, the applications have also scaled in complexity by several factors, e.g., from smart phones to smart cities. On the other hand, the device explosion and high connectivity have induced new research challenges affecting a wide diversity of areas, including health care, retail, computer security, data analytics, computer architecture, physical design, and more. Furthermore, a comprehensive solution to the research challenges requires a close collaboration between these different areas to ensure usability and interoperability of solutions. This special issue documents some recent progress in this challenging research area. Note that the area is vast, touching almost every subject in computing and electrical engineering with a large variety of tools, techniques, and applications. Covering the entire research spectrum is far beyond the scope of a single special issue. Instead, our goal has been to try to provide a sampling of different topics in this exciting domain, highlight the diversity of research involved, and capture some emerging trends. With that goal in mind, this issue provides five representative articles covering a wide range of topics encompassing new applications, challenges and approaches towards designing IoT systems. The first three articles provide a glimpse of the new technology in healthcare and biomedical applications. “Adaptive and Personalized Gesture Recognition using Textile Capacitive Sensor Arrays” by Alexander Nelson, Gurashish Singh, Ryan Robucci, Chintan Patel, and Nilanjan Banerjee, presents a non-contact proximity gesture recognition system. The approach permits gesture recognition of patients with upper extremity mobility impairment through fabric capacitive sensor arrays, avoiding the physical contact and intrusiveness of current assistive technology solutions. In the next article titled “Asthma Pattern Identification via Continuous Diaphragm Motion Monitoring”, Menghan Liu and Ming-Chun Huang propose an ultrasound system for monitoring respiratory status of asthma through diaphragm movement detection. Finally, in “Energy-Efficient Long-term Continuous Personal Health Monitoring”, Arsalan Mohsen Nia, Mehran MozaffariKermani, Susmita Sur-Kolay, Anand Raghunathan, and Niraj K. Jha discuss continuous health monitoring (CHM), which is another critical topic in biomedical applications. They present ways for energy-efficient long-term CHM through novel, low-energy schemes for sample aggregation, anomaly-driven transmission, and compressive sensing. The final two papers deal with another critical aspect of the emergent applications, security. The paper “Privacy and Security in Internet of Things and Wearable Devices” by Orlando Arias, Jacob Wurm, Khoa Hoang, and Yier JIn, considers privacy concerns in the environment in which embedded systems with sensors attached are continually collecting data; it proposes design flow enhancements and security enhancements to address such concerns. Finally, the article “A PUF-Enabled Secure Architecture for FPGAbased IoT Applications” by Anju P. Johnson, Rajat Subhra Chakraborty, and Debdeep Mukhopadhyay proposes a secure architecture for IoT applications based on the Dynamic Partial Reconfiguration (DPR) capabilities of FPGAs. They present a modified DPR methodology to implement a light-weight cryptographic security protocol, identify threats from availability of DPR at IoT nodes, and implements a solution based on Physically Unclonable Function (PUF). The emerging world of wearables, implants, and IoTs will encompass a large diversity of applications, with unique challenges in design, validation, security, and energy requirements. Addressing all the technology challenges for these applications will likely remain an elusive goal in the foreseeable future. However, the area is vast, the challenges are real, and there is an encouraging trend of different areas coming together in close collaboration to address them. We hope these five articles provide a glimpse to the various applications and technology challenges in the broad and rapidly evolving field of internet-of-things. We hope that they introduce new concepts, tickle your intellect, and spur innovation in this field of growing importance. S. Ray is with the Strategic CAD Labs, Intel, Hillsboro, OR 97124. E-mail: sandip.ray@intel.com. J. Park is with School of Electrical Engineering, Korea University, Seoul 136-701, Korea. E-mail: jongsun@korea.ac.kr. S. Bhunia is with the Department of Electrical & Computer Engineering, University of Florida, Gainesville, FL 32611. E-mail: swarup@ece.ufl.edu.	anomaly detection;assistive technology;capacitive sensing;chemdraw;compressed sensing;computer architecture;computer engineering;computer form factor;computer security;computer-aided design;cryptographic protocol;cryptography;diaphragm (acoustics);electrical engineering;embedded system;emergence;field-programmable gate array;gesture recognition;intellect;internet of things;interoperability;jin au kong;mind;pervasive informatics;physical design (electronics);physical unclonable function;requirement;sampling (signal processing);sensor;smart city;smartphone;usability;wearable computer	Sandip Ray;Jongsun Park;Swarup Bhunia	2015	IEEE Trans. Multi-Scale Computing Systems	10.1109/TMSCS.2015.2494978	computer science;multimedia;biological engineering	Mobile	-60.526803636041286	-1.4392564019623675	2178
408b59571b809ad84621ade02db8240cd321b9a4	understanding sequential user behavior in social computing: to answer or to vote?	analytical models;social computing;game theory;incentives;web sites decision making human factors social sciences computing;computational modeling;social networks;games;predictive models;user generated content ugc;social computing computational modeling analytical models predictive models games data models numerical models;numerical models;social networks game theory incentives;stack overflow sequential user behavior social computing system answering voting externality sequential decision making strategy equilibrium threshold structure;data models	Understanding how users participate is of key importance to social computing systems since their value is created from user contributions. In many social computing systems, users decide sequentially whether to participate or not and, if participate, whether to create a piece of content directly, i.e., answering, or to rate existing content, i.e., voting. Moreover, there exists an answering-voting externality as a user's utility for answering depends on votes received in the future. We present in this paper a game-theoretic model that formulates the sequential decision making of strategic users under the presence of such an answering-voting externality. We prove theoretically the existence and uniqueness of a pure strategy equilibrium. To further understand the equilibrium participation of users, we show that there exist advantages for users with higher abilities and for answering earlier. Therefore, the equilibrium has a threshold structure and the threshold for answering gradually increases as answers accumulate. We further extend our results to a more general setting where users can choose endogenously their efforts for answering. To show the validness of our model, we analyze user behavior data collected from a popular Q&A site Stack Overflow and show that the main qualitative predictions of our model match up with observations made from the data. Finally, we formulate the system designer's problem and abstract from numerical simulations several design principles that could potentially guide the design of incentive mechanisms for social computing systems in practice.	computer simulation;emoticon;existential quantification;game theory;numerical analysis;question answering;randomness;social computing;stack overflow;systems design;user (computing)	Yang Gao;Yan Chen;K. J. Ray Liu	2015	IEEE Transactions on Network Science and Engineering	10.1109/TNSE.2015.2470542	games;data modeling;game theory;simulation;incentive;computer science;machine learning;data mining;mathematics;management science;predictive modelling;computational model;social computing;social network	ECom	-22.907570351910937	-41.41222003477766	2179
8bf71620722b4f661c3ce48ad94641dbd6aa0f94	a participative method to improve knowledge absorption capacity in collaborative innovation projects	absorption;technological innovation;collaboration;stakeholders;companies;project management innovation management knowledge management organisational aspects;companies collaboration technological innovation absorption stakeholders transforms;transforms;organisational routines collaborative innovation projects knowledge absorption capacity participative method small and medium sized companies collaborative networks knowledge absorption process participatory techniques;organisational routines absorptive capacity participative methods	Knowledge absorption capacity, known as the ability of a firm to identify, ussimilate, transform and exploit external knowledge, plays an important role in explaining and fostering innovation in companies. In particular, this capacity is crucial for small and medium-sized companies relying on collaborative networks to develop their innovation projects. The problem is how such companies can absorb maximum knowledge through collaboration with their partners. This can help them to overcome resource scarcity and enhance competitiveness. In this study we aim to provide a participative method for modelling the knowledge absorption process in innovative project processes. This method, conducted with participatory techniques, will help us to identify organisational routines related to knowledge absorption. These routines provide the means to improve knowledge absorption in organisations.	collaborative network	Fatemeh Movahedian-Attar	2016	2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS)	10.1109/RCIS.2016.7549359	absorption;stakeholder;systems engineering;knowledge management;management science;management;collaboration	SE	-78.15458404007161	3.473592244749528	2180
b61808ce04ff7174456f2aef36fa512345fb06e6	walking the path: a new journey to explore and discover through visual analytics	interactions visualization;homeland security;general and miscellaneous mathematics computing and information science;keywords;computer graphics;interactive visualization;information visualization;knowledge representation visual analytics;visual representation;analytical reasoning;data exploration;visual analytics;man machine systems;interactive visual interfaces;pnnl;knowledge discovery;pacific northwest	Received: 20 February 2006 Revised: 31 July 2006 Accepted: 3 August 2006 Abstract Under the leadership of the US Department of Homeland Security (DHS), researchers at the Pacific Northwest National Laboratory (PNNL) established a research center focusing on the discipline of visual analytics in 2004. A year later, the center led a multidisciplinary panel representing academia, industry, and government to formally define directions and priorities for future research and development (R&D) for visual analytics tools. The R&D agenda, Illuminating the Path, defines the term visual analytics as 'the science of analytical reasoning facilitated by interactive visual interfaces'. This article describes our progress to date in walking that path. We briefly describe the background of the subject, present major professional activities and accomplishments of its community, and highlight some of the ongoing R&D efforts being carried out by researchers at PNNL to fulfill the requirements and missions of a new discipline that promises to change the way we deal with today's information. Information Visualization (2006) 5, 237--249. doi:10.1057/palgrave.ivs.9500133	information visualization;requirement;visual analytics	Pak Chung Wong;Stuart J. Rose;George Chin;Deborah A. Frincke;Richard May;Christian Posse;Antonio Sanfilippo;James J. Thomas	2006	Information Visualization	10.1057/palgrave.ivs.9500133	homeland security;computer vision;visual analytics;simulation;analytic reasoning;information visualization;interactive visualization;computer science;artificial intelligence;data science;machine learning;data mining;cultural analytics;computer graphics	Visualization	-47.890719826789805	-17.93227005294777	2181
39a5fb6934995e0e97df5462db40d2042e40a4a9	improved modelling of the freshwater provisioning ecosystem service in water scarce river basins	freshwater provisioning;integrated modelling;water scarcity;water resources management;aquatool;ecosystem services	Freshwater provisioning by the landscape contributes to human well-being through water use for drinking, irrigation and other purposes. The assessment of this ecosystem service involves the quantification of water resources and the valuation of water use benefits. Models especially designed to assess ecosystem services can be used. However, they have limitations in representing the delivery of the service in water scarce river basins where water management and the temporal variability of water resource and its use are key aspects to consider. Integrating water resources management tools represents a good alternative to ecosystem services models in these river basins. We propose a modelling framework that links a rainfall-runoff model and a water allocation model which allow accounting for the specific requirements of water scarce river basins. Moreover, we develop a water tracer which rebounds the value of the service from beneficiaries to water sources, allowing the spatial mapping of the service.	ecosystem services;provisioning	Andrea Momblanch;Javier Paredes-Arquiola;Joaquín Andréu	2017	Environmental Modelling and Software	10.1016/j.envsoft.2017.03.033	water conservation;ecosystem services;irrigation;integrated water resources management;computer science;water scarcity;water resource management;water use;environmental resource management;drainage basin;water resources	Mobile	-13.184315287021375	-21.007267743349956	2183
93271ccd7d47054ff2584d149963b888f56c31c1	"""automatic extraction of hidden keywords by producing """"homophily"""" within semantic networks"""			semantic network	Hiroyuki Akama;Maki Miyake;Jaeyoung Jung	2011			homophily;semantic network;machine learning;computer science;artificial intelligence	NLP	-24.28902649984261	-61.19071208874575	2188
bece9321bc52d1e7fe6bb0707196d1dfa8451ea4	low-dimensional models for traffic data processing using graph fourier transform		The reliability of services offered by intelligent transportation systems is attributed to the accuracy and timely availability of road-network traffic information. However, in the present era of big data, compliance with anticipated service quality requirements mandates consistent real-time processing of big spatiotemporal traffic data. Thus, development of low-dimensional models is a crucial challenge in traffic data processing. The authors developed such representations using data graph framework and graph Fourier transform (GFT) approaches. Experimental results on California daily network traffic data showed that, even with a 15:1 compression ratio, GFT-based models offered less than 6 percent reconstruction error (RE), instigating a less than 2 percent increase in mean absolute percentage error of corresponding predictions. The authors also proposed a 3D graph framework, which reduced RE by almost 2 percent compared to its 2D counterpart.	adjacency matrix;approximation error;big data;computation;consistency model;discrete fourier transform;electronic engineering;network packet;network traffic control;nikon cx format;principal component analysis;real-time clock;requirement;sampling (signal processing)	Narendra Babu Chindanur;Pallaviram Sure	2018	Computing in Science & Engineering	10.1109/MCSE.2018.110111913	computer science;theoretical computer science;fourier transform;big data;mean absolute percentage error;dimensionality reduction;data modeling;matrix decomposition;intelligent transportation system;data processing	ML	-14.700517578594265	-30.925362165609204	2195
9d3866b0c1c404861cee598cafd80931357c4d6c	content-based prediction of temporal boundaries for events in twitter	twitter social media temporal boundaries svm hmm;text analysis classification hidden markov models social networking online support vector machines;relational data;support vector machines;hidden markov model;prediction algorithms;hmm;text analysis;classification;media;accuracy;social activities content based prediction event temporal boundary social media services flickr you tube user generated content event analysis event related data tweet content analysis svm classifier hidden markov model twitter data sports weather;hidden markov models;temporal boundaries;social networking online;hurricanes;svm;support vector machine;twitter;user generated content;social media;accuracy hidden markov models twitter hurricanes prediction algorithms support vector machines media	Social media services like Twitter, Flickr and You Tube publish high volumes of user generated content as a major event occurs, making them a potential data source for event analysis. The large volume and noisy content of social media makes automatic preprocessing essential. Intuitively, the event-related data falls into three major phases: the buildup to the event, the event itself, and the post-event effects and repercussions. We describe an approach to automatically determine when an anticipated event started and ended by analyzing the content of tweets using an SVM classifier and hidden Markov model. We evaluate our performance by predicting event boundaries on Twitter data for a set of events in the domains of sports, weather and social activities.	domain model;dynamic web page;flickr;hidden markov model;machine learning;markov chain;preprocessor;social media;support vector machine;user-generated content	Akshaya Iyengar;Timothy W. Finin;Anupam Joshi	2011	2011 IEEE Third Int'l Conference on Privacy, Security, Risk and Trust and 2011 IEEE Third Int'l Conference on Social Computing	10.1109/PASSAT/SocialCom.2011.196	support vector machine;computer science;data science;complex event processing;machine learning;pattern recognition;data mining;hidden markov model	Vision	-22.968281815667805	-55.28791605747825	2197
239ffa4d59a6a91a3dd41818f764cc946f6c566c	editorial: human-centered product design and development	product design			Chun-Hsien Chen;Keiichi Sato;Kun-Pyo Lee	2009	Advanced Engineering Informatics	10.1016/j.aei.2009.02.002	computer science;product design	SE	-51.951884465406756	-12.78811714620492	2217
5e1381640f2646d213ac8e2b9cb2a914b2f838da	high-quality synthesis of lpc speech using multiband excitation model.			lpc	C. F. Chan	1993			speech recognition;acoustics	NLP	-13.392061414953034	-86.79475080459368	2224
61e5c243447a77c5433036fcf8fda22a8a8d7518	morphology of vocal affect bursts: exploring expressive interjections in japanese conversation		Expressive interjection (EI) is defined as non-lexical speech sound which indicates the speaker’s cognitive/affective state changes. It is a type of vocal affect burst, i.e., brief and sudden nonverbal expressions that are produced spontaneously and unconsciously. Although EI as a social signal is assumed to play an important part in speech communication, very little is known about its linguistic, paralinguistic, and pragmatic nature. The goal of this study is to unveil the structure and functions of vocal affect bursts in human interactions. This paper focuses on the surface structure of EIs, which is an indispensable foundation for further analysis and modeling. Based on linguistic/acoustic analyses of a natural, spontaneous dialog corpus, the distinctiveness of EI was revealed as: (1) less variation in transcribed expression, (2) may have very short duration, and (3) higher F0 and intensity. In addition, it was revealed that an apparent correlation between formant frequencies and perceived paralinguistic information was observed only for EIs with the vowel /a/, which suggests that the vowel /a/ as an EI can accommodate richer paralinguistic information than other vowels.	acoustic cryptanalysis;binary prefix;burst mode (computing);burst transmission;expressive power (computer science);interaction;mathematical morphology;spontaneous order;dialog	Hiroki Mori	2015			conversation;speech recognition;communication;morphology (linguistics);computer science	NLP	-10.348982595895974	-82.0982896181702	2225
cce647c795bb44b9bb82f1f2b80baabbaa72a363	4th ifac conference on analysis and design of hybrid systems, adhs 2012, eindhoven, the netherlands, june 6-8, 2012					2012				EDA	-53.410734351878546	-3.301998902814828	2226
34452b3539fd2401a5e07ca75239dac412457515	user-chosen phrases in interactive query formulation for information retrieval	information retrieval system;information retrieval;query formulation;indexation;investment timing	The impact of using phrases as content representation for documents and for queries has generall y been accepted as a desirable feature in information retrieval systems because phrases are generall y regarded as being more content-bearing than their constituent words. This has been borne by experiments in which the impact of phrases on retrieval performance has usuall y been found to be positi ve. However, most of the experimental results reported have derived phrases from documents and from queries in a full y automatic way. While this is acceptable for document indexing it is less acceptable for query formulation which is increasingly heading towards being an iterative process with users investing time in browsing the term space to choose appropriate search terms. In this paper we report a series of experiments in which two users, one experienced and the other a novice, formulate their queries by browsing the term space in advance of issuing a retrieval request. For these users we analyse the relative contributions and the impact of single words and multi -word phrases as search terms, on overall retrieval performance. Our results have impli cations for how choosing phrases as search terms should be presented to novice and to experienced searchers.	course (navigation);experiment;information retrieval;iteration	Alan F. Smeaton;Fergus Kelledy	1998			query expansion;computer science;data mining;world wide web;information retrieval;human–computer information retrieval	Web+IR	-34.94042836149281	-54.21056995515451	2229
3d1c6f6460eda6f27f5bebb89f516393b105b582	leveraging typing phenomena to design one-handed wearable keyboards	keyboards;english language;human computer interaction;user study;wearable computers;design practice;english language hci touch typing psychomotor rhythms one handed wearable keyboards reconfigurable keyboard;natural languages;natural languages wearable computers keyboards human computer interaction;keyboards natural languages topology belts wearable computers strain measurement human computer interaction psychology rhythm textiles	Design practice in the HCI tradition often focuses on developing requirements from a task-based model of behavior. Touch typing is a complex task involving the translation of language into psychomotor rhythms acting on a spatial topology. An accurate model with appropriate emphases is difficult to construct; however, we may not need to construct the model if we can directly leverage the patterns of language and the innate tendencies of the human typist. This paper describes a design approach that leverages the phenomena of typing to inform the design of one-handed keyboards for wearable use. A reconfigurable keyboard is constructed and used in conjunction with a phrase set representative of the English language in a user study. The study resulted in various keyboard topologies and information about one-handed keyboarding relevant to design.	human–computer interaction;neural oscillation;requirement;touch typing;usability testing;wearable computer	Jill Coffin	2005	Ninth IEEE International Symposium on Wearable Computers (ISWC'05)	10.1109/ISWC.2005.30	embedded system;simulation;wearable computer;human–computer interaction;computer science;english;operating system;natural language	SE	-49.91273422858853	-44.3667817812471	2236
9d5eca772f96d63fedf350dfcc20d7cbbfeb12bb	automated interoperability testing of healthcare information systems	iot;ehealth	Abstract Over the last two decades, the number of healthcare services at the edge of the traditional medical care and computer technologies has increased dramatically, making eHealth infrastructure-related services ubiquitous. The obvious outcome is that many of the traditional medical care activities and practices were partially or completely replaced by the newest and more efficient ones based on Internet or using advances in the information technology. Services such as telemedicine, telehealth, Electronic Health Record (EHR) systems, automated retrieval, or update of the electronically stored patient data are common terms and practices in the actual medical care sector. Irrespective of the way the information is stored, either in the form of paper-based patient records or electronically, for example in the form of EHRs, the healthcare field is very data intensive , i.e., the information is huge and very complex. This is a characteristic of the healthcare domain that will not change, even if the movement from traditional Healthcare Information System (HIS) to electronic HIS is taking place. Among other important pieces of information in the healthcare systems, the patient record is a key one. The development of EHR solutions represents the base of the information systems in the IT medical industry. Many vendors provide solutions that are rather provider-centred approaches (i.e., proprietary protocols and message formats), but interoperability is not concerned. Obviously, automated test systems can help vendors of those eHealth solutions to validate the conformance to specifications. The major problem of HIS solutions is the lack of product interoperability. The publication of standards such as Health Level Seven Messaging Standard (HL7) for defining a common message structuring scheme for message exchange between medical information systems, or the adoption of the Integrating the Healthcare Enterprise (IHE) integration profiles for specifying the use cases that implementers should follow, is an important step in enabling interoperable HISs. These standards and recommendations are the basis for the interoperability testing. This extended chapter proposes an interoperability testing methodology and its realization concepts to cope with the aforementioned issues in HIS. The main problem addressed in this work is how to design a test system that can deal with very data-intensive systems and, at the same time, is capable of emulating the interacting parties. The challenge in this approach is how to automatically customize and configure the test platform to simulate an interoperability scenario by instantiating test components programmed in advance to simulate the behavior of particular interacting entities.	information system	Diana Vega	2012	Advances in Computers	10.1016/B978-0-12-396526-4.00005-9	semantic interoperability;knowledge management;data mining;cross-domain interoperability;world wide web	SE	-54.83682657991474	-62.27895350321933	2246
0d0c98c511dc851d345203aa412a2f9409f78077	name disambiguation boosted by latent topics from web directories	web documents;document handling;pediatrics;data mining intelligent agent frequency linear discriminant analysis informatics context modeling feature extraction web sites world wide web search engines;latent topic extraction;name disambiguation;vector space model;internet document handling information retrieval;search engines;information retrieval;document similarity personal name disambiguation knowledge base latent dirichlet allocation latent topic extraction;data mining;latent dirichlet allocation;noise measurement;smoothing methods;internet;named entity recognition;named entity recognition name disambiguation latent topics web directory personal name query web documents latent dirichlet allocation name ambiguity documents context measurements vector space model approach;feature extraction;personal name disambiguation;conferences;document similarity;knowledge base	Search results for personal name queries often contain documents relevant to several people as a personal name is often shared by several people. In order to differentiate people in these search results, it is required to extract contexts relevant to people in documents. However, since web documents are noisy and the texts related to people might be short, it is difficult to extract contexts of people effectively. We propose a new method that uses web directories as additional information in order to recognize topic terms in documents more easily and to extract contexts of people more effectively. First, we apply latent Dirichlet allocation method to extract latent topics in web directories. Then, the extracted topics are used to recognize topics contained in name ambiguity documents so that common context measurements can be calculated more effectively. Our experiments, conducted with documents of real people in the web and several well-known web directories, show that our approach disambiguates personal names better than some other conventional approaches like vector space model approach and named entity recognition approach.	experiment;latent dirichlet allocation;named entity;named-entity recognition;web page;word-sense disambiguation	Quang Minh Vu;Atsuhiro Takasu;Jun Adachi	2008	2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WIIAT.2008.171	latent dirichlet allocation;knowledge base;the internet;feature extraction;computer science;noise measurement;machine learning;data mining;world wide web;vector space model;information retrieval	Web+IR	-27.57001701736241	-58.48856534698428	2248
cb55a2758d26d96dadcf301a11dadee9f703f3c0	first steps towards multi-engine machine translation	promising translation;knowledge-based approach;commercial system;pharaoh decoder;multi-engine machine translation;possible refinement;integrated architecture;heuristic algorithm;mt task;source sentence	We motivate our contribution to the shared MT task as a first step towards an integrated architecture that combines advantages of statistical and knowledge-based approaches. Translations were generated using the Pharaoh decoder with tables derived from the provided alignments for all four languages, and for three of them using web-based and locally installed commercial systems. We then applied statistical and heuristic algorithms to select the most promising translation out of each set of candidates obtained from a source sentence. Results and possible refinements are discussed. 1 Motivation and Long-term Perspective ”The problem of robust, efficient and reliable speech-to-speech translation can only be cracked by the combined muscle of deep and shallow processing approaches.” (Wahlster, 2001) Although this statement has been coined in the context of VerbMobil, aiming at translation for direct communication, it appears also realistic for many other translation scenarios, where demands on robustness, coverage, or adaptability on the input side and quality on the output side go beyond today’s technological possibilities. The increasing availability of MT engines and the need for better quality has motivated considerable efforts to combine multiple engines into one “super-engine” that is hopefully better than any of its ingredients, an idea pionieered in (Frederking and Nirenburg, 1994). So far, the larger group of related publications has focused on the task of selecting, from a set of translation candidates obtained from different engines, one translation that looks most promising (Tidhar and K̈ ussner, 2000; Akiba et al., 2001; Callison-Burch and Flournoy, 2001; Akiba et al., 2002; Nomoto, 2004). But also the more challenging problem of decomposing the candidates and re-assembling from the pieces a new sentence, hopefully better than any of the given inputs, has recently gained considerable attention (Rayner and Carter, 1997; Hogan and Frederking, 1998; Bangalore et al., 2001; Jayaraman and Lavie, 2005). Although statistical MT approaches currently come out as winners in most comparative evaluations, it is clear that the achievable quality of methods relying purely on lookup of fixed phrases will be limited by the simple fact that for any given combination of topic, application scenario, language pair, and text style there will never be sufficient amounts of pre-existing translations to satisfy the needs of purely data-driven approaches. Rule-based approaches can exploit the effort that goes into single entries in their knowledge repositories in a broader way, as these entries can be unfolded, via rule applications, into large numbers of possible usages. However, this increased generality comes at significant costs for the acquisition of the required knowledge, which needs to be encoded by specialists in formalisms requiring extensive training to be used. In order to push the limits of today’s MT technology, integrative approaches will have to be developed that combine the relative advantages of	algorithm;heuristic;information repository;lookup table;machine translation;pharaoh;verbmobil;web application;word lists by frequency	Andreas Eisele	2005			natural language processing;transfer-based machine translation;computer science;theoretical computer science;machine learning;algorithm	NLP	-25.037213429658145	-74.5636577990683	2251
6b142540de804f216b6a9a7c1cb4625de4f360f8	predicting relevant news events for timeline summaries	timeline;summarization;news event	This paper presents a framework for automatically constructing timeline summaries from collections of web news articles. We also evaluate our solution against manually created timelines and in comparison with related work.	timeline	Giang Binh Tran;Mohammad Alrifai;Dat Quoc Nguyen	2013		10.1145/2487788.2487829	timeline;computer science;automatic summarization;data mining;world wide web;information retrieval	Web+IR	-24.809972646910975	-55.47198425229542	2253
b797b191ccb066c7789f096b030d6b00ddac3b9d	slowee : a smart eating-speed guide system with light and vibration feedback	eating speed;eating monitoring;indigestion;obesity;esophageal cancer;feedback device	In this paper we introduce Slowee, a smart eating-speed guide system with light and vibration. Slowee aims to improve the user's eating habits by delivering right feedback in real time to the user while eating. We designed and implemented our system, Slowee, and conducted a pilot study to investigate the usability of Slowee and obtain feedbacks from the users. Although the number of the participants is rather small (n=10), the participants gave positive feedbacks on the potentials of Slowee. We expect that our device can help maintaining appropriate eating speed and chewing numbers for patients (e.g., those who have undergone esophageal resection) as well as for those who eat fast or chew less than the recommended number of times. As future work, we plan to conduct a long-term period study to evaluate the effectiveness of Slowee on the formation of an eating habit beyond immediate action improvements.	usability	Joohee Kim;Kwang-Jae Lee;Mankyung Lee;Nahyeon Lee;Byung-Chull Bae;Genehee Lee;Juhee Cho;Young Mog Shim;Jun-Dong Cho	2016		10.1145/2851581.2892323	obesity;simulation;multimedia	HCI	-58.61115176423111	-55.49804248851982	2255
138d6e475490f61333b7af0b381650d9bffbe438	text sentiment analysis based on fusion of structural information and serialization information		Tree-structured Long Short-Term Memory (Tree-LSTM) has been proved to be an effective method in the sentiment analysis task. It extracts structural information on text, and uses Long Short-Term Memory (LSTM) cell to prevent gradient vanish. However, though combining the LSTM cell, it is still a kind of model that extracts the structural information and almost not extracts serialization information. In this paper, we propose three new models in order to combine those two kinds of information: the structural information generated by the Constituency TreeLSTM and the serialization information generated by Long-Short Term Memory neural network. Our experiments show that combining those two kinds of information can give contributes to the performance of the sentiment analysis task compared with the single Constituency TreeLSTM model and the LSTM model.	artificial neural network;bidirectional search;effective method;experiment;gradient;long short-term memory;sentiment analysis;serialization;statistical parsing	Ling Gan;Houyu Gong	2017			serialization;sentiment analysis;artificial intelligence;natural language processing;computer science;fusion	NLP	-18.344501651387684	-71.75157479397211	2256
26a014c91802ade64fafc5c63cb75ee87cf33902	a case-based mechanical redesign system	system performance;general methods;cantilever beam;problem solving	We present a system, FIRST, that redesigns structural beams by accessing a case memory of solution plans. FIRST starts by analysing an existing design, using general knowledge about elementary physics. If design constraints are unsatisfied, FIRST searches for similar problem situations in its case memory and retrieves the solution plans associated to those situations. The system performs a transfer by analogy of each plan into the new problem situation and combines the transferred plans and symbolic analysis knowledge into a global redesign plan that is applied to the problem. FIRST is implemented in BB1, a blackboard system that allows the cooperation of problem solving knowledge from different sources. The system, that includes general methods for transferring a plan by analogy and mapping parts of it into a new problem situation is described through the analysis and redesign of a round cantilever beam. 1 Introduction Mechanical design is the process of going from a set of specifications to a physical artifact meeting those specifications. It is a very underconstrained process whose complexity has been pointed out in previous research [Howe et a/., 1987], [Mittal et a/., 1986]. Mechanical design rarely starts from first principles. Rather, an existing artifact is often modified until it meets the design specifications. Problems in which the structure of the redesigned artifact remains fixed throughout the modification process belong to the category of routine design problems. The knowledge to modify a particular design is traditionally encoded as rules or even plans that are instantiated during the solution process. More recent developments such as PROMPT [Murthy and Addanki, 1987] or l st PRINCE [Cagan and Agogino, 1988] have focused on the ability to derive routine and non-routine modifications by performing a symbolic analysis of the behavioral equations describing the design. Another possibility is to derive the modifications from similar cases. In a designer's memory, these cases represent the knowledge acquired on similar projects and make the difference between the expert and the novice designer. This redesign knowledge is naturally expressed by plans. Plans are attractive because they potentially embody all the knowledge required to successfully modify an artifact. Our work investigates the potential of a case-based approach to mechanical design. To serve that purpose, we have built a system that uses a case memory of past problems and solution plans to redesign structural beams. Beam analysis is interesting for various reasons. First, its theory is well established and …	blackboard system;class hierarchy;experiment;heuristic;problem solving	Francois Daube;Barbara Hayes-Roth	1989			cantilever;simulation;computer science;computer performance	AI	-87.5178938877461	-39.32195579728669	2257
74270adf31dc7590a7faea321f7e136b59aef8d2	achieving flexibility, efficiency, and generality in blackboard architectures	appropriate blackboard development tool;achieving flexibility;application code;general purpose blackboard database;blackboardbased ai application;customized blackboard database implementation;blackboard architecture;generic blackboard development system;blackboard representation;blackboard database implementation;blackboard implementation	Achieving flexibility and efficiency in blackboard-based AI applications are often conflicting goals. Flexibility, the ability to easily change the blackboard representation and retrieval machinery, can be achieved by using a general purpose blackboarddatabase implementation, at the cost of efficient performance for a particular application. Conversely, a customized blackboard-database implementation, while efficient, leads to strong interdependencies between the application code (knowledge sources) and the blackboard-database implementation. Both flexibility and efficiency can be achieved by maintaining a sufficient level of data abstraction between the application code and the blackboard implementation. The abstraction techniques we present are a crucial aspect of the generic blackboard-development system GBB. Applied in concert, these techniques simultaneously provide flexibility, efficiency, and sufficient generality to make GBB an appropriate blackboarddevelopment tool for a wide range of applications.	abstraction (software engineering);applications of artificial intelligence;blackboard system;interdependence	Daniel D. Corkill;Kevin Q. Gallagher;Philip J M Johnson	1987			blackboard system;computer science;knowledge management;artificial intelligence	AI	-29.461154057053818	-4.109523773437676	2263
ae0b1047339b6af13e7a12a6cfb7706263af8692	a one-pass search algorithm for understanding natural spoken time utterances by stochastic models	representation of syntactic and semantic knowledge;speech recognition;spoken man-machine-dialogue;one- pass search;language understanding;stochastic models;search algorithm;stochastic model;search space	A system for understanding time utterances spoken in German language is presented. Stochastic models contain the knowledge in the semantic, syntactic and acousticphonetic levels. An adequate semantic representation allows the integration of these models within a one-pass Viterbi search. The simultaneous use of all knowledge sources for the search procedure results in the smallest possible search space for the determination of the most probable semantic content accurately following the Bayes classification rule. Both the recognition accuracy and the computing speed facilitate a realistic application.	search algorithm;stochastic process;viterbi algorithm	Josef G. Bauer;Holger Stahl;Johannes Müller	1995			classification rule;stochastic modelling;viterbi algorithm;speech recognition;syntax;pattern recognition;artificial intelligence;semantic search;bayes' theorem;computer science;search algorithm	AI	-21.192100157358585	-87.72295973029905	2264
d2f1e8499c1c80361443a5049b348ea0f0162c6c	smart infusion pump limit violations and high alert medications: the role of the single step titration error prevention system				Cary Ikemoto;Tim Hoh;Idal Beer	2014			titration;real-time computing;infusion pump;engineering	AI	-58.369592109319576	-66.428563464532	2268
5412f43873694d883a0c7702bfdb9b7db90416d8	towards automatic detection of reported speech in dialogue using prosodic cues		The phenomenon of reported speech – whereby we quote the words, thoughts and opinions of others, or recount past dialogue – is widespread in conversational speech. Detecting such quotations automatically has numerous applications: for example, in enhancing automatic transcription or spoken language understanding applications. However, the task is challenging, not least because lexical cues of quotations are frequently ambiguous or not present in spoken language. The aim of this paper is to identify potential prosodic cues of reported speech which could be used, along with the lexical ones, to automatically detect quotations and ascribe them to their rightful source, that is reconstructing their attribution relations. In order to do so we analyze SARC, a small corpus of telephone conversations that we have annotated with attribution relations. The results of the statistical analysis performed on the data show how variations in pitch, intensity, and timing features can be exploited as cues of quotations. Furthermore, we build a SVM classifier which integrates lexical and prosodic cues to automatically detect quotations in speech that performs significantly better than chance.	automatic differentiation;lexicon;natural language understanding;pitch (music);support vector machine;transcription (software)	Alessandra Cervone;Catherine Lai;Silvia Pareti;Peter Bell	2015			indirect speech;speech recognition;support vector machine;attribution;spoken language;classifier (linguistics);computer science;phenomenon	NLP	-17.967395323131942	-81.05259314216441	2270
750b5934248360cf0c370b871dd8f515f5aea822	what makes an effective clinical query and querier?				Bevan Koopman;Guido Zuccon;Peter Bruza	2017	JASIST	10.1002/asi.23959	information retrieval;data mining;computer science	HCI	-41.73204562460677	-16.953962185425553	2271
79daa57bae62a244aecbf5091fad9d29625edbf5	user-centered approach in creating a metadata schema for video games and interactive media	video games;metadata;interactive media;seattle interactive media museum;cultural artifacts;description	Video games and interactive media are increasingly becoming important part of our culture and everyday life, and subsequently, of archival and digital library collections. However, existing organizational systems often use vague or inconsistent terms to describe video games or attempt to use schemas designed for textual bibliographic resources. Our research aims to create a standardized metadata schema and encoding scheme that provides an intelligent and comprehensive way to represent video games. We conducted interviews with 24 gamers, focusing on their video game-related information needs and seeking behaviors. We also performed a domain analysis of current organizational systems used in catalog records and popular game websites, evaluating metadata elements used to describe games. With these results in mind, we created a list of elements which form a metadata schema for describing video games, with both a core set of 16 elements and an extended set of 46 elements providing more flexibility in expressing the nature of a game.	archive;controlled vocabulary;database schema;digital library;domain analysis;faceted classification;functional requirements for bibliographic records;information needs;interactive media;library (computing);library of congress subject headings;line code;organizational behavior;organizing (structure);simm;user-centered design;vagueness;video clip;xml schema	Jin Ha Lee;Hyerim Cho;Violet Fox;Andrew Perti	2013		10.1145/2467696.2467702	cultural artifact;computer science;multimedia;interactive media;internet privacy;metadata;world wide web;metadata repository	HCI	-46.31183441252261	-23.50372943047319	2274
42c52128e806f55823b94e7d53c7f29a20953d4f	combining concept maps and bibliometric maps: first explorations	bibliometrie;etude utilisateur;maps;concept;interfase usuario;mapa;visualizacion;user interface;user study;sciences;information mapping;bibliometria;estudio usuario;cartografia informacion;science policy;carte;ciencia;visualization;visualisation;concept map;bibliometrics;cartographie information;interface utilisateur;concepto	Bibliometric maps of science are a well-established research subject. But their adoption as a science policy support tool is lacking. We think this is because the user does not immediately comprehend a map and (as a result) is not enticed into using it. To help this comprehension, we propose the use of “qualitative maps”: an umbrella term for diverse tools such as concept maps and mental maps. We developed a tool that interfaces between a qualitative map and a bibliometric map which lets the user create a correspondence between the distinct vocabularies of the maps. We also conducted two user studies: the first explored the combined use of bibliometric and qualitative maps and the second the preferred format of the map and the word-usage in the description of its elements.	bibliometrics;cognitive map;concept map;umbrella term;usability testing;vocabulary	R. K. Buter;Ed C. M. Noyons;M. Van Mackelenbergh;T. Laine	2006	Scientometrics	10.1007/s11192-006-0027-y	visualization;human–computer interaction;computer science;artificial intelligence;data mining	HCI	-61.72428856316773	-49.00282391634833	2277
e15216728b39b21ce84c90f96a8433a7a3018ec1	representing affective facial expressions for robots and embodied conversational agents by facial landmarks	robots;embodied conversational agents;emotion;facial expression;facial landmarks;facetracker	Affective robots and embodied conversational agents require convincing facial expressions to make them socially acceptable. To be able to virtually generate facial expressions, we need to investigate the relationship between technology and human perception of affective and social signals. Facial landmarks, the locations of the crucial parts of a face, are important for perception of the affective and social signals conveyed by facial expressions. The goal of our study is to determine to what extent facial landmarks are sufficient to represent facial expressions of emotions. If facial landmarks contain sufficient information, it should be possible to recognize and generate emotional expressions based on the landmarks only. This study focusses on the human recognition of emotional expressions from landmark sequences. Using face-analysis software, we digitally extracted landmark sequences from full-face videos of acted emotions. The landmark sequences were presented to sixteen participants who were instructed to classify the sequences according to the emotion represented. The results of the experiment revealed that participants were able to recognize the emotion reasonably well from the landmark sequences, suggesting that landmarks contain information about the expressed emotions. The implications of our findings for the virtual generation of facial expressions in robots and embodied conversational agents are discussed. We conclude by stating that landmarks provide a sufficient basis for the virtual generation of emotions in humanoid agents. Caixia Liu · Jaap Ham · Cees Midden Human-Technology Interaction Group, Department of Industrial Engineering and Innovation Sciences, Eindhoven University of Technology, Eindhoven, The Netherlands E-mail: {c.liu, j.r.c.ham, c.j.h.midden}@tue.nl Caixia Liu · Eric Postma · Bart Joosten · Martijn Goudbeek Tilburg center for Cognition and Communication, Tilburg University, Tilburg, The Netherlands E-mail: {e.o.postma, b.joosten, m.b.goudbeek}@tilburguniversity.edu	cognition;dialog system;embodied agent;facial recognition system;industrial engineering;regular expression;robot;eric	Caixia Liu;Jaap Ham;Eric O. Postma;Cees J. H. Midden;Bart Joosten;Martijn Goudbeek	2013	I. J. Social Robotics	10.1007/s12369-013-0208-9	computer vision;facial action coding system	AI	-54.71699691447936	-51.27301997271251	2278
44634d7a2848def5a751aa5441ec84d1339a3b82	the myth of technological neutrality in copyright and the rights of institutional users: recent legal challenges to the information organization as mediator and the impact of the dmca, wipo, and teach	utilisation information;legislation;distance education;fair use;teleenseignement;north america;intellectual property;informacion electronica;america del norte;droit auteur;amerique du nord;information use;amerique;copyright;ownership;etats unis;estados unidos;information organization;information electronique;teach technology education and copyright harmonization;ompi organisation mondiale de la propriete intellectuelle;legislacion;propiedad intelectual;medio ambiente electronico;electronic environment;copyrights;dmca digital millennium copyright act;electronic information;teleensenanza;enseignement;remote teaching;america;utilizacion informacion;propriete intellectuelle;federal legislation;uso leal;teaching;derecho autor;environnement electronique;ensenanza	This article discusses the accelerating trend of ownership rights in digital property, copyright, in specific. This trend is in contrast to the stated legislative purpose of copyright law to be neutral as to the technology that either owners employ to embody the copyrighted work or that others employ to facilitate access and use of the work. Recent legislative initiatives as well as interpretive court decisions have undermined this important concept. There is an ascendancy of digital ownership rights that threatens to undermine the concept of technological neutrality, which in essence guarantees that ownership and well as “use” rights apply equally to analog and digital environments. The result of this skewing is twofold: an unstable environment with respect to the access and use rights of individuals, institutions, and other users of copyrighted material, and the incentive of copyright owners to present works to the public in digital formats alone, where ownership rights are strongest. This article attempts to plot that digital ascendancy and demonstrate the undermining of neutrality principles.	ascendancy;control theory;digital millennium copyright act;digital data;digital media;knowledge organization;mike lesser;net neutrality	Tomas A. Lipinski	2003	JASIST	10.1002/asi.10269	distance education;education;social science;law;intellectual property;reservation of rights	HCI	-76.32207262477398	-12.630094415385383	2279
1c81836fb6281e5f3f49544eeec05d9b0dd61643	asynchronous data replication: a national integration strategy for databases on telemedicine network	databases;telemedicine distributed databases medical information systems relational databases;national integration strategy;software;portals;distributed database;computed tomography;image databases;telemedicine networks;telemedicine biomedical imaging image databases medical diagnostic imaging relational databases picture archiving and communication systems portals hemodynamics computed tomography hospitals;telemedicine;medical distributed databases;personal patient information;hospitals;biomedical imaging;data replication;relational database;hemodynamics;servers;telemedicine network database;relational database postgresql;telemedicine networks distributed databases data replication;medical information systems;asynchronous data replication;integral operator;distributed databases;relational database postgresql asynchronous data replication national integration strategy telemedicine network database personal patient information medical distributed databases postgresreplication;postgresreplication;relational databases;medical diagnostic imaging;picture archiving and communication systems	Telemedicine systems currently have increased the volume of information stored in their databases. A centralized telemedicine system project covers datasets that ranges from personal patient's information, physicians and institutions to all images of examinations performed. As they store large amounts of examinations, the medical databases can reach several terabytes of volume. This paper presents a contribution characterized by an asynchronous replication model for medical distributed databases. The model, called postgresreplication, is an extension to the relational database postgreSQL. In our experiment, an engine has been created to manage all integration operations and information replication for the medical databases. The early results indicate that the model and its implementation have successfully reached a good performance level and interoperability.	centralized computing;distributed database;interoperability;postgresql;relational database;replication (computing);terabyte	Douglas Dyllon Jeronimo de Macedo;Hilton Ganzo William Perantunes;Rafael Andrade;Aldo von Wangenheim;Mario A. R. Dantas	2008	2008 21st IEEE International Symposium on Computer-Based Medical Systems	10.1109/CBMS.2008.76	relational database;computer science;data mining;database;world wide web;distributed database	DB	-53.32711761557243	-63.111520807057346	2281
eebd3508d029370577c85a1d1fb1f4d4f4803737	real-time traffic simulation using cellular automata	real time traffic;categories and subject descriptors according to acm ccs i 3 5 computer graphics computational geometry and object modeling physically based modeling;keywords traffic simulation mesoscopic simulation cellular automata road generation vehicle animation;i 6 8 simulation and modeling types of simulation animation;cellular automata	In this paper, we present a method to simulate large-scale traffic networks, at real-time frame-rates. Our novel contributions include a method to automatically generate a road graph from real-life data, and our extension to a discrete traffic model, which we use to simulate traffic, demonstrating continuous vehicle motion between discrete locations. Given Ordnance Survey data, we automatically generate a road graph, identifying roads, junctions, and their connections. We distribute cells at regular intervals throughout the graph, which are used as discrete vehicle locations in our traffic model. Vehicle positions are then interpolated between cells to obtain continuous animation. We test the performance of our model using a 500 x 500m2 area of a real city, and demonstrate that our model can simulate over 600 vehicles at real-time frame-rates (> 80% network density).	cellular automaton;graphics processing unit;interpolation;real life;real-time clock;real-time transcription;scalability;screenshot;simulation;viewing frustum	Christopher S. Applegate;Stephen D. Laycock;Andrew M. Day	2010		10.2312/LocalChapterEvents/TPCG/TPCG10/091-098	simulation;computer science;theoretical computer science;network traffic simulation;computer graphics (images)	Graphics	-24.31717782490323	-36.688250394099704	2289
a0e0614994d715789142720e961e5018135b611b	new trends within the basic training of i.t. professionals in israel	basic training;t. professionals;new trends			Ben-Zion Barta;Moshe Telem	1992			engineering management;family medicine;medicine	NLP	-73.93358972617362	-33.15765346015553	2290
994b91f6348b01cfd4fdab3209eff72734eabe8f	conceptualization of hybrid web sites	semantics;conceptual model;information content;worldwide web;irregular domain;virtual campus;entity relationship;design methodology	Purpose – The purpose of this paper is to provide a mechanism to characterize web sites, at the conceptualization stage, whose information content can be defined in terms of hybrid conceptual models. Usually in this type of web site, some of the domain information units are modeled in terms of classes/entities while others remain as heterogeneous irregular elements. Web sites built on this type of hybrid conceptual domain are referred to as hybrid web sites in this paper.Design/methodology/approach – The paper characterizes a hybrid web site, at the conceptualization stage – the site of the Virtual Campus of the Universidad Complutense de Madrid. For the characterization of this site the Pipe notation, a notation that has proven to be appropriate when characterizing web sites built on irregular domains, was used. In addition, the Pipe notation was combined with entity‐relationship diagrams to characterize the most homogeneous and regular elements of the web site. The paper also analyzed several alternativ...	conceptualization (information science)	Antonio Navarro;Alfredo Fernández-Valmayor	2007	Internet Research	10.1108/10662240710737059	web modeling;simulation;data web;self-information;design methods;entity–relationship model;computer science;conceptual model;social semantic web;semantics;multimedia;world wide web	ECom	-35.76697134479118	-12.412933825012177	2292
292ef593d656d6972e50ac773232562fd705c396	processing social media data for crisis management in athena		During a crisis citizens turn to their smartphones. They report what they see, they comment on other’s reports, they offer their help, support and sympathy and, in doing so, they create vast amounts of data. Meanwhile, law enforcement agencies (LEAs) and first responders  including humanitarian relief agencies are desperately trying to improve their own situational awareness, but can struggle to do so, especially in places that cannot be easily, quickly or safely reached. Since this user-generated content is often posted to social media, LEAs can tap into these resources by analysing this data. However, making sense of this data is not straightforward. In this paper we present a system that is able to process and analyse this data through categorisation and crisis taxonomies, classification techniques and sentiment analysis. This processed data can then be presented back to LEAs in informative ways to allow them to enhance their situation awareness of the current crisis.	social media	Babak Akhgar;Helen Gibson	2015		10.1007/978-3-319-23276-8_1	public relations;engineering;data mining;computer security	DB	-22.04983388166698	-55.10211977278446	2295
685200cf23b57306a39e97fd3d95dea4751fe468	source and system features for speaker recognition using aann models	linear predictive;speaker recognition;feature vector;linear predictive coding;feature extraction;learning artificial intelligence speaker recognition feature extraction feedforward neural nets linear predictive coding;feedforward neural nets;learning artificial intelligence;linear predictive cepstral coefficients;speech production;speaker models speaker recognition feature extraction linear prediction analysis linear prediction cepstral coefficients feedforward autoassociative neural network;neural network;speaker recognition cepstral analysis speech analysis feature extraction speech processing production systems neural networks feedforward neural networks vectors system testing	In this paper we study the effectiveness of the features extracted from the source and system components of speech production process for the purpose of speaker recognition. The source and system components are derived using linear prediction (LP) analysis of short segments of speech. The source component is the LP residual derived from the signal, and the system component is a set of weighted linear prediction cepstral coefficients. The features are captured implicitly by a feedforward autoassociative neural network (AANN). Two separate speaker models are derived by training two AANN models using feature vectors corresponding to source and system components. A speaker recognition system for 20 speakers is built and tested using both the models to evaluate the performance of source and system features. The study demonstrates the complementary nature of the two components.	artificial neural network;autoassociative memory;cepstrum;coefficient;feature vector;feedforward neural network;speaker recognition	Bayya Yegnanarayana;K. Sharat Reddy;Kishore Prahallad	2001		10.1109/ICASSP.2001.940854	speaker recognition;speech production;linear predictive coding;speech recognition;feature vector;feature extraction;computer science;machine learning;pattern recognition;time delay neural network	NLP	-15.519155214768444	-89.33655177408454	2297
4fd47c78bcfb9e54049dbd558fd798d82560c3f5	2018 ieee real-time systems symposium, rtss 2018, nashville, tn, usa, december 11-14, 2018					2018				Embedded	-54.15805188097128	-6.17976504477917	2298
de4dc99849bea9f59accb3f04d792bbfa155c189	human-centered design of an mhealth app for the prevention of burnout syndrome		BACKGROUND Stress-related disorders have become one of the main health problems in many countries and organizations worldwide. They can generate depression and anxiety, and could derive in work absenteeism and reduction in productivity.   OBJECTIVE Design, develop, and evaluate an mHealth App for the prevention of Burnout Syndrome following the recommendations of standard User-Centered Design methodologies.   RESULTS 1) A descriptive cross-sectional study was performed on a sample of 59 faculty members and workers at the University of Cauca, Colombia using the Maslach Burnout Inventory as an instrument for measuring Burnout, accompanied by a demographic and technological questionnaire. 2) Three prototypes of the mHealth App were iteratively developed following the recommendations provided by the ISO Usability Maturity Model and the ISO User-Centered Design model. 3) Usability tests of the system were performed based on the ISO 9126 standard.   CONCLUSIONS The results obtained are considered positive, particularly those regarding user's satisfaction measured using the System Usability Scale.	absenteeism;anxiety disorders;capability maturity model;cross-sectional data;deploy;depressive disorder;description;fifty nine;futures studies;iso/iec 9126;isoproterenol;mhealth;software deployment;stiff-person syndrome;system usability scale;trichohepatoenteric syndrome;user-centered design	Santiago Narváez;Ángela M. Tobar;Diego M. Lopez;Bernd Blobel	2016	Studies in health technology and informatics	10.3233/978-1-61499-678-1-215	applied psychology;knowledge management;anxiety;burnout;system usability scale;absenteeism;nursing;capability maturity model;mhealth;usability;user-centered design;medicine	HCI	-61.90570492203498	-62.617338538501265	2299
b168e5716b0520fee549c0c03c7a89999d3ffd73	counting practice with pictures, but not objects, improves children's understanding of cardinality		When counting, the final word used to tag the final item in a set represents the cardinality, or total number, of the set. Understanding of this concept serves as a foundation for children’s basic mathematical skills. However, little is known about how the early learning environment can be structured to help children understand this important concept. The current study examined the effects of the representational status of tobe-counted items on preschoolers’ understanding of cardinality. Children (M age = 3 years, 6 months) were randomly assigned to receive counting practice with either physical objects or pictures over five practice sessions. Children’s counting skill and understanding of cardinality were assessed at pretest and posttest. Results revealed that only children in the picture condition increased their understanding of cardinality from pretest to posttest. These results suggest that picture books are better than physical objects at supporting children’s understanding of cardinality.	book;image;randomness;the current	Lori Petersen;Nicole McNeil;Alice Tollaksen;Alexander Boehm;Casey Hall;Cristina Carrazza;Brianna Devlin	2014				HCI	-74.17972882049546	-46.28626979327777	2300
95886c45023a88c0a7da37ead205e24fcc7ebd74	semi-supervised microblog clustering method via dual constraints	dual constraints;term correlation matrix;nonnegative matrix factorization;期刊论文;microblogs;semi supervised clustering	In this paper, we present a semi-supervised clustering method for microblog in which both word-level and microblog document-level constraints are automatically generated totally based on statistical information rather than any kind of external knowledge. The key idea is first to explore term correlation data, which investigates both inter and intra correlation of words, and the initial similarity between words can therefore be deduced. And then an iterative method is established to calculate both word similarity and microblog similarity. The mechanism of incorporating dual constraints is presented based on word similarity and microblog similarity. We then formulate short text clustering problem as a non-negative matrix factorization based on dual constraints. Empirical study of two real-world dataset shows the superior performance of our framework in handling noisy and microblogs.	lagrange multiplier;semiconductor industry	Huifang Ma;Meihuizi Jia;Weizhong Zhao;Xianghong Lin	2015		10.1007/978-3-319-25159-2_33	computer science;microblogging;machine learning;pattern recognition;data mining;non-negative matrix factorization	NLP	-19.96321276104149	-65.65927238049946	2310
43ff478e92a221a7326aa29405bc561b0a856b60	course and exercise sequencing using metadata in adaptive hypermedia learning systems	adaptive hypermedia;learning object metadata;sequencing of course material;learning system;educational resource;adaptive hypermedia systems;adaptive hypermedia system;hypermedia learning;dublin core;knowledge engineering	In the last few years the (semi-) automatic sequencing of course    material has become an important research issue, particularly the           standardization of metadata for educational resources. Sequencing can help to generate hypermedia documents which, at their best match the learner's   needs. To perform (semi-) automatic course sequencing, a knowledge library as well as modular resources can be used. Both must be described by         metadata.                                                                                                                                       First, metadata standards (IEEE Learning Objects Metadata,             Instructional Mangement Systems Global Learning Consortium, Dublin Core) are analyzed with regard to course  sequencing.    As an application example, Multibook, an adaptive hypermedia system used to teach multimedia technology, is described. Multibook uses metadata to create course sequences semi-automatically. In this article we explain how a knowledge library can be used to create exercises automatically. We give an example of how courses can be sequenced in general by analyzing the creation of exercises. An evaluation of our system shows the advantages and drawbacks of the automatic sequencing approach.  are analyzed with regard to course sequencing. As an application example, Multibook uses metadata to create course sequences semi-automatically. In this article we explain how a knowledge library can be used to create automatically. We give an example of how courses can be sequenced in general by  analyzing the creation of exercises. An evaluation of our system shows the advantages and drawbacks of the automatic course sequencing approach.	adaptive hypermedia;consortium;dublin core;learning object metadata;multibook;semiconductor industry	Stephan Fischer	2001	ACM Journal of Educational Resources in Computing	10.1145/376697.376700	computer science;knowledge management;artificial intelligence;software engineering;knowledge engineering;multimedia;world wide web	Comp.	-83.15166673958672	-44.6302778251466	2311
0be03f34b8bcecc8a4d6ed46b7a84d9579847d6a	a method to combine linguistic ontology-mapping techniques	distributed system;ontologie;linguistique;systeme reparti;correspondance ontologie;ontology mapping;industrie alimentaire;web semantique;industria alimenticia;linguistica;sistema repartido;food industry;web semantica;semantic web;ontologia;ontology;correspondencia ontologia;linguistics	We discuss four linguistic ontology-mapping techniques and evaluate them on real-life ontologies in the domain of food. Furthermore we propose a method to combine ontology-mapping techniques with high Precision and Recall to reduce the necessary amount of manual labor and computation.	computation;ontology (information science);precision and recall;real life;semantic integration	Willem Robert van Hage;Sophia Katrenko;Guus Schreiber	2005		10.1007/11574620_52	natural language processing;food industry;semantic integration;computer science;semantic web;ontology;data mining;linguistics;world wide web	NLP	-36.70742062200215	-64.36742379048057	2314
14208612112d357e2d21db4a84ee2ebff0629cee	special issue for the sbrn guest editorial				Marley M. B. R. Vellasco;Marcílio Carlos Pereira de Souto;André Carlos Ponce de Leon Ferreira de Carvalho	2010	Neurocomputing	10.1016/j.neucom.2010.08.011	machine learning;artificial intelligence;mathematics	NLP	-51.844463345739136	-13.666991893683266	2318
c3efda7a65ead87f28fd804afaf155a26fcb7946	integrating rich information for video recommendation with multi-task rank aggregation	video recommendation;information sources;multi task rank aggregation;multi task learning;rank aggregation	Video recommendation is an important approach for helping people to access interesting videos. In this paper, we propose a scheme to integrate rich information for video recommendation. We regard video recommendation as a ranking problem and generate multiple ranking lists by exploring different information sources. A multi-task rank aggregation approach is proposed to integrate the ranking lists for different users in a joint manner. Our scheme is flexible and can easily incorporate other methods by adding their generated ranking lists into our multi-task learning algorithm. We conduct experiments with 76 users and more than 10,000 videos. The results demonstrate the feasibility and effectiveness of our approach.	algorithm;computer multitasking;experiment;multi-task learning;video	Xiaojian Zhao;Guangda Li;Meng Wang;Jin Yuan;Zheng-Jun Zha;Zhoujun Li;Tat-Seng Chua	2011		10.1145/2072298.2072055	multi-task learning;computer science;machine learning;data mining;world wide web;information retrieval	AI	-19.871667978615104	-48.01546542682881	2321
1753c2dc85cc40e0a2e8b4a405c1690eab066d8d	fennel: streaming graph partitioning for massive scale graphs	streaming;distributed computing;balanced graph partitioning	Balanced graph partitioning in the streaming setting is a key problem to enable scalable and efficient computations on massive graph data such as web graphs, knowledge graphs, and graphs arising in the context of online social networks. Two families of heuristics for graph partitioning in the streaming setting are in wide use: place the newly arrived vertex in the cluster with the largest number of neighbors or in the cluster with the least number of non-neighbors.  In this work, we introduce a framework which unifies the two seemingly orthogonal heuristics and allows us to quantify the interpolation between them. More generally, the framework enables a well principled design of scalable, streaming graph partitioning algorithms that are amenable to distributed implementations. We derive a novel one-pass, streaming graph partitioning algorithm and show that it yields significant performance improvements over previous approaches using an extensive set of real-world and synthetic graphs.  Surprisingly, despite the fact that our algorithm is a one-pass streaming algorithm, we found its performance to be in many cases comparable to the de-facto standard offline software METIS and in some cases even superiror. For instance, for the Twitter graph with more than 1.4 billion of edges, our method partitions the graph in about 40 minutes achieving a balanced partition that cuts as few as 6.8% of edges, whereas it took more than 81/2 hours by METIS to produce a balanced partition that cuts 11.98% of edges. We also demonstrate the performance gains by using our graph partitioner while solving standard PageRank computation in a graph processing platform with respect to the communication cost and runtime.	computation;graph (abstract data type);graph partition;heuristic (computer science);interpolation;knowledge graph;metis;online and offline;pagerank;scalability;social network;streaming algorithm;synthetic intelligence	Charalampos E. Tsourakakis;Christos Gkantsidis;Bozidar Radunovic;Milan Vojnovic	2014		10.1145/2556195.2556213	pathwidth;graph bandwidth;graph product;computer science;graph partition;clique-width;theoretical computer science;machine learning;comparability graph;data mining;voltage graph;distance-hereditary graph;distributed computing;graph;world wide web;complement graph;strength of a graph	ML	-10.78557801477907	-40.788251929287235	2326
3f827c57222145aa08c052487c01c132bd0144b8	a smooth transition to modern mathoid-based math rendering in wikipedia with automatic visual regression testing		Pixelated images of mathematical formulae, which are inaccessible to screen readers and computer algebra systems, disappeared recently from Wikipedia. In this paper, we describe our efforts in maturing mathoid, the new services that provides better math rendering to Wikipedia, from a research prototype to a production service and a novel visual similarity image comparison tool designed for regression testing mathematical formulae rendering engines. Currently, updates to Math rendering engines that are used in production are infrequent. Due to their high complexity and large variety of special cases, developers are intimidated by the dangers involved in introducing new features and resolving non critical problems. Today’s hardware is capable of rendering large collections of mathematical contents in a reasonable amount of time. Thus, developers can run their new algorithms before using them in production. However, until now they could not identify the most significant changes in rendering due to the large data volume and necessity for human inspection of the results. The novel image comparison tool we are proposing, will help to identify critical changes in the images and thus lower the bar for improving production level mathematical rendering engines.	algorithm;computer algebra system;list of 3d rendering software;pixelation;prototype;regression testing;scalability;web browser engine;wikipedia	Moritz Schubotz;Alan P. Sexton	2016			rendering (computer graphics);regression testing;computer science;computer vision;artificial intelligence	Graphics	-40.5726177177974	-32.58115387737325	2333
9f7970f363fc70bc01449f3b0596a00344400987	transitlabel: a crowd-sensing system for automatic labeling of transit stations semantics	railway stations;indoor location based service;automatic floorplans construction;crowdsourcing;activity recognition	We present TransitLabel, a crowd-sensing system for automatic enrichment of transit stations indoor floorplans with different semantics like ticket vending machines, entrance gates, drink vending machines, platforms, cars' waiting lines, restrooms, lockers, waiting (sitting) areas, among others. Our key observations show that certain passengers' activities (e.g., purchasing tickets, crossing entrance gates, etc) present identifiable signatures on one or more cell-phone sensors. TransitLabel leverages this fact to automatically and unobtrusively recognize different passengers' activities, which in turn are mined to infer their uniquely associated stations semantics. Furthermore, the locations of the discovered semantics are automatically estimated from the inaccurate passengers' positions when these semantics are identified. We evaluate TransitLabel through a field experiment in eight different train stations in Japan. Our results show that TransitLabel can detect the fine-grained stations semantics accurately with 7.7% false positive rate and 7.5% false negative rate on average. In addition, it can consistently detect the location of discovered semantics accurately, achieving an error within 2.5m on average for all semantics. Finally, we show that TransitLabel has a small energy footprint on cell-phones, could be generalized to other stations, and is robust to different phone placements; highlighting its promise as a ubiquitous indoor maps enriching service.	gene ontology term enrichment;map;mined;mobile phone;purchasing;sensor;signature	Moustafa Elhamshary;Moustafa Youssef;Akira Uchiyama;Hirozumi Yamaguchi;Teruo Higashino	2016		10.1145/2906388.2906395	real-time computing;simulation;telecommunications;computer science;artificial intelligence;world wide web;computer security;crowdsourcing;activity recognition	Mobile	-19.3460321393652	-31.65264681968965	2334
059e9552035c06658829a2e382e118acd2c28eed	representing public health nursing intervention concepts with hhcc and nic		PURPOSE It is imperative that public health nurses define their services and provide evidence supporting the effectiveness of interventions. The purpose of this paper is to examine the ex-tent to which two standardized nursing terminologies--Home Health Care Classification (HHCC) and Nursing Interventions Classification (NIC)--represent public health nursing practice according to core public health function in Public Health Nursing Intervention model.   METHODS First, we divided all HHCC and NIC interventions into intervention focus levels: individual/family-focused, community-focused, and system-focused. Second, we categorized HHCC and NIC interventions according to core public health functions: assessment, policy development, and assurance and the categories of interventions in the PHI Model.   RESULTS We identified HHCC and NIC Nursing interventions that represented public health nursing concepts across core public health functions and categories of the PHI model. Analysis of the findings demonstrated that HHCC and NIC have terms for the concepts in the PHI model.   CONCLUSION Although HHCC and NIC cover many concepts in public health nursing practice, additional research is needed to extend these terminologies and to evaluate other standardized terminologies that can reflect more comprehensively public health nursing interventions.	categories;categorization;discipline of nursing;health information systems;imperative programming;information system;network interface controller;nursing interventions classification;public health nursing;public health practice;standardized nursing terminology	Nam-Ju Lee;Suzanne Bakken;Virginia K. Saba	2004	Studies in health technology and informatics	10.3233/978-1-60750-949-3-525	public health nursing;knowledge management;family medicine;nursing;medicine	HCI	-61.677604521704446	-63.720558320509596	2340
561878a533dfa5a50f0bac19f2ee14d8e3034899	programming challenges: the programming contest training manual	programming challenge;programming contest training manual;programming contest training	There are many distinct pleasures associated with computer programming. Craftsmanship has its quiet rewards, the satisfaction that comes from building a useful object and making it work. Excitement arrives with the flash of insight that cracks a previously intractable problem. The spiritual quest for elegance can turn the hacker into an artist. There are pleasures in parsimony, in squeezing the last drop of performance out of clever algorithms and tight coding. The games, puzzles, and challenges of problems from international programming competitions are a great way to experience these pleasures while improving your algorithmic and coding skills. This book contains over 100 problems that have appeared in previous programming contests, along with discussions of the theory and ideas necessary to attack them. Instant online grading for all of these problems is available from two WWW robot judging sites. Combining this book with a judge gives an exciting new way to challenge and improve your programming skills. This book can be used for self-study, for teaching innovative courses in algorithms and programming, and in training for international competition.	adobe flash;algorithm;competitive programming;computational complexity theory;computer programming;maximum parsimony (phylogenetics);occam's razor;www	Steven Skiena;Miguel A. Revilla	2003	SIGACT News	10.1145/945526.945539	mathematical optimization;combinatorics;programming domain;reactive programming;computer science;theoretical computer science;mathematics;distributed computing;inductive programming;programming language;algorithm	Theory	-61.364713705669814	-23.207346620091016	2350
49adc7ecdb9d66fc48b3ed6803ae75283647e5a9	response order effects in online surveys: an empirical investigation	primacy effect;experimental design;online survey;recency effects;response order effects	Online surveys are fast becoming the favourite tools of researchers due to various advantages they offer like ease of administration, reduced survey cost and real time data analysis. However they also have their drawbacks like any survey method; some of them being lack of population representativeness due to digital divide, consideration of the survey as spam eliciting low responses and technical glitches. Survey errors are generally classified in to two groups of Sampling & non-Sampling errors. Respondent errors, one of the most widely studied non-Sampling errors consist of Primacy and recency effects. The response order effects both Primacy and Recency have not been studied in online surveys according to accessible literatures; though their effect in oral and paper -pencil surveys are well documented. The existence of respondent errors in online surveys may vary vastly from other survey methods due to the respondent characteristics like higher education levels, control on the response setting and time and independence in response in the absence of a survey administrator. Using an experimental design we examined and provided preliminary evidence for response order effect (Primacy effect) in online surveys. We have also explored the impact of question complexity and questionnaire length on response order effects. The results indicate the existence of response order effects in online surveys, much like the traditional methods. The result also indicates the exacerbation of response errors due to question complexity and questionnaire length. Our study may offer valid insights and ideas to survey researchers, who use online survey tools, to reduce response order effects and thereby make their survey results more accurate.		M. A. Sanjeev;Parul Balyan	2014	IJOM	10.4018/ijom.2014040103	psychology;econometrics;simulation;social psychology	HCI	-87.08809277687396	-24.230674787063872	2352
33f33197434dbcb6dbe5b2f5e27d646262fcd19d	generative content models for structural analysis of medical abstracts	hidden markov models;support vector machines;important domain;discourse structure;content structure;structural analysis;certain condition;generative model;discriminative technique;generative content model;medical abstract;application level;generative approach	The ability to accurately model the content structure of text is important for many natural language processing applications. This paper describes experiments with generative models for analyzing the discourse structure of medical abstracts, which generally follow the pattern of “introduction”, “methods”, “results”, and “conclusions”. We demonstrate that Hidden Markov Models are capable of accurately capturing the structure of such texts, and can achieve classification accuracy comparable to that of discriminative techniques. In addition, generative approaches provide advantages that may make them preferable to discriminative techniques such as Support Vector Machines under certain conditions. Our work makes two contributions: at the application level, we report good performance on an interesting task in an important domain; more generally, our results contribute to an ongoing discussion regarding the tradeoffs between generative and discriminative techniques.	automatic summarization;computational linguistics;discriminative model;experiment;generative model;hidden markov model;information system;machine learning;markov chain;natural language processing;ontology (information science);question answering;stateless protocol;structural analysis;support vector machine;text corpus	Jimmy Lin;Damianos Karakos;Dina Demner-Fushman;Sanjeev Khudanpur	2006		10.3115/1567619.1567631	natural language processing;computer science;data science;machine learning;data mining;generative design	NLP	-21.712602030265955	-66.16162592350457	2355
5ee8aa82ea391c6cfe33ede6851ccd13156ccc33	a gis-based evaluation of the effectiveness and spatial coverage of public transport networks in tourist destinations	public transport;tourism;geographic information systems;seasonality;spatial coverage	This article develops a methodology for evaluating the effectiveness and spatial coverage of public transport in tourist cities. The proposed methodology is applied and validated in Cambrils municipality, in the central part of the Costa Daurada in Catalonia, a coastal destination characterised by the concentration of tourism flows during summer. The application of GIS spatial analysis tools allows for the development of a system of territorial indicators that spatially correlate the public transport network and the distribution of the population. The main novelty of our work is that this analysis not only includes the registered resident population, but also incorporates the population that temporarily inhabits the municipality (tourists). The results of the study firstly permit the detection of unequal spatial accessibility and coverage in terms of public transport in the municipality, with significant differences between central neighbourhoods and peripheral urban areas of lower population density. Secondly, they allow observation of how the degree of public transport coverage differs significantly in areas with a higher concentration of tourist accommodation establishments.	accessibility;geographic information system;peripheral;spatial analysis	Antoni Domènech;Aaron Gutiérrez	2017	ISPRS Int. J. Geo-Information	10.3390/ijgi6030083	environmental engineering;geography;environmental protection	HCI	-12.463038494570599	-23.77040236784616	2357
6925ea1e7e83f86fa72b6368537d186960784b16	time for our field to grow up	scientific community;computer science colleague;own worst enemy;data management problem;engineering field;information management research;brief existence;computer science;research dollar;conference system	Compared to centuries of physics and millennia of mathematics, the 50-year-history of computer science and information management research makes us the toddlers of the scientific community. Yet during our brief existence, we’ve revolutionized the world and, not content with that, gone on to build and study virtual worlds. We have justly taken pride in our accomplishments, and developed our own unique way of conducting research, unlike other scientific and engineering fields. But cracks have appeared in this edifice we have built. The conference system that served us so well for our first 50 years is falling apart. Our ever-increasing population competes ever more energetically for a finite set of resources. Other scientific and engineering disciplines still think that our field equates to programming, and look down on us. While we may also look down on them, it is undeniably true that high-energy physicists get many more research dollars per capita than we do, and our computer science colleagues wonder whether all the data management problems haven’t already been solved. Other departments have started to teach courses that overlap our turf. Are we our own worst enemies? Why doesn’t everyone understand how important our research is? Do we have to abandon the conference system? Must we become more like the stodgy old fields of science and engineering? Or can we find our own way?	history of computer science;history of computing hardware;information management;virtual world	Anastasia Ailamaki;Laura M. Haas;H. V. Jagadish;David Maier;M. Tamer Özsu;Marianne Winslett	2010	PVLDB	10.14778/1920841.1921070	simulation;computer science;operations research	DB	-59.5010061656574	-23.309155437123028	2360
d46c422a6ea8cb3c92199f07c7fdf2ce8d736fba	application and evaluation of open wonderland in constructing web based 3d virtual world: a case study			open wonderland;virtual world	V Vani;R. Pradeep Kumar;S. Mohan;Esrah Livingston	2011			computer science;web application;human–computer interaction;multimedia	Web+IR	-49.696236747252534	-32.824489600305036	2374
13f48de90deb26c202b22b774c757c9a7104908b	choices in batch information retrieval evaluation	information retrieval;relevance judgment;effectiveness;evaluation	"""Web search tools are used on a daily basis by billions of people. The commercial providers of these services spend large amounts of money measuring their own effectiveness and benchmarking against their competitors; nothing less than their corporate survival is at stake. Techniques for offline or """"batch"""" evaluation of search quality have received considerable attention, spanning ways of constructing relevance judgments; ways of using them to generate numeric scores; and ways of inferring system """"superiority"""" from sets of such scores.  Our purpose in this paper is consider these mechanisms as a chain of inter-dependent activities, in order to explore some of the ramifications of alternative components. By disaggregating the different activities, and asking what the ultimate objective of the measurement process is, we provide new insights into evaluation approaches, and are able to suggest new combinations that might prove fruitful avenues for exploration. Our observations are examined with reference to data collected from a user study covering 34 users undertaking a total of six search tasks each, using two systems of markedly different quality.  We hope to encourage broader awareness of the many factors that go into an evaluation of search effectiveness, and of the implications of these choices, and encourage researchers to carefully report all aspects of the evaluation process when describing their system performance experiments."""	experiment;file spanning;information retrieval;money;online and offline;relevance;usability testing;web search engine	Falk Scholer;Alistair Moffat;Paul Thomas	2013		10.1145/2537734.2537745	simulation;computer science;evaluation;data mining;management science;world wide web;information retrieval	Web+IR	-33.273039641211064	-50.98201778930584	2375
500051f5a6e41a2ecda83c0303a67b8de9552cdb	fuzzy set approaches to spatial data mining of association rules	fuzzy set;spatial data;fuzzy data;soil type;data association;spatial data mining;spatial relation;association rule	This paper presents an approach to the discovery of association rules for fuzzy spatial data. Association rules provide information of value in assessing significant correlations that can be found in large databases. Here we are interested in correlations of spatially related data such as soil types, directional or geometric relationships, etc. We have combined and extended techniques developed in both spatial and fuzzy data mining in order to deal with the uncertainty found in typical spatial data.	association rule learning;blackwell (series);bloch sphere;data mining;database;fuzzy set;lu decomposition;test template framework;word lists by frequency	Roy Ladner;Frederick E. Petry;Maria Cobb	2003	Trans. GIS	10.1111/1467-9671.00133	spatial relation;association rule learning;computer science;machine learning;pattern recognition;data mining;mathematics;spatial analysis;fuzzy set;remote sensing;soil type	DB	-5.205361316785957	-26.552962622020733	2376
f085e947ae9409ed491f8cc9af253fb0490ff910	effectiveness of using simulation tutoring systems at a technical university	control system;virtual reality	This paper discusses the results of implementation and usage of educational simulation tutoring systems at the Department of Computer science and Information Control Systems, Kazan State Energy University, for a long time. The design and implementation principles of simulation tutoring programs are presented along with psychological, didactic, and organizational circumstances for their effective use. Simulation tutoring systems are considered as the first stage of using virtual reality in education. 	simulation	V. A. Belavin;I. N. Golitsina;S. M. Kutsenko	2000	Educational Technology & Society		computer science;simulation;human–computer interaction;virtual reality;control system	HCI	-67.93005470451807	-48.790502437161116	2378
97914dc4bad43be0446e8d318f813d829241616d	meaning in artificial agents: the symbol grounding problem revisited	symbol grounding problem;chinese room argument	The Chinese room argument has presented a persistent headache in the search for Artificial Intelligence. Since it first appeared in the literature, various interpretations have been made, attempting to understand the problems posed by this thought experiment. Throughout all this time, some researchers in the Artificial Intelligence community have seen Symbol Grounding as proposed by Harnad as a solution to the Chinese room argument. The main thesis in this paper is that although related, these two issues present different problems in the framework presented by Harnad himself. The work presented here attempts to shed some light on the relationship between John Searle’s intentionality notion and Harnad’s Symbol Grounding Problem.	artificial consciousness;artificial intelligence;chinese room;intelligent agent;intentionality;mind;symposium on geometry processing	Dairon Rodríguez;Jorge Hermosillo;Bruno Lara	2011	Minds and Machines	10.1007/s11023-011-9263-x	psychology;philosophy;epistemology;computer science;artificial intelligence;algorithm;cognitive science;symbol grounding	AI	-56.02210123525031	-22.051161713003847	2391
3063a03736ccfd383ce289a8d14a910d0e00f7ad	a new framework for textual information mining over parse trees	pragmatics;probability;senior citizens;text analysis;trees mathematics;data mining;query languages;grammars;engines;pattern matching;engines data mining pragmatics pattern matching probabilistic logic database languages senior citizens;computational linguistics;trees mathematics computational linguistics data mining grammars probability query languages text analysis;probabilistic logic;linguistic exception textual information mining tree based linguistic query language probabilistic parser main parts annotated parse trees grammatical ambiguity probabilistic rules;database languages	This paper introduces a new text mining framework using a tree-based Linguistic Query Language, called LQL. The framework generates more than one parse tree for each sentence using a probabilistic parser, and annotates each node of these parse trees with \textit{main-parts} information which is set of key terms from the node's branch based on the branch's linguistic structure. Using main-parts-annotated parse trees, the system can efficiently answer individual queries as well as mine the text for a given set of queries. The framework can also support grammatical ambiguity through probabilistic rules and linguistic exceptions.	parse tree;parsing;query language;text mining	Hamid Mousavi;Deirdre Kerr;Markus Iseli	2011	2011 IEEE Fifth International Conference on Semantic Computing	10.1109/ICSC.2011.19	natural language processing;computer science;computational linguistics;data mining;database;linguistics;programming language;query language;pragmatics	DB	-32.2615656126158	-69.34586118707723	2392
3b67a0689929c6611625806a234d29cdbb08c6e8	curriculum framework for the development of information literacy: methodological issues based on hungarian experiences		In Hungary, the digital pillars of an information society have not been given serious consideration as a complex entity; the structured foundation and development of information literacy have not been achieved. A complex set of competencies necessary to navigate in the information society has to be developed at three levels: basic education (primary and secondary schools), higher education and adult education. The components of information literacy are to be compared with the requirements of the national curriculum, and assigned to the appropriate levels of education. The core elements at each level are selected. In this way a systematic approach for teaching information literacy can be applied from the elementary school to adult education. The aim of the paper is to outline a methodology of creating a curriculum framework for the consecutive development of information literacy skills and competencies at all levels of education.	information literacy	Katalin Varga;Dóra Egervári	2014		10.1007/978-3-319-14136-7_53	mathematics education;library science;political science;pedagogy	Robotics	-75.47229334528953	-34.52254805882732	2393
59a2641249bacc99bdbe50edb344ffdf888aa827	introduction to the theory of computation	formale sprache;theory of computing;einfuhrung;automatentheorie	Find the secret to improve the quality of life by reading this introduction to the theory of computation. This is a kind of book that you need now. Besides, it can be your favorite book to read after having this book. Do you ask why? Well, this is a book that has different characteristic with others. You may not need to know who the author is, how well-known the work is. As wise word, never judge the words from who speaks, but make the words as your good value to your life.	introduction to the theory of computation;need to know;the quality of life	Michael Sipser	1996		10.1145/230514.571645	combinatorics;computer science;theoretical computer science;mathematics;distributed computing;geometry;algorithm	NLP	-59.88067595296743	-23.45389757497091	2395
fa94d02b232f3fa351be0db57309488011619101	a spatial-phenomenological lens to examine psychological and philosophical issues in thinking				Hugh Gash	2015	Cybernetics and Systems	10.1080/01969722.2015.1038479	machine learning;applied mathematics;artificial intelligence;phenomenology (philosophy);mathematics	Robotics	-53.120988225948906	-20.555147615548574	2396
850ae96817a74487e5ecb40e2910a1a67e722d4f	towards better cross-cloud data integration: using p2p and etl together	p2p;etl;data integration	Cloud computing has been increasingly used in a variety of scenarios and environments to deal with huge amounts of data, accordingly, data integration among different clouds have also been extensively concerned by both academia and the business community. With the division of private and public clouds and different contents and functions of clouds, cross-cloud data integration becomes a grand challenge. Various methods are proposed to cope with the challenge; however, how to achieve better cross-cloud data integration still involves a lot of tradeoff analysis. In this paper, we propose weaving P2P technique into ETL process to integrate cross-cloud data. And we built a middleware prototype system to testify the feasibility of our approach.		Jian Dai;Shuanzhu Du	2012		10.1007/978-3-642-33469-6_51	computer science;data integration;operating system;peer-to-peer;data mining;database;world wide web	DB	-34.028347142310274	-1.5121152637720945	2397
af619f8c37df73a0614bed513e3f74ee154fb7ad	introduction to the inter-organizational collaborative dynamics and role of information technology minitrack	innovation interorganizational collaboration dyanmics it;technological innovation;collaboration medical services information technology technological innovation organizations communications technology;information technology;interorganizational collaboration dyanmics;collaboration;innovation;medical services;it;communications technology;organizations	Breakthrough innovation increasingly requires intense interaction that involves external parties jointly solving problems or exploring new opportunities. In healthcare, care coordination and transitions of care require coordination of patient care among multiple and often independent care settings that are often completely different systems of care, both professionally and institutionally. Multiparty cloud solutions and infrastructure management services require close collaboration by multiple vendors and the client particularly during times of transition. The aftermath of catastrophic events often involves impromptu groups of individuals from different organizations and backgrounds that collaborate to provide disaster relief. This minitrack explores inter-organizational collaboration, particularly in terms of multi-level dynamics and the role of information and communication technology in such dynamics. We celebrate any acceptable methodology and theory, and encourages any level of analysis and papers that take a cross-level perspective.	half-life 2: episode one;itil;impromptu	Sirkka L. Jarvenpaa;Holly Jordan Lanham	2015	2015 48th Hawaii International Conference on System Sciences	10.1109/HICSS.2015.521	public relations;innovation;information and communications technology;organization;knowledge management;marketing;management;law;information technology;collaboration	HPC	-78.91781069086986	0.6446168537337463	2403
9e2a9b10cff1edf2f867f3d0edc759edd186e648	map-based image tag recommendation using a visual folksonomy	anotacion;vocabulaire;image processing;metadata;automatic image annotation;vocabulary;procesamiento imagen;annotation;estimation a posteriori;vocabulario;image annotation;folksonomy;traitement image;a posteriori estimation;estimacion a posteriori;metadonnee;tag recommendation;metadatos;tagging	Descriptive tags are needed to enable efficient and effective search in vast collections of images. Tag recommendation represents a trade-off between automatic image annotation techniques and manual tagging. In this letter, we formulate image tag recommendation as a maximum a posteriori (MAP) problem, making use of a visual folksonomy. A folksonomy can be seen as a collaboratively created set of metadata for informal social classification. Our experimental results show that the use of a visual folksonomy for image tag recommendation has two significant benefits, compared to a conventional approach using a limited concept vocabulary. First, our tag recommendation technique can make use of an unrestricted and rich concept vocabulary. Second, our approach is able to recommend a higher number of correct tags.	folksonomy	Sihyoung Lee;Wesley De Neve;Konstantinos N. Plataniotis;Yong Man Ro	2010	Pattern Recognition Letters	10.1016/j.patrec.2009.12.024	computer science;pattern recognition;data mining;metadata;automatic image annotation;world wide web;information retrieval	Vision	-14.148538165789187	-61.147336421384466	2406
a8c8b3ee58dc138b11c41467394c2fdf609d78c2	mining product intention rules from transaction logs of an ecommerce portal	e commerce;rule based;search strategy;data mining;query intention	In this paper, we address the following problem: In the context of an ecommerce portal with product based inventory, predict the product p the user is interested, when he/she issues a query q. A viable solution to the above problem is necessary for e-commerce portals to a:) increase the relevance of their search results and b:) provide high quality recommendations. Higher quality search results and recommendations foster user purchases and thereby leading to increased revenue.  We propose a rule based framework that maps a user's query to a product. We propose a systematic search strategy that mines product intention rules from transaction logs of an ecommerce site. We validate the efficacy of the rules by running extensive experiments. Our results show that our approach produces product intention rules with high accuracy and coverage.	algorithm;database;display resolution;e-commerce;emoticon;experiment;inventory;map;mined;portals;purchasing;relevance;scalability;transaction log	Ravi Chandra Jammalamadaka;Naren Chittar;Sanjay Ghatare	2009		10.1145/1620432.1620468	e-commerce;rule-based system;computer science;data mining;database;world wide web	DB	-21.048904649215167	-50.433807318320305	2407
eca06ee6fd27963e53a756f2bdc5eb4fc76e5d77	a study of online digital music evaluation		The understanding of digital music consumer behavior and determinants of online digital music evaluation helps music retailers implement online digital music marketing strategies. In this study, the authors investigate the profiles of music consumers on the Internet and explore how consumers use product sampling and customer reviews for online music evaluation. The authors find most people use free radio as their main music source, piracy and digital music remains a problem. The authors also find consumers still depend on traditional word of mouth for their music evaluation. This study shows that many consumers are more likely to trust online sampling than online reviews, and online sampling plays a more important role than online reviews in their music evaluation. The authors also investigate post-sampling results including the music evaluation, willingness to pay (WTP), free rider, enjoyable sampling process, perceived usefulness of online sampling, knowing the true music value, further reading online reviews, using other music evaluation channels, and writing customer reviews after sampling. The authors also conduct coefficient correlation analysis for post-sampling results and provide managerial interpretations.		Yanbin Tu;Min Lu	2012	IJOM	10.4018/ijom.2012040103	psychology;marketing;multimedia;advertising	HCI	-88.88685418914947	-13.145110948904371	2414
fb1c1ecca1026e59d16fa3168014b16109542c98	team based assignments in moocs: results and observations		Teamwork and collaborative learning are considered superior to learning individually by many instructors and didactical theories. Particularly, in the context of e-learning and Massive Open Online Courses (MOOCs) we see great benefits but also great challenges for both, learners and instructors. We discuss our experience with six team based assignments on the openHPI and openSAP1 MOOC platforms.	massive open online course;theory;openhpi	Thomas Staubitz;Christoph Meinel	2018		10.1145/3231644.3231705	knowledge management;collaborative learning;peer assessment;teamwork;computer science	AI	-75.18145518106547	-39.58489074006097	2420
53a89112bcce82308945a7ac61c9bb8c627ac058	a study on saudi diabetic patients' readiness to use mobile health	diabetes;mobile health;saudi arabia	The acceptance and feasibility for using mobile health technologies for diabetes management in Saudi Arabia remains to be explored. We created the Mobile Health Effectiveness and Readiness Questionnaire (MHERQ) to measure its validity and reliability in assessing the readiness of Saudi diabetic patients use of mobile health technologies for diabetes self-management. The study was able to measure the validity and reliability of MHERQ and found that MHERQ provides promising results for Saudi diabetic patients' use of mobile health technologies.	diabetes mellitus;mobile health;patients;self-management (computer science);women's health services	Hanan Alenazi;Mariam M. Alghamdi;Sarah Alradhi;Mowafa Said Househ;Nasriah Zakaria	2017	Studies in health technology and informatics	10.3233/978-1-61499-830-3-1210		HCI	-61.97368809875246	-62.65917007349369	2424
c1d95ea1d60c0486812aed97d45d877e70185a3a	vrbox: a virtual reality augmented sandbox for immersive playfulness, creativity and exploration		Augmented sandboxes have been used as playful and educative tools to create, explore and understand complex models. However, current solutions lack interactive capabilities, missing more immersive experiences such as exploring the sand landscape from a first person perspective. We extend the interaction space of augmented sandboxes into virtual reality (VR) to offer a VR-environment that contains a landscape, which the user designs via interacting with real sand while wearing a virtual reality head-mounted display (HMD). In this paper, we present our current VR-sandbox system consisting of a box with sand, triple Kinect depth sensing, a virtual reality HMD, and hand tracking, as well as an interactive world simulation use case for exploration and evaluation. Our work explores the important and timely topics how to integrate rich haptic interaction with natural materials into VR and how to track and present real physical materials in VR. In a qualitative evaluation with nine experts from computer graphics, game design, and didactics we identified potentials, limitations as well as future application scenarios.	computer graphics;experience;first-person (video games);haptic technology;head-mounted display;interaction;kinect;open world;simulation;virtual reality headset	Thomas Fröhlich;Dmitry Alexandrovsky;Timo Stabbert;Tanja Döring;Rainer Malaka	2018		10.1145/3242671.3242697	multimedia;immersion (virtual reality);haptic technology;sandbox (computer security);computer graphics;virtual reality;creativity;computer science;game design	Visualization	-50.63038601443144	-36.7722972516248	2434
7cc16d3fd2d2f74249d01c37f32bbf4f1470bf2c	experience with the distance learning bachelor study in the field of finance, banking and investment	distance learning;lms moodle	Three years ago Faculty of Economics started the internal faculty project named “Preparation and realization of the distance learning bachelor study in the field of Finance, Banking and Investment”. Last year we reached the most important milestone – we got the first Bachelor graduates in August 2008. Based on the students’ feedback we extended the project objectives by preparation, implementation and realization of distance learning in engineer study program. One aim of the paper is to present current state of the mentioned project, to show the improved timetable of the particular phases of the mentioned project.	dot-com bubble;schedule;teaching method	Dana Palová;Libusa Révészová	2010	iJET	10.3991/ijet.v5s2.1223	distance education;simulation;computer science;knowledge management;pedagogy	Theory	-80.53423995256391	-31.733905914217218	2437
d494f39e6aae31475d1cd8f21e211b3c25163bda	patent-related activities in serbia from 1921 to 1995	europa;statistique;scientometrics;international patent classification;technology development;innovation policy;yougoslavie;serbia;scientometria;patents;yugoslavia;scientometrie;statistics;serbie;patente;europe;brevet;estadistica	In 1883 the Kingdom of Serbia was a co-founder of the well-known Paris Convention dedicated to protection of industrial property. This paper presents the analysis of inventive activities in Serbia in the period from 1921 to 1995. The available patent statistics is analyzed from the aspects of: (a) patenting structure according to the International Patent Classification sections, and (b) patenting dynamics. The findings of analysis indicate: (1) the fields in which technology development potentials are created in Serbia, and (2) the variations in inventors' productivity as a direct consequence of the variation in the country's innovation policy.	bibliographic database;data aggregation;emoticon;experience;noise shaping;scientometrics;whole earth 'lectronic link	Djuro Kutlaca	1998	Scientometrics	10.1007/BF02458354	development economics;scientometrics;computer science;economy;law;statistics	SE	-75.20155763798721	-22.006917918679836	2438
04e7401393a24d32050c13cefb544c469e17b804	mobile phone graph evolution: findings, model and interpretation	distribution;graph theory;lognormal;time scale;mobile phone graph distribution generative process lognormal convolution;fitting approximation mobile phone graph evolution evolutional graph generation massive who call whom networks mobile phone communication networks multiscale data delta stable distribution multiscale distribution fitting problem scale power convolutional distribution mixture;convolution;generative process;heavy tail;data distribution;mobile phone;approximation theory;large scale;mobile phone graph;community networks;multiple time scale;mobile radio;distributed generators;stable distribution;mobile handsets random variables distribution functions data mining data models cities and towns convolution;power modeling;telecommunication networks approximation theory graph theory mobile radio;telecommunication networks	What are the features of mobile phone graph along the time? How to model these features? What are the interpretation for the evolutional graph generation process? To answer the above challenging problems, we analyze a massive who-call-whom networks as long as a year, gathered from records of two large mobile phone communication networks both with 2 million users and 2 billion of calls. We examine the calling behavior distribution at multiple time scales (e.g., day, week, month and quarter), and find that the distribution is not only skewed with a heavy tail, but also changing at different time scales. How to model the changing behavior, and whether there exists a distribution fitting the multi-scale data well? In this paper, first, we define a delta-stable distribution and a Multi-scale Distribution Fitting (MsDF) problem. Second, to analyze our observed distributions at different time scales, we propose a framework, Scale Power, which not only fits the multi-scale data distribution very well, but also works as a convolutional distribution mixture to explain the generation mechanism of the multi-scale distribution changing behavior. Third, Scale Power can conduct a fitting approximation from a small time scale data to a large time scale. Furthermore, we illustrate the interesting and appealing findings from our Scale Power model and large scale real life data sets.	approximation;curve fitting;fits;mobile phone;real life;telecommunications network	Siyuan Liu;Lei Li;Christos Faloutsos;Lionel M. Ni	2011	2011 IEEE 11th International Conference on Data Mining Workshops	10.1109/ICDMW.2011.123	distribution;heavy-tailed distribution;stable distribution;graph theory;theoretical computer science;machine learning;data mining;log-normal distribution;mathematics;convolution;statistics;approximation theory	DB	-17.912507023122522	-39.23781001649698	2439
190497afa02df51ea05523916392bc97c553ac34	neurophysiological experimental facility for quality of experience (qoe) assessment	electroencephalography speech electrodes skin physiology conferences blood;speech;quality of experience;human factors;multimedia communication;cognition;visual perception;visual perception cognition electroencephalography human factors infrared spectroscopy laboratories multimedia communication neurophysiology quality of experience speech;neurophysiology;infrared spectroscopy;electroencephalography;multimedia qoe evaluation neurophysiological experimental facility quality of experience assessment human brain human behavior human cognition neurophysiological monitoring tool qoe constructs available equipment natural speech synthesized speech qoe perception image preference characterization	The human brain is the epicenter of every human action, thus neurophysiology will pave the way for understanding human behavior and cognition and their interplay with Quality of Experience (QoE). Recent advances in neurophysiological monitoring tools have allowed useful QoE constructs to be measured in real-time, such as human cognition, attention, emotion, fatigue, perception and task performance. In this paper, we describe a multimodal neurophysiological experimental facility recently implemented for QoE evaluation. A description of the facility and the available equipment is presented. Results of three recent studies are also presented, thus showing that neurophysiological correlates can be obtained for i) natural speech and ii) synthesized speech QoE perception, as well as iii) image preference characterization for multimedia QoE evaluation.	cognition;multimodal interaction;natural language;real-time locating system;speech synthesis	Khalil ur Rehman Laghari;Rishabh Gupta;Sebastian Arndt;Jan-Niklas Antons;Robert Schleicher;Sebastian Möller;Tiago H. Falk	2013	2013 IFIP/IEEE International Symposium on Integrated Network Management (IM 2013)		infrared spectroscopy;cognition;electroencephalography;visual perception;speech;multimedia;neurophysiology	Embedded	-50.740526941025514	-47.3708706936038	2448
24902b54f436d180c3fb296a534488b799d35dee	learning communities in the crowd: characteristics of content related interactions and social relationships in mooc discussion forums		Abstract This mixed method study used social network analysis (SNA) and inductive qualitative analysis to compare social relationships and the underlying interactions they represent in discussions related and unrelated to the learning of course content in a statistics MOOC. It additionally examined the impact of how social relationships are conceptualized (via network tie definition) on resultant network structures and properties. Using a previously developed natural language classifier, 817 threads containing 3124 discussion posts from 567 forum participants were characterized as either related to the course content or not. Content, non-content, and overall interaction networks were constructed based on five different tie definitions: Direct Reply, Star, Direct Reply + Star, Limited Copresence, and Total Copresence. Results showed network properties were robust to differences in tie definition with the notable exception of Total Copresence. Comparison of content and non-content networks showed key differences at the network, community, and node (individual) levels. The two networks consisted of largely different people, and participants in the content network and communities had more repeated interactions with a larger number of peers. Analysis of the contributing threads helped to explain factors leading to some of these differences, showing the content discussions to be more diverse and complex in their communication purposes, conversation structures, and participantsu0027 interaction techniques. Within content discussions, the network of learners surrounding each of the two instructors showed distinct characteristics that appeared related to the instructoru0027s facilitation approach. Finally, a group of learners tightly connected to each other through content discussions showed nascent learning community-like characteristics. This work contributes to the literature by (1) deepening understanding of MOOC discussion learning processes; (2) drawing connections between network structures and specific discussion practices; (3) providing evidence demonstrating the importance of separately examining content and non-content discussions; and (4) drawing attention to the empirical impact of the choice of tie definition in SNA studies of MOOC forums.	interaction;massive open online course	Alyssa Friend Wise;Yi Cui	2018	Computers & Education	10.1016/j.compedu.2018.03.021	conversation;knowledge management;social network analysis;learning community;computer science;natural language;facilitation;thread (computing)	HCI	-74.24329053576788	-42.275698174313604	2451
300c8917ea3de9db80e13da025534ec52ee16cec	voice activated command and control with java-enabled speech recognition over wifi	speech processing;java native interface;command and control;software development;speech recognition;ubiquitous computing;java media framework;language engineering	In this paper we present recent research in the development of a voice enabled command and control application, using Java, in which a remote robotic device, with a JVM, is controlled over a Wifi/WLAN/TCPIP network from a mobile handheld PC (iPaq) or a PC workstation. The research considers three different scenario configurations. A recognition grammar for command and control of the robot has been created and implemented in Java, in part in the recognition engine and in part on the robot. The robot is a proxy for one of a number of JVM enabled intelligent devices that can be controlled in this manner. The physical topology involves Java at each node endpoint, that is, at the handheld PC (iPaq), the PC workstation, the Linux server and onboard the robot (including its Java based Lejos OS). Network communications is primarily WLAN with an element of IR and the possibility of BlueTooth (subject to the resolution of certain important Java and Bluetooth issues). For placement of a speech recognition engine on Linux we are initially using Sphinx through the Java Native Interface but plan to develop our own speech recognition engine, in Java, for deployment on Linux. Traditionally speech processing in software has resided in the domain of C software development. Recent advances in Java with the Java Speech API, along with the Java Media Framework, have facilitated the consideration of Java for speech and language engineering activities. Our hypothesis is that Java is now a suitable platform for speech and language engineering in software. The evidence provided by our initial results, for Java speech recognition, achieved using the Cloudgarden implementation of JSAPI, validates this hypothesis. We outline our future plans to move our framework more fully into the ubiquitous computing arena and extend the reach of Java and speech processing in support of command and control a structured way, including, for example, camera feedback to base.	java;speech recognition	Tony Ayres;Brian Nolan	2004		10.1145/1071565.1071586	speech recognition;computer science;voice tag;programming language;communication;speech synthesis	HCI	-37.789169809358555	-42.360020776206774	2455
46ce3fd02fdc2fa596794b6dbac463ad4e45fb2d	retrieving correct semantic boundaries in dependency structure	argument structure;error analysis;dependence structure	This paper describes the retrieval of correct semantic boundaries for predicateargument structures annotated by dependency structure. Unlike phrase structure, in which arguments are annotated at the phrase level, dependency structure does not have phrases so the argument labels are associated with head words instead: the subtree of each head word is assumed to include the same set of words as the annotated phrase does in phrase structure. However, at least in English, retrieving such subtrees does not always guarantee retrieval of the correct phrase boundaries. In this paper, we present heuristics that retrieve correct phrase boundaries for semantic arguments, called semantic boundaries, from dependency trees. By applying heuristics, we achieved an F1-score of 99.54% for correct representation of semantic boundaries. Furthermore, error analysis showed that some of the errors could also be considered correct, depending on the interpretation of the annotation.	dependency grammar;error analysis (mathematics);f1 score;heuristic (computer science);machine translation;phrase structure rules;propbank;text corpus;tree (data structure);treebank	Jinho D. Choi;Martha Palmer	2010			natural language processing;noun phrase;computer science;pattern recognition;phrase structure rules;linguistics;dependency grammar	NLP	-24.13101432216114	-75.79265408063759	2461
53f49cc56afdd85ea7217a796d50a29f810113b5	focusing and reference resolution in pundit	definite pronoun;pundit text processing system;important feature;one-anaphoric noun phrase;pronoun resolution;indefinite noun phrase;elided noun phrase;pundit system;reference resolution;pundit reference resolution system;noun phrase	This paper describes the use of focusing in the PUNDIT text processing system. 1 Focusing, as discussed by [Sidner1979] (as well as the closely related concept of centering, as discussed by [Grosz1983] ), provides a powerful tool for pronoun resolution. However, its range of application is actually much more general, in that it can be used for several problems in reference resolution. Specifically, in the PUNDIT system, focusing is used for one-anaphora, elided noun phrases, and certain types of definite and indefinite noun phrases, in addition to its use for pronouns. Another important feature in the FUNDIT reference resolution system is that tile focusing algorilJnn is based on syntactic constituents, rather than on thematic roles, as in Sidner's system. This feature is based on considerations arising from the extension of focusing to cover oneanaphora. These considerations make syntactic focusing a more accurate predictor of the interpretat ion of one-anaphoric noun phrases without decreasing the accuracy for definite pronouns. 1 Th i s w o r k is supported in p a r t by D A R P A u n d e r c o n t r a c t N00014-85 -C-0012 , a d m i n i s t e r e d by the Office o f N a v a l : R e s e a r c h .	anaphora (linguistics);kerrison predictor	Deborah A. Dahl	1986			computer science	AI	-33.925985880056736	-82.56254478953208	2462
d0ce184a1cc22be16ab09d47b9ea5d2c11822ee2	thinking of a system for image retrieval	image retrieval	Increasing applications are demanding effective and efficient support to perform retrieval in large collections of digital images. The work presented here is an early stage research focusing on the integration between text-based and contentbased image retrieval. The main objective is to find a valid solution to the problem of reducing the so called semantic gap, i.e. the lack of coincidence existing between the visual information contained in an image and the interpretation that a user can give of it. To address the semantic gap problem, we intend to use a combination of several approaches. Firstly, a linking between low-level features and text description is obtained by a semi-automatic annotation process, which makes use of shape prototypes generated by clustering. Precisely, the system indexes objects based on shape and groups them into a set of clusters, with each cluster represented by a prototype. Then, a taxonomy of objects that are described by both visual ontologies and textual features is attached to prototypes, by forming a visual description of a subset of the objects. The paper outlines the architecture of the system and describes briefly algorithms underpinning the proposed approach.	algorithm;cluster analysis;digital image;high- and low-level;image retrieval;ontology (information science);prototype;semiconductor industry;taxonomy (general);text-based (computing)	Giovanna Castellano;Gianluca Sforza;Maria Alessandra Torsello	2010			automatic image annotation;digital image;machine learning;artificial intelligence;semantic gap;visual word;ontology (information science);cluster analysis;architecture;image retrieval;computer science	Web+IR	-14.145478328056685	-59.030309175190155	2467
54a08bc0a87d3c1e3e0a0d5a3d98e4aa7fc68b4c	rereading in interactive stories: constraints on agency and procedural variation	agency;selection;ordering;reframing;procedural variation;coherence;interactive storytelling;rereading;constraints	A central problem for interactive storytelling research is how to create a story which procedurally varies as the result of a user’s actions, while still feeling like a story. Research has largely concentrated on how to provide coherent variations each time a user experiences an interactive story, without consideration for the relationship between subsequent experiences. This paper examines the issues that arise when designing an interactive story system which is intended to be reread as the result of a reframing. Through a discussion of several types of reframing drawn from non-interactive films, we argue that, when an interactive story makes use of a reframing to encourage rereading, the requirements for narrative coherence, selection and ordering extend across reading sessions. This introduces constraints in terms of what can be varied procedurally in response to user actions which do not occur in interactive stories which are not explicitly designed to be reread.	coherence (physics);experience;interactive storytelling;interactivity;requirement	Alex Mitchell;Kevin McGee	2011		10.1007/978-3-642-25289-1_5	selection;coherence;order theory;computer science;agency;cognitive reframing;multimedia;social psychology;literature	HCI	-60.187702393564535	-33.45490252626087	2471
a62b8de47cc0d40f9a89c2ab2acf1faf6cd9edaf	informatics support for the management of drug resistant tuberculosis in peru and russia	biomedical research;bioinformatics		informatics	Hamish S. F. Fraser;Libby Levison;Michael Nikiforov;Darius Jazayeri;Candy Day;Peter Szolovits;Jim Y. Kim	2001			data science;tuberculosis;drug resistance;pharmacology;informatics;medicine	HPC	-55.85580040899235	-64.85311049031084	2472
2a6a6e324fc1f81e8883de8ca59764b0398d3868	guest editor's foreword				Lance Fortnow	2001	J. Comput. Syst. Sci.	10.1006/jcss.2000.1724		Theory	-53.91425306416537	-15.123888872218188	2475
a38bdf3803b1cd00d57f69516be1d60a3c8688c9	raincloud plots: a multi-platform tool for robust data visualization		Across scientific disciplines, there is a rapidly growing recognition of the need for more statistically robust, transparent approaches to data visualization. Complimentary to this, many scientists have realized the need for plotting tools that accurately and transparently convey key aspects of statistical effects and raw data with minimal distortion. Previously common approaches, such as plotting conditional mean or median barplots together with error-bars have been criticized for distorting effect size, hiding underlying patterns in the raw data, and obscuring the assumptions upon which the most commonly used statistical tests are based. Here we describe a data visualization approach which overcomes these issues, providing maximal statistical information while preserving the desired ‘inference at a glance’ nature of barplots and other similar visualization devices. These “raincloud plots” can visualize raw data, probability density, and key summary statistics such as median, mean, and relevant confidence intervals in an appealing and flexible format with minimal redundancy. In this tutorial paper we provide basic demonstrations of the strength of raincloud plots and similar approaches, outline potential modifications for their optimal use, and provide open-source code for their streamlined implementation in R, Python and Matlab (https://github.com/RainCloudPlots/RainCloudPlots). Readers can investigate the R and Python tutorials interactively in the browser using Binder by Project Jupyter. Introduction Effective data visualization is key to the interpretation and communication of data analysis. Ideally a statistical plot or data graphic should balance functionality, interpretability, and complexity, all without needlessly sacrificing aesthetics. That is to say, the perfect visualization is one which uses as little ‘ink’ as possible to capture exactly the desired statistical inference in an intuitive and appealing format (Tufte, 1983). As PeerJ Preprints | https://doi.org/10.7287/peerj.preprints.27137v1 | CC BY 4.0 Open Access | rec: 23 Aug 2018, publ: 23 Aug 2018 concerns regarding the need for robust, reproducible data science have grown in recent years, so too have calls for more meaningful approaches to plotting one’s data. Here we present an open source, multi-platform tutorial for the raincloud plot (Neuroconscience, 2018). A common visualization method of raw datapoints is the barplot (see Figure 1, left panel) to represent the mean or median of some condition or group via horizontal bars (or lines) and represents uncertainty about the illustrated parameter estimated via ‘whisker’ errorbars, usually conveying the standard error or 95% confidence interval. This approach has been widely criticized on several counts, including: 1) it is prone to distortion (e.g., by cropping of the Y-axis), 2) it fails to represent the actual data underlying relevant parameter inferences, 3) it often leads to misleading inferences about the magnitudes of statistical differences between conditions (Weissgerber, Milic, Winham, & Garovic, 2015) and 4) it may obscure differences in distributions (and concurrent violations of distributional assumptions in parametric statistics). These limitations are illustrated in Figure 1, below. Indeed, criticism of this approach has reached such a pitched fervor that a movement to “bar bar plots” (“#barbarplots,” 2016; Piccinini, 2016) has arisen with many signees pledging to request all such plots be changed to something more informative1. Figure 1. The trouble with barplots. Example reproduced from “Boxplots vs. Barplots” (2016) two simulated datasets with mean = 50, sd = 25, and 1000 observations. A) a barplot and errorbars representing +/standard error of the mean gives the impression that the measure is equivalent between the two groups. In fact, group 1 is drawn from an exponential distribution as seen in B) boxplots, and C) histograms. The barplot not only obscures the underlying nature of the observations, but also hides the fact that these data are not appropriate for standard parametric inference. See figure1.Rmd for code to generate these figures. 1 This raises the question of why such uninformative plots became widespread in the first place. Speculatively, they may simply have been easier to produce before the advent of personal computers and associated statistical software, when plots were typically hand-drawn. Manual plotting of this type was time consuming and error-prone; simply plotting all raw data points would have considerably increased workload and the full-scale plotting of probability distributions may have been beyond the grasp of many researchers. PeerJ Preprints | https://doi.org/10.7287/peerj.preprints.27137v1 | CC BY 4.0 Open Access | rec: 23 Aug 2018, publ: 23 Aug 2018 To remedy these shortcomings, a variety of visualisation approaches have been proposed, illustrated in Figure 2, below. One simple improvement is to overlay individual observations (datapoints) beside the standard bar-plot format, typically with some degree of randomized jitter to improve visibility (Figure 2A). Complementary to this approach, others have advocated for more statistically robust illustrations such as boxplots (Tukey, 1970), which display sample median alongside interquartile range. Dot plots can be used to combine a histogram-like display of distribution with individual data observations (Figure 2B). In many cases, particularly when parametric statistics are used, it is desirable to plot the distribution of observations. This can reveal valuable information about how e.g., some condition may increase the skewness or overall shape of a distribution. In this case, the ‘violin plot’ (Figure 2C) which displays a probability density function of the data mirrored about the uninformative axis is often preferred (Hintze & Nelson, 1998). With the advent of increasingly flexible and modular plotting tools such as ggplot2 (Wickham, 2010; Wickham & Chang, 2008), all of the aforementioned techniques can be combined in a complementary fashion. Figure 2. Extant approaches to improved data plotting. A) The simplest improvement is to add jittered raw data points to the standard boxplot and +/standard error scheme. B) Alternatively, dotplots can be used to supplement visualizations of central tendency and error, at the risk of added complexity due to the dependence of such plots on choices such as bin-width and dot size. C) A popular recent alternative is the violin plot coupled with boxplots or similar. However, this needlessly mirrors information about the redundant data axis (here, the x-axis). See figure2.Rmd for code to generate these figures. Indeed, this combined approach is typically desirable as each of these visualization techniques have various trade-offs. Simply plotting raw data can reveal valuable information about individual differences, outliers, and unexpected patterns within the data. However, human observers are notoriously poor2 at estimating statistical moments and distributions from raw data (Bobko & Karren, 1979; “Guess the Correlation,” 2017; Spence, Dux, & Arnold, 2016; Zylberberg, Roelfsema, & Sigman, 2014), and the utility of such plots can be limited when the number of observations is large. In this case the dotplot may be advantageous, as it displays both a histogram of raw data points and the frequency of different binned observations. On the other hand, the interpretation of 2 Indeed, try it yourself at http://guessthecorrelation.com/ PeerJ Preprints | https://doi.org/10.7287/peerj.preprints.27137v1 | CC BY 4.0 Open Access | rec: 23 Aug 2018, publ: 23 Aug 2018 dotplots depends heavily on the choice of dot-bin and dot-size, and these plots can also become extremely difficult to read when there are many observations. The violin plot in which the probability density function (PDF) of observations are mirrored, combined with overlaid boxplots, have recently become a popular alternative. This provides both an assessment of the data distribution and statistical inference at a glance (SIG) via overlaid boxplots3. However, there is nothing to be gained, statistically speaking, by mirroring the PDF in the violin plot, and therefore they are violating the philosophy of minimising the “data-ink ratio” (Tufte, 1983)4. To overcome these issues, we propose the use of the ‘raincloud plot’ (Neuroconscience, 2018), illustrated in Figure 3. The raincloud plot combines a wide range of visualization suggestions, and similar precursors have been used in various publications (e.g., Ellison, 1993, Figure 2.4; Wilson et al., 2018). The plot attempts to address the aforementioned limitations in an intuitive, modular, and statistically robust format. In essence, raincloud plots combine a ‘split-half violin’ (an un-mirrored PDF plotted against the redundant data axis), raw jittered data points, and a standard visualization of central tendency (i.e., mean or median) and error, such as a boxplot. As such the raincloud plot builds on code elements from multiple developers and scientific programming languages (Hintze & Nelson, 1998; Patil, 2018; Wickham & Chang, 2008; Wilke, 2017). Many previous attempts have been made to produce more robust, intuitive, and transparent plots. Our goal here is not to propose a totally novel invention, but rather to make a powerful visualization strategy freely, easily, and transparently available across commonly used platforms. To this end, similar but distinct plotting strategies include beanplots (Kampstra, 2008), estimation plots (Ho, Tumkaya, Aryal, Choi, & ClaridgeChang, 2018), pirateplots (Phillips, 2016), sinaplots (Sidiropoulos et al., 2018), stripcharts (Chambers, 2017), beeswarm plots (Eklund, 2016), and many others. Our hope here is to offer a cross-platform, open science tool which builds upon these approaches and makes robust and transparent data-plotting available to as wide an audience as possible. 3 See http://www.fharrell.com/post/interactive-graph		Micah Allen;Davide Poggiali;Kirstie J. Whitaker;Tom R. Marshall;Rogier A. Kievit	2018	PeerJ PrePrints	10.7287/peerj.preprints.27137v1	redundancy (engineering);raw data;matlab;data visualization;statistical hypothesis testing;data mining;visualization;python (programming language);robust statistics;computer science	Visualization	-26.33952863511653	-37.675245166281016	2476
12adf9ed8d78f2042be87f0eb296fedf6b15027d	the logic of persistence	default reasoning;default logic	It seems unreasonable to think Räikkönen et al. argued that Yellowstone wolves (or any other wolves) are, or are not, genetically threatened. If we had, as Mech and Cronin suggest (paragraph 3), we would have committed what logicians refer to as the fallacy of overgeneralization – a mistaken use of inductive logic. There is a significant difference in the logic of our argument: we referred to others who had used Isle Royale wolves to support arguments that other small populations are viable (genetically or otherwise), and then explained how this is inappropriate. Mech and Cronin criticize contending that ‘‘many. . . downplay the threats posed by genetic deterioration” and that ‘‘genetic deterioration is likely a problem in many populations.” An extensive literature supports the former concern (see references in Räikkönen et al.), and the latter represent a fundamental premise of the subdiscipline conservation genetics. Mech and Cronin write that we ‘‘claim that selection against deleterious alleles (purging) will not increase population fitness.” In fact, we wrote ‘‘. . .purging is now understood to be unreliable for mitigating inbreeding depression. . .”, and we provided supporting references. Again, there is a significant difference in logic between what we argued and what Mech and Cronin claim we argued. Moreover, Mech and Cronin argue that the existence of many captive populations represents evidence of purging’s efficacy. However, Speke’s gazelle is the only captive population considered, and only by some, as evidence of successful purging. Moreover, the costs of inbreeding for captive populations are too well documented to review here, and evidence suggests that inbreeding costs tend to be even greater in wild populations. Similarly, the existence of inbred, domesticated lines is not evidence of inbreeding’s unimportance. The relevant observation is that most inbred lineages end in extinction. Mech and Cronin write ‘‘despite inbreeding, the [Isle Royale] population has survived, the ultimate test.” Like others cited in Räikkönen et al., they seem to believe Isle Royale wolves represent evidence that being small and isolated does not preclude viability. This seems the essence of Mech and Cronin’s criticism. That proposition represents an argument whose salience goes beyond inbreeding, and relates to the logic of population viability generally. That argument seems to be:	captive portal;inductive reasoning;persistence (computer science);population;threat (computer)	Henry A. Kautz	1986			computer science;artificial intelligence;non-monotonic logic;reasoning system;deductive reasoning;default logic;algorithm	NLP	-13.3302164849455	2.761782894648197	2477
b7069dd4891ad152cd6d169f4ddb2bba4ff8c38f	mob data sourcing	declarative systems;crowdsourcing	Crowdsourcing is an emerging paradigm that harnesses a mass of users to perform various types of tasks. We focus in this tutorial on a particular form of crowdsourcing, namely crowd (or mob) datasourcing whose goal is to obtain, aggregate or process data. We overview crowd datasourcing solutions in various contexts, explain the need for a principled solution, describe advances towards achieving such a solution, and highlight remaining gaps.	aggregate data;crowdsourcing;programming paradigm	Daniel Deutch;Tova Milo	2012		10.1145/2213836.2213905	simulation;crowdsourcing software development;computer science;data science;data mining;crowdsourcing	DB	-36.28273306267341	-6.733640766707823	2482
356e372d1eab65ef160c0c30924279c0a56d8bae	sentinel: a codesigned platform for semantic enrichment of social media streams		We introduce the Sentinel platform that supports semantic enrichment of streamed social media data for the purposes of situational understanding. The platform is the result of a codesign effort between computing and social scientists, iteratively developed through a series of pilot studies. The platform is founded upon a knowledge-based approach, in which input streams (channels) are characterized by spatial and terminological parameters, collected media is preprocessed to identify significant terms (signals), and data are tagged (framed) in relation to an ontology. Interpretation of processed media is framed in terms of the 5W framework (who, what, when, where, and why). The platform is designed to be open to the incorporation of new processing modules, building on the knowledge-based elements (channels, signals, and framing ontology) and accessible via a set of user-facing apps. We present the conceptual architecture for the platform, discuss the design and implementation challenges of the underlying stream-processing system, and present a number of apps developed in the context of the pilot studies, highlighting the strengths and importance of the codesign approach and indicating promising areas for future research.	framing (world wide web);gene ontology term enrichment;social media;stream processing;streaming media;the sentinel	Alun Preece;Irena Spasi&#x0107;;Kieran Evans;David Honegger Rogers;William M. Webberley;Colin Roberts;Martin Innes	2018	IEEE Transactions on Computational Social Systems	10.1109/TCSS.2017.2763684	data mining;streams;computer science;ontology (information science);semantics;social media;conceptual architecture;data modeling	Web+IR	-36.56467689614093	-4.438600136563697	2488
073ce355f788ac586254b94288d28c34488697fc	where did i see you before... a holistic method to compare and find archaeological artifacts		This paper describes the Secanto (Section Analysis Tool) computer program designed to find look-alikes of archaeological objects by comparing their shapes (sections, profiles). The current database contains the low resolution images of about 1000 profiles of handmade Iron Age ceramic vessels from The Netherlands and Northern Germany, taken from 14 ‘classic’ publications. A point-and-click data entry screen enables the user to enter her/his own profile and within 2 minutes the best look-alikes (best, according to a calculated similarity parameter) are retrieved from the database. The images, essentially treated as two-dimensional information carriers, are directly compared by measuring their surface curvatures. The differences between these curvatures are expressed in a similarity parameter, which can also be interpreted as a ‘distance between’. The method looks very promising, also for other types of artifacts like stone tools and coins.	dudebro: my shit is fucked up so i got to shoot/slice you ii: it's straight-up dawg time;holism	Vincent Mom	2006		10.1007/978-3-540-70981-7_77	computer program;archaeology;stone tool;computer science	NLP	-50.897530549871284	-76.36546362201283	2489
a47888c0243cac0b173c2748d8ed1b0a2a15fdd8	automatic information extraction from large websites	unsupervised learning;theoretical framework;generic algorithm;information extraction;wrappers;regular language;large scale;relational model;polynomial time;wrapper induction;web information extraction	Information extraction from websites is nowadays a relevant problem, usually performed by software modules called wrappers. A key requirement is that the wrapper generation process should be automated to the largest extent, in order to allow for large-scale extraction tasks even in presence of changes in the underlying sites. So far, however, only semi-automatic proposals have appeared in the literature.We present a novel approach to information extraction from websites, which reconciles recent proposals for supervised wrapper induction with the more traditional field of grammar inference. Grammar inference provides a promising theoretical framework for the study of unsupervised---that is, fully automatic---wrapper generation algorithms. However, due to some unrealistic assumptions on the input, these algorithms are not practically applicable to Web information extraction tasks.The main contributions of the article stand in the definition of a class of regular languages, called the prefix mark-up languages, that abstract the structures usually found in HTML pages, and in the definition of a polynomial-time unsupervised learning algorithm for this class. The article shows that, differently from other known classes, prefix mark-up languages and the associated algorithm can be practically used for information extraction purposes.A system based on the techniques described in the article has been implemented in a working prototype. We present some experimental results on known Websites, and discuss opportunities and limitations of the proposed approach.	algorithm;grammar induction;html;information extraction;markup language;polynomial;prototype;regular language;semiconductor industry;time complexity;unsupervised learning;wrapper (data mining)	Valter Crescenzi;Giansalvatore Mecca	2004	J. ACM	10.1145/1017460.1017462	unsupervised learning;time complexity;relational model;genetic algorithm;regular language;computer science;machine learning;data mining;database;programming language;information extraction;algorithm	AI	-30.53566644546174	-69.1238792481804	2494
09705c29c6961ef0940ab592a2d38a86cb0eec34	a comparison of a printed patient summary document with its electronic equivalent: early results		Clinicians are always searching for efficient access to clinical data. The Regenstrief Medical Record System has a printed report that fills this niche: Pocket Rounds. Handheld computers may offer an alternative, but it is unclear how effectively a handheld computer can display such data. We surveyed residents and students on the general medicine services for their opinions regarding Pocket Rounds. Those with handheld computers were given access to an electronic version of Pocket Rounds-e-Rounds. We surveyed the subjects who used e-Rounds for their opinions on the electronic format and how it compared to paper. Users overall satisfaction with Pocket Rounds was 5.8 on a seven-point scale. User s overall satisfaction for e-Rounds was 5.6 on a seven-point scale. The most useful function was retrieval of lab data for both modalities. The results suggest that the electronic format is a viable alternative to paper. Further evaluation is needed, and we plan a prospective controlled trial to study this further.	computer;computers;computers, handheld;medical records, problem-oriented;mobile device;niche blogging;overall satisfaction with treatment received for prostate cancer;printing;prospective search;general practice (field)	Sean M. Thomas;J. Marc Overhage;Jeff S. Warvel;Clement J. McDonald	2001	Proceedings. AMIA Symposium		modalities;randomized controlled trial;world wide web;patient summary document;medical record;multimedia;mobile device;medicine	HCI	-59.63885989261533	-64.7431932367137	2497
ebcb04588edcd28b5b199910690c6dda3ac88710	humans are dynamic - our tools should be too	creativity;technological innovation;computer security;human factors;malware	Security Operation Centers (SOCs) are being operated by universities, government agencies, and corporations to defend their enterprise networks and identify and thwart malicious behaviors in both networks and hosts. The success of a SOC depends on combining good tools and processes with efficient and effective analysts. During four years of anthropological fieldwork methods to study SOCs, the authors discovered that successful SOC innovations must resolve multiple internal and external conflicts to be effective and efficient. This discovery, guided by activity theory (AT) as a framework for analyzing the fieldwork data, enabled them understand these realities. Their research indicates conflict resolution is a prerequisite for continuous improvement of SOCs in both human and technological aspects. Failure to do so can lead to adverse effects, such as analyst burnout and reduction in overall effectiveness.	field research;humans;malware;reduction (complexity);system on a chip	Sathya Chandran Sundaramurthy;Michael Wesch;Xinming Ou;John McHugh;S. Raj Rajagopalan;Alexandru G. Bardas	2017	IEEE Internet Computing	10.1109/MIC.2017.52	simulation;computer science;artificial intelligence;human factors and ergonomics;database;distributed computing;malware;creativity;world wide web;computer security	DB	-71.5973011009405	-7.396891025286167	2498
01f5d5480bb114f372832e836836f837bec3283b	user needs in chemical information	on line processing;user needs;document publie;articulo sintesis;information source;article synthese;source information;information technology;besoin utilisateur;necesidad usuario;technologie information;information access;informacion;tratamiento en linea;estudio impacto;chimie;etude impact;user need;published document;chemistry;quimica;acces information;acceso informacion;traitement en ligne;tecnologia informacion;review;impact study;documento publicado;information;fuente informacion	Information is of great value in our modern industrial society. In chemistry, a discipline in which compounds and compound classes play the most important role, information on about 10 million compounds has been registered. This number increases annually by 0.5 million compounds published in about 0.5 million documents. In this context it is a prerequisite that the information hidden in books, scientific and technical journals, conference proceedings, dissertations, etc. be evaluated and presented by abstracting and indexing services and database producers. Timeliness, accuracy, and completeness of the information are high on the list of desirata of the users in chemistry. It is of great importance that all new information published in a primary source be considered and made searchable. Furthermore, properties of compounds including stereochemistry, toxicity, environmental behavior, etc. have to be made searchable, too. Factual and/or numerical data and reviews are requested as well. User friendliness of the services is of high priority. In the future, the electronic media will dominate the field of information more and more therefore many improvements in search methods are necessary	cheminformatics	Guenter Poetzscher;A. J. C. Wilson	1990	Journal of Chemical Information and Computer Sciences	10.1021/ci00066a013	chemistry;information;telecommunications;computer science;information technology;world wide web	Theory	-71.72438330181267	-22.584623019760798	2509
af99de07bf8ff47be4ba7f42d5f4933875e98e1b	benchmarking stability of bipedal locomotion based on individual full body dynamics and foot placement strategies–application to impaired and unimpaired walking		Citation: Ho Hoang K-L, Wolf SI and Mombaur K (2018) Benchmarking Stability of Bipedal Locomotion Based on Individual Full Body Dynamics and Foot Placement Strategies–Application to Impaired and Unimpaired Walking. Front. Robot. AI 5:117. doi: 10.3389/frobt.2018.00117 Benchmarking Stability of Bipedal Locomotion Based on Individual Full Body Dynamics and Foot Placement Strategies–Application to Impaired and Unimpaired Walking	robot	Khai-Long Ho Hoang;Sebastian I. Wolf;Katja D. Mombaur	2018	Front. Robotics and AI	10.3389/frobt.2018.00117		Robotics	-51.47681265933949	-23.5812311438989	2512
2e8125e235fb5259a6b0a6e481320b7078c97341	perceived instability of virtual haptic texture. ii. effect of collision-detection algorithm.	collision detection;haptic perception	This article reports the second study in a series that investigates perceived instabilityunrealistic sensations associated with virtual objectsof virtual haptic texture. Our first study quantified the maximum stiffness values under which virtual haptic textures were perceived to be stable (Choi & Tan, 2004). The present study investigated the effect of the collision-detection algorithm by removing the step changes in force magnitude that could have contributed to perceived instability in the first study. Our results demonstrate a significant increase in the maximum stiffness for stable haptic texture rendering. We also report a new type of perceived instability, aliveness, that is characterized by a pulsating sensation. We discuss the possible cause of aliveness and show that it is not always associated with control instability. Our results underscore the important roles played by environment modeling and human haptic perception, as well as control stability, in ensuring a perceptually stable virtual haptic environment.	algorithm;collision detection;computation;control theory;experiment;haptic technology;instability;numerical analysis;os-tan;primary source;pulse (signal processing);rendering (computer graphics);requirement;stationary process;stiffness;stylus (computing);transaction authentication number;virtual reality	Seungmoon Choi;Hong Z. Tan	2005	Presence: Teleoperators & Virtual Environments	10.1162/105474605774785271	stereotaxy;computer vision;simulation;computer science;artificial intelligence;multimedia;collision detection	HCI	-44.48317344290359	-50.681096798433195	2514
c7575d0c6d2a253e4f29267670df10c59acd3bb6	vista: interactive coffee-corner display	information management system;visual system design;social interaction;office and workplace;user centered design;interactive display;information sharing;public displays;social awareness;public display;social acceptance;interactive displays;visual system;interaction design;walk up and use systems	In the contemporary information-saturated world, there is a need for an easier, faster, and more social way to keep office workers updated and better aware of surrounding activities. Today's information management systems tend to consume time rather than simplify information sharing.The Vista system tries to solve this problem. It is designed to be used in places of social interaction, where it displays information about professional activities happening in the department. In this paper, the origins of the project, the user-centered design process, and iterative evaluation of the concept are described. The paper concludes with observations regarding the social acceptance of Vista and reflections on future research aspects.Vista is the result of a design project conducted in cooperation between the User-System Interaction postgraduate program at Eindhoven University of Technology, and the Research Group of Océ Technologies in the Netherlands.	amiga reflections;information management;iteration;iterative and incremental development;user-centered design;vista enhancer browser	Marcin Wichary;Lucy T. Gunawan;Nele Van den Ende;Qarin Hjortzberg-Nordlund;Aga Matysiak;Ruud Janssen;Xu Sun	2005		10.1145/1056808.1056818	social relation;user-centered design;simulation;visual system;human–computer interaction;computer science;interaction design;management information systems;multimedia;world wide web;social consciousness	HCI	-60.64512935389875	-32.23671184601236	2518
b1c7266eab7a372ca6ce9e3cc4a5d5d4c6d3a2b2	recommendation of open educational resources. an approach based on linked open data		In an open and distributed platform as the Web there are problems associated with the heterogeneity and information overload. In this context, teaching community and learners may need some support to discover the Open Educational Resources best suited for their learning processes. In this paper, the authors propose the high-level design of a framework for the recommendation of learning content in a flexible way. In order to provide a personalized set of resources, an adaptive approach of filtering is used according to the data available of each user. To achieve this goal, the framework has been designed taking into account the best features provided by technologies of the Semantic Web in order to find online material.	gensim;high- and low-level;information filtering system;information needs;information overload;information theory;iterative and incremental development;level design;linked data;personalization;semantic web;world wide web	Janneth Chicaiza;Nelson Piedra;Jorge López-Vargas;Edmundo Tovar Caro	2017	2017 IEEE Global Engineering Education Conference (EDUCON)	10.1109/EDUCON.2017.7943018	knowledge management;linked data;data mining;open educational resources;semantic web;information overload;computer science	Visualization	-81.61008550019378	-45.5991594634945	2533
7f58a016c43d16ef52b1033d49232d318baedbca	what alan turing might have discovered		When we look back at the twentieth century, I have no doubt that the single most important idea that we will see to have emerged there is the idea of computation. And already that idea has transformed our technology and many aspects of our world. But there is, I believe, still much more to come. Although he certainly did not realize the magnitude of what he was starting, Alan Turing in 1936 laid the single most critical foundation for the idea of computation when he invented the universal Turing machine. By the time Turing died in 1954, this idea had come by a circuitous route (through neural networks and the like) to inform early practical electronic computers. And it had also led Turing himself to think in a real way about the creation of artificial intelligence. But that was about as far as it got. And in his last years, when Turing thought, for example, about theories of biology, he did not realize that his ideas of computation might be relevant to them. Through the rest of the 1950s and into the 1960s and 1970s, practical computers became more and more powerful, and more and more common. And, at least among the small community of theoretical computer scientists, universal computing took its place as a foundational concept. Meanwhile, however, the rest of science continued its development, based in some cases on experiment and in some cases on mathematical analysis. Computers were occasionally used to support these existing methods. But there was no real idea that computation as an abstract concept might be centrally relevant. And indeed, in a sense, as computer technology advanced, computation as a concept seemed to recede more and more – as something to be mentioned for background but not something to be made the core of what should be studied. If Turing had lived longer, I rather suspect he might not have left it that way –	artificial intelligence;artificial neural network;computation;computer scientist;our world;theory;universal turing machine	Stephen Wolfram	2016		10.1017/CBO9780511863196.010	turing;artificial intelligence;computer science	AI	-56.83456391344074	-22.475723379439152	2534
3383420234d059b5785afdae5563fd5f6fc84cd1	using network centrality measures to improve national journal classification lists	network centrality measures;info eu repo semantics conferenceobject;circ classification;clasificacion circ;bibliometric indicators;journals;journal lists;journal categories;social networks analysis	Research productivity for the scholar is often evaluated on the basis of his/her journal articles; however, specific journals are said to possess a higher measure of impact than others (Archambault & Larivière, 2009; Garfield, 2006; Glänzel & Moed, 2002). When a scholar decides where to publish, (s)he might consider a journal’s impact factor. Although Garfield (1973) claimed that citation counts to individual articles will determine the impact factor of a journal, newer evidence points to the contrary: a journal with a high impact factor can also influence an article’s readership and subsequent citation rates (Larivière & Gingras, 2010). This “chicken-and-egg” dispute (i.e., which comes first – citations or impact?) can be tested, but can still have negative consequences for how journals are selected, rated, listed, and used by policy-makers for developing measures of scholarly performance. For instance, in countries like Denmark and Spain classified journal lists are now being produced and used in the calculation of nationwide performance indicators. As a result, Danish and Spanish scholars are advised to contribute to journals of high “authority” (as in the former) or those within a high class (as in the latter). This can create a few problems.	centrality	Alesia Zuccalá;Nicolas Robinson-Garcia;Rafael Repiso;Daniel Torres-Salinas	2016	CoRR		data science;data mining;operations research	Web+IR	-76.77625264506025	-22.202664372551304	2535
2c3dd258e4d5130ba2bd0beccf1e6efee3261ab0	tweet sentiment: from classification to quantification	market research;standards;social networking online learning artificial intelligence pattern classification sentiment analysis;frequency estimation;twitter aggregates estimation frequency estimation market research standards;estimation;social networks;aggregates;compressive sensing;twitter;quantification specific learning algorithms tweet sentiment classification ubiquitous enabling technology twittersphere suboptimal approach positive class label negative class label neutral class label tsc datasets classification oriented algorithm tweet sentiment prevalence;inter community detection	"""Sentiment classification has become a ubiquitous enabling technology in the Twittersphere, since classifying tweets according to the sentiment they convey towards a given entity (be it a product, a person, a political party, or a policy) has many applications in political science, social science, market research, and many others. In this paper we contend that most previous studies dealing with tweet sentiment classification (TSC) use a suboptimal approach. The reason is that the final goal of most such studies is not estimating the class label (e.g., Positive, Negative, or Neutral) of individual tweets, but estimating the relative frequency (a.k.a. """"prevalence"""") of the different classes in the dataset. The latter task is called quantification, and recent research has convincingly shown that it should be tackled as a task of its own, using learning algorithms and evaluation measures different from those used for classification. In this paper we show, on a multiplicity of TSC datasets, that using a quantification-specific algorithm produces substantially better class frequency estimates than a state-of-the-art classification-oriented algorithm routinely used in TSC. We thus argue that researchers interested in tweet sentiment prevalence should switch to quantification-specific (instead of classification-specific) learning algorithms and evaluation measures."""	algorithm;machine learning;remote desktop services;sentiment analysis	Wei Gao;Fabrizio Sebastiani	2015	2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)	10.1145/2808797.2809327	market research;estimation;social science;computer science;artificial intelligence;data science;machine learning;data mining;mathematics;compressed sensing;world wide web;statistics;social network	NLP	-15.025609268421643	-48.92969149457754	2536
617662e014f95e829dfaa7fe7e9ed882197bd3ad	visto: a new cbir system for vector images	image features;vector images;distance function;computacion informatica;graphical interface;user interface;satisfiability;ciencias basicas y experimentales;feature extraction;image search;visual features;experimental evaluation;scalable vector graphics;point of view;grupo a;content based image retrieval	In this paper, we present the main features of VISTO (Vector Image Serach TOol), a new Content-Based Image Retrieval (CBIR) system for vector images. Though unsuitable for photorealistic imagery, vector graphics are continually becoming more advanced and diffused. In fact, vector images are made up of individual, scalable objects defined by mathematical equations rather than pixels as in the case of raster images. This makes vector images fully scalable, resolution independent, not restricted to rectangular shape, allowing layering and editable/searchable text. Notwithstanding this increasing interest, all the CBIR systems proposed in the literature deal with raster images, while the research area concerning CBIR systems for vectorial images is quite new. To the best of our knowledge, VISTO is the first CBIR system for vector images proposed in the literature, and it has been designed for the retrieval of vector images in SVG (Scalable Vector Graphics) format. The contribution of this paper is twofold: we first describe the main characteristics of VISTO from the engine and the interface point of view, highlighting the differences with respect to CBIR systems for raster images known in the literature, and then evaluate VISTO’s engine from an experimental point of view within an advanced high quality 2D animation environment supporting cartoon episodes management.	content-based image retrieval;display resolution;pixel;raster graphics;scalability;scalable vector graphics	Tania Di Mascio;Daniele Frigioni;Laura Tarantino	2010	Inf. Syst.	10.1016/j.is.2009.10.003	computer vision;vector graphics;metric;feature extraction;computer science;artificial intelligence;theoretical computer science;machine learning;data mining;scalable vector graphics;graphical user interface;database;user interface;feature;satisfiability	Graphics	-11.435171078510328	-57.41582958762553	2537
2b8bf08fd641964f350e0a76a65fd012d2c36845	exploring od patterns of interested region based on taxi trajectories	filtering;od pattern;urban visualization;trajectory	Traffics of different regions in a city have different Origin-Destination (OD) patterns, which potentially reveal the surrounding traffic context and social functions. In this work, we present a visual analysis system to explore OD patterns of interested regions based on taxi trajectories. The system integrates interactive trajectory filtering with visual OD patterns exploration. Trajectories related to interested region are selected by a suite of graphical filtering tools, from which OD clusters are detected automatically. OD traffic patterns can be explored at two levels: overview of OD and detailed exploration on dynamic OD patterns, including information of dynamic traffic volume and travel time. By testing on real taxi trajectory data sets, we demonstrate the effectiveness of our system by case studies.	global positioning system;interaction;pattern recognition;time series;visual analytics;wheel (unix term)	Min Lu;Jie Liang;Zuchao Wang;Xiaoru Yuan	2016	J. Visualization	10.1007/s12650-016-0357-7	filter;simulation;trajectory;physics	HCI	-22.974791503333492	-34.0126104812853	2538
2d3e6724a28030c81d90d1b86c06c89afc7e18ae	an xml-based visual shading language for vertex and fragment shaders	extensible markup language;java programming;extensible 3d x3d;extensible markup language xml;three dimensional;visual programming language;visual programming;visual development;fragment shader;dataflow programming;vertex shader;shading languages	This paper presents a new system for the visual development of complex vertex and fragment shaders. The system makes usage of the advantages of visual programming languages. The core of the system is a Java program. With this program users can develop and test dataflow diagrams that describe the functionality of OpenGL ARB vertex and fragment programs. To get a graphical feedback the system is able to display rendered and shaded scenes immediately. The rendering of these three dimensional scenes will be done with the common Java-OpenGL binding GL4Java. Further on Cg4Java, a new binding for connecting Java to NVIDIA's High-Level Shading Language C for graphics (Cg) was developed. For an easy and fast way of verification, and for the possibility of a future integration into XML based 3D formats like Extensible 3D (X3D), the whole topology of the dataflow diagrams will be stored in XML. The concept of shader programming with dataflow diagrams and the architecture of our system will be described in detail. For a better understanding two examples will be presented and explained.	cg (programming language);dataflow programming;diagram;graphical user interface;graphics;high-level shading language;java;opengl architecture review board;shader;visual programming language;x3d;xml	Frank Goetz;Ralf Borau;Gitta Domik	2004		10.1145/985040.985054	computer science;theoretical computer science;extensible programming;signal programming;shading language;visual programming language;programming language;hlsl2glsl;computer graphics (images)	Graphics	-41.30326915410602	-30.80997299685712	2546
1cc193c3fa6c61b6de2b100a7ecf8aa928581aa5	an integrated method for estimating selectivities in a multidatabase system	multidatabase system;maintenance cost;query optimization;database management;method integration;distributed environment;adaptive sampling;selectivity;cost estimation;sampling methods;database management system;data sampling	A multidatabase system (MDBS) integrates information from autonomous local databases managed by diierent database management systems (MDBS) in a distributed environment. A number of challenges are raised for query optimization in such an MDBS. One of the major challenges is that some local optimization information may not be available at the global level. We recently proposed a query sampling method to drive cost estimation formulas for local databases in an MDBS 22]. To use the derived formulas to estimate the costs of queries, we need to know the selectivities of the qualii-cations of the queries. Unfortunately, existing methods for estimating selectivities cannot be used eeciently in an MDBS environment. This paper discusses diiculties of estimating selec-tivities in an MDBS. Based on the discussion, this paper presents an integrated method to estimate selectivities in an MDBS. The method integrates and extends several existing methods so that they can be used in an MDBS eeciently. It extends Christodoulakis' para-metric method so that estimation accuracy is improved and more types of queries can be handled. It extends Lipton and Naughton's adaptive sampling method so that both performance and accuracy are improved. Theoretical and experimental results show that the extended Lipton and Naughton's method described in this paper can be many times faster than the original one. In addition, the integrated method uses a new piggyback approach to collect and maintain statistics, which can reduce the statistic maintenance cost. The integrated method is designed for the MDBS in the CORDS project (CORDS-MDBS). Implementation considerations are also given in the paper.	adaptive sampling;autonomous robot;database;eros (microkernel);mathematical optimization;need to know;query optimization;sampling (signal processing)	Qiang Zhu	1993		10.1145/962388	sampling;query optimization;real-time computing;selectivity;computer science;data mining;database;distributed computing;cost estimate;distributed computing environment	DB	-24.900817292854235	1.7873527483342333	2547
9be9219c6177e3113d7a7c79279536fbb5bd4bd0	modelling the interplay of emotions, beliefs and intentions within collective decision making based on insights from social neuroscience	social neuroscience;belief;social interaction;mirroring;computer model;computational modeling;emotion;collective decision making;group decision;intention	Collective decision making involves on the one hand individual mental states such as beliefs, emotions and intentions, and on the other hand interaction with others with possibly different mental states. Achieving a satisfactory common group decision on which all agree requires that such mental states are adapted to each other by social interaction. Recent developments in Social Neuroscience have revealed neural mechanisms by which such mutual adaptation can be realised. These mechanisms not only enable intentions to converge to an emerging common decision, but at the same time enable to achieve shared underlying individual beliefs and emotions. This paper presents a computational model for such processes.	collective intelligence;computation;computational model;converge;mental state;social neuroscience	Mark Hoogendoorn;Jan Treur;C. Natalie van der Wal;Arlette van Wissen	2010		10.1007/978-3-642-17537-4_25	r-cast;mirroring;emotion;social neuroscience;knowledge management;belief	AI	-22.5007481591942	-15.346303208104032	2549
3c3fcdccf282b7c63920e6f4ba8c59ddba3825ef	trec-3: experience with conceptual relations in information retrieval.	use;query language;evaluation performance;performance evaluation;noun phrase;information retrieval;evaluacion prestacion;query formulation;formulacion pregunta;operateur booleen;boolean operator;formulation question;lenguaje interrogacion;utilizacion;documentation data processing;trec 3;utilisation;recherche documentaire;estudio caso;recuperacion documental;concept oriented;etude cas;langage interrogation;document retrieval;oriente concept;experimentation;experimentacion;informacion documental;operador de boole;informatique documentaire	This report describes an experiment evaluating the performance gains that can be achieved by using high-level conceptual relations in information retrieval. The objective of the experiment is to determine if conceptual relations can improve overall retrieval performance and, if so, under what conditions using relations is likely to be justified. We represent five TREC topics each as two concepts linked by a single relation, where a concept corresponds to a noun phrase and a relation corresponds to a verb phrase or a noun phrase that describes an action, activity, or relationship. A Boolean search (with proximity) is associated with each concept and a parameterized search with each relation. We then compare the performance of the expanded concept-relation-concept representation with the searches for the two concepts linked by each of several proximity operators. Our results show that use of relations can provide significant performance improvements but that the improvements are dependent on the nature of the two concepts and the relation with respect to the text collection being searched.	boolean algebra;experiment;high- and low-level;information retrieval;text retrieval conference	David A. Gardiner;John Riedl;James R. Slagle	1994			natural language processing;document retrieval;noun phrase;computer science;artificial intelligence;linguistics;information retrieval;query language	Web+IR	-35.01912270603372	-63.17039932811594	2553
a0c8d0b6e0d589a7968813904a42210f07ace544	system support for name authority control problem in digital libraries: opendblp approach	irregularity;pistage;mise a jour;building block;mando numerico;digital library;rastreo;systematique;test bed;commande numerique;irregularite;dato bibliografico;actualizacion;scenario;control problem;biblioteca electronica;sistematica;argumento;script;irregularidad;taxonomy;electronic library;digital control;bibliographic data;bibliotheque electronique;updating;tracking;donnee bibliographique	In maintaining Digital Libraries, having bibliographic data up-to-date is critical, yet often minor irregularities may cause information isolation. Unlike documents for which various kinds of unique ID systems exist (e.g., DOI, ISBN), other bibliographic entities such as author and publication venue do not have unique IDs. Therefore, in current Digital Libraries, tracking such bibliographic entities is not trivial. For instance, suppose a scholar changes her last name from A to B. Then, a user, searching for her publications under the new name B, cannot get old publications that appeared under A although they are by the same person. For such a scenario, since both A and B are the same person, it would be desirable for Digital Libraries to track their identities accordingly. In this paper, we investigate this problem known as name authority control, and present our system-oriented solution. We first identify three core building blocks that underlie the phenomenon, and show taxonomy where different combinations of the building blocks can occur. Then, we consider how systems can support the problem in two common functions of Digital Libraries Update and Search. Finally, our test-bed called OpenDBLP is presented where the suggested solution is fully implemented as a proof of the concept.	dbl-browser;digital library;entity;international standard book number;library (computing);taxonomy (general);testbed;venue (sound system)	Yoojin Hong;Byung-Won On;Dongwon Lee	2004		10.1007/978-3-540-30230-8_13	digital library;digital control;computer science;artificial intelligence;scenario;database;tracking;world wide web;algorithm;taxonomy;testbed	DB	-26.311707142714283	-58.93366374124666	2559
f8abdaf0312ec8848675fe3fc347c6a497d701fd	tree-structured neural machine for linguistics-aware sentence generation		Different from other sequential data, sentences in natural language are structured by linguistic grammars. Previous generative conversational models with chain-structured decoder ignore this structure in human language and might generate plausible responses with less satisfactory relevance and fluency. In this study, we aim to incorporate the results from linguistic analysis into the process of sentence generation for high-quality conversation generation. Specifically, we use a dependency parser to transform each response sentence into a dependency tree and construct a training corpus of sentencetree pairs. A tree-structured decoder is developed to learn the mapping from a sentence to its tree, where different types of hidden states are used to depict the local dependencies from an internal tree node to its children. For training acceleration, we propose a tree canonicalization method, which transforms trees into equivalent ternary trees. Then, with a proposed tree-structured search method, the model is able to generate the most probable responses in the form of dependency trees, which are finally flattened into sequences as the system output. Experimental results demonstrate that the proposed X2TREE framework outperforms baseline methods over 11.15% increase of acceptance ratio.	baseline (configuration management);dependency grammar;dialog system;encoder;natural language;relevance	Ganbin Zhou;Ping Luo;Rongyu Cao;Yijun Xiao;Fen Lin;Bo Chen;Qing He	2018			canonicalization;generative grammar;conversation;natural language;computer science;fluency;linguistics;dependency grammar;sentence;rule-based machine translation	AI	-17.367935860986154	-75.24227712492112	2568
68e1b9f92649ca3b228a0c5102df48700618d28e	a framework for high-resolution geo-specific road database creation based on image processing techniques for driving simulation	high resolution;image processing;data interpretation;driving simulator;3d model;image processing techniques;the united states geographical survey;road database	0965-9978/$ see front matter 2009 Elsevier Ltd. A doi:10.1016/j.advengsoft.2009.01.014 * Corresponding author. Tel.: +1 239 590 7583; fax E-mail addresses: dguo@fgcu.edu (D. Guo), wee klee@mail.ucf.edu (H. Klee), xyan1@utk.edu (X. Yan). Geo-specific road modeling is an important aspect of driving simulation studies. A challenge in this operation is that it requires intensive manual work to collect data, interpret data, and create 3D models. Each of these components is time consuming. In this research, we propose a framework for fast geo-specific road modeling based on high-resolution aerial photos. This framework has been experimented on a real driving simulator. 2009 Elsevier Ltd. All rights reserved.	3d computer graphics;3d modeling;aerial photography;driving simulator;fax;image processing;image resolution;like button;simulation	Dahai Guo;Arthur Robert Weeks;Harold Klee;Xuedong Yan	2009	Advances in Engineering Software	10.1016/j.advengsoft.2009.01.014	computer vision;simulation;image resolution;image processing;computer science;engineering;data mining;data analysis	AI	-24.580079204160846	-30.035390771626464	2571
4cc5646be4bb21e90617500d779af03cf14e90d9	highlights from cesun 2016: contemporary issues in methodological rigor for systems research			systems theory	Zoe Szajnfarber;Paulien M. Herder	2017	Systems Engineering	10.1002/sys.21416	economics;finance;social science	SE	-74.92304601437868	-2.079476609530919	2585
d53609a2fd575383a0be19e9d9cb37f11fd7d145	using neighbourhood density and selective snr boosting to increase the intelligibility of synthetic speech in noise		Motivated by the fact that words are not equally confusable, we explore the idea of using word-level intelligibility predictions to selectively boost the harder-to-understand words in a sentence, aiming to improve overall intelligibility in the presence of noise. First, the intelligibility of a set of words from dense and sparse phonetic neighbourhoods was evaluated in isolation. The resulting intelligibility scores were used to inform two sentencelevel experiments. In the first experiment the signal-to-noise ratio of one word was boosted to the detriment of another word. Sentence intelligibility did not generally improve. The intelligibility of words in isolation and in a sentence were found to be significantly different, both in clean and in noisy conditions. For the second experiment, one word was selectively boosted while slightly attenuating all other words in the sentence. This strategy was successful for words that were poorly recognised in that particular context. However, a reliable predictor of wordin-context intelligibility remains elusive, since this involves – as our results indicate – semantic, syntactic and acoustic information about the word and the sentence.	acoustic cryptanalysis;experiment;intelligibility (philosophy);kerrison predictor;signal-to-noise ratio;sparse matrix;speech synthesis;synthetic intelligence	Cassia Valentini-Botinhao;Mirjam Wester;Junichi Yamagishi;Simon King	2013			natural language processing;speech recognition;computer science;communication	NLP	-10.998095392315525	-84.16619188276434	2586
0c512a60bb0b5d6443788b07d79af8aefd896dfa	extracting human mobility and social behavior from location-aware traces	mobility;pattern analysis;mobility model;contact graph	Gaito S, Maggiorini D, Rossi G.P., Sala A (2012). Bus switched networks: An ad hoc mobile platform enabling urban-wide communications. AD HOC NETWORKS, vol. 10, p. 931-945, ISSN: 1570-8705 Zignani M, Gaito S, Rossi GP (2012). Extracting human mobility and social behavior from location-aware traces. WIRELESS COMMUNICATIONS AND MOBILE COMPUTING, ISSN: 1530-8669 Francesco Alberti, Silvio Ghilardi, Elena Pagani, Silvio Ranise, Gian Paolo Rossi. ``Univ ersal Guards, Relativization of Quantifiers, and Failure Models in Model Checking Modulo Theories'' . In Journal on satisfiability, boolean modeling and computation (JSAT), Vol. 8, pp. 29-61. ISSN 1574-0617 (2012).	algorithmic inference;boolean satisfiability problem;computation;hoc (programming language);international standard serial number;location awareness;mobile computing;mobile operating system;model checking;modulo operation;oracle machine;tracing (software)	Matteo Zignani;Sabrina Gaito;Gian Paolo Rossi	2013	Wireless Communications and Mobile Computing	10.1002/wcm.2209	simulation;telecommunications;computer science;artificial intelligence;operating system;data mining;mobility model;mobile computing;computer security;statistics	Mobile	-53.4650838628455	-3.315830141431945	2587
e2e28d2fb18eb7b3fe97db49e17bcc75a49ef312	abstract left-corner parsing for unification grammars		Left corner Parsing for Uni cation Grammars Noriko Tomuro and Steven L Lytinen DePaul University School of Computer Science Telecommunications and Information Systems S Wabash Ave Chicago IL flytinen tomurog cs depaul edu	computer science;han unification;left corner;parsing	Noriko Tomuro;Steven L. Lytinen	2001			parser combinator;parsing expression grammar;indexed grammar;bottom-up parsing;programming language;top-down parsing;l-attributed grammar;s-attributed grammar;computer science;top-down parsing language	AI	-47.57687118078599	-11.125699722468951	2590
5176d2390840bc57f99e3b8e4f5192d808ccfe22	a flexible human agent collaboration (hac) framework for human-human activity coordination (h2ac)		This paper presents an innovative shared intelligence framework for flexible human-agent collaboration. By ‘flexible’, we mean the level of collaboration is selected through a negotiated and iterative human-agent collaboration (HAC) process, which ensures that the needs of a system user are balanced with the availability of suitable experts to form and maintain an expert team that supports the user’s decision-making. To enable flexible human-agent collaboration to develop expert teams, our framework suitably represents team members’ roles and capabilities, represents tasks and environments, reasons simultaneously about task decomposition and team formation, and coordinates human experts and software agents. We describe our prototype implementation as it applies to a military medical service scenario.	collective intelligence;computation;experience;high-availability cluster;iteration;prototype;software agent	Wei Chen;Vikram Manikonda;Edmund H. Durfee	2007			machine learning;artificial intelligence;systems engineering;software agent;computer science;simulation	HCI	-18.154680456510008	-10.037229005228214	2593
03271b0260bce09e620ec8fe27a01bff3f5e71e8	on convention	practical reasoning;distinct type;main criticism;complex issue;vantage point	If my main criticism of Lewis is sound, we must conclude that there are at least two distinct types of convention: co-ordination conventions and conventions constituting autonomous practices. It is only possible in the case of the former, but not the latter, to specify the agents' structure of preferences, and the problem the convention is there to solve, antecedently and independently of the content of the conventions themselves. Conventions constituting an autonomous practice are constitutive of the point of, and the values inherent in the practice itself and hence they are not explicable in terms of solutions to co-ordination problems. Thus, from the vantage point of practical reasoning, Lewis' theory of conventions is partial and limited. It is superior, however, to the alternative offered by Gilbert, as it provides a good answer, albeit limited in scope, to the question of the normativity of conventions. Gilbert's analysis is more fundamentally flawed. She has failed to undermine Lewis' insight that conventions are arbitrary rules, due to her misconstrual of what arbitrariness consists in. Consequently, Gilbert's analysis of the normativity of social conventions in terms of ‘joint acceptance’ is doubly inadequate: it fails to distinguish conventions from many other types of rule people follow, and it fails to answer the question of the normativity of conventions in terms of reasons for action. In the course of this discussion, I have side-stepped all the difficult questions concerning the conventionality of language, judging them to be far too complex issues to be dealt with within the confines of this article. I do hope, however, that an awareness of the distinction between co-ordination conventions and conventions of autonomous practices, will facilitate the arguments over the conventionality of language as well.		Andrei Marmor	1996	Synthese	10.1007/BF00413841		AI	-13.409958512775718	2.7021527497464435	2594
3dc0c5362cd03520824aa7730d4271daa9f76e8d	two qubits for c.g. jung’s theory of personality	quantum cognition;projection operator;type indicator;qubit;entanglement;universiteitsbibliotheek;hilbert space;quantum computer;personality theory;big five	We propose a formalization of C.G. Jung's theory of personality using a four-dimensional Hilbert-space for the representation of two qubits. The first qubit relates to Jung's four psychological functions Thinking, Feeling, Sensing and iNtuition, which are represented by two groups of projection operators {T, F} and {S, N}. The operators in each group are commuting but operators of different groups are not. The second qubit represents Jung's two perspectives of extraversion and introversion. It is shown that this system gives a natural explanation of the 16 psychological types that are defined in the Jungian tradition. Further, the system accounts for the restriction posed by Jung concerning the possible combination of psychological functions and perspectives. Interestingly, the unitary transformation called X-gate in the quantum computation community realizes the cognitive operation connected to Jung's idea of the shadow. The empirical consequences of the present model are discussed and it is shown why the present praxis of personality diagnostics based on classical statistics is insufficient.	altran praxis;bell state;bell's theorem;boolean algebra;computation;consciousness;entity;hilbert space;interference (communication);interpretation (logic);jung;linear algebra;numerical analysis;quantum hall effect;quantum computing;quantum entanglement;quantum mechanics;qubit;requirement;self-reflection;semantics (computer science);theory;uncertainty principle	Reinhard Blutner;Elena Hochnadel	2010	Cognitive Systems Research	10.1016/j.cogsys.2009.12.002	psychology;quantum cognition;projection;artificial intelligence;qubit;quantum computer;social psychology;quantum entanglement;cognitive science;hilbert space	AI	-11.217408587172166	3.9926871437325224	2599
81b7d24015b3d086f5c082e686e38cc2ba8c2dfa	concept and design of a hand-held mobile robot system for craniotomy	intuitive robot;hand-held robot;hand-held mobile robot system;critical phase;craniotomy drill;surgical craniotomy procedures	Give us 5 minutes and we will show you the best book to read today. This is it, the concept and design of a hand held mobile robot system for craniotomy that will be your best choice for better reading book. Your five times will not spend wasted by reading this website. You can take the book as a source to make better concept. Referring the books that can be situated with your needs is sometime difficult. But here, this is so easy. You can find the best thing of book that you can read.	book;mobile device;mobile robot;situated	Gavin J. Kane	2011			mobile robot	Robotics	-46.32969922718278	-42.57481464796625	2602
0eb815409443d62a892fe4632f55e2c1b73e2a04	effect of cooperation between chinese scientific journals and international publishers on journals' impact factor	english language;international publishers;distributed networks;impact factor;indexation;chinese scientific journals	Growing cooperation between Chinese journals and international publishers invites an investigation of the effect of this cooperation, based on an analysis of journal IF changes. Data from 23 Chinese academic journals were chosen from about 50 English-language academic journals indexed by SCI or SCIE and with a long history of cooperation. The data do not suggest that cooperation has improved the journals’ IF thus far. It appears that cooperation is generally limited to international distribution, and this has a weak influence on the quality of the journal and its IF, even though the papers can be accessed by worldwide users through publishers’ international distribution networks. Cooperation with international publishers is one step, but actively working on the quality of the journals is a more important step. © 2009 Elsevier Ltd. All rights reserved.		Shuhua Wang;Hengjun Wang;Paul R. Weldon	2010	J. Informetrics	10.1016/j.joi.2009.11.008	english;operations research	Arch	-76.58992531223713	-20.863088432638694	2603
34ead52ee8def3f07ad5ee1fea6b5e06fed3385c	the rise of social bots		Todayu0027s social bots are sophisticated and sometimes menacing. Indeed, their presence can endanger online ecosystems as well as our society.	ecosystem	Emilio Ferrara;Onur Varol;Clayton A. Davis;Filippo Menczer;Alessandro Flammini	2016	Commun. ACM	10.1145/2818717	multimedia	Theory	-66.94757547899233	-10.014362210666558	2606
66ff86c531883ddc8effec5df6c2db8d0a476744	a survey-based study of factors that motivate nurses to protect the privacy of electronic medical records	biological patents;adulto;health informatics;hospitais militares;biomedical journals;electronic medical records;text mining;europe pubmed central;citation search;questionarios;feminino;citation networks;privacy protection;information systems and communication service;humanos;recursos humanos de enfermagem no hospital;taiwan;research articles;issn 1472 6947;abstracts;management of computing and information systems;open access;masculino;life sciences;clinical guidelines;registros eletronicos de saude;decomposed theory of planned behavior;atitude do pessoal de saude;nurses;full text;meia idade;privacidade;rest apis;orcids;europe pmc;bmc medical informatics and decision making;biomedical research;bioinformatics;literature search	BACKGROUND The purpose of this study is to investigate factors that motivate nurses to protect privacy in electronic medical records, based on the Decomposed Theory of Planned Behavior.   METHODS This cross-sectional study used questionnaires to collect data from nurses in a large tertiary care military hospital in Taiwan.   RESULTS The three hundred two (302) valid questionnaires returned resulted in a response rate of 63.7 %. Structural equation modeling identified that the factors of attitude, subjective norm, and perceived behavioral control of the nurses significantly predicted the nurses' intention to protect the privacy of electronic medical records. Further, perceived usefulness and compatibility, peer and superior influence, self-efficacy and facilitating conditions, respectively predicted these three factors.   CONCLUSIONS The results of our study may provide valuable information for education and practice in predicting nurses' intention to protect privacy of electronic medical records.	cross-sectional data;electronic health records;electronics, medical;medical device incompatibility problem;military hospitals;privacy;questionnaire domain;self efficacy;structural equation modeling;tertiary healthcare	Chen-Chung Ma;Kuang-Ming Kuo;Judith W. Alexander	2015		10.1186/s12911-016-0254-y	health informatics;text mining;medical research;medicine;data science;nursing	HCI	-61.93108738248265	-63.55695858810296	2609
561088e260e653efed21310434ff3e1bcfc41b11	automatic segmentation of sequences through hierarchical reinforcement learning	cognitive agents;automatic segmentation;reinforcement learning;a priori knowledge;levels of abstraction;decision process;domain specificity;domain structure	Sequential behaviors (sequential decision processes) are fundamental to cognitive agents. The use of reinforcement learning (RL) for acquiring sequential behaviors is appropriate, and even necessary, when there is no domain-specific a priori knowledge available to agents (Sutton 1995, Barto et al 1995, Kaelbling et al 1996, Bertsekas and Tsitsiklis 1996, Watkins 1989). Given the complexity and differing scales of events in the world, there is a need for hierarchical RL that can produce action sequences and subsequences that correspond with domain structures. This has been demonstrated time and again, in terms of facilitating learning and/or dealing with non-Markovian dependencies, e.g., by Dayan and Hinton (1993), Kaelbling (1993), Lin (1993), Wiering and Schmidhuber (1998), Tadepalli and Dietterich (1997), Parr and Russell (1997), Dietterich (1997), and many others. Different levels of action subsequencing correspond to different levels of abstraction. Thus, subsequencing facilitates hierarchical planning as studied in traditional AI as well (Sacerdoti 1974, Knoblock, Tenenberg, and Yang 1994, Sun and Sessions 1998).	reinforcement learning	Ron Sun;Chad Sessions	2001		10.1007/3-540-44565-X_11	computer science;artificial intelligence;machine learning;pattern recognition;learning classifier system	Vision	-23.72647905087631	-18.50559815927417	2612
f0009c07a478268701a11963a2c5b3b1af6fbcfa	evidence-based re-design of an introductory course “programming in c”	software;electronic learning;electronic mail;programming profession;videos	This paper describes the step-wise re-design of a traditional introductory programming course into a blended learning course. By combining lectures with an online programming environment, short instructional videos, and Tutorial-worksheets, we intend to increase student learning and help students develop the ability to write software. To ensure a successful revision of the course, student learning is closely monitored. The course is changed in separate steps spread over several semesters. By administering a German translation of the SCS1 Assessment at each step, the effects of the changes to the course can be analyzed. The translation of the SCS1 and the data gathering process are described and preliminary data on student learning in the course are shown.	align (company);integrated development environment;precondition	Dion Timmermann;Christian H. Kautz;Volker Skwarek	2016	2016 IEEE Frontiers in Education Conference (FIE)	10.1109/FIE.2016.7757492	simulation;computer science;multimedia;world wide web	Robotics	-78.05520873180932	-36.24097724886571	2613
1c109425eadb3bc735bbc32ab2b433a006a6f506	crowdwalk: leveraging the wisdom of the crowd to inspire walking activities	self quantification;behavior change;activity tracking;persuasive technologies;crowdsourcing	"""Despite the initial premise of activity trackers, recent work has questioned their long-term efficacy in supporting behavior change. This paper makes two contributions. First, we present a study that inquired into individuals' ways of incorporating physical activity into their daily routines -- and specifically, the """"why, how, when and where"""" of physical activity. Secondly, we present CrowdWalk, a mobile app that leverages the wisdom of the crowd to produce location-based """"walking challenges"""", and thus attempts to assist behavior change through highlighting opportunities for physical activity."""	activity tracker;mobile app;wisdom of the crowd	Tiago Ornelas;Ana Karina Caraban;Rúben Gouveia;Evangelos Karapanos	2015		10.1145/2800835.2800923	simulation;computer science;behavior change;crowdsourcing	HCI	-60.53456352548415	-53.88517044476878	2614
6b6b9205646a2eb71536933a670d6401bf93a55e	how did the discussion go: discourse act classification in social media conversations.		Within last two decades, social media has emerged as almost an alternate world where people communicate with each other and express opinions about almost anything. This makes platforms like Facebook, Reddit, Twitter, Myspace etc. a rich bank of heterogeneous data, primarily expressed via text but reflecting all textual and non-textual data that human interaction can produce. We propose a novel attention based hierarchical LSTM model to classify discourse act sequences in social media conversations, aimed at mining data from online discussion using textual meanings beyond sentence level. The very uniqueness of the task is the complete categorization of possible pragmatic roles in informal textual discussions, contrary to extraction of question-answers, stance detection or sarcasm identification which are very much role specific tasks. Early attempt was made on a Reddit discussion dataset. We train our model on the same data, and present test results on two different datasets, one from Reddit and one from Facebook. Our proposed model outperformed the previous one in terms of domain independence; without using platformdependent structural features, our hierarchical LSTM with word relevance attention mechanism achieved F1-scores of 71% and 66% respectively to predict discourse roles of comments in Reddit and Facebook discussions. Efficiency of recurrent and convolutional architectures in order to learn discursive representation on the same task has been presented and analyzed, with different word and comment embedding schemes. Our attention mechanism enables us to inquire into relevance ordering of text segments according to their roles in discourse. We present a human annotator experiment to unveil important observations about modeling and data annotation. Equipped with our text-based discourse identification model, we inquire into how Subhabrata Dutta Jadavpur University, Kolkata, India, e-mail: subha0009@gmail.com Tanmoy Chakraborty IIIT Delhi, India, e-mail: tanmoy@iiitd.ac.in Dipankar Das Jadavpur University, Kolkata, India, e-mail: dipankar.dipnil2005@gmail.com 1 ar X iv :1 80 8. 02 29 0v 1 [ cs .C L ] 7 A ug 2 01 8 2 Subhabrata Dutta, Tanmoy Chakraborty and Dipankar Das heterogeneous non-textual features like location, time, leaning of information etc. play their roles in charaterizing online discussions on Facebook.	categorization;comment (computer programming);computation;computational linguistics;email;introspection;long short-term memory;memory segmentation;multimodal interaction;recurrent neural network;relevance;social media;social network;software propagation;supratik chakraborty;text corpus;text-based (computing)	Subhabrata Dutta;Tanmoy Chakraborty;Dipankar Das	2018	CoRR		natural language processing;data annotation;online discussion;sarcasm;artificial intelligence;categorization;social media;computer science;sentence	NLP	-20.969485187712394	-68.74286253957902	2622
45039e5599342d3231343c1ec0b64e9539dc5540	value co-creation and co-destruction in online video games: an exploratory study and implications for future research		In this empirical study we studied how players of online video games co-create and co-destroy value. From players’ perceptions we identified that value co-creation and co-destruction occur amid themes of giving feedback and building relations. Feedback encourages players but it may also be harmful in the form of verbal abuse. Building relations relates to making friends in general but also on an international level. Building relations also relates to competition that creates a bad spirit. The most intensive interplay between value co-creation and codestruction was found in gaming groups. Gaming groups motivate players to engage in intense gameplay, but at the same time they are resourcedemanding with respect to time and mental capacity. In conclusion, we argue that further study is required of the ways that value co-creation and co-destruction interact in online video games.		Jarkko Kokko;Tero Vartiainen;Tuure Tuunanen	2018				HCI	-86.7738242802571	-18.171910038201787	2623
20d363f7dd14a6745dfdcf954d036867bc205373	are friends overrated? a study for the social news aggregator digg.com	information propagation;online social networks;role of friendships	The key feature of online social networks is the ability of users to become active, make friends and interact with those around them. Such interaction is typically perceived as critical to these platforms; therefore, a significant share of research has investigated the characteristics of social links, friendship relations, community structure, searching for the role and importance of individual members. In this paper, we present results from a multi-year study of the online social network Digg.com, indicating that the importance of friends and the friend network in the propagation of information is less than originally perceived. While we note that users form and maintain social structure, the importance of these links and their contribution is very low: Even friends with nearly identical interests are only activated with a probability of 2% and only in 50% of stories that became popular we find evidence that the social ties were critical to the spread.	academy;freedom of information laws by country;news aggregator;social network aggregation;social structure;software propagation	Christian Doerr;Norbert Blenn;Siyu Tang;Piet Van Mieghem	2012	Computer Communications	10.1016/j.comcom.2012.02.001	telecommunications;computer security	Web+IR	-83.39266956526646	-16.907413231770082	2626
b2f8aeeb461ddaaabd9ab2c66c246f0c2c218b6d	book review: panning for gold: information literacy and the net lenses model by sylvia edwards 2006, adelaide: auslib press, 212pp, a$55.00 isbn 1875145605	information literacy	There are a number of information literacy models in existence, of which Christine Bruce’s Seven Faces of IL, SCONUL’s Seven Pillars model and the Big 6 are possibly the best known. Panning for Gold, which aims to identify information literacy education implications for academic curricula and library programmes, presents an alternative: the Net Lenses Model, developed to represent searching behaviour in the electronic information environment. Essentially, this book is the author’s doctoral thesis, and is based on research carried out with students at Queensland University of Technology (QUT). It examines information literacy from a phenomenographical approach and defines four conceptions of information seeking in an online environment. Phenomenography, as a qualitative research method, has its roots in education and has been developed from investigations into students’ experiences of learning. Edwards, a librarian who became an academic in the School of Information Systems at QUT, chose to apply this method to her study of web-based informationseeking behaviour to better understand the variation in student perceptions, experiences and conceptions of finding information. The Net Lenses Model model builds on Kuhlthau’s Information Search Process and Bruce’s Seven Pillars model. Edwards identifies four conceptions, or categories, which depict the information-searching skill levels of the students who participated in the study. Category 1 describes searching as looking for a needle in a haystack, with web-based information visualized as a formless, unstructured mass from which it is difficult to find relevant information. Category 2 defines the search process as finding a way through a maze, which, by exploring blind alleys and dead ends, selecting search terms and using synonyms, will persevere to achieve a successful outcome. Category 3 introduces the idea of planning searches and understanding how to use tools to filter out irrelevant material, thus reducing search results to a manageable set. Category 4 is seen as panning for gold, by using filtering mechanisms and modifying strategies to locate quality primary, rather than secondary sources of information. Edwards’s Net Lenses Model is an electronic portrayal of the categories by which students’ information searching is defined. It uses a Flash program to demonstrate interactively the ‘outcome space’ which illustrates the critical dimensions of and relationships between the four conceptions identified by the author’s research. ethnography in its number. She also includes grounded theory in this section and offers an interesting debate on whether grounded theory is in fact a method or a mode of analysis. I applaud the way Pickard distinguishes between methodology and methods and between research methods and data collection methods, again, terminology too often confused by those beginning research. Part 3 looks at various methods used to collect data including interviews, diaries, focus groups and questionnaires. Pickard reminds us that research is not a static process and she encourages us to try out different techniques since, as she notes, finding out what does not work can be just as illuminating as discovering what does – she gives an example of this when describing the use of diaries as a collection method. She also reminds us that in many studies, data collection and data analysis go hand-in-hand since what we discover will undoubtedly influence the next step in data collection. The introduction to this section includes a number of practical tips which are both reassuring and sensible – a recurring theme in this book. The final section of the text is concerned with data analysis and presentation. Pickard begins this section with a helpful disclaimer: she lets us know that her text cannot and does not attempt to cover the depth and detail of data analysis and suggests that we read much more widely to learn more. With this proviso in mind, her chapters on analysis cover the essential elements but do not go into sufficient detail to allow the novice researcher to use them to guide their data analysis. Pickard writes briefly about the advantages and disadvantages of using software for data analysis. She discusses SPSS and MINITAB for quantitative analysis but mentions only NUD.IST as an example of qualitative data analysis (QDA). The last chapter of the book lays out a rubric for presenting the research and stresses the need for justification of every step of the research process. Pickard has evidently learned much from her own research as well as from her interactions with research students; her sage advice has the hallmark of those experiences stamped on it. Overall, the book does exactly what it sets out to do: it provides a how-to guide to the research process from conception to presentation and it does so in an accessible, practical manner. It almost feels as if she is helping you through the thinking involved in the process. This book will be of practical value to LIS students and to those studying archives and records management as well as to beginning research in practice. On a final note, one of Pickard’s aims in writing the book was to share the joy of research, comparing research to a grand adventure and researchers to intrepid explorers: she conveys these aspects extremely well and I finished this book excitedly anticipating my next research adventure.	adobe flash;archive;experience;focus group;information systems;information literacy;information search process;information seeking;interaction;interactivity;international standard book number;librarian;mind;minitab;pdf/a;relevance;spss;secondary source;web application;window blind	Maggie Fieldhouse	2009	JOLIS	10.1177/09610006090410010203	library science;computer science;information literacy;media studies;sociology	HCI	-73.61672788766208	-29.87570087136099	2632
dd9050ffe91aea9a612622d78a37d032e5619de8	german medical data sciences: visions and bridges - proceedings of the 62nd annual meeting of the german association of medical informatics, biometry and epidemiology (gmds e.v.), gmds 2017, oldenburg, germany, 17-21 september 2017			biostatistics;generalized multidimensional scaling;informatics		2017				ML	-56.743788983781265	-10.276691584033909	2634
f2638eb5fc27e7e73b7a619cbcdaf030125d9cf7	an evaluation model of digital educational resources	digital educational resources;quality;criteria;evaluation grid			Abderrahim El Mhouti;Mohamed Erradi;Azeddine Nasseh	2013	iJET	10.3991/ijet.v8i2.2501	computer science;knowledge management;management science;dominance-based rough set approach	HCI	-64.71929203607714	-1.700791405861338	2636
75665b10a6dfb0ce2108484ee61dbbe37d34139d	putting intelligent characters to work		ize intelligent characters. Our technology grew out of research on intelligent agents, begun at the Rand Corporation and pursued over a decade at Stanford University. At its core, the “dynamic control architecture” models the orderly yet opportunistic nature of human cognition (Hayes-Roth, 1985). It provides a uniform mechanism by which an agent triggers and chooses among context-appropriate actions for both task-level and meta-level actions. A series of challenging applications were built to evaluate the architecture and inspire extensions for new functionality. In early applications, cognitive agents performed heuristic design tasks, such as protein structure modeling and site layout, where dynamic control produced efficiency in complex reasoning computations. The architecture was extended with reusable design ontologies, languages, and strategies, which also supported semantic explanation of the design process and explicit reasoning traces for learning. In later applications, situated agents performed monitoring and control tasks, for example office robots, semiconductor manufacturing, and patient monitoring in the intensive care unit. Here, the architecture was extended to support continuous operation in complex real-time environments; coordination of concurrent perception, cognition, and action; asynchronous performance of loosely coupled tasks, such as situation monitoring, fault detection, diagnosis, and planning; context-sensitive selection among alternative methods for particular instances of each task; and closed-loop control (Hayes-Roth 1995). Addressing practical matters of software development, our next-generation architecture also provided a component-based plug-and-play approach to supporting these capabilities for a broad class of adaptive intelligent agents (HayesRoth and Larsson 1997). In the early 1990s, we were ready for new challenges. At the 1994 AAAI Spring Symposium on believable agents (Stanford, California), Joe Bates demonstrated his delightful Woggles—spherical creatures that evinced social-emotional dynamics while playing together in a colorful virtual world (Bates 1994). I was hooked! Bates’s evangelizing of believable agents reignited my original professional interest in psychology (on hiatus since arriving at Stanford) and the potential for embodied agents that manifest personality, emotion, and social dynamics. It also led to the performing arts literature, notably Keith Johnstone’s (1987) brilliant, deeply psychological theory of theatrical improvisation. It was intriguing to realize that our agent architecture offered a felicitous foundation for a new class of “improvisational characters” and new classes of application genres related to learning, play, and the performing arts. Our first new application was a toy that turned out to be a learning toy. We created two “Improv Puppets” by using our architecture to build improvisational character “minds” and integrating them with Articles	agent architecture;cognition;component-based software engineering;computation;context-sensitive grammar;continuous operation;control theory;embodied agent;fault detection and isolation;hayes microcomputer products;hayes command set;heuristic;intelligent agent;loose coupling;lotus improv;ontology (information science);oxford spelling;plug and play;rand index;real-time clock;realms of the haunting;robot;semiconductor device fabrication;situated;social dynamics;software development;tracing (software);virtual world	Barbara Hayes-Roth	2008	AI Magazine		bubble;the internet;simulation;computer science;engineering;artificial intelligence	AI	-26.33621775217202	-18.131278418090588	2639
dea2c94b5de5a2e27bc8968db32a82e378efa6b2	two sides of the story: media choice and media use of web based email and live chat customer services	log files;customer services;media use;real time;qualitative data;customer service;data analysis;media choice;user interaction	Chat services that provide real-time help for customers have been adopted widely and rapidly on many websites in the past few years. Our paper investigates online live chat customer services from two perspectives: media choice between chat service and web e-mail, and media use of chat service analyzed from the perspectives of characteristics, interactivity and socioemotional content. We collected four types of data including system log files, surveys, excerpts of chat transcripts, and unstructured interviews with service representatives. In addition to quantitative data analysis, ATLAS.ti was used to analyze qualitative data in our study. We found that for the purpose of seeking help with questions, more users chose to use web email than chat service. When using the chat service, representatives and users interact with each other through text exchange, page pushing, and co-browsing. They also perform activities such as clarification and attracting attention, and use socioemotional content such as greetings and expressing feelings.	americas conference on information systems;chat room;data logger;dyadic transformation;email;interactivity;real-time computing;real-time transcription;synchronicity;webmail	Shu Zou;Sam Stormont	2005			customer to customer;voice of the customer;customer reference program;multimedia;customer intelligence;business;internet privacy;world wide web	HCI	-64.89776749385246	-28.48598380581935	2641
51fa8a197399f7925c30208ced3368fa3f7e6e58	iqr: an interactive query relaxation system for the empty-answer problem	query relaxation;optimization framework;empty answer problem	We present IQR, a system that demonstrates optimization based interactive relaxations for queries that return an empty answer. Given an empty answer, IQR dynamically suggests one relaxation of the original query conditions at a time to the user, based on certain optimization objectives, and the user responds by either accepting or declining the relaxation, until the user arrives at a non-empty answer, or a non-empty answer is impossible to achieve with any further relaxations. The relaxation suggestions hinge on a proba- bilistic framework that takes into account the probability of the user accepting a suggested relaxation, as well as how much that relaxation serves towards the optimization objec- tive. IQR accepts a wide variety of optimization objectives - user centric objectives, such as, minimizing the number of user interactions (i.e., effort) or returning relevant results, as well as seller centric objectives, such as, maximizing profit. IQR offers principled exact and approximate solutions for gen- erating relaxations that are demonstrated using multiple, large real datasets.	approximation algorithm;interaction;linear programming relaxation;mathematical optimization	Davide Mottin;Alice Marascu;Senjuti Basu Roy;Gautam Das;Themis Palpanas;Yannis Velegrakis	2014		10.1145/2588555.2594512	mathematical optimization;simulation;database	AI	-7.173275752086719	3.595795853475488	2642
8c09574d80b3ce6b260e7978fc23de78fa46f484	cue: a preprocessor system for restricted, natural english	grammar;syntax;semantics;parsing;natural language parsing;computational linguistic;natural language;experimental model;english;computational linguistics;cue;relades;semantic analysis	"""CUE, an input interface system which permits the computer to utilize natural but restricted English as input, is presented. In addition, an experimental model for CUE, Proto-RELADES, which can """"understand"""" and execute English sentences about the content of the library at IBM's Boston Programming Center is described. These sentences can be query, command, or conditional sentences. The linguistic component of the system is based on a transformational grammar of English that performs a full syntactic and semantic analysis of each input sentence and translates it into relevant computer operations. The capabilities and limitations of this system are described."""	input device;preprocessor;transformational grammar	David B. Loveman;John A. Moyne;Robert G. Tobey	1971		10.1145/511285.511292	natural language processing;speech recognition;syntax;computer science;computational linguistics;english;parsing;grammar;semantics;natural language	NLP	-29.532722902730143	-82.4629312740197	2647
52de92236038e7630a3a9584bae0628d2f052bc8	mizan: a large persian-english parallel corpus		One of the most major and essential tasks in natural language processing is machine translation that is now highly dependent upon multilingual parallel corpora. Through this paper, we introduce the biggest Persian-English parallel corpus with more than one million sentence pairs collected from masterpieces of literature. We also present acquisition process and statistics of the corpus, and experiment a base-line statistical machine translation system using the corpus.	baseline (configuration management);natural language processing;parallel text;satisfiability modulo theories;statistical machine translation;text corpus	Omid Kashefi	2018	CoRR		natural language processing;artificial intelligence;machine translation;persian;computer science;sentence	NLP	-22.931183729939015	-77.17074802796414	2649
2259149a35fcb01559e17f00f0a0de053e8e8340	is a dark virtual environment scary?	stress;illumination;emotionally intense simulations;virtual environment;users emotions;nighttime lighting conditions;vision	This study investigated the effects of nighttime lighting conditions and stress on the affective appraisal of a virtual environment (VE). The effective application of VEs in emotionally intense simulations requires precise control over their characteristics that affect the user's emotions and behavior. It is known that humans have an innate fear of darkness, which increases after exposure to stress and extrapolates to ecologically valid (immersive) VEs. This study investigated if the simulated level of illumination determines the affective appraisal of a VE, particularly after stress. Participants explored either a daytime or a nighttime version of a VE, after performing either an acute psychosocial stress task (Trier Social Stress Test, or TSST) or a relaxing control task. The affective qualities of the VE were appraised through the Russel and Pratt semantic questionnaire on the valence and arousal dimensions. Distress was assessed through free salivary cortisol, the state self-report scale from the Spielberger State-Trait Anxiety Inventory (STAI), and heart rate. In addition, memory for scenic details was tested through a yes-no recognition test. Free salivary cortisol levels, heart rates, and scores on the STAI all indicate that participants who were subjected to the stress task indeed showed signs of distress, whereas participants in the control group showed no signs of stress. The results of the semantic questionnaire and the recognition test showed no significant overall effect of time-of-day conditions on the affective appraisal of the VE or on the recognition of its details, even after prior stress. The experiences of users exploring the VE were not affected by the simulated lighting conditions, even after acute prior stress. Thus, lowering the illumination level in a desktop VE is not sufficient to elicit anxiety. Hence, desktop VE representations are different from immersive VE representations in this respect. This finding has implications for desktop VE representations that are deployed for serious gaming and training purposes.		Alexander Toet;Marloes van Welie;Joske Houtkamp	2009	Cyberpsychology & behavior : the impact of the Internet, multimedia and virtual reality on behavior and society	10.1089/cpb.2008.0293	psychology;vision;developmental psychology;computer science;virtual machine;psychotherapist;stress;communication;social psychology	HCI	-54.2571043772464	-51.70658108732982	2660
9b291f268e9567e4b250b2b65efdb7645d8fb7e7	“woodlands” - a virtual reality serious game supporting learning of practical road safety skills		In developed societies road safety skills are taught early and often practiced under the supervision of a parent, providing children with a combination of theoretical and practical knowledge. At some point children will attempt to cross a road unsupervised, at that point in time their safety depends on the effectiveness of their road safety education. To date, various attempts to supplement road safety education with technology were made. Most common approach focus on addressing declarative knowledge, by delivering road safety theory in an engaging fashion. Apart from expanding on text based resources to include instructional videos and animations, some stakeholders (e.g.: Irish Road Safety Authority) attempt to take advantage of game-based learning [1]. However, despite the high capacity for interaction being common in Virtual Environments, available game-based solutions to road safety education are currently limited to delivering and assessing declarative knowledge. With recent advancements in the field of Virtual Reality (VR) Head Mounted Displays, procedural knowledge might also be addressed in Virtual Environments. This paper describes the design and development process of a computer-supported learning system that attempts to address psycho-motor skills involved in crossing a road safely, changing learners' attitude towards road safety best practices, and enabling independent practice of transferable skills. By implementing game-based learning principles and following best practice for serious game design (such as making educational components essential to successful game-play, or instructional scaffolding) we hope to make it not only more effective, but also engaging, allowing us to rely on learners' intrinsic motivation [2], to increase their independent practice time and provide them with feedback that will help to condition safe behaviour and increase retention. Presence in Virtual Reality might evoke responses to Virtual Environment as if it was real (RAIR) [3] and enable learners to truly experience learning scenarios. In consequence leading to formation of autobiographical memories constructed from multisensory input, which should result in an increased knowledge retention and transfer [4].	animation;best practice;forests;memory, episodic;societies;solutions;text-based (computing);unsupervised learning;vr - veterans rand health survey;virtual reality exposure therapy	Krzysztof Szczurowski;Matt Smith	2018	2018 IEEE Games, Entertainment, Media Conference (GEM)	10.1109/GEM.2018.8516493	knowledge management;descriptive knowledge;procedural knowledge;best practice;virtual machine;principles of learning;instructional scaffolding;computer science;game design;transferable skills analysis	HCI	-75.77174353010393	-35.920140303306376	2666
5b3f67e037439ba1213aa872a43ddfc10a77d661	framework of automatic text summarization using reinforcement learning	automatic text summarization;automatic summarization problem;art ilp-style method;automatic summarization;rouge score;feature representation;score function;reinforcement learning;new approach	We present a new approach to the problem of automatic text summarization called Automatic Summarization using Reinforcement Learning (ASRL) in this paper, which models the process of constructing a summary within the framework of reinforcement learning and attempts to optimize the given score function with the given feature representation of a summary. We demonstrate that the method of reinforcement learning can be adapted to automatic summarization problems naturally and simply, and other summarizing techniques, such as sentence compression, can be easily adapted as actions of the framework. The experimental results indicated ASRL was superior to the best performing method in DUC2004 and comparable to the state of the art ILP-style method, in terms of ROUGE scores. The results also revealed ASRL can search for sub-optimal solutions efficiently under conditions for effectively selecting features and the score function.	approximation;automatic summarization;bellman equation;converge;radial basis function network;reinforcement learning	Seonggi Ryang;Takeshi Abekawa	2012			computer science;automatic summarization;machine learning;pattern recognition;data mining	NLP	-19.164021727534408	-63.18759413468018	2669
f1cba844a35ac1ff691929e6515c72695c325c6b	families that play together stay together: investigating family bonding through video games				Bingqing Wang;L Elaine Taylor;Qiusi Sun	2018	New Media & Society	10.1177/1461444818767667		HCI	-54.311857141305815	-31.95734331452466	2670
38b782444481470d43b45b8984cd7baadbd584f2	collecting semantic data from mechanical turk for a lexical knowledge resource in a text to picture generating system		WordsEye is a system for automatically converting natural language text into 3D scenes representing the meaning of that text. At the core of WordsEye is the Scenario-Based Lexical Knowledge Resource (SBLR), a unified knowledge base and representational system for expressing lexical and real-world knowledge needed to depict scenes from text. To enrich a portion of the SBLR, we need to fill out some contextual information about its objects, including information about their typical parts, typical locations and typical objects located near them. This paper explores our proposed methodology to achieve this goal. First we try to collect some semantic information by using Amazon’s Mechanical Turk (AMT). Then, we manually filter and classify the collected data and finally, we compare the manual results with the output of some automatic filtration techniques which use several WordNet similarity and corpus association measures.	amazon mechanical turk;automatic control;baseline (configuration management);commonsense knowledge (artificial intelligence);knowledge base;knowledge-based systems;library (computing);microsoft word for mac;natural language;the turk;wordnet	Masoud Rouhizadeh;Margit Bowler;Richard Sproat;Bob Coyne	2011				NLP	-27.816587759390988	-70.56204188797825	2672
383daf83b99ea90319bf3060ba82438bea83de3c	agents of diffusion - insights from a survey of facebook users	viral channel;internet business;empirical evidence;business model;web 2.0;electronic marketing;facebook users;viral distribution;facebook;marketing data processing;internet;facebook user;online marketing;convincing user;electronic commerce;word-of-mouth marketing;social networking (online);active viral channels;active viral channel;account user interaction;survey data;communication channels;word of mouth	In times of web 2.0 and its strong focus on user interaction in business models, entrepreneurs and investors of internet businesses often back up their ambitious growth expectations with the argument of viral distribution. However, there exists little evidence on the determinants of consumers' willingness to voluntarily and actively exchange information about internet applications. Based on survey data of 475 Facebook users, this paper makes a contribution to fill this gap. Key findings are that passive (observation of other users) and active (purposeful recommendations from peers) viral channels are equally important to make users aware of a novel product. Active viral channels, however, dominate in convincing users to actually start using a product or service. We also find that users are altruistically motivated to recommend applications and predominantly use built-in invitation mechanisms in the application as a communication channel for recommendations. This paper contributes to the field of electronic marketing in two ways. First and foremost it brings forward empirical evidence on the interpersonal aspects of the mechanisms behind viral distribution and word-of-mouth marketing. Second, it presents the illustrative case of Facebook which has become a fore-runner in online marketing when it comes to taking into account user interaction and behavior.	backup;blade runner;canonical account;channel (communications);foremost;human–computer interaction;online advertising;web 2.0	Rebecca Ermecke;Philip Mayrhofer;Stefan Wagner	2009	2009 42nd Hawaii International Conference on System Sciences	10.1109/HICSS.2009.564	public relations;business model;word of mouth;empirical evidence;marketing;survey data collection;viral marketing;sociology of the internet;advertising;management;world wide web;channel	Metrics	-86.25853187450795	-13.514997918370746	2675
374770f80649f8b7d7410af12ac00fa7c027cf54	cloud service placement via subgraph matching	lead memory management;memory management;search problems cloud computing graph theory pattern matching query processing;revised pruning algorithm cloud service placement subgraph matching storage network connectivity cloud administration data center networks node labels edge labels cpu cycles network bandwidth network topology graph indexing techniques frequent label updates numeric labels gradin multidimensional vectors query subgraphs index parameters update performance search performance;lead	Fast service placement, finding a set of nodes with enough free capacity of computation, storage, and network connectivity, is a routine task in daily cloud administration. In this work, we formulate this as a subgraph matching problem. Different from the traditional setting, including approximate and probabilistic graphs, subgraph matching on data-center networks has two unique properties. (1) Node/edge labels representing vacant CPU cycles and network bandwidth change rapidly, while the network topology varies little. (2) There is a partial order on node/edge labels. Basically, one needs to place service in nodes with enough free capacity. Existing graph indexing techniques have not considered very frequent label updates, and none of them supports partial order on numeric labels. Therefore, we resort to a new graph index framework, Gradin, to address both challenges. Gradin encodes subgraphs into multi-dimensional vectors and organizes them with indices such that it can efficiently search the matches of a query's subgraphs and combine them to form a full match. In particular, we analyze how the index parameters affect update and search performance with theoretical results. Moreover, a revised pruning algorithm is introduced to reduce unnecessary search during the combination of partial matches. Using both real and synthetic datasets, we demonstrate that Gradin outperforms the baseline approaches up to 10 times.	approximation algorithm;baseline (configuration management);central processing unit;cloud computing;computation;data center;database;fingerprint;line number;network topology;numerical analysis;prune and search;subgraph isomorphism problem;synthetic intelligence	Bo Zong;Ramya Raghavendra;Mudhakar Srivatsa;Xifeng Yan;Ambuj K. Singh;Kang-Won Lee	2014	2014 IEEE 30th International Conference on Data Engineering	10.1109/ICDE.2014.6816704	lead;computer science;theoretical computer science;operating system;data mining;database;distributed computing;memory management	DB	-25.657639786746717	-0.7674333801817514	2678
ac264b3c26ef6efb8aaa13b133b1ccef66b04976	leveraging discourse information effectively for authorship attribution		We explore techniques to maximize the effectiveness of discourse information in the task of authorship attribution. We present a novel method to embed discourse features in a Convolutional Neural Network text classifier, which achieves a state-ofthe-art result by a significant margin. We empirically investigate several featurization methods to understand the conditions under which discourse features contribute non-trivial performance gains, and analyze discourse embeddings.1	bigram;convolutional neural network;display resolution;domain of discourse;intel matrix raid;parser combinator;stylometry;tree structure	Su Wang;Elisa Ferracane;Raymond J. Mooney	2017			convolutional neural network;natural language processing;computer science;artificial intelligence;classifier (linguistics);attribution	NLP	-19.47481225518845	-72.37209361594297	2682
4dc29997e228e6ebe0fef78ce1396c3dc1564319	the incompleteness of dispositional predicates	science philosophy;context dependent;philosophie des sciences	Elizabeth Prior claims that dispositional predicates are incomplete in the sense that they have more than one argument place. To back up this claim, she offers a number of arguments that involve such ordinary dispositional predicates as ‘fragile’, ‘soluble’, and so on. In this paper, I will first demonstrate that one of Prior’s arguments that ‘is fragile’ is an incomplete predicate is mistaken. This, however, does not immediately mean that Prior is wrong that ‘fragile’ is an incomplete predicate. On the contrary, I maintain that she has offered another valid argument that does indeed establish the claim that ‘fragile’ is an incomplete predicate. I will argue further that Prior is right that ‘soluble’ is an incomplete predicate. Then does this mean that all dispositional predicates are incomplete? I don’t think so. I will suggest that there are complete dispositional predicates that have no more than one argument place. Finally, by relying on my discussion of the incompleteness of dispositional predicates, I will attempt to provide a better understanding of the context-dependence and intrinsic nature of dispositional ascriptions.	backup;monadic predicate calculus;predicate (mathematical logic);syntactic predicate	Sungho Choi	2007	Synthese	10.1007/s11229-007-9195-4	epistemology;context-dependent memory;algorithm	OS	-13.689631327736587	3.8847273791463435	2684
366a10597eac506b45f1d2f153dc3777736e7234	from problems to protocols: towards a negotiation handbook	negotiation repository;scenario metrics;testbed framework;scenario generation;automated negotiation	Automated negotiation protocols represent a potentially powerful tool for problem solving in decision support systems involving participants with conflicting interests. However, the effectiveness of negotiation approaches depends greatly on the negotiation problem under consideration. Since there is no one negotiation protocol that clearly outperforms all others in all scenarios, we need to be able to decide which protocol is most suited for each particular problem. The goal of our work is to meet this challenge by defining a “negotiation handbook”, that is, a collection of design rules which allow us, given a particular negotiation problem, to choose the most appropriate protocol to address it. This paper describes our progress towards this goal, including a tool for generating a wide range of negotiation scenarios, a set of high-level metrics for characterizing how negotiation scenarios differ, a testbed environment for evaluating protocol performance with different scenarios, and a community repository which allows us to systematically record and analyze protocol performance data.	decision support system;high- and low-level;problem solving;testbed	Ivan Marsá-Maestre;Mark Klein;Catholijn M. Jonker;Reyhan Aydogan	2014	Decision Support Systems	10.1016/j.dss.2013.05.019	computer science;knowledge management;management science	Web+IR	-14.743616318960688	-9.608802817954823	2685
c1e6e93528dc4c703768ec710dae1ad52c01d772	agglomeration dynamics and first nature asymmetries	secs s 06 metodi mat dell economia e scienze attuariali e finanziarie;settore secs s 06 metodi matematici dell economia e delle scienze attuariali e finanziarie;settore secs s 06 metodi mat dell economia e d scienze attuariali e finanz;settore secs p 01 economia politica;articolo su rivista scientifica specializzata;border collision bifurcation;new economy geography;piecewise map;asymmetric first nature firms	The standard footloose capital (FC) model, as well as the discrete time version, assumes that all capital units are internationally mobile between two regions. In this paper, we assume that in one of the two regions some of the blueprints/capital units may be immobile because their utilization requires some locally specific natural resource (first nature advantage). Mobile blueprints, instead, can be utilized in both regions. We focus on this asymmetric distribution of immobile firms/capital units, labeled first nature firms. The central question of our paper is how the existence of first nature asymmetry affects agglomerative processes framed in discrete time. This modification of the FC model leads to a one dimensional piecewise smooth map for which we show analytically that border collision bifurcations are pervasive and (even asymmetric) multistability is possible.		Anna Agliari;Pasquale Commendatore;Ilaria Foroni;Ingrid Kubin	2015	Mathematics and Computers in Simulation	10.1016/j.matcom.2014.05.001	mathematical optimization;discrete time and continuous time;mathematics;collision;piecewise;asymmetry;multistability;hierarchical clustering;economies of agglomeration	Metrics	-4.607072967451718	-11.165947156219467	2687
471c18589caf74f7e149fb74df314668b239ff6f	lexico-semantic pattern matching as a companion to parsing in text understanding	pattern matching	Ordinarily, one thinks of the problem of na tura l language understanding as one of making a single, left-to-right pass through an input, producing a progressively refined and detailed interpretation. In text interpretat ion, however, the constraints of strict left-to-right processing are an encumbrance. Multi-pass methods, especially by interpreting words using corpus da ta and associating uni ts of text with possible interpretations, can be more accurate and faster t han single-pass methods of data extraction. Quality improves because corpus-based da ta and global context help to control false interpretations; speed improves because processing focuses on relevant sections. The most useful forms of pre-processing for text interpretat ion use fairly superficial analysis tha t complements the style of ordinary parsing but uses much of the same knowledge base. Lexico-semantic pa t t e rn matching, with rules tha t combine lexlocal analysis with ordering and semantic categories, is a good method for this form of analysis. This type of pre-processing is efficient, takes advantage of corpus data, prevents many garden paths and fruitless parses, and helps the parser cope with the complexity and flexibility of real text. I N T R O D U C T I O N The interpretat ion of large volumes of text poses many control problems, including limiting the complexity of analysis and ensuring the product ion of valid interpretat ions without considering too many possibifities. These problems are especially severe in processing news stories, where long sentences, information-rich news-style constructions, and the complex structure of events make normal syntax-first analysis especially impractical. Normal left-to-right syntactic parsing, in virtually all its forms, is a disaster for interpret ing broad classes of extended texts. Multiple-path methods are haunted by a t tachment problems tha t can lead to a combinatoric explosion of paths, while simple deterministic methods bring on parser failures and problems in combining preferences. In previous work aimed at word sense coding of news stories [1], we have found tha t even heavy pruning of a mult iple-path chart parsing strategy often leaves hundreds of parses to consider for a single sentence. Even worse, minor irregularities in linguistic s t ructure or word usage bring on parser failures and inadequate interpretations. Better parsing strategies, including control using statistical data, flexible part ial parsing, and recovery, can certainly help with some of these problems, bu t some of the easiest improvements in the control of parsing come from the creative use of pre-processing. Our system incorporates a lexico-semantic pattern mateher, which uses much of the same knowledge base as the parser and semantic interpreter but performs a global, superficial analysis of text prior to parsing. The design and implementat ion of the pa t te rn matcher is simple; instead of concentrating on its details, this paper focuses on the functionality of pre-processing and its impact on parser control. Three aspects of pre-processing have particular promise for the quality and efficiency of later processing--tagging, template aciiva~ion (including topic analysis), and segmentation (or bracketing). Tagging uses lexical da ta to constrain the par t of speech and word senses of impor tan t words, template activation determines a set of possible templates, or frames, and segmentation associates portions of text with templates or template fillers. These techniques help the language analyzer to cope with the complexity of real text, bo th by reducing the combinatorics of parsing and by constraining word senses and a t tachment decisions. The following is a sample text taken from the development corpus of the MUC-3 message understanding evaluation 1, with the results of pre-processing after segmentation: Original text: SIX P E O P L E WERE KILLED AND FIVE WOUNDED TODAY IN A BOMB ATTACK THAT DESTROYED A PEASANT HOME IN THE TOWN OF QUINCHIA, ABOUT 300 KM WEST OF BOGOTA, IN THE COFFEE-GROWING DEPARTMENT OF RISARALDA, QUINCHIA MAYOR SAUL BOTERO HAS REPORTED. (41 words) Segmented text: [SiX PEOPLE] [h: WERE KILLED] AND FIVE [A: WOUNDED] [TIME: TODAY] IN [A: A BOMB ATTACK] THAT [h: DESTROYED] [ i PEASANT HOME] [LOCATION: IN THE TOWN OF QUINCHIA] [DISTANCE: *COMMA* ABOUT 300 KM WEST OF BOGOTA] [LOCATION: *COMMA* IN THE 1MUC-3, the third government-sponsored message understanding evaluation, is in progress. Later in this paper, we will discuss the task and performance on the task.	call of duty: black ops;chart parser;han unification;knowledge base;lexico;natural language understanding;numerical aperture;os-tan;parsing;pattern matching;preprocessor;semantic interpretation;text corpus;the superficial;word sense	Paul S. Jacobs;George R. Krupka;Lisa F. Rau	1991			speech recognition;computer science;bottom-up parsing;pattern matching;pattern recognition;programming language	NLP	-27.170253356076017	-79.88685043663	2694
db7970ba38ae0e858d246483335aa5008db65119	continual htn robot task planning in open-ended domains: a case study		The fact that many AI planning approaches are still based on too simplifying assumptions makes it often hard to apply these approaches to real-world robotics. In particular, it is in many cases difficult to generate a complete plan in advance, because not all information is available at the beginning of the planning process. We briefly present the continual planning system ACogPlan and a preliminary test case that demonstrates how the planning system can enable mobile robots to continually plan and execute activities in an open-ended domain. Introduction High-level reasoning and task planning are essential if we want to enable robots to autonomously perform high-level tasks (e.g., “Bring me a cup of coffee”). Planning algorithms have been developed that in principle are efficient enough to solve complex planning problems in real time. However, many AI planning approaches are still based on too simplifying assumptions. Therefore, it is in many cases hard to apply these approaches to real-world robotics. In particular, the fact that in real-world scenarios often not all necessary information is available at the beginning of the planning process makes it difficult to a priori generate a complete plan—as necessary in the most AI planning approaches. Most of the previous approaches that are able to generate plans in partially known environments generate conditional plans—or policies—for all possible contingencies. Unfortunately, planning approaches that generate conditional plans are computationally hard, scale badly in dynamic unstructured domains and are only applicable if it is possible to foresee all possible outcomes of a knowledge acquisition process (Ghallab, Nau, and Traverso 2004; Brenner and Nebel 2009). Mobile robots can usually acquire additional information from a multitude of sources. Thus, we believe that continual planning (Brenner and Nebel 2009) is a more promising approach for mobile robots, since it enables them to interleave planning and execution such that missing information can be acquired via active information gathering. However, if we want to enable robots to autonomously acquire information by means of active information gathering, then—as Copyright c © 2011, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. already pointed out by (Nau 2007)—we have to enable them to answer the following questions: What information to look for? How to acquire the necessary information? Yet, these questions have not been sufficiently addressed by existing planning approaches (Nau 2007). We believe that this is one major reason why it is still difficult to apply AI planning to real-world robots that inhabit a partially known environment. Continual Planning in Open-Ended Domains If we want to enable robots to autonomously extend their knowledge about the environment by means of active information gathering, then the planning system needs to be able to derive which extensions of the current domain model are relevant and possible. Most planning systems are unable to do that, since their underlying domain model is based on the assumption that all information is available at the beginning of the planning process (Nau 2007). In contrast, the proposed continual planning system—called ACogPlan—is based on the open-ended domain model ACogDM (Off and Zhang 2011). ACogDM enables the planner to reason about relevant extensions of its domain model. It is particularly intended for forward search (i.e., forward decomposition) Hierarchical Task Network (HTN) planning approaches like ACogPlan. Forward decomposition HTN planners choose between a set of relevant (Ghallab, Nau, and Traverso 2004, Definition 11.4) methods (i.e., STN methods) or planning operators (i.e., actions) that can be in principle applied to the current task network. Let σ be a substitution. A relevant method or planning operator can actually be applied if and only if its precondition p holds (i.e., an instance pσ is derivable) with respect to the given domain model. Therefore, we define the set of relevant preconditions with respect to a given planning context (i.e., a domain model and a task list) to be the set of all preconditions of relevant methods or planning operators. A HTN planner cannot continue the planning process in situations where no relevant precondition is derivable with respect to the domain model at hand. The notation of a relevant precondition is a first step to determine relevant extensions of a domain model, since only domain model extensions that make the derivation of an additional instance of a relevant precondition possible constitute an additional way to continue the planning process. All other possible extensions are irrelevant, because they do not 74 Automated Action Planning for Autonomous Mobile Robots: Papers from the 2011 AAAI Workshop (WS-11-09)	algorithm;artificial intelligence;automated planning and scheduling;domain model;hierarchical task network;high- and low-level;knowledge acquisition;mobile robot;nonlinear gameplay;planner;precondition;relevance;robotics;substitution (logic);super-twisted nematic display;test case	Dominik Off;Jianwei Zhang	2011			simulation;computer science;artificial intelligence	AI	-19.74392034137374	-5.404355516590965	2698
6f74566658ebdff8789cdc280d7eb70ea31fc8b3	logic, rationality, and interaction - third international workshop, lori 2011, guangzhou, china, october 10-13, 2011. proceedings			rationality		2011		10.1007/978-3-642-24130-7	ecological rationality;principle of rationality	Vision	-54.46150369182001	-8.873317762094077	2702
779f6b078df565f60f9ed7923ae894200b93e7ca	a multi-agent system for creating art based on boids with evolutionary and neural networks		In this paper, we proposed a multi-agent system for creating art that can produce a set of abstract and complex style images given an input image. The proposed system consists of Boids, and each Boid object contains the genetic programming trees and neural networks. The role of genetic programming is to create unique color patterns, which will be embellished to the input image. And neural networks in each agent adjust its Boids properties, to perform more emergent group behavior in the progress of art creating. The results of the proposed system can show abstractly and complexly embellished images given an input image in each run.	boids;multi-agent system;neural networks	Tae Jong Choi;Jaehun Jeong;Chang Wook Ahn	2016		10.1007/978-981-10-3611-8_49	machine learning;evolutionary algorithm;genetic programming;artificial neural network;artificial intelligence;boids;computer science;multi-agent system	AI	-27.76521809272099	-24.220398072787656	2703
a8cdf966cfe65d942f7685f2805e6d614240c9e1	supporting interactive animation using multi-way constraints	3d interaction;3d animation;contributo in un libro;interactive animation;object oriented;data reduction;performance driven animation	This paper presents how the animation subsystem of an interactive environment for the visual construction of 3D animations has been modeled on top of an object-oriented constraint imperative architecture. In our architecture, there is no intrinsic diierence between user-interface and application objects. Multi-way dataaow constraints provide the necessary tight coupling among components that makes it possible to seamlessly compose animated and interactive behaviors. Indirect paths allow an effective use of the constraint model in the context of dynamic applications. The ability of the underlying constraint solver to deal with hierarchies of multi-way, multi-output dataaow constraints, together with the ability of the central state manager to handle indirect constraints are exploited to deene most of the behaviors of the modeling and animation components in a declarative way. The ease of integration between all system's components opens the door to novel interactive solution to modeling and animation problems. By recording the eeects of the user's manipulations on the models, all the expressive power of the 3D user interface is exploited when deening animations. This performance-based approach complements standard key-framing systems by providing the ability to create animations with straight-ahead actions. At the end of the recording session, animation tracks are automatically updated to integrate the new piece of animation. Animation components can be easily synchronized using constrained manipulation during playback. The system demonstrates that, although they are limited to expressing acyclic connict-free graphs, multi-way dataaow constraints are general enough to model a large variety of behaviors while remaining eecient enough to ensure the responsiveness of large interactive 3D graphics applications.	3d computer graphics;3d modeling;3d user interaction;directed acyclic graph;framing (world wide web);imperative programming;responsiveness;solver;user interface;virtual studio	Jean-Francis Balaguer;Enrico Gobbetti	1995		10.1007/978-3-7091-9457-7_4	computer vision;computer facial animation;skeletal animation;interactive skeleton-driven simulation;computer animation;multimedia;computer graphics (images)	Graphics	-41.05283599554034	-33.5140717048086	2707
670ec9c744031bd113a5752f68065920b5d66d98	proceedings of the 7th international workshop on social software engineering, sse 2015, bergamo, italy, september 1, 2015			social software engineering		2015				SE	-55.13996021746927	-2.51868332295176	2709
a38b29504040ff5a1d8d502f319283d2366c496d	teaching motion gestures via recognizer feedback	motion gestures;sensors;android;smartphone;recognizer feedback	When using motion gestures, 3D movements of a mobile phone, as an input modality, one significant challenge is how to teach end users the movement parameters necessary to successfully issue a command. Is a simple video or image depicting movement of a smartphone sufficient? Or do we need three-dimensional depictions of movement on external screens to train users? In this paper, we explore mechanisms to teach end users motion gestures, examining two factors. The first factor is how to represent motion gestures: as icons that describe movement, video that depicts movement using the smartphone screen, or a Kinect-based teaching mechanism that captures and depicts the gesture on an external display in three-dimensional space. The second factor we explore is recognizer feedback, i.e. a simple representation of the proximity of a motion gesture to the desired motion gesture based on a distance metric extracted from the recognizer. We show that, by combining video with recognizer feedback, participants master motion gestures equally quickly as end users that learn using a Kinect. These results demonstrate the viability of training end users to perform motion gestures using only the smartphone display.	feedback;finite-state machine;kinect;mobile phone;modality (human–computer interaction);smartphone;video	Ankit Kamal;Yang Li;Edward Lank	2014		10.1145/2557500.2557521	computer vision;computer science;operating system;multimedia;android	HCI	-45.53000204612064	-43.56994342083673	2711
5dc0efd880cd2dfdde6e9707a9b7b7fc8580d4d8	leadership in moving human groups	biological locomotion;human movement;communications;leadership;collective human behavior;social behavior;games;humans;behavior;computer games;communication;vision;movement	How is movement of individuals coordinated as a group? This is a fundamental question of social behaviour, encompassing phenomena such as bird flocking, fish schooling, and the innumerable activities in human groups that require people to synchronise their actions. We have developed an experimental paradigm, the HoneyComb computer-based multi-client game, to empirically investigate human movement coordination and leadership. Using economic games as a model, we set monetary incentives to motivate players on a virtual playfield to reach goals via players' movements. We asked whether (I) humans coordinate their movements when information is limited to an individual group member's observation of adjacent group member motion, (II) whether an informed group minority can lead an uninformed group majority to the minority's goal, and if so, (III) how this minority exerts its influence. We showed that in a human group--on the basis of movement alone--a minority can successfully lead a majority. Minorities lead successfully when (a) their members choose similar initial steps towards their goal field and (b) they are among the first in the whole group to make a move. Using our approach, we empirically demonstrate that the rules of swarming behaviour apply to humans. Even complex human behaviour, such as leadership and directed group movement, follow simple rules that are based on visual perception of local movement.	apply;emoticon;flocking (behavior);knowledge acquisition;money;movement;numerous;programming paradigm;rule (guideline);visual perception;physical hard work	Margarete Boos;Johannes Pritz;Simon Lange;Michael Belz	2014		10.1371/journal.pcbi.1003541	movement;biology;games;vision;simulation;leadership;social behavior;behavior	ML	-16.38052066827981	-14.639450561895615	2713
21585030fda6b2d8ce50140f5c64e25b1bf022cb	individual differences and task-based user interface evaluation: a case study of pending tasks in email	human computer interaction;email interfaces;quantitative research;individual differences;user interface;external representation;user studies;psychology;la telecommunications;journal article paginated;user interface evaluation;bi user interfaces usability;working memory;visual memory;user interface design;evaluation;individual difference;task management;external representations;cb user studies	This paper addresses issues raised by the ever-expanding role of email as a multi-faceted application that combines communication, collaboration, and task management. Individual differences analysis was used to contrast two email user interfaces in terms of their demands on users. The results of this analysis were then interpreted in terms of their implications for designing more inclusive interfaces that meet the needs of users with widely ranging abilities. The specific target of this research is the development of a new type of email message representation that makes pending tasks more visible. We describe a study that compared a new way of representing tasks in an email inbox, with a more standard representation (the Microsoft Outlook inbox). The study consisted of an experiment that examined how people with different levels of three specific cognitive capabilities (flexibility of closure, visual memory, and working memory) perform when using these representations. We then identified combinations of representation and task that are disadvantageous for people with low levels of the measured capabilities. q 2004 Elsevier B.V. All rights reserved.	email;faceted classification;inbox by gmail;microsoft outlook for mac;user interface	Jacek Gwizdka;Mark H. Chignell	2004	Interacting with Computers	10.1016/j.intcom.2004.04.008	differential psychology;user interface design;human–computer interaction;quantitative research;visual memory;computer science;evaluation;working memory;multimedia;user interface;world wide web	HCI	-55.98961255771536	-43.887360325333034	2714
be41d925fcaf059b2a44193e18e40d19f83667a9	selected papers from the eighth itu kaleidoscope academic conference		The articles in this special section were presented at the Eighth International Telecommunication Union (ITU) Kaleidoscope Academic Conference. The conference took place in Bangkok, Thailand from 14–16 November 2016, in parallel with ITU Telecom World 2016. The topic of the conference was “ICTs for a Sustainable World” and the event was technically co-sponsored by the Institute of Electrical and Electronics Engineers (IEEE) and the IEEE Communication Society.		Mostafa Hashem Sherif;Kai Jakobs;Christoph Dosch;Martin Adolph	2017	IEEE Communications Standards Magazine	10.1109/MCOMSTD.2017.8082576	kaleidoscope;engineering management;icts;library science;engineering	Visualization	-62.00361930322619	-15.185628217072521	2715
6bcaaaf38b4ae75c6a6f04f9e3884d3254b867a7	cindi at imageclef 2006: image retrieval & annotation tasks for the general photographic and medical image collections	multi modality;integrated approach;classifier combination;vector space model;fusion;annotation;matching function;image annotation;medical image;feature extraction;automatic annotation;support vector machine;query expansion;content based image retrieval;user interaction;relevance feedback;image retrieval	This paper presents our techniques used and their analysis for the runs made and the results submitted by the CINDI group for the task of the image retrieval and automatic annotation of ImageCLEF 2006. For the ah-hoc image retrieval from both the photographic and medical image collections, we have experimented with cross-modal (image and text) interaction and integration approaches based on the relevance feedback in the form of textual query expansion and visual query point movement with adaptive similarity matching functions. Experimental results show that our approaches performed well compared to initial visual or textual only retrieval without any user interactions or feedbacks. We are ranked first and second and achieved the highest MAP score (0.3850) for the ad-hoc retrieval in the photographic collection (IAPR) among all the submissions. For the automatic annotation tasks for both the medical (IRMA) and object collections (LTU), we have experimented with a classifier combination approach, where several probabilistic multi-class SVM classifiers with features at different levels as inputs are fused with several combination rules to predict the final probability score of each category as image annotation. Analysis of the results of the different runs we made for both the image retrieval and annotation tasks are reported in this paper.	automatic image annotation;history of the scheme programming language;hoc (programming language);image retrieval;interaction;international association for pattern recognition;irma board;machine learning;modal logic;query expansion;relevance feedback;supervised learning	Md. Mahmudur Rahman;Varun Sood;Bipin C. Desai;Prabir Bhattacharya	2006		10.1007/978-3-540-74999-8_90	support vector machine;computer vision;query expansion;visual word;fusion;feature extraction;image retrieval;computer science;machine learning;pattern recognition;automatic image annotation;vector space model;information retrieval	Vision	-31.224544026330225	-62.75058352137529	2722
e5cb918a0107daae38e747a7a0bbfd5adcfd6c6e	collaborative learning across space and time: ethnographic research in online affinity spaces			affinity analysis;spaces	Alecia Marie Magnifico;J. H. C. M. Lammers;Jen Scott Curwood	2013				AI	-69.27151677760475	-34.53126620170674	2724
9dc386dfb3ad63f1940902054f266dbb33a2cde0	loop optimization (dagstuhl seminar 18111)		This report documents the programme of Dagstuhl Seminar 18111 Loop Optimization. The seminar brought together experts from three areas: (1) model-based loop optimization, chiefly, in the polyhedron model, (2) rewriting and program transformation, and (3) metaprogramming and symbolic evaluation. Its aim was to review the 20+ years of progress since the Dagstuhl Seminar 9616 Loop Parallelization in 1996 and identify the challenges that remain.	loop optimization	Sebastian Hack;Paul H. J. Kelly;Christian Lengauer	2018	Dagstuhl Reports	10.4230/DagRep.8.3.39	loop optimization;theoretical computer science;polyhedron model;metaprogramming;program transformation;computer science;rewriting	EDA	-49.16914650854863	-5.3409383168125535	2731
18396d905a7fdd1c4829db3cf6a59b51a9c068bd	flora: fluent oral reading assessment of children's speech	computer program;reading tracker;fluency assessment;oral reading fluency;speech recognition;speech verification;system architecture	We present initial results of FLORA, an accessible computer program that uses speech recognition to provide an accurate measure of children's oral reading ability. FLORA presents grade-level text passages to children, who read the passages out loud, and computes the number of words correct per minute (WCPM), a standard measure of oral reading fluency. We describe the main components of the FLORA program, including the system architecture and the speech recognition subsystems. We compare results of FLORA to human scoring on 783 recordings of grade level text passages read aloud by first through fourth grade students in classroom settings. On average, FLORA WCPM scores were within 3 to 4 words of human scorers across students in different grade levels and schools.	computer program;speech recognition;systems architecture;words per minute	Daniel Bolaños;Ronald A. Cole;Wayne H. Ward;Eric Borts;Edward Svirsky	2011	TSLP	10.1145/1998384.1998390	natural language processing;speech recognition;computer science;systems architecture	NLP	-17.23219323251427	-82.18848810220786	2733
24fb4c057010169d6e422b77880b7bf7b32333a8	the architecture of prome instant question answering system	document handling;faq;search engines;similarity calculation;information retrieval;question answering information retrieval;mobile internet users prome instant question answering system automated question answering system search engines instant messenger question matching faq database tf idf algorithm term frequency inverse document frequency algorithm information extraction web pages personalized information search services;search engines knowledge discovery web pages html algorithm design and analysis data mining;information retrieval question answering system faq similarity calculation tf idf;tf idf;search engines document handling electronic messaging internet mobile computing question answering information retrieval;internet;question answering system;electronic messaging;mobile computing	An instant question answering system ProMe is proposed in this paper which sets automated question answering system as prototype and combines with the search engines and instant messenger. For any question queried by a user, ProMe looks for the answers in the flow of three methods. The first one is to match questions in FAQ database with TF-IDF (Term Frequency-Inverse Document Frequency) algorithm. If still not found, submit it to some search engines and get the answers by extracting information from the web pages returned by the search engine. If the answer is not found or not satisfied after evaluation, it will be sent to other users who are probably interested in it through instant messengers, and get the final answers. Experimental results show that ProMe greatly improves the effectiveness of the automated question answering systems. It can be applied for information searching to provide real-time and personalized information search services for mobile Internet users.	algorithm;http 404;instant messaging;personalization;prototype;question answering;real-time locating system;tf–idf;web page;web search engine	Guangzhi Zhang;Tao Jiang;Rongfang Bie;Xiaochun Liu;Zhichun Wang;Junyang Rao	2013	2013 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery	10.1109/CyberC.2013.46	the internet;question answering;computer science;data mining;database;mobile computing;tf–idf;world wide web;information retrieval;search engine	Web+IR	-29.901768775096812	-52.71602014534231	2735
c92bde4843cd3503f4e235f0ca20f18df51638cc	issues and challenges in annotating urdu action verbs on the imagact4all platform				Sharmin Muzaffar;Pitambar Behera;Girish Nath Jha	2016			artificial intelligence;natural language processing;speech recognition;urdu;computer science	NLP	-30.2838202522698	-77.10530132356125	2737
96a0cef0c924e1e3e9b8ffacde8f002956c8f592	construction of an annotated corpus to support biomedical information extraction	corpus annotation;vocabulary controlled;information extraction;text mining;gene regulation;environmental conditions;computational biology bioinformatics;text corpus;semantic role;algorithms;databases factual;event frame;combinatorial libraries;computational biology;computer appl in life sciences;information storage and retrieval;natural language processing;microarrays;bioinformatics;knowledge discovery	Information Extraction (IE) is a component of text mining that facilitates knowledge discovery by automatically locating instances of interesting biomedical events from huge document collections. As events are usually centred on verbs and nominalised verbs, understanding the syntactic and semantic behaviour of these words is highly important. Corpora annotated with information concerning this behaviour can constitute a valuable resource in the training of IE components and resources. We have defined a new scheme for annotating sentence-bound gene regulation events, centred on both verbs and nominalised verbs. For each event instance, all participants (arguments) in the same sentence are identified and assigned a semantic role from a rich set of 13 roles tailored to biomedical research articles, together with a biological concept type linked to the Gene Regulation Ontology. To our knowledge, our scheme is unique within the biomedical field in terms of the range of event arguments identified. Using the scheme, we have created the Gene Regulation Event Corpus (GREC), consisting of 240 MEDLINE abstracts, in which events relating to gene regulation and expression have been annotated by biologists. A novel method of evaluating various different facets of the annotation task showed that average inter-annotator agreement rates fall within the range of 66% - 90%. The GREC is a unique resource within the biomedical field, in that it annotates not only core relationships between entities, but also a range of other important details about these relationships, e.g., location, temporal, manner and environmental conditions. As such, it is specifically designed to support bio-specific tool and resource development. It has already been used to acquire semantic frames for inclusion within the BioLexicon (a lexical, terminological resource to aid biomedical text mining). Initial experiments have also shown that the corpus may viably be used to train IE components, such as semantic role labellers. The corpus and annotation guidelines are freely available for academic purposes.	abstract summary;biomedical research;biomedical text mining;body of uterus;british informatics olympiad;collections (publication);entity;experiment;frame (physical object);frame language;gene expression regulation;gene ontology;information extraction;inter-rater reliability;medline;personnameuse - assigned;text corpus	Paul Thompson;Syed A. Iqbal;John McNaught;Sophia Ananiadou	2009	BMC Bioinformatics	10.1186/1471-2105-10-349	natural language processing;text mining;regulation of gene expression;dna microarray;computer science;bioinformatics;data mining;text corpus;information extraction;information retrieval	NLP	-35.01652205664541	-69.77396231885818	2738
1906a324d51e286246328ae064215cb7fa9e5498	talk to me: the influence of audio quality on the perception of social presence	mono;speech;emotional understanding;dialogue;stereo;presence;binaural;social presence;spatial	In this paper, we compare the impact of monophonic, stereophonic, and binaural human speech recordings in terms of their ability to induce the feeling of presence and influence the understanding of the emotional state the speakers were in. These factors are generally important in entertainment applications, for example when conversing with a non-player character or in mediated synchronous human-to-human communication. Our results show a significant advantage of binaural over mono and stereo sound for inducing the sense of being present in an (virtual) environment. Furthermore, we found that listening to a stereophonic recording of a conversation leads to a significantly stronger understanding of the emotional state of speakers than listening to a mono or binaural recording.	binaural beats;social presence theory	Christina Dicke;Viljakaisa Aaltonen;Anssi Rämö;Miikka Vilermo	2010			psychology;speech recognition;acoustics;communication	HCI	-9.047081969203278	-82.33382001023182	2745
c9d5a1dffd509093454a905e2db9e39fbc6ded53	rough sets: some extensions	rough set	In this article, we present some extensions of the rough set approach and we outline a challenge for the rough set based research.	andrzej grzegorczyk;approximation algorithm;incisive;intelligent agent;mereology;rough set;zak mckracken and the alien mindbenders	Zdzislaw Pawlak;Andrzej Skowron	2007	Inf. Sci.	10.1016/j.ins.2006.06.006	rough set;computer science;machine learning;dominance-based rough set approach	AI	-27.741724488655535	-8.17498406189037	2752
ed5b7ef396fbc0d14a2fecd6f7d863628dc402e1	machine learning for the geosciences: challenges and opportunities		Geosciences is a field of great societal relevance that requires solutions to several urgent problems facing our humanity and the planet. As geosciences enters the era of big data, machine learning (ML)— that has been widely successful in commercial domains—offers immense potential to contribute to problems in geosciences. However, problems in geosciences have several unique challenges that are seldom found in traditional applications, requiring novel problem formulations and methodologies in machine learning. This article introduces researchers in the machine learning (ML) community to these challenges offered by geoscience problems and the opportunities that exist for advancing both machine learning and geosciences. We first highlight typical sources of geoscience data and describe their properties that make it challenging to use traditional machine learning techniques. We then describe some of the common categories of geoscience problems where machine learning can play a role, and discuss some of the existing efforts and promising directions for methodological development in machine learning. We conclude by discussing some of the emerging research themes in machine learning that are applicable across all problems in the geosciences, and the importance of a deep collaboration between machine learning and geosciences for synergistic advancements in both disciplines.		Anuj Karpatne;Imme Ebert-Uphoff;Sai Ravela;Hassan Ali Babaie;Vipin Kumar	2017	CoRR		computer science;data mining;data science;machine learning;artificial intelligence;big data;data modeling	ML	-36.98567672850457	-7.986734723390097	2756
e7a86c31a37a2da1f97c4704cec4c4e16a1ea36f	21st century electronica: mir techniques for classification and performance.	relational data;music genre classification;user interface;real time;col	The performance of electronica by Disc Jockys (DJs) presents a unique opportunity to develop interactions between performer and music. Through recent research in the MIR field, new tools for expanding DJ performance are emerging. The use of spectral, loudness, and temporal descriptors for the classification of electronica is explored. Our research also introduces the use of a multitouch interface to drive a performance-oriented DJ application utilizing the feature set. Furthermore, we present that a multi-touch surface provides an extensible and collaborative interface for browsing and manipulating MIRrelated data in real time.	interaction;multi-touch	Dimitri Diakopoulos;Owen Vallis;Jordan Hochenbaum;Jim W. Murphy;Ajay Kapur	2009			speech recognition;relational database;computer science;multimedia;user interface;world wide web	HCI	-46.172994050560135	-33.207517939272414	2760
2cd50aaaa025e0092f20e52202393737a57cba4e	two-way recommendation methods for social networks	two way recommendation;co clustering;social networks;online dating networks;recommendation methods	In this work, we present the challenges associated with the two-way recommendation methods in social networks and the solutions. We discuss them from the perspective of community-type social networks such as online dating networks.	social network	Richi Nayak	2014		10.1145/2663714.2668054	public relations;political science;data mining;internet privacy	AI	-83.44661190972298	-14.549627745168202	2769
a86a8d68c301a891d4a965e800481c8e70a439c5	the web is watching you: a comprehensive review of web-tracking techniques and countermeasures			countermeasure (computer);world wide web	Iskander Sánchez-Rola;Xabier Ugarte-Pedrero;Igor Santos;Pablo García Bringas	2017	Logic Journal of the IGPL	10.1093/jigpal/jzw041	multimedia	Security	-66.17050130618422	-8.102442653667731	2772
60df960438b5c20843f175ed884530537cf8173d	reliable pitch marking of affective speech at peaks or valleys using restricted dynamic programming	databases;speech algorithm design and analysis databases dynamic programming labeling proposals heuristic algorithms;dynamic programming;anotacion;variabilidad;text to speech synthesis;cabeza;interfase usuario;programacion dinamica;confiance;human computer interaction;metodologia;multimedia;unit selection;speech synthesis;user interface;expressed emotion;dynamic programming algorithm;acoustics;localization;speech processing;canal transmision;speech analysis;tratamiento palabra;traitement parole;unit selection text to speech synthesis affective speech dynamic programming pitch marking speech analysis;speech;text to speech synthesizer;annotation;dynamic program;localizacion;trustworthy speech labeling reliable pitch marking affective speech restricted dynamic programming algorithm affective communication channel multimodal human computer interaction text to speech synthesizer us tts systems neutral speech;reliable pitch marking;methodologie;marqueur;pitch marking;man machine system;multimodal human computer interaction;speech synthesis dynamic programming human computer interaction;confidence;us tts systems;marcador;localisation;texto hacia palabra;emotion emotionality;confianza;canal transmission;transmission channel;unit selection text to speech synthesis;heuristic algorithms;programmation dynamique;restricted dynamic programming algorithm;text to speech;affective speech;sistema hombre maquina;talking head;emotion emotivite;interface utilisateur;synthetiseur;sintesis palabra;head;texte a parole;emocion emotividad;marker;tete;variability;methodology;communication channels;sintetizador;variabilite;proposals;trustworthy speech labeling;acoustique;affective communication channel;neutral speech;algorithm design and analysis;synthese parole;labeling;acustica;synthesizer;systeme homme machine	The affective communication channel plays a key role in multimodal human-computer interaction. In this context, the generation of realistic talking-heads expressing emotions both in appearance and speech is of great interest. The synthetic speech of talking-heads is generally obtained from a text-to-speech (TTS) synthesizer. One of the dominant techniques for achieving high-quality synthetic speech is unit-selection TTS (US-TTS) synthesis. Affective US-TTS systems are driven by affective annotated speech databases. Since affective speech involves higher acoustic variability than neutral speech, achieving trustworthy speech labeling is a more challenging task. To that effect, this paper introduces a methodology for achieving reliable pitch marking on affective speech. The proposal adjusts the pitch marks at the signal peaks or valleys after applying a three-stage restricted dynamic programming algorithm. The methodology can be applied as a post-processing of any pitch determination and pitch marking algorithm (with any local criterion for locating pitch marks), or their merging. The experiments show that the proposed methodology significantly improves the results of the input state-of-the-art markers on affective speech.	dynamic programming;item unique identification	Francesc Alías;Natalia Munné	2010	IEEE Trans. Multimedia	10.1109/TMM.2010.2051873	voice activity detection;natural language processing;speech recognition;telecommunications;computer science;dynamic programming;speech processing;speech synthesis	Vision	-23.105530571266836	-86.6381784916121	2786
ea09e3d8994eb3b12db3518f489111a3fc6f2c16	proceedings of the 7th annual acm symposium on theory of computing, may 5-7, 1975, albuquerque, new mexico, usa			symposium on theory of computing		1975				Theory	-52.96587535692667	-7.1428949772669865	2789
a03ca57919afb6be9c2808f48b167dcd9b112b7f	query-friendly compression of graph streams	social network services;frequency estimation;pattern matching;transportation;blogs;time frequency analysis;real time systems	We study the problem of synopsis construction of massive graph streams arriving in real-time. Many graphs such as those formed by the activity on social networks, communication networks, and telephone networks are defined dynamically as rapid edge streams on a massive domain of nodes. In these rapid and massive graph streams, it is often not possible to estimate the frequency of individual items (e.g., edges, nodes) with complete accuracy. Nevertheless, sketch-based stream summaries such as Count-Min can preserve frequency information of high-frequency items with a reasonable accuracy. However, these sketch summaries lose the underlying graph structure unless one keeps information about start and end nodes of all edges, which is prohibitively expensive. For example, the existing methods can identify the high-frequency nodes and edges, but they are unable to answer more complex structural queries such as reachability defined by high-frequency edges. To this end, we design a 3-dimensional sketch, gMatrix that summarizes massive graph streams in real-time, while also retaining information about the structural behavior of the underlying graph dataset. We demonstrate how gMatrix, coupled with a onetime reverse hash mapping, is able to estimate important structural properties, e.g., reachability over high frequency edges in an online manner and with theoretical performance guarantees. Our experimental results using large-scale graph streams attest that gMatrix is capable of answering both frequency-based and structural queries with high accuracy and efficiency.	approximation algorithm;directed graph;hash function;identifier;reachability;real-time clock;real-time transcription;social network;telecommunications network;video synopsis;vii	Arijit Khan;Charu C. Aggarwal	2016	2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)	10.1109/ASONAM.2016.7752224	transport;combinatorics;feedback arc set;time–frequency analysis;computer science;theoretical computer science;force-directed graph drawing;machine learning;pattern matching;data mining;spatial network;distributed computing;random geometric graph;world wide web;graph database	DB	-10.778062860504152	-39.342201493527334	2794
3994f1908ec4198400b0fb9dee1e1fc6dcd5df3a	study on contexts in tracking usage and attention metadata in multilingual technology enhanced learning	multilingual;technology enhanced learning;attention metadata;lecture notes in informatics;working paper;context	Vuorikari, R., & Berendt, B. (2009). Study on contexts in tracking usage and attention metadata in multilingual Technology Enhanced Learning. In S. Fischer, E. Maehle & R. Reischuk (Eds.), Im Focus das Leben, Lecture Notes in Informatics (LNI) (Vol. 154, pp. 181, 1654-1663). Informatik 2009, Lubeck, Germany: Gesellschaft fur Informatik.		Riina Vuorikari;Bettina Berendt	2009			natural language processing;computer science;multimedia;information retrieval	HCI	-61.21270208640498	-13.373018036794672	2806
45500eaf664af2513e05dcce0196342205aa16aa	paper interface design for classroom orchestration	scattered interface;tangible user interface tui;paper;geometry;tangible user interface;tangible interface;interface design;paper interface;tangibles;augmented reality;scattered interfaces;classroom orchestration;geometry teaching	Designing computer systems for educational purpose is a difficult task. While many of them have been developed in the past, their use in classrooms is still scarce. We make the hypothesis that this is because those systems take into account the needs of individuals and groups, but ignore the requirements inherent in their use in a classroom. In this work, we present a computer system based on a paper and tangible interface that can be used at all three levels of interaction: individual, group, and classroom. We describe the current state of the interface design and why it is appropriate for classroom orchestration, both theoretically and through two examples for teaching geometry.	computer;requirement;tangible user interface	Sébastien Cuendet;Quentin Bonnard;Frédéric Kaplan;Pierre Dillenbourg	2011		10.1145/1979742.1979904	augmented reality;simulation;human–computer interaction;computer science;interface design;multimedia;natural user interface;user interface	HCI	-68.5035218493777	-42.07244175618386	2807
dc52dfa205ae3279d237388ca09d408a08df79be	feature extraction and classification of textile images: towards a design information system for the textile industry.	feature extraction;information system;textile industry	In the textile industry, it is common practice to use designs that have been stored from earlier days as a reference for new designs. These companies often have thousands of historic samples stored in company storerooms, or museums. To use these resources, we introduce an Information System for Design Patterns (ISDP). It is a data management system that contains data generated by the analysis of graphical design patterns obtained from old textile samples. This paper describes the proposed framework for obtaining the structure of a textile design. Firstly, we propose a sequence of operations for analyzing textile images. Then we describe the methodology used in each stage, devoting special attention to the techniques used in the image segmentation, object extraction, and clustering stages. The way objects are organized in the 2D plane to form the textile design is described with the fundamental parallelogram. Finally, we classify the whole design through the plane symmetry group attribute.	feature extraction;information system	José Miguel Valiente;Francisco Albert;José María Gomis	2002			textile industry;feature extraction;computer science;machine learning;information system	Robotics	-25.52701231534944	-32.513543688801235	2811
2b96370729af7e2c3e8a2118181f36321ee11455	discussion: the pros and cons of a special ir language: comments		The following popers were presented at an open technical meeting* held by the ACM Computer Language Committee on Information Retrieval on October 20-21, 1961 at the RCA David Sarnoff Research Laboratory, Princeton, New Jersey. This meeting was one in the series of ACM Special Interest Symposia, sponsored by a special interest group, limited to a special interest field, and approved by the ACM Program Committee. Several of the papers presented and some of the introductory comments offered for discussion were published prior to the meeting, in the September 1961 issue of the Communications.	comment (computer programming);computer language;information retrieval	H. G. Bohnert	1962	Commun. ACM	10.1145/366243.366299	algorithm	Graphics	-60.53507993943273	-17.04100822660614	2817
6f5794389ba369f649de663cd08bc1c0d4a392d7	probabilistic logic encoding of spatial domains		This paper presents a formalisation of a spatial domain in terms of a qualitative spatial reasoning formalism, encoded in a probabilistic description logic. The QSR formalism chosen is a subset of a cardinal direction calculus and the probabilistic description logic used has the relational structures of the wellknown ALC language, allied with the inference methods of Bayesian Networks. We consider a scenario consisting of a road navigated by an experimental vehicle equipped with three on-board sensors: a digital map, a GPS and a video camera. This paper presents experiments where the proposed formalism is used to answer queries about driving directions, lanes and vehicles.	bayesian network;description logic;endeavour (supercomputer);experiment;fabio paternò;formal system;global positioning system;on-board data handling;reasoning system;semantics (computer science);sensor;spatial–temporal reasoning;undecidable problem	Paulo E. Santos;Fábio Gagliardi Cozman;Valquiria Fenelon;Britta Hummel	2010			spatial intelligence;machine learning;description logic;inference;probabilistic logic;assisted gps;artificial intelligence;formalism (philosophy);computer science;bayesian network;video camera	AI	-26.695587138748575	-7.492422543773757	2818
89e1954ec45541a5f23e9b510a90510aaf1b9130	the escalating cost of college	costs educational institutions;academic quality college tuition cost control higher education;higher education college tuition college administration salaries college athletics costs college faculty costs;college administration salaries;college athletics costs;higher education;college faculty costs;college tuition;educational administrative data processing;further education;further education educational administrative data processing	Controlling skyrocketing college tuition costs will require parents, students, and other stakeholders in higher education to recognize that maintaining academic quality means accepting trade-offs in nonessential aspects of the college experience.		Ann E. Kelley Sobel	2013	Computer	10.1109/MC.2013.438	further education;higher education	HCI	-77.75708663322102	-31.592611643288855	2820
aacf4820b870ae1e0a8c9a2c2b61ced7ed0266af	managing knowledge development in the network economy: methodological contributions	network economy;methodological contributions;knowledge development	The business conditions associated with the network economy have implied difficult challenges related to organizational and inter-organizational knowledge development. This paper delineates problem areas in this context and outlines a model of knowledge development intended to serve as a methodological contribution to knowledge management. The model is defined in relation to a conceptual framework that compiles elements from evolutionary epistemology, the concept of tacit knowing, theories of systemic thinking, and decision making. The usefulness of the result is discussed in relation to the described problem areas.		Håkan Sterner	2001			knowledge economy;knowledge management;environmental resource management;political science;management science	Vision	-78.30841799913372	-2.1060855796995925	2822
99d2a0cb75e0c086892d8695940d54aaf1e01817	the establishment of a pilot telemedical information society	new technology;telemedicine;spectrum;information soceiety;standardisation;medical information system;information society;world wide web;member states;business planning;work practice;health care	National and international telecommunication infrastructures have been set up through Europe to facilitate the movement of information. One major benefactor of the improved communication infrastructures is the health care community. The accessibility and interoperability of medical information systems is one of the grand challenges for the 21st century. Within Europe current developments in the application of telemedicine are being defined in separate initiatives. There are a number of pilot actions concentrating on various aspects of telemedicine. These actions involving the introduction of new technology or working practices rarely fail for technology related problems. However, in order to fully assess the likely take-up of telemedical technologies it is vital that all the aspects including non-technical are also addressed.#R##N##R##N#This paper describes how a complete pilot telemedical information society will be set up which facilitates to support secure and standardised remote diagnosis, teleconsultations and advanced medical facilities in a number of sectors covering a crucial spectrum of those required to support a complete telemedical information society. This pilot testbed will then be assessed in the context of a European environment identifying a business plan for its extension to other member states therefore promoting a truly international telemedical information society for the 21st century.		Andy Marsh	1999	Future Generation Comp. Syst.	10.1016/S0167-739X(98)00059-4	spectrum;simulation;computer science;management science;computer security;standardization;health care	Arch	-56.462655197932705	-61.61714030182824	2823
9751ea1f101fd189e3e0ac082075c61efaeff5de	use of online social networking services from a theoretical perspective of the motivation-participation-performance framework	sns;online social networking services;performance;online wait wait management progress bar attentional gate model temporal information distractor perceived waiting time uncertainty attention distortion;motivation;participation			Mohammad Salehan;Dan Jong Kim;Changsu Kim	2017	J. AIS	10.17705/1jais.00449	psychology;simulation;motivation;performance;knowledge management;social psychology;online participation	Metrics	-55.360944272042154	-49.25541366014178	2824
e1a5454834e7997a9b982fa877aecf06148e551b	comparison of the methods of self-organizing maps and multidimensional scaling in analysis of estonian emotion concepts		Self-organizing map (SOM) and multidimensional scaling (MDS) are the methods of data analysis that reduce dimensionality of the input data and visualize the structure of multidimensional data by means of projection. Both methods are widely used in different research areas. In the studies of emotion vocabulary and other psycho-lexical surveys the MDS has been prevalent. In this paper both of the methods are introduced and as an illustration they are applied to a case study of Estonian emotion concepts. There is a need to introduce some new methods to the field because exploiting only one analytical tool may tend to reveal only specific properties of data and thus have an unwanted impact on the results.	exploit (computer security);image scaling;multidimensional scaling;organizing (structure);self-organizing map;vocabulary	Toomas Kirt;Ene Vainik	2007			computer science;data science;data mining;communication	AI	-26.25094426785821	-35.282368438252334	2828
3ef93a7ab3e1c57ebe80af134ac222371c6f6de8	a sat-based approach to learn explainable decision sets		The successes of machine learning in recent years have triggered a fast growing range of applications. In important settings, including safety critical applications and when transparency of decisions is paramount, accurate predictions do not suffice; one expects the machine learning model to also explain the predictions made, in forms understandable by human decision makers. Recent work proposed explainable models based on decision sets which can be viewed as unordered sets of rules, respecting some sort of rule non-overlap constraint. This paper investigates existing solutions for computing decision sets and identifies a number of drawbacks, related with rule overlap and succinctness of explanations, the accuracy of achieved results, but also the efficiency of proposed approaches. To address these drawbacks, the paper develops novel SAT-based solutions for learning decision sets. Experimental results on computing decision sets for representative datasets demonstrate that SAT enables solutions that are not only the most efficient, but also offer stronger guarantees in terms of rule non-overlap.		Alexey Ignatiev;Filipe Pereira;Nina Narodytska;Joao Marques-Silva	2018		10.1007/978-3-319-94205-6_41	computer science;discrete mathematics;sort;succinctness;machine learning;transparency (graphic);artificial intelligence	AI	-4.599091812896827	-29.960735908977767	2831
98fbe1c49174b03d6244cfdd48619d8d5c05591e	cea list's participation to visual concept detection task of imageclef 2011		This paper describes the CEA LIST participation in the ImageCLEF 2011 Photo Annotation challenge. This year, our motivation was to investigate the annotation performance by using provided Flickr-tags as additionnal information. First, we present an overview of our local and global visual features used in this work. Second, we present a new method, that we call ”Fuzzy-tfidf”, which takes into account the uncertainty of user tags. Our textual descriptor is based on semantic similarity between tags and visual concepts. To compute this similarity, we used two distances: the first one is based on Wordnet ontology and the second is based on social networks. We perform a late fusion to combine scores from visual and textual modalities. Our best model, a late fusion trained on global visual features and user tags, obtains 38.3 % MAP, almost a 8 % MAP absolute improvement compared to our best visual-only system. The results show that the combination of Flickr-tags with visual features improves the results of the run using only visual features. It corroborates the importance of taking into account the uncertainty of user tags and the complementarity between visual and textual modalities.	complementarity theory;flickr;fuzzy concept;semantic similarity;social network;tf–idf;wordnet	Amel Znaidia;Hervé Le Borgne;Adrian Popescu	2011			computer vision;computer science;data mining;information retrieval	Vision	-26.065186968684692	-60.58194985909127	2833
fb61d870e595fede569b6de64a39d80547f31342	a scalable framework for creating open government data services from open government data catalog		Open government data (OGD) is a global initiative to promote transparency, service innovation and citizen participation. The most common means for publishing OGD is usually in forms of datasets made available on OGD catalogs. Although publishing open data as datasets is straightforward and requires minimal technological skills, it is not ideal for the users who want to use the data in a more dynamic fashion. This paper proposes a scalable framework for creating OGD services from OGD catalog. Our framework emphasizes the need to convert existing OGD datasets to RDF data and value-added services that provides more convenient access to the users. Data querying APIs are among the OGD services to promote application development from the OGD datasets. Our framework is unique in that it does not require additional user intervention in the dataset publishing process and hides the complexity of the linked data technology from the data publishers and users. In this framework, the datasets listed in the OGD catalog were collected and validated for its well-formedness of the tabular data. The service building system converted the data to the RDF format and utilized SPARQL query templates in building the OGD services for each dataset. The framework was applied with the datasets on Data.go.th. The results on overall successful conversion rate of the datasets into the OGD services are reported. The case study exemplifies a scalable approach to augmenting access to OGD and provide a first step in moving OGD towards linked data.	conversion marketing;linked data;resource description framework;sparql;scalability;service innovation;table (information)	Marut Buranarach;Pattama Krataithong;Sirinaree Hinsheranan;Somchoke Ruengittinun;Thepchai Supnithi	2017		10.1145/3167020.3167021	linked data;rdf;data mining;open data;service innovation;scalability;sparql;computer science;table (information);data as a service	Web+IR	-42.33361828268451	-0.26244400653603206	2839
c409bc9d41880c07891e3ba7df0a49010205db7e	attention-based recurrent neural network for urban vehicle trajectory prediction		As the number of various positioning sensors and location-based devices increase, a huge amount of spatial and temporal information data is collected and accumulated. These data are expressed as trajectory data by connecting the data points in chronological sequence, and thses data contain movement information of any moving object. Particularly, in this study, urban vehicle trajectory prediction is studied using trajectory data of vehicles in urban traffic network. In the previous work, Recurrent Neural Network model for urban vehicle trajectory prediction is proposed. For the further improvement of the model, in this study, we propose Attention-based Recurrent Neural Network model for urban vehicle trajectory prediction. In this proposed model, we use attention mechanism to incorporate network traffic state data into urban vehicle trajectory prediction. The model is evaluated by using the Bluetooth data collected in Brisbane, Australia, which contains the movement information of private vehicles. The performance of the model is evaluated with 5 metrics, which are BLEU-1, BLEU-2, BLEU-3, BLEU-4, and METEOR. The result shows that ARNN model have better performance compared to RNN model.		Seongjin Choi;Jiwon Kim;Hwasoo Yeo	2018	CoRR		machine learning;data mining;data point;artificial intelligence;trajectory;recurrent neural network;computer science;bluetooth	ML	-16.623706127868687	-34.402931919552664	2842
9a85b783247fdf50e34fb90c39506759b719813b	use of a clinical event monitor to prevent and detect medication errors		Errors in health care facilities are common and often unrecognized. We have used our clinical event monitor to prevent and detect medication errors by scrutinizing electronic messages sent to it when any medication order is written in our facility. A growing collection of medication safety rules covering dose limit errors, laboratory monitoring, and other topics may be applied to each medication order message to provide an additional layer of protection beyond existing order checks, reminders, and alerts available within our computer-based record system. During a typical day the event monitor receives 4802 messages, of which 4719 pertain to medication orders. We have found the clinical event monitor to be a valuable tool for clinicians and quality management groups charged with improving medication safety.	charge (electrical);health care facility;rule (guideline);message	Thomas H. Payne;James Savarino;Rick Marshall;Christopher T. Hoey	2000	Proceedings. AMIA Symposium		health care;medical emergency;medicine	SE	-58.85894719920203	-66.52338615761097	2845
436e7e485ca63cc78dcf7e552712c976fff22541	enhancing player experience using procedural level generation		In this paper we explore different types of procedurally generated content to see if and how it can affect the gameplay experience of the player. We conduct a survey with different types of procedurally generated content in order to see if and how it affects the player when playing a game. The paper presents a simple turn based tactical strategy game where the objective of the player is to eliminate the enemy team. The player must achieve this goal in different circumstances: from a simple grid to a procedurally random generated levels. The experiments conducted will show the way procedurally generation will enhance the gameplay experience of the player and where it should be used.	artificial intelligence;experiment;game mechanics;job stream;procedural generation;replay value	Bogdan Maxim;Daniel Ciugurean;Dorian Gorgan	2018				HCI	-54.97549781620436	-48.07499206162251	2853
69f7532e32ef247b57b0afa27a9f400c70037353	ubiquitous connectivity: a framework for business models for wireless community networks	wireless communication;business model	With the growing need for ubiquitous connectivity, it is essential to develop business models which better fit noncommercial wireless communications services, particularly Wireless Community Networks (WCNs). Developing these business models for WCNs is challenging due to their public-private hybrid nature, lack of strong commercial incentives, high uncertainty, and the high complexity of the relationships among key business partners. The purpose of this paper is to propose a framework for developing public-private hybrid business model for WCNs and test it using several case studies. The framework addresses several elements such as product innovation, customer relationships, infrastructure management, and financial aspects of this emerging business. This framework would serve as a guide for WCNs to achieve digital, social, and economic inclusion for particular groups such as rural residents, underserved communities, and the mobile workforce. In addition, it should have a positive impact on addressing the pressing issue of the digital divide.	americas conference on information systems;control theory;frequency band;internet access;location-based service	Abdelnasser Abdelaal;Hesham H. Ali	2006			management science;wireless network;wireless;knowledge management;product innovation;municipal wireless network;computer science;digital divide;workforce;business model;incentive	Web+IR	-81.78795958348464	-8.134653265711815	2855
e01879c7cf4919d268cca4e90021f31696628239	formulating effective national strategies for market transformation	information management system;mercado economico;paises en desarrollo;information systems security;infrastructure information;mis systems;information systems research;journal of it;government policy;pays en developpement;jit;teaching cases;economic market;policy;information security;case studies;information science;information infrastructure;information security systems;chine;cambio;information technology;business information technology;security information systems;it journals;estrategia;information systems management;it teaching cases;politique gouvernementale;operational research society;strategy;change;business model;journal of information technology teaching cases;market transformation;telecomunicacion;asie;computer information systems;jit journal;social determinants;geographic information systems;national strategy;marche economique;information technology journal;information management;telecommunication;information systems journals;information systems technology;managing information systems;accounting information systems;changement;information and management;management information systems;define information systems;strategic information systems;business information management;soft system methodology;information system;health information systems;computer information technology;journal of information technology;china;business information systems;business systems analyst;politica;strategie;politique;infraestructura informacion;journal information technology;it journal;management science;telecommunications;asia;journal of information systems;developing countries;information technology journals	National initiatives for the development of information infrastructure have become critical to moving nations into the information age. In this paper, we are concerned with the features of information infrastructure development strategy, the social determinants for a country to choose a strategy and the principles of its design. We investigate China's telecommunications market transformation over the last two decades. China's experience is interesting as it is a case par excellence of a large transitory economy. We observe that China's national strategy was based on multiple social elements, not on technological prerogatives alone. This suggests that a national strategy for infrastructure construction should be derived from carefully considering both the technological options available as well as the social and political environment and the situation in the market structure.		Ping Gao;Kalle Lyytinen	2005	JIT	10.1057/palgrave.jit.2000039	public relations;economics;computer science;engineering;knowledge management;electrical engineering;management information systems;management;information technology;information system	AI	-71.76037128458692	1.9635145870474144	2857
13746fb8c315b2255098ff37de16bed97fadb1d2	ape 2008 academic publishing in europe, quality and publishingjanuary 22-23, 2008, berlin		Those of you who were here for last year’s conference might remember that I was here too and chaired one of the sessions. Last year, I mentioned that we had just started a new project called “VolltextsucheOnline” which stands for “full-text search online”. Today, I am here to present this project again. I am quite proud to be able to tell you that it is now up and running, following the launch of the website at the last Frankfurt Book Fair. Furthermore, we have changed the name of the project, because full-text search, or searches in the full text, is just one small functionality in the whole set of features we want to offer. The project’s new name is libreka!. We also wanted to make the point that we are not a “YACS” – “Yet Another Californian Start-up”. On the contrary, MVB is based at the heart of the German publishing industry and is wholly owned by the Börsenverein, the German Publishers and Booksellers Association. Now, what do we want to achieve with libreka!? To put it very simply: we want to put every Germanlanguage book in print online. We want to be the leading internet platform for the German book trade or, figuratively speaking, we want to be the Swiss army knife of e-content. First of all, we have a marketing objective. We want to increase the reach of publishers and booksellers. We want to open up new business models and sales channels for booksellers and publishers and want to protect intellectual property. We want to give publishers control over how much and what they publish on the internet. Now, what do I mean when I say: “We want to increase the reach of the publisher or bookseller”? First of all, by putting every book in print online with libreka, we want to give end-users access via the internet to culture, to knowledge, to education. At the same time, we offer every bookseller a service similar to the “Search Inside” offered by a large online retailer. Furthermore, we want to integrate the content on libreka! in the main search engines Google, Yahoo and Microsoft. If you look for a book that is on libreka! today, you will probably find it on Google as well. But what we want is to drive initiatives like “Google Book Search” or “Microsoft Life Search” by adding our content and therefore making it more easily available. At the same time, libreka! gives booksellers and publishers the opportunity to offer their customers a search inside the book-function and a chance to read examples of the books on libreka!. The integration in the search engines basically works in two ways. One way is very easy: the search engine indexes our html-pages. This is what they are already doing today. The second model is more complicated: the data we get from publishers is in pdf-format, though it is not a perfect format to use. We want to move to xml-format, but this data is rather difficult to get. That is why we are stuck with pdf for the moment. What we do is to extract the text from the pdf and build our own text index – this is purely text, no images and no meta-information about the book. Then we give access to that text	am broadcasting;book;google search;html;internet;online shopping;portable document format;train communication network;web search engine;xml;yet another	Ronald Schild	2008	Inf. Services and Use	10.3233/ISU-2008-0576	library science;history;media studies;engineering physics	Web+IR	-67.42527015010712	-21.504723091673227	2859
b0f5bf5b3a0c206f253b38708c4ac8e84595007d	topology, computational models, and social-cognitive complexity	medical diagnosis system;topology;group dynamics;detective cases;complex systems;structure;cognitive complexity	The topology or topological structure S, respectively, of a complex system can be defined in a graph theoretical way, i.e., S ((V V), E), V being a set of vertices and E a set of edges. Therefore, a topological structure in this sense can be represented as a directed graph. A relation e(v1, v2), e E, v1 , v2 V may represent, e.g., a social relation in a social group between group members, a cognitive (semantical or logical) relation between concepts or an economical relation between economical actors. By defining a certain topology and by adding certain rules of interaction between elements vi and vj V, one obtains a literally universal modeling schema for arbitrarily complex problems (6). This modeling schema will be applied in this article to several different problems, i.e., predictions of social group dynamical processes, the diagnosis of certain diseases via a medical diagnosis system constructed this way, and the solving of a murder case in a detective story. The schema will in some cases be extended to two levels, i.e., one element of a first level will consist of different elements itself. © 2006 Wiley Periodicals, Inc. Complexity 11: 43–55, 2006	cognitive complexity;complex system;computational model;directed graph;emoticon;graph theory;john d. wiley	Jürgen Klüver;Christina Klüver	2006	Complexity	10.1002/cplx.20122	structure;complex systems;combinatorics;computer science;artificial intelligence;machine learning;cognitive complexity;mathematics;algorithm;group dynamics	AI	-24.288676643134405	-10.436244603677688	2860
1bc51ed093ee42af828efde127e975b997c8197d	learning to identify reduced passive verb phrases with a shallow parser	thematic roles;verb phrase	Our research is motivated by the observation that NLP systems frequently mislabel passive voice verb phrases as being in the active voice when there is no auxiliary verb (e.g., “The man arrested had a long record”). These errors directly impact thematic role recognition and NLP applications that depend on it. We present a learned classifier that can accurately identify reduced passive voice constructions in shallow parsing environments.	experiment;heuristic (computer science);natural language processing;parser;shallow parsing	Sean Igo;Ellen Riloff	2008			natural language processing;active voice;speech recognition;reflexive verb;valency;computer science;verb phrase ellipsis;specifier	NLP	-24.726095096661844	-74.4858607133479	2870
4eb5bfae6c85b26a0b5f72dcb058e3171d4618d6	spotting prosodic boundaries in continuous speech in french	time delay neural network	Two kinds of marks have been set by the listeners (frontiers and accents), which are attached to the syllable nucleus. The MLP fed with any of the previously described values (F0,duration...), no matter the size of the temporal window, is not capable of reproducing the accent marking with a good score. Thus we consider that listeners' accent marks are not consistent, at least from a local point of view. But for the frontier marks, the MLP fed with the duration, on a 5 vowel context , achieves the task with 11% insertion and 43% omissions. Phonetician marks At this stage, we use the auditory marks to select a significative subset of marks set by the expert. Considering the given number of mark types obtained, we found it necessary to gather them in generic classes to achieve a correct training of the MLP : R for initial rise (129 occurrences), P for peaks (128), B for baseline (105), C for continuation rise (50), Nil for no marking at all (1287). After several tests, we kept vowel duration, F0 values, and pseudo-syllable duration on a 7 vocalic nucleus window to feed a MLP with 10 neurons in its hidden layer. The MLP has 5 outputs: one for each class mentioned above. Nil 227 6 0 4 3 B 7 20 0 0 0 C 0 5 7 1 1 P 5 0 1 25 5 R 0 0 0 5 34 The MLP gives no answer for 44 configurations (concurrent answers). Surprisingly, no nasality tag is required to draw the MLP attention on the fact that nasal vowels are much longer than vocalic ones. RESULTS AND CONCLUSION The main result is that this experience validates both the expert prosodic marking and the automatic spotting system. Furthermore, the confusion rate between P and R marks is rather low, which agrees with the results of [4]: lengthening is a more important correlate of F0 peak for P than for R. R marks recognized as P, are accented monosyllabics words. The recognition rate for C is enhanced when we add F0 regression parameters, as involved vowels bear a long upward F0 move. However this adds a slight confusion in the identification of P marks. Future work will aim at incorporating long term prosodic variations in the modelling of our prosodic marks. REFERENCES [1] J. Vaissière (1982), «A supra-seg-mental component in a French speech recognition system: …	baseline (configuration management);continuation;item unique identification;memory-level parallelism;nil;speech recognition;supra, inc.;syllable	Vincent Pagel;Noëlle Carbonell;Yves Laprie;Jacqueline Vaissière	1998	CoRR		natural language processing;speech recognition;computer science;time delay neural network	ML	-12.314141042525163	-81.50562113612965	2879
980b1e67c3d5a17bffb1b92bb6b862aa11f31718	music recommendation and discovery revisited	long tail;recommender system;music information retrieval;recommender systems	"""The world of music is changing rapidly. We are now just a few clicks away from being able to listen to nearly any song that has ever been recorded. This easy access to a nearly endless supply of music is changing how we explore, discover, share and experience music.  As the world of online music grows, music recommendation and discovery tools become an increasingly important way for music listeners to engage with music. Commercial recommenders such as Last.fm, iTunes Genius and Pandora have enjoyed commercial and critical success. But how well do these systems really work? How good are the recommendations? How far into the """"long tail"""" do these recommenders reach?  In this tutorial we look at the current state-of-the-art in music recommendation and discovery. We examine current commercial and research systems, focusing on the advantages and the disadvantages of the various recommendation strategies. We look at some of the challenges in building music recommenders and we explore some of the novel techniques that are being used to improve future music recommendation and discovery systems."""	accessibility;last.fm;long tail;online music store;recommender system	Òscar Celma;Paul Lamere	2011		10.1145/2043932.2043936	computer science;multimedia;world wide web;long tail;recommender system	ML	-55.91461767831031	-32.585700245249356	2882
a9fe8d51d1483ba7f530e366c1a53276b40e29f8	user interest in future mobile applications	france mobile applications scenario based approach u s italy spain portugal;social network services;future;portugal;mobile;wireless;u s;france;scenario;refrigerators;mobile applications;settore ing inf 05 sistemi di elaborazione delle informazioni;secs p 10 organizzazione aziendale;mobile communication;scenario mobile wireless application future;settore secs p 10 organizzazione aziendale;mobile computing behavioural sciences;behavioural sciences;italy;user interest;correlation;mobile computing;application;scenario based approach;security;mobile communication privacy security mobile computing refrigerators social network services correlation;mobile application;privacy;spain	Identifying what mobile applications users will want to use in the future is difficult. This paper presents a scenario-based approach for investigating the interest that users have in thirteen future mobile applications. The paper also examines eleven constructs to determine how they impact interest in the scenarios. The subjects surveyed in the research were located in five countries: the U.S., Italy, Spain, Portugal, and France. The results show that certain future applications are of more interest than others and that this interest is fairly consistent across the countries studied. The results also show that most of the constructs positively impact interest in the scenarios.	mobile app	Robert C. Nickerson;Jamie Eng;Andrea Carignani;Vanessa Gemmo;Lorenzo Negri	2011	2011 10th International Conference on Mobile Business	10.1109/ICMB.2011.11	simulation;geography;telecommunications;computer security	SE	-19.48972049776185	-34.728476968635874	2884
3b75ae2fb1b08cf550a5758789782a206e6dd6d9	a requirements engineering and management training course for software development professionals	software;software development professionals;first level academic degree;training;materials;software engineering;management training software engineering engineering management project management continuing education computer industry programming profession software development management certification software testing;requirements engineering;computer science education;industrial training;requirement engineering;csdp certification;educational courses;software development;unified modeling language;software developers;csdp certification requirements engineering and management industrial training;requirements engineering and management;programming;management training course;first level academic degree requirements engineering management training course software development professionals software developers;software engineering computer science education educational courses	Devising a course for software professionals working in industry depends on several factors. In order to create a course that fulfils professionals' expectations, it is important to take account of the skills of the participants, the time available, and the specific topics to be covered. This paper presents the curriculum of a course in requirements engineering and management intended for software developers with a first-level academic degree in computing and experience in developing real software solutions. This context requires the course to concentrate on topics that were not taught in the participants' previous education and that can have a positive impact on their daily practices.	requirements engineering;software developer;software development;xojo	João M. Fernandes;Ricardo J. Machado;Stephen B. Seidman	2009	2009 22nd Conference on Software Engineering Education and Training	10.1109/CSEET.2009.24	systems engineering;engineering;social software engineering;software engineering;computer engineering	SE	-83.09363440117133	-33.72413309994678	2889
1cfff23b4fdaab0015de3ec6ff055daad6bb4e17	the research of implementing sc to evaluate complexity in flight		In aviation, the Standard Operating procedures (SOPs) provides typi- cally a list of action items that allowing the pilots to complete tasks in flight en- vironment. Therefore, the complexity of SOPs should be appropriate to guaran- tee the flight safety. In this paper, step complexity (SC) from nuclear power plant is introduced to evaluate complexity in flight in nine tasks selected from SOPs. The verification measurement of SC is difference of heart rate (HR-D) of pilots. From experiment result, SC is correlative to HR-D. However, the corre- lation is not significant enough. Thus, to evaluate complexity in flight efficient- ly, the SC measure should be modified.		Yiyuan Zheng;Dan Huang;Shan Fu	2014		10.1007/978-3-319-07515-0_44	real-time computing;simulation;engineering;operations management	HPC	-24.228561912364913	-24.821176241213436	2892
2167054da02b0bb2dddfccfa2c60866858478da2	predicting search satisfaction metrics with interleaved comparisons	information retrieval;universiteitsbibliotheek;interleaved comparisons;evaluation	The gold standard for online retrieval evaluation is AB testing. Rooted in the idea of a controlled experiment, AB tests compare the performance of an experimental system (treatment) on one sample of the user population, to that of a baseline system (control) on another sample. Given an online evaluation metric that accurately reflects user satisfaction, these tests enjoy high validity. However, due to the high variance across users, these comparisons often have low sensitivity, requiring millions of queries to detect statistically significant differences between systems. Interleaving is an alternative online evaluation approach, where each user is presented with a combination of results from both the control and treatment systems. Compared to AB tests, interleaving has been shown to be substantially more sensitive. However, interleaving methods have so far focused on user clicks only, and lack support for more sophisticated user satisfaction metrics as used in AB testing. In this paper we present the first method for integrating user satisfaction metrics with interleaving. We show how interleaving can be extended to (1) directly match user signals and parameters of AB metrics, and (2) how parameterized interleaving credit functions can be automatically calibrated to predict AB outcomes. We also develop a new method for estimating the relative sensitivity of interleaving and AB metrics, and show that our interleaving credit functions improve agreement with AB metrics without sacrificing sensitivity. Our results, using 38 large-scale online experiments en- compassing over 3 billion clicks in a web search setting, demonstrate up to a 22% improvement in agreement with AB metrics (constituting over a 50% error reduction), while maintaining sensitivity of one to two orders of magnitude above the AB tests. This paves the way towards more sensitive and accurate online evaluation.	a/b testing;baseline (configuration management);experiment;experimental system;forward error correction;web search engine	Anne Schuth;Katja Hofmann;Filip Radlinski	2015		10.1145/2766462.2767695	real-time computing;computer science;theoretical computer science;evaluation;data mining;world wide web;information retrieval	Web+IR	-37.26726301798224	-54.65417846634488	2893
12caa4f98f27e96325b9abeb57f357fed9919769	a self-organized approach to collaborative handling of multi-robot systems	self organized;formation control;collaborative handling	"""The purpose of this paper is to develop a general self-organized approach to multi-robot's collaborative handling problem. Firstly, an autonomous motion planning graph (AMP-graph) is described for individual movement representations. An individual autonomous motion rule (IAM-rule) based on """"free-loose"""" and """"well-distributed load-bearing"""" preferences is presented. By establishing the simple and effective individual rule model, an ideal handling formation can be formed by each robot moving autonomously under their respective preferences. Finally, the simulations show that both the AMP-graph and the IAMrule are valid and feasible. On this basis, the self-organized approach to collaborative hunting and handling with obstacle avoidance of multi-robot systems can be further analyzed effectively."""	robot	Tian-Yun Huang;Xue-Bo Chen;Wang-Bao Xu;Wei Wang	2011		10.1007/978-3-642-21524-7_11	simulation;computer science;knowledge management;artificial intelligence	Robotics	-18.885629707152386	-10.855359675535022	2899
a429be4d2674b814d11d9f6cfb834ef76dbd4d97	implementation of mutual recognition and voluntary standardization via sharing of expertise in education of electrical engineers	blackboard mutual recognition voluntary standardization electrical engineers education expertise sharing universities curricula europe technological development riga technical university tempus erasmus daad bilateral agreements e learning methods moodle;standardisation computer aided instruction educational courses electrical engineering education;computer aided instruction;standardisation;educational institutions europe industries training electrical engineering laboratories;educational courses;electrical engineering education;curricula for electrical engineers mutual recognition voluntary standardization education of electrical engineers e learning platforms	The education of electrical engineers is popular subject in universities curricula's as in Europe, as worldwide. The methodological approach and needed qualification is standardized in national level, however the technological development level and carrier perspectives requires mutual recognition of education between counties. This article aimed to collect the best practice and experience of Riga Technical University in creation of curricula for electrical engineers in the frame of TEMPUS, Erasmus, DAAD and several bilateral agreements. The ways how to create compatible curricula for student training and its carrier development are discussed. The development e - learning methods and special virtual laboratories, as well as using e - learning platforms Moodle and Blackboard, its advantages and disadvantages are analyzed. The recommendations towards mutual recognition and voluntary standardization of education approaches for electrical engineers are offered.	best practice;bilateral filter;electrical engineering	Nadezhda Kunicina;Anatolijs Zabasta;Yelena Chaiko;Leonids Ribickis	2013	2013 IEEE Global Engineering Education Conference (EDUCON)	10.1109/EduCon.2013.6530146	engineering management;engineering;knowledge management;pedagogy	Vision	-77.93027222891097	-33.730783033315156	2909
219563739f0833bca125336d0754dc82cee9563d	optimal user interface parameters for dual-sided transparent screens in layered window conditions	transparent display;transparency;layered interface;both sided interaction	In this research, we assess a set of optimal user interface parameters for a dual-sided transparent display in a collaborative working environment. To provide an experiment setup, we develop a prototype that simulates a dual-sided transparent display using two conventional displays and associated simulation software. The user interface parameters controlled in the experiment include the transparency level and the overlapped or layered size of foreground and background user interface windows, where a target marker being searched by subjects is presented along with distraction markers. To evaluate the optimal parameter setting, we measure the response time and correct response rate from the subject input to both the foreground and background displays.i¾?From the pilot study, we found that appropriate levels of transparency and windows overlapping potentially enhance the visibility of a user interface realized on layered multiple windows.i¾?Based on this finding, we propose an extended user research, where a depth factor and a contour effect are employed in addition to the user interface parameters, which may enhance the user response time especially in cases where the windows are highly overlapped.	user interface	Hae Youn Joung;Se Young Kim;Seung Hyun Im;Bo Kyung Huh;Heesun Kim;Gyu Hyun Kwon;Ji-Hyung Park	2016		10.1007/978-3-319-39516-6_15	simulation;human–computer interaction;z-order;multimedia;transparency;multiple document interface	HCI	-45.482899242203885	-46.478864762575775	2913
bfa1f2774c54928c400a263c6e6023d5e7fec70d	spatial learning using locomotion interface to virtual environment	computers;cognitive map;partial training trial spatial learning locomotion interface virtual environment handicaps visually impaired people haptics technology speech technology treadmill style locomotion interface unconstrained walking plane virtual environment exploration cognitive maps turning motions straight walking motions spatial layout knowledge object localization task target post training trial;interactive techniques for learning;comparative analysis;simulation systems for training;navigation legged locomotion haptic interfaces training virtual environments safety computers;training methods;predictor variables;legged locomotion;physical activities;training;virtual reality;computer system design;psychology;virtual environments;cognitive maps;navigation;object localization;blindness;handicapped aids;foreign countries;computer assisted instruction;simulated environment;adults;statistical analysis;spatial learning;perceptual motor learning;virtual reality gait analysis handicapped aids interactive systems psychology;safety;observation;gait analysis;assistive technology;spatial ability;interviews;visual impairment;cognitive mapping;adolescents;questionnaires;instructional effectiveness;locomotion interface devices for learning;computer software evaluation;virtual environment;haptic interfaces;computer interfaces;interactive systems;computer simulation;spatial information;interaction technique;simulation systems for training assistive technology cognitive maps interactive techniques for learning locomotion interface devices for learning;program effectiveness;reading and writing;haptic interface;pretests posttests	The inability to navigate independently and interact with the wider world is one of the most significant handicaps that can be caused by blindness, second only to the inability to communicate through reading and writing. Many difficulties are encountered when visually impaired people (VIP) need to visit new and unknown places. Current speech or haptics technology does not provide a good solution. Our approach is to use treadmill-style locomotion interface, unconstrained walking plane (UWP), to allow a richer and more immersive form of virtual environment (VE) exploration to enable VIP to create cognitive maps efficiently and thereby to enhance their mobility. An experimental study is reported that tests design of UWP for both straight walking and turning motions. Two groups of participants, blind-folded-sighted and blind, learned spatial layout in VE using two exploration modes: guided (training phase) and unguided (testing phase). Spatial layout knowledge was assessed by asking participants to perform object-localization task and target-object task. Our results showed a significant decrease in time and helps taken to complete tasks, subjective workload, and errors in a post-training trial as compared to a partial-training trial. UWP has been found to significantly improve interaction with VE with visualizations such as spatial information.	cognitive map;experiment;haptic technology;multimodal interaction;simulation;virtual reality	Kanubhai K. Patel;Sanjay K. Vij	2012	IEEE Transactions on Learning Technologies	10.1109/TLT.2011.29	computer simulation;computer vision;simulation;human–computer interaction;cognitive map;computer science;artificial intelligence;virtual reality;multimedia;statistics	HCI	-46.68563145561779	-49.36821761607914	2918
08d4c8f15a6b2a955f848cbcaf6ce5550d54f1ed	proceedings of the third acm international symposium on design and analysis of intelligent vehicular networks and applications, divanet@mswim 2013, barcelona, spain, november 3-4, 2013					2013				Arch	-55.56792321413017	-5.355692607986044	2925
4a310c83ff0380713992d9fec7ec5b663d631fd6	statistical analysis of financial networks	conjunto independiente;graph theory;stock price fluctuations;web graph;loi puissance;teoria grafo;47a10;computacion informatica;analisis estadistico;analisis datos;cross correlation;independent set;call graph;ley poder;correlation croisee;datos financieros;market structure;donnee financiere;spectrum;classification;theorie graphe;financial data;stock markets;degree distribution;marche valeurs;data analysis;theorie du portefeuille;ensemble independant;statistical analysis;diversified portfolio;stock price;market graph;clustering coefficient;ciencias basicas y experimentales;portfolio theory;matematicas;statistical computation;analyse statistique;calculo estadistico;power law model;teoria de la cartera;analyse donnee;calcul statistique;62p05;massive datasets;estructura mercado;graphe marche;power law;classification automatique;grupo a;structure marche;automatic classification;60e05;clasificacion automatica;clique;cours action;structural properties;correlacion cruzada	Massive datasets arise in a broad spectrum of scientific, engineering and commercial applications. In many practically important cases, a massive dataset can be represented as a very large graph with certain attributes associated with its vertices and edges. Studying the structure of this graph is essential for understanding the structural properties of the application it represents. Well-known examples of applying this approach are the Internet graph, the Web graph, and the Call graph. It turns out that the degree distributions of all these graphs can be described by the power-law model. Here we consider another important application—a network representation of the stock market. Stock markets generate huge amounts of data, which can be used for constructing the market graph reflecting the market behavior. We conduct the statistical analysis of this graph and show that it also follows the power-law model. Moreover, we detect cliques and independent sets in this graph. These special formations have a clear practical interpretation, and their analysis allows one to apply a new data mining technique of classifying financial instruments based on stock prices data, which provides a deeper insight into the internal structure of the stock market.		Vladimir Boginski;Sergiy Butenko;Panos M. Pardalos	2005	Computational Statistics & Data Analysis	10.1016/j.csda.2004.02.004	econometrics;power law;null model;artificial intelligence;graph theory;mathematics;critical graph;intersection graph;statistics	ML	-4.787505970843935	-31.62903264283761	2928
880e15e83db8289aba78fb001e4be495b1eb64de	gtts systems for the sws task at mediaeval 2013		This paper briefly describes the systems presented by the Software Technologies Working Group (http://gtts.ehu.es, GTTS) of the University of the Basque Country (UPV/EHU) to the Spoken Web Search (SWS) task at MediaEval 2013. GTTS systems consist of four main modules: (1) feature extraction; (2) speech activity detection; (3) DTW-based query matching; and (4) score calibration and fusion. The most remarkable contributions are the use of phone loglikelihood ratio features, the normalization of the DTW distance matrix and the calibration/fusion approach (which is imported from language/speaker verification).	distance matrix;feature extraction;sinewave synthesis;speaker recognition	Luis Javier Rodríguez-Fuentes;Amparo Varona;Mikel Peñagarikano;Germán Bordel;Mireia Díez	2013			natural language processing;speech recognition;engineering;pattern recognition	AI	-15.337157667153555	-86.8051993841542	2929
02cb148ad49c4255505c661b320377376570554a	teaching adult learners in online career and technical education	career and technical education;adult learner	Online education is becoming an important component of career and technical education (CTE) in teacher preparation and at the graduate level. In the midst of such growth, and in response to questions about quality compared with traditional learning, there is a consensus that online courses and programs should be designed based on the needs of adult learners. However, much of the literature in online CTE lacks implicit connections to emerging notions of adult development and learning. This article provides an overview of the status of online education in CTE at the postsecondary level, discusses related issues and current research focus, and highlights adult learning developments and the implications for curriculum design, instruction, and use of technology. The article concludes with an outline of emerging trends bridging adult learning and online education relevant to career and technical education. DOI: 10.4018/jwbltt.2009091503 IGI PUBLISHING This paper appears in the publication, International Journal of Web-Based Learning and Teaching Technologies, Volume 4, Issue 4 edited by Eugenia M.W. Ng, Nikos Karacapilidis, and Mahesh S. Raisinghani © 2009, IGI Global 701 E. Choc late Avenue, He shey PA 17033-1240, USA Tel: 717/533-8845; Fax 717/533-8661; URL-http://www.igi-global.com ITJ 5454 International Journal of Web-Based Learning and Teaching Technologies, 4(4), 32-49, October-December 2009 33 Copyright © 2009, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. for online education, related curriculum and program development, and perceptions about quality and barriers and opportunities for adoption (Flowers, 2005; Flowers & Baltzer, 2006b; Schmidt & Gallegos, 2001). As such, there is a need for an examination of adult learning principles in the context of online education and the implications for curriculum development, teaching, and use of technology. To this end, the objectives of this article are to: First, review the status of online education with an emphasis in career and technical education and related issues for adoption; second, highlight adult learning developments with potential to inform curriculum design and instruction; third, outline implications on the use of instructional technology; and fourth, point out emerging trends bridging adult learning and online education relevant to CTE efforts in this area.	bridging (networking);national research and education network;tail value at risk	Victor M. Hernández-Gantes	2009	IJWLTT	10.4018/jwbltt.2009091503	adult education;computer science;pedagogy	HCI	-76.79284366760884	-30.97323698579712	2938
71480871913fb3125d2bfb61dda20eab7eb5cb05	peeling back the multiple layers of twitter's private disclosure onion: the roles of virtual identity discrepancy and personality traits in communication privacy management on twitter	privacy management;social networking;neo big 5;tweets;private disclosure;virtual identity discrepancy;user generated content ugc;microblogging;twitter;social media	This study examined multiple layers of private disclosure on the microblogging site Twitter. Survey data (N = 375) were collected from current Twitter users (N = 198), nonusers (N = 116), and dropouts (N = 61). Data from current Twitter users revealed the existence of multiple strata of private disclosure boundaries on Twitter. There were significant differences at the descriptive and inferential levels among the multiple dimensions of private information, including daily lives, social identity, competence, socio-economic status, and health. Private information regarding daily lives and entertainment was disclosed easily and located at the outermost layer of the disclosure onion. In contrast, health-related private information was concealed and located within the innermost layer of the disclosure onion. ANOVAs (N = 375) also indicated that there were significant differences among current Twitter users, nonusers, and dropouts with regard to personality traits and privacy concerns about Twitter. Theoretical...	discrepancy function	Seung-A. Annie Jin	2013	New Media & Society	10.1177/1461444812471814	public relations;social media;computer science;marketing;microblogging;advertising;internet privacy;world wide web;social network	DB	-87.16344923699126	-15.62719298277491	2939
12fcea6de6cc4294705508cf18407ba2d1a2df0e	chinese-uyghur statistical machine translation: the initial explorations	phrase based;decoding;morphemes;training;statistical machine translation;government;language translation;hieroglyphics;svo;uyghur;agglutinative language;morpheme processing;chinese sentence structure reordering;derivational word formation process;morphology;computational modeling;phrase based statistical machine translation system;statistical analysis;morphemes uyghur phrase based splitting granularity;chinese uyghur statistical machine translation;splitting granularity;morpheme processing chinese uyghur statistical machine translation phrase based statistical machine translation system hieroglyphics agglutinative language derivational word formation process chinese sentence structure reordering svo sov;computational linguistics;statistical analysis language translation natural language processing;decoding morphology training computational linguistics computational modeling conferences government;natural language processing;sov;conferences	In this paper, we present results of initial explorations to a phrase-based statistical machine translation system for a new language pair, namely Chinese-Uyghur. They are very different from each other, the characters of the former almost are hieroglyphics, morpheme processing don't work at all, but the latter is an agglutinative language with very productive inflectional and derivational word-formation processes. To make them more similar, we reorder Chinese sentence structures from SVO to SOV and split Uyghur words into morphemes. The experiments show reordering Chinese sentence structure and properly splitting granularity for Uyghur can effectively improve the performances of translation system.	experiment;moses;parallel text;parsing;performance;sparse voxel octree;statistical machine translation;vii	Xinghua Dong;Huajian Xue;Bo Ma;Lei Wang	2010	2010 4th International Universal Communication Symposium	10.1109/IUCS.2010.5666183	natural language processing;speech recognition;computer science;linguistics	NLP	-21.816223390139978	-77.21432228251697	2940
720c9f34d70712899b0ea4c56fd5f245e5186e87	beyond classical planning: procedural control knowledge and preferences in state-of-the-art planners	search space;dynamic system;user preferences;ai planning	Real-world planning problems can require search over thousands of actions and may yield a multitude of plans of differing quality. To solve such real-world planning problems , we need to exploit domain control knowledge that will prune the search space to a manageable size. And to ensure that the plans we generate are of high quality, we need to guide search towards generating plans in accordance with user pre ferences. Unfortunately, most state-of-the-art planners c annot exploit control knowledge, and most of those that can exploi t user preferences require those preferences to only talk abo ut the final state. Here, we report on a body of work that extends classical planning to incorporate procedural control know ledge and rich, temporally extended user preferences into th e specification of the planning problem. Then to address the en suing nonclassical planning problem, we propose a broadlyapplicablecompilation techniquethat enables a diversity of state-of-the-art planners to generate such plans without a dditional machinery. While our work is firmly rooted in AI planning it has broad applicability to a variety of computer science problems relating to dynamical systems.	adaptive binary optimization;automated planning and scheduling;computer science;display resolution;dynamical system;user (computing)	Jorge A. Baier;Christian Fritz;Meghyn Bienvenu;Sheila A. McIlraith	2008			automated planning and scheduling;simulation;computer science;knowledge management;artificial intelligence;dynamical system	AI	-20.828246120003644	-7.752040216939172	2941
f7ce8adf553a39b14baefd8a304e9076c8499c88	using xml logical structure to retrieve (multimedia) objects	xml document;test collection	This paper investigates the use of the logical structure in XML documents for the retrieval of XML multimedia objects. We study different logical levels and their combinations. Our investigation is carried on a purposebuilt test collection based on the INEX test collection. Our findings are the followings. First, all logical levels allow discriminating between elements contained in different documents, whereas the lower logical levels allow discriminating between elements within a same document. Second, combining the logical levels improve retrieval performance.	archive;experiment;simulation;xml	Zhigang Kong;Mounia Lalmas	2007		10.1007/978-3-540-74851-9_9	well-formed document;xml validation;xml;computer science;document structure description;data mining;xml schema;database;xml schema editor;information retrieval;efficient xml interchange	Web+IR	-33.84839854176224	-60.88084722322993	2942
19cf827b22fb8ec957f28a0df672b576c4ee1936	visualizing the tape of life: exploring evolutionary history with virtual reality		Understanding the evolutionary dynamics created by a given evolutionary algorithm is a critical step in determining which ones are most likely to produce desirable outcomes for a given problem. While it is relatively easy to come up with hypotheses that could plausibly explain observed evolutionary outcomes, we often fail to take the next step of confirming that our proposed mechanism accurately describes the underlying evolutionary dynamics. Visualization is a powerful tool for exploring evolutionary history as it actually played out. We can create visualizations that summarize the evolutionary history of a population or group of populations by drawing representative lineages on top of the fitness landscape being traversed. This approach integrates information about the adaptations that took place with information about the evolutionary pressures they were being subjected to as they evolved. However, these visualizations can be challenging to depict on a two-dimensional surface, as they integrate multiple forms of three-dimensional (or more) data. Here, we propose an alternative: taking advantage of recent advances in virtual reality to view evolutionary history in three dimensions. This technique produces an intuitive and detailed illustration of evolutionary processes. A demo of our visualization is available here: https://emilydolson.github.io/fitness_landscape_visualizations.	evolutionary algorithm;population;virtual reality	Emily Dolson;Charles Ofria	2018		10.1145/3205651.3208301	computer science;fitness landscape;visualization;data visualization;machine learning;artificial intelligence;human–computer interaction;evolutionary dynamics;virtual reality;population;evolutionary algorithm	Visualization	-26.24204694110562	-27.37692242422992	2943
0ee93827fad11535a8bed25b8d00eea35f41770e	predicting elections with twitter: what 140 characters reveal about political sentiment	elections;data mining;sentiment analysis;microblogging;twitter;politics	Twitter is a microblogging website where users read and write millions of short messages on a variety of topics every day. This study uses the context of the German federal election to investigate whether Twitter is used as a forum for political deliberation and whether online messages on Twitter validly mirror offline political sentiment. Using LIWC text analysis software, we conducted a content analysis of over 100,000 messages containing a reference to either a political party or a politician. Our results show that Twitter is indeed used extensively for political deliberation. We find that the mere number of messages mentioning a party reflects the election result. Moreover, joint mentions of two parties are in line with real world political ties and coalitions. An analysis of the tweets’ political sentiment demonstrates close correspondence to the parties' and politicians’ political positions indicating that the content of Twitter messages plausibly reflects the offline political landscape. We discuss the use of microblogging message content as a valid indicator of political sentiment and derive suggestions for further research.	online and offline	Andranik Tumasjan;Timm Oliver Sprenger;Philipp G. Sandner;Isabell M. Welpe	2010			election;politics;computer science;microblogging;internet privacy;world wide web;sentiment analysis	Web+IR	-81.98697474023585	-17.42299868217661	2948
44fce2f8ff27aad254399713d1ec264397c916da	pestel modeler: strategy analysis using metaedit+, istar 2.0, and semantic technologies		In strategic management, strategy analysis includes an analysis of a companyu0027s strategic position. In particular, the PESTEL framework serves to analyze a companyu0027s macroenvironment, i.e., the political, economic, social, technological, ecological, and legal factors that influence a companyu0027s strategic position. In this paper, we demonstrate a modeling tool for PESTEL analysis implemented in MetaEdit+ using iStar 2.0 notation. Semantic technologies then serve to infer new knowledge from PESTEL models, namely the opportunities and threats that a company faces.	automated reasoning;ecology;goal modeling;linked data;metaedit+;modeling language;olap cube;online analytical processing;ontology (information science);strategic management;usability testing	Christoph G. Schütz;Eva Mair;Michael Schrefl	2018	2018 IEEE 22nd International Enterprise Distributed Object Computing Workshop (EDOCW)	10.1109/EDOCW.2018.00040	systems engineering;strategic management;management science;notation;environmental analysis;computer-aided software engineering;semantic technology;swot analysis;computer science;business model	SE	-68.5995234577014	0.08519423101910743	2959
7f795fbe16386a1fdb156e4351cf7e9662442fde	comment: calculi or diagrams?			diagram	Dirk Rustemeyer	2013	Cybernetics and Human Knowing		cognitive science;psychology	Vision	-52.95356373701819	-20.39479920144389	2964
16a0200daa68c912b1cad33de060b23f28e0e460	an augmented lagrangian method for piano transcription using equal loudness thresholding and lstm-based decoding		A central goal in automatic music transcription is to detect individual note events in music recordings. An important variant is instrument-dependent music transcription where methods can use calibration data for the instruments in use. However, despite the additional information, results rarely exceed an f-measure of 80%. As a potential explanation, the transcription problem can be shown to be badly conditioned and thus relies on appropriate regularization. A recently proposed method employs a mixture of simple, convex regularizers (to stabilize the parameter estimation process) and more complex terms (to encourage more meaningful structure). In this paper, we present two extensions to this method. First, we integrate a computational loudness model to better differentiate real from spurious note detections. Second, we employ (Bidirectional) Long Short Term Memory networks to re-weight the likelihood of detected note constellations. Despite their simplicity, our two extensions lead to a drop of about 35% in note error rate compared to the state-of-the-art.	augmented lagrangian method;condition number;estimation theory;f1 score;long short-term memory;matrix regularization;sensor;thresholding (image processing);transcription (software)	Sebastian Ewert;Mark B. Sandler	2017	2017 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)	10.1109/WASPAA.2017.8170012	machine learning;loudness;word error rate;artificial intelligence;speech recognition;spurious relationship;hidden markov model;decoding methods;estimation theory;thresholding;augmented lagrangian method;mathematics	Vision	-15.96707117205603	-94.84562104878647	2985
1b21c278284f6a9ff88ca51d3c0c31740b714555	using publicly available data to characterize consumers use of email to communicate with healthcare providers	biological patents;health information technology;biomedical journals;text mining;europe pubmed central;citation search;citation networks;email;research articles;abstracts;open access;life sciences;clinical guidelines;consumer involvement;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	The use of patient focused technology has been proclaimed as a means to improve patient satisfaction and improve care outcomes. The Center for Medicaid/Medicare Services, through its EHR Incentive Program, has required eligible hospitals and professionals to send and receive secure messages from patients in order to receive financial incentives and avoid reimbursement penalties. Secure messaging between providers and patients has the potential to improve communication and care outcomes. The purpose of this study was to use National Health Interview Series (NHIS) data to identify the patient characteristics associated with communicating with healthcare providers via email. Individual patient characteristics were analyzed to determine the likelihood of emailing healthcare providers. The use of email for this purpose is associated with educational attainment, having a usual place of receiving healthcare, income, and geography. Publicly available data such as the NHIS may be used to better understand trends in adoption and use of consumer health information technologies.	academic achievement;crew resource management, healthcare;email;geography;patients;secure messaging;message	Ryan H. Sandefer;Saif Sherif Khairat;David S. Pieczkiewicz;Stuart M. Speedie	2015	Studies in health technology and informatics	10.3233/978-1-61499-564-7-401	public relations;medicine;data mining;world wide web	HCI	-61.25157800250042	-64.4039082744998	2987
305d10306fa2c148d78325d7673cdfe8835b00bb	book review: noah wardrip-fruin and nick montfort (eds.), the new media reader, mit press, cambridge, ma, 2003. 823 p.	computacion informatica;humanidades;psicologia y educacion;filologias;humanidades generalidades;didacticas aplicadas;ciencias basicas y experimentales;filologias generalidades;new media;grupo b			David Kolb	2004	Computers and the Humanities	10.1007/s10579-004-0816-y	new media	NLP	-60.36470279325406	-12.02244304407387	2988
1de3c8a6e7e631bf1393c6dcd6413e4caea0c422	on social reasoning in multi-agent systems	multi agent system	This work presentsthecorenotionsof a social reasoningmechanism, basedon dependencetheory. This model enablesan agentto reasonaboutthe others,in particularto calculatehis dependencerelationsanddependence situations.An agentis saidto bedependent onanotherif thelattercanhelp/preventhim to achieveoneof hisgoals. We considerour socialreasoningmechanismasanessentialbuilding block for thedesignof really autonomous artificial agents,which areimmersedin anopenmulti-agentworld. By open,we meanthatagentsmayenteror leavethesocietyatany moment.In suchsystems, astheorganizationof theagentscannotbeconcei vedatdesign time, thecooperati veproblemsolvingparadigmis basedon dynamiccoalition formation. In this context, agents mustbe ableto adapt themselvesto dynamicallychangingconditions,by evaluatingat executiontime if their goalsareachievableandif their plansarefeasible. As we do not supposethatagentsarebenevolent,our model proposesa criterionto evaluatewhich partnersaremoresusceptibleto accepta propositionof coalition. Finally, asin thesekind of systemsagentsusuallydo not have a completeandcorrectrepresentationof eachother, our modelhelpsthemto detectanagencylevel inconsistencyandto choosea context to bemaintained.	intelligent agent	Jaime Simão Simao;Yves Demazeau	2001	Inteligencia Artificial, Revista Iberoamericana de Inteligencia Artificial		simulation;computer science;artificial intelligence;multi-agent system	AI	-19.341101625188273	-11.45839812463838	2997
ae60bff3c9e0617b158f6e239b30b28f95e90599	spatiotemporal complexity of a city traffic jam			jam	F. Castillo;Benjamín A. Toledo;Víctor Muñoz;José Rogan;Roberto Zarama;Juan Felipe Penagos;Miguel Kiwi;Juan Alejandro Valdivia	2016	J. Cellular Automata		traffic congestion reconstruction with kerner's three-phase theory;mathematics;discrete mathematics	Theory	-16.135360096268244	-26.133476080203888	2999
a38f1f3ae1759c91cda1bb6c98e44f132872c905	density-based graph model summarization: attaining better performance and efficiency		Several algorithms based on PageRank algorithm have been proposed to rank the document sentences in the multidocument summarization field and LexRank and T-LexRank algorithms are well known examples. In literature different concepts such as weighted inter-cluster edge, cluster-sensitive graph model and document-sensitive graph model have been proposed to improve LexRank and T-LexRank algorithms (e.g. DsR-G, DsR-Q) for multi-document summarization. In this paper, a density-based graph model for multi-document summarization is proposed by adding the concept of density to LexRank and T-LexRank algorithms. The resulting generic multi-document summarization systems, DensGS and DensGSD were evaluated on DUC 2004 while the query-based variants, DensQS, DensQSD were evaluated on DUC 2006, DUC 2007 and TAC 2010 task A. ROUGE measure was used in the evaluation. Experimental results show that density concept improves LexRank and T-LexRank algorithms and outperforms previous graph-based models (DsR-G and DsR-Q) in generic and query-based multi-document summarization tasks. Furthermore, the comparison of the number of iterations indicates that the density-based algorithm is faster than the other algorithms based on PageRank.		Mohammadreza Valizadeh;Pavel Brazdil	2015	Intell. Data Anal.	10.3233/IDA-150735	computer science;theoretical computer science;machine learning;pattern recognition	AI	-26.33958379873526	-64.37906180132539	3001
284c3a4d27b1e011a09b702a1b7b7f7dc9449fb3	facilitating the creation of natural interactions for live audiovisual performances: an authoring-by-demonstration approach	interaction;open sound control;real time;spatial mapping;fuzzy logic;gesture following;tracking	In this paper an approach for creating natural interactions is discussed, which can be used to facilitate the authoring of interactive live audiovisual performances. The approach is supported by flexible, yet simple software tools and combines spatial mapping, gesture following and fuzzy logic in a way that enables the configuration and authoring of complex interactive mechanisms by demonstration. Due to the connectivity properties of the tools, the approach can be easily incorporated in almost any workflow for creating interactive installation or live performance applications, utilizing sensor and tracking data and combining it with other real-time parameters to drive the behavior of elements, which performers can interact with. This approach was used to facilitate the creation of a gestural interface for a conductor, which enabled him to control a virtual pianist during a live music performance by moving his hands in a natural manner. This gestural interface was configured by letting the conductor demonstrate the desired gestures and by feeding the resulting tracking data to the tools. The advantages and shortcomings of using such an approach are presented and discussed.	fuzzy logic;gesture recognition;interaction;performance;real-time clock	Dionysios Marinos;Christian Geiger	2014		10.1145/2636879.2636893	fuzzy logic;interaction;simulation;human–computer interaction;computer science;artificial intelligence;operating system;tracking;multimedia	HCI	-44.61509171767629	-35.579971710542246	3005
ef5e04f150afc7ab2b52d169a0221e99076d6b20	a new architecture for managing enterprise log data	detailed activity log;linux-based pcs;high-end network security;new architecture;enterprise log data;log management system;process log;data management platform;network operation;log record;traditional data management system;large-scale log management	Rights to individual papers remain with the author or the author's employer. Permission is granted for noncommercial reproduction of the work for educational or research purposes. This copyright notice must be included in the reproduced paper. USENIX acknowledges all trademarks herein.		Adam Sah	2002			computer science;data mining;database;world wide web	Security	-69.12279984760157	-18.60837276247385	3009
d3541b6360563e609ac5cef50336408e6cde0ff5	collaborative discourse theory as a foundation for tutorial dialogue	agent tutoriel paco;systeme tutoriel intelligent;intelligent tutoring system;generic model;educational software program;teaching and learning;didacticiel;user assistance;col;assistance utilisateur;dialogue tutoriel;asistencia usuario;intelligent tutoring systems;enseignement;programa didactico;learning artificial intelligence;teaching;ensenanza;apprentissage intelligence artificielle	Research on intelligent tutoring systems has not leveraged general models of collaborative discourse, even though tutoring is inherently collaborative. Similarly, research on collaborative discourse theory has rarely addressed tutorial issues, even though teaching and learning are important components of collaboration. We help bridge the gap between these two related research threads by presenting a tutorial agent, called Paco, that we built using a domain-independent collaboration manager, called Collagen. Our primary contribution is to show how a variety of tutorial behaviors can be expressed as rules for generating candidate discourse acts in the framework of collaborative discourse theory.		Jeff Rickel;Neal Lesh;Charles Rich;Candace L. Sidner;Abigail S. Gertner	2002		10.1007/3-540-47987-2_56	education;collaborative learning;simulation;computer science;artificial intelligence;machine learning;database;distributed computing;multimedia;mountain pass	NLP	-78.70373653592988	-48.2688886221818	3015
bbbfe5856803123b93184cf17ccf9426bf6f1d9b	proceeding from performance: an ethnography of the birmingham laptop ensemble			laptop	Graham Booth;Michael Gurevich	2012			ethnography;simulation;laptop;engineering	Vision	-70.11538867034874	-34.13898416838007	3018
ddb847218369dff122495cac1d2a1ac9b20bcf09	innovation opportunities in critical results communication: practical solutions				Bruce I. Reiner	2013	Journal of Digital Imaging	10.1007/s10278-013-9629-0	knowledge management;management science	EDA	-66.53361745537796	-2.1273707671721653	3022
6127532c7fb3af77754fe6e9712a3e4c9f4e8c95	oceanrt: real-time analytics over large temporal data	performance;design;management	We demonstrate OceanRT, a novel cloud-based infrastructure that performs online analytics in real time, over large-scale temporal data such as call logs from a telecommunication company. Apart from proprietary systems for which few details have been revealed, most existing big-data analytics systems are built on top of an offline, MapReduce-style infrastructure, which inherently limits their efficiency. In contrast, OceanRT employs a novel computing architecture consisting of interconnected Access Query Engines (AQEs), as well as a new storage scheme that ensures data locality and fast access for temporal data. Our preliminary evaluation shows that OceanRT can be up to 10x faster than Impala [10], 12x faster than Shark [5], and 200x faster than Hive [13]. The demo will show how OceanRT manages a real call log dataset (around 5TB per day) from a large mobile network operator in China. Besides presenting the processing of a few preset queries, we also allow the audience to issue ad hoc HiveQL [13] queries, watch how OceanRT answers them, and compare the speed of OceanRT with its competitors.	apache hive;big data;cloud computing;computer architecture;hoc (programming language);locality of reference;mapreduce;online and offline;real-time transcription;terabyte	Shiming Zhang;Yin Yang;Wei Fan;Liang Lan;Mingxuan Yuan	2014		10.1145/2588555.2594513	design;performance;computer science;data mining;database;world wide web	OS	-32.64855607866756	-0.868515366696878	3025
587bcc8c4fc980cff445695f4162eee5820dd001	[letters to editor]		THE question put by your correspondent with reference to the germination of seeds taken from ancient Egyptian tombs appears to be directly answered by M. A. de Candolle in his work on “The Origin of Cultivated Plants.” His words are:—“I think it pertinent to say that no grain taken from an ancient Egyptian sarcophagus and sown by agriculturists has ever been known to germinate. It is not that the thing is impossible, for grains are all the better preserved that they are protected from the air and from variations of temperature or humidity, and certainly these conditions are fulfilled by Egyptian monuments; but as a matter of fact, the attempts at raising wheat from these ancient seeds have not been successful.”	relevance	Landon M. Klein	1998	Nature	10.1038/035463e0		Crypto	-63.35461258093037	-21.75610811514389	3028
4b32963404d736792af4b05e14d7c52cc9e178da	social implications of smartphone use: korean college students' smartphone use and psychological well-being		The purpose of this study is to explore the relationship between motives of smartphone use, social relation, and psychological well-being. The correlation analysis shows that the motives of smartphone use were positively related to bonding relations but negatively related to bridging relations. The hierarchical multiple regression analysis finds the associations among motives of smartphone use, social relations, perceived social support, and variables of psychological well-being. The results demonstrate that needs for caring for others were negatively related to loneliness and depression and positively related to self-esteem. However, the communication motives are not a significant predictor to determine self-esteem, loneliness, and depression. In addition, bonding and bridging social relations and social support significantly increase self-esteem and decrease loneliness and depression.		Namsu Park;Hyunjoo Lee	2012	Cyberpsychology, behavior and social networking	10.1089/cyber.2011.0580	psychology;psychotherapist;social psychology;clinical psychology	HCI	-87.34559524465324	-20.86541921863238	3029
2fdd50fee403ab9293bb452e31e310eac797fa36	intelligent ambient technology: friend or foe?	loss of control;user study;user expectations;user studies;acceptance of technology;intelligent system;ubiquitous computing;intelligence;smart environments;smart environment	"""This paper presents a part of findings from a study carried out to gain insight on user understanding of smart environments and preferred ways and places for interaction with smart services therein. Here we concentrate on qualitative interview data discussing the concept of intelligence with regard to technology and the participants' perceptions of it. Such understanding of potential users' expectations is critical in developing novel technologies and launching the first services based on it. Furthermore, naming the offered technology or service smart or intelligent might give wrong impressions of its capabilities, thus leading to experiences of worry or disappointment. The main finding is that the participants understood """"intelligence"""" to mean different things, which are usually related to their own needs or technological novelty. In addition, an intelligent system and ability to act proactively raised concerns of loss of control."""	artificial intelligence;experience;identification friend or foe;smart environment	Minna Kynsilehto;Thomas Olsson	2011		10.1145/2181037.2181055	simulation;engineering;knowledge management;multimedia;internet of things	HCI	-58.676527940618584	-42.5662005179527	3034
8e68b9caf3b5dc4cd92e2846c8a68b7e4c3b2081	the educational potential of e‐portfolios – by lorraine stefani			lorraine borman	Nick Rushby	2008	BJET	10.1111/j.1467-8535.2008.00890_16.x	pedagogy;knowledge management;computer science	NLP	-71.26630991151322	-34.643130243117135	3041
4d4d4048ceeb11e2b01d56747dc7cd53ddf01247	advances in information systems and technologies [worldcist'13, olhão, algarve, portugal, march 27-30, 2013]			information system		2013		10.1007/978-3-642-36981-0		AI	-57.69638937960554	-7.0738029191680445	3052
0e3fb0a11ac053ec792b92783e7910c0585dbe99	core manufacturing simulation data - a manufacturing simulation integration standard: overview and case studies	probability theory and statistics;industrial engineering and economy;relational data;mathematics;information model;production engineering human work science and ergonomics;information systems;produktionsteknik;cmsd;other environmental engineering;information technology;systems engineering;simulation;computer and information science;standard;data exchange;mathematical statistics;computational mathematics;industriell teknik och ekonomi;systemteknik;mechanical engineering;standardisation;natural sciences;manufacturing engineering;engineering and technology;produktion och arbetsvetenskap;other information technology;manufacturing;manufacturing engineering and work sciences;matematisk statistik;environmental engineering;optimization systems theory;core manufacturing simulation data;interoperability;ovrig informationsteknik;simulation model;miljoteknik;informationsteknik;optimeringslara systemteori;other computer and information science	Core Manufacturing Simulation Data – a manufacturing simulation integration standard: overview and case studies Yung-Tsun Tina Lee a , Frank H. Riddick a & Björn Johan Ingemar Johansson b a Manufacturing Systems Integration Division , National Institute of Standards and Technology , Gaithersburg, USA b Product and Production Department , Chalmers University of Technology , Gothenburg, Sweden Published online: 21 Jul 2011.	ingemar ragnemalm;simulation;system integration	Y. Tina Lee;Frank Riddick;Björn Johan Ingemar Johansson	2011	Int. J. Computer Integrated Manufacturing	10.1080/0951192X.2011.574154	data exchange;interoperability;integrated computer-aided manufacturing;process development execution system;numerical analysis;information model;relational database;computer science;engineering;artificial intelligence;industrial engineering;simulation modeling;mathematical statistics;database;computer-integrated manufacturing;manufacturing;management;information technology;information system;standardization;manufacturing engineering;mechanical engineering	Robotics	-62.278213712748745	-0.41961745773401166	3053
9feaca6683c77cd48298498d09b30d21e61548e0	mguides, design and usability of a mobile system to assist learning in critical situations	learning guides;web editor;mobile learning;usability	This work presents the usability evaluation of the mGuides system, which emerged as a response to the educational needs of students affected by the earthquake that hit Chile in the year 2010. With this system, teachers generate working guides through an editor, including learning guides and questionnaires for their learners. At the same time, students visualize and complete these working guides on cellular phones. The objective of this work is to present the impact of usability evaluations as part of the process for the development of the mGuides system, contributing mainly to the validation of the functionalities and the detection of errors. The results show that the mGuides system was highly accepted by both teachers and students, and that it is an intuitive and easy-touse tool.	usability	Jaime Sánchez;Matías Espinoza	2011		10.1007/978-3-642-21666-4_46	usability goals;pluralistic walkthrough;web usability;component-based usability testing;cognitive walkthrough;simulation;usability;human–computer interaction;computer science;system usability scale;usability engineering;multimedia;heuristic evaluation;usability lab;usability inspection	HCI	-64.90521227163715	-45.05718516056732	3055
f63116413b645a6290549e5a373e135c91c69672	concise guide to formal methods		The first € price and the £ and $ price are net prices, subject to local VAT. Prices indicated with * include VAT for books; the €(D) includes 7% for Germany, the €(A) includes 10% for Austria. Prices indicated with ** include VAT for electronic products; 19% for Germany, 20% for Austria. All prices exclusive of carriage charges. Prices and other details are subject to change without notice. All errors and omissions excepted. G. O'Regan Concise Guide to Formal Methods	book;formal methods	Gerard O'Regan	2017		10.1007/978-3-319-64021-1	management science;formal methods;computer science	Theory	-58.127354111444724	-15.323321507531329	3056
2d27d44cc948b9676c33c8e1f21023cfa097382f	adaptive qos for educational user created content(ucc)	web based learning environment;user participation;tacit knowledge;collaborative learning;learning environment;knowledge sharing	Until now, the most web-based communication is based on texts or graphics in a collaborative learning context. However, texts have many limitations as a means of communication. The use of multimedia is very useful for effective communication because it helps to deliver nonverbal messages as tacit knowledge. User participation and communication techniques, which are emphasized in Web 2.0, are important for facilitating knowledge sharing. The latest User Created Content (UCC) technique, such as YouTube, Video Blog and Pandora TV, has many advantages for communication and knowledge sharing. In this paper, an adaptive QoS architecture is proposed to use Educational User Created Contents as multimedia and realtime multimedia pedagogically. This paper contributes towards an understanding of how to support adaptive QoS for learning environments in a web-based learning environment utilizing UCC.	quality of service	Hee-Seop Han;SeonKwan Han;Soo-Hwan Kim;Hyeoncheol Kim	2007		10.1007/978-3-540-73011-8_32	collaborative learning;educational technology;computer science;knowledge management;multimedia;world wide web;pedagogy	Vision	-79.7377054197066	-43.346875280748606	3061
3d8ae3c81196d44c705147fc4474fe06d1a835c3	self-organizing maps to find computational thinking features in a game building workshop		Various didactic strategies to develop Computational Thinking (CT) skills have been successful in terms of student engagement and educational outcomes. However, monitoring the learning progress of students is still a hurdle to teachers and researchers. In this context, we explore the use of self-organizing maps for analyzing games produced in a game building workshop offered simultaneously to technical education students in Brazil and to undergraduate students in Computer Engineering in Chile. Metrics from seven CT features present in the games were extracted with the Dr. Scratch tool and used as an input in the training process. The results allowed a clustering analysis considering the identified features and the correlation between learning behaviors. The organization of the map reflected a progressive skill acquisition identified by features present in the developed games. Also, it could be identified that students of both educational levels reached similar levels of CT skill development.	cluster analysis;computation;computational thinking;computer engineering;organizing (structure);self-organization;self-organizing map	A. A. Souza;Thiago Schumacher Barcelos;Roberto Munoz;Ismar Frango Silveira;Nizam Omar;L. A. Silva	2017	2017 XLIII Latin American Computer Conference (CLEI)	10.1109/CLEI.2017.8226407	knowledge management;scratch;self-organizing map;cluster analysis;student engagement;computational thinking;dreyfus model of skill acquisition;computer science;vocational education	HCI	-81.58422510468641	-33.49626667714232	3064
d3df1c2df190116ee83ba0857f2d84e72b9c418d	is small really beautiful? a review of the concept of niches in innovation		ABSTRACTThis article reviews the concept of innovation niches through three categories: strategic niche management (SNM), specialised markets and niches formed as a technology declines. In the literature, innovation niches generate interest from both innovation and marketing perspectives. This review focuses predominately on the former from which the niche types have been adopted and analysed. Mostly, contributions since 1980 have been included, representing the period of academic interest in innovative small firms, while both temporal and locational filters were applied to the study. It is noted that SNM has been proposed as a means to protect potentially useful innovations from full market competition, while specialist niches supply technologies to few customers in more stable environments. Incumbent technologies at the stage of decline may also retreat to niches where they can still remain competitive. Finally, it is suggested that further research on innovation niches would extend our understanding of...		Anne-Marie Coles;Athena Piterou;Anton Sentic	2018	Techn. Analysis & Strat. Manag.	10.1080/09537325.2017.1408907	marketing;environmental resource management;economics;niche;ecological niche	NLP	-78.63678683446604	-9.823943082053837	3065
e05f94ef8b317b532a55cebefe89fb59f0f479d0	opinion analysis of product reviews	automobiles;feature recognition;information extraction;information filtering;conditional random fields;data mining;supervised method;domain knowledge;reviews information filtering internet;hidden markov models;internet;lexical information;product features recognition;feature extraction;data mining feature extraction fuzzy systems research and development organizing information analysis association rules frequency measurement web sites discussion forums;dictionaries;web sites;product review analysis;conditional random field;world wide web;web browsing;reviews;information extraction task;context;world wide web product review analysis web browsing product features recognition information extraction task supervised method conditional random fields lexical information domain knowledge opinionated product feature orientation;opinionated product feature orientation	With more and more reviews on the web, browsing through a mass of the related reviews becomes a heavy work. How to effectively analyzing and organizing these reviews attracts more attention. This paper pursues on the analysis of product reviews. It focuses on the product features that customer commented on and also whether their opinions are positive or negative. Different from the traditional method, we view the product features recognition as an information extraction task. Combined the domain knowledge and lexical information, we adopt the supervised method--Conditional Random Fields to find the opinionated features. For the identification of the opinionated product feature’s orientation, it mainly bases on the domain knowledge, and considers from three levels, including sentence, context and word level. Our experimental results show that the proposed techniques are effective and promising.	conditional random field;information extraction;organizing (structure)	Shu Zhang;Wen-Jie Jia;Yingju Xia;Yao Meng;Hao Yu	2009	2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2009.200	computer science;machine learning;pattern recognition;data mining;conditional random field;information extraction;information retrieval	NLP	-23.050057253633497	-58.19377121495562	3071
9b833c5b7298b9808d4856ac6dba6acf9b4d614c	experiences from the sigcomm 2005 european shadow pc experiment	program committee;shadow program committee;experience report	This note is an informal report about the Shadow Program Commit-tee experiment that I organized for Sigcomm 2005. It (i) discusses the motivation for a Shadow Program Committee (PC), (ii) presents the expected benefit to the community, (iii) explains the process by which it was organized, (iv) gives some statistics on the program that the Shadow PC selected, how much, and why it differed from the real PC's program, and (v) discusses some of the insights from the Shadow PC process.	emoticon;organizing (structure)	Anja Feldmann	2005	Computer Communication Review	10.1145/1070873.1070889	simulation;operations research	Vision	-62.05486235320748	-16.519033321435206	3073
c93c4fcbbda286bc4342f746bfb0251a79213348	a high-fidelity immersive cluster-based driving simulator for transportation safety research	cluster;motion control;virtual reality;driving simulator;vehicle dynamics	There are many challenges to create a high-fidelity immersive driving simulator based on PC clusters with multi-channeled projector support, while still maintaining a high frame rate for complex scenes. This paper describes how such a system was conceived and implemented to support behavioral research on highway safety and operations. The real highway safety research study is used to compare the driver behavior derived from real-world roadway data with data collected in a simulated environment to valid the simulator. The hardware and software architectures are discussed in detail, respectively. Such architectures have been constructed to support upgradeability, scalability, extendibility, and flexibility. The experimental results of the real study are shown in daytime and nighttime, respectively. The conclusions and future work are described in the end.	driving simulator;immersion (virtual reality);scalability;simulation;software architecture;video projector;virtual reality	Duoduo Liao	2006		10.1145/1128923.1128988	embedded system;computer architecture simulator;simulation;engineering;computer graphics (images)	HCI	-38.50427383648495	-41.05221248929511	3074
6c87c3354bbb88d623ced746e9d563c37a325b91	the norwegian national it plan, 1987-1990: whence it came, what it was, and how it ended		In the late 1970s and early 1980s most of the technically advanced nations organized national R&D programs for speeding up the intake of information technologies in industry and society as a whole. In addition, Norway organized a National IT plan that ran for four years from 1987–90. The idea of having a national plan was initiated in 1982–83. This paper shortly covers events of around ten years from 1982 until 1991. There is a short description of the relevant processes and of the central actors, and of the technical and political background where the planning processes took place. There is also a short analysis of why things came about as they came, what the consequences of the plan were, and whether we could have done things differently. The main priority of most of the other national IT plans was to support their computer industries through public financing of relevant research. The Norwegian IT plan came with a wider agenda. Not only was it to be a support plan for the Norwegian IT industry, but it was to be a plan for transforming society as a whole, form the industrial to the post-industrial stage. Therefore, the Norwegian IT plan can be seen as a result of negotiations among the “narrow” industrial interests and the wider interests of the emerging information society.		Arne Sølvberg	2010		10.1007/978-3-642-23315-9_29		AI	-74.92793645977366	-10.720050207388333	3077
b7954111b95e667fcc303d6eeccf98f9f760216a	taking empirical studies seriously: the principle of concentration and the measurement of welfare and inequality	empirical study;social welfare;satisfiability	The paper investigates the implications of empirical studies by Amiel and Cowell (J Public Econ 47:3–26, 1992) of the public’s attitude towards inequality. It demonstrates that the value judgments concerning the redistribution of income which have been revealed in these studies can be represented by the principle of concentration. A concentration is a redistribution of income which reduces the distance between each income and the average income in the same proportion. Imposing this principle and some other basic properties the paper characterizes several families of social welfare orderings which imply generalized Atkinson inequality measures. They do not necessarily satisfy the principle of progressive transfers.	social inequality	Udo Ebert	2009	Social Choice and Welfare	10.1007/s00355-008-0339-3	economics;income;public economics;social welfare;income inequality metrics;mathematics;microeconomics;mathematical economics;empirical research;welfare economics;satisfiability	ECom	-7.437349815754031	-2.1635417280786724	3081
2dd9a3ffde3221d0b43a7b12db3bb69f03a95a96	on emerging entity detection		While large Knowledge Graphs (KGs) already cover a broad range of domains to an extent sufficient for general use, they typically lack emerging entities that are just starting to attract the public interest. This disqualifies such KGs for tasks like entity-based media monitoring, since a large portion of news inherently covers entities that have not been noted by the public before. Such entities are unlinkable, which ultimately means, they cannot be monitored in media streams. This is the first paper that thoroughly investigates all types of challenges that arise from out-of-KG entities for entity linking tasks. By large-scale analytics of news streams we quantify the importance of each challenge for real-world applications. We then propose a machine learning approach which tackles the most frequent but least investigated challenge, i.e., when entities are missing in the KG and cannot be considered by entity linking systems. We construct a publicly available benchmark data set based on English news articles and editing behavior on Wikipedia. Our experiments show that predicting whether an entity will be added to Wikipedia is challenging. However, we can reliably identify emerging entities that could be added to the KG according to Wikipedia’s own notability criteria.	benchmark (computing);entity linking;experiment;f1 score;kasparov's gambit;machine learning;sensor;wikipedia	Michael Färber;Achim Rettinger;Boulos El Asmar	2016		10.1007/978-3-319-49004-5_15	data mining;streams;information retrieval;entity linking;notability;novelty detection;text annotation;weak entity;media monitoring;computer science;analytics	Web+IR	-24.430501881591677	-59.55336653910007	3083
48a54df22a6e7dbfff70922f83461a062488e7cd	design on the fault diagnostic system based on virtual instrument technique	virtual instrumentation;performance evaluation;virtual instrumentation fault diagnosis military computing military equipment performance evaluation ships test equipment;vi technology;diagnostic ratiocination;military equipment;virtual instrument;designs of fault diagnosis system vi technology diagnostic ratiocination;ships;designs of fault diagnosis system;fault diagnosis system;test equipment;instruments hardware system testing computer displays fault diagnosis databases software measurement chemical technology software testing chemical analysis;warship equipment fault diagnostic system virtual instrument technique shipboard equipment testing modularization database based design concept odbc technique grey diagnosis method state prediction;military computing;fault diagnosis	Virtual Instrument (VI) is one of the most prevalent technologies in the domain of testing, control and fault diagnosis systems, etc. In order to update entirely the means of the equipment testing for shipboard equipment, the fault diagnostic system for shipboard equipment is developed, based on VI technology, Delphi and database. The performance and constitutes of VI are introduced briefly. The modularization and universalization are proposed in its database-based design concept, realizing the design of software and hardware. The ODBC technique is applied for the interconnection of databases to ensure the generality and flexibility of the system. The aim of this design is to resolve the problems existing in the usage of testing equipments. The system mode the best of VI platform and grey diagnosis method, broke through conventional check diagnosis patterns for warships equipment, solved the problems of state prediction and trouble-mode recognition of warships equipment. It has been proved from the application that the system has merits both the testing speed and high accuracy.	interconnection;open database connectivity	Shijun Lv;Minghu Zhang;Youfeng Li;Xiaojuan Yu	2009	2009 Second International Workshop on Knowledge Discovery and Data Mining	10.1109/WKDD.2009.138	embedded system;simulation	Robotics	-28.860208120400245	-5.844398407322028	3088
6265822ef23ff99dfb57e47fb9d54d354fd91509	vibrotactile signal generation from texture images or attributes using generative adversarial network		Providing vibrotactile feedback that corresponds to the state of the virtual texture surfaces allows users to sense haptic properties of them. However, hand-tuning such vibrotactile stimuli for every state of the texture takes much time. Therefore, we propose a new approach to create models that realize the automatic vibrotactile generation from texture images or attributes. In this paper, we make the first attempt to generate the vibrotactile stimuli leveraging the power of deep generative adversarial training. Specifically, we use conditional generative adversarial networks (GANs) to achieve generation of vibration during moving a pen on the surface. The preliminary user study showed that users could not discriminate generated signals and genuine ones and users felt realism for generated signals. Thus our model could provide the appropriate vibration according to the texture images or the attributes of them. Our approach is applicable to any case where the users touch the various surfaces in a predefined way.		Yusuke Ujitoko;Yuki Ban	2018		10.1007/978-3-319-93399-3_3	generative grammar;computer vision;adversarial system;haptic technology;computer science;artificial intelligence	Vision	-44.71345875080468	-44.0972709328297	3090
8b5af62da2c096050693a8b2e1cbd9e0e8f48af0	rosody/parse scoring and its application in atis		"""Prosodic patterns provide important cues for resolving syntactic ambiguity, and might he used to improve the accuracy of automatic speech understanding. With this goal, we propose a method of scoring syntactic parses in terms of observed prosodic cues, which can be used in ranking sentence hypotheses and associated parses. Specifically, the score is the probability of acoustic features of a hypothesized word sequence given an associated syntactic parse, based on acoustic and """"language"""" (prosody/syntax) models that represent probabilities in terms of abstract prosodic labeis. This work reports initial efforts aimed at extending the algorithm to spontaneous speech, specifically the ATIS task, where the prosody/parse score is shown to improve the average rank of the correct sentence hypothesis. 1. I N T R O D U C T I O N Human listeners bring several sources of information to bear in interpreting an utterance, including syntax, semantics, discourse, pragmatics and prosodic cues. Prosody, in particular, provides information about syntactic structure (via prosodic constituent structure) and information focus (via phrasal prominence), and is encoded in the acoustic signal in terms of timing, energy and intonation patterns. Since computer knowledge representations are not as sophisticated as human knowledge, utterances that are straightforward for a human to interpret may be """"ambiguous"""" to an automatic speech understanding system. For this reason, it is useful to include as many knowledge sources as possible in automatic speech understanding, and prosody is currently an untapped resource. In fact, some syntactic ambiguities can be resolved by listeners from prosody alone [1]. One way to incorporate prosody in speech understanding is to score the expected prosodic structure for each candidate sentence hypothesis and syntactic parse in relation to the observed prosodic structure. In a speech understanding system where multiple sentence hypotheses are passed from recognition to natural language processing, the prosody/parse score could be used to rank hypotheses and associated parses, directly or in combination with other scores. The parse scoring approach was proposed in previous work [2], where automatically detected prosodic phrase breaks were scored either in terms of their correlation with prosodic structure predicted from parse information or in terms of their likelihood according to a probabilistic prosody/syntax model. Recently, the parse scoring approach was reformulated [3] to avoid explicit recognition of prosodic patterns, which is a sub-optimal intermediate decision. Specifically, the new score is the probability of a hypothesized word sequence and associated syntactic parse given acoustic features, where both an acoustic model and a """"language"""" (prosody/syntax) model are used to represent the probability of utterance, analogous to speech recognition techniques. The parse scoring formalism was also extended to incorporate phrasal prominence information, in addition to phrase breaks. In previous work, we demonstrated the feasibility of using parse scoring to find the correct interpretation in a corpus of professionally read ambiguous sentences. In this work, we use the parse scoring approach to rerank a speech understanding system's N-best output, specifically in the ATIS task domain, in order to improve sentence understanding accuracy. In the following section, we describe the parse scoring system and the probabilistic acoustic and prosody/syntax models. Next, we discuss issues that arose in extending the parse scoring algorithm to the ATIS task, including several modifications needed to handle new problems associated with spontaneous speech and the new parser and recognizer. We then present experimental results for the task of reranking the top N recognizer hypotheses and associated parses using prosody/parse scores. Finally, we discuss the implications of the results for future work. 2. P A R S E S C O R I N G 2.1. G e n e r a l F o r m a l i s m The goal of this work is to reorder the set of N-best recognizer hypotheses by ranking each hypothesis and associated parse in terms of a prosody score. More specifically, the prosody-parse score is the probability of a sequence of acoustic observations x = { z l , . . . , zn} given the hypothesized parse, p(x[parse), where x is a sequence of"""	acoustic cryptanalysis;acoustic model;algorithm;ambiguous grammar;automatic transmitter identification system (television);finite-state machine;natural language processing;parse tree;parsing;phrasal template;semantic prosody;semantics (computer science);speech recognition;spontaneous order	N. M. Veilleuz;Mari Ostendorf	1993				NLP	-19.907521284530862	-81.77326081675893	3091
a5d628ee7044c2c7d44a0d68ecb743495dd7091d	preechvis: visual profiling using multiple-word combinations		Words in the corpus include features and information, and the visualizing of such words can improve the user’s understanding of them. Words in text corpus may be consist of one-word or they may be a combination of words that together, constitute a word. The latter is referred to as a multiword expression. And if we analyze both single word and multiword with visualization, we can get more accurate results and more information than we analyze only single word from corpus. An interactive visualization can be useful for analyzing multiword expressions, because the following features are of interest to linguistics scholars: (1) Showing the combinatory POS pattern of a hierarchical form, (2) exploring results according to the POS pattern, and (3) searching the source corpus for the analysis-result verification. Therefore, we propose PreechVis, an interactive-visualization tool that includes all of the requisite functions for an analysis for which multiple words (http://202.30.24.167:3010/PreechVisMWE) are utilized. For the present study, we used a total of 957 speeches of 43 U.S. Presidents from George Washington to Barack Obama as the corpus data. PreechVis is divided into two views. In the first view, the system consists of a combination of Sunburst and RadVis. Through the circular Sunburst, we present the POS and its combination patterns for each gram. In RadVis, the Presidents were positioned according to their frequency value. In addition, when the President was selected, the frequency value was displayed on Sunburst to improve the user’s understanding. In the second view, the user can simultaneously confirm and verify the details of the result using the Wordcloud. The two different views are synchronized with each other and are changed by the selected grams, issues, and Presidents. In the experiments and case studies on the U.S.-President speech data, we verified the effectiveness and usability of PreechVis.	combinatory logic;corpus linguistics;experiment;grams;interactive visualization;n-gram;parsing expression grammar;regular expression;tag cloud;text corpus;usability	Seongmin Mun;Gyeongcheol Choi;Guillaume Desagulier;Kyungwon Lee	2018		10.5220/0006615500970107	information retrieval;machine learning;visualization;profiling (computer programming);interaction design;usability;expression (mathematics);interactive visualization;cluster analysis;computer science;artificial intelligence;sunburst	NLP	-32.40221291949845	-60.7456690690494	3092
28a1181dcddcf698e9467853364bc3c962942599	some simple algorithms for structural comparison	multivariate analysis;multivariate methods;text analysis;structure comparison;multivariate method;organizational form;social network analysis;algorithms;structural comparison;graph labeling	Structural comparison (i.e., the simultaneous analysis of multiple structures) is a problem which arises frequently in such diverse arenas as the study of organizational forms, social network analysis, and automated text analysis. Prior work has demonstrated the applicability of a range of standard multivariate analysis procedures to the structural comparison problem. Here, some simple algorithms are provided which elucidate several of these methods in an easily implemented form.	algorithm	Carter T. Butts;Kathleen M. Carley	2005	Computational & Mathematical Organization Theory	10.1007/s10588-005-5586-6	econometrics;text mining;social network analysis;social science;graph labeling;computer science;machine learning;data mining;mathematics;multivariate analysis	Vision	-9.375753501013866	-46.754733749260275	3097
254166b4d7ec092a8c44f3e9d8a3f5ed25f75e58	contextual factors and adaptative multimodal human-computer interaction: multi-level specification of emotion and expressivity in embodied conversational agents	sensibilidad contexto;modele comportement;modelizacion;animacion por computador;television;anotacion;behavior model;interfase usuario;factor humano;multiagent system;belief;embodiment;context aware;personality;user interface;computer model;modelo comportamiento;personnalite;specification;conversacion;annotation;multimodal human computer interaction;modelisation;croyance;senal video;signal video;emotion emotionality;especificacion;human factor;agent intelligent;personalidad;intelligent agent;conversation;agent systems;video signal;emotion emotivite;interface utilisateur;context dependent;encarnacion;emocion emotividad;agente inteligente;embodied conversational agent;sensibilite contexte;incarnation;creencia;computer animation;sistema multiagente;modeling;facteur humain;verbal behavior;systeme multiagent;animation par ordinateur	In this paper we present an Embodied Conversational Agent (ECA) model able to display rich verbal and non-verbal behaviors. The selection of these behaviors should depend not only on factors related to her individuality such as her culture, her social and professional role, her personality, but also on a set of contextual variables (such as her interlocutor, the social conversation setting), and other dynamic variables (belief, goal, emotion). We describe the representation scheme and the computational model of behavior expressivity of the Expressive Agent System that we have developed. We explain how the multi-level annotation of a corpus of emotionally rich TV video interviews can provide context-dependent knowledge as input for the specification of the ECA (e.g. which contextual cues and levels of representation are required for enabling the proper recognition of the emotions).	computational model;context-sensitive language;dialog system;embodied agent;human–computer interaction;multimodal interaction;simulation;text corpus	Myriam Lamolle;Maurizio Mancini;Catherine Pelachaud;Sarkis Abrilian;Jean-Claude Martin;Laurence Devillers	2005		10.1007/11508373_17	behavioral modeling;systems modeling;computer science;artificial intelligence;human factors and ergonomics;belief;context-dependent memory;computer animation;personality;television;user interface;social psychology;specification;intelligent agent	AI	-53.1362239635711	-47.43112706223264	3103
2f60913316db8d690c62cacbb23eccafc9ea4831	improving education experience with augmented reality (ar)	teaching augmented reality computer aided instruction;ar learning method education experience augmented reality education process teaching experience learning experience learning material learning activities aravet project;computers visualization augmented reality education software real time systems neurons	In the modern world, information is everything. It is important that it can be accessed from anywhere and at any time. What is even more important is that information must be relevant to the user and presented in such a manner that it is easily understood. Emerging technologies, such as augmented reality (AR) might within short period of time be widely accepted, as smart-phones are today. If this happens, it will probably change the way we perceive information and our reality. AR is not hype any more - it is a solid technology that is already used in some creative applications. One area which might significantly benefit in the future from this technology is the education process. AR tools could guide students through learning process in enhanced way, as AR can upgrade traditional books with a digital layer. We think it will improve both, teaching and learning experience, and bring interactive dimension into the whole picture. We also predict that this new layer will encompass several senses which could speed up memorization process. Furthermore, AR learning method might raise common understanding of the learning material. Moreover, learning activities could be supervised by a mentor or automated process which might also lead to a lower school dropout rate. Our still-in-progress ARAVET project is exploring mentioned predictions about AR learning method. We will present the results we have so far.	augmented reality;book;digital data;dropout (neural networks);interaction;machine learning;mind;next-generation network;personalization;sensor;smartphone;user experience;user interface	Bojan Kraut;Jelena Jeknic	2015	2015 38th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)	10.1109/MIPRO.2015.7160372	computer-mediated reality;simulation;human–computer interaction;computer science;mixed reality;multimedia	HCI	-69.39069465300594	-38.4067200666209	3105
0ef1d7acf85fe38dddb3c7038742583cc700d888	pmb investments: an enterprise system implementation	enterprise system	This case describes the implementation of an enterprise information system at the printed materials division of a multinational investment company. There are several issues in the implementation that are worthy of class discussion. These issues include enterprise system implementation rationale and investment justification, software and consultant selection, business process reengineering, change and project management, and evaluation of enterprise system success.	enterprise system;pmb	Nancy A. Bagranoff;Peter C. Brewer	2003	J. Information Systems	10.2308/jis.2003.17.1.85	functional software architecture;enterprise system;enterprise application integration;enterprise systems engineering;enterprise software;nist enterprise architecture model;computer science;knowledge management;architecture domain;operations management;integrated enterprise modeling;digital firm;enterprise architecture management;enterprise data management;enterprise architecture;enterprise integration;management;enterprise planning system;enterprise information security architecture;enterprise information system;enterprise life cycle	OS	-70.56882118854298	2.7004045794760154	3109
524df39db33c554d65d513ec870593584b9460f1	a rationale-driven team plan representation for autonomous intra-robot replanning*		For autonomous multi-robot teams, the individual team members are tasked with completing their assigned tasks as defined by a team plan provided by a centralized team planner. However in complex dynamic domains, the team plans are generated by the team planner with assumptions due to the complexity of modeling the domain. Failures in execution are therefore inevitable for the team members, and as such, replanning will occur for the team. In this paper, we introduce a rationale-driven team plan representation that provides rationales on why actions were chosen by the team planner. During a failure, the individual team members autonomously use our described intra-robot replanning algorithm to select all applicable replan policies for a given rationale. We then describe a method to learn the predicted cost of each replan policy, given a state of the environment, in order for the individual robots to select the lowest costing replan policy to improve team performance.		Philip Cooksey;Manuela M. Veloso	2018	2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	10.1109/IROS.2018.8593765	control engineering;task analysis;global positioning system;planner;computer science;operations research;robot;activity-based costing;state of the environment	Robotics	-18.88192872897891	-8.315216971819353	3125
4a234b8c10a5cc794b8c004aa5cd88e6a4d27968	a comparison of gaussian distribution and polynomial classifiers in a hidden markov model based system for the recognition of cursive script	employment;symbol generation;image recognition;polynomial classifiers;handwriting recognition;gaussian distribution polynomials hidden markov models handwriting recognition image recognition vector quantization text recognition statistical distributions employment target recognition;hidden markov model;symbol sequence;handwriting recognition systems;cursive script recognition;polynomials;approximation theory;statistical distributions;hidden markov model based system;hidden markov models;vector quantization;statistical analysis;symbol generation gaussian distribution polynomial classifiers hidden markov model based system cursive script recognition handwriting recognition systems vector quantizer symbol sequence semi continuous hidden markov models statistical distribution;target recognition;generalized gaussian distribution;vector quantizer;text recognition;vector quantisation;semi continuous hidden markov models;statistical distribution;gaussian distribution;statistical analysis gaussian distribution hidden markov models handwriting recognition vector quantisation approximation theory polynomials	Handwriting recognition systems based on hidden Markov models commonly use a vector quantizer to get the required symbol sequence. In order to get better recognition rates semi-continuous hidden Markov models have been applied. Those recognizers need a soft vector quantizer which superimposes a statistical distribution for symbol generation. In general, Gaussian distributions are applied. A disadvantage of this technique is the assumption of a specific distribution. No proof can be given whether this presupposition holds in practice. Therefore, the application of a method which employs no model of a distribution may achieve some improvements. The paper presents the employment of a polynomial classifier as a replacement of a Gaussian classifier in the handwriting recognition system. The replacement improves the recognition rate significantly, as the results show.	hidden markov model;markov chain;polynomial	Jürgen Franke;Joachim M. Gloger;Alfred Kaltenmeier;Eberhard Mandler	1997		10.1109/ICDAR.1997.620552	probability distribution;speech recognition;computer science;machine learning;hidden semi-markov model;pattern recognition;hidden markov model;statistics	Vision	-20.066236407945684	-92.19721887821294	3131
1e7e0f3af670e2d36e4ae9cb8b24f19f7355b66e	opinion holder extraction from author and authority viewpoints	opinion holder;opinion extraction;ntcir	Opinion holder extraction research is important for discriminating between opinions that are viewed from different perspectives. In this paper, we describe our experience of participation in the NTCIR-6 Opinion Analysis Pilot Task by focusing on opinion holder extraction results in Japanese and English. Our approach to opinion holder extraction was based on the discrimination between author and authority viewpoints in opinionated sentences, and the evaluation results were fair with respect to the Japanese documents.	information extraction;keyword extraction	Yohei Seki	2007		10.1145/1277741.1277936	data mining;management science	NLP	-37.27398675024068	-69.2512841577834	3132
2f5014363f4dcaec970ce15219e4ccaac11dbbb7	integration, provenance, and temporal queries for large-scale knowledge bases	query processing;temporal;optimization;computer science;knowledge base	Knowledge bases that summarize web information in RDF triples deliver many benefits, including support for natural language question answering and powerful structured queries that extract encyclopedic knowledge via SPARQL. Large scale knowledge bases grow rapidly in terms of scale and significance, and undergo frequent changes in both schema and content. Two critical problems have thus emerged: (i) how to support temporal queries that explore the history of knowledge bases or flash-back to the past; (ii) how to integrate knowledge from difference sources and improve the quality of integrated knowledge base while preserving the provenance information. In this dissertation, we propose a framework that supports knowledge integration, temporal query evaluation and user-friendly interfaces for large-scale knowledge bases. Towards this goal, we make the following contributions:(i) We propose SPARQLT, a temporal extension of structured query language SPARQL based on a point temporal model which simplifies the expression of temporal joins and eliminates the need for temporal coalescing. This approach makes possible an end-user interface HKB (Historical Knowledge Browser) where users can browse the evolution history of knowledge bases and express historical queries via simple by-example conditions in the infoboxes of Wikipedia pages.(ii) We have designed and implemented RDF-TX (RDF Temporal eXpress), an efficient system for managing temporal RDF data and evaluating SPARQLT queries. RDF-TX takes advantage of compressed Multiversion B+ trees to achieve fast evaluation of temporal queries. The experimental result demonstrates that our indexing and query optimization techniques deliver superior performance over other systems.(iii) We propose a framework for knowledge extraction and integration. We first introduce IBMiner, a novel NLP-based system that derives knowledge bases from free text and preserves the provenance of extracted triples. IBminer uses a deep NLP-based approach to extract subject-attribute-value triples from free text, and maps the attributes to those introduced in existing knowledge bases. Then we integrate public knowledge bases with the knowledge base generated by IBMiner into one of superior quality and coverage, called IKBStore. User-friendly interfaces are provided to manage the knowledge in IKBStore while maintaining provenance information.		Shi Gao	2016			knowledge base;computer science;knowledge-based systems;open knowledge base connectivity;data mining;database;knowledge extraction;information retrieval	DB	-36.188895985371516	3.453723301949729	3133
3fca9cfd207fee838bbf7a3a8dcfe757cb5d4f81	persistent homology for the evaluation of dimensionality reduction schemes	methodology and techniques;interaction techniques;i 3 6 computer graphics methodology and techniques interaction techniques;i 3 6 computer graphics;categories and subject descriptors according to acm ccs	High-dimensional data sets are a prevalent occurrence in many application domains. This data is commonly visualized using dimensionality reduction (DR) methods. DR methods provide e.g. a two-dimensional embedding of the abstract data that retains relevant high-dimensional characteristics such as local distances between data points. Since the amount of DR algorithms from which users may choose is steadily increasing, assessing their quality becomes more and more important. We present a novel technique to quantify and compare the quality of DR algorithms that is based on persistent homology. An inherent beneficial property of persistent homology is its robustness against noise which makes it well suited for real world data. Our pipeline informs about the best DR technique for a given data set and chosen metric (e.g. preservation of local distances) and provides knowledge about the local quality of an embedding, thereby helping users understand the shortcomings of the selected DR method. The utility of our method is demonstrated using application data from multiple domains and a variety of commonly used DR methods.	algorithm;application domain;approximation;computer graphics;data point;dimensionality reduction;eurographics;experiment;homology (biology);institute for operations research and the management sciences;john d. wiley;persistent homology;perturbation theory	Bastian Rieck;Heike Leitte	2015	Comput. Graph. Forum	10.1111/cgf.12655	computer vision;computer science;artificial intelligence;theoretical computer science;machine learning;data mining;mathematics;geometry;algorithm;statistics;computer graphics (images)	ML	-27.054565561467776	-35.22798195404424	3139
2946ca62cd1976580957a31d7dd7566ba307a565	the personal software process in the classroom: student reactions (an experience report)	computer program;surveys personal software process classroom student reactions experience report software product quality software development process quality computer program defects personal productivity beginning college students introductory programming courses laboratory assignments programming project student attitudes programming language learning;software process improvement;programming language;college students;experience report;introductory programming;information systems software quality application software databases productivity springs telecommunications programming profession educational institutions position measurement;computer science education;educational courses;student attitude;psp;time log;personal software process;programming;defect log;software quality;programming course;software process improvement software quality computer science education programming educational courses	Most people would agree that the quality of a product is related to the quality of the process used to develop that product. The quality of a computer program is often measured by the number of defects it contains. The Personal Software Process was developed to help programmers measure and improve their personal productivity. A subset of the Personal Software Process has been suggested as appropriate for beginning college students in introductory programming courses. This subset has been used over the past two years in several sections of a large first and second semester programming course, with mixed success. Students recorded data during the development of their lab assignments and major programming project, and submitted these along with their programs. Surveys were taken at the end of each course to determine student attitudes toward the Personal Software Process. Many students failed to recognize the benefits of such a process, and felt that it just took time away from learning the programming language. This paper explores the results of these surveys.	computer program;personal software process;programmer;programming language;software development process	Susan K. Lisack	2000		10.1109/CSEE.2000.827035	team software process;computer science;software engineering;multimedia;computer engineering	SE	-83.10199887744946	-34.66757458044703	3144
9fa39f58635cc9566f034ec55744ffc45c0a71c5	hashing supported iterative mapreduce based scalable sbe reduct computation		Feature Selection plays a major role in preprocessing stage of Data mining and helps in model construction by recognizing relevant features. Rough Sets has emerged in recent years as an important paradigm for feature selection i.e. finding Reduct of conditional attributes in given data set. Two control strategies for Reduct Computation are Sequential Forward Selection (SFS), Sequential Backward Elimination(SBE). With the objective of scalable feature seletion, several MapReduce based approaches were proposed in literature. All these approaches are SFS based and results in super set of reduct i.e. with redundant attributes. Even though SBE approaches results in exact Reduct, it requires lot of data movement in shuffle and sort phase of MapReduce. To overcome this problem and to optimize the network bandwidth utilization, a novel hashing supported SBE Reduct algorithm(MRSBER_Hash) is proposed in this work and implemented using Iterative MapReduce framework of Apache Spark. Experiments conducted on large benchmark decision systems have empirically established the relevance of proposed approach for decision systems with large cardinality of conditional attributes.	computation;hash function;mapreduce	U. Venkata Divya;P. S. V. S. Sai Prasad	2018		10.1007/978-3-319-72344-0_13	scalability;machine learning;cardinality;theoretical computer science;distributed computing;reduct;rough set;sort;feature selection;computer science;hash function;artificial intelligence;in shuffle	Crypto	-5.078330848297312	-38.34201494791904	3145
29a4ac13df517f6b06024188dccf39a4314595bf	semi-automatic identification of counterfeit offers in online shopping platforms		Product counterfeiting in online platforms is an increasingly serious problem causing estimated losses of billions of dollars every year. The huge number of online shops and offered products call for largely automated approaches to identify likely counterfeits, although identifying counterfeits is very difficult even for humans. The authors propose the adoption of a semiautomatic workflow to inspect product offers in online platforms and to determine likely counterfeit offers based on different criteria. Such suspicious offers are to be presented to a domain expert for manual verification. The workflow includes steps to match and cluster similar product offers, and to assess the counterfeit suspiciousness based on different criteria. The goal is to support the periodic identification of many counterfeit offers with a limited amount of manual effort. The authors also present a preliminary evaluation of the proposed approach on a case study using the eBay platform.	automatic identification and data capture;cluster analysis;online shopping;product type;semiconductor industry;subject-matter expert;trust (emotion)	Christian Wartner;Patrick Arnold;Erhard Rahm	2015	CoRR		marketing;advertising;world wide web;commerce	ML	-33.7467057090209	-17.898531006949348	3146
7aae760aa0730d484ece5bdb8b1baa39f5f75fce	in memoriam: edsger w. dijkstra 1930-2002	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;ciencias basicas y experimentales;tecnologias	"""E dsger Wybe Dijkstra, a noted pioneer of the science and industry of computing, died August 6 at his home in Nuenen, The Netherlands. Dijkstra was the 1972 recipient of the ACM Tur-ing Award, often viewed as the Nobel Prize for computing. He was a member of the Netherlands Royal Academy of Arts and Sciences, a member of the American Academy of Arts and Sciences, and a Distinguished Fellow of the British Computer Society. Foundation of Japan recognized Dijkstra """" for his pioneering contributions to the establishment of the scientific basis for computer software through creative research in basic software theory, algorithm theory, structured programming, and semaphores. """" Dijkstra is renowned for the insight that mathematical logic is and must be the basis for sensible computer program construction and for his contributions to mathematical methodology. He is responsible for the idea of building operating systems as explicitly synchronized sequential processes, for the formal development of computer programs, and for the intellectual foundations for the disciplined control of non-determinacy. He is well known for his amazingly efficient shortest path algorithm and for having designed and coded the first Algol 60 compiler. He was the celebrated leader in the abolition of the GOTO statement from programming. Dijkstra was a prodigious writer. His entire collection of over 1,300 written works was digitally scanned and is accessible at www.cs.utexas.edu/users/EWD. He corresponded regularly with hundreds of friends and colleagues over the years—not by email but by conventional postal mail. He emphatically preferred the fountain pen to the computer in producing his scholarly output and letters. Dijkstra was notorious for his wit, eloquence, and way with words. Consider some of his classic remarks: """" The question of whether computers can think is like the question of whether submarines can swim. """" His advice to a promising researcher, who"""	acm turing award;algol 60;academy;compiler;computer program;dijkstra prize;dijkstra's algorithm;email;formal methods;goto;operating system;pen computing;postal;semaphore (programming);shortest path problem;structured programming;system wide information management	Robert S. Boyer;Wim H. J. Feijen;David Gries;C. A. R. Hoare;Jayadev Misra;J. Moore;H. Richards	2002	Commun. ACM	10.1145/570907.570921		Theory	-60.24510758645893	-20.44515823835255	3148
2407b24093a02442f6d531b1e456780eca3a4aeb	impact of media and interaction variety on student attitudes in a web-based undergraduate course	student attitude		web application	Hsin-Liang Chen;J. Patrick Williams	2006		10.1002/meet.14504301239	computer science;multimedia	NLP	-71.59792561963685	-35.52505306941953	3149
96a9c7afd1d60d29824c353a77c6011f7ed43b05	climate change: a grand software challenge	research agenda;climate change;computer model;control system;human activity	Software is a critical enabling technology in nearly all aspects of climate change, from the computational models used by climate scientists to improve our understanding of the impact of human activities on earth systems, through to the information and control systems needed to build an effective carbon-neutral society. Accordingly, we, as software researchers and software practitioners, have a major role to play in responding to the climate crisis. In this paper we map out the space in which our contributions are likely to be needed, and suggest a possible research agenda.	computational model;control system;information and computation	Steve M. Easterbrook	2010		10.1145/1882362.1882383	engineering;control system;management science;climate change	SE	-76.0958014649582	-9.856191138650297	3158
d91fb99f9a2af21dd33bdc78c9f7fbed090e2dcc	animal-like behavior design of small robots by consciousness-based architecture	robot movil;hierarchical system;architecture systeme;comportement;mobile robot;systeme hierarchise;robotics;sistema jerarquizado;software architecture;human interface;robot mobile;conducta;consciousness;robotica;conscience;arquitectura sistema;computer control;robotique;conciencia;behavior;system architecture;hierarchical model;autonomous robot;moving robot;spatial information;coordinate system	This paper proposes an aproach to designing animal-like behavior of autonomous robots with use of a five-layered hierarchical model of the relation between consciousness and behavior. The hierarchy of behavior includes reflex motion, detour, and a limited use of temporal and spatial information of environments. The corresponding consciousness has an emotion-valued coordinate system, stably lasting emotion that enables an animal to detour an obstacle for a prey, and symbolic information on time and space. The basic idea of the software architecture realizing the above model of consciousness and behavior is that a level in the hierarchy of consciousness is activated when an action on the immediately lower level is obstructed and that the activated level of consciousness selects and drives a higher behavior. With this software architecture, all the five levels of behavior were successfully shown by experiment with the use of two small mobile robots. Their instantaneous consciousness is visualized on the screen of a host computer controling robot motion and the screen image of the robot's consciousness works to design behaviors as a bilateral human interface.	altered level of consciousness;autonomous robot;bilateral filter;hierarchical database model;host (network);mobile robot;prey;software architecture;user interface	Tadashi Kitamura	1997	Advanced Robotics	10.1163/156855398X00190	mobile robot;software architecture;simulation;computer science;engineering;artificial intelligence;coordinate system;consciousness;conscience;robotics;behavior	Robotics	-35.1272922977756	-26.738943508842898	3159
39bb4343a419d22a7d29f7a62a1cfe3bd5ac85c3	proceedings of the 1st workshop on natural language for artificial intelligence co-located with 16th international conference of the italian association for artificial intelligence (ai*ia 2017), bari, italy, november 16th - to - 17th, 2017			artificial intelligence;natural language		2017				Robotics	-55.24817049947472	-10.48519046334041	3162
ebd6c3f659c881036abbc7dadb456496f5cf0e72	evidence-based modelling of hybrid organizational strategies	nonparametric;strategy;data analysis;dempster shafer theory;structures;artificial intelligence;computational organization theory;carbs	Organizations frequently adopt multiple strategies to satisfy conflicting and competing goals. Modeling the organizational characteristics associated with such hybrid strategies is an important challenge for organization scientists. This study proposes the use of a novel evidence-based computational approach to the ambiguous classification of organizations (N-state Classification and Ranking Belief Simplex or NCaRBS) to model hybrid organizational strategies. Drawing on the Dempster–Shafer theory of evidence methodology, the computational mechanics of NCaRBS are illustrated by modelling hybrid configurations of Miles and Snow’s (Organizational strategy, structure and process, 1978) classic strategic stances: prospecting, defending and reacting. Analysis is carried out using data on the characteristics of over 100 organizations. The results show that NCaRBS is uniquely able to demonstrate the full range of ambiguity in the relationships between contingent organizational characteristics. Further potential applications of NCaRBS in the field of computational and mathematical organization theory are discussed.	artificial neural network;computational and mathematical organization theory;computational mechanics;contingency (philosophy);equifinality;nonlinear system;organizational behavior;strategic management	Malcolm J. Beynon;Rhys Andrews;George A. Boyne	2015	Computational & Mathematical Organization Theory	10.1007/s10588-014-9174-5	psychology;nonparametric statistics;social science;simulation;dempster–shafer theory;strategy;computer science;artificial intelligence;structures;mathematics;management science;sociology;data analysis;management;operations research;statistics	Web+IR	-23.230207963138184	-14.363634420005473	3164
e144058b2831d194952776473860e31d662752b6	knowledge in dialogue: empowerment and learning in public libraries	libraries;social inclusion;learning style;learning;research design;social space;knowledge management;knowledge society;cultural capital;empowerment;denmark;ethnic minorities;public libraries;design methodology	Purpose – The demand for learning is constantly increasing in transcultural knowledge societies. This paper aims to consider the impact of learning concepts, as developed by Danish libraries, and the way they relate to mutual recognition and social inclusion of ethnic minority groups.Design/methodology/approach – Conducting research on open social spaces as libraries and learning labs in libraries implies a multiple research design along with a differentiated analytical framework.Findings – Libraries in multicultural districts will be able to contribute to the fulfilment of integration purposes more effectively if they cease to be bound to the concept of information. In transformative and cross‐cultural learning contexts, the concept of knowledge should be employed.Practical implications – Studying activities in libraries still need to be delimited from learning in schools. Enhancing multicultural learning with focus on learning styles, which permits a mutual reflection of significant symbol systems, will...	library (computing);public library	Hans Elbeshausen	2007	J. Inf., Comm, Ethics in Society	10.1108/14779960710837597	educational technology;social learning;empowerment;social science;social exclusion;design methods;knowledge management;experiential learning;learning sciences;sociology;active learning	NLP	-74.59234284794915	-35.534373371040374	3168
d89673276896421c5b84d859fa1f555d4285661a	event annotation schemes and event recognition in spanish texts	spanish text;different proposal;annotated corpus;good event identification agreement;best result;automatic recognition;annotation scheme;proposed scheme;event recognition;event annotation scheme;annotated text;manual annotation	spanish text;different proposal;annotated corpus;good event identification agreement;best result;automatic recognition;annotation scheme;proposed scheme;event recognition;event annotation scheme;annotated text;manual annotation		Dina Wonsever;Aiala Rosá;Marisa Malcuori;Guillermo Moncecchi;Alan Descoins	2012		10.1007/978-3-642-28601-8_18	natural language processing;speech recognition;computer science;data mining	NLP	-26.00258395197942	-74.94886154134963	3182
42528a9ae0fb0cc491a78e6018705ed2e438508d	cpp-sns: a solution to influence maximization problem under cost control	influence maximization;social networking online advertising data processing;advertising data processing;cost control;social network;cost control social network viral marketing influence maximization;spread function cpp sns cost control viral marketing online social network advertising information propagation influence maximization problem ad companies marketing budget partial node loading submodular property;social networking online;greedy algorithms social network services integrated circuit modeling algorithm design and analysis loading cost function mathematical model;viral marketing	As more and more people join social network, viral marketing on online social network becomes a new trend of advertising. Motivated by this, plenty of research focuseson how to maximize the information propagation, which is called the influence maximization problem. Traditional work has made significant progress on this topic. However all ad companies have marketing budget, the research of influence maximization problem should take account of cost control. Under the condition of cost control, we model each user's cost of helping spread information as a feature of each node in the network. Then we modify several most widely studied algorithms to suit the new model. In this paper, a new algorithm called CPP-SNS is proposed, which selects seeds according to cost performance of nodes. Further improvements, based on strategy of partial node loading and submodular property of spread function, make CPP-SNS more effective in practical scenarios. Extensive experiments show this method has a good performance in different social networks. Based on results of our research, we also provide some advice for the practical marketing.	consistent pricing process;entropy maximization;expectation–maximization algorithm;experiment;route inspection problem;social network;software propagation;submodular set function	Qianyi Zhan;Hongchao Yang;Chong-Jun Wang;Junyuan Xie	2013	2013 IEEE 25th International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2013.129	machine learning;viral marketing;social network	DB	-16.822222072146566	-43.82391675271557	3184
64fd5cdae82694191cc0c2b5f5016c828117691d	using syntactic dependency-pairs conflation to improve retrieval performance in spanish	linguistique;information retrieval;indexing method;linguistica;analisis morfologico;indexing;recherche information;indexation;spanish;morphological analysis;indizacion;analyse morphologique;recuperacion informacion;espagnol;espanol;linguistics	This article presents two new approaches for term indexing which are particularly appropriate for languages with a rich lexis and morphology, such as Spanish, and need few resources to be applied. At word level, productive derivational morphology is used to conflate semantically related words. At sentence level, an approximate grammar is used to conflate syntactic and morphosyntactic variants of a given multi-word term into a common base form. Experimental results show remarkable improvements with regard to classical indexing methods.	algorithmic efficiency;approximation algorithm;attribute grammar;database;galaxy morphological classification;information retrieval;lemmatisation;mathematical morphology;parsing;term indexing;time complexity;while	Jesús Vilares;Francisco-Mario Barcala;Miguel A. Alonso	2002		10.1007/3-540-45715-1_40	natural language processing;speech recognition;morphological analysis;computer science;linguistics;spanish	NLP	-26.721572562450596	-77.71923831006286	3187
9c6f41998f8d1c2a14cebdeac01ca89746ba0fec	inducing sound segment differences using pair hidden markov models	pair hidden markov models;sequence distance measure;induced vowel distance;expectation maximisation;sound segment distance;dutch dialect material;segment distance;dialect comparison;sound segment difference;goeman-taeldeman-van reenen-project;levenshtein distance;hidden markov model;col	Pair Hidden Markov Models (PairHMMs) are trained to align the pronunciation transcriptions of a large contemporary collection of Dutch dialect material, the GoemanTaeldeman-Van Reenen-Project (GTRP, collected 1980–1995). We focus on the question of how to incorporate information about sound segment distances to improve sequence distance measures for use in dialect comparison. PairHMMs induce segment distances via expectation maximisation (EM). Our analysis uses a phonologically comparable subset of 562 items for all 424 localities in the Netherlands. We evaluate the work first via comparison to analyses obtained using the Levenshtein distance on the same dataset and second, by comparing the quality of the induced vowel distances to acoustic differences.	acoustic cryptanalysis;align (company);expectation–maximization algorithm;hamming distance;hidden markov model;levenshtein distance;markov chain	Martijn Wieling;Therese Leinonen;John Nerbonne	2007			speech recognition;computer science;machine learning;pattern recognition;mountain pass;hidden markov model	NLP	-12.861196339690315	-82.89161944854106	3188
687912fffe876d91f439d50a69a3f08885d82dd2	an agent-based simulation of destigmatization (dsim): introducing a contact theory and self-fulfilling prophecy approach	destigmatization;social psychology;intergroup contact	In this paper, we propose a novel approach to exploring the destimgatisation process, an agent-based model called the destigmatization model (DSIM). In the DSIM, we demonstrate that, even if individual interactions (intergroup contact) are based on rules of the self-fulfilling prophecy, it can lead to destigmatisation. In a second study, we empirically verify a prediction that there is a positive relationship between minority group size and perceived stigmatization. Finally, we confirm that DSIM successfully implements Allport's (1954) four moderators, in turn decreasing the level of perceived stigma of the minority group. Interestingly, however, some of Allport's moderators influence the speed of destigmatisation, rather than having a lasting impact on the process of prejudice reduction. The findings suggest that moderators of 'intergroup contact' can function in one of two ways, either by improving how much contact helps to reduce stigmatization or by improving how quickly destigmatization can occur.	simulation	Dietmar Heinke;Gregory Carslaw;Julie Christian	2013	J. Artificial Societies and Social Simulation		psychology;developmental psychology;sociology;social psychology	AI	-87.90565736956313	-18.502610279174345	3194
2d07e1f571238c75cbded83f695592c6443284ef	the evolution of computerised notational analysis through the example of squash		By analysing past and current work in squash, it was found that notational analysis of sport could be systematically analysed by using these delimitations. The development of analysis and technology in the analysis of squash The technological developments in notational analysis have inevitably lagged those in the applied computing technology environment. Application of feedback in squash The main applied areas of objective feedback were found to be:Tactical evaluation Technical evaluation Movement analysis Databases and modelling Performance profiling and reliability Performance profiling The definition of profiles is much less a matter of guesswork because of methodological advances. Reliability The methods of measuring and calculating the reliability of non-parametric data has grown with research over the last few years. Areas of Research and Support More research in modelling in performance analysis is vital as we extend our knowledge and databases into those exciting areas of prediction. It is clear from these analyses of the on-going research and development work in squash, that the working notational analyst must have a broad set of skills and be prepared to maintain and extend those skills just as the research in this area develops the knowledge base.	database;delimiter;knowledge base;profiling (computer programming)	Michael T. Hughes;Mike Hughes	2005	Int. J. Comp. Sci. Sport		algorithm;notational analysis;squash;political science	SE	-75.35263007783196	-17.96560761535523	3196
93104cbde9e0576421a0f5c7847c5107c76d8316	channel choice and source choice of entrepreneurs in a public organizational context: the dutch case	search engine;source choice;entrepreneurs;businesses;channel choice;vignette method;public service delivery;public service	Most e-Government research focuses on citizens, the use and effects of electronic channels and services. However, businesses are an important target group for governmental agencies as well. Governmental agencies have a duty to inform businesses and to make this information easy to access. In order to increase accessibility it is important to closely relate to the behavior of users. Therefore, the purpose of the present investigation is to gain insight about the channel and source choice of entrepreneurs in a public organizational context. According to 323 entrepreneurs, who filled out an electronic questionnaire, the internet is the most preferred channel and a search engine is the most preferred source for obtaining governmental information. Business-, entrepreneurand situational characteristics have, although small, effect on these choices.	accessibility;e-government;internet;web search engine	Jurjen Jansen;Lidwien van de Wijngaert;Willem Pieterson	2010		10.1007/978-3-642-14799-9_13	public relations;computer science;marketing;management;world wide web;search engine	HCI	-83.38141527586731	-10.833861982731369	3197
6e68d9a840f8311f868f03809432c233fd76fcf9	a three-dimensional building authoring tool based on line drawing understanding	three dimensional;authoring tool	Recently three-dimensional (3D) graphics has been applied in areas such as building and mechanical design, with the help of CAD tools to first construct the two-dimensional (2D) and 3D models. Building synthetic environments usually involves lots of work in constructing virtual reality worlds, and making authoring more efficient is one of the most important goals in virtual reality. We propose a prototype system that integrates several modules such as image preprocessing, vectorization, editing, and 3D model generation, to transform a 2D architecture design diagram into a 3D building model. We also propose an improved method that can efficiently recognize slant lines in addition to vertical and horizontal lines. To do this, since a line has a constant slope, we use back-tracking in our method and utilize a line slope consistency check to prune wrong targets.	3d computer graphics;3d modeling;automatic vectorization;computer-aided design;diagram;preprocessor;prototype;synthetic intelligence;virtual reality	Ming Ouhyoung;Yung-Huei Yan	1996	Presence: Teleoperators & Virtual Environments	10.1162/pres.1996.5.1.1	three-dimensional space;simulation;computer science;artificial intelligence;operating system;computer graphics (images)	Visualization	-38.12195674057864	-32.375636638029135	3202
cce2bbf38819ec384a2f53b93212ad6a3c311aea	non-visual presentation of graphs using the novint falcon	accessible graphs;force feedback;novint falcon;visual impairment;haptic technology	"""Several technological advances have contributed to providing non-visual access to information by individuals who have sight impairments. Screen readers and Braille displays, however, are not the means of choice for conveying pictorial data such as graphs, maps, and charts. This paper thus proposes the """"Falcon Graph"""" interface which has been developed to enable visually impaired individuals to access computer-based visualisation techniques: mainly pie charts, bar charts, and line graphs. In addition to its interaction with Microsoft Excel, the interface uses the Novint Falcon as the main force feedback media to navigate the haptic virtual environment. Initial findings gathered from testing the interface are also presented."""		Reham Alabbadi;Peter Blanchfield;Maria Petridou	2012		10.1007/978-3-642-31534-3_76	simulation;computer hardware;computer science;computer graphics (images)	NLP	-48.628717267583625	-40.29669773248586	3203
2b319c21c5d9a9038e7e32879c9e474da84d12cc	social use of computer-mediated communication by adults on the autism spectrum	online communities;autism spectrum disorder;autism spectrum disorders;information visualization;spectrum;online community;social support;perspective taking;computer mediated communication;social skills training;participatory design	The defining characteristics of autism, including difficulty with nonverbal cues and need for structure, and the defining characteristics of computer-mediated communication (CMC), including reduction of extraneous cues and structured exchange, suggest the two would be an ideal match. Interviews and observations of 16 adults on the high-functioning end of the autism spectrum reveal that many seek greater social connectedness and take advantage of interest-based online communities to foster successful, supportive relationships. However, CMC intensifies problems of trust, disclosure, inflexible thinking, and perspective-taking, making it difficult for some to maintain relationships. Interventions in the form of information visualization and CMC-specific social skills training are presented. Intervention considerations and participatory design opportunities are discussed.	computer-mediated communication;information visualization;online community	Moira Burke;Robert E. Kraut;Diane Williams	2010		10.1145/1718918.1718991	psychology;social skills;spectrum;information visualization;developmental psychology;computer science;communication;social psychology;computer-mediated communication	HCI	-63.40090777993787	-42.01375334675317	3209
04bdbc105150920d0f952164ce94a7f2a71bef15	kgnr: a knowledge-based geographical news recommender	geology semantics knowledge based systems collaboration ontologies context feeds;recommender systems collaborative filtering geographic information systems internet knowledge based systems mobile computing;feeds;collaboration;semantics;geology;ontologies;recommendation system modeling kgnr knowledge based geographical news recommender online news reading services google news yahoo news internet news articles preferences matching content based systems collaborative filtering systems mobile phones personalized news recommendation system geolocation user profiles content based recommendation mechanism topic maps;context;knowledge based systems	Online news reading services, such as Google News and Yahoo! News, have become very popular since the Internet provides fast access to news articles from various sources around the world. A key issue of these services is to help users to find interesting articles that match their preferences as much as possible. This is the problem of personalized news recommendation. Recently, personalized news recommendation has become a promising research direction and a variety of techniques have been proposed to tackle it, including content-based systems, collaborative filtering systems and hybrid versions of these two. In addition, the widespread use of mobile phones today and the different features that these phones offer users allow the possibility to keep users up to date with the latest news that have taken place in their environment, anywhere and at any time. This paper presents KGNR (Knowledge-based Geographical News Recommender), a new approach to develop a personalized news recommendation system as an application for mobile phones that takes into account the geolocation of the user and uses learned user profiles to generate personalized news recommendations. For this purpose, a content-based recommendation mechanism have been combined with topic-maps and geolocation for modeling the recommendation system.	collaborative filtering;expert system;geolocation;google news;internet;knowledge representation and reasoning;knowledge-based systems;map;mobile phone;natural language processing;ontology (information science);personalization;recommender system;topic maps;user profile;verification and validation	Angel L. Garrido;Maria G. Buey;Sergio Ilarri;Igor Furstner;Livia Szedmina	2015	2015 IEEE 13th International Symposium on Intelligent Systems and Informatics (SISY)	10.1109/SISY.2015.7325378	geography;multimedia;internet privacy;world wide web;news aggregator	Web+IR	-29.480740106405097	-48.0088247374046	3213
9c72e14b8af32303229a217dd25fdd78296b6262	visualization and establishment of product design regulations as interactive modules: an interaction design study at ikea	produktionsteknik;regulations;arbetsvetenskap och ergonomi;visualization;communication;management;action research;interaction design	Purpose – This paper aims to explore the preferable manner for visualizing different product regulations to be used in the training of and communication between people working at different levels in the production process. Many organizations struggle to communicate important and compulsory regulations, but the intended users are often reluctant to use them. Design/methodology/approach – The study has an action research approach, and the visualized regulations were the result of a human-centered design process that considered aspects for successful organizational change. Findings – The action research approach proved to be a successful framework to design the transformation of well-constructed illustrations in interactive guides, communicate and convince managers and users of the potential of the concept, develop a number of different well-functioning guides and establish regulations with illustrative elements and interactivity in a long-term perspective of an organization. Research limitations/implications – Further research is needed to follow-up the usage of visualized regulations to clarify how communication and quality are supported in design and production processes. Practical implications – The study shows how different product regulations should be visualized and established in an organization, with a potential for further dissemination. It is likely that the approach to design and visualize regulations in this study can function in other branches. Originality/value – The study finds a preferable manner for visualizing different product regulations to be used in the training of and communication between people working at different levels in the production process.	electronic commerce regulations 2002;interaction design;interactivity;nl-complete;organizational behavior;performance rating;user-centered design	Mikael Blomé	2015	J. Systems and IT	10.1108/JSIT-11-2013-0061	regulation;visualization;human–computer interaction;computer science;systems engineering;engineering;knowledge management;marketing;interaction design;action research;database;management;law;world wide web	HCI	-81.4006896928762	-0.5043369051632651	3215
e757d1fbf5195ec9d176bbe7856fc5e80a9f86d9	main trends in semantic-research of estonian language technology	main trends;main focus;tartu university;computational semantics;estonian language technology;general overview;estonia beginning;computational linguistics;research group	The paper gives a general overview of the development of computational semantics in Estonia beginning from the second half of the 20th century. Main focus concentrates on the work we have done so far and on the problems we try to solve at present in our research group of computational linguistics at Tartu University.	language technology	Haldur Õim;Heili Orav;Kadri Kerner;Neeme Kahusk	2010		10.3233/978-1-60750-641-6-201	humanities;mathematics education;engineering;literature	NLP	-59.71705762692412	-20.0662796378196	3220
841a0afb444e1dd1bafeb4bc6d05a59d6534ad17	augmented touch without visual obtrusion	artificial;rendering computer graphics augmented reality data visualisation haptic interfaces;haptic device;image based rendering augmented touch visuo haptic mixed reality virtual object see through display technology haptic device haptic interaction real scene;geometry;virtual reality;visuo haptic mixed reality;artificial augmented and virtual realities h 5 1 information interfaces and presentation multimedia information systems;indexing terms;image based modeling;augmented touch;multimedia information system;augmented;see through display technology;proof of concept;artificial augmented and virtual realities;data visualisation;visualization;virtual object;haptic interfaces virtual reality layout space technology actuators rendering computer graphics optical devices displays multimedia systems medical services;h 5 1 information interfaces and presentation multimedia information systems;heuristic algorithms;field of view;real scene;and virtual realities;augmented reality;image based rendering;haptic interfaces;information interfaces and presentation;rendering computer graphics;mixed reality;cameras;haptic interaction	Visuo-haptic mixed reality consists of adding to a real scene the ability to see and touch virtual objects. It requires the use of see-through display technology for visually mixing real and virtual objects, and haptic devices for adding haptic interaction with the virtual objects. However, haptic devices tend to be bulky items that appear in the field of view of the user. In this work, we propose a novel mixed reality paradigm where it is possible to touch and see virtual objects in combination with a real scene, but without visual obtrusion produced by the haptic device. This mixed reality paradigm relies on the following three technical steps: tracking of the haptic device, visual deletion of the device from the real scene, and background completion using image-based models. We have developed a successful proof-of-concept implementation, where a user can touch virtual objects in the context of a real scene.	display device;haptic technology;programming paradigm;see-through display;visuo-haptic mixed reality	Francesco I. Cosco;Carlos Garre;Fabio Bruno;Maurizio Muzzupappa;Miguel A. Otaduy	2009	2009 8th IEEE International Symposium on Mixed and Augmented Reality	10.1109/ISMAR.2009.5336492	stereotaxy;computer vision;augmented reality;virtual image;image-based modeling and rendering;visualization;index term;field of view;computer science;artificial intelligence;virtual reality;mixed reality;multimedia;haptic technology;proof of concept;computer graphics (images)	Visualization	-42.28248415361372	-38.906966766329255	3222
3f5382d375120552cc9f6b5a316672c78858edae	cyber-sustainability: leaving a lasting legacy of human wellbeing	cyberspace;wellbeing;worldview;sustainability;qa75 electronic computers computer science;environment;design	This paper presents a case for the importance of sustainability in HCI as it relates to the Web. So far, the discussion about sustainability in HCI has focused on environmental aspects. However, our belief is that cyber-sustainability is much greater than this. We argue that to address cybersustainability correctly, the principles of sustainability should be considered in relation to 3 concerns: 1) environmental impacts, 2) psychological impacts, and 3) the worldview that the Web tends to promote. Several broad implications for more sustainable Web development are proposed.	human–computer interaction;web development;world wide web	Bran Richards;Stuart Walker;Lynne Blair	2011			sustainability organizations;social sustainability;engineering;environmental resource management;socioeconomics;management science	HCI	-76.74868370463201	-10.711078249898101	3225
8d73f063957864f5faa19edb16f21e7c86e9f9f6	working solutions for telehealth in low resource areas				S. B. Gogia;S. K. Meher;Arindam Basu;Maurice Mars;Gunnar Hartvigsen	2013			environmental science;environmental resource management;telehealth;water resource management	HCI	-68.0031724806082	-1.8896344823907818	3229
7744c16f5b24d331d7c28192f4159d37939b3df9	city, self, network: transnational migrants and online identity work	urban informatics;transnationalism;identity work;social media	This paper uses qualitative interviews with 26 transnational migrants in New York City to analyze socio-technical practices related to online identity work. We focus specifically on the use of Facebook, where benefits included keeping in touch with friends and family abroad and documenting everyday urban life. At the same time, many participants also reported experiences of fatigue, socio-cultural tensions and concerns about maintaining a sense of personal privacy. These experiences highlight how transnational practices complicate context collapse, where the geographic dispersal of participants' personal networks renders visible conflicts of 'flattened' online networks. Our findings also suggest a kind of technology-enabled code-switching, where transnational migrants leverage social media to perform identities that alternate between communities, nationalities and geographies. This analysis informs HCI research on transnationalism and technological practices, as well as the complexities of online identity work in terms of shifting social and spatial contexts.	experience;human–computer interaction;institute for operations research and the management sciences;online identity;privacy;rendering (computer graphics);social media;sociotechnical system;software documentation	Jessica Lingel;Mor Naaman;Danah Boyd	2014		10.1145/2531602.2531693	social science;social media;computer science;gender studies;sociology;communication;management;social psychology;world wide web;anthropology	HCI	-79.0911837943353	-13.09542087868947	3234
d956f4ac57595176f672e4d0a7db377d447280de	the significance of bidding, accepting and opponent modeling in automated negotiation	qa75 electronic computers computer science	Given the growing interest in automated negotiation, the search for effective strategies has produced a variety of different negotiation agents. Despite their diversity, there is a common structure to their design. A negotiation agent comprises three key components: the bidding strategy, the opponent model and the acceptance criteria. We show that this three-component view of a negotiating architecture not only provides a useful basis for developing such agents but also provides a useful analytical tool. By combining these components in varying ways, we are able to demonstrate the contribution of each component to the overall negotiation result, and thus determine the key contributing components. Moreover, we study the interaction between components and present detailed interaction effects. Furthermore, we find that the bidding strategy in particular is of critical importance to the negotiator’s success and far exceeds the importance of opponent preference modeling techniques. Our results contribute to the shaping of a research agenda for negotiating agent design by providing guidelines on how agent developers can spend their time	baseline (configuration management);noise shaping;preference learning	Tim Baarslag;A. S. Y. Dirkzwager;Koen V. Hindriks;Catholijn M. Jonker	2014		10.3233/978-1-61499-419-0-27	simulation;computer science;knowledge management;artificial intelligence	AI	-10.435226224901639	-10.5607992549606	3242
023994eab27d18b56ce230f16316c7b4bfa593b7	age and the nobel prize revisited	scientometrics;productivite;age;productividad;age structure;scientometria;scientometrie;productivity;recherche scientifique;prix nobel;scientific research;investigacion cientifica;edad	This paper analyzes the relationship between age and productivity for Nobel prize winners in science during the period 1901–1992. The relationship found is field dependent as well as dependent upon the definition used to measure the age at which the ward-winning work was done. The results suggest that although it does not require extraordinary youth to do prizewinning work, the odds decrease markedly in mid-life and fall off precipitously after age 50, particularly in chemistry and physics. The discussion underscores the problem of drawing conclusions about the age structure of research by examining medians instead of the entire distribution.	k-medians clustering	Paula E. Stephan;Sharon G. Levin	1993	Scientometrics	10.1007/BF02026517	demography;productivity;scientific method;epistemology;population pyramid;scientometrics;computer science;operations research;world wide web	HCI	-76.41393760805678	-22.184185991451468	3258
30e3d15198aec091f5822dc883522ae8af233767	describing a product opportunity: a method of understanding the user's environment				Andrew Hutt;Nick Donnelly;Linda A. Macaulay;Chris J. H. Fowler;Deborah Twigger	1987				HPC	-41.5955063944666	-15.619768496554212	3265
2fe7f30a72cc3f43acdc72dcfb07c245d69832be	reconstructing semantic structures in technical documentation with vector space classification		With the increasing popularity of component content management systems, a large part of technical documentation in manufacturing and mechanical engineering is written semantically structured in xml-based information models. Content delivery portals can utilize these information to provide users with advanced retrieval or filtering functions. However, legacy content is often excluded from such granular access due to the lack of semantic structures in archival file formats, as for instance, untagged pdf documents. In this paper we introduce an approach that uses the classification knowledge present in available content components to reconstruct document structures in text extracted from legacy files. The method leverages transitions in classification confidence for distributed text chunks to detect boundaries between content components of different semantic classes. Classification is done using a modified vector space model for technical documentation. To measure confidence we derive a measure based on properties of cosine similarity in multiclass scenarios. We present first results that show a strong correlation of predicted semantic structures and original document outlines and give proposals for further improvement. CCS Concepts •Information systems → Clustering and classification; Content analysis and feature selection;	component content management system;content-control software;cosine similarity;feature selection;information model;portable document format;portals;statistical classification;technical documentation;xml	Jan Oevermann	2016			vector space;data mining;information retrieval;technical documentation;computer science	Web+IR	-28.662612860129055	-56.48339722305729	3271
abc9e7fb90c0a025483114f08e0ea6ad5d16dd69	artificial life meets entertainment: lifelike autonomous agents	complex dynamics;artificial intelligent;autonomous agent;molecular evolution;artificial evolution;artificial life	The relatively new field of artificial life attempts to study and understand biological life by synthesizing artificial life forms. To paraphrase Chris Langton, the founder of the field, the goal of artificial life is to “model life as it could be so as to understand life as we know it.” Artificial life is a very broad discipline which spans such diverse topics as artificial evolution, artificial ecosystems, artificial morphogenesis, molecular evolution, and many more. Langton offers a nice overview of the different research questions studied by the discipline [6]. Artificial life shares with artificial intelligence (AI) its interest in synthesizing adaptive autonomous agents. Autonomous agents are computational systems that inhabit some complex, dynamic environment, sense and act autonomously in this environment, and by doing so realize a set of goals or tasks for which they are designed.	artificial intelligence;artificial life;autonomous robot;computation;ecosystem;evolutionary algorithm;intelligent agent;langton's ant	Pattie Maes	1995	Commun. ACM	10.1145/219717.219808	simulation;complex dynamics;molecular evolution;computer science;artificial intelligence;autonomous agent;evolutionary algorithm;artificial creation;artificial intelligence, situated approach;artificial life	AI	-20.91801733391867	-17.088073687407444	3273
1697aee55e3da68765ed44a9a63535802a8c0274	last house on the hill: digitally remediating data and media for preservation and access	global illumination;lighting analysis;virtual archaeology;minoan crete	The idea of embedding, interweaving, entangling and otherwise linking the data and media from archaeological excavations with their interpretation and meaningful presentation in an open access sharable platform has long been an ambition of those of us working in the digital documentation of archaeological research and the public presentation of cultural heritage. Formidable barriers still exist to making it possible for projects to achieve these aims, ranging from intellectual property concerns to providing commitments to the long-term sustainability of the digital content. Working in collaboration with the contributors, archaeological project managers, publishers and information technologists, we devised a content licensing agreement that makes it possible for the primary research media and data, combined with the monograph texts, to be freely and openly accessible in perpetuity.  The aim of our project, Last House on the Hill (LHotH), is to holistically reconstitute the rich multimedia and primary research data with the impressive texts of the monograph, the printed final report of the Berkeley Archaeologists at Çatalhöyük (BACH) project, in which a team from UC Berkeley excavated a group of Neolithic 9000-year old buildings at this famous cultural heritage location in Central Anatolia, Turkey. The Last House on the Hill brings together the published text, complete project database (including all media formats such as photographs, videos, maps, line drawings), related websites, data and media outside the direct domain of the BACH project, and recontextualised presentations of the data as remixes, movies, and other interpretive works by BACH team members and many others. We are achieving this through an event-centered, CIDOC-CRM compatible implementation ontology, expressed with the open source Omeka web-publishing platform, providing open access, transparency and open-endedness to what is normally the closed and final process of monograph publication.  This paper describes the strategy, goals, architecture and implementation for the project, emphasizing the novel and innovative approaches that were required to make the project successful.	digital recording;documentation;holism;map;open-source software;printing;uc browser	Michael Ashley López;Ruth Tringham;Cinzia Perlingieri	2009		10.2312/VAST/VAST09/109-116	computer science;data mining;global illumination	HCI	-48.34259523366295	-23.837119543277247	3276
0ec3e44b44c0ff87c9913fe339f6d36023cd413c	spontaneous handwriting text recognition and classification using finite-state models	artefacto;busqueda informacion;analisis imagen;modelizacion;integrated approach;analisis contenido;vocabulaire;modelo markov oculto;model based reasoning;text;raisonnement base sur modele;handwriting recognition;analisis estadistico;image processing;modelo markov;modele markov cache;caracter manuscrito;hidden markov model;information retrieval;maquina estado finito;manuscript character;vocabulary;procesamiento imagen;vocabulario;texte;probabilistic approach;classification;traitement image;artefact;text classification;modelisation;content analysis;reconnaissance ecriture;markov model;reconnaissance caractere;statistical analysis;recherche information;enfoque probabilista;approche probabiliste;analyse statistique;classification system;pattern recognition;image analysis;reconnaissance forme;analyse contenu;modele markov;reconocimiento patron;machine etat fini;texto;modeling;caractere manuscrit;analyse image;character recognition;clasificacion;finite state machine;reconocimiento caracter	Finite-state models are used to implement a handwritten text recognition and classification system for a real application entailing casual, spontaneous writing with large vocabulary. Handwritten short phrases which involve a wide variety of writing styles and contain many non-textual artifacts, are to be classified into a small number of predefined classes. To this end, two different types of statistical framework for phrase recognition-classification are considered,based on finite-state models. HMMs are used for text recognition process. Depending to the considered architecture, N-grams are used for performing text recognition and then text classification (serial approach) or for performing both simultaneously (integrated approach). The multinomial text classifier is also employed in the classification phase of the serial approach. Experimental results are reported which, given the extreme difficulty of the task, are encouraging.		Alejandro Héctor Toselli;Moisés Pastor;Alfons Juan-Císcar;Enrique Vidal	2005		10.1007/11492542_45	computer vision;image analysis;speech recognition;systems modeling;content analysis;image processing;biological classification;computer science;artificial intelligence;model-based reasoning;machine learning;noisy text analytics;handwriting recognition;markov model;hidden markov model;statistics	Vision	-21.84352281498162	-90.72819817213738	3286
2df0142c3aec1231bbc2698f984b54d7e7ff53af	objective assessment of ornamentation in indian classical singing	ornamentation;indian music;polynomial curve fitting;singing scoring	Important aspects of singing ability include musical accuracy and voice quality. In the context of Indian classical music, not only is the correct sequence of notes important to musical accuracy but also the nature of pitch transitions between notes. These transitions are essentially related to gamakas (ornaments) that are important to the aesthetics of the genre. Thus a higher level of singing skill involves achieving the necessary expressiveness via correct rendering of ornamentation, and this ability can serve to distinguish a welltrained singer from an amateur. We explore objective methods to assess the quality of ornamentation rendered by a singer with reference to a model rendition of the same song. Methods are proposed for the perceptually relevant comparison of complex pitch movements based on cognitively salient features of the pitch contour shape. The objective measurements are validated via their observed correlation with subjective ratings by human experts. Such an objective assessment system can serve as a useful feedback tool in the training of amateur singers.	approximation;computation;computational model;copycat (software);curve fitting;differentiator;glide;holomatix rendition;pitch (music);polynomial;time series	Chitralekha Gupta;Preeti Rao	2011		10.1007/978-3-642-31980-8_1	speech recognition;art;acoustics;communication	ML	-9.28046490466148	-85.44644996885076	3288
e75479674281a65d77d5d72114b9c30d9c41d323	towards emotion acquisition in it usability evaluation context	usability evaluation;emotion recognition;user experience;affective computing	The paper concerns extension of IT usability studies with automatic analysis of the emotional state of a user. Affect recognition methods and emotion representation models are reviewed and evaluated for applicability in usability testing procedures. Accuracy of emotion recognition, susceptibility to disturbances, independence on human will and interference with usability testing procedures are the criteria, that were identified and addressed in this paper. A study of a usability evaluation case was also performed to spot realistic challenges. As a result, a number of concerns were identified, providing a list of pros and cons for affect acquisition applied in usability testing context.	emotion recognition;interference (communication);usability testing	Agnieszka Landowska	2015		10.1145/2814464.2814470	usability goals;pluralistic walkthrough;web usability;component-based usability testing;cognitive walkthrough;usability;human–computer interaction;computer science;usability engineering;multimedia;social psychology;heuristic evaluation;usability lab;usability inspection	HCI	-62.47456717243015	-47.41801927363972	3289
35211401c7ace6260576282abd9f97fe8a3a0659	consequences of publishing real personal information in online social networks				Theodoros Tzouramanis;Eleni Vourou;Argyro Gkorogia	2014		10.1007/978-1-4614-6170-8_349	public relations;computer science;knowledge management;personal information management;world wide web	ML	-68.60056096281713	-7.273705833453582	3290
94adf34f7ba33dc9e55d741ac07fa01f5e0b3bb5	modeling user interest and community interest in microbloggings: an integrated approach		To explain why a user generates some observed content and behaviors, one has to determine the user’s topical interests as well as that of her community. Most existing works on modeling microblogging users and their communities however are based on either user generated content or user behaviors, but not both. In this paper, we propose the Community and Personal Interest (CPI) model, for modeling interest of microblogging users jointly with that of their communities using both the content and behaviors. The CPI model also provides a common framework to accommodate multiple types of user behaviors. Unlike the other models, CPI does not assume a hierarchical relationship between personal interest and community interest, i.e., one is determined purely based on the other. We build the CPI model based on the principle that a user’s personal interest is different from that of her community. We further develop a regularization technique to bias the model to learn more socially meaningful topics for each community. Our experiments on a Twitter dataset show that the CPI model outperforms other state-of-the-art models in topic learning and user classification tasks. We also demonstrate that the CPI model can effectively mine community interest through some representative case examples.		Tuan-Anh Hoang	2015		10.1007/978-3-319-18038-0_55	human–computer interaction;knowledge management;multimedia	Theory	-19.179457409416486	-45.240699551611534	3292
3aff6f6008ab8da2e83a60e430ea48351af79776	csedu 2009 - proceedings of the first international conference on computer supported education, lisboa, portugal, march 23-26, 2009 - volume 2					2009				Vision	-54.90204214217935	-8.16354538825532	3296
92b8d524ed198ab045c1cfb90ec4249d774b3c02	computer conferencing; discourse, education and conflict mediation	teleconferencing;computer uses in education;teacher education;modern history;skill development;professional development;foreign countries;secondary school students;computer conferencing;conflict resolution;world problems;teaching methods			Roger Austin	1997	Computers & Education	10.1016/S0360-1315(97)00038-9	professional development;psychology;simulation;teleconference;conflict resolution;teaching method;modern history;multimedia;sociology;pedagogy	NLP	-72.0565307372483	-34.56152064399741	3298
6a0683090ec3220e928672cd2ae3abcd5fd40216	collaborative scientific data visualization		We have designed a collaborative scientific visualization package that will aid researchers from distant, diverse locations to work together in developing scientific codes, providing them with a system to analyze their scientific data. We have utilized Java to develop this infrastructure. Two important areas which we have concentrated on developing are 1) a collaborative framework from which the scientific data is interpreted and utilized, and 2) a framework, which is customizable to the suit the needs of a particular task and/or scientific group.	black hole;code;data visualization;java;scientific visualization	Byeongseob Ki;Scott Klasky	1997	Concurrency - Practice and Experience	10.1002/(SICI)1096-9128(199711)9:11%3C1249::AID-CPE338%3E3.0.CO;2-K	geovisualization;visual analytics;scientific visualization;information visualization;visualization;human–computer interaction;computer science;data science;programming language;java;world wide web;data	HPC	-30.781222211315466	-29.080967915361406	3299
df9562ce3c89be01de5d8b55f1c9942d462284ac	4th international workshop on managing requirements knowledge, mark@re 2011, trento, italy, august 30, 2011			requirement		2011				Vision	-55.1041009771686	-7.33061160585955	3301
28eb1b1dde190be16c94a952dfc199a8672b8672	the implications of mobile notifications for user experience of a social network service	field study;user experience	Smartphones enable an always-on connection to Social Network Services (SNS). A typical way of interacting with SNSs is to access them when the user has a suitable situation to check the status of her social networks or to write an update. One way to enhance the usage of SNSs is to have the service automatically push notifications about events to the smartphone user interface. However, there is no research on how users experience such SNS notifications. We present an explorative field study with 11 participants to assess how users experience mobile notifications compared to reading SNS content manually, initiated by the user. The participants first used Facebook for a month without notifications and then for a month with an application called Socially that sends frequent notifications about Facebook events to the user’s smartphone desktop. The participants who kept the notification feature on reported increased reading of Facebook. However, after a while, many were unwilling to receive the notifications, mainly because of lack of control. We report the qualitative findings on user experience, which reveal for example, that the use of mobile notifications decreases interest in Facebook. Notifications limit user control, and using Facebook feels more meaningful when accessed manually. Implications for design are		Sami Vihavainen;Kaisa Väänänen	2013	iJIM		user experience design;human–computer interaction;public land mobile network;computer science;internet privacy;world wide web;field research	HCI	-56.256597898984886	-43.1234233562862	3305
1cb15c77ff3f157f99d6e3a737281c8cc09cf576	remarks on supercomputing in germany		Prof. Dr.-Ing. Michael M. Resch is the director of the Höchstleistungsrechenzentrum Stuttgart (HLRS) at Stuttgart, Germany and holds a full professorship as the chair for High Performance Computing at the Universität Stuttgart, Germany. He is speaker of the board of the Center for Competence in High Performance Computing of the State of BadenWürttemberg and a member of the scientific advisory board of the Centro Svizzero di Calcolo Scientifico (CSCS), Manno, Switzerland. Prof. Resch won the HPC Challenge Award at SC ’2003 in November 2003 and led a research group that received the Award for High Performance Distributed Computing in 1999 from the US National Science Foundation. Prof. Resch holds a Dr.-Ing. (PhD) in Mechanical Engineering from the Universität Stuttgart/ Germany and a Dipl.-Ing. (MSc) in Technical Mathematics from the Technical University of Graz/Austria. He was an Assistant Professor for Computer Science at the University of Houston until 2002.	acm/ieee supercomputing conference;computer science;darpa grand challenge;dr-dos;distributed computing;high performance computing center, stuttgart;istituto di scienza e tecnologie dell'informazione;supercomputer;switzerland	Michael M. Resch	2005	Praxis der Informationsverarbeitung und Kommunikation	10.1515/PIKO.2005.233	supercomputing in europe	HPC	-48.05430464674431	-9.028477024810401	3307
05abfe5e430ae8638f26e6bfee71e10bd3407bd6	mtmonkey: a scalable infrastructure for a machine translation web service		We present a web service which handles and distributes JSON-encoded HTTP requests for machine translation (MT) among multiple machines running an MT system, including text preand post-processing. It is currently used to provide MT between several languages for cross-lingual information retrieval in the EU FP7 Khresmoi project. The software consists of an application server and remote workers which handle text processing and communicate translation requests to MT systems. The communication between the application server and the workers is based on the XML-RPC protocol. We present the overall design of the software and test results which document speed and scalability of our solution. Our software is licensed under the Apache 2.0 licence and is available for download from the Lindat-Clarin repository and Github.	application programming interface;application server;cross-language information retrieval;download;hot swapping;json;machine translation;moses;response time (technology);scalability;server (computing);video post-processing;web service;xml;xml-rpc	Ales Tamchyna;Ondrej Dusek;Rudolf Rosa;Pavel Pecina	2013	Prague Bull. Math. Linguistics		computer science;operating system;database;world wide web	Web+IR	-47.10915038891946	3.9991514193729096	3309
9462a9c54bc8020cf47852ee48d032c0eb67b30d	access modalities to an imagistic library for medical e-learning	electronic learning;digital library;topic maps;color feature;semantic query;texture features;topic map;medical image;content based visual query;imagistic library;multimedia database;medical diagnosis;texture feature	The paper presents the organization way and the access facilities to a multimedia digital library with medical information for electronic learning. The digital library contains course materials and medical images collected in the patient's diagnosis process. The originality of the paper is given by the presentation of two access modalities to multimedia information from the digital library: content-based visual query and semantic query. The content-based visual query can be effectuated at the image or region level using colour and texture characteristics automatically extracted from medical images at their loading in the database. Also, semantic queries against the multimedia database can be automatically launched with the help of the topic map based on a part of MeSH thesaurus, the part that includes the medical diagnosis names. The student can navigate through topic map depending on its interest subject, bringing in this way big advantages. These access paths can be combined for retrieving the interest information. The multimedia digital library represents a very useful tool in the medical knowledge improvement, addressing to the students, resident doctors, young specialists or family doctors.		Liana Stanescu;Dumitru Dan Burdescu;Gabriel Mihai;Cosmin Stoica Spahiu;Anca Loredana Ion	2008		10.1007/978-3-540-87599-4_27	topic maps;digital library;computer science;multimedia;world wide web;information retrieval	EDA	-48.23838264487859	-63.40381227227381	3315
b6cd2d28398a1efb7472039ba077625c2d5a7686	modeling multi-turn conversation with deep utterance aggregation		Multi-turn conversation understanding is a major challenge for building intelligent dialogue systems. This work focuses on retrieval-based response matching for multi-turn conversation whose related work simply concatenates the conversation utterances, ignoring the interactions among previous utterances for context modeling. In this paper, we formulate previous utterances into context using a proposed deep utterance aggregation model to form a fine-grained context representation. In detail, a self-matching attention is first introduced to route the vital information in each utterance. Then the model matches a response with each refined utterance and the final matching score is obtained after attentive turns aggregation. Experimental results show our model outperforms the state-of-the-art methods on three multi-turn conversation benchmarks, including a newly introduced e-commerce dialogue corpus.	artificial neural network;dialog system;e-commerce;interaction;social network aggregation	Zhuosheng Zhang;Jiangtong Li;Pengfei Zhu;Hai Zhao;Gongshen Liu	2018			machine learning;computer science;natural language processing;conversation;artificial intelligence;context model;utterance	NLP	-18.09910151985327	-69.66596118238087	3318
2e180ae2d0c141681f44247dfc31c51bc85633e2	burst detection based on measurements of intensity discrimination	voice onset time;support vector machine;error rate	Detection of burst-related impulses, such as those accompanying plosive stop consonants, is an important problem for accurate measurement of acoustic features for recogntion (e.g., voice-onset-time) and for accurate automatic phonetic alignment. The proposed method of burst detection utilizes techniques for identifying and combining information about specific acoustic characteristics of bursts. One key element of the proposed method is the use of a measurement of intensity discrimination based on models from perceptual studies. Our experiments compared the proposed method of burst detection to the support vector machine (SVM) method, described below. The total error rate for the proposed method is 13.2% on the test-set partition of the TIMIT corpus, compared to a total error rate of 24% for the SVM method.	acoustic cryptanalysis;experiment;onset (audio);support vector machine;timit	John-Paul Hosom;Ronald A. Cole	2000			speech recognition;artificial intelligence;word error rate;timit;voice-onset time;pattern recognition;support vector machine;intensity discrimination;computer science	AI	-12.12666364477944	-89.02862607336667	3323
82992f116e95eefe24a8c04470bb5826a9a997bf	facilitating effective hci design meetings	effective hci design meeting;methodologies;user centered design;human computer interaction;design process	Raison d’Etre is a hypermedia design history application. It provides access to a database of video clips containing stories and personal perspectives of design team members recorded at various times through the course of a project. The system is intended to provide a simple framework for recording and organizing the informal history and rationale that design teams create and share in the course of their collaboration, This paper describes(1) the scenarios of use we are trying to support, (2) the methods we used collecting and organizing the database, and (3) the status of our prototype.	database;design rationale;human–computer interaction;hypermedia;organizing (structure);prototype;video clip	John L. Bennett;John Karat	1994		10.1145/259963.260352	user experience design;user-centered design;design process;human–computer interaction;computer science;knowledge management;methodology	HCI	-62.653575422218196	-38.57554978834384	3328
8d3faf7738a210b93ece7a4bf150201c070d3c2b	modeling adoption and diffusion: a multiple-relation approach	adoption;social network;diffusion	Previous studies on adoption and diffusion of a new product in a social network commonly assumed a single tie between a pair of actors. That means they only looked at one type of relation, while analyzing a diffusion process. However, we may have multiple ties between a pair of actors as multiple relations can arise from different modes of interaction or because of different roles people play within a network setting. Building on the IS literature on adoption and diffusion, the statistical literature on social network analysis, and the sociology literature on multiple relationships, this study proposes a new approach to develop a dynamic adoption model in a context of multiple relations. To this end, the study remodels the three well-discussedsocial forces of the diffusion process, including network effect, neighborhood effectand adopter effect (the self-influence by the potential adopter) in a way that reflects a significant role of the multiple-relation context.	social network analysis	Tung Cu	2013			management science;computer science;knowledge management;social network	Web+IR	-80.80185177493085	-0.08696076193938679	3329
a538a2e991d0759359129bf47bb216a5fa2ba48c	smartkitchen media enhanced cooking environment	smart home;insitu projection;smartkitchen;multimodal interaction;multimodal interfaces;interactive displays	This work-in-progress paper describes our project SMARTKITCHEN, an interdisciplinary research project focusing on interactive display deployment in the kitchen - in particular around the cooking area. By applying a user-centered design approach the project aims to examine how screen-based interactive digital media can be accessed naturally in a constrained environment during the cooking process using multimodal interaction. Our main focus is on exploring new directions of supporting social and emotional aspects of the cooking experience. In this work-in-progress paper, we provide an overview on research directions, envisioned use-cases, and used technologies.	digital media;multimodal interaction;software deployment;user-centered design	Jürgen Scheible;Arnd Engeln;Michael Burmester;Gottfried Zimmermann;Tobias Keber;Uwe Schulz;Sabine Palm;Markus Funk;Uwe Schaumann	2016		10.1145/2991561.2998471	simulation;human–computer interaction;computer science;multimodal interaction;multimedia	HCI	-53.27606490600381	-36.57336260655278	3331
06d7f605794630de179f38e4faf1e3974e435464	implementation of simple spectral techniques to enhance the intelligibility of speech using a harmonic model		We have designed a system that increases the intelligibility of speech signals in noise by manipulating the parameters of a harmonic speech model. The system performs the transformation in two steps: in the first step, it modifies the spectral slope, which is closely related to the vocal effort; in the second step, it amplifies low-energy parts of the signal using dynamic range compression techniques. Objective and subjective measures involving speech-shaped noise confirm the effectiveness of these simple methods. As the harmonic model has been used in previous works to implement the waveform generation module of high-quality statistical synthesizers, the system presented here can provide the synthesis engine with a higher degree of control on the intelligibility of the resulting artificial speech.	dynamic range;intelligibility (philosophy);spectral slope;waveform	Daniel Erro;Yannis Stylianou;Eva Navas;Inma Hernáez	2012			artificial intelligence;pattern recognition;speech recognition;computer science;harmonic;intelligibility (communication)	Graphics	-9.523918388770706	-86.26912771091865	3332
d830ea427c66f7213f2c81093d3bbf563357f1e4	scenarios for strategic sourcing of information and communication technology	outsourcing;business aspects strategic sourcing information technology communication technology research project international companies scenario planning environmental aspects;information technology;communications technology hip outsourcing electrical capacitance tomography companies identity based encryption context business communication virtual enterprises read only memory;strategic planning;information and communication technology;business data processing;scenario planning;business data processing information technology outsourcing strategic planning	s Abstract This paper describes parts of the results of a Nolan Norton Institute research project “Strategic Sourcing and Partnerships” executed with 20 international companies. We applied scenario planning to arrive at a number of plausible future scenarios for ICT sourcing and partnerships for the year 2003 / 2005.The scenarios elaborate on issues such as: (1) What are the key environmental and business aspect that will drive future business and ICT partnerships when entering the next century? (2) What are relevant, plausible and realistic consequences for the role of ICT as businessenhancing capability? (3) What are the relevant consequences for business executives and internal and external providers of ICT?	emergence;futures and promises;global illumination;pervasive informatics;scenario planning	Han T. M. van der Zee;Pieter M. A. Ribbers	2000		10.1109/HICSS.2000.926961	information and communications technology;strategic planning;knowledge management;scenario planning;marketing;operations management;strategic sourcing;management;law;information technology;commerce;outsourcing	AI	-72.5118755090609	2.9412449876408266	3338
d01352e84c1774c750abf2f346655472fdaaf13c	tactical forms: classification of applied games for game design		Entertainment game genres provide game designers with a taxonomy of known sets of mechanics, which are used as a foundation to design games. Serious games taxonomy in comparison do not provide the same kind of design knowledge. For this reason, we adopted a way of classifying serious games into four categories by tactical form, or the way the game is deployed in a certain context to achieve its primary purpose. Central to this paper is the discussion of our extended tactical from termed adaptive. DJ Fiero, a game designed to rehabilitate children with ABI (Acquired Brain Injury), is used as a case study to examine how the adaptive form fits the current sociopolitical and economic design challenges of the Dutch healthcare domain.		Micah Hrehovcsik;Joeri Taelman;Joep Janssen;Niels Keetels	2014		10.1007/978-3-658-07141-7_10	video game design;combinatorial game theory;game design;simulation;turns, rounds and time-keeping systems in games;computer science;game mechanics;mathematical game;multimedia;operations research	HCI	-69.21594013259961	-33.63593969316271	3340
2b453edf6190cec41a35179ea2c39251653abedb	vox populi annotation: measuring intensity of ideological perspectives by aggregating group judgments	computer program;mass media;social issues	Polarizing discussions about political and social issues are common in mass media. Annotations on the degree to which a sentence expresses an ideological perspective can be valuable for evaluating computer programs that can automatically identify strongly biased sentences, but such annotations remain scarce. We annotated the intensity of ideological perspectives expressed in 250 sentences by aggregating judgments from 18 annotators. We proposed methods of determining the number of annotators and assessing reliability, and showed the the sentence-level annotations on ideological perspectives were reliable across different annotator groups.	computer program;polarizer;vox	Wei-Hao Lin;Alexander G. Hauptmann	2008			computer science;social issues;mass media	NLP	-27.403275600281177	-74.68158490945497	3351
b86bcf9805d7da0dc717ec911f1b6b52100a03e0	a framework for the detection and interaction with pedestrian and objects in an unknown environment	natural language interfaces;visual scene description;semantic operators;tracking humans image analysis semantics labeling accuracy visualization;semantics;mobile object;stereo vision system;classification;computer vision;accuracy;visualization;natural language scene analysis classification tracking;natural language;pedestrian;stereo image processing;stereo vision;image analysis;humans;language;pedestrian visual scene description mobile objects detection tracking stereo vision system language semantic operators;mobile objects detection;tracking computer vision image sequences natural language interfaces object detection stereo image processing;labeling;tracking;object detection;scene analysis;image sequences	In this paper, we present a visual scene description and interaction framework for pedestrian and mobile objects detection and tracking applications. The framework is built upon a previously developed stereo vision system. The proposed algorithms raise up the information level in order to allow to query about the scene using natural language or semantic operators and give a simpler interface with other technologies.	algorithm;computer vision;natural language;natural language user interface;real-time clock;sensor web;stereopsis;top-down and bottom-up design	Alessandro Moro;Kenji Terabayashi;Kazunori Umeda;Enzo Mumolo	2010	2010 Seventh International Conference on Networked Sensing Systems (INSS)	10.1109/INSS.2010.5572219	computer vision;computer science;multimedia;communication	Robotics	-12.27306373576343	-54.36753943928045	3353
951f1e8da43b6f49023a159a51035d9fe7264eca	deriving user's profile from sparse egocentric networks: using snowball sampling and link prediction	dblp sparse egocentric networks snowball sampling link prediction user profile modeling process user social network information information mining;social networking online data mining sampling methods;communities social network services buildings sociology context data mining statistics;theorie de l information;link prediction;snowball sampling;user modeling;snowball sampling user modeling social network analysis link prediction;social network analysis;recherche d information	Several studies demonstrate effectiveness and benefits of using user's social network information to enrich user's profile. In this context, one of our contributions [1] proposes an algorithm enabling to compute user's interests using information from egocentric network extracted communities. Therefore, mining information from a small or a sparse network remains challenging because there is not enough information to enrich a relevant user's profile. So, one of the main lock is to cope with the lack of information that is considered as an important issue to extract a relevant community and could lead to misinterpretations in the user's profile modeling process. We aim to improve the performance of [1], regarding the lack of information problem, in the case of a small and/or a sparse network. We propose to add more information (i.e. relations) into user's network before extracting the data and enriching his profile. To achieve this enrichment, we suggest using snowball sampling technique to identify and add user's distance-2 neighbors (friends of a friend) into the user's egocentric network. Our experimentation conducted in DBLP demonstrates the interest of node integration into small and sparse network. This leads to the study of link prediction that enables us to provide better performances and results compared to the existing work.	algorithm;dbl-browser;gene ontology term enrichment;interaction;performance;sampling (signal processing);social network;sparse matrix;user modeling	Sirinya On-at;C. Marie-Françoise Canut;André Péninou;Florence Sèdes	2014	Ninth International Conference on Digital Information Management (ICDIM 2014)	10.1109/ICDIM.2014.6991421	snowball sampling;social network analysis;user modeling;computer science;artificial intelligence;machine learning;data mining;database;world wide web;computer security	DB	-20.76172704580792	-46.07798542582481	3354
28e88beb0c0197e0444ed9955ded23f25101a39b	adjustment and control methods for precise rotation and positioning of virtual object by hand	quaternion algebra;immersive environment;linear interpolation;spherical linear interpolation;hand manipulation;control method;rotation adjustment;immersive virtual environment	A rotation adjustment method for precisely and efficiently manipulating a virtual 3D object by hand in an immersive virtual environment is proposed. A relative direction between both hands adjusts the rotation of the virtual object. This adjustment method also uses spherical linear interpolation based on quaternion algebra to scale down rotations, making small rotation adjustment easier. The scaled adjustment enables a user to precisely manipulate the virtual object. Activation of the rotation adjustment is controlled by the distance between both hands or by the distance between the thumb and forefinger. This rotation adjustment method was implemented as well as the translational position, viewpoint, and release adjustment methods. Combinations of these adjustment and control methods were evaluated in an experiment. The experimental results suggest that the rotation adjustment method helps a user who cannot precisely control rotation by his/her hand pinching a virtual object.	bundle adjustment;linear interpolation;slerp;user interface;virtual reality	Noritaka Osawa;Kikuo Asai	2010		10.1145/1900179.1900205	computer vision;simulation;computer science;quaternion algebra;linear interpolation;computer graphics (images)	Visualization	-42.83530329269881	-46.410807451343075	3364
a86c2072b48b6be17d00097305991605ce363efa	gamifying the city: pervasive game elements in the urban environment		After years using ICT to be connected with others, the world population average weight had tremendously increased. To face the rapid spread of obesity the World Health Organization (WHO) has leveraged the popularity of augmented reality games such as Pokémon go to force people out of their homes pushing them to walk. An application, namely Gamifying the City (GC), has been set up, immediately involving millions of users. Since then, the use of the application has pervaded many other aspects of people’s city life, going beyond its original aim of making people engage in healthier habits. This paper focuses on understanding how the use of this technology is affecting our behavior in society. Author	augmented reality;goto;human body weight;pervasive informatics	Alessia Calafiore;Amon Rapp	2016			multimedia;pervasive game;business	HCI	-59.54289405375106	-28.03547824405359	3367
75bca1d5af0a0cdc27e48bc807bdb649dfc6d567	performance improvement of probabilistic transcriptions with language-specific constraints	automatic speech recognition resources;mismatched crowdsourcing;probabilistic transcription;g2p	This article describes a method for reducing the error rate of probabilistic phone-based transcriptions resulting from mismatched crowdsourcing by using language-specific constraints to post-process the phone sequence. In the scenario under consideration, there are no native-language transcriptions or pronunciation dictionary available in the test language; instead, available resources include non-native transcriptions, a rudimentary rule-based G2P, and a list of orthographic word forms mined from the internet. The proposed solution post-processes non-native transcriptions by converting them to test-language orthography, composing with testlanguage word forms, then converting back to a phone string. Experiments demonstrate that the phone error rate of the transcription is reduced, using this method, by 22% on an independent evaluation-test dataset. c © 2016 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the Organizing Committee of SLTU 2016.	baseline (configuration management);bit error rate;crowdsourcing;dictionary;experiment;logic programming;mined;orthographic projection;transcription (software)	Xiang Kong;Preethi Jyothi;Mark Hasegawa-Johnson	2016		10.1016/j.procs.2016.04.026	natural language processing;speech recognition;computer science	NLP	-22.32604930534065	-79.53686452679298	3370
d2d7948831c596ff1dde81d430e2bf3f86670dd7	how much of a person influencing the others and being influenced matters in opinion formation games		The opinion forming process in a social network could be naturally modeled as an opinion influencing and updating dynamics. This already attracted researchers interest a while ago in mathematical sociology, and recently in theoretical computer science. In so-called opinion formation games, when underlying networks are directed, a bounded price of anarchy is only known for weighted Eulerian graphs, which may not be the most general class of directed graphs that give a bounded price of anarchy. Thus, we aim to bound the price of anarchy for games with directed graphs more general than weighted Eulerian graphs in this paper. We first bound the price of anarchy for a more general class of directed graphs with conditions intuitively meaning that each node does not influence the others more than she is influenced by herself and the others, where the bounds depend on such influence differences. This generalizes the previous results on directed graphs, and recovers and matches the previous bounds in some specific classes of (directed) Eulerian graphs. We then show that there exists an example that just slightly violates the conditions with an unbounded price of anarchy. We further propose more directions along this line of research.	anarchy;directed graph;eulerian path;social network;theoretical computer science;while	Po-An Chen;Yi-Le Chen;Chi-Jen Lu	2016	CoRR		price of stability;combinatorics;mathematics;mathematical economics;algorithm;price of anarchy	Theory	-13.493709526242219	-16.610123892722072	3371
043411db28a8a1f33117560a770b96fabb439afe	the application of bibliometrics to research evaluation in the humanities and social sciences: an exploratory study using normalized google scholar data for the publications of a research institute		In the humanities and social sciences, bibliometric methods for the assessment of research performance are (so far) less common. The current study takes a concrete example in an attempt to evaluate a research institute from the area of social sciences and humanities with the help of data from Google Scholar (GS). In order to use GS for a bibliometric study, we have developed procedures for the normalisation of citation impact, building on the procedures of classical bibliometrics. In order to test the convergent validity of the normalized citation impact scores, we have calculated normalized scores for a subset of the publications based on data from the WoS or Scopus. Even if scores calculated with the help of GS and WoS/Scopus are not identical for the different publication types (considered here), they are so similar that they result in the same assessment of the institute investigated in this study: For example, the institute's papers whose journals are covered in WoS are cited at about an average rate (compared with the other papers in the journals). 1 Introduction In the classical core areas of natural and life sciences (hard sciences), quantitative methods have meanwhile become an integral part of research evaluation (Moed, 2005). In the humanities and social sciences (soft sciences) quantitative methods for the evaluation of research performance are (still) not so widespread. However, in times of limited research funding, the evaluation pressure is also rising in these disciplines, but the methodical preconditions for the application of quantitative methods are (still) not very developed. In the natural and life sciences, bibliometrics in particular has established itself as a standard procedure for quantitative research evaluation. With respect to the selection of suitable data sources and indicators, as well as the realization of a bibliometric study, standards have been developed in the meantime and also applied (Bornmann et al., 2014; Bornmann & Marx, 2014). The most used databases are Web of Science (WoS) from Thomson Reuters and Scopus from Elsevier. WoS currently contains a core set of around 11000 journals (WoS source journals); Scopus covers more than 20000 journals. However, WoS and Scopus are multidisciplinary databases which are biased towards natural and life sciences. 1.1 Problems of bibliometrics in the humanities and social sciences Bibliometrics on the basis of WoS and Scopus is unsuitable for use in the humanities and social sciences, chiefly for the following two reasons: (1) A higher proportion of …	bibliometrics;database;floor and ceiling functions;google scholar;precondition;roland gs;scopus;web of science;word lists by frequency	Lutz Bornmann;Andreas Thor;Werner Marx;Hermann Schier	2016	JASIST	10.1002/asi.23627	computer science;data science;information retrieval	ML	-77.64192331582063	-22.17993887152382	3372
3b74092563dd052d02b48ea5faa121ff345121da	semantically distinct verb classes involved in sentiment analysis	sentiment analysis	The paper describes a novel rule-based approach to classification of opinion statements on the level of individual sentences. In contrast to existing approaches, the proposed method relies on the rules elaborated for semantically distinct verb classes. To deeply analyse the type, strength, and confidence level of expressed opinion, the system relies on the compositionality principle and lexicon of sentiment-conveying terms, functional words, modifiers, and modal expressions. The method is capable of processing sentences of different complexity, including simple, compound, complex (with complement and relative clauses), and complex-compound sentences.	complement (complexity);complexity;lexicon;logic programming;modal logic;sentiment analysis;strong and weak typing;word-sense disambiguation	Alena Neviarouskaya;Helmut Prendinger;Mitsuru Ishizuka	2009			natural language processing;mathematics;linguistics;communication	NLP	-27.467916651108936	-72.15692260964148	3383
32dcd1ed2196e0123819b53246f24a0282bf7da8	visual ethnography in game design: a case study of user-centric concept for a mobile social traffic game	visual ethnography;design research;game design;traffic;urban area;mobile application	The increase in more active forms of commuting is beginning to cause friction between motorists in urban areas. This paper asks: can we use visual ethnography as a viable design research method for designing a game to address these traffic issues? This paper first conducted a visual ethnographic study with 12 respondents, filming their commutes for a week each over three months. Subsequently, by combining the ethnographic analysis and an exploration of the existing framework of hybrid reality games, the research proposes a speculative game concept, Playing in Traffic. This game aims to increase awareness and aid communication between commuters to facilitate progression through traffic.	color gradient;mixed reality;speculative execution;video game design	Kah Chan	2011		10.1145/2181037.2181051	game design;simulation;engineering;game mechanics;game art design;game developer;multimedia;advertising;game design document	HCI	-55.959190336917175	-39.36470270517419	3386
dc865cba7c9de018bff76a189ec2d8b486cdd52e	prediction in signed heterogeneous networks	social networking signed heterogeneous networks network analysis computer science communities sign prediction link prediction rule based methodology rulepredict positive features generalized least squares gls hetesign epinions networks imdb networks;signed heterogeneous networks link prediction sign prediction;motion pictures accuracy predictive models training hafnium educational institutions feature extraction;social networking online computer science	The problem of prediction is an important task in network analysis, which has attracted more attention from computer science communities. In this paper, prediction in signed heterogeneous networks is addressed, which contains two aspects, link prediction and sign prediction. Most of previous studies focus on non-signed networks that have only positive links or homogeneous networks that have only one type of nodes. However, there are many signed heterogeneous networks in which the nodes and links belong to different types and links can be either positive (indicating relationships such as trust, preferences, friendship, and etc) or negative (indicating relationships such as distrust, dislike, opposition, and etc) in real world. For link prediction, a rule-based methodology called RulePredict is proposed in the paper. In RulePredict, we first extract all features systematically which contain positive features that promote the existence of links and negative ones that reduce the possibility reversely. Then, the weights associated with different features will be learned by a supervised method based on generalized least squares (GLS). For sign prediction, we put forward a new method called HeteSign to calculate the polarity of the links based on the similarity of two objects depends on their linked objects in heterogeneous networks. Experiments are conducted on real networks, the IMDB and Epinions networks, which demonstrate that our approach gets better performance in terms of accuracy.	ampersand;computer science;distrust;experiment;generalized least squares;hyperlink;internet movie database (imdb);logic programming;network theory;semantic network;similarity measure;supervised learning	Li Pan;Zhaohui Peng;Xinjun Wang;Qingzhong Li	2014	Proceedings of the 2014 IEEE 18th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2014.6846865	computer science;theoretical computer science;machine learning;data mining	ML	-21.009247972441468	-46.12316582637114	3387
be900431c30a6c851bb62b4f1c8f10fb7bc709d9	an exploration of issues and limitations in current methods of topsis and fuzzy topsis	reliability;standards;decision making reliability standards artificial intelligence;topsis decision making fuzzy set theory;ftopsis fuzzy topsis multicriteria decision making technique for order preference by similarity to ideal solution fuzzy sets;artificial intelligence	Multi Criteria Decision Making is a challenging but vital process for organizations. One of the best-known techniques to support Multi-Criteria Decision Making is the `Technique for Order Preference by Similarity to Ideal Solution' (TOPSIS) approach. In recent years, a variety of extensions, including fuzzy extensions of TOPSIS have been proposed. Besides the many variations of standard TOPSIS, one family of extensions employing fuzzy sets is referred to as fuzzy TOPSIS (FTOPSIS). One challenge that has arisen is that it is not straightforward to choose between the multiple variants of TOPSIS existing today. Previously, none of the papers that have compared the key differences between standard and fuzzy TOPSIS have fully explored each of the step-wise stages. In this paper, we now provide a detailed comparison of these key stages in a systematic stepwise manner, clearly highlighting differences. We also identify and discuss the limitations, issues and challenges which exist in the present FTOPSIS method. The crucial and main issues are identified as relating to concepts of reliability, truth and meaning. Having identified these conceptual issues, we then go on to highlight what we argue to be the main issue, that of reliability, to discuss further. We proceed to present a potential solution and propose a framework to address the issue. This study will provide guidelines to researchers in this field and to provide potential pathways to further solutions, which have the capacity to advance the area of FTOPSIS as a whole.	common criteria;fuzzy set;stepwise regression	Elissa Nadia Madi;Jonathan M. Garibaldi;Christian Wagner	2016	2016 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2016.7737950	computer science;artificial intelligence;data mining;reliability;mathematics;management science	EDA	-5.108301440591678	-19.0554512596612	3390
a02b4b66500d0018e934cfa956018f4449f2ff4d	curbing electronic shopper perceived opportunism and encouraging trust		PurposernrnrnrnrnConsumers can face a situation of information asymmetry in electronic shopping (ES). The purpose of this paper to examine the relationships between: relational variables such as satisfaction, trust and perceived opportunism; and website cues (cognitive signals such as security and personalization, and experiential signals, such as design and entertainment).rnrnrnrnrnDesign/methodology/approachrnrnrnrnrnThe paper opted for the structural equation methodology to analyze data collected from 447 Spanish e-shoppers.rnrnrnrnrnFindingsrnrnrnrnrnResults show different factors that relate to satisfaction, trust and perceived opportunism in ES. Satisfactory experience with ES and entertainment emerge as the most relevant factors to achieve trust and prevent perceived opportunism in e-commerce.rnrnrnrnrnOriginality/valuernrnrnrnrnThe five contributions of this study are: the introduction of variables from several theoretical approaches to the study of an agency problem in e-commerce; the study of different ways to gain buyer trust and reduce perceived opportunism in an electronic shopper-vendor relationship; the application of signaling theory as part of the process of helping the principal (e-shopper) to solve their shopping problem in a context of information asymmetry; the analysis of the impact of external cues from e-vendor/site, which allows for a comparison between internal experiences and external quality signals; and the study of entertainment as an important hedonic variable in order to have satisfied and confident e-shoppers.		Sonia San Martín Gutiérrez;Nadia H. Jiménez	2017	Industrial Management and Data Systems	10.1108/IMDS-08-2016-0315	marketing;personalization;opportunism;experiential learning;engineering;principal–agent problem;cognition;originality;signalling;information asymmetry	DB	-90.2018183291288	-12.859344269064836	3396
34ffc413974e4fd2207dfd8ec1ec9eda75664195	hypertext browsing: a new model based on hypergraph's dynamic construction and data analysis methods	data analysis methods		browsing;hypertext	Bracha Shapira;Adi Raveh;Uri Hanani	1995			computer science;hypergraph;data mining;database;data analysis;hypertext	Robotics	-43.261394686441164	-23.644856637643596	3400
e3141498e71c0896fd75922b3423b0ac755b1700	entrepreneurial universities and the dynamics of academic knowledge production: a case study of basic vs. applied research in belgium	triple helice;belgica;europa;recherche fondamentale;scientometrics;communication scientifique;universite;comunicacion cientifica;industrie;industria;fundamental research;monde academique;belgique;belgium;industry;social contract;estudio caso;investigacion fundamental;production connaissance;scientometria;recherche appliquee;growth rate;scientometrie;etude cas;scientific communication;university;europe;applied research;norms;universidad;basic research;produccion conocimiento;investigacion aplicada;society;knowledge production	This paper explores issues related to the impact of Science-Industry relationships on the knowledge production of academic research groups, in particular on the alleged shift to the more applied research end under the influence of business partners' needs. Our findings from a case study of the Belgian Katholieke Universiteit Leuven ((K.U. Leuven) show a significant steady growth over time of publications produced by academic research groups involved in University-Industry linkages, closely related to factors both internal and external to the university that have stimulated academic entrepreneurial behaviour. On an aggregated level for 1985-2000, basic research publications appear to be more present than applied ones, both in total numbers and in growth rates. Our findings show that applied and basic research publications generally rose together in the same year. No clear and generalised evidence of a shift towards the applied research end determined by the involvement in U-I linkages was found, the weak indications of such a shift within groups coming only for groups that have already high applied versus basic orientation. These results suggest that the academic research groups examined have developed a record of applied publications without affecting their basic research publications and, rather than differentiating between applied and basic research publications, it is the combination of basic and applied publications that consolidate the group's R&D potential. Accordingly, critical assessments of the University side of the emerging 'Triple Helix' need to take into account the dynamic nature of the research dimension.		Liana Marina Ranga;Koenraad Debackere;Nick von Tunzelmann	2003	Scientometrics	10.1023/A:1026288611013	social science;philosophy;epistemology;scientometrics;sociology;society;operations research;law;social contract	Web+IR	-75.4264993506155	-21.74787389377517	3401
313d2c99ebf6345320a5cb99e358a06d0eed6860	semi-automated semantic annotation of the biomedical literature		Semantic annotations are a core enabler for efficient retrieval of relevant information in the life sciences as well in other disciplines. The biomedical literature is a major source of knowledge, which however is underutilized due to the lack of rich annotations that would allow automated knowledge discovery. We briefly describe the results of the SASEBio project (Semi Automated Semantic Enrichment of the Biomedical Literature) which aims at adding semantic annotations to PubMed abstracts, in order to present a richer view of the existing literature.	gene ontology term enrichment;pubmed;semiconductor industry	Fabio Rinaldi	2014			semantic computing;computer science;data science;data mining;world wide web;information retrieval	NLP	-33.8547200003517	-67.48319582101368	3402
ddd66070d89bbc4e251045b63a39ac0419997a94	proceedings of the 4th biennial international workshop on balto-slavic natural language processing, bsnlp@acl 2013, sofia, bulgaria, august 8-9, 2013			natural language processing		2013				Robotics	-55.29135551202168	-10.711906039807404	3404
9635be9c67ebcbcdbfc44e19ee0517900f1c9230	towards a conversational expert system for rhetorical and vocal quality assessment in call center talks		This article presents the concept and development steps towards a conversational expert system for rhetorical and vocal quality assessment in call center talks. At first the state of the art in quality assessment is discussed. The influencing rhetorical and vocal factors are introduced. In our novel approach, the recognition of vocal factors is modeled by competing classification systems and combined into a multi-classifier system which is based on decision trees. Finally we propose an expert system which incorporates the generated decision rules. The system accuracy can be improved by user-adapted rule sets. Furthermore solutions to the problem of inconsistent rules are discussed.	decision tree;expert system;learning classifier system;rule 184	Mathias Walther;Baldur Neuber;Oliver Jokisch;Taïeb Mellouli	2015			computer science;speech recognition;vocal quality;expert system;rhetorical question	AI	-12.16806563191302	-86.86249494661874	3408
482aa953a4b34ee0d29483e21cf264a62e7ee228	an explanation component for a connectionist inference system			connectionism;inference engine	Joachim Diederich	1990			machine learning;artificial intelligence;connectionism;computer science;inference	ML	-27.431810357021515	-8.415802617749758	3409
0de38149e6976a43192b8f2f3c2d2c88df281cf2	tell me why bob dylan and the beatles song titles are used in biomedical literature		How often and why do scientists refer to music titles in their papers? There has been a growing trend of using popular music titles in scientific literature since the 1990s. We have investigated the extent to which songs by Nobel Prize winner Bob Dylan, and by The Beatles are used in titles of biomedical scientific publications. The Beatles appear more popular than Dylan (in 589 and 211 publications, respectively): they are used more often in the titles and work with Beatles inspired titles also appear to be cited more often than work using Dylan titles. The Beatles’ hit used most often is The long and winding road; for Dylan it is The times they are a-changing. There are also geographical and gender-related preferences. This interdisciplinary study used	dylan;scientific literature;the times	Ger T. Rijkers;Anya Luscombe;Carla Sloof	2017	Webology			HCI	-75.4966128334004	-19.766289032654264	3414
87ccbad888066f2491c7727f6ec72c14bc031b46	a directory service for multi-literate users	boolean algebra;cataloguing;graphical user interfaces;query formulation;query processing;boolean query mechanism;gui;ldap system;catalogue database service;computer literacy;iconography;lightweight directory access protocol;marginalized rural communities;multiliterate user directory service;people directory searches;user query formulation;written literacy	User directory services, such as a database service cataloging people in a company or community, are important components today to many online applications. Furthermore, the design of computer applications and interfaces that are appropriate to currently marginalized communities, such as those in rural and poor areas of the developing world, has become an increasingly important research area. We have developed and tested a novel user directory service made specifically for rural communities and for users with low written and computer literacy. Our system supports a new interface design that allows users to perform directory searches for people across a number of dimensions without requiring written literacy nor keyboarding skills. This user directory service was tested in a rural community of the Dominican Republic. Initial results suggest that the general user interface and iconography, was effective in supporting users with a range of written literacy and computer skills. However, results show that the Boolean query mechanism, as implemented, is difficult to master	boolean algebra;computer;directory service;typing;user interface	M. Sin;M. Escobedo;M. Best	2004	2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)		lightweight directory access protocol;directory service;computer science;operating system;graphical user interface;database;multimedia;information technology;world wide web;organizational unit	Visualization	-65.64539980138332	-41.819380418649686	3417
0b8e1a623896089774f4275768612ee573cae486	post-processing association rules using networks and transductive learning	databases;silicon;pattern classification data mining learning artificial intelligence;label propagation;networks;association rules;association rules classification algorithms mathematical model equations silicon computational modeling databases;pruning;computational modeling;conferenceobject;classification algorithms;mathematical model;networks association rules pruning post processing label propagation;classification task transductive learning algorithm association rule post processing approach;post processing	Association is widely used to find relations among items in a given database. However, finding the interesting patterns is a challenging task due to the large number of rules that are generated. Traditionally, this task is done by post-processing approaches that explore and direct the user to the interesting rules of the domain. Some of these approaches use the user's knowledge to guide the exploration according to what is defined (thought) as interesting by the user. However, this definition is done before the process starts. Therefore, the user must know what may be and what may not be interesting to him/her. This work proposes a general association rule post-processing approach that extracts the user's knowledge during the post-processing phase. That way, the user does not need to have a prior knowledge in the database. For that, the proposed approach models the association rules in a network, uses its measures to suggest rules to be classified by the user and, then, propagates these classifications to the entire network using transductive learning algorithms. Therefore, this approach treats the post-processing problem as a classification task. Experiments were carried out to demonstrate that the proposed approach reduces the number of rules to be explored by the user and directs him/her to the potentially interesting rules of the domain.	algorithm;association rule learning;database;machine learning;transduction (machine learning);video post-processing	Renan de Padua;Solange Oliveira Rezende;Veronica Oliveira de Carvalho	2014	2014 13th International Conference on Machine Learning and Applications	10.1109/ICMLA.2014.57	statistical classification;association rule learning;computer science;artificial intelligence;pruning;machine learning;pattern recognition;mathematical model;data mining;silicon;computational model;video post-processing	DB	-13.477020291215023	-63.50938324187783	3419
791bde51e77b7edc7adcc613aaaf86d02e731a42	guest editors' foreword				Otfried Cheong;Yoshio Okamoto	2012	Int. J. Comput. Geometry Appl.	10.1142/S0218195912020013		Theory	-52.4849361260402	-14.076509454180911	3422
2ce6d8ae814dea40c27217f007d2a56faa6e6036	factors influencing sme compliance with government regulation on use of it: the case of south africa	discriminant function analysis;electronic commerce;information technology;government regulation;psychological factor;it;smes;compliance;south africa;development policy	Information technologies (IT) play a key role in the development of nations. Governments are encouraging IT adoption by small and medium-sized organizations (SME) to address poverty, facilitate networking and alliances between buyers and sellers, improve market intelligence, and increase productivity (Nicol, 2003). While IT can provide such benefits, the rise in the level of electronic abuse has led to the establishment of regulatory measures by governments and several SMEs are struggling to comply with them (SMME Review 2003, 2004; SBP, 2003). In addition, there have been very few studies investigating compliance with legislations in SMEs (Massey, 2003; SBP, 2003; Washkush, 2006) and in particular compliance with regulation on use of IT. Consequently, little assistance or guidance is available for aBstraCt	discriminant;security controls	Michael Kyobe	2009	JGIM	10.4018/jgim.2009040102	superconducting magnetic energy storage;public relations;regulation;computer science;marketing;discriminant function analysis;sociology;management;law;information technology;economic growth;commerce	AI	-82.4050104014991	-7.40645131912641	3427
2a0e88434fd0bc811adc9a0a50c69a5254eea74c	engage and educate: engineering laboratory activities for first-year engineering students	seminars;stem;logic gates;capacitors;transistors;resistors;switches	This paper discusses the importance and effectiveness of structured hands-on STEM-related project-based engineering laboratory activities in the critical entry-level course, First-Year Seminar in Engineering, for undergraduate engineering majors at ABET-accredited institutions of higher education. At our institution, the First-Year Seminar in Engineering is offered once each year during the fall term. The enrollment in this course ranges from ninety to hundred first-year students who are expected to graduate with engineering degrees from the four-year ABET-accredited programs. One component of this course comprises hands-on engineering laboratory activities in sessions of short duration (fifty-five minutes apiece) in disciplines such as Biomedical Engineering (BME), Electrical and Computer Engineering (ECE), Environmental Engineering (ENV), and Mechanical Engineering (ME). In the short interval of time allotted for STEM-based laboratory experiences, the motivation, commitment, and level of engagement can range from total indifference to unbridled enthusiasm with the desire to do and learn more. The broad goal is to deliver key aspects of the engineering design process, from concept-to-product (the E in STEM), during this short interval of time. Therefore, it behooves us to develop STEM-based, project-oriented laboratory activities that focus the student on well-defined, easy-to-attain, yet insightful experimental objectives.	computer engineering;electrical engineering;engineering design process;experience;hands-on computing	Ramakrishnan Sundaram	2016	2016 IEEE Frontiers in Education Conference (FIE)	10.1109/FIE.2016.7757662	engineering;electrical engineering;mechanical engineering	DB	-79.99157358066458	-32.19633176162977	3431
4a6f98182e52aad53a6fcf204659626c22c6a6b5	improved recommendations via (more) collaboration	information extraction;data exchange;online learning;rule inference;recommender system;web objects;collaborative filtering	We consider in this paper a popular class of recommender systems that are based on Collaborative Filtering (CF for short). CF is the process of predicting customer ratings to items based on previous ratings of (similar) users to (similar) items, and is typically used by a single organization, using its own customer ratings.  We argue here that a multi-organization collaboration, even for organizations operating in different subject domains, can greatly improve the quality of the recommendations that the individual organizations provide to their users. To substantiate this claim, we present C2F (Collaborative CF), a recommender system that retains the simplicity and efficiency of classical CF, while allowing distinct organizations to collaborate and boost their recommendations. C2F employs CF in a distributed fashion that improves the quality of the generated recommendations, while minimizing the amount of data exchanged between the collaborating parties. Key ingredient of the solution are succinct signatures that can be computed locally for items (users) in a given organization and suffice for identifying similar items (users) in the collaborating organizations. We show that the use of such compact signatures not only reduces data exchange but also allows to speed up, by over 50%, the recommendations computation time.	antivirus software;collaborative filtering;computation;distributed computing;recommender system;time complexity;type signature	Rubi Boim;Haim Kaplan;Tova Milo;Ronitt Rubinfeld	2010		10.1145/1859127.1859143	data exchange;computer science;collaborative filtering;data mining;database;world wide web;information extraction;recommender system	Web+IR	-12.442664580505964	-37.77338756051914	3445
04d4cc36d377d48c95d37940c5a0db265dd7b2c2	ontology stratification methods: a comparative study		Comparing the importance of axioms in ontologies is an essential task in a variety of applications such as ontology repair and inconsistency management. It guides the choice of axioms to remain in the ontology or which should prevail when a conflict arises. While evaluating the importance of an axiom is difficult, there are different approaches to stratify ontologies by criteria that act as proxies for importance. However, there is little work about how these methods are related and their adequacy considering different applications. In this work, we evaluate specificity and modularity-based stratification approaches, and work towards understanding how they relate. We compare empirically the result of five stratification methods over a corpus of real-world ontologies. In particular, we investigate correlations between their rankings and their ability to distinguish axioms.	axiomatic system;cns;computation;debugging;depth perception;experiment;ontology (information science);sensitivity and specificity;text corpus;web ontology language	Ricardo Ferreira Guimarães;Ulrike Sattler;Renata Wassermann	2018				AI	-44.36542295441991	-67.70964914277916	3446
44110a133aaf8ec3bd687ab36371a85402e16d69	chinese computational linguistics and natural language processing based on naturally annotated big data			big data;computation;computational linguistics;natural language processing		2017		10.1007/978-3-319-69005-6		NLP	-30.932534446911028	-77.34433726043461	3451
60176f3f3dd4454b7195bf864001fd4749b88078	where it's at: mapping battle highlights new era of revenue and development models	google;apple geolocation mobile computing internet mapping platforms google;mobile computing geographic information systems internet;mapping platforms;internet;global positioning system;geographic information systems;apple;economics;mobile computing;mapping ecosystem mapping battle highlights new era development models revenue models mobile dominated internet mapping platforms geolocation platforms financial growth mobile location services;geolocation;internet mobile computing global positioning system economics	Experts predict that we're at the dawn of a mobile-dominated Internet in which geolocation and mapping platforms will drive considerable financial growth and spending. For these forecasts to come true, however, the maps that are the base of these mobile location services must be accurate. Several intriguing questions surround the overall development of the mapping ecosystem.	ecosystem;geolocation	Greg Goth	2013	IEEE Internet Computing	10.1109/MIC.2013.18	mobile search;the internet;simulation;global positioning system;computer science;operating system;geolocation;internet privacy;mobile computing;law;world wide web	Metrics	-83.45756340935233	-10.2470157704152	3454
54f17a6b047f9cd8c79e5ed5907ff9a7d469774b	rational task analysis: a methodology to benchmark bounded rationality	benchmarking;journal_article;rational analysis;ecological rationality;bounded rationality;bounded rationality benchmarking optimality task environment rational analysis ecological rationality;optimality;task environment	How can we study bounded rationality? We answer this question by proposing rational task analysis (RTA)—a systematic approach that prevents experimental researchers from drawing premature conclusions regarding the (ir-)rationality of agents. RTA is a methodology and perspective that is anchored in the notion of bounded rationality and aids in the unbiased interpretation of results and the design of more conclusive experimental paradigms. RTA focuses on concrete tasks as the primary interface between agents and environments and requires explicating essential task elements, specifying rational norms, and bracketing the range of possible performance, before contrasting various benchmarks with actual performance. After describing RTA’s core components we illustrate its use in three case studies that examine human memory updating, multitasking behavior, and melioration. We discuss RTA’s characteristic elements and limitations by comparing it to related approaches. We conclude that RTA provides a useful tool to render the study of bounded rationality more transparent and less prone to theoretical confusion.	anomaly detection;benchmark (computing);computer multitasking;experiment;information;rationality;sensor;task analysis;technical standard	Hansjörg Neth;Chris R. Sims;Wayne D. Gray	2015	Minds and Machines	10.1007/s11023-015-9368-8	ecological rationality;computer science;artificial intelligence;management science;rational analysis;social psychology;algorithm;cognitive science;bounded rationality;benchmarking	AI	-14.636438914548263	1.6279855450861793	3466
979955f2ada1e308bc0c0256dee96d543c3d3d8c	a speech-based web co-authoring platform for the blind		Today, even in the presence of IT applications built for the blind, they are facing many problems. Either the applications are for individual’s use or if offer collaborative writing, they are not up to the mark. In the collaborative writing, for instance, in Microsoft Word Add-In and the Google Docs UI, the authors do not know about changes made in the document. Though the former facilitates this feature through adding comments in the document, but the dynamic actions, e.g. notifications (the user sign-in, editing the document, closing it) and communication option is yet to be considered. We describe a web application for the blind community to work on a shared document from different locations. Users are able to write, read, edit, and update the collaborative document in a controlled way. We aim to enhance the self-reliance among users and improve performance.	closing (morphology);docs (software);google forms;microsoft word for mac;user interface;web application	Madeeha Batool;Mirza Muhammad Waqar;Ana María Martínez Enríquez;Aslam Muhammad	2016		10.1007/978-3-319-62434-1_12	machine learning;multimedia;web application;collaborative writing;artificial intelligence;computer science	HCI	-44.50053809588647	-24.72563307562276	3471
7cdcc56e8e57dc0e6e2261808d24d7de94351c18	keeping the internet open with an open-source virtual assistant		Virtual assistants, such as Alexa, Google Home, and Siri, are revolutionizing our digital life. In the future, they will provide us with a uniform, fully personalized, natural-language interface to all our diverse data sources, web services and IoT devices. The virtual assistant will become a powerful platform as it sees all our personal data and has great influence over the services and vendors we use. We propose a collaborative research effort to develop open-source virtual assistant technology, in concert with a commercially viable distributed infrastructure that safeguards users' data privacy, supports interoperability, and promotes open competition. To jumpstart this effort, we have developed Almond, a working open-source prototype of distributed virtual assistants. Almond lets users use natural language to share their data, IoT, and services with fine-grain control, while preserving their privacy by keeping data on their own devices. Almond also lets users issue advanced commands that monitor real-time events and connect multiple services together. This research lays the groundwork for the creation of three key open, non-proprietary, collaborative virtual assistant resources: (1) Thingpedia, a repository of virtual assistant skills, (2) LUInet (Linguistic User Interface Network), a neural network that translates natural language into ThingTalk, a virtual assistant programming language, and (3) a Distributed ThingTalk Protocol, DTP, that supports sharing with privacy via cooperating virtual assistants.	artificial neural network;digital life;distributed transaction;information privacy;interoperability;natural language;open-source software;personalization;personally identifiable information;programming language;prototype;real-time transcription;siri;user interface;web service	Monica S. Lam	2018		10.1145/3241539.3241586	world wide web;computer network;web service;interoperability;natural language;the internet;natural language user interface;computer science;digital life;information privacy;user interface	Web+IR	-41.92362078093927	-23.984412060335842	3477
274dc69dd24c297b873a53126bde7f6fdb441a70	empowerment and embodiment for collaborative mixed reality systems			mixed reality	Ye Pan;David Sinclair;Kenny Mitchell	2018	Journal of Visualization and Computer Animation	10.1002/cav.1838	simulation;telecollaboration;human–computer interaction;mixed reality;computer science;empowerment	Visualization	-52.62541332591964	-34.426409184351684	3478
0aadec9721e54c01d17faa4b6e41e6d7070225d0	personalized news recommendation with context trees	news;publikationer;real time;konferensbidrag;personalization;online recommender system;recommender system;artiklar;rapporter;artificial intelligence laboratory epfl	The proliferation of online news creates a need for filtering interesting articles. Compared to other products, however, recommending news has specific challenges: news preferences are subject to trends, users do not want to see multiple articles with similar content, and frequently we have insufficient information to profile the reader.  In this paper, we introduce a class of news recommendation systems based on context trees. They can provide high-quality news recommendations to anonymous visitors based on present browsing behaviour. Using an unbiased testing methodology, we show that they make accurate and novel recommendations, and that they are sufficiently flexible for the challenges of news recommendation.	recommender system	Florent Garcin;Christos Dimitrakakis;Boi Faltings	2013		10.1145/2507157.2507166	news;computer science;personalization;multimedia;internet privacy;world wide web;information retrieval;recommender system;news aggregator	Web+IR	-25.83842240866009	-48.146117979322746	3480
121ce9bf0cd42a7b42c967a1889acad37b6cb605	the surface of language and humanities computing	databases;sentence structure;computational techniques;century 20;computer uses in education;semantics;higher education;ensemble flou;computer modelling;etats unis;symbols literary;language research;semantique;literary theory;structural grammar;structural analysis linguistics;modelisation;cognitive process;large scale;systeme linguistique;text structure;humanities;language processing;text database;siecle 20;processus cognitif;literary studies;cognition;theorie litteraire;etudes litteraires;computer software;computer analysis;devinette;usa;cognitive processes;traitement informatique;guessing game;humanities instruction	Recent articles have noted that humanities computing techniques and methodologies remain marginal to mainstream literary scholarship. Mark Olsen's paper discusses this phenomenon and argues for large scale analyses of text databases that would incorporate a shift in theoretical orientation to include greater stress on intertextuality and sign theory. Part of Olsen's argument revolves on the need to move away from the syntactic and overt grammatical elements of textual language to more subtle semantics and meaning systems. While provocative and important, Olsen's stance remains rooted in literary theoretical constructs. Another level of language, the cognitive, offers equally interesting challenges for humanities computing, though the paradigms for this type of computer-based exploration are derived from disciplines traditionally removed from the humanities. The riddle, a nearly universal genre, offers a window onto some of the cognitive processes involved in deep level language function. By analyzing the riddling process, different methods of computational modelling can be inferred, suggesting new avenues for computing in the humanities.	digital humanities	Charles Henry	1993	Computers and the Humanities	10.1007/BF01829381	natural language processing;cognition;philosophy;computer science;literary theory;mathematics;semantics;linguistics;sociology;literature	NLP	-54.2700925860186	-23.0489029986097	3481
542bbb347076536de80cef3e59b6641dfff1425e	comparative statics in a simple class of strategic market games	market entry;hc economic history and conditions;strategic market game;competitive equilibrium;two sided market;comparative statics;strategic market games two sided markets bilateral oligopoly supermodularity and comparative statics market entry	This paper investigates the e¤ects of entry in two-sided markets where buyers and sellers act strategically. Applying new tools from supermodular optimization/games, su¢ cient conditions for di¤erent comparative statics results are obtained. While normality of one good is su¢ cient for the equilibrium price to be increasing in the number of buyers, normality of both goods is required for equilibrium bids and sellersequilibrium utilities to be increasing in the number of buyers. When the economy is replicated, normality of both goods and gross substitutes guarantee that the equilibrium of the strategic market game converges monotonically (in quantities) to the competitive equilibrium. Simple counter-examples are provided to settle other potential conjectures of interest. jel: D43, D51, L13 keywords: Strategic market games, two-sided markets, bilateral oligopoly, supermodularity and comparative statics, market entry. We are grateful to an anonymous referee of this Journal, Stefano Demichelis, Jean-Francois Mertens and Ben Zissimos for helpful suggestions and/or feedback. Thanks also go to participants of the workshop in honor of Jean Gabszewicz (CORE, Louvain-la-Neuve, 2002) and of the VIth SAET Meeting (Rhodos, 2003) for their comments. yDepartment of Economics, University of Arizona, Tucson, AZ 85721 (E-mail: ramir@eller.arizona.edu) zGREQAM, Aix-Marseille Universités. (E-mail:francis.bloch@univmed.fr) Francis Bloch is also a¢ liated with the University of Warwick.	assignment zero;bilateral filter;bilateral sound;bloch sphere;francis;goto;jean;linear algebra;louvain modularity;mathematical optimization;nash equilibrium;supermodular function	Rabah Amir;Francis Bloch	2009	Games and Economic Behavior	10.1016/j.geb.2007.09.002	industrial organization;partial equilibrium;economics;comparative statics;supply and demand;microeconomics;mathematical economics;market economy;factor market	ECom	-6.932398411204399	-4.321251342080804	3484
d6e8fb9ac7588fd2db2fc649c7fdd4660b5b38bf	navcog: turn-by-turn smartphone navigation assistant for people with visual impairments or blindness	assistive technologies;turn by turn navigation;bluetooth low energy beacons;navigation assistance for people with visual impairments or blindness;indoor and outdoor localization	NavCog is a novel smartphone navigation system for people with visual impairments or blindness, capable of assisting the users during autonomous mobility in complex and unfamiliar indoor/outdoor environments.  The accurate localization achieved by NavCog is used for precise turn-by-turn way-finding assistance as the first step, but the ultimate goal is to present a variety of location based information to the user, such as points of interest gathered from social media and online geografic information services.	autonomous robot;point of interest;smartphone;social media	Dragan Ahmetovic;Cole Gleason;Kris M. Kitani;Hironobu Takagi;Chieko Asakawa	2016		10.1145/2899475.2899509	turn-by-turn navigation;computer vision;simulation;geography;multimedia	HCI	-39.343663509707305	-43.82704977489566	3491
6c1799171c24ad676d6ddc6fac43a4c785fddab5	the ethnic lyrics fetcher tool	signal image and speech processing;acoustics;mathematics in music;engineering acoustics	The task of automatic retrieval and extraction of lyrics from the web is of great importance to different Music Information Retrieval applications. However, despite its importance, very little research has been carried out for this task. For this reason, in this paper, we present the Ethnic Lyrics Fetcher (ELF), a tool for Music Information Researchers, which has a novel lyrics detection and extraction mechanism. We performed two experiments to evaluate ELF’s lyrics extraction mechanism and its performance as a lyrics fetcher tool. Our experimental results show that ELF performs better than the current state of the art, using website-specific lyrics fetchers or manually retrieving the lyrics from the web.	apache nutch;experiment;information retrieval	Rafael P. Ribeiro;Murilo Almeida;Carlos Nascimento Silla	2014	EURASIP J. Audio, Speech and Music Processing	10.1186/s13636-014-0027-4	speech recognition;acoustics;physics	NLP	-28.209283119682294	-68.68853086972976	3495
976282526b6a4b7c6bd498e7b092e64ae249a253	software security in an internet world: an executive summary	electronic commerce;risk management;risk management security of data internet business communication electronic commerce;business communication;internet;software security;collaborations software security internet risk businesses sales purchasing;security of data;security business application software marketing and sales web and internet services operating systems collaborative software internet telephony programming profession testing	Businesses of all sizes use the Internet for sales, purchasing, and collaborations. They all need reliable systems. Faced with substantial numbers of reported security problems, Internet users must decide how much risk they are willing to take to participate in what the Internet world offers. After presenting the scope and origin of the Net's security problems, the authors outline three immediate steps we can take to help ensure software security. The third, examination and repair of existing systems, rivals the magnitude of the Y2K worldwide effort.	application security	Timothy J. Shimeall;John J. McDermott	1999	IEEE Software	10.1109/52.776950	software security assurance;internet architecture board;public relations;cloud computing security;web application security;the internet;security through obscurity;security information and event management;security association;risk management;internet draft;computer science;threat;information security;marketing;security service;internet presence management;business communication;commerce	Vision	-69.58386939186951	-9.761985036607552	3502
b298dfd62ece4fbe8dcdc3129ea7ce29eee0e5c6	downs and acrosses: textual markup on a stroke level	informatica;paleogeographie;paleogeografia;balisage document;text;information communication technology;computacion informatica;sciences humaines;caracter manuscrito;historia y critica literaria;xml language;manuscript character;filologias;grupo de excelencia;ciencias humanas;texte;markup;codificacion;linguistica;humanities;ciencias basicas y experimentales;old document;documento antiguo;coding;etiqueta;informatique;computer science;paleogeography;grupo a;texto;caractere manuscrit;langage xml;lenguaje xml;nueva tecnologia informacion comunicacion;technologie information communication;codage;document ancien	Textual encoding is one of the main focuses of Humanities Computing. However, existing encoding schemes and initiatives focus on ‘text’ from the character level upwards, and are of little use to scholars, such as papyrologists and palaeographers, who study the constituent strokes of individual characters. This paper discusses the development of a markup system used to annotate a corpus of images of Roman texts, resulting in an XML representation of each character on a stroke by stroke basis. The XML data generated allows further interrogation of the palaeographic data, increasing the knowledge available regarding the palaeography of the documentation produced by the Roman Army. Additionally, the corpus was used to train an Artificial Intelligence system to effectively ‘read’ in stroke data of unknown text and output possible, reliable, interpretations of that text: the next step in aiding historians in the reading of ancient texts. The development and implementation of the markup scheme is introduced, the results of our initial encoding effort are presented, and it is demonstrated that textual markup on a stroke level can extend the remit of marked up digital texts in the humanities.	artificial intelligence system;digital humanities;documentation;markup language;xml	Melissa Terras;Paul Robertson	2004	LLC	10.1093/llc/19.3.397	ruleml;natural language processing;information and communications technology;xml;speech recognition;computer science;palaeogeography;pcdata;linguistics;markup language;coding;world wide web	AI	-32.711372509633	-77.7539319979191	3504
e3eede30ce53318c23dc75ad4e07004ad263851b	comparing context-aware recommender systems in terms of accuracy and diversity	diversity;contextual modeling;post filtering;accuracy;pre filtering;performance measures;context aware recommender systems;cars	Although the area of context-aware recommender systems (CARS) has made a significant progress over the last several years, the problem of comparing various contextual pre-filtering, post-filtering and contextual modeling methods remained fairly unexplored. In this paper, we address this problem and compare several contextual pre-filtering, post-filtering and contextual modeling methods in terms of the accuracy and diversity of their recommendations to determine which methods outperform the others and under which circumstances. To this end, we consider three major factors affecting performance of CARS methods, such as the type of the recommendation task, context granularity and the type of the recommendation data. We show that none of the considered CARS methods uniformly dominates the others across all of these factors and other experimental settings; but that a certain group of contextual modeling methods constitutes a reliable “best bet” when choosing a sound CARS approach since they provide a good balance of accuracy and diversity of contextual recommendations.	eclipse process framework;human body weight;marginal model;recommender system;sparse matrix	Umberto Panniello;Alexander Tuzhilin;Michele Gorgoglione	2012	User Modeling and User-Adapted Interaction	10.1007/s11257-012-9135-y	simulation;data mining;accuracy and precision;world wide web;statistics	Web+IR	-20.071541506761598	-50.90509218291508	3509
64c25e68cdfc301f6dae1ec9a170b2bbcb1a6a61	adding possibilistic knowledge to probabilities makes many problems algorithmically decidable		Many physical theories accurately predict which events are possible and which are not, or – in situations where probabilistic (e.g., quantum) effects are important – predict the probabilities of different possible outcomes. At first glance, it may seem that this probabilistic information is all we need. We show, however, that to adequately describe physicists’ reasoning, it is important to also take into account additional knowledge – about what is possible and what is not. We show that this knowledge can be described in terms of possibility theory, and that the presence of this knowledge makes many problems algorithmically decidable.	algorithm;possibility theory	Olga Kosheleva;Vladik Kreinovich	2015			artificial intelligence;mathematics;algorithm	AI	-16.407233540326207	0.8122214277248679	3517
4a2c5356a45afbd07f023905937493911cc7cd03	naf: the netsa aggregated flow tool suite	time series;data format;numerical analysis;data visualization;network flow	In this paper we present a new suite of tools – NAF (for NetSA Aggregated Flow) – that accepts network flow data in multiple different formats and flexibly processes it into time-series aggregates represented in an IPFIX-based data format. NAF also supports both unidirectional and bidirectional flow data by matching uniflows into biflows where sufficient information is available. These tools are designed for generic aggregation of flow data with a focus on security applications. They can be used to reduce flow data for long-term storage, summarize it as the first step in numerical analysis, or as a back-end to flow data visualization processes.	data visualization;flow network;nato architecture framework;numerical analysis;time series	Brian Trammell;Carrie Gates	2006			data flow diagram;flow network;numerical analysis;computer science;time series;data mining;database;world wide web;data visualization	HPC	-37.08604663567433	0.33236533571366844	3521
8be70a1fed95771c5d39eec359ac5abbadce1195	predicting users’ search behavior using stochastic multi-mode network models		Multidimensional relationships can be represented as a multi-mode network or graph, where each vertex or node corresponds to an object, and each edge or link is attributed to one of the multiple types of relationships between a pair of objects. Web search log includes users' search behavior and can also be represented as such a multi-mode network, where each vertex corresponds to a query and each attributed edge corresponds to a relationship between a pair of queries. The relational attributes can be derived from multiple assumptions, for instance, two queries are considered to be related to each other when two different users input those queries and click through from respective search result lists to the sameWeb pages. In order to analyze such complex data, this paper proposes a new multi-mode block model based on latent variable modeling. We evaluate the effectiveness of our multi-mode block model through experiments on the task of predicting queries related to each given query using real search query log.	experiment;graph (discrete mathematics);latent variable;mathematical optimization;multi-objective optimization;sparse matrix;web search engine	Shohei Umehara;Koji Eguchi	2017	2017 IEEE International Conference on Data Mining Workshops (ICDMW)	10.1109/ICDMW.2017.25	mixture model;web page;latent variable model;network model;artificial intelligence;web search query;machine learning;data modeling;computer science;complex data type;graphical model	DB	-17.12712987757591	-48.07305303249337	3532
895639b531736866657c14a8fc726367b5e4a57c	only for casual players?: investigating player differences in full-body game interaction	video games;motion gestures;full body interaction;kinect;player differences	Full-body motion gestures enable realistic and intuitive input in video games. However, little is known regarding how different kinds of players engage/disengage with full-body game interaction. In this paper, adopting a user-typing approach, we explore player differences and their preferences in full-body gesture interaction (i.e., Kinect). Specifically, we hypothesize three human factors that influence player engagement in full-body game interaction, i.e., the player's motivation to succeed (achiever vs. casual player), motivation to move (mover vs. non-mover), and game expertise (gamer vs. non-gamer). To explore the hypotheses, we conducted an experiment where participants were tasked with playing three different video games supporting full-body game gestures. The results suggest a significant correlation and main effect of the three factors on players' engagement. The results also suggest three important game properties that affect players' preferences: level of cognitive challenge, level of physical challenge and level of realistic interaction.	human factors and ergonomics;kinect	Ryo Mizobata;Chaklam Silpasuwanchai;Xiangshi Ren	2014		10.1145/2592235.2592244	non-cooperative game;video game design;game design;simulation;simultaneous game;engineering;game mechanics;multimedia;screening game;sequential game;communication;complete information	HCI	-51.9293678509576	-50.12914519871989	3539
b7681545240988a2369d5d6e728f8ba280c4c312	pbs: an economical natural language query interpreter	information retrieval;natural language	A natural language interface, named PBS, to a bibliographic information retrieval system, is described, which receives natural language search statements from an end-user and identifies search facets and implied Boolean logic operators. The program is intended for use in conjunction with an intermediary program (OAK) for online database searching, operating in a useru0027s personal computer. Such a program must be fast and make minimal demands on memory, which places severe restrictions on storage of dictionaries and thesauri needed for full natural language interpretation. This initial version deals with a single domain, bibliographic files, almost all of which use the same attributes, such as subject, author, or journal name. The objective of PBS is to identify terms in a natural language query, classify them by attribute, recognize the boolean logic stated or implied, conflate terms that have minor spelling variations, and present the terms to the intermediary program, organized by facet or term category. In testing, the main difficulty resulted from false identification of journal names. Yet, in light of the editorial capabilities of OAK, which allow a user to correct a query before it is given to an IRS, PBS can be regarded as a workable natural language interface that can alleviate some of the problems inherent in native command languages. © 1993 John Wiley u0026 Sons, Inc.	natural language user interface	Uwe Samstag-Schnock;Charles T. Meadow	1993	JASIS	10.1002/(SICI)1097-4571(199306)44:5%3C265::AID-ASI2%3E3.0.CO;2-V	natural language processing;language identification;boolean algebra;natural language programming;computer science;artificial intelligence;applied linguistics;database;linguistics;natural language;user interface;world wide web;information retrieval;algorithm	NLP	-36.615187236299754	-73.68158426896433	3541
fad2c40e022bf16390715e0f93b9942598fdc7d9	feature generation and representations for protein-protein interaction classification	text classification;large scale;automatic detection;protein protein interaction;biomedical text classification;feature representation;ppi	Automatic detecting protein-protein interaction (PPI) relevant articles is a crucial step for large-scale biological database curation. The previous work adopted POS tagging, shallow parsing and sentence splitting techniques, but they achieved worse performance than the simple bag-of-words representation. In this paper, we generated and investigated multiple types of feature representations in order to further improve the performance of PPI text classification task. Besides the traditional domain-independent bag-of-words approach and the term weighting methods, we also explored other domain-dependent features, i.e. protein-protein interaction trigger keywords, protein named entities and the advanced ways of incorporating Natural Language Processing (NLP) output. The integration of these multiple features has been evaluated on the BioCreAtIvE II corpus. The experimental results showed that both the advanced way of using NLP output and the integration of bag-of-words and NLP output improved the performance of text classification. Specifically, in comparison with the best performance achieved in the BioCreAtIvE II IAS, the feature-level and classifier-level integration of multiple features improved the performance of classification 2.71% and 3.95%, respectively.	bag-of-words model in computer vision;biocreative;biological database;body of uterus;digital curation;document classification;entity name part qualifier - adopted;experiment;extraction;feature integration theory;internet authentication service;named entity;named-entity recognition;natural language processing;normalize;part-of-speech tagging;pixel density;proton pump inhibitors;sensor;shallow parsing;protein protein interaction	Man Lan;Chew Lim Tan;Jian Su	2009	Journal of biomedical informatics	10.1016/j.jbi.2009.07.004	protein–protein interaction;computer science;pattern recognition;u.s. producer price index;data mining;information retrieval	NLP	-24.26188130572709	-70.07816447459092	3550
ee433d18a70714016aa2bc03809fa7b42c174895	proposing a research model for slot machine usage		In this article, we combine the Technology Acceptance Model with social psychology research to propose a research model for slot machine usage. More specifically, we postulate positive influences of Perceived Usefulness, Perceived Enjoyment, Perceived Ease of Use, and Perceived Belonging on the Actual System Use of slot machines. Overall, we provide an interdisciplinary view on slot machine usage behavior that promises important practical implications for operators. Foremost, if confirmed, our hypotheses would suggest that operators need to focus on both utilitarian and hedonic aspects when designing/choosing their slot machines or gambling halls, and that they need to focus on factors driving people’s Perceived Belonging, such as friendly waitpersons, in order to (indirectly) drive the usage of slot machines.	foremost;lisp machine;usability	Claus-Peter H. Ernst;Christoph Hock;Franz Rothlauf	2015			simulation;engineering;advertising;social psychology	HCI	-89.43001303989182	-18.36298663456021	3556
5154ea0d4f43c387b34d250e904b4a40a6ba2207	first person view video summarization subject to the user needs	video summarization;wearable and consumer videos;first person view;episodic memory retrieval;user s preferences	Our life is becoming heavily documented and expressed on the digital substrate. This booming flow of consumer video has lead to an increasing demand of multimedia analysis tools to organize and summarize those visual memories. Due to the personal nature of such videos, though, the summarization needs to be adapted to the user needs and preferences. Yet, most summarization systems rely solely on pre-defined criteria, e.g. story-coherence or interestingness pre-trained classifiers. I propose a system which is capable of finding relevant digital memories to a given semantic query, and then summarize them on a customized manner. The proposed framework includes a wide set of tools to match a user's needs, from retrieval using multimodal queries to summarization striving to his/her preferences, both provided passively and actively. Preliminary results show the high potential of such a framework, with over 70% retrieval accuracy. More importantly, as seen from the user study, the summaries generated achieve an unprecedented compromise between usability and quality.	automatic summarization;information needs;multimodal interaction;semantic query;usability testing	Ana Garcia del Molino	2016		10.1145/2964284.2971474	computer vision;multi-document summarization;computer science;automatic summarization;data mining;multimedia;world wide web	Web+IR	-28.70950635698943	-46.768111937717364	3559
cca523c4fa93512eb5b4c8b87e1c0a38d2333ef9	using web sources for improving video categorization	video streaming;decision tree;information sources;supervised learning;automatic speech recognition;machine learning;video categorization;k nearest neighbor;support vector machine;automatic speech recognition transcriptions	In this paper, several experiments about video categorization using a supervised learning approach are presented. To this end, the VideoCLEF 2008 evaluation forum has been chosen as experimental framework. After an analysis of the VideoCLEF corpus, it was found that video transcriptions are not the best source of information in order to identify the thematic of video streams. Therefore, two web-based corpora have been generated in the aim of adding more informational sources by integrating documents from Wikipedia articles and Google searches. A number of supervised categorization experiments using the test data of VideoCLEF have been accomplished. Several machine learning algorithms have been proved to validate the effect of the corpus on the final results: Naïve Bayes, K-nearest-neighbors (KNN), Support Vectors Machine (SVM) and the j48 decision tree. The results obtained show that web can be a useful source of information for generating classification models for video data.	categorization;decision tree;experiment;information source;k-nearest neighbors algorithm;machine learning;naive bayes classifier;streaming media;supervised learning;test data;text corpus;web application;wikipedia	José Manuel Perea Ortega;Arturo Montejo Ráez;María Teresa Martín-Valdivia;Luis Alfonso Ureña López	2010	Journal of Intelligent Information Systems	10.1007/s10844-010-0123-6	support vector machine;speech recognition;computer science;machine learning;decision tree;pattern recognition;data mining;supervised learning;k-nearest neighbors algorithm	ML	-22.152765398318174	-68.46013223241684	3569
5011cbfe645c879aacd7478d701053f22b37c500	graphic storywriter: an interactive environment for emergent storytelling	story grammars;causal effect;rule based;educational software;interactive system;interactive environment;user interaction	The Graphic StoryWriter (GSW) is an interactive system that enables its users to create structurally complete stories through the manipulation of graphic objects in a simulated storybook. A rule-based story engine manages character and prop interaction, guides story development, and generates text. Through the simple interface and story writing engine, the Graphic StoryWriter provides an environment for early readers to learn about story structures, to experience the relationship between pictures and text, and to experiment with causal effects. This paper describes the motivation for and design of the Graphic StoryWriter, and reports on an empirical comparison of childrens' stories generated orally and using the GSW.	admissible rule;causality;emergence;graphics;image;interaction;interactivity;logic programming;screenwriting;typing;user interface	Karl E. Steiner;Thomas G. Moher	1992		10.1145/142750.142831	rule-based system;simulation;human–computer interaction;computer science;artificial intelligence;multimedia;educational software;world wide web	HCI	-39.338520432825455	-31.59249087704577	3575
863fb00c154006bf30789d691370cdfe13bf5aa3	communicative capital for prosthetic agents.		This work presents an overarching perspective on the role that machine intelligence can play in enhancing human abilities, especially those that have been diminished due to injury or illness. As a primary contribution, we develop the hypothesis that assistive devices, and specifically artificial arms and hands, can and should be viewed as agents in order for us to most effectively improve their collaboration with their human users. We believe that increased agency will enable more powerful interactions between human users and next generation prosthetic devices, especially when the sensorimotor space of the prosthetic technology greatly exceeds the conventional control and communication channels available to a prosthetic user. To more concretely examine an agency-based view on prosthetic devices, we propose a new schema for interpreting the capacity of a human-machine collaboration as a function of both the human’s and machine’s degrees of agency. We then introduce the idea of communicative capital as a way of thinking about the communication resources developed by a human and a machine during their ongoing interaction. Using this schema of agency and capacity, we examine the benefits and disadvantages of increasing the agency of a prosthetic limb. To do so, we present an analysis of examples from the literature where building communicative capital has enabled a progression of fruitful, task-directed interactions between prostheses and their human users. We then describe further work that is needed to concretely evaluate the hypothesis that prostheses are best thought of as agents. The agent-based viewpoint developed in this article significantly extends current thinking on how best to support the natural, functional use of increasingly complex prosthetic enhancements, and opens the door for more powerful interactions between humans and their assistive technologies.	agent-based model;artificial intelligence;assistive technology;coat of arms;color gradient;database schema;futures studies;intelligence amplification;interaction;machine learning	Patrick M. Pilarski;Richard S. Sutton;Kory Wallace Mathewson;Craig Sherstan;Adam S. R. Parker;Ann L. Edwards	2017	CoRR		machine learning;computer science;artificial arms;human–computer interaction;schema (psychology);artificial intelligence	HCI	-21.906793983934715	-15.438117710331948	3578
44cd660d88425d3f6b65e79075149ae303ec3f99	responding to the challenges of teaching computer ethics	bepress selected works;computer ethics	The proposed panel will discuss the challenges of teaching computer ethics in four different colleges/universities and the problems inherent in different educational environments: size of school, size of class, support as a stand-alone course within the department, across the curriculum, and as a mixed major course. It will also address interactive pedagogic techniques, use of webbased tools and writing across the curriculum. We intend this to be an interactive panel with short presentations by each and then an open discussion with the members of the audience to address their questions and particular problems. The references reflect the expertise of the panelists.		Frances S. Grodzinsky;Edward F. Gehringer;Laurie A. Smith King;Herman T. Tavani	2004		10.1145/971300.971398	computer science;management science;information ethics;computer ethics	HCI	-78.11516858207952	-35.146933892247546	3582
830b1581fbba4dc477f5c61bd705a3da2480bf7d	some approaches to the model error problem in data mining systems	distributive law;data mining;statistical model;data mining frequency data processing error analysis delta modulation statistical analysis statistical distributions protection data analysis ontologies;model error;data mining systems;statistical analysis;statistics model error problem data mining systems;statistics;statistical analysis data mining;model error problem	In traditional methodology of statistics as well as in contemporary methodology of knowledge search in field KDD and DM the problem of object is almost completely ignored and the problem of the error of statistical model is insufficiently explored. The paper pursues several objectives. Firstly, it aims to demonstrate the significance of these two problems. Secondly, the paper intends to show that the problem of object cannot be solved within the limits of rigorous mathematical theories. The problem of model error cannot be obtained in the general case, if the error is entirely specified by means of distribution law. Thirdly, it aims to suggest a methodological analysis of new effective approaches to the mentioned problems for a number of special cases which have been developed in empirical metrological concept of statistics	data mining;knowledge search;regular expression;statistical model;theory	V. Reznikov	2006	17th International Workshop on Database and Expert Systems Applications (DEXA'06)	10.1109/DEXA.2006.130	distributive property;statistical model;statistical theory;computer science;data science;probability of error;errors-in-variables models;data mining;exploratory data analysis;statistics	ML	-15.309391538631635	-0.12316082184214318	3584
66efa2632c3d4f36dd06ffdc54b0145ff82ec7a5	using soclab for a rigorous assessment of the social feasibility of agricultural policies	h informatique;f2 sociologie	This paper presents a theoretical and methodological framework to take into consideration the social dimension in a sustainable development project. To do this, the authors have developed the SocLab software environment, which implements a formalization of a well-established sociological theory, and enables the modeling of social organizations, to analyze their properties and to simulate social actors’ behaviors. SocLab was used to assess the social acceptability of new agricultural practices more in line with the preservation of water resources and natural environments, in a well defined context. The paper shows how it was used and presents the main results. DOI: 10.4018/978-1-4666-0333-2.ch013	simulation	Françoise Adreit;Pascal Roggero;Christophe Sibertin-Blanc;Claude Vautier	2011	IJAEIS	10.4018/jaeis.2011070101	computer science;engineering;operations management;management science;management;operations research;economic growth	AI	-74.83869702776181	-2.179678320176652	3588
f0e6f74680fc8e6046582ddda277a9f858c58039	modelling and simulation of inclined fuel transfer machine in prototype fast breeder reactor operator training simulator	nuclear power;nuclear safety;kalpakkam breeder simulator;simulation;pfbr;fuel assemblies;handling control room;prototype fbrs;operator training simulators;inclined fuel transfer machine;animation;fuel handling systems;fast breeder reactors;virtual panel;full scale replica simulator;nuclear reactors;nuclear energy;spent fuel	Indira Gandhi Centre for Atomic Research, Kalpakkam has successfully designed a 500 MWe prototype fast breeder reactor (PFBR). It is a proven fact that the critical factor in ensuring safe and reliable operation of any nuclear power plant is a qualified and well-trained personnel and hence, the need for operator training using a simulator. Fuel handling is one of the most important subsystems in a prototype fast breeder reactor. Ex-vessel subassembly transfer is done using an inclined fuel transfer machine (IFTM) which operates remotely and safely. Using IFTM, fresh fuel assemblies are loaded into the reactor, and spent fuel assemblies get unloaded. This paper deals with modelling and simulation of operations of IFTM in a simulator. Virtual panel models and control logic models were modelled using modelling tools present in the simulator. The process modelling was developed in-house using platform independent C++ code with 3D models.	prototype;reactor (software);simulation	Bindu Sankar;T. Jayanthi;Jaideep Chakraborty;H. Seetha;Adhivaraganatham A. Venkatesan;K. Madhusoodhanan;S. A. V. Satya Murty	2016	IJSPM	10.1504/IJSPM.2016.079193	nuclear power;simulation;engineering;mechanical engineering	Robotics	-23.238300141371127	-25.235064552094666	3593
11663991048ccad04158e993d82661dd25d0a98f	efficient semantic search on dht overlays	busqueda informacion;hachage;modelizacion;semantic indexing;locality sensitive hashing;top term;localite;vector space model;distributed hash table;information retrieval;par a par;localization;interrogation base donnee;vector space;interrogacion base datos;semantics;locality;localizacion;probabilistic approach;semantica;semantique;modelisation;hashing;localisation;poste a poste;indexing;recherche information;enfoque probabilista;approche probabiliste;indexation;indizacion;recall;semantic search;espace vectoriel;peer to peer;modeling;espacio vectorial;database query;semantic locating	Distributed hash tables (DHTs) excel at exact-match lookups, but they do not directly support complex queries such as semantic search that is based on content. In this paper, we propose a novel approach to efficient semantic search on DHT overlays. The basic idea is to place indexes of semantically close files into same peer nodes with high probability by exploiting information retrieval algorithms and locality sensitive hashing. A query for retrieving semantically close files is answered with high recall by consulting only a small number (e.g., 10–20) of nodes that stores the indexes of the files semantically close to the query. Our approach adds only index information to peer nodes, imposing only a small storage overhead. Via detailed simulations, we show that our approach achieves high recall for queries at very low cost, i.e., the number of nodes visited for a query is about 10–20, independent of the overlay size. © 2007 Elsevier Inc. All rights reserved.	algorithm;approximation algorithm;database;distributed hash table;hash function;information retrieval;locality of reference;overhead (computing);query expansion;query optimization;refinement (computing);relevance;sl (complexity);scalability;semantic search;simulation;viable system model;with high probability;lsh	Yingwu Zhu;Yiming Hu	2007	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2007.01.005	search engine indexing;hash function;systems modeling;internationalization and localization;semantic search;vector space;computer science;chord;database;recall;semantics;world wide web;vector space model;information retrieval;locality-sensitive hashing	DB	-25.457505649908764	1.9122719336044052	3602
c090d6dcb7ec31edd7688a0a3628c68a686502e1	encoding local contexts of sentences with convolutions on pq-gram representations of dependency trees		In this paper, we present our sentence encoding approach that uses local contexts constructed from pq-gram representations of a sentence’s dependency tree. The context localization scope can be adjusted through parameters p, the dependency depth, and q, the dependency width, which allows controlling context-sensitivity. We show competitive results of using our sentence encoding approach for sentence-pair modeling tasks.		Vu Tran;Minh Le Nguyen;Ken Satoh	2018	2018 10th International Conference on Knowledge and Systems Engineering (KSE)	10.1109/KSE.2018.8573348	machine learning;pattern recognition;computer science;artificial intelligence;encoding (memory);gram;convolution;sentence	Robotics	-17.78737178628126	-74.33866987684556	3605
16c7424bbc064c7da30077007b9d6642151fa5a0	a dual-layer user model based cognitive system for user-adaptive service robots	cognitive systems;bottom up;user adaptation;service robots;rule extraction;inference mechanisms;mobile robots;user preferences;data mining;recommender system;user adaptive coffee menu recommendation system dual layer user model cognitive system user adaptive service robots descriptive service recommendation generation association rules user preferences inference process bottom up rule extraction process;association rule;service robot;associative memory;probabilistic logic;learning artificial intelligence;service robots cognitive systems data mining inference mechanisms learning artificial intelligence mobile robots recommender systems;recommender systems;user model	This paper proposes a dual-layer user model to generate descriptive service recommendations for user-adaptive service robots. The user model represents user preferences as the associative memory in the bottom-layer and association rules in the top-layer. The learning and inference processes in the two layers, and the bottom-up rule extraction process, are explained. The proposed user model was applied to a user-adaptive coffee menu recommendation system, and the quantitative and qualitative performances of the user-adaptive and descriptive recommendation system were evaluated by comparison with non-descriptive and random recommendation methods.	artificial intelligence;association rule learning;bottom-up parsing;content-addressable memory;performance;recommender system;robot;rule induction;user (computing);user modeling	Seong-Yong Koo;Kiru Park;Hyun Jin Kim;Dong-Soo Kwon	2011	2011 RO-MAN	10.1109/ROMAN.2011.6005282	mobile robot;user modeling;association rule learning;computer science;knowledge management;artificial intelligence;top-down and bottom-up design;data mining;probabilistic logic;world wide web;recommender system	AI	-26.421988123109447	-42.62365472987012	3608
63676b06b263d55e13b4c2ecd12fe887d168277a	2014 ieee symposium on computational intelligence in biometrics and identity management, cibim 2014, orlando, fl, usa, december 9-12, 2014			biometrics;computation;computational intelligence;identity management	Ruggero Donida Labati;Vincenzo Piuri;Roberto Sassi;Fabio Scotti;Michael Blumenstein;Gelson da Cruz;Marina Gavrilova;Qinghan Xiao	2014				Embedded	-57.20554845686485	-4.748820427431143	3614
758e50c786e6bc045a3dc77aab78e8d83665edca	embedded reasoning, papers from the 2010 aaai spring symposium, technical report ss-10-04, stanford, california, usa, march 22-24, 2010			embedded system		2010				Logic	-51.73122771535806	-10.090062536006936	3616
b30fc89a0d6c954714e99602e127bf9a4262dcec	tackling the class-imbalance learning problem in semantic web knowledge bases		In the Semantic Web context, procedures for deciding the class-membership of an individual to a target concept in a knowledge base are generally based on automated reasoning. However, frequent cases of incompleteness/inconsistency due to distributed, heterogeneous nature and the Web-scale dimension of the knowledge bases. It has been shown that resorting to models induced from the data may offer comparably effective and efficient solutions for these cases, although skewness in the instance distribution may affect the quality of such models. This is known as class-imbalance problem. We propose a machine learning approach, based on the induction of Terminological Random Forests, that is an extension of the notion of Random Forest to cope with this problem in case of knowledge bases expressed through the standard Web ontology languages. Experimentally we show the feasibility of our approach and its effectiveness w.r.t. related methods, especially with imbalanced datasets.		Giuseppe Rizzo;Claudia d'Amato;Nicola Fanizzi;Floriana Esposito	2014		10.1007/978-3-319-13704-9_35	natural language processing;computer science;knowledge management;data science;semantic web;social semantic web;semantic web stack;semantic analytics	AI	-10.299492455725611	-32.55151510193663	3636
22b717b47fc0f97b1ae436a29ebd7fe3b30e5e68	a characterization of combinatorial demand		We prove that combinatorial demand functions are characterized by two properties: continuity and the law of demand.	scott continuity	Christopher P. Chambers;Federico Echenique	2018	Math. Oper. Res.	10.1287/moor.2017.0859	economics;microeconomics	Theory	-5.674070632104949	-1.1068260714143157	3637
31d97c793e0ce74033e5a5a95739bf50ce24c851	application of virtual reality for the treatment of strabismus and amblyopia		This work presents a technique that uses the immersion of patients in an interactive 3D virtual environment in the orthoptic treatment of strabismus. The most important part of this work is the act of forcing the eyes to cooperate, increasing the level of adaptation of the nervous system to the binocular vision, allowing the diverted eye to be rehabilitated. Returning to the patient better visual comfort and quality of life. The virtual environment, because it is attractive, has the function of entertainment, possessing as its property the ability to propose challenges directed towards specific objectives. In addition to offering real-time biological feedback to the healthcare professional who is making use of this product. Another point is that this interface has ideal approaches to be used in orthoptic treatment. And all of it was developed with free software and made by a low-cost virtual reality glasses, Google Cardboard, which uses a smartphone as a display for its display.	accessibility;binocular vision;google cardboard;immersion (virtual reality);real-time locating system;smartphone;virtual reality	Arata Andrade Saraiva;Alexandre Tolstenko Nogueira;Nuno M. Fonseca Ferreira;António Valente	2018	2018 IEEE 6th International Conference on Serious Games and Applications for Health (SeGAH)	10.1109/SeGAH.2018.8401357	google cardboard;immersion (virtual reality);visualization;human–computer interaction;software;virtual machine;strabismus;virtual reality;binocular vision;computer science	Visualization	-41.971369397727464	-46.186193413165114	3639
79b132b49655b9ac791edbbfcf34dffef1f5e93d	an intelligent agent with affect sensing from metaphorical language and speech	g400 computer science;agent interaction;social interaction;anger metaphor;ambient intelligence;human robot interaction;affective state;emotional speech recognition;intelligent agent;affect sensing;speech recognition;multimodal interaction;affective computing	We report new developments on affect detection from textual metaphorical affective expression and affect sensing from speech. The textual affect detection component has been embedded in an intelligent conversational AI agent interacting with human users under loose scenarios. The detected affective states from text also play an important role in producing emotional animation for users' avatars. Evaluation of the affect detection from speech and text is provided. Our work contributes to the conference themes on affective computing and ambient intelligence, human-robots interaction, multimodal interaction, narrative storytelling in education and evaluation of affective social interaction.	affective computing;ambient intelligence;embedded system;intelligent agent;multimodal interaction;robot	Xiang Lin	2009		10.1145/1690388.1690398	psychology;natural language processing;multimedia;communication	HCI	-52.74374493694218	-46.707501116216804	3642
67de194fb5a8c22ad24c0a3808d5d907dadd6391	the role of public funding in nanotechnology scientific production: where canada stands in comparison to the united states	collaboration;1600 genie industriel;nanotechnology;scientific papers;network analysis;research funding	This paper presents cross-country comparisons between Canada and the United States in terms of the impact of public grants and scientific collaborations on subsequent nanotechnology-related publications. In this study we present the varying involvement of academic researchers and government funding to capture the influence of funded research in order to help government agencies evaluate their efficiency in financing nanotechnology research. We analyze the measures of quantity and quality of research output using time-related econometric models and compare the results between nanotechnology scientists in Canada and the United States. The results reveal that both research grants and the position of researchers in co-publication networks have a positive influence on scientific output. Our findings demonstrate that research funding yields a significantly positive linear impact in Canada and a positive non-linear impact in the United States on the number of papers and in terms of the number of citations we observe a positive impact only in the US. Our research shows that the position of scientists in past scientific networks plays an important role in the quantity and quality of papers published by nanotechnology scientists.	econometric model;nonlinear system	Leila Tahmooresnejad;Catherine Beaudry;Andrea Schiffauerova	2014	Scientometrics	10.1007/s11192-014-1432-2	network analysis;computer science;public administration;management;collaboration	AI	-75.98068373203967	-20.62647224413888	3646
d7e07d261efc0afb491aadd237bfc152f544af97	volcano: an interactive sword generator	game content design volcano tool interactive sword generator procedural generation 3d model generation interactive evolution visual exploration design space exploration standard modeling software;solid modelling computer games interactive systems;blades games volcanoes shape weapons solid modeling diamonds	In this work, we introduce Volcano, a tool for the procedural generation of 3D models of swords. Unlike common procedural content generation tools, it exploits interactive evolution to reduce as much as possible the effort of the users during the generation process. Indeed, Volcano allows to forge the desired type of swords through a rather simple visual exploration of the design space. The 3D models generated with the tool can be directly used as game assets or further developed with a standard modeling software. A prototype of Volcano was tested by 30 users, including both students and game developers. The feedbacks received are very positive: tools like Volcano might be useful both for players, to create user contents, and for developers, to speed-up the design of game contents.	3d modeling;blender (software);cluster analysis;forge;interactive evolutionary computation;online and offline;procedural generation;prototype;user interface;user-generated content;on-line system	Michele Pirovano;Renato Mainetti;Daniele Loiacono	2015	2015 IEEE Games Entertainment Media Conference (GEM)	10.1109/GEM.2015.7377226	simulation;engineering;multimedia	HCI	-40.39821472248058	-34.31581644469758	3647
6befcaa918a05b9cd64ee58956121a29dd53916c	"""guest editorial: joint special issue on """"innovation in technologies for educational computing"""""""		The papers in this special issue focus on new and innovative technologies for educational computer applications. Educational computing encompasses the full range of uses of computers pursuant to conducting the profession of educators. History of educational computing is scattered of innovations and discoveries pertaining both technical matters and learning sciences, which all contributed at shaping the way education is delivered today. In some cases, revolutionary technologies with a disruptive potential have been introduced, which brought immediate changes to common education practice, such as with distance and ubiquitous learning, massive online open courses, etc. In other cases, developments in the field have been the result of rediscovery of methods presented years before, as it is happening today, for instance, with virtual and augmented reality applications. Lastly, there are cases in which new approaches to educational computing derive from an evolution of existing solutions, which are sometimes applied for the first time to education, e.g., in reaction to changes in the society. An example is represented by gamification, which indeed has been made possible by achievements in the field of mobile computing, but also responds to the changed habits of a generation of learners who has grown up playing video games.		Fabrizio Lamberti;Gwo-Jen Hwang;Baltasar Fernández-Manjón;Wenping Wang	2018	TLT	10.1109/TLT.2018.2813860	multimedia;computer science;knowledge management;educational technology;ubiquitous learning;augmented reality;computer applications;mobile computing;learning sciences	HCI	-69.08546985483423	-38.54497413700078	3653
ead11086fba2337780fcd5358693b160b7e79243	towards green metrics integration in the measure platform				Alessandra Bagnato;Jérôme Rocheteau	2018				Vision	-40.995097393498575	-15.19164751050075	3654
67cb86396986d18e7f85215a0da1c9f2b1ad1a3d	external validity in is survey research		This study focuses on the issues of external validity, coverage error and nonresponse error in IS survey research. Data from the empirical papers in 5 years of issues from three “A rated” IS journals are presented and analyzed. Recommendations are made based on the analyses, basic scientific principles and the authors’ experience and judgment.		William R. King;Jun He	2005	CAIS		management science;engineering;survey research;scientific method;coverage error;external validity	SE	-79.0880689329004	-22.009400706833528	3662
25908555b2ae69f52b71c64069f389972a313dea	closure vs. structural holes: how social network information and culture affect choice of collaborators	closure;national culture;guanxi;structural holes;willingness to collaborate;social network sites sns	Collaboration is important to successful organizations and how coworkers are selected is crucial to the dynamics of effective collaborations. In this study we explore how people use social network information, which is increasingly accessible on enterprise systems in organizations, to choose people with whom to collaborate. We conducted a scenario-based study of 459 respondents in a global high-tech company. Our data indicate cultural differences in how social network information was valued when choosing a collaborator. The Chinese, consistent with the cultural value of Guanxi, more closely followed a closure model, whereas Americans favored neither a closure nor a structural holes model. These results provide new insights into how needs for social network information may vary between cultures and how social networking sites might support workers in choosing collaborators from within and across national cultures.	enterprise system;social network;structural holes	Ge Gao;Pamela J. Hinds;Chen Zhao	2013		10.1145/2441776.2441781	knowledge management;closure;communication;management;social psychology;world wide web	HCI	-86.08446638987387	-0.8917781651644784	3663
a2cb4880fb333f892722bb6effff07e309b49ca2	tucan: twitter user centric analyzer	twitter user centric;meaningful information;actual result;different angle;bird song pair;target user;time window;recurrent topic;different user;twitter timeline;bird song;user interfaces;information retrieval	Twitter has attracted millions of users that generate a humongous flow of information at constant pace. The research community has thus started proposing tools to extract meaningful information from tweets. In this paper, we take a different angle from the mainstream of previous work: we explicitly target the analysis of the timeline of tweets from “single users”. We define a framework named TUCAN to compare information offered by the target users over time, and to pinpoint recurrent topics or topics of interest. First, tweets belonging to the same time window are aggregated into “bird songs”. Several filtering procedures can be selected to remove stop-words and reduce noise. Then, each pair of bird songs is compared using a similarity score to automatically highlight the most common terms, thus highlighting recurrent or persistent topics. TUCAN can be naturally applied to compare bird song pairs generated from timelines of different users. By showing actual results for both public profiles and anonymous users, we show how TUCAN is useful to highlight meaningful information from a target user’s Twitter timeline.	graphical user interface;multi-user;persistence (computer science);preprocessor;recurrent neural network;text mining;timeline	Luigi Grimaudo;Han Hee Song;Mario Baldi;Marco Mellia;Maurizio M. Munafò	2014		10.1007/978-3-319-13590-8_4	computer science;data mining;multimedia;internet privacy;user interface;world wide web	Web+IR	-24.350652791550317	-52.197330524962254	3672
be5188c71e9e1448e95a5bd8e44f6947990c4794	computational design of input methods		Designing a user interface or input method requires to evaluate and trade-off many criteria. The corresponding design spaces are huge, making it impossible to consider every potential design. Therefore, my work focuses on the use of computational methods for the design of input methods. I follow a modelling-optimization approach: understand and model the characteristics of the interaction, formulate the design space and develop (multi-) objective functions to evaluate designs, and develop algorithms to systematically search for the best design. In my projects I applied this approach to develop better text entry methods. Among others, I modelled the performance and anatomical constraints of the hand to computationally optimize multi-finger gestures for mid-air input, and studied how people type on physical keyboards, in order to understand and model the performance of two-hand typing.	algorithm;computation;input method;mathematical optimization;user interface	Anna Maria Feit	2017		10.1145/3027063.3027134	computational resource;computational model	HCI	-49.270689890466414	-44.81377290679284	3673
5f714b12c83136e16f7c492a042d518f95a9ec6f	wafer-level testing and test planning for integrated circuits		WAFER-LEVEL TESTING AND TEST PLANNING FOR INTEGRATED CIRCUITS by Sudarshan Bahukudumbi Department of Electrical and Computer Engineering Duke University	computer engineering;integrated circuit;test plan;wafer (electronics)	Sudarshan Bahukudumbi	2008				EDA	-50.39432954473386	-2.321902580489245	3678
f4d915b71bbd34a083150836d222ff1f90840a8b	diagram server			diagram	Giuseppe Di Battista;Giuseppe Liotta;M. Strani;Francesco Vargiu	1992	J. Vis. Lang. Comput.	10.1006/jvlc.1995.1016		Metrics	-37.717281889645854	-13.85712741308652	3683
927ac13b3459a8bdf4afdb7fa48ae3f68c90c361	multi-agent based modeling and simulation of microscopic traffic in virtual reality system	traffic simulation;microscopic traffic behavior;virtual reality;multi agent	Traffic simulation in virtual reality system plays an important part in the research of microscopic traffic behavior, but developing the traffic simulation is a difficult work because of its inherent complexity. This article focuses on the modeling and simulation of microscopic traffic behavior in virtual reality system using multi-agent technology, a hierarchical modular modeling methodology and distributed simulation. Besides, the dynamic features of the real world have been considered in the simulation system in order to improve the microscopic traffic analysis. First, the multi-agent based system framework is designed and analyzed. Then, the environment agent and the intelligent vehicle agent are presented for the simulation of interaction between vehicles and environment, especially the road geometry and wind affect on the vehicle. Finally, the application results are presented to show the feasibility of the proposed method.	agent-based model;simulation;virtual reality	Yue Yu;Abdelkader El Kamel;Guanghong Gong;Fengxia Li	2014	Simulation Modelling Practice and Theory	10.1016/j.simpat.2014.04.001	computer vision;simulation;human–computer interaction;computer science;engineering;artificial intelligence;virtual reality;network traffic simulation	Metrics	-21.490182224582796	-23.263088556950812	3684
b1f53f7c3dd942414cf317e93990f68d4ed9d200	fuzzy relational knowledge representation and context in the service of semantic information retrieval	document handling;information retrieval;fuzzy relational knowledge representation;fuzzy relation;data mining;multimedia systems;fuzzy set theory;fuzzy sets;semantic information retrieval;user context fuzzy relational knowledge representation semantic information retrieval query context document context;knowledge representation context aware services information retrieval ontologies data mining multimedia systems fuzzy sets document handling image retrieval laboratories;information retrieval fuzzy set theory knowledge representation;semantic information;query context;ontologies;document context;information service;knowledge representation;user context;context aware services;image retrieval	We follow a fuzzy relational approach to knowledge representation. With the use of semantic fuzzy relations we define and extract the semantic context out of a set of semantic entities. Based on this, we then proceed to the case of information retrieval and explain how the three participating contexts, namely the context of the query, the context of the document and the context of the user, can be estimated and utilized towards the achievement of more intuitive information services.	entity;information retrieval;knowledge representation and reasoning	Manolis Wallace;Yannis S. Avrithis	2004	2004 IEEE International Conference on Fuzzy Systems (IEEE Cat. No.04CH37542)	10.1109/FUZZY.2004.1375376	semantic similarity;semantic computing;explicit semantic analysis;image retrieval;computer science;artificial intelligence;data mining;database;context model;fuzzy set;information retrieval	Visualization	-28.739718289871277	-58.01471447940535	3685
a053b7cce3098c7828c0a2bdf22c0cea01d14043	smart qualitative data (squad): information extraction in a large document archive	information extraction;qualitative data;digital archive;social science	In this paper, we present the results of an investigation into methodologies and technical solutions for exposing the structured metadata contained within digital qualitative data, to make them more shareable and exploitable. In particular, we develop mechanisms for using Information Extraction (IE) technology to provide user-friendly tools for semi-automating the process of preparing qualitative data in the social science domain for digital archiving, in order to archive enriched marked-up data.	archive;computational linguistics;entity;folksonomy;information extraction;logic programming;named-entity recognition;ontology (information science);pseudonymity;semantic web;semiconductor industry;usability	Maria Milosavljevic;Claire Grover;Louise Corti	2007			computer science;data mining;world wide web;information retrieval	AI	-40.72202842692711	3.4603609585289226	3688
492a3da033bcb0a4e39fe85a6ee61732fa7dd58b	automatic extending hownet's attribute lexicon on the web	hownet s attribute lexicon;web pages;search engines;lexical knowledge sources;web based attribute classifier hownet s attribute lexicon world wide web lexical knowledge sources wordnet hownet natural language processing applications artificial intelligence web mining algorithm conjunctive lexical pattern position exchanging search;information filtering;position exchanging search;data mining;natural language processing applications;artificial intelligent;iterative methods;conjunctive lexical pattern;internet;attribute learning;filtering algorithms;classification algorithms;pattern classification;classification algorithms filtering algorithms search engines information filters information filtering web pages knowledge based systems;web mining;artificial intelligence;world wide web;wordnet;attribute learning hownet;false positive;pattern classification artificial intelligence data mining internet iterative methods natural language processing;information filters;web mining algorithm;web based attribute classifier;natural language processing;knowledge based systems;hownet	It is well known that lexical knowledge sources as WordNet, HowNet are very important to natural language processing applications in artificial intelligence. This paper proposes a new Web-mining algorithm to automatically extend HowNetpsilas attribute set. Seeded by the original attribute set in HowNet, the algorithm uses a conjunctive lexical pattern plus a validation mechanism called PES (position exchanging search) to extend the lexicon iteratively on the Web. Also, a Web-based attribute classifier is constructed which behaves as a filter to control the level of false positives during each iteration. The algorithm is evaluated using both standard human judgements and HowNet based evaluation. Some experimental results about the performance of the method are provided.	algorithm;artificial intelligence;attribute grammar;iteration;lexicon;natural language processing;potential energy surface;web application;web mining;wordnet;world wide web	Jinglei Zhao;Hui Liu;Ruzhan Lu	2007	2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System	10.1109/SITIS.2007.28	natural language processing;wordnet;web mining;the internet;type i and type ii errors;computer science;artificial intelligence;machine learning;web page;data mining;database;iterative method;information retrieval	Vision	-28.717168950251462	-55.3019903508721	3694
fcbedd3954b97ba9719716b8096d329010bcf5d7	applications of complex adaptive systems by yin shan and ang yang (eds.)			complex adaptive system;yang	Gönenç Yücel	2009	J. Artificial Societies and Social Simulation			AI	-49.454098557944135	-10.640919997732865	3697
6e3fb0b91598253e60914ae1cba73baef097e2e8	the design and evaluation of an auditory navigation system for blind and visually impaired	way finding navigation system the blind and visually impaired reaction time;handicapped aids electronic publishing;navigation broadcasting timing legged locomotion analysis of variance roads;broadcasting pattern auditory navigation system blind impaired people visually impaired people navigation information blind people performance navigation system taiwan digital talking books association tdtb	Previous research has highlighted that blind and visually impaired people find various factors inhibit their abilities to make journeys. This paper proposes that the lack of appropriate and timely navigation information is one of the factors for this issue. The objective of this study is to examine the effects of completeness of information and broadcasting timing on blind people performance in using navigation system procedures. Sixteen subjects participated in this experiment and each subject performed an actual Way-finding test to get back and forth between Xi-mending and TDTB (Taiwan Digital Talking Books association) locations. Results demonstrated that the broadcasting timing significantly influenced the walking time, missed routes, and workload. Results suggested that the performance with broadcasting timing in 5m of navigation system was better than that of broadcasting timing in 7m. It highlighted that a new broadcasting pattern of voice information by providing navigation information about their surroundings in a relevant, efficient and usable way may facilitate more accessible travel for blind and partially sighted people.	dos;final fantasy xi;global positioning system	Chun-Hung Yang;Sheue-Ling Hwang;Jan-Li Wang	2014	Proceedings of the 2014 IEEE 18th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2014.6846866	computer vision;simulation;multimedia	Visualization	-47.475200648296976	-46.0837971334384	3699
f8a964b36741cd33dc26c942968c839194e6df9e	natural emotions as evidence of continuous assessment of values, threats and opportunities in humans, and implementation of these processes in robots and other machines			humans;robot;value (computer science)	Jean-Daniel Dessimoz	2017			management science;machine learning;artificial intelligence;robot;continuous assessment;computer science	Robotics	-63.758270311145345	-51.08675056290684	3711
4ec27e0302c21eebb9c87923ff5401cfdfd1b283	personality-based recommendation in e-commerce		In recent years there has been an exponential increase in the number of users each day adopting e-commerce as a purchasing vehicle of products and services. This has led to a growing interest from the scientific community in approaches and models that would improve the customer experience. Specifically, it has been repeatedly pointed out that the definition of a customer experience tailored to the user personality traits would likely increase the probability of purchase. In this article we illustrate a recommender system for e-commerce capable of adapting the product and service offer according to not only the user interests and preferences, and his context of use, but also his personality profile derived from information relating to his professional activities.	artificial neural network;e-commerce payment system;prototype;purchasing;recommender system;time complexity	Ciro Bologna;Anna Chiara De Rosa;Alfonso De Vivo;Matteo Gaeta;Giuseppe Sansonetti;Valeria Viserta	2013			user modeling;e-commerce;recommender system;knowledge management;business;big five personality traits;purchasing;context awareness;personality	AI	-54.71528065491215	-41.96499983060023	3712
47cb9bde34d387ba0a18c31a83f5c414f4f41472	public policy and the global public inclusive infrastructure project	global public inclusive infrastructure;government policy;public policy forum;broad term;interaction designer;public policy;non-governmental organization;human-computer interaction;standards body;hci researcher;jonathan lazar	"""Public policy increasingly plays a role in influencing the work that we do as HCI researchers, interaction designers, and practitioners. """"Public policy"""" is a broad term that includes both government policy and policy within non-governmental organizations, such as standards bodies. The Interacting with Public Policy forum focuses on topics at the intersection of human-computer interaction and public policy. Jonathan Lazar, Editor"""	human–computer interaction;interaction design	Clayton Lewis;Jutta Treviranus	2013	Interactions	10.1145/2510123	public policy;public relations;public economics;policy analysis;public administration;management;policy studies	HCI	-77.31195236536264	-11.829007820723362	3719
5f569c7befc2feb2be698e70faf9f9948a6d0e80	case study of bushbank concept	annotation;conference paper;corpus;treebank;rapid development	In this paper, we present a new type of annotated corpus, called BushBank, which improves handling of ambiguity in natural language. Unlike in traditional approaches where data are directly disambiguated, in a BushBank, disambiguation is done later, based on application needs. This has major impact on the structures used in the corpus, since ordinary syntactic trees disallow ambiguity. Our approach was tested on 10.000 sentences and more than a hundred annotators when creating Czech BushBank. The paper contains information about creating such a resource and the methods used to obtain high inter-annotator	inter-rater reliability;natural language;text corpus;word-sense disambiguation	Marek Grác	2011			natural language processing;computer science;linguistics;information retrieval	NLP	-28.660328013471464	-73.23492601302247	3724
c6d01a75cbf0ef454f3cd1cf1675e818fc2bb6ff	dsacl+-tree: a dynamic data structure for similarity search in secondary memory	secondary memory;dynamic metric indexes	Metric space searching is an emerging technique to address the problem of efficient similarity searching in many applications, including multimedia databases and other repositories handling complex objects. Although promising, the metric space approach is still immature in several aspects that are well established in traditional databases. In particular, most indexing schemes are not dynamic. From the few dynamic indexes, even fewer work well in secondary memory. That is, most of them need the index in main memory in order to operate efficiently. In this paper we introduce two different secondary-memory versions of the Dynamic Spatial Approximation Tree with Clusters (DSACL-tree from Barroso et al.) which has shown to be competitive in main memory. These two indexes handle well the secondary memory scenario and are competitive with the state of the art. But in particular the innovations proposed by the version DSACL+-tree lead to significant performance improvements.The resulting data structures can be useful in a wide range of database application.	auxiliary memory;data structure;dynamic data;similarity search	Luis Britos;A. Marcela Printista;Nora Reyes	2012		10.1007/978-3-642-32153-5_9	auxiliary memory;distributed shared memory;computer science;theoretical computer science;machine learning;data mining;database;world wide web	DB	-29.97212764231806	1.220869277819953	3728
f376e082986e615ecaaa4b91535a84b4cd722564	a distributed normative infrastructure for situated multi-agent organisations	normative multi agent systems;multi agent system;social simulation;multi agent sys tems;situated multi agent systems;modelling language;normative infrastructure;situated organisations;environment modelling	In most of the existing approaches to the design of multiagent systems, there is no clear way in which to relate organisational and normative structures to the model of the environment where they are to be situated and operate. Our work addresses this problem by putting together, in a practical approach to developing multi-agent systems (and social simulations in particular), a high-level environment modelling language that incorporates aspects of agents, organisations, and normative structures. The paper explains in some detail how the ideas of normative objects and normative places, put together as a distributed normative infrastructure, allow the definition of certain kinds of situated multi-agent organisations, in particular organisations for multi-agent systems that operate within concrete environments. Normative objects are environment objects used to explicitly convey normative content that regulate the behaviour of agents within the place where such objects can be perceived by agents. The paper briefly introduces such concepts, showing how they were integrated into the MASSOC multi-agent systems platform for social simulation, and hints on new problems of (situated) organisational and normative structures that were brought forward by the work presented here.	multi-agent system;situated	Fabio Y. Okuyama;Rafael H. Bordini;Antônio Carlos da Rocha Costa	2008		10.1145/1402821.1402909	simulation;computer science;knowledge management;artificial intelligence;multi-agent system;social simulation	ML	-21.77868592308777	-12.423187107649133	3732
5a0cc05753097721d2c6397d7a7ad0ce4acf4569	government domain named entity recognition for south african languages		This paper describes the named entity language resources developed as part of a development project for the South African languages. The development efforts focused on creating protocols and annotated data sets with at least 15,000 annotated named entity tokens for ten of the official South African languages. The description of the protocols and annotated data sets provide an overview of the problems encountered during the annotation of the data sets. Based on these annotated data sets, CRF named entity recognition systems are developed that leverage existing linguistic resources. The newly created named entity recognisers are evaluated, with F-scores of between 0.64 and 0.77, and error analysis is performed to identify possible avenues for improving the quality of the systems.	conditional random field;error analysis (mathematics);named entity	Roald Eiselen	2016			artificial intelligence;natural language processing;linguistics;languages of africa;computer science;government;named-entity recognition	NLP	-29.26694135768664	-74.3422658790191	3734
2e5ec5b0bff139fe81bf9d14d7f49b111379abdf	book reviews: the early british computer conferences, volume 14 in the charles babbage institute reprint series for the ijistory of computing edited by michael r. williams and martin campbell-kelly, the mit press (cambridge, ma), 1989, 508pp. isbn 0-262-23136-0		"""Presper Eckert and John Mauchly started work on the Electric Numeric Integrator and Computer (ENIAC) at the Moore School of the University of Pennsylvania in the spring of 1943. The ENIAC was working well in the spring of 1945. In response to a growing number of requests for information, the Moore School sponsored an eight week course on computing topics during the summer of 1946, entitled """"Theory and Techniques for Design of Electronic Digital Computers."""" 2 Maurice V. Wilkes, the Director of the Mathematical Laboratory at Cambridge University attended some of these lectures . On the return trip to Britain, Wilkes outlined his plans for building a computer."""	babbage;computer;eniac;eckert–mauchly award;google summer of code;international standard book number;kelly criterion	Tim Bergin	1991	SIGCAS Computers and Society	10.1145/122652.1017899	law and economics	Theory	-58.395865623321654	-14.730048671578688	3736
d5299ccbda91e75dd67e295c99e920dfca6f08f0	establishing volunteer us cyber defense units: a holistic approach		The global use of the cyber domain has heightened speed, agility, and interconnectivity within our societies. Consequently, it has also increased threats that share the same characteristics. No longer is reality linear, as two points in time and individuals can connect from varied locations almost instantly, shifting the balance of how we approach traditional security challenges. This paper argues for the creation of volunteer United States (US) Cyber Defense Units (US CDU) at the state-level, similar to the Estonian Defence League's Cyber Defence Unit (EDL CDU). The goal in its establishment being to achieve a whole-of-society approach by creating the opportunity for individuals across sectors to volunteer in the joint cause of protecting US cyberspace. Voluntarism has worked before (e.g. US Minutemen, US National Guard, Civil Air Patrol) and it can certainly work again — this time, for the cyber domain. This paper provides background on prior US cyber defense initiatives and delves into the EDL CDU to draw possible theoretical structures and lessons for the formation and integration of the proposed US CDU. It also examines ongoing developments with the US Cyber Mission Force (CMF) to compare efforts. The paper includes primary and secondary source material from academia, government, and private sectors in both the US and Estonia. It analyzes ongoing efforts for cyber defense and reviews academic literature and research on the topics discussed.	control display unit;cyberspace;holism;list of content management frameworks;secondary source;threat (computer)	Monica M. Ruiz	2017	2017 International Conference on Cyber Conflict (CyCon U.S.)	10.1109/CYCONUS.2017.8167512	guard (information security);computer security;volunteer;cyberspace;computer science;secondary source;interconnectivity;private sector;voluntarism (action);government	SE	-72.89465807105768	-9.53227147495439	3737
c0048fef6c8d3fc0a3c9eed9b3e91b375051efd4	a global intranet for an international scientific society		The International Medical Informatics Association (IMIA) has built up a world-wide infrastructure which is using the Internet as a backbone for a global Intranet. The work has been supported by cost analysis and user acceptance monitoring. As one of the first international scientific societies, IMIA is offering professional electronic communication services to its members. This step has been taken to advance international cooperation and to support the dissemination and exchange of information on the Health Informatics Sector. The current ways of communication and Information Exchange do not meet the requirements of the Information Society because they are too slow and too expensive. The implementation of an Intranet based on the Internet provides a communication channel which is easily accessible for all IMIA members and which will allow efficient information exchange and built up links between IMIA related projects and organizations.	channel (communications);communications media;informatics (discipline);information exchange;international cooperation;intranet;requirement;societies;societies, scientific	Thomas Kleinoeder;Otto Rienhoff	1998	Studies in health technology and informatics	10.3233/978-1-60750-896-0-197	knowledge management;intranet;medicine	DB	-69.83879958061236	-17.79626332521139	3739
23193afc7b1653376cde767d6549746cd405057f	declarations of independence	journal article	According to orthodox (Kolmogorovian) probability theory, conditional probabilities are by definition certain ratios of unconditional probabilities. As a result, orthodox conditional probabilities are regarded as undefined whenever their antecedents have zero unconditional probability. This has important ramifications for the notion of probabilistic independence. Traditionally, independence is defined in terms of unconditional probabilities (the factorization of the relevant joint unconditional probabilities). Various “equivalent” formulations of independence can be given using conditional probabilities. But these “equivalences” break down if conditional probabilities are permitted to have conditions with zero unconditional probability. We reconsider probabilistic independence in this more general setting. We argue that a less orthodox but more general (Popperian) theory of conditional probability should be used, and that much of the conventional wisdom about probabilistic independence needs to be rethought.	undefined behavior	Branden Fitelson;Alan Hájek	2014	Synthese	10.1007/s11229-014-0559-2	conditional probability distribution;econometrics;philosophy;regular conditional probability;chain rule;mathematics;law of total probability;algorithm;statistics	ML	-13.721620444239926	3.957293800667834	3745
d2a316965456dc455ab002928aba7f38bb10e0c0	complete systems analysis: the workbook, the textbook, the answers: james and susan robertson dorset house new york (1994) 2 vols 592 pp $74.75 isbn 0 932633 25 0	system analysis		international standard book number	R. Clay Sprowls	1994	J. Strategic Inf. Sys.	10.1016/0963-8687(94)90030-2	economics;law and economics;system analysis	AI	-58.48591595962492	-11.841120004787179	3753
0e918ee54b744771ac5b1520f177dfb438c6d9ca	using pressure input and thermal feedback to broaden haptic interaction with mobile devices	qa75 electronic computers computer science;bf psychology	Pressure input and thermal feedback are two under-researched aspects of touch in mobile human-computer interfaces. Pressure input could provide a wide, expressive range of continuous input for mobile devices. Thermal stimulation could provide an alternative means of conveying information non-visually. This thesis research investigated 1) how accurate pressure-based input on mobile devices could be when the user was walking and provided with only audio feedback and 2) what forms of thermal stimulation are both salient and comfortable and so could be used to design structured thermal feedback for conveying multi-dimensional information.#R##N##R##N#The first experiment tested control of pressure on a mobile device when sitting and using audio feedback. Targeting accuracy was >= 85% when maintaining 4-6 levels of pressure across 3.5 Newtons, using only audio feedback and a Dwell selection technique. Two further experiments tested control of pressure-based input when walking and found accuracy was very high (>= 97%) even when walking and using only audio feedback, when using a rate-based input method. #R##N##R##N#A fourth experiment tested how well each digit of one hand could apply pressure to a mobile phone individually and in combination with others. Each digit could apply pressure highly accurately, but not equally so, while some performed better in combination than alone. 2- or 3-digit combinations were more precise than 4- or 5-digit combinations. Experiment 5 compared one-handed, multi-digit pressure input using all 5 digits to traditional two-handed multitouch gestures for a combined zooming and rotating map task. Results showed comparable performance, with multitouch being ~1% more accurate but pressure input being ~0.5sec faster, overall.#R##N##R##N#Two experiments, one when sitting indoors and one when walking indoors tested how salient and subjectively comfortable/intense various forms of thermal stimulation were. Faster or larger changes were more salient, faster to detect and less comfortable and cold changes were more salient and faster to detect than warm changes. The two final studies designed two-dimensional structured ‘thermal icons’ that could convey two pieces of information. When indoors, icons were correctly identified with 83% accuracy. When outdoors, accuracy dropped to 69% when sitting and 61% when walking.#R##N##R##N#This thesis provides the first detailed study of how precisely pressure can be applied to mobile devices when walking and provided with audio feedback and the first systematic study of how to design thermal feedback for interaction with mobile devices in mobile environments.	haptic technology;mobile device	Graham Alasdair Wilson	2013			simulation;engineering;multimedia;communication	HCI	-46.58677780659414	-45.70566699877263	3756
51d05903ecf0eeca09fd531606628fce771362e5	a rule-based and mt-oriented approach to prepositional phrase attachment	noun attachment;mt-oriented approach;structural ambiguity;lexical knowledge;verb attachment;phrase attachment;different attachment;possible attachment;lexical cue;semantic knowledge;machine translation;prepositional phrase;noun;rule based	Prepositional Phrase is the key issue in structural ambiguity. Recently, researches in corpora provide the lexical cue of prepositions with other words and the information could be used to partly resolve ambiguity resulted from prepositional phrases. Two possible attachments are considered in the literature: either noun attachment or verb attachment. In this paper, we consider the problem from viewpoint of machine translation. Four diierent attachments are told out according to their functionality: noun attachment, verb attachment, sentence-level attachment, and predicate-level attachment. Both lexical knowledge and semantic knowledge are involved resolving attachment in the proposed mechanism. Experimental results show that considering more types of prepositional phrases is useful in machine translation.	attachments;machine translation;rule-based system;text corpus	Kuang-hua Chen;Hsin-Hsi Chen	1996			natural language processing;noun;noun phrase;computer science;linguistics;machine translation	NLP	-25.12135203563191	-76.49166759340835	3757
f5226968baf4445f7783be7e046043f64b85f5eb	on the time evolution of received citations, in different scientific fields: an empirical study	mean received citations;chemistry;scientific fields;received citations trends;medians of citations;management	The time evolution of mean received citations is calculated on a sample of journals from two ISI subject categories (“Chemistry, multidisciplinary”, ISI Science Edition, and “Management”, ISI Social Science edition) with the use of an original methodology. Mean received citations are plotted against the time gap in years existing between publication of the cited article and received citations. For most Chemistry journals in the sample the maximum number of average received citations occurs two years after publication, and then a decrease is experimented. Some peculiar cases present a different trend. Management journals, conversely, do not present in most cases a peak of citations: average received citations instead grow from year of publication to the age of 10 years (maximum time gap studied). A subsample of journals show similar results for longer time series (up to 23 years). Medians of average received citations per year partly show a similar behavior. Results suggest that citedness follows very different trends in very different fields, and partly suggest why differences in Journal Impact Factor exist between different categories. At the end of the work conclusions are drawn, together with suggestions for future research. © 2013 Elsevier Ltd. All rights reserved.	information sciences institute;time series	Ugo Finardi	2014	J. Informetrics	10.1016/j.joi.2013.10.003	data science;data mining	Metrics	-77.41651102607939	-21.068701370116134	3760
d69f7879346e081880d1a23ac41e88f3a850a134	anonymous single-profile welfarism	inegalite sociale;equity procedure en;economie;anonymity;welfarism;jel d63 microeconomie economie du bien etre egalite justice inegalite et autres criteres normatifs et mesures;hc economic history and conditions;hypothese;possibilite;choix collectif;responsabilite du fait de la justice;single profile social choice;justice;hb economic theory;equite;jel d63 microeconomics welfare economics equity justice inequality and other normative criteria and measurement;equity;maitre de justice;single ofile social choice;egalite;economies et finances;social choice;mesure;telecommunications en justice;assomption;article;h social sciences;social choice theory;histoire	This note reexamines the single-profile approach to social-choice theory. If an alternative is interpreted as a social state of affairs or a history of the world, it can be argued that a multi-profile approach is inappropriate because the information profile is determined by the set of alternatives. However, single-profile approaches are criticized because of the limitations they impose on the possibility of formulating properties such as anonymity. We suggest an alternative definition of anonymity that applies in a single-profile setting and characterize anonymous single-profile welfarism under a richness assumption. Journal of Economic Literature Classification Number: D63.		Charles Blackorby;Walter Bossert;David J. Donaldson	2006	Social Choice and Welfare	10.1007/s00355-006-0131-1	social choice theory;economics;public economics;sociology;microeconomics;law;welfare economics	ECom	-8.0538297717323	-0.35427137492503086	3764
57336feacb69967f31532d6be4769b013fd9c509	where go is going and what it means for ontology extension		Developing and maintaining a biomedical ontology is a time and effort-consuming task, given the dynamic and expanding nature of biomedical knowledge. This is a relevant issue for very large ontologies which cover a broad domain, for smaller ontologies maintained by a small team and also for domains where being able to perform quick updates is critical (e.g. epidemiology). The first step in the process of extending an ontology is identifying the areas of the ontology that need to be changed change capturing. In this paper we propose that this process can be semi-automated by exploring ontology information. This would be a valuable tool to support ontology developers in ontology extension, easing their burden. In order to accomplish this, we have developed a framework for analysing the extension of ontologies, to create a general panorama of ontology extension processes that can guide the development of change capturing techniques. We have applied it to the analysis of the extension of the Gene Ontology and uncovered some of the underlying tendencies in its extension. Building upon the results of this analysis and a set of guidelines for ontology change capturing, we then investigated the feasibility of prediciting which classes of the ontology will be extended in a future version. Finally, we discuss the obtained results and indentify the main challenges and future directions for the budding area of ontology extension prediction.	gene ontology;ontology (information science);semiconductor industry;web ontology language	Catia Pesquita;Francisco M. Couto	2011			data mining;ontology;ontology (information science);computer science	AI	-40.501058180885835	1.1070129279228735	3769
4fde5e28b270e56a63bc5eb214daa33952ee8107	where is the technology-induced pedagogy? snapshots from two multimedia efl classrooms	enseignement superieur;enseignement des langues;multi media instruction;enseignement multi media;higher education;technologie de l education;multimedia instruction;chine rp;educational change;foreign countries;secondary education;teacher role;technology integration;informatique;china pr;computer science;educational technology;language teaching;english second language	This research examines two multimedia secondary EFL classrooms to identify what changes, pedagogical or otherwise, have taken place in technologically integrated classroom practice. The research analyses data generated from a range of sources: classroom observations, videotapes and teacher’s lesson plans. It is argued that substantial pedagogical innovations will not come unless there is a perceived change in the understanding of the process of teaching and learning and philosophy of language. The research concludes that the traditional Chinese notion of teaching and the role of the teacher in the classroom need to be redefined to allow for a learner-centred multimedia language classroom to emerge. New trends in Chinese ELT A new educational reform, which emphasises the integration of new technologies into the curriculum, is surging in China with an increased momentum. EFL professionals are either constantly searching themselves for, or being timetabled into various computer literacy courses, to develop and upgrade technology-based skills. It is not uncommon for some forward-thinking institutions to establish a skill database that contains information about staff skills in using various computer software. On the other hand, the ability to use PowerPoint, Authorware or Flash to preen their courseware, and give showcase “Multimedia EFL Lessons” has been admired as an enviable skill. 05Zhong 04/01/2002 1:21 pm Page 39	adobe authorware;adobe flash;autonomy;computer;database;definition;emergence;endeavour (supercomputer);enlightenment foundation libraries;harris affine region detector;pedagogical agent;transmitter	Ying Xue Zhong;Hui Zhong Shen	2002	BJET	10.1111/1467-8535.00237	psychology;mathematics education;educational technology;social science;computer science;multimedia;higher education;world wide web;pedagogy	DB	-72.99843526193492	-32.73519017614071	3772
ca790d3adbaba88a09770ec72084c2b9eb13aba8	clustering avatars behaviours from virtual worlds interactions	hierarchical clustering;degree of freedom;clustering techniques;data processing;group formation;behavioral patterns;social network;3d environment;automatic detection;conferenceobject;clustering method;data preprocessing;bookpart;eye gaze;graph and overlapping clustering;virtual worlds	Virtual Worlds (VWs) platforms and applications provide a practical implementation of the Metaverse concept. These applications, as highly inmersive and interactive 3D environments, have become very popular in social networks and games domains. The existence of a set of open platforms like OpenSim or OpenCobalt have played a major role in the popularization of this technology and they open new exciting research areas. One of these areas is behaviour analysis. In virtual world, the user (or avatar) can move and interact within an artificial world with a high degree of freedom. The movements and iterations of the avatar can be monitorized, and hence this information can be analysed to obtain interesting behavioural patterns. Usually, only the information related to the avatars conversations (textual chat logs) are directly available for processing. However, these open platforms allow to capture other kind of information like the exact position of an avatar in the VW, what they are looking at (eye-gazing) or which actions they perform inside these worlds. This paper studies how this information, can be extracted, processed and later used by clustering methods to detect behaviour or group formations in the world. To detect the behavioural patterns of the avatars considered, clustering techniques have been used. These techniques, using the correct data preprocessing and modelling, can be used to automatically detect hidden patterns from data.	avatar (computing);behavioral pattern;cluster analysis;data pre-processing;eye tracking;interaction;iteration;modeling language;opensimulator;preprocessor;social network;virtual world	Gema Bello Orgaz;María Dolores Rodríguez-Moreno;David Camacho;David F. Barrero	2012		10.1145/2189736.2189743	simulation;computer science;communication;world wide web	Web+IR	-23.413802484158616	-40.97354615094872	3776
f7854db6bc19dab78bb5d06babd82d694c7dbb98	the development of the critical theory of evolution: the scientific career of wolfgang f. gutmann	critical theory;evolutionary biology	The critical theory of evolution was developed by a group of scientists working together with Wolfgang F. Gutmann at the Senckenberg-Research-Institute in Frankfurt am Main. Gutmann worked at Senckenberg for 37 years. In this time he presented 247 contributions which are distributed over 47 periodicals and books. The ideas that were developed by Gutmann and his colleagues were innovative and pathbreaking for morphology and evolutionary biology. The large number of his morphological publications is indicative of the wide field that was opened up by the concepts of constructional morphology. As some of his colleagues have suggested, constructional morphology as an engineering approach to the study of organisms (i. e., engineering morphology) may replace the traditional concepts of morphology and anatomy and provides the observational base for the historical reconstruction of evolutionary pathways. Constructional morphology as a quasi-engineering approach can be the morphological pendant to the contemporary molecular approaches to biology, as it can provide the necessary morphological basis for the interpretation of the results of molecular studies in the light of evolution.	book;evolution;galaxy morphological classification;mathematical morphology;peter gutmann (computer scientist)	Michael Gudo	2002	Theory in Biosciences	10.1078/1431-7613-00052	biology;zoology;critical theory	Vision	-57.757159203202406	-21.264909763995668	3777
6eec3549c019fefc3659ef2cb30150ddcdc083a6	new prospects of network-based urban cellular automata		Cellular automata (CA) build on complexity theory, focus on bottom-up processes that lead to global forms, highlight non-equilibrium or disruptive events, and complement to GIS and remote sensing techniques. Therefore, urban cellular automata (i.e., the applications of CA in urban modeling and simulation) became popular since the early 1990s. However, the CA momentum gradually subsided among urban modelers a decade later due to the criticism on the simplicity and rigidity of urban CA. Michael Batty in his seminal work, The New Science of Cities, interprets cities not simply as places but as systems of networks and flows, which can be examined in better ways by using big data and emerging computational techniques. This book sets a new benchmark for urban CA modeling, which is shedding new lights to dynamic urban modeling. Inspired by the recommendations in Batty’s book, a new network-based global urban CA framework is developed in this paper. According to the science of design and planning, this paper describes the global urban CA framework at the micro-, meso-, macro- and global-scales and examines the dynamic flows (i.e. interactions) over the urban networks at the four scales by using terminologies that are often seen in the urban CA modeling literature. In addition, the paper will analyze how big data analytics affect computational implementations of the networked global urban cellular automata, including (1) multi-scales of networked urban CA spaces that lead to modifiable areal unit problems; (2) boundary discords of CA spaces that cause areal unit inconsistency problem; and (3) incomplete data that prevent from a full implementation of the global urban CA framework.		Yichun Xie;Hai Lan	2016		10.1007/978-3-319-42111-7_7	computer science;implementation;computer network;big data;macro;cellular automaton;distributed computing;modeling and simulation	Vision	-13.143723491731905	-24.440628453075778	3779
c2739fd1de5bf9e49507ceae615ffad8ca7778fe	initiator: noise-contrastive estimation for marked temporal point process		Copious sequential event data has consistently increased in various high-impact domains such as social media and sharing economy. When events start to take place in a sequential fashion, an important question arises: “what type of event will happen at what time in the near future?” To answer the question, a class of mathematical models called the marked temporal point process is often exploited as it can model the timing and properties of events seamlessly in a joint framework. Recently, various recurrent neural network (RNN) models are proposed to enhance the predictive power of mark temporal point process. However, existing marked temporal point models are fundamentally based on the Maximum Likelihood Estimation (MLE) framework for the training, and inevitably suffer from the problem resulted from the intractable likelihood function. Surprisingly, little attention has been paid to address this issue. In this work, we propose INITIATOR a novel training framework based on noise-contrastive estimation to resolve this problem. Theoretically, we show the exists a strong connection between the proposed INITIATOR and the exact MLE. Experimentally, the efficacy of INITIATOR is demonstrated over the state-of-the-art approaches on several real-world datasets from various areas.		Ruocheng Guo;Jundong Li;Huan Liu	2018		10.24963/ijcai.2018/303	artificial intelligence;machine learning;computer science;point process	AI	-17.965918922904475	-44.40727034776878	3784
71a51e4ddacb2ac8305380e67c99038a7e990f41	interview with jon kleinberg	links;small world;authorities;web mining;social network analysis	Interview with Jon Kleinberg, a pioneer in web mining, social network analysis, and other fields and a winner of many awards, including 2 KDD Best Papers and a MacArthur u0027geniusu0027 award.	social network analysis;web mining	Gregory Piatetsky-Shapiro	2007	SIGKDD Explorations	10.1145/1345448.1345457	web mining;social network analysis;computer science;artificial intelligence;data mining;operations research	ML	-59.27496377331812	-15.757822301617589	3785
028bbb1883755563e783e052b3558ceb1e189bfb	engineering the new boundaries of ai	ai;pervasive computing;computing education;xprize;intelligent systems;scientific computing;artificial intelligence	AI surrounds us. It’s in our search engines, automobiles, phones, video-streaming websites, and even the systems that run our nancial markets. We interact with and rely on intelligent machines throughout our daily activities. AI has made steady, linear progress toward adoption and integration over the past 50 years. It’s now at an important in ection point—the adoption curve could soon transcend the linear growth pattern and take an exponential leap. With machine learning, AI technologies have the potential to make sense of vast, complex datasets. This begs the question: How can we best leverage both human intelligence and these powerful AI technologies to bene t humanity now and in the future? ENTER XPRIZE It’s this question of the impact of AI on mankind that inspired the IBM Watson AI XPRIZE, the latest innovation challenge from the XPRIZE Foundation. IBM sponsored the competition with a prize purse of $5 million, including a grand prize of $3 million, a secondplace prize of $1 million, and a thirdplace prize of $500,000. The goal of the competition is to accelerate the development of scalable AI solutions to address humanity’s greatest challenges. The four-year competition will have milestone completions in 2017, 2018, and 2019, with the top three nalists competing for the grand prize in 2020. Recognizing the competition’s humanitarian importance and global reach, the IEEE Computer Society (CS) formed a partnership agreement in August 2016 with the XPRIZE Foundation. Select CS members will join the XPRIZE scienti c advisory board, and the CS will draw from its global network of experts to help judge and advise the competitors. The CS will also encourage Engineering the New Boundaries of AI	global network;linear function;machine learning;scalability;thomas j. watson research center;time complexity;watson (computer);web search engine	Amir Banifatemi;Jean-Luc Gaudiot	2016	IEEE Computer	10.1109/MC.2016.328	applications of artificial intelligence;intelligent decision support system;progress in artificial intelligence;computer science;artificial intelligence;software engineering;artificial intelligence, situated approach;ubiquitous computing	AI	-57.25161763720668	-18.298768395044558	3786
5c1a532ba27ac340431a546756960ba38243a42d	development of an instrument to measure enjoyment of computer game play	instrument design;construct validity;technological progress;computer game	This article reports on the development of an instrument designed to measure the enjoyment of computer game play. Despite the enormous technological progress in the field of computer games, enjoyment of computer game play is still not a well-defined construct. Based on Nabi and Krcmar's (2004) tripartite model of media enjoyment, a survey questionnaire was developed to measure computer game players' affective, behavioral, and cognitive reactions. Expert consultation, exploratory, and confirmatory card sorting sessions were used to refine the instrument. A survey of computer game players was subsequently conducted to test the instrument. Reliabilities and construct validities were analyzed. Findings and their implications were discussed.	pc game	Xiaowen Fang;Susy S. Chan;Jacek Brzezinski;Chitra Nair	2010	Int. J. Hum. Comput. Interaction	10.1080/10447318.2010.496337	technological change;simulation;construct validity;multimedia;statistics	HCI	-61.63753882946775	-44.885110295472145	3796
379010700a297c1ffdddd07f3767fe06c43fbc41	speeding up the multimedia feature extraction: a comparative study on the big data approach		The current explosion of multimedia data is significantly increasing the amount of potential knowledge. However, to get to the actual information requires to apply novel content-based techniques which in turn require time consuming extraction of indexable features from the raw data. In order to deal with large datasets, this task needs to be parallelized. However, there are multiple approaches to choose from, each with its own benefits and drawbacks. There are also several parameters that must be taken into consideration, for example the amount of available resources, the size of the data and their availability. In this paper, we empirically evaluate and compare approaches based on Apache Hadoop, Apache Storm, Apache Spark, and Grid computing, employed to distribute the extraction task over an outsourced and distributed infrastructure.	apache hadoop;apache spark;apache storm;big data;feature extraction;grid computing;parallel computing	David Mera;Michal Batko;Pavel Zezula	2016	Multimedia Tools and Applications	10.1007/s11042-016-3415-1	computer science;data science;operating system;machine learning;data mining;database;world wide web;computer security;algorithm	DB	-31.918212721389335	-1.1099703510271384	3797
8b30782de3ea7bf65aa54b5fca649db365534223	an information model of interagency communication based on distributed data storage	multifunctional centers of public and municipal services;swot analysis;e government;social services;government and municipal services portal;telos analysis	The organization of interagency communication is largely determined by accepted practice from the information model, by the principles which are used for the development of standards for information exchange and by the methods used to bring government reports into conformance with those standards. In world practice various models are applied. This article presents a comparative analysis of these models and proposes a variation of the information model that is based on distributed data storage. The proposed model answers the needs for flexibility and expandability, and also offers an opportunity to distribute responsibility and ensure a sufficient level of security of government data. The basis for interagency communication in the proposed model is a three-layer data hub, including a general hub, an object field hub, and an object-oriented portion of the hub. Horizontal and vertical connection among the separate parts of the hub is accomplished by means of a model of intermodel connections.	computer data storage;conformance testing;data hub;information exchange;information model;multitier architecture;qualitative comparative analysis;the hub (forum);usb hub	Yuri P. Lipuntsov	2016		10.1145/3014087.3014097	public relations;engineering;operations management;data mining	DB	-71.14790112357008	2.8932113174913257	3798
c4f07eb589e685a869999200aaf34a8ab3f0f0a4	computational processing of verbal polysemy with conceptual structures (research note)	representacion conocimientos;systeme intelligent;sistema inteligente;tratamiento lenguaje;systeme base connaissances;language processing;polisemia;conceptual graph;linguistique structurale;traitement langage;linguistica estructural;intelligent system;polysemy;grafo conceptual;polysemie;knowledge representation;structural linguistics;representation connaissances;graphe conceptuel;knowledge based systems	Our work takes place in the general framework of lexico-semantic knowledge representation to be used by a Natural Language Understanding system. More specifically, we were interested in an adequate modelling of verb descriptions allowing to interpret semantic incoherence due to verbal polysemy. The main goal is to realise a module which is able to detect and to deal with figurative meanings. Therefore, we first propose a lexico-semantic knowledge base; then we present the processes allowing to determine the different meanings which may be associated to a given predicate, and to discriminate these meanings for a given sentence. Each verb is defined by a basic action (its supertype) specified by the case relations allowing to specify it (its definition graph), that means the object, mean, manner, goal and/or result relations which distinguish the described verb meaning from the specified basic action. This description is recursive: the basic actions are in turn defined using more general actions. To help interpreting the different meanings conveyed by a verb and its hyponyms, we have determined three major types of heuristics consisting in searching the type lattice, and/or examining the associated definitions.	computation	Karim Chibout;Anne Vilnat	1998		10.1007/BFb0054928	natural language processing;conceptual graph;knowledge representation and reasoning;computer science;artificial intelligence;structural linguistics;mathematics;algorithm	Logic	-21.755783575561797	0.09277922343561333	3799
b616cb5cfbf21d6bc831c76c1f5165a1df5e7d4e	a professor's moral thinking at the abstract level versus the professor's moral thinking in the real life situation (consistency problem)	bandura s sociocognitive theory;statistical significance;exploratory factor analysis;moral behavior patterns;moral behavior over time;patterns of moral thinking at the abstract level;moral thinking at the abstract level	"""We conducted an on-line survey to investigate the professor's idea of """"morality"""" and then to compare their moral thinking at the abstract level with their moral thinking in the real life situations by sampling 257 professors from the University of Novi Sad. We constructed questionnaire based on related theoretical ethical concepts. Our results show (after we performed exploratory factor analysis) that the professor's idea of """"morality"""" consists of the three moral thinking patterns which are simultaneously activated during the process of their abstract moral thinking. We have identified these patterns in the following manner: deontological, formal and subjective pattern. In addition, our results show that of the three, the subjective pattern is more activated than the other two during their process of the moral thinking at the abstract level. We also discovered that there is a statistically significant difference between professor's moral thinking patterns activation level at the abstract level and their moral thinking patterns activation level in the real life situation."""	exploratory factor analysis;feel sad question;formal system;online and offline;real life;sampling (signal processing)	Mladen Pecujlija;Ilija Cosic;Velibor Ivanisevic	2011	Science and engineering ethics	10.1007/s11948-009-9190-x	psychology;vertical thinking;exploratory factor analysis;developmental psychology;moral reasoning;moral development;statistical significance;sociology;moral disengagement;social psychology;social cognitive theory of morality;moral psychology	SE	-68.13142273480435	-52.007754573937135	3811
bf645a6875dc725a2baf034e2338095c2157bd68	our departments: charting the path of computer graphics	computer graphics character generation data visualization virtual reality application software feedback business haptic interfaces art defense industry;computer graphics;graphics and multimedia;virtual reality;computer graphic;virtual reality computer graphics graphics and multimedia visualization;visualization;real world application;cg application technologies;animation;cg and a departments;cg application techniques;cg application technologies cg and a departments computer graphics animation cg application techniques;computer animation	In this paper, the author discusses CG&A's departments and encourages to consider submitting an article to one or more of them. This department covers using CG to solve realworld problems. It comes from consistent feedback from readers requesting more practical content, real-world applications, implementation details, experience-related information, and more bridging of the gap between theory and application. The department presents interesting or unique CG application techniques and technologies in different problem domains.	computer graphics	Gabriel Taubin	2010	IEEE Computer Graphics and Applications	10.1109/MCG.2010.59	anime;scientific visualization;visualization;computer facial animation;human–computer interaction;computer science;artificial intelligence;computer graphics lighting;real-time computer graphics;virtual reality;computer animation;multimedia;graphics software;computer graphics;3d computer graphics;computer graphics (images)	Visualization	-47.400191842508065	-30.284193844608907	3814
577db66f6a74c908d0d5754101f684a9807a7d47	steps towards the extraction of vehicular mobility patterns from 3g signaling data	refined data;data processing chain;mobility pattern;anonymous trace;passive monitoring;mobility study;vehicular mobility pattern;cell boundary;cellular network;call data records;road traffic monitoring	Millions of mobile users daily traveling on urban roads and highways The cellular network signaling traffic is rich of information related to the movement of devices across cell and Location Areas boundaries Our goal: use mobile devices and their signaling as traffic sensors for both real-time applications and historical analysis © FTW-2/13	mobile device;real-time clock;sensor	Pierdomenico Fiadino;Danilo Valerio;Fabio Ricciato;Karin Anna Hummel	2012		10.1007/978-3-642-28534-9_7	telecommunications;computer security;computer network	Mobile	-18.67577701991908	-33.144313899225146	3822
633e2c582254fe1e1879c7a1f8b1eaf5a7d3134c	identification of sympathy in free conversation		Dialog systems are generally categorized into two types: task oriented and non task oriented systems. Recently, the study of non task oriented dialog systems or chat systems becomes more important since robotic pets or nursing care robots are paid much attention in our daily life. In this paper, as a fundamental technique in a chat system, we propose a method to identify if a speaker displays sympathy in his/her utterance. Our method is based on supervised machine learning. New features are proposed to train a classifier for identifying the sympathy in user’s utterance. Results of our experiments show that the proposed features improve the F-measure by 3-4% over a baseline.	baseline (configuration management);categorization;content-control software;dialog system;experiment;f1 score;machine learning;robot;robotic pet;statistical classification;supervised learning	Tomotaka Fukuoka;Kiyoaki Shirai	2015			conversation;natural language processing;communication;utterance;classifier (linguistics);artificial intelligence;psychology;sympathy;dialog box	NLP	-16.3595717093916	-81.75146755588192	3830
3a55a300c2441b200555b3615d9e7594c260c21f	access controlled: the shaping of power, rights, and rule in cyberspace; networks and states: the global politics of internet governance	political aspects;information policy;internet;international aspects;access to resources		cyberspace;noise shaping	ShinJoung Yeo	2011	JASIST	10.1002/asi.21554	the internet;law	ECom	-68.50861804582718	-8.233170166522257	3833
6768d0ad5d0a4b706e83578e381809d256c9e4a7	formalization of expert knowledge about the usability of web pages based on user criteria aggregation	human computer interaction;fuzzy measure;formalization;user interface;choquet integral;university rankings;usability ranking;expert knowledge;aggregation operators;usability	The Choquet integral based on fuzzy measure is a generalization of the weighted average operator. Due to flexibility in the aggregation of information and ability to take into account possible uncertainties in data the integral has been gaining popularity in the application of multicriteria decision making. In this paper an application of fuzzy integral is considered in the method of expert knowledge formalization about the usability of web pages. Also the problem of identification of fuzzy measures for aggregating user criteria is presented. Examples of assessments for 9 main usability criteria of web pages and results of web pages evaluation of 25 sites of leading universities in the world according QS ranking are provided.		Alexander Alfimtsev;Sergey Sakulin;Alexey Levanov	2016	IJSI	10.4018/IJSI.2016070103	usability goals;web usability;usability;computer science;knowledge management;data science;data mining;heuristic evaluation	ML	-5.640067262938532	-18.896354017216503	3844
2a6801b0a921ddff03e790f4a2781a0abc3be3d6	cyberbullying in the world of teenagers and social media: a literature review		Cyberbullying amongst teenagers is a major issue, due to their increased use of social media. Previous literature surveys have not covered in detail cyberbullying studies in 2014 and cyberbullying risk factors. This literature review explores cyberbullying research areas, such as the use of social media by teenagers, themes from cyberbullying studies carried out since 2012, cyberbullying risk factors and how teenagers deal with cyberbullying incidents. Current cyberbullying studies highlighted issues such as the high volume of cyberbullying incidents in school, increased personal information disclosure on social media, peer influences and the safety of the school environment for both bully and victim. Studies focusing on cyberbullying risk factors raised debates on factors such as whether males or females are most likely to be victims/cyberbullies. Tackling cyberbullying requires awareness, education for actors involved in cyberbullying, development of software to detect cyberbullying and including actors in the monitoring of cyberbullying. KeyWoRdS Cyberbullying, Internet, Risk Factors, Social Media, Social Network Sites, Teenagers	cyberbullying;personally identifiable information;social media;social network	Sophia Alim	2016	IJCBPL	10.4018/IJCBPL.2016040105	psychology;advertising;social psychology;computer security	HCI	-85.82139257313504	-20.150955498262764	3845
46e223842fcc2da4b6cb56da038b648ebd7322b9	it's all 'about you': diversity in online profiles	self expression;social networking;self description;reuse;social network;user profile;impression formation;user profiles;social networking sites	User profiles on today's social networking sites support only a small set of predefined questions. We report on an alternative way for users to richly describe themselves, by entering not only responses, but their own questions as well. Data from 10 months of usage shows that users of a social networking site created thousands of diverse questions and reused existing questions from other users. Our findings suggest that those with highly diverse user profiles have a higher number of friends.	online community;user profile	Casey Dugan;Werner Geyer;Michael J. Muller;Joan Morris DiMicco;Beth Brownholtz;David R. Millen	2008		10.1145/1460563.1460672	social science;knowledge management;multimedia;sociology;world wide web;social network	HCI	-26.816263088829327	-48.11323723941224	3853
5283e1b9a228f04de5d3295fa675df6ed16c42ed	finding similar mobile consumers with a privacy-friendly geosocial design	analytical modeling;network analysis;mobile computing;design science	"""This paper focuses on finding the same and similar users based on location-visitation data in a mobile environment. We propose a new design that uses consumer-location data from mobile devices smartphones, smart pads, laptops, etc. to build a """"geosimilarity network"""" among users. The geosimilarity network GSN could be used for a variety of analytics-driven applications, such as targeting advertisements to the same user on different devices or to users with similar tastes, and to improve online interactions by selecting users with similar tastes. The basic idea is that two devices are similar, and thereby connected in the GSN, when they share at least one visited location. They are more similar as they visit more shared locations and as the locations they share are visited by fewer people. This paper first introduces the main ideas and ties them to theory and related work. It next introduces a specific design for selecting entities with similar location distributions, the results of which are shown using real mobile location data across seven ad exchanges. We focus on two high-level questions: 1 Does geosimilarity allow us to find different entities corresponding to the same individual, for example, as seen through different bidding systems? And 2 do entities linked by similarities in local mobile behavior show similar interests, as measured by visits to particular publishers? The results show positive results for both. Specifically, for 1, even with the data sample's limited observability, 70%-80% of the time the same individual is connected to herself in the GSN. For 2, the GSN neighbors of visitors to a wide variety of publishers are substantially more likely also to visit those same publishers. Highly similar GSN neighbors show very substantial lift."""		Foster J. Provost;David Martens;Alan Murray	2015	Information Systems Research	10.1287/isre.2015.0576	simulation;network analysis;computer science;artificial intelligence;marketing;advertising;mobile computing;world wide web;computer security	HCI	-24.10411894680929	-43.70998799927431	3854
36c15b6cfee4b8676838b2026be0ac880f9a473e	development of course modules for multidisciplinary stem education	software;digital signal processing;sensors;collaboration;smart phones;stem education;online learning;mobile learning;signal processing algorithms;conferences	Traditional STEM education models in electrical engineering and computer science rely on structured classes, laboratories, and textbooks to transfer key concepts. Even though this process meets most of the ABET objectives, it does not respond well to current workforce needs that require widely accessible programs that will provide a large pool of graduates with STEM backgrounds, analytical and programming skills, critical thinking, and leadership abilities. In this work in progress paper, we describe our efforts to motivate students to pursue studies in STEM areas. We accomplish this by creating and disseminating modules that demonstrate how math and engineering theory enable modern applications such as those embedded in wireless devices.	computer engineering;computer science;electrical engineering;embedded system;immersion (virtual reality);mobile app;streaming media;type class	Andreas Spanias;Mahesh K. Banavar;Henry Braun;Photini Spanias;Yongpeng Zhang	2016	2016 IEEE Frontiers in Education Conference (FIE)	10.1109/FIE.2016.7757416	simulation;engineering;knowledge management;computer engineering	DB	-78.79305731936344	-34.84863991530177	3859
31716e5c5936b7484e76a80dd2ae615401c55b15	long-range fractal correlations in literary corpora	statistical mechanics;time series;fundamental unit	In this paper we analyse the fractal structure of long human-language records by mapping large samples of texts onto time series. The particular mapping set up in this work is inspired on linguistic basis in the sense that is retains the word as the fundamental unit of communication. The results confirm that beyond the short-range correlations resulting from syntactic rules acting at sentence level, long-range structures emerge in large written language samples that give rise to long-range correlations in the use of words.	fractal;text corpus;time series	Marcelo A. Montemurro;Pedro A. Pury	2002	CoRR		statistical mechanics;time series;mathematics;language;fundamental unit;quantum mechanics	NLP	-36.90102700754965	-81.7159393908218	3861
45da881cb280819ae1197be4e781eab7f41ce78e	visualizing uncertainty in flow diagrams: a case study in product costing		Business Intelligence applications often handle data sets that contain uncertain values. In this work we focus on product costing, which deals with the average costs of product components - that vary significantly based on many factors such as inflation, exchange rates, and commodity prices. After experts provide the uncertainty information for single items, decision makers need to quickly understand the cost uncertainties within the hierarchical data structure of the complete product.  To provide this kind of quick overview, we propose a holistic visualization that contains both data and uncertainty. Since Flow diagrams are suitable to visualize tree data structures associated with value attributes, we focus on incorporating uncertainty information directly into these diagrams. Interviews with product costing experts led us to base our solution on Sankey diagrams.  We chose three visualization techniques that are able to convey uncertainty information to the user: Color-code, Gradient, and Margin. We contribute a user study, which involved solving different product costing tasks using these three different visualizations. From the recorded error rates and subjective feedback, we designed an integrated approach that combines elements from all three distinct techniques.	best, worst and average case;color;data flow diagram;data structure;encode;feedback;gradient;gradient method;hierarchical database model;holism;interviews;margin (machine learning);music visualization;naruto shippuden: clash of ninja revolution 3;sankey diagram;usability testing;voronoi diagram	Zana Vosough;Dietrich Kammer;Mandy Keck;Rainer Groh	2017		10.1145/3105971.3105972	tree (data structure);data mining;visualization;flow (psychology);business intelligence;activity-based costing;management science;hierarchical database model;data set;computer science;sankey diagram	HCI	-29.110654032147423	-27.962101412292053	3870
34ac2ef764e9abf7dd87e643e3f555d73f3f8515	transparent queries: investigating users' mental models of search engines	search engine;user study;software systems;web search engine;indexing;compression;mental model	Typically, commercial Web search engines provide very little feedback to the user concerning how a particular query is processed and interpreted. Specifically, they apply key query transformations without the users knowledge. Although these transformations have a pronounced effect on query results, users have very few resources for recognizing their existence and understanding their practical importance. We conducted a user study to gain a better understanding of users knowledge of and reactions to the operation of several query transformations that web search engines automatically employ. Additionally, we developed and evaluated Transparent Queries, a software system designed to provide users with lightweight feedback about opaque query transformations. The results of the study suggest that users do indeed have difficulties understanding the operation of query transformations without additional assistance. Finally, although transparency is helpful and valuable, interfaces that allow direct control of query transformations might ultimately be more helpful for end-users.	mental model;software system;usability testing;web search engine	Jack Muramatsu;Wanda Pratt	2001		10.1145/383952.383991	sargable;search engine indexing;query optimization;query expansion;web query classification;ranking;web search engine;computer science;database;web search query;world wide web;compression;information retrieval;query language;search engine;software system	HCI	-35.162967489762515	-52.097259776256784	3880
94a8e03da349ff84947653c4a27a9e669c5fc566	an nfc-based method for rapid identification of teaching resources	near field communication electrical engineering education;education receivers radio transmitters near field communication radiofrequency identification web pages wires;nfc technology nfc based method teaching resource rapid identification electrical engineering optimum material base teaching aids near field communication;near field communication teaching aids wireless radio frequency identification	To ensure effective teaching in electrical engineering, it is essential to provide a continuous adjustment of the practical support to the current requirements. A frequent problem is related to the process of organizing an optimum material base that would allow educators to quickly identify the appropriate items, making it possible to implement more relevant teaching aids. This paper proposes a method of organizing the available material resources based on the Near Field Communication (NFC) technology, by which teachers can rapidly identify the required physical parts and approach practically in real time a wide range of information on the topic, leading to significant streamlining of his work.	electrical engineering;near field communication;organizing (structure);requirement	Marllene Daneti	2016	2016 IEEE Global Engineering Education Conference (EDUCON)	10.1109/EDUCON.2016.7474556	electronic engineering;telecommunications;engineering;electrical engineering	DB	-86.35843365007366	-35.348017922217274	3885
c03d87e01dc3d0a91175c9376f474f639b0d5bb4	design, evaluation and impact of educational olfactory interfaces	learning;prototypes;testing;olfactory interfaces;design;usability	Olfactory interfaces (digital systems that generate and diffuse smells to a human user with a purpose) have been proposed and developed to support learning in a number of educational settings. This emerging type of human-computer interfaces has great potential for stimulating information recall, helping immerse learners into educational simulations, and supporting other human senses for learning. However, little is known on the proper design and evaluation of olfactory interfaces for learning. This paper discusses research in progress on the design and evaluation of an educational olfactory interfaces, including prototyping development methods based on user-centered design (UCD) and usability methods. An electronic prototype is to be used as a testbed. Prototyping+UCD approach indicates potential for developing practical, efficient and effective olfactory interfaces for learning. Future usability tests with our olfactory interface will confirm the design and testing methodologies used in our project.	code smell;digital electronics;prototype;simulation;testbed;usability;user-centered design	Miguel Ángel García-Ruíz;Pedro C. Santana-Mancilla	2013			simulation;human–computer interaction;computer science;multimedia	HCI	-65.52655367331079	-44.83361174913997	3893
b1843b296d38ed2949c2efa7f35859e656383c93	walrasian analysis via two-player games	nash equilibrium;walrasian equilibrium nash equilibrium aubin core;nash equilibria;exchange economy;walrasian equilibrium	We associate to any pure exchange economy a game with only two players, regardless of the number of consumers. In this two-player game, each player represents a different role of the society, which is formed by all the individuals in the economy. Player 1 selects feasible allocations trying to make Pareto improvements. Player 2 chooses an alternative from the wider range of allocations that are feasible in the sense of Aubin. The set of Nash equilibria of our game is non-empty and our main result provides a characterization of Walrasian equilibria allocations as strong Nash equilibria of the associated society game. JEL Classification: D49, D51, C70, C72.	nash equilibrium;pareto efficiency	Carlos Hervés-Beloso;Emma Moreno-García	2009	Games and Economic Behavior	10.1016/j.geb.2007.12.001	price of stability;implementation theory;bayesian game;epsilon-equilibrium;best response;trembling hand perfect equilibrium;coordination game;general equilibrium theory;economics;subgame;non-credible threat;folk theorem;repeated game;correlated equilibrium;chicken;microeconomics;risk dominance;normal-form game;mathematical economics;market economy;subgame perfect equilibrium;equilibrium selection;solution concept;nash equilibrium;symmetric equilibrium	ECom	-5.403310203201533	-2.5114922891824416	3895
24a3f6aae955085515633338ec1026fc7c9437b7	partial sums-based p-rank computation in information networks		P-Rank is a simple and captivating link-based similarity measure that extends SimRank by exploiting both in- and out-links for similarity computation. However, the existing work of P-Rank computation is expensive in terms of time and space cost and cannot efficiently support similarity computation in large information networks. For tackling this problem, in this paper, we propose an optimization technique for fast P-Rank computation in information networks by adopting the spiritual of partial sums. We write P-Rank equation based on partial sums and further approximate this equation by setting a threshold for ignoring the small similarity scores during iterative similarity computation. An optimized similarity computation algorithm is developed, which reduces the computation cost by skipping the similarity scores smaller than the give threshold during accumulation operations. And the accuracy loss estimation under the threshold is given through extensive mathematical analysis. Extensive experiments demonstrate the effectiveness and efficiency of our proposed approach through comparing with the straightforward P-Rank computation algorithm.	approximation algorithm;computation;experiment;iterative method;mathematical optimization;simrank;similarity measure;tree accumulation	Jinhua Wang;Mingxi Zhang;Zhenying He;Wei Wang	2017		10.1145/3106426.3109447	spacetime;discrete mathematics;computation;series (mathematics);similarity measure;mathematical optimization;mathematics;simrank	DB	-10.29262304704716	-41.49359516707172	3902
604bbfb6c520ef5019dd22765484f13da1f1c98c	link prediction of multimedia social network via unsupervised face recognition	link prediction;social network;real world application;face recognition;social networks;empirical validation;affinity propagation;constraint affinity propagation	We propose a new challenge for predicting links of social networks by unsupervised face recognition on photo albums. We solve the task by formulating it into Kernel Set Discovery problem. We enhance Affinity Propagation algorithm to tackle the problem with more constraints. More specifically, the face cannot appear more than once in the same photo and we impose constraints such that detected face images in the same photograph are never clustered into the same person. We construct a synthetic dataset based on AT\&T image benchmark for empirical validation. Moreover, we validate our algorithms by a real world application which contains a real friend relation on the Web 2.0 social network system. Results indicate our Constraint Affinity Propagation method is suitable to unsupervisedly predict links of social network.	affinity propagation;algorithm;benchmark (computing);cluster analysis;computer vision;facial recognition system;feature vector;kernel (operating system);social network;software propagation;synthetic intelligence;web 2.0	Dijun Luo;Heng Huang	2009		10.1145/1631272.1631419	facial recognition system;computer science;artificial intelligence;machine learning;pattern recognition;data mining;social network	AI	-16.10496631037858	-46.88038331130136	3905
a2a8cdd9cdfebd8b933b7d61cc891b96267e9d22	experimental measures of news personalization in google news	news publishers;filter bubbles;web search results	Search engines and social media keep trace of profileand behavioral-based distinct signals of their users, to provide them personalized and recommended content. Here, we focus on the level of web search personalization, to estimate the risk of trapping the user into so called Filter Bubbles. Our experimentation has been carried out on news, specifically investigating the Google News platform. Our results are in line with existing literature and call for further analyses on which kind of users are the target of specific recommendations by Google.	experiment;google news;interaction;personalization;social media;web search engine	Vittoria Cozza;Van Tien Hoang;Marinella Petrocchi;Angelo Spognardi	2016		10.1007/978-3-319-46963-8_8	computer science;personalization;multimedia;world wide web;news aggregator	Web+IR	-25.66490179860863	-48.72785235388834	3907
04d72cc34aeeeaa65b28454932c959e786943232	15th european conference on computer supported cooperative work - panels, demos and posters, ecscw 2017 panels, demos and posters, sheffield, uk, august 28 - september 1, 2017			computer-supported cooperative work		2017				Vision	-52.03920684092377	-8.980639676229675	3913
f4cb1ecae150ef2e363b9b34dd74b691c313f169	a unified framework for grammar error correction		In this paper we describe the PKU system for the CoNLL-2014 grammar error correction shared task. We propose a unified framework for correcting all types of errors. We use unlabeled news texts instead of large amount of human annotated texts as training data. Based on these data, a tri-gram language model is used to correct the replacement errors while two extra classification models are trained to correct errors related to determiners and prepositions. Our system achieves 25.32% in f0.5 on the original test data and 29.10% on the revised test data.	error detection and correction;language model;test data;triangular function;unified framework	Longkai Zhang;Houfeng Wang	2014			natural language processing;speech recognition;algorithm	NLP	-23.185658586007218	-76.23317638721944	3914
3a8019cbfc0fd0b1106b261d97fd02ae8d101c4a	projection based olfactory display with nose tracking	object recognition;nose position olfactory display nose tracking human olfaction primary odors spatio temporal control interactive olfactory displays visual displays head mounted displays users nose restricted space air cannon toroidal vortices scented air;olfactory displays nose humans control system synthesis solids scattering atmosphere prototypes target tracking;virtual reality;chemioception target tracking gesture recognition computer displays helmet mounted displays virtual reality object recognition;computer displays;target tracking;gesture recognition;helmet mounted displays;chemioception;head mounted display	"""Most attempts to realize an olfactory display have involved capturing and synthesizing the odor, processes that still pose many challenging problems. These difficulties are mainly due to the mechanism of human olfaction, in which a set of so-called """"primary odors"""" has not been found. Instead, we focus on spatio-temporal control of odor rather than synthesizing odor itself. Many existing interactive olfactory displays simply diffuse the scent into the air, which does not provide the ability of spatio-temporal control of olfaction. Recently, however, several researchers have developed olfactory displays that inject scented air under the nose through tubes. On the analogy of visual displays, these systems correspond to head-mounted displays (HMD). These yield a solid way to achieve spatio-temporal control of olfactory space, but they require the user to wear something on his or her face. Here, we propose an unencumbering olfactory display that does not require the user to attach anything on the face. It works by projecting a clump of scented air from a location near the user's nose through free space. We also aim to display a scent to the restricted space around a specific user's nose, rather than scattering scented air by simply diffusing it into the atmosphere. To implement this concept, we used an """"air cannon"""" that generates toroidal vortices of the scented air. We conducted a preliminary experiment to examine this method's ability to display scent to a restricted space. The results show that we could successfully display incense to the target user. Next, we constructed prototype systems. We could successfully bring the scented air to a specific user by tracking the nose position of the user and controlling the orientation of the air cannon to the user's nose."""	alpha compositing;head-mounted display;optimal design;prototype;surrogate key;taylor–green vortex;toroidal graph	Yasuyuki Yanagida;Shinjiro Kawato;Haruo Noma;Akira Tomono;Nobuji Tetsutani	2004	IEEE Virtual Reality 2004	10.1109/VR.2004.62	computer vision;simulation;computer science;artificial intelligence;optical head-mounted display;cognitive neuroscience of visual object recognition;gesture recognition;virtual reality	HCI	-41.19195737840103	-41.72274792213347	3915
2a08091dc63e29a2c76e97bd5700947c1cf8b665	"""""""who is key...?"""" - characterizing value adding users in enterprise social networks"""		Whereas the use of Enterprise Social Networks (ESN) is a pervasive topic in research and practice, both parties are still struggling to come to a better understanding of the role and impact of ESN in and on knowledge-intensive corporate work. As a part of this phenomenon, employees who communicate their knowledge in ESN helping other users to do their daily work play a decisive role. We need to come to a better understanding of the role and behaviour of such value adding users. This is a prerequisite, for example, for understanding knowledge support hubs or for enabling more effective internal information and knowledge sharing. Against this background, we investigate the structural characteristics of value adding users in ESN using qualitative text analysis and Social Network Analysis. Based on a large scale dataset of a global consulting company using the ESN Yammer.com we analyse the social relationships of value adding users. We confirm their significant position and draw conclusions for research and practice.	categorization;directed graph;echo state network;eigenvector centrality;enterprise social networking;european conference on information systems;pervasive informatics;scientific literature;social graph;social network analysis	Katharina Berger;Julia Klier;Mathias Klier;Alexander Richter	2014			public relations;knowledge management;world wide web	HCI	-80.12685428523544	-17.316001039213596	3916
3a42cc9555bc8a3fb8ce9a43423d3ebd8812d29e	solidarity across borders: navigating intersections towards equity and inclusion		"""There is a growing community within CSCW that examines issues of equity and inclusion in internet and social media use. With researchers focused on global development, social justice, accessibility, and more, we contend that there are issues of equity and inclusion impacting the research subjects located on the """"margins"""" of digital existence, the research that examines these issues, and the researchers engaged in this research. The goal of our workshop is to brainstorm and discuss how we might demarginalize those researched, this research, and these researchers within CSCW scholarship. For this, we build on the concepts of intersectionality and solidarity from feminist scholarship, aiming to recognize the differences and similarities across disparate contexts and to uncover synergistic research trajectories and objectives. Our workshop will be led by academic and industry researchers pursuing CSCW, Social Computing, and Information and Communication Technologies and Development (ICTD) research focused on intersectionality, equity, and inclusion. We invite a broad range of participants from research and practice interested in learning about or deepening their understanding of these topics. Our workshop will foster solidarity across diverse subsections of the CSCW community and beyond."""	accessibility;brainstorm;computer-supported cooperative work;internet;social computing;social media;synergy	Michaelanne Dye;Neha Kumar;Ari Schlesinger;Marisol Wong-Villacres;Morgan G. Ames;Rajesh Veeraraghavan;Jacki O'Neill;Joyojeet Pal;Mary L. Gray	2018		10.1145/3272973.3273007	scholarship;intersectionality;knowledge management;the internet;equity (finance);public relations;computer-supported cooperative work;social media;social computing;solidarity;computer science	HCI	-77.1407981943614	-16.163051712260852	3927
055239f7c3e8ba075521de34da6833b2a14ab195	multidimensional scaling for fast speaker clustering	baseline speaker clustering method;speaker models;pattern clustering;speaker clustering;acoustics;acoustic modeling;speech segmentation;speech;fast speaker clustering;speech segments;speaker models speaker clustering multidimensional scaling;speaker recognition;vector quantization;matrix decomposition;feature extraction;clustering method;density estimation robust algorithm;multidimensional scaling;transforms;initial acoustic models;speech acoustics density estimation robust algorithm transforms conferences feature extraction matrix decomposition;speaker recognition pattern clustering;vector quantizer;acoustic speaker models;baseline speaker clustering method multidimensional scaling fast speaker clustering speech segments initial acoustic models vector quantization acoustic speaker models;conferences	This study presents a fast speaker clustering method based on multidimensional scaling. Speech segments are trained as initial acoustic models. MDS is utilized to transform acoustic models to a space with the coordinate best preserve the distances or dissimilarity between models. Speaker clusters are clustered using vector quantization on the MDS coordinates and the acoustic speaker models are trained on MFCCs features for each cluster. Experimental results show the proposed method outperforms the baseline speaker clustering method in lower execution time.	acoustic cryptanalysis;acoustic model;baseline (configuration management);cluster analysis;computer cluster;geographic coordinate system;image scaling;kullback–leibler divergence;multidimensional scaling;run time (program lifecycle phase);vector quantization	Chi-Chun Hsia;Kuo-Yuan Lee;Chih-Chieh Chuang;Yu-Hsien Chiu	2010	2010 7th International Symposium on Chinese Spoken Language Processing	10.1109/ISCSLP.2010.5684888	speaker recognition;speech recognition;multidimensional scaling;feature extraction;computer science;speech;machine learning;pattern recognition;speech segmentation;matrix decomposition;vector quantization	NLP	-17.395374457528455	-93.46537890404507	3931
9ee25f052436f2183ed22ee7b82e3b4bc6f0a187	cognitive simulation in virtual patients	this virtual patient;software agent;goal orientation;knowledge base;multiple choice;virtual human;cognitive model	We present an overview of the Virtual Patient project at the University of Maryland, which is developing a cognitive model of humans experiencing various states of health and disease to be used in interactive simulations for physician training.	artificial intelligence;cognitive model;interactive design;simulation	Sergei Nirenburg;Marjorie McShane;Stephen Beale;Thomas P. O'Hara;Bruce Jarrell;George Fantry;John Raczek	2006			cognitive model;simulation;goal orientation;software agent;human–computer interaction;knowledge base;learning environment;computer science;virtual patient;cognition	AI	-66.50369322971821	-51.33039020696763	3933
43a6c84beefe3bc5ec0e86b44f055c8154f979b1	friendships through im: examining the relationship between instant messaging and intimacy	instant messaging	Abstract#R##N##R##N#This study explores the relationship between the amount of Instant Messenger (IM) use and the level of perceived intimacy between friends. Results showed the amount of IM use was positively associated not only with verbal intimacy, but also with affective and social intimacy. Findings are consistent with the relationship liberated perspective of computer-mediated communication, and suggest that IM promotes rather than hinders intimacy. Moreover, frequent conversation via IM actually encourages the desire to meet face-to-face. Theoretical as well as practical implications of the results for geographically remote friends and families are discussed.	instant messaging	Yifeng Hu;Jacqueline Fowler Wood;Vivian Smith;Nalova Westbrook	2004	J. Computer-Mediated Communication	10.1111/j.1083-6101.2004.tb00231.x	psychology;computer science;sociology;communication;social psychology	HCI	-87.0486836634864	-18.254625731362022	3937
e2f6ed72768a3781c69c278b4fadc6743943ceaf	twinkle megane: near-eye led indicators on glasses in tele-guidance for elderly	twinkle megane dementia simulated navigational tasks visual cues eyeglasses based navigation system light emitting diode indicators navigation interface memory loss senior citizens aged society global social issues wearable technologies elderly tele guidance near eye led indicators;senior citizens;light emitting diodes;glass;navigation;visualization;wearable computers assisted living computerised navigation eye protection geriatrics handicapped aids led lamps;dementia;usability;navigation senior citizens visualization light emitting diodes glass dementia usability	The development of wearable technologies has generated significant interest in the last decades. Considering global social issues such as aged society besides the technologies, senior citizens suffering from memory loss would be one of potential user groups. Since the use of eyeglasses among the elderly is quite common, we have constructed a navigation interface on eyeglasses by implanting a set of light emitting diode indicators on the frame of the glasses. We aim to realize eyeglasses-based navigation system that provides the elderly with the visual cues and could be interpreted intuitively as navigational commands. Furthermore, we believe that our system would improve the independent mobility of the elderly. This paper explains our first prototype glasses with near-eye LED indicators, incremental experimentation, and the preliminary results that are used to optimize the visual cues for real navigational tasks. The system was evaluated in simulated navigational tasks by the elderly participants suffering from dementia. We assessed our system by he experimentation and living lab methodology with data-driven approach.	diode;experience;experiment;iterative method;living lab;prototype;sensor;twinkle;television;usability;wearable computer	Yukitoshi Kashimoto;Aryan Firouzian;Zeeshan Asghar;Goshiro Yamamoto;Petri Pulli	2016	2016 IEEE International Conference on Pervasive Computing and Communication Workshops (PerCom Workshops)	10.1109/PERCOMW.2016.7457134	embedded system;computer vision;navigation;simulation;visualization;usability;human–computer interaction;computer science;glass;multimedia;light-emitting diode	Robotics	-42.9157261839558	-45.85287004723654	3942
4ddf6cd55ade356c74baa410a223ee677a2a8db8	role based access control design using three-way formal concept analysis		Role based access control (RBAC) is one of the popular access control models. On representing the policy behind RBAC, the literatures investigate the use of various knowledge representation techniques such as Descriptive logics, Formal Concept Analysis (FCA), Ontology etc. Based on the input of binary access control table, the existing knowledge representation techniques on RBAC derives two-way decisions whether to permit the access request or not. It works well when single element in the set of elements of a constituent of RBAC initiates the access request. Consider the scenario of multiple distinct elements in the set of elements of a constituent of RBAC initiate the collective access request to a set of elements in other constituent of RBAC. In many cases of this scenario, some elements possess but not all of the elements possess the permission to access all elements in other subset of a constituent of RBAC. On this situation, the collective access decision to those multiple distinct elements in the set of elements of a RBAC constituent appears in three forms such as permit, deny and non-commitment. Three-way formal concept analysis (3WCA) is an emerging knowledge representation technique which provides two types of three-way concepts and their lattices to enable three-way decisions from the binary information table. At this juncture, it is more suitable to apply 3WCA on representing the RBAC policy to enable three-way decisions instead of existing two-way decisions in classical FCA and triadic FCA. The main objective of this paper is to propose a methodology for modelling RBAC using 3WCA and attain its distinctive merits. Our discussion is on two lines of inquiry. We present on how 3WCA can provide suitable representation of RBAC policy and whether this representation follows role hierarchy and constraints of RBAC.	formal concept analysis;role-based access control	Chandra Mouliswaran Subramanian;Cherukuri Aswani Kumar;Chandrasekar Chelliah	2018	Int. J. Machine Learning & Cybernetics	10.1007/s13042-018-0840-7	management science;knowledge representation and reasoning;access control;lattice (order);role-based access control;role hierarchy;juncture;permission;formal concept analysis;computer science	PL	-20.68362227286734	4.127710552566799	3946
166ca3821db54cc9b58bc7044e787d113fea2e9d	what is needed the most in mt-supported paper writing	conference paper	This paper addresses our system which provides an effective method to write an English paper suitable for international conferences and analyze the system’s pros and cons through the user’s data collected from operating the system for 6 months. The system consists of Korean-English paper MT module supported by user interaction environment. Our original Korean-English paper MT system was quite useful for understanding, but not satisfactory for writing. So, we analyzed our system to trace what caused such dissatisfaction. We classified the analysis results into three main categories, that is, the errors in the source sentence itself, the errors of our MT system, and the absence of the appropriate domain-specific expression information. For each category we provide an alternative method and show the effectiveness through analyzing the user’s data. We can confirm that our system can be used quite usefully for paper writing.	computer-aided software engineering;display resolution;domain-specific language;effective method;entropy maximization;error detection and correction;machine translation;parsing;structural analysis;usability;word-sense disambiguation	Changhyun Kim;Oh-Woog Kwon;Young Kil Kim	2008			gerontology;geography;media studies;cartography	SE	-28.499774198677095	-76.0120382431619	3949
f4ffd5b0bd39ab78bf08da6ec1f1414c555a104f	spiral theme plot	theme river;temporal data visualization;scatter plot;keywords;picture image generation;line and curve generation;i 3 3 computer graphics	We introduce a new visualization method for temporal data, Spiral Theme Plot, by combining ThemeRiver method, spiral patterns, and scatter plot technique. Similar to ThemeRiver, data in different categories (themes) are visualized in different bands, but also in a spiral pattern. Themes are stacked along a spiral curve, which represent the time axis. Individual data points are plotted within the regions of the themes, with various visual features. In addition to showing the overall theme patterns over time, this approach also shows plotting patterns within the themes. Compared to ThemeRiver, Spiral Theme Plot can accommodate longer time axis, and more importantly, can provide periodic patterns that are typically not available in ThemeRiver.	apache axis;data point	Shenghui Jiang;Shiaofen Fang;Shaun J. Grannis	2016		10.2312/eurovisshort.20161170	computer science;artificial intelligence;cartography;computer graphics (images)	Visualization	-26.044366526100006	-33.207135996936636	3950
0a60d9d62620e4f9bb3596ab7bb37afef0a90a4f	chimpanzee faces in the wild: log-euclidean cnns for predicting identities and attributes of primates		In the following, we present our chimpanzee face dataset in detail and give additional results for age and age group prediction. Although the content of this document is not essential for the main paper, it contains additional details to support our contributions. S1 Statistics of Our Chimpanzee Datasets For a detailed understanding of experimental results on both datasets, it is essential to analyze their statistics in advance to check for potential dataset bias. In the following, we provide several views on the provided data of both datasets. As in the experimental setup of the main paper, we exclude categories with less than 5 examples for evaluation. These categories are either artifacts of incorrect annotations in meta-data (e.g., chimpanzees identified as “Allex” instead of “Alex”) or contain rare individuals for which classification estimates are hardly reliable. In consequence, we obtain all 24 categories for C-Zoo and 62 of 78 categories for C-Tai. Statistics of Individuals The distribution of annotated faces per individual is shown in Fig. S1. As can be seen, the C-Zoo dataset offers a moderately balanced setting. In contrast, the C-Tai dataset is strongly heavy-tailed. Thus, models and evaluation metrics need to consider this aspect, e.g., by reporting averaged class-wise recognition rates instead of overall recognition rates. Statistics of Age We further analyze the available faces within each age group and visualize the resulting statistics in Fig. S2. First of all, we notice tiny inconsistencies of age group labels, especially at the border between age groups. In addition, we observe that the Sub-Adult group is rarely recorded in the dataset C-Tai. Furthermore, the recordings in wild life (dataset C-Tai) contain substantially more infants. Again, imbalance of distributions should be reflected in the chosen evaluation metric. 2 A. Freytag, E. Rodner, M. Simon, A. Loos, H. Kühl, J. Denzler	evaluation function;zoo (file format)	Alexander Freytag;Erik Rodner;Marcel Simon;Alexander Loos;Hjalmar S. Kühl;Joachim Denzler	2016		10.1007/978-3-319-45886-1_5	psychology;zoology;anthropology	Vision	-6.116232229309856	-75.39771573165754	3951
47ecab2caef80d7f3a6be84b316b92a55a07e847	how to go from strategy to results? institutionalising bpm governance within organisations	bpm unit;business process management;bpm governance;process owners;organisational design	Purpose – The purpose of this paper is to examine how business process management (BPM) is incorporated within organisational structure. The authors demonstrate how a strategic interest in BPM and formal responsibilities for BPM activities shape the efficiency, quality and agility of BPM initiatives. By conducting field research, useful empirical insights were drawn about the necessary conditions for ensuring the success of BPM initiatives. Design/methodology/approach – A questionnaire survey of BPM adoption practices was conducted among private- and public-sector organisations with more than 50 employees. A cross-national sample of 60 Croatian and 51 Slovenian companies is analysed by applying a subsampling strategy and using inferential statistics methods. Findings – The study clearly shows how particular structural decisions can foster the operational excellence of BPM initiatives. Formal process roles and specialised BPM units were recognised as important drivers of organisational success. In addition...	beam propagation method	Tomislav Hernaus;Vesna Bosilj-Vuksic;Mojca Indihar Stemberger	2016	Business Proc. Manag. Journal	10.1108/BPMJ-03-2015-0031	systems engineering;knowledge management;business process management;database;management	ML	-79.53195297953268	1.0125731188285285	3953
27d4b8bc5c21c0ee4a8de42b4d97d766fb617207	sharing nursing data across the continuum of care using ccc system			apache continuum	Virginia K. Saba;Deborah Aristo;Veronica Feeg;Debbie Raposo;LuAnn Whittenburg	2012			family medicine;continuum (design consultancy);nursing;medicine	HCI	-56.888531647233535	-63.88555968267705	3958
350c89a9592e459d8f17f7e13c7b6def833c273f	investigating ontological similarity theoretically with fuzzy set theory, information content, and tversky similarity and empirically with the gene ontology	semantic similarity;ontological similarity;information content;tversky s parameterized ratio model;gene ontology	This paper theoretically and empirically investigates ontological similarity. Tversky's parameterized ratio model of similarity [3] is shown as a unifying basis of many of the well-known ontological similarity measures. A new family of ontological similarity measures is proposed that allows parameterizing the characteristic set used to represent an ontological concept. The three subontologies of the prominent GO are used in an empirical investigation of several ontological similarity measures. A new ontological similarity measure derived from the proposed family is also empirically studied. A detailed discussion of the correlation among the measures is presented as well as a comparison of the effects of two different methods of determining a concept's information content, corpus-based and ontology-based.	fuzzy set;gene ontology;set theory	Valerie V. Cross;Xinran Yu	2011		10.1007/978-3-642-23963-2_30	natural language processing;semantic similarity;self-information;computer science;data mining;mathematics;information retrieval;statistics	ML	-5.237828825505873	-23.153462932653174	3960
00888eb18721c3c0f7f02902b07047b3d636715f	simulation of logistics: effectiveness of naval surface fire support to the army brigade commander in a littoral campaign	naval surface fire support;army brigade commander;cold war;future mission;well-constructed coa;littoral campaign;simulation tool;fire support;u.s. interest;lethal force;future threat	Since the end of the Cold War, the Army has engaged in an unprecedented number of joint contingency operations hinting at future missions aimed at protecting U.S. interests worldwide. To engage and defeat future threats to our national security, the Army must transform itself into a more strategically responsive, lethal force. This paper analyzes the effectiveness of Naval Surface Fire Support (NSFS), which can help lighten the force by providing support for brigade-sized units. The Fire Support Simulation Tool (FSST) simulates the employment of various indirect fire courses of action (COA's) for analysis. Comparing the utility of several well-constructed COA's using the FSST's output can help decision-makers determine the effectiveness of NSFS for specific campaigns. The results of this analysis conclude that there is strong quantitative and analytical evidence to support the effectiveness of NSFS to an Army Brigade commander engaged in a littoral campaign.	distrust;kinetic data structure;logistics;moe;not safe for work;simulation	Juan K. Ulloa;Eugene P. Paulo	2001			simulation;engineering;operations research	HCI	-23.090820842610285	-23.453711914096647	3966
08fc2cdb4b2f8e81705d9c53c334213c34d1dbaf	linguistically motivated descriptive term selection	linguistically motivated approach;complex term;applications environment;indexing strategy;shallow text processing;index term source;descriptive term;linguistically motivated descriptive term;language processing;term concept;text expression;indexation;power generation;indexing terms	A linguistically motivated approach to indexing, that is the provision of descriptive terms for texts of any kind, is presented and illustrated. The approach is designed to achieve good, i.e. accurate and flexible, indexing by identifying index term sources in the meaning representations built by a powerful general purpose analyser, and providing a range of text expressions constituting semantic and syntactic variants for each term concept. Indexing is seen as a legitimate form of shallow text processing, but one requiring serious semantically based language processing, particularly to obtain well-founded complex terms, which is the main objective of the project described. The type of indexing strategy described is further seen as having utility in a range of applications environments.	domain-specific language;information retrieval;mental representation;vii	Karen Spärck Jones;John Tait	1984			natural language processing;electricity generation;index term;computer science;data mining;information retrieval	DB	-32.03568762065543	-71.22669336705026	3970
1979f6ef73696f0748f09d80facd4b59819306c5	how companion-technology can enhance a multi-screen television experience: a test bed for adaptive multimodal interaction in domestic environments		This article deals with a novel multi-screen interactive TV setup (smarTVision) and its enhancement through Companion-Technology. Due to their flexibility and the variety of interaction options, such multi-screen scenarios are hardly intuitive for the user. While research known so far focuses on technology and features, the user itself is often not considered adequately. Companion-Technology has the potential of making such interfaces really user-friendly. Building upon smarTVision, it’s extension via concepts of Companion-Technology is envisioned. This combination represents a versatile test bed that not only can be used for evaluating usefulness of Companion-Technology in a TV scenario, but can also serve to evaluate Companion-Systems in general.	automated planning and scheduling;component-based software engineering;deployment environment;dialog manager;display device;multimodal interaction;singlet fission;testbed;usability	Jan Gugenheimer;Frank Honold;Dennis Wolf;Felix Schüssel;Julian Seifert;Michael Weber;Enrico Rukzio	2015	KI - Künstliche Intelligenz	10.1007/s13218-015-0395-7	simulation;human–computer interaction;multimedia	HCI	-52.02015681916817	-38.564330936730485	3976
6defdc9e0d3f7f0a5000b06b4f530778f05f87df	a semi-automatic annotation method of effect clue words for chinese patents based on co-training			co-training;semiconductor industry	Na Deng;Chunzhi Wang;Mingwu Zhang;Zhiwei Ye;Liang Xiao;Jingbai Tian;Desheng Li;Xu Chen	2018	IJDWM	10.4018/IJDWM.2018100101	data mining;computer science;co-training;annotation	NLP	-25.580929667044494	-68.07951562584948	3979
1bf15cee6646c6ffae1e424dc71a133c9b857651	an approach to automatic text production in electronic medical record systems	modelizacion;lenguaje documental;text;medical record;analisis estadistico;time complexity;frase;semantics;intelligence artificielle;texte;probabilistic approach;semantica;semantique;modelisation;grammaire cf;sentence;langage documentaire;complexite temps;statistical analysis;dossier medical;filter;context free grammar;enfoque probabilista;approche probabiliste;analyse statistique;gramatica independiente;historial clinico;filtre;information language;artificial intelligence;phrase;inteligencia artificial;statistical language model;electronic medical record;complejidad tiempo;texto;modeling;filtro	The paper describes basic properties of a sentence generator which requires minimal input information. Input is a set of unstructured semantic concepts, and the generator produces sentences which are compatible with this set by utilizing information from a statistical language model. Output is filtered by a simple context-free grammar. The system is trained on text from electronic medical records, and it is able to produce well-formed sentences in cases involving simple medication prescriptions and symptom descriptions. Basic complexity aspects of the problem are described, and suggestions for efficient implemented generators which manage to produce sentences within acceptable time limits, despite the complexity of the approach, are presented in the final sections.		Torbjørn Nordgård;Martin Thorsen Ranang;Jostein Ven	2005		10.1007/11553939_165	natural language processing;time complexity;speech recognition;systems modeling;filter;computer science;artificial intelligence;machine learning;database;semantics;context-free grammar;medical record;algorithm	NLP	-36.23627028356515	-78.58682972905245	3985
a4c881efa8199aa0a6788c8fa8496aad43549e03	vast 2007 contest interactive poster: data analysis using ndcore and reggae	legislation;data discovery visualization visual analytics text analysis;text document;text analysis;relational database;data mining;text analysis data analysis data mining data visualisation legislation relational databases;reggae tool;data analysis text analysis relational databases engines performance analysis prototypes multidimensional systems application software wildlife user interfaces;data visualisation;data analysis;visualization;visual analytics data analysis ats intelligent discovery ndcore tool reggae tool relationship generating graph analysis engine wildlife law enforcement endangered species issue ecoterrorism vast contest scenario relational database text document;relationship generating graph analysis engine;data discovery;vast contest scenario;law enforcement;endangered species;ecoterrorism;wildlife law enforcement;relational databases;ndcore tool;visual analytics;endangered species issue;ats intelligent discovery	ATS intelligent discovery analyzed the VAST 2007 contest data set using two of its proprietary applications, NdCore and REGGAE (relationship generating graph analysis engine). The paper describes these tools and how they were used to discover the contest's scenarios of wildlife law enforcement, endangered species issues, and ecoterrorism.		Lynn Schwendiman;Jonathan McLean;Jonathan Larson	2007	2007 IEEE Symposium on Visual Analytics Science and Technology	10.1109/VAST.2007.4389016	visual analytics;relational database;computer science;data science;data mining;world wide web;data visualization	Embedded	-31.794535466356134	-30.018728648306148	3988
a4b8615492af27bfe5cf9960849fdba7a2e34ad3	bertrand networks	networks;bertrand	We study scenarios where multiple sellers of a homogeneous good compete on prices, where each seller can only sell to some subset of the buyers. Crucially, sellers cannot price-discriminate between buyers. We model the structure of the competition by a graph (or hyper-graph), with nodes representing the sellers and edges representing populations of buyers. We study equilibria in the game between the sellers, prove that they always exist, and present various structural, quantitative, and computational results about them. We also analyze the equilibria completely for a few cases. Many questions are left open.	bertrand (programming language);computation;population	Moshe Babaioff;Brendan Lucier;Noam Nisan	2013	CoRR	10.1145/2482540.2482564	industrial organization;computer science;microeconomics;mathematical economics;commerce;forward auction	AI	-4.697341838309223	-2.3952503369256886	3998
61eff30e68c4c65924b6abc2b1dffd5fe07a2499	user interface design for mobile-based sexual health interventions for young people: design recommendations from a qualitative study on an online chlamydia clinical care pathway	health informatics;healthcare;information systems and communication service;management of computing and information systems;sexual health;article;mobile technologies	BACKGROUND The increasing pervasiveness of mobile technologies has given potential to transform healthcare by facilitating clinical management using software applications. These technologies may provide valuable tools in sexual health care and potentially overcome existing practical and cultural barriers to routine testing for sexually transmitted infections. In order to inform the design of a mobile health application for STIs that supports self-testing and self-management by linking diagnosis with online care pathways, we aimed to identify the dimensions and range of preferences for user interface design features among young people.   METHODS Nine focus group discussions were conducted (n = 49) with two age-stratified samples (16 to 18 and 19 to 24 year olds) of young people from Further Education colleges and Higher Education establishments. Discussions explored young people's views with regard to: the software interface; the presentation of information; and the ordering of interaction steps. Discussions were audio recorded and transcribed verbatim. Interview transcripts were analysed using thematic analysis.   RESULTS Four over-arching themes emerged: privacy and security; credibility; user journey support; and the task-technology-context fit. From these themes, 20 user interface design recommendations for mobile health applications are proposed. For participants, although privacy was a major concern, security was not perceived as a major potential barrier as participants were generally unaware of potential security threats and inherently trusted new technology. Customisation also emerged as a key design preference to increase attractiveness and acceptability.   CONCLUSIONS Considerable effort should be focused on designing healthcare applications from the patient's perspective to maximise acceptability. The design recommendations proposed in this paper provide a valuable point of reference for the health design community to inform development of mobile-based health interventions for the diagnosis and treatment of a number of other conditions for this target group, while stimulating conversation across multidisciplinary communities.	audio media;chlamydia;community;focus group;forty nine;gene regulatory network;infection;mhealth;patients;personalization;physiological sexual disorders;privacy;rectangular potential barrier;self-management (computer science);sexually transmitted diseases;stimulation (motivation);transcript;trusted operating system;user interface device component;user interface design;user journey;women's health services;college;disease transmission	Voula Gkatzidou;Kate Hone;Lorna J. Sutcliffe;Jo Gibbs;Syed Tariq Sadiq;Ala Szczepura;Pam Sonnenberg;Claudia S. Estcourt	2015		10.1186/s12911-015-0197-8	health informatics;medicine;human–computer interaction;knowledge management;nursing;mobile technology;multimedia	HCI	-60.803617906149015	-58.17584729538781	3999
0ac0e29ac09a58fb5c5a6d01b014aff6058d047a	human capability of discriminating relief-like 2d figures in tactile displaying	human biomechanics;sensor or actuator design;proprioception;cutaneous senses;thenar part;man machine system;tactile display;finger pad;teleoperation;psychophysics;haptic interface	† Department of Complex Systems Science, Graduate School of Information Science, Nagoya University, Furo-cho, Chikusa-ku, Nagoya 464-8601, Japan ‡ Honda R&D Co., Ltd., Motorcycle R&D Center, 3-15-1, Senzui, Asaka-shi, Saitama 351-0024, Japan. E-mail: Hiroki.Yoshino@mail.a.rd.honda.co.jp §Shizuoka Institute of Science and Technology, Faculty of Comprehensive Informatics, 2200-2, Toyosawa, Fukuroi-shi, Shizuoka 473-8555, Japan. E-mail: miyaoka@cs.sist.ac.jp	biological specimen;complex systems;computer cooling;experiment;finger tree;gaussian blur;iso 8601;informatics;information science;ku band;level of detail;list of information schools;outline of object recognition;robot;super smash bros.;systems science	Masahiro Ohka;Hiroki Yoshino;Tetsu Miyaoka	2011	Robotica	10.1017/S026357471000041X	computer vision;teleoperation;computer science;engineering;artificial intelligence;haptic technology;proprioception;engineering drawing;psychophysics	Robotics	-46.89667763087671	-9.019583328214305	4002
a836f8284fc29ee02e1ef5cc7f41129aae75e3bf	372: comparing the benefit of different dependency parsers for textual entailment using syntactic constraints only	different dependency parsers;syntactic constraint;stanford parser;standard evaluation metrics;linear classification technique;textual entailment;art dependency parsers;linear classifier;comparable result;instance maltparser;standard test data;evaluation exercise pete;inferior result	We compare several state of the art dependency parsers with our own parser based on a linear classification technique. Our primary goal is therefore to use syntactic information only, in order to keep the comparison of the parsers as fair as possible. We demonstrate, that despite the inferior result using the standard evaluation metrics for parsers like UAS or LAS on standard test data, our system achieves comparable results when used in an application, such as the SemEval-2 #12 evaluation exercise PETE. Our submission achieved the 4 position out of 19 participating systems. However, since it only uses a linear classifier it works 17-20 times faster than other state of the parsers, as for instance MaltParser or	linear classifier;parsing;test data;textual entailment;usb attached scsi	Alexander Volokh;Günter Neumann	2010				NLP	-22.28609763858662	-74.50332370308892	4007
2032367be7c7210be37628a4c91d233426370418	a report on the complex word identification shared task 2018		We report the findings of the second Complex Word Identification (CWI) shared task organized as part of the BEA workshop colocated with NAACL-HLT’2018. The second CWI shared task featured multilingual and multi-genre datasets divided into four tracks: English monolingual, German monolingual, Spanish monolingual, and a multilingual track with a French test set, and two tasks: binary classification and probabilistic classification. A total of 12 teams submitted their results in different task/track combinations and 11 of them wrote system description papers that are referred to in this report and appear in the BEA workshop proceedings.	artificial neural network;binary classification;colocation centre;deep learning;feature engineering;semeval;test set;word embedding	Seid Muhie Yimam;Christian Biemann;Shervin Malmasi;Gustavo Paetzold;Lucia Specia;Sanja Stajner;Anaïs Tack;Marcos Zampieri	2018			natural language processing;artificial intelligence;binary classification;probabilistic classification;computer science;german;test set	NLP	-22.2031404107989	-70.08272896799618	4008
0e3162accaf24a0a3311541b0f12318ee6bf4a4b	semantic labeling of places with mobile robots	g700 artificial intelligence;h671 robotics;g760 machine learning	Indoor environments can typically be divided into places with different function-alities like corridors, rooms or doorways. The ability to learn such semantic categories from sensor data enables a mobile robot to extend the representation of the environment, and to improve its capabilites. As an example, natural language terms like corridor or room can be used to communicate the position of the robot in a more intuitive way. Other tasks, like exploration or localization, can also be carried out by the robot in a better way when semantic information is taken into account. In this thesis, we present a method that enables a mobile robot to classify the different places of indoor environments into semantic classes, and then use this information to extend its representations of the environments. The main idea is to classify the position of the robot based on the current observations taken by the robot. In this work, we use as main observations the scans obtained from a laser range sensor. Each scan is represented by a set of features that encode the geometrical properties of the current position. These features are then used to classify the scan into the corresponding semantic class. The output of the classification is represented by a probability distribution over the set of possible semantic classes. This probabilistic representation permits us to apply further probabilistic techniques to improve the final classification, reducing the number of errors. We also present an extension which enables the robot to include other types of observations in the classification, like camera images. This work additionally introduces several applications of the previous approach in different robotic tasks. First, we will show how the semantic information can be used to extract topological maps from indoor environments. In a second application , we present a method that incorporates transitions between different places when classifying a trajectory taken by a mobile robot. It will also be shown that the semantic information can reduce the time needed by the robot in exploration and localization tasks. Finally, we present the semantic classification of places as part of an integrated robotic system designed for interacting with humans using natural language. Acknowledgments I would like to thank all the people who made this thesis possible. First of all, I would like to thank Prof. Wolfram Burgard for giving me the opportunity to work in his research group. I must admit that this was one of the …	encode;interaction;internationalization and localization;map;mobile robot;natural language	Óscar Martínez Mozos	2008		10.1007/978-3-642-11210-2	simulation;engineering;artificial intelligence;communication	Robotics	-32.93920831741434	-41.63594604329321	4009
2d7e64b1358f67325fcacf482335a76ed0d9a773	combining demographic data with collaborative filtering for automatic music recommendation	economie;economia;business information management incl records;and intelligence;musica;acoustique musicale;recommandation;intelligence artificielle;musical acoustics;ciencias economicas;musique;collaborative filtering;acustica musical;recomendacion;artificial intelligence;knowledge and information management;recommendation;sciences economiques;economy;inteligencia artificial;economics;music	It has been shown in several studies that demographics such as gender, socio-economic background and age affect one’s musical tastes. In this work we combine these factors with traditional collaborative filtering techniques in order to improve recommendation precision. We propose a simple measure for combining the data and show that it has potential for this application.	algorithm;coefficient;collaborative filtering;computer science;encode;minimal recursion semantics	Billy Yapriady;Alexandra L. Uitdenbogerd	2005		10.1007/11554028_29	computer science;artificial intelligence;data science;collaborative filtering;machine learning;musical acoustics;music;multimedia	Web+IR	-50.0743257655951	-22.561207139944646	4010
6ae64a9111e81be5ee8f51dcddced5370de45e62	rgb-d computer vision techniques for simulated prosthetic vision		Recent research on visual prosthesis demonstrates the possibility of providing visual perception to people with certain blindness. Bypassing the damaged part of the visual path, electrical stimulation provokes spot percepts known as phosphenes. Due to physiological and technological limitations the information received by patients has very low resolution and reduced dynamic range. In this context, the inclusion of new computer vision techniques to improve the semantic content in this information channel is an active and open key topic. In this paper, we present a system for Simulated Prosthetic Vision based on a head-mounted display with an RGB-D camera, and two tools, one focused on human interaction and the other oriented to navigation, exploring different proposals of phosphenic representations.	computer vision	Jesus Bermudez-Cameo;Alberto Badias-Herbera;Manuel Guerrero-Viu;Gonzalo López-Nicolás;Josechu J. Guerrero	2017		10.1007/978-3-319-58838-4_47	computer vision;artificial intelligence;rgb color model;dynamic range;phosphene;stimulation;visual prosthesis;visual perception;computer science;blindness;communication channel	Vision	-38.512963102141484	-46.99134490141614	4011
a04340de3aaaa05560d83adc28c469c0edbe2b1e	detection of bibliographic coupling communities using research output (2004-2013) from nepal		This study explores a country-level bibliometric analysis to extract bibliographic coupling (BC) communities as clusters of documents coupled through publications in their reference lists using the BiblioTool software. The 2004-2013 research output from Nepal represented by relatively small dataset of 3,011 documents (peer reviewed articles and reviews) indexed as core collections in the Web of Science (WoS) database was used. Setting a threshold of 10 documents, twenty-five BC communities, each with 12-443 documents, which provide a comprehensive picture on the research themes characterized by diverse items (keywords, subjects, journals, institutions, countries, authors, references, and title words) were discriminated. Twelve communities (i.e., 48%) deal with medical &amp; health sciences (maternal &amp; child health; tropical infectious diseases; cancer &amp; cardiovascular diseases; mountain sickness; blindness) closely linked also with social aspects; 4 communities with earth, environment and biodiversity (tectonics and natural hazards; environmental pollution, remediation and conservation; wild-life preservation); 3 communities with agriculture and veterinary sciences (pathogens of major crops (maize, wheat, rice) &amp; crop yields, plant genes, and dairy farming); 3 communities with nanomaterials and metal-alloys; 2 communities with pharmacology including ethnomedicine, and one community of 12 documents is related to galactic observations. These new results provide wider insights on the research volume &amp; diversity, international collaboration and the contributors (academic, national &amp; international, governmental &amp; non-profit agencies, etc.) engaged in research in Nepal.		Pitambar Gautam	2017	2017 6th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)	10.1109/IIAI-AAI.2017.72	library science;ethnomedicine;agriculture;environmental pollution;higher education;bibliometrics;bibliographic coupling;developing country;dairy farming	ML	-76.6559350347469	-20.80973496415426	4014
6e7f9664dcb7b07dd582c41d334c10b11ea6bd68	unique n-phone ranking based spoken language identification	n phone ranking based spoken language identification prlm phone recognition followed by language modelling baseline system single language phone recogniser discriminative training phone sequences phonotactic lid phonetic based language identification;ranking;speech recognition;phonotactic language identification;ranking phonotactic language identification;speech accuracy speech recognition training pragmatics educational institutions target recognition	This paper presents a novel approach to phonetic-based language identification (LID). Motivated by the assumption underlying phonotactic LID that accounting for permissible phone sequences supports the process of distinguishing one language from another, this paper presents a novel approach based on the automatic identification of phone sequences of different lengths unique to a language, which are subsequently employed to determine which language has been spoken. The approach implements a discriminative training that involves a ranking procedure on unique phone sequences generated by a single-language phone recogniser. As a baseline system, phone recognition followed by language modelling (PRLM) is used to compare the performance of the proposed approach. Having 21 languages in the target set, the experiments show that the proposed approach achieves better accuracies. Moreover, it requires a 5.5 times shorter processing time than the baseline system.	automatic identification and data capture;baseline (configuration management);discriminative model;experiment;language identification;language model	Amalia Zahra;Julie Carson-Berndsen	2013	2013 Fifth International Conference on Computational Intelligence, Communication Systems and Networks	10.1109/CICSYN.2013.34	natural language processing;language identification;cache language model;speech recognition;ranking;computer science	NLP	-19.488046925414523	-86.1888098229403	4017
bb6e62f2c5eb06ffb89acc3855f3041588e47184	a survey on the importance of learning object metadata for relevance judgment	article δημοσίeυση πeριοδικού	The purpose of this study was to investigate university students' per- ceptions about the usefulness - importance of learning object metadata elements of the UK LOM Core application profile when judging the relevance of learn- ing objects. In order to address this objective an online questionnaire survey was conducted among university students using a clustered sampling technique. A total of 252 students respondent to the questionnaire. Participants represented different disciplines (for example, from Humanities & Social Sciences to Sci- ences & Engineering), levels of familiarization with the web and educational level (postgraduates and undergraduates). The results showed that participants preferred content related and educational metadata elements as well as metadata elements about the date and the language of a learning object as opposed to technical metadata elements or metadata elements about the version of the learning object. The conclusions show that these findings can have implications in the design and use of learning object metadata schemas for students in the UK Higher Education.	learning object metadata;relevance	Panos Balatsoukas;Emmanouel Garoufallou;Stella Asderi;Rania Siatri	2011		10.1007/978-3-642-24731-6_31	computer science;knowledge management;artificial intelligence;database;multimedia;world wide web	ML	-77.5506888047253	-41.66308534313027	4020
08e317c8b6889c412bb6c366f41c3685347641a1	effectiveness of the rapael smart board for upper limb therapy in stroke survivors: a pilot controlled trial		We aim to assess the effectiveness of using the RAPAEL Smart Board as an assistive tool for therapists in clinical rehabilitation therapy settings and to investigate if it can be used to improve the motor recovery rate of stroke survivors. The RAPAEL Smart Board is a therapy tool where therapists actively engage patients, giving necessary verbal and physical interventions as in traditional treatment sessions. We conducted a randomized controlled study with 17 stroke survivors. An experimental group received therapy using the RAPAEL Smart Board for 30 minutes a day, 5 days per week, for 4 weeks in addition to their traditional treatments (i.e., 30 minutes of functional arm movement therapy). A control group received two 30-minute sessions of traditional treatment 5 days per week, for 4 weeks. The upper-extremity function was measured using the Wolf Motor Function Test before and after the 4-week interventions. Our results demonstrate that using the RAPAEL Smart Board, in combination with traditional treatment, significantly improves motor recovery when compared to traditional treatments alone.	cerebrovascular accident;experiment;large;limb structure;muscular dystrophies, limb-girdle;patients;randomized algorithm;smart board;stroke rehabilitation;survivors;therapeutic procedure;video games;sensor (device)	Joonwoo Park;Hee-Tae Jung;Jean-François Daneault;Sungji Park;Taekyeong Ryu;Yangsoo Kim;Sunghoon Ivan Lee	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8512813	computer vision;rehabilitation;randomized controlled trial;stroke;physical therapy;artificial intelligence;computer science;psychological intervention	Visualization	-56.0939976996326	-55.12638754022992	4027
c39e51c3a474c3ac350229a9b1585a1ddd283d1e	service system modeling of field offices within a government agency	service system;technical report	An extensive simulation modeling study effort has been undertaken by the Social Security Administration (SSA) in order to develop a tool which assists in making resource allocation decisions. This modeling study will examine and determine the effect of staffing size and staffing mixes on the level of service provided to clientele served through SSA field offices. These widely distributed field offices are initial point of contact facilities, often receiving large volumes of walkin and telephone business on a daily basis. Modeling of individual field offices provides SSA with a tool to study various methods of operation. The simulation modeling study effort undertaken to provide the required degree of insight into the field office system dynamics encompasses a widely dispersed range of individual characteristics particular to each office location throughout the United States. These characteristics coincide primarily with the differences in population demographics between office locations. ProModel, and ServiceModel software, developed by ProModel Corporation, have been applied in the study effort. The logical constructs and graphical animation features inherent within the software environments have been elemental in creating robust system models, as well as in quickly securing valid model results.	elemental;graphical user interface;simulation;social security;system dynamics	Julian A. Swedish	1992		10.1145/167293.167893	computer science;technical report;service delivery framework;service design;service system	HCI	-36.27984784576694	-10.79200521991291	4033
1f9593e1b25f6c162a7a3c430055786e75e5d084	experiments with the eurospider retrieval system for clef 2000	linguistique;estudio translinguistica;information retrieval;machine readable dictionary;language translation;traduction connaissance;systeme recuperation;etude translinguistique;dictionnaire;linguistica;recherche information;clef 2001;dictionaries;recuperacion informacion;query translation;cross linguistic study;multilinguisme;eurospider retrieval system;diccionario;multilingualism;machine translation;multilinguismo;linguistics;retrieval systems	Eurospider participated in both the multilingual and monolingual retrieval tasks for CLEF 2001. Our multilingual experiments, the main focus of this year’s work, combine multiple approaches to cross-language retrieval: machine translation, similarity thesauri, and machine-readable dictionaries. We experimented with both query translation and document translation. The monolingual experiments focused on the use of two fundamentally different stemming components: one commercially and one linguistically motivated stemmer.	dictionary;experiment;general-purpose modeling;human-readable medium;information architecture institute;machine translation;stemming;thesaurus	Martin Braschler;Peter Schäuble	2000		10.1007/3-540-45691-0_8	natural language processing;speech recognition;computer science;linguistics;machine translation;translation	NLP	-35.42545081752363	-63.28004849505643	4036
88b53106f90c53420f8e846f92eaad521a3c2cff	uncertain density balance triggers scale-free evolution in game of life		Since Conway proposed the Game of Life, it has attracted researchers’ attention due to complex “life” evolutions despite simple rules. It is known that the Game of Life exhibits self-organized criticality, which might be related to scale-free evolutions. Despite the interesting phenomenon of self-organized criticality, the Game of Life turns to steady states within several generations. Here, we demonstrate a new version of the Game of Life in which cells tried to stay “alive” even though neighboring sites were overor underpopulated. These rule changings enabled the system to show scale-free evolutions for many generations.	conway's game of life;self-organization;self-organized criticality	Tomoko Sakiyama;Yukio-Pegio Gunji	2017	Complex Systems		mathematics;simulation;machine learning;artificial intelligence	ECom	-15.454347047387312	-17.41871701715902	4038
ce39bd45f2756c772033eb7570af58d0c98b2f3f	social informatics in information science: an introduction		Social informatics (SI) refers to a multidisciplinary research field that examines the design, uses, and implications of information and communication technologies (ICTs) in ways that account for their interactions with institutional and cultural contexts. This Special Issue presents seven articles that illustrate the range and depth of research in SI. This essay outlines the concerns of SI researchers and briefly describes the articles that follow. © 1998 John Wiley u0026 Sons, Inc.	information science;social informatics	Rob Kling;Howard Rosenbaum;Carol A. Hert	1998	JASIS	10.1002/(SICI)1097-4571(1998)49:12%3C1047::AID-ASI1%3E3.0.CO;2-V	health administration informatics;business informatics;library science;social science;engineering informatics;computer science;media studies;sociology;informatics;materials informatics;management	NLP	-73.78592405642529	-18.285353766297685	4040
d2544835ae2a5626bffb71bfd6fa0b7f29811a90	higher education sub-cultures and open source adoption	chief information officer;comparative analysis;interactive learning environments;distance education and telelearning;total cost of ownership;postsecondary education;higher education;deans;teaching and learning;open source technology;adoption ideas;distributed learning environments;distributed learning environment;evaluation of cal systems;computer software;educational technology;interactive learning environment;administrators;open source software;surveys;open source	Successful adoption of new teaching and learning technologies in higher education requires the consensus of two sub-cultures, namely the technologist sub-culture and the academic sub-culture. This paper examines trends in adoption of open source software (OSS) for teaching and learning by comparing the results of a 2009 survey of 285 Chief Academic Officers and Chief Information Officers with the 2006 administration of the same survey. Results indicate that while the key drivers of OSS adoption continue to differ for the academic and technologist sub-cultures, both sub-cultures converge in deeming total cost of ownership as the most important metric for making a go/no go adoption decision. 2011 Elsevier Ltd. All rights reserved.	baseline (configuration management);cardiovascular technologist;chief information officer;converge;emoticon;heterogeneous element processor;incidence matrix;logistic regression;open sound system;open-source software;oversampling;snapshot (computer storage);total cost of ownership	Shahron Williams van Rooij	2011	Computers & Education	10.1016/j.compedu.2011.01.006	psychology;qualitative comparative analysis;educational technology;social science;knowledge management;multimedia;sociology;higher education;world wide web;pedagogy	AI	-73.9866669277986	-34.22161671489891	4049
a8f761b3091f5bea56fd5e1d3fc516168c578b43	high-level concept detection based on mid-level semantic information and contextual adaptation	retrieval algorithm;educational standards;learning resource;information retrieval;e commerce;computer aided instruction;e learning system;recommendation system;recommender system;unsupervised learning feature extraction fuzzy set theory image representation multimedia computing ontologies artificial intelligence pattern clustering;meta data;personalised e learning resources;fuzzy sets unsupervised learning information analysis feature extraction thesauri clustering methods neural networks detectors algebra ontologies;rdf based e learning framework;region thesaurus high level concept detection mid level semantic information contextual adaptation unsupervised learning semantic multimedia analysis feature extraction hierarchical clustering method neural network based detector fuzzy algebra fuzzy set theory fuzzy relation ontology image representation;reputation metadata	In this paper we propose the use of enhanced mid-level information, such as information obtained from the application of supervised or unsupervised learning methodologies on low-level characteristics, in order to improve semantic multimedia analysis. High-level, a priori contextual knowledge about the semantic meaning of objects and their low-level visual descriptions are combined in an integrated approach that handles in a uniform way the gap between semantics and low-level features. Prior work on low-level feature extraction is extended and a region thesaurus containing all mid-level features is constructed using a hierarchical clustering method. A model vector that contains the distances from each mid-level element is formed and a neural network-based detector is trained for each semantic concept. Contextual adaptation improves the quality of the produced results, by utilizing fuzzy algebra, fuzzy sets and relations. The novelty of the presented work is the context- driven mid-level manipulation of region types, utilizing a domain-independent ontology infrastructure to handle the knowledge. Early experimental results are presented using data derived from the beach domain.	artificial neural network;cluster analysis;feature extraction;fuzzy set;hierarchical clustering;high- and low-level;image processing;sentient computing;shape analysis (digital geometry);supervised learning;thesaurus;unsupervised learning	Phivos Mylonas;Evaggelos Spyrou;Yannis S. Avrithis	2007	Second International Workshop on Semantic Media Adaptation and Personalization (SMAP 2007)	10.1109/SMAP.2007.38	computer science;machine learning;data mining;information retrieval	AI	-15.143235074416655	-57.9966448933382	4055
ba07ba41dee79304a187493b770f905fcfebcd1d	towards modeling user behavior in interactions mediated through an automated bidirectional speech translation system	relation medecin malade;mediated communication;spoken dialog system;spoken dialog systems;interaction;user modeling;traduction orale;traduction assistee par ordinateur;bayesian reasoning;agent;speech translation;feedback;anglais;retroaction;reconnaissance de la parole;machine mediated communication;cross lingual interactions;speech recognition;persian;english;computational linguistics;speech to speech translation;user behavior;methode bayesienne;persan;computer aided translation;linguistique informatique;oral translation;doctor patient relation;user model;objective and subjective measures	This paper addresses modeling user behavior in interactions between two people who do not share a common spoken language and communicate with the aid of an automated bidirectional speech translation system. These interaction settings are complex. The translation machine attempts to bridge the language gap by mediating the verbal communication, noting however that the technology may not be always perfect. In a step toward understanding user behavior in this mediated communication scenario, usability data from doctor–patient dialogs involving a two way English–Persian speech translation system are analyzed. We specifically consider user behavior in light of potential uncertainty in the communication between the interlocutors. We analyze the Retry (Repeat and Rephrase) versus Accept behaviors in the mediated verbal channel and as a result identify three user types – Accommodating, Normal and Picky, and propose a dynamic Bayesian network model of user behavior. To validate the model, we performed offline and online experiments. The experimental results using offline data show that correct user type is clearly identified as a user keeps his/her consistent behavior in a given interaction condition. In the online experiment, agent feedback was presented to users according to the user types. We show high user satisfaction and interaction efficiency in the analysis of user interview, video data, questionnaire and log data. 2009 Elsevier Ltd. All rights reserved.	dynamic bayesian network;experiment;interaction;machine translation;network model;online and offline;retry;usability	JongHo Shin;Panayiotis G. Georgiou;Shrikanth (Shri) Narayanan	2010	Computer Speech & Language	10.1016/j.csl.2009.04.008	natural language processing;user;user modeling;speech recognition;computer user satisfaction;computer science;computational linguistics;machine learning;linguistics;statistics	AI	-53.343581758085065	-47.47142240988997	4059
ec6def73c8d115661d0666703ed45241c7a1d413	a statistical dialog manager for the luna project		In this paper, we present an approach for the development of a statistical dialog manager, in which the system response is selected by means of a classification process which considers all the previous history of the dialog to select the next system response. In particular, we use decision trees for its implementation. The statistical model is automatically learned from training data which are labeled in terms of different SLU features. This methodology has been applied to develop a dialog manager within the framework of the European LUNA project, whose main goal is the creation of a robust natural spoken language understanding system. We present an evaluation of this approach for both human machine and human-human conversations acquired in this project. We demonstrate that a statistical dialog manager developed with the proposed technique and learned from a corpus of human-machine dialogs can successfully infer the task-related topics present in spontaneous humanhuman dialogs.	decision tree;dialog manager;luna;natural language understanding;spontaneous order;statistical model	David Griol;Giuseppe Riccardi;Emilio Sanchis Arnal	2009			speech recognition;natural language processing;decision tree;human–machine system;statistical model;dialog box;computer science;artificial intelligence;training set;spoken language;knowledge management	NLP	-27.19376257307904	-85.82290039002605	4063
42cfe3e49800432503c8611217b86726507b4b04	normative shaping of scientific practice: the magic of merton	scientometrics;sociologie de la science;comportement;etude theorique;citation;conducta;scientometria;scientometrie;estudio teorico;sociology of science;citacion;theoretical study;behavior	Overview of the functionalist vs interpretivist positions on citation behavior. Excerpts of the correspondance between the author and MERTON (theories of citing, counternorms...)	noise shaping	Blaise Cronin	2004	Scientometrics	10.1023/B:SCIE.0000027306.30138.49	scientometrics;computer science;sociology;world wide web;behavior	HPC	-74.58176988893943	-22.91848482894175	4068
8de5f4ee48e1d809a8c6b835242f17de113a9b62	piracy of digital products: a critical review of the theoretical literature	software;ip protection;piracy;l86;music;copyright;l82;information good;peer-to-peer;internet;l11;asymmetric information;file sharing;network effect	Digital products can be copied at almost no cost and are subject to non-commercial copying by final consumers. Because the copy of a copy typically does not deteriorate in quality, copies can become available on a large scale basis – this can be illustrated by the surge of file-sharing networks. In this paper we provide a critical overview of the theoretical literature that addresses the economic consequences of end-user copying. We analyze basic models of piracy, models with indirect appropriation, models with network effects, and models with asymmetric information. We discuss the applicability of the different modeling strategies to a number of industries such as software, video and computer games, music, and movies.		Martin Peitz;Patrick Waelbroeck	2006	Information Economics and Policy	10.1016/j.infoecopol.2006.06.005	economics;telecommunications;computer science;marketing;network effect;music;multimedia;advertising;internet privacy;information good;law;file sharing	HCI	-83.52548613276795	-12.61399360732396	4077
53e6027a8e3b67183626cc0923471eaf04ae7916	supply chain-related adverse events and patient safety in healthcare	inventory management policies;adverse events;patient safety;healthcare supply chain;recall and outdate management	This research investigates adverse events and patient safety in healthcare due to poor supply chain management practices, and inadequate and disorganized product validation procedures. Focusing on commodity medical and surgical products, this research investigates correct product validation points for maximum patient safety. This study also explores benefits of standard product identifying technologies such as HIBC or GS1 data standards as well as automated validation systems such as barcode or Auto ID to minimize workflow interruptions. Site visits and phone interviews are conducted with six healthcare providers to document common product validation practices and procedures. Based on observations and collected data, a simulation model is developed. Different scenarios are compared for patient safety, care delay, and system efficiency. The results show that validation points during PAR picking or bedside product administration, and warehouse picking operations provide optimal overall system performance. The results also indicate that standard product identifying technologies and automated validation systems significantly impact the efficiency of supply chain. Supply Chain-Related Adverse Events and Patient Safety in Healthcare	barcode;chaos theory;new product development;simulation	Nebil Buyurgan;Paiman Farrokhvar	2015	IJHISI	10.4018/IJHISI.2015040102	adverse effect	HCI	-59.724995500369545	-65.09294272196236	4078
0fea905226ed725d997f5e606e1be481990a4f6c	test technology tc newsletter				Theocharis Theocharides	1995	IEEE Design & Test of Computers	10.1109/MDAT.2015.2506858		EDA	-61.63342279296545	-10.58792818500305	4079
e8a976ac35aec11a8aae9a665f0e69a11a374245	speech separation algorithms for multiple speaker environments	microphones speech source separation prototypes array signal processing microwave integrated circuits speech recognition;microphones;microwave integrated circuits;speaker identification;multiple speakers;high performance speaker identification;prototypes;speaker recognition source separation;speech;array signal processing;speaker recognition;multiple speaker environments;speech recognition algorithms;speech recognition;speech separation algorithms;source separation;high performance;high performance speaker identification speech separation algorithms multiple speaker environments speech recognition algorithms multiple speakers	Conventional speaker identification and speech recognition algorithms do not perform well if there are multiple speakers in the background. For high performance speaker identification and speech recognition applications in multiple speaker environments, a speech separation stage is essential. Here we summarize the implementation of three speech separation techniques. Advantages and disadvantages of each method are highlighted, as no single method can work under all situations. Stand-alone software prototypes for these methods have been developed and evaluated.	algorithm;software prototyping;speaker recognition;speech recognition	Chiman Kwan;Jiateng Yin;Bulent Ayhan;S. Chu;Xin Liu;K. Puckett;Yunsong Zhao;K. C. Ho;Martin Kruger;Irma Sityar	2008	2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)	10.1109/IJCNN.2008.4634018	voice activity detection;speaker recognition;speaker diarisation;speech recognition;computer science;speech;prototype	Visualization	-13.536161667764983	-90.28436393709437	4082
9fbb61b1100f46ea38ee7ec01b43d8828c887762	improving the sustainability of soa providers' networks via a collaborative process innovation model				João F. Santanna-Filho;Ricardo J. Rabelo;Peter Bernus;Alexandra A. Pereira Klen	2016		10.1007/978-3-319-51133-7_61	systems engineering;knowledge management;process management;business	HCI	-68.98781161213837	2.2301889659200462	4083
afe106f7aa46546dad38e9e5f520956e63f89d95	on the pathway to success: becoming a leading earth observation centre through the excelsior project		This paper presents the pathway towards the establishment of the ERATOSTHENES Centre of Excellence (ECoE), through the upgrade of the existing Remote Sensing u0026 Geo-Environment Group - ERATOSTHENES Research Centre (ERC), within the Cyprus University of Technology (CUT). The ECoE aspires to become a sustainable, viable and autonomous Centre of Excellence for Earth Surveillance and Space-Based Monitoring of the Environment. The ECoE will provide the highest quality of related services in the National, European, Eastern Mediterranean and Middle East and Northern Africa areas (EMMENA). Therefore, drawing on the capitalization of experience and knowledge from previous projects and the research areas and international networks of the ERC, this papers highlights the importance of the establishment of the ECoE in the EMMENA area.	gene regulatory network	Diofantos G. Hadjimitsis;Georgia Kouta;Kyriacos Themistocleous;Silas C. Michaelides;Kyriakos Neocleous;Rodanthi-Elisabeth Mamouri;Argyro Nisantzi;Christiana Papoutsa;Marios Tzouvaras;Christodoulos Mettas;Andreas Christofe;Evagoras Evagorou;Gunter Schreier;Egbert Schwarz;Haris Kontoes	2018		10.1007/978-3-030-01762-0_57	environmental resource management;environmental monitoring;geography;capitalization;middle east;earth observation;excellence;cultural heritage	Logic	-63.87506239219862	-5.959428099469822	4097
bf68d27145d4a055a12415c4ed61395116a33f33	a form-correcting system of chinese characters using a model of correcting procedures of calligraphists	generic model;support system;knowledge acquisition	A support system for form-correction of Chinese characters is developed based upon a generation model SAM, and its feasibility is evaluated. SAM is excellent as a model for generating Chinese characters, but it is difficult to determine appropriate parameters because the use of calligraphic knowledge is needed. By noticing that calligraphic knowledge of calligraphists is included in their corrective actions, we adopt a strategy to acquire calligraphic knowledge by monitoring, recording and analyzing corrective actions of calligraphists, and try to realize an, environment under which calligraphists can easily make corrections to character forms and which can record corrective actions of calligraphists without interfering with them. In this paper, we first construct a model of correcting procedures of calligraphists, which is composed of typical correcting procedures that are acquired by extensively observing their corrective actions and interviewing them, and develop a form-correcting system for brush-written Chinese characters by using the model. Secondly, through actual correcting experiments, we demonstrate that parameters within SAM can be easily corrected at the level of character patterns by our system, and show that it is effective and easy for calligraphists to be used by evaluating effectiveness of the correcting model sufficiency of its functions and execution speed.	experiment;sam	Jianchao Zeng;Hidehiko Sanada;Yoshikazu Tezuka;Guangyou Xu	1995	Journal of Computer Science and Technology	10.1007/BF02939519	simulation;artificial intelligence;algorithm	AI	-26.802973693026473	-88.00747151437662	4102
167ac1ad717925b7f23785aff4ab16bce4db32f4	decision support in healthcare supply chain management and pharmaceutical inventory control	management practice;pharmaceuticals;decision support;decision support tool;healthcare decision support;quantitative method;inventory control;supply chain management	This exploratory research examines the pharmaceutical inventory control practices of a local area hospital and demonstrates the utility of two alternative quantitative approaches. Pharmaceuticals represent a large cost factor for most hospitals due to the significant costs of these products and the storage and control requirements. The hospital stores drugs in the Central Pharmacy and at various Care Units (CUs) throughout the hospital and employs advanced technology to manage inventory and automate the ordering processes at these local storage units. This research examines current hospital policies, employs quantitative methods to improve upon these practices, and provides a decision support tool that allows managers to quickly understand operational, tactical, and strategic implications of changes in the formulary (pharmaceutical product mix available in hospital). This decision support tool affords managers the opportunity to improve management practices and the capacity to support negotiations with stakeholders on issues related to the formulary.	clinical decision support system;decision support system;formulary (model document);group policy;inventory control;requirement;thread-local storage	John M. Woosley;Sonja Wiley-Patton	2009			decision support system;systems engineering;knowledge management;operations management;business	HCI	-71.7191893958135	1.3924900859641658	4105
d9a547ac06fb0de91e45631083bc05891831e3c3	increasing bicycle usage in smart cities	urban planning;smart cities;mobile sensing;behavior change;tracking	The emergence and market uptake of technologies for mobile and ubiquitous computing is opening a window of opportunities for innovative applications that promote cycling and walking in new forms. These technologies allow affordable and accessible ways of tracking the walking and cycling of individuals which, when combined with new community-centric applications, promise to unleash the behavior-change potential to unprecedented levels.  A particular synergy is between local businesses, who are interested in segmenting their customer base to attract new clients who arrive by bicycle or on foot; and potential customers, interested in obtaining discounts. Likewise, cities and governments are interested in attributing benefits to people choosing to cycle or walk. However, achieving so requires applications that are able to trace individual mobility choices, at the same time respecting both technical and social requirements.  This paper sheds some new light on the delicate balance between the the social and technical requirements that determine the actual outcome of behavior change towards more sustainable mobility in smart cities. We focus on a particular application, called Cycle-to-Shop, which is under development in the context of the TRACE H2020 project.	emergence;individual mobility;requirement;smart city;synergy;ubiquitous computing	Joño Barreto;Miguel B. Costa;Rodrigo Lourenço;Paulo José Azevedo Vianna Ferreira;Joño Bernardino;Bossuyt Evelien;Jan Christiaens;Deham Nick;Franchois Elke;Vleugels Ilse	2016		10.1145/3009912.3009913	simulation;engineering;operations management;advertising	HCI	-35.61233456205099	-18.542583656038033	4106
9f7e975cac3b4fb61a216c894c8fecfd48f4b0a5	how good is my map? a tool for semi-automated thematic mapping and spatially explicit confidence assessment		Abstract Thematic maps are important for a range of disciplines including spatial planning and ecosystem status assessments. Despite an increasing focus on accuracy assessment methods to ensure maps are fit for purpose, the adoption of these recommendations has not been widespread. We present a methodology which utilises bootstrap aggregation and adheres to recommended practices for accuracy assessments. Furthermore, additional information is extracted from the model outputs to produce spatial maps of confidence also supporting map interpretation. The methodology has been applied to two study sites using both pixel-based and object-based units of analyses. Accuracy assessments for both study sites identified the classes that were responsible for most of the map error. In addition, spatially explicit confidence maps supported our understanding of the sources of error. This paper provides a useful methodology to improve accuracy assessment and reporting and is well suited to studies where groundtruth data are limited.	object-relational mapping;semiconductor industry	Peter J. Mitchell;Anna-Leena Downie;Markus Diesing	2018	Environmental Modelling and Software	10.1016/j.envsoft.2018.07.014	spatial planning;management science;bootstrap aggregating;thematic map;computer science	SE	-22.420984247880533	-32.083844677045136	4111
27a55ec8d5642734cf2156d552a6f6c7ad2633a0	finding more relevance: propagating similarity on markov random field for image retrieval	bag of visual words;image retrieval	To effectively retrieve objects from large corpus with high accuracy is a challenge task. In this paper, we propose a method that propagates visual feature level similarities on a Markov random field (MRF) to obtain a high level correspondence in image space for image pairs. The proposed correspondence between image pair reflects not only the similarity of low-level visual features but also the relations built through other images in the database and it can be easily integrated into the existing bag-of-visual-words(BoW) based systems to reduce the missing rate. We evaluate our method on the standard Oxford5K, Oxford-105K and Paris-6K dataset. The experiment results show that the proposed method significantly improves the retrieval accuracy on three datasets and exceeds the current state-of-the-art retrieval performance.	bag-of-words model in computer vision;feature vector;high- and low-level;high-level programming language;image retrieval;markov chain;markov random field;relevance;text corpus	Peng Lu;Xujun Peng;Xinshan Zhu;Xiaojie Wang	2013	CoRR			Vision	-15.491354515414473	-59.99759108139169	4115
b4aafbcc57fe29e62fefc58541a95cb77fddcbbc	a quantitative insight into the impact of translation on readability		In this paper we investigate the impact of translation on readability. We propose a quantitative analysis of several shallow, lexical and morpho-syntactic features that have been traditionally used for assessing readability and have proven relevant for this task. We conduct our experiments on a parallel corpus of transcribed parliamentary sessions and we investigate readability metrics for the original segments of text, written in the language of the speaker, and their translations.	experiment;parallel text	Alina Maria Ciobanu;Liviu P. Dinu	2014		10.3115/v1/W14-1212	natural language processing;speech recognition;computer science;multimedia	NLP	-27.647064430605454	-75.33977176099499	4117
c2a7afbb5609a723f8eea91bfde4b02579b048d6	unsupervised neural machine translation		In spite of the recent success of neural machine translation (NMT) in standard benchmarks, the lack of large parallel corpora poses a major practical problem for many language pairs. There have been several proposals to alleviate this issue with, for instance, triangulation and semi-supervised learning techniques, but they still require a strong cross-lingual signal. In this work, we completely remove the need of parallel data and propose a novel method to train an NMT system in a completely unsupervised manner, relying on nothing but monolingual corpora. Our model builds upon the recent work on unsupervised embedding mappings, and consists of a slightly modified attentional encoder-decoder model that can be trained on monolingual corpora alone using a combination of denoising and backtranslation. Despite the simplicity of the approach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014 French → English and German → English translation. The model can also profit from small parallel corpora, and attains 21.81 and 15.24 points when combined with 100,000 parallel sentences, respectively. Our implementation is released as an open source project1.	bleu;baseline (configuration management);encoder;experiment;neural machine translation;noise reduction;open-source software;parallel text;semi-supervised learning;semiconductor industry;supervised learning;text corpus;triangulation (geometry);unsupervised learning	Mikel Artetxe;Gorka Labaka;Eneko Agirre;Kyunghyun Cho	2017	CoRR		artificial intelligence;pattern recognition;machine learning;natural language processing;machine translation;bleu;unsupervised learning;computer science;triangulation (social science);spite;embedding	NLP	-19.80244163049103	-74.52131407968801	4119
4b0c71b58863610284d44f3be242207cbd564ceb	introduction: human-computer interaction studies in information systems	human information processing;human computer interaction;human factors;information system	The guest editors are grateful to the DATA BASE editors-in-chief, Thomas Stafford and Patrick Y.K. Chau, for this opportunity and their strong support of this AIS SIGHCI-sponsored special issue on HCI studies in IS. The guest editors also thank the following reviewers who have played an important role in the development of the manuscripts included in this special issue: Alanah Davis, Haiyan Fan, Andrew Hardin, Jakob Iversen, Xin Li, Sherrie Komiak, Eleanor Loiacono, Tomasz Miaskiewicz, John Murphy, Lorne Olfman, Veena Parboteeah, Robin Poston, Shu Schiller, Nikhil Srinivasan, Heshan Sun, Nan Sun, Peter Tarasewich, Jason Thatcher, Chelley Vician, Dezhi Wu, and Jie Yang. Background	european ais database;human–computer interaction;information system;ising model;jason;nan;thatcher effect;yang	Matt Germonprez;Traci J. Hess;Charles J. Kacmar;Younghwa Lee	2008	DATA BASE	10.1145/1453794.1453798	human–computer interaction;computer science;human factors and ergonomics;information system	HCI	-59.411976228453106	-14.49513812462768	4135
5c2bd00fee10faedbed3c9d46b49914534825c17	scanpath clustering and aggregation	bottom up;dotplot;usability evaluation;top down;linear regression;pattern analysis;sequence analysis;eye tracking;sequential clustering;string analysis	Eye tracking specialists often need to understand and represent aggregate scanning strategies, but methods to identify similar scanpaths and aggregate multiple scanpaths have been elusive. A new method is proposed here to identify scanning strategies by aggregating groups of matching scanpaths automatically. A dataset of scanpaths is first converted to sequences of viewed area names, which are then represented in a dotplot. Matching sequences in the dotplot are found with linear regressions, and then used to cluster the scanpaths hierarchically. Aggregate scanning strategies are generated for each cluster and presented in an interactive dendrogram. While the clustering and aggregation method works in a bottom-up fashion, based on pair-wise matches, a top-down extension is also described, in which a scanning strategy is first input by cursor gesture, then matched against the dataset. The ability to discover both bottom-up and top-down strategy matches provides a powerful tool for scanpath analysis, and for understanding group scanning strategies.	aggregate data;aggregate function;bottom-up proteomics;cluster analysis;cursor (databases);dendrogram;dot plot (bioinformatics);eye tracking;top-down and bottom-up design;viewport	Joseph H. Goldberg;Jonathan Helfman	2010		10.1145/1743666.1743721	computer science;machine learning;data mining;world wide web	ML	-28.730877635411325	-33.96223111741766	4141
d8e554315d884dacb12133c863ea2e24342e217a	broadband adoption in pakistan	pakistan;e government;internet;broadband adoption;electronic government;consumer behaviour;institutional repository research archive oaister;survey;developing countries	The aim of this study is to provide a context for understanding the factors affecting the adoption of broadband internet in a developing country context, in this instance, Pakistan. In order to achieve the stated aim, this study identified and examined various attitudinal, normative and control factors to provide insights into broadband adoption. The data on these variables was collected using a survey approach. A self-administered questionnaire was sent between October and December 2006 to 275 consumers, with a total of 237 responses obtained from the respondents. The findings of this paper suggest that primary influence, facilitating conditions resources, cost and perceived ease of use are significant factors for explaining behavioural intentions to adopt broadband in Pakistan. The paper also outlines the theoretical contributions, implications for practice and limitations of this research.	instant messaging;internet access;internet protocol suite;randomness;sampling (signal processing);snapshot (computer storage);usability	Khalil Khoumbati;Yogesh Kumar Dwivedi;Banita Lal;Hsin Chen	2007	EG	10.1504/EG.2007.015038	public relations;the internet;e-government;developing country;computer science;marketing;law;world wide web;consumer behaviour;commerce	HCI	-89.04922056688672	-9.824769137980423	4142
e86469ae118af73b7c19ac46c98f2b20f0b79b32	reducing software requirement perception gaps through coordination mechanisms	information systems development;project management;vertical coordination;coordination mechanisms;project manager;consonance;user perception;project partnering;software requirements;requirements uncertainty;user perception gaps;horizontal coordination;information system;information system development	Users and information system professionals view the world differently. This perception difference leads to an inability to fully define the information requirements of a new system. Practitioners understand this difficulty and look for solid approaches to address the problem. A model is developed that links coordination mechanisms and project partnering practices to perception gaps and project success. The premise is to use the model to confirm the expected relationships and examine coordination practices in particular for effectiveness in promoting common understanding. Survey results from information system project professionals indicate that the managerial interventions of coordination and partnering are successful in reducing the perception gaps and improving project performance. Prior research had not established a link. The results support the principle that organizations must install specific coordination techniques and implement partnering procedures prior to the commencement of project activities.	requirement	Houn-Gee Chen;James J. Jiang;Gary Klein;Jengchung V. Chen	2009	Journal of Systems and Software	10.1016/j.jss.2008.09.032	project management;systems engineering;engineering;knowledge management;management science;management;software requirements;information system	SE	-84.22554494477886	1.0358783031728163	4145
22833cd21b25477f2b0a11d84c09564a1d7c3e77	modeling the task - leveraging knowledge-in-the-head at design time		A key problem in Human Computer Interaction is the evaluation and comparison of tasks that are designed in different interaction styles. A closely related problem is how to create a model of the task that allows this comparison. This paper tries to tackle these two questions. It initially presents a structure (Specific User Knowledge Representation) that allows the creation of task models which allow direct comparisons between different interaction styles. The model allows the researcher or the designer to evaluate an interaction design very early in the design process.	experiment;human computer;human–computer interaction;interaction design;knowledge representation and reasoning	Georgios Christou;Robert J. K. Jacob;Pericles Leng Cheng	2006			machine learning;knowledge management;knowledge representation and reasoning;engineering design process;interaction styles;computer science;interaction design;artificial intelligence	HCI	-52.84998556929909	-36.97251837406181	4146
8e0adda8ade9fea3ff7c35117de85433a1a2298a	effects of using learners' produced screencast as worked examples in learning		In this study, we compared the effect of learning by worked example and the cognitive load imposed by learner creating or using screencast in three conditions; studying worked examples (USER), example-problem pairs (PRUS) and problem solving (PRODUCE) in learning calculus problems. Our results showed a significant difference in transferring test performance and effectiveness between PRUS and USER conditions for the difficult questions while there was no significant difference for moderate and easy questions, in the three learning conditions. Moreover, our findings also showed no significant difference in cognitive load imposed between the three learning conditions with different levels of difficulty either during learning phase or testing phase. In conclusion, combination of studying worked examples with problem solving is more superior than studying worked examples alone when learning difficult concepts through screencast.	problem solving;screencast	I. Yang;B. T. Lau	2017	ICST Trans. e-Education e-Learning	10.4108/eai.29-11-2017.153390	multimedia;knowledge management;computer science	AI	-73.38039691642469	-45.95996320226385	4147
a6e1993a353b408620f786066b63a7ccbaa290ae	modeling of biological immune system mapped on situation awareness model	antibody;situation awareness	Situation Awareness (SA) is a fundamental characteristic for a system. For understanding the effective parameters in SA, by describing the Biological Immune System, a model for behavior of antibody are proposed. Furthermore, four levels of Endsley Model of SA (EMSA) will be described and SA process in the proposed model will compared and mapped on EMSA. For simulating the proposed model a notation for agents are introduced and some parameters of two main categories in SA are presented. By running the simulation in different cases, the effect of memory, learning ability and communication in SA of each agent will be illustrated and compared. The results emphasize on importance of learning and communication in SA and robustness of a system. By recognizing the important parameters of SA, designing and implementation of self-aware system would be possible. © 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of [name organizer] Keywors: Antibody; Biological Immune System; Endsley Model of Situation Awareness; Situation Awareness	antibody microarray;electronic organizer;list comprehension;netlogo;self-awareness;simulation	Touraj Banirostam;Hossein Parvar	2013		10.1016/j.procs.2013.06.153	simulation;artificial intelligence	AI	-21.036387627247166	-17.850328102363402	4148
32911d47c81024b889ff2a4ba10669b68bdab3ff	enhanced agility of e-learning adoption in high schools		Education is one among the many social services that enjoyed information technology as an enabler. The digital media and e-learning systems have played significant role as a learning content as well as learning platform with the aim to enhance access to education and quality of learning. In this paper, we investigate the practice of adopting digital media (combination of text, images, audio and video) into the school curricula (taking Ethiopia as a case study). We surveyed the accessibility of multimedia-rich e-learning resources; the experiences of students and teachers on using multimedia technologies; and their experiences on adopting multimedia in teaching learning process. Our findings indicated that the experiences of teachers and students on using advanced digital technologies is fair. However, there is only limited access to multimedia rich e-learning resources, and premature practice of adopting the technologies into the teaching learning. The mapping of these results to the existing models of adopting e-learning into the curricula showed that the schools’ status correspond to the initial phases and further recommendations on successful e-learning adoption is provided. In addition, we proposed an agile model to continuously catch the evolving technological innovation and for large scale e-learning adoption into a curricula.	accessibility;agile software development;color gradient;digital media;educational entertainment;experience;gamification;problem solving;virtual reality	Gebremariam Mesfin;George Ghinea;Tor-Morten Grønli;Wu-Yuin Hwang	2018	Educational Technology & Society			HCI	-75.21035154122853	-38.06734368987595	4151
e4f45b4bb33cdbb3ca7ca1cb4721de7b7baf29ca	nuclear reactor control room simulators: human factors research and development	pedestrian safety;nuclear reactor;poison control;injury prevention;safety literature;traffic safety;injury control;home safety;injury research;safety abstracts;research and development;human factors;occupational safety;safety;situation awareness;safety research;simulation study;accident prevention;violence prevention;bicycle safety;human reliability analysis;poisoning prevention;falls;ergonomics;suicide prevention	Simulator studies are powerful means for understanding, designing and managing the complexity of nuclear reactor control if, along with their scenarios, they are correctly designed for that purpose. This contribution to an international state of the art of the use of nuclear reactor control room simulators in human factors research and development summarises the trends and novelties in the theories and methodologies (the reduction of the ambitions of cognitive simulation and the renewal of process-tracing methods, the eclectic search for theoretical and methodological complementarity, the conquests of situation awareness and their limitations, the study of cooperation), in the use of the results (with stress on probabilistic human reliability analysis and design of procedures) and in the construction of simulated situations (with stress on part task simulations and on relations between testing practical and empirical hypotheses and testing theoretical ones).		Jacques Theureau	2000	Cognition, Technology & Work	10.1007/s101110050031	situation awareness;simulation;medicine;environmental health;engineering;suicide prevention;human factors and ergonomics;injury prevention;nuclear reactor;forensic engineering;computer security;mechanical engineering	Robotics	-11.06204829480662	-15.678244534478557	4152
53ba25d899b0c986cae7baaf2f62addee1b25353	a comprehensive study of idistance partitioning strategies for k nn queries and high-dimensional data indexing	retrieval;idistance;large scale;knn;high dimensional;indexing	Efficient database indexing and information retrieval tasks such as k -nearest neighbor (kNN) search still remain difficult challenges in large-scale and high-dimensional data. In this work, we perform the first comprehensive analysis of different partitioning strategies for the state-of-the-art high-dimensional indexing technique iDistance. This work greatly extends the discussion of why certain strategies work better than others over datasets of various distributions, dimensionality, and size. Through the use of novel partitioning strategies and extensive experimentation on real and synthetic datasets, our results establish an up-todate iDistance benchmark for efficient kNN querying of large-scale and high-dimensional data and highlight the inherent difficulties associated with such tasks. We show that partitioning strategies can greatly affect the performance of iDistance and outline current best practices for using the indexing algorithm in modern application or comparative evaluation.	algorithm;baseline (configuration management);benchmark (computing);best practice;dataspaces;experiment;graph partition;idistance;information retrieval;nearest neighbor search;overhead (computing);synthetic intelligence	Michael A. Schuh;Tim Wylie;Juan M. Banda;Rafal A. Angryk	2013		10.1007/978-3-642-39467-6_22	search engine indexing;computer science;data mining;database;k-nearest neighbors algorithm;information retrieval	DB	-4.742006384167422	-40.49947445160496	4155
585ce6819410ca779c4492b5a934d40a5f7a550e	expertise matching via constraint-based optimization	expertise matching;constrained optimization;optimal solution;optimisation;online matching algorithm;query processing;online matching algorithm expertise matching problem conference paper reviewer assignment product reviewer alignment product endorser matching query information retrieval method reviewing process constraint based optimization framework;information retrieval;real time;user feedback;paper reviewer assignment;pattern matching;query processing optimisation pattern matching;product reviewer alignment;query;expertise matching problem;reviewing process;paper reviewer assignment expertise matching constrained optimization;constraint based optimization framework;conference paper reviewer assignment;domain specificity;information retrieval method;product endorser matching	Expertise matching, aiming to find the alignment between experts and queries, is a common problem in many real applications such as conference paper-reviewer assignment, product-reviewer alignment, and product-endorser matching. Most of existing methods for this problem usually find “relevant” experts for each query independently by using, e.g., an information retrieval method. However, in real-world systems, various domain-specific constraints must be considered. For example, to review a paper, it is desirable that there is at least one senior reviewer to guide the reviewing process. An important question is: “Can we design a framework to efficiently find the optimal solution for expertise matching under various constraints?” This paper explores such an approach by formulating the expertise matching problem in a constraint based optimization framework. Interestingly, the problem can be linked to a convex cost flow problem, which guarantees an optimal solution under given constraints. We also present an online matching algorithm to support incorporating user feedbacks in real time. The proposed approach has been evaluated on two different genres of expertise matching problems. Experimental results validate the effectiveness of the proposed approach.	algorithm;domain-specific language;flow network;information retrieval;mathematical optimization;program optimization;world-system	Wenbin Tang;Jie Tang;Chenhao Tan	2010	2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2010.133	constrained optimization;computer science;theoretical computer science;machine learning;pattern matching;optimal matching;data mining;information retrieval	AI	-26.963956367048997	-60.987728402151376	4159
66d32c79b141c4faa858bdbac16298283a0b2c8b	toward better data sharing methods for genebanks		The conservation of plant genetic resources (PGR) is an important task that requires collaborative effort from many stakeholders. For this, common means of data exchange and effective methods to profit from the collected information need to be established. In this paper, we describe a demonstrator promoting findability of PGR, according to the FAIR (Findable, Accessible, Interoperable & Reusable) data principles. PGR providers can each expose their germplasm information, using the FAO Multicrop Passport Descriptor (MCPD), which subsequently can be queried in a distributed manner via a single user interface. PGR users can select among predefined questions, for example for specific crops, accessions or phenotypes.. On the back end, data integration from a distributed query is achieved through annotations with the MCPD semantics.	biometric passport;effective method;findability;information needs;interoperability;user interface	Evangelia Papoutsoglou;Rajaram Kaliyaperumal;Theo van Hintum;Richard G. F. Visser;Ioannis N. Athanasiadis;Richard Finkers	2017			data integration;germplasm;information needs;interoperability;data mining;data sharing;data exchange;user interface;findability;engineering	AI	-41.73320330418265	1.9337477180724871	4162
35cbbf678eeca5893ec11fe1a6fbef0919004c10	heightened amusement park dark ride interactivity and creativity made possible with highly integrated technology	control systems;control system;interactivity;integrated and reliable solid state audio and control systems	At Six Flags Belgium, a new interactive dark ride called Challenge of Tutankhamon takes visitors on a journey deep into a replica of an ancient pyramid where the tomb of the legendary pharaoh, King Tutankhamon, was hidden from the world for thousands of years. The riders' challenge is to enter the uncharted passageways of the tomb and find the treasure. The ancient god Seth -- Lord of Disorder and Chaos -- has vowed to protect the sanctity of the tomb, and has unleashed the mystical terrors of the curse. The visitors' journey involves an interactive mythological battle with 3,000 year-old gods and demons that still protect the tomb of the pharaoh. We believe that the realism, interactivity and unique, individual riders' experience of this ride, created by Sally Corporation, together with many other amusement park dark rides, has advanced substantially in the last five years. The new dark ride phenomenon is being created by highly innovative companies utilizing major developments in technology that have enabled the enhanced interactivity, sophistication, and overall experience of these rides. Where rides once provided limited interactivity and clumsy movements powered by multiple types of systems and truckloads of cables with questionable reliability, they now give visitors complex interactivity that is achieved with a highly integrated and reliable solid-state audio and control system. This new approach replaces the bundles of cables with simple serial cable runs. Because the controllers are 100% solid-state, they can be reprogrammed on a moment's notice.	control system;gods;interactivity;pharaoh;solid-state electronics;the sims	Ray Dominey;Rick Simon;Doug Wong	2004	Computers in Entertainment	10.1145/1008213.1008235	simulation;computer science;control system;artificial intelligence;marketing;interactivity;management	HCI	-55.590765978482096	-26.809262767936872	4168
9a920b7a169bd76df9ccbf92743c5c2fc4f1ff7e	design and implementation of system prediction and traffic conditions visualization in two dimensional map (case study: bandung city)	linear regression;data mining;extract traffic condition;visualization;urban areas;data visualization;twitter;time series prediction;real time chat	Traffic jam today in the city is one of the focus from the government, because it has a very big impact, from wasting a lot of time, the fuel until air pollution. Searching information about traffic conditions in the city has been widely available through the Twitter account @infobdg, with hashtag #lalinbdg and from the website bandung247.com. However, the rapid development of online information services resulted in the lack of time to read the complete information and for extracting the right information. To resolve these problems, it is necessary to design and implementation the visualization of traffic conditions in the form of map, which the information obtained from Twitter, cctv, user and operator prfm (the radio information about traffic conditions in Bandung). And then designing the predictive system for traffic conditions based on information from Twitter, so the people can predict traffic conditions for one week ahead. Making the visualization begins with taking a summary of the information that will be used for the visualization on the map. From the information Twitter, cctv, user and operator has been able to display traffic conditions in real time and predictive traffic conditions to allow users to know the traffic conditions.	closed-circuit television;hashtag;jam	Dian Anggraini;Wisnu Siswantoko;Diotra Henriyan;Devie Pratama Subiyanti;Mochamad Vicky Ghani Aziz;Ary Setijadi Prihatmanto	2016	2016 International Conference on Frontiers of Information Technology (FIT)	10.1109/ICSEngT.2016.7849629	simulation;geography;data mining;world wide web	HPC	-17.105206540907133	-31.43259853377641	4172
be89acf76edf8d752069038a7e97addff6f2b469	clues to compare languages for morphosyntactic analysis: a study run on parallel corpora and morphosyntactic lexicons	lexical statistics;language typology for nlp;comparative study;morphosyntactic lexicons;parallel corpora;multilingual resources	The aim of the present work is to find clues on how to compare the difficulties of five languages for morphosyntactic analysis and the development of lexicographic resources running a corpora and lexical comparative study on multilingual parallel corpora and morphosyntactic lexicons. First, we ran some corpus-based experiments without any other type of knowledge, following classical measures used in lexical statistics. Then we carried out further experiments on the corpora using morphosyntactic lexicons. Finally, we plotted given diagrams using different clues to offer an overview of the difficulty of a language for the development of morphosyntactic resources.	lexicon;parallel text;text corpus	Helena Blancafort;Claude de Loupy	2009		10.1007/978-3-642-20095-3_31	natural language processing;speech recognition;computer science;linguistics	NLP	-28.78481588824686	-74.8130621315126	4182
5bdf91fd7b56ffb77a4410687815e8be8b4c1532	semantic understanding of spatial trajectories		The advances in location-acquisition technologies and the prevalence of locationbased services have generated massive spatial trajectory data, which represent the mobility of a diversity of moving objects, such as people, vehicles, and animals. Such trajectories offer us unprecedented information to understand moving objects and locations that could benefit a broad range of applications. These important applications in turn calls for novel computing technologies for discovering knowledge from trajectory data. Under the circumstances, trajectory data mining has become an increasingly important research theme in the past decade [10]. Extensive research has been done in the field of trajectory data mining with many interesting patterns have been proposed and studied. However, most existing studies focus on only trajectory data and did not consider rich spatial-temporal contexts that are associated with trajectories. As a consequence, trajectory patterns detected from existing methods could be trivial. Let’s examine an example below.	data mining	Zhenhui Li	2017		10.1007/978-3-319-64367-0_24	data mining;computer science;trajectory	HCI	-18.957765528809443	-35.55986792344123	4185
19cb8d20e0ac7fa8bf7cce32b74efa8203be6561	the auckland layout editor: an improved gui layout specification process	layout manager;layout editing;gui builder;constraint based layout	Constraint-based layout managers are more powerful than the common grid, grid-bag, and group layout managers. However, they are also more complex and come with potential problems such as over-constrained specifications and overlap in a GUI. Current GUI builders have little support for layout constraints, and it is not clear how such constraints can be made easily accessible to GUI designers.  We will demonstrate a GUI builder -- the Auckland Layout Editor (ALE) -- that addresses these challenges, by allowing GUI designers to specify constraint-based layouts using only simple mouse operations. ALE guarantees that all operations lead to sound specifications, making sure that the layout is solvable and non-overlapping. To achieve the latter, we propose an algorithm that automatically generates the missing constraints that are necessary to keep a layout non-overlapping. Today's applications need to run on multiple devices with different screen sizes. For this a layout must have a good appearance at different sizes. To aid the designer in creating a layout with good resizing behavior, we propose a novel automatic layout preview, which displays the layout at its minimal and at an enlarged size chosen to visualize layout problems directly.	graphical user interface	Clemens Zeidler;Christof Lutteroth;Gerald Weber;Wolfgang Stuerzlinger	2012		10.1145/2379256.2379287	layout versus schematic;layout;ic layout editor;layout manager;computer science;operating system;database;comprehensive layout;programming language;computer graphics (images)	HCI	-41.3151552337005	-30.77111461947022	4193
7a1a47a158a048fa58a23635d48231bd30ba39a0	sexuality and the internet: a study of the perspectives of turkish university students	online sexual activity;internet;university students;sexuality;turkey	The purpose of this study was to determine Turkish university students' uses of and attitudes toward the Internet concerning sexuality. The study was conducted in two public universities in the Central Anatolia and Eastern Anatolia regions of Turkey. Among the students invited to take part in the study, 1,330 students agreed to do so. The study data were collected using a questionnaire designed by researchers to determine participants' personal characteristics, computer and Internet uses in general, and for sexual matters. The findings suggest that approximately half of the students (51%) reported using the Internet to obtain information about sexuality. Among the students, 30.5% said that they visit erotic and pornographic Web sites, 21.1% said that they chat on the Internet about sexuality, and 9.3% said that they bought sexual products online. Compared to the female students, the male students, statistically, more frequently show behaviors such as obtaining sexual information on the Internet, online sexual shopping, chatting on the Internet about sexuality, and visiting pornographic and erotic Web sites. In addition, female students have more negative attitudes toward using the Internet for sexual purposes. This study discusses its results along with the literature from Turkey and other countries.		Tuba Uçar;Zehra Golbasi;Ayten Senturk Erenel	2016	Cyberpsychology, behavior and social networking	10.1089/cyber.2016.0433	psychology;the internet;medicine;multimedia;human sexuality;law;pedagogy	HCI	-84.58435621560193	-22.608924210736944	4194
377ca8e6970b5197d45016b561ae6ce49e1abfee	google image swirl: a large-scale content-based image visualization system	semantic similarity;image retrieval and clustering;user feedback;automatic group;large scale;image browsing;image search;visual system;image retrieval	Web image retrieval systems, such as Google or Bing image search, present search results as a relevance-ordered list. Although alternative browsing models (e.g. results as clusters or hierarchies) have been proposed in the past, it remains to be seen whether such models can be applied to large-scale image search. This work presents Google Image Swirl, a large-scale, publicly available, hierarchical image browsing system by automatically group the search results based on visual and semantic similarity. This paper describes methods used to build such system and shares the findings from 2-years worth of user feedback and usage statistics.	computer cluster;image retrieval;image viewer;relevance;semantic similarity	Yushi Jing;Henry A. Rowley;Jingbin Wang;David Tsai;Chuck Rosenberg;Michele Covell	2012		10.1145/2187980.2188116	semantic similarity;visual word;visual system;image retrieval;computer science;multimedia;automatic image annotation;world wide web;information retrieval	Web+IR	-16.570699435432317	-58.37864689537057	4197
4648c02c36112207b1d901710300bbc86377c8f0	automatically discovering offensive patterns in soccer match data	spatial data;sports analytics;strategy detection	In recent years, many professional sports clubs have adopted camera-based tracking technology that captures the location of both the players and the ball at a high frequency. Nevertheless, the valuable information that is hidden in these performance data is rarely used in their decision-making process. What is missing are the computational methods to analyze these data in great depth. This paper addresses the task of automatically discovering patterns in offensive strategies in professional soccer matches. To address this task, we propose an inductive logic programming approach that can easily deal with the relational structure of the data. An experimental study shows the utility of our approach.		Jan Van Haaren;Vladimir Dzyuba;Siebe Hannosset;Jesse Davis	2015		10.1007/978-3-319-24465-5_25	data mining;spatial analysis;multimedia;internet privacy;statistics	ML	-21.211411497265225	-51.21102436227682	4199
24d761d5a1924af903e7b27eb85442db1f877abb	exploring portuguese academics' understanding of ownership and intellectual property of online educational materials		This article presents the results of an exploratory study that investigates how academics perceive the impact of e-learning systems in the ownership and intellectual property of educational materials. It has been inductively discovered that academics are uncomfortable with the idea of uncontrolled pick up and use of educational resources by third parties, including the institutions they are affiliated with. The main reasons for this mistrust are associated with perceptions of ownership and intellectual property, resources integrity and perceived insufficient institutional support. Two suggestions are advanced to counter academics' mistrust about making educational materials available through e-learning systems: i the institutional recognition and accreditation of the development of high-quality online teaching resources; ii and the clarification of legal ambiguities concerning this type of ownership and intellectual property, through the creation of clear institutional rules and negotiation of institutional policies.		Jorge Tiago Martins;José Miguel Baptista Nunes	2016	JOEUC	10.4018/JOEUC.2016100103	accreditation;computer science;exploratory research;marketing;knowledge management;intellectual property;grounded theory;negotiation;portuguese	AI	-76.38169605734923	-26.538900455538656	4205
f81817ff66923bea473b54c74e2197658a12878f	automatically weighting tags in xml collection	tag weighting model;xml retrieval;relevance ranking;xml document;topic generalization	In XML retrieval, nodes with different tags play different roles in XML documents and then tags should be reflected in the relevance ranking. An automatic method is proposed in this paper to infer the weights of tags. We first investigate 15 features about tags, and then select five of them based on the correlations between these features and manual tag weights. Using these features, a tag weight assignment model, ATG, is designed. We evaluate the performance of ATG on two real data sets, IEEECS and Wikipedia from two different perspectives. One is to evaluate the quality of the model by measuring the correlation between weights generated by our model and those given by experts. The other is to test the effectiveness of the model in improving retrieval performance. Experimental results show that the tag weights generated by ATG are highly correlated with the manually assigned weights and the ATG model improves retrieval effectiveness significantly.	relevance;tag cloud;wikipedia;xml retrieval	Dexi Liu;Changxuan Wan;Lei Chen;Xiping Liu	2010		10.1145/1871437.1871603	xml;computer science;data mining;database;programming language;world wide web;information retrieval	Web+IR	-27.613086030859055	-63.615574860407015	4210
e877349854bec3385469ab93e11c11ed6d58b400	an approach to automatic construction of a hierarchical subject domain for question answering systems	navegacion;lenguaje natural;ontologie;text;electronic mail;analisis estadistico;red www;repondeur;redundancia;hierarchized structure;text processing;langage naturel;interrogation base donnee;reseau web;interrogacion base datos;structure hierarchisee;correo electronico;texte;probabilistic approach;information presentation;quantite information;courrier electronique;navigation;internet;redundancy;statistical analysis;anglais;question answering system;enfoque probabilista;approche probabiliste;natural language;analyse statistique;responder;world wide web;ontologia;english;cantidad informacion;texto;ingles;ontology;information quantity;database query;estructura jerarquizada;contestador;redondance	We propose a new statistical algorithm for automatic construction of subject domains that can be used in e-mail or Web question answering systems and ontology generating. The domain hierarchy is extracted from electronic texts written in a natural language, e.g., in English. During the text processing, the quality and quantity of information presented in the texts are being evaluated and then the hierarchical relationships between the pieces of texts are established depending on the derived data. Using this approach, we have created a question answering system which executes hierarchy navigation based on a query analysis including evaluation of the user's conversance with the subject domain. In combination, these steps result in comprehensive and non-redundant answers.	automatic taxonomy construction;question answering	Anna Fensel;Pavel V. Mankevich	2003		10.1007/978-3-540-39866-0_55	natural language processing;navigation;computer science;artificial intelligence;english;ontology;database;redundancy;natural language;world wide web;information retrieval	Logic	-35.6475313966671	-63.14847337350362	4212
ee66086788c54a18803582d8806c2fccaab83ed3	a proposal for including behavior in the process of object similarity assessment with examples from artificial life	automatic code generation;methode recursive;generacion automatica;generation code;metodo recursivo;generacion codigo;code generation;recursive method;intelligence artificielle;automatic generation;similitude;generation automatique;vie artificielle;similarity;artificial intelligence;inteligencia artificial;similitud;rough set;ensemble approximatif;artificial life	"""The similarity assessment process often involves measuring the similarity of objects X and Y in terms of the similarity of corresponding constituents of X and Y, possibly in a recursive manner. This approach is not useful when the verbatim value of the data is of less interest than what they can potentially """"do,"""" or where the objects of interest have incomparable representations. We consider the possibili ty that objects can have behavior independent of their representation, and so two objects can look similar, but behave differently, or look quite different and behave the same. This is of practical use in fields such as Artificial Life and Automatic Code Generation, where behavior is considered the ultimate determining factor. It is also useful when comparing objects that are represented in different forms and are not directly comparable. We propose to map behavior into data values as a preprocessing step to Rough Set methods. These data values are then treated as normal attributes in the similarity assessment process."""	artificial life;automatic programming;boyce–codd normal form;object-based language;preprocessor;recursion;rough set	Kamran Karimi;Julia A. Johnson;Howard J. Hamilton	2000		10.1007/3-540-45554-X_81	rough set;similarity;computer science;artificial intelligence;similitude;machine learning;data mining;mathematics;algorithm;artificial life;code generation	Web+IR	-20.231252512366385	-0.6767971069426545	4213
83e132e88ddd0bc5386cee2219c6c0fe9dd46977	representing knowledge levels in clinical guidelines	clinical guideline;informatica biomedical;representacion conocimientos;biomedical data processing;architecture systeme;metodologia;analisis datos;informatique biomedicale;conceptual analysis;classification;analisis conceptual;methodologie;data analysis;analyse donnee;arquitectura sistema;analyse conceptuelle;point of view;methodology;knowledge representation;system architecture;representation connaissances;clasificacion	In this paper, we argue that different levels of knowledge are involved in the representation of clinical guidelines, and that distinguishing among these levels is important from both the conceptual and the methodological point of view. In particular, at the pistemological level , one points out different types of actions and distinguishes between structural relations and control relations. On the other hand, the ontological level specifically concerns the clinical domain, consisting in the definition of the basic attributes of clinical actions and in the description of some specific types of actions . We also show how the above distinctions are important for our formalism and for the design of our acquisition module.	control flow;point of view (computer hardware company);semantics (computer science)	Paolo Terenziani;Paolo Raviola;Oscar Bruschi;Mauro Torchio;Marina Marzuoli;Gianpaolo Molino	1999		10.1007/3-540-48720-4_28	knowledge representation and reasoning;biological classification;computer science;artificial intelligence;methodology;data mining;data analysis;algorithm;systems architecture	AI	-25.269506193942803	-4.538244630505818	4224
7942d7a63d770316bb640ceece806e0a2aeb892e	fdt 2.0: improving scalability of the fuzzy decision tree induction tool - integrating database storage	databases;training;training data;accuracy;decision trees;algorithm design and analysis	Effective machine-learning handles large datasets efficiently. One key feature of handling large data is the use of databases such as MySQL. The freeware fuzzy decision tree induction tool, FDT, is a scalable supervised-classification software tool implementing fuzzy decision trees. It is based on an optimized fuzzy ID3 (FID3) algorithm. FDT 2.0 improves upon FDT 1.0 by bridging the gap between data science and data engineering: it combines a robust decisioning tool with data retention for future decisions, so that the tool does not need to be recalibrated from scratch every time a new decision is required. In this paper we briefly review the analytical capabilities of the freeware FDT tool and its major features and functionalities; examples of large biological datasets from HIV, microRNAs and sRNAs are included. This work shows how to integrate fuzzy decision algorithms with modern database technology. In addition, we show that integrating the fuzzy decision tree induction tool with database storage allows for optimal user satisfaction in today's Data Analytics world.	bridging (networking);data science;database storage structures;decision tree;handling (psychology);id3 algorithm;information engineering;machine learning;mysql;powerflasher fdt;programming tool;published database;scalability;trees (plant)	Erin-Elizabeth A. Durham;Xiaxia Yu;Robert W. Harrison	2014	2014 IEEE Symposium on Computational Intelligence in Healthcare and e-health (CICARE)	10.1109/CICARE.2014.7007853	computer science;data science;data mining;database	DB	-9.501964058745857	-31.909996536623275	4229
380cdaa04311d5d6b92c6b15ef5feaf5b3a6afd2	analysing computer science students' teamwork role adoption in an online self-organised teamwork activity	human to human;collaboration;students team roles;conference paper;team roles;teamwork;students	Computer Science (CS) professionals are regularly required to work in teams to solve complex problems. Agile software development processes are increasingly popular in organisations as a method for teamwork but the self-organising nature of the method and lack of strictly allocated roles means that graduates need to know how to adopt and transition between roles effectively. While online teamwork makes team processes and behaviours transparent, educators are often confronted by the amount of data and difficulty in how to judge roles and behaviours to provide meaningful feedback to students. Furthermore, assessment of teamwork does not necessarily ignite a need to identify roles and behaviours as feedback is usually based on the product, rather than processes and behaviours.  Using Dickinson and McIntyre's teamwork roles, we extend the framework to include explicit behaviours to analyse one class of students' self-organised team interactions in an online discussion space as solved open-ended problems. The collaborative activity did encourage role adoption, however not all students moved fluidly through the roles. Despite the lack of defined roles, one or two students adopted leadership roles, but attempts at leadership were not always successful. We discovered other less-obvious roles were equally important for maintaining and progressing team discussions. In this paper, we discuss the roles that emerged and suggest strategies for encouraging and assessing online teamwork. Our framework may prove to be a guide for others seeking to analyse students' teamwork and provides a guide for what behaviours a teacher might look for in online environments. Our findings support the need to develop tools that provide real-time visual feedback to students and teachers about student behaviour and roles when undertaking teamwork in online spaces.	agile software development;computer science;feedback;interaction;need to know;nonlinear gameplay;real-time computing;real-time transcription;self-organization	Rebecca Vivian;Katrina E. Falkner;Nickolas J. G. Falkner	2013		10.1145/2526968.2526980	simulation;teamwork;engineering;knowledge management;pedagogy	AI	-74.72896208372545	-38.630512538573306	4234
a82b6bc934308192acf898e7745d6e08982c988c	volunteer best practices for k12 cs	cs4all;industry volunteers;k12 cs education;csforall	Computer Science Education is rapidly expanding in the United States[5]. As a part of this expansion, many programs are using university students and industry volunteers for a variety of purposes within schools. These volunteers can bring a wealth of content knowledge and professional experience in their interactions with students [3], and can be inspirational when talking about the problems they work on[1]. Some programs even advocate for the use of professionals for instruction based upon their content knowledge[2]. Although professionals often have a high level of content knowledge, they may lack the training or experience necessary to be effective in the classroom[3, 4]. This panel brings together 4 different organizations with experience working with content expert volunteers with widely disparate preparation in teaching.  In this panel we will share lessons learned by the organizations whose programs rely on volunteer instructors and mentors, that combined work with over 1,200 volunteers for multiple years. Topics discussed by the panel will include recruitment and selection of volunteers, volunteer training prior to entering the classroom, appropriate supports for volunteers throughout the experience, volunteer retention strategies, and preliminary efforts at evaluating the implementations. Panelists will also discuss volunteers for short-term engagements such as speaking opportunities and school-based hackathons.	best practice;hackathon;high-level programming language;interaction	Leigh Ann DeLyser;Tom O'Connell;Diane Levitt;Rebecca Novak;Kevin Wang	2017		10.1145/3017680.3017687	knowledge management;pedagogy	HCI	-79.77753551254226	-31.282078274573205	4235
2d54799526443925b246e123920d6d7c7e0bc73f	manning the boat with a diverse (non-traditional) crew	critical point;wireless;library service;training;user survey;help desk;library services;support;computer lab;management;staffing;grants	Due to a lack of increase in departmental funding, the Pennington Biomedical Research Center departments of Computing Services and Library Services are continually looking for ways to increase efficiency and productivity without the increase of personnel and resources. A continual need for office space in the research facility was at a critical point in the year 2000. Computing Services and Library Services worked together to develop an arrangement that was beneficial to both departments: the move of the Computer Lab and Training Area to the Library Services public access area, and a change in the way technical support was offered to the community of PBRC computer users.This collaborative project was just the beginning of a long-lasting relationship between the two departments, and has provided users with exceptional if non-traditional services from the Library and Computing Services departments. With the success of this first merger, these two departments have proceeded to undertake many other collaborative projects. Some of these projects have been completed while others are in the planning / development stages. The list of projects, past and present include:Space SharingComputer Lab Support and End User Hardware Usage TrainingPortal Project / Intranet DevelopmentMaintenance of PINE Usage ReportsWireless ImplementationLibrary Users Survey DevelopmentSoftware Training Class OfferingsGrant Application SubmissionLibrary Integrated Online System DevelopmentBoth areas continue to act as independent departments while finding that they are still very dependent on the other; the interactions of the two departments continue and the relationship thrives. This paper will take you through the steps that were used during the first collaborative effort between the two departments to merge the resources of the Computing Learn Lab and Training Area with the existing Library Services public access area. The paper will also discuss each of the other collaborative projects during the discovery, planning, and implementation phases.	computer lab;critical point (network science);interaction;intranet;pine;technical support;user (computing)	David E. Alexander;Claire C. Lassalle;Lori C. Steib	2005		10.1145/1099435.1099474	simulation;engineering;knowledge management;services computing;world wide web	HCI	-69.19053845968973	-25.74204949985969	4237
712af743e6b2836d609e41857af716c9b9898c4a	technology strategy and management: the puzzle of apple	technology strategy	Given Apple's unique characteristics, should it strive to be a platform or a product leader?		Michael A. Cusumano	2008	Commun. ACM	10.1145/1378727.1378736	computer science;technology strategy	Theory	-69.26942076963053	-0.43788833661381427	4245
cd54b18486133c7c5eb40dbbd9b36ddb5eea496d	learning from labeled and unlabeled vertices in networks		Networks such as social networks, citation networks, protein-protein interaction networks, etc., are prevalent in real world. However, only very few vertices have labels compared to large amounts of unlabeled vertices. For example, in social networks, not every user provides his/her profile information such as the personal interests which are relevant for targeted advertising. Can we leverage the limited user information and friendship network wisely to infer the labels of unlabeled users?  In this paper, we propose a semi-supervised learning framework called weighted-vote Geometric Neighbor classifier (wvGN) to infer the likely labels of unlabeled vertices in sparsely labeled networks. wvGN exploits random walks to explore not only local but also global neighborhood information of a vertex. Then the label of the vertex is determined by the accumulated local and global neighborhood information. Specifically, wvGN optimizes a proposed objective function by a search strategy which is based on the gradient and coordinate descent methods. The search strategy iteratively conducts a coarse search and a fine search to escape from local optima. Extensive experiments on various synthetic and real-world data verify the effectiveness of wvGN compared to state-of-the-art approaches.	citation graph;coordinate descent;dhrystone;experiment;gradient;local optimum;loss function;optimization problem;semi-supervised learning;semiconductor industry;social network;supervised learning;vertex (geometry)	Wei Ye;Linfei Zhou;Dominik Mautz;Claudia Plant;Christian Böhm	2017		10.1145/3097983.3098142	artificial intelligence;data mining;computer science;local optimum;semi-supervised learning;support vector machine;machine learning;vertex (geometry);coordinate descent;user information;classifier (linguistics);targeted advertising	ML	-15.31947360639804	-44.26191862220553	4246
19f99462f54484c67f7546bcdf3ea05f12e48e1a	model parameter estimation for mixture density polynomial segment models	trajectoire;speech processing;timit vowel classification experiments;hmm;variance trajectories;polynomials speech recognition speech processing parameter estimation pattern classification hidden markov models;classification;polynomials;trajectories;identificacion sistema;modelisation;hidden markov models;parameter estimation polynomials hidden markov models solid modeling speech recognition covariance matrix cepstrum;system identification;expectation maximization;segment clustering;cepstrum;expectation maximization training;solid modeling;mixture density polynomial segment models;pattern classification;speech recognition;analyse regression;arbitrary regression order;regression analysis;reconnaissance parole;parameter estimation;estimation parametre;mean trajectories;identification systeme;hmm speech recognition parameter estimation mixture density polynomial segment models arbitrary regression order segment clustering expectation maximization training mean trajectories variance trajectories timit vowel classification experiments;covariance matrix	In this paper, we propose parameter estimation techniques for mixture density polynomial segment models (MDPSM) where their trajectories are specified with an arbitrary regression order. MDPSM parameters can be trained in one of three different ways: (1) segment clustering, (2) expectation maximization (EM) training of mean trajectories, or (3) EM training of mean and variance trajectories. These parameter estimation methods were evaluated in TIMIT vowel classification experiments. The experimental results showed that modeling both the mean and variance trajectories are consistently superior to modeling only the mean trajectory. We also found that modeling both trajectories results in significant improvements over the conventional HMM.	estimation theory;polynomial	Toshiaki Fukada;Yoshinori Sagisaka;Kuldip K. Paliwal	1997		10.1109/ICASSP.1997.596210	covariance matrix;speech recognition;system identification;expectation–maximization algorithm;biological classification;computer science;trajectory;machine learning;cepstrum;pattern recognition;mathematics;solid modeling;estimation theory;hidden markov model;regression analysis;statistics;polynomial	ML	-19.73615538069342	-91.99328537999634	4247
b7e04978992851255d26fd8a00b6673ea9f27f84	measuring information quality in the web context: a survey of state-of-the-art instruments and an application methodology	information quality	Various powerful instruments exist today to evaluate information quality in the web context. They can be categorized into five types of tools, namely performance monitoring systems, site analyzers, traffic analyzers, web mining tools and survey tools (to generate opinion-based user feedback). The combined use of these tools can enable an organization to measure the multiple dimensions of information quality in the Internet or Intranet context. This however requires a clear methodology that is based on systematic sequential steps and on an information quality framework that outlines relevant measurement criteria. In this paper we show which information quality criteria can be measured with the help of these tools and we provide an overview on the most important of these instruments. We present the IQM-methodology to match information quality criteria with adequate measurement tools.	categorization;clementine;hyperion;information quality;internet;intranet;multihoming;sane;spss;urchin software;web mining;webmaster;world wide web	Martin J. Eppler;Peter Muenzenmayer	2002			information quality;world wide web;information retrieval;data mining;business	HCI	-26.096541159245415	-55.08919665429551	4248
8a1eea1962237068548b22ec7560a69551284a61	web image size prediction for efficient focused image crawling	html code;http request;hypermedia markup languages;web sites hypermedia markup languages image retrieval internet text analysis;web pages;image element;information extraction;training;filtering component web image size prediction web image content large scale image crawling web page http request image element decorative element dimension information image crawler information extraction html code text classification image url html element;web image size prediction;decorative element;text analysis;data mining;html element;vegetation;uniform resource locators web pages feature extraction vegetation html training data mining;text classification;html;dimension information;internet;image crawler;image url;feature extraction;large scale image crawling;web sites;web page;web image content;filtering component;uniform resource locators;image retrieval	In the context of using Web image content for analysis and retrieval, it is typically necessary to perform large-scale image crawling. A serious bottleneck in such set-ups pertains to the fetching of image content, since for each web page a large number of HTTP requests need to be issued to download all included image elements. In practice, however, only the relatively big images (e.g., larger than 400 pixels in width and height) are potentially of interest, since most of the smaller ones are irrelevant to the main subject or correspond to decorative elements (e.g., icons, buttons). Given that there is often no dimension information in the HTML img tag of images, to filter out small images, an image crawler would still need to issue a GET request and download the respective files before deciding whether to index them. To address this limitation, in this paper, we explore the challenge of predicting the size of images on the Web based only on their URL and information extracted from the surrounding HTML code. We present two different methodologies: The first one is based on a common text classification approach using the n-grams or tokens of the image URLs and the second one relies on the HTML elements surrounding the image. Eventually, we combine these two techniques, and achieve considerable improvement in terms of accuracy, leading to a highly effective filtering component that can significantly improve the speed and efficiency of the image crawler.	document classification;download;grams;graphics;html;image resolution;meta element;n-gram;pixel;relevance;supervised learning;text-based (computing);web crawler;web page;world wide web	Katerina Andreadou;Symeon Papadopoulos;Yiannis Kompatsiaris	2015	2015 13th International Workshop on Content-Based Multimedia Indexing (CBMI)	10.1109/CBMI.2015.7153609	image map;image retrieval;computer science;web page;database;world wide web;information extraction;information retrieval	Web+IR	-28.88051735226093	-55.56556113472609	4253
1000c587bac8bf86a4caace00a75acdaf2538fe4	multimedia structuring using trees	hierarchical structure;multimedia data;graphic user interface;user interaction	Traditionally work on multimedia structuring has been centered on the creation of indices and their use for searching. Although searching is important there are many cases where the user just wants to browse through the data to find something interesting without having any particular search goal. Multimedia data exhibits hierarchical structure that can be exploited for more natural user interaction with the content. In order to handle the large amounts of multimedia data more structure than what is currently available is required. In this paper, we have focused on structuring multimedia data using trees to describe both temporal and categorical relations. The pervasive use of trees to express hierarchies facilitates browsing, profiling, and authoring. Our main target application is the implementation of a personalized TV−guide. The constraints imposed by this application caused the development of a new simple compact graphical user interface for tree browsing. Introduction There is a huge increase in the amount of multimedia data on the Web and elsewhere. This increase will continue as the television, video, and music industries gradually become digital. More advanced tools than what those which are currently available are required to handle this data efficiently. Structuring the information for browsing and retrieval is an important part of this process. File systems with directories were introduced in the early days of computing as a way of organizing the increasing amounts of computer files. In a similar manner trees are representations that can be used to hierarchically organize temporal multimedia data streams like video and audio. In this paper, we propose the use of trees as data representations that can be used for better browsing and analysis of temporal data streams. Multimedia data exhibits hierarchical structure at different time granularities. For example, a news broadcast is organized in sections, each section has different topics and each topic several scene changes or shots. As another example, music exhibits hierarchical structure at different time granularities. In our system the hierarchical structure of trees is used to express temporal and categorical relations and allows for more natural browsing, user−profiling and searching than the traditional tape−recorder user interface paradigm especially for large data sets. Traditionally, work on multimedia data has been centered on the creation of indices and their use for searching. Although searching is important there are many cases where the user just wants to browse through the data to find something interesting without having any particular search goal. In our system trees are not only used internally but are exposed and used extensively both by the multimedia author and by the end user. A prototype implementation of a system for authoring and viewing trees containing multimedia data is described. It is implemented within the Open Agent Architecture (OAA) (Martin et al, 1999), a distributed multiagent framework that enables rapid integration of component technologies. Issues related to the creation, presentation and maintenance of this representation are discussed. As an application of the system we describe a personalized TV guide. A novel graphical user interface for tree viewing on a TV screen using the discrete keys of a remote control has been developed.	agent-based model;browsing;computer file;graphical user interface;natural user interface;open agent architecture;organizing (structure);personalization;pervasive informatics;profiling (computer programming);programming paradigm;prototype;remote control;type system;world wide web	George Tzanetakis;Luc E. Julia	2000			computer science;database;multimedia;world wide web	Web+IR	-40.172560057022416	-24.343254175932742	4256
2d1711e47776666a033b2af5eefd1ad81a9021ed	an information infrastructure for government regulation analysis and compliance assistance	information infrastructure;government regulation	1 Project Overview The complexity and diversity of government regulations make understanding the regulations a non-trivial task. One of the issues is the existence of multiple sources of regulations and interpretive guides; the latter are often independent of governing bodies. In this work, we describe a research prototype system that combines text mining and knowledge management techniques to help better manage, understand and analyze regulatory documents. This regulatory information infrastructure includes three integral parts: a document repository, a tool for similarity analysis and a compliance assistance system. This paper first presents the development of a legal corpus with multiple sources of regulatory documents consolidated into a unified format. A shallow parser is developed to consolidate different regulations into a unified XML format, which is well suited for handling semi-structured data such as legal documents. Important features, such as concepts, measurements, definitions and so on, are extracted and incorporated into the corpus by using handcrafted rules and text mining tools. A regulation compliance assistance system is introduced next, where First Order Predicate Calculus (FOPC) logic sentences are implemented to help users to perform compliance check in a question and answer session. Finally, a similarity analysis for regulations is developed, where Information Retrieval (IR) and structural matching techniques are used to identify related provisions among regulations.	diff utility;first-order logic;information retrieval;interpreter (computing);knowledge management;prototype;semi-structured data;semiconductor industry;sequent calculus;text corpus;text mining;xml	Gloria T. Lau;Shawn Kerrigan;Haoyi Wang;Kincho H. Law;Gio Wiederhold	2004			computer science;data mining;database;information retrieval	Web+IR	-41.89389134971658	4.110448424628907	4257
79486ad093b8f83aa83b6f0c472be47dc01948d3	looking past planned and habitual it use	mobile communication context indexes cities and towns mathematical model sociology statistics;indexes;adaptive behaviour it use;it use;adaptive behaviour;habit formation information technology planned it use models habitual it use models mobile ticket use it use intention adaptive it use it use relation;mobile communication;statistics;mathematical model;cities and towns;social aspects of automation human factors;context;sociology	Information technology is often used as means to some more fundamental ends. Such use is often adaptive rather than planned or habitual and, therefore, alien to the dominant IT use models. In this paper, we argue that the role, which IT plays, should be taken into account when trying to predict IT use. We re-evaluate previously reported data on mobile ticket use and demonstrate that, when IT use is not an end in and of itself, IT use intention can be used, rather counter-intuitively, to predict more accurately adaptive IT use than planned IT use. Our findings also suggest that IT habit should not be used as the default explanation for IT use, when IT intention -- IT use relation fails to materialize, unless there is further supporting evidence for habit formation.	alien;relation (database)	Anssi Öörni;Kalle Lyytinen	2015	2015 48th Hawaii International Conference on System Sciences	10.1109/HICSS.2015.434	database index;simulation;mobile telephony;computer science;artificial intelligence;mathematical model;statistics	HCI	-92.40675298189436	-5.643630936340466	4258
4afb58578ebdb550c2892fee563d12f77fc15b24	continuous monitoring and digital systems for elders		Ageing of the European population raises issues both socially and economically, creating major challenges for the traditional care and healthcare paradigm. Recent technological developments generate a favorable environment for a paradigm shift in the way care and healthcare is provided, by promoting the inclusion of the elders in the digital society. This paper presents an approach to promote elders inclusion, based on a RWD platform, capable of being used in multiple devices (including SmartTVs), and in wireless sensor networks. Studies involving end users have shown how well-adjusted interfaces ease the process of inclusion of IT in elders’ life. This work has been developed within the frame of the European project HELASCoL.	crossword;email;information system;programming paradigm;responsive web design;sensor;sudoku;user (computing);web application;webapp.net	Nuno Barbosa Rocha;Raquel Sousa;Gil Gonçalves	2015		10.5220/0005491200810086	environmental science;real-time computing;continuous monitoring	Mobile	-60.81836246303758	-55.80269728525687	4260
15aa5b703a56c6af7e09076238f77ce78cd577d7	simple signals for complex rhetorics: on rhetorical analysis with rich-feature support vector models	coherent structures;support vector;rhetorical structure theory;tree structure;part of speech;global optimization	Most text displays an internal coherence structure, which can be analyzed as a tree structure of relations that hold between short segments of text. We present a machine-learning governed approach to such an analysis in the framework of Rhetorical Structure Theory. Our rhetorical analyzer observes a variety of textual properties, such as cue phrases, part-of-speech information, rhetorical context and lexical chaining. A two-stage parsing algorithm uses local and global optimization to find an analysis. Decisions during parsing are driven by an ensemble of support vector classifiers. This training method allows for a non-linear separation of samples with many relevant features. We define a chain of annotation tools that profits from a new underspecified representation of rhetorical structure. Classifiers are trained on a newly introduced German language corpus, as well as on a large English one. We present evaluation data for the recognition of rhetorical relations.	algorithm;global optimization;machine learning;mathematical optimization;nonlinear system;parsing;support vector machine;teaching method;text corpus;tree structure	David Reitter	2003	LDV Forum		natural language processing;support vector machine;lagrangian coherent structures;speech recognition;part of speech;computer science;artificial intelligence;machine learning;linguistics;tree structure;global optimization	NLP	-22.476085732117557	-74.20127523207883	4269
db58ba6bfbedb29ea8ec970940331b659ef59597	m-payment - how disruptive technologies could change the payment ecosystem		Within developed economies, the field of m-payment appears to be driven by (disruptive) technological innovations. M-payments, similar to e-payments, have been regulated in such a way that banks and other established financial institutions have been able to maintain an unchallenged position in the payment ecosystem. However, disruptive technologies like Near Field Communication, but more importantly cloud technology based solutions might lead to dramatic changes. In the long run this may change the position of banks in the payment ecosystem including their control over “money flows”. Yet, for this to happen m-payment solution and service providers need to understand the role of money and payment instruments as well as how payment ecosystems work, in-depth. In this conceptual paper we discuss how the ecosystem of m-payment is expected to change due to technology changes. Based on platform and ecosystems concepts, theories of money and behavioral theories a comprehensive literature review and a qualitative meta-analyses of the m-payment literature is presented. On the basis of the theory review and literature analysis we expect that the role of Over The Top (OTT) providers in the m-payment ecosystems will be driven by cloud-based solutions and threaten the position of traditional players. Banks need regulators to safeguard their control over the money flow.	cloud computing;ecosystem;electronic funds transfer;money;near field communication;theory	Tomi Dahlberg;Harry Bouwman;Narciso Cerpa;Jie Guo	2015			quantity theory of money;payment service provider;economics;computer science;environmental resource management;marketing;world wide web;commerce;mobile payment	HCI	-78.25956241442636	-9.653685613460267	4270
509538c5de17af5e3271b1eb517445a2b79fad61	rapid parser development: a machine learning approach for korean	machine learning	This paper demonstrates that machine learning is a suitable approach for rapid parser development. From 1000 newly treebanked Korean sentences we generate a deterministic shift-reduce parser. The quality of the treebank, particularly crucial given its small size, is supported by a consistency checker.	dependency grammar;evaluation function;machine learning;shift-reduce parser;spell checker;text corpus;treebank	Ulf Hermjakob	2000			natural language processing;parser combinator;speech recognition;computer science;machine learning;glr parser;programming language	NLP	-22.77851541208378	-77.15402904913118	4272
c24ce843a2244129bff5524561084a728332eeb7	monitoring rural water points in tanzania with mobile phones: the evolution of the sema app		Development professionals have deployed several mobile phone-based ICT (Information and Communications Technology) platforms in the global South for improving water, health, and education services. In this paper, we focus on a mobile phone-based ICT platform for water services, called Sensors, Empowerment and Accountability in Tanzania (SEMA), developed by our team in the context of an action research project in Tanzania. Water users in villages and district water engineers in local governments may use it to monitor the functionality status of rural water points in the country. We describe the current architecture of the platform’s front-end (the SEMA app) and back-end and elaborate on its deployment in four districts in Tanzania. To conceptualize the evolution of the SEMA app, we use three concepts: transaction-intensiveness, discretion and crowdsourcing. The SEMA app effectively digitized only transaction-intensive tasks in the information flow between water users in villages and district water engineers. Further, it resolved two tensions over time: the tension over what to report (by decreasing the discretion of reporters) and over who should report (by constraining the reporting “crowd”).	android;app store;baseline (configuration management);crowdsourcing;downtime;institute for operations research and the management sciences;mobile phone;organizational behavior;requirement;sensor;sociotechnical system;software deployment;software development process;system deployment;traceability;wps office	Rob Lemmens;Juma Hemed Lungo;Yola Georgiadou;Jeroen Verplanke	2017	ISPRS Int. J. Geo-Information	10.3390/ijgi6100316	software deployment;information infrastructure;architecture;mobile phone;water industry;computer security;empowerment;information and communications technology;geography;crowdsourcing	HCI	-67.6750629681527	-0.6188736099088459	4280
666cb59cdb5a9bbcfe066d378713be634d9aa0f0	james bond and michael ovitz: the secret life of agents	agent architecture;agent coordination	As agents populate Cyberspace in their many guises and roles, they coordinate and interact in different ways, spanning self-interested, as well as collaborative interactions. Agent coordination should be supported by an agent’s internal architecture and agent societal frameworks. We take a micro-economic view of coordination. In this talk we report on our work on adaptive agent architecture and the primitive agent behaviors it supports, agent organizations, contracting protocols among agents and presence of middle agents.	agent architecture;cyberspace;file spanning;interaction;population	Katia P. Sycara	1997			agent architecture;computer science;artificial intelligence	AI	-20.546464707431145	-13.418839260736465	4288
b6fe50292e29079f5ad7425a07e60b0c9d611577	addressing social issues with non-linear training programs	social issues;training program		nonlinear system	Albert R. Haugerud;Pattrick O. Chambers	1990	SIGCAS Computers and Society	10.1145/97351.97415	computer science;social issues;management science;sociology;law	AI	-71.36005372381888	-32.88906070711108	4291
824321cd926dc59750f07fb2ad6d4038797b4532	special session 8a: e.j. mccluskey doctoral thesis award semi-final	medical services awards activities educational institutions very large scale integration industries communities europe;reliability;very large scale integration;industries;medical services;awards activities;europe;communities;medical services awards activities very large scale integration industries reliability communities	Named after Prof. E.J. McCluskey, a key contributor to the field of test technology, the 2014 TTTC's Doctoral Thesis Award serves the purpose to i) promote the most impactful doctoral student work, ii) provide the students with the exposure to the community and the prospective employers, and iii) support interaction between academia and industry in the field of test technology. TTTC's E.J. McCluskey Best Doctoral Thesis Award will be given to the winning student of the doctoral student contest and his or her advisor. The award consists of a certificate, an honorarium and an invitation to submit a paper on the presented work to the IEEE Design & Test magazine.	prospective search;semiconductor industry	Michele Portolan;Michail Maniatakos	2014	2014 IEEE 32nd VLSI Test Symposium (VTS)	10.1109/VTS.2014.6818779	engineering management;engineering ethics;engineering;electrical engineering;reliability;very-large-scale integration;statistics	Embedded	-57.84476452931331	-3.330825621633717	4294
e612139611d0e799ed9ecc416c0a05e9dd5e8150	heterogeneity, brokerage, and innovative performance: endogenous formation of collaborative inventor networks	performance;innovation;social networks;endogeneity;brokerage;heterogeneity;mediation effect	In this study, I examine how past performance influences the relative positions of actors in a network and how the actor-level heterogeneity in quality mediates the often-demonstrated association between brokerage and performance. On the collaboration network of U.S. biotech inventors during 1976--1995, I find that inventors with superior track records are more apt to form collaboration ties that enhance brokerage, thereby occupying positions that allow them to broker across network boundaries. Controlling for past performance significantly weakens the positive relationship between brokering position and innovative performance. Furthermore, when inventor-level heterogeneity is controlled for through inventor fixed effects, the position-performance correlation disappears. These findings suggest that, at least for collaborative inventors, actor-level heterogeneity such as performance history largely drives the asymmetry in brokerage, explaining most of the position--performance association.		Jeongsik Jay Lee	2010	Organization Science	10.1287/orsc.1090.0488	public relations;innovation;endogeneity;social science;economics;performance;marketing;heterogeneity;management;social network	Vision	-86.45142609802734	-14.1486649466214	4296
cee72434f914015619152780df86a6523ad36600	ssketch: a scalable sketching technique for pca in the cloud		Multidimensional data appear frequently in many web-related applications, e.g., product ratings, the bag-of-words representation of web pages, etc. Principal Component Analysis (PCA) has been widely used for discovering patterns in relationships among entities in multidimensional data. However, existing algorithms for PCA have limited scalability since they explicitly materialize intermediate data, whose size rapidly grows as the dimension increases. To avoid scalability issues, we propose sSketch, a scalable sketching technique for PCA that employs several optimization ideas, such as mean propagation, efficient sparse matrix operations, and effective job consolidation to minimize intermediate data. Using sSketch, we also provide two other scalable methods for deriving singular value and 2-norm of reconstruction error, both of which are used for data analysis purpose. We provide our implementation on popular Spark framework for distributed platform. We compare our method against state-of-the-art library functions available for distributed settings, namely MLlib-PCA and Mahout-PCA with real big datasets. Our experiments show that our method outperforms both of them by a wide margin. To encourage reproducibility, the source code of sSketch is made publicly available at \hrefhttps://github.com/DataMiningResearch/sSketch https://github.com/DataMiningResearch/sSketch.	algorithm;apache mahout;apache spark;bag-of-words model;cloud computing;entity;experiment;extensibility;margin (machine learning);mathematical optimization;principal component analysis;scalability;semiconductor consolidation;software propagation;sparse matrix;web page	Md. Mehrab Tanjim;Muhammad Abdullah Adnan	2018		10.1145/3159652.3159736	web page;distributed algorithm;data mining;big data;computer science;principal component analysis;scalability;source code;sparse matrix;cloud computing	ML	-8.251280020701868	-43.08346202482607	4297
3f210e56804ebdc2fc767e0f58df39f8751856fb	discriminative multi-domain plda for speaker verification	eer discriminative multidomain plda speaker verification source domain training speaker models application specific target domain domain mismatch training datasets generative modeling discriminative probabilistic linear discriminant analysis multitask learning paradigm jhu domain adaptation challenge dataset dac dataset equal error rate;speaker recognition;speaker recognition multi task learning discriminative training probabilistic linear discriminant analysis;multi task learning;discriminative training;speaker recognition learning artificial intelligence probability;probabilistic linear discriminant analysis;training support vector machines data models adaptation models nist training data	Domain mismatch occurs when data from application-specific target domain is related to, but cannot be viewed as iid samples from the source domain used for training speaker models. Another problem occurs when several training datasets are available but their domains differ. In this case training on simply merged subsets can lead to suboptimal performance. Existing approaches to cope with these problems employ generative modeling and consist of several separate stages such as training and adaptation. In this work we explore a discriminative approach which naturally incorporates both scenarios in a principled way. To this end, we develop a method that can learn across multiple domains by extending discriminative probabilistic linear discriminant analysis (PLDA) according to multi-task learning paradigm. Our results on the recent JHU Domain Adaptation Challenge (DAC) dataset demonstrate that the proposed multi-task PLDA decreases equal error rate (EER) of the PLDA without domain compensation by more than 35% relative and performs comparable to another competitive domain compensation technique.	computer multitasking;computer performance;domain adaptation;enhanced entity–relationship model;generative modelling language;linear discriminant analysis;multi-task learning;programming paradigm;speaker recognition	Alexey Sholokhov;Tomi Kinnunen;Sandro Cumani	2016	2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2016.7472635	speaker recognition;multi-task learning;speech recognition;computer science;machine learning;pattern recognition;discriminative model	Vision	-16.78146032627133	-91.16169637259874	4299
8a7894870242cd44676e1343ae6d06aca8fe1024	is the swedish territorial defence ordinance applicable on the fourth arena?	government policies;legislation;national security;swedish territorial defence ordinance;digital infrastructure;fourth arena;geographic territory;international law;legislative solutions;national law;national legislation;national ordinance;transboundary features;digital territory;violation;internet;water purification;law;force	Like other modern societies, Sweden is highly dependent on its digital infrastructure in order to run vital functions such as electricity, water purification, information and communications. Even though this infrastructure is characterized by transboundary features, it is clearly a part of the Swedish state. In peacetime, the Swedish armed forces are tasked to protect and defend the geographic territory of the state from violations, and the authority to do so is given by the Territorial Defence Ordinance. However, according to the analysis of this paper, the ordinance can not be applied on the digital parts of the society, by the military called “the fourth arena”. Numerous difficulties rises with an application of the ordinance in its present wording and against this background, it is of interest to clarify the present legal situation and suggest a way forward in order to achieve adequate protection on the same premises as the other arenas. The interdependency between national and international law on this matter is pointed out and international law is used to interpret the national ordinance. The conclusion is that the Swedish politicians and legislators' needs to find legal support for the defence of the Swedish digital interests and infrastructure by seeking cooperation and legislative solutions in an international context and by doing so, hopefully the national legislation will follow. The legal challenges faced by Sweden are likely to be similar in several comparable countries, why this discussion should be of interest for other states and held in an international context.	computer;digital asset;interdependence;purification of quantum state	Victoria Ekstedt	2011	2011 3rd International Conference on Cyber Conflict			Visualization	-73.66142273016801	-8.977758300140904	4308
377d9c66b5256ab8feb223f71984fea2329f5e97	the datalex legal workstation: integrating tools for lawyers	expert systems;search engines;legal reasoning;inferencing;text retrieval;datalex;artificial intelligence;hypertext	Computerisation of law has developed from a number of originally unrelated technologies: the development of online free text retrieval systems from the 1960s; the revival of artificial intelligence research in the form of expert systems in the 1970s, the reIated development of automated document generators, and the ‘rediscovery’ of hypertext in the late 1980s 1. Lawyers are interested in the computerisation of a number of different aspects of legal practice, including retrieval of documents relevant to decision-making, other forms of research, the decision-making itself, and the generation of legal documents. We use ‘computerisation of law’ to encompass both the computerisation of these various aspects of legal practice, and of the legal source materials (such as cases, statutes, comment~) used in them.	artificial intelligence;document retrieval;expert system;hypertext;workstation	Graham Greenleaf;Andrew Mowbray;Alan Tyree	1991		10.1145/112646.112673	legal expert system;hypertext;computer science;artificial intelligence;data science;data mining;database;expert system	Web+IR	-57.09416884001416	-19.948132436373065	4309
9a9b372f87df64c9882d7f322a0846818ac74cc6	from p-books to e-books	personal computing	TE R R Y M IU R A The dream of electronic books has been with us at least since Vannevar Bush published his famous article, “As We May Think,” in which he speculated on a desk-sized machine that would hold one’s personal writing and library [1]. Alan Kay named his prototype of the modern PC the Dynabook, and related research has been done at prestigious centers including Xerox PARC, MIT, Bell Labs, and Brown University. I have speculated about e-books and portable devices earlier (see [6, 7]), but am still reading paper books (p-books) because content is abundant and user interaction is simple and subconscious. The idea of an e-book is appealing— a single device with an entire library of interlinked documents, dictionary lookup, unlimited, sharable annotation, search capability, and so forth. But the technology to date has not been good enough to displace the p-book. Is it now? For a first pass at answering that question, I looked at two new e-book devices, the Rocket Ebook (REB) from NuvoMedia (www.nuvomedia.com) and the Softbook (SB) from Softbook Press (www.softbook.com). Both are PC pads with flash RAM storage and backlit, touch-sensitive monochrome screens. The REB is 5” x 7.5” and weighs 22 ounces; the SB is 8.75” x 8.5” and weighs 2.9 pounds. Both are designed solely for reading and annotating documents and have simple user interfaces. The REB has three buttons: on/off, page forward and page backward, and the SB has four buttons: a neat rocker switch for next/previous page plus menu, top-of-document, and devicecontents buttons. If I were an early gadget adopter or traveled a lot, I would own one of these devices. I prefer them to a standard laptop PC for reading. They balance well, have reasonable battery life, are small and light, turn pages fairly thoughtlessly, boot quickly and never display the Windows “blue	as we may think;backlight;book;dictionary;dynabook;e-book;instruction unit;laptop;lookup table;microsoft windows;monochrome monitor;personal digital assistant;principle of good enough;prototype;random-access memory;rocket ebook;sandy bridge;softbook;switch;touchscreen;user interface	Larry Press	2000	Commun. ACM	10.1145/332833.332849	applied mathematics;programming language;computer science	OS	-63.77777280662128	-25.274736727700592	4314
2677f9a9ab485caed3d5c5ac6d0f0f99fc4f5ba5	supporting rapid processing and interactive map-based exploration of streaming news	newsstand;information extraction;text mining;streaming news;semi structured data;database design	The database architecture and system design of NewsStand, a database system that analyzes and displays streaming news using a map user interface, is described. Special emphasis is given to NewsStand's pipe server, which coordinates individual, independent analysis modules in a processing pipeline, and NewsStand's relational database schema, designed to accommodate responsive spatial querying and retrieval via NewsStand's user interface. Examples of these spatial queries, which are variants of top-k window queries, are also presented. Experiments on the live NewsStand database system demonstrate its capability for rapidly processing large amounts of streaming news as well as the interactivity of its map user interface as measured by database querying.	computer;database schema;geographic coordinate system;interactivity;map;relational database;scalability;server (computing);streaming media;systems design;user interface;world wide web	Michael D. Lieberman;Hanan Samet	2012		10.1145/2424321.2424345	text mining;semi-structured data;computer science;data mining;database;world wide web;information extraction;information retrieval;database design	DB	-39.29431425343488	-21.69856322114961	4320
d956f588417a34229cec9926363881218a5e9d23	an excellent resource for parallel computing	parallel computing;vipin kumar parallel computing book review ananth grama anshul gupta george karypis;ananth grama;parallel computer;anshul gupta;george karypis;parallel processing parallel algorithms parallel programming sections concurrent computing algorithm design and analysis books parallel architectures sorting performance analysis;vipin kumar;book review	"""A review of """"Introduction to Parallel Computing, 2nd edition,"""" by Ananth Grama, Anshul Gupta, George Karypis, and Vipin Kumar."""	parallel computing	Helen D. Karatza	2004	IEEE Distributed Systems Online	10.1109/MDSO.2004.12	computer science;artificial intelligence;theoretical computer science	HPC	-50.39364607998487	-4.92822712641589	4322
cb2353f05023facde23006e694623bdf3df95fcd	emotive transforms		Emotional expressivity in singing is examined by comparing neutral and expressive performances of a set of music excerpts as performed by a professional baritone singer. Both the neutral and the expressive versions showed considerable deviations from the nominal description represented by the score. Much of these differences can be accounted for in terms of the application of two basic principles, grouping, i.e. marking of the hierarchical structure, and differentiation, i.e. enhancing the differences between tone categories. The expressive versions differed from the neutral versions with respect to a number of acoustic characteristics. In the expressive versions, the structure and the tone category differences were marked more clearly. Furthermore, the singer emphasized semantically important words in the lyrics in the expressive versions. Comparing the means used by the singer for the purpose of emphasis with those used by a professional actor and voice coach revealed striking similarities.	acoustic cryptanalysis;aphonia;categories;category theory;excerpts;expressive power (computer science);item unique identification;laryngeal prosthesis flushing device,blom-singer in4050;performance;singing;version	Johan Sundberg	2000	Phonetica	10.1159/000028465		Web+IR	-10.091607917471318	-82.44278932946035	4329
9689c3d28b74909a7bb20665d596c117cf051b9f	ieee young professionals activities at icce-berlin [society news]		Reports on CES young professional activities.		Carsten Dolar	2015	IEEE Consumer Electronics Magazine	10.1109/MCE.2014.2361181	multimedia;computer science;young professional	Vision	-64.56535545214275	-11.572300612286126	4343
1e25c4811e377c9f47e311e448377fbb8cfeabda	two simulation applications to outpatient clinics	general practice;ear nose and throat;waiting time;cost effectiveness;technical report;simulation model	This paper describes two applications of simulation modeling for outpatient clinics in a major urban medical center. The first application was developed for the Ear, Nose and Throat (ENT) Clinic where patients first see the physician and; when the physician requires a hearing test to be done immediately before a diagnosis can be made and treatment prescribed, then the patients see an audiologist.The simulation model tested various scheduling policies for scheduling patients for ENT physicians to provide a uniform hearing test load to the audiologists. In the other application, a simulation model was developed for a general practice medical clinic. This model provided results on patient waiting times and utilization levels for resources at different staffing levels and configurations of reception areas, nursing areas and combination office/exam rooms. The experience with the two models indicated that simulation modeling can be of great help in testing various strategies and configurations and thus assisting in the development of efficient and cost-effective outpatient clinics	scheduling (computing);simulation	S. K. Kachhal;Georgia-Ann Klutke;Edward B. Daniels	1981			cost-effectiveness analysis;computer science;technical report;simulation modeling;world wide web	AI	-60.734353803518275	-66.84549493123455	4346
a92d1d18af0bdd708c3e82a5054b308d87e4102c	11th international symposium on autonomous decentralized systems, isads 2013, mexico city, mexico, 6-8 march 2013			autonomous decentralized system		2013				Arch	-51.99560757295809	-7.435466531030408	4350
5ddac9b93d6f84b66efac45634cd7c5315620473	25 tweets to know you: a new model to predict personality with social media		Predicting personality is essential for social applications supporting human-centered activities, yet prior modeling methods with users’ written text require too much input data to be realistically used in the context of social media. In this work, we aim to drastically reduce the data requirement for personality modeling and develop a model that is applicable to most users on Twitter. Our model integrates Word Embedding features with Gaussian Processes regression. Based on the evaluation of over 1.3K users on Twitter, we find that our model achieves comparable or better accuracy than state-of-the-art techniques with 8 times fewer data.	gaussian process;social media;word embedding	Pierre-Hadrien Arnoux;Anbang Xu;Neil Boyette;Jalal Mahmud;Rama Akkiraju;Vibha Sinha	2017			internet privacy;social psychology	NLP	-19.27401184479382	-51.23819364614586	4352
463511b64cd6d6c4e3d3faedb13ad5a00affe1e7	from copyright to access rights? how public policy might shape industry strategies	protection information;edicion;intellectual property;droit auteur;edition;publishing;industria informacion;copyright;information industry;proteccion informacion;information protection;industrie information;propiedad intelectual;propriete intellectuelle;derecho autor	As you gathered from my title, I am a lawyer, and as such normally more concerned with legal rather than strategic issues in publishing. However, because copyright is so important for publishing, legislative changes in the copyright area, even those whose impact may be some years away from national implementation, must influence the strategic thinking of the business strategists among you. As Legal Counsel of the International Publishers’ Association, I am also attending the diplomatic conferences at the World Intellectual Property Organisation WIPO and UNESCO, whenever they deal with copyright and its limitations. And it is at these conferences that I started to observe a trend that goes further than requests for “open access” (addressed in the previous session) – and this trend is the call for legally enshrined rights to access, put forward in particular by developing country representatives, but also by consumer groups. It is this experience that I would like to relate to you today – as in my view, the trend is strong enough to force us lobbyists to amend our lobbying strategy and you, the STM publishers present, perhaps to review aspects of your future business strategy.	access control	Antje Sörensen	2006	Inf. Services and Use		public relations;political science;public administration;management	HCI	-70.67386163304764	-15.860634710581955	4354
23b2a6c80077fa8952655a8be3a9341033bfe2b9	dita: a distributed in-memory trajectory analytics system		Trajectory analytics can benefit many real-world applications, e.g., frequent trajectory based navigation systems, road planning, car pooling, and transportation optimizations. In this paper, we demonstrate a distributed in-memory trajectory analytics system DITA to support large-scale trajectory data analytics. DITA exhibit three unique features. First, DITA supports threshold-based and KNN-based trajectory similarity search and join operations, as well as range queries (i.e., space and time). Second, DITA is versatile to support most existing similarity functions to cater for different analytic purposes and scenarios. Last, DITA is seamlessly integrated into Spark SQL to support easy-to-use SQL and DataFrame API interfaces. Technically, DITA proposes an effective partitioning method, global index and local index, to address the data locality problem. It also devises cost-based techniques to balance the workload, and develops a filter-verification framework for efficient and scalable search and join.	application programming interface;darwin information typing architecture;in-memory database;k-nearest neighbors algorithm;locality of reference;range query (data structures);sql;scalability;similarity search;visual analytics;web analytics	Zeyuan Shang;Guoliang Li;Zhifeng Bao	2018		10.1145/3183713.3193553	workload;computer science;data mining;database;pooling;sql;scalability;range query (data structures);data analysis;nearest neighbor search;analytics	DB	-31.4178512926471	0.46667725478441036	4357
72c453ee759ceb044c174cef587a8d7b1d9068ad	participatory design - introduction to the special section.	participatory design	participatory design		Sarah Kuhn;Michael J. Muller	1993	Commun. ACM	10.1145/153571.255960	computer science	Graphics	-52.559517506010714	-14.461939506482977	4360
9a66349bd076d436827da6ab8d6a911f87c78744	wireless integrated sensor network: boundary intellect system for elephant detection via cognitive theory and fuzzy cognitive maps	human elephant conflict;elephant cognition;fuzzy cognitive maps;wireless integrated sensor network	Human–elephant conflict is a result of habitat loss and fragmentation in forest borders. Wireless sensor networks (WSN) are broadly used to real measure for generation of an early warning against elephant intrusion. The present work proposes a Wireless Integrated Sensor Network (WISN) based boundary intellect system for accurate detection of Elephants. Moreover, the proposed system combines the utilization of three sensors, namely, acoustic sensor, vibration sensor and camera. Acoustic and vibration sensors are enable elephant detection even when they have out of sight while visual identification enabled by camera. The integration of these three sensors along with the cognition theory and Fuzzy Cognitive Map (FCM) increases the novelty of the proposed work. The decision making section is enhanced by FCM and Fuzzy If-Then rules for setting the priority based on performance evaluation. ‘Theory of mind’ is the most appropriate theory for Elephant cognition and inferences various information about elephant depending on the sensors. Acoustic monitoring provides inference on elephant’s behaviour, visual monitoring provides inference on elephant’s motion patterns and vibration monitoring on age and gender classification of elephants. Overall the proposed system has highlights the efficiency in the detection of the presence of the elephant based on the integration of three sensors with the respective ranking scores.	cognitive science;fuzzy cognitive map;intellect	Jerline Sheebha Anni;Arun Kumar Sangaiah	2018	Future Generation Comp. Syst.	10.1016/j.future.2017.02.019	simulation;fuzzy cognitive map;computer science;artificial intelligence	Mobile	-11.61452095683605	-29.054530380427508	4363
1ac2137cb4e1c4ee1687d4144ae51bdc500a01e7	on structure and organization: an organizing principle	organization;hyperstructure;many body systems;binding structure;brunnian structure	We discuss the nature of structure and organization and the process of making new things. Hyperstructures are introduced as binding and organizing principles, and we show how they can transfer from one situation to another. A guiding example is the hyperstructure of higher order Brunnian rings and similarly structured many-body systems.	organizing (structure)	Nils A. Baas	2013	Int. J. General Systems	10.1080/03081079.2012.728406	organization;knowledge management;artificial intelligence;mathematics	NLP	-25.475052337835105	-13.338318815916255	4365
15093f2d367a445011d252cdc4c600c32ef34331	a hybrid intelligent system for the analysis of atmospheric pollution: a case study in two european regions			artificial intelligence;hybrid intelligent system	Ángel Arroyo;Álvaro Herrero;Emilio Corchado;Verónica Tricio	2017	Logic Journal of the IGPL	10.1093/jigpal/jzx050	discrete mathematics;mathematics;machine learning;pollution;hybrid intelligent system;artificial intelligence	AI	-11.258268790646369	-25.82813569946668	4366
9e537dbe152189a2d388dacd3f6ae5576713f05e	embodied sound media technology for the enhancement of the sound presence	sound interface;physical fitness;human movement;social interaction;sound conversion;human motion;assistive technology;social musical interaction;wearable device;embodied sound media;embodied interaction	In this paper, the paradigms of Embodied Sound Media (ESM) technology are described with several case studies. The ESM is designed to formalize a musical sound-space based on the conversion of free human movement into sounds. This technology includes the measurement of human motion, processing, acoustic conversion and output. The first idea was to introduce direct and intuitive sound feedbacks within the context of not only embodied interaction between humans and devices but also social interaction among humans. The developed system is a sort of active aid for an embodied performance that allows the users to get feedback for emotional stimuli in terms of sound surrounding the users. The overviews of several devices developed in this scenario and the potential applications to physical fitness, exercise, entertainment, assistive technology and rehabilitation are also addressed.		Kenji Suzuki	2009		10.1007/978-3-642-02577-8_82	social relation;embodied agent;multimedia;physical fitness	EDA	-52.01497775121678	-45.87844737991556	4367
b111c02bba0e8001336d03536637467269d15329	haptic interaction - science, engineering and design, 2nd international conference, asiahaptics 2016, chiba, japan, november 29 - december 1, 2016			haptic technology		2018		10.1007/978-981-10-4157-0		Robotics	-51.88164936158943	-9.396801220395302	4368
d70b35b04ac750944ff883d0e576f9cb56947ec4	a new era	user experience	I want to remind you that this will be the last printed issue of Queue but also to reassure you that Queue is not going away. As I mentioned in my letter in the last issue, ACM has decided to migrate Queue to the Web. As of July 2008, Queue will expand its publication frequency to 10 issues per year and publish those issues online using the most cutting-edge digital-editions technology available, as well as revamp the existing Queue Web site to provide an overall improved user experience.	aclarubicin;printing;type iii site-specific deoxyribonuclease;user experience;world wide web;edition	James Maurer	1958		10.1145/1394127.1394133	user experience design;simulation;computer science;database;multimedia;world wide web	Web+IR	-62.293957859594116	-19.511136875301794	4370
9d47e357645749b60de845ccc7a24480977f15a2	first ieee international symposium on cluster computing and the grid (ccgrid 2001), may 15-18, 2001, brisbane, australia			computer cluster		2001				Arch	-52.60151618599613	-4.474603358971026	4373
1a8b1f8427a427d2a58ee0a630b6d3bbc5b38b6c	cryptogram decoding for ocr using numerization strings	optical character recognition;cryptography	OCR systems for printed documents typically require large numbers of font styles and character models to work well. When given an unseen font, performance degrades even in the absence of noise. In this paper, we perform OCR in an unsupervised fashion without using any character models by using a cryptogram decoding algorithm. We present results on real and artificial OCR data.	algorithm;cryptogram;optical character recognition;printing	Gary B. Huang;Erik G. Learned-Miller;Andrew McCallum	2007	Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)	10.1109/ICDAR.2007.93	computer vision;speech recognition;computer science;cryptography;pattern recognition;optical character recognition	Robotics	-24.87934409696535	-82.21143095682687	4375
bf51ec55db28ffaabe8c6664b310bfa7272c746c	space symbol detection on complex background using visual context		In this paper, we present a new technique of space symbol detection in the task of monospaced text recognition for credit cardholder name as an example. In the considered case, standard methods fail or have low quality because of background complexity and variability of symbol colors. Suggested method is based on the usage of two conjoined symbol images as an input for artificial neural network. This provides background visual context for the recognizer, which helps it to distinguish between symbols and spaces.	artificial neural network;color;finite-state machine;optical character recognition;spatial variability	Alexander Sheshkus;Vladimir L. Arlazarov	2015		10.7148/2015-0532	computer vision;communication	Robotics	-16.38342826289469	-81.95310131994889	4377
e3b07c2926ccb61d99c742045c11339284cbffbb	detecting temporally redundant association rules	derivative rule change history redundant association rule association rule discovery association rule pruning business data detectable rule change;statistical testing data mining;statistical test;data mining;association rule;association rules history data mining internet pattern analysis intelligent systems intelligent structures testing data analysis relational databases;survey data;statistical testing	"""Methods for association rule discovery and pruning assume implicitly that the associations hidden in the data are stable over time and thus provide a rather static view on data and their underlying structure. This is unrealistic in time-stamped domains, which are standard for real life business data. The question """"which association rules exist?"""" is replaced by """"how do properties of association rules change?"""" In order to cope with the vast number of detectable rule changes, preprocessing techniques are required that find those rules which are root cause to interesting rule changes. The paper proposes an approach based on statistical tests that finds derivative rule change histories and marks the respective rules as redundant. The effectiveness in reducing the number of rule histories is demonstrated using real life survey data."""	algorithm;association rule learning;preprocessor;real life;redundancy (engineering);rule 184;sensor;temporal logic	Mirko Böttcher;Martin Spott;Detlef D. Nauck	2005	Fourth International Conference on Machine Learning and Applications (ICMLA'05)	10.1109/ICMLA.2005.22	statistical hypothesis testing;association rule learning;computer science;data science;machine learning;data mining;k-optimal pattern discovery;statistics	DB	-6.411060838958582	-34.25086063832473	4378
5d0f776d4a3232eca335e1bffaddf2ab1d67c705	design transformations for rule-based procedural modeling		We introduce design transformations for rule-based procedural models, e.g., for buildings and plants. Given two or more procedural designs, each specified by a grammar, a design transformation combines elements of the existing designs to generate new designs. We introduce two technical components to enable design transformations. First, we extend the concept of discrete rule switching to rule merging, leading to a very large shape space for combining procedural models. Second, we propose an algorithm to jointly derive two or more grammars, called grammar co-derivation. We demonstrate two applications of our work: we show that our framework leads to a larger variety of models than previous work, and we show fine-grained transformation sequences between two procedural models.	algorithm;computer graphics;eurographics;john d. wiley;logic programming;mathematical model;procedural modeling	Stefan Lienhard;Cheryl Lau;Pascal Müller;Peter Wonka;Mark Pauly	2017	Comput. Graph. Forum	10.1111/cgf.13105		Graphics	-37.05334551749516	-29.735647349266554	4384
1f04f291f6f2ecab68d97b18861301f586b666b1	inducing word senses to improve web search result clustering	web search	In this paper, we present a novel approach to Web search result clustering based on the automatic discovery of word senses from raw text, a task referred to as Word Sense Induction (WSI). We first acquire the senses (i.e., meanings) of a query by means of a graphbased clustering algorithm that exploits cycles (triangles and squares) in the co-occurrence graph of the query. Then we cluster the search results based on their semantic similarity to the induced word senses. Our experiments, conducted on datasets of ambiguous queries, show that our approach improves search result clustering in terms of both clustering quality and degree of diversification.	algorithm;beagle;cluster analysis;dictionary;diversification (finance);encode;experiment;grams;graph theory;information retrieval;lunar lander (video game series);n-gram;semantic similarity;text corpus;wafer-scale integration;web search engine;word sense;word-sense disambiguation;word-sense induction;wordnet	Roberto Navigli;Giuseppe Crisafulli	2010			natural language processing;correlation clustering;fuzzy clustering;semantic search;computer science;data mining;cluster analysis;web search query;information retrieval	NLP	-26.461841442402747	-65.04917866915652	4388
f1ee3aa79a40c39ac47181b91b61ea159ded2b78	a framework for applying the principles of depth perception to information visualization	depth cues;information visualization;fuzzy logic;depth perception;cue combination	During the visualization of 3D content, using the depth cues selectively to support the design goals and enabling a user to perceive the spatial relationships between the objects are important concerns. In this novel solution, we automate this process by proposing a framework that determines important depth cues for the input scene and the rendering methods to provide these cues. While determining the importance of the cues, we consider the user's tasks and the scene's spatial layout. The importance of each depth cue is calculated using a fuzzy logic--based decision system. Then, suitable rendering methods that provide the important cues are selected by performing a cost-profit analysis on the rendering costs of the methods and their contribution to depth perception. Possible cue conflicts are considered and handled in the system. We also provide formal experimental studies designed for several visualization tasks. A statistical analysis of the experiments verifies the success of our framework.	decision support system;depth perception;experiment;fuzzy logic;information visualization	Zeynep Cipiloglu;Abdullah Bulbul;Tolga K. Çapin	2013	TAP	10.1145/2536764.2536766	computer vision;information visualization;depth perception;computer science;multimedia;optics;communication	Visualization	-32.8068048384708	-36.70773437541317	4390
765973b78a9242f3f9eba3c3eb7a8e6310a5d0ec	a spatial dashboard for alzheimer's disease in new south wales	ageing;dashboard;informatics;spatial;visualisation	This paper illustrates a proof of concept scenario for the application of comprehensive data visualisation methods in the rapidly changing aged care sector. The scenario we explored is population ageing and the dementias with an emphasis on the spatial effects of change over time at the Statistical Area 2 (SA2) level for the state of New South Wales. We did this using a combination of methods, culminating in the use of the Tableau software environment to explore the intersections of demography, epidemiology and their formal cost of care implications. In addition, we briefly illustrate how key infrastructure data can be included in the same data management context by showing how service providers can be integrated and mapped in conjunction with other analyses. This is an innovative and practical approach to some of the complex issues already faced in the health and aged care sectors which can only become more pronounced as population ageing progresses.		Hamish Robertson;Nick Nicholas;Amit Dhagat;Joanne Travaglia	2017	Studies in health technology and informatics	10.3233/978-1-61499-783-2-126	dashboard (business);optometry;disease;medicine	HCI	-58.69818652167742	-60.10310594337011	4394
dfda8c4c5fe70770ba716e08de229ee5f06bf77d	world wide web-course tool: an environment for building www-based courses	electronic mail;computer aided learning;environment;automatic indexing;authoring;world wide web;www education	It is difficult for educators that lack technical background to create sophisticated WWW-based courses. This paper describes Web-CT, an easy-to-use environment for creating WWW-based courses that are otherwise beyond the ability of the non computer programmer. Web-CT not only produces courses for the WWW, but also uses WWW browsers as the GUI for the course-building environment. Web-CT allows the course-author to create a course and then to add a wide variety of tools and features to his or her course. Examples of tools include bulletin-boards, student self-evaluation, navigation tools, timed quizzes, electronic mail, automatic index generation, and more. New features and tools are continually being added to Web-CT.	email;graphical user interface;programmer;www;world wide web	Murray W. Goldberg;Sasan Salari;Paul Swoboda	1996	Computer Networks	10.1016/0169-7552(96)00021-9	human–computer interaction;computer science;multimedia;natural environment;world wide web	Graphics	-66.14205711448759	-41.860597966434824	4395
3fb923022866477a1cabd6697272506c07aee62b	siarct-cfp: improving precision and the discovery of inexact musical patterns in point-set representations	conference	The geometric approach to intra-opus pattern discovery (in which notes are represented as points in pitch-time space in order to discover repeated patterns within a piece of music) shows promise particularly for polyphonic music, but has attracted some criticism because: (1) the approach extends to a limited number of inexact repetition types only; (2) typically geometric pattern discovery algorithms have poor precision, returning many false positives. This paper describes and evaluates a solution to the inexactness problem where algorithms for pattern discovery and inexact pattern matching are integrated for the first time. Two complementary solutions are proposed and assessed for the precision problem, one involving categorisation (hence reduction) of output patterns, and the second involving a new algorithm that calculates the difference between consecutive point pairs, rather than all point pairs.	algorithm;categorization;computers, freedom and privacy conference;pattern matching	Tom Collins;Andreas Arzt;Sebastian Flossmann;Gerhard Widmer	2013			computer science;artificial intelligence;machine learning;mathematics;algorithm;statistics	DB	-42.00531536320564	-63.21304910538953	4398
cce14991ab374b5dd0f25bac6f9ca839b669d162	improved online wilson score interval method for community answer quality ranking		In this paper, a fast and easy-to-deploy method with a strong interpretability for community answer quality ranking is proposed. This method is improved based on the Wilson score interval method [Wilson, 1927], which retains its advantages and simultaneously improve the degree of satisfaction with the ranking of the highquality answers. The improved answer quality score considers both Wilson score interval and the spotlight index, the latter of which will be introduced in the article. This method could significantly improve the ranking of the best answers with high attention in diverse scenarios.	dbpedia;e-commerce;horner's method;taobao marketplace;yahoo! answers	Xin Cao	2018	CoRR		data mining;computer science;quality score;interpretability;ranking	Web+IR	-22.02222270655459	-49.71097279905223	4402
522a7140e8c4377f58aef6c1a34937f2891429d3	the mit encyclopedia of the cognitive sciences, edited by robert wilson and frank keil	cognitive science	The MIT Encyclopedia of the Cognitive Sciences has collected nearly 500 entries on cognitive science, each written by a leading researcher in the field. It is a useful and timely book with many strong points. It will be an essential reference work for any student of the cognitive neuroscience. I have used it to learn, to browse and to teach. The Encyclopedia is available online; this feature is quite helpful and easy to use. In this review I will focus on five entries in the encyclopedia, that bear closest connection with my own work; I found these articles immensely informative. Hauser and Marler’s entry reminds the cognitive scientist of several major findings from animal communication. These include the result from behavioral ecology that although animals communicate, they do not always tell the truth. Furthermore, few animals produce vocalizations that tell others about specific events (see social cognition entry from Cheney and Seyfarth below). Animals do not do what humans do, which is to combine speech elements into an infinite variety of meaningful sounds. Song birds show this recombination ability, but their recombinations lack meaning and are primarily affective signals. Nevertheless, the many common features shared with human language make bird song a great model for communication. Like humans, song birds are superb vocal learners. Both learn their vocal motor behavior early in life, with a strong dependence on hearing both the adults that they will imitate, as well as themselves as they practice. The similarities and differences between human and animal communication described in this entry show that animal models are an essential part of cognitive science. Rauscheker’s review of auditory physiology shows how complex sound stimuli are processed by the auditory system. The brains of animals like frogs, songbirds, owls and bats all show sensitivity to complex sounds. The key is that the complex sounds used in these neurophysiological studies have a clear behavioral context identified in ethological studies. Responses to other mammalian vocalizations (apart from bats), are only beginning to be better understood (e.g., the communication sounds of monkeys). At present, cognitive	browsing;cognitive science;computational neuroscience;ecology;humans;information;natural language;reference work;social cognition;tell-tale	Catherine Carr	2001	Artif. Intell.	10.1016/S0004-3702(01)00095-9	computer science;cognitive science	HCI	-55.01037027235739	-22.999165410255266	4404
8d916d4599e775f2fc64ab0e70f6c8496e8332d7	co-training on authorship attribution with very fewlabeled examples: methods vs. views	authorship attribution;co training;very few labeled examples	Authorship attribution (AA) aims to identify the authors of a set of documents. Traditional studies in this area often assume that there are a large set of labeled documents available for training. However, in the real life, it is hard or expensive to collect a large set of labeled data. For example, in the online review domain, most reviewers (authors) only write a few reviews, which are not enough to serve as the training data for accurate classification. In this paper, we present a novel two-view co-training framework to iteratively identify the authors of a few unlabeled data to augment the training set. The key idea is to first represent each document as several distinct views, and then a co-training technique is adopted to exploit the large amount of unlabeled documents. Starting from 10 training texts per author, we systematically evaluate the effectiveness of co-training for authorship attribution with limited labeled data. Two methods and three views are investigated: logistic regression (LR) and support vector machines (SVM) methods, and character, lexical, and syntactic views. The experimental results show that LR is particularly effective for improving co-training in AA, and the lexical view performs the best among three views when combined with a LR classifier. Furthermore, the co-training framework does not make much difference between one classifier from two views and two classifiers from one view. Instead, it is the learning approach and the view that plays a critical role.	co-training;lr parser;logistic regression;real life;stylometry;support vector machine;test set	Tieyun Qian;Bing Liu;Ming Zhong;Guoliang He	2014		10.1145/2600428.2609470	natural language processing;computer science;artificial intelligence;machine learning;data mining;world wide web;information retrieval	NLP	-20.965171526680074	-66.57285069026302	4408
8fe7bb169e34a337294f04c1ec9c80ed72b2c408	constant connectivity, selective participation: mobile-social interaction of students and faculty	social communication;mobile device;social interaction;social network;iphone;social norm;mobile interaction	"""beyond voice and textual communication, by enabling ubiquitous online connectivity and changing mediated social interaction. We report the results of a study of the mobile-social practices of students who use such devices, and the ways in which hierarchical relationships between students and professors were affected by the use of smart-mobile devices. The common premise is that because such devices enable continuous interaction, students are constantly using social networking and communication applications on the go, across different types of relationships. Our study shows that in hierarchy-based interaction mobile-social communication is more limited than could be expected. Social norms and usability issues both played a part in shaping students' mobile-social practices, resulting in """"selective participation"""" - as students carefully crafted their mobile interaction to maintain hierarchical distance."""	mobile device;mobile interaction;noise shaping;norm (social);smart device;usb on-the-go;usability	Dana Rotman	2010		10.1145/1753846.1754149	social relation;mobile interaction;human–computer interaction;social competence;computer science;mobile device;multimedia;world wide web;social network;norm	HCI	-57.426776033823984	-41.387573839108825	4416
58d0eab47c2a30baf497dc00782b4e9c9780e8ae	collecting high quality overlapping labels at low cost	labeling scheme;relevance labels;overlapping labels;performance improvement;web search;majority voting;learning to rank	This paper studies quality of human labels used to train search engines' rankers. Our specific focus is performance improvements obtained by using overlapping relevance labels, which is by collecting multiple human judgments for each training sample. The paper explores whether, when, and for which samples one should obtain overlapping training labels, as well as how many labels per sample are needed. The proposed selective labeling scheme collects additional labels only for a subset of training samples, specifically for those that are labeled relevant by a judge. Our experiments show that this labeling scheme improves the NDCG of two Web search rankers on several real-world test sets, with a low labeling overhead of around 1.4 labels per sample. This labeling scheme also outperforms several methods of using overlapping labels, such as simple k-overlap, majority vote, the highest labels, etc. Finally, the paper presents a study of how many overlapping labels are needed to get the best improvement in retrieval accuracy.	data quality;display resolution;experiment;overhead (computing);relevance;web search engine	Grace Hui Yang;Anton Mityagin;Krysta Marie Svore;Sergey Markov	2010		10.1145/1835449.1835526	majority rule;computer science;machine learning;data mining;information retrieval;learning to rank	Web+IR	-19.102330618246636	-64.29204710760163	4419
0e3e3c3d8ae5cb7c4636870d69967c197484d3bb	verb semantics and lexical selection	chinese verb;lexical selection problem;correct lexical selection;computer system;verbs semantics;novel representation scheme;transfer-based mt;knowledge-based mt approach;selection restriction;semantic representation;lexical selection;knowledge base;machine translation	This paper will focus on the semantic representation of verbs in computer systems and its impact on lexical selection problems in machine translation (MT). Two groups of English and Chinese verbs are examined to show that lexical selection must be based on interpretation of the sentence as well as selection restrictions placed on the verb arguments. A novel representation scheme is suggested, and is compared to representations with selection restrictions used in transfer-based MT. We see our approach as closely aligned with knowledge-based MT approaches (KBMT), and as a separate component that could be incorporated into existing systems. Examples and experimental results will show that, using this scheme, inexact matches can achieve correct lexical selection.	amiga walker;artificial neural network;cog (project);cognition;columbia (supercomputer);computation;computational linguistics;computer science;coppersmith–winograd algorithm;datr;denotational semantics;dictionary;experimental system;frege–church ontology;generative grammar;generative lexicon;information science;information system;knowledge-based systems;learnability;lexicography;machine translation;natural language processing;natural language understanding;os-tan;p (complexity);parsing;part-of-speech tagging;prototype;recurrent neural network;semantic interpretation;semantic network;simulation;software incompatibility;statistical machine translation;super robot monkey team hyperforce go!;syntactic predicate;the new york times;theory;unicon	Zhibiao Wu;Martha Palmer	1994			natural language processing;lexical density;knowledge base;computer science;linguistics;machine translation	NLP	-29.743672090413053	-79.2947320665837	4432
4fe554e2a143a73a0594d0a6f4b26a8585bc6bcb	segmented and unsegmented dialogue-act annotation with statistical dialogue models	unsegmented dialogue-act annotation;dialogue turn;accurate annotation;correct segmentation;dialogue problem;statistical model;dialogue system;annotation use information;natural language processing;annotation model;statistical dialogue model	Dialogue systems are one of the most challenging applications of Natural Language Processing. In recent years, some statistical dialogue models have been proposed to cope with the dialogue problem. The evaluation of these models is usually performed by using them as annotation models. Many of the works on annotation use information such as the complete sequence of dialogue turns or the correct segmentation of the dialogue. This information is not usually available for dialogue systems. In this work, we propose a statistical model that uses only the information that is usually available and performs the segmentation and annotation at the same time. The results of this model reveal the great influence that the availability of a correct segmentation has in obtaining an accurate annotation of the dialogues.	dialog system;natural language processing;statistical model	Carlos D. Martínez-Hinarejos;Ramón Granell;José-Miguel Benedí	2006		10.3115/1273073.1273146	natural language processing;computer science;data mining	NLP	-23.257753448445587	-78.79521827282173	4435
5fbdb811ddd2492dd96602e180cebf7847c7df25	robot motion algorithm based on interaction with human			algorithm	Yoshikazu Mori;Koji Ota;Tatsuya Nakamura	2002	JRM	10.20965/jrm.2002.p0462	robot;simulation;entrainment (chronobiology);computer vision;boredom;artificial intelligence;computer science	Vision	-35.98277614074252	-39.36890537924586	4437
695724a283c3683a5ddc850a3316eb803b959bdc	annotated bibliography of literature in the field of artificial life.	artificial life			Chris Langton	1987			computer science;artificial intelligence;data science;artificial life	HCI	-51.19053862833996	-19.838945214031344	4439
e01207e0b326aa9d8999710f2cb2e29b79b07b48	leveraging knowledge for innovation in collaborative networks, 10th ifip wg 5.5 working conference on virtual enterprises, pro-ve 2009, thessaloniki, greece, october 7-9, 2009. proceedings	computer communication networks;computers and education;universiteitsbibliotheek;internet computing;community networks;collaborative networks;information system	This book constitutes the refereed proceedings of the 10th IFIP WG 5.5 Working Conference on Virtual Enterprises, PRO-VE 2009, held in Thessaloniki, Greece, in October 2009. The 84 revised papers were selected from numerous submissions. They are organized in topical sections on co-innovation in collaborative networks; collaboration patterns; needs and practices; collaboration in supply chains; teams and collaboration; VO breeding environments modeling; modeling and managing competencies; knowledge management in collaboration; partners selection; e-procurement and collaborative procurement; trust and soft issues in collaboration; processes and decision; management aspects in collaborative networks; performance management; agile business models; service-based systems; formal methods; socio-technical issues in collaboration; collaborative work environments; collaborative networks for active ageing; and collaborative educational networks.	collaborative network;international federation for information processing		2009		10.1007/978-3-642-04568-4	engineering management;engineering;knowledge management;management science	HPC	-64.46286757437294	-3.115799497663246	4440
e6e549bc0dd27d2ec484e68ca9e458900b77697d	what are the determinants of rural-urban digital inequality among schoolchildren in taiwan? insights from blinder-oaxaca decomposition	decomposition;digital inequality;taiwan;schoolchildren	Since digital inequality among schoolchildren may exacerbate the existing rural-urban disparity, determining how to reduce rural-urban digital inequality among students remains an important policy issue. This study uses a unique and nationally representative dataset of 1953 elementary and junior high school students in Taiwan to examine the extent to which students' characteristics, autonomy of use, family background and resource inputs may be associated with the digital self-efficacy of schoolchildren. The Blinder-Oaxaca decomposition method was applied to further investigate the relative contributions the observed characteristics made to the rural-urban digital inequality of schoolchildren. The results show that the observed differences in factors associated with students' digital self-efficacy account for 35% of rural-urban digital inequality. Furthermore, the number of computers in homes and schools, internet connectivity at home, mothers' educational level, and the number of weekly computer classes provided by the school play a significant role with regard to the digital inequality between rural and urban students. We examine digital divide of students between rural and urban areas in Taiwan.The Blinder-Oaxaca decomposition method was utilized.Differences in observed characteristics account for 35% of the digital divide.To increase computer availability can reduce digital divide of students.	oaxaca decomposition;social inequality	Pei-An Liao;Hung-Hao Chang;Jiun-Hao Wang;Lih-Chyun Sun	2016	Computers & Education	10.1016/j.compedu.2016.01.002	mathematics education;simulation;decomposition;pedagogy	HCI	-85.75749949079814	-23.333891246014772	4445
46c1d5c063729b9ee7251929e13b92f13ce23afa	a transformational creativity tool to support chocolate designers	creativity;creativity support system;cognigtive system	A new formulation of combinational, exploratory and transformational creativity is presented.The creativity support system is based on the relationship between appropriateness and relevance.A novel and flavorful combination of chocolate and fruit can be suggested by the creativity support system. A new formulation of the central ideas of Boden's well-established theory on combinational, exploratory and transformational creativity is presented. This new formulation, based on the idea of conceptual space, redefines some terms and includes several types of concept properties (appropriateness and relevance), whose relationship facilitates the computational implementation of the transformational creativity mechanism. The presented formulation is applied to a real case of chocolate designing in which a novel and flavorful combination of chocolate and fruit is generated. The experimentation was conducted jointly with a Spanish chocolate chef. Experimental results prove the relationship between appropriateness and relevance in different frameworks and show that the formulation presented is not only useful for understanding how the creative mechanisms of design works but also facilitates its implementation in real cases to support creativity processes.		Francisco Javier Ruiz;Cristóbal Raya;Albert Samà;Núria Agell	2015	Pattern Recognition Letters	10.1016/j.patrec.2015.05.012	simulation;creativity technique;artificial intelligence;creativity	Vision	-64.0265581013055	-36.038468502735185	4447
0dfffb0530aeb8b55aaa0bc9bf1a5f6f5e017c26	mobile app retrieval for social media users via inference of implicit intent in social media text	implicit intent;mobile app retrieval;app recommendation	"""People often implicitly or explicitly express their needs in social media in the form of """"user status text"""". Such text can be very useful for service providers and product manufacturers to proactively provide relevant services or products that satisfy people's immediate needs. In this paper, we study how to infer a user's intent based on the user's """"status text"""" and retrieve relevant mobile apps that may satisfy the user's needs. We address this problem by framing it as a new entity retrieval task where the query is a user's status text and the entities to be retrieved are mobile apps. We first propose a novel approach that generates a new representation for each query. Our key idea is to leverage social media to build parallel corpora that contain implicit intention text and the corresponding explicit intention text. Specifically, we model various user intentions in social media text using topic models, and we predict user intention in a query that contains implicit intention. Then, we retrieve relevant mobile apps with the predicted user intention. We evaluate the mobile app retrieval task using a new data set we create. Experiment results indicate that the proposed model is effective and outperforms the state-of-the-art retrieval models."""	entity;framing (world wide web);mobile app;parallel text;social media;text corpus;topic model	Dae Hoon Park;Yi Fang;Mengwen Liu;ChengXiang Zhai	2016		10.1145/2983323.2983843	computer science;data mining;database;multimedia;internet privacy;world wide web;information retrieval	Web+IR	-25.82358945740425	-48.718409303006645	4454
2d10885837df470f8b4d1e41f84f09d32b83e005	voice-based person perception: two dimensions and their phonetic properties		This paper proposes a two-dimensional model of voice-based person perception, building on previous findings from social cognition. These two dimensions (warmth or valence and competence or dominance) are compared with two dimensions of animal vocalizations (affective state and size). This two-dimensional model appears compatible with findings from previous studies on vocal stereotypes and visual face trait evaluation.	social cognition	Mihoko Teshigawara	2011			social perception;communication;psychology	HCI	-9.004132149411705	-81.69400451688774	4455
bb21d73e1a9068f34ce546b7e91fc6b7b5124b14	an approach for designing and evaluating a plug-in vision-based tabletop touch identification system	interactive tabletops;user differentiation;design;evaluation	Key functionality for interactive tabletops to provide effective collaboration affordances requires touch identification, where each touch is matched to the right user. This can be valuable to provide adaptive functions, personalisation of content, collaborative gestures and capture of differentiated interaction for real-time or further analysis. While there is increased attention on touch-identification mechanisms, currently there is no developed solution to readily enhance available tabletop hardware to include such functionality. This paper proposes a plug-in system that adds touch identification to a conventional tabletop. It also presents an analysis tool and the design of an evaluation suite to inform application designers of the effectiveness of the system to differentiate users. We illustrate its use by evaluating the solution under a number of conditions of: scalability (number of users); activity density; and multi-touch gestures. Our contributions are: (1) an off-the-shelf system to add user differentiation and tracking to currently available interactive tabletop hardware; and (2) the foundations for systematic assessment of touch identification accuracy for vision-based systems.	interactive media;multi-touch;personalization;plug-in (computing);real-time transcription;scalability	Andrew Clayphan;Roberto Martínez Maldonado;Christopher James Ackad;Judy Kay	2013		10.1145/2541016.2541019	design;simulation;human–computer interaction;evaluation;multimedia	HCI	-45.74968748110423	-39.55074227724224	4457
40c60e124e20da09445b8267f597f2e3d645b811	spectral conversion based on statistical models including time-sequence matching		This paper proposes a spectral conversion technique based on a new statisticalmodel which includes time-sequence matching. In conventional GMM-based approaches, the Dynamic Programming (DP) matching between source and target feature sequences is performed prior to the training of GMMs. Although a similarity measure of two frames, e.g., the Euclid distance is typically adopted, this might be inappropriate for converting the spectral features. The likelihood function of the proposed model can directly deal with two different length sequences, in which a frame alignment of source and target feature sequences is represented by discrete hidden variables. In the proposed algorithm, the maximum likelihood criterion is consistently applied to the training of model parameters, sequence matching and spectral conversion. In the subjective preference test, the proposed method is superior than the conventionalGMM-based method.	algorithm;dynamic programming;euclid;experiment;google map maker;hidden variable theory;similarity measure;statistical model	Yoshihiko Nankaku;Kenichi Nakamura;Tomoki Toda;Keiichi Tokuda	2007			statistics;statistical model;mathematics	Vision	-14.729291214142492	-94.10078598032435	4460
bd85ce20bfb5dfc4adafde3d937c89fe814f564f	digital libraries as learning and teaching support	digital library	For 30 years repeated attempts have been made to use computers to support the teaching and learning process, albeit with only moderate success. Whenever major attempts failed, some seemingly convincing reasons were presented the for less than satisfactory results. In the early days cost or even lack of suitable equipment was blamed; after colour graphics computers started to be widespread, production costs of interactive and graphically appealing material were considered the main culprits; when modern multimedia authoring techniques did not change the situation either, the lack of personalized feed-back, of network support and the di culty of producing high quality simulations were seen as main obstacles. With networks now o ering excellent multimedia presentation and communication facilities the nal breakthrough of computers as ultimate teaching and learning tool is (once more) predicted. And once more results will be disappointing if one crucial component is again overlooked: good courseware must give both guidance to students but also provide a rich variety of background material whenever such is needed. It is the main claim of this paper that the advent of sizeable digital libraries provides one of the most signi cant chances for computer based training ever. We will argue that such libraries not only allow the e cient production of courseware but also provide the extensive background reservoir of material needed in many situations.	computer;digital library;display resolution;failure;feedback;graphics;library (computing);personalization;simulation	Hermann A. Maurer;Jennifer Lennon	1995	J. UCS	10.3217/jucs-001-11-0719	educational technology;computer science;teaching and learning center;multimedia	Web+IR	-78.19084456845827	-36.939939946069	4462
4927383334f13fffac4dc1b61b9c2ae3cd031e37	informatics application provides instant research to practice benefits.	quality of life;outcome and process assessment health care;long term care;data collection;internet;frail elderly;abstracting and indexing as topic;medical informatics applications;databases as topic;humans;aged	A web-based research information system was designed to enable our research team to efficiently measure health related quality of life among frail older adults in a variety of health care settings (home care, nursing homes, assisted living, PACE). The structure, process, and outcome data is collected using laptop computers and downloaded to a SQL database. Unique features of this project are the ability to transfer research to practice by instantly sharing individual and aggregate results with the clinicians caring for these elders and directly impacting the quality of their care. Clinicians can also dial in to the database to access standard queries or receive customized reports about the patients in their facilities. This paper will describe the development and implementation of the information system. The conference presentation will include a demonstration and examples of research to practice benefits.		Kathryn H. Bowles;Tao Peng;Rongrong Qian;Mary D. Naylor	2001	Proceedings. AMIA Symposium		medicine;knowledge management;data science;data mining	HCI	-58.026692499876525	-63.43118999908326	4465
d814646369ff4d7ad13e0404209af003ce7a3289	editor-in-chief's note - i2mtc 2009 special issue		The 57 papers in this special issue are extended versions of papers presented at the 2009 International Instrumentation and Measurement Technology Conference (I MTC 2009), held in Singapore, May 5-7, 2009.	comparison of relational database management systems	R. Zoughi	2010	IEEE Trans. Instrumentation and Measurement	10.1109/TIM.2010.2044006		Embedded	-57.852429692930095	-14.146222823116243	4469
85e9a391aa9269de3fd187ecd09d385d315e176a	robots learning from experiences (dagstuhl seminar 14081)	004;learning experiences cognitive systems	"""This report documents the programme and the outcomes of Dagstuhl Seminar 14081 """"Robots Learning from Experiences"""". The report begins with a summary comprising information about the seminar topics, the programme, important discussion points, and conclusions. The main body of the report consists of the abstracts of 25 presentations given at the seminar, and of four reports about discussion groups."""		Anthony G. Cohn;Bernd Neumann;Alessandro Saffiotti;Markus Vincze	2014	Dagstuhl Reports	10.4230/DagRep.4.2.79	mathematics education;library science;computer science;multimedia	HCI	-78.13600082393107	-32.421256365424426	4470
d909c464aaecb658b72f1e7f0e084d5a2d3339d3	analyzing trust perceptions in system implementations	trust;implementation;modernity;giddens;abstract systems	Implementations of large scale information systems are complex and problematic with a reputation for being delayed and going over budget. A critical factor in the success of these implementations is trust in the system, in the project and between the various stakeholders. As problems and delays mount, trust relations become strained, leading to a circle of suspicion and disbelief which is both destructive and hard to break out of. This case study analyses trust relations during a problematic period of time in the implementation of the Faroese integrated healthcare information system, using a framework based on Giddens ́ theory of modernity. The framework theorizes dynamic elements of the evolution of trust, not previously investigated in this context. The data collection involves 4 actors interviewed twice in 2006 and 2007; and the data analysis strategy is content analysis using Nvivo software. A major contribution is that if an implementation project interacts with many or complex abstract systems, the managers must focus on continuous embedding and reembedding by interacting directly with representatives of the abstract systems in question to maintain trust. Also we observe that actors’ perceptions of trust relations influence future actions, and in this way have both negative and positive consequences. We also conclude that Giddens’ theories of trust provide a promising insight into the dynamic aspects of trust relations in implementation projects, which go further than trust theories currently used in the IS field.	causality;distrust;enterprise system;information system;interaction;limbo;theory;trust metric	Bjarne Rerup Schlichter;Jeremy Rose	2009			public relations;political science;management;social psychology;computational trust	Security	-83.90352732184837	-3.2386138209468434	4471
0318d9f24745bb654b1c1743b10cefa69e29862f	improved character-based chinese dependency parsing by using stack-tree lstm		Almost all the state-of-the-art methods for Character-based Chinese dependency parsing ignore the complete dependency subtree information built during the parsing process, which is crucial for parsing the rest part of the sentence. In this paper, we introduce a novel neural network architecture to capture dependency subtree feature. We extend and improve recent works in neural joint model for Chinese word segmentation, POS tagging and dependency parsing, and adopt bidirectional LSTM to learn n-gram feature representation and context information. The neural network and bidirectional LSTMs are trained jointly with the parser objective, resulting in very effective feature extractors for parsing. Finally, we conduct experiments on Penn Chinese Treebank 5, and demonstrate the effectiveness of the approach by applying it to a greedy transition-based parser. The results show that our model outperforms the state-of-the-art neural joint models in Chinese word segmentation, POS tagging and dependency parsing.	binary tree;long short-term memory;parsing	Hang Liu;Mingtong Liu;Yujie Zhang;Jinan Xu;Yufeng Chen	2018		10.1007/978-3-319-99501-4_17	parsing;tree (data structure);architecture;dependency grammar;artificial neural network;treebank;artificial intelligence;sentence;text segmentation;pattern recognition;computer science	NLP	-18.723611430679945	-73.55101663598788	4475
1af57017a3cccdf7b1fa3dd726c8cb022229794e	context-aware and adaptive usage control model	u learning system;ccapl;art;u learning;context aware;thesis or dissertation;school and learning;councellor;technology;social sciences;formal methods;pervasive system;enforcement;natural;travel;ubicomp;law;computer security;usage control model;usage control;cca;computer sciences;humanities;adaptive systems;365983646x;ubiquitous learning;adaptation;medical;calculus of context aware ambients;9783659836466;specialised book;context aware and adaptive usage control model;fiction;economics;other;book;children and youth books;context aware systems;978 3 659 83646 6;music;specialized book	Information protection is a key issue for the acceptance and adoption of pervasive computing systems where various portable devices such as smart phones, Personal Digital Assistants (PDAs) and laptop computers are being used to share information and to access digital resources via wireless connection to the Internet. Because these are resources constrained devices and highly mobile, changes in the environmental context or device context can affect the security of the system a great deal. A proper security mechanism must be put in place which is able to cope with changing environmental and system context. Usage CONtrol (UCON) model is the latest major enhancement of the traditional access control models which enables mutability of subject and object attributes, and continuity of control on usage of resources. In UCON, access permission decision is based on three factors: authorisations, obligations and conditions. While authorisations and obligations are requirements that must be fulfilled by the subject and the object, conditions are subject and object independent requirements that must be satisfied by the environment. As a consequence, access permission may be revoked (and the access stopped) as a result of changes in the environment regardless of whether the authorisations and obligations requirements are met. This constitutes a major shortcoming of the UCON model in pervasive computing systems which constantly strive to adapt to environmental changes so as to minimise disruptions to the user.	access control;ccir system a;computer;graphics device interface;immutable object;internet;laptop;personal digital assistant;requirement;scott continuity;smartphone;ubiquitous computing	Abdulgader Almutairi	2013			simulation;computer science;knowledge management;multimedia	HCI	-64.84997624788548	-29.297167836288743	4478
9e2cfca6f47bf81b80f4b71a85c9c7bd5200d2c7	ten years of cybertech: the educational benefits of bullfighting robotics	control engineering education;robot sensing systems;college instruction;competition;information technology;student projects;robotics;instructional design;learning processes;team working;computer science education;foreign countries;innovation management;upm;educational courses;robots;conferences education europe robot sensing systems mobile communication;engineering education;mobile communication;innovation educational benefits bullfighting robotics cybertech robotics competition innovative educational experience engineering teaching universidad politecnica de madrid upm robotic contest robotaurus bullfighting academic activity spanning theory laboratory practical lessons seminars tutoring spectacular contest educational approach student motivation teamwork oral presentations budget management;robotics workshop education interdisciplinary curricula robotics contest;instructional effectiveness;europe;robotics contest;instructional innovation;interdisciplinary approach;group activities;teaching methods;team working control engineering education educational courses innovation management robots teaching;educational benefits;program descriptions;conferences;interdisciplinary curricula;undergraduate students;program effectiveness;robotics workshop;teaching	After 10 years of organizing the Cybertech robotics competition, this paper presents this unique and innovative educational experience of teaching engineering at Universidad Politécnica de Madrid (UPM), Spain. Cybertech is not only a well-known robotic contest in Spain due to the Robotaurus bullfighting, but is also a whole academic activity spanning theory, laboratory practical lessons, seminars, tutoring, and a spectacular contest in which robots, developed by the students, compete. It is an open activity, for all students and grades, requiring knowledge of various subjects such as mechanics, microcontrollers, control, and electronics. The experience acquired has shown how this novel educational approach can boost the motivation of students, who in a real applied project effectively learn not only the particular subject matter, but also skills in teamwork, oral presentations, budget management, and so on. This is considered the flagship of innovation in education at UPM. This paper describes the evolution of Cybertech over the past 10 years, summarizes the educational experience, and provides some statistics and results as well as a perspective for future editions of the competition.	file spanning;game mechanics;microcontroller;organizing (structure);robot;robotics;subject matter expert turing test	Miguel Hernando;Ramón Galán;Iñaki Navarro;Diego Rodríguez-Losada	2011	IEEE Transactions on Education	10.1109/TE.2010.2095014	robot;simulation;competition;engineering education;mobile telephony;innovation management;computer science;engineering;knowledge management;electrical engineering;artificial intelligence;teaching method;instructional design;robotics;information technology	Robotics	-78.30221749405864	-33.50412420380196	4483
5f1bb6250944112deaba725aafa68578c87b0bed	aesthetics of urban media façades	media facades;design methods;aesthetics;ambient media;urban screens	This paper sets out to develop and extend current literature on design practices for ambient media façades. It does this by bringing together theories of ambient media, computational aesthetics, and urban aesthetics. This unique theoretical combination has informed the design of several exemplars produced by the author, which are discussed as case studies.	theory	Gavin Sade	2014		10.1145/2682884.2682887	visual arts;art;aesthetics;multimedia	HCI	-59.57211874468686	-36.85284434327602	4494
fe12676114cc356f5eab05733a1247b595f9fa08	new approach for aggregating multi-sensory data	objet;agregacion;funcion utilidad;fonction utilite;utility function;object;robotics;aggregation;teoria decision;captador medida;measurement sensor;capteur mesure;theorie decision;decision theory;pattern recognition;agregation;robotica;robotique;reconnaissance forme;theorie information;reconocimiento patron;multiple;objeto;information theory;teoria informacion	Abstract#R##N##R##N#The task of sensory data fusion may involve the aggregation of sensory measurements that may be from different phenomenological domains and that, in many cases, could embrace some conflicting information cues. It is rather a challenge to find suitable strategies by which measurements obtained by the different sensors of the system can be aggregated so that a consistent interpretation of these measurements is achieved. In this article, we present a novel approach to achieve this goal. A recursive group utility function that is capable of bringing the group of sensors into consensus is used. After each sensor in the group gathers information relevant to the sensory task, the group engages in what we call the uncertainty estimation stage. This is an information theorybased process that allows each sensor to assess its self-uncertainty and the conditional uncertainties of other sensors. This process facilitates the computation of a weighting scheme that operates recursively on sensor observations until the group reaches a consensus. Whenever new observations are made, the uncertainty estimates of sensors are updated and used to compute a new weighting scheme. To demonstrate the efficacy and to show how the methodology works, the article discusses how the method can be used to tackle the multi-sensor object identification problem. © 1993 John Wiley & Sons, Inc.		Otman A. Basir;Helen C. Shen	1993	J. Field Robotics	10.1002/rob.4620100805	decision theory;information theory;computer science;artificial intelligence;object;robotics;operations research;algorithm;multiple	Robotics	-20.983950277683434	-2.8391306479744505	4495
96352853dff6853afb57f7693d82fbbf17fa416a	rapid adaptation of n-gram language models using inter-word correlation for speech recognition	language model;speech recognition	In this paper, we study the fast adaptation problem of n-gram language model under the MAP estimation framework. We have proposed a heuristic method to explore inter-word correlation to accelerate MAP adaptation of n-gram model. According to their correlations, the occurrence of one word can be used to predict all other words in adaptation text. In this way, a large n-gram model can be efficiently adapted with a small amount of adaptation data. The proposed fast adaptation approach is evaluated in a Japanese newspaper corpus. We have observed a significant perplexity reduction even when we have only several hundred adaptation sentences.	heuristic;language model;n-gram;perplexity;speech recognition	Koki Sasaki;Hui Jiang;Keikichi Hirose	2000			artificial intelligence;n-gram;speech recognition;speaker recognition;pattern recognition;acoustic model;speech corpus;language model;trace (psycholinguistics);computer science	NLP	-19.84223338846321	-85.0531695524469	4498
6f93b86a6e3910b8552c3982cd08e8c751b6e7fa	nlm tele-educational application for radiologists to interpret mammography		The goal of this study was to provide unique tools for an educational program to improve the skills, namely consistency and accuracy, of radiology residents who interpret digital mammograms. The tele-educational tools, created at UNC, will be implemented locally and connected to the National Digital Mammography Archive (NDMA) through the Next Generation Internet (NGI). This application includes an annotation tool, as well as a teaching and testing tool. The annotation tool will allow radiologists to label all imaging findings including the specific location information in mammograms, and make lesion diagnosis based on pathology reports. The teaching tool will allow teachers to demonstrate cases of specific types and diagnoses. Trainees themselves will also be able to use the teaching tool for reviewing of cases of types of their choosing. Our testing tool can test radiology residents inverted exclamation mark performance in interpreting digital mammograms, and provides them detailed performance test results, such as, sensitivity, specificity, ROC curves, AUC values, etc. A local Oracle database was designed and implemented at UNC to support those tools. We developed a method to map information of cases from the local database to DICOM Structure Reports by using XML techniques.	area under curve;dicom;digital archive;dimethylnitrosamine;mammography;national library of medicine (u.s.);netware loadable module;next generation identification;oracle database;roc curve;radiology;review [publication type];sensitivity and specificity;telephone number;television;test automation;united states national institutes of health;xml;pathology report	Min Wu;Yuanshui Zheng;Michael North;Etta D. Pisano	2002	Proceedings. AMIA Symposium		medical diagnosis;oracle;information retrieval;the internet;multimedia;digital mammography;teleradiology;dicom;mammography;annotation;medicine	SE	-56.40285565091833	-66.4795265807328	4500
9e4a17124ebd2709b4261bae611eababef9c0634	aligning your warring tribes: the art of managing web site globalization projects				Simon Laight	2004			globalization;knowledge management;engineering	HCI	-69.97777220478613	0.2723099818425754	4503
48f5c8d75e3abd3d3547b19a1d797adaeb7c61cf	when the public has a right to know: using toulmin's method to protect sensitive information on government websites		Publicly accessible U.S. government websites often provide sensitive information that can be abused by terrorists. For example they may provide extensive information on a region’s nuclear power plants or water supply systems or emergency preparedness. It is possible for terrorists and other malcontents to use such information to identify ‘soft targets’. However, due to laws such as the Freedom of Information Act, and also due to precedent, the government cannot simply choose not to provide much of this information. This calls for a mechanism whereby the government may be able to intelligently control the dissemination of information so as to reduce the probability of sensitive information falling into the wrong hands. In particular, the government needs a system to analyze and assess the legitimacy of claims to information. This paper proposes an agent-based framework that has the potential to allow the government to control, in an intelligent fashion, the dissemination of sensitive information via government websites. This framework employs the ‘Toulmin method for analyzing arguments’ to assess the legitimacy of claims to information on government websites.		Abhijit Jain	2006			public relations;business;internet privacy;computer security	AI	-71.9876130342329	-9.45418920332245	4508
fcd87d7b8cdcf6e55a049d4716c54e41da2bdb1b	effects of individuals' locus of control and computer self-efficacy on their e-learning acceptance in high-tech companies	electronic learning;perceived ease of use;electronic learning e learning;personality;locus of control;e learning system;technology acceptance model;work environment;global economy;computer self efficacy;individual difference;review;user acceptance;perceived usefulness	Effects of individuals' locus of control and computer self-efficacy on their e-learning acceptance in hightech companies Jung-Wen Hsia, Chia-Chi Chang & Ai-Hua Tseng a Department of International Business, Chung Hua University, Hsinchu, Taiwan b Department of Management Science, National Chiao Tung University, Hsinchu, Taiwan c Center for General Education, Chung Hua University, Hsinchu, Taiwan Accepted author version posted online: 13 Jun 2012.Published online: 12 Jul 2012.	chi;coefficient;flaw hypothesis methodology;futures studies;game demo;higgins;ibm tivoli access manager;locus;management science;nl (complexity);numerical aperture;performance rating;snapshot (computer storage);technical support;thatcher effect;usability	Jung-Wen Hsia;Chi-Ching Chang;Ai-Hua Tseng	2014	Behaviour & IT	10.1080/0144929X.2012.702284	psychology;simulation;knowledge management;locus of control;personality;management;social psychology		-62.565657632157226	-5.384219028115477	4510
c38844257d21b468addbf8e74ddeaf4932b35df3	special issue on online communities and social network: an editorial introduction	online community;social network		online community;social network	Wenjing Duan	2009	Decision Support Systems	10.1016/j.dss.2009.02.010	computer science;social network;online participation	AI	-65.57673176276924	-9.61416210691336	4523
4d51a4eb2f006be641c51500fa50762d127aa1fc	the waw corpus: the first corpus of interpreted speeches and their translations for english and arabic		This article presents the WAW Corpus, an interpreting corpus for English/Arabic, which can be used for teaching interpreters, studying the characteristics of interpreters’ work, as well as to train machine translation systems. The corpus contains recordings of lectures and speeches from international conferences, their interpretations, the transcripts of the original speeches and of their interpretations, as well as human translations of both kinds of transcripts into the opposite language of the language pair. The article presents the corpus curation, statistics, assessment, as well as a case study of the corpus use.	dvb-s2;digital curation;machine translation;speech recognition;text corpus	Ahmed Abdelali;Irina P. Temnikova;Samy Hedaya;Stephan Vogel	2018			artificial intelligence;natural language processing;arabic;computer science;annotation	NLP	-31.68633027480543	-77.91260834915016	4524
f129807d2567e82528b7e806feb40207b9e79bc2	the development and preliminary application ofplant quarantine remote teaching system inchina	design and development;information technology;teaching assistant;system development	With the development of modern information technology, the traditional teaching mode becomes more deficient for the requirement of modern education. Plant Quarantine has been accepted as the common course for the universities of agriculture in China after the entry of WTO. But the teaching resources of this course are not enough especially for most universities with lack base. The characteristic of e-learning is regarded as one way to solve the problem of short teaching resource. PQRTS (Plant Quarantine Remote Teaching System) was designed and developed with JSP (Java Sever Pages), MySQL and Tomcat in this study. The system included many kinds of plant quarantine teaching resources, such as international glossary, regulations and standards, multimedia information of quarantine process and pests, ppt files of teaching, and training exercise. The system prototype implemented the functions of remote learning, querying, management, examination and remote discussion. It could be a tool for teaching, teaching assistance and learning online.	application programming interface	Zhigang Wu;Zhihong Li;Ding Yang;Guozhen Zhang	2008		10.1007/978-1-4419-0213-9_41	simulation;engineering;biological engineering;computer engineering	Theory	-84.32806825703555	-42.73969306449724	4525
7a3e0db7ee21d0955492d7e39271848041fd0745	guest editors' introduction: rapid prototyping in software development			rapid prototyping;software development	Murat M. Tanik;Raymond T. Yeh	1989	IEEE Computer	10.1109/MC.1989.10055	computer science;software engineering;software development;rapid prototyping	Visualization	-54.16808743622899	-0.8724446960943392	4526
68d2d57537ee8de61e311002c1e1fedb525f0cbf	intelligent query formulation for mobile visual search	mobile visual search;query formulation;mobile location recognition;visual search;on the fly;content based image retrieval	While much progress is being made in mobile visual search, most efforts are on how to improve search performance (precision, recall, speed) given queries. How to help the user form a good query has generally left unexplored. Successful mobile search should keep users in the loop and have the machine and user work closely as a team to solve the difficult problem - user provide fast feedback on the fly and machine does the data intensive analysis. Therefore, helping the user to form a good query has a great potential in improving the search performance. We describe a novel framework, Active Query Sensing, to provide interactive query formulation solutions for mobile location search. We also discuss new research directions addressing the important open issues of interactive query formulation for mobile visual search.	data-intensive computing;on the fly	Felix X. Yu	2011		10.1145/2072298.2072494	beam search;online aggregation;sargable;query optimization;query expansion;web query classification;mobile search;ranking;visual search;computer science;concept search;data mining;web search query;world wide web;information retrieval;query language;search engine	HCI	-33.57706283554212	2.4969136744885874	4527
32defbcee9970f248153552a59b1bd605cb3282a	challenges of human behavior understanding	universiteitsbibliotheek;qa75 electronic computers computer science;bf psychology	Recent advances in pattern recognition has allowed computer scientists and psychologists to jointly address automatic analysis of of human behavior via computers. The Workshop on Human Behavior Understanding at the International Conference on Pattern Recognition explores a number of different aspects and open questions in this field, and demonstrates the multi-disciplinary nature of this research area. In this brief summary, we give an overview of the Workshop and discuss the main research challenges.	computer scientist;pattern recognition	Albert Ali Salah;Theo Gevers;Nicu Sebe;Alessandro Vinciarelli	2010		10.1007/978-3-642-14715-9_1	human–computer interaction;computer science;artificial intelligence;management science	Vision	-55.272362505500986	-20.63880187245542	4528
db721cd2e77e752e6ea803b331b1c143a556ad08	rigid structures, independent units, monitoring: organizing patterns in frontline firefighting	design process;ethnography;conceptual understanding;user study;pattern research;qualitative analysis;work environment;safety critical work;firefighting;ubiquitous computing	Providing firefighters working on the frontline of interventions with ubiquitous computing support remains an open challenge. Designing meaningful solutions for this complex work environment requires reflective thought and conceptual understanding of its social configuration. This paper presents organizing patterns of firefighting frontline practice as a means to inform ubiquitous computing design processes. The patterns originate from a qualitative analysis of an extensive range of user studies conducted with French and German firefighters. As the patterns show, firefighting on the frontline is based on a rigid structure that gains its flexibility through independent units whose safety is ensured by a number of monitoring activities. We conclude that the interaction between the presented patterns forms a balanced whole and needs to be recognized by ubiquitous computing design.	organizing (structure);ubiquitous computing;usability testing	Sebastian Denef;David V. Keyson;Reinhard Oppermann	2011		10.1145/1978942.1979225	simulation;design process;human–computer interaction;computer science;qualitative research;ethnography;ubiquitous computing;firefighting	HCI	-60.57770323672104	-40.53290367483556	4529
f5950325690b6017f5c2bc3b35ccd6ef8a50d544	human-computer agent negotiation using cross culture reliability models		People’s cultural background has been shown to affect the way they reach agreements in negotiation and how they fulfill these agreements. This paper presents a novel methodology that can be used as a good infrastructure to design a computer-agent for negotiating with people from different cultures. Our setting involved data from different agents and human versus human data that were based on an alternating-offer protocol that allowed parties to choose the extent to which they kept each of their agreements during the negotiation. A challenge to develop this methodology for such setting is to create cross culture models automatically that will predict how people reciprocate their actions over time, despite the scarcity of prior data on different cultures. Our methodology addresses this challenge by using a Leave-One-Out algorithm named CCMA, which is described in Sect. 5, with classical machine learning algorithms to predict the extent to which people fulfill agreements. Our methodology based its strategy on a data from different agents that used the same negotiation scenario in different cultures. This methodology used data in three countries: Lebanon, the U.S.A and Israel, in which people are known to vary widely in their negotiation behaviour. Our methodology was able to find the accurate models that should be used when designing a computer-agent in the negotiation scenario.	software agent	Galit Haim;Dor Nisim;Marian Tsatkin	2016		10.1007/978-3-319-57285-7_8	management science;scarcity;negotiation;software agent;business	NLP	-10.450749655942971	-11.065022283733445	4541
aaa583248e9d62f073797dd2fcbb6a8a6bc72637	comparison of peer and citation assessment of the influence of scientific journals	comparative analysis;sciences;scientists;scholarly journals;influences;citations references;surveys	Abstract#R##N##R##N#A survey was undertaken to ascertain the extent of agreement between scientists' subjective assessment of the average influence per article for articles in 58 different scientific journals, when compared with corresponding citation influence ratings for articles in the same journals. The scientists' assessments were derived from questionnaires sent to faculty at 97 American universities covering journals in ten different research fields. A strong positive relationship was found to exist between the scientists' assessment of journal influence and the citation influence ratings, with product-moment and Spearman rank correlations in the 0.7–0.9 range for seven of the ten fields.		Paul R. McAllister;Richard C. Anderson;Francis Narin	1980	JASIS	10.1002/asi.4630310304	qualitative comparative analysis;social science;data science;information retrieval	HPC	-77.88703851396409	-21.281636828567933	4542
571b9b63683e276a2ac1aeff82a64cfc4d03917d	ethically situated information systems development.	information system development			Trevor Wood-Harper;Steve Corder;B. Byrne;Jim Hughes	1999	Australian Computer Journal		computer science;knowledge management	HCI	-68.56214298308518	1.5435821608260698	4548
525e634abea1a4e16a532f5d098b2b6f13383d64	extending the campus network: bringing data connectivity and cable television to the residence halls	campus network;cable television;residence hall;data connectivity	At Tulane University, acquisition of funding to extend the campus network and bring cable television into, the residence halls was viewed as an opportunity to integrate residence hall programming with the academic program of the university. Today, every dormitory resident can connect to the campus network backbone to use Tulane’s shared computer systems and to access information around the world on the Internet. In addition, each dormitory resident can plug into a campus cable system that provides campus programming, satellite broadcasts, and curriculum-related programming, as well as the popular channels generally associated with cable television systems. Providing these services required extensive plimning with respect to the logistics of bringing the networlc to multiple disjoint buildings, topology selection, software distribution, and cable channel selection. The addition of these services presents new management challenges to Computing Services. In this paper, we discuss the background, planning, and logistics of bringing cable television and data connectivity to Tulane’s dormitory residents, as well as the new issues and opportunities that arose as a result of this project. Discussion includes administrative, technical, and support issues, ranging from funding decisions to planning and support considerations. The management of campus video programming and new services will also be discussed.	internet backbone;logistics;software distribution	Cliff Woodruff;Thomas A. Gerace	1994		10.1145/196355.196534	telecommunications;computer science;world wide web;computer network	HCI	-69.56873649310347	-24.44021343378166	4557
a184f6c1374f0b4330bb63d57265765c2440473c	learning the communication of intent prior to physical collaboration	learning;receivers robots humans feature extraction decision trees;human robot interaction;robot vision;robot vision human robot interaction learning artificial intelligence pose estimation;learning artificial intelligence;pose estimation;human robot interaction intent communication physical collaboration tasks picnic basket gaze speech gestures movement posture discriminative features machine learning techniques multichannel vision pose data instrumented kitchen prehandover communication inter personal distance	When performing physical collaboration tasks, like packing a picnic basket together, humans communicate strongly and often subtly via multiple channels like gaze, speech, gestures, movement and posture. Understanding and participating in this communication enables us to predict a physical action rather than react to it, producing seamless collaboration. In this paper, we automatically learn key discriminative features that predict the intent to handover an object using machine learning techniques. We train and test our algorithm on multi-channel vision and pose data collected from an extensive user study in an instrumented kitchen. Our algorithm outputs a tree of possibilities, automatically encoding various types of pre-handover communication. A surprising outcome is that mutual gaze and inter-personal distance, often cited as being key for interaction, were not key discriminative features. Finally, we discuss the immediate and future impact of this work for human-robot interaction.	algorithm;human–robot interaction;machine learning;poor posture;seamless3d;set packing;usability testing	Kyle Strabala;Min Kyung Lee;Anca D. Dragan;Jodi Forlizzi;Siddhartha S. Srinivasa	2012	2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication	10.1109/ROMAN.2012.6343875	human–robot interaction;robot learning;computer vision;simulation;pose;computer science;artificial intelligence	Robotics	-50.67022027969997	-49.00332946414802	4559
538eef364dfa0ab8a914f91cbb7b68212e3d47b3	tango or waltz?: putting ballroom dance style into tempo detection	signal image and speech processing;acoustics;mathematics in music;engineering acoustics	Rhythmic information plays an important role in Music Information Retrieval. Example applications include automatically annotating large databases by genre, meter, ballroom dance style or tempo, fully automated D.J.-ing, and audio segmentation for further retrieval tasks such as automatic chord labeling. In this article, we therefore provide an introductory overview over basic and current principles of tempo detection. Subsequently, we show how to improve on these by inclusion of ballroom dance style recognition. We introduce a feature set of 82 rhythmic features for rhythm analysis on real audio. With this set, data-driven identification of the meter and ballroom dance style, employing support vector machines, is carried out in a first step. Next, this information is used to more robustly detect tempo. We evaluate the suggested method on a large public database containing 1.8 k titles of standard and Latin ballroom dance music. Following extensive test runs, a clear boost in performance can be reported.	database;information retrieval;sequence labeling;support vector machine;tango	Björn W. Schuller;Florian Eyben;Gerhard Rigoll	2008	EURASIP J. Audio, Speech and Music Processing	10.1155/2008/846135	speech recognition;acoustics;computer science;multimedia;physics	Web+IR	-35.20394862530234	-73.21212988836947	4560
5ba0c039c38534a34d10fbac307c8ff419721bd9	soft skills: an important asset acquired from organizing regional student group activities	social communication;social networking;graduates;careers;leadership;scientists;reward;humans;human learning;computational biology;africa;social skills;students;jobs	Contributing to a student organization, such as the International Society for Computational Biology Student Council (ISCB-SC) and its Regional Student Group (RSG) program, takes time and energy. Both are scarce commodities, especially when you are trying to find your place in the world of computational biology as a graduate student. It comes as no surprise that organizing ISCB-SC-related activities sometimes interferes with day-to-day research and shakes up your priority list. However, we unanimously agree that the rewards, both in the short as well as the long term, make the time spent on these extracurricular activities more than worth it. In this article, we will explain what makes this so worthwhile: soft skills.	computation;computational biology;organizing (structure);rewards;roberts-sc phocomelia syndrome;tremor	Jeroen de Ridder;Pieter Meysman;Olugbenga O. Oluwagbemi;Thomas Abeel	2014		10.1371/journal.pcbi.1003708	social skills;leadership	Comp.	-65.29253721557325	-20.174066331492888	4561
9d4a5d9cf599afc677b0f0af15aaba685f2455c6	perceiving and reasoning about liquids using fully convolutional networks		Liquids are an important part of many common manipulation tasks in human environments. If we wish to have robots that can accomplish these types of tasks, they must be able to interact with liquids in an intelligent manner. In this paper, we investigate ways for robots to perceive and reason about liquids. That is, the robots ask the questions What in my sensory data stream is liquid? and How can I use that to infer all the potential places liquid might be? We collected two datasets to evaluate these questions, one using a realistic liquid simulator and another on our robot. We used fully convolutional neural networks to learn to detect and track liquids across pouring sequences. Our results show that our networks are able to perceive and reason about liquids, and that integrating temporal information is important to performing these tasks well.	artificial neural network;convolutional neural network;robot	Connor Schenck;Dieter Fox	2018	I. J. Robotics Res.	10.1177/0278364917734052	simulation;engineering;artificial intelligence	AI	-33.11899278623923	-39.212279027910235	4564
b58acf2f7d15bfde19c6c5ef374b708c7e391f1e	kasparov versus deeper blue: the ultimate man versus machine challenge			deep blue (chess computer)	Daniel King	1997	ICGA Journal	10.3233/ICG-1997-20309	artificial intelligence;computer science	ECom	-53.60989246340697	-18.644612057167844	4572
15b1a796c66698cf0ff8008746961475b600b139	integrated design of the intelligent web-based chinese medical diagnostic system (cmds) - systematic development for digestive health	whole body;complementary medicine;knowledge based system;health system;web interface;clinical diagnosis;integrated design;digestive system;domain knowledge;shared knowledge;knowledge acquisition;object oriented approach;intelligent system;chinese medical diagnostic system;system development;ontology;web based expert system;expert system	Chinese Medicine (CM) has been recognized as the popular complementary medicine in the world and the abundance of healing knowledge has been transmitted and enriched from generation to generation. The well-recorded archive of Chinese medical knowledge has grown and developed into very detailed theory and philosophy together with a comprehensive and subtle system of diagnosis. Recently, the Internet has been quite often used in a variety of applications for medical purpose, i.e. to provide real-time and platform-independent access which can build and share knowledge about clinical diagnosis experiences, knacks, diseases treatments, and even prescriptions. In this respect, there is a real need of an intelligent system for Chinese medical physician or education because Chinese medicine has evolved complex methods of diagnosis and treatment tailored to the individual’s subtle patterns of disharmony. This allows it not only to treat fully manifest diseases, but also to assist in maintaining health and balance to prevent illnesses from occurring. Ontologies become an important mechanism to build knowledge-based systems. The role of ontologies is to capture domain knowledge and provide a commonly agreed upon understanding of a domain. The advantages include the sharing and re-use of knowledge, and the better engineering of knowledge-based system with respect to acquisition, verification, and maintenance.#R##N##R##N#In this paper, we propose a unifying framework for intelligent disease diagnosis system named CMDS – Chinese Medical Diagnostic System where the medical ontology has been integrated for the system development, and the methodologies of its implementation for digestive health. CMDS uses web interface and expert system technology to act as human expertise and diagnose a number of digestive system diseases. Besides, to efficiently elicit the knowledge of digestive system from domain experts and construct the medical ontology, a hybrid knowledge acquisition strategy is proposed. CMDS provides a truly precise analysis for digestive system disease and the prototype system can diagnose up to 50 types of diseases amongst 10 species of primary digestive system, and just uses over 500 rules and 600 images for various diseases. The satisfactory performance of the system has proven that it could serve the educational purpose, act as a consultant role and the functionality can be extended to the whole body health system.	multidimensional scaling;web application	Mu-Jung Huang;Mu-Yen Chen	2007	Expert Syst. Appl.	10.1016/j.eswa.2006.01.037	digestion;computer science;knowledge management;artificial intelligence;ontology;data mining;user interface;expert system;domain knowledge	AI	-54.39550753581397	-66.78472913609644	4581
2d59f1d108bc43f410e4b9467e61c5dd8ad53af0	combining learn-based and lexicon-based techniques for sentiment detection without using labeled examples	opinion mining;sentiment classification;information retrieval	"""In this work, we propose a novel scheme for sentiment classification (without labeled examples) which combines the strengths of both """"learn-based"""" and """"lexicon-based"""" approaches as follows: we first use a lexicon-based technique to label a portion of informative examples from given task (or domain); then learn a new supervised classifier based on these labeled ones; finally apply this classifier to the task. The experimental results indicate that proposed scheme could dramatically outperform """"learn-based"""" and """"lexicon-based"""" techniques."""	information;lexicon;machine learning	Songbo Tan;Yuefen Wang;Xueqi Cheng	2008		10.1145/1390334.1390481	computer science;machine learning;pattern recognition;data mining;information retrieval;sentiment analysis	AI	-20.212137707913037	-65.8422096070169	4583
0da3a3061396e036de4d69a9b1527574a5aecca2	global research output on date palm (pheonix dactylifera): a 12 years scientometric perspective	scientometrics;date palm;plant species;phoenix dactylifera	Date palm (Phoenix dactylifera) is one of the commonly used polyphenolic rich fruits attributing also to various therapeutic effect in different diseases and disorders. We aimed to study and analyse the global research output related to date palm based on a fact of its large consumption and production in Middle East. We analysed 1,376 papers obtained from SCOPUS database for the period of 2000–11. The study examines major productive countries and their citation impact. We have also analysed inter-collaborative linkages, national priorities of date palm research, besides analysing the characteristics of its high productivity institutions, authors and journal.	cab direct (database);scientometrics;scopus	Ibrahim Alhaider;K. K. Mueen Ahmed;B. M. Gupta	2013	Scientometrics	10.1007/s11192-013-0991-y	scientometrics;computer science;world wide web	Web+IR	-76.43325122524547	-21.104188436029695	4587
63d80901036dcd3e98edc3f63016fb0916f05708	an integrated fuzzy analytic hierarchy process and fuzzy multiple-criteria decision-making simulation approach for maintenance policy selection	simulation;maintenance policy;fuzzy multiple criteria decision making approach;fuzzy analytic hierarchy process	Selecting a proper maintenance strategy in an attempt to preclude failures is of critical significance in system engineering due to its fallbacks in the safety and economics of plants operation. This process is a typical multiple-criteria decision-making MCDM problem that involves both tangible and intangible parameters that are often in conflict with each other. In this paper, an integrated analytic hierarchy process AHP-fuzzy MCDM approach is proposed to perform a comprehensive comparison between different maintenance policies. For this purpose, various criteria are taken into account that are different in nature, as some give a crisp value obtained from simulation, some are defined in linguistic terms based on experts' opinions and some are in the form of triangular fuzzy numbers. The AHP method is used to determine the importance weights of the criteria. Subsequently, a distance-based fuzzy MCDM approach is employed to rank different maintenance policies and select the most appropriate one. Moreover, the fuzzy technique for the order of prioritization by similarity to ideal solution is used for verification of the proposed integrated approach. Lastly, the impact of each criterion on the rankings is examined. Four commonly implemented maintenance policies, namely condition-based, time-based, failure-based and opportunistic, are considered in this study. Also, a real-world example is presented to demonstrate the applicability of the proposed approach. The most significant feature of this approach lies in its capability in incorporating data in the forms of linguistic variables, triangular fuzzy numbers and crisp numbers into the evaluation process.	analytical hierarchy;simulation	Ali Azadeh;Saeed Abdolhossein Zadeh	2016	Simulation	10.1177/0037549715616686	reliability engineering;simulation;defuzzification;fuzzy classification;computer science;engineering;fuzzy number;management science;fuzzy set operations	AI	-5.434084160940846	-17.224245892430467	4595
366aa0f2835e9f1f25d45ebebb5f4b0aa8ab998f	towards a standardized linguistic annotation of the textual content of labels in knowledge representation systems	knowledge representation	We propose applying standardized linguistic annotat ion to terms included in labels of knowledge repres entation schemes (taxonomies or ontologies), hypothesizing that this would help improving ontology-based semantic annotation of tex ts. We share the view that currently used methods for including lexical and te rminological information in such hierarchical netwo rks of concepts are not satisfactory, and thus put forward – as a prelimina ry step to our annotation goal – a model for modula r representation of conceptual, terminological and linguistic information within kn owledge representation systems. Our CTL model is based on two recent initiatives that describe the representation of terminologies a nd lexicons in ontologies: the Terminae method for building terminological and ontological models from text (Aussenac-Gilles et al ., 2008), and the LexInfo metamodel for ontology lexica (Buitelaar et al., 2 009).	knowledge representation and reasoning;lexicon;metamodeling;modula;ontology (information science);taxonomy (general)	Thierry Declerck;Piroska Lendvai	2010			natural language processing;artificial intelligence;knowledge representation and reasoning;computer science;metamodeling;data mining;linguistics;ctl*;ontology;ontology (information science);modular design;annotation;rule-based machine translation	AI	-33.03060271153401	-69.16057045973928	4596
647c4c1b329627c27aaf67089239b2751031c78f	the sharing economy in computing: a systematic literature review		The sharing economy has quickly become a very prominent subject of research in the broader computing literature and the in human--computer interaction (HCI) literature more specifically. When other computing research areas have experienced similarly rapid growth (e.g. human computation, eco-feedback technology), early stage literature reviews have proved useful and influential by identifying trends and gaps in the literature of interest and by providing key directions for short- and long-term future work. In this paper, we seek to provide the same benefits with respect to computing research on the sharing economy. Specifically, following the suggested approach of prior computing literature reviews, we conducted a systematic review of sharing economy articles published in the Association for Computing Machinery Digital Library to investigate the state of sharing economy research in computing. We performed this review with two simultaneous foci: a broad focus toward the computing literature more generally and a narrow focus specifically on HCI literature. We collected a total of 112 sharing economy articles published between 2008 and 2017 and through our analysis of these papers, we make two core contributions: (1) an understanding of the computing community's contributions to our knowledge about the sharing economy, and specifically the role of the HCI community in these contributions (i.e.what has been done) and (2) a discussion of under-explored and unexplored aspects of the sharing economy that can serve as a partial research agenda moving forward (i.e.what is next to do).	digital library;human-based computation;human–computer interaction;sharing economy;systematic review	Tawanna Dillahunt;Xinyi Wang;Earnest Wheeler;Hao Fei Cheng;Brent J. Hecht;Haiyi Zhu	2017	PACMHCI	10.1145/3134673	data science;human computation;digital library;systematic review;computer science;sharing economy	HCI	-61.28951518285126	-41.59689525175415	4603
e8f2dea8e1ec1744811144aa6ee2dd0fcf6a46bb	the economic benefits of health information exchange interoperability for australia.	health care sector;hospital information systems;medical records systems computerized;medical record linkage;systems integration;australia	OBJECTIVE To estimate costs and benefits for Australia of implementing health information exchange interoperability among health care providers and other health care stakeholders.   DESIGN A cost-benefit model considering four levels of interoperability (Level 1, paper based; Level 2, machine transportable; Level 3, machine readable; and Level 4, machine interpretable) was developed for Government-funded health services, then validated by expert review.   RESULTS Roll-out costs for Level 3 and Level 4 interoperability were projected to be $21.5 billion and $14.2 billion, respectively, and steady-state costs, $1470 million and $933 million per annum, respectively. Level 3 interoperability would achieve steady-state savings of $1820 million, and Level 4 interoperability, $2990 million, comprising transactions of: laboratory $1180 million (39%); other providers, $893 million (30%); imaging centre, $680 million (23%); pharmacy, $213 million (7%) and public health, $27 million (1%). Net steady-state Level 4 benefits are projected to be $2050 million: $1710 million more than Level 3 benefits of $348 million, reflecting reduced interface costs for Level 4 interoperability due to standardisation of the semantic content of Level 4 messages.   CONCLUSIONS Benefits to both providers and society will accrue from the implementation of interoperability. Standards are needed for the semantic content of clinical messages, in addition to message exchange standards, for the full benefits of interoperability to be realised. An Australian Government policy position supporting such standards is recommended.	cpu cache;collegehumor;ephrin type-b receptor 1, human;financial cost;health care;health information exchange;human-readable medium;hypericum perforatum;interface device component;interoperability;manuscripts;patients;projections and predictions;steady state;the australian;benefit;interest;message;standards characteristics	Peter Sprivulis;Jan Walker;Douglas Johnston;Eric C. Pan;Julia Adler-Milstein;Blackford Middleton;David W. Bates	2005	Australian health review : a publication of the Australian Hospital Association	10.1071/AH070531	medicine;environmental resource management;hrhis;nursing;emergency medicine	Web+IR	-56.40936166899701	-63.48047777616412	4605
4617105d9b18f116c750739eca87925284dbe3c3	visual verification of the properties of pseudorandom sequences	statistical analysis computer aided instruction educational courses further education random number generation;random sequences generators histograms visualization education computers complexity theory;polytechnic of zagreb visual verification pseudorandom sequences graphical presentation pseudorandom number generator graphical test analytical test human perception visual tests statistics undergraduate higher education curricula courses electrical engineering	This paper describes properties of graphical presentation of pseudorandom number generator. Numerous more-or-less rigorous tests for randomness are available in the literature, and some of them are presented here. It is shown that both graphical and analytical tests give almost equal results, but graphical tests are simpler and closer to human perception. Because of that properties, visual tests combined with simple statistics are proposed as optimal for undergraduate higher education curricula. Mentioned methods are used on multiple courses at professional study of electrical engineering at the Polytechnic of Zagreb.	electrical engineering;graphical user interface;numerical analysis;pseudorandom number generator;pseudorandomness;randomness tests	S. Predarne;G. Vujisic;T. Horvat	2014	2014 37th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)	10.1109/MIPRO.2014.6859684	computer science;theoretical computer science	Graphics	-82.5266920107533	-40.07030712597713	4607
8f98e790ebdf0fe34f916d8b98a25c577fed7247	mixing statistical and symbolic approaches for chemical names recognition	text mining;rule based;chemical informatics;hybrid approach;statistical techniques;term recognition;organic chemistry	This paper investigates the problem of automatic chemical Term Recognition (TR) and proposes to tackle the problem by fusing Symbolic and statistical techniques. Unlike other solutions described in the literature, which only use complex and costly human made ruledbased matching algorithms, we show that the combination of a seven rules matching algorithm and a näıve Bayes classifier achieves high performances. Through experiments performed on different kind of available Organic Chemistry texts, we show that our hybrid approach is also consistent across different data sets.	algorithm;automatic summarization;critical point (network science);experiment;grams;information extraction;logic programming;n-gram;naive bayes classifier;pattern matching;performance;smoothing;text corpus	Florian Boudin;Juan-Manuel Torres-Moreno;Marc El-Bèze	2008		10.1007/978-3-540-78135-6_28	natural language processing;text mining;computer science;artificial intelligence;machine learning;data mining	AI	-24.672310035819784	-69.69541756926957	4610
8c63e3d97eea4b3c5b4b8e1a9d81159ef31f0c0e	"""creative commons and contemporary copyright: a fitting shoe or """"a load of old cobblers""""?"""		This article examines copyrightu0027s historic trajectory from a common law to a statutory privilege, turning almost full circle in recent years, in the current age of high technology. It simultaneously probes theories of intellectual property rights which are grounded in somewhat skewed ideas related to tangible property, and contextual parallels and contrasts are drawn between physical and ephemeral resources throughout. The founding and fomenting of various civil society organisations in response to the expansions in the term and scope of copyright law, such as Creative Commons, is then charted. This leads on to complex questions about what constitutes the public domain, and whether and how it should be facilitated. The aims of grassroots movements such as Creative Commons to persuade and assist authors, through voluntary means, to relax their legislative rights and its impact on copyright law and practice, are also critically evaluated.		Maureen O'Sullivan	2008	First Monday		public domain;economics;computer science;sociology;management;law	Theory	-75.07963159369758	-13.36435862978394	4615
bbcf8d6eab032b36d43fe5b50716e03c9466b3cb	knowledge management problems in hospital work		In this in-depth case study, nine interviews were carried out to investigate knowledge management problems in one healthcare department in a hospital. Based on the Grounded Theory approach, we discovered six thematic knowledge management problem categories: Patient, Patient Data, Physician, Midwife, ICT Systems and Medical Equipment. Each thematic category was further decomposed into multiple items (traits) ranging from 3 to 18 items.	knowledge management	Helvi Nyerwanire;Erja Mustonen-Ollila;Antti Valpas;Jukka Heikkonen	2014		10.5220/0005123802610267	obstetrics and gynaecology	AI	-56.652164288151496	-63.257083289596125	4617
4f4e1fab4ae110423e0c1236fcf5ffd35a2845fb	community-based greedy algorithm for mining top-k influential nodes in mobile social networks	influence maximization;community detection;empirical study;approximate algorithm;mobile device;dynamic programming algorithm;social network;social networks;greedy algorithm;information diffusion;wireless technology;word of mouth;mobile network;new products	"""With the proliferation of mobile devices and wireless technologies, mobile social network systems are increasingly available. A mobile social network plays an essential role as the spread of information and influence in the form of """"word-of-mouth"""". It is a fundamental issue to find a subset of influential individuals in a mobile social network such that targeting them initially (e.g. to adopt a new product) will maximize the spread of the influence (further adoptions of the new product). The problem of finding the most influential nodes is unfortunately NP-hard. It has been shown that a Greedy algorithm with provable approximation guarantees can give good approximation; However, it is computationally expensive, if not prohibitive, to run the greedy algorithm on a large mobile network.  In this paper we propose a new algorithm called Community-based Greedy algorithm for mining top-K influential nodes. The proposed algorithm encompasses two components: 1) an algorithm for detecting communities in a social network by taking into account information diffusion; and 2) a dynamic programming algorithm for selecting communities to find influential nodes. We also provide provable approximation guarantees for our algorithm. Empirical studies on a large real-world mobile social network show that our algorithm is more than an order of magnitudes faster than the state-of-the-art Greedy algorithm for finding top-K influential nodes and the error of our approximate algorithm is small."""	analysis of algorithms;approximation algorithm;color graphics adapter;dynamic programming;greedy algorithm;mobile device;mobile social network;np-hardness;provable prime;provable security;sensor	Yu Wang;Gao Cong;Guojie Song;Kunqing Xie	2010		10.1145/1835804.1835935	mathematical optimization;greedy algorithm;computer science;machine learning;data mining;social network	ML	-16.358355848784278	-44.23357367867383	4622
3429ad07060d835be64c41e612e176d3d89863dd	sms-based library catalogue system: a preliminary investigation of user acceptance	etude utilisateur;information media;sms short message service;oceanie;perceived ease of use;university libraries;university student;modele d acceptation de la technologie;mobile radiocommunication;bibliotheque universitaire;gestion de sistemas de informacion;short message service;user study;gestion des systemes d information;estudio usuario;catalogs;technology acceptance model;information systems management;user studies;catalogue;radiocommunication service mobile;nueva zelandia;data analysis;enquete;self efficacy;catalogues;biblioteca universitaria;nouvelle zelande;technology acceptance;mobile information system;encuesta;catalogo;radiocomunicacion servicio movil;new zealand;survey;oceania;user acceptance;university library;design methodology;perceived usefulness	Purpose – The purpose of this paper is to investigate potential users' cognitive beliefs and intention to use (IU) a proposed short message service (SMS)‐based library catalogue system. The motivation for this research is the growing popularity of mobile information systems and the need to explore if SMS is a technology that libraries could tap into to enhance their services to users.Design/methodology/approach – A review of literature on SMS‐based services and applications within the library sector is followed by a prototyping of an SMS‐based library catalogue system and the development of a number of hypotheses using the technology acceptance model (TAM) as the base framework. The study investigates potential users' cognitive beliefs and IU the systems as well as the effect of self‐efficacy (SE) on these. A survey questionnaire is distributed to a purposeful and convenient sample of university students who are also users of the university library online public access catalogue.Findings – The results of ...		Tiong T. Goh;Chern Li Liew	2009	The Electronic Library	10.1108/02640470910966853	self-efficacy;design methods;telecommunications;computer science;electrical engineering;management information systems;database;data analysis;world wide web;short message service	Logic	-91.50201077156449	-9.145749753394147	4624
cb29f8c84e249df3431c995f42e635c82119b08a	proceedings of the 9th international joint conference on biomedical engineering systems and technologies (biostec 2016) - volume 3: bioinformatics, rome, italy, february 21-23, 2016			biostec;bioinformatics		2016				Visualization	-49.84180802726976	-11.52438843777909	4629
62d90e96213c373bfbd41456ad1aef23f66dc700	recent advances in constraints, 13th annual ercim international workshop on constraint solving and constraint logic programming, csclp 2008, rome, italy, june 18-20, 2008, revised selected papers	annual ercim international workshop;recent advances;selected papers;constraint logic programming	annual ercim international workshop;recent advances;selected papers;constraint logic programming	constraint logic programming		2009		10.1007/978-3-642-03251-6		Arch	-51.27662891177967	-6.585252953287808	4640
c591b6de84fd2ce7646943686a722f51119a60ed	introduction to data science and analytics for collaboration minitrack			data science	Lakshmi Iyer;Lina Zhou;Souren Paul	2017			computer science;data science;human–computer interaction;analytics	ML	-48.00029006810446	-16.637368297066253	4642
781d6c9d6601f56a25844546cffb7fed08ad9db1	video game play: effects on nighttime dreams	dreams;video games;social context;positive emotion;video game;lucid dreams;content analysis;consciousness;emotion regulation	Two sets of content analyses were computed on 56 dreams of 27 hard core video game players gathered during semi-structured interviews in the winter term of 2006 at a Canadian college. The standard dream content analysis system from Hall and VandeCastle [19] was used to analyze these dreams as was another content analysis focused upon lucid/control dreaming. As expected gamers dreamt about gaming and indeed well over half of the dreams reported included easily recognized references to games. Since emotional regulation is thought to be a central feature of dreams, emotions of gaming which range from joy to anger and sadness were investigated in their social contexts in dreams with mixed results. Although gamers evidenced more self negativity in these dreams other indicates of positive emotional environments were present. If hard core gaming created distorted world views at a deep level of consciousness (i.e., in dreams) then this would be expected to appear in their dreams. However, despite the differences from norms, the overall picture is one of dreams reflecting game play while not dramatically distorting their emotional lives as depicted in dreams.	altered level of consciousness;distortion;dreams;lucid;negativity (quantum mechanics);sadness;semiconductor industry	Jayne Gackenbach;Ian Matty;Bena Kuruvilla	2007		10.1145/1328202.1328217	psychology;simulation;dream diary;multimedia;social psychology	HCI	-85.78988645444828	-19.91490628883002	4643
a66103d39c25cc5dbc254b24952d16ddb5ab4832	a pda-based collaborative tool for learning chemistry skills	computers;software;groupware;software tool;collaborative work;computer aided instruction;collaboration;collaborative tools chemistry collaborative work personal digital assistants software tools collaborative software computer science computer science education information technology hardware;materials;collaborative learning;computer supported collaborative learning;collaborative tools;teaching computer aided instruction groupware notebook computers;learning activities;pda based software tool;collaborative learning environment;learning activities design;monitoring;pdas;pdas cscl learning activities design;chemistry;notebook computers;classrooms;face;classrooms computer supported collaborative learning pda based software tool chemistry;cscl;teaching	Computer Supported Collaborative Learning could achieve a high impact on education for countries around the world if good enough tools were accounted in order to set Collaborative Learning environment in classrooms. In this paper we describe the design of a collaborative learning activity for teaching Chemistry. We describe a PDA-based software tool that allows teachers to create workgroups in their classrooms, in order to work on the designed activity. The software tool has a module for teachers, which runs on a conventional PC and lets them to create material and setting groups. There is also a PDA module for students which let them execute the activity.	collaborative software;personal computer;personal digital assistant;principle of good enough;programming tool	Carlos Hurtado;Luis A. Guerrero	2009	2009 13th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2009.4968088	face;collaborative learning;simulation;human–computer interaction;computer science;multimedia;management;collaboration	HCI	-80.3232299278662	-41.88208782872085	4645
26a68cdfd71a190e8d6b0d04c25cd3aa9fc7c271	legal knowledge and information systems - jurix 2012: the twenty-fifth annual conference, university of amsterdam, the netherlands, 17-19 december 2012			information systems		2012			information system;media studies;medicine	EDA	-58.919465778865295	-8.260519689875718	4649
4ff84f5cf9243b704d602d3e57ee06ea4f10a57d	towards a better protection of social media users: a legal perspective on the terms of use of social networking sites		The ‘Terms of Use’ of Social Networking Sites (SNS) increasingly attract attention from policymakers and civil society. It is argued that these terms are rarely read by users and that, consequently, users cannot correctly assess their implications. This article attempts to evaluate the validity of SNS Terms of Use based on the requirements that are imposed in existing legal instruments. Firstly, we look at the phenomenon of standard contracts in the offline world. Secondly, we try to identify whether the SNS environment adds additional elements to the manner in which consumers approach standard Terms of Use. Thirdly, as a case study, we examine the Terms of Use of Facebook and assess whether the clauses could be found invalid on the basis of several law requirements. Finally, we try to put forward a number of remedies for the imbalance of the rights and responsibilities that can currently be found in SNS Terms of Use. K E Y W O R D S : social network sites, terms of use, standard contracts, consumer protection law, contract law 1 . I N T R O D U C T I O N ‘Terms of Use’ of Social Networking Services (SNS) increasingly attract attention both from policymakers and civil society. It is argued that these terms are rarely read * Researcher, Interdisciplinary Centre for Law & ICT (ICRI) – KU Leuven – iMinds, Sint-Michielsstraat 6 B3443, 3000 Leuven (Belgium); E-mail: ellen.wauters@law.kuleuven.be † Postdoctoral Researcher Research Fund Flanders, Interdisciplinary Centre for Law & ICT (ICRI) – KU Leuven – iMinds, Sint-Michielsstraat 6 B3443, 3000 Leuven (Belgium); E-mail: eva.lievens@law.kuleuven.be ‡ Research Professor, Interdisciplinary Centre for Law & ICT (ICRI) – KU Leuven – iMinds, SintMichielsstraat 6 B3443, 3000 Leuven (Belgium); E-mail: peggy.valcke@law.kuleuven.be 1 There is a great diversity in the use of terminology of SNS to indicate that there are rules which lay down the rights and obligations for both parties, such as ‘User agreement’ (LinkedIn), ‘Terms of Service’ (Twitter, Pinterest), ‘Terms of Use agreement’ (Myspace) and ‘Terms of Use’ (Instagram). Throughout this article, we will use the notion ‘Terms of Use’. VC The Author (2014). Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com. 254 International Journal of Law and Information Technology, 2014, 22, 254–294 doi: 10.1093/ijlit/eau002 Advance Access Publication Date: 25 March 2014 Article at U niersity of Sdney on Sptem er 4, 2014 http://ijlirdjournals.org/ D ow nladed from by users before agreeing to them and that, consequently, users cannot correctly assess the implications that these Terms of Use may have. This article aims to approach this general finding from a contract law and consumer rights perspective and attempts to evaluate the validity of SNS Terms of Use based on the legal requirements that are imposed on both parties (provider and user) in existing contract and consumer law instruments. The article focuses on the validity of the actual provisions that are used by SNS in their Terms of Use. The question whether there was a valid consent to these Terms of Use (which are often accepted by simply clicking ‘I agree’) is a separate issue that falls outside the scope of this article. In the first section, we look at the phenomenon of standard contracts or ‘fine print’ in the offline world, and analyse how consumers interact with the standard contracts. In the second section, we try to identify whether the SNS environment adds additional elements to the manner in which consumers approach standard Terms of Use. Thirdly, as a case study, we examine the Terms of Use of Facebook and assess whether the clauses could be found invalid on the basis of contract or consumer law requirements. Finally, we try to put forward a number of remedies for the imbalance of the rights and responsibilities that can be found in SNS Terms of Use. 2 . T E R M S O F U S E I N T H E O F F L I N E W O R L D Standard contracts in particular could thus become effective instruments in the hands of powerful industrial and commercial overlords enabling them to impose a new feudal order of their own making upon a vast host of vassals. Although it would be possible to assume that this is a recent quote, it is in fact from an article that was written in 1943 about the freedom of contract. Standard contracts have their origins in the industrialisation period, when mass production of goods introduced a need for standardized contracts because negotiating every aspect and drafting tailor-made agreements for each transaction would be very time consuming and expensive for both parties. The use of standard contracts can thus be regarded as a rationalization tool which helps to streamline the process of contract formation. In this section, we will take a closer look at standard contracts in a consumer environment. The terms in a contract are considered standard when they are not intended to control transactions with a single customer, but form the basis of ‘an indefinite number of similar transactions with an unlimited number of customers’. Moreover, these Terms of Use are often offered on a take-it-or-leave-it basis. In consumer related 2 Friedrich Kessler, ‘Contracts of Adhesion Some Thoughts About Freedom of Contract’ (1943) 2731 Faculty Scholarship Series Paper 629–42, 640. 3 Hanneke A Luth, ‘Extending the scope of the Unfair Terms discipline in consumer contracts – an economic and behavioural perspective’ (2008) Working Paper Series Rotterdam, Institute of Law and Economics (RILE) No 2008/01, 4, <http://www.uea.ac.uk/ j033/RNBE2008/Details/HL.pdf> accessed 9 September 2013. 4 Karl-Heinz Neumayer, ‘Contracting Subject to Standard terms and conditions’ International Encyclopaedia of Comparative Law Volume VII Contract in General (1999), 12–7. 5 ibid p 7. Towards a better protection of social media users 255 at U niersity of Sdney on Sptem er 4, 2014 http://ijlirdjournals.org/ D ow nladed from transactions this may place the consumer in a weaker position. However, despite this disadvantage, Terms of Use also have the advantage that consumers do not have to negotiate each contract individually, thus saving transaction costs (which are ultimately passed on to consumers and more generally, saving the consumer a lot of time and effort. Terms of Use are ubiquitous and consumers are often unaware that many transactions are subject to standard terms: when buying a train ticket, dropping off clothes at the drycleaner, going to a concert, etc. It is assumed that the attitude of consumers vis-à-vis Terms of Use is influenced by the expectations they have, such as that standard terms are offered on a take-it-or-leave-it basis; that it is highly unlikely that they would understand the terms because they are often very long and drafted in complex legal terms; that is unlikely that terms will vary substantively from those of other businesses that offer similar goods or services; and that is unlikely that the specific risks assigned to the consumer will materialize. Traditionally, law and economic approaches perceived consumers as rational beings who are ‘reasonably well informed and reasonably observant and circumspect’. This assumes that consumers observe information, rationally process it and act in predictable ways. In this view, vulnerable consumers are atypical. Within this regard, ‘rational choice theory’ is used to predict the choices people will make in order to increase their welfare. The theory departs from the assumption that, when several choices are available, people will choose the alternative that produces the most expected welfare. Behavioural economics approaches, however, challenge these assumptions of rational action by studying how individuals make decisions and respond to law and policy, showing that the predictions based on a rational approach often do not hold. While rational choice theory works with ‘predicted’ or ‘hypothesised’ behaviour, behavioural economics tries to shed a light on ‘actual’ behaviour. 6 Aaron T Chiu, ‘Note. Irrationally bound: Terms of Use Licenses and the Breakdown of Consumer Rationality in the Market for Social Network Sites’ (2011) 21 S Cal Interdisc LJ 167–213, 2; Robert A Hillman and Jeffrey Rachlinski, ‘Standard-Form Contracting in the Electronic Age’ (2001) <http://ssrn. com/abstract1⁄4287819> accessed 7 September 2013. 7 Recital 18, European Parliament and Council Directive (EC)2005/29 concerning unfair business-to-con sumer commercial practices in the internal market and amending Council Directive 84/450/EEC, Directives 97/7/EC, 98/27/EC and 2002/65/EC of the European Parliament and of the Council and Regulation (EC) No 2006/2004 of the European Parliament and of the Council [2005] OJ L149/22 (Unfair Commercial Practices Directive). Cf also Case C-210/96 Gut Springenheide and Tusky [1998] ECR I-4657; Case C-220/98 Estee Lauder Cosmetics GmbH & Co. OHG v Lancaster Group GmbH [2000] ECR I-117; Case C-358/01 Commission of the European Communities v Kingdom of Spain [2003] ECR I-13145; Case C-239/02 Douwe Egberts NV v Westrom Pharma NV [2004] ECR I-7007. 8 Adam Smith’s Wealth of Nations (1776) is often mentioned as the forefather of Rational Choice Theory. Rational choice theory has been applied in various disciplines, from economics to sociology. Various authors have developed, discussed and criticized this theory: cf for instance Richard A Posner, ‘Rational Choice, Behavioral Economics, and the Law’ (1998) 50(5) Stanford L Rev, 1551–76; Mark Kelman, ‘Behavioral Economics as Part of a Rhetorical Duet: A Response to Jolls, Sunstein, and Thaler’ (1998) 50(5) Stanford L Rev, 1577–92; Herbert Simon, Models of Man, Social and Rational. Mathematical Essays on Rational Human Behavior in a Social Setting (Wiley 1957) 287. 9 Hanneke A Luth, ‘Behavioural Economics in Consumer Policy, the Economic Analysis of Standard Terms in Consumer Contracts Revisited’ (DPhil thesis, Erasmus Univers	adobe streamline;directive (programming);email;feudalism;google sites;instagram;john d. wiley;lightweight java;mail (macos);naruto shippuden: clash of ninja revolution 3;nv network;online and offline;rev;rationality;requirement;social media;social network;standard form contract;terms of service;typical set;vii;visual instruction set	Ellen Wauters;Eva Lievens;Peggy Valcke	2014	I. J. Law and Information Technology	10.1093/ijlit/eau002	socioeconomics;social psychology	Web+IR	-64.54912028945766	-20.551137497722834	4650
f579e768a2d97a3c631e3ee4ee8364cafc2af39b	knowing in mobile organisations - trust and knowledge sharing in virtual teams	artefacto;trust;teleenseignement;m learning;base de connaissances;telecommunication sans fil;virtual teams;communication service mobile;journal article;artefact;mobile learning;peer reviewed;telecomunicacion sin hilo;virtual team;mobile communication;knowledge sharing;base conocimiento;teleensenanza;remote teaching;cross disciplinary collaboration;knowing;mobile organisations;knowledge base;wireless telecommunication	We investigate how trust and knowledge sharing affect collaboration in virtual teams, as knowing across boundaries in a mobile organization. Important for collaborative work is sufficient understanding and awareness in situations, and where resources are coordinated between participants to adjust to situations as they arise. This collaboration is dependent upon shared common goals, knowing your colleagues competence and thereby be able to share knowledge in cross-disciplinary collaboration, and finally a shared language facilitated by technological visualization artifacts. The consequences are that through shared language the ability to create collaborating relationships and share knowledge based on trust increases.	awareness;enterprise application integration;sensor;virtual reality	Cathrine Filstad;Petter Gottschalk	2010	IJMLO	10.1504/IJMLO.2010.033555	knowledge base;peer review;simulation;mobile telephony;computer science;knowledge management;artificial intelligence;trustworthy computing;world wide web	HCI	-73.61793953788936	-50.816606216491515	4652
f7aac2fe67ac75d7df3a8905feb6ffbeb16c106e	understanding the fidelity effect when evaluating games with children	software engineering;prototyping;user experience;children;evaluation;usability	There have been a number of studies that have compared evaluation results from prototypes of different fidelities but very few of these are with children. This paper reports a comparative study of three prototypes ranging from low fidelity to high fidelity within the context of mobile games, using a between subject design with 37 participants aged 7 to 9. The children played a matching game on either an iPad, a paper prototype using screen shots of the actual game or a sketched version. Observational data was captured to establish the usability problems, and two tools from the Fun Toolkit were used to measure user experience. The results showed that there was little difference for user experience between the three prototypes and very few usability problems were unique to a specific prototype. The contribution of this paper is that children using low-fidelity prototypes can effectively evaluate games of this genre and style.	mobile game;paper prototyping;prototype;screenshot;usability;user experience;ipad	Gavin Sim;Brendan Cassidy;Janet C. Read	2013		10.1145/2485760.2485769	simulation;human–computer interaction;computer science;multimedia	HCI	-58.63653413925718	-46.78337687231175	4655
e1e74ea95451b6f4952506ee1a11394737c07f65	special issue on adaptive and learning agents 2017				Patrick Mannion;Anna Harutyunyan;Kaushik Subramanian	2018	Knowledge Eng. Review	10.1017/S026988891800022X	management science;knowledge management;computer science	AI	-65.39701775567355	-3.239618069479082	4659
0879d06efb01c02f3e0c7e2a41559fc69010c9f5	sharing, liking, commenting, and distressed? the pathway between facebook interaction and psychological distress	job satisfaction;loneliness;information overload;self esteem;adolescents;communication;social networking sites;article;online;psychology social;problematic internet use;criteria	Studies on the mental health implications of social media have generated mixed results. Drawing on a survey of college students (N=513), this research uses structural equation modeling to assess the relationship between Facebook interaction and psychological distress and two underlying mechanisms: communication overload and self-esteem. It is the first study, to our knowledge, that examines how communication overload mediates the mental health implications of social media. Frequent Facebook interaction is associated with greater distress directly and indirectly via a two-step pathway that increases communication overload and reduces self-esteem. The research sheds light on new directions for understanding psychological well-being in an increasingly mediated social world as users share, like, and comment more and more.	feeling upset;gene regulatory network;inventory;self esteem;social communication disorder;social media;social reality;structural equation modeling;mental health	Wenhong Chen;Kye-Hyoung Lee	2013	Cyberpsychology, behavior and social networking	10.1089/cyber.2012.0272	psychology;computer science;information overload;job satisfaction;psychotherapist;social psychology;clinical psychology	HCI	-87.25294512385918	-19.348331339455573	4661
c96248c33f577ed53ebd3a843510b4eb69e53523	collaborative sequence prediction for sequential recommender		With the surge of deep learning, more and more attention has been put on the sequential recommender. It can be casted as sequence prediction problem, where we will predict the next item given the previous items. RNN approaches are able to capture the global sequential features from the data compared with the local features derived in Markov Chain methods. However, both approaches rely on the independence of users' sequences, which are not true in practice. We propose to formulate the sequential recommendation problem as collaborative sequence prediction problem to take the dependency of users' sequences into account. In order to solve the collaborative sequence prediction problem, we define the dynamic neighborhood relationship between users and introduce manifold regularization to RNN on the basis of the multi-facets of collaborative filtering, referred to as MrRNN. Experimental results on benchmark datasets show that our approach outperforms the state-of-the-art baselines.	baseline (configuration management);benchmark (computing);collaborative filtering;deep learning;encode;manifold regularization;markov chain;random neural network;recommender system;recurrent neural network	Shuzi Niu;Rongzhi Zhang	2017		10.1145/3132847.3133079	data mining;collaborative filtering;recommender system;machine learning;deep learning;computer science;mathematical optimization;artificial intelligence;manifold regularization;markov chain	AI	-18.004916520534515	-48.16530097145465	4662
06bb92ca4563383ff7894e861188db39199323c7	social control in information systems development	information technology;social control;interaction pattern;institutionalism;system development;control;organizations;information system development;systems development	Examines sources of control over information system development decisions. Although past research has examined sources of internal organizational control that were solely determined by technical/rational goals, this article analyzes the symbolic role of social institutions in exerting control over system development decisions. Three regulatory mechanisms, developed by institutional theorists, are used to explain how specific social institutions exert their control. The mechanisms of coercive isomorphism, mimetic isomorphism and normative isomorphism help illustrate the types of social forces that enhance similarity of systems across organizations. Three conditions also are identified which moderate these effects: dependence on external institutions having control over an organization's resources; unclear performance standards for system development; and interaction patterns during development. These conditions imply that social control would differ greatly according to whether the major influences on the process of system development arise from within the organization or are imposed from external institutions. The examination of symbolic/institutional forces in system development is useful in both the evaluation of system effectiveness and the assessment of the `̀ appropriateness'' of managerial interventions in the process. Future research should empirically examine these manifestations of social control and their influence on system development	information system;norm (social);software development process	Andreas I. Nicolaou	1999	IT & People	10.1108/09593849910267189	social science;economics;organization;engineering;operations management;social control;sociology;management;social psychology;law;information technology;economic growth;scientific control;mimetic isomorphism	SE	-82.03071314416151	0.6892552710052373	4666
138129662a5ba6fb2db4418079a3f810e350dab5	organizational violations of externally governed privacy and security rules: explaining and predicting selective violations under conditions of strain and excess	soipsvm;selective organizational information privacy and security violations model soipsvm;pci dss;policy violations;hipaa;selective organizational rule violations model;information abuse;theory building;hippa;organizational security;organizational privacy;selective organizational rule violations model sorvm;rule violations;security;article;privacy	Privacy and security concerns are pervasive because of the ease of access to information. Recurrent negative cases in the popular press attest to the failure of current privacy regulations to keep consumer and protected health information sufficiently secure in today’s climate of increased IT use. One reason for such failure is that organizations violate these regulations for multiple reasons. To address this issue, we propose a theoretical model to explain the likelihood that organizations will select an externally governed privacy or security rule for violation in response to organizational strain or slack resources. Our proposed theoretical model, the selective organizational information privacy and security violations model (SOIPSVM), explains how organizational structures and processes, along with characteristics of regulatory rules, alter perceptions of risk when an organization’s performance does not match its aspiration levels and thereby affects the likelihood of rule violations. Importantly, SOIPSVM is contextualized to organizational privacy and security violations. SOIPSVM builds on and extends the selective organizational rule violations model (SORVM), which posits that organizational rule violations are selective. SOIPSVM provides at least four contributions to the privacy and security literature that can further guide empirical research and practice. First, SOIPSVM introduces the concept of selectivity in rule violations to privacy and security research. This concept can improve privacy and security research by showing that organizational violations of privacy and security rules are dynamic and selective yet influenced by external forces. Second, SOIPSVM extends the boundaries of SORVM, which is limited to explaining the behavior of organizations under strain, such as economic hardship. We contribute to the theory of selective deviance by proposing that selectivity extends to organizations with slack resources. Third, we address ideas of non-economic risk and strain in addition to economic risk and strain. SOIPSVM thus explains organizational rule-violating behavior as an attempt to protect core organizational values from external entities that pressure organizations to change their values to comply with rules. Fourth, we broaden the theoretical scope of two important constructs, namely structural secrecy and procedural emphasis to improve the explanatory power of the model. Fifth, we identify important elements of rule enforcement by drawing from the tenets of general deterrence theory. We also discuss how constructs from general deterrence theory can be studied at the organizational level. To conclude, we offer recommendations for the structuring of organizations and external regulations to decrease organizational rule violations, which often lead to the abuse of consumer information.		Jeffrey D. Wall;Paul Benjamin Lowry;Jordan B. Barlow	2016	J. AIS	10.17705/1jais.00420	public relations;computer science;information security;management;privacy;social psychology;computer security	AI	-85.86002248870936	-5.159072267437339	4675
468d5240d92725eebc413a78e66d0fc7c33b431e	medical imaging 2003: image processing, san diego, california, united states, 15-20 february 2003			image processing;medical imaging		2003				Vision	-49.714808433722474	-8.860026023189493	4683
3ea10d57f37c3c8430cea7fea6b41a475b95aa15	proceedings of the 7th acm sigplan international workshop on programming based on actors, agents, and decentralized control, agere 2017, vancouver, bc, canada, october 23 - 27, 2017			distributed control system		2017		10.1145/3141834		EDA	-51.96643396279044	-7.302323906992873	4684
269d6fd4839ca2393bedb98ad0fa3277ec1aa270	an enhanced hal-based pseudo relevance feedback model in clinical decision support retrieval		In an actual electronic health record (EHR), patient notes are written with terse language and clinical jargons. However, most Pseudo Relevance Feedback (PRF) technique methods do not take into account the significant degree of candidate term in feedback documents and the co-occurrence relationship between a candidate term and a query term simultaneously. In this paper, we study how to incorporate proximity information into the Rocchio’s model, and propose a HAL-based Rocchio’s model, called HRoc. A new concept of term proximity feedback weight is introduced to model in the query expansion. Then, we propose three normalization methods to incorporate proximity information. Experimental results on 2016 TREC Clinical Support Medicine collections show that our proposed models are effective and generally superior to the state-of-the-art relevance feedback models.		Min Pan;Yue Zhang;Tingting He;Xingpeng Jiang	2018		10.1007/978-3-319-95933-7_12	normalization (statistics);clinical decision support system;medical record;computer science;relevance feedback;machine learning;query expansion;artificial intelligence	Web+IR	-33.08307761547929	-63.64544478786751	4685
4e37755aa0925e9e40b0abf7fb5a710b9571ead3	exploring boundaries to the benefits of lifelogging for identity maintenance for people with dementia	lifelogging;sensecam;dementia;identity	In the absence of a medical cure for some forms of memory loss caused by dementia, new technologies specialised in pervasive image recording are being incorporated into practical interventions. Lifelogging is the digital capture of life experiences typically using mobile devices such as SenseCam. This lightweight wearable digital camera passively captures up to 3,000 images a day. Lifelogging results in personal, recent visual prompts, potentially encouraging the sharing of personal memories. The authors’ research investigated the incorporation of lifelogging technology into a therapeutic approach to support people with dementia by using the case study method, an exploratory and descriptive approach. SenseCam therapy aimed to stimulate the cognition of a person with dementia, with maintenance of their personal identity as its primary goal. There is limited literature on practical recommendations on how to use lifelogging devices and their effect on people with dementia. The results from the authors’ research indicate a number of factors that should be considered when using lifelogging technology with people with dementia. This paper explores the boundaries to the benefits of using lifelogging technology for identity maintenance in dementia. Implications of not working within these boundaries show clear potential for risk of undermining the human rights and potentially the wellbeing of people with dementia. Exploring Boundaries to the Benefits of Lifelogging for Identity Maintenance for People with Dementia	cognition;digital camera;lifelog;microsoft sensecam;mobile device;wearable computer	Paulina Piasek;Kate Irving;Alan F. Smeaton	2015	IJMHCI	10.4018/IJMHCI.2015100105	computer science;lifelog	HCI	-59.923302823593275	-54.93967289871555	4687
24129abae0143ec56fc167975195ec086cc6512a	let's search together, but not too close! an analysis of communication and performance in collaborative information seeking	measurement;collaboration;human factors;experimentation;communication;information seeking	Communication is considered to be one of the most essential components of collaboration, but our understanding as to which form of communication provides the most optimal cost-benefit balance lacks severely. To help investigate effects of various communication channels on a collaborative project, we conducted a user study with 30 pairs (60 participants) in three different conditions - co-located, remotely located with text chat, and remotely located with text as well as audio chat, in an exploratory search task. Using both quantitative and qualitative data analysis, we found that teams with remotely located participants were more effective in terms of being able to explore more diverse information. Adding audio support for remote collaboration helped participants to lower their cognitive load as well as negative emotions compared to those working in the same space. We also show how these findings could help design more effective systems for collaborative information seeking tasks using adequate and appropriate communication. We argue that collaboration is an important aspect of human-centered IR, and that our work provides interesting insights into people doing information seeking/retrieval in collaboration.	collaborative information seeking	Roberto I. González-Ibáñez;Müge Haseki;Chirag Shah	2013	Inf. Process. Manage.	10.1016/j.ipm.2012.12.008	human–computer interaction;computer science;knowledge management;human factors and ergonomics;multimedia;world wide web;measurement;collaboration	DB	-60.067709212798405	-42.70008559377867	4689
c4f248ee1cabba80973abfe884853696ea6648be	recognising the predicate-argument structure of tagalog	predicate-argument structure;linguistic phenomenon;pas parsing experiment;parsing tagalog text;corpus annotation process;natural language processing	This paper describes research on parsing Tagalog text for predicate–argument structure (PAS). We first outline the linguistic phenomenon and corpus annotation process, then detail a series of PAS parsing experiments.	attachments;experiment;parsing;structured prediction	Meladel Mistica;Timothy Baldwin	2009			natural language processing;speech recognition;computer science;linguistics	NLP	-29.729782384038884	-76.94723459224666	4704
b11766f672968cf0efe4b4c090990b808399cbd0	optimizing acoustic models for commercial speech recognition using foreground scores and data weighting	optimisation;telephones;error statistics speech recognition optimisation telephony maximum likelihood estimation;degradation;acoustic modeling;data weighting;data driven technique;commercial speech recognition;maximum likelihood estimation;telephony;gender;training data;error analysis;boosting;statistics;speech recognition;error statistics;optimization;acoustic models;foreground scores;semantic errors optimization acoustic models commercial speech recognition foreground scores data weighting data driven technique telephones frame averaged foreground log likelihoods recognition errors gender;semantic errors;speech recognition maximum likelihood estimation error analysis telephony training data boosting statistics acoustic applications real time systems degradation;recognition errors;acoustic applications;real time systems;frame averaged foreground log likelihoods	This paper describes a data-driven technique for optimizing the acoustic models for speech recognition systems that target commercial applications over telephones. Frame-averaged foreground log-likelihoods (foreground scores) correlate to recognition errors. These scores are used together with gender to optimize data weighting for the acoustic model. This process is interpreted as increasing the priors and associated parameters for poorly modeled data. The score-based optimization leads to about 7% fewer semantic errors on a live evaluation set collected after the last data used to estimate the acoustic model.	acoustic cryptanalysis;acoustic model;mathematical optimization;optimizing compiler;speech recognition	Daniel Boies;Brian Strope;Mitch Weintraub;Su-Lin Wu	2004	2004 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2004.1326111	training set;speech recognition;degradation;computer science;machine learning;pattern recognition;maximum likelihood;telephony;boosting;statistics	Robotics	-18.15191364488243	-91.63346105019458	4708
584dc23e173b9d3f5a6f1b39d5aee0807b58dacc	multimedia technology and cost savings in hotel applications				Tat Y. Choi;Robert Law	1996			marketing;commerce;business	HCI	-69.69953133511694	-1.54443042611937	4709
7ba3e3622d361e6ff3d51beb9edf6f8ccd184aa5	user profiles and learning objects as ontology individuals to allow reasoning and interoperability in recommender systems	recommender systems computer aided instruction inference mechanisms meta data ontologies artificial intelligence open systems;informatics in education ontology recomender systems;informatics in education;computer aided instruction;inference mechanisms;ontologies artificial intelligence;user profile;recommender system;learning object;ieee lom standard user profile learning object reasoning educational recommender system owl ontology individual web ontology language domain interoperability knowledge description obaa metadata standard brazilian context;meta data;open systems;ontology;recommender systems;ontologies materials cognition owl recommender systems history;recomender systems	This work presents an alternative model to traditional educational recommender systems techniques. The model proposes the description of Learning Objects (LO) and User Profiles as OWL ontology individuals. We propose that the use of ontologies can be very helpful when we seek to accomplish an overall domain interoperability and knowledge description. It is also fundamental for our proposal that a common vocabulary is used. For that, the core of the ontologies are described with the use of the OBAA metadata standard, an extension to IEEE LOM that provides interoperability among hardware platforms for the Brazilian context. Also is part of this work to present a set of practices to develop educational Recommender Systems supported by ontologies.	interoperability;ontology (information science);recommender system;scalability;semantic web;semantic reasoner;user profile;vocabulary;web service	Tiago Thompsen Primo;Rosa Maria Vicari;K Bernardi	2012	Proceedings of the 2012 IEEE Global Engineering Education Conference (EDUCON)	10.1109/EDUCON.2012.6201139	computer science;knowledge management;data mining;world wide web	Web+IR	-82.08361825386714	-45.509250984609324	4710
f5d014533b492583e1fdc21e6b6cb7d3529c3459	the corporate social responsibility in the greek agri-food sector		The Corporate Social Responsibility has become an essential factor involved in the process of customers choosing products or services. It focuses on the common place notion of “think global, act local”. While Corporate Social Responsibility research has been conducted in many industries, the food sector has been largely ignored. Especially, the agri-food sector has a strong impact on the economy, the environment and the society and in the past it has been plagued by many scandals of environmental degradation. In this context, the purpose of this paper is to analyze the largest fifty six Greek food companies in dairy and meat industries about their Corporate Social Responsibilities. The analysis provides an overview of the current status of the Corporate Social Responsibility practices of the leading companies in the aforementioned industries as well as insights in future trends in this unfolding national financial-debt crisis.	elegant degradation;list of code lyoko episodes;unfolding (dsp implementation)	Anastasios Liapakis;Constantina Costopoulou;Alexander B. Sideridis	2015			corporate social responsibility;corporate security;stakeholder;social responsibility;business;public relations;corporate governance;environmental degradation	AI	-75.68623183855097	-6.9263259063655696	4712
0c2a42df54485a9b8cee9936bc21fc2aaf1f9b1a	research on teaching methods of motor drive technology based on information technology	enlighten to make a thorough inquiry;motor drive technology;project-driven;research guided;teaching methods	It is university and college that bring up graduates who own creative talent, which is needed urgently by company and the whole society. Creative talent can be trained by proper teaching methods. Taken motor drive technology course as an example, this paper researched on teaching methods in detail. As compulsory course of mechanical engineering and automation, mechatronics and so on, motor drive technology course plays an important role in course system. Aim to these characteristics, the paper combined course system, teaching content and teaching methods suitably. Meanwhile, synthesizing three teaching methods are proposed effectively. That are method of enlighten to make a thorough inquiry, project-driven and research guided. By these methods, individuals are treated separately, and guided in different way. Finally students can find position of their own. © 2011 Springer-Verlag Berlin Heidelberg.		Shufang Wang;Wei Xi;Yeming Zheng	2011		10.1007/978-3-642-23345-6_1	simulation;engineering;electrical engineering;computer engineering	EDA	-77.90874120621318	-34.5421255590141	4714
c0ac41e46d2f0d01fa51cee691fe03d601666e05	a multiple criteria model for comparison of subjective-objective evaluations and its application	会议论文	A multiple criteria decision model addressing the comparison of both subjective and objective evaluation results is proposed in this paper. Firstly, based on cluster analysis, a method to select representative sample data set from all alternatives under evaluation is designed; next, experts are invited to review these sample data and dominance-based rough set theory is used to analyze expert decisions in format of a set of decision rules; then, these trained decision rules are applied to all alternatives and hence, an objective-oriented results can be obtained and used to compare with the alternatives’ self-evaluation results which contains subjective orientation; finally, the method is applied to analyze the graduate’s leaning ability to demonstrate its feasibility.		Ye Chen;Yao Li;Wangqun Sun;Haiyan Xu	2015		10.1007/978-3-319-19515-5_8	decision rule;data mining;multiple-criteria decision analysis;decision model;sampling (statistics);rough set;computer science	NLP	-4.892471119224712	-18.613182211658586	4717
30e2f3f275284ee2d06256e84e6261935c58239f	are users willing to search cross-language? an experiment with the flickr image sharing repository	flickr image sharing repository;search task;multiple language;interactive task;favorable setting;unknown language;search system	This paper summarizes the participation of UNED in the CLEF 2006 interactive task. Our goal was to measure the attitude of users towards cross-language searching when the search system provides the possibility (as an option) of searching cross-language, and when the search tasks can clearly benefit from searching in multiple languages. Our results indicate that, even in the most favorable setting (the results are images that can be often interpreted as relevant without reading their descriptions, and the system can make translations in a transparent way to the user), users often avoid translating their query into unknown languages.	flickr;image	Javier Artiles;Julio Gonzalo;Fernando López-Ostenero;Victor I Peinado	2006		10.1007/978-3-540-74999-8_28	computer science;data mining;world wide web;information retrieval	HCI	-35.08074181086435	-54.628384191810504	4721
347196f0dfe9f3d9ff764741ef90fb04bb0bf818	benevolent deception in human computer interaction	benevolent deception;criminology;design principles	"""Though it has been asserted that """"good design is honest"""", [42] deception exists throughout human-computer interaction research and practice. Because of the stigma associated with deception - in many cases rightfully so - the research community has focused its energy on eradicating malicious deception, and ignored instances in which deception is positively employed. In this paper we present the notion of benevolent deception, deception aimed at benefitting the user as well as the developer. We frame our discussion using a criminology-inspired model and ground components in various examples. We assert that this provides us with a set of tools and principles that not only helps us with system and interface design, but that opens new research areas. After all, as Cockton claims in his 2004 paper """"Value-Centered HCI"""" [13], """"Traditional disciplines have delivered truth. The goal of HCI is to deliver value."""""""	benevolent dictator for life;human computer;human–computer interaction;malware	Eytan Adar;Desney S. Tan;Jaime Teevan	2013		10.1145/2470654.2466246	artificial intelligence;design elements and principles	HCI	-61.11318627402277	-43.20413978314419	4722
873b2ab135d3a500979336b4aa202bd77ceca73f	biased discriminant euclidean embedding for content-based image retrieval	content management;busqueda informacion;dimensionalidad;corel image gallery;evaluation performance;manifold regularization based item;corel image gallery biased discriminative euclidean embedding content based image retrieval multimedia applications image management web search relevance feedback intraclass geometry interclass discrimination manifold regularization based item;document multimedia;high dimensionality;performance evaluation;learning;multimedia applications;recherche image;information retrieval;evaluacion prestacion;geometry;dimensionality;bridges;multimedia application;manifold learning;multimedia document;journal article;multimedia systems;stability;algorithme;aprendizaje;discriminant analysis;analyse discriminante;algorithm;accuracy;analisis discriminante;apprentissage;feedback;radio frequency;precision;dimensionality reduction;relevance feedback content based retrieval image retrieval multimedia systems;relevance feedback content based image retrieval dimensionality reduction manifold learning;biased discriminative euclidean embedding;recherche information;image management;busqueda por contenido;dimensionnalite;solid modeling;semantic gap;multimedia communication;interclass discrimination;visual features;web search;analisis semantico;analyse semantique;content based image retrieval;communication multimedia;image retrieval content based retrieval radio frequency content management web search feedback bridges solid modeling geometry stability;discriminacion;intraclass geometry;dimensional reduction;relevance feedback;content based retrieval;recherche par contenu;discrimination;semantic analysis;algoritmo;image retrieval;documento multimedia	With many potential multimedia applications, content-based image retrieval (CBIR) has recently gained more attention for image management and Web search. A wide variety of relevance feedback (RF) algorithms have been developed in recent years to improve the performance of CBIR systems. These RF algorithms capture user's preferences and bridge the semantic gap. However, there is still a big room to further the RF performance, because the popular RF algorithms ignore the manifold structure of image low-level visual features. In this paper, we propose the biased discriminative Euclidean embedding (BDEE) which parameterises samples in the original high-dimensional ambient space to discover the intrinsic coordinate of image low-level visual features. BDEE precisely models both the intraclass geometry and interclass discrimination and never meets the undersampled problem. To consider unlabelled samples, a manifold regularization-based item is introduced and combined with BDEE to form the semi-supervised BDEE, or semi-BDEE for short. To justify the effectiveness of the proposed BDEE and semi-BDEE, we compare them against the conventional RF algorithms and show a significant improvement in terms of accuracy and stability based on a subset of the Corel image gallery.	algorithm;asymmetric cell division;broadcast driver architecture;content-based image retrieval;dimensionality reduction;discriminant;gain;high- and low-level;linear discriminant analysis;manifold regularization;marginal model;multimedia;paraffin embedding;radio frequency;relevance feedback;sampling - surgical action;semi-supervised learning;semiconductor industry;similarity measure;subgroup;support vector machine;web search engine	Wei Bian;Dacheng Tao	2010	IEEE Transactions on Image Processing	10.1109/TIP.2009.2035223	computer vision;image retrieval;computer science;machine learning;accuracy and precision;multimedia;statistics	Vision	-13.239981732049186	-61.15738218055622	4723
ed202c9f3d64be9c5533f60e715e63d282f08a97	more realistic, flexible, and expressive social crowds using transactional analysis	pair walking;social crowd simulation;transactional analysis	Recent algorithms have been able to simulate “social crowds” that allow agents to interact socially as opposed to only treating other agents as obstacles. Unfortunately, past social crowd algorithms lack realism and flexibility because they do not allow agents to move in and out of different and repeated social interactions, are built around a specific obstacle avoidance algorithm, or are tuned only for a specific social setting and do not allow for artist directed changes. We propose a new, simplified social crowd algorithm that focuses on the evolving social needs of agents and allows each agent to join and leave different encounters as desired. Our algorithm is based on the psychology research area of transactional analysis, does not require a specific obstacle avoidance algorithm, and allows for easy artist direction for determining the precise social environment being simulated. Our algorithm runs in real-time with 3,000 to 4,000 agents without the restrictions of previous research.	algorithm;interaction;obstacle avoidance;real-time clock;simulation	Brian C. Ricks;Parris K. Egbert	2012	The Visual Computer	10.1007/s00371-012-0712-1	simulation;artificial intelligence;transactional analysis	AI	-21.21734030914913	-20.82605628674213	4725
2b1d2b44c7761e9c0cd26401a2d71dee1cad1e1c	an event-based notification approach for the delivery of patient medical information	data sharing;take the best;web service;satisfiability;treatment outcome;healthcare costs;information exchange;publish subscribe;event notification;health information system;publish subscribe services;health information systems	Data sharing is pivotal in current medical practice so as to better treat patients by taking the best medical decisions, and to optimize healthcare costs by reducing the need to repeat unnecessary medical tests and by better managing healthcare structures. To improve the delivery of treatment outcomes and test results, the request-triggered retrieval of clinical documents provided by current Health Information Systems is not sufficient. The addition of a notification solution is necessary to inform users as soon as their clinical documents of interest have been produced so that they can retrieve them by means of the traditional Health Information Systems. In addition, this notification solution also has to implement the event-based information exchange patterns, which characterize the current attempts at integrating heterogeneous Health Information Systems in a seamless manner. This paper proposes an architecture for an effective asynchronous notification of clinical documents. Our intention is to bridge the gap between primary and secondary care, and between the clinical personnel and the administrators. The proposed solution is based on a publish/subscribe service, properly extended to allow us to jointly notify collections of correlated documents. Moreover, it has been implemented by means of a web service-based platform in accordance with the Web Service Notification specification so as to obtain a solution easy to integrate and manage. A systematic analysis has been carried out to assess the suitability of the implemented solution to satisfy the requirements for notifying medical documents, and to evaluate the notification latency in different use conditions.		Christian Esposito;Mario Ciampi;Giuseppe De Pietro	2014	Inf. Syst.	10.1016/j.is.2013.07.002	web service;health informatics;information exchange;computer science;data mining;database;publish–subscribe pattern;world wide web;computer security;satisfiability	DB	-52.9461730225469	-66.83984390960742	4738
ca2dea9263a3170ff8cd742554b65ca577206f56	the importance of security culture for crowd energy systems		Driven by the energy turnaround, it can be seen that the centralized architecture of our energy system is becoming increasingly decentralized. This is fueled in particular by digital innovations. Security concerns in bottom-up energy networks such as Crowd Energy systems are growing, especially because the protection of private information is quite a complex problem. Technology alone is not enough to assure accepted levels of security. Energy prosumers are involved in every process of energy production, storage, and consumption. It is just a matter of time before this Crowd develops a security culture that impacts the security outcomes directly. In this paper we investigate the components that form this culture, and the methods to direct it in a desired path. We present a security culture framework that intends to enhance security outcomes, and we apply a cultural repositioning framework to further support security.	centralized computing;energy systems language;high-level programming language;personally identifiable information	Mohammad Aldabbas;Stephanie Teufel;Bernd Teufel	2017	2017 Information Security for South Africa (ISSA)	10.1109/ISSA.2017.8251783	computer security;energy system;architecture;cultural diversity;smart grid;information security;private information retrieval;computer science;security culture	Arch	-74.95186493494963	-6.543172078356945	4745
8403a9bfcb7c15b694cc57239f12f8cb2c440472	memreflex: adaptive flashcards for mobile microlearning	learner accuracy;successful study session;dynamically scheduling future test;quick succession;memreflex system;intense initial memoriztion;new direction;subsequent test;adaptive flashcards;mobile microlearning;user study;mobile opportunity;new item;full detail;flashcard system;adaptive systems;language learning	Flashcard systems typically help students learn facts (e.g., definitions, names, and dates), relying on intense initial memoriztion with subsequent tests delayed up to days later. This approach does not exploit the short, sparse, and mobile opportunities for microlearning throughout the day, nor does it support learners who need the motivation that comes from successful study sessions. In contrast, our MemReflex system of adaptive flashcards gives fast-feedback by retesting new items in quick succession, dynamically scheduling future tests according to a model of the learner's memory. Full details can be found in the paper [1].	scheduling (computing);sparse matrix;succession	Darren Edge;Stephen Fitchett;Michael Whitney;James A. Landay	2012		10.1145/2371664.2371707	language acquisition;simulation;computer science;artificial intelligence;adaptive system;multimedia	HCI	-74.78970613830516	-46.80423133948052	4748
0ee34b98adc8edb991161fc481b0ea48730eedb5	a machine learning based topic exploration and categorization on surveys	pattern clustering;document handling;categorization topic modeling survey clustering fuzzy clustering;pattern clustering document handling fuzzy set theory learning artificial intelligence;large scale integration computational modeling buildings vocabulary clustering algorithms education noise;topic modeling;fuzzy set theory;fuzzy clustering;question banks machine learning based topic exploration survey categorization relevance ranking model multilingual surveys topic modeling fuzzy clustering automatically generated question survey categories question banks category specific survey templates multilingual survey text german languages spanish languages french languages portuguese languages;survey clustering;learning artificial intelligence;categorization	This paper describes an automatic topic extraction, categorization, and relevance ranking model for multi-lingual surveys and questions that exploits machine learning algorithms such as topic modeling and fuzzy clustering. Automatically generated question and survey categories are used to build question banks and category-specific survey templates. First, we describe different pre-processing steps we considered for removing noise in the multilingual survey text. Second, we explain our strategy to automatically extract survey categories from surveys based on topic models. Third, we describe different methods to cluster questions under survey categories and group them based on relevance. Last, we describe our experimental results on a large group of unique, real-world survey datasets from the German, Spanish, French, and Portuguese languages and our refining methods to determine meaningful and sensible categories for building question banks. We conclude this document with possible enhancements to the current system and impacts in the business domain.	algorithm;business domain;categorization;cluster analysis;computer cluster;filter bank;fuzzy clustering;latent dirichlet allocation;latent semantic analysis;machine learning;off topic;preprocessor;question answering;relevance;topic model;whole earth 'lectronic link	Clint P. George;Daisy Zhe Wang;Joseph N. Wilson;Liana M. Epstein;Philip Garland;Annabell Suh	2012	2012 11th International Conference on Machine Learning and Applications	10.1109/ICMLA.2012.132	natural language processing;document clustering;fuzzy clustering;computer science;machine learning;pattern recognition;data mining;fuzzy set;topic model;categorization;conceptual clustering	NLP	-24.529057878907807	-67.03991359397438	4750
6e08a2d353f750fdce9f796fbf929b8efcab9ccb	causality in information technology business value: a review	mediating factors;organization dynamic capability;itbv causality;information technology business value;it enabled organizational transformation;itbv benefits	"""Users who downloaded this article also downloaded: Russell Torres, Anna Sidorova, (2015),""""The effect of business process configurations on user motivation"""", Business Process Management Journal, Vol. 21 Iss 3 pp. 541-563 http:// dx.doi.org/10.1108/BPMJ-09-2013-0131 Tobias Roeser, Eva-Maria Kern, (2015),""""Surveys in business process management – a literature review"""", Business Process Management Journal, Vol. 21 Iss 3 pp. 692-718 http://dx.doi.org/10.1108/ BPMJ-07-2014-0065 Mithu Bhattacharya, (2015),""""A conceptual framework of RFID adoption in retail using Rogers stage model"""", Business Process Management Journal, Vol. 21 Iss 3 pp. 517-540 http://dx.doi.org/10.1108/ BPMJ-06-2014-0047"""	bird's-eye view;business process;causality;database;file spanning;holism;list comprehension;nl (complexity);orthogonal defect classification;region of interest;resource-oriented architecture;synergy	Sonal Daulatkar;Purnima S. Sangle	2015	Business Proc. Manag. Journal	10.1108/BPMJ-06-2014-0061	engineering;knowledge management;marketing;operations management;management science;management	DB	-69.61906890145008	2.683120620474633	4754
6a5987d33b47c26412abbb1eac5f667870f6f7eb	a fully automated derivation of state-based eigentriphones for triphone modeling with no tied states using regularization		Recently we proposed an alternative method called eigentriphone to solve the data insufficiency problem in triphone acoustic modeling without the need of state tying. The idea is to treat the acoustic modeling problem of infrequent triphones (“poor triphones”) as an adaptation problem from the more frequent triphones (“rich triphones”): firstly, an eigenbasis is developed over the rich triphones that have sufficient training data and the eigenvectors are called eigentriphones; then the poor triphones are adapted in a fashion similar to eigenvoice adaptation. Since, in general, no states are tied in our method, all triphones (states) are distinct so that they can be more discriminative than tied-state triphones. In our previous work, the number of eigentriphones was determined in advance with a set of development data. In this paper, we investigate simply using all of them with the help of regularization to naturally penalize the less important ones. In addition, the modelbased eigenbasis is replaced by three state-based eigenbases. Experimental evaluation on the WSJ 5K task shows that triphone models trained using our new eigentriphone approach without state tying perform at least as well as the common tied-state triphone models.	acoustic cryptanalysis;acoustic model;convergence insufficiency;matrix regularization;the wall street journal;triphone	Tom Ko;Brian Kan-Wing Mak	2011			pattern recognition;artificial intelligence;triphone;computer science;derivation;regularization (mathematics)	NLP	-17.52123924820741	-92.13794935912978	4759
a4e0910045e4c2db946f0fc44f60d64963db815a	tratamiento de la negación en el análisis de opiniones en español	negation scope identification;computacion informatica;filologias;info eu repo semantics article;informacion documentacion;analisis de la opinion;linguistica;ciencias basicas y experimentales;sentiment analysis;identificacion del ambito de la negacion;clasificacion de la polaridad;polarity classification;grupo a;ciencias sociales;grupo b	Sentiment Analysis is a task that still has several opened challenges. One of those challenges is the treatment of the negation, because a negative opinion can be built using negated positive words. Negation is a particular feature of each language, thus it must be considered differently per each language. In this article is shown a linguistic approach for the negation scope identification with the aim of integrating it in a polarity classification system in the domain of movie reviews.	linear algebra;sentiment analysis	Salud M. Jiménez Zafra;Eugenio Martínez-Cámara;María Teresa Martín-Valdivia;M. Dolores Molina-González	2015	Procesamiento del Lenguaje Natural		natural language processing;computer science;sentiment analysis	NLP	-27.810735782364684	-77.17582924981414	4760
2c6300127d1ba77e7f39526fc81786e4f97a3cb1	monitoring probabilistic threshold sum query processing in uncertain streams		Many sources of data streams, e.g. geo-spatial streams derived from GPS-tracking systems or sensor streams provided by sensor networks are inherently uncertain due to impreciseness of sensing devices, due to outdated information, and due to human errors. In order to support data analysis on such data, aggregation queries are an important class of queries. This paper introduces a scalable approach for continuous probabilistic SUM query processing in uncertain stream environments. Here we consider an uncertain stream as a stream of uncertain values, each given by a probability distribution among the domain of the sensor values. Continuous probabilistic sum queries maintain the probability distribution of the sum of possible sensor values actually derived from the streaming environment. Our approach is able to efficiently compute the probabilistic SUM according to the possible world semantics, i.e., without any loss of information. Furthermore, we show the query’s answer can be efficiently updated in dynamic environments where attribute values change frequently. Our experimental results show that our approach computes probabilistic sum queries efficiently, and that processing queries incrementally instead of performing computation from scratch further boosts the performance of our algorithm significantly.		Nina Hubig;Andreas Züfle;Tobias Emrich;Matthias Renz;Mario A. Nascimento;Hans-Peter Kriegel	2014		10.1007/978-3-319-05810-8_28	data mining;database;information retrieval	DB	-24.10294740598909	3.0501019101916995	4762
93a1acb47af772aaf7721b768b26057467d9bbfb	where object-oriented dbmss should do better: a critique based on early experiences	early experience;object oriented		database	Angelika Kotz Dittrich;Klaus R. Dittrich	1995			developmental psychology;knowledge management;social psychology	HCI	-52.85101841192262	-21.820639216455866	4765
f3357e331cc56b046a485772f8a00a0d711cd5cb	validating contradiction in texts using online co-mention pattern checking	contradiction detection;web mining;textual entailment;chinese	Detecting contradictive statements is a foundational and challenging task for text understanding applications such as textual entailment. In this article, we aim to address the problem of the shortage of specific background knowledge in contradiction detection. A novel contradiction detecting approach based on the distribution of the query composed of critical mismatch combinations on the Internet is proposed to tackle the problem. By measuring the availability of mismatch conjunction phrases (MCPs), the background knowledge about two target statements can be implicitly obtained for identifying contradictions. Experiments on three different configurations show that the MCP-based approach achieves remarkable improvement on contradiction detection and can significantly improve the performance of textual entailment recognition.	experiment;internet;sensor;textual entailment	Chengwei Shih;Chengwei Lee;Richard Tzonghan Tsai;Wenlian Hsu	2012	ACM Trans. Asian Lang. Inf. Process.	10.1145/2382593.2382599	natural language processing;web mining;textual entailment;computer science;data mining;linguistics;chinese;algorithm	Web+IR	-28.680410971726637	-67.0495334423527	4771
54db9a78dda2a1f6b86b737bde685a9fb626086a	linking knowledge mapping and lessons learned in a research and development group: a pilot study		In Software Engineering, Knowledge Mapping is a process to discover aspects or meanings through the analysis of relationships between artifacts or people. However, to create a knowledge map, we need a process for capturing and analyzing data, so that we can extract information that reflects those aspects. In this paper, we propose a knowledge mapping process that generates a knowledge map and a set of knowledge profiles considering each mapped member. We developed a new technique by improving existing techniques in literature. In addition, we planned and performed a pilot study in a Research and Development (Ru0026D) group. In this paper, we present our findings regarding the application of the proposed technique and the analysis of the knowledge map for that group. Additionally, we generated links between the knowledge profiles and collected lessons learned for one of the projects that was performed by this Ru0026D group.		Erivan Souza da Silva Filho;Davi Viana;Jacilane Rabelo;Tayana Conte	2016		10.1007/978-3-319-62386-3_10	knowledge management;data mining;computer science	HCI	-91.06422801275845	2.9968514221839126	4777
5489d0487d1c7f70dad4370253f9432d0c12c939	robot rescue camp	robot rescue camp	ing consumers from real innovation?” The question should be, “Is the misunderstanding and misuse of UCD tools by business failing to give useful product ideas their due?” Continuing the Discussion. There was some debate about whether the premise of the discussion was false. Reimann noted that human-centered design currently has a greater role in scoping and validating, rather than proposing, innovations, but that innovation could and should be driven by human-centered design methods. An audience member argued that the best thing for users is also best for business. Considering the nature of users, Perks said we should not reduce the human condition to needs. Oppenheimer argued that real innovation lies in seeing higher needs, and that we should “get out of the Web window.” We expect this discussion to continue, at SIGCHI-sponsored conferences and elsewhere. It has already prompted some commentary, and this and future responses will be documented at www.spy.co.uk/Events/Panels/DI S2004	failure;sigchi;scope (computer science);user-centered design;world wide web	Jean Scholtz	2005	Interactions	10.1145/1052438.1052485	robot;human–computer interaction;engineering	HCI	-62.217992274052996	-28.192365300043832	4779
4653f3e88527b820f2bcb42861fd0f620ff535af	designers' perceptions of methods of involving and understanding users	numerical method;design practice;cluster analysis;design method;user involvement	Numerous methods have been developed to help designers to understand and consider the needs and desires of end-users, but many have had limited uptake in design practice. In order to understand why this is and to enable the development of more effective methods and tools, it is important to uncover how designers themselves think about and react to these methods. We are therefore currently conducting a card-sorting study with designers. We aim to uncover their perceptions of underlying similarities and relationships between design methods, and relate them to the frequency and enjoyment of use. This paper presents results from an initial sample of six designers. A cluster analysis identified a very strong clustering in these results, indicating that common underlying views about methods do exist. Six key clusters are identified, including two focused on user involvement and one on understanding users without direct user contact. The effect of different method characteristics on the frequency and enjoyment of method use are also considered. Initial results indicate that certain clusters of methods are used more often, as are methods that are informal and cheap.	cluster analysis;sorting	Joy Goodman-Deane;Susannah Clarke;Patrick Langdon;P. John Clarkson	2007		10.1007/978-3-540-73279-2_15	simulation;human–computer interaction;engineering;multimedia	HCI	-59.57946088444875	-44.7221782046419	4785
3cffbb6c307390ed230a00688fb135a2b214c1ce	adding insight: a qualitative cross-site study of physician order entry	hospital information system;qualitative research;qualitative analysis;hospital information systems;computerized physician order entry;multidisciplinary teams;medical records systems computerized;qualitative study;success factor;field data;physician order entry;user computer interface;attitude to computers;diffusion of innovation	"""The research questions, strategies, and results of a six-year qualitative study of computerized physician order entry implementation (CPOE) at successful sites are reviewed over time. The iterative nature of qualitative inquiry stimulates a consecutive stream of research foci which, with each iteration, add further insight into the overarching research question. A multidisciplinary team of researchers studied CPOE implementation in four organizations using a multi-method approach to address the question """"what are the success factors for implementing CPOE?"""" Four major themes emerged after studying three sites; ten themes resulted from blending the first results with those from a fourth site; and twelve principles were generated when results of a qualitative analysis of consensus conference transcripts were combined with the field data. The study has produced detailed descriptions of factors related to CPOE success and insight into the implementation process."""		Joan S. Ash;Dean F. Sittig;Veena Seshadri;Richard H. Dykstra;James D. Carpenter;P. Zoë Stavri	2004	Studies in health technology and informatics	10.1016/j.ijmedinf.2005.05.005	simulation;medicine;knowledge management;qualitative research;nursing;management science	HCI	-80.11265211717166	-25.79565276318146	4790
354e61236435a2d241e3b416db8ae21dda89583e	the importance of search as intertextual practice for undergraduate research		By first reassessing the role of search in the literacy event of the lower division undergraduate paper, this article argues that searching is not a lower-order mental activity but a concurrent, integral component of the research-writing process. This conclusion has large implications for information literacy instructional design, and several practical applications to further support undergraduate research-writing are outlined.	energy (psychological);information literacy	Brett B. Bodemer	2012	C&RL		library science;computer science;information literacy;multimedia;sociology;literacy;information retrieval;pedagogy	HCI	-73.29147023150394	-33.48227736950218	4796
4f751f84434f45892dde015d7e456e68807c33b4	click4buildingid@ntu: click for building identification with gps-enabled camera cell phone	scene matching;photo recognition building identification service gps enabled camera cell phone information mms messaging remote client server system gps tagged image matching feature matching earth mover distance measure scene matching location estimation;image recognition;building identification service;distance measure;image matching;earth;location estimation;prototypes;mms messaging;earth mover distance measure;mobile radio client server systems digital photography electronic messaging feature extraction geographic information systems global positioning system image matching image recognition mobile computing;client server systems;telecommunication computing;layout;feature matching;digital photography;remote client server system;cameras cellular phones global positioning system buildings prototypes earth motion measurement layout telecommunication computing image recognition;gps enabled camera cell phone information;global positioning system;geographic information systems;feature extraction;mobile radio;electronic messaging;photo recognition;motion measurement;mobile computing;cameras;buildings;cellular phones;gps tagged image matching	A working prototype of a building identification service which can be used on any camera cell phones equipped with GPS capability has been developed. Users can simply snap photos of architectures and send them, together with the corresponding GPS coordinates, via MMS to a remote server. The server will match the photos with the stored, GPS-tagged images using a combination of scale saliency algorithm for feature matching and earth movers distance measure for scene matching. The estimated location and other information are then sent back to the users via MMS. This prototype will have better accuracy than systems which rely solely on photo recognition given the exploitation of GPS information. Moreover, it is computationally lighter since the recognition engine only needs to compare stored images which lie within the GPS coordinates error range. It is relatively inexpensive as no special phones or subscriptions to telecommunication providers for provision of GPS equivalent location data (i.e.cell location) are needed.	algorithm;cell (microprocessor);geographic coordinate system;global positioning system;mobile phone;prototype;server (computing)	Chai Kiat Yeo;Liang-Tien Chia;Tat-Jen Cham;D. Rajon	2007	2007 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2007.4284836	layout;computer vision;digital photography;secure user plane location;global positioning system;feature extraction;computer science;operating system;prototype;earth;internet privacy;mobile computing;world wide web;gps tracking server	Mobile	-33.97254003174944	-36.22570882825341	4802
2017cdbf1c16e43b0ddee56bd2a84184a2fe89f7	understanding and organizing user generated data: methods and applications		The Internet in general, and the Web 2.0, together with the trend towards mobile terminals in particular, have recently had an immense impact on the society. As a result of these developments, users nowadays produce data on an unprecedented scale. This new kind of data has attracted the attention of researchers from a wide variety of disciplines. In this thesis we contribute some small pieces to the huge interdisciplinary efforts to understand this implicitly and explicitly generated data. More importantly, we put these analytic efforts into a practical context by making the insights directly accessible to the end-users by means of concrete applications. In the first part of the thesis we investigate the interconnections between people in (online) social networks. Based on some relevant properties of these networks, we then propose two mobile applications, one to assist a user who wants to address a group of people from within a resource restricted device, and one that unobtrusively searches for potential friends while the user is pursuing everyday activities. The second part of the thesis studies the extraction of similarity measures from user generated content. We thereby focus on two main domains: Scientific conferences and music. We show that a large collection of publication records implicitly contains information about different aspects of conference similarities. Two of these aspects – quality and thematic scope – form the fundamental building blocks of confsearch, a conference search engine we have implemented. Our conference similarity measure is further used to draw a map of conferences using a graph embedding algorithm and to discuss the world of conferences in a playful manner. Towards the end of the thesis we discuss different facets of music similarity and its use in end-user applications. In particular, we take advantage of the fact that the cumulated listening histories of a large user basis contain valuable information about the similarity of songs. The resulting similarity measure is known to better reflect the users’ perception than state-of-the-art audio based methods. However, it lacks a compact representation as known from audio based techniques, a fact that greatly complicates the design of intuitive user interfaces. To overcome this problem, we pick up the idea of a map, as already discussed in the context of scientific conferences. In particular, we propose to compactly embed our usage data based music similarity measures into a Euclidean space. For this purpose, we make use of two different techniques, one that solely relies on the listening behavior, and one that combines this data with the more explicit information contained in social tags. We finally demonstrate the practical usefulness of the concept of a music map in a comprehensive mobile music player for the Android platform that gained a remarkable popularity. In a user study, we show that the integrated similarity aware features are frequently used. From this study, and from user comments, we conclude that our map in fact facilitates the design of similarity based music retrieval interfaces, and that such interfaces are also well accepted by the community.	algorithm;android;graph embedding;internet;mobile app;organizing (structure);similarity measure;social network;usability testing;usage data;user interface;user-generated content;web 2.0;web search engine;world wide web	Michael Kuhn	2011			user-generated content;the internet;mobile music;active listening;search engine;data mining;similarity measure;user interface;computer science;usage data	Web+IR	-27.949188196444766	-46.16262448235914	4805
0a19e3c2140d31e73eefbfb915438d73935974b3	design, implementation and experimental tests of a new generation of antarctic rover	software design antarctic rover arctic mobile robot hardware design;vehicles control engineering computing hardware software codesign mobile robots	The Arctic and Antarctic, as the harshest environments on the earth, are of great importance to the nation. The extreme environments can be harmful, even fatal, to human beings and mobile robots. To execute missions on the Antarctic in place of human, the State Key Laboratory of Robotics of Shenyang Institute of Automation, Chinese Academy of Sciences has designed three generations of Antarctic rovers. The hardware and software design and implementation of the third generation of Antarctic rover, which has been tested on the Antarctic during the 28th Chinese National Antarctic Research Expedition in 2011, will be presented in this paper. The preliminary experimental results, as introduced in the last part of the paper, suggest that the design and implementation of the hardware and software system can ensure efficiency and reliability of the rover working on the Antarctic.	3d scanner;algorithm;automation;institute of automation, chinese academy of sciences;mobile robot;robotics;rover (the prisoner);sonar (symantec);sensor;smart environment;software design;software system;systems design	Cheng Chen;Chunguang Bu;Yuqing He;Jianda Han	2012	2012 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2012.6491286	simulation;computer science;engineering;marine engineering	Robotics	-32.78940963613503	-19.75653542118924	4808
876fa0af63685dae280053cfe991e2a4111c781e	a rule-based approach for developing a competency-oriented user model for e-learning systems	electronic learning;resource description format;project management;personalized functionalities competency oriented user model e learning systems two layer user model ontological constructs rule based solution user profile;competency oriented user model;e learning systems;web and internet services;rule based solution;probability density function;rule based system;computer aided instruction;competencies;rule based;personalized functionalities;recommendations user model development e learning competencies rule based system;collaboration;e learning system;recommendations;knowledge based systems computer aided instruction human factors;data mining;ontological constructs;user profile;human factors;electronic learning ontologies collaboration human resource management taxonomy project management web and internet services educational institutions blogs tagging;cognition;e learning;taxonomy;ontologies;user model development;blogs;human resource management;knowledge based systems;two layer user model;user model;tagging	The present paper exposes a two layer user model (competences and interests) expressed through ontological constructs. As well, the paper illustrates a rule-based solution for developing the user profile in the context of the e-learning systems. The user model was conceived in the view of providing the users of an e-learning system with personalized functionalities, especially with recommendations on potential collaborators.	logic programming;personalization;user modeling;user profile	Mihaela Brut;Laura Asandului;Gheorghe Grigoras	2009	2009 Fourth International Conference on Internet and Web Applications and Services	10.1109/ICIW.2009.90	user interface design;rule-based system;probability density function;user modeling;computer user satisfaction;cognition;computer science;knowledge management;ontology;artificial intelligence;competence;database;multimedia;management;world wide web;collaboration	DB	-81.55233387267624	-44.481916454783835	4811
2d6c8ec71307f8db06afd2ee0f69f37affd779f7	metis: a scalable natural-language-based intelligent personal assistant for maritime services		We implement an intelligent personal conversational assistant, communicating in natural language and designed specifically for the maritime industry. A multi-stage message analysis is performed, first classifying the topic of the request and finally applying special parsers to extract the parameters needed to execute the task. Our system is scalable and robust, employing generic and efficient algorithms. Our contributions are manifold. First, we present a complex and multi-level natural-language-processing-based system, focused particularly on the maritime domain and incorporating expert knowledge of the field. Next, we introduce a series of algorithms that can extract deep information using the syntactic structure of the message. Lastly, we implement and evaluate our approach, testing and proving our system’s effectiveness and efficiency.	metis;natural language	Nikolaos Gkanatsios;Konstantina Mermikli;Serafeim Katsikas	2018		10.1007/978-3-319-99972-2_2	metis;natural language;parsing;theoretical computer science;scalability;syntax;computer science	Robotics	-18.148445631236772	-70.2469385860579	4815
76bff20d8c4467157bc31a76b714a7f0d119bb24	proceedings of the seventh annual structure in complexity theory conference, boston, massachusetts, usa, june 22-25, 1992					1992				Robotics	-54.664942639911764	-7.561274431673013	4818
901d690344722305d3e945a8442b236f8ab3fd0c	2011 spring simulation multi-conference, springsim '11, boston, ma, usa, april 03-07, 2011. volume 1: proceedings of the 2011 workshop on agent-directed simulation (ads)			simulation		2011				Vision	-52.75677129652789	-8.292990485950716	4822
66b9055f0e659c8613352cce935abf8ddee55c2d	trust in healthcare: an information perspective	trust;sweden;text;healthcare;information use;information studies;exploratory analysis;internet use;biblioteks och informationsvetenskap;national survey;survey data;general surveys;exploratory study	This article reports on an exploratory analysis of existing data obtained through a national survey carried out in Sweden. The survey questionnaire seeks information on a wide range of issues, including healthcare, library use and Internet use. The analysis presented here explores the relationship among these variables and the concept of trust in healthcare institutions. The results indicate that most of the correlations theoretically suggested were very small and that trust in health institutions in general is high but not strongly related to standard demographic variables found in a general survey of a large population. This exploratory study suggests that more specific indicators of health, experience from health institutions and health-related media exposure are needed to test, in greater depth, the relationships between information exposure, health and attitudes towards health institutions.	internet;variable (computer science)	Lars Höglund;Elena Maceviciute;Thomas D. Wilson	2004	Health Informatics Journal	10.1177/1460458204040667	social science;computer science;data science;survey data collection;data mining;trustworthy computing;exploratory research	HCI	-87.17758400541311	-15.651793443338939	4823
73eb10bbee22e5f0797e9a21b55d0fd5fd5a5495	the role of communication complexity in adaptive contextualization	cost benefit analysis cognition communication complexity computer mediated communication;complexity theory;atmospheric measurements;particle measurements;contextualization collaboration effort communication complexity computer mediated communication;adaptive contextualization structured communication task performance cost benefit framework unbalanced panel data analysis cognitive communication complexity message representation computer supported collaboration human communication theories communication process message contextualization computer mediated communication communication quality contextual information;collaboration;receivers;complexity theory receivers collaboration context atmospheric measurements particle measurements adaptation models;adaptation models;context	Research problem: Adding contextual information to a core message has been shown to be critical in improving communication quality, especially in computer mediated communication. This paper models how people contextualize messages in the face of changing communication complexity. Research question: Can changes in communication complexity that occur during the communication process explain and predict contextualization? Literature review: Theories of human communication and studies of computer supported collaboration suggest that communication complexity reflects potentially problematic conditions resulting from 1) the difference in perspective and context held by the collaborators; 2) the incompatibility between the message representation and the way it is interpreted and used by the receiver; and 3) the intensity of information exchanged between communicators. We use this definition as a basis of for developing a measure of cognitive communication complexity. The literature further suggests that higher communication complexity induces higher contextualization. Methodology: First, we conducted a pilot study to develop and validate measures of communication complexity. Second, we conducted a laboratory experiment, in which 258 participants working in pairs collaborated on a sixteen-step assembly task. They used a tailored system that structured each message as core (the essence of the message) and context (additional information that explains the core and the sender's perspective). We used unbalanced panel data analysis to examine the repeated measures of contextualization and communication complexity associated with each step of the task. Results and discussion: We found that collaborators respond to changes in communication complexity at the expense of higher collaborative effort. We offer a cost-benefit framework in which, at the step level, people contextualize to reduce the communication complexity, and at the task level, they additionally consider the impact of contextualization on task performance. The main limitation of this study was the need to structure the communication between collaborators, to control and measure contextualization. Future research can adapt and extend our measure of communication complexity to less structured communication.	communication complexity;computer-mediated communication;panel data;software incompatibility;unbalanced circuit	Adi Katz;Dov Te'eni	2014	IEEE Transactions on Professional Communication	10.1109/TPC.2014.2312454	communication noise;simulation;economics;computer science;knowledge management;communication;management;world wide web;collaboration	Visualization	-86.68825074606788	-1.3874445357147758	4836
f0024b6e4832362fded8f84b50bdd416a31cb15d	estimation and identification of spatio-temporal models with applications in engineering, healthcare and social science		Several natural phenomena are known to exhibit a spatio-temporal evolution process. The study of such processes, which is pivotal to our understanding of how best to predict and control spatio-temporal systems, has motivated researchers to develop appropriate tools that infer models and their parameters from observed data. This paper reviews this active area of research by providing an insight into the fundamental ideas spanning the development of spatio-temporal models, dimensionality reduction methods and techniques for state and parameter estimation. Recent advances are discussed in the context of novel spatio-temporal approaches proposed for applications in three specific domains – engineering, healthcare and social science. They illustrate the wide applicability of estimation and identification of spatio-temporal processes as novel advances in sensor systems and data collection are used to observe them.		Julian Mercieca;Visakan Kadirkamanathan	2016	Annual Reviews in Control	10.1016/j.arcontrol.2016.09.011	engineering;artificial intelligence;data science;data mining;management science	ML	-22.41374635336865	-34.959591436777444	4837
dc3397978cafea0f5159c25a83d49d204d137f39	artificial intelligence research and development, proceedings of the 11th international conference of the catalan association for artificial intelligence, ccia 2008, october 22-24, 2008, sant martí d'empúries, spain	artificial intelligent;research and development		artificial intelligence		2008			engineering;artificial intelligence;operations research	Robotics	-53.916671791803104	-10.483589531361538	4838
b6ca34d1c728572a93de5e33728dd3d776539801	blockchains, smart contracts and future applications (dagstuhl seminar 18152)		This report documents the Dagstuhl seminar 18152 Blockchains, Smart Contracts u0026 Future Applications. While Bitcoin currently works well in practice, there are many open questions regarding the long-term perspective of blockchain technologies, for both public and private/permissioned blockchains. It is yet unclear how processes can be designed to work in predictive ways and how to embed security in the lifecycle of smart contract development and deployment. Furthermore, the distributed nature of the system needs to be considered when thinking about which groups or individuals can influence future developments. Similar to u0027real-worldu0027 societies, blockchains are based on mutual recognition of conventions. Diverse academic disciplines as well as industry can and need to collaborate to advance research in blockchain and to fully understand how the technology might impact our future lives.	smart contract	Foteini Baldimtsi;Stefan Katzenbeisser;Volkmar Lotz;Edgar R. Weippl	2018	Dagstuhl Reports	10.4230/DagRep.8.4.20	knowledge management;software deployment;smart contract;discipline;blockchain;business	HCI	-62.08568341145522	-2.608780919558499	4840
fd2af4758ee53dc1a9befc7d38342cd025522440	handheld use in k-12: a descriptive account	michigan schools;collaborative work;rivers;handheld computers use in michigan schools;handheld computer;palm artifact management handheld computers use in michigan schools students michigan schools organizational abilities research aid group collaboration activities student tasks wireless ipaq;computer aided instruction;organizational abilities;collaborative tools;mobile radio notebook computers computer aided instruction;wireless ipaq;computer science education;group collaboration activities;mobile radio;research aid;palm artifact management;animation;time use;notebook computers;software tools;handheld computers educational institutions computer science education collaborative tools animation software tools rivers environmental management collaborative work peer to peer computing;peer to peer computing;student tasks;environmental management;handheld computers;students	This paper describes ways handheld computers have been used by students at four different Michigan schools. Regardless of age or environment, our experience has shown that the primary, and most powerful uses of handheld computers have not been for organizational purposes. While students do take advantage of the organizational abilities, handhelds are most often used as tools to aid in research, alternatives to paper-based tasks, group collaboration activities, and much more. In addition to describing student tasks, this paper provides a context as to how much time handheld computers are being used in each classroom. This framework of time use and task use provides a better understanding of what a classroom with handheld computers might look like.	computer;mobile device	Michael Curtis;Kathleen Luchini;William Bobrowsky;Chris Quintana;Elliot Soloway	2002		10.1109/WMTE.2002.1039217	simulation;human–computer interaction;computer science;multimedia	HCI	-69.88829021093069	-39.925810648222	4843
3dc3e27379c5133b7928feba6d54a9725fb6ad90	target-aware language models for spoken language recognition	language model	This paper studies a new way of constructing multiple phone tokenizers for language recognition. In this approach, each phone tokenizer for a target language will share a common set of acoustic models, while each tokenizer will have a unique phone-based language model (LM) trained for a specific target language. The target-aware language models (TALM) are constructed to capture the discriminative ability of individual phones for the desired target languages. The parallel phone tokenizers thus formed are shown to achieve better performance than the original phone recognizer. The proposed TALM is very different from the LM in the traditional PPRLM technique. First of all, the TALM applies the LM information in the front-end as opposed to PPRLM approach which uses a LM in the system back-end; Furthermore, the TALM exploits the discriminative phones occurrence statistics, which are different from the traditional n-gram statistics in PPRLM approach. A novel way of training TALM is also studied in this paper. Our experimental results show that the proposed method consistently improves the language recognition performance on NIST 1996, 2003 and 2007 LRE 30-second closed test sets.	acoustic cryptanalysis;compiler;finite-state machine;language identification;language model;lexical analysis;n-gram	Rong Tong;Bin Ma;Haizhou Li;Chng Eng Siong;Kong-Aik Lee	2009			language technology;picture language;universal networking language;language transfer;language identification;spoken language;object language;comprehension approach;natural language processing;computer science;artificial intelligence	NLP	-20.128572960194433	-85.380330463797	4847
a18adf2d6ddca56062a464e9e87a2be63c767d16	estimating the uniqueness of test scenarios derived from recorded real-world-driving-data using autoencoders		Advanced Driver Assistant Systems (ADAS) use a multitude of input signals for tasks like trajectory planning and control of vehicle dynamics provided by a large variety of information sources such as sensors and digital maps. To assure the feature’s valid behavior all realistically possible environmental situations have to be tested. The test scenarios used for simulation can be derived from real-worlddriving-data. However, the significance of derived scenarios is weakened by repetitive similar situations within the driving data, which increase the test efforts without providing new insights regarding the test of the ADAS. In this contribution, an automated selection algorithm for test scenarios based on relevant environmental parameters is presented. Starting with a randomly selected initial testset, the machine-learning concept of autoencoders is utilized to recognize novel scenarios within the data pool, which are iteratively added to the initial testset. Furthermore, the key parameters for the autoencoder’s performance are shown in depths. The approach is fully automated, so that the identified novel scenarios within an entire testset are automatically combined to a reduced testset of unique relevant scenarios. The achieved testset reduction and thereby the saving potential in simulation time is demonstrated on a dataset including several thousand test kilometers.	architecture design and assessment system;autoencoder;machine learning;map;randomness;scenario testing;selection algorithm;sensor;simulation;time series;trusted computer system evaluation criteria	Jacob Langner;Johannes Bach;Yi-Ying Hsiao;Stefan Otten;Marc Holzapfel;Eric Sax	2018	2018 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2018.8500464	uniqueness;selection algorithm;autoencoder;machine learning;vehicle dynamics;scenario testing;digital mapping;software;data modeling;computer science;artificial intelligence	Robotics	-14.022976012163804	-28.365271004004224	4850
32b3b073fdd9d054939f1bd7a87d0216866075d2	multilingual tokenization and part-of-speech tagging. lightweight versus heavyweight algorithms		This work focuses on morphological analysis of raw text and provides a recipe for tokenization, sentence splitting and part-of-speech tagging for all languages included in the Universal Dependencies Corpus. Scalability is an important issue when dealing with large-sized multilingual corpora. The experiments include both lightweight classifiers (linear and decision trees) and heavyweight LSTM-based architectures which are able to attain state-of-the-art results. All the experiments are carried out using the provided data “as-is”. We apply lightweight and heavyweight classifiers on 5 distinct tasks, on multiple languages; we present some lessons learned during the training process; we look at per-language results as well as task averages, we present model footprints, and finally draw a few conclusions regarding trade-offs between the classifiers’ characteristics.	algorithm;part-of-speech tagging;tokenization (data security)	Tiberiu Boros;Stefan Daniel Dumitrescu	2015		10.1007/978-3-319-93782-3_11	sequence labeling;tokenization (data security);linear model;artificial neural network;decision tree;scalability;machine learning;artificial intelligence;computer science;part-of-speech tagging;sentence	NLP	-21.371616782178258	-73.12129172675591	4852
648c9f2d0c4daa701e8203ccbe9459e87a4f25f9	challenges in ontology-based association rules mining		Data mining has emerged to address the problem of drawing interesting knowledge from data. Among the most used data mining techniques, we concentrate on association rules which lead to the derivation of useful associations and correlations within data. In parallel, the advance of the ontology which is one of the most important concepts in knowledge representation, has speedily altered the way of information structuring and sharing. Recently, the area of coupling association rules and ontology has been a focus for several researchers, and hence, the introduced strategies are rising very rapidly. This survey aims to discuss the ontology-based association rules mining methods, and to provide a vision for future work in such a promising issue.	association rule learning;data mining;knowledge representation and reasoning	Eya Ben Ahmed	2013	IJWA		association rule learning;computer science;knowledge management;data science;data mining	DB	-34.61946349015977	-4.5713918191233835	4854
f5cfa0573765277ac39ddb8b13d9b5edb9d319c6	variations in breast density and mammographic risk factors in different ethnic groups	book chapter;breast density;ethnicity;breast screening;digital;mammogram	This study investigates variations in mammographic density by ethnic group in women attending the NHS breast screening programme in Greater Manchester. Density was estimated using VolparaTM and QuantraTM. Data was analysed for 651 Asian/Asian British, 416 Black/Black British, 394 Jewish origin, 181 'Mixed', 700 'Other' and a random sample of 10,000 women who declared their ethnic origin as White British or Irish. Age ranged from 46---84 years and mean BMI was 27.4i¾?kg/m2. Fibroglandular volume VolparaTM was highest in women of Black/Black British origin 59.4i¾?cm3 and lowest in Asian/Asian British women 47.9i¾?cm3. After adjusting for a number of hormonal and other factors the magnitude of the difference between groups decreased, however, there were still a number of statistical differences between groups. Ethnic differences in mammographic density and personal factors may subsequently contribute to differences in breast cancer incidence.		Elaine F. Harkness;Fatik Bashir;Philip Foden;Megan Bydder;Soujanya Gadde;Mary Wilson;Anthony Maxwell;Emma Hurley;Anthony Howell;D Gareth R Evans;Susan M. Astley	2016		10.1007/978-3-319-41546-8_64	demography;medicine;gynecology;genealogy	ML	-62.492130996917695	-67.27443915163892	4863
948bacbd73431b0916cac3d32849e0b5d9f54d9c	automatic extraction of angiogenesis bioprocess from text	software;vocabulary;data mining;angiogenesis inhibitors;neovascularization pathologic;neovascularization physiologic;models statistical;artificial intelligence;biological processes;natural language processing;documentation	MOTIVATION Understanding key biological processes (bioprocesses) and their relationships with constituent biological entities and pharmaceutical agents is crucial for drug design and discovery. One way to harvest such information is searching the literature. However, bioprocesses are difficult to capture because they may occur in text in a variety of textual expressions. Moreover, a bioprocess is often composed of a series of bioevents, where a bioevent denotes changes to one or a group of cells involved in the bioprocess. Such bioevents are often used to refer to bioprocesses in text, which current techniques, relying solely on specialized lexicons, struggle to find.   RESULTS This article presents a range of methods for finding bioprocess terms and events. To facilitate the study, we built a gold standard corpus in which terms and events related to angiogenesis, a key biological process of the growth of new blood vessels, were annotated. Statistics of the annotated corpus revealed that over 36% of the text expressions that referred to angiogenesis appeared as events. The proposed methods respectively employed domain-specific vocabularies, a manually annotated corpus and unstructured domain-specific documents. Evaluation results showed that, while a supervised machine-learning model yielded the best precision, recall and F1 scores, the other methods achieved reasonable performance and less cost to develop.   AVAILABILITY The angiogenesis vocabularies, gold standard corpus, annotation guidelines and software described in this article are available at http://text0.mib.man.ac.uk/~mbassxw2/angiogenesis/   CONTACT xinglong.wang@gmail.com.	abstract summary;annotation;biological factors;biological processes;blood vessel;body of uterus;body tissue;conditional random field;contain (action);domain-specific language;entity;f1 score;information systems;kidney failure, chronic;language model;lexicon;medline;machine learning;national centre for text mining;parsing;pattern matching;relaxation;science;sensor;solutions;technical standard;temporomandibular joint disorders;terminology extraction;text corpus;treebank;vocabulary	Xinglong Wang;Iain McKendrick;Ian Barrett;Ian Dix;Tim French;Jun'ichi Tsujii;Sophia Ananiadou	2011		10.1093/bioinformatics/btr460	documentation;computer science;bioinformatics;data science;data mining	NLP	-35.17874446754268	-69.69550208466367	4864
a5fccf5987bb6a0100d25b05a11113b250059695	2nd workshop on cognitive architectures for social human-robot interaction 2016 (cogarch4shri 2016)		This volume is the proceedings of the 2nd workshop on Cognitive Architectures for Social Human-Robot Interaction, held at the ACM/IEEE HRI 2016 conference, which took place on Monday 7th March 2016, in Christchurch, New Zealand. Organised by Paul Baxter (Plymouth University, U.K.), J. Gregory Trafton (Naval Research Laboratory, USA), and Severin Lemaignan (Plymouth University, U.K.).	baxter (robot);cognitive architecture;human–robot interaction;plymouth	Paul Baxter;J. Gregory Trafton;Séverin Lemaignan	2016	CoRR		engineering	Visualization	-48.26560631749149	-10.845626088022511	4872
41dda71071b515daa7f3d2cfd80decfc7d701dc4	supplementary proceedings of the 4th international conference on analysis of images, social networks and texts (aist'2015), yekaterinburg, russia, april 9-11, 2015			social network		2015				Robotics	-57.74625107588099	-10.138078964869317	4875
bd1a2789db1be33252df92065a8d91f1aa33ddde	exploring the structure of tpack with video-embedded and discipline-focused assessments	pedagogical issues;evaluation methodologies;improving classroom teaching	The appropriate selection and implementation of tec hnology in instruction is made possible by teachers’ Technological Pedagogica l Content Knowledge (TPACK). The TPACK that inservice teachers develop is practi tioner-based and can be continuously transformed with teaching experiences. In this study, we constructed video-embedded and discipline-focused questionnaire s to measure science teachers’ TPACK. Item sets were generic across four disciplin es and designed to investigate teachers’ TPACK at different levels of the cognitiv e process. Each questionnaire was embedded with three instructional clips in which pr eservice teachers demonstrated their previously-prepared lessons on selected topic s in biology, chemistry, earth science, and physics. Through exploratory factor an alysis, four factors (i.e., evaluation, evaluation/synthesis , application/analysis , and knowledge/comprehension ) emerged from the data. The presumed hierarchical in terrelationships among these cognitive processes were investigated through a pat h analysis. The findings indicated that teachers’ TPACK at the knowledge/comprehension level made significant loadings to TPACK at higher levels, but this was no t the case for application/analysis . The disconnect for application/analysis within the simple-to-complex cognitive process hierarchy suggests that it should be viewed as different from the other three constructs that incorporate more instructional reas oning. The designs for the questionnaire items and embedded instructional clip s that were used to elicit practical knowledge and prompt teachers to respond are presen ted herein.	cognition;embedded system	Yi-Fen Yeh;Ying-Shao Hsu;Hsin-Kai Wu;Sung-Pei Chien	2017	Computers & Education	10.1016/j.compedu.2016.10.006	computer science;knowledge management;multimedia;pedagogy	HCI	-74.1200802497057	-42.6319146348047	4881
3e14c4e1c63e5a983518ae66f8b2822f5eceff33	centralities in large networks: algorithms and observations		Node centrality measures are important in a large number of graph applications, from search and ranking to social and biological network analysis. In this paper we study node centrality for very large graphs, up to billions of nodes and edges. Various definitions for centrality have been proposed, ranging from very simple (e.g., node degree) to more elaborate. However, measuring centrality in billion-scale graphs poses several challenges. Many of the “traditional” definitions such as closeness and betweenness were not designed with scalability in mind. Therefore, it is very difficult, if not impossible, to compute them both accurately and efficiently. In this paper, we propose centrality measures suitable for very large graphs, as well as scalable methods to effectively compute them. More specifically, we propose effective closeness and LINERANK which are designed for billion-scale graphs. We also develop algorithms to compute the proposed centrality measures in MAPREDUCE, a modern paradigm for large-scale, distributed data processing. We present extensive experimental results on both synthetic and real datasets, which demonstrate the scalability of our approach to very large graphs, as well as interesting findings and anomalies.	algorithm;apache hadoop;approximation;betweenness;biological network;centrality;computation;computational social science;distributed computing;evolving networks;information;line graph;mapreduce;programming paradigm;scalability;social network analysis;synthetic intelligence	U. Kang;Spiros Papadimitriou;Jimeng Sun;Hanghang Tong	2011		10.1137/1.9781611972818.11	artificial intelligence;scalability;computer science;biological network;machine learning;centrality;algorithm;closeness;ranging;ranking;betweenness centrality;graph	ML	-12.364179948920736	-41.306215204644154	4885
205d4ab3fd3cffbba88bb4975ca4010e8a4f5c33	science overlay maps: a new tool for research policy and library management	science and technology;temporal change	We present a novel approach to visually locate bodies of research within the sciences, both at each moment of time and dynamically. This article describes how this approach fits with other efforts to locally and globally map scientific outputs. We then show how these science overlay maps help benchmarking,explore collaborations, and track temporal changes, using examples of universities,corporations, funding agencies,and research topics. We address their conditions of application and discuss advantages, downsides, and limitations. Overlay maps especially help investigate the increasing number of scientific developments and organizations that do not fit within traditional disciplinary categories. We make these tools available online to enable researchers to explore the ongoing sociocognitive transformations of science and technology systems.	apple maps;benchmark (computing);emergence;fits;map;prospective search;requirement;socio-cognitive;traceability;transparency (graphic);web page	Ismael Rafols;Alan L. Porter;Loet Leydesdorff	2010	JASIST	10.1002/asi.21368	biology;science, technology and society	HPC	-70.26544429799303	-16.386434946274356	4887
d91a108f97813b66bbe357606c87b386d6e43305	special issue on disc 2011		This special issue of Distributed Computing is based on papers that originally appeared, in preliminary and abbreviated form, in the Proceedings of the 25th International Symposium on Distributed Computing (DISC 2011), held in Rome, Italy on September 20–22, 2011. The papers were chosen by the Program Committee from the 31 regular papers presented at the Symposium, based on their quality and representation of the range of topics addressed in the Symposium. In addition to being reviewed, in preliminary	disc;distributed computing	David Peleg	2013	Distributed Computing	10.1007/s00446-013-0193-0	geotechnical engineering;software engineering;engineering	Arch	-60.07947804828748	-16.9916367912508	4889
fb2f872a953781dbb01507b5489898e01221c497	stepbywatch: a smartwatch-based enhanced navigation system for visually impaired users		The worldwide diffusion of mobile technology has opened the door to a new era of distributed sensing. Indeed, mobile sensing and wireless technology can be exploited to create new information and services that have the potential to improve our lives in many ways. This becomes even more interesting if the benefits could reach the whole community, even people with disadvantages that are often left out by the digital divide. To this aim, we have developed a system able to offer an enhanced route navigation system, while at the same time gathering quality data through smartwatches. Even more interesting, we have endowed our system with an interaction paradigm based on vibration patterns so as to guide the user without the need for looking at the device. Our proposal avoids user distraction and field trials demonstrate its effectiveness when employed by visually impaired people.	mobile device;programming paradigm;smartphone;smartwatch;usability testing	Ombretta Gaggi;Claudio E. Palazzi;Matteo Ciman;Armir Bujari	2018	2018 15th IEEE Annual Consumer Communications & Networking Conference (CCNC)	10.1109/CCNC.2018.8319311	mobile technology;smartwatch;digital divide;wireless;distraction;navigation system;computer science;distributed computing;data acquisition;server	HCI	-50.7489696031031	-42.91604065158048	4896
b0ed84f483f7811aeff4a3a06551e858fb402cf3	cooperative game theory approaches for network partitioning		Data from a voluntary association are used to construct a new formal model for a traditional anthropological problem, fission in small groups. The process leading to fission is viewed as an unequal flow of sentiments and information across the ties in a social network. This flow is unequal because it is uniquely constrained by the contextual range and sensitivity of each relationship in the network. The subsequent differential sharing of sentiments leads to the formation of subgroups with more internal stability than the group as a whole, and results in fission. The Ford-Fulkerson labeling algorithm allows an accurate prediction of membership in the subgroups and of the locus of the fission to be made from measurements of the potential for information flow across each edge in the network. Methods for measurement of potential information flow are discussed, and it is shown that all appropriate techniques will generate the same predictions.	game theory;network partition	Konstantin E. Avrachenkov;Aleksei Yu. Kondratev;Vladimir V. Mazalov	2017		10.1007/978-3-319-62389-4_49	modularity (networks);clique percolation method;discrete mathematics;girvan–newman algorithm;social network;information flow (information theory);network formation;fission;theoretical computer science;cooperative game theory;social psychology;computer science	Theory	-91.3004883369005	-18.42288304674908	4898
67ef2a281b6b2d35f1d56293fb5439eed810b951	cross task study on mirex recent results: an index for evolution measurement and some stagnation hypotheses		In the last 20 years, Music Information Retrieval (MIR) has been an expanding research field, and the MIREX competition has become the main evaluation venue in MIR field. Analyzing recent results for various tasks of MIREX (MIR Evaluation eXchange), we observed that the evolution of task solutions follows two different patterns: for some tasks, the results apparently hit stagnation, whereas for others, they seem getting better over time. In this paper, (a) we compile the MIREX results of the last 6 years, (b) we propose a configurable quantitative index for evolution trend measurement of MIREX tasks, and (c) we discuss possible explanations or hypotheses for the stagnation phenomena hitting some of them. This paper hopes to incite a debate in the MIR research community about the progress in the field and how to adequately measure evolution trends.	compiler;emoticon;evolution;information retrieval;venue (sound system)	Ricardo Scholz;Geber Ramalho;Giordano Ribeiro de Eulalio Cabral	2016			machine learning;speech recognition;artificial intelligence;computer science	Web+IR	-41.07862660727377	-62.75208530293674	4903
cb14faa916f0eaae463b6ffb1c7c040466b912e7	relation between visual effects and gain of motion parallax	parallaxe;movimiento;profondeur stimulus;hombre;profundidad estimulo;parallax;stimulus depth;depth;percepcion;motion;paralaje;stimulus visuel;visual stimulus;mouvement;human;profundidad;estimulo visual;profondeur;perception;motion parallax;vision;homme	"""This paper examines v i s u a l e f f e c t s of motion pa ra l l ax (MP) which is an important element of depth percept ion. A d i sp l ay technology was developed which does no t cause a delay of motion pa ra l l ax t o a viewer watching an image with a motion p a r a l l a x rel a t e d to viewpoint pos i t i on . Using t h i s apparatus , a method of con t ro l was examined which a f f e c t s a viewer 's emotion by changing t h e magnitude of t h e motion p a r a l l a x . term """"gain of motion p a r a l l a x Gm"""" which r ep resen t s t h e magnitude of a motion pa ra l l a x i s def ined. An assumption i s made t h a t a v i s u a l e f f e c t induced by an image with a motion pa ra l l ax depends on Gm. t h i s assumption, t h e undetectable threshold of a delay of a motion p a r a l l a x was found t o be approximately 60 m s . t h a t the motion-parallax d i sp lay apparatus developed has s h o r t e r delay than t h i s value. By changing t h e va lue of Gm, s u b j e c t i v e evaluat ions were c a r r i e d o u t f o r t h r e e evaluat i o n items: and """"linkage."""" t h r e e i t e m s form func t ions of Gm which a r e """" sa tu ra t ion shape,"""" """"dul l peak shape"""" and ''sharp peak shape,"""" r e spec t ive ly . A"""	emoticon;linkage (software);naruto shippuden: clash of ninja revolution 3;pa-risc;parallax;spec#;visual effects	Haruo Hoshino;Nobuyuki Hiruma;Mitsuho Yamada;Tadahiko Fukuda	1991	Systems and Computers in Japan	10.1002/scj.4690220306	parallax;computer vision;kinetic depth effect;computer graphics (images)	AI	-43.896797439560906	-51.29450495655918	4909
d265a684e877ee21098c0f2797b752b0f08e4a68	dynamic large-scale gestural control in supercollider server		Discusses a number of classes in the JoshLib extension library for the SuperCollider real-time synthesis language. ProcMod gives the user the ability to control groups of events with global controls and gestural shaping, as well as real-time performance flexibility. ProcEvents and ProcSink give the composer and performer control over instances and overall structure of ProcMod events.		Joshua Parmenter	2007			computer hardware;operating system;world wide web	AI	-46.31386984391124	-35.55287868377341	4918
f0fdc44a27958093f7df3bbc739b3c1179298707	measuring the difficulty of activities for adaptive learning	difficulty estimation;difficulty measure;learning activity;adaptive learning	An effective adaptive learning system would theoretically maintain learners in a permanent state of flow. In this state, learners are completely focused on activities. To attain this state, the difficulty of learning activities must match learners’ skills. To perform this matching, it is essential to define, measure and deeply analyze difficulty. However, very few previous works deal with difficulty in depth. Most commonly, difficulty is defined as a one-dimensional value. This permits ordering activities, but limits the possibilities of deep analysis of activities and learners’ performance. This work proposes a new definition of difficulty and a way to measure it. The proposed definition depends on learners’ progress on activities over time. This expands the concept of difficulty over a two-dimensional space, also making it drawable. The difficulty graphs provide a rich interpretation with insights into the learning process. A practical case is presented: the PLMan learning system. This system is formed by a web application and a game to teach computational logic. The proposed definition is applied in this context. Measures are taken and analyzed using difficulty graphs. Some examples of these analyses are shown to illustrate the benefits of this proposal. Singularities and interesting spots are easily identified in graphs, providing insights in the activities. This new information lets experts adapt the learning system by improving activity classification and assignment. This first step lays solid foundations for automation, making the PLMan learning system fully adaptive.	computational logic;graph (discrete mathematics);graph of a function;match moving;mind;prolog;requirement;web application	Francisco José Gallego-Durán;Rafael Molina-Carmona;Faraón Llorens-Largo	2017	Universal Access in the Information Society	10.1007/s10209-017-0552-x	web application;computational logic;automation;computer science;machine learning;adaptive learning;flow (psychology);artificial intelligence;graph	AI	-77.77816598439485	-46.40250338420332	4921
e2407790e79b6a29270fc59320eb413c988bf6be	hasta: hasta training application learning theory based design of bharatanatyam hand gestures tutor	conferences training educational institutions mobile communication games engines;teaching computer based training computer games humanities mobile computing multimedia computing;bharatanatyam;kinect;blender;hastas;web cam hasta training application learning theory based design bharatanatyam hand gestures tutor indian classical dance forms functional aspects aesthetic appeal nritta pure dance performances teaching learning experience mobile application multimedia learning principles learner interface instructional strategy demo phases practice phases perfect phases blender game engine bge based demo practice and perfect module kinect;hastas bharatanatyam mobile application blender kinect;mobile application	"""Hastas (Hand Gestures) are key elements in any of the Indian Classical dance forms. They have both functional aspects and an aesthetic appeal during Nritta (pure dance) performances. In this paper we report a pilot study conducted to understand what is the desired teaching-learning experience for teaching the Hastas as perceived by the students and the instructors. Based on these need analysis we propose a design for developing a mobile application """"HasTA"""", as a Bharatanatyam gesture tutor. The design of the various elements in the tutor applies multimedia-learning principles to develop the learner interface. A proposed instructional strategy to use this application has essential 3 phases: demo - practice - perfect. An idea of a Blender Game Engine (BGE) based Demo, Practice and Perfect module in the application by integrating Kinect or web cam is discussed."""	blender game engine;kinect;mobile app;performance;tutor;webcam	Rwitajit Majumdar;Pooja Bhawar;Sameer Sahasrabudhe;Priya Dinesan	2014	2014 IEEE 14th International Conference on Advanced Learning Technologies	10.1109/ICALT.2014.188	simulation;computer science;artificial intelligence;multimedia;natural user interface;world wide web	Visualization	-69.57428428652733	-43.076813674208374	4933
4dac7984538644ae47e23d5449b327e40c64e51e	progress in artificial intelligence, 15th portuguese conference on artificial intelligence, epia 2011, lisbon, portugal, october 10-13, 2011. proceedings			epia;progress in artificial intelligence		2011		10.1007/978-3-642-24769-9		AI	-55.06925304396392	-9.442372907692302	4934
1425cee907627baeb8b57f39f814d05c41864f00	three social distance measures for film rankings	information sources;online searching;information retrieval;indexes;research methodology;search strategies;relevance information retrieval;information seeking;social distance;films	Abstract#R##N##R##N#We describe the use of three alternative methods for ranking films for information retrieval (IR). A large film-person incidence matrix is generated using the principle cast, directors, producers and screenwriters for each film. These attributes are used to measure film-film distances by creating a distance matrix: two films are considered to be adjacent if there is any overlap in the people associated with each film. The distance between any two films is measured by the shortest path used to connect them through their adjacent members. The second and third methods involve the creation of a similarity matrix that expresses the amount of overlap in the people associated with any two films using Dice's coefficient. A “product distance” matrix is then derived that express the distances between any two films based on the product of the similarity weights on a path that connects those films. The highest value is chosen when alternate paths connect the two films. We also describe an “accumulative difference distance” matrix that also expresses the distances among pairs of films. The distance, product distance and accumulative difference distance matrices are used to generate rankings for a random sample of films.		Gregory H. Leazer;Jonathan Furner;Satyajit Samanta	2003		10.1002/meet.1450400103	database index;relevance;computer science;machine learning;methodology;data mining;world wide web;information retrieval;social distance	HCI	-39.937499750759805	-57.79999593836187	4938
197a001d822808eb53b7c88f3529c5b71ea168c0	uaic participation at rte5		Textual entailment recognition is the task of deciding, given two text fragments, whether the meaning of one text can be deduced from the other. This year, at our third participation in the RTE competition, we improved the system built for the RTE4 competition. Main Task: The main idea of our system is to map every word in the hypothesis to one or more words in the text. For that, we transform the hypothesis, using extensive semantic knowledge from sources like DIRT, WordNet, VerbOcean, Wikipedia and the Acronym database. The main improvement this year was related to the pre-processing part. Last year we observed how this part can improve the quality of the output for the tools used (LingPipe and Minipar). Because this year the texts were obtained from a variety of sources and were not edited from their source documents, we focused on this part. Thus, we identify and eliminate special characters that occur frequently on web pages. This choice is based on the fact that “with or without these characters the meaning of the text is the same, but the quality of the tools output is improved. Additionally, we process the LingPipe output with GATE in order to identify some named entities categories unidentified by LingPipe such as nationality, language, and job. One of the better components of last year’s system, the one responsible with the solving of contradiction cases, has not functioned properly this year. Also, cases in which the texts were very long and hypothesis were very short, but for which most of the words in the hypothesis were found in the text, were not treated properly by our system, because we did not use proper differences that come from semantic role labeling. Pilot Task: Regarding the new pilot task introduced this year, we used Lucene in order to index documents in which we must identify sentences that entail a given hypothesis. On this index we performed searches using the initial hypotheses, and after filtering the results offered by Lucene, we applied our RTE system.	application programming interface;comefrom;gate;google search;nist hash function competition;named entity;named-entity recognition;preprocessor;semantic role labeling;symmetric multiprocessing;textual entailment;web page;wikipedia;wordnet	Adrian Iftene;Mihai Alex Moruz	2009				NLP	-29.247373239661762	-68.74013965225105	4941
83915a5f080d0e2663b0644715fee8ca104e6b1a	eleven quick tips for finding research data		1 Data Archiving and Networked Services, Royal Netherlands Academy of Arts and Sciences, The Hague, Netherlands, 2 National Snow and Ice Data Centre, Cooperative Institute for Research in Environmental Sciences, University of Colorado, Boulder, Colorado, United States of America, 3 College of University Libraries & Learning Sciences, The University of New Mexico, Albuquerque, New Mexico, United States of America, 4 Institute of Applied Biosciences, Centre for Research and Technology Hellas, Thessaloniki, Greece, 5 Research Data Management Solutions, Elsevier, Jericho, Vermont, United States of America, 6 Australia National Data Service, Melbourne, Australia	academy;algorithm;archive;biologic preservation;data quality;discoverability;environmental illness;library (computing);research data archiving;reuse (action);science;citation	Kathleen Gregory;Siri Jodha Khalsa;William K. Michener;Fotis E. Psomopoulos;Anita de Waard;Mingfang Wu	2018		10.1371/journal.pcbi.1006038	bioinformatics;biology	ML	-45.07080819259953	-10.69075016498163	4944
d64794ccda29dfb73778db3002da69d3b716aac9	co-production and co-creation in public services: resolving confusion and contradictions		Publications﻿continue﻿to﻿affirm﻿that﻿there﻿are﻿no﻿agreed﻿definitions﻿or﻿conceptual﻿frameworks﻿for﻿coproduction﻿and﻿co-creation﻿in﻿relation﻿to﻿public﻿services.﻿Consequently,﻿across﻿and﻿within﻿academic﻿ and﻿ grey﻿ literature﻿ lie﻿ many﻿ examples﻿ of﻿ confusion﻿ and﻿ contradictions.﻿ These﻿ hinder﻿ insightful﻿ discussion﻿and﻿explanatory﻿research.﻿This﻿paper﻿argues﻿that﻿underlying﻿this﻿muddle﻿is﻿a﻿failure﻿to﻿be﻿ clear﻿about﻿the﻿nature﻿and﻿structure﻿of﻿public﻿services.﻿The﻿commonly﻿used﻿“service﻿to﻿customers”﻿ model﻿from﻿commerce﻿is﻿a﻿misleading﻿oversimplification.﻿To﻿re-frame﻿the﻿discussions﻿on﻿co-creation﻿ and﻿co-production,﻿a﻿model﻿is﻿developed﻿of﻿a﻿generic﻿multi-actor,﻿multi-instrument﻿system﻿that﻿helps﻿ to﻿ identify﻿ the﻿real﻿ issues﻿associated﻿with﻿governmental﻿and﻿non-governmental﻿actors﻿combining﻿ to﻿achieve﻿a﻿social﻿outcome.﻿The﻿system﻿can﻿be﻿assessed﻿in﻿terms﻿of﻿relationships﻿(e.g.﻿degrees﻿of﻿ openness﻿and﻿collaboration)﻿and﻿the﻿role﻿of﻿technology﻿(e-government).﻿The﻿essential﻿role﻿of﻿the﻿ government﻿is﻿determined﻿to﻿be﻿policy﻿and﻿system﻿design. KEywoRdS Co-Creation, Co-Production, E-Government, Governance, Government, Instruments, Policy, Public Services, System	e-government	Paul Waller	2017	IJEGR	10.4018/IJEGR.2017040101	confusion;e-government;public relations;conceptual framework;grey literature;government;sociology;corporate governance;openness to experience;co-creation	HCI	-71.18440878726675	-0.03827651014692399	4946
97da3a91d44414c2f9bd88e33af5b2063bbcf2dd	artificial laboratories	artificial laboratory	A wide variety of mathematical and statistical software tools are available today, and the list grows daily. Means for representing and storing data and scientific information are likewise increasing, from sophisticated database and knowledge base technologies to high-speed, high-resolution graphics. Imagine a computing environment that couples all of these in a user-friendly way, using the best mathematical, computing, and AI technology to allow a scientist to quickly and easily perform all types of modeling and simulation by computer to assist in research. Imagine also that this computing environment is implemented in such a way that the human-computer interface is set up to resemble the laboratory or field environment in which real data might actually be obtained. Because of the range of computing capabilities at the scientist’s disposal and the ease with which these capabilities can be brought to bear on a research problem, a computing environment of this sort might be called an artificial laboratory. The artificial laboratory is, therefore, a computing environment that not only simulates the laboratory environment but also allows analysis of the data. Most likely, the laboratory environment that is simulated would be one which is relatively stable or mature. Research using custom-designed instruments, for example, might make it difficult to say with confidence that the measurement portion of the scientist–instrument–object-of-study system can be assumed to not influence the data which are obtained. Cutting-edge research might require frequent changes to computer programs used for analysis. An artificial laboratory is more suited for those situations where the laboratory technology is mature enough to permit focus only on the object of study. ne of the major characteristics of modern science is that theory and experimentation drive one another in a cyclic process of progressive refinement, leading to new conclusions about the world around us. Theory guides and directs the course of experimentation, and experimental results subsequently suggest ways in which theory must be modified. Some theories can, in fact, be discarded altogether. Over the past 30 years, computer modeling and simulation, analogous to theory and experimentation, has frequently guided scientific investigation. John von Neumann was one of the first to pioneer and promote the use of computers to numerically study the behavior of systems and use the results as a “heuristic guide to theorizing” (Burks 1966, p. 3). The solutions provided by the computer can serve as “an aid to discovering useful concepts, broad principles, and general theories.” Certainly, the use of computers in modeling and simulation of static and dynamic systems has become a significant part of scientific endeavor. Computer modeling is an extremely powerful way of working with representations that help us better understand the systems we study. We can guess that modeling and simulation will become ever more advanced in years to come, but where does the future of computers in science lie? As rapidly as computer technology is developing, extrapolations from the present are numerous and dangerous. Although we might successfully guess that parallel processing and supercomputing will be cheaper, faster, and more widely accessible, undoubtedly many aspects of future computing would amaze us if we could use a crystal ball and see them. Let us consider for a moment, though, one direction that the use of computers in science might take. An artificial laboratory is a hypothetical computing environment of the future that would integrate mathematical and statistical tools with AI methods to assist in computer modeling and simulation. An integrated approach of this kind has great potential for accelerating the rate of scientific discovery.	amaze (software);arthur burks;computer program;computer simulation;database;dynamical system;graphics;heuristic;human–computer interaction;image resolution;knowledge base;list of statistical packages;ne (complexity);numerical analysis;parallel computing;progressive refinement;refinement (computing);supercomputer;theory;usability	Mark E. Lacy	1989	AI Magazine			HPC	-8.567125314476213	-56.69147852416552	4948
23af7ea704b48de2a6e5933efad3fe1363ce052f	on quantum renyi entropies: a new definition and some properties		Martin Müller-Lennert,1 Frédéric Dupuis,2 Oleg Szehr,3 Serge Fehr,4 and Marco Tomamichel5 Department of Mathematics, ETH Zurich, 8092 Zürich, Switzerland Department of Computer Science, Aarhus University, 8200 Aarhus, Denmark Department of Mathematics, Technische Universität München, 85748 Garching, Germany CWI (Centrum Wiskunde & Informatica), 1090 Amsterdam, The Netherlands Centre for Quantum Technologies, National University of Singapore, Singapore 117543, Singapore	computer science;marco dorigo;quantum;rényi entropy;switzerland	Martin Müller-Lennert;Frédéric Dupuis;Oleg Szehr;Serge Fehr;Marco Tomamichel	2013	CoRR		physics;quantum;quantum mechanics	Theory	-46.29340914389017	-10.365123679773038	4954
7bbd0a48ec35b6d15cab30e1e4040be24ad2d562	phrase animation generation reflecting impression of words	kinetic typography;impression words;impression space;web search;kinetics	This paper proposes a phrase animation generation reflecting impressions of words. The process of generating phrase animations consists of two procedures; impression estimation and animation output. In the former procedure, impressions of an inputted phrase are estimated from impressions of an inputted adjective/adjectival verb. That is derived from the number of co-occurrence on web search between the adjective/adjectival verb and prepared specific words. Experiments are performed in order to confirm validity of outputted phrase animations. As a result, it is found that the phrase animations have the possibility to reflect impressions of inputted adjective/adjectival verb.	web search engine	Ryou Morita;Takehisa Onisawa	2008		10.1145/1501750.1501775	natural language processing;computer science;linguistics;communication	NLP	-15.054419127782493	-80.44789550257514	4958
64b503f536f8c5caa5e06b28591b54c67cc4ee2f	scaling effects for streaming video vs. static panorama in multirobot search	reducing temporal demands streaming video scaling effects static panorama multirobot search camera guided teleoperation controlling remote robots asynchronous control controlling multiple robots reviewing camera video urban search and rescue map interface conventional streaming video store panoramic images ancillary measures;reviewing camera video;streaming media cameras robot vision systems layout communication system control robot control feeds humans vehicles mobile robots;streaming video scaling effects;video streaming;conventional streaming video;scale effect;image processing;static panorama;video streaming cameras image processing multi robot systems telerobotics;camera guided teleoperation;streaming video;map interface;controlling remote robots;multirobot search;ancillary measures;navigation;store panoramic images;controlling multiple robots;streaming media;team performance;multi robot systems;urban search and rescue;telerobotics;panoramic image;search problems;asynchronous control;robot vision systems;cameras;robot kinematics;reducing temporal demands	Camera guided teleoperation has long been the preferred mode for controlling remote robots with other modes such as asynchronous control only used when unavoidable. Because controlling multiple robots places additional demands on the operator we hypothesized that removing the forced pace for reviewing camera video might reduce workload and improve performance. In an earlier experiment participants operated four teams performing a simulated urban search and rescue (USAR) task using a conventional streaming video plus map interface or an experimental interface without streaming video but with the ability to store panoramic images on the map to be viewed at leisure. Operators were more accurate in marking victims on maps using the conventional interface; however, ancillary measures suggested that the asynchronous interface succeeded in reducing temporal demands for switching between robots. This raised the possibility that the asynchronous interface might perform better if teams were larger. In this experiment we evaluate the usefulness of asynchronous video for teams of 4, 8, or 12 robots. Operators in the two conditions were equally successful in finding victims, however, the streaming video maintained its advantage for accuracy in locating victims.	2.5d;item unique identification;map;robot;streaming media	Prasanna Velagapudi;Huadong Wang;Paul Scerri;Michael Lewis;Katia P. Sycara	2009	2009 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2009.5354342	telerobotics;computer vision;navigation;simulation;image processing;computer science;artificial intelligence;multimedia;robot kinematics	Robotics	-42.7211930688131	-49.494510974480185	4963
dc770ba5aa644cc69425979e0080092c4bc391bb	information privacy in institutional and end-user tracking and recording technologies	personal computing;information privacy;tracking and recording technologies;capture and access;institutional;user interfaces and human computer interaction;theoretical analysis;computer science general;user attitudes;ubiquitous computing;computer science;credit cards;end user	This paper presents an analysis of attitudes towards everyday tracking and recording technologies (e.g., credit cards, store loyalty cards, store video cameras). This work focuses on both institutional and end-user tracking and recording technologies. In particular, this paper describes (1) an empirical interview and survey study of everyday institutional tracking and recording technologies and (2) an analysis of these empirical data against a framework originally used to describe tension points for end-user tracking and recording technologies. Results from the study demonstrate that people can be highly concerned with information privacy while simultaneously reporting significantly less concern regarding the use of everyday technologies that have the capabilities to collect, process, and disseminate personal information. The empirical results and theoretical analysis identify and begin to explain this dissonance. Furthermore, we provide extensions to the analytic framework for capture and access technologies to address differences, similarities, and interplay between institutional and end-user tracking and recording technologies. The results of this paper contribute to the fields of personal and ubiquitous computing by providing significant insight relevant to the evaluation, design, deployment, and adoption of new tracking and recording technologies.	amanda;bluetooth;discrepancy function;embedded system;experience;hayes microcomputer products;information privacy;jennifer rexford;personal and ubiquitous computing;personally identifiable information;software deployment;threat (computer);usability testing;user (computing);video;yang	David H. Nguyen;Gillian R. Hayes	2009	Personal and Ubiquitous Computing	10.1007/s00779-009-0229-4	end user;human–computer interaction;information privacy;computer science;operating system;multimedia;internet privacy;world wide web;computer security;ubiquitous computing	HCI	-57.86181252753551	-42.74004851239209	4966
448cbb295cc8585f8503def7ff58ce7a76aad9b3	a spatially distributed risk screening tool to assess climate and land use change impacts on water-related ecosystem services	ukcp09united kingdom climate projections 2009;lcms1988land cover map of scotland 1988;wfdwater framework directive;climate change;water resources;lca2050land capability for agriculture 2050;sepascottish environment protection agency;qualitative risk assessment;ipccintergovernmental panel on climate change;eueuropean union;land use;adaptation;lcm2007land cover map 2007;lcfland capability for forestry;esecosystem service s;fffuture flows;petpotential evapotranspiration;rbmpriver basin management plan ning;ecosystem services	"""To support the implementation of the European Water Framework Directive (WFD), and as part of a tiered approach to prioritise detailed modelling, a high-level screening methodology has been developed to assess the vulnerability of water-related ecosystem services (ES) to future change. The approach incorporates a range of spatially distributed scenarios of land use and climate, which are used as inputs to a qualitative risk assessment model underpinned by expert opinion. The method makes use of widely available datasets and provides a structured way of capturing and """"codifying"""" expert knowledge, as well as for assessing the degree of consensus between different expert groups. The range of model output reflects uncertainty in both the expert-derived assumptions and the climate & land use simulations considered. The approach has been developed in collaboration with the Scottish Environment Protection Agency (SEPA) and applied in Scotland to support the second cycle of River Basin Management Planning. We develop a transparent, structured methodology for capturing expert opinion.Estimated impacts include uncertainty in both future simulations and expert consensus.We consider 12 ecosystem services, 23 scenario combinations and more than 3000 catchments.Results have informed Scotland's second cycle of River Basin Management Planning."""	ecosystem services	James E. Sample;Ingrid Baber;Rebecca Badger	2016	Environmental Modelling and Software	10.1016/j.envsoft.2016.05.011	ecosystem services;biology;water resources;land use;hydrology;environmental protection;environmental resource management;climate change;ecology;adaptation	SE	-14.278399568080006	-20.81652485997184	4967
ddfa9cbf59ab95cb7162e2f135328f9a872291a2	building software testing skills in undergraduate students using spiral model approach	software testing;software engineering;spirals;computer science;buildings	Spiral Learning aims to strengthen students’ understanding of the basic concepts by revisiting the concepts periodically with different contexts and with increasing sophistication throughout the curriculum. This approach helps to overcome the limitations of the instructional design and delivery such as concepts taught in isolation and not being emphasized in later stages of learning leading to poor appreciation of learned concepts and repetition disregarding earlier knowledge limiting the depth of treatment. Software testing is an important skill required for computer science and engineering professionals. Students are able to write quality programs only if they know what is to be tested. Earlier, “software testing” was taught as a course in higher semester of undergraduate (UG) curriculum of computer science and engineering. As it was taught in isolation it was difficult for to build up requi red testing skill in the students. @@@@@@@This paper discusses the experience of authors in building software testing skills among the students of engineering degree program in computer science and engineering as a solution to make up for the deficiency in the earlier curriculum. Authors explain the need for building software testing skills seamlessly integrating with programming, software engineering and project courses through spiral approach.	angular defect;computer science;software engineering;software testing;spiral model;three utilities problem	Gopalkrishna Joshi;Padmashree Desai	2016	2016 IEEE Eighth International Conference on Technology for Education (T4E)	10.1109/T4E.2016.061	simulation;computer science;pedagogy;computer engineering	SE	-82.24500570380268	-35.14607173678996	4968
60549d73115299f669fed987e5d16fdd417b6f1a	mark on the globe: a quest for scientific bases of geographic information and its international influence	geographic information science;ncgia;digital elevation or terrain models;article;ontology;david m mark	David M. Mark published his first journal article in 1970. Since then, he has written or coauthored more than 220 publications over a period of 40 years as of 28 May 2012. Based on data from Web of Science (WoS) and Google Scholar, Mark’s publications have been cited over 7410 times by researchers in more than 80 countries or regions as of 28 May 2012, when this paper was first prepared. The geographic extent of Mark’s scholarly influence is truly global. An examination of his 20 most cited articles reveals that his work in diverse areas as digital elevation models, geomorphology, geographic cognition, and ontology of the geospatial domain enjoyed a lasting impact worldwide.		F. Benjamin Zhan;Xi Gong;Xingjian Liu	2014	International Journal of Geographical Information Science	10.1080/13658816.2013.847186	geography;data science;ontology;cartography	DB	-75.9771878089981	-20.459909238535484	4970
899c941bf642b2674373f295d3b1ab8b90818fdd	from design to implementation to practice a learning by teaching system: betty’s brain	science instruction;brain;educational research;learning processes;computer assisted instruction;guidelines;independent study;learning problems;scaffolding teaching technique;models;teaching methods;science teachers	This paper presents an overview of 10 years of research with the Betty’s Brain computer-based learning environment. We discuss the theoretical basis for Betty’s Brain and the learning-by-teaching paradigm. We also highlight our key research findings, and discuss how these findings have shaped subsequent research. Throughout the course of this research, our goal has been to help students become effective and independent science learners. In general, our results have demonstrated that the learning by teaching paradigm implemented as a computer based learning environment (specifically the Betty’s Brain system) provides a social framework that engages students and helps them learn. However, students also face difficulties when going about the complex tasks of learning, constructing, and analyzing their learned science models. We have developed approaches for identifying and supporting students who have difficulties in the environment, and we are actively working toward adding more adaptive scaffolding functionality to support student learning.	programming paradigm	Gautam Biswas;James Segedy;Kritya Bunchongchit	2015	International Journal of Artificial Intelligence in Education	10.1007/s40593-015-0057-9	mathematics education;cooperative learning;social science;educational research;computer science;artificial intelligence;experiential learning;learning sciences;teaching and learning center;teaching method;multimedia;active learning;independent study;adaptive learning;pedagogy	AI	-73.59024018742394	-37.53457962155868	4974
d53fd05963b8553f1044d4e6ab27464a7d4d46ce	network forensics and challenges for cybersecurity		Societies in the contemporary world are becoming more and more dependent on open networks such as the Internet where commercial activities, business transactions, and government services are realized. This has led to the fast development of new cyber threats and information security issues, which are utilized by cyber criminals. Mistrust for telecommunications and computer network technologies have tremendous socioeconomic impacts on global enterprises as well as individuals. Moreover, the occurrence of international frauds often requires the investigation of facts that cross international borders. They are also often subject to different jurisdictions and legal systems. The increased complexity of the communication and networking infrastructure is making investigation of the crimes difficult. Clues of illegal digital activities are often buried in large volumes of data that are hard to inspect in order to detect crimes and collect evidence. This poses new challenges for law enforcement and forces computer societies to utilize digital forensics to combat the growing number of cybercrimes. Forensic professionals need to be fully prepared in order to be able to provide effective evidence. To achieve these goals forensic techniques must keep pace with new technologies. That is why the field of digital forensics is becomingmore and more important for law enforcement and information and network security. Network forensics is a newly emerged research area, and its importance has attracted a great attention among computer professionals, law enforcers, and practitioners. It is a multidisciplinary area that includes multiple fields, i.e., law, computer science, finance, networking, data mining, and criminal justice. However, network forensics still faces diverse challenges and issues in terms of the efficiency of digital evidence processing and the related forensic procedures. In this special issue, we are delighted to present a selection of ten papers, which, in our opinion, will contribute to the enhancement of knowledge in network forensics and cybersecurity. The collection of high-quality research papers provides a view on the latest research advances on special security incidents, steganography, and steganalysis. In the first paper [1], Dohoon Kim, Jungbean Lee, YoungGab Kim, Byungsik Yoon, and Hoh Peter propose an architecture for IMS/SIP-based lawful interception in wireless 3G networks and original techniques of interception, where content service providers are separated from network providers. The authors present the results of a Quality of Service performance analysis conducted on their proposed interception architecture for various numbers of IMS users. The authors of the second paper [2], Robert Filasiak, Maciej Grzenda, Marcin Luckner, and Pawel Zawistowski, introduce a new way of testing methods detecting network threats, including a procedure for creating realistic reference data sets describing network threats and the processing and use of these data sets in testing environments. The new approach is evaluated on the basis of the problem of spam detection, and two measures, accuracy and performance of threat detection, are considered. Bo-Chao Cheng, Guo-Tan Liao, Hsu-Chen Huang, and Ping-Hai Hsu in their paper [3] propose a new mechanism to overcome the disadvantage of requiring huge data storage for network forensics analysis tools for denial-of-service attacks. The experimental results confirmed that the proposed mechanism, based on advanced training methods to build proper data classifiers, is useful in reduction of data quantity. W. Mazurczyk (*) :K. Szczypiorski Warsaw University of Technology, Warsaw, Poland e-mail: wmazurczyk@tele.pw.edu.pl	computer security	Wojciech Mazurczyk;Krzysztof Szczypiorski;Hui Tian	2014	Annales des Télécommunications	10.1007/s12243-014-0434-7	information security;the internet;architecture;network security;computer security;network forensics;government;lawful interception;digital forensics;mathematics	Crypto	-71.05907809370363	-9.78258971420897	4976
c1dbdb204ecb6b57dd21a1b01496d2415370c49d	computer self-efficacy, gender, and educational background in south africa	information technology computer self efficacy gender educational background south africa women;information technology;computer science education;gender issues computer science education information technology;gender issues;computer self efficacy;self efficacy;africa educational institutions computer science information technology software measurement software packages programming profession nominations and elections computer science education;south africa	Research has demonstrated possible factors for low participation by women, including self-efficacy. This paper considers computer self-efficacy and its relationship to gender and educational background. Self-efficacy is based on self-perception and is defined as the belief an individual has about their ability to perform a particular task. Self-efficacy is important as it influences the choice of activities by an individual, the amount of effort they will expend on a task and how long they will persevere in stressful situations to complete the task. Self-efficacy beliefs about computing may be a factor in whether people choose to get involved in computing. Therefore, self-efficacy is linked to participation rates and hence important to consider in our attempts to understand why people choose to become involved in information technology.		Vashti Galpin;Ian Douglas Sanders;Heather Turner;Bernadine Venter	2003	IEEE Technol. Soc. Mag.	10.1109/MTAS.2003.1237471	self-efficacy;social science;computer science;law;information technology	Vision	-83.15931739711144	-33.49378065169584	4992
7bec8b4d9cab6a1b3fd85abedc494be7e1cd1d37	community meeting the namibian education technology policy with olpc's xo laptops: is it a viable approach?	community development	Research problem    There is a need in the literature to describe the implementation processes of technology integration in education through community involvement. In particular, there is limited research available about the mechanism or process behind the community technology trends in Namibia. Few cases explore community involvement in meeting educational technology policy needs. The ICT Policy for Education and the Tech/Na! Implementation policy plan aims to prepare learners to participate in new global economies of the 21st century. It also recognizes that presently, schools and other educational institutions are ill-prepared for the demands of the 21 st  century (ICT policy for Education, 2004).  The policy also presupposes that integrating technology in the classroom is the appropriate vehicle to achieve the goal of knowledge, equity, quality and access for all. Although the Namibian Ministry of Education has focused on developing the technology infrastructure at secondary school level first, many educators and community activists has argued that technology integration would be more successful if implemented at primary school level.  It is for this purpose that the Ngoma community explored ways in which to integrate technology in and outside of the classroom as a community effort.          Key Findings    Results in this case study reveals that despite the valiant efforts of community the educational approaches and understanding of the policy hampered further advancement of these XO computers in the schools for learning. Moreover, the OLPC model approach of ownership and alleged focus on constructivist education and 'digital utopianism appeared to be conflicting in the implementation and sustainability of the community project. Community members priorities changed as the project was implemented due to events of thefts, parent complaints which resulted in short-term ineffective solutions. The Itenge Development Foundation remains an integral part of the project, however with minimal community involvement and use of laptops.	laptop;olpc xo	Perien J. Boer	2015	J. Community Informatics		community organization;knowledge management;political science;management;pedagogy	HCI	-76.2736063253094	-31.645741562857832	4996
829dca547e98a7cccaac5aca457105d5fb439e47	no task left behind?: examining the nature of fragmented work	empirical study;three dimensions;interruptions;information overload;attention management;multi tasking	We present data from detailed observation of 24 information workers that shows that they experience work fragmentation as common practice. We consider that work fragmentation has two components: length of time spent in an activity, and frequency of interruptions. We examined work fragmentation along three dimensions: effect of collocation, type of interruption, and resumption of work. We found work to be highly fragmented: people average little time in working spheres before switching and 57% of their working spheres are interrupted. Collocated people work longer before switching but have more interruptions. Most internal interruptions are due to personal work whereas most external interruptions are due to central work. Though most interrupted work is resumed on the same day, more than two intervening activities occur before it is. We discuss implications for technology design: how our results can be used to support people to maintain continuity within a larger framework of their working spheres.	collocation;fork (software development);fragmentation (computing);interrupt;scott continuity	Gloria Mark;Víctor M. González;Justin Harris	2005		10.1145/1054972.1055017	three-dimensional space;simulation;human multitasking;computer science;information overload;empirical research;world wide web	HCI	-85.65533738691012	-3.624315469452696	5007
166150b9305e3fa916da84e0aeed2f63f22b99c9	data organization issues in presence systems		"""These components are poorly developed in the Region. They require clear responsibility and accountability structures, setting of objectives and targets for individuals and departments, and mechanisms for motivating people and for providing feedback about their achievements. Lack of organizational rationality, limited organizational skills, and inability to manage and use information for decision-making constitute significant issues. Illiteracy is a barrier to the growing area of consumer-oriented health applications or """" consumer informatics """" , the basis for individual access to health information and self-help. Adequate institutional infrastructure requires the presence of a framework that allows information to be used in a way that encourages individuals to take advantage of existing data according to their particular needs and the objectives of the organization. A recent survey of the health information infrastructure in the Region revealed major problems and constraints related to data collection, information utilization and dissemination, and the capacitation of human resources. The survey (PAHO/WHO Health Services Information Systems Resources Survey), conducted in 1996, had the objective of determining the status of development of the information function in the Region, including organizational development and infrastructure. Key informants in twenty-four countries responded to the survey. Data capture and its accuracy represent the most serious problem in the operation of information systems, and major stumbling blocks confronted by systems operators relate to the quality of data sources and timely data collection and recording. An analysis of the degree of development of nine core information systems functions studied by the PAHO/WHO Health Services Information Systems Resources Survey showed that nearly all countries conduct systematic health data collection, recording, and archiving, based on norms and standards defined at the national level (Table 1). Most of the information collected refers to services provided and epidemiological surveillance. In two-thirds of the countries it was considered to be of intermediate level of detail and data organization, in about one-sixth to be of low level of detail and data organization, and in only 12 to 16% of cases considered to be advanced. Significantly, data related to users and their families, the environment, health risk factors, user satisfaction with health services and violence to women and children were not collected or sporadically collected in about two-thirds of the countries surveyed. When data are processed and information is available, its utilization by health professionals is another important problem. Of the seven areas of application studied, the level of information use was …"""	archive;computer user satisfaction;feedback;informatics;information systems;information system;level of detail;rationality;stumbleupon	Ramesh Jain	1998				HCI	-60.87043395990953	-62.63417665777735	5012
aeb7136cc634649b34482de001794df5deaf49e2	a system for analyzing facial expression and verbal response of a person while answering interview questions on video		We have developed a system for analyzing facial expressions of a person while answering interview questions on a video. A video capturing the answerer is analyzed by OpenCV and the feature parameter for an eye area in addition to the mouth area focused in our reported research. Moreover, the time to utterance of the person answering just after an interview question and the fundamental frequencies of his or her voice are measured for analyzing his or her mental state.	mental state;opencv	Taro Asada;Yasunari Yoshitomi;Masayoshi Tabuse	2017	JRNAL	10.2991/jrnal.2017.4.2.2	verbal response;cognitive psychology;multimedia;facial expression;psychology	Vision	-51.11935385930526	-48.95771380174503	5016
08ef099b96aabe3c1ed9b7e27df802c350b6ae69	the underrepresentation of women in computing fields: a synthesis of literature using a life course perspective		Using a life course perspective, this literature review synthesizes research on women’s underrepresentation in computing fields across four life stages: 1) pre-high school; 2) high school; 3) college major choice and persistence; and 4) post-baccalaureate employment. Issues associated with access to, and use of, computing resources at the pre-high school and high school levels are associated with gender differences in interest and attitudes toward computing. At the college level, environmental context (classroom design, interactions with peers and role models, signals from stereotypical images) contribute to whether students will major in computing, whereas psychosocial factors (e.g., sense of belonging and self-efficacy) and departmental culture play a role in persistence in computing fields. As in other fields, issues associated with work-life conflict, occupational culture, and mentoring/networking opportunities play a role in women’s participation in the computing workforce. Several initiatives and programs have been implemented to address women’s underrepresentation in computing fields. While great strides have been made in making computing more accessible, the life course perspective highlights the importance of longitudinal studies in identifying students’ pathways to and through computing fields, as well as how interventions across life stages may intersect or cumulate to generate trends in computing participation.	interaction;persistence (computer science);women in computing	Joyce B. Main;Corey Schimpf	2017	IEEE Transactions on Education	10.1109/TE.2017.2704060	computer engineering;women in computing;life course approach;computer science;applied psychology;psychosocial;self-efficacy;human–computer interaction;psychological intervention;workforce	HPC	-74.63527903829991	-33.7096577097212	5020
e0258e2cb460f03d2783f9f513a0daf5b58c0701	neural networks for scientific paper classification	citation analysis;document handling;neural networks;content based naive bayes method;neural nets;bayes methods;naive bayes;neural networks artificial neural networks system performance search engines data mining feature extraction mathematics statistics computer science artificial intelligence;classification;system performance;citation link structures;neural nets bayes methods citation analysis classification document handling learning artificial intelligence;scientific paper classification;document class labels neural networks scientific paper classification content based naive bayes method citation link structures;learning artificial intelligence;document class labels;neural network	This paper describes an approach to the use of neural networks for improving the scientific paper classification performance. On the basis of the initial classification results obtained from the content-based naive Bayes method, this approach uses neural networks to model the citation link structures of the scientific papers for refining the class labels of the documents. The approach is examined and compared with the naive Bayes method on a standard paper classification data set with increasing training set sizes. The results suggest that using citation link structures, neural networks can significantly improve the system performance over the content-based naive Bayes method for all the training set sizes	bayesian network;hidden markov model;markov chain;naive bayes classifier;neural networks;scientific literature;test set	Mengjie Zhang;Xiaoying Gao;Minh Duc Cao;Yuejin Ma	2006	First International Conference on Innovative Computing, Information and Control - Volume I (ICICIC'06)	10.1109/ICICIC.2006.319	naive bayes classifier;biological classification;computer science;artificial intelligence;machine learning;pattern recognition;data mining;artificial neural network	AI	-21.338908215795836	-63.518043999480106	5022
db5114030451868e2b21bea8ec47e1f42285920f	18th international conference on pattern recognition (icpr 2006), 20-24 august 2006, hong kong, china			pattern recognition		2006				Robotics	-55.31462936659922	-8.986886842858551	5026
3c52815050b9cd7392ca1b2e40839f78daced986	emotional modeling of the green purchase intention improvement using the viral marketing in the social networks	viral marketing emotions;social network;green purchase intention;social value;consumer	This study explores a model of viral marketing emotional methods to increase the green purchase intention in the social networks. In the process of this research, 500 forms were distributed to respondents, and 384 responses used for analysis. All of the viral marketing emotional method items were created by Delphi method. The study discovered that the viral marketing-based joy and surprise have a significant positive effect on the social value of the green product consumption. Also, the effect of the social value of green product consumption on the green purchase intention was confirmed. The green activists and marketers can improve their green product markets for the future using this approach to viral marketing. In this way, the marketers in all green product industries can increase the consumption of the green product. The main contribution of this study is the light it sheds on how the viral marketing emotions have an effect on the green purchase intention in the social network.		Yaser Sobhanifard;Ghodrat Allah Balighi	2018	Social Network Analysis and Mining	10.1007/s13278-018-0528-8	marketing;viral marketing;social network;business;delphi method;product market	Web+IR	-87.44296043922294	-12.333948067822794	5034
8ed07b145e348ab31504121c0cb78eb6dfa585e7	using a sustainable livelihoods approach to assessing the impact of icts in development	sustainable livelihoods;access;evaluation	This paper describes the sustainable livelihoods framework as a useful tool in assessing the contribution of ICTs to development projects.  Assessing the role of ICTs in development can be difficult because they are so multifaceted, and because the effect of ICT use is often indirect.  This paper argues that applying the sustainable livelihood frameworks in assessment can help to broaden their scope in a manageable way and prove more analytically rigorous than other available methods.  The example of an impact assessment of a Colombian telecentre is used to demonstrate how such an approach can be applied.		Sarah Parkinson;Ricardo Ramírez	2006	J. Community Informatics		environmental planning;geography;environmental resource management;economic growth	HCI	-77.98783775320996	-5.803367861656122	5041
178d069ca68c81e2d06e9b45ef66f50fd84d8bcd	two-handed gesture in multi-modal natural dialog	natural dialog;gestural input;two handed input;multi modal interaction	Tracking both hands in free-space with accompanying speech input can augment the user's ability to communicate with computers. This paper discusses the kinds of situations which call for two-handed input and not just the single hand, and reports a prototype in which two-handed gestures serve to input concepts, both static and dynamic, manipulate displayed items, and specify actions to be taken. Future directions include enlargement of the vocabulary of two-handed “coverbal” gestures and the modulation by gaze of gestural intent.	computer;gesture recognition;modal logic;modulation;prototype;vocabulary;dialog	Richard A. Bolt;Edward Herranz	1992		10.1145/142621.142623	speech recognition;computer science;dialog system;multimedia	HCI	-46.481112878908505	-41.92990072038918	5044
0cbfb6a9ffe740d98f25625bbc7ce503bb865021	a new dynamic hmm model for speech recognition	speech recognition	In this paper, we describe a new method to perform speech recognition based on Dynamic HMM architecture. Pitch values are treated as hidden layer and used to modify the parameters of observation probability functions. The results show that the new model achieves approximately 10 percent relative error reductions both in base-syllable recognition task and tonal syllable recognition task. The new method can be used compatibly with conventional HMM based EM training algorithm and Viterbi decoding algorithm.	approximation error;hidden markov model;multilayer perceptron;speech recognition;syllable;viterbi algorithm	Feili Chen;Eric Chang	2001			speech recognition;architecture;viterbi decoder;artificial intelligence;hidden markov model;syllable;speaker recognition;pattern recognition;computer science;approximation error	NLP	-17.617585772951056	-88.32745166270564	5049
40789322ab882df21fb50f98a6048a32a0657035	career advisor expert system based on myers briggs personality assessment		The knowledge of what career to specialize in could be a late discovery for adults who have traded their youthful years through several professions/vocations but found no fulfillment. On the other hand, it could be a strenuous exercise for children and youths who are exposed to different academic areas. The aim of this project is to develop a career-advisor expert system based on Myer-Briggs Personality Assessment. It advises the user based on his/her personality. This is achieved through the method of creating facts from the Myers-Briggs Type Indicator (MBTI) thereby mapping them to common Careers using a rule-based system based on the sixteen Personality Types (according to Myers-Briggs). All these facts and rules form the database whereas ―Prolog‖ which stands for ―Programming in Logic‖ is the tool used for the implementation. The results of the query determine whether an advisee should choose a particular career or not. It displays ―true‖ if he/she could choose the predetermined career and ―false‖ if he/she should not. The results equally lists the possible career paths an advisee could follow. For example, when asked the career that someone with the personality trait of Introversion-Intuition-Thinking-Judging can pursue, it advises the following careers: Scientist, Engineer, Professor, Teacher, Medical Doctor, Dentist, etc. In conclusion, this expert system would minimize cost, alleviate career problems and always provide reliable career advice void of human error. Meanwhile future work can focus on the engineering of other models that can influence the choice of career other than the complex personality trait. CCS Concepts • Information systems ➝ Information systems applications ➝ Decision-support systems ➝ Expert systems	expert system;human error;information system;prolog;rule-based system	Ayodeji Iwayemi;Bolanle F. Oladejo;Damilare S. Adeleke	2016			expert system;applied psychology;personality assessment inventory;psychology	AI	-62.82928927175816	-66.31483480020026	5053
0f162636a1a5deb4576fafbe023bcb12839a9813	on the statistical estimation of stochastic finite-state transducers in machine translation	computer assisted translation;text input;speech translation;expectation maximization;word alignment;natural language;grammatical inference;statistical techniques;finite state transducer;statistical estimation;machine translation	"""The inference of finite-state transducers from bilingual training data plays an important role in many natural-language tasks and mainly in machine translation. However, there are only a few techniques to infer such models. One of these techniques is the grammatical inference and alignments for transducer inference (GIATI) technique that has proven to be very adequate for speech translation, text-input machine translation, or computer-assisted translation. GIATI is a heuristic technique that requires segmented training data (i.e., the input sentences and the output sentences must be segmented with the restriction that the input segments and the output segments must be monotone aligned). For the purpose of obtaining segmented training data, pure statistical word-alignment models are used. This technique is revisited in this article. The main goal is to formally derive the complete GIATI technique using classical expectation-maximization statistical estimation procedure. This new approach allows us to avoid a hard dependence on heuristic """"external"""" statistical techniques (statistical alignments and n-grams). A first set of experimental results obtained in a machine-translation task are also reported to initially validate this new version of the inference technique of finite-state transducers."""	estimation theory;statistical machine translation;transducer	Jesús Andrés-Ferrer;Francisco Casacuberta;Alfons Juan-Císcar	2008	Applied Artificial Intelligence	10.1080/08839510701853051	natural language processing;finite state transducer;statistical theory;speech recognition;transfer-based machine translation;example-based machine translation;expectation–maximization algorithm;computer science;machine learning;pattern recognition;machine translation;rule-based machine translation;natural language	AI	-23.097982083205224	-77.98377137989952	5054
270321b1e6ef3ba9cb4dd67e43adbf62b84d051a	self-adaptive user profiles for large-scale data delivery	information resources;incremental nature;information retrieval;bandwidth allocation;user interests;filters;user access behavior;user feedback;complex user interests;large scale data delivery;push based data delivery;profile sizes;profile sizes self adaptive user profiles large scale data delivery push based data delivery user interests scheduling bandwidth allocation routing decisions user profiles incremental algorithm user feedback single weighted interest vector multiple interest vectors user access behavior flexible approach complex user interests profile complexity incremental nature large scale information filtering applications push based www page dissemination yahoo filtering effectiveness;push based www page dissemination;single weighted interest vector;flexible approach;large scale;user profile;self adaptive user profiles;routing decisions;ear;human factors;monitoring;scheduling;multiple interest vectors;filtering effectiveness;bandwidth;user profiles;large scale information filtering applications;world wide web;large scale systems national electric code world wide web information retrieval computer science bandwidth monitoring ear filters read only memory;national electric code;incremental algorithm;computer science;profile complexity;human factors document delivery information retrieval user interfaces information resources;user interfaces;read only memory;document delivery;large scale systems;yahoo	Push-based data delivery requires knowledge of user interests for making scheduling, bandwidth allocation, and routing decisions. Such information is maintained as user profiles. We propose a new incremental algorithm for constructing user profiles based on monitoring and user feedback. In contrast to earlier approaches, which typically represent profiles as a single weighted interest vector, we represent user profiles as multiple interest vectors, whose number, size, and elements change adaptively based on user access behavior. This flexible approach allows the profile to more accurately represent complex user interests. Although there has been significant research on user profiles, our approach is unique in that it can be tuned to trade off profile complexity and quality. This feature, together with its incremental nature, makes our method suitable for use in large-scale information filtering applications such as push-based WWW page dissemination. We evaluate the method by experimentally investigating its ability to categorize WWW pages taken from Yahoo! categories. Our results show that the method can provide high filtering effectiveness with modest profile sizes and can effectively adapt to changes in users’ interests.	algorithm;categorization;experiment;information filtering system;modal logic;population;publish–subscribe pattern;routing;scheduling (computing);user profile;www;xml	Ugur Çetintemel;Michael J. Franklin;C. Lee Giles	2000		10.1109/ICDE.2000.839477	national electrical code;user modeling;computer science;human factors and ergonomics;operating system;data mining;database;user interface;scheduling;world wide web;read-only memory;bandwidth;bandwidth allocation	DB	-30.817949301449538	-52.314660490674854	5057
ade120a2604809b3ed54832bb3ae12cdf744ed8a	how can software engineers help make government better?	software engineering;federal government	Using their technical expertise to bring transparency to the federal government, developers are unlocking data one API at a time.	application programming interface;software engineer	Luigi Montanez	2011	ACM Crossroads	10.1145/2043236.2043247	computer science	HCI	-62.912696876530376	-3.212431874476128	5060
30a748c2abaf10c3e4793282112ddd83e3377537	control of complex systems: k. aström, p. albertos, m. blamke, a. isidori, w. schaufelberger and r. sanz; springer, london, 2001, isbn: 1-85233-324-3	complex system	complex system;book review	complex systems;international standard book number;springer (tank)	Zhong-Ping Jiang	2003	Automatica	10.1016/S0005-1098(03)00120-1	mathematics	DB	-56.68988806970404	-12.05375168802321	5063
dc413d611e69e5e8e39beee84bb3e902688f107f	towards efficient and precise queries over ten million asteroid trajectory models	million asteroid trajectory model;precise query	We consider the problem of finding known asteroids in a given region of space and time. Each asteroid’s trajectory is known precisely at any given point in time, but evaluation of the model describing its location is prohibitively expensive at query time. We propose a framework for sampling the base model and indexing the resulting “observations.” Our system includes 11 million simulated asteroids, and our requirements include 5 milliarcsecond accuracy and 15 second query response time. We evaluate the effect of various sampling and indexing alternatives in this approach and propose two exemplar solutions: a faster but space-intensive interpolation-based method, or a slower method that relies on bounding regions tailored to the object’s behavior but requires fewer sampled points. We implement all solutions in a relational database and evaluate them on a full-scale dataset of known asteroid trajectories.	cubic hermite spline;cubic function;full scale;molecular orbital;polynomial interpolation;relational database;requirement;response time (technology);sampling (signal processing);spline (mathematics);tweaking	Yusra AlSayyad;K. Simon Krughoff;Bill Howe;Andrew J. Connolly;Magdalena Balazinska;Lynne Jones	2011		10.1007/978-3-642-22351-8_40	computer science;comet;astronomy;data mining;asteroid;trajectory;galaxy;stars;sky;large synoptic survey telescope;data flow diagram	DB	-12.703826672247299	-35.951233186873694	5072
a99ad47044adcdf40cad801bbe6bd85c9a40526a	towards the use of collaborative virtual environments to crew unmanned oil platforms	groupware;collaborative work;submarine installation operation;computer graphics;virtual environment offshore installations collaborative work petroleum virtual reality visualization humans international collaboration computer graphics military computing;crewed unmanned oil platform;digital environment;computer supported cooperative work;collaboration;virtual reality;data mining;companies;virtual reality groupware knowledge based systems marine engineering offshore installations;computer graphic;collaborative virtual environments;visualization;petroleum;intelligent offshore oilfield;monitoring;submarine installation operation collaborative virtual environment crewed unmanned oil platform onshore collaborative hybrid environment intelligent offshore oilfield computer science digital environment computer graphics virtual reality computer supported cooperative work;oil gas;marine engineering;offshore installations;humans;computer science;virtual environment;oil gas collaborative virtual environments visualization;collaborative virtual environment;knowledge based systems;military computing;onshore collaborative hybrid environment	This paper presents a human-centered vision of unmanned but crewed platforms, combining an onshore collaborative hybrid environment and an intelligent offshore oilfield. Computer Science plays a major role in this vision since digital environments are paramount for the job. We discuss the importance of research in the fields of Computer Graphics, Virtual Reality and Computer Supported Cooperative Work in this context and present the basic technologies needed to accomplish the task. We instantiate our vision appointing the results of some initial experiments using Virtual Reality in submarine installation operations.	augmented reality;collaborative virtual environment;computer graphics;computer science;computer-supported cooperative work;experiment;simulation;unmanned aerial vehicle;virtual reality	Hugo Fuks;Alberto Barbosa Raposo;Simone D. J. Barbosa;Heloisa Moura;Andreia Soares;Marcio Cunha;Marcelo Gattass;Carlos José Pereira de Lucena	2009	2009 13th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2009.4968102	simulation;visualization;human–computer interaction;computer science;virtual machine;artificial intelligence;computer-supported cooperative work;virtual reality;computer graphics;management;petroleum;collaboration	Visualization	-33.993867474569356	-24.85904443558072	5074
ae137bbf1fb5879b33abfa585b3438da7f9e18f1	analyzing and visualizing web server access log file		Websites have endlessly multiplied during the recent decades and the number of visitors to the websites keeps the pace with them simultaneously, which leads to the process of huge data creation. The data are believed to consist of hidden knowledge well worth considering in various activities related to e-Business, e-CRM, e-Services, e-Newspapers, e-Government, Digital Libraries, and so on. In order to extract knowledge from the web data efficiently, a process called web usage mining is applied to such data. In this literature, we use the process to uncover interesting patterns in web server access log file gathered from Ho Chi Minh City University of Technology (HCMUT) in Vietnam. Moreover, we propose a novel model to construct and add new attributes encompassing country, province (or city), Internet Service Provider (ISP) from the existing attribute IP. The model belongs to attribute construction (or feature construction) which is one of strategies of data transformation being a data pre-processing technique. By utilizing the aforementioned mining process, we have wide knowledge about user access patterns for every country, province and ISP. Such knowledge can be leveraged for optimizing system performance as well as enhancing personalization. Furthermore, the valuable knowledge can be useful for deciding reasonable caching policies for web proxies.	web server	Minh-Tri Nguyen;Thanh-Dang Diep;Tran Hoang Vinh;Takuma Nakajima;Nam Thoai	2018		10.1007/978-3-030-03192-3_27	service provider;web mining;personalization;world wide web;web server;digital library;the internet;business	Web+IR	-30.14105895713889	-50.44083777386818	5076
