id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
9d8b7ba1bc971fba6f779337ce229b42f67b2f16	developments of the in-home display systems for residential energy monitoring	demand response;niobium wireless communication zigbee servers smart meters monitoring electricity;ihd system development;radio transmitters niobium servers zigbee wireless communication monitoring water heating;automatic meter reading;narrow bandwidth radios;demand side management;consumer demand response;frequency 2 4 ghz;niobium;display instrumentation;network architectures;water heating;in home display systems;power line communication technique;radio transmitters;energy monitoring information;wireless communication;automatic meter systems;zigbee automatic meter reading carrier transmission on power lines;servers;monitoring;home networks;building management systems;zigbee;carrier transmission on power lines;zigbee building management systems carrier transmission on power lines computerised monitoring demand side management display instrumentation home networks power consumption;frequency 2 4 ghz in home display systems residential energy monitoring electricity usage reduction consumer demand response consumer dr ihd system energy monitoring information zigbee power line communication sub ghz narrow bandwidth radio network architectures;building structures;zigbee radio;energy monitoring;consumer dr;in home display;in home display automatic meter reading energy monitoring demand response;frequency 2 4 ghz in home display systems residential energy monitoring electricity usage amount reduction residential areas consumer demand response consumer dr energy monitoring information building structures automatic meter systems zigbee radio power line communication technique narrow bandwidth radios ihd system development network architectures;power consumption;residential energy monitoring;computerised monitoring;electricity usage amount reduction;residential areas	In order to efficiently reduce the amount of electricity usage in residential areas, the demand response (DR) of consumers is of importance. The in-home display (IHD) system provides energy monitoring information for the consumer DR. Considering the building structures and the existing automatic meter systems, several types of IHD systems have recently been developed based on the 2.4 GHz ZigBee radio, the power line communication technique, and the sub 1-GHz narrow-bandwidth radios. In this paper, five cases of IHD system developments and implementations are introduced and their technologies including network architectures compared1.	network architecture;power-line communication	Dong Sik Kim;Sung-Yong Son;Jeongjoon Lee	2013	IEEE Transactions on Consumer Electronics	10.1109/TCE.2013.6626229	embedded system;building management system;niobium;transmitter;electronic engineering;network architecture;telecommunications;computer science;engineering;electrical engineering;automatic meter reading;wireless;server	Visualization	1.3587911450162102	32.98134738556279	5154
ee43f6263bf1b572bc9b4512688f2ac9e19e4323	performance analysis in table tennis - stochastic simulation by numerical derivation		The aim of this study was to identify the impact of different tactical behaviors on the winning probability in table tennis. The performance analysis was done by mathematical simulation using a Markov chain model. 259 high-level table tennis games were evaluated by means of a new simulation approach using numerical derivation to remove the necessity to perform a second modeling step in order to determine the difficulty of tactical behaviors. Based on the derivation, several mathematical constructs like directional derivations and the gradient are examined for application in table tennis. Results reveal errors and long rallies as the most influencing game situations, together with the positive effect of risky play on the winning probability of losing players.	computation;gradient;high- and low-level;key derivation function;markov chain;numerical analysis;numerical differentiation;numerical method;profiling (computer programming);relevance;simulation	S. Wenninger;Martin Lames	2016	Int. J. Comp. Sci. Sport	10.1515/ijcss-2016-0002	simulation;computer science;theoretical computer science	AI	42.01265948314219	5.433759263032528	5155
7910cc64adbbc1fcc601679a5ab4c2d36b512b8f	the empty hexagon theorem	convex set;convex hull	Let P be a finite set of points in general position in the plane. Let C(P) be the convex hull of P and let C P be the i th convex layer of P. A minimal convex set S of P is a convex subset of P such that every convex set of P ∩ C(S) different from S has cardinality strictly less than |S|. Our main theorem states that P contains an empty convex hexagon if C1 P is minimal and C 4 P is not empty. Combined with the Erdős–Szekeres theorem, this result implies that every set P with sufficiently many points contains an empty convex hexagon, giving an affirmative answer to a question posed by Erdős in 1977.		Carlos M. Nicolas	2007	Discrete & Computational Geometry	10.1007/s00454-007-1343-6	convex analysis;subderivative;support function;mathematical optimization;combinatorics;convex optimization;krein–milman theorem;convex polytope;topology;convex combination;orthogonal convex hull;convex body;convex hull;absolutely convex set;gauss–lucas theorem;mathematics;geometry;convex set;convex curve;logarithmically convex function;choquet theory	Theory	37.576443982297896	24.30489148111785	5161
db87da08b1ef1542498150ff4b7a982b150b8047	evaluation of linear relaxations in ad network optimization for online marketing	simulation and modeling;data structures;computer science general;computer system implementation;operating systems	Ad Networks connect advertisers to websites that want to host advertisements. When users request websites, the Ad Network decides which ad to send so as to maximize the number of ads that are clicked by users. Due to the difficulty in solving such maximization problems, there are solutions in the literature that are based on linear programming (LP) relaxations. We contribute with a formulation for the Ad Network optimization problem, where it is cast as a Markov decision process (MDP). We analyze theoretically the relative performance of MDP and LP solutions. We report on an empirical evaluation of solutions for LP relaxations, in which we analyze the effect of problem size in performance loss compared to the MDP solution. We show that in some configurations, the LP relaxations incur in approximately 58 % revenue loss when compared to MDP solutions. However, such relative loss decreases as problem size increases. We also propose new heuristics to improve the use of solutions achieved by LP relaxation. We show that solutions obtained by LP relaxations are suitable for Ad Networks, as the performance loss introduced by such solutions are small in large problems observed in practice.	analysis of algorithms;expectation–maximization algorithm;heuristic (computer science);lp-type problem;linear programming relaxation;markov chain;markov decision process;mathematical optimization;online advertising;optimization problem	Valdinei Freire da Silva;Flavio Sales Truzzi;Anna Helena Reali Costa;Fábio Gagliardi Cozman	2015	Journal of the Brazilian Computer Society	10.1186/s13173-015-0029-9	simulation;data structure;computer science;marketing;theoretical computer science;operating system;distributed computing;programming language	ML	19.188478004463907	16.081918210304703	5172
9e88d34594c78ca0c9b67f2e63fd56b3d221e845	monomial ideals with primary components given by powers of monomial prime ideals	canonical primary decompositions;monomial ideals of intersection type;edge ideals;polymatroidal ideals	We characterize monomial ideals which are intersections of powers of monomial prime ideals and study classes of ideals with this property, among them polymatroidal ideals.	monomial	Jürgen Herzog;Marius Vladoiu	2014	Electr. J. Comb.		discrete mathematics;semiprime ring;topology;fractional ideal;going up and going down;mathematics;boolean prime ideal theorem;algebra	Logic	43.40800810915821	31.62760154659861	5173
85feeee78f9270bf1879e753e20270c747d53627	sufficiency of markov policies for continuous-time markov decision processes and solutions to kolmogorov's forward equation for jump markov processes	nondiscounted total costs markov policies continuous time markov decision processes kolmogorov forward equation jump markov processes ctmdp borel state action spaces unbounded transition rates marginal distribution state action pairs discounted total costs;markov processes decision making;markov processes equations aerospace electronics kernel process control trajectory;markov processes	In continuous-time Markov decision processes (CTMDPs) with Borel state and action spaces, unbounded transition rates, for an arbitrary policy, we construct a relaxed Markov policy such that the marginal distribution on the state-action pairs at any time instant is the same for both the policies. This result implies the existence of a relaxed Markov policy that performs equally to an arbitrary policy with respect to expected discounted and non-discounted total costs as well as average costs per unit time. The proof consists of two steps. The first step describes the properties of solutions to Kolmogorov's forward equation for jump Markov Processes. The second step applies these results to CTMDPs.	dynamic programming;kolmogorov equations;marginal model;markov chain;markov decision process;markov property;point process;stochastic control;turing completeness	Eugene A. Feinberg;Manasa Mandava;Albert N. Shiryaev	2013	52nd IEEE Conference on Decision and Control	10.1109/CDC.2013.6760792	forward algorithm;markov decision process;kolmogorov's criterion;time reversibility;markov chain;mathematical optimization;markov kernel;combinatorics;discrete mathematics;partially observable markov decision process;markov property;continuous-time markov chain;balance equation;mathematics;markov renewal process;additive markov chain;markov process;markov chain mixing time;markov model;hidden markov model;statistics;variable-order markov model	ML	38.63615717844716	5.214236730520467	5174
0abc640a86c9a40035c52adf01628f1cf4ac394e	unified padring design flow	integrated circuit layout;integrated circuit layout application specific integrated circuits electronic design automation;padring;databases optimization planning routing packaging synchronization space vehicles;asic padring design;padring asic padring design;application specific integrated circuits;excel spreadsheet padring design unified padring design flow design planning board level design power integrity signal integrity orbit io full chip backend database padring design integration floorplanning product cost estimation application specific integrated circuits;electronic design automation	In the early design phase, padring design is one of the critical elements in design planning. The result from padring design not only will impact packaging, board level design, power integrity and signal integrity result, but also the overall product cost .In the past, padring design is often done through separate standalone tool like Orbit IO or internal excel estimation spreadsheet. The objective of this paper is to share the unified padring design methodology where single design database is referenced hence padring design will always be in sync with fullchip backend database. Unified padring flow allows consistent cross functional review reference point as well as better controllability for core and padring design integration. Hopefully the methodology proposed will benefit the padring designers in floorplanning and product cost estimation through unified padring flow.	database;design flow (eda);floorplan (microelectronics);level design;signal integrity;socket.io;spreadsheet	Ang Boon Chong;Ho Kah Chun	2013	2013 Fifth International Conference on Computational Intelligence, Communication Systems and Networks	10.1109/CICSYN.2013.72	embedded system;real-time computing;electronic design automation;computer science;operating system;integrated circuit layout;application-specific integrated circuit	EDA	10.177819021682176	54.074809462866654	5187
301a033d935a1f84af07cddd2705ed609dd47dc5	design automation and design space exploration for quantum computers		A major hurdle to the deployment of quantum linear systems algorithms and recent quantum simulation algorithms lies in the difficulty to find inexpensive reversible circuits for arithmetic using existing hand coded methods. Motivated by recent advances in reversible logic synthesis, we synthesize arithmetic circuits using classical design automation flows and tools. The combination of classical and reversible logic synthesis enables the automatic design of large components in reversible logic starting from well-known hardware description languages such as Verilog. As a prototype example for our approach we automatically generate high quality networks for the reciprocal 1/x, which is necessary for quantum linear systems algorithms.	algorithm;automation;computer;design space exploration;digital physics;display resolution;hardware description language;linear system;logic synthesis;mathematical optimization;nor gate;prototype;quantum algorithm;quantum circuit;quantum computing;quantum simulator;qubit;reversible computing;simulation;software deployment;verilog	Mathias Soeken;Martin Roetteler;Nathan Wiebe;Giovanni De Micheli	2017	Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017		algorithm design;reversible computing;quantum information;logic synthesis;electronic design automation;logic gate;logic family;computer science;theoretical computer science;mathematics;hardware description language;boolean function;quantum computer;digital electronics;register-transfer level;algorithm	EDA	10.775492750205302	49.45546290254294	5194
22f8dad2dc44d91e941fc2cc85739515dfafebc8	this side up!	bin packing problem;rotations;online algorithm;bin packing;three dimensional;performance bounds;online algorithms	We consider two- and three-dimensional bin-packing problems where 90° rotations are allowed. We improve all known asymptotic performance bounds for these problems. In particular, we show how to combine ideas from strip packing and two-dimensional bin packing to give a new algorithm for the three-dimensional strip packing problem where boxes can only be rotated sideways. We propose to call this problem “This side up”. Our algorithm has an asymptotic performance bound of 9/4.	algorithm;bin packing problem;integrated development environment;set packing	Leah Epstein;Rob van Stee	2006	ACM Trans. Algorithms	10.1145/1150334.1150339	online algorithm;mathematical optimization;combinatorics;bin packing problem;set packing;computer science;mathematics;square packing in a square	Theory	29.37159216948919	18.223859879294867	5205
a9e1de6234268d146f8d318730e86d6aa01581a2	designing multi-link robot arms in a convex polygon	geometry;robotics;robot arm;multi link arm;convex polygon	The problem of designing a k-link robot arm confined in a convex polygon that can reach any point in the polygon starting from a fixed initial configuration is considered. The links of an arm are assumed to be all of the same length. We present a necessary condition and a sufficient condition on the shape of the given polygon for the existence of such a k-link arm for various values of k, as well as necessary and sufficient conditions for rectangles, triangles and diamonds to have such an arm. We then study the case k=2, and show that, for an arbitrary n-sided convex polygon, in O(n2) time we can decide whether there exists a 2-link arm that can reach all inside points, and construct such an arm if it exists. Finally, we prove a lower bound and an upper bound on the number of links needed to construct an arm that can reach every point in a general n-sided convex polygon, and show that the two bounds can differ by at most one. The constructive proof of the upper bound thus provides a simple method for designing a desired arm having at most k+1 links when a minimum of k links are necessary, for any k≥3. The method can be implemented to run in O(n2) time.	coat of arms	Ichiro Suzuki;Masafumi Yamashita	1996	Int. J. Comput. Geometry Appl.	10.1142/S0218195996000290	internal and external angle;combinatorics;krein–milman theorem;complex polygon;robotic arm;visibility polygon;simple polygon;rectilinear polygon;computer science;carpenter's rule problem;mathematics;geometry;regular polygon;convex set;monotone polygon;robotics;polygon covering;pick's theorem	Theory	33.01301588501597	19.37687195460136	5209
9df4c5f49507ba4dd482ef8d076f457e798c9042	local dcpos, local cpos and local completions	topological space	Abstract   We use a subfamily of the Scott-closed sets of a poset to form a  local completion  of the poset. This is simultaneously a topological analogue of the ideal completion of a poset and a generalization of the sobrification of a topological space. After we show that our construction is the object level of a left adjoint to the forgetful functor from the category of local cpos to the category of posets and Scott-continuous maps, we use this completion to show how local domains can play a role in the study of domain-theoretic models of topological spaces. Our main result shows that any topological space that is homeomorphic to the maximal elements of a continuous poset that is weak at the top also is homeomorphic to the maximal elements of a bounded complete local domain. The advantage is that continuous maps between such spaces extend to Scott-continuous maps between the modeling local domains.		Michael W. Mislove	1999	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(04)80085-9	topological ring;topological vector space;category of topological spaces;combinatorics;discrete mathematics;topology;isolated point;computer science;mathematics;topological space;graded poset;homeomorphism	Theory	41.02405214654319	27.150077178872227	5210
a5f686684cbbbadd8b47ef07f636163bea5ad7e4	some formal analysis of roccio's similarity-based relvance feedback algorithm	learning algorithm;algorithm complexity;information retrieval;complejidad algoritmo;algorithme apprentissage;complexite algorithme;recherche information;informatique theorique;estructura datos;retroaction pertinence;structure donnee;recuperacion informacion;algoritmo aprendizaje;data structure;relevance feedback;computer theory;informatica teorica	Rocchio's similarity-based Relevance feedback algorithm, one of the most important query reformation methods in information retrieval, is essentially an adaptive supervised learning algorithm from examples. In spite of its popularity in various applications there is little rigorous analysis of its learning complexity in literature. In this paper we show that in the Boolean vector space model, if the initial query vector is 0, then for any of the four typical similarities (inner product, dice coefficient, cosine coefficient, and Jaccard coefficient), Rocchio's similarity-based relevance feedback algorithm makes at least n mistakes when used to search for a collection of documents represented by a monotone disjunction of at most k relevant features (or terms) over the n-dimensional Boolean vector space {0,1} n . When an arbitrary initial query vector in {0,1} n  is used, it makes at least (n + k - 3)/2 mistakes to search for the same collection of documents. The linear lower bounds are independent of the choices of the threshold and coefficients that the algorithm may use in updating its query vector and making its classification.	algorithm	Zhixiang Chen;Binhai Zhu	2000		10.1007/3-540-40996-3_10	ranking;data structure;computer science;artificial intelligence;machine learning;mathematics;programming language;algorithm	Robotics	4.915852033547454	17.614864034933486	5218
5abb922800d62d3404d7775185a5328cf3761056	a fast composite heuristic for the symmetric traveling salesman problem	traveling salesman problem;heuristic;networks graphs;scheduling;symmetric traveling salesman problem	This article describes a new composite heuristic for the symmetric Traveling Salesman Problem. The heuristic consists of three phases: construction of an initial envelope, insertion of the remaining vertices, and improvement procedure. The heuristic is shown to perform very well both on randomly generated instances and on TSPLIB problems.	heuristic;travelling salesman problem	Jacques Renaud;Fayez F. Boctor;Gilbert Laporte	1996	INFORMS Journal on Computing	10.1287/ijoc.8.2.134	heuristic;traveling purchaser problem;2-opt;mathematical optimization;greedy algorithm;heuristic;computer science;lin–kernighan heuristic;machine learning;travelling salesman problem;scheduling;algorithm;3-opt;bottleneck traveling salesman problem	Theory	22.781649499635265	6.603343769714081	5241
24da39f26a262d17d60d2a17d966a287554b1980	optimal algorithms for rectangle problems on a mesh-connected computer	optimal algorithm	In this paper, Mesh-Connected Computer (MCC) algorithms for computing several properties of a set of, possibly intersecting rectangles are presented. Given a set of n iso-oriented rectangles, we describe MCC algorithms for determining the following properties: (i) the area of the logic “OR” of these rectangles (i.e., the area of the region covered by at least one rectangle); (ii) the area of the union of pairwise “AND” of the rectangles (i.e., the area of the region covered by two or more rectangles); (iii) the largest number of rectangles that overlap (this solves the fixed-size rectangle placement problem, i.e., given a set of planar points and a rectangle, find a placement of the rectangle in the plane so that the number of points covered by the rectangle is maximal); (iv) the minimum separation between any pair of a set of nonoverlapping rectangles. All these algorithms can be implemented on a 2√n × 2√n MCC in O(√n) time which is optimal. The algorithms compare favorably with the known sequential algorithms that have O(n log n) time complexity.	algorithm	Mi Lu;Peter J. Varman	1988	J. Parallel Distrib. Comput.	10.1016/0743-7315(88)90026-3	mathematical optimization;combinatorics;discrete mathematics;computer science;largest empty rectangle;mathematics;rectangle method	HPC	29.32377037121874	20.38185675233154	5270
475066a848dc63b0eca8da7a989144cdb9d39298	provably efficient scheduling of cache-oblivious wavefront algorithms		Iterative wavefront algorithms for evaluating dynamic programming recurrences exploit optimal parallelism but show poor cache performance. Tiled-iterative wavefront algorithms achieve optimal cache complexity and high parallelism but are cache-aware and hence are not portable and not cache-adaptive. On the other hand, standard cache-oblivious recursive divide-and-conquer algorithms have optimal serial cache complexity but often have low parallelism due to artificial dependencies among subtasks. Recently, we introduced cache-oblivious recursive wavefront (COW) algorithms, which do not have any artificial dependencies, but they are too complicated to develop, analyze, implement, and generalize. Though COW algorithms are based on fork-join primitives, they extensively use atomic operations for ensuring correctness, and as a result, performance guarantees (i.e., parallel running time and parallel cache complexity) provided by state-of-the-art schedulers (e.g., the randomized work-stealing scheduler) for programs with fork-join primitives do not apply. Also, extensive use of atomic locks may result in high overhead in implementation.  In this paper, we show how to systematically transform standard cache-oblivious recursive divide-and-conquer algorithms into recursive wavefront algorithms to achieve optimal parallel cache complexity and high parallelism under state-of-the-art schedulers for fork-join programs. Unlike COW algorithms these new algorithms do not use atomic operations. Instead, they use closed-form formulas to compute the time when each divide-and-conquer function must be launched in order to achieve high parallelism without losing cache performance. The resulting implementations are arguably much simpler than implementations of known COW algorithms. We present theoretical analyses and experimental performance and scalability results showing a superiority of these new algorithms over existing algorithms.	cache-oblivious algorithm;computation;correctness (computer science);dynamic programming;fastest;graph coloring;iterative method;linearizability;locality of reference;lock (computer science);overhead (computing);parallel computing;randomized algorithm;recurrence relation;recursion;scalability;scheduling (computing);symmetric multiprocessing;time complexity;work stealing	Rezaul Alam Chowdhury;Pramod Ganapathi;Yuan Tang;Jesmin Jahan Tithi	2017		10.1145/3087556.3087586	scalability;distributed computing;parallel computing;computer science;divide and conquer algorithms;cache;parallel running;scheduling (computing);dynamic programming;cache-oblivious algorithm;cache algorithms;algorithm	DB	1.1017571243873805	39.97646773436788	5276
2d55d43db80ac062cf3dc9485b467eecb282d202	meta densities and the shape of their sample clouds	limit shape;level sets;primary;level set;heavy tail;secondary;meta distribution sample clouds level sets limit shape multivariate extremes regular variation;regular variation;dependence structure;convex set;sample clouds;meta distribution;risk theory;multivariate extremes	This paper compares the shape of the level sets for two multivariate densities. The densities are positive and continuous, and have the same dependence structure. The density f is heavy-tailed. It decreases at the same rate – up to a positive constant – along all rays. The level sets {f > c} for c ↓ 0 have a limit shape, a bounded convex set. We transform each of the coordinates to obtain a new density g with Gaussian marginals. We shall also consider densities g with Laplace, or symmetric Weibull marginal densities. It will be shown that the level sets of the new light-tailed density g also have a limit shape, a bounded star-shaped set. The boundary of this set may be written down explicitly as the solution of a simple equation depending on two positive parameters. The limit shape is of interest in the study of extremes and in risk theory since it determines how the maximal observations in different directions relate. Although the densities f and g have the same copula – by construction –, the shapes of the level sets are not related. Knowledge about the limit shape of the level sets for one density does not give any information about the limit shape for the other density.	convex set;marginal model;maximal set	A. A. Balkema;P. Embrechts;N. Nolde	2010	J. Multivariate Analysis	10.1016/j.jmva.2010.02.010	combinatorics;discrete mathematics;level set;mathematics;statistics	ML	43.176974443251694	14.992945509927269	5288
625706a0dc4473066eb3b145a26e2e99ddf2aa83	cell assisted apmc	microprocessors;random access memory;model checker;probability;computer architecture microprocessors probabilistic logic computational modeling random access memory program processors broadband communication;program verification probability;cell architecture cell assisted apmc approximate probabilistic model checker cell processor;cell architecture;cell;cell processor;apmc;program verification;probabilistic model;computer architecture;computational modeling;cell assisted apmc;approximate probabilistic model checker;model checker cell apmc;probabilistic logic;broadband communication;program processors	In this paper, we give an overview of APMC-CA (cell assisted approximate probabilistic model checker). APMC-CA is a new version of APMC dedicated to the cell processor. We show that using the cell architecture, we achieve better performances than APMC 3.0.	approximation algorithm;cell (microprocessor);cell signaling;model checking;performance;statistical model	Alexandre Borghi;Thomas Hérault;Richard Lassaigne;Sylvain Peyronnet	2008	2008 Fifth International Conference on Quantitative Evaluation of Systems	10.1109/QEST.2008.36	model checking;cell;statistical model;computer architecture;parallel computing;computer science;theoretical computer science;probability;mathematics;probabilistic logic;computational model;statistics	Robotics	7.590612041400771	52.6781386903862	5291
708bcd7b9eb63856c2359497e2c3fda689b0aae1	the intersection theorem for direct products	direct product			Rudolf Ahlswede;Harout K. Aydinian;Levon H. Khachatrian	1998	Eur. J. Comb.	10.1006/eujc.1998.0223	mathematics;direct product;algebra	Theory	45.94399601721743	30.500985151371278	5315
9f35b65b8a277bc755200b6612cb6b8d59837737	semi-markov decision problems and performance sensitivity analysis	lyapunov methods;optimisation;optimisation discrete event systems markov processes sensitivity analysis lyapunov methods perturbation techniques iterative methods;sensitivity analysis markov processes learning poisson equations performance analysis stochastic processes statistics queueing analysis user generated content state estimation;reinforcement learning;iteration algorithms discounted poisson equations discrete event dynamic systems lyapunov equations markov decision processes perturbation analysis poisson equations policy iteration reinforcement learning sensitivity analysis;discrete event dynamic system;perturbation techniques;semi markov process;iterative methods;first order;sensitivity analysis;semi markov decision process;markov process;discrete event systems;markov decision problem;perturbation analysis;policy iteration;markov processes;markov decision process;point of view	Recent research indicates that Markov decision processes (MDPs) can be viewed from a sensitivity point of view; and perturbation analysis (PA), MDPs, and reinforcement learning (RL) are three closely related areas in optimization of discrete-event dynamic systems that can be modeled as Markov processes. The goal of this paper is two-fold. First, we develop PA theory for semi-Markov processes (SMPs); and second, we extend the aforementioned results about the relation among PA, MDP, and RL to SMPs. In particular, we show that performance sensitivity formulas and policy iteration algorithms of semi-Markov decision processes (SMDPs) can be derived based on performance potential and realization matrix. Both the long-run average and discounted-cost problems are considered; this approach provides a unified framework for both problems, and the long-run average problem corresponds to the discounted factor being zero. The results indicate that performance sensitivities and optimization depend only on first-order statistics. Single sample path-based implementations are discussed.	algorithm;decision problem;dynamical system;first-order predicate;iteration;markov chain;markov decision process;markov property;mathematical optimization;perturbation theory;reinforcement learning;semiconductor industry;unified framework	Xi-Ren Cao	2003	IEEE Trans. Automat. Contr.	10.1109/TAC.2003.811252	markov decision process;mathematical optimization;discrete mathematics;machine learning;mathematics;markov process;reinforcement learning;statistics	ML	39.12181280221563	4.93440045079068	5319
b45686b6156b8cd3cf939e814e9d7c937375ecb7	flow shop scheduling problem and solution in cooperative robotics - case-study: one cobot in cooperation with one worker		This research combines between two different manufacturing concepts. On the one hand, flow shop scheduling is a well-known problem in production systems. The problem appears when a group of jobs shares the same processing sequence on two or more machines sequentially. Flow shop scheduling tries to find the appropriate solution to optimize the sequence order of this group of jobs over the existing machines. The goal of flow shop scheduling is to obtain the continuity of the flow of the jobs over the machines. This can be obtained by minimizing the delays between two consequent jobs, therefore the overall makespan can be minimized. On the other hand, collaborative robotics is a relatively recent approach in production where a collaborative robot (cobot) is capable of a close proximity cooperation with the human worker to increase the manufacturing agility and flexibility. The simplest case-study of a collaborative workcell is one cobot in cooperation with one worker. This collaborative workcell can be seen as a special case of the shop flow scheduling problem, where the required time from the worker to perform a specific job is unknown and variable. Therefore, during this research, we implement an intelligent control solution which can optimize the flow shop scheduling problem over the previously mentioned case-study.	cobot;flow shop scheduling;intelligent control;job stream;makespan;robot;robotics;scheduling (computing);scott continuity	Ahmed R. Sadik;Bodo Urban	2017	Future Internet	10.3390/fi9030048	computer science;job shop scheduling;real-time computing;robot;intelligent control;workcell;multi-agent system;special case;flow shop scheduling;robotics;artificial intelligence	Robotics	12.47416259715456	6.328985921679676	5329
9e6a3bc9a1bd5fe34a989c7d7d718db50970a31c	xdgp: a dynamic graph processing system with adaptive partitioning.		Many real-world systems, such as social networks, rely on mining efficiently large graphs, with hundreds of millions of vertices and edges. This volume of information requires partitioning the graph across multiple nodes in a distributed system. This has a deep effect on performance, as traversing edges cut between partitions incurs a significant performance penalty due to the cost of communication. Thus, several systems in the literature have attempted to improve computational performance by enhancing graph partitioning, but they do not support another characteristic of realworld graphs: graphs are inherently dynamic, their topology evolves continuously, and subsequently the optimum partitioning also changes over time. In this work, we present the first system that dynamically repartitions massive graphs to adapt to structural changes. The system optimises graph partitioning to prevent performance degradation without using data replication. The system adopts an iterative vertex migration algorithm that relies on local information only, making complex coordination unnecessary. We show how the improvement in graph partitioning reduces execution time by over 50%, while adapting the partitioning to a large number of changes to the graph in three real-world scenarios.	algorithm;distributed computing;elegant degradation;graph (abstract data type);graph partition;iterative method;replication (computing);run time (program lifecycle phase);social network;world-system	Luis M. Vaquero;Félix Cuadrado;Dionysios Logothetis;Claudio Martella	2013	CoRR		real-time computing;replication (computing);distributed computing;vertex (geometry);social network;computer science;graph partition;modular decomposition;graph bandwidth;graph operations;graph	HPC	2.211868471661007	36.301133040395435	5335
daa5e440eaad091533e7dd67a76994a1f473c4b8	gibbs-shannon entropy and related measures: tsallis entropy		In this research paper, it is proved that an approximation to Gibbs-Shannon entropy measure naturally leads to Tsallis entropy for the real parameter q =2 . Several interesting measures based on the input as well as output of a discrete memoryless channel are provided and some of the properties of those measures are discussed. It is expected that these results will be of utility in Information Theoretic research.	approximation;channel (communications);entropy (information theory);input/output;shannon (unit);tsallis entropy	Garimella Rama Murthy	2003	CoRR		entropy power inequality;mathematical optimization;joint entropy;conditional quantum entropy;quantum relative entropy;generalized relative entropy;information diagram;binary entropy function;rényi entropy;transfer entropy;maximum entropy probability distribution;principle of maximum entropy;mathematics;maximum entropy thermodynamics;joint quantum entropy;configuration entropy;entropy rate;conditional entropy;tsallis entropy;min entropy;statistics;entropy	ML	45.6982885780444	15.196077289711198	5338
cd6f8bc19eb5711deff6c2dcfb1fab1d970d605e	application of krylov based methods in calibration for radio astronomy	arrays calibration vectors covariance matrices jacobian matrices complexity theory signal processing;radiotelescopes radioastronomy;optimization krylov subspace calibration radio astronomy minresqlp;modern radiotelescopes krylov based methods radio astronomy khatri rao structure covariance data lofar radio telescope	As the number of antennas in the modern radio-telescopes increases, the computational complexity of the calibration algorithms becomes more and more important. In this paper we use the Khatri-Rao structure of the covariance data model used for such calibrations and combine it with Krylov subspace based methods to achieve accurate calibration results with low complexity, very small memory usage and fast convergence properties. We also demonstrate the proposed method on experimental data measured by the LOFAR radio-telescope.	algorithm;computational complexity theory;data model;krylov subspace	Ahmad Mouri Sardarabadi;Alle-Jan van der Veen	2014	2014 IEEE 8th Sensor Array and Multichannel Signal Processing Workshop (SAM)	10.1109/SAM.2014.6882363	astrophysics;physics;statistics	Robotics	53.365936411592585	7.33936849493311	5341
c0fff17b3423f8f03e789a8edea4404cadb2058d	a fortification model for decentralized supply systems and its solution algorithms		Service disruptions due to deliberate sabotage are serious threats to supply systems. To alleviate the loss of accessibility caused by such disruptions, identifying the system vulnerabilities that would be worth strengthening is a critical problem in critical infrastructure protection. Today's supply systems tend to be organized in a decentralized manner, with different components belonging to different entities, keeping much information private. Therefore, a protection plan must balance its benefits among these entities for universal agreement to be reached. This paper addresses the issue of decentralized supply chain fortification by proposing the R-Interdiction Median problem with Fortification for Decentralized supply systems (D-RIMF). In the D-RIMF, each demand node is private and is a client of a certain facility; each facility evaluates its potential worst-case reduction in accessibility, measured as the increase in service provision costs considering only its own clients, and the objective is to minimize the largest evaluation values. To model the D-RIMF, we introduce a bilevel multiagent framework, in which all facilities and the defender are considered as independent agents. To solve the D-RIMF, both heuristic and optimal algorithms are designed to satisfy different requirements. Finally, the usefulness of the D-RIMF and the performances of the proposed algorithms are observed through simulations performed on typical datasets.	accessibility;agent-based model;algorithm;best, worst and average case;bilevel optimization;critical infrastructure protection;disaster recovery plan;entity;heuristic;performance;requirement;simulation	Xiaoyi Zhang;Zheng Zheng;Kai-Yuan Cai	2018	IEEE Transactions on Reliability	10.1109/TR.2017.2761827	reliability engineering;mathematics;robustness (computer science);critical infrastructure protection;supply chain;heuristic;algorithm;vulnerability	AI	-1.0627514486336442	4.9389784272722075	5357
87b10ced5b22c3d32cb69f581bb16a8d1c6ad27a	a metric to compare vulnerability of the graphs of different sizes		Abstract Node immunization and estimation of vulnerability are essential for a number of applications from safe guarding computer networks against virus attacks to protecting human population from highly contagious biological viruses. The concepts of node immunization can be used in the fast diffusion of information on a network and viral marketing. In this article, normalized eigenvalue based measure to compare vulnerability of Graphs of different sizes is proposed. The measure is based on largest eigenvalue of the adjacency matrix of the graph. Erdos-Renyi Random Graphs of different size and connectivity been used for experimental verification using susceptible infected (SI) model. It has been found that the proposed metric is good to compare vulnerability of graphs when graphs are moderately or highly connected, or when contagion strength is not too weak.		Kushal Kanwar;Harish Kumar;Sakshi Kaushal	2017	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2017.11.051	adjacency matrix;mathematics;discrete mathematics;viral marketing;normalization (statistics);random graph;eigenvalues and eigenvectors;population;vulnerability;graph	Theory	36.913607664640786	13.923642888137	5370
e0eac0bb747ea1b4ee14c3d814ce5bc12f66c71f	another characterization of alephs: decompositions of hyperspace	euclidean space;cross section			John C. Simms	1997	Notre Dame Journal of Formal Logic	10.1305/ndjfl/1039700694	mathematical analysis;topology;euclidean space;euclidean distance;mathematics;cross section;geometry;euclidean distance matrix	EDA	36.99859004530903	21.20007299495809	5376
23a8710280ac4b0eb5745248db9a9b692cbab229	computing intersections and normalizers in soluble groups	finite group;theorie groupe;subgrupo;subgroup;grupo acabado;calculo automatico;sous groupe;interseccion;group theory;computing;algorithme;calcul automatique;algorithm;normalisateur;construccion;groupe resoluble;solvable group;groupe fini;intersection;construction;teoria grupo;algoritmo	"""Let H and K be arbitrary subgroups of a finite soluble group G. The purpose of this paper is todescribe algorithms for constructing H@?K and N""""G(H). The first author has previously described algorithms for constructing H@?K when the indices |G:H| and |G:K| are coprime, and for constructing N""""G(H) when |G:H| and |H| are coprime (i.e. when H is a Hall subgroup of G). The intersection and normalizer algorithms described in the present paper are constructed from generalizations of these algorithms and from an orbit-stabilizer algorithm."""		Stephen P. Glasby;Michael C. Slattery	1990	J. Symb. Comput.	10.1016/S0747-7171(08)80079-X	computing;construction;calculus;solvable group;intersection;mathematics;subgroup;group theory;algorithm;algebra	Logic	38.92217258607404	36.71925932243113	5393
3f7dd60fa461fecf9e34013c81ccf50a3e5397d2	finding near-optimal independent sets at scale	maximum independent set problem;minimum vertex cover problem;evolutionary/genetic algorithms;heuristic algorithms;local search;kernelization	The independent set problem is NP-hard and particularly difficult to solve in large sparse graphs. In this work, we develop an advanced evolutionary algorithm, which incorporates kernelization techniques to compute large independent sets in huge sparse networks. A recent exact algorithm has shown that large networks can be solved exactly by employing a branch-and-reduce technique that recursively kernelizes the graph and performs branching. However, one major drawback of their algorithm is that, for huge graphs, branching still can take exponential time. To avoid this problem, we recursively choose vertices that are likely to be in a large independent set (using an evolutionary approach), then further kernelize the graph. We show that identifying and removing vertices likely to be in large independent sets opens up the reduction space—which not only speeds up the computation of large independent sets drastically, but also enables us to compute high-quality independent sets on much larger instances than previously reported in the literature.	computation;connected component (graph theory);display resolution;evolutionary algorithm;exact algorithm;independent set (graph theory);iterative and incremental development;kernelization;np-hardness;parallel computing;recursion;sparse matrix;time complexity;vertex (geometry)	Sebastian Lamm;Peter Sanders;Christian Schulz;Darren Strash;Renato F. Werneck	2016		10.1137/1.9781611974317.12	mathematical optimization;combinatorics;discrete mathematics;independent set;machine learning;mathematics;maximal independent set	ML	25.169720117382823	6.1939421860787895	5401
845645c27138cd20a7a334e361ed08ef43da4742	partitions to improve spatial reasoning	topology;spatial reasoning;discrete space;spatial partitions	The field of spatial reasoning has provided a litany of formal models and reasoning systems aimed at providing users with information about spatial tasks and concepts, ranging from point-to-point distance measurements coming from sensors all the way to topological information coming from the interaction of multiple sensor readings. In this short paper, the concept of using topology to augment partitions is addressed. Future work within the dissertation includes other partition-based relation theories, including digital topological relations and surrounds configurations within a collection of objects.	point-to-point protocol;sensor;spatial–temporal reasoning	Matthew P. Dube;Max J. Egenhofer	2014		10.1145/2694859.2694864	combinatorics;discrete mathematics;pure mathematics;mathematics	HCI	39.170769196606884	21.566478016131242	5408
d524a33982a2ba7aeae7610fd1cf4814bf41d450	minimal representation of -openings via pattern bases	minimal representation;pattern base	Abstract   Minimization of binary τ-opening bases is characterized by defining openings relative to pattern classes. Minimal pattern bases are unique and algorithmically derived for finite bases. They are used to derive a minimal bounding τ-opening for an antiextensive, increasing operator from the minimal erosion representation of the operator.		Edward R. Dougherty	1994	Pattern Recognition Letters	10.1016/0167-8655(94)90035-3	combinatorics;discrete mathematics;topology;mathematics	Vision	41.06857696347749	26.772868367427254	5420
0e9081c622283866220d4ded53ff219fc18421f9	compact routing with additive stretch using distance labelings	circular arc graph;interval graph;compact routing;permutation graph;outerplanar graph	Distance labelings -- introduced as a new way to encode graph topology in a distributed fashion -- have been an active area of research (see [1, 2] for details). In both exact and approximate settings, results in distance labelings and compact routing (for an introduction, esp. for definitions of routing tables and headers, see [3]) seem to go hand in hand, but so far these results have been produced separately. It was already known that graphs with constantsized separators such as trees, outerplanar graphs, seriesparallel graphs and graphs of bounded treewidth, support both exact distance labelings and optimal (additive stretch 0, multiplicative stretch 1) compact routing schemes, but there are classes of graphs known to admit exact distance labelings which do not have constant-sized separators. Our main result is to demonstrate that every n-vertex graph which supports an exact distance labeling with O(l(n))-sized labels also supports a compact routing scheme with O(l(n) + log2 n)-sized headers, O(√n(l(n) + log2 n))-sized routing tables, and an additive stretch of 6. Our general result produces the first known compact routing schemes for classes of graphs where no previous compact routing scheme was known, such as permutation graphs.We note that it is possible to improve substantially on our general result for the classes of interval graphs and circular arc graphs (neither of which admits constant-sized separators). In both cases, a compact routing scheme exists with polylogarithmic headers and routing tables, and an additive stretch of 1; due to space constraints, we defer further discussion of these cases to future presentations of this work.	approximation algorithm;binary logarithm;encode;interval arithmetic;outerplanar graph;polylogarithmic function;routing table;topological graph theory;tree (data structure);treewidth;utility functions on indivisible goods	Arthur Brady;Lenore Cowen	2006		10.1145/1148109.1148147	1-planar graph;outerplanar graph;pathwidth;mathematical optimization;combinatorics;discrete mathematics;interval graph;topology;permutation graph;mathematics;partial k-tree;chordal graph;indifference graph	Theory	25.76839616603727	21.379483847678948	5423
b9ee96c42c10d09c473cabbb67ac79eaf0d1c0a8	rebel and tdc: two embedded test structures for on-chip measurements of within-die path delay variations	embedded systems;microprocessor chips;time-digital conversion;ets;rebel;tdc;delay defect;design debug;embedded test structure;hardware trojan;on-chip measurement;path delay measurement;physical unclonable function;product design;regional delay behavior;time-to-digital converter;within-die path delay variation	As feature printability becomes more challenging in advanced technology nodes, measuring and characterizing process variation effects on delay and power is becoming increasingly important. In this paper, we present two embedded test structures (ETS) for carrying out path delay measurement in actual product designs. Of the two structures proposed here, one is designed to be incorporated into a customer's scan structures, augmenting selected functional units with the ability to perform accurate path delay measurements. We refer to this ETS as REBEL (regional delay behavior). It is designed to leverage the existing scan chain as a means of reducing area overhead and performance impact. For cases in which very high resolution of delay measurements is required, a second standalone structure is proposed which we refer to as TDC for time-to-digital converter. Beyond characterizing process variations, these ETSs can also be used for design debug, detection of hardware Trojans and small delay defects and as physical unclonable functions.	embedded system;enterprise test software;overhead (computing);time-to-digital converter;trojan horse (computing)	Charles Lamech;Jim Aarestad;James F. Plusquellic;Reza M. Rad;Kanak Agarwal	2011	2011 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)		chip;embedded system;electronic engineering;real-time computing;genetic algorithm;telecommunications;computer science;engineering;electrical engineering;discrete event simulation;elmore delay;operating system;product design;process variation;network delay	EDA	21.807396155835733	55.68897111214874	5431
2c7c982e1531ec3f0b2774c1558787b3080d3cdf	end-extensions preserving power set	power set			Thomas E. Forster;Richard Kaye	1991	J. Symb. Log.		cardinal number;topology;calculus;mathematics;permutation;axiom;model theory;set theory;algebra	Logic	45.20656922539124	28.719744596930905	5445
e7479595cdd205822f3f2c1d9c95a485f6084d53	algorithms for the constrained longest common subsequence problems	dynamic programming;time complexity;edit distance;dynamic program;longest common sub sequence;longest common subsequence;constrained subsequence	Given strings S1, S2, and P , the constrained longest common subsequence problem for S1 and S2 with respect to P is to find a longest common subsequence lcs of S1 and S2 such that P is a subsequence of this lcs. We present an algorithm which improves the time complexity of the problem from the previously known O(rnm) to O(rnm) where r, n, and m are the lengths of P, S1, and S2, respectively. As a generalization of this, we extend the definition of the problem so that the lcs sought contains a subsequence whose edit distance from P is less than a given parameter d. For the latter problem, we propose an algorithm whose time complexity is O(drnm).	algorithm;dynamic programming;edit distance;longest common subsequence problem;time complexity	Abdullah N. Arslan;Ömer Egecioglu	2004	Int. J. Found. Comput. Sci.	10.1142/S0129054105003674	time complexity;subsequence;combinatorics;discrete mathematics;longest increasing subsequence;edit distance;computer science;dynamic programming;longest common subsequence problem;mathematics;longest alternating subsequence;algorithm	Theory	13.75000339186631	26.686491891768757	5455
fb65e758f7f908185e97096cdd13b9ffc6409b14	reactive proximity data structures for graphs		We consider data structures for graphs where we maintain a subset of the nodes called sites, and allow proximity queries, such as asking for the closest site to a query node, and update operations that enable or disable nodes as sites. We refer to a data structure that can efficiently react to such updates as reactive. We present novel reactive proximity data structures for graphs of polynomial expansion, i.e., the class of graphs with small separators, such as planar graphs and road networks. Our data structures can be used directly in several logistical problems and geographic information systems dealing with real-time data, such as emergency dispatching. We experimentally compare our data structure to Dijkstra’s algorithm in a system emulating random queries in a real road network.	communications protocol;data structure;dijkstra's algorithm;emulator;experiment;geographic information system;graph (abstract data type);graph theory;logistics;planar graph;planar separator theorem;polynomial expansion;proximity problems;real-time data;real-time locating system	David Eppstein;Michael T. Goodrich;Nil Mamano	2018		10.1007/978-3-319-77404-6_56	discrete mathematics;data structure;computer science;polynomial expansion;planar graph;geographic information system;dijkstra's algorithm;graph	Theory	18.729987315035217	30.964993682235388	5457
5747cc5bf3c8ace96817444daeddcf18a483632d	online sparse linear regression		We consider the online sparse linear regression problem, which is the problem of sequentially making predictions observing only a limited number of features in each round, to minimize regret with respect to the best sparse linear regressor, where prediction accuracy is measured by square loss. We give an inefficient algorithm that obtains regret bounded by Õ( √ T ) after T prediction rounds. We complement this result by showing that no algorithm running in polynomial time per iteration can achieve regret bounded by O(T 1−δ) for any constant δ > 0 unless NP ⊆ BPP. This computational hardness result resolves an open problem presented in COLT 2014 (Kale, 2014) and also posed by Zolghadr et al. (2013). This hardness result holds even if the algorithm is allowed to access more features than the best sparse linear regressor up to a logarithmic factor in the dimension.	algorithm;bpp (complexity);colt;cobham's thesis;comparator;iteration;polynomial;regret (decision theory);sparse matrix;time complexity	Dean P. Foster;Satyen Kale;Howard J. Karloff	2016			mathematical optimization;combinatorics;machine learning;mathematics;statistics	ML	16.817739516962046	18.015940886240166	5460
4a17507932ebff33572d4e7dcc2c59cf1f73bc3b	polymorphic p systems with non-cooperative rules and no ingredients		Polymorphic P systems represent a variant of the bio-inspired computational model of P systems, in which the rules are not explicitly given in the description of the system, but are implicitly defined by the contents of certain membranes. In this paper we give a characterisation of the most basic class of such systems, in which only non-cooperative rules are allowed and no ingredients are included. We start by formulating two different formal definitions of non-cooperativity and then show that they have the same generative power. We also show that the generative power of polymorphic P systems is less than (NRE) and, finally, that the languages produced by such systems form a hierarchy related to the maximal allowed depth of the membrane structure.	p system	Sergiu Ivanov	2014		10.1007/978-3-319-14370-5_16	generative grammar;discrete mathematics;hierarchy;mathematics;membrane	Logic	1.1571988654524905	24.572108677663	5490
c169f1aaff3b903505f94c7eb3cf7f03d07cfe8e	systolic generation of combinations from arbitrary elements	linear array;linear array of processors;cost optimization;combinations;generating combinatorial objects	A systolic algorithm is described for generating, in lexicographically ascending order, all combinations of rn o$ects chosen from an arbitrary set of n elements. The algorithm is designed to be executed on a linear array of zn processors, each having consta.nt size memory (except processor rn, which has O(n) memory), and each being responsible fot producing one element of a given combination. There is a constant delay per combination, leading to an O(C(rn, rz)) time solution, where C(rn, n) is the total number of combinations. The 'lgorithm is cost-optimal (assuming the time to output the combinations is counted), a,nd does not deal with very large integers, Kellwoxbt Combinations, linear array of processors, generating combinatorial objects.	algorithm;central processing unit;charge-coupled device;cost efficiency;lexicographical order;sorting	Hassan Elhage;Ivan Stojmenovic	1992	Parallel Processing Letters	10.1142/S0129626492000374	arithmetic;combinatorics;combination;theoretical computer science;mathematics;algorithm	Arch	12.841458026180916	33.391202505671046	5497
a1ad37e2db2601c9b7015d976de3e2e176a3d382	on the average case performance of some greedy approximation algorithms for the uncapacitated facility location problem	location problem;approximate algorithm;asymptotic optimality;approximation algorithms;uncapacitated facilty location problem;probabilistic analysis of algorithms;polynomial time;uncapacitated facility location problem;combinatorial optimization;plane partition	In combinatorial optimization, a popular approach toNP-hard problems is the design of approximation algorithms. These algorithms typically run in polynomial time and are guaranteed to produce a solution which is within a known multiplicative factor of optimal. Unfortunately, the known factor is often known to be large in pathological instances. Conventional wisdom holds that, in practice, approximation algorithms will produce solutions closer to optimal than their proven guarantees. In this paper, we use the rigorous-analysis-of-heuristics framework to investigate this conventional wisdom.We analyze the performance of 3 related approximation algorithms for the uncapacitated facility location problem (from [Jain, Mahdian, Markakis, Saberi, Vazirani, 2003] and [Mahdian, Ye, Zhang, 2002]) when each is applied to an instances created by placing n points uniformly at random in the unit square. We find that, with high probability, these 3 algorithms do not find asymptotically optimal solutions, and, also with high probability, a simple plane partitioning heuristic does find an asymptotically optimal solution.	approximation algorithm;asymptotically optimal algorithm;best, worst and average case;coefficient;combinatorial optimization;facility location problem;greedy algorithm;heuristic (computer science);mathematical optimization;time complexity;with high probability	Abraham D. Flaxman;Alan M. Frieze;Juan Carlos Vera	2005		10.1145/1060590.1060656	time complexity;mathematical optimization;combinatorics;discrete mathematics;probabilistic analysis of algorithms;combinatorial optimization;computer science;plane partition;mathematics;approximation algorithm;algorithm	Theory	21.842099747914034	19.27117160939021	5524
1e76cbe20495e4209bbc62faa053b9d0ce2895e5	on the confluence of trace rewriting systems	complexite calcul;information retrieval;tree data structures;structure donnee arborescente;complejidad computacion;rewriting systems;recherche information;computational complexity;rewrite systems;informatique theorique;recuperacion informacion;systeme reecriture;computer theory;informatica teorica	In [NO88], a particular trace monoid M is constructed such that for the class of length–reducing trace rewriting systems over M , confluence is undecidable. In this paper, we show that this result holds for every trace monoid, which is neither free nor free commutative. Furthermore we will present a new criterion for trace rewriting systems that implies decidability of confluence.	confluence;newman's lemma;rewriting;semiconductor industry;trace monoid;undecidable problem	Markus Lohrey	1998		10.1007/978-3-540-49382-2_30	discrete mathematics;computer science;mathematics;semi-thue system;tree;computational complexity theory;algorithm	Logic	-3.3279157650308067	20.26786697233672	5530
ff703dec157e2f5626dd56f375a293e98c22dadb	a note on regular subgroups of the automorphism group of the linear hadamard code			graph automorphism;hadamard code	Ivan Yu. Mogilnykh	2018	CoRR		algebra;hadamard code;automorphism;mathematics	Crypto	41.30232212695897	34.410845161318626	5531
c63695413355fcd5649717d10f2faeeacffac82b	microarchitecture of hal's cpu	register renaming;multiprocessing systems parallel architectures instruction sets;64 bit;hat pm1 cpu;instruction set architecture;microarchitecture central processing unit pipelines availability computer aided instruction computer architecture registers out of order maintenance workstations;out of order;dataflow model;parallel architectures;64 bit hat pm1 cpu 64 bit sparc version 9 instruction set architecture superscalar instruction issue register renaming dataflow model;64 bit sparc version 9 instruction set architecture;multiprocessing systems;superscalar instruction issue;instruction sets	The HaL PMI CPU is the first implementation of the 64bit SPARC Version 9 instruction set architecture. The processor utilizes superscalar instruction issue, register renaming, and a dataflow model of execution. Instructions can complete out-of-order and are later committed in ordel: The PMI CPU maintains precise state. The processor has a higher level of reliability than is currently available in desktop computers for the commercial marketplace.	64-bit computing;central processing unit;dataflow;desktop computer;microarchitecture;out-of-order execution;register renaming;sparc;superscalar processor	Niteen Patkar;Akira Katsuno;Simon Li;Tak Maruyama;Sunil Savkar;Mike Simone;Gene Shen;Ravi Swami;DeForest Tovey	1995		10.1109/CMPCON.1995.512394	dataflow architecture;program counter;reduced instruction set computing;computer architecture;parallel computing;register window;addressing mode;machine code;application-specific instruction-set processor;computer hardware;microarchitecture;computer science;out-of-order execution;minimal instruction set computer;central processing unit;register renaming;instruction set;instruction register;transport triggered architecture;processor register;control unit;orthogonal instruction set	Arch	6.160944070265813	49.127482728417405	5537
6c6d7c104b88c4cf8dc6671c4b4fea2d8f906370	approximating multi commodity network design on graphs of bounded pathwidth and bounded degree		In the Multicommodity Network Design problem (MCND) we are given a digraph G together with latency functions on its edges and specified flow requests between certain pairs of vertices. A flow satisfying these requests is said to be at Nash equilibrium if every path which carries a positive amount of flow is a shortest path between its source and sink. The goal of MCND is to find a subgraph H of G such that the flow at Nash equilibrium in H is optimal. While this has been shown to be hard to approximate (with multiplicative error) for a fairly large class of graphs and latency functions, we present an algorithm which computes solutions with small additive error in polynomial time, assuming the graph G is of bounded degree and bounded path-width, and the latency functions are Lipschitz-continuous. Previous hardness results in particular apply to graphs of bounded degree and graphs of bounded path-width, so it is not possible to drop one of these assumptions.	approximation algorithm;degree (graph theory);directed graph;nash equilibrium;numerical stability;pathwidth;polynomial;shortest path problem;time complexity;utility functions on indivisible goods	Kord Eickmeyer;Ken-ichi Kawarabayashi	2013		10.1007/978-3-642-41392-6_12	mathematical optimization;combinatorics;discrete mathematics;mathematics;bounded function	Theory	22.55362523422965	18.19424347649297	5541
4d46acdb9fc34e6698ca6b34b6acb45f05bb0f79	stochastic semantics of signaling as a composition of agent-view automata	stochastic process;continuous time markov chain;signal transduction networks;markov process;stochastic automata composition;stochastic dynamics;cell signaling	In this paper we present a formalism based on stochastic automata to describe the stochastic dynamics of signal transduction networks that are specified by rule-sets. Our formalism gives a modular description of the underlying stochastic process, in the sense that it is a composition of smaller units – agent-views. The view of an agent is an automaton that identifies all local modification changes of that agent, including internal state modifications and (un)binding changes but also – those of interacting agents, that are tested by that agent within a rule. We show how to represent the generator matrix of the underlying Markov process of the whole rule-set as Kronecker sums of the rate matrices belonging to individual view-automata. In the absence of birth the automata are finite, since the number of different contexts of one agent that appear in a rule-set are finite. Moreover, the construction of the automata network is linear in the size of the rule-set. We illustrate the framework by examples that are related to cellular signaling events.	automata theory;automaton;bottom-up parsing;cell signaling;enumerated type;fork (software development);fragmentation (computing);generator matrix;interaction;moore's law;petri net;quantum superposition;reachability;reconstruction conjecture;semantics (computer science);state space;stochastic process;top-down and bottom-up design;transduction (machine learning)	Heinz Koeppl;Tatjana Petrov	2011	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2011.04.002	stochastic cellular automaton;stochastic neural network;stochastic process;time reversibility;markov chain;combinatorics;discrete mathematics;cell signaling;continuous-time stochastic process;quantum finite automata;continuous-time markov chain;theoretical computer science;mathematics;markov process;interacting particle system	AI	41.85289200633444	8.604897296645067	5550
a3008aa70b9befa5e1faa25b6233e87dffd39af6	cycles through a prescribed vertex set in n-connected graphs	graph theory;connected graph;cycles;n connected graphs	A well-known result of Dirac (Math. Nachr. 22 (1960) 61) says that given n vertices in an nconnected G; G has a cycle through all of them. In this paper, we generalize Dirac’s result as follows: Given at most 3 2 n vertices in an n-connected graph G when nX3 and jVðGÞjX 2 n; then G has a cycle through exactly n vertices of them. This improves the previous known bound given by Kaneko and Saito (J. Graph Theory 15(6) (1991) 655). r 2003 Elsevier Inc. All rights reserved.	connectivity (graph theory);graph theory;itakura–saito distance;vertex (geometry)	Ken-ichi Kawarabayashi	2004	J. Comb. Theory, Ser. B	10.1016/j.jctb.2003.08.002	graph power;strongly regular graph;combinatorics;discrete mathematics;connected component;independent set;topology;level structure;graph toughness;distance-regular graph;connectivity;graph theory;pseudoforest;pancyclic graph;hypercube graph;cycle graph;symmetric graph;path graph;mathematics;k-vertex-connected graph;windmill graph;wheel graph;bound graph;complete graph;line graph;neighbourhood	Theory	29.240727765356326	30.595642029960324	5561
b2ecbc2f318699ffebc4dbf1697f836cc588de00	total outer-connected domination numbers of trees	optimisation;connected dominating set;combinatorics;subgrafo;tree;optimizacion;05c05;combinatoria;vertex;arbol;combinatoire;connected graph;dominating set;trees;sous graphe;informatique theorique;vertex graph;68r10;borne inferieure;arbre;total outer connected domination number;nombre domination totale;conjunto dominando;total domination number;optimization;vertice;cardinalite;domination number;subgraph;graphe connexe;vertice grafo;lower bound;sommet graphe;ensemble dominant;cota inferior;computer theory;grafo conexo;informatica teorica	Let G=(V,E) be a graph without an isolated vertex. A set D@?V(G) is a total dominating set if D is dominating, and the induced subgraph G[D] does not contain an isolated vertex. The total domination number of G is the minimum cardinality of a total dominating set of G. A set D@?V(G) is a total outer-connected dominating set if D is total dominating, and the induced subgraph G[V(G)-D] is a connected graph. The total outer-connected domination number of G is the minimum cardinality of a total outer-connected dominating set of G. We characterize trees with equal total domination and total outer-connected domination numbers. We give a lower bound for the total outer-connected domination number of trees and we characterize the extremal trees.	dominating set	Joanna Cyman;Joanna Raczek	2009	Discrete Applied Mathematics	10.1016/j.dam.2009.06.027	vertex;combinatorics;discrete mathematics;topology;dominating set;connectivity;vertex;connected dominating set;mathematics;tree;upper and lower bounds	Theory	24.144643181160003	30.7310323356851	5567
ff556df37a2ee423b184fb99bb81e49a1a4ad602	bifix codes in acyclic sets			code;directed acyclic graph	Valérie Berthé;Clelia de Felice;Francesco Dolce;Dominique Perrin;Christophe Reutenauer;Giuseppina Rindone	2013	CoRR			Theory	47.967363453050595	28.11329028200404	5568
6f791c5596a22adfa40dd5ad69dfd21b5b1dd45d	the relation between derivations and syntactical structures in phrase-structure grammars	context free grammar	It is well known that, for context-free grammars, a leftmost derivation of a sentence univocally defines its syntactical tree; the construction of this tree consists of an iterative procedure during which two successive strings in the leftmost derivation are compared (see, e.g., [1, 2]). These -o r similar--properties do not hold for leftmost derivations in general phrase-structure grammars [3-5] nor for (not necessarily leftmost) derivations in context-free grammars (see, e.g., [6, 7]). In this paper conditions for a general phrase-structure grammar are established under which each of its derivations univocally defines a syntactical structure (Sections 2-5). The simplifications for context-sensitive and context-free grammars are indicated in Sections 6 and 7. The case of leftmost derivations is discussed briefly in Section 8.	context-free grammar;context-free language;context-sensitive grammar;context-sensitive language;iterative method;phrase structure grammar	Jürgen Eickel;Jacques Loeckx	1972	J. Comput. Syst. Sci.	10.1016/S0022-0000(72)80006-0	natural language processing;context-sensitive grammar;tree-adjoining grammar;generative grammar;indexed grammar;synchronous context-free grammar;categorial grammar;l-attributed grammar;link grammar;phrase structure grammar;computer science;affix grammar;phrase structure rules;extended affix grammar;emergent grammar;definite clause grammar;context-free grammar;ambiguous grammar;transformational grammar;adaptive grammar;mildly context-sensitive grammar formalism;combinatory categorial grammar;algorithm	NLP	-1.5001403195738816	18.391696962275358	5601
ed9d3e0000bf53ffc9d83dbdbe6cef65b78e1c02	approximate performance analysis of workflow model	approximation method;operations analysis performance analysis workflow model multidimensional workflow net mwf net organization resource perspectives perspectives mapping boundedness verification method queuing network;queueing theory;performance analysis context modeling routing petri nets process control automation carbon capture and storage delay graphics timing;operations research;production management;performance analysis;queuing networks;operations research queueing theory production management petri nets;petri nets;petri net;structure analysis	Multi-dimension Worylow net (MWF-net) [I], which includes process, organization, and resource perspectives, is inhoduced. Using the struchtre analysis of the '7WF.net in the process perspective and the perspectives mapping, the routing of transaction instances in the multi-TWF-nets can be projected into the flow of hamaction instance between different resource pools in the resource perspective. Afer the relevant work in [ I] is briefy reviewed. the boundedness veriJication method of a MWF-net is proposed. A MWF-net is bounded implies the corresponding queuing network in the resource perspective has stable solution. Based on the discussion ofseveral operationol principles in the context of workjlow model, an opproximate method for perjormance analysis of a worylow model is presented	approximation algorithm;operations research;process (computing);profiling (computer programming);routing	Jianqiang Li;Yushun Fan;Mengchu Zhou	2003		10.1109/ICSMC.2003.1244570	computer science;database;distributed computing;petri net;workflow management system	HPC	5.005870545947548	11.417505160668208	5604
3903953d374f3d67b257acffce78b54b9974c3e1	a resistance problem (e. n. gilbert and l. a. shepp)		Problem 84-14, by E. N. GILBERT and L. A. SHEPP (Bell Telephone Laboratories, Murray Hill, NJ). The sides of polygon A An are resistances rl rn. One measures the equivalent resistances 0 < pi ri (R -ri)/R, where R rl +... + rn, between consecutive pairs of vertices Ai, Ai+! (i n and An+l A 1). Show that the ri’s are uniquely determined from the Oi’S. This problem arose in electrical tomography where an object is regarded as an unknown resistive network, and the unknown internal resistors in the network are deduced from external electrical measurements, analogous to x-ray tomography. The ring of resistors was proposed to learn whether or not electrical tomography is possible for this simple network topology. Although the problem remains unsolved for general networks, more general topologies are considered in a forthcoming paper. Editorial note. The following algorithmic solution by D. K. BHARGAVA (Government Engineering College, Raipur, India) gives explicit formulae for the resistances by a slightly different measurement scheme. For the previous solution, see SlAM Rev., Sept. 1985, p. 449. The calculation of the rk’s is based on the formulae	algorithm;ct scan;gilbert cell;network topology;tomography	D. K. Bhargava	1993	SIAM Review	10.1137/1035099	mathematics;combinatorics;mathematical analysis	AI	33.95888998963106	27.94970863504848	5607
68bb30d60ac797bbb96009b95ee0576b21657178	joint source localization and sensor position refinement for sensor networks	time of arrival estimation distributed sensors sensor fusion source separation;time of arrival sensor network sensor position refinement source localization;distributed sensors;position measurement accuracy vectors maximum likelihood estimation noise covariance matrices;time of arrival estimation;algebraic solution sensor position refinement sensor networks sensor position improvement localization performance joint estimator multiple unknown source localization toa measurements small noise analysis crlb performance;sensor fusion;source separation	Modern localization systems/platforms such as sensor networks often experience uncertainty in the sensor positions. Improving the sensor positions is necessary in order to achieve better localization performance. This paper proposes a joint estimator for locating multiple unknown sources and refining the sensor positions using TOA measurements. Rather than resorting to the traditional iterative nonlinear least-squares approach that requires careful initializations, the proposed estimator is algebraic and computationally attractive. The small noise analysis shows that the proposed estimator is able to attain the CRLB performance for both the unknown sources and the sensor positions. Simulations support the efficiency of the proposed estimator.	computer simulation;internationalization and localization;iterative method;non-linear least squares;nonlinear system;refinement (computing);sensor;time of arrival	Ming Sun;Zhenhua Ma;K. C. Ho	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6638415	computer vision;mathematical optimization;soft sensor;computer science;control theory;sensor fusion	Robotics	51.740846506764704	4.88707774315794	5612
abde977ece37a9a3af152ee19ef5412e47c7d237	an algorithm with better approximation ratio for multicast traffic in unidirectional sonet/wdm rings	cost function;circular arc graph;traffic grooming;upper bound;add drop multiplexer;lower bound	The goal for the problem of efficient grooming of given non-uniform multicast traffic demands on a unidirectional SONET/WDM ring is to try to minimize the network cost as given by (i) the number of wavelengths required per fiber and (ii) the number of electronic Add- Drop Multiplexers (ADMs) required in the ring. The problem with cost function (i) can be reduced to a corresponding traffic grooming problem for unicast traffic which can then be modeled as a standard circular-arc graph coloring problem.The function (ii) is a main research topic in recent studies.The problem is NP hard for both the cost functions. For the problem with fuction (ii), we present a algorithm with better approximation ratio, $ \frac{3}{2}(\frac{N}{{N - 1}} + 1)$. Additionally, we give a lower bound and upper bound for the number of ADMs.	approximation algorithm;multicast;synchronous optical networking;wavelength-division multiplexing	Jiguo Yu;Suxia Cui;Guanghui Wang	2009		10.1007/978-3-642-02026-1_50	combinatorics;mathematics;distributed computing;upper and lower bounds;computer network	ECom	22.689003606809596	18.498297178437962	5613
318e5b2815d7a813705d94b1bc0104a653ce6603	optimal p/n width ratio selection for standard cell libraries	cach cell;n width ratio selection;cmos logic circuit delay;logic gate;theoretical framework;n width ratio;delay model;accurate delay;high-performance standard cell library;various logic gate;optimal p;logic synthesis;satisfiability;logic gates	The effectiveness of logic synthesis to satisfy increasingly tight timing constraints in deep-submicron high-performance circuits heavily depends on the range and variety of logic gates available in the standard cell library. Primarily, research in the design of high-performance standard cell libraries has been focused on drive strength selection of various logic gates. Since CMOS logic circuit delays not only depend on the drive strength of each gate but also on its P/N width ratio, it is crucial to provide good P/N width ratios for cach cell. The main contribution of this paper is the development of a theoretical framework through which library designers can determine “optimal” P/N width ratio for each logic gate in their high-performance standard cell library. This theoretical framework utilizes new gate delay models that explicitly represent the dependence of delay on P/N width ratio and load. These delay models yield highly accurate delay for CMOS gates in a 0.12&mgr;m Leff deep-submicron technology.	library (computing);standard cell	David S. Kung;Ruchir Puri	1999			control engineering;electronic engineering;real-time computing;delay calculation;logic gate;computer science;pass transistor logic	PL	19.78517867287783	58.03281391716565	5620
7aa0aab35fd3c0358d8cada0427dfebdcb2a86c0	eulerian and hamiltonian dicycles in directed hypergraphs	de bruijn dihypergraphs;11xxx;directed hypergraphs;eulerian and hamiltonian dicycles;de bruijn dihyper graphs mathematics subject classification 2000 11xxx	In this article, we generalize the concepts of Eulerian and Hamiltonian digraphs to directed hypergraphs. A dihypergraph H is a pair (V(H), E(H)), where V(H) is a non-empty set of elements, called vertices, and E(H) is a collection of ordered pairs of subsets of V(H), called hyperarcs. It is Eulerian (resp. Hamiltonian) if there is a dicycle containing each hyperarc (resp. each vertex) exactly once. We first present some properties of Eulerian and Hamiltonian dihypergraphs. For example, we show that deciding whether a dihypergraph is Eulerian is an NP-complete problem. We also study when iterated line dihypergraphs are Eulerian and Hamiltonian. Finally, we study when the generalized de Bruijn dihypergraphs are Eulerian and Hamiltonian. In particular, we determine when they contain a complete Berge dicycle, i.e. an Eulerian and Hamiltonian dicycle.		Júlio Araújo;Jean-Claude Bermond;Guillaume Ducoffe	2014	Discrete Math., Alg. and Appl.	10.1142/S1793830914500128	eulerian number;combinatorics;discrete mathematics;best theorem;topology;mathematics;eulerian path	Theory	32.30220468276715	30.68281731937009	5621
e11f21a8f37d18871059c13a5438eb5350216e69	a method of locating open faults on incompletely identified pass/fail information	bist;tecnologia electronica telecomunicaciones;open fault;pass fail information;fail information;autoprueba;compact design;concepcion compacta;autotest;minimizacion costo;built in self test;minimisation cout;detection defaut;diagnostic panne;cost minimization;conception compacte;pass;fault diagnostic;diagnostico pana;defaut ouvert;tecnologias;grupo a;deteccion imperfeccion;fault diagnosis;defect detection	In order to reduce the test cost, built-in self test (BIST) is widely used. One of the serious problems of BIST is that the compacted signature in BIST has very little information for fault diagnosis. Especially, it is difficult to determine which tests detect a fault. Therefore, it is important to develop an efficient fault diagnosis method by using incompletely identified pass/fail information. Where the incompletely identified pass/fail information means that a failing test block consists of at least one failing test and some passing tests, and all of the tests in passing test blocks are the passing test. In this paper, we propose a method to locate open faults by using incompletely identified pass/fail information. Experimental results for ISCAS'85 and ITC'99 benchmark circuits show that the number of candidate faults becomes less than 5 in many cases.		Koji Yamazaki;Yuzo Takamatsu	2008	IEICE Transactions	10.1093/ietisy/e91-d.3.661	embedded system;real-time computing;mountain pass;algorithm	SE	22.391940802030735	50.31286525111832	5631
3142f5db2284128dda8a44dbc5391732b7d69805	a model for the dual of the generalised hexagon h(q), q odd	science general	Bader and Lunardon found a model for the dual of the split Cayley hexagon H(q), q odd and not a power of 3, using a twisted cubic in PG(3,q). We propose a slightly modified version of this model which also works if q is a power of 3, and discuss the connection with a model for the dual of the twisted triality hexagon H(q3, q) described by Lunardon.		Elisabeth Kuijken	2003	J. Comb. Theory, Ser. A	10.1016/S0097-3165(03)00024-4	combinatorics;mathematics;geometry;algebra	Logic	40.538531346431924	32.99052029195779	5632
873cf376ad7cdc3564d917d878a2b91401550482	optimising and evaluating designs for reconfigurable hardware			field-programmable gate array;reconfigurable computing	Tobias Becker	2011			computer architecture;reconfigurable computing;computer science	EDA	4.273747792213365	49.28530722425531	5638
2a6151c9a778a207be73a852c858bb765e194a72	end-extensions of models of weak arithmetic from complexity-theoretic containments		We prove that if the linear-time and polynomial-time hierarchies coincide, then every model of Π1(N)+¬Ω1 has a proper end-extension to a model of Π1(N), and so Π1(N) +¬Ω1 ` BΣ1. Under an even stronger complexity-theoretic assumption which nevertheless seems hard to disprove using present-day methods, Π1(N)+¬Exp ` BΣ1. Both assumptions can be modified to versions which make it possible to replace Π1(N) by I∆0 as the base theory. We also show that any proof that I∆0 + ¬Exp does not prove a given finite fragment of BΣ1 has to be “non-relativizing”, in the sense that it will not work in the presence of an arbitrary oracle. The work presented below aims at a better understanding of the following notoriously hard open problem about moderately weak theories of arithmetic: Does I∆0 + ¬Exp prove BΣ1? (?) Here I∆0 is induction for bounded formulas in the language of ordered rings, Exp is the axiom ∀x ∃y (y = 2x) with y = 2x expressed by an appropriate ∆0 formula, and BΣ1 is the Σ1 collection scheme, ∀x≤u∃y φ(x, y)⇒ ∃w ∀x≤u∃y≤wφ(x, y), where φ is ∆0 and may contain parameters. It is well-known and easy to show that I∆0 6` BΣ1 [Par70], but all known proofs of this (e.g. [Par70, PK78, Ada88, Bek98]) use objects of at least exponential size, often in the form of a definition of satisfaction for Σ1 formulas. Problem (?) was first explicitly stated in [WP89]. The expected answer is negative, and there have been a number of results of the form “the answer to (?) is negative under some complexity-theoretic assumptions” [WP89, Fer94, ∗Institute of Mathematics, University of Warsaw, Banacha 2, 02-097 Warszawa, Poland, lak@mimuw.edu.pl. Partially supported by Polish National Science Centre grant no. 2013/09/B/ST1/04390.	bounded quantifier;computational complexity theory;exptime;mathematical induction;oracle database;ordered pair;polynomial;time complexity	Leszek Aleksander Kolodziejczyk	2016	J. Symb. Log.	10.1017/jsl.2015.53	combinatorics;discrete mathematics;calculus;mathematics	Theory	8.550437465278732	20.384045777816674	5649
817822be3680ecf9b33f6df1f1918b371f395add	a very difficult scheduling problem with communication delays	parallel computation;makespan;precedence constraints;complexity class;computational complexity;scheduling;precedence constraint;parallel computer;scheduling problem;communication delay;communication delays	A set of unit-time tasks has to be processed on an unrestricted number of processors subject to precedence constraints and unit-time communication delays such that the makespan is minimized. What is the smallest number m^* such that increasing the number of processors beyond m^* cannot decrease the makespan any more? We prove that answering this problem is complete for the complexity class FP^N^P^[^l^o^g^n^]. Hence, the problem is at least as difficult as all the problems in NP and at least as difficult as all the problems in coNP, and unless some complexity classes collapse, it is even more difficult than all these problems. This answers a question raised by Ivan Rival.	scheduling (computing)	Han Hoogeveen;Gerhard J. Woeginger	2001	Oper. Res. Lett.	10.1016/S0167-6377(01)00103-1	complexity class;job shop scheduling;mathematical optimization;real-time computing;computer science;mathematics;distributed computing;computational complexity theory;scheduling;algorithm	Theory	16.092530504116525	11.11947562061702	5651
31934877601a4afb1a1f41f61787251802942ede	an empirical study of hyperheuristics for managing very large sets of low level heuristics	forecasting;empirical study;reliability;project management;information systems;maintenance;soft or;information technology;packing;operations research;location;investment;journal;journal of the operational research society;inventory;purchasing;history of or;logistics;marketing;scheduling;scheduling problem;production;communications technology;computer science;operational research;combinatorial optimisation;applications of operational research;or society;jors;management science;infrastructure	Hyperheuristics give us the appealing possibility of abstracting the solution method from the problem, since our hyperheuristic, at each decision point, chooses between different low level heuristics rather than different solutions as is usually the case for metaheuristics. By assembling low level heuristics from parameterised components we may create hundreds or thousands of low level heuristics, and there is increasing evidence that this is effective in dealing with every eventuality that may arise when solving different combinatorial optimisation problem instances since at each iteration the solution landscape is amenable to at least one of the low level heuristics. However, the large number of low level heuristics means that the hyperheuristic has to intelligently select the correct low level heuristic to use, to make best use of available CPU time. This paper empirically investigates several hyperheuristics designed for large collections of low level heuristics and adapts other hyperheuristics from the literature to cope with these large sets of low level heuristics on a difficult realworld workforce scheduling problem. In the process we empirically investigate a wide range of approaches for setting tabu tenure in hyperheuristic methods, for a complex real-world problem. The results show that the hyperheuristic methods described provide a good way to trade off CPU time and solution quality.	central processing unit;combinatorial optimization;heuristic (computer science);hyper-heuristic;iteration;mathematical optimization;metaheuristic;scheduling (computing);tabu search	Stephen Remde;Peter I. Cowling;Keshav P. Dahal;Nic Colledge;E. Selensky	2012	JORS	10.1057/jors.2011.48	project management;logistics;inventory;economics;forecasting;investment;computer science;marketing;operations management;heuristics;reliability;mathematics;management science;location;management;operations research;information technology;scheduling	AI	18.054802740657898	4.515934361203401	5653
33ff42f771b5ae46ed2208f6f7ee4b13bb2dd67e	small fpga based multiplication-inversion unit for normal basis representation in gf(2m)	itoh tsujii inversion algorithms field programmable gate arrays fpga multiplication inversion unit normal basis representation halving methods ecc primitives multicore processors side channel attacks binary field extensions ecc methods permuted normal basis massey omura multiplication;clocks;halving scalar multiplication finite field arithmetic binary fields normal basis multiplication inversion ecc;inversion;ecc;binary fields;polynomials;clocks field programmable gate arrays registers table lookup hardware polynomials;multiprocessing systems circuit optimisation field programmable gate arrays microprocessor chips;normal basis;registers;halving scalar multiplication;finite field arithmetic;field programmable gate arrays;table lookup;multiplication;hardware	Halving methods have been proposed for parallel implementation of ECC primitives on multicore processors. In hardware, they can also provide protection against some side channel attacks (thanks to parallel independent operations). But they require affine coordinates for curve points and costly inversions. We propose a new combined multiplication-inversion unit for binary field extensions and halving based ECC methods optimized for FPGAs. We target small area solutions compared to very fast but costly ones from state-of-art. Our solution is based on permuted normal basis, Massey-Omura multiplication and Itoh-Tsujii inversion algorithms. Our FPGA implementations show better efficiency for large fields.	application-specific integrated circuit;central processing unit;cryptosystem;division by two;ecc memory;field-programmable gate array;inversion (discrete mathematics);itoh-tsujii inversion algorithm;mathematical optimization;multi-core processor;normal basis;side-channel attack;trionic	Jérémy Métairie;Arnaud Tisserand;Emmanuel Casseau	2015	2015 IEEE Computer Society Annual Symposium on VLSI	10.1109/ISVLSI.2015.32	parallel computing;theoretical computer science;mathematics;algorithm	Arch	9.692692805905391	44.0923782707109	5664
455e5ee66ddc073c7a997f3eb308d27724074ed9	efficient computations of irredundant triangular decompositions with the regularchains library	regularchains;quasi component;irredundant triangular decomposition;inclusion test	We present new functionalities that we have added to the RegularChains library in Maple to efficiently compute irredundant triangular decompositions. We report on the implementation of different strategies. Our experiments show that, for difficult input systems, the computing time for removing redundant components can be reduced to a small portion of the total time needed for solving these systems.	experiment;maple;regularchains;triangular decomposition	Changbo Chen;François Lemaire;Marc Moreno Maza;Wei Pan;Yuzhen Xie	2007		10.1007/978-3-540-72586-2_38	combinatorics;discrete mathematics;mathematics;algorithm	HPC	34.38467813650964	39.34414228450466	5672
1bf3cce5daa3951b715e4209ef8e17806ec6fa97	greedy trees, subtrees and antichains	greedy trees degree sequences subtrees antichains;greedy trees;bepress selected works;antichains;degree sequences;subtrees	Greedy trees are constructed from a given degree sequence by a simple greedy algorithm that assigns the highest degree to the root, the second-, third-, . . . highest degrees to the root’s neighbors, and so on. They have been shown to maximize or minimize a number of different graph invariants among trees with a given degree sequence. In particular, the total number of subtrees of a tree is maximized by the greedy tree. In this work, we show that in fact a much stronger statement holds true: greedy trees maximize the number of subtrees of any given order. This parallels recent results on distance-based graph invariants. We obtain a number of corollaries from this fact and also prove analogous results for related invariants, most notably the number of antichains of given cardinality in a rooted tree.	degree (graph theory);graph property;greedy algorithm;parallels desktop for mac;tree (data structure)	Eric Ould Dadah Andriantiana;Stephan G. Wagner;Hua Wang	2013	Electr. J. Comb.		combinatorics;greedy algorithm;discrete mathematics;topology;mathematics;greedy coloring	Theory	30.827179851002697	25.788050010155814	5676
503e228286ce46db4c8f0db86543ca57c93bab1e	blocking and parallelization of the hari-zimmermann variant of the falk-langemeyer algorithm for the generalized svd	generalized eigenvalue problem;mathematics;generalized singular value problem;blocking;computing;parallelization	The paper describes how to modify the two-sided Hari–Zimmermann algorithm for computation of the generalized eigenvalues of a matrix pair (A, B), where B is positive definite, to an implicit algorithm that computes the generalized singular values of a pair (F, G). In addition, we present blocking and parallelization techniques for speedup of the computation. For triangular matrix pairs of a moderate size, numerical tests show that the double precision sequential pointwise algorithm is several times faster than the Lapack DTGSJA algorithm, while the accuracy is slightly better, especially for small generalized singular values. Cache-aware algorithms, implemented either as the block-oriented, or as the full block algorithm, are several times faster than the pointwise algorithm. The algorithm is almost perfectly parallelizable, so parallel shared memory versions of the algorithm are perfectly scalable, and their speedup almost solely depends on the number of cores used. A hybrid shared/distributed memory algorithm is intended for huge matrices that do not fit into the shared memory. © 2015 Elsevier B.V. All rights reserved.	algorithm;blocking (computing);computation;distributed memory;double-precision floating-point format;ervand kogbetliantz;gene expression programming;lapack;math kernel library;message passing interface;modulus robot;numerical analysis;numerical stability;parallel computing;preprocessor;scalability;shared memory;singular value decomposition;speedup;triangular matrix	Vedran Novakovic;Sanja Singer;Sasa Singer	2015	Parallel Computing	10.1016/j.parco.2015.06.004	mathematical optimization;suurballe's algorithm;combinatorics;computing;discrete mathematics;parallel computing;ramer–douglas–peucker algorithm;computer science;operating system;mathematics;parallel algorithm;blocking;shortest path faster algorithm;cornacchia's algorithm	HPC	-1.9686098032447412	38.618433467374764	5682
c08d08defe773118ab6defb43cc4c472c1189594	fpga-based efficient modular multiplication for elliptic curve cryptography	public key cryptography pkc elliptic curve cryptography ecc montgomery modular multiplication mmm field programmable gate array fpga vhsic hardware description language vhdl;vhsic hardware description language vhdl;protocols;elliptic curve cryptography ecc;field programmable gate array fpga;elliptic curve cryptography;public key cryptography digital arithmetic galois fields multiplying circuits;yttrium;public key cryptography pkc;montgomery modular multiplication mmm;elliptic curve cryptography protocols yttrium;efficient modular multiplication nist standards galois field xilinx virtex 7 fpga field programmable gate array national institute of standards and technology elliptic curve cryptoprocessor public key cryptography elliptic curve cryptography	Modular multiplication is the backbone for the whole asymmetric cryptographic process. In this paper, we have focused on a high-speed hardware implementation of modular multiplication for public-key cryptography, specially for a high-performance Elliptic Curve Crypto-processor (ECC). The proposed design has been implemented over a prime finite field of size p using the National Institute of Standards and Technology (NIST) recommended standards. Field-Programmable Gate-Array (FPGA) technology with the VHDL language has been used for this hardware implementation. The computational time of a 256-bit modular multiplication in a modern Xilinx Virtex-7 FPGA is 1.683 μs at frequency 152.709 MHz; in this technology we have implemented an area-efficient hardware design technique which takes only 605 slices for a 256-bit modular multiplication. The required area and time are also very low compared with all other recent designs. The product of area and time (AT) of our design is also nearly 9-98 times better than the related designs. To our knowledge, our implemented modular multiplication over GF(p) provides a better performance than the recent hardware implementations.	elliptic curve cryptography;fastest;field-programmable gate array;high- and low-level;internet backbone;maple;mathematical optimization;montgomery modular multiplication;public-key cryptography;time complexity;vhdl	Md. Selim Hossain;Yinan Kong	2015	2015 International Telecommunication Networks and Applications Conference (ITNAC)	10.1109/ATNAC.2015.7366811	parallel computing;kochanski multiplication;computer hardware;elliptic curve digital signature algorithm;computer science;theoretical computer science;elliptic curve cryptography	EDA	9.122251689493634	44.56275335214459	5708
16f47cebfad53512509b5c3e043ba1f6eb46ee5c	normal matrices and the completion problem	calcul matriciel;normal matrix;permutation group;matrice normale;probleme completion;groupe lie;orientation matricielle;variedad matematica;orientation;matrix algebra;matrice unitaire;normal matrices;groupe symetrique;matriz normal;grupo lie;grupo simetrico;completion problem;complecion;characterization;matriz unitaria;orientacion;lie group;matrix orientation;groupe permutation;15a57;matrix calculus;unitary matrix;caracterisation;matrice hermitienne gauche;skew hermitian matrix;algebre matricielle;completion;symmetric group;caracterizacion;grupo permutacion;calculo de matrices;variete mathematique;manifold	We show that there exists a normal matrix with an arbitrary upper triangular part.		Shmuel Friedland	2002	SIAM J. Matrix Analysis Applications	10.1137/S0895479801386444	combinatorics;topology;mathematics;geometry;normal matrix;algebra	Theory	40.960093939661036	31.912757353270315	5712
17526a243c6dece195b7a18170c7af402b2f33c9	parallel implementation of cholesky ll t -algorithm in fpga-based processor	floating point;parallel implementation	The fixed-size processor array architecture, which is intended for realization of matrix LLT-decomposition based on Cholesky algorithm, is proposed. In order to implement this architecture in modern FPGA devices, the arithmetic unit (AU) operating in the rational fraction arithmetic is designed. The AU is intended for configuring in the Xilinx Virtex4 FPGAs, and its hardware complexity is much less than the complexity of similar AUs operating with floating-point numbers.		Oleg Maslennikov;Volodymyr Lepekha;Anatoli Sergyienko;Adam Tomas;Roman Wyrzykowski	2007		10.1007/978-3-540-68111-3_15	computer architecture;parallel computing;computer science;floating point;theoretical computer science;operating system	EDA	4.881477407754091	45.193319120393674	5714
660a8e1542695f2dfd5ad9848de4d7df03fd0720	on the structure of locally outerplanar graphs			graph (discrete mathematics);outerplanar graph	Hung-Lung Wang;Chun-Yu Tseng;Jou-Ming Chang	2015	IEICE Transactions		1-planar graph;pathwidth;combinatorics;discrete mathematics;topology;dense graph;metric dimension;partial k-tree;chordal graph;indifference graph	DB	27.69856869809845	30.342379651390598	5719
86a5c930772fcbb7393417bbb3b618bd48e842f2	zero-sum problems and coverings by proper cosets	finite abelian group;covering problem	Let G be a finite Abelian group and D(G) its Davenport constant, which is defined as the maximal length of a minimal zero-sum sequence in G. We show that various problems on zero-sum sequences in G may be interpreted as certain covering problems. Using this approach we study the Davenport constant of groups of the form(Z/nZ)r , with n ≥ 2 andr ∈ N. For elementaryp-groupsG, we derive a result on the structure of minimal zero-sum sequences Shaving maximal length|S| = D(G). © 2003 Elsevier Science Ltd. All rights reserved.	covering problems;maximal set	Weidong Gao;Alfred Geroldinger	2003	Eur. J. Comb.	10.1016/S0195-6698(03)00033-7	combinatorics;discrete mathematics;elementary abelian group;mathematics;algebra	Theory	37.210038379647806	32.162893254118416	5742
795006bfee000ebba1c4d2dc77bfd772d00382a0	a matrix of combinatorial numbers related to the symmetric groups	symmetric group	"""For permutation groups G of finite degree we define numbers t""""B(G)=|G|^-^1@?""""R""""@?""""G@?""""1(1a""""1(g))^b^""""^i, where B=(b""""1,...,b""""1) is a tuple of non-negative integers and a""""1(g) denotes the number of i cycles in the element g. We show that t""""B(G) is the number of orbits of G, acting on a set @D""""B(G) of tuples of matrices. In the case G=S""""n we get a natural interpretation for combinatorial numbers connected with the Stiring numbers of the second kind."""		Michael Klemm;Bernd Wagner	1979	Discrete Mathematics	10.1016/0012-365X(79)90094-3	function composition;combinatorics;discrete mathematics;mathematics;symmetric group;algebra	Theory	38.72671110532835	32.00598698647524	5751
058e090efb2a09a7f36376c0ea652a8fb95d798d	a parallel sorting algorithm for a novel model of computation	algoritmo paralelo;processor architecture;parallel algorithm;programme tri;shared memory;parallel sorting;multiprocessor;time complexity;complexite calcul;complejidad calculo;implementation;memoria compartida;sistema informatico;rule based;programa ordenacion;computer system;procesador panel;computing complexity;satisfiability;array processor;red mallada cerrada;algorithme parallele;processeur tableau;ejecucion;sort routine;complexite temps;calculateur mimd;reseau maille;computational complexity;sorting network;meshed network;systeme informatique;systeme parallele;parallel system;model of computation;multiprocesador;complejidad tiempo;sorting algorithm;sistema paralelo;mimd computer;space application;memoire partagee;multiprocesseur	The computational complexity of a parallel algorithm depends critically on the model of computation. We describe a simple and elegant rule-based model of computation in which processors apply rules asynchronously to pairs of objects from a global object space. Application of a rule to a pair of objects results in the creation of a new object if the objects satisfy the guard of the rule. The model can be efficiently implemented as a novel MIMD array processor architecture, the Intersecting Broadcast Machine. For this model of computation, we describe an efficient parallel sorting algorithm based on mergesort. The computational complexity of the sorting algorithm isO(nlog2 n), comparable to that for specialized sorting networks and an improvement on theO(n 1.5) complexity of conventional mesh-connected array processors.	array processing;central processing unit;computational complexity theory;logic programming;mimd;merge sort;model of computation;parallel algorithm;sorting algorithm;sorting network;tuple space	Amitabha Das;Louise E. Moser;P. M. Melliar-Smith	1991	International Journal of Parallel Programming	10.1007/BF01407814	model of computation;rule-based system;time complexity;shared memory;parallel computing;multiprocessing;decision tree model;microarchitecture;sorting network;computer science;theoretical computer science;operating system;sorting algorithm;parallel algorithm;computational complexity theory;implementation;algorithm;satisfiability	Theory	11.166385929624477	34.63173598544296	5792
cce58c4e8eaa0daa8672063901f77e512d2ce446	rapid almost-complete broadcasting in faulty networks	tolerancia falta;sense of direction;hypercube;cluster computing;calcul tolerant les pannes;dynamique;seuil;point to point;distributed computing;synchronous;threshold;radiodifusion;reseau;diffusion telecommunications;calculo automatico;synchrone;computing;red;dinamica;calcul automatique;68m15;graphe communication;graph connectivity;fault tolerant computing;sincronico;dynamics;informatique theorique;fault tolerance;68r10;conectividad grafo;communication graph;calculo repartido;umbral;broadcasting;grafo completo;complete graph;communication;graphe complet;connectivite graphe;comunicacion;68q85;calcul reparti;radiodiffusion;tolerance faute;network;grafo comunicacion;computer theory;informatica teorica;hipercubo	This paper studies the problem of broadcasting in synchronous point-to-point networks, where one initiator owns a piece of information that has to be transmitted to all other vertices as fast as possible. The model of fractional dynamic faults with threshold is considered: in every step either a fixed number c(G)-1, where c(G) is the edge connectivity of the communication graph, or a fraction @a of sent messages can be lost depending on which quantity is larger. As the main result we show that in complete graphs and hypercubes it is possible to inform all but a constant number of vertices, exhibiting only a logarithmic slowdown, i.e. in time O(Dlogn) where D is the diameter of the network and n is the number of vertices. Moreover, for complete graphs under some additional conditions (sense of direction, or @a<0.55) the remaining constant number of vertices can be informed in the same time, i.e. O(logn).		Rastislav Kralovic;Richard Královic	2009	Theor. Comput. Sci.	10.1016/j.tcs.2008.12.023	dynamics;fault tolerance;combinatorics;computing;graph center;computer science;theoretical computer science;mathematics;distributed computing;complete graph;broadcasting;algorithm;hypercube	ECom	19.039715764741118	32.220222418968426	5793
8deb1f6244bcb9d08d60f890b4ec3d78a677a327	on upper bounds for real roots of chromatic polynomials	graph theory;teoria grafo;nombre entier;mathematiques discretes;ordered set;matematicas discretas;chromatic polynomial;discrete mathematics;ensemble ordonne;polynomial;theorie graphe;upper bound;integer;polinomio;entero;ordre n;68r10;06axx;root;orden n;simplicial vertex;n order;borne superieure;polynome;cero;cota superior;conjunto ordenado;zero	For any positive integer n, let Gn denote the set of simple graphs of order n. For any graph G in Gn, let P(G; ) denote its chromatic polynomial. In this paper, we -rst show that if G ∈Gn and (G)6 n− 3, then P(G; ) is zero-free in the interval (n − 4 + =6 − 2= ;+∞), where = (108 + 12√93)1=3 and =6 − 2= (=0:682327804 : : :) is the only real root of x + x − 1; we proceed to prove that whenever n − 66 (G)6 n − 2, P(G; ) is zero-free in the interval ( (n+ (G))=2 − 2;+∞). Some related conjectures are also proposed. c © 2003 Elsevier B.V. All rights reserved.	chromatic polynomial;graph (discrete mathematics)	Feng Ming Dong;Khee Meng Koh	2004	Discrete Mathematics	10.1016/j.disc.2003.12.005	integer;chromatic polynomial;combinatorics;discrete mathematics;graph theory;root;mathematics;geometry;upper and lower bounds;polynomial;algebra	Theory	30.32640096519495	31.254062327964714	5801
b243092c5485cc7cca8d64102cc8f79ab9fbb378	undecidability of the surjectivity of the subshift associated to a turing machine		We consider Turing machines (TM) from a dynamical system point of view, and in this context, we associate a subshift by taking the sequence of symbols and states that the head has at each instant. Taking a subshift that select only a part of the state of a system is a classical technic in dynamical systems that plays a central role in their analysis. Surjectivity of Turing machines is equivalent to their reversibility and it can be simply identified from the machine rule. Nevertheless, the associated subshift can be surjective even if the machine is not, and the property results to be undecidable in the symbolic system.	string (computer science);turing machine	Rodrigo Torres-Avilés;Nicolas Ollinger;Anahí Gajardo	2012		10.1007/978-3-642-36315-3_4	combinatorics;discrete mathematics;description number;algorithm	ML	-0.6983187782829179	21.998953032436603	5809
265d36c00daf6748e505751eac615594b7c2299f	simultaneous pq-ordering with applications to constrained embedding problems	pq trees;simultaneous embedding;ordering problem;interval graphs;planar embeddings	In this article, we define and study the new problem of S<scp>imultaneous</scp> PQ-O<scp>rdering</scp>. Its input consists of a set of PQ-trees, which represent sets of circular orders of their leaves, together with a set of child-parent relations between these PQ-trees, such that the leaves of the child form a subset of the leaves of the parent. S<scp>imultaneous</scp> PQ-O<scp>rdering</scp> asks whether orders of the leaves of each of the trees can be chosen <i>simultaneously</i>; that is, for every child-parent relation, the order chosen for the parent is an extension of the order chosen for the child. We show that S<scp>imultaneous</scp> PQ-O<scp>rdering</scp> is <i>NP</i>-complete in general, and we identify a family of instances that can be solved efficiently, the <i>2-fixed instances</i>. We show that this result serves as a framework for several other problems that can be formulated as instances of S<scp>imultaneous</scp> PQ-O<scp>rdering</scp>. In particular, we give linear-time algorithms for recognizing simultaneous interval graphs and extending partial interval representations. Moreover, we obtain a linear-time algorithm for P<scp>artially</scp> PQ-C<scp>onstrained</scp> P<scp>lanarity</scp> for biconnected graphs, which asks for a planar embedding in the presence of PQ-trees that restrict the possible orderings of edges around vertices, and a quadratic-time algorithm for S<scp>imultaneous</scp> E<scp>mbedding with</scp> F<scp>ixed</scp> E<scp>dges</scp> for biconnected graphs with a connected intersection. Both results can be extended to the case where the input graphs are not necessarily biconnected but have the property that each cutvertex is contained in at most two nontrivial blocks. This includes, for example, the case where both graphs have a maximum degree of 5.	algorithm;biconnected component;biconnected graph;bottom-up parsing;decision problem;interval arithmetic;np-completeness;pq tree;planar graph;planarity;polynomial;problem solving;simultaneous multithreading;time complexity;top-down and bottom-up design	Thomas Bläsius;Ignaz Rutter	2015	ACM Trans. Algorithms	10.1145/2738054	mathematical optimization;combinatorics;discrete mathematics;topology;mathematics	Theory	25.654189750445315	23.607503148579628	5810
46fa9000a55a0d7a17eb712f62edc3b1539a4430	an improved lower bound for the complementation of rabin automata	full automata rabin automata complementation determinization omega automata;rabin automata technique;formal languages automata theory computational complexity;complexity theory;determinization;automata usa councils formal languages instruments upper bound logic computer science multidimensional systems arithmetic encoding;improved lower bound;bismuth;construction industry;formal languages;upper bound rabin automata technique infinite word formal language theory omega automata state complexity improved lower bound;usa councils;data mining;full automata;infinite word;state complexity;upper bound;automata;rabin automata;computational complexity;reactive system;automata theory;formal language theory;omega automata;complementation;lower bound;formal language	Automata on infinite words (ω-automata) have wide applications in formal language theory as well as in modeling and verifying reactive systems. Complementation of ω-automata is a crucial instrument in many these applications, and hence there have been great interests in determining the state complexity of the complementation problem. However, obtaining nontrivial lower bounds has been difficult. For the complementation of Rabin automata, a significant gap exists between the state-of-the-art lower bound 2^Ω(NlgN) and upper bound 2^O(kNlgN), where k, the number of Rabin pairs, can be as large as 2N. In this paper we introduce multidimensional rankings to the full automata technique. Using the improved technique we establish an almost tight lower bound for the complementation of Rabin automata. We also show that the same lower bound holds for the determinization of Rabin automata.	automata theory;automaton;formal language;powerset construction;verification and validation;ω-automaton	Yang Cai;Shaobo Zhang;Haifeng Luo	2009	2009 24th Annual IEEE Symposium on Logic In Computer Science	10.1109/LICS.2009.13	combinatorics;formal language;discrete mathematics;computer science;mathematics;upper and lower bounds;algorithm	Logic	-1.4224969662574418	23.680886954237337	5816
e6ead1a89d961c654f03dae03912983556aa4fcf	an algorithmic approach to the identification of rigid domains in proteins	algoritmo aleatorizado;conformational change;approximate algorithm;algorithmique;protein complex;proteine;descomposicion funcion;rigid domains;approximation algorithm;protein flexibility;biologia molecular;algorithme randomise;structure function relationship;hinge motion;structure proteine;protein structure;algorithmics;algoritmica;pattern matching;decomposition fonction;molecular biology;algoritmo aproximacion;randomized algorithm;proteina;concordance forme;algorithme approximation;protein;dynamic domains;point pattern matching;function decomposition;biologie moleculaire	Many proteins undergo conformational changes to perform their functions. A simple mechanism of conformational change in proteins is a rigid domain motion, in which two parts of a structure move rigidly with respect to each other. The identification of rigid domains is therefore useful in understanding the structure-function relationship of proteins. Many algorithms, including those in [16], [22], [13], [10], and [19], have been developed to identify rigid domains. In this paper we complement these works by proposing a mathematical definition of a rigid domain. We argue that our definition more accurately captures the intuitive notion of rigid domain in the previous work, than the quantitative definition of a rigid domain introduced by Nichols et al. [19]. Furthermore, our definition admits a practical approximation algorithm. We can prove theoretical guarantee on the quality of the output of our algorithm. We implement a randomized version of our algorithm, and demonstrate its effectiveness on several known protein complexes.	approximation algorithm;connected component (graph theory);experiment;graphical user interface;molecular dynamics;nichols plot;randomized algorithm;simulation;vmd	Vicky Choi;Navin Goyal	2007	Algorithmica	10.1007/s00453-007-0186-0	functional decomposition;protein structure;computer science;pattern matching;mathematics;geometry;multiprotein complex;randomized algorithm;algorithmics;approximation algorithm;algorithm	Comp.	16.69814860963578	22.055256860290175	5820
76339d01f90e6c9fcdc199cfe75822a4a8fd4a5e	elliptic near-mds codes over f5	finite fields;elliptic curves;94b05;codes;51e20;14g50;mds code	Let Γ6 be the elliptic curve of degree 6 in PG(5, q) arising from a non-singular cubic curve $${\mathcal{E}}$$ of PG(2, q) via the canonical Veronese embedding $$\nu:\quad (X,Y,Z)\to (X^2,XY,Y^2,XZ,YZ,Z^2).$$ (1) If Γ6 (equivalently $${\mathcal{E}}$$ ) has n GF(q)-rational points, then the associated near-MDS code $${\mathcal{C}}$$ has length n and dimension 6. In this paper, the case q = 5 is investigated. For q = 5, the maximum number of GF(q)-rational points of an elliptic curve is known to be equal to ten. We show that for an elliptic curve with ten GF(5)-rational points, the associated near-MDS code $${\mathcal{C}}$$ can be extended by adding two more points of PG(5, 5). In this way we obtain six non-isomorphic [12, 6]5 codes. The automorphism group of $${\mathcal{C}}$$ is also considered.	code	Vito Abatangelo;Bambina Larato	2008	Des. Codes Cryptography	10.1007/s10623-007-9144-8	combinatorics;discrete mathematics;mathematics;geometry;elliptic curve;code;finite field;algebra	Crypto	41.27990461483134	33.35756974422485	5826
bd7871f8534d93542de3c6a74e1e52ba47704be0	generating the fewest redundancy-free scheme trees from acyclic conceptual-model hypergraphs in polynomial time	conceptual model based scheme tree generation;acyclic conceptual model hypergraphs;minimal scheme tree forests;data redundancy in scheme trees	Generating the fewest redundancy-free scheme trees from conceptual-model hypergraphs is NP-hard [11]. We show, however, that the problem has a polynomial-time solution if the conceptual-model hypergraph is acyclic. We define conceptual-model hypergraphs, cycles, and scheme trees, and then present a polynomial-time algorithm and show that it generates the fewest redundancy-free scheme trees. As a practical application for the algorithm, we comment on its use for the design of “good” XML schemas for data storage.	algorithm;computer data storage;directed acyclic graph;np-hardness;polynomial;polynomial-time approximation scheme;time complexity;xml schema	Wai Yin Mok;Joseph Fong;David W. Embley	2014	Inf. Syst.	10.1016/j.is.2013.10.009	theoretical computer science	DB	18.266464423290547	24.200274079501813	5827
b52ca834e425768b0ba2b251ec67b51afe8abd1a	cae functionality for verification of diagnostic programs	printed circuit testing automatic test equipment automatic testing cad cam digital simulation electronic engineering computing fault location integrated circuit testing;functional tests ic testing pcb testing cae functionality verification of diagnostic programs feasibility study computer aided engineering cae built in test fault simulation bit verification embedded bit program ate automatic test equipment;computer aided engineering computational modeling circuit simulation circuit faults circuit testing fault diagnosis computer simulation automatic test equipment automatic testing integrated circuit testing;fault simulation;functional testing;integrated circuit;automatic testing;automatic test equipment;feasibility study;computer aided engineering;cad cam;integrated circuit testing;built in test;electronic engineering computing;printed circuit testing;digital simulation;fault location	Verification of embedded built-in tes t (BIT) diagnostic programs is typically accomplished by manual analysis and fault insertion techniques. Digital fault simulation offers the opportunity to automate the verification of BIT. Frequently, fault simulators do not support the capacity to completely simulate and fault grade a BIT. A feasibility study conducted by Texas Instruments has identified computer-aided engineering (CAE) features and a methodology approach that will support BIT verification through fault simulation. With an example, this paper illustrates the evolutionary fault simulation features and the attendant methodology to support BIT verification by simulation.	canonical account;embedded system;simulation;x/open	Carol Pyron;Rex Sallade	1989		10.1109/TEST.1989.82282	embedded system;automatic test equipment;feasibility study;electronic engineering;verification and validation of computer simulation models;verification;computer science;engineering;integrated circuit;functional testing;functional verification;computer-aided technologies;computer engineering	EDA	9.672121423319192	52.807479878510634	5828
8bb003d1ad1ab8e3dce4b0e344076fa16bf632f8	a high accuracy-low complexity model for cmos delays	piecewise linear;piecewise linear techniques;complex structure;low complexity;delay equation;semiconductor device modeling delay cmos technology capacitance voltage electronic mail nonlinear equations circuits timing computational complexity;circuit optimization cmos logic circuits cmos digital integrated circuits delay estimation integrated circuit modeling logic gates piecewise linear techniques circuit analysis computing timing;logic gates;cmos digital integrated circuits;cmos logic circuits;mos timing macromodel high accuracy low complexity model cmos delays delays estimation complex gate behavior series connected mos delay equations time piecewise linearization nonlinear circuit model parameters mos width functions optimization algorithms scaling capability deep submicron technologies;integrated circuit modeling;nonlinear circuits;circuit analysis computing;optimal algorithm;delay estimation;circuit optimization;timing	This paper presents a new model for CMOS structures delays estimation based on a deep analysis of complex gates behavior. This approach can supply a high level of accuracy. A complex structure is reduced first to series-connected MOS, then the delay equations are applied to that reduced rate. The model is based on a time piecewise linearization so that a strongly nonlinear circuit can he solved using well known linear techniques. The delay formulas involve model parameters as MOS width functions, therefore providing routines suitable for optimization algorithms. The high level of accuracy, the low CPU time and the high degree of scaling capability are proved in the paper. These features make the model attractive for deep submicron technologies.	cmos	Mario R. Casu;Guido Masera;Gianluca Piccinini;Massimo Ruo Roch;Maurizio Zamboni	2000		10.1109/ISCAS.2000.857129	control engineering;electronic engineering;piecewise linear function;logic gate;computer science;control theory;generalized complex structure;mathematics	Logic	25.362912071536236	50.15464501739813	5841
243a40c208a38c1a7e0fcb114acb70f7caf8e9b2	gray codes for at-free orders via antimatroids		The ({{mathrm{mathrm {AT}}}})-free order is a linear order of the vertices of a graph the existence of which characterizes ({{mathrm{mathrm {AT}}}})-free graphs. We show that all ({{mathrm{mathrm {AT}}}})-free orders of an ({{mathrm{mathrm {AT}}}})-free graph can be generated in O(1) amortized time.	antimatroid	Jou-Ming Chang;Ton Kloks;Hung-Lung Wang	2015		10.1007/978-3-319-29516-9_7	chordal graph;gray code;vertex (geometry);interval graph;topology;mathematics;amortized analysis;graph	Theory	26.9418150989749	29.592469923949874	5854
70af31fdbf2a45d47131d690e4ce6aa398e9346f	an efficient source of random numbers for modeling symmetrically distributed noise	modelizacion;traitement signal;ley uniforme;ruido aleatorio;loi probabilite;ley probabilidad;gaussian processes;variable aleatoire;bruit aleatoire;funcion densidad probabilidad;probability density function;random number generation;simulation;variable aleatoria;modelisation;fonction densite probabilite;random noise;stochastic processes;signal processing;probability distribution;generation nombre aleatoire;random variable;signal processing algorithms random numbers symmetrically distributed noise modelling symmetric random noise kurtosis random variates pseudorandom numbers mock gaussian variate gaussian moments fourth order moments computer simulation;filters multidimensional signal processing statistics filtering speech processing fuzzy systems optimized production technology error analysis hardware input variables;random numbers;procesamiento senal;modeling;loi uniforme;computer simulation;gaussian processes random noise random number generation stochastic processes digital simulation simulation signal processing;generacion numero aleatorio;digital simulation;uniform distribution	Computer simulation of signal processing algorithms inevitably requires an efficient source of pseudorandom numbers to model noise. If symmetric random noise is defined by its kurtosis rather than by its distribution, it can be simulated by simple combinations of random variates X/sub 1/, X/sub 2/, ... uniformly distributed on the interval (-1, 1). A notable example is the mock-Gaussian variate Y=0.9828X/sub 1/+2.493SX/sub 2/X/sub 3/, which appears to be the simplest generator possible for giving Gaussian moments up to the fourth order.		Roger J. Webster	1996	IEEE Trans. Signal Processing	10.1109/78.482025	computer simulation;random variate;probability distribution;random variable;probability density function;systems modeling;random number generation;theoretical computer science;signal processing;gaussian process;mathematics;uniform distribution;statistics	Embedded	52.457856725445566	14.043444864064394	5865
742dbc32adce8772547001e94c5587aaa49952a9	scan chain configuration based x-filling for low power and high quality testing	design for testability;shift power;circuito secuencial;flip flop circuits;flip flops;circuit sequentiel;electronica potencia;boundary scan testing;scan flip flops scan chain configuration x filling low power testing high quality testing scan based testing dft shift power capture power;power electronics;x filling;electronique puissance;low power;circuit bistable;scan flip flops;low power electronics;high quality testing;scan based testing;scan chain configuration;low power testing;electronique faible puissance;low power electronics boundary scan testing design for testability flip flops;dft;capture power;sequential circuit	Test power is a serious problem in the scan-based testing. DFT-based techniques and X-filling are two effective ways to reduce both shift power and capture power. However, few of the previous methods pay attention to the defect coverage when reducing the test power. Many of them, especially for X-filling methods, may lead to low defect coverage. In this paper, based on an effective scan chain configuration, we present a segment-based X-filling to reduce test power and keep the defect coverage. The scan chain configuration tries to cluster the scan flip-flops with common successors into one scan chain, in order to distribute the specified bits per pattern over a minimum number of chains. Based on the configuration, all the bits to some scan chains in a vector may be don't care(X). For these scan chains, segment-based X-filling is used to reduce test power and keep the defect coverage. Compared with the ordinary full-scan architecture, experimental results show that low test power and high defect coverage can be achieved.	display resolution	Zhen Chen;Jianwei Feng;Dong Xiang;Boxue Yin	2010	IET Computers & Digital Techniques	10.1049/iet-cdt.2008.0163	embedded system;electronic engineering;scan chain;real-time computing;engineering;electrical engineering;test compression;discrete fourier transform;power electronics;design for testing;sequential logic;low-power electronics	EDA	20.223087785777402	53.42827556272296	5869
a7616d2a5f05cad2d61ee0af17ac9b249f3dd741	a nonlinear optimization methodology for resistor matching in analog integrated circuits	resistors analogue integrated circuits integrated circuit layout nonlinear programming;resistor ratios;relative position;layout phase;topology;integrated circuit layout;intellectual property;nonlinear programming;niobium;design flow;centrosymmetrical shape nonlinear optimization methodology resistor matching analog integrated circuits analog design flow resistor ratios layout phase matching quality rectangular structure fixed outline constraint layout designers rectilinear shape;layout;analog design flow;resistors layout optimization shape niobium dispersion topology;analogue integrated circuits;matching quality;shape;layout designers;resistor matching;analog integrated circuits;nonlinear optimization methodology;resistors;optimization;rectilinear shape;electrical properties;centrosymmetrical shape;nonlinear optimization;dispersion;fixed outline constraint;rectangular structure	In analog design flow, one of the most important issues is to achieve accurate resistor ratios during the layout phase, which is called resistor matching. In the literature, researchers have proposed several methodologies achieving high matching quality in a rectangular structure. However, under the fixed-outline constraint, layout designers will place normal blocks such as macros and intellectual properties (IPs) first and then place the resistors. But the remaining space for resistors is usually rectilinear rather than rectangular, which is not appropriate for achieving high matching quality. To overcome this problem, we propose a nonlinear optimization methodology for globally improving the matching quality. Our algorithm enhances the matching quality by deforming the rectilinear shape into centro symmetrical shape and simultaneously maintains the relative positions of each block which is important for reserving the designed electrical property in the input layout. Experimental result shows that the proposed algorithm is very promising.	algorithm;integrated circuit;mathematical optimization;nonlinear programming;nonlinear system;regular grid	Sheng-Jhih Jiang;Chan-Liang Wu;Tsung-Yi Ho	2012	Proceedings of Technical Program of 2012 VLSI Design, Automation and Test	10.1109/VLSI-DAT.2012.6212630	mathematical optimization;electronic engineering;mathematics;engineering drawing	EDA	14.421222695157587	51.17101039108019	5892
de97623568c64b5b1ae58876bbdbb920afb65db8	improving error resilience for compressed test sets by don't care assignment	bit flip;device under test;test data compression;automatic test equipment;resilience circuit testing system on a chip circuit faults benchmark testing manufacturing test data compression system testing automatic testing integrated circuit testing;integrated circuit testing automatic test equipment fault diagnosis;compressed test data stream;ate;system on chip;fault coverage ate error resilience soc test data compression don t care assignment;fault coverage loss;integrated circuit testing;error resilience;test data compression error resilience don t care assignment compressed test data stream automatic test equipment device under test bit flip fault coverage loss system on chip;soc;fault coverage;fault diagnosis;don t care assignment	Error-resilience is related to the capability of a compressed test data stream (which is transferred from an automatic test equipment (ATE) to the device-under-test (DUT)) to tolerate bit-flips. The bit-flips may occur in an ATE in the electronics components of the loadboard. As reported in (Hashempour et al., 2005), 10%-30% loss in the fault coverage of compressed test streams can occur due to bit flips for ISCAS89 benchmark circuits. This paper presents a novel technique based on don't care assignment (prior to compression) to improve the error-resilience of a compressed test stream. Experimental results substantiate its effectiveness: fault coverage loss was contained to only 0.5%-6% compared to (Hashempour et al., 2005)	benchmark (computing);built-in test equipment;device under test;don't-care term;fault coverage;test data	Hamidreza Hashempour;Fabrizio Lombardi	2005	Proceedings 2005 IEEE International SOC Conference	10.1109/SOCC.2005.1554456	system on a chip;embedded system;electronic engineering;real-time computing;computer science;engineering	EDA	21.081724419034234	52.89751862839643	5898
b915d95b14c24608183121f199a08abad3387b37	perfect graph codes over two dimensional lattices	graph theory;quadrature amplitude modulation error correction codes gaussian processes graph theory;gaussian graphs;perfect code;l graphs;error correction codes;lattices;gaussian processes;construction industry;perfect graph;qam type constellations;multidimensional circulants;error correcting codes perfect codes qam type constellations l graphs multidimensional circulants gaussian graphs lee graphs kronecker product perfect two dimensional lee codes;lattices multidimensional systems extraterrestrial measurements signal design error correction codes constellation diagram;error correcting codes;perfect codes;perfect two dimensional lee codes;constellation diagram;extraterrestrial measurements;lee graphs;quadrature amplitude modulation;kronecker product;information theory	In this paper we consider perfect codes over two dimensional QAM-type constellations of any cardinal. Such constellations are going to be modeled by L-graphs, which are the two-dimensional family of multidimensional circulants, defined in [3]. We show that Gaussian graphs, Lee graphs and the Kronecker product of two cycles are included in this family. Therefore, our method to obtain perfect codes over these lattice subsets is a generalization of the techniques for searching perfect two-dimensional Lee codes and perfect codes over the Kronecker products of two cycles. In addition, we introduce some previously unreported perfect codes.	code;graph (discrete mathematics);hamming bound	Carmen Martínez;Cristobal Camarero;Ramón Beivide	2010	2010 IEEE International Symposium on Information Theory	10.1109/ISIT.2010.5513724	block code;perfect graph theorem;combinatorics;discrete mathematics;quadrature amplitude modulation;constellation diagram;perfect graph;information theory;hamming bound;perfect set property;graph theory;trivially perfect graph;pure mathematics;lattice;gaussian process;mathematics;kronecker product;perfect power;unitary perfect number;statistics	Theory	40.92914102885708	55.089474217386105	5904
e0fe10989f959d811f9e2a43863d772a74503400	towards a home environment testbed: experiments with human body simulators and a real house		This paper illustrates a design and implementation of a home environment testbed. The proposed testbed aims to support experiments on real home environments with human subjects. However, conducting experiments with real human subjects has several limitations regarding costs, time, and user privacy. In order to avoid such issues, human body simulators (HBSims), which are designed to support 24-hour in-house repeatable experiments, are employed. Using HBSims, the patterns of human humidity and temperature are generated. Based on human activity schedules together with home appliance usage time obtained from one family, HBSims were employed in experiments in a real house. The evaluation results demonstrate that (1) our proposed testbed can potentially be used for real home environment experiments and (2) HBSims can be used instead of real human subjects for studying the effects of a human body in real home environments.	24-hour clock;experiment;privacy;simulation;testbed	Tanatorn Tanantong;Yoshiki Makino;Yasuo Tan	2017	2017 IEEE 6th Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2017.8229249	simulation;schedule;testbed;computer science	Robotics	1.7241220236554715	33.31389591045805	5925
dc4fe639012048e98eb14500e41b04275a43b192	recursive circle packing problems	packing problems;knapsack problems;practice of or;integer programming;loading problems;heuristics;combinatorial optimization;local search	This paper presents a class of packing problems where circles may be placed either inside or outside other circles, the whole set being packed in a rectangle. This corresponds to a practical problem of packing tubes in a container; before being inserted in the container, tubes may be put inside other tubes in a recursive fashion. A variant of the greedy randomized adaptive search procedure is proposed for tackling this problem, and its performance assessed in a set of benchmark instances.	benchmark (computing);combinatorial optimization;disjunctive normal form;grasp;greedy algorithm;greedy randomized adaptive search procedure;heuristic;mathematical optimization;metaheuristic;programming model;randomized algorithm;recursion (computer science);relevance;semiconductor industry;set packing;unix domain socket	João Pedro Pedroso;Sílvia Cunha;João Nuno Tavares	2016	ITOR	10.1111/itor.12107	mathematical optimization;packing problems;combinatorics;discrete mathematics;set packing;integer programming;covering problems;combinatorial optimization;local search;heuristics;mathematics	AI	23.38420999419191	6.632926778058418	5940
b509e7cf5f3f2a2c01e125be31473c635edf3a74	efficient high-speed cmos design by layout based schematic method	cmos integrated circuits;estimation method;circuit optimisation cmos integrated circuits circuit layout cad mosfet digital simulation;circuit design;cad high speed cmos design layout based schematic method diffusion area wire capacitance circuit performance mos transistors simulation circuit layout optimization;diodes parasitic capacitance circuit simulation wire circuit optimization mosfets design optimization cost function circuit synthesis very large scale integration;circuit layout cad;mosfet;circuit optimisation;high speed;digital simulation	As the diffusion area and the wire capacitance worsen the circuit performance in very high speed CMOS design, the results between schematic and layout differ from each other because of missing parasitic components in the schematic. We address a layout based schematic (LBS) method for high speed CMOS cell design. In our method, we introduce different types of MOS transistors and a wire capacitance estimation method, based on layout knowledge. The simulation results at very high speed show that the difference between LBS and real circuit layout is much smaller, less than 3 percent in rise time, compared to the difference in the worst case up to 65 percent in original schematic. The result of LBS is reliable and easy to be optimized during the schematic procedure. It will reduce the design time and cost in high speed circuit design. We also believe that the LBS is more convenient to be translated into the real layout than the original schematic.	cmos;schematic	Fenghao Mu;Christer Svensson	1998		10.1109/EURMIC.1998.711823	equivalent circuit;physical design;embedded system;circuit diagram;electronic engineering;computer hardware;ic layout editor;engineering;circuit design;design layout record;integrated circuit layout;circuit extraction;standard cell	EDA	17.38449160966241	54.61553844535877	5947
246a9fde424fac58efba5472c930c3d0fbae739a	review of 'communication theory' (balakrishnan, a.v., ed.; 1968)	signal detection book reviews communication theory;signal detection;communication theory;book reviews	First Page of the Article		Stuart C. Schwartz	1968	IEEE Trans. Information Theory	10.1109/TIT.1968.1054228	communication theory;detection theory	Theory	51.37045639450015	25.205546814900515	5948
d0be889d05ae8c692525dd0aacc71cb2006c27d7	challenges and perspectives of computer architecture at the nano scale	computers;cmos integrated circuits;nanocomputing;cmos technology;neuro inspired computing structure;nanobioscience;nano scale;nanotechnology;materials;computer architecture;transistors;nanobioscience computer architecture cmos integrated circuits transistors materials europe computers;nanoelectronics;neuro inspired computing structure computer architecture nano scale nanotechnology nano component cmos technology nanocomputing;europe;nano component;nanoelectronics cmos integrated circuits computer architecture	Advances in nanotechnology and the research of new materials has led to the elaboration of nano-components with novel properties and functions. Exploring how those novel components could be used to devise future computer architectures, complementing rather than supplementing CMOS technology, is a new research subject known as Nanocomputing. In this talk we will present the major challenges of such a research, the potential benefits of using technologies other than CMOS and some perspectives in terms of design and applications. We will illustrate the topic by presenting some of the most advanced results in the field, focusing on results from the European project FP7, NABAB, that explores how to build neuro-inspired computing structures with a variety of nanotechnologies.	cmos;computer architecture;gnu nano;nanocomputer	Christian Gamrat	2010	2010 IEEE Computer Society Annual Symposium on VLSI	10.1109/ISVLSI.2010.118	electronic engineering;engineering;nanotechnology;computer engineering	Arch	12.153246029284736	57.79838044299432	5951
f2aa1a517a60dbdac3b055ec137a83db54826b14	a spatial index for convex simplicial complexes in d dimensions	simplicial complex;spatial index;sequential search;data structure	"""A data structure for representing convex simplicial complexes in d-dimensional space is presented with which a k-face of the complex containing a query point can be determined in time o(1ogd nd). This is an improvement over a sequential search approach requiring O(nd3 ) time. We show that a structure of O(d!nd ) storage can be easily constructed and present a compression technique which is conjectured to produce a structure of O(nd2d ) storage. IThis research was supported, through the Leonardo Fibonacci Institute, by the Istituto Trentino di Cultura, Trento Italy. 2Additional support was provided by NSF grant CCR-86-19817 to Purdue University. 3 Additional support was provided by PF """"Edilizia"""" and """"Robotica"""" of the Italian National Research Council."""	data structure;face (geometry);ibm notes;linear search;simplicial complex;spatial database	Vincenzo Ferrucci;George Vanecek	1991		10.1007/3-540-54414-3_47	betti number;combinatorics;n-skeleton;topology;simplicial approximation theorem;abstract simplicial complex;barycentric subdivision;mathematics;geometry;delta set;simplicial manifold;simplicial complex;simplicial homology;simplex	Theory	35.14428610488477	18.722417751715817	5956
962d7790862bd00fc5606c747fd05f4e8d0e8f64	a class of self-orthogonal 2-sequencings	character sum;hamiltonian path;generalization bounds	Let 2Kndenote the complete multigraph on n vertices in which each edge has multiplicity two. If 2Kncan be partitioned into Hamiltonian paths such that any two distinct paths have exactly one edge in common, write 2Kn→ Pn. This paper considerably expands the set of known positive integers n such that 2Kn→ Pn. The solutions found have application to other similar problems. The basic idea is to consider an algebraic formulation of the problem in terms of 2-sequencings (terraces) with additional properties. Construction of these 2-sequencings gives a special type of solution for which very few examples have been known. The constructions detailed here hold eventually for certain classes of prime powers. For example, it is shown that there is a positive integer N such that if N < pn≡ 5 (mod 8) and 3 is not a fourth power residue of GF[pn], then the additive group of GF[pn] has a 2-sequencing of the required type—a self-orthogonal 2-sequencing. Some of the solutions admit a 2-coloring which is important for applications. The method of construction appears to be much better than the theoretical bounds that are obtained. The general bounds are found by means of a character sum argument.		B. A. Anderson;P. A. Leonard	1991	Des. Codes Cryptography	10.1007/BF00157619	hamiltonian path;combinatorics;discrete mathematics;mathematics;geometry;algorithm;algebra	Crypto	37.26076637509853	34.546981674309734	5969
e41dddcd86f48b18441e4a655e594b56c6d3da48	computing irreducible representations of finite groups	finite group;bit complexity;generators set;exact computations;inequivalent irreducible representations;randomized polynomial time;algebraic number fields;polynomials algebra matrix decomposition chromium;equivalence class;deterministic polynomial time;absolutely irreducible constituents;complex numbers;group theory;group theory computational complexity;polynomial time algorithm;las vegas polynomial time;multiplication table;computational complexity;irreducible representation;finite groups;exact computation;polynomial time;deterministic polynomial time exact computations matrices list randomized polynomial time las vegas polynomial time generators set finite groups bit complexity algebraic number fields polynomial time algorithm inequivalent irreducible representations complex numbers multiplication table equivalence class polynomial size description absolutely irreducible constituents;polynomial size description;matrices list	We consider the bit-complexity of the problem stated in the title. Exact computations in algebraic number fields are performed symbolically. We present a polynomial-time algorithm to find a complete set of nonequivalent irreducible representations over the field of complex numbers of a finite group given by its multiplication table. In particular, it follows that some representative of each equivalence class of irreducible representations admits a polynomial-size description. We also consider the problem of decomposing a given representation 'V of the finite group G over an algebraic number field F into absolutely irreducible constituents. We are able to do this in deterministic polynomial time if 'V is given by the list of matrices {^(g) ', g 6 G} ; and in randomized (Las Vegas) polynomial time under the more concise input {'P'(g) ; g € S} , where S is a set of generators of G .	computation;context of computational complexity;irreducibility;las vegas algorithm;linear algebra;polynomial;randomized algorithm;time complexity;turing completeness	László Babai;Lajos Rónyai	1989		10.1109/SFCS.1989.63461	equivalence class;irreducible polynomial;time complexity;combinatorics;discrete mathematics;irreducible representation;representation theory of su;multiplication table;mathematics;complex number;computational complexity theory;group theory;(g,k)-module;irreducible element;irreducible component;algebra	Theory	41.91973005296691	39.98254822635793	5986
245f2e60e2c1a5805dfcb2f36ed2c9d97c117908	reducing data hazards on multi-pipelined dsp architecture with loop scheduling	data flow graph;scheduling algorithm;loop scheduling;simulation tool;high performance	Computation intensive DSP applications usually require parallel/pipelined processors in order to meet specific timing requirements. Data hazards are a major obstacle against the high performance of pipelined systems. This paper presents a novel efficient loop scheduling algorithm that reduces data hazards for such DSP applications. This algorithm has been embedded in a tool, called SHARP, which schedules a pipelined data flow graph to multiple pipelined units while hiding the underlying data hazards and minimizing the execution time. This paper reports significant improvement for some well-known benchmarks showing the efficiency of the scheduling algorithm and the flexibility of the simulation	algorithm;benchmark (computing);central processing unit;computation;dataflow;embedded system;loop scheduling;pipeline (computing);requirement;run time (program lifecycle phase);schedule (computer science);scheduling (computing);simulation	Sissades Tongsima;Chantana Phongpensri;Edwin Hsing-Mean Sha;Nelson L. Passos	1998	VLSI Signal Processing	10.1023/A:1008063207990	fair-share scheduling;embedded system;parallel computing;real-time computing;dynamic priority scheduling;computer science;operating system;data-flow analysis;distributed computing;programming language;scheduling	EDA	-0.7395651039778651	51.252862807671626	5991
e561ce0385e46671983b33a87481ed5863a70533	design of voltage-scalable meta-functions for approximate computing	chained data path component;pattern clustering;kernel;multimedia;support vector machines;computational techniques;clocks;system level simulations;meta functions;radiation detectors;k means;k means based clustering approximate computing computational kernel inherent resilience multimedia data mining dynamic segmentation multicycle error compensation delay budgeting chained data path component voltage over scaling transistor level simulations optimized metafunction implementations system level simulations motion estimation support vector machine based classification;motion estimation;radiation detector;indexing terms;data mining;multimedia systems;support vector machines data mining motion estimation multimedia systems pattern classification pattern clustering power aware computing;inherent resilience;power aware computing;design technique;voltage over scaling;function approximation;multicycle error compensation;adders;k means based clustering;delay budgeting;support vector machine based classification;error compensation;pattern classification;error rate;dynamic segmentation;optimized metafunction implementations;low power design;computational kernel;support vector machine;delay clocks error compensation adders radiation detectors algorithm design and analysis kernel;meta functions approximate computing low power design voltage over scaling;approximate computing;algorithm design;hardware implementation;algorithm design and analysis;transistor level simulations	Approximate computing techniques that exploit the inherent resilience in algorithms through mechanisms such as voltage over-scaling (VOS) have gained significant interest. In this work, we focus on meta-functions that represent computational kernels commonly found in application domains that demonstrate significant inherent resilience, namely Multimedia, Recognition and Data Mining. We propose design techniques (dynamic segmentation with multi-cycle error compensation, and delay budgeting for chained data path components) which enable the hardware implementations of these meta-functions to scale more gracefully under voltage over-scaling. The net effect of these design techniques is improved accuracy (fewer and smaller errors) under a wide range of over-scaled voltages. Results based on extensive transistor-level simulations demonstrate that the optimized meta-function implementations consume up to 30% less energy at iso-error rates, while achieving upto 27% lower error rates at iso-energy when compared to their baseline counterparts. System-level simulations for three applications, motion estimation, support vector machine based classification and k-means based clustering are also presented to demonstrate the impact of the improved meta-functions at the application level.	approximate computing;approximation algorithm;baseline (configuration management);cluster analysis;computation;data mining;image scaling;k-means clustering;motion estimation;scalability;simulation;support vector machine;transistor	Debabrata Mohapatra;Vinay K. Chippa;Anand Raghunathan;Kaushik Roy	2011	2011 Design, Automation & Test in Europe	10.1109/DATE.2011.5763154	embedded system;support vector machine;algorithm design;electronic engineering;real-time computing;computer science;theoretical computer science;operating system;machine learning;particle detector;algorithm;statistics	EDA	12.616077064493126	48.68749082447952	5996
1947373e58594d73a3a75ca03dd014152f9c577d	average time complexity of the sat 1.2 algorithm	time complexity;efficient algorithm;satisfiability;davis putnam;exhaustive search	In this paper, we give an efficient algorithm, the SAT1.2 algorithm, for the SAT problem. For randomly generated formulas with n clauses, m variables, and l literals per clause, the average run time of the SAT1.2 algorithm is O(m  o(1) n 2) for l3 and n/m2l/l, where l is a constant. Real algorithm executions indicate that the SAT1.2 algorithm is much more efficient than the well known Davis-Putnam algorithm for certain classes of CNF formulas with small l. This is important in practice, since for large l, most vectors in {0, 1}m are the solutions of the problem. Thus, a random exhaustive search can efficiently solve the problem. The SAT1.2 algorithm can find a solution for a satisfiable CNF formula efficiently but gives an answer in O(m  o(1)2m) time to an unsatisfiable CNF formula. 3	algorithm;time complexity	Jun Gu;Qian-Ping Gu	1994		10.1007/3-540-58325-4_176	time complexity;combinatorics;discrete mathematics;average-case complexity;computer science;brute-force search;worst-case complexity;mathematics;dpll algorithm;algorithm;satisfiability	EDA	10.824485467649383	18.033198812172376	6015
edb988735ab9393e509c7ca1add042b2aca0b2e5	application dependent fpga testing method using compressed deterministic test vectors	compression system;table lookup field programmable gate arrays logic testing shift registers;test pattern compression;test pattern overlapping;memory management;circuit faults;dynamic reconfiguration;application dependent testing fpga testing test pattern compression;ora;internal structure;compas algorithm;field programmable gate arrays circuit faults table lookup application specific integrated circuits memory management test pattern generators;compression test;fpga testing;fpga testing method;application dependent testing;lut based shift registers;test pattern generators;application specific integrated circuits;tpg;shift registers;test pattern decompression;logic testing;test methods;application dependent tests;ora fpga testing method compressed deterministic test vectors application dependent tests compas algorithm compression system test pattern overlapping test pattern decompression lut based shift registers tpg;field programmable gate arrays;table lookup;compressed deterministic test vectors	Tests that exercise complete FPGA resources are often more time and memory consuming than application dependent tests due to the high number of reconfigurations required for complete test. Presented application dependent test does not require reconfiguration of the tested hardware, thus it preserves conditions that led to the erroneous behavior of the FPGA device. The test method saves time and memory requirements of the test by storing compressed test patterns into the internal structure of the FPGA. The patterns are obtained with the help of the improved COMPAS algorithm – compression system based on test pattern overlapping. The COMPAS requires unused scan chains for the test pattern decompression. This is well suited for nowadays FPGAs which contain high number of LUT based shift registers. The neighborhood of the tested circuit is dynamically reconfigured into TPG and ORA. The TPG contains compressed test patterns which allow fast test pattern decompression. The paper demonstrates efficiency of this approach on experimental results.	algorithm;data compression;field-programmable gate array;requirement;shift register;software bug;test card	Martin Rozkovec;Jiri Jenícek;Ondřej Novák	2010	2010 IEEE 16th International On-Line Testing Symposium	10.1109/IOLTS.2010.5560208	embedded system;electronic engineering;parallel computing;computer hardware;computer science;automatic test pattern generation;operating system;test compression;shift register;application-specific integrated circuit;test method;field-programmable gate array;memory management	EDA	20.16279305557995	51.67007914500026	6017
1a29c370a3fca8b866ef3b3e7ec61d31157671cd	"""on """"exponential lower bounds for polytopes in combinatorial optimization"""" by fiorini et al. (2015): a refutation for models with disjoint sets of descriptive variables"""		We provide a numerical refutation of the developments of Fiorini et al. (2015) for models with disjoint sets of descriptive variables. We also provide an insight into the meaning of the existence of a one-to-one linear map between solutions of such models.	combinatorial optimization;numerical analysis;one-to-one (data model)	Moustapha Diaby;Mark H. Karwan;Lei Sun	2016	CoRR		combinatorics;discrete mathematics;mathematics;algorithm	NLP	26.754285297579983	13.075800905322406	6018
49c9fab5e09d76c79a3eccc619ef37f4873ee087	rook theory iii. rook polynomials and the chromatic structure of graphs		The purpose of this paper is to study the relationship between the rook vector of a general board and the chromatic structure of an associated set of graphs. Although part of a numbered series, this paper is self-contained except for a few comments on Ferrers boards at the end. A board B is a finite subset of N x Nwhere N = the set of positive integers. Thus, with [n] = {I, 2 ,..., n}, given a board B we have B C [c] x [r], that is, B has c columns and r rows (some possibly empty). Also, we may consider B as a subset of the set of cells of an n x n chess board; we shall frequently utilize this intuitive terminology. If B C [n] x [n], call B an n-board. For a board B, we let rb = rk(B) = the number of ways of placing k non-taking rooks on B (no two in the same column or row). The rook vector of a board B is defined to be the vector r(B) = (rO , r]. , r, ,...), where r,, = 1. If B is an n-board, then rk = 0 for k > n. Two boards are called rook equivalent if they have the same rook vector. The principal tools for studying rook equivalence have been combinatorial arguments and the rook polynomial c rk . xk. For a systematic treatment of this topic we refer to [5]; also to [l] for some results concerning Ferrers boards. In [3], for B C [c] x [r] and n 3 c we introduced the n-factorialpolynomial p,,(x, B) = x rk * (x),-k ,where (x)~ = x(x 1)(x 2) ... (x j + 1) is the falling factorial, and used this in [3] and [4] to elucidate completely the structure of Ferrers boards. A proper coloring of a graph G (no loops or multiple edges) is a coloring	column (database);falling and rising factorials;graph (discrete mathematics);graph coloring;multiple edges;rook polynomial;turing completeness;xojo	Jay R. Goldman;James T. Joichi;Dennis E. White	1978	J. Comb. Theory, Ser. B	10.1016/0095-8956(78)90033-3	rook's graph;combinatorics;discrete mathematics;mathematics;algebra	Theory	35.772449022588084	34.00091021963442	6024
e1580cd623e746936be7981c14d43f5ddbe2f8ef	une generalisation du theoreme de richardson sur l'existence de noyaux dans les graphes orientes		"""Richardson's theorem [4] asserts that if a digraph has no odd circuit, it possesses a kernel. We improve this theorem in the following manner: if each odd circuit has two short crossing chords, i.e. two chords of the type (X""""i,X""""i""""+""""2), (X""""i""""+""""1,X""""i""""+""""3), it possesses a kernel."""	richardson number	Pierre Duchet;Henry Meyniel	1983	Discrete Mathematics	10.1016/0012-365X(83)90017-1	combinatorics;calculus;mathematics	Theory	31.449289940299277	32.64296008372642	6042
82021a932d1d33dee14177512aad0e07d1335524	effectiveness of software-based hardening for radiation-induced soft errors in real-time operating systems		For decades, radiation-induced failures have been a known issue for aero-space systems, in which redundancy mechanisms are employed as a protection method. Due to the shrinking of structures and operating voltages, these failures are increasingly becoming an issue even for terrestrial applications. Unfortunately, redundancy increases costs, area usage, and power consumption, which can hinder its utilization in costand power-sensitive safety-critical applications, such as automotive. To overcome this limitation, multiple software-based approaches have been proposed, which assume the existence of an underlying error-free operating system. In this paper, we investigate the radiation reliability of two dependability-oriented real-time operating systems, namely, the popular eCos operating system hardened through aspect-oriented programming methods, and dOSEK, an embedded kernel designed from the ground up having reliability as a major concern. Both operating systems were evaluated through extensive neutron-beam testings on a 28nm ARM-based state-of-the-art system-on-chip, and their fault tolerance mechanisms reached reductions in the overall cross-sections relative to their baselines up to 91 percent and 74 percent, respectively.	algorithm;aspect-oriented programming;dependability;embedded system;fault tolerance;hardening (computing);real-time clock;real-time operating system;real-time transcription;soft error;system on a chip;terrestrial television;windows aero;ecos	Thiago Santini;Christoph Borchert;Christian Dietrich;Horst Schirmeier;Martin Hoffmann;Olaf Spinczyk;Daniel Lohmann;Flávio Rech Wagner;Paolo Rech	2017		10.1007/978-3-319-54999-6_1	real-time computing;computer science;fault injection;redundancy (engineering);real-time operating system;fault tolerance;software;radiation;hardening (computing);soft error	Embedded	6.406266164463593	59.08263052785318	6053
6ef8f308b5b4ebf5c023b13e77d4d175595ce51e	on non-blocking collectives in 3d ffts	parallel algorithm;collective communication;non blocking collectives;fast fourier transform;fast fourier transforms;mpi;3 dimensional;parallel algorithms	With the inclusion of non-blocking global collective operations in the MPI 3.0 draft specification many fundamental algorithms such as those for performing 3-dimensional (3D) FFTs will be modified to take advantage of non-blocking collectives. Novel modifications to such fundamental algorithms will need to be suitable for incorporation in general-purpose FFT libraries to be routinely used by HPC application users. Here we present such a general-purpose algorithmic strategy to utilize non-blocking collective communications in the calculation of a single parallel 3D FFT. In this scheme, the global collective communication is partitioned into blocking and non-blocking components such that overlap between communication and computation is obtained in the 3D FFT calculation. We present benchmarks of our scheme for overlapping computation and communication in the calculation of single variable 3D FFTs on two different architectures (a) HECToR, a Cray XE6 machine and (b) a Fujitsu PRIMERGY Intel Westmere cluster with InfiniBand interconnect.	blocking (computing);computation;cray xe6;emoticon;fast fourier transform;general-purpose markup language;hector;infiniband;library (computing);message passing interface;nehalem (microarchitecture);non-blocking algorithm;primergy;supercomputer;westmere (microarchitecture)	Radhika S. Saksena	2011		10.1145/2133173.2133180	parallel computing;computer science;theoretical computer science;distributed computing	HPC	-3.895574352142472	38.540984810127945	6070
c5abb39456f53f9e6450ca2a0df8c9998cbc686b	the distribution of 2^n 2 n -periodic binary sequences with fixed k-error linear complexity		The linear complexity and k-error linear complexity of sequences are important measures of the strength of key-streams generated by stream ciphers. Fu et al. studied the distribution of 2-periodic binary sequences with 1-error linear complexity in their SETA 2006 paper. Recently, people have strenuously promoted the solving of this problem from k = 2 to k = 4 step by step. Unfortunately, it still remains difficult to obtain the solutions for larger k. In this paper, we propose a new sieve method to solve this problem. We first define an equivalence relationship on error sequences and build a relation between the number of sequences with given k-error linear complexity and the number of pairwise non-equivalent error sequences. We introduce the concept of cube fragment and build specific equivalence relation based on the concept of the cube classes to figure out the number of pairwise non-equivalent error sequences. By establishing counting functions for several base cases and building recurrence relations for different cases of k and L, it is easy to manually get the complete counting function when k is not too large. And an efficient algorithm can be derived from this method to solve the problem using a computer when k is large.	algorithm;computer program;execution unit;recurrence relation;stream cipher;turing completeness	Wenlun Pan;Zhenzhen Bao;Dongdai Lin;Feng Liu	2016		10.1007/978-3-319-49151-6_2	time complexity;complementary sequences	AI	43.10764768041544	40.17449440540345	6094
aa2e0e7e67329524f8384320e1f5eaf4b90377d5	space-efficient approximation algorithms for maxcut and coloring semidefinite programs	coloracion grafo;approximate algorithm;algorithm complexity;algorithm analysis;geometrie algorithmique;complejidad algoritmo;computational geometry;optimisation combinatoire;coloration graphe;complexite algorithme;geometria computacional;analyse algorithme;algorithme approximation;combinatorial optimization;semidefinite relaxation;analisis algoritmo;graph colouring;semidefinite program;optimizacion combinatoria	The essential part of the best known approximation algorithm for graph MAXCUT is approximately solving MAXCUT’s semidefinite relaxation. For a graph with n nodes and m edges, previous work on solving its semidefinite relaxation for MAXCUT requires space Õ(n). Under the assumption of exact arithmetic, we show how an approximate solution can be found in space O(m + n), where O(m) comes from the input; and therefore reduce the space required by the best known approximation algorithm for graph MAXCUT. Using the above space-efficient algorithm as a subroutine, we show an approximate solution for COLORING’s semidefinite relaxation can be found in space O(m)+ Õ(n). This reduces not only the space required by the best known approximation algorithm for graph COLORING, but also the space required by the only known polynomial-time algorithm for finding a maximum clique in a perfect graph.	approximation algorithm;clique (graph theory);graph coloring;linear programming relaxation;maximum cut;polynomial;relaxation (approximation);semidefinite programming;subroutine;successive over-relaxation;time complexity	Philip N. Klein;Hsueh-I Lu	1998		10.1007/3-540-49381-6_41	mathematical optimization;combinatorics;discrete mathematics;computational geometry;combinatorial optimization;mathematics;geometry	Theory	28.51755400988029	17.767248460534017	6095
39bc17ddf50b9337b8f6342cc50e4d37c7e7af8c	permutation problems and channelling constraints	variabilidad;programmation logique avec contrainte;satisfactoriabilidad;empirical study;primal dual method;programacion logica con restriccion;duality;methode primale duale;satisfiability;permutation;dualite;metodo primal dual;permutacion;constraint programming;dualidad;constraint logic programming;satisfaisabilite;variability;variabilite	When writing a constraint program, we have to decide what to m ake the decision variable, and how to represent the constraints on hese variables. In many cases, there is considerable choice for the decision va riables. For example, with permutation problems, we can choose between a primal an d a dual representation. In the dual representation, dual variables stand fo r the primal values, whilst dual values stand for the primal variables. By means of chann elli g constraints, a combined model can have both primal and dual variables. In t his paper, we perform an extensive theoretical and empirical study of the se different models. Our results will aid constraint programmers to choose a mode l for a permutation problem. They also illustrate a general methodology fo r comparing different	constraint logic programming;duality (optimization);local consistency;look-ahead (backtracking);pdf/a;problem domain;programmer;software propagation;while	Toby Walsh	2001		10.1007/3-540-45653-8_26	constraint logic programming;mathematical optimization;constraint programming;combinatorics;duality;computer science;constraint satisfaction dual problem;mathematics;permutation;programming language;empirical research;algorithm;satisfiability	AI	25.205370711561883	10.270466495098582	6096
4faab292ab16ab665abca8aa09a71e8d56116e77	an industrial-strength design flow in just fifteen easy weeks!	design process;design flow;vlsi design;integrated circuit design;pipelined binary multiplier vlsi design cad tool software package undergraduate education;electronic engineering education;software package;vlsi;circuit cad;electronic engineering education vlsi integrated circuit design circuit cad;very large scale integration design automation process design algorithm design and analysis education fabrication software packages graphics cmos process spice	Educators continue to face pressure from students and industry to employ the newest technology in the classroom. With regard to VLSI design and the role of CAD tools, a balance must be struck between fundamentals and training to a particular software package. This paper describes a semester project, suitable for an undergraduate VLSI course, which emphasized the design process, rather than individual tools. This process and the experiences associated with producing a pipelined, two's complement binary multiplier are presented.	binary multiplier;computer-aided design;design flow (eda);pipeline (computing);two's complement;very-large-scale integration	James F. Frenzel	1997		10.1109/MSE.1997.612544	design closure;physical design;embedded system;computer architecture;electronic engineering;electronic design automation;computer science;design flow;electrical engineering;circuit design;very-large-scale integration;computer engineering;integrated circuit design	EDA	9.997437948283205	52.62547957223118	6097
2243a1d942edc14059cac751330097d99828a04b	efficient switching window computation for cross-talk noise	verification;coupling;multiple solution;time window;iterative algorithm;clock schedule;static timing analysis	In this paper, we present an efficient method for computing switching windows in the presence of delay noise. In static timing analysis, delay noise has traditionally been modeled using a simple switch-factor based noise model and the computation of switching windows is performed using an iterative algorithm where timing window propagation and switch factor updates are computed repeatedly until convergence. It was shown that the worst-case number of iterations required for convergence is O(n), where n is the number of gates in the circuit, resulting in an overall run time of O(n2). It was also shown that the iterations converge to different solutions, depending on the initial assumptions, making it unclear which solution is correct. In this paper, we show that the iterative nature of the problem is due to the switching-factor noise model and the order in which events are evaluated. Based on superposition model, we propose a time-sort based algorithm to compute the impact of delay noise on timing windows. We prove that the proposed algorithm has a run time that is linear with the circuit size. Since the algorithm is non-iterative and does not require initial assumptions, it eliminates the multiple solution problem. We tested the algorithm on a number of designs and show that it achieves significant speedup over the iterative approach.	algorithm;benchmark (computing);best, worst and average case;complex event processing;computation;converge;crosstalk;iteration;microsoft windows;quantum superposition;run time (program lifecycle phase);software propagation;speedup;static timing analysis;worst-case complexity	Bhavana Thudi;David Blaauw	2002		10.1145/589411.589429	mathematical optimization;real-time computing;computer science;theoretical computer science	EDA	17.735864906737568	51.938409263004594	6125
afa298c5fcfd9be144ac8eaa7703abb3745db439	kolmogorov complexity and the garden of eden theorem		Suppose τ is a cellular automaton over an amenable group and a finite alphabet. Celebrated Garden of Eden theorem states, that pre-injectivity of τ is equivalent to non-existence of Garden of Eden configuration. In this paper we will prove, that imposing some mild restrictions , we could add another equivalent assertion: non-existence of Garden of Eden configuration is equivalent to preservation of asymptotic Kolmogorov complexity under the action of cellular automaton. It yields a characterisation of the cellular automata, which preserve the asymptotic Kolmogorov complexity.	assertion (software development);automata theory;cellular automaton;garden of eden (cellular automaton);kolmogorov complexity	Andrey Alpeev	2012	CoRR		reversible cellular automaton;combinatorics;discrete mathematics;mathematics;algorithm	Logic	38.85496817370825	27.387669722911383	6131
362f8e0ba6bdf30492d0a4a2fc9bfaf0fb3333f5	a class of $p$-ary cyclic codes and their weight enumerators		Let m, k be positive integers such that m gcd(m,k) ≥ 3, p be an odd prime and π be a primitive element of Fpm. Let h1(x) and h2(x) be the minimal polynomials of −π−1 and π pk+1 2 over Fp, respectively. In the case of odd m gcd(m,k) , when k is even, gcd(m,k) is odd or when k gcd(m,k) is odd, Zhou et al. in [25] obtained the weight distribution of a class of cyclic codes C over Fp with parity-check polynomial h1(x)h2(x). In this paper, we further investigate this class of cyclic codes C over Fp in the rest case of odd m gcd(m,k) and the case of even m gcd(m,k) . Moreover, we determine the weight distribution of cyclic codes C.	cyclic code;enumerator polynomial	Long Yu;Hongwei Liu	2016	Adv. in Math. of Comm.		combinatorics;discrete mathematics;mathematics;algebra	Theory	41.01779456104878	38.53896070299143	6134
1740baf8badf00239ae1cb7512c850db6e14d18a	variable neighborhood search with ejection chains for the antibandwidth problem	metaheuristics;vns;layout problems	In this paper, we address the optimization problem arising in some practical applications in which we want to maximize the minimum difference between the labels of adjacent elements. For example, in the context of location models, the elements can represent sensitive facilities or chemicals and their labels locations, and the objective is to locate (label) them in a way that avoids placing some of them too close together (since it can be risky). This optimization problem is referred to as the antibandwidth maximization problem (AMP) and, modeled in terms of graphs, consists of labeling the vertices with different integers or labels such that the minimum difference between the labels of adjacent vertices is maximized. This optimization problem is the dual of the well-known bandwidth problem and it is also known as the separation problem or directly as the dual bandwidth problem. In this paper, we first review the previous methods for the AMP and then propose a heuristic algorithm based on the variable neighborhood search methodology to obtain high quality solutions. One of our neighborhoods implements ejection chains which have been successfully applied in the context of tabu search. Our extensive experimentation with 236 previously reported M. Lozano Departamento de Ciencias de la Computación e Inteligencia Artificial, Universidad de Granada, Granada, Spain e-mail: lozano@decsai.ugr.es A. Duarte · F. Gortázar Departamento de Ciencias de la Computación, Universidad Rey Juan Carlos, Madrid, Spain e-mail: abraham.duarte@urjc.es F. Gortázar e-mail: francisco.gortazar@urjc.es R. Martí (B) Departamento de Estadística e Investigación Operativa, Universidad de Valencia, Valencia, Spain e-mail: rafael.marti@uv.es	algorithm;analysis of algorithms;code;computation;dev-c++;display resolution;email;entropy maximization;granada;graph bandwidth;heuristic (computer science);iteration;linear algebra;location-based service;mathematical optimization;maxima and minima;neighbourhood (graph theory);optimization problem;tabu search;ub-tree;undefined behavior;variable neighborhood search;whole earth 'lectronic link;window function	Manuel Lozano;Abraham Duarte;Francisco Gortázar;Rafael Martí	2012	J. Heuristics	10.1007/s10732-012-9213-7	mathematical optimization;combinatorics;computer science;machine learning;mathematics;metaheuristic	ML	22.029148866626812	7.595684921005974	6142
c16ca9c420bdc988cf7b0ef1f392ec1a1e9ff07d	polyhedral and algorithmic properties of quantified linear programs	multistage stochastic programming;right hand side;linear program;zero sum game	Quantified linear programs (QLPs) are linear programs with variables being either existentially or universally quantified. The integer variant is PSPACE-complete, and the problem is similar to games like chess, where an existential and a universal player have to play a two-person-zero-sum game. At the same time, a QLP with n variables is a variant of a linear program living in Rn, and it has strong similarities with multistage-stochastic programs with variable right-hand side. We show for the continuous case that the union of all winning policies of the existential player forms a polytope in Rn, that its vertices are games of so called extremal strategies, and that these vertices can be encoded with polynomially many bits. The latter allows the conclusion that solving a QLP is in PSPACE. The hardness of the problem stays unknown.	linear programming;polyhedral;system of linear equations	Ulf Lorenz;Alexander Martin;Jan Wolf	2010		10.1007/978-3-642-15775-2_44	mathematical optimization;combinatorics;discrete mathematics;formula game;linear programming;mathematics;geometry;zero-sum game;algorithm	Theory	6.243529535253439	17.38400926354046	6144
00a2d4895885dd4926203f002262c0e1e3a99337	the biweight enumerator of self-orthogonal binary codes		Abstract   Let  C  be a binary code of length  n  and let  J   C   ( a ,  b ,  c ,  d ) be its biweight enumerator. If  n  is even and  C  is self-dual, then  J   C   is an element of the ring  R    G    of absolute invariants of a certain group   G  . Under the additional assumption that all codewords of  C  have weight divisible by 4, a similar result holds with a different group. If  n  is odd and  C  is maximal self-orthogonal, then  J   C   is an element of a certain  R    G   -module. Again a similar result holds if the codewords of  C  have weights divisible by 4. The groups involved are related to finite groups generated by reflections. In this paper the structure of these groups is described, and polynomial bases for the rings and modules in question are obtained. This answers a question posed in  The Theory of Error- correcting Codes  by F.J. MacWilliams and N.J.A. Sloane.	binary code;enumerator polynomial	W. Cary Huffman	1979	Discrete Mathematics	10.1016/0012-365X(79)90119-5	enumerator polynomial;combinatorics;discrete mathematics;mathematics;algebra	Theory	40.65757363720497	52.53442238022041	6145
43e710052184789bf827da7edb610d9bd82723db	approximation algorithms for the transportation problem with market choice and related models	approximation algorithms;transportation problem with market choice;capacitated facility location	Given facilities with capacities and clients with penalties and demands, the transportation problem with market choice consists in finding the minimum-cost way to partition the clients into unserved clients, paying the penalties, and into served clients, paying the transportation cost to serve them. We give polynomial-time reductions from this problem and variants to the (un)capacitated facility location problem, directly yielding approximation algorithms, two with constant factors in the metric case, one with a logarithmic factor in the general case.	approximation algorithm;facility location problem;polynomial;polynomial-time reduction;time complexity;transportation theory (mathematics)	Karen Aardal;Pierre Le Bodic	2014	Oper. Res. Lett.	10.1016/j.orl.2014.09.008	mathematical optimization;mathematics;1-center problem;approximation algorithm	Theory	15.835133772070733	4.905063865774631	6161
b7dbbf3dc1edf13f6fc276507286f7f150ca2ec4	intricacies of simple word equations: an example	word equations;solutions of instances of pcp	The theory of word equations is fundamental for many areas of mathematics and computing. Despite of that, many fragments of this theory are quite poorly understood. In fact, the whole theory is full of amazingly simple open problems. After the discovery of the algorithmic undecidability, it was thought by A. Markov in late 1950's, that maybe word equations could be used to solve negatively Hilbert's 10th Problem, see [3]. This hope was motivated by at that time discovered undecidable word problems for semigroups. However, this turned out not to be the case: Hilbert's 10th Problem is undecidable, as shown by Matiyasevich [10], while	graph coloring;hilbert's tenth problem;markov chain;microsoft word for mac;undecidable problem	Elena Czeizler;Stepan Holub;Juhani Karhumäki;Markku Laine	2007	Int. J. Found. Comput. Sci.	10.1142/S0129054107005212	arithmetic;computer science;algorithm	Theory	-2.027123899492733	14.2758150835032	6162
d9f65716b21d1661e921c247c2bdf0a05817d62c	finding heaviest h-subgraphs in real weighted graphs, with applications	h subgraph;polynomial algorithm;matrix multiplication;weighted graph	For a graph <i>G</i> with real weights assigned to the vertices (edges), the MAX <i>H</i>-SUBGRAPH problem is to find an <i>H</i>-subgraph of <i>G</i> with maximum total weight, if one exists. Our main results are new strongly polynomial algorithms for the MAX <i>H</i>-SUBGRAPH problem. Some of our algorithms are based, in part, on fast matrix multiplication.  For vertex-weighted graphs with <i>n</i> vertices we solve a more general problem: the <i>all pairs</i> MAX <i>H</i>-SUBGRAPH problem, where the task is to find for every pair of vertices <i>u,v,</i> a maximum <i>H</i>-subgraph containing both <i>u</i> and <i>v</i>, if one exists. We obtain an <i>O</i>(<i>n</i><sup><i>t</i>(ω,<i>h</i>))</sup>-time algorithm for the <i>all pairs</i> MAX <i>H</i>-SUBGRAPH problem in the case where <i>H</i> is a fixed graph with <i>h</i> vertices and <i>ω</i> < 2.376 is the exponent of matrix multiplication. The value of <i>t</i>(ω,<i>h</i>) is determined by solving a small integer program. In particular, heaviest triangles for all pairs can be found in <i>O</i>(<i>n</i><sup>2+1/(4-ω)</sup>) ≤ <i>o</i>(<i>n</i><sup>2.616</sup>)-time. For <i>h</i>=4,5,8 the running time of our algorithm essentially matches that of the (unweighted) <i>H</i>-subgraph detection problem. Using rectangular matrix multiplication, the value of <i>t</i>(<i>ω,h</i>) can be improved; for example, the runtime for triangles becomes <i>O</i>(<i>n</i><sup>2.575</sup>).  We also present improved algorithms for the MAX <i>H</i>-SUBGRAPH problem in the edge-weighted case. In particular, we obtain an <i>O</i>(<i>m</i><sup>2−1/<i>k</i></sup> log <i>n</i>)-time algorithm for the heaviest cycle of length 2<i>k</i> or 2<i>k</i>−1 in a graph with <i>m</i> edges and an <i>O</i>(<i>n</i><sup>3</sup>/log <i>n</i>)-time randomized algorithm for finding the heaviest cycle of any fixed length.  Our methods also yield efficient algorithms for several related problems that are faster than any previously existing algorithms. For example, we show how to find chromatic <i>H</i>-subgraphs in edge-colored graphs, and how to compute the most significant bits of the distance product of two real matrices, in truly subcubic time.	graph (discrete mathematics);integer programming;matrix multiplication;max;most significant bit;polynomial;randomized algorithm;time complexity;vertex (geometry)	Virginia Vassilevska Williams;Ryan Williams;Raphael Yuster	2010	ACM Trans. Algorithms	10.1145/1798596.1798597	combinatorics;discrete mathematics;matrix multiplication;subgraph isomorphism problem;mathematics;induced subgraph isomorphism problem;algorithm	Theory	23.66790744018446	22.095368311237614	6163
876de679bf96a713fdf03b4182e1958965b9cfc9	on the steady state of continuous time stochastic opinion dynamics		The present paper proposes a computational framework for continuous time opinion dynamics with additive noise. We derive a non-local partial differential equation for the distribution of opinions differences. We use Mellin transforms to solve the stationary solution of this equation in closed form. This approach can be applied both to linear dynamics on an interaction graph and to bounded confidence dynamics in the Euclidean space. It leads to several new qualitative results proper to continuous time bounded confidence dynamics. To the best of our knowledge, the closed form expression on the stationary distribution of the bounded confidence model is the first quantitative result on the equilibria of this class of models. The solutions are presented here in the simplest possible cases and extensions in a large network.	additive white gaussian noise;stationary process;stationary state;steady state;utility functions on indivisible goods	Jae Oh Woo;François Baccelli;Sriram Vishwanath	2017	CoRR		mathematical analysis;steady state;euclidean space;stationary distribution;closed-form expression;quantitative result;mathematics;bounded function;partial differential equation;graph	ML	44.00952818802365	12.80965754984467	6166
882d9414e6996789bf1afb3b59a2fc2f15989b2a	space efficient algorithms for series-parallel graphs	algorithme rapide;graph theory;algoritmo paralelo;teoria grafo;reachability;parallel algorithm;algorithmique;time complexity;efficient algorithm;theorie graphe;path finding;algorithme parallele;series parallel graph;decision problem;algorithmics;algoritmica;asequibilidad;directed graph;fast algorithm;graphe oriente;space complexity;atteignabilite;grafo orientado;series parallel;algoritmo rapido	The subclass of directed series-parallel graphsplays an important role in computer science. To determine whether a graph is ser es-parallel is a well studied problem in algorithmic graph theory. Fast sequ ential and parallel algorithms for this problem have been developed in a sequenc e of papers. For series-parallel graphs methods are also known to solve the r eachability and the decomposition problem time efficiently. However, no dedica ted results have been obtained for the space complexity of these problems – the top ic of this paper. For this special class of graphs, we develop deterministic a lgorithms for the recognition, reachability, decomposition and thepath counting problemthat use only logarithmic space. Since for arbitrary directed graph s reachability and path counting are believed not to be solvable in log-space the mai n contribution of this work are novel deterministic path finding routines that work correctly in series-parallel graphs, and a characterization of seriesparallel graphs by forbidden subgraphs that can be tested space-efficiently. The spac bounds are best possible, i.e. the decision problems is shown to be L-complete with respect to AC0-reductions, and they have also implications for the parall el time complexity of series-parallel graphs. Finally, we sketch how these res ults can be generalised to extension of the series-parallel graph family: to graphs with multiple sources or multiple sinks and to the class of minimal vertex series-parallel graphs.	computer science;dspace;decision problem;directed graph;forbidden subgraph problem;graph theory;l (complexity);nl (complexity);parallel algorithm;path (graph theory);pathfinding;reachability;series and parallel circuits;series-parallel graph;time complexity	Andreas Jakoby;Maciej Liskiewicz;Rüdiger Reischuk	2001		10.1007/3-540-44693-1_30	1-planar graph;implicit graph;block graph;time complexity;pathwidth;mathematical optimization;split graph;combinatorics;series and parallel circuits;discrete mathematics;cograph;directed graph;graph product;longest path problem;computer science;pathfinding;graph theory;forbidden graph characterization;metric dimension;decision problem;trapezoid graph;mathematics;tree-depth;parallel algorithm;maximal independent set;modular decomposition;dspace;treewidth;partial k-tree;reachability;algorithmics;chordal graph;indifference graph;algorithm	Theory	19.82334911266443	27.519741309713933	6191
f9fe628f60bf57fef40caca097319e5314ecd269	"""review of """"automatic sequences: theory, applications, generalizations"""" by jean-paul allouche and jeffrey shallit. cambridge university press."""	jean-paul allouche;cambridge university press;jeffrey shallit;automatic sequence	[9] M. O. Rabin. Decidability of second-order theories and automata on infinite trees. Generalized finite automata with an application to a decision problem of second order logic.	automata theory;decision problem;finite-state machine;jean	Jean Berstel	2004	SIGACT News	10.1145/970831.970838	applied mathematics;computer science;cognitive science	Logic	-2.8155015788775097	22.14799903207895	6204
8c52ccf30629183a94dc5636be0c6928f11b6315	disjoint even cycles packing	even cycle;theta graph;satisfiability;vertex disjoint;minimum degree;disjoint paths	We generalize the well-known theorem of Corrádi and Hajnal which says that if a given graph G has at least 3k vertices and the minimum degree of G is at least 2k, then G contains k vertex-disjoint cycles. Our main result is the following; for any integer k, there is an absolute constant ck satisfying the following; let G be a graph with at least ck vertices such that the minimum degree of G is at least 2k. Then either (i) G contains k vertex-disjoint even cycles, or (ii) (2k − 1)K1+pK2⊆G⊆K2k−1+pK2 (p≥k≥ 2), or k=1 and each block in G is either a K2 or a odd cycle, especially, each endblock in G is a odd cycle. In fact, our proof implies the following; the “even cycles” in the conclusion (i) can be replaced by “theta graphs”, where a theta graph is a graph that has two vertices x, y such that there are three disjoint paths between x and y. Let us observe that if there is a theta graph, then there is an even cycle in it. Furthermore, if the conclusion (ii) holds, clearly there are no k vertex-disjoint even cycles (and hence no k vertex-disjoint theta graphs).	andrás hajnal;graph (discrete mathematics);set packing;theta graph;vertex (geometry);whole earth 'lectronic link	Shuya Chiba;Shinya Fujita;Ken-ichi Kawarabayashi;Tadashi Sakuma	2009	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2009.07.019	theta graph;combinatorics;discrete mathematics;topology;graph toughness;graph factorization;mathematics;k-vertex-connected graph;satisfiability	Theory	30.464405826707118	28.186267710673615	6217
42351cc861b7f8f0b52b9a4767d936af2c0872b9	an fpga implementation of a montgomery multiplier over gf(2^m)	montgomery s multiplication method;cosic;systolic array;fpga;finite field;fpga implementation;cryptography;elliptic curve cryptosystem;modular multiplication;elliptic curve cryptosystems	This paper describes an efficient FPGA implementation for modular multiplication in the finite field GF(2) that is suitable for implementing Elliptic Curve Cryptosystems. We have developed a systolic array implementation of a Montgomery modular multiplication. Our solution is efficient for large finite fields (m=160-193) that offer a high security level, and it can be scaled easily to larger values of m. The clock frequency of the implementation is independent of the field size. In contrast to earlier work, the design is not restricted to field representations using irreducible trinomials.	bit-length;clock rate;cryptosystem;field-programmable gate array;irreducibility;irreducible complexity;irreducible polynomial;lagrange multiplier;matrix multiplication;montgomery modular multiplication;operand;parameter (computer programming);pipeline (computing);systolic array;trinomial	Nele Mentens;Siddika Berna Ors Yalcin;Bart Preneel;Joos Vandewalle	2004	Computers and Artificial Intelligence		arithmetic;systolic array;computer science;cryptography;theoretical computer science;mathematics;elliptic curve point multiplication;finite field;algebra	EDA	9.501734316973625	44.11320401815843	6219
3d627cd9237f0fae7baa7ebf700294cc61e35449	on the design and analysis of quaternary serial and parallel adders	adders;circuit optimisation;logic design;binary logic system;full adder design;gate delays;logarithmic stage parallel adder;mathematical expressions;optimization techniques;parallel adder circuit;quaternary logic system;quaternary serial adder design;logarithmic stage adder;quaternary fast adder;quaternary full adder;ripple carry adder	Optimization techniques for decreasing the time and chip area of adder circuits have been thoroughly studied for years mostly in binary logic system. In this paper, we provide the necessary equations required to design a full adder in quaternary logic system. We provide the design of a logarithmic stage parallel adder which can compute the carries within log2(n) time delay for n qudits. At last, we compare the gate delays of full adder and logarithmic stage parallel adder with the help of mathematical expressions.	adder (electronics);broadcast delay;carry-lookahead adder;delay calculation;fan-in;parallel algorithm;propagation delay;ripple effect	Anindya Das;Ifat Jahangir;Masud Hasan	2010	TENCON 2010 - 2010 IEEE Region 10 Conference		embedded system;electronic engineering;parallel computing;computer science;serial binary adder;carry-save adder;algorithm;adder	EDA	16.072055057717538	45.57106829474	6241
547518f750d7df496ac8157e3a6264089d799fc3	on fuzzy subnets	topology;fuzzy net;convergence;topological space;fuzzy set;topologia difusa;fuzzy filters;fuzzy filter;fuzzy topology;theoreme convergence moore smith;subnets;topologie floue;conjunto difuso;ensemble flou;topologia;sous reseau;convergencia;filter;moore smith convergence theorem;filtre flou;reseau flou;fuzzy nets;filtre;subnet;filtro	Abstract   In General Topology, there is a close paralellism between the theories of convergence of nets and of filters, in which “subnet” corresponds to “finer filter”, but this relationship depends on the notion of subnet that one uses. Various authors have defined, for fuzzy topological spaces, the convergence of fuzzy filters and fuzzy nets, and have obtained connections between these theories; however these authors do not obtain a satisfactory relation between a fuzzy net and the fuzzy net based on the prefilter generated by it. In this paper we define for fuzzy nets a new notion of fuzzy subnet, that solves this question.	fuzzy concept;subnetwork	Francisco Gallego Lupiáñez	2001	Fuzzy Sets and Systems	10.1016/S0165-0114(99)00085-8	fuzzy logic;discrete mathematics;topology;convergence;membership function;defuzzification;subnet;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;filter;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy subalgebra;fuzzy number;neuro-fuzzy;fuzzy measure theory;mathematics;fuzzy set;topological space;fuzzy associative matrix;fuzzy set operations	Robotics	44.23872015299905	23.558151942141635	6245
02514ff22c82354b0ebb065dcb604c016e67a15e	audit: stress testing the automatic way	voltage droop;stress analysis audit capabilities stress testing power supply voltage droops timing errors microprocessors test programs integer linear programming genetic algorithms single core systems cycle level simulators single core stress mark generation tool automated di dt stress mark generation framework microarchitectural changes dithering algorithm thread alignment issues multicore processors audit generated stress marks multithreaded multicore systems out of order pipelines;hardware measurement;inductive noise;low power;di dt;genetic algorithm;stress analysis integrated circuit testing microprocessor chips multiprocessing systems;stressmark generation;hardware measurement di dt inductive noise stressmark generation voltage droop power distribution network low power genetic algorithm;power distribution network	Sudden variations in current (large di/dt) can lead to significant power supply voltage droops and timing errors in modern microprocessors. Several papers discuss the complexity involved with developing test programs, also known as stress marks, to stress the system. Authors of these papers produced tools and methodologies to generate stress marks automatically using techniques such as integer linear programming or genetic algorithms. However, nearly all of the previous work took place in the context of single-core systems, and results were collected and analyzed using cycle-level simulators. In this paper, we measure and analyze di/dt issues on state-of-the-art multi-core x86 systems using real hardware rather than simulators. We build on an existing single-core stress mark generation tool to develop an Automated DI/dT stress mark generation framework, referred to as AUDIT, to generate di/dt stress marks quickly and effectively for multicore systems. We showcase AUDIT's capabilities to adjust to micro architectural and architectural changes. We also present a dithering algorithm to address thread alignment issues on multi-core processors. We compare standard benchmarks, existing di/dt stress marks, and AUDIT-generated stress marks executing on multi-threaded, multi-core systems with complex out-of-order pipelines. Finally, we show how stress analysis using simulators may lead to flawed insights about di/dt issues.	benchmark (computing);central processing unit;dither;genetic algorithm;integer programming;linear programming;microprocessor;multi-core processor;pipeline (computing);power supply;simulation;single-core;stress testing;stress–strain analysis;thread (computing);x86	Youngtaek Kim;Lizy Kurian John;Sanjay Pant;Srilatha Manne;Michael J. Schulte;William Lloyd Bircher;Madhu Saravana Sibi Govindan	2012	2012 45th Annual IEEE/ACM International Symposium on Microarchitecture	10.1109/MICRO.2012.28	embedded system;parallel computing;real-time computing;genetic algorithm;voltage droop;computer science;operating system;programming language	Arch	19.878681147090763	57.001796761079305	6246
19e144a08c0205bb44fb0cbf6142238a9a089efe	planar graphs are 9/2-colorable		We show that every planar graph G has a 2-fold 9-coloring. In particular, this implies that G has fractional chromatic number at most 92 . This is the first proof (independent of the 4 Color Theorem) that there exists a constant k < 5 such that every planar G has fractional chromatic number at most k.	four color theorem;fractional coloring;graph coloring;planar graph	Daniel W. Cranston;Landon Rabern	2018	J. Comb. Theory, Ser. B	10.1016/j.jctb.2018.04.002	combinatorics;discrete mathematics;topology;mathematics	Theory	30.504971102984822	28.870187992322	6256
8ba03bd6ea6921e5fc8a0a583ec00131440613ab	approximate input sensitive algorithms for point pattern matching	distance function;transformation group;metric;similitude;approximation;algorithme;algorithm;aleatorizacion;similarity transformation;general methods;grupo transformacion;pattern matching;similarity;pattern recognition;randomisation;hausdorff distance;metrico;approximate matching;hausdorff metric;concordance forme;reconnaissance forme;similitud;reconocimiento patron;randomization;groupe transformation;metrique;point pattern matching;geometric pattern matching;algoritmo	We study input sensitive algorithms for point pattern matching under various transformations and the Hausdorff metric as a distance function. Given point sets P and Q in the plane, the problem of point pattern matching is to determine whether P is similar to some portion of Q, where P may undergo transformations from a group G of allowed transformations. All algorithms are based on methods for extracting small subsets from Q that can be matched to a small subset of P. The runtime is proportional to the number k of these subsets. Let d be the number of points in P that are needed to define a transformation in G. The key observation is that for some set B@?P of cardinality larger than d, the number of subsets of Q of this cardinality that match B, is practically small, as the problem becomes more constrained. We present methods to extract efficiently all these subsets in Q. We provide algorithms for homothetic, rigid and similarity transformations in the plane and give a general method that works for any dimension and for any group of transformations. The runtime of our algorithms depends roughly linearly on the number of subsets k, in addition to an nlogn factor. Thus our approximate matching algorithms run roughly in time O(nlogn+kmlogn), where m and n are the number of points in P and Q, respectively. The constants hidden in the big O vary depending on the group of transformations G.	algorithm;pattern matching	Dror Aiger;Klara Kedem	2010	Pattern Recognition	10.1016/j.patcog.2009.05.014	hausdorff distance;combinatorics;discrete mathematics;topology;metric;mathematics;algorithm;statistics	AI	29.953933089888192	18.211668437596547	6257
ae04dc306b42b3cde0ea2b4ed3f3a21908aee0ec	p3-equicoverable graphs - research on h-equicoverable graphs	optimisation;h;combinatorics;subgrafo;optimizacion;combinatoria;h coverable;combinatoire;recherche;probleme recouvrement;problema recubrimiento;sous graphe;informatique theorique;68r10;characterization;optimization;caracterisation;covering problem;subgraph;h covering;investigacion;05b40;caracterizacion;h equicoverable;computer theory;informatica teorica	"""Let H be a fixed graph. An H-covering of G is a set L={H""""1,H""""2,...,H""""k} of subgraphs of G, where each subgraph H""""i is isomorphic to H and every edge of G appears in at least one member of L. If there exists an H-covering of G, G is called H-coverable. An H-covering of G with k copies H""""1,H""""2,...,H""""k of H is called minimal if, for any H""""j, @?""""i""""=""""1^kH""""i-H""""j is not an H-covering of G. An H-covering of G with k copies H""""1,H""""2,...,H""""k of H is called minimum if there exists no H-covering with less than k copies of H. A graph G is called H-equicoverable if every minimal H-covering in G is also a minimum H-covering in G. In this paper, we investigate the characterization of P""""3-equicoverable graphs."""		Yuqin Zhang	2008	Discrete Applied Mathematics	10.1016/j.dam.2007.08.020	arithmetic;haplogroup h;combinatorics;mathematics;subgroup	Theory	24.479068732096803	30.09234482062028	6268
055209ea53e54f0ca41a083724561178ad721c12	refined dual stable grothendieck polynomials and generalized bender-knuth involutions	dual stable grothendieck polynomials;bender knuth involutions;schur functions;young tableaux;reverse plane partitions;symmetric functions;plane partitions	The dual stable Grothendieck polynomials are a deformation of the Schur functions, originating in the study of the K-theory of the Grassmannian. We generalize these polynomials by introducing a countable family of additional parameters, and we prove that this generalization still defines symmetric functions. For this fact, we give two self-contained proofs, one of which constructs a family of involutions on the set of reverse plane partitions generalizing the Bender-Knuth involutions on semistandard tableaux, whereas the other classifies the structure of reverse plane partitions with entries 1 and 2.	method of analytic tableaux;polynomial ring	Pavel Galashin;Darij Grinberg;Gaku Liu	2016	Electr. J. Comb.		young tableau;combinatorics;discrete mathematics;schur polynomial;mathematics;symmetric function;algebra	Theory	41.808433158258445	31.61562131904095	6274
062b43c4d78bc8e6d8dd256b9086a055fa2c25ad	intelligent radiant floor heating regulation system with wireless sensors		Thermal comfort of person living in building with radiant floor heating is not usually perfect. There is usually absence of control system based on each single room. This work proposes a simple, promising, effective and cost-effective regulation system for radiant floor heating. Designed system is based on small wireless sensors placed in every room to measure the temperature and wirelessly send it to the cloud. The data is analyzed and compared with user selected values and appropriate actions are taken by wireless relay unit that controls flow through each heating circuit by thermoelectric actuators. Main benefits of this system is Internet of Things (IoT) solution, which means that all the computing is made in the cloud. Used sensors and relay board can be relatively cheap due to low demands on its computing power. There is not any expensive main unit with display and user interface, because this system can be controlled via cloud from any kind of device (such as notebook, tablet, smart phone etc.). Prototype have been tested in a normal environment for its basic functions, but more data needs to be measured for final verification.	cloud computing;control system;internet of things;prototype;radiant ai;relay;sensor;smartphone;tablet computer;user interface;wireless router	Michal Kerndl;Pavel Steffan	2017	2017 40th International Conference on Telecommunications and Signal Processing (TSP)	10.1109/TSP.2017.8075936	actuator;real-time computing;wireless;wireless sensor network;cloud computing;computer science;relay;user interface;control system;thermal comfort	Mobile	1.5667698955232978	32.013684020883595	6298
d18a0ee62f60ae23d7d31e52225cecbdefe085a2	high-level customization framework for application-specific noc architectures	network on chip;regular and irregular topologies;automation framework;buffer sizing;mapping;priorities assignment;design methodology	Network-on-Chip (NoC) has been recognized as the new paradigm to interconnect and organize a high number of cores. NoCs address global communication issues in System-on-Chips (SoC) involving communication-centric design and implementation of scalable communication structures evolving application-specific NoC design as a key challenge to modern SoC design. In this paper we present a SystemC customization framework and methodology for automatic design and evaluation of regular and irregular NoC architectures. The presented framework also supports application-specific optimization techniques such as priority assignment, node clustering and buffer sizing. Experimental results show that generated regular NoC architectures achieve an average of 5.5 % lower communication-cost compared to other regular NoC designs while irregular NoCs proved to achieve on average 4.5×higher throughput and 40 % network delay reduction compared to regular mesh topologies. In addition, employing a buffer sizing algorithm we achieve a reduction in network's power consumption by an average of 45 % for both regular and irregular NoC design flow.	network on a chip	Iraklis Anagnostopoulos;Alexandros Bartzas;Iasonas Filippopoulos;Dimitrios Soudris	2012	Design Autom. for Emb. Sys.	10.1007/s10617-013-9114-5	embedded system;computer architecture;parallel computing;real-time computing;design methods;computer science;network on a chip	EDA	2.3404965123408004	60.171334355833814	6303
47704281a8346e35b41f4f618269815627d5222f	locating pairs of vertices on hamiltonian cycles	hamiltonian cycle;degree condition	Given a fixed positive integer   k≥2     k  ≥  2        and a fixed pair of vertices   x     x        and   y     y        in a graph of sufficiently large order   n=n(k)     n  =  n   (  k  )        , minimum degree conditions that imply the existence of a Hamiltonian cycle   C     C        such that the distance on the cycle   C     C        between   x     x        and   y     y        is precisely   k     k        will be proved.	hamiltonian (quantum mechanics);vertex (geometry)	Ralph J. Faudree;Hao Li	2012	Discrete Mathematics	10.1016/j.disc.2012.02.006	hamiltonian path;combinatorics;discrete mathematics;topology;mathematics	Theory	30.967192787505866	29.5591133960889	6312
78d5cf48fbbb3d24f2683cf65f9bf40570a1bae2	the erdös-sós conjecture for graphs withoutc4		Erdo?s and Sos conjectured in 1963 that ifGis a graph of ordernand sizee(G) withe(G)>12n(k?1), thenGcontains every treeTof sizek. We prove the conjecture in the case whereGdoes not contain the cycleC4.		Jean-François Saclé;Mariusz Wozniak	1997	J. Comb. Theory, Ser. B	10.1006/jctb.1997.1758	lonely runner conjecture;combinatorics;discrete mathematics;mathematics;algebra	Theory	32.47287623419002	33.221631490106326	6314
c0056c412f8b3fe473ccbe1eafa2774be6a85c93	minimum cuts, girth and a spectral threshold	spectre laplace;procesamiento informacion;coupe minimum;laplacian spectrum;coupe graphe;minimum cuts;laplacian matrix;connected graph;corte grafo;informatique theorique;graph cut;information processing;girth;graph algorithm;a priori information;minimun cut;algorithme graphe;traitement information;graph algorithms;graphe connexe;minimum degree;minimum cut;computer theory;grafo conexo;informatica teorica	Let G = (V, E) be a simple, undirected, unweighted, connected graph. A cut (A, A) defined by a subset A of V is called trivial if either A or A is a singleton set. Let µ be the second smallest eigenvalue of the Laplacian matrix of G. The length of the shortest cycle in the graph is called the girth g of the graph. Let the minimum degree of the graph be δ ≥ 3. We show that if µ is greater than a threshold, namely 8δ/((δ - 1)⌊(g-1)/2⌋ - 2), then every minimum cut in G is trivial. The proof is based on the observation that in graphs of large girth and minimum degree δ ≥ 3, there exists a dichotomy of minimum cuts: Either the minimum cut is trivial or there must be a lot of vertices (Ω ((δ - 1)⌊(g-1)/2⌋)) on both sides of the cut. We illustrate that, for large enough values of g, the value obtained by us for this threshold is of the correct order by constructing a graph with girth at least g and minimum degree δ and µ = Ω (g-1 (δ - 1)-⌊(g-1)/2⌋), but possessing a nontrivial minimum cut, assuming that a well-known conjecture about the existence of certain high girth graphs is true. Our results in this paper have the obvious algorithmic implication that when we have the a priori information that the value of µ for the given graph is greater than the threshold suggested by our theorems, the algorithmic problems of finding a minimum cut or enumerating all the minimum cuts in the graph becomes trivial.	girth (graph theory)	L. Sunil Chandran	2004	Inf. Process. Lett.	10.1016/j.ipl.2003.10.009	graph power;k-edge-connected graph;maximum cut;combinatorics;discrete mathematics;topology;minimum cut;cut;laplacian matrix;information processing;degree;connectivity;mathematics;cage	DB	24.48316327269591	31.002474321621953	6321
13712db3722f7728f91a5edc30c55fb033403bba	a linear construction for certain kerdock and preparata codes	information theory;hamming code;second order;hamming weight;linear code;cyclic code;reed muller code	The Nordstrom-Robinson, Kerdock and (slightly modified) Preparata codes are shown to be linear over 4, the integers mod 4. The Kerdock and Preparata codes are duals over 4, and the Nordstrom-Robinson code is self-dual. All these codes are just extended cyclic codes over 4. This provides a simple definition for these codes, and explains why their Hamming weight distributions are dual to each other. Firstand second-order Reed-Muller codes are also linear codes over 4, but Hamming codes in general are not, nor is the Golay code. A different version of this paper appeared in: Bulletin Amer. Math. Soc., 29 (1993), 218–222. It is also DIMACS Technical Report 93–50, August 1993. A Linear Construction for Certain Kerdock and Preparata Codes A. R. Calderbank Mathematical Sciences Research Center AT&T Bell Laboratories, Murray Hill, NJ 07974 U.S.A. A. R. Hammons, Jr. Hughes Aircraft Company 8433 Fallbrook Avenue, Canoga Park, CA 91304 U.S.A. P. Vijay Kumar Communication Science Institute, EE-Systems University of Southern California, Los Angeles, CA 90089 U.S.A. N. J. A. Sloane Mathematical Sciences Research Center AT&T Bell Laboratories, Murray Hill, NJ 07974 U.S.A. Patrick Solé CNRS – I3S, 250 rue A. Einstein, bâtiment 4 Sophia – Antipolis, 06560 Valbonne, France	binary golay code;cyclic code;hamming code;hamming weight;preparata code;reed–muller code	A. Robert Calderbank;A. Roger Hammons;P. Vijay Kumar;N. J. A. Sloane;Patrick Solé	1993	CoRR		block code;arithmetic;reed–muller code;polynomial code;concatenated error correction code;hamming weight;combinatorics;discrete mathematics;constant-weight code;hamming distance;low-density parity-check code;information theory;hamming bound;cyclic code;linear code;hamming code;mathematics;ternary golay code;hamming(7,4);raptor code;group code;second-order logic;reed–solomon error correction;statistics	Theory	43.12914710010295	55.529475454755435	6326
4c4c565994b9c951d4bd46de74d0aece6e42817f	a weakly universal cellular automaton on the grid {8, 3} with two states		In this chapter we present a result which improves a previous one established by the author. Here we prove that it is possible to construct a weakly universal cellular automaton on the tessellation ({8,3}) with two states only. Note that the cellular automaton lives in the hyperbolic plane, that the proof yields an explicit construction and that the constructed automaton is not rotationally invariant.	cellular automaton	Maurice Margenstern	2018		10.1007/978-3-319-73216-9_5	discrete mathematics;grid;tessellation;cellular automaton;hyperbolic geometry;invariant (mathematics);mathematics	Logic	43.538660297908564	29.730369044981906	6336
739783936d52c6e2338effaf4a6f3a96ac45d309	a comprehensive and robust procedure for obtaining the nofit polygon using minkowski sums	bin packing problem;modele geometrique;algorithmique;hd28 management industrial management;manufacturing process;metrique minkowski;polygone;packing;geometric algorithms;problema relleno;metrico minkowski;cutting stock problem;production process;nesting;polygon;configuration space;probleme decoupe;algorithmics;algoritmica;procedimiento fabricacion;processus fabrication;trigonometrie;poligono;probleme remplissage;geometric algorithm;cutting and packing;problema troquelado;minkowski metric;h social sciences general;trigonometry;minkowski sum;procede fabrication;trigonometria;garnissage;proceso fabricacion;geometrical model;relleno;modelo geometrico	The nofit polygon an important tool in the area of irregular shape stock cutting problems. It provides efficient handling of the geometric characteristics of the problem. The paper presents a new algorithmic procedure for deriving this tool. Abstract The nofit polygon is a powerful and effective tool for handling the geometric requirements of solution approaches to irregular cutting and packing problems. Although the concept was first described in 1966, it was not until the early 90s that the general trend of research moved away from direct trigonometry to favour the nofit polygon. Since then, the ability to calculate the nofit polygon has practically become a prerequisite for researching irregular packing problems. However, realisation of this concept in the form of a robust algorithm is a highly challenging task with few instructive approaches published. In this paper, a procedure using the mathematical concept of Minkowski sums for the calculation of the nofit polygon is presented. The described procedure is more robust than other approaches using Minkowski Sum knowledge and includes details of the removal of internal edges to find holes, slits and lock and key positions. The procedure is tested on benchmark data sets and gives examples of complicated cases. In addition the paper includes a description of how the procedure is modified in order to realise the inner-fit polygon.	algorithm;benchmark (computing);computation;electron hole;minkowski addition;requirement;set packing	Julia A. Bennell;Xiang Song	2008	Computers & OR	10.1016/j.cor.2006.02.026	mathematical optimization;combinatorics;trigonometry;polygon;mathematics;geometry;algorithmics	Graphics	29.64019206004314	15.549320071798494	6356
f2a356d65fbe2a0967b9094df7de8b3fc2ede855	the increase of the instability of networks due to quasi-static link capacities	adversarial quasi static queuing theory;file attente;dynamic change;numerical stability;resolution;network stability;nombre entier;protocolo red;network protocol;subgrafo;03cxx;dynamique;composition;composicion;longest in system;estabilidad numerica;queueing theory;nudo;queue;theorie modeles;packet switched;reseau;red;dinamica;instability;integer;stabilite reseau;dynamics;sous graphe;informatique theorique;entero;contention resolution;68r10;instabilite;vinculo;stabilite numerique;greedy protocols;noeud;68m12;protocole reseau;inestabilidad;subgraph;adversarial queuing theory;link;teoria modelos;fila espera;node;lien;network;computer theory;model theory;informatica teorica	In this work, we study the impact of the dynamic changing of the network link capacities on the stability properties of packet-switched networks. Especially, we consider the Adversarial, Quasi-Static Queueing Theory model, where each link capacity may take on only two possible (integer) values, namely 1 and C > 1 under a (w, ρ)-adversary. We show that allowing the dynamic changing of the link capacities of a network with just ten nodes that uses the LIS (Longest-in-System) protocol for contention-resolution results in instability at rates ρ > √ 2− 1 for large enough values of C. The combination of dynamically changing link capacities with compositions of contention-resolution protocols on network queues suffices to drop the instability bound of a network to a substantially low value. We show that the composition of LIS with any of SIS (Shortest-in-System), NTS (Nearest-to-Source) and FTG (Furthest-to-Go) protocols is unstable at rates ρ > √ 2−1 for large enough values of C. We prove that the instability bound of the network subgraphs that are forbidden for stability is affected by the dynamic changing of the link capacities presenting improved instability bounds for all the directed subgraphs that are known to be forbidden for stability on networks running a certain greedy protocol.	control theory;greedy algorithm;instability;network packet;null-terminated string;packet switching;queueing theory	Dimitrios Koukopoulos;Marios Mavronicolas;Paul G. Spirakis	2007	Theor. Comput. Sci.	10.1016/j.tcs.2007.04.008	integer;composition;dynamics;combinatorics;resolution;link;telecommunications;lien;computer science;mathematics;node;queueing theory;queue;numerical stability;algorithm;instability;model theory;algebra	Theory	22.66254841777708	32.47218317362578	6370
4155b9d3e3012c9ebd00e4c85e098f81cf47a481	average widths of wrhomega in c(r)	average width	average width		Gensun Fang	1995	J. Complexity	10.1006/jcom.1995.1024	mathematical optimization;combinatorics;calculus	Theory	32.48314689160599	34.89171075256009	6383
035187cee76d5007db43c5f7d0ef26f475682753	a new kkm theorem in l-convex spaces and some applications	fixed point theorem;maximal element;existence theorem;fixed point;equilibrium;kkm theorem;l convex space	In this paper, a new KKM theorem is established in L-convex spaces. As applications, a Ky Fan matching theorem for compactly open covers, a Fan-Browder coincidence theorem, a Fan-Browder fixed point theorem and a maximal element theorem are obtained in L-convex spaces. These theorems unify, improve and generalize some recent results in the references therein. Finally, the equilibrium existence theorems for abstract economies and qualitative games in L-convex spaces are yielded.		Kai Ting Wen	2008	Computers & Mathematics with Applications	10.1016/j.camwa.2008.07.014	mean value theorem;maximal element;closed graph theorem;carlson's theorem;mathematical analysis;discrete mathematics;brouwer fixed-point theorem;kakutani fixed-point theorem;arzelà–ascoli theorem;topology;schauder fixed point theorem;factor theorem;danskin's theorem;kelvin–stokes theorem;fundamental theorem;mathematics;fixed point;riesz–thorin theorem;bruck–ryser–chowla theorem;picard–lindelöf theorem;open mapping theorem;fixed-point theorem;compactness theorem;compact space;fréchet space	Crypto	45.706283643404845	24.324712282277748	6393
104124cd41dd898b1636913b4c5dd7168917ea6c	work-in-progress: heterogeneous redundancy to address performance and cost in multi-core simt		As manufacturing processes scale to smaller feature sizes and processors become more complex, it is becoming challenging to have fabricated devices that operate according to their specification in the first place: yield losses are mounting [3].	central processing unit;multi-core processor;single instruction, multiple threads	M. Naghashi;Sayyed Hasan Mozafari;Shaahin Hessabi	2017	2017 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)	10.1145/3125502.3125547	work in process;parallel computing;redundancy (engineering);real-time computing;computer science;multi-core processor;benchmark (computing)	EDA	-1.5952389254883759	50.32820348989466	6402
023c8c410c2d9b636f4e0b3d53e32da73c8e66b7	maximal paths on rectangular boards	maximal path;adjacent edge;combinatorial approach;n square;certain property;unique path;maximum number;rectangular board;path length;m n	A combinatorial approach is made to the problem of obtaining a path on a rectangular board of m by n squares with both terminals at the edges of the board. A square is said to be covered when the path enters one edge and leaves an adjacent edge. All other squares are said to be missed. Maximal paths are found, i.e., those which cover a maximum number of squares. For m = n, m - 2 squares are missed when m is even, and m - 1 squares are missed when m is odd. For m u003c n, m - 2 squares are missed if m is even, and n - 2 squares are missed if m is odd. The method of proof for m and n even is quite different from that for m or n odd. Certain properties of terminal positions, path length, types of missed squares, and unique paths are also investigated. The dependence of the results on the parity of m and n is again very striking.	maximal set	Raymond E. Miller;John L. Selfridge	1960	IBM Journal of Research and Development	10.1147/rd.45.0479	mathematical optimization;combinatorics;mathematics;geometry	Robotics	31.62960073704249	25.816539737041584	6403
95faa1e052251e8002ed6aa2c034b1aa6ec1ea32	soft-error-tolerant dual-modular-redundancy architecture with repair and retry scheme for memory-control circuit on fpga			dual modular redundancy;field-programmable gate array;retry	Makoto Saen;Tadanobu Toba;Yusuke Kanno	2017	IEICE Transactions		embedded system;parallel computing;real-time computing;computer science;memory controller;field-programmable gate array	EDA	8.066845580902122	58.56156007353645	6404
60fbb1494dd3bb728a22f9b933e33a60835e24c9	tunable cmos delay gate with improved matching properties	size 90 nm time based asynchronous computation systems particle detection delay locked loops readout circuits power consumption tdcs time to digital converters delay lines delay time variability mos transistor mismatch osi gates osi circuit output split inverter current limiting transistor csi current starved inverter improved matching properties tunable cmos delay gate;delays logic gates transistors open systems discharges electric capacitance limiting;mosfet circuits cmos logic circuits current limiters delay lines logic gates;fabrication mismatch cmos current starved inverter delay line	This paper presents the analysis and design of a tunable CMOS delay gate with improved matching properties as compared with the commonly used “current starved inverter” (CSI). The main difference between these structures lies in the location of the current limiting transistor on the inverter's output rather than on the side of the power rail. This improves the dynamic performance of the proposed “output split inverter” (OSI) circuit reducing the influence of the MOS transistor mismatch on the generated delay time variability. A test chip including two arrays consisting of 512 16-stage delay lines employing the CSI and OSI gates has been designed and fabricated in a standard 90 nm CMOS technology. The experimental results show that the proposed OSI circuit is about 10-50% more accurate than the conventional current starved inverter with no penalty in terms of the increased area, power consumption or complexity. Applications of the proposed circuit are in the design of time-to-digital converters (TDCs), delay locked loops, readout circuits for particle detection and time-based asynchronous computation systems.	analog-to-digital converter;cmos;computation;current limiting;heart rate variability;osi model;power inverter;power supply unit (computer);simulation;spatial variability;time-to-digital converter;transistor	Przemyslaw Mroszczyk;Piotr Dudek	2014	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2014.2312491	electronic engineering;real-time computing;delay calculation;engineering;electrical engineering;fo4;pass transistor logic;inverter;delay line oscillator	EDA	20.089523187202644	60.07139058034526	6410
bb441bb6b87268895c84247a238acf929f73d49b	easy to win, hard to master: optimal strategies in parity games with costs		The winning condition of a parity game with costs requires an arbitrary, but fixed bound on the distance between occurrences of odd colors and the next occurrence of a larger even one. Such games quantitatively extend parity games while retaining most of their attractive properties, i.e, determining the winner is in NP and co-NP and one player has positional winning strategies. We show that the characteristics of parity games with costs are vastly different when asking for strategies realizing the minimal such bound: The solution problem becomes PSPACE-complete and exponential memory is both necessary in general and always sufficient. Thus, solving and playing parity games with costs optimally is harder than just winning them. Moreover, we show that the tradeoff between the memory size and the realized bound is gradual in general. All these results hold true for both a unary and binary encoding of costs. Moreover, we investigate Streett games with costs. Here, playing optimally is as hard as winning, both in terms of complexity and memory.	binary file;co-np;color;np (complexity);pspace;pspace-complete;time complexity;unary operation;ω-automaton	Alexander Weinert;Martin Zimmermann	2017	Logical Methods in Computer Science	10.23638/LMCS-13(3:29)2017	simulation;computer science;mathematics;mathematical economics	Theory	12.980792176561305	18.532018559952952	6416
0a0341a58b21d3cf5933513ca56b70c9211697c6	extensions of infinite partition regular systems	ramsey theory;image partition regular	A finite or infinite matrixA with rational entries (and only finitely many non-zero entries in each row) is called image partition regular if, whenever the natural numbers are finitely coloured, there is a vector x, with entries in the natural numbers, such that Ax is monochromatic. Many of the classical results of Ramsey theory are naturally stated in terms of image partition regularity. Our aim in this paper is to investigate maximality questions for image partition regular matrices. When is it possible to add rows on to A and remain image partition regular? When can one add rows but ‘nothing new is produced’? What about adding rows and also new variables? We prove some results about extensions of the most interesting infinite systems, and make several conjectures. Our most surprising positive result is a compatibility result for Milliken-Taylor systems, stating that (in many cases) one may adjoin one Milliken-Taylor system to a translate of another and remain image partition regular. This is in contrast to earlier results, which had suggested a strong inconsistency between different Milliken-Taylor systems. Our main tools for this are some algebraic properties of βN, the Stone-Čech compactification of the natural numbers.	linear algebra;monochrome;szemerédi regularity lemma	Neil Hindman;Imre Leader;Dona Strauss	2015	Electr. J. Comb.		rank of a partition;combinatorics;discrete mathematics;ramsey theory;mathematics;algebra;partition regularity	Theory	38.12367077666799	32.5804903964245	6424
fff39f5080a8077ce9506c3a97980b77f9482f6e	variable-version lovász local lemma: beyond shearer's bound		A tight criterion under which the abstract version Lov&#xe1;sz Local Lemma (abstract-LLL) holds was given by Shearer [41] decades ago. However, little is known about that of the variable version LLL (variable-LLL) where events are generated by independent random variables, though variable- LLL naturally models and is enough for almost all applications of LLL. We introduce a necessary and sufficient criterion for variable-LLL, in terms of the probabilities of the events and the event-variable graph specifying the dependency among the events. Based on this new criterion, we obtain boundaries for two families of event-variable graphs, namely, cyclic and treelike bigraphs. These are the first two non-trivial cases where the variable-LLL boundary is fully determined. As a byproduct, we also provide a universal constructive method to find a set of events whose union has the maximum probability, given the probability vector and the event-variable graph.Though it is #P-hard in general to determine variable- LLL boundaries, we can to some extent decide whether a gap exists between a variable-LLL boundary and the corresponding abstract-LLL boundary. In particular, we show that the gap existence can be decided without solving Shearer&#x2019;s conditions or checking our variable-LLL criterion. Equipped with this powerful theorem, we show that there is no gap if the base graph of the event-variable graph is a tree, while gap appears if the base graph has an induced cycle of length at least 4. The problem is almost completely solved except when the base graph has only 3-cliques, in which case we also get partial solutions.A set of reduction rules are established that facilitate to infer gap existence of a event-variable graph from known ones. As an application, various event-variable graphs, in particular combinatorial ones, are shown to be gapful/gapless.	bigraph;cycle (graph theory);eisenstein's criterion;induced path;lenstra–lenstra–lovász lattice basis reduction algorithm;p (complexity);sharp-p	Kun He;Liang Li;Xingwu Liu;Yuyi Wang;Mingji Xia	2017	2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS)	10.1109/FOCS.2017.48	random regular graph;discrete mathematics;combinatorics;lovász local lemma;forbidden graph characterization;mathematics;approximation algorithm;line graph;complement graph;random variable;cubic graph	Theory	27.012663513909274	24.87149189229593	6464
e69684735571e74d81b35b9f4d9bf7867c465d81	forensic data carving	computer network;digital media	File or data carving is a term used in the field of Cyber forensics. Cyber forensics is the process of acquisition, authentication, analysis and documentation of evidence extracted from and/or contained in a computer system, computer network and digital media. Extracting data (file) out of undifferentiated blocks (raw data) is called as carving. Identifying and recovering files based on analysis of file formats is known as file carving. In Cyber Forensics, carving is a helpful technique in finding hidden or deleted files from digital media. A file can be hidden in areas like lost clusters, unallocated clusters and slack space of the disk or digital media. To use this method of extraction, a file should have a standard file signature called a file header (start of the file). A search is performed to locate the file header and continued until the file footer (end of the file) is reached. The data between these two points will be extracted and analyzed to validate the file. The extraction algorithm uses different methods of carving depending on the file formats.	algorithm;authentication;bmp file format;computer forensics;digital media;digital-to-analog converter;directory information tree;documentation;embedded system;fragmentation (computing);gif;jt (visualization format);portable document format;slack variable;type signature	Digambar Povar;V. K. Bhadran	2010		10.1007/978-3-642-19513-6_12	internet privacy;computer graphics (images)	OS	4.711246819814103	14.900588535193442	6478
e77d9362da3b3ae9b380da873801ab6e9fa37273	on the circumferences of regular 2-connected graphs	connected graph;regular graph	LetGbe a 2-connectedd-regular graph onn?rd(r?3) vertices andc(G) denote the circumference ofG. Bondy conjectured thatc(G)?2n/(r?1) ifnis large enough. In this paper, we show thatc(G)?2n/(r?1)+2(r?3)/(r?1) for any integerr?3. In particular,Gis hamiltonian ifr=3. This generalizes a result of Jackson. Examples to show that the bond forc(G) is sharp and that Bondy's conjecture does not hold ifris allowed to take non-integer values are given.		Bing Wei	1999	J. Comb. Theory, Ser. B	10.1006/jctb.1998.1866	combinatorics;discrete mathematics;regular graph;connectivity;mathematics;algebra	Theory	29.98467103497388	30.843525330633575	6479
d9af2536cc0862b1357fb03d8f41023355308697	a platform for the development of software defined radio	electronic engineering;software defined radio;software radio gsm hardware software standards phase noise base stations communication standards signal resolution standards development radio frequency;software radio;sdr implementation specification;reconfigurable hardware software defined radio sdr implementation specification wireless standards;wireless standards;reconfigurable hardware	This paper describes the development of an SDR (software defined radio) platform for use in investigating the requirements for implementing many popular standards such as GSM, WiFi and 3G through SDR. The first stage of this work is to generate specifications for an SDR implementation from various wireless standard requirements. The next stage is the development of suitable reconfigurable hardware. The final stage is the development of suitable software for the reconfiguration of the hardware and the implementation of the standards.	carrier recovery;etsi satellite digital radio;emoticon;field-programmable gate array;reconfigurable computing;requirement;testbed	Livia Ruiz;Gerard Baldwin;Ronan Farrell	2007	2007 IEEE 18th International Symposium on Personal, Indoor and Mobile Radio Communications	10.1109/PIMRC.2007.4394528	embedded system;real-time computing;computer science;software-defined radio;software construction	Embedded	30.27761727869892	59.61051501031267	6485
654f6b53e05db6e01fc9240a186a3a85ee2aac0d	sequential circuit test generation using decision diagram models	decision diagrams;reliability;built in self repair bisr;decision diagram;automatic test pattern generation;sequential circuits;pattern generation;yield;integrated circuit testing sequential circuits logic testing automatic test pattern generation decision diagrams fault location integrated logic circuits;conformance testing;logic testing;integrated circuit testing;test generation;circuit testing sequential circuits sequential analysis circuit faults software testing radio access networks circuit simulation benchmark testing automata multiplexing;fault coverage;test pattern generator;atpg sequential circuit test generation decision diagram models multilevel decision diagram representations scanning test generation procedures conformity test generation procedures structural faults datapath part control part fast symbolic path activation strategy random local test pattern generation functional units high fault coverage sequential circuit benchmarks;integrated logic circuits;functional unit;fault location	A novel approach to testing sequential circuits that uses multi-level decision diagram representations is introduced. The proposed algorithm consists of a combination of scanning and conformity test generation procedures. Structural faults in both, datapath and control part are targeted. High-level simplified and fast symbolic path activation strategy is combined with random local test pattern generation for functional units. The current approach has achieved high fault coverages for known sequential circuit benchmarks in a very short time.	algorithm;conformity;datapath;influence diagram;sequential logic;test card	Jaan Raik;Raimund Ubar	1999	Design, Automation and Test in Europe Conference and Exhibition, 1999. Proceedings (Cat. No. PR00078)	10.1145/307418.307602	reliability engineering;yield;electronic engineering;influence diagram;fault coverage;computer science;automatic test pattern generation;conformance testing;reliability;sequential logic;algorithm	EDA	20.783894466674866	50.542497249157634	6517
f658b5fb0b19cd7e50c3145283b536a73f32a86b	technical report column		Quasi-Linear Size Zero Knowledge from Linear-Algebraic PCPs, Eli Ben-Sasson, Alessandro Chiesa, Ariel Gabizon, Madars Virza, TR16-001. Strong ETH Breaks With Merlin and Arthur: Short Non-Interactive Proofs of Batch Evaluation, Ryan Williams, TR16-002. On the logspace shortest path problem, Boris Brimkov, Illya Hicks, TR16-003. Further extensions of Clifford circuits and their classical simulation complexities, Dax Enshan Koh, TR16-004. Extension Variables in QBF Resolution, Olaf Beyersdorff, Leroy Chew, Mikolas Janota, TR16-005. An almost Cubic Lower Bound for Depth Three Arithmetic Circuits, Neeraj Kayal, Chandan Saha, Sébastien Tavenas, TR16-006. Property Testing, PCP, andJuntas, Guy Kindler, TR16-007. Algorithms from Natural Lower Bounds, Marco L. Carmosino, Russell Impagliazzo, Valentine Kabanets, Antonina Kolokolova, TR16-008. Identity Testing for constant-width, and commutative, read-once oblivious ABPs, Rohit Gurjar, Arpita Korwar, Nitin Saxena, TR16-009. On the Width of Semi-Algebraic Proofs and Algorithms, Alexander Razborov, TR16-010. Understanding Gentzen and Frege systems for QBF, Olaf Beyersdorff, Jn Pich, TR16-011. Autoreducibility of NP-Complete Sets, John Hitchcock, Hadi Shafei, TR16-012. Bounds on the Kolmogorov complexity function for infinite words, Ludwig Staiger, TR16-013. Extractors for Near Logarithmic Min-Entropy, Gil Cohen, Leonard Schulman, TR16-014. The uniform distribution is complete with respect to testing identity to a fixed distribution, Oded Goldreich, TR16-015. Doubly infinite separation of quantum information and communication, Zi-Wen Liu, Christopher Perry, Yechao Zhu, Dax Enshan Koh, Scott Aaronson, TR16-016. Limitations of Linear Programming Techniques for Bounded Color Matchings, Georgios Stamoulis, TR16-017. Randomness Extraction in AC0 and with Small Locality, Kuan Cheng, Xin Li, TR16-018. Fast Learning Requires Good Memory: A Time-Space Lower Bound for Parity Learning, Ran Raz, TR16-019. The Hilbert Function, Algebraic Extractors, and Recursive Fourier Sampling, Zachary Remscrim, TR16-020. Noisy Population Recovery from Unknown Noise, Shachar Lovett, Jiapeng Zhang, TR16-021.	ac0;alessandro vespignani;algorithm;binary prefix;complexity function;cubic function;eli;frege;kolmogorov complexity;l (complexity);linear programming;locality of reference;ludwig staiger;np-completeness;neeraj kayal;parity learning;property testing;quantum information;ran raz;randomness;ruth aaronson bari;shortest path problem;simulation;true quantified boolean formula;zachary lemnios	Dean Kelley	2016	SIGACT News	10.1145/2951860.2951868		Theory	12.258208205573155	21.931559468180186	6523
afb524959c00128f735bba73c7e90f5a7fe28699	an o(kn lgn) algorithm for optimum k-level quantization on histograms of n points	digital signal processing;non linear programming;time complexity;efficient algorithm;cognitive modeling with heuristics;dynamic program;polynomial time algorithm;machine learning;learning strategy;mean square error;space complexity;heuristics;divide and conquer;density functional;information theory	Optimum quantization is a fundamental problem in digital signal processing and information theory. In 1964 Bruce [1] devised a polynomial-time algorithm to solve this particular non-linear programming problem using the dynamic programming technique. For the mean-square error measure and when the amplitude density function of the quantized signal is represented by a histogram of <italic>N</italic> points, Bruce's algorithm can generate the optimum <italic>K</italic>-level quantizer in <italic>O</italic>(<italic>KN</italic><supscrpt>2</supscrpt>) time. This paper proposes an efficient algorithm which can do the same job with the worst-case time complexity of <italic>O</italic>(<italic>KN</italic> lg <italic>N</italic>). This is due to the discovery of some useful properties of optimum meansquare quantizers and an innovative algorithm structure combining the two algorithmic techniques, dynamic programming and divide-and-conquer. This algorithm structure contributes a new effective methodology to the design of efficient algorithms. Finally the paper outlines a more sophisticated algorithm which can reduce both the time and space complexity of the <italic>O</italic>(<italic>KN</italic> lg <italic>N</italic>) algorithm derived in the paper.	algorithm;backtracking;best, worst and average case;dspace;digital signal processing;dynamic programming;information theory;linear programming;mean squared error;nonlinear programming;nonlinear system;quantization (signal processing);time complexity	Xiaolin Wu;Jon G. Rokne	1989		10.1145/75427.75472	time complexity;mathematical optimization;divide and conquer algorithms;ramer–douglas–peucker algorithm;information theory;computer science;artificial intelligence;theoretical computer science;digital signal processing;heuristics;mean squared error;dspace;freivalds' algorithm;algorithmics;algorithm;population-based incremental learning	Theory	30.341787333634777	6.007843449579132	6525
744c505a6ad75267ec5d8c0b0f6d4b6bf086e6df	holistic energy consumption monitoring in buildings with ip-based wireless sensor networks	gaussian process model;user preference;ashrae;gaussian process;pmv;thermal comfort sampling	We present UBI-AMI v2 for holistic real-time monitoring of building energy consumption with two types of wireless sensors. A Mains sensor monitors the aggregate load at the root of the load tree and the individual loads of up to 30 circuit breakers using analog Hall sensors. A Socket sensor monitors the load of the connected individual appliances. The energy consumption is visualized in user interface in Web browser, through a proxy abstracting the wireless sensor network as a RESTful Web service. Data requests to the proxy are injected dynamically into the sensor network as computational tasks. These tasks can then be used as services for other tasks in the system and for the Web.	aggregate data;holism;proxy server;real-time clock;representational state transfer;sensor;user interface;web service;world wide web	Teemu Leppänen;Jani Ylioja;Pauli Närhi;Teijo Räty;Timo Ojala;Jukka Riekki	2012		10.1145/2422531.2422567	embedded system;real-time computing;simulation;engineering;key distribution in wireless sensor networks	Mobile	1.6152744323761004	32.482596584645535	6527
582a7d3e60a55e5599c0e5bdeed636e93e921176	dual ascent for uncapacitated telecommunications network design with access, backbone, and switch costs	dual ascent;telecommunication network design;uncapacitated;design;uncapacitated facility location problem;capacity constraint;steiner tree;network;telecommunications;switching cost	We consider the telecommunications network design problem of simultaneously determining at which locations to place a switch, interconnecting all switches with backbone trunks, and connecting each location to some switch by an access circuit. We assume there are no capacity constraints, and minimize the sum of switch, backbone trunk, and access circuit costs using a dual ascent method that solves a sequence of dual uncapacitated facility location problems. A Steiner tree based heuristic provides a primal feasible design. On 15 random problems with 100 locations, the average duality gap is 2.0%.		Eric Rosenberg	2001	Telecommunication Systems	10.1023/A:1016623229800	design;mathematical optimization;telecommunications;computer science;computer network	Theory	20.928134546621184	12.991294040519787	6530
07f38b067b395bd1cc313127e10e900e11daf757	digit serial multipliers	digital circuit;red sistolica;data transmission;concepcion circuito;multiplier;architecture systeme;implementation;circuit design;digital transmission;circuit vlsi;circuit numerique;ejecucion;vlsi circuit;multiplicateur;systolic network;transmission donnee;circuito numerico;reseau systolique;transmision numerica;procesador oleoducto;arquitectura sistema;conception circuit;procesador;circuito vlsi;transmission numerique;processeur;processeur pipeline;system architecture;processor;multiplicador;transmision datos;pipeline processor	Digit serial data transmission can be used to an advantage in the design of special purpose processors where communicat ion issues dominate and where digit pipelining can be used to ma intain high data rates. VLSI signal processing is one such problem doma in. We propose detailed designs of unidirectional systolic and semisystolic programmable digit pipelined (serial) mu ltipliers. These mu ltipliers are programmable; i.e., one operand is prestored in the mu ltiplier and the other operand is fed in a digit serial fashion. The VLSI implementation of the systolic mu ltiplier is given. This systolic mu ltiplier is used in our VLSI signal processing system. Lastly, for the sake of completeness we also propose designs of nonprogrammable unidirectional and bidirectional digit serial mu ltipliers. o 1991 Academic PXSS, h.	central processing unit;operand;pipeline (computing);serial communication;signal processing;systolic array;very-large-scale integration	Poras T. Balsara;Robert Michael Owens;Mary Jane Irwin	1991	J. Parallel Distrib. Comput.	10.1016/0743-7315(91)90121-O	embedded system;parallel computing;computer science;systems architecture;data transmission	ML	16.004566629175212	40.77276997179719	6532
4b391db477ae2a17d1190065b5f3b6ebfd02fa9b	a note on the spt heuristic for solving scheduling problems with generalized due dates	parallel identical machines;shortest processing time;scheduling;scheduling problem;heuristics;lower bound	Two NP-hard scheduling problems on parallel identical machines with generalized due dates are studied. We focus on two objectives: (i) minimizing maximum tardiness and (ii) minimizing total tardiness. In both cases, we introduce a shortest processing time first (SPT)-based heuristic and simple lower bounds on the optimal cost. Our numerical study indicates that the SPT heuristic performs extremely well in all settings.	hall-effect thruster;heuristic;scheduling (computing)	Gur Mosheiov;Daniel Oron	2004	Computers & OR	10.1016/S0305-0548(03)00018-2	job shop scheduling;mathematical optimization;real-time computing;computer science;heuristics;mathematics;distributed computing;upper and lower bounds;scheduling	AI	15.809976555125278	9.85409436981286	6557
5fa415d36788632968ea0cf678ca176c4db6255d	minimum-cost linear coverage by sensors with adjustable ranges	constant-approximation algorithm;continuous variant;coverage range;adjustable range;wireless sensor network;constant k;2-approximation algorithm;chosen power;minimum-cost linear coverage;wireless sensor;adjustable coverage range;discrete variant	One of the most fundamental tasks of wireless sensor networks is to provide coverage of the deployment region. In this paper, we study the coverage of a line segment with a set of wireless sensors with adjustable coverage ranges. Each coverage range of a sensor is an interval centered at that sensor. The objective is to find a range assignment with the minimum cost. There are two variants of the optimization problem. In the discrete variant, each sensor can only choose from a finite set of powers while in the continuous variant, each sensor can choose power from a given interval. For the discrete variant of the problem, we present a polynomial-time exact algorithm. For the continuous variant of the problem, we develop constant-approximation algorithms when the cost for all sensors is proportional to r^κ for some constant κ 1, where r is the covering radius corresponding to the chosen power. Specifically, if κ = 1, we give a simple 1.25-approximation algorithm and a polynomial-time approximation scheme (PTAS); if κ > 1, we give a simple 2-approximation algorithm.	approximation algorithm;assignment problem;exact algorithm;mathematical optimization;optimization problem;ptas reduction;polynomial;polynomial-time approximation scheme;sensor;software deployment;time complexity	Minming Li;Xianwei Sun;Yingchao Zhao	2011		10.1007/978-3-642-23490-3_3	mathematical optimization;real-time computing;mathematics	Mobile	27.086532411500226	18.725977837766706	6561
a7e682c8c1c8812dc8c4840ec69c332839e0a09c	a constant update time finger search tree	arbre recherche;tiempo busqueda;algorithm analysis;temps recherche;analysis of algorithms;search trees;arbol investigacion;data structures;estructura datos;analyse algorithme;structure donnee;search tree;search time;data structure;analisis algoritmo	Levcopolous and Overmars [L088] described a search tree in which the time to insert or delete a key was O( 1) once the position of the key to be inserted or deleted was known. Their data structure did not support fingers, pointers to points of high access or update activity in the set such that access and update operations in the vicinity of a finger are particularly efficient [GMPR77, BT80, Kos81, HM82, Tsa85]. Levcopolous and Overrnars left open the question of whether a data structure could be designed which allowed updates in constant time and supported fingers. We answer the question in the affirmative by giving an algorithm in the RAM with logarithmic word size. CR Classification Number: [F.2.2 Sorting and Searching]	acm computing classification system;algorithm;data structure;finger search tree;random-access memory;sorting;time complexity	Paul F. Dietz;Rajeev Raman	1994	Inf. Process. Lett.	10.1016/0020-0190(94)00115-4	data structure;computer science;artificial intelligence;analysis of algorithms;data mining;search tree;programming language;algorithm	Theory	15.178719589532955	27.732297417354243	6565
6814013255038c2a4daf909239a4886e98ef559d	compact architecture for high-throughput regular expression matching on fpga	intrusion detection;fpga;scaling up;bram;route optimization;high throughput;nfa;high speed;regular expression;finite state machine	In this paper we present a novel architecture for high-speed and high-capacity regular expression matching (REM) on FPGA. The proposed REM architecture, based on nondeterministic finite automaton (RE-NFA), efficiently constructs regular expression matching engines (REME) of arbitrary regular patterns and character classes in a uniform structure, utilizing both logic slices and block memory (BRAM) available on modern FPGA devices. The resulting circuits take advantage of synthesis and routing optimizations to achieve high operating speed and area efficiency. The uniform structure of our RE-NFA design can be stacked in a simple way to produce multi-character input circuits to scale up throughput further. An n-state m-character input REME takes only O (n X log2 m) time to construct and occupies no more than O (n X m) logic units. The REMEs can be staged and pipelined in large numbers to achieve high parallelism without sacrificing clock frequency.  Using the proposed RE-NFA architecture, we are able to implement 3 copies of two-character input REMEs, each with 760 regular expressions, 18715 states and 371 character classes, onto a single Xilinx Virtex 4 LX-100-12 device. Each copy processes 2 characters per clock cycle at 300 MHz, resulting in a concurrent throughput of 14.4 Gbps for 760 REMEs. Compared with the automatic NFA-to-VHDL REME compilation [13], our approach achieves over 9x throughput efficiency (Gbps*state/LUT). Compared with state-of-the-art REMEs on FPGA, our approach also indicates up to 70% better throughput efficiency.	binary logarithm;clock rate;clock signal;compiler;data rate units;field-programmable gate array;finite-state machine;high-throughput computing;nondeterministic finite automaton;parallel computing;pipeline (computing);regular expression;routing;throughput;vhdl;virtex (fpga)	Yi-Hua Edward Yang;Weirong Jiang;Viktor K. Prasanna	2008		10.1145/1477942.1477948	intrusion detection system;high-throughput screening;parallel computing;real-time computing;computer science;theoretical computer science;operating system;finite-state machine;programming language;regular expression;field-programmable gate array	EDA	8.41433514018617	47.20680635682706	6578
e3e8e48b7764b14f7e197ac4137d7177bd2dc8cf	asymmetrically reliable caches for multicore architectures under performance and energy constraints	asymmetric cores;selective protection;fault injection;reliability	Cache structures in a multicore system are more vulnerable to soft errors due to high transistor density. Protecting all caches unselectively has notable overhead on performance and energy consumption. In this study, we propose asymmetrically reliable caches to supply reliability need of the system using sufficient additional hardware under the performance and energy constraints. In our framework, a chip multiprocessor is composed of a high reliability core which has ECC protection, and a set of low reliability cores which have no protection on their data caches. Between two types of cores, there is also a middle-level reliability core which has only parity check. Application threads are mapped on the different cores in terms of reliability based on their critical data usage. The experimental results for selected applications show that our proposed techniques improve reliability with considerable performance and energy overhead on the average compared to traditional unsafe caches.	cpu cache;experiment;failure rate;fault injection;multi-core processor;overhead (computing);parity bit;protection mechanism;run time (program lifecycle phase);soft error;symmetric multiprocessing;thread (computing);transistor;vulnerability (computing)	Sanem Arslan;Haluk Topcuoglu;Mahmut T. Kandemir;Oguz Tosun	2016	Cluster Computing	10.1007/s10586-016-0641-2	embedded system;parallel computing;real-time computing;computer science;operating system	Arch	6.753926247013481	60.31641381192716	6585
8bb9708efd2712ccb3afaf261c0b3bed839aad45	a stability result for the katona theorem	extremal problems;families;finite sets;union;intersection	Let  n ,  s    be positive integers,   n≥s+2     n  ≥  s  +  2       . In 1964 Katona   [5]   established the maximum possible size of a family of subsets of   {1,2,…,n}     {  1  ,  2  ,  …  ,  n  }        such that the union of any two members of the family has size of at most  s . Katona also proved that the optimal families are unique up to isomorphism. In the present paper we sharpen this result by showing that excluding those optimal families one can get better bounds. These new bounds are best possible.		Peter Frankl	2017	J. Comb. Theory, Ser. B	10.1016/j.jctb.2016.10.003	combinatorics;mathematical analysis;discrete mathematics;finite set;intersection;mathematics	Theory	37.982813164738644	30.015531203418334	6587
903dc7ba8c014af25aa7cbf45f4be6c4f2160d90	structured motifs identification in dna sequences	dna sequences;dna sequence	In this paper, we present an algorithm that finds structured motifs in a DNA sequence. A structured motif consists of a central motif and one or two satellite motifs, which may be located to the left and / or right of the central motif. The search of the motifs is performed in two stages: first, the central motifs are located through an exact set matching process, which is implemented by a deterministic finite automaton; in the second stage, the satellite motifs are located from the position of the central motifs at a distance defined as input. This last phase requires two steps: first, a matrix is calculated through a dynamic programming technique using the Levenshtein algorithm. After this, we identify the satellite motifs using the matrix. Based on our results, our method is fast at the moment to search for central patterns (in linear time), and the second phase is most expensive because it is necesary to identify all the possible alignments and after that, perform the alignment with their respective satellite.	acm computing surveys;approximate string matching;bioinformatics;dna database;deterministic finite automaton;dynamic programming;edit distance;experiment;finite-state machine;lecture notes in computer science;micai;motif;springer (tank);string searching algorithm;structured programming;the matrix;time complexity	Yuridia P. Mejia;Iván Olmos;Jesus A. Gonzalez	2010			dna sequencing;computer science;bioinformatics;machine learning	Comp.	13.6624569015844	27.68818044786224	6595
106f301e2c6cfc31fb3c0147f3de3187d50ce105	a covering system with least modulus 25	calcul scientifique;analisis numerico;nombre entier;satisfiability;gran sistema;analyse numerique;integer;large scale;computacion cientifica;numerical analysis;probleme recouvrement;problema recubrimiento;large system;entero;covering problem;scientific computation;05b40;grand systeme	A collection of congruences with distinct moduli, each greater than 1, such that each integer satisfies at least one of the congruences, is said to be a covering system. A famous conjecture of Erdös from 1950 states that the least modulus of a covering system can be arbitrarily large. This conjecture remains open and, in its full strength, appears at present to be unattackable. Most of the effort in this direction has been aimed at explicitly constructing covering systems with large least modulus. Improving upon previous results of Churchhouse, Krukenberg, Choi, and Morikawa, we construct a covering system with least modulus 25. The construction involves a large-scale computer search, in conjunction with two general results that considerably reduce the complexity of the search.	modulus of continuity;modulus robot;search algorithm	Donald Jason Gibson	2009	Math. Comput.	10.1090/S0025-5718-08-02154-6	integer;combinatorics;numerical analysis;mathematics;geometry;algorithm;algebra;satisfiability	Theory	42.91493460653668	37.07515562108733	6596
6b3e02c8e1bc47f072e41f2672c53ea28fcbe2e4	linear inequalities for covering codes: part ii: triple covering inequalities	triple covering inequalities;local covering problem;error correction codes;covering codes;lower bounds;linear inequality method;problem lead;numerous new lower bound;new linear inequality;association scheme;binary codes;linear code;concrete;upper bound;indexing terms;lower bound;history;linear inequalities;binary code;satisfiability	For Pt.I, see ibid., vol.37, no.3, p.573-82 (May 1991). The linear inequality method for covering codes is generalized. This method reduces the study of covering codes to the study of some local covering problems. One of these problems, the 1-3 covering system, is formulated and studied in detail. The results for this local covering problem lead to new linear inequalities satisfied by covering codes, which are used to obtain numerous new lower bounds on K(n, R) and t[n, k]	code;linear inequality	Zhen Zhang;Chiaming Lo	1992	IEEE Trans. Information Theory	10.1109/18.165440		Theory	39.00000663471281	54.73347880297706	6614
0be43230214703d94548624744c2a06ae1c09b76	sums of two and four squares		This document gives the formal proofs of the following results about the sums of two and four squares: 1. Any prime number p ≡ 1 mod 4 can be written as the sum of two squares. 2. (Lagrange) Any natural number can be written as the sum of four squares. The proofs are largely based on chapters II and III of the book by Weil [Wei83]. The results have been formalised before in the proof assistant HOL Light [Har]. A more complete study of the sum of two squares, including the first result, has been formalised in Coq [The04]. The results can also be found as numbers 20 and 19 on the list of ‘top 100 mathematical theorems’ [Wie]. This research is part of an M.Sc. thesis under supervision of Jaap Top and Wim H. Hesselink (RU Groningen). For more information see [Oos07].		Roelof Oosterhuis	2007	Archive of Formal Proofs		fermat's theorem on sums of two squares;algebra;prime number;natural number;mathematical proof;mathematics;hol;proof assistant	Crypto	38.64295356944195	38.5857671814558	6626
2eb2be10c4183fe9f53a620546e855b0d346e349	new approximability and inapproximability results for 2-dimensional bin packing	bin packing problem;bin packing;approximate algorithm;1 dimensional;2 dimensional;polynomial time approximation scheme	We study the 2-dimensional generalization of the classical Bin Packing problem: Given a collection of rectangles of specified size (width, height), the goal is to pack these into minimum number of square bins of unit size. A long history of results exists for this problem and its special cases [3, 14, 10, 18, 9, 1, 15]. Currently, the best known approximation algorithm achieves a guarantee of 1.69 in the asymptotic case (i.e. when the optimum uses a large number of bins) [1]. However, an important open question has been whether 2-dimensional bin packing is essentially similar to the 1-dimensional case in that it admits an asymptotic polynomial time approximation scheme (APTAS) [8, 13] or not? We answer the question in the negative and show that the problem is APX hard in the asymptotic case. On the other hand, we give an asymptotic PTAS for the special case when all the rectangles to be packed are squares (or more generally hypercubes). This improves upon the previous best known guarantee of 1.454 for d = 2 [9] and 2 - (2/3)d for d > 2 [15], and settles the approximability for this special case.	apx;approximation algorithm;bin packing problem;hardness of approximation;ptas reduction;polynomial;polynomial-time approximation scheme;set packing	Nikhil Bansal;Maxim Sviridenko	2004			mathematical optimization;combinatorics;discrete mathematics;bin packing problem;apx;computer science;mathematics;bin;algorithm;square packing in a square	Theory	23.1750649706234	21.708351695692027	6649
77e8052c42d6d0bcff6e9df58582dae6ecf86ff5	high throughput multiplierless architecture for vp9 fractional motion estimation		This paper presents a dedicated hardware design for the Fractional Motion Estimation (FME) of VP9 encoders. The presented hardware was designed to reach real-time when processing high definition videos. The designed FME filters use pure combinational logic. The multiplications were designed through shift-adds and the common sub-expressions were shared to reduce the hardware area and to increase the architecture throughput. Two architectural versions were designed, targeting two video resolutions. These architectural versions have distinct levels of parallelism and reach different throughputs. The synthesis was targeted to 45nm Nangate standard-cells technology, and the results show that the architecture with the highest parallelism has the performance to process Full HD videos (1920×1080 pixels) at 30 frames per second with a power dissipation of 569.9mW. To the best of our knowledge, there is no other published work with dedicated hardware for a complete VP9 FME design.	blu-ray;combinational logic;computation;encoder;formal methods europe;low-pass filter;motion estimation;parallel computing;pixel;real-time clock;real-time computing;throughput;vp9	Jones Goebel;Lucas Agostini;Luciano Agostini;Bruno Zatt;Marcelo Porto	2018	2018 31st Symposium on Integrated Circuits and Systems Design (SBCCI)	10.1109/SBCCI.2018.8533255	encoder;real-time computing;throughput;interpolation;pixel;frame rate;architecture;motion estimation;combinational logic;computer science	Arch	12.291380848109355	40.678050299118965	6665
8690395000ed2591dc1fc502d5e16ef882390c97	total domination critical and stable graphs upon edge removal	graphe critique;optimisation;combinatorics;optimizacion;total domination edge critical;combinatoria;vertex;critical graph;combinatoire;total domination edge stable;dominating set;informatique theorique;68r10;edge graph;arete graphe;nombre domination totale;conjunto dominando;total domination number;optimization;vertice;cardinalite;domination number;grafo critico;arista grafico;ensemble dominant;computer theory;informatica teorica	A set S of vertices in a graph G is a total dominating set of G if every vertex of G is adjacent to some vertex in S. The minimum cardinality of a total dominating set of G is the total domination number of G. A graph is total domination edge critical if the removal of any arbitrary edge increases the total domination number. On the other hand, a graph is total domination edge stable if the removal of any arbitrary edge has no effect on the total domination number. In this paper, we characterize total domination edge critical graphs. We also investigate various properties of total domination edge stable graphs.	dominating set	Wyatt J. Desormeaux;Teresa W. Haynes;Michael A. Henning	2010	Discrete Applied Mathematics	10.1016/j.dam.2010.06.003	vertex;combinatorics;independent set;topology;domination analysis;dominating set;edge cover;mathematics;geometry;critical graph	ML	24.762797014045226	30.930516065240568	6677
325cf2aa4f624b566fe4931e3859b3b079fdefdb	applying parallel computing techniques to analyze terabyte atmospheric boundary layer model outputs		In the atmospheric sciences, the size of simulation output continues to grow as computational resources able to handle simulations with fine-scale spatial and temporal resolutions become more accessible. As output size increases, serial data analysis methods become overwhelmed, resulting in either long delays during processing or total failures due to memory constraints. Parallel data analysis methods can alleviate these issues, however atmospheric scientists are often unfamiliar with how to achieve this. Therefore, example methods are needed to help guide the use of parallel processing in the analysis of Big Data from atmospheric simulations.#R##N##R##N#In this work, practical methods are presented by which an analysis may be executed in parallel using the Message Passing Interface (MPI) and Python. These methods first consider the inherent spatial dependencies of a particular data analysis process. By identifying these dependencies, horizontal or vertical distribution of the dataset across processes can be carried out with minimal process intercommunication. In addition, an analysis method is classified as either data-transfer-limited or computationally-limited. In data-transfer-limited problems, data transfer time outweighs processing time. In computationally-limited problems, processing time outweighs data transfer time.#R##N##R##N#The results show that by increasing processor count, the execution time of computationally-limited problems shows improvement. For data-transfer-limited problems, increasing node count offers the greatest improvement. To further improve the performance of computationally-limited problems, a Graphics Processing Unit (GPU) and the Compute Unified Device Architecture (CUDA) framework are used. It is shown that this GPU implementation offers further improvement over the MPI version of the analysis methods tested.		Timothy S. Sliwinski;Song-Lak Kang	2017	Big Data Research	10.1016/j.bdr.2017.01.001	parallel computing;real-time computing;computer science;theoretical computer science;data mining	ML	-4.3916182834160065	35.202486098831464	6684
7102cf1939133c84520acda21af08c3a9eec9fe9	upper bound on the number of processors for scheduling with interprocessor communication delays	arbre graphe;tiempo total acabamiento;minimum number of processors;execution time;tree graph;gestion labor;multiprocessor;multiprocessor systems;temps total achevement;problema np duro;delay system;communication interprocesseur;processing time;constrenimiento precedencia;upper bound;np hard problem;gestion tâche;makespan;systeme a retard;probleme np difficile;scheduling;uct;precedence constraint;contrainte precedence;scheduling problem;communication delay;temps traitement;temps execution;ordonamiento;procesador;temps retard;delay time;sistema con retardo;task scheduling;processeur;multiprocesador;tiempo ejecucion;arbol grafo;borne superieure;key words scheduling;tiempo retardo;tiempo proceso;processor;ordonnancement;communication delays;cota superior;multiprocesseur	The problem of scheduling a task system with communication delays on multiprocessor systems is known to be NP-hard in its general form as well as many restricted cases even on an unlimited number of processors. In this paper, we study the problem of determining an upper bound on the minimum number of processors achieved by a schedule that minimizes the makespan for scheduling problems with communication delays. We prove that the minimum number of partitioning paths of the precedence graph is an upper bound on the minimum number of processors for UET-UCT (Unit Execution Time-Unit Communication Time) task systems. Then we propose an algorithm of O(n) (n designates the number of tasks) to compute an upper bound, which is valid independently of task processing times and communication delays, in the special case when the precedence graph is an out-tree or an in-tree.	central processing unit;inter-process communication;scheduling (computing)	Aziz Moukrim	2000	Math. Meth. of OR	10.1007/s001860000062	job shop scheduling;mathematical optimization;parallel computing;real-time computing;multiprocessing;computer science;np-hard;mathematics;distributed computing;upper and lower bounds;scheduling;multiprocessor scheduling;tree	Theory	17.09886078470253	11.11897218982265	6695
a8f68941958d3d55e4fe1c8c9fcec71623acaecd	decision support for consumer direct grocery initiatives	integrated approach;commerce electronique;insertion heuristics;real time decision making;new technology;decision support;entrega;comercio electronico;e business;logistique;delivery windows;systeme aide decision;routing;vehicle routing problem;e commerce;real time;livraison a domicile;approche heuristique;vehicle routing;probleme tournee vehicule;real time information;sistema ayuda decision;result;problema ruta vehiculo;methode calcul;metodo calculo;service model;livraison;business model;decision support system;home delivery;logistics;heuristic methods;scheduling;temps reel;decision support systems;enfoque heuristico;scheduling problem;tiempo real;resultado;schedules and scheduling;door to door service;profitability;resultat;delivery good;heuristic approach;grocery delivery service;experimentation;computing method;ordonnancement;electronic trade;reglamento;profit maximization;experimentacion;delivery service;logistica	Many companies with consumer direct service models, especially grocery delivery services, have found that home delivery poses an enormous logistical challenge due to the unpredictability of demand coupled with strict delivery windows and low profit margin products. These systems have proven difficult to manage effectively and could benefit from new technology, particularly to manage the interaction between order capture and promise and order delivery. In this paper, we define routing and scheduling problems that capture important features of this emerging business model and propose algorithms, based on insertion heuristics, for their solution. The emphasis is on profit maximization. The vendor has to decide which requests to accept and in which time slot to guarantee delivery, for those that are accepted. Computational experiments demonstrate the importance of an integrated approach to order capture and promise and order delivery and the quality and value of the proposed algorithms.	computation;expectation–maximization algorithm;experiment;heuristic (computer science);logistics;microsoft windows;routing;scheduling (computing)	Ann Melissa Campbell;Martin W. P. Savelsbergh	2005	Transportation Science	10.1287/trsc.1040.0105	business model;logistics;mathematical optimization;real-time data;routing;simulation;decision support system;computer science;engineering;operations management;service-oriented modeling;operations research;scheduling;profitability index	AI	16.833175108354556	5.328822299895819	6697
cb55145fd886fdbc461fbf43f1ed5f2e3b2be763	on the length of the tail of a vector space partition	perfect code;nombre entier;methode element fini;metodo elemento finito;vector space;cola;queue;11txx;finite element method;vecteur;corps fini;finite element;finite field;integer;particion;entero;champ fini;borne inferieure;partition;campo finito;perfect codes;vector;code;espace vectoriel;element fini;espacio vectorial;vector space partitions;codigo;tail;lower bound;elemento finito;cota inferior	"""A vector space partition P of a finite dimensional vector space V=V(n,q) of dimension n over a finite field with q elements, is a collection of subspaces U""""1,U""""2,...,U""""t with the property that every non zero vector of V is contained in exactly one of these subspaces. The tail of P consists of the subspaces of least dimension d""""1 in P, and the length n""""1 of the tail is the number of subspaces in the tail. Let d""""2 denote the second least dimension in P. Two cases are considered: the integer q^d^""""^2^-^d^""""^1 does not divide respective divides n""""1. In the first case it is proved that if 2d""""1>d""""2 then n""""1>=q^d^""""^1+1 and if 2d""""1@?d""""2 then either n""""1=(q^d^""""^2-1)/(q^d^""""^1-1) or n""""1>2q^d^""""^2^-^d^""""^1. These lower bounds are shown to be tight and the elements in the subspaces in tails of minimal length will constitute a subspace of V of dimension 2d""""1 respectively d""""2. In case q^d^""""^2^-^d^""""^1 divides n""""1 it is shown that if d""""2 =q^d^""""^2-q^d^""""^1+q^d^""""^2^-^d^""""^1 and if 2d""""1@?d""""2 then n""""1>=q^d^""""^2. The last bound is also shown to be tight. The results considerably improve earlier found lower bounds on the length of the tail."""		Olof Heden	2009	Discrete Mathematics	10.1016/j.disc.2009.05.026	partial word;function composition;combinatorics;generic property;finite element method;calculus;mathematics;geometry;incidence;algebra	Theory	37.54552771719775	32.96040954936689	6704
ee104b3054caea007ef0073e011fba479bf1638b	non-commutative extrapolation algorithms	non commutative;clifford algebra	This paper contains two general results. The first is an extension of the theory of general linear extrapolation methods to a non-commutative field (or even a non-commutative unitary ring). The second one, by exploiting these new results, is to solve an old conjecture about Wynn's vector ε-algorithm. Then, by using designants and Clifford algebras, we show how the vectors ∈ k (n) can be written as a ratio of two designants. This result allow us to find, as a particular case, some well-known results and some others which are new.	algorithm;extrapolation	A. Salam	1994	Numerical Algorithms	10.1007/BF02140685	classification of clifford algebras;mathematical analysis;discrete mathematics;calculus;pure mathematics;mathematics;clifford algebra;algebra	Theory	45.69505392159337	32.166671497210125	6720
7940c9ca5994026d258e57435411aa22b9edee73	multicore processing and efficient on-chip caching for h.264 and future video decoders	desciframiento;parallelisme;circuit decodeur;cache storage;video sequence;evaluation performance;interleaved entropy slice technique;gestion memoire;power saving;multiframe processing;coding efficiency;entropia;storage access;mobile device;performance evaluation;image resolution;criterio resultado;integrated circuit;decodage;off chip memory access;decoding;video signal processing;energy efficient;routing;vitesse sequentielle;relacion orden;storage management;evaluacion prestacion;raster;simulation;rendement energetique;routage;frame rate;ordering;performance requirement;simulacion;cache memory;circuito integrado;video sequences;lower power consumption;critere performance;video decoders;circuito desciframiento;system on a chip;video decoder;chip;antememoria;memory access;video coding;relation ordre;decoding circuit;low voltage;gestion memoria;antememoire;consumo electricidad;parallelism;performance improvement;multicore;low power;paralelismo;senal video;signal video;baja tension;codage video;multicore processing decoding hardware delay energy consumption voltage system on a chip video sequences parallel processing entropy;video coding cache storage decoding image resolution image sequences microprocessor chips multiprocessing systems system on chip;system on chip;energy consumption;multicore processing;voltage;rendimiento energetico;entropie;image sequence;trame;electric power consumption;acces memoire;basse tension;on chip caching;h 264;traitement signal video;acceso memoria;video signal;secuencia imagen;entropy;parallel hardware decoder;multiprocessing systems;power consumption;consommation energie electrique;video decoders h 264 low power multicore parallelism;voltage scaling;energetic efficiency;memory bandwidth;memory power;consommation electricite;parallel processing;circuit integre;sequence image;trama;microprocessor chips;parallel decoder;hardware;image sequences;interleaved macroblock ordering	Performance requirements for video decoding will continue to rise in the future due to the adoption of higher resolutions and faster frame rates. Multicore processing is an effective way to handle the resulting increase in computation. For power-constrained applications such as mobile devices, extra performance can be traded-off for lower power consumption via voltage scaling. As memory power is a significant part of system power, it is also important to reduce unnecessary on-chip and off-chip memory accesses. This paper proposes several techniques that enable multiple parallel decoders to process a single video sequence; the paper also demonstrates several on-chip caching schemes. First, we describe techniques that can be applied to the existing H.264 standard, such as multiframe processing. Second, with an eye toward future video standards, we propose replacing the traditional raster-scan processing with an interleaved macroblock ordering; this can increase parallelism with minimal impact on coding efficiency and latency. The proposed architectures allow N parallel hardware decoders to achieve a speedup of up to a factor of N. For example, if N=3, the proposed multiple frame and interleaved entropy slice multicore processing techniques can achieve performance improvements of 2.64times and 2.91times, respectively. This extra hardware performance can be used to decode higher definition videos. Alternatively, it can be traded-off for dynamic power savings of 60% relative to a single nominal-voltage decoder. Finally, on-chip caching methods are presented that significantly reduce off-chip memory bandwidth, leading to a further increase in performance and energy efficiency. Data-forwarding caches can reduce off-chip memory reads by 53%, while using a last-frame cache can eliminate 80% of the off-chip reads. The proposed techniques were validated and benchmarked using full-system Verilog hardware simulations based on an existing decoder; they should also be applicable to most other decoder architectures. The metrics used to evaluate the ideas in this paper are performance, power, area, memory efficiency, coding efficiency, and input latency.	algorithmic efficiency;benchmark (computing);cache (computing);computation;computer memory;dynamic voltage scaling;h.264/mpeg-4 avc;hdmi;high- and low-level;image scaling;integrated encryption scheme;macroblock;memory bandwidth;mobile device;multi-core processor;parallel computing;raster scan;requirement;simulation;speedup;systemverilog;verilog;video decoder	Daniel F. Finchelstein;Vivienne Sze;Anantha Chandrakasan	2009	IEEE Transactions on Circuits and Systems for Video Technology	10.1109/TCSVT.2009.2031459	system on a chip;multi-core processor;embedded system;parallel processing;entropy;parallel computing;real-time computing;telecommunications;computer science	Arch	13.842262901013331	40.65587346635791	6725
33403c9b950be453b0d5482336222c05b20f7130	t-designs with general angle set	espace delsarte;polinomio ortogonal;ensemble angles;orthogonal polynomial;quaternion;interseccion;espacio progectivo;t design;cuaternion;projective space;t plan;polynome orthogonal;intersection;spherical design;espace projectif;plan spherique;coefficient indicateur	The known infinite Delsarte spaces are  d -spheres, and projective spaces over the reals, complex numbers, quaternions and octonions. We derive, in a unified manner, intersection numbers and other parameters for general  t -designs in these spaces.		Stuart G. Hoggar	1992	Eur. J. Comb.	10.1016/S0195-6698(05)80032-0	projective space;combinatorics;topology;intersection;mathematics;geometry;orthogonal polynomials;examples of vector spaces;quaternion;algebra	Theory	40.042144251088146	24.185946344307606	6727
31a737fc5c2f6071b55eaf634b40b48706287820	a comparison of cabac throughput for hevc/h.265 vs. avc/h.264	video coding entropy codes telecommunication standards video codecs;jct vc standardization body hevc h 265 avc h 264 cabac entropy coding engine video codec context coded bins bypass bins bjontegaard delta cycles bjontegaard delta measurement method;video coding;entropy codes;telecommunication standards;video codecs;arithmetic coding hevc h 265 avc h 264 cabac throughput;context throughput syntactics video coding encoding delays engines;article	The CABAC entropy coding engine is a well known throughput bottleneck in the AVC/H.264 video codec. It was redesigned to achieve higher throughput for the latest video coding standard HEVC/H.265. Various improvements were made including reduction in context coded bins, reduction in total bins and grouping of bypass bins. This paper discusses and quantifies the impact of these techniques and introduces a new metric called Bjontegaard delta cycles (BD-cycle) to compare the CABAC throughput of HEVC vs. AVC. BD-cycle uses the Bjontegaard delta measurement method to compute the average difference between the cycles vs. bit-rate curves of HEVC and AVC. This metric is useful for estimating the throughput of an HEVC CABAC engine from an existing AVC CABAC design for a given bit-rate. Under the common conditions set by the JCT-VC standardization body, HEVC CABAC has an average BD-cycle reduction of 31.1% for all intra, 24.3% for low delay, and 25.9% for random ac-cess, when processing up to 8 bypass bins per cycle.	blu-ray;codec;context-adaptive binary arithmetic coding;data compression;entropy encoding;h.264/mpeg-4 avc;high efficiency video coding;throughput;vc dimension;video coding format	Vivienne Sze;Madhukar Budagavi	2013	SiPS 2013 Proceedings	10.1109/SiPS.2013.6674499	real-time computing;telecommunications;computer science;theoretical computer science;context-adaptive variable-length coding;context-adaptive binary arithmetic coding	Arch	12.990882876938713	39.284946682647295	6752
aede6c8c6bd7ae37279c2658f88d6f492a520845	the design and implementation of adaptive reconfigurable computing array	software;reconfigurable system;netfpga adaptive reconfigurable computing array networked adaptive array;performance evaluation;networked adaptive array;reconfigurable computing;dynamic reconfiguration;resource management;arrays;adaptive array reconfigurable computing netfpga dynamic reconfiguration;design and implementation;cryptography;adaptive arrays;adaptive array reconfigurable computing;adaptive arrays embedded computing hardware multicore processing acceleration field programmable gate arrays computer architecture educational institutions computer science adaptive systems;netfpga;field programmable gate arrays;adaptive reconfigurable computing array;hardware	More and more reconfigurable devices have been used to accelerate specific computation in traditional computing systems. But isolate reconfigurable system has some shortcomings such as limited computation ability, low utilization of reconfigurable devices. In this paper, a networked adaptive array of reconfigurable computing nodes was proposed, which is composed of host and reconfigurable devices. Via sharing reconfigurable resources among nodes in the system, the ability of computation of one node is enhanced and the utilization ratio of reconfigurable resources is increased. The experiment result shows that about 19.5%-48.2% execution time could be reduced by using 2-5 nodes in the array comparing with a single node for heavy workload.	computation;reconfigurable computing;run time (program lifecycle phase)	Binbin Wu;Like Yan;Degui Feng;Tianzhou Chen	2009	2009 International Conference on Scalable Computing and Communications; Eighth International Conference on Embedded Computing	10.1109/EmbeddedCom-ScalCom.2009.51	embedded system;parallel computing;real-time computing;computer science	Robotics	-2.400342172507249	50.435634936348045	6765
7048600cfe2e0e5f0a4cd3ca759e353d47d2e039	an approach for synthesizing energy-efficient controllers for production systems from scenario-based specifications		Rising costs of energy production have made saving energy an important topic in many areas, including modern production systems. One idea is taking advantage of the braking energy becoming available when decelerating moving components of a machine. However, using the braking energy is a di cult task, as it requires the synchronization of the movement of di erent parts of a production system. Storing this energy often is not an economically viable solution. Optimizing the entire production process, in particular recognizing all optimization opportunities while still ful lling all requirements, is a di cult and error-prone task. To support engineers in this task, we propose behavior modeling through scenario-based speci cations, to be able to automatically generate all valid behavior strategies for the system, combined with energy usage modeling through state machines, to automatically identify the most energy-e cient strategy.	behavior model;cognitive dimensions of notations;mathematical optimization;optimizing compiler;production system (computer science);requirement	Joel Greenyer;Daniel Gritzner	2016			efficient energy use;control engineering;computer science	OS	5.584432214998599	5.522789859242255	6771
4d34aa30b42898462254b8c61ff3bf3c933b6f4f	a conjecture on tangent intersections of surface patches	tecnologia electronica telecomunicaciones;intersection of surfaces;computacion informatica;genus;surface surface intersections;ciencias basicas y experimentales;tecnologias;grupo a;connected component	This note conjectures that if two surface patches intersect with G1 continuity along an entire curve, th probability is one that the curve is rational. This idea has significance for surface intersection algorithms.  2003 Elsevier B.V. All rights reserved.	algorithm;scott continuity	Thomas W. Sederberg;Jianmin Zheng;Xiaowen Song	2004	Computer Aided Geometric Design	10.1016/j.cagd.2003.07.005	intersection curve;genus;combinatorics;connected component;topology;mathematics;geometry	Graphics	35.70825492886238	23.315920212587958	6777
c773930b40e6eb6e428c69f437d2efb4f6a3e777	on the subsets of rank two in a free monoid: a fast decision algorithm (extended abstract)	free monoid;extended abstract;fast decision algorithm	Given a finite subset X of a free monoid A*, we define the rank of X as r(X)=min{|Y|: XY*}. The problem we study here, is to decide whether r(X)2 or not. We propose an O(n.ln2m) algorithm, where n stands for the sum of the lengths of the words in X, and m stands for the length of the longest word.	algorithm;free monoid	Jean Néraud	1991		10.1007/3-540-54458-5_80	free monoid;combinatorics;discrete mathematics;mathematics;monoid;algebra	Theory	35.98745007480542	35.38173721936572	6782
211df12534b1c353a754331084593dbf54924690	a simpler linear-time recognition of circular-arc graphs	recognition algorithm;consecutive ones property;circular arc model;intersection graph	We give a linear-time recognition algorithm for circular-arc graphs based on the algorithm of Eschen and Spinrad (Proceedings of the Fourth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 128–137, 1993) and Eschen (PhD thesis, 1997). Our algorithm both improves the time bound of Eschen and Spinrad, and fixes some flaws in it. Our algorithm is simpler than the earlier linear-time recognition algorithm of McConnell (Algorithmica 37(2):93–147, 2003), which is the only linear time recognition algorithm previously known.	algorithm;algorithmica;steve mcconnell;symposium on discrete algorithms;time complexity	Haim Kaplan;Yahav Nussbaum	2010	Algorithmica	10.1007/s00453-010-9432-y	combinatorics;computer science;machine learning;mathematics;intersection graph;algorithm	Theory	26.123629939872092	24.104825307452867	6785
72e077f24695f2d559f63229b4357e0b32c923cf	maximum flow in networks with a small number of random arc capacities	maximum flow	Abstract#R##N##R##N#In a directed, capacitated network with single source and sink in which the capacities of some of the arcs are random variables, the max-flow value is also a random variable. I propose a new approach to the problem of computing its distribution and expected value via a corollary of the max-flow min-cut theorem, and implement it explicitly for small numbers of random capacities. I consider the error obtained in estimating the expected max-flow value by setting some of the random capacities equal to their means. When the flows are restructed by lower bounds, I give the probability of existence of a feasible flow.	maximum flow problem	J. E. Somers	1982	Networks	10.1002/net.3230120304	random variate;random graph;maximum flow problem;mathematical optimization;combinatorics;discrete mathematics;random element;convergence of random variables;computer science;mathematics;algorithm	Theory	22.77989712202484	17.053627232809582	6789
292460648aecb65f4511381f0104d27cabe4c73d	implementation of mpeg-2 aac on 16-bit fixed-point dsp	16 bit fixed point digital signal processor advanced audio coding decoder computational complexity spectrum data fast fourier transform mpeg 2 aac decoder;digital signal processing chips audio coding codecs;codecs;mpeg 2 aac;mpeg 2 aac decoder;spectrum;spectrum data;fixed point;fast fourier transform;fixed point mpeg 2 aac dsp 16 bit;audio coding;advanced audio coding;efficient implementation;computational complexity;16 bit;advanced audio coding decoder;digital signal processing chips;fixed point digital signal processor;digital signal processing decoding transform coding costs audio coding filter bank computational complexity digital audio players sampling methods noise level;dsp	Efficient implementation of MPEG-2 advanced audio coding (AAC) decoder on low cost 16-bit fixed-point DSP needs some techniques to reduce the computational complexity. In this paper, we introduce an extra gain factor to adjust the value range of the spectrum data, and by adapting other techniques such as FFT, a low cost and high quality MPEG-2 AAC decoder is obtained	16-bit;computational complexity theory;display resolution;fast fourier transform;fixed point (mathematics);mpeg-2	Wenbin Xu;Xin Dong;Chuanzhen Li;Wenhua Yu	2006	APCCAS 2006 - 2006 IEEE Asia Pacific Conference on Circuits and Systems	10.1109/APCCAS.2006.342231	embedded system;spectrum;fast fourier transform;electronic engineering;codec;computer hardware;advanced audio coding;computer science;operating system;digital signal processing;16-bit;fixed point;computational complexity theory	EDA	11.918113088342077	42.16803356887584	6796
3fb52e3cc43dda5c927b4c602e991c438e2bfbbc	mapping an unfriendly subway system	black hole;lower bound;dynamic networks	We consider a class of highly dynamic networks modelled on an urban subway system. We examine the problem of creating a map of such a subway in less than ideal conditions, where the local residents are not enthusiastic about the process and there is a limited ability to communicate amongst the mappers. More precisely, we study the problem of a team of asynchronous computational entities (the mapping agents) determining the location of black holes in a highly dynamic graph, whose edges are defined by the asynchronous movements of mobile entities (the subway carriers). We present and analyze a solution protocol. The algorithm solves the problem with the minimum number of agents possible. We also establish lower bounds on the number of carrier moves in the worst case, showing that our protocol is also move-optimal.	algorithm;best, worst and average case;entity	Paola Flocchini;Matthew Kellett;Peter C. Mason;Nicola Santoro	2010		10.1007/978-3-642-13122-6_20	black hole;simulation;mathematics;distributed computing;upper and lower bounds	ML	18.012194930971006	34.369830774461235	6818
1f337af4d37065659b4acff26d3fd7fa9b9f62ae	computing a tree having a small vertex cover		We consider a new Steiner tree problem, called vertex-cover-weighted Steiner tree problem. This problem defines the weight of a Steiner tree as the minimum weight of vertex covers in the tree, and seeks a minimum-weight Steiner tree in a given vertex-weighted undirected graph. Since it is included by the Steiner tree activation problem, the problem admits an O(logn)-approximation algorithm in general graphs with n vertices. This approximation factor is tight up to a constant because it is NP-hard to achieve an o(logn)-approximation for the vertex-cover-weighted Steiner tree problem on general graphs even if the given vertex weights are uniform and a spanning tree is required instead of a Steiner tree. In this paper, we present constant-factor approximation algorithms for the problem with unit disk graphs and with graphs excluding a fixed minor. For the latter graph class, our algorithm can be also applied for the Steiner tree activation problem.	apx;approximation algorithm;file spanning;graph (discrete mathematics);minimum weight;np-hardness;spanning tree;steiner tree problem;time complexity;unit disk graph;vertex cover	Takuro Fukunaga;Takanori Maehara	2016		10.1007/978-3-319-48749-6_6	segment tree;euclidean minimum spanning tree;mathematical optimization;combinatorics;discrete mathematics;tree rotation;vantage-point tree;minimum degree spanning tree;spanning tree;steiner tree problem;prim's algorithm;minimum spanning tree;range tree;gomory–hu tree;k-ary tree;interval tree;k-minimum spanning tree;mathematics;tree-depth;tree structure;search tree;tree;avl tree;shortest-path tree	Theory	24.022651610751335	21.36093135833314	6829
755d9e958daf0135ca1db1bbe8c75ae2ea224d42	recognizing disguised nr(1) instances of the satisfiability problem	satisfiability	It is well known that the satisfiability problem (SAT) for Boolean expressions in conjunctive normal form (CNF) is NP-complete, and that the problem is polynomial-time solvable if each clause contains at most two literals (2~SAT) [ 1, 4, 5, 71. The satisfiability problem is also solvable in polynomial time if none of the clauses contains more than one negated variable {3, 5, 81. We call a CNF expression k-negation restricted, NR(k), if it contains at most k negated variables per clause. It is straightforward to show that NR(2)SAT is NP-complete [3]. Since NR(l)-SAT is in P, but NR(2)SAT is NP-complete, it is of interest to determine whether a given CNF expression can be transformed into an equivalent NR(1) expression with at most a polynomial increase in the length of the expression. We call a CNF expression E a disguised NR(1) expression if it can be mapped to an equivalent NR( 1) expression E’ such that, for each variable x in E, either x H x’, or x H x”, where X denotes the negation of x and i is equivalent to x. If E’ exists it is called an apparenr NR(1) version of E (we allow E’ to be identical to E). For example,	boolean expression;boolean satisfiability problem;conjunctive normal form;decision problem;karp's 21 np-complete problems;np-completeness;noise reduction;polynomial;time complexity	Bengt Aspvall	1980	J. Algorithms	10.1016/0196-6774(80)90007-3	combinatorics;discrete mathematics;mathematics;algorithm;satisfiability	Theory	6.44661604224516	19.29459404160566	6837
285d4ad3689528fb9ca736a63a2e6adf22241d07	high-speed fpga implementation of orthogonal matching pursuit for analog to information converter		Analog-to-Information Converter (AIC) based on Compressive Sensing (CS) broke the bottleneck of traditional sampling theorem. The required data is much less than the amount of data acquired by the Nyquist sampling. However, algorithms implemented in software inhibited timely decisions and prevents the use of adaptive sensing strategies. Therefore, it is necessary to achieve hardware acceleration. In this paper, we mainly proposed the complex-valued system of the signal reconstruction for the CS-based AIC structure. In order to achieve high performance and high speed hardware, we propose a superior design for inversion based on Goldschmidt algorithm. This design can double the speed of division than previous works. In addition, we have completed the functionalities on the Xilinx Virtex5 FPGA. The implementation results showed that the Orthogonal Matching Pursuit (OMP) algorithm achieved a recovery signal-to-noise-ratio (RSNR) of 21.15 dB with the clock frequency of 130.4 MHZ.	algorithm;clock rate;compressed sensing;field-programmable gate array;hardware acceleration;matching pursuit;nyquist–shannon sampling theorem;openmp;sampling (signal processing);signal reconstruction;signal-to-noise ratio	SuJuan Liu;Ning Lyu;ZiSheng Wang	2017	2017 IEEE 12th International Conference on ASIC (ASICON)	10.1109/ASICON.2017.8252434	real-time computing;matching pursuit;field-programmable gate array;electronic engineering;compressed sensing;clock rate;algorithm design;nyquist–shannon sampling theorem;computer science;signal reconstruction;hardware acceleration	EDA	12.217675877381359	44.292313582661784	6848
ae1dbcdfe02d47b88ebb8c587aaee61178b4be27	performance bounds for stochastic timed petri nets	performance measure;time petri net;concurrent systems;community networks;flexible manufacturing system;performance analysis;parallel computer;linear program;performance bounds;upper and lower bounds;computational efficiency	Stochastic timed Petri nets are a useful tool in performance analysis of concurrent systems such as parallel computers, communication networks and flexible manufacturing systems. In general, performance measures of stochastic timed Petri nets are difficult to obtain for problems of practical sizes. In this paper, we provide a method to compute efficiently upper and lower bounds for the throughputs and mean token numbers in general Markovian timed Petri nets. Our approach is based on uniformization technique and linear programming.	petri net	Zhen Liu	1995		10.1007/3-540-60029-9_47	real-time computing;stochastic petri net;computer science;linear programming;theoretical computer science;distributed computing;upper and lower bounds	Logic	6.73058962258195	14.170117984425627	6857
fc7a7adec7316c326d9fc5dcd47638fb87b469a2	a linear time algorithm for the feasibility of pebble motion on trees	linear time algorithm	We consider the following pebble motion problem. We are given a tree T with n vertices and two arrangements \(\cal R\) and \(\cal S\) of k<n distinct pebbles numbered 1, . . ., k on distinct vertices of the tree. Pebbles can move along edges of T provided that at any given time at most one pebble is traveling along an edge and each vertex of T contains at most one pebble. We are asked the following question:	algorithm;time complexity	Vincenzo Auletta;Angelo Monti;Mimmo Parente;Giuseppe Persiano	1996		10.1007/3-540-61422-2_137	combinatorics;discrete mathematics;computer science;mathematics;algorithm	Theory	28.990616732161786	22.99808402636892	6862
07d159d92d49799173a35542bcb1e29fb9c95e7d	roa-brick topology for low-skew rotary resonant clock network design	topology;clocks;oscillators;hspice roa brick topology low skew rotary resonant clock network design rotary oscillator array clock distribution network design traveling wave oscillation uniform ring rotation phase tapping point ring rotation direction phase clock signal roa clock generation ispd 10 clock benchmark;synthesis clock distribution network design resonant clock;oscillators clock distribution networks;synchronization;capacitance;structural rings;power transmission lines;oscillators clocks topology structural rings synchronization power transmission lines capacitance	This paper presents a topology-based solution for a low-skew rotary oscillator array (ROA) clock distribution network design. An ROA-brick structure is proposed that limits the traveling wave oscillation to only two uniform ring rotation directions in the ROA-brick: all the rings in clockwise (CW) direction or all the rings in counter CW direction. An ROA built from the ROA-bricks has the following advantages: 1) similar to the ROA-brick, only two uniform ring rotation directions are feasible in the ROA; 2) the same phase tapping points of all the rings in the ROA are identifiable; and 3) these same phase tapping points of the ROA are independent from the two possible rotation directions. It is mathematically proved that the ROA-brick is the only ROA structure, which can limit the ring rotation direction combinations so as to guarantee the generation of same phase clock signals. The proposed brick-based ROA clock generation and distribution networks are designed for ISPD 10 clock benchmarks demonstrating the gigahertz operation with the low-skew clock generation and distributions through HSPICE.	circuit complexity;clock network;clock signal;international symposium on physical design;network planning and design;resource-oriented architecture;rotary woofer;spice 2;simulation;token ring	Ying Teng;Baris Taskin	2015	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2014.2385835	synchronization;electronic engineering;clock angle problem;telecommunications;clock domain crossing;clock skew;computer science;engineering;electrical engineering;capacitance;clock drift;electric power transmission;synchronous circuit;oscillation	EDA	29.016127077219334	50.989643116976595	6870
7e0c1b98fe48f89ee287b546c362b3e9a7665f9b	a low-cost multi-modal sensor network for the monitoring of honeybee colonies/hives		Honeybees, which play an essential role as pollinators, have suffered a significant decline in recent years. Different types of sensors, including acoustic, chemical, vision, mass and temperature, can provide important information to assess their well-being. However, a multi-modal sensor system would need to be economical and affordable in order to be used on a large scale, including by less wealthy farmers or beekeepers. We present details of a low-cost sensor network system to allow the continuous monitoring of honeybee hives in a non-invasive manner, discussing its advantages relative to other existing systems for the same purpose, and initial results from the deployment of such a system in four hives.		Donald Howard;Olga Duran;Gordon Hunter	2018		10.3233/978-1-61499-874-7-69	software deployment;real-time computing;wireless sensor network;modal;continuous monitoring;computer science	Mobile	3.56931780249917	32.34216398306674	6871
75c5f9a3b3f49117f3d9d2853ab4dda3f499cb2b	an efficient wakeup scheduling considering resource constraint for sensor-based power gating designs	resource constraint;efficient wakeup scheduling;power gating;job shop scheduling voltage hardware surges delay sleep clocks scheduling algorithm leakage current capacitance;virtual ground voltage;surges;電源閘控;sleep;integrated circuit design;喚醒排程技術;wakeup scheduling low power leakage power power gating;transistor circuits integrated circuit design leakage currents scheduling;low power;leakage power;leakage currents;optimal scheduling;scheduling;transistors;transistor circuits;power gating designs;sleep transistors;wakeup scheduling;spice;virtual ground voltage wakeup scheduling power gating designs leakage power surge current sleep transistors;sensor based power gating designs;hardware;surge current	Power gating has been a very effective way to reduce leakage power. One important design issue for a power gating design is to limit the surge current during the wakeup process. Normally, a wakeup scheduling is required to control turn-on times of sleep transistors. In this paper, we adopt a voltage sensor to compare pre-designed reference voltages with the virtual ground voltage and use the comparison result to determine turn-on times of sleep transistors. Special properties and optimizations of using voltage sensors are discussed. Since a wakeup scheduling with fast wakeup time may require significant hardware resources, we propose a new wakeup scheduling formulation which considers the trade-off between wakeup times and hardware resources. Our experimental results show that with small increases on wakeup times, we can reduce significant hardware resources for a power gating design.	algorithm;power gating;scheduling (computing);sensor;spectral leakage;transistor;virtual ground	Ming-Chao Lee;Yu-Ting Chen;Yo-Tzu Cheng;Shih-Chieh Chang	2009	2009 IEEE/ACM International Conference on Computer-Aided Design - Digest of Technical Papers	10.1145/1687399.1687485	embedded system;electronic engineering;real-time computing;computer science;engineering;operating system;sleep;scheduling;transistor;integrated circuit design	EDA	16.327093485237786	56.56847329026923	6873
d5a3d84cb6e23e82594e69a90c9bc12c16d4a5b2	factors in graphs with odd-cycle property	condicion existencia;graphe biparti;grafo bipartido;facteur parite g f;facteur g f;cycle graphe;condition existence;cycle graph;factor grafo;facteur graphe;existence condition;bipartite graph;graph factor;propriete cycle impair;ciclo diagrama	Chen, C. and J. Wang, Factors in graphs with odd-cycle property, Discrete Mathematics 112 (1993) 29-40. We present some conditions for the existence of a (g,f)-factor or a (g,f)-parity factor in a graph G with the odd-cycle property that any two odd cycles of G either have a vertex in common or are joined by an edge. 1. Definitions and notations We consider finite graphs G with vertex set I’(G) and edge set E(G). For any UE V(G), we denote by C&(U) the degree of v in G. For any SE I’(G), we denote by G[S] the subgraph of G induced by S, and by G-S the subgraph of G obtained from G by deleting the vertices in S together with their incident edges. Similarly, for any McE(G), we write G-M for the subgraph of G obtained from G by deleting the edges in M. If S and Tare subsets of V(G), we denote by ec(S, T) the number of edges of G joining a vertex in S to a vertex in T. Write Qj(G)={O 1 UE V(G) and &(u)=j), and put qj (G)= IQj (G)I. In particular, let i(G)=qo(G), i.e. i(G) is the number of the isolated vertices of G. If G is a bipartite graph with bipartition (X, Y), then write G=(X, Y; E(G)). Let Z denote the set of nonnegative integers. Correspondence to: Ciping Chen, Department of Mathematics, Wayne State University, Detroit, MI 48202, USA *Supported by the National Science Foundation of China. 0012-365X/93/$06.00	discrete mathematics;entity–relationship model;minimum spanning tree	Ciping Chen;Jianfang Wang	1993	Discrete Mathematics	10.1016/0012-365X(93)90221-E	combinatorics;discrete mathematics;bipartite graph;cycle graph;mathematics	Theory	29.898685022977087	30.712053500207226	6875
2f8bf3576afaf9e1b316d96ac372dc9c62dd2e9b	imperfect random sources and discrete controlled processes	extremal set theory	We consider a simple model for a class of discrete control processes, motivated in part by recent work about the behavior of imperfect random sources in computer algorithms. The process produces a string of characters from {0, 1} of length <italic>n</italic> and is a “success” or “failure” depending on whether the string produced belongs to a prespecified set <italic>L</italic>. In an uninfluenced process each character is chosen by a fair coin toss, and hence the probability of success is |<italic>L</italic>|/2<supscrpt>n</supscrpt>. We are interested in the effect on the probability of success in the presence of a player (controller) who can intervene in the process by specifying the value of certain characters in the string. We answer the following questions in both worst and average case: (1) how much can the player increase the probability of success given a fixed number of interventions? (2) in terms of |<italic>L</italic>| what is the expected number of interventions needed to guarantee success? In particular our results imply that if |<italic>L</italic>|/2<supscrpt>n</supscrpt> = 1/<italic>w</italic>(<italic>n</italic>) where <italic>w</italic>(<italic>n</italic>) tends to infinity with <italic>n</italic> (so the probability of success with no interventions is o(1)) then with &Ogr;(√<italic>n</italic>log<italic>w</italic>(<italic>n</italic>)) interventions the probability of success is 1-o(1). Our main results and the proof techniques are related to a well-known theorem of Kruskal, Katona, and Harper in extremal set theory.	best, worst and average case;discrete manufacturing;extremal combinatorics;kruskal's algorithm;set theory	David Lichtenstein;Nathan Linial;Michael E. Saks	1987		10.1145/28395.28414	mathematical optimization;combinatorics;discrete mathematics;mathematics;algorithm;statistics	Theory	35.990567553212806	16.38933120432581	6889
300b43bb5ddac2c8e2ce3817b8836c7471bcc97c	on some algorithmic problems regarding the hairpin completion	context free language;regular language	It is known that a single stranded DNA molecule might produce a hairpin structure due to two biological principles, namely Watson-Crick complementarity and annealing. In many DNA-based algorithms, these DNA molecules cannot be used in the subsequent computations. Hairpin or hairpin-free DNA structures have numerous applications to DNA computing and molecular genetics. Suggested by the two aforementioned biological phenomena together with that of lengthening DNA by polymerases, we defined in [1] a new unary operation called hairpin completion. This operation might be defined informally as follows:	algorithm;complementarity theory;computation;dna computing;simulated annealing;unary operation	Victor Mitrana;Florin Manea;Carlos Martín-Vide	2006	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2006.08.061	natural language processing;regular language;computer science;mathematics;context-free language;programming language;algorithm	Theory	1.789243685069587	23.60232961073779	6901
a0ca9b30e0e686bfa4dec8c2f85080175bce7739	simple reed-solomon forward error correction (fec) scheme for fecframe		This document describes a fully-specified simple Forward Error Correction (FEC) scheme for Reed-Solomon codes over the finite field (also known as the Galois Field) GF(2^^m), with 2 <= m <= 16, that can be used to protect arbitrary media streams along the lines defined by FECFRAME. The Reed-Solomon codes considered have attractive properties, since they offer optimal protection against packet erasures and the source symbols are part of the encoding symbols, which can greatly simplify decoding. However, the price to pay is a limit on the maximum source block size, on the maximum number of encoding symbols, and a computational complexity higher than that of the Low-Density Parity Check (LDPC) codes, for instance.	block size (cryptography);computational complexity theory;forward error correction;low-density parity-check code;network packet;reed–solomon error correction	Vincent Roca;Mathieu Cunche;Jérôme Lacan;Amine Bouabdallah;Kazuhisa Matsuzono	2013	RFC	10.17487/RFC6865	erasure code;discrete mathematics;fountain code;theoretical computer science;mathematics;algorithm	Theory	40.75953656501034	57.881102980804336	6913
8adc06fb7ceb388fa349c931aa3a27fe8744d656	efficient parallel algorithm for constructing a unit triangular matrix with prescribed singular values	parallel algorithm;shared memory;distributed memory architecture;singular value;parallel implementation;numerical experiment	The problem tackled in this paper is the parallel construction of a unit triangular matrix with prescribed singular values, when these fulfill Weyl’s conditions [9]; this is a particular case of the Inverse Singular Value Problem. A sequential algorithm for this problem was proposed in [10] by Kosowsky and Smoktunowicz. In this paper parallel versions of this algorithm will be described, both for shared memory and distributed memory architectures. The proposed parallel implementation is better suited for the shared memory paradigm; this is confirmed by the numerical experiments; the shared memory version, reaches an efficiency over 90%, and reduces substantially the execution times compared with the sequential algorithm.	central processing unit;compiler;computation;data structure;directive (programming);distributed memory;experiment;multiprocessing;numerical analysis;olami–feder–christensen model;parallel algorithm;parallel computing;performance;programmer;programming paradigm;scalability;sequential algorithm;serial digital video out;shared memory;the matrix;triangular matrix	Georgina Flores Becerra;Víctor M. García;Antonio M. Vidal	2006		10.1007/978-3-540-71351-7_27	shared memory;parallel computing;computer science;theoretical computer science;operating system;distributed computing;parallel algorithm;singular value;algebra	HPC	-2.920880920847374	38.08765963392104	6915
877b3ee143dac2725870e194b5357210c99a6e76	peak load shaving model based on individual's habit	software;artificial intelligence software barium;equal interval search;equal interval search algorithm peak load shaving model smart grid energy management demand side management habit based dsm hbdsm model peak demand management markov chain;demand side management;barium;equal interval search hems demand side management habit model hbdsm markov chain;hems;habit model hbdsm;artificial intelligence;smart power grids demand side management energy management systems load shedding markov processes;markov chain	Smart Grid is supposed to play an important role in future energy management. In smart grid, Demand Side Management (DSM) is one of the main areas which is under focus of researchers in order to solve the classical problem of peak demand management. In this paper, we have proposed a Habit Based DSM (HBDSM) model for peak load shaving. Proposed method is based on individuals habit which is modeled using Markov Chain. The main focus of the work is to minimize the cost by optimizing battery consumption using Equal Interval Search algorithm in order to minimize energy consumption from the grid and so as to shave the demand curve. Simulation results prove the effectiveness of the proposed model.	grid computing;load profile;markov chain;search algorithm;simulation	Hifsa Ashraf;Ahmad Hassan;Usman Khurshid;Anzar Mahmood;Nusrat Shaheen;Zahoor Ali Khan;Umar Qasim;Nadeem Javaid	2015	2015 Ninth International Conference on Complex, Intelligent, and Software Intensive Systems	10.1109/CISIS.2015.94	simulation;engineering;operations management;operations research	Robotics	4.303904496568504	5.162704291953433	6917
3c82ddc4d533f8363bd008c0f00ad3c69c51370b	a note on the gap between rank and border rank	algebraic complexity theory;15a69;quantum information theory;68q17;w state;tensor rank;16z05;border rank	We study the tensor rank of a certain algebra. As a result we find a sequence of tensors with a large gap between rank and border rank, and thus a counterexample to a conjecture of Rhodes. We also obtain a new lower bound on the tensor rank of powers of the generalized W-state.	w state	Jeroen Zuiddam	2015	CoRR	10.1016/j.laa.2017.03.015	tensor product;rank of an abelian group;symmetric tensor;combinatorics;discrete mathematics;quantum information;w state;rank;tensor field;tensor;ricci decomposition;cartesian tensor;tensor;tensor contraction;tensor product of algebras;mathematics;tensor density;tensor product of hilbert spaces;tensor product of modules;algebra	Theory	41.75843064616023	32.84546804639758	6939
b24a5510efc0fce71670605b72a98148cd2f954d	"""description of an extension of the matrix package of : 20reduce"""""""	matrix subprogram;matrix manipulation;matrix package;basic algebraic operation;restrictive possibility;algebraic mode	Matrix manipulations in REDUCE [1] are governed by a matrix subprogram made by HEARN which works nicely but gives too restrictive possibilities to the user working exclusively in the algebraic mode. Specifically, apart from the basic algebraic operations, one has the possibilities to compute the inverse, the transpose, the determinant and the trace of a matrix.	reduce;subroutine;the matrix	Hubert Caprasse	1986	ACM SIGSAM Bulletin	10.1145/14956.14957	discrete mathematics;matrix of ones;mathematics;state-transition matrix;block matrix;transpose;algebra	AI	51.37947566448223	39.15672759683647	6948
a9c6c2d196bbb900fac0d30442cd53763b83b44a	conflict-free coloring of points on a line with respect to a set of intervals	conflict free coloring;approximation algorithms;frequency assignment	We present approximation algorithms for CF-coloring of points on a line with respect to a given set of intervals. For the restricted case where no two intervals have a common right endpoint, we present a 2-approximation algorithm, and, for the general case where intervals may share a right endpoint, we present a 4-approximation algorithm. The running time of both algorithms is O ( n log n ) .	algorithm;time complexity	Matthew J. Katz;Nissan Lev-Tov;Gila Morgenstern	2007	Comput. Geom.	10.1016/j.comgeo.2012.01.013	mathematical optimization;combinatorics;discrete mathematics;mathematics;approximation algorithm	Theory	24.56959172193107	22.13224979444902	6958
2d8a6a196a8a0bb2327ec59e413d2623895d4bf9	understanding microprocessors: rich, l, prentice-hall, hemel hempstead, uk (1981) pp 296, £11.65			microprocessor	Ian R. Whitworth	1981	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(81)90410-5	parallel computing;computer science;electrical engineering	EDA	6.217627923673965	50.35148695992414	6959
a73ba50f567fb8641a4669eeba346c3d18520e32	a quadratic algorithm for finding next-to-shortest paths in graphs	next to shortest paths;strictly second shortest paths;graph algorithms	Given an edge-weighted undirected graph G and two prescribed vertices u and v, a next-to-shortest (u,v)-path is a shortest (u,v)-path amongst all (u,v)-paths having length strictly greater than the length of a shortest (u,v)-path. In this paper, we deal with the problem of computing a next-to-shortest (u,v)-path. We propose an ${\mathcal{O}}(n^{2})$ time algorithm for solving this problem, which significantly improves the bound of a previous one in ${\mathcal{O}}(n^{3})$ time where n is the number of vertices in G.	algorithm;graph (discrete mathematics);integrated circuit layout design protection;shortest path problem;time complexity;vertex (geometry)	Kuo-Hua Kao;Jou-Ming Chang;Yue-Li Wang;Justie Su-tzu Juan	2010	Algorithmica	10.1007/s00453-010-9402-4	combinatorics;discrete mathematics;machine learning;mathematics;shortest-path tree	Theory	23.366409453215134	21.542166972891508	6960
9fe160ca0c8962e12f99bed69d355a2b7f12ddcc	research on the maximum flow in large-scale network	granular computing;scientific application;optimisation;complex networks;algorithm design and analysis approximation algorithms contracts complexity theory educational institutions computer science complex networks;approximate algorithm;complexity theory;maximum flow;approximation algorithms;complex network;combinatorial optimization problem;contracts;operations research;optimisation combinatorial mathematics complex networks computational complexity network theory graphs;large scale;maximal clique;computational complexity;computer science;short period;network theory graphs;maximal clique large scale network maximum flow problem combinatorial optimization problem computer science operational research computational complexity granular computing;maximal clique granular computing complex network maximum flow;combinatorial mathematics;algorithm design;algorithm design and analysis	This article covers a problem that often arises in real life situations-the maximum flow problem. This problem is a classical combinatorial optimization problem, which arises in many engineering and scientific applications. It is also the important content of computer science and operational research. In order to reduce computational complexity, many improvement methods have been proposed. In this paper, applying the thought of granular computing and combining the maximal clique, a new method is proposed to solve the approximately maximum flow problem in complex and large-scale network. By contracting the appropriate maximal clique in the network, we can calculate approximate maximum flow much more efficiently. Experimental results demonstrate that the algorithm we proposed can be used to compute approximate maximum flow in a relatively short period of time and also provide a new approach to the study on the maximum flow problem.	approximation algorithm;clique (graph theory);combinatorial optimization;computational complexity theory;computer science;flow network;granular computing;mathematical optimization;maximal set;maximum flow problem;operations research;optimization problem;real life	Yanping Zhang;Bo Hua;Juan Jiang;Yuan Zhang;Xiaoyan Chen	2011	2011 Seventh International Conference on Computational Intelligence and Security	10.1109/CIS.2011.113	computational problem;algorithm design;mathematical optimization;combinatorics;flow network;circulation problem;maximum coverage problem;minimum-cost flow problem;multi-commodity flow problem;granular computing;computer science;theoretical computer science;machine learning;mathematics;maximum common subgraph isomorphism problem;complex network;algorithm	AI	20.688245766311695	18.403058609831383	6973
13b9606992a3c7e9956fd04ca1e284667a9e9b16	extreme points of some families of non-additive measures	additivity;multiple criteria analysis;multicriteria analysis;additivite;investigacion operativa;analisis decision;vertices;algoritmo genetico;decision analysis;p symmetry;programacion lineal;complexity measure;extreme point;mesure complexite;aditividad;linear programming;algorithme genetique;programmation lineaire;linear program;algorithms;genetic algorithm;k additivity;analisis multicriterio;analyse multicritere;non additive measures;analyse decision;medida complexidad;mesure non additive;convex combination	Non-additive measures are a valuable tool to model many different problems arising in real situations. However, two important difficulties appear in their practical use: the complexity of the measures and their identification from sample data. For the first problem, additional conditions are imposed, leading to different subfamilies of non-additive measures. Related to the second point, in this paper we study the set of vertices of some families of non-additive measures, namely k-additive measures and p-symmetric measures. These extreme points are necessary in order to properly apply a new method of identification of non-additive measures based on genetic algorithms, whose cross-over operator is the convex combination. We solve the problem through techniques of Linear Programming. 2005 Elsevier B.V. All rights reserved.	existential quantification;genetic algorithm;linear programming;matrix representation;the matrix;utility functions on indivisible goods;vertex (geometry);vertex (graph theory)	Pedro Miranda;Elías F. Combarro;Pedro Gil	2006	European Journal of Operational Research	10.1016/j.ejor.2005.03.005	vertex;extreme point;mathematical optimization;combinatorics;genetic algorithm;convex combination;linear programming;mathematics;additive function	Theory	26.460009359378613	11.481068877436222	6986
a389971ffb3c6d07fdd94c32845dd314c8eb9b3c	realization methods for asynchronous sequential circuits	built in delays;fundamental mode circuits;asynchronous sequential circuits built in delays fundamental mode circuits realization methods speed independent operation;sequential circuits;satisfiability;speed independent;realization methods;asynchronous sequential circuits;speed independent operation	This paper gives a unified approach for describing various systematic ways of using built-in delays in normal fundamental mode circuits. The transition of the circuit from one total stable state to another is characterized by the constraints imposed upon the next-state functions, and the realization method is characterized by the conditions under which these constraints can be satisfied simultaneously.	normal mode	Gyula A. Magó	1971	IEEE Transactions on Computers	10.1109/T-C.1971.223233	real-time computing;control theory;mathematics;sequential logic;satisfiability	EDA	22.636637841000343	46.955276678935796	7008
4300fbae9e3a72e5383976a2f595b1c742c62561	representations of signals (corresp.)	first page	The purpose of this correspondence is to show that graph theoretic codes are threshold, or more specifically, majority decodable.lrl In a forthcoming paper, we intend to present a rather complete study of graph theoretic codes, their efficiency, their error correcting capability, their limitations, and their generalizations. It has been shown that the circuit matrix (or cut-set matrix) of a linear graph G generates a binary linear code of distance d and length n an (n, d) code-where n is the number of branches in G and,d is the minimum number of branches in a circuit (or a	graph theory;linear code	M. M. Crum	1967	IEEE Trans. Information Theory	10.1109/TIT.1967.1053984	discrete mathematics;combinatorics;computer science	Theory	39.31735970699515	51.015182090083485	7014
49cf04dd02e0714d177f5ee2ad3ac7757348dcdc	algorithmes pour l'étude des solutions réelles des systèmes polynomiaux	systemes polynomiaux;calcul formel;real roots;polynomial systems;computer algebra;zeros reels	This presentation summarizes a set of general methods for solving systems of polynomial equations (with or without inequalities), mainly centered on the study of their real roots; The main subject is the “resolution” of systems with an arbitrary number of solutions (finite or infinite), depending or not on parameters. Since the field is vast, one constrains it by imposing it that the algorithms are exact or certified or, in other words, that the results are never ambiguous from the user’s point of view (number or structure of the solutions, numerical approximations when it makes sense, real character of the solutions, etc.). The exposed work was carried out with two principal objectives: to progress in the development of useful effective methods in real geometry, but especially to propose some credible alternatives to the standard tools for scientific computations, with the objective of answering to some open problems (or considered difficult) in various applications. This assessment of several years of work is, in particular, the occasion to show the specific efforts which seem to be necessary to obtain convincing results (efficient implementations, cost of the certification/exactness, balance between theoretical and practical efficiency, etc.) and is articulated around some selected applications which justify the main theoretical, algorithmic but also technical	algebraic equation;algorithm;approximation;coefficient;computation;espace;electroconvulsive therapy;emoticon;estdomains;fractal dimension;general motors en-v;generative grammar;holographic principle;large eddy simulation;linear algebra;list of minor characters in the matrix series;maximal set;modulo operation;numerical analysis;power dividers and directional couplers;quel;r.u.r.;rouge (metric);robot;sans institute;silicon on insulator;sturm's theorem;system of polynomial equations;variable (computer science)	Fabrice Rouillier	2007			mathematical economics;philosophy	Theory	49.323988905189786	34.163721493159706	7021
2ba32f0b121d1e3e16bb858cfa990345b332d192	bin packing		In the bin packing problem, we get a sequence of packets of size r 1 ; r 2 ; r 3 ; : : :, each r i 1, and we must place the packets into bins of size 1 using as few bins as possible. The size of a bin is the accumulated size of all packets in the bin, and the free capacity of a bin is 1 minus its size.	bin packing problem;set packing	David S. Johnson	2008		10.1007/978-0-387-30162-4_49		Theory	17.40455917433587	14.175638481380577	7054
21a138e5d7f4bdfbdad338d86c64b10fc432e652	linear index coding via graph homomorphism	encoding computational complexity directed graphs;indexes encoding vectors computational complexity receivers educational institutions color;np complete linear index coding graph homomorphism minimum broadcast rate algebraic invariant undirected graph vertex transitive digraph computational complexity scalar linear index;computational complexity of the minrank index coding linear index coding graph homomorphism minrank of a graph	In [1], [2] it is shown that the minimum broadcast rate of a linear index code over a finite field Fq is equal to an algebraic invariant of the underlying digraph, called minrankq. In [3], it is proved that for F2 and any positive integer k, minrankq(G) ≤ k if and only if there exists a homomorphism from the complement of the graph G to the complement of a particular undirected graph family called “graph family {Gk}”. As observed in [2], by combining these two results one can relate the linear index coding problem of undirected graphs to the graph homomorphism problem. In [4], a direct connection between linear index coding problem and graph homomorphism problem is introduced. In contrast to the former approach, the direct connection holds for digraphs as well and applies to any field size. More precisely, in [4], a graph family {Hkq} has been introduced and shown that whether or not the scalar linear index of a digraph G is less than or equal to k is equivalent to the existence of a graph homomorphism from the complement of G to the complement of Hkq. In this paper, we first study the structure of the digraphs Hkq defined in [4]. Analogous to the result of [2] about undirected graphs, we prove that Hkq are vertex transitive digraphs. Using this, and by applying a lemma of Hell and Nesetril [5], we derive a class of necessary conditions for digraphs G to satisfy lindq(G) ≤ k. Particularly, we obtain new lower bounds on lindq(G). Our next result is about the computational complexity of scalar linear index of a digraph. It is known that deciding whether the scalar linear index of an undirected graph is equal to k or not is NP-complete for k ≥ 3 and is polynomially decidable for k = 1, 2 [3]. For digraphs, it is shown in [6] that for the binary alphabet, the decision problem for k = 2 is NP-complete. We use graph homomorphism framework to extend this result to arbitrary alphabet.	computational complexity theory;decision problem;directed graph;graph (discrete mathematics);graph homomorphism;isogonal figure;linear algebra;multigraph;np-completeness	Javad B. Ebrahimi;Mahdi Jafari Siavoshani	2014	2014 International Conference on Control, Decision and Information Technologies (CoDIT)	10.1109/CoDIT.2014.6996886	graph power;petersen graph;combinatorics;clique graph;discrete mathematics;graph bandwidth;null graph;degree;median graph;distance-regular graph;simplex graph;comparability graph;mathematics;voltage graph;graph;windmill graph;graph homomorphism;butterfly graph;complement graph;line graph;string graph;strength of a graph;circulant graph;algebra	Theory	32.43123487446192	37.88824487497967	7056
7bc289389d7dbe9367aff8f5bf6400730e4cfc3c	covering finite groups by subset products				H. V. Chen;A. Y. M. Chin	2017	Ars Comb.		mathematics;discrete mathematics;combinatorics	Theory	46.85356240328005	30.626747660205073	7062
8ddd5df2931f5cad372792eb1f320cd229d68dcb	integrating direct and indirect load control for congestion management in lv networks		With the energy transition, capacity challenges are expected to occur more frequently in low-voltage (LV) distribution networks. In the literature, several direct and indirect load control methods have been suggested as solutions to alleviate network congestion. Direct methods involve the network operator directly controlling appliances at the households, while indirect methods aim to motivate end-users to shift their consumption through price changes. In this research, the direct and indirect methods are combined into an integrated approach, making use of the advantages of both methods. An agent-based architecture is adopted so that distributed and computational intelligence can be combined to ensure a smooth coordination among the actors. A sensitivity- based curtailment scheme is used to incorporate the unbalanced loading condition of the LV networks. The efficiency of the proposed integrated approach is investigated through simulations in the unbalanced IEEE European LV test feeder. Simulation results reveal up to 94\% reduction in congestion by the integrated approach, while maintaining the required levels of supply in the network.		Niyam Haque;Michiel Nijhuis;Gu Ye;P. H. Nguyen;Frits Bliek;J. Chris Slootweg	2018	2018 IEEE Power & Energy Society General Meeting (PESGM)	10.1109/TSG.2017.2751743	engineering;control engineering;operator (computer programming);demand response;network congestion;energy transition;direct methods;computational intelligence;dynamic pricing;load management	HPC	2.8115585878728138	5.389458381612503	7065
4abce3c736806fcf5889ba36d496f6b1796109ff	packing squares into a square	bin packing;multiprocessor;probleme np complet;resource allocation;sistema informatico;espacio 2 dimensiones;computer system;probleme combinatoire;problema combinatorio;two dimensional space;scheduling;ordonamiento;espace 2 dimensions;problema np completo;systeme informatique;asignacion recurso;combinatory problem;multiprocesador;allocation ressource;article;ordonnancement;np complete problem;multiprocesseur	Abstract   The problem of determining whether a set of rectangles can be orthogonally packed into a larger rectangle has been studied as a geometric packing problem and as a floor planning problem. Recently, there is some renewed interest in this problem, as it is related to a job scheduling problem in a partitionable mesh connected system. In this paper we show that the problem of deciding whether a set of squares can be packed into a larger square is strongly NP-complete, answering an open question posed by Li and Cheng.	set packing	Joseph Y.-T. Leung;Tommy W. Tam;C. S. Wong;Gilbert H. Young;Francis Y. L. Chin	1990	J. Parallel Distrib. Comput.	10.1016/0743-7315(90)90019-L	mathematical optimization;combinatorics;two-dimensional space;bin packing problem;multiprocessing;set packing;np-complete;resource allocation;computer science;cutting stock problem;operating system;mathematics;scheduling;algorithm;square packing in a square	HPC	18.02835944081936	11.941675002838634	7080
77461e18e291cff5e8fe807ea8a78bd6b8d2775e	a concrete final coalgebra theorem for zf set theory	electronic mail;set theory;zermelo fraenkel;theorem prover;logic in computer science;basic research;research funding	A special final coalgebra theorem, in the style of Aczel’s [2], is proved within standard Zermelo-Fraenkel set theory. Aczel’s AntiFoundation Axiom is replaced by a variant definition of function that admits non-well-founded constructions. Variant ordered pairs and tuples, of possibly infinite length, are special cases of variant functions. Analogues of Aczel’s Solution and Substitution Lemmas are proved in the style of Rutten and Turi [12]. The approach is less general than Aczel’s, but the treatment of non-well-founded objects is simple and concrete. The final coalgebra of a functor is its greatest fixedpoint. The theory is intended for machine implementation and a simple case of it is already implemented using the theorem prover Isabelle [10]. ? Thomas Forster alerted me to Quine’s work. Peter Aczel and Andrew Pitts offered considerable advice and help. Daniele Turi gave advice by electronic mail. I have used Paul Taylor’s macros for commuting diagrams. K. Mukai commented on the text. Research funded by the ESPRIT Basic Research Action 6453 ‘Types.’	automated theorem proving;diagram;email;initial algebra;isabelle;ordered pair;quine (computing);turi;walter pitts;zermelo–fraenkel set theory	Lawrence C. Paulson	1994		10.1007/3-540-60579-7_7	discrete mathematics;computer science;artificial intelligence;mathematics;automated theorem proving;programming language;algorithm;set theory	Theory	-4.0978462161046005	12.107050289109212	7081
7954e802e53cfe480955cc6b4a75545ac59603ef	vlsi training - an integral part of the silicon broker concept			very-large-scale integration	Jim Lipman	1982			theoretical computer science;very-large-scale integration;silicon;computer science	Vision	9.048521441139464	50.395883944796495	7095
d2c414eadfbb226099dc518fe3263639de3d49c0	improved bounds for poset sorting in the forbidden-comparison regime		We study the classical problem of sorting when comparison between certain pair of elements are forbidden. Along with the set of elements V, the input to our problem is an undirected graph G(V, E), whose edges represent the pairs that can be directly compared in constant time. We call this the comparison graph. It is also possible that the set of elements forms a partial-order, and not a total-order in which case, the sorting problem is the problem of determining all possible relations in the partial order, i.e. determining the (transitive) orientations of the edges of the graph.	sorting	Arindam Biswas;Varunkumar Jayapaul;Venkatesh Raman	2017		10.1007/978-3-319-53007-9_5	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	32.737881965419575	29.995092069265485	7104
fc050f691476bb20f7476c19818bb1b669961c5f	on terminating and non-terminating q-gauss hypergeometric series distributions and the associated q-orthogonal polynomials	inverse q hypergeometric distribution;q gauss hypergeometric series distributions;q hypergeometric distribution;q hahn and big q jacobi orthogonal polynomials;negative and inverse negative q hypergeometric distributions;q factorial moments;birth abort death processes;q hahn and big q jacobi processes	In this paper, we establish the families of terminating and n on-terminatingq-Gauss hypergeometric series discrete distributions and we associate t hem with defined classes of generalized qHahn and bigq-Jacobi orthogonal polynomials, respectively. Also, we gi ve theq-factorial moments and the usual moments for these two families of q-Gauss hypergeometric series distributions. Moreover, we present their probabilistic interpretation as q-steady-state distributions from Markov chains and we designate the generalized q-Hahn processes and generalized big q-Jacobi processes emerged by theseq-Markov chains. As special cases the q-hypergeometric, the negative q-hypergeometric distributions and their inverses are presented.	divergence (computer science);jacobi method;markov chain;newman's lemma;polynomial ring;steady state	A. Kyriakoussis;Malvina Vamvakari	2012	Fundam. Inform.	10.3233/FI-2012-698	hypergeometric function of a matrix argument;lauricella hypergeometric series;combinatorics;mathematical analysis;frobenius solution to the hypergeometric equation;hypergeometric function;generalized hypergeometric function;appell series;bilateral hypergeometric series;hypergeometric identity;hahn polynomials;mathematics;basic hypergeometric series;confluent hypergeometric function;barnes integral;algebra	Theory	43.5576878486654	12.219124355832495	7115
d22784fc8adda29b108d2871b8d9f333005af337	a novel hardened design of a cmos memory cell at 32nm	power supplies;size 32 nm;cmos integrated circuits;random access memory;hardening;hardening design;simulation;nano cmos hardening soft error tolerance memory;cmos memory cell;circuit stability;read operations;static stability;size 32 nm cmos memory cell hardening design write operations read operations static stability pull down transistors hardened memory cell soft error tolerance;radiation hardening electronics cmos memory circuits;nano cmos;pull down transistors;cmos memory circuits;write operations;capacitors;transistors;soft error tolerance;radiation hardening electronics;cmos technology circuit stability capacitance random access memory circuit simulation delay integrated circuit technology voltage latches capacitors;high performance;soft error;hardened memory cell;memory	This paper proposes a new design for hardening a CMOS memory cell at the nano feature size of 32nm. By separating the circuitry for the write and read operations, the static stability of the proposed cell configuration increases more than 4.4 times at typical process corner, respectively compared to previous designs. Simulation shows that by appropriately sizing the pull-down transistors, the proposed cell results in a 40% higher critical charge and 13% less delay than the conventional design. Simulation results are provided using the predictive technology file for 32nm feature size in CMOS to show that the proposed hardened memory cell is best suited when designing memories for both high performance and soft error tolerance.	cmos;electronic circuit;error-tolerant design;gnu nano;memory cell (binary);nonvolatile bios memory;norm (social);simulation;soft error;transistor	Sheng Lin;Yong-Bin Kim;Fabrizio Lombardi	2009	2009 24th IEEE International Symposium on Defect and Fault Tolerance in VLSI Systems	10.1109/DFT.2009.18	longitudinal static stability;embedded system;electronic engineering;hardening;capacitor;soft error;computer hardware;computer science;engineering;memory;cmos;transistor	Arch	17.581277118817425	59.46153707750228	7121
5cd697bc5231d3e6e0236efe1a9dee3f1ff73580	a practical approach to simulation of electrical peak demand levelling in industry			simulation	M. Pegan;M. Bizjak;Z. Marinsek	1995			automotive engineering;levelling;mechanical engineering;peak demand;engineering	Vision	3.6178293776039046	8.646266637147642	7130
2e0a883a096ac52da8fd2f73e9aaccf9264596f8	radius, diameter, and minimum degree	graph theory;teoria grafo;theorie graphe;diameter;connected graph;radius;characterization;caracterisation;graphe connexe;caracterizacion;minimum degree;grafico connexo	We give asymptotically sharp upper bounds for the maximum diameter and radius of (i) a connected graph, {ii) a connected trangle-free graph, (iii) a connected C,-free graph with n vertices and with minimum degree 6, where n tends to infinity. Some conjectures for J&-free graphs are also stated. Let G be a connected graph with vertex set V(G) and edge set E(G). For any XJJ E V(G) let dG(x,y) denote the distance between x and y, i.e., the minimum length of an x-y path in G. The diameter and the radius of G are defined as The following theorem answers a question of Gallai [6]. THEOREM 1. Let G be a connected graph M*ith n vertices and with minimum degree 6 2 2. Then (ii) diam G< &-1.	connectivity (graph theory);random graph;vertex (geometry);vertex (graph theory)	Paul Erdös;János Pach;Richard Pollack;Zsolt Tuza	1989	J. Comb. Theory, Ser. B	10.1016/0095-8956(89)90066-X	k-edge-connected graph;combinatorics;discrete mathematics;topology;degree;distance-regular graph;connectivity;graph theory;radius;diameter;path graph;mathematics;k-vertex-connected graph	Theory	26.17390445881961	30.572941505469203	7140
5a9af5f6ccda25a3ddc7986c85899b7f4ba3a05c	evolutionary digital circuit design using genetic programming	genetic program;input output;evolutionary process;digital circuits;data flow;logic gate	In this chapter, we study two different circuit encodings used for digital circuit evolution. The first approach is based on genetic programming, wherein digital circuits consist of their data flow based specifications. In this approach, individuals are internally represented by the abstract trees/DAG of the corresponding circuit specifications. In the second approach, digital circuits are thought of as a map of rooted gates. So individuals are represented by twodimensional arrays of cells. Each of these cells consists of the logic gate name together with the corresponding input signal names as the name of the output signal is fixed. Furthermore, we compare the impact of both individual representations on the evolution process of digital circuits. Evolved circuits should minimise space and time requirements. We show that for the same input/output behaviour, employing either of these approaches yields circuits of almost the same characteristics in terms of space and response time. However, the evolutionary process is much shorter with the second encoding.	genetic programming;integrated circuit design	Nadia Nedjah;Luiza de Macedo Mourelle	2006		10.1007/3-540-32498-4_7	electronic engineering;asynchronous circuit;computer science;theoretical computer science;algorithm	EDA	15.698552967752109	46.859508690508015	7141
0437d5bac449331fd57528544a2a4ac4c899c4d3	matching preclusion for k-ary n-cubes with odd k ≥ 3		The matching preclusion number of a graph is the minimum number of edges whose deletion results the remaining graph that has neither perfect matchings nor almost perfect matchings. In this paper, we prove that the matching preclusion number of k-ary n-cubes is 4n − 1 except k = 3 and n = 2, where k is odd and k ≥ 3. © 2017 Elsevier B.V. All rights reserved.	holographic principle;matching preclusion;olap cube	Xiaomin Hu;Bin Zhao;Yingzhi Tian;Jixiang Meng	2017	Discrete Applied Mathematics	10.1016/j.dam.2017.06.001		Theory	26.768182943950272	27.957763411965363	7177
f06e96896dfb2699dd03d33b77aa79dbb6b5868d	two families of low-correlated binary sequences	binary sequence;cross correlation	We apply a recent construction of binary Kerdock and Delsarte-Goethals codes in a cyclic form to construct good sequences with low cross-correlation.	code;cross-correlation	Alexander Barg	1996	Applicable Algebra in Engineering, Communication and Computing	10.1007/BF01293261	cross-correlation;pseudorandom binary sequence;mathematics;statistics	DB	41.95772126012677	48.124916601859645	7180
40fb14ce84e1f1f774de99cae59a06713f5f4155	parallel k-means++ for multiple shared-memory architectures	openmp data clustering gpgpu multithreaded architecture;data clustering;gpgpu;k means clustering parallel k means shared memory architectures parallelization exact k means algorithm correctness proof multicore cpu high performance gpu multithreaded cray xmt platform visual approach data sizes graphics processing unit;graphics processing units;multicore processing;multithreaded architecture;openmp;clustering algorithms;shared memory systems graphics processing units memory architecture multi threading parallel processing pattern clustering;probabilistic logic;algorithm design and analysis;clustering algorithms graphics processing units probabilistic logic multicore processing instruction sets algorithm design and analysis;instruction sets	In recent years k-means++ has become a popular initialization technique for improved k-means clustering. To date, most of the work done to improve its performance has involved parallelizing algorithms that are only approximations of k-means++. In this paper we present a parallelization of the exact k-means++ algorithm, with a proof of its correctness. We develop implementations for three distinct shared-memory architectures: multicore CPU, high performance GPU, and the massively multithreaded Cray XMT platform. We demonstrate the scalability of the algorithm on each platform. In addition we present a visual approach for showing which platform performed k-means++ the fastest for varying data sizes.	algorithm;approximation;central processing unit;cluster analysis;correctness (computer science);cray xmt;fastest;graphics processing unit;k-means clustering;k-means++;multi-core processor;parallel computing;scalability;shared memory;thread (computing)	Patrick Mackey;Robert R. Lewis	2016	2016 45th International Conference on Parallel Processing (ICPP)	10.1109/ICPP.2016.18	computer architecture;parallel computing;computer science;theoretical computer science;operating system;cluster analysis	HPC	-1.9456398411734244	43.06749955359446	7192
00ba403198e24e917ca09c4b8f95aa949c6da65d	an auction based pre-processing technique to determine detour in global routing	significant improvement;congestion elimination;network routing;detour algorithm;auction;pre-processing technique;technology cad (electronics);new preprocessing framework;congested global routing location;congestion elimination process;consistent congestion elimination;global routing;interval overflow lower bound technique;reroute framework;global router;fpga;integrated circuits;fault tolerance;mathematical model;lower bound;cost function;routing	Global Routing has been a traditional EDA problem. It has congestion elimination as the first and foremost priority. Despite of the recent development for popular rip-up and reroute framework, the congestion elimination process remains arbitrary and requires significant tunings. In order to achieve more consistent congestion elimination, we propose a new preprocessing framework for global routing. In the framework, we first identify the most congested global routing locations by an interval overflow lower bound technique. Then we use auction based detour algorithm to compute which nets and where to detour. The framework can be applied to any global router and would help them to achieve significant improvement in both solution quality and runtime.	algorithm;foremost;network congestion;preprocessor;router (computing);routing	Yue Xu;Chris C. N. Chu	2010	2010 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)		mathematical optimization;routing;real-time computing;computer science;theoretical computer science;distributed computing	EDA	15.72470681056674	52.467108841071045	7203
4c9f336026ceff03a3e90a2fa81b0c66e144be53	analysis of an open non-markovian gi - (gi | ∞) k  queueing network with high-rate renewal arrival process	multivariate normal distribution;k queueing network;multivariate distribution;open non-markovian;unlimited number;arbitrary service policy;queueing network;markovian routing;high-rate renewal arrival process;busy server;arrival rate;network node	Abstract—We analyze an open non-Markovian queueing network with high-rate renewal arrival process, Markovian routing, arbitrary service policy, and unlimited number of servers at nodes. We obtain mean values for the number of busy servers at nodes of the queueing network in question. We show that, under an infinitely increasing arrival rate, the multivariate distribution of the number of busy servers at network nodes can be approximated by a multivariate normal distribution; we find parameters of this distribution.	approximation algorithm;queueing theory;routing	Anatoly A. Nazarov;Alexander N. Moiseev	2013	Probl. Inf. Transm.	10.1134/S0032946013020063	arrival theorem;layered queueing network;markovian arrival process	Metrics	8.620288569740056	11.604317053616537	7204
8f419f0907e24767a4edf37e60354b3783f2c613	conveyor merges in zone picking systems: a tractable and accurate approximate model		Sequential zone picking systems are popular conveyor-based picker-to-parts order picking systems that divide the order picking area in work zones. When designing a zone picking system, it is important to know whether the throughput capability of the system can meet customer demand. However, the performance and maximum throughput capability of a zone picking system is largely determined by congestion and blocking that occur at the various conveyor merges in the system. In this paper we develop an analytical model to study the impact of conveyor merges in sequential zone picking systems. Because of finite buffers, blocking, recirculation, and merging, the resulting queueing model does not have a product-form stationary queue-length distribution which makes exact analysis practically infeasible. Therefore, we develop an approximate solution by using an aggregation technique and matrix-geometric methods to study the throughput capability of the system. The model is suitable to support rapid design of complex zone picking systems, in terms of number and length of zones, input and output buffer capacities, and storage allocation of products to zones to meet prespecified performance targets. Comparison of the approximation results to simulation show that for a wide range of parameters the mean relative error in the system throughput is typically less than 5%. The model accurately predicts the loss in throughput due to congestion and blocking at the merges, and can be used to allocate input and output buffer spaces to maximize the throughput capability of the system.		Jelmer P. van der Gaast;René M. B. M. de Koster;Ivo J. B. F. Adan	2018	Transportation Science	10.1287/trsc.2017.0782	mathematical optimization;mathematics;throughput;merge (version control);input/output;queueing theory;order picking;approximation error	Logic	9.140140107026333	8.262154946226138	7211
bf92349c6d564242d2e9f658303a1ca7f09b7645	the asic implementation of sm3 hash algorithm for high throughput			algorithm;application-specific integrated circuit;hash function;throughput	Xiaojing Du;Shuguo Li	2016	IEICE Transactions		high-throughput screening;computer architecture;parallel computing;hash function;computer science;operating system	DB	7.765328314326017	46.84205217003395	7226
6431f26a70eb2a3cf0da3ee31b547c15123d6eb4	on a tiling problem of r.b. eggleton		A tiling of the plane with polygonal tiles is said to be strict if any point common tcl two tiles is a vertex of both or a vertex of neither. A triangle is said tc> be rational if its sides have rational length. Recently R.B. Eggleton asked if it is pos+le to strictly tile the plane <with rational triangles us@ preci.sely one triangle from each congruence clas\. In this paper we cDnstructivelv prove the existence of such a tiling by a suitable modification of the technique !qgested by E_g@et#n. The theory of rational points on elliptic curves, in parricular,‘the Nageil-Lutz theorem. plays a crucial role in completing the proof. .	congruence of squares;jack lutz;tcl;tiling window manager;vertex (graph theory)	Carl Pomerance	1977	Discrete Mathematics	10.1016/0012-365X(77)90007-3	combinatorics;discrete mathematics;topology;integer triangle;square tiling;mathematics;trihexagonal tiling	Theory	34.05204186421964	25.43948598884547	7246
3279f5ab71f965026af40367bf31031cdecc02ca	the equivalence of generalized hölder and cesáro matrices		Abstract   We show that the generalized Holder and Cesaro matrices of order  α  > −1 are equivalent. We also show that the corresponding is true for doubly infinite generalized Holder and Cesaro matrices.	turing completeness	F. Aydin Akgun;B. E. Rhoades	2012	Applied Mathematics and Computation	10.1016/j.amc.2011.12.027	combinatorics;mathematical analysis;discrete mathematics;mathematics	Robotics	45.23604524010071	33.3311940633086	7284
8486d3c6fc783bb2eb078d655fbb94f6b8efaa82	power laws for monkeys typing randomly: the case of unequal probabilities	unequal probability power laws monkeys typing randomly rank frequency distribution rational log ratios analytic information theory analytic number theory;keyboards;mathematics;probability;history;analytic information theory;lognormal distribution;complexity analysis;computer aided software engineering history keyboards information analysis information theory natural languages internet psychology mathematics frequency;natural languages;psychology;probability rational functions information theory number theory;rational log ratios;number theory;analytic number theory;computer aided software engineering;internet;power laws;monkeys typing randomly;rank frequency distribution;power law;rational functions;unequal probability;frequency;information analysis;information theory	An early result in the history of power laws, due to Miller, concerned the following experiment. A monkey types randomly on a keyboard with N letters (N>1) and a space bar, where a space separates words. A space is hit with probability p; all other letters are hit with equal probability (1-p)/N. Miller proved that in this experiment, the rank-frequency distribution of words follows a power law. The case where letters are hit with unequal probability has been the subject of recent confusion, with some suggesting that in this case the rank-frequency distribution follows a lognormal distribution. We prove that the rank-frequency distribution follows a power law for assignments of probabilities that have rational log-ratios for any pair of keys, and we present an argument of Montgomery that settles the remaining cases, also yielding a power law. The key to both arguments is the use of complex analysis. The method of proof produces simple explicit formulas for the coefficient in the power law in cases with rational log-ratios for the assigned probabilities of keys. Our formula in these cases suggests an exact asymptotic formula in the cases with an irrational log-ratio, and this formula is exactly what was proved by Montgomery.	approximation;coefficient;discretization;event (computing);gap theorem;montgomery modular multiplication;randomness;rationality;space bar;time complexity;word lists by frequency	Brian Conrad;Michael Mitzenmacher	2004	IEEE Transactions on Information Theory	10.1109/TIT.2004.830752	analytic number theory;power law;combinatorics;number theory;information theory;computer science;mathematics;statistics	Crypto	47.630247442845935	13.214148169140254	7291
a5c50dd7b712d67d0a8df22ad2ed9607862d3786	tight bound between nonlinearity and algebraic immunity	boolean function	Abstract: We obtain tight bound between nonlinearity and algebraic immunityof a Boolean function and construct balanced functions that achive thisbound for all possible values of parameters.	linear algebra;nonlinear system	Mikhail Lobanov	2005	IACR Cryptology ePrint Archive		algebraic number;discrete mathematics;boolean function;nonlinear system;algorithm;mathematics	Crypto	43.37509996506327	38.296874961470856	7310
5eac4e7fd86a69b20784d919acbc5a7fb94da98d	analysis of uniform hashing	theoretical model;dynamic behavior	"""Umform hashing or random probing is often used as a theoretical model of certain types of hashing schemes based on open addressmg, and, m pamcular, of double hashing. Earlier analyses of umform hashing are extended here to multlrecord buckets. Three different situations are analysed: initial loadmg assuming uniform access frequencies, frequency loading assuming nonuniform access frequencies, and the dynamic behavior when msertions and deletions occur. Stmple """"closed"""" formulas cannot be found, but numerical results are readily computed. For larger bucket sizes the retrieval performance is signdicanfly better than that of linear probing and separate chaining Hence double hashing and similar techniques are competmve alternatives also for organizing externally stored files. Categories and Subject Descnptors. E.2 [Data Storage Representations]: hash-table representations; F.2.2 [Analysis of Algorithms and Problem Complexity]: Nonnumerical Algonthms and Problems--sorting and searching,, H 2 2 [Database Management]: Physical Design--access methods General Terms: Algorithms, Performance, Theory Ad&tional"""	algorithm;analysis of algorithms;cryptographic hash function;data storage tag;double hashing;hash table;linear probing;numerical analysis;organizing (structure);physical design (electronics);sorting;theory	Per-Åke Larson	1983	J. ACM	10.1145/2157.322407	simulation;computer science;data mining;world wide web	Theory	10.321484405162606	29.5419004943219	7315
617be08e85e8ca1d9a5ebf14d22cdadf00de6c3a	on the brodutch and modi method of constructing geometric measures of classical and quantum correlations	quantum correlations;classical correlations;geometric measures of correlations;bell diagonal states	Recently, Brodutch and Modi proposed a general method of constructing meaningful measures of classical and quantum correlations. We systematically apply this method to obtain geometric classical and quantum correlations based on the Bures and the trace distances for two-qubit Bell diagonal states. Moreover, we argue that in general the Brodutch and Modi method may provide non-unique results, and we show how to modify this method to avoid this issue.		Zbigniew Walczak;Iwona Wintrowicz	2017	Quantum Information Processing	10.1007/s11128-017-1539-5	calculus;mathematics;geometry	Theory	45.899130581378486	17.7760645396459	7326
1a7acb64392581c07a8528cb47b622cb9d24da03	an optimal design method for de-synchronous circuit based on control graph	control graph;performance evaluation;optimal method;asynchronous circuit;algorithm;design method;optimal design;linear program;de synchronous;petri net;optimal algorithm;asynchronous	De-synchronous is a very useful method to design asynchronous circuit automatically from synchronous description of circuits. This paper introduces an optimal design method based on Control Graph which is an abstract model of the de-synchronous circuit. The main purpose of this optimal design method is to reduce the extra overhead in the area of the de-synchronous circuit. The optimization algorithm takes the performance evaluation function based on the Control Graph of the de-synchronous circuit as its heuristic function. The performance evaluation function presented in this paper is a linear programming problem. In the end of this paper, the optimal method is applied to a set of benchmark circuits. The number of the local controllers in these circuits is markedly reduced by 54%, and the number of C-elements that is required to construct the handshake circuitry between local controllers is also reduced by 76.3%. So the entire area of the circuit is sharply reduced. Because this design method is directed by the performance evaluation function of the circuit, there is no penalty in performance of the de-synchronous circuit.	optimal design;synchronous circuit	Gang Jin;Lei Wang;Zhiying Wang;Kui Dai	2007		10.1007/978-3-540-76837-1_11	equivalent circuit;physical design;parallel computing;asynchronous circuit;design methods;computer science;linear programming;optimal design;theoretical computer science;asynchronous communication;distributed computing;circuit extraction;synchronous circuit;petri net	EDA	16.70470375836349	50.86179693397899	7330
fa466fd725e58721ebc840ebda8d8ad43b2554c9	majority decisions in overlapping committees and asymptotic size of dichotomies	graph sieves;mitchinson durbin bound;renyi s inequality;sums of binomial coefficients;05a19;60e15;92b20;05a20;05a16	In this paper we settle an open combinatorial conjecture in artificial neural networks: we show that the bound on the number of dichotomies given by Mitchinson and Durbin [Biological Cybernetics, 60 (1989), pp. 345–365] is tight, and that their structural asymptotics remain unchanged with varying required success probability. In our proof we use Rényi’s graph-sieves inequalities, and we derive a contracted version and a sharp bound for a triple-indexed sum of binomial coefficients with dependent indices.	artificial neural network;biocybernetics;coefficient;cybernetics	Andreas Wendemuth;Italo Simonelli	2012	SIAM J. Discrete Math.	10.1137/110836717	combinatorics;discrete mathematics;mathematics;statistics;algebra	Theory	36.133148131373936	29.428408220529004	7333
399131bcfbad9b5d197efbd2a01e5269ca548e94	simultaneous optimization for low dropout regulator and its error amplifier with process variation	ldo circuit;process variation effects;optimisation;low noise properties;simultaneous optimization;low dropout regulator;analog circuits;error amplifier;system on chip;automatic optimization process;transistors;optimization regulators mathematical model equations analog circuits transistors system on chip;mathematical model;small ripple properties;voltage regulators;optimization;low noise amplifiers;regulators	Due to its low power, small ripple and low noise properties, low-dropout regulators (LDO) are often used in on-chip applications. However, there are few design automation works focusing on this important circuit. In this paper, an automatic optimization process is proposed to generate the optimal sizing of low dropout regulators. The devices in the LDO circuit and its error amplifier are both considered in the optimization process for reducing the overall circuit cost. The process variation effects are also considered in this work to guarantee the circuit performance after manufactured. As demonstrated in the experiments, the proposed approach successfully solves the unreachable specification in previous work and significantly improves the design yield of the generated circuits.	dropout (neural networks);electronic design automation;error amplifier (electronics);experiment;low-dropout regulator;mathematical optimization;ripple effect;unreachable memory	Yen-Lung Chen;Guan-Ming Chu;Ying-Chi Lien;Ching-Mao Lee;Chien-Nan Jimmy Liu	2014	Technical Papers of 2014 International Symposium on VLSI Design, Automation and Test	10.1109/VLSI-DAT.2014.6834870	control engineering;electronic engineering;engineering;control theory	EDA	24.283299490948558	57.778794183289975	7359
fb81f6219345704d1e04552a83cce6b3170c2bb8	an accurate and efficient gate level delay calculator for mos circuits	digital simulation;field effect integrated circuits;integrated logic circuits;logic cad;logic gates;mos circuits;spice-like circuit simulator;gate delay models;gate delays;gate-level delay calculator;incremental characterization process;production multiple delay simulator;production timing analyzer;scaled one-dimensional table;simulation technique;transmission gate circuits;two-dimensional delay table;waveform slope effects	This paper describes an accurate and efficient gate level delay calculator that automatically characterizes and computes the gate delays of MOS circuits. The high accuracy is attributed to a sophisticated delay model, which includes an accurate representation of the waveform, a consistent and meaningful definition of delay, a consideration of waveform slope effects at both the input and output of a gate, and an innovative approach for handling transmission gate circuits. Meanwhile, the high efficient delay characterization is accomplished through a fast timing simulation technique instead of using a circuit simulation or a timing simulation technique, a theorem to reduce a two-dimensional delay table into a scaled one-dimensional table, and an incremental characterization process. The delay calculator has been used in a production timing analyzer and a production multiple delay simulator since 1986. The results show that the multiple delay simulator performs 5000 times faster than a SPICE-like circuit simulator at only 15% cost of accuracy. Gate delay models, delay characterization, and practical examples are presented in this paper.	delay calculation;electronic circuit simulation;input/output;propagation delay;spice;timing closure;transmission gate;waveform	Foong-Charn Chang;Chin-Fu Chen;Prasad Subramaniam	1988			propagation delay;electronic engineering;real-time computing;delay calculation;logic gate;computer hardware;computer science;gate equivalent;elmore delay;logic simulation;software testing;combinational logic;delay line oscillator;algorithm	EDA	26.33162124063957	54.1163518530971	7384
5437023ab8015a9dc5ccef2b65acb32247b9f786	bioviz: an interactive visualization engine for the design of digital microfluidic biochips		In order to shorten the required time for the analysis of medical substances, Digital Microfluidic Biochips (DMFBs) have been suggested. They allow for handling small amounts of samples and reagents on a circuit board and, thus, automatically execute medical experiments that are usually conducted manually in laboratories. However, there are various challenges in the design of DMFBs. Issues such as routing and layouting are complex and currently being investigated by various researchers and engineers. Although first automatic solutions assist them, the obtained results are usually provided in a complex and \mbox{non-intuitive} fashion. This makes the utilization and evaluation of existing approaches for DMFB design a tedious task. In this paper, we present a solution for this problem by proposing a visualization scheme for DMFBs that explicitly addresses these problems. To this end, a grammar is proposed which allows the description of resulting designs and their properties. The contributions of this work allow for a design methodology which is easy to use and provides a hassle-free environment for the involved researchers and engineers.	experiment;interactive visualization;printed circuit board;routing	Jannis Stoppe;Oliver Keszöcze;Maximilian Luenert;Robert Wille;Rolf Drechsler	2017	2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)	10.1109/ISVLSI.2017.38	microfluidics;biochip;algorithm design;visualization;theoretical computer science;interactive visualization;computer science	Visualization	11.13726130242174	50.47740278210074	7393
e6d0d1a2c1f398ba8c89a1aa882f7b1636a3e347	a group-theoretical bound for the number of main eigenvalues of a graph		An eigenvalue of a graph is called main if the corresponding eigenspace contains an eigenvector in which the sum of coordinates is different from zero. It is proved that the number of main eigenvalues does not exceed the number of orbits (sets of vertices equivalent under the group of automorphisms of the graph).		Drago Cvetkovi;Patrick W. Fowler	1999	Journal of Chemical Information and Computer Sciences	10.1021/ci9900231	graph power;graph energy;integral graph;combinatorics;discrete mathematics;wagner graph;null graph;regular graph;distance-regular graph;simplex graph;cubic graph;voltage graph;butterfly graph;crossing number;spectral graph theory;bound graph;quartic graph;complement graph;line graph;strength of a graph;coxeter graph;adjacency matrix;algebra	Theory	29.542502582711883	32.94521323174408	7396
52a322122f38bcd2a276ef318aeeec53e4491eaa	two minimal forbidden subgraphs for double competition graphs of posets of dimension at most two	matematicas aplicadas;subgrafo;mathematiques appliquees;double competition graph;minimal forbidden subgraph;conjunto parcialmento ordenado;partially ordered set;poset of dimension at most two;sous graphe;vertex graph;forbidden subgraphs;ensemble partiellement ordonne;subgraph;applied mathematics;calcul 2 dimensions;vertice grafo;sommet graphe;two dimensional calculations	Let S be any set of points in the Euclidean plane R2. For any p = (x, y) ∈ S, put SW (p) = {(x, y) ∈ S : x < x and y < y} and NE(p) = {(x, y) ∈ S : x > x and y > y}. Let GS be the graph with vertex set S and edge set {pq : NE(p) ∩ NE(q) 6= ∅ and SW (p) ∩ SW (q) 6= ∅}. We prove that the graphH with V (H) = {u, v, z, w, p, p1, p2, p3} and E(H) = {uv, vz, zw, wu, p1p3, p2p3, pu, pv, pz, pw, pp1, pp2, pp3} and the graph H ′ obtained from H by removing the edge pp3 are both minimal forbidden subgraphs for the class of graphs of the form GS . © 2008 Elsevier Ltd. All rights reserved.	forbidden graph characterization;forbidden subgraph problem;roland gs;shattered world	Junjie Lu;Yaokun Wu	2009	Appl. Math. Lett.	10.1016/j.aml.2008.06.046	partially ordered set;combinatorics;mathematical analysis;discrete mathematics;topology;applied mathematics;vertex;mathematics	Theory	29.12516909194888	32.191070559462766	7405
6bbdf96b7853c67a0cd38195af227d5d9a1ee196	parallel processing of regions represented by linear quadtrees	parallel calculus;image processing;multiprocessor;binary image;geometrie algorithmique;computational geometry;procesamiento imagen;intelligence artificielle;traitement image;algorithme;algorithm;calculo paralelo;image binaire;geometria algoritmica;imagen binaria;artificial intelligence;inteligencia artificial;multiprocesador;calcul parallele;parallel processing;algoritmo;multiprocesseur	We show how computation of geometric properties of a region represented by a linear quadtree can be speeded up by about a factor of p by using a p -processor CREW PRAM model of parallel computation. Similar speedups are obtained for computing the union and intersection of two regions, and the complement of a region, using linear quadtree representations.	linear programming;parallel processing (dsp implementation)	Sangeeta Bhaskar;Azriel Rosenfeld;Angela Y. Wu	1988	Computer Vision, Graphics, and Image Processing	10.1016/S0734-189X(88)80045-8	parallel processing;computer vision;multiprocessing;binary image;image processing;computational geometry;computer science;artificial intelligence;theoretical computer science;algorithm	Vision	11.595435401435951	35.25541332388928	7409
e7d51f16dbabe90bf791978ac78fe5de92f2cd19	the labelings of a variation of banana trees	null			Gao Zhenbin	2010	Ars Comb.		discrete mathematics;combinatorics;mathematics	ML	32.39297634916549	33.99470138033931	7414
ebe077d691c6baa2c62b9c8e08244d0f08a72483	renormalization of the global quantum correlation and monogamy relation in the anisotropic heisenberg xxz model	quantum correlation;monogamy relation;quantum renormalization group;quantum phase transition	In this study, the global quantum correlation, monogamy relation and quantum phase transition of the Heisenberg XXZ model are investigated by the method of quantum renormalization group. We obtain, analytically, the expressions of the global negativity, the global measurement-induced disturbance and the monogamy relation for the system. The result shows that for a three-site block state, the partial transpose of an asymmetric block can get stronger entanglement than that of the symmetric one. The residual entanglement and the difference of the monogamy relation of measurement-induced disturbance show a scaling behavior with the size of the system becoming large. Moreover, the monogamy nature of entanglement measured by negativity exists in the model, while the nonclassical correlation quantified by measurement-induced disturbance violates the monogamy relation and demonstrates polygamy.	quantum correlation	Meng Qin;Zhong-Zhou Ren;Xin Zhang	2016	Quantum Information Processing	10.1007/s11128-015-1167-x	quantum phase transition;quantum correlation;mathematics;quantum electrodynamics;condensed matter physics;physics;quantum mechanics	Arch	50.05029192225692	21.294224987983007	7422
2595b3058d73994229a326ff2f15bdb2350a4caa	automaton recognition of doubly connected labyrinths with finite cyclic diameter	chess labyrinth;finite cyclic diameter;automaton recognition;infinite class	The problem of existence of a recognizing automaton for a subclass of an infinite class of chess labyrinths (denoted as C 0) is studied. It is proved in [1] that, for C 0, there does not exist a recognizing automaton. In [2], it is proved that there exists a recognizing collective of type (1, 1) (collective consisting of an automaton and stone). In this paper, it is proved that there exists a recognizing automaton for some subclass of the class of chess labyrinths with finite cyclic diameter.	automaton	Biljana Stamatovic	2010	Programming and Computer Software	10.1134/S0361768810030035	powerset construction;reversible cellular automaton;block cellular automaton;combinatorics;discrete mathematics;büchi automaton;elementary cellular automaton;two-way deterministic finite automaton;probabilistic automaton;continuous automaton;deterministic automaton;mathematics;algorithm	Theory	-1.263744824924798	22.091085059409757	7427
1970f0aba8760b9a5f11244f77bbde1a6d4e7381	decomposition algorithms for solving the minimum weight maximal matching problem	vertex cover;gallai edmonds decomposition;benders decomposition;minimum maximal matching;mixed integer programming	We investigate the problem of finding a maximal matching that has minimum total weight on a given edge-weighted graph. Although the minimum weight maximal matching problem is NP-hard in general, polynomial time exact or approximation algorithms on several restricted graph classes are given in the literature. In this paper, we propose an exact algorithm for solving several variants of the problem on general graphs. In particular, we develop integer programming formulations for the problem and devise a decomposition algorithm, which is based on a combination of integer programming techniques and combinatorial matching algorithms. Our computational tests on a large suite of randomly generated graphs show that our decomposition approach significantly improves the solvability of the problem compared to the underlying integer programming formulation.	approximation algorithm;benders decomposition;blossom algorithm;branch and bound;computation;edmonds' algorithm;exact algorithm;graph (discrete mathematics);integer programming;matching (graph theory);maximal set;minimum weight;np-hardness;polynomial;procedural generation;time complexity;vertex cover	Merve Bodur;Tinaz Ekim;Z. Caner Taskin	2013	Networks	10.1002/net.21516	benders' decomposition;mathematical optimization;combinatorics;discrete mathematics;integer programming;vertex cover;computer science;3-dimensional matching;edge cover;mathematics	Theory	23.542653286609283	15.626740217832127	7434
eba53c0c836777f75f026db0dfc0d8af7ea04f35	co-synthesis of floorplanning and powerplanning in 3d ics for multiple supply voltage designs		This paper addresses a 3D floorplanning methodology, which considers floorplanning and powerplanning at the same time for Multiple Supply Voltage (MSV) circuits. Physical design becomes more complex for MSV designs since modules with the same power domain have to be placed at close locations in 3D space to facilitate powerplanning and reduce IR-drop, which would deteriorate wirelength. By properly partitioning modules of the same power domain into several voltage islands and increasing overlap area of the voltage islands in contiguous dies, we can reduce routing resource usage without increasing wirelength significantly. Further, unlike previous works, our approach not only can handle a netlist with soft modules and hard modules but also can meet the fixed-outline constraint. The experimental results show that our methodology gets better results than other approach in designs with single voltage domain and is also promising for MSV designs.	floorplan (microelectronics);netlist;overlap zone;physical design (electronics);power domains;power supply unit (computer);routing	Jai-Ming Lin;Chien-Yu Huang;Jhih-Ying Yang	2018	2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)	10.23919/DATE.2018.8342221	real-time computing;netlist;computer science;electronic circuit;power domains;physical design;floorplan;voltage	EDA	14.118022885156444	53.99443612772738	7436
55a836fb25c31068c14704a3a18f27f3edf59c80	efficient identification of crosstalk induced slowdown targets	slow down effect;crosstalk;required time;extractors;timing circuits;filters;timing circuits circuit analysis computing integrated circuit testing logic testing crosstalk filters;crosstalk filters timing automatic test pattern generation fault diagnosis circuit faults circuit analysis computing information analysis signal analysis coupling circuits;logic testing;integrated circuit testing;slow down effect crosstalk induced slowdown targets filter development crosstalk target identification boolean errors vectorless process xiden framework signal transitions static timing analysis single capacitive crosstalk coupling multiple capacitive crosstalk coupling extractors required time;static timing analysis;static timing analysis crosstalk extractors filters required time slow down effect;circuit analysis computing	"""This paper deals with filter development in XIDEN, a """"pruning """" tool used to identify crosstalk targets that can potentially create Boolean errors. XIDEN employs multiple tools to adoptively estimate and/or extract electrical parameters required by its filters, and uses a novel approach to construct an efficient sequence of extractors and filters that are applied to a circuit. Thus, an initially enormous collection of targets can usually be reduced to a very small set of targets via a vectorless process. This process flow is much more efficient than using ATPG without pruning to identify targets that represent faults. The XIDEN framework, including the filters that capture the effect of crosstalk-induced pulses, has been previously presented. In this paper, our focus is on filters associated with crosstalk induced slowdown targets. To accurately compute timing information associated with signal transitions, we have enhanced the XIDEN framework with enhanced static timing analysis procedures that take into consideration single and multiple capacitive crosstalk couplings in a circuit."""	clock rate;computation;computer-aided design;crosstalk;domain relational calculus;quality of results;speedup;static timing analysis;time complexity;very-large-scale integration	Melvin A. Breuer;Sandeep K. Gupta;Shahin Nazarian	2004	13th Asian Test Symposium	10.1109/ATS.2004.38	embedded system;electronic engineering;real-time computing;crosstalk;telecommunications;computer science;static timing analysis	EDA	21.34078710368175	50.605265846744345	7443
356bb729b7366084561dca5f6b12ac8f2e2691f6	darknoc: designing energy-efficient network-on-chip with multi-vt cells for dark silicon	network on chip;dark silicon;computational sprinting;silicon switches microprocessors computer architecture optimization threshold voltage libraries;dark silicon chips network on chip darknoc multivt cells multivt circuit optimization multiple network layers interlayer switching mechanism in network packets dvfs energy efficient communication fabric;silicon circuit optimisation elemental semiconductors integrated circuit interconnections low power electronics network on chip	In this paper, we propose a novel NoC architecture, called darkNoC, where multiple layers of architecturally identical, but physically different routers are integrated, leveraging the extra transistors available due to dark silicon. Each layer is separately optimized for a particular voltage-frequency range by the adroit use of multi-Vt circuit optimization. At a given time, only one of the network layers is illuminated while all the other network layers are dark. We provide architectural support for seamless integration of multiple network layers, and a fast inter-layer switching mechanism without dropping in-network packets. Our experiments on a 4 × 4 mesh with multi-programmed real application workloads show that darkNoC improves energy-delay product by up to 56% compared to a traditional single layer NoC with state-of-the-art DVFS. This illustrates darkNoC can be used as an energy-efficient communication fabric in future dark silicon chips.	dark silicon;dynamic voltage scaling;experiment;frequency band;integrated circuit;mathematical optimization;network on a chip;seamless3d;transistor;transport layer security	Haseeb Bokhari;Haris Javaid;Muhammad Shafique;Jörg Henkel;Sri Parameswaran	2014	2014 51st ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2593069.2593117	embedded system;electronic engineering;real-time computing;computer science;operating system;network on a chip;computer network	EDA	2.924162964555317	60.33862363411635	7478
d9d21a10f6428069db9b1ebe8f69af8fd2500d62	on the existence of optimal quantizers	quantization signal;signal quantization;signal quantization quantization signal	The existence of optimal N -level quantizers is demonstrated for several classes of quantizers including block quantizers, memoryless quantizers, and uniform step-size quantizers. No assumptions whatsoever are made regarding the input probability distribution. The distortion measure considered generalizes many of the commonly used error-based distortion measures, including mean squared-error distortion and r th law distortion.	quantization (signal processing)	Efren F. Abaya;Gary L. Wise	1982	IEEE Trans. Information Theory	10.1109/TIT.1982.1056582	mathematical optimization;discrete mathematics;control theory;mathematics	Theory	50.70419387951295	15.289836062428817	7542
16542bc4540bc20e73a9c72f4ce32193cde7e64f	the quantum fourier transform on a linear nearest neighbor architecture	quantum fourier transforms;quantum circuits;shor s factoring algorithm;linear nearest neighbor architectures	We show how to construct an efficient quantum circuit for computing a good approximation of the quantum Fourier transform on a linear nearest neighbor architecture. The constructed circuit uses no ancillary qubits and its depth and size are O(n) and O(n log n), respectively, where n is the length of the input. The circuit is useful for decreasing the size of Fowler et al.'s quantum circuit for Shor's factoring algorithm on a linear nearest neighbor architecture.	quantum fourier transform	Yasuhiro Takahashi;Noboru Kunihiro;Kazuo Ohta	2007	Quantum Information & Computation		quantum fourier transform;shor's algorithm;nearest neighbor graph;combinatorics;discrete mathematics;theoretical computer science;mathematics;quantum computer;quantum algorithm for linear systems of equations;quantum algorithm;quantum phase estimation algorithm	Theory	8.607109382873697	23.176308652512635	7560
0a4feffbbc57f031debdec818cc07f0f5ddb9144	weak square bracket relations for pkappa (lambda)				Pierre Matet	2008	J. Symb. Log.			Logic	45.75270293903121	29.282371171239642	7562
27ad749677d0206c2373807ab055fc0c99b433f2	concatenated codes for the lee metric	concatenated code	where X = h’P. It would be desirable at this point to use the decoding algorithm for D to find h. If P contains negative entries, then X’ = X P may contain negative entries. However, the decoding algorithm for D’ is supposed to solve (A.6) for x’ with entries in (0, I}. It is not difficult to find examples where the above “obvious” algorithm simply will not work. S’Q’ = AD, (A.71 The Lee metric codes are attractive for phase modulated channels and multilevel quantized-pulse modulated channels [3], [4], [5]. There are several classes of codes designed for the Lee metric, but they either have a minimum distance less than the size of the alphabet [3], [4], [5] or a relatively small information rate [7], [9]. In the following we shall see that a very simple construction by Justesen [6] produces a class of Lee codes that are easily implemented and have fairly good distance properties.	algorithm;concatenated error correction code;concatenation;modulation	Jaakko Astola	1982	IEEE Trans. Information Theory	10.1109/TIT.1982.1056550	concatenated error correction code;lee distance;combinatorics;discrete mathematics;serial concatenated convolutional codes;pure mathematics;linear code;expander code;mathematics	Theory	39.30465871593872	52.296077064902356	7576
b387f1f065f12838e450389bf99cfb8911cd07e4	stability and complexity of minimising probabilistic automata		We consider the state-minimisation problem for weighted and probabilistic automata. We provide a numerically stable polynomialtime minimisation algorithm for weighted automata, with guaranteed bounds on the numerical error when run with floating-point arithmetic. Our algorithm can also be used for “lossy” minimisation with bounded error. We show an application in image compression. In the second part of the paper we study the complexity of the minimisation problem for probabilistic automata. We prove that the problem is NP-hard and in PSPACE, improving a recent EXPTIME-result.	algorithm;automata theory;exptime;finite-state transducer;image compression;lossy compression;np-hardness;numerical analysis;numerical error;numerical stability;pspace;probabilistic automaton	Stefan Kiefer;Björn Wachter	2014		10.1007/978-3-662-43951-7_23	mathematical optimization;combinatorics;discrete mathematics;quantum finite automata;mathematics	Theory	7.256203244776845	22.655137973746047	7578
bf4338fe9c59fd66c58fb7644e071bfa68c2bc72	making wom codes decodable using short synchronous wom codes	publikationer;decoding;binary codes;konferensbidrag;decoding encoding vectors memory management synchronization computers merging;decoding binary codes;artiklar;rapporter;all zero codeword short synchronous wom codes write once memory codes binary nondecodable t write wom code code rate t 1 additional cells synchronous t 1 write wom code	While some write once memory (WOM) codes are inherently decodable, others require the added knowledge of the current generation in order to successfully decode the state of the memory. If there is no limit on the code length, n, a binary non-decodable t-write WOM code can be made decodable at an insignificant cost in terms of code rate by adding t - 1 cells to store the current generation after replicating the code enough times for the t - 1 cells to be of negligible weight. This justifies the research on non-decodable WOM codes. However, if n is bounded, the t - 1 additional cells may introduce a significant loss in terms of code rate. In this paper, we propose a new method to make non-decodable WOM codes decodable at a lower price when n is bounded. The main idea is to add cells that do not only store the current generation, but also additional data, by using a synchronous (t - 1)-write WOM code of length t - 1 or slightly above which does not contain the all-zero codeword. A bound on the rate of a simple family of synchronous WOM codes with n = t is given, as well as very short codes from this family. Better codes are then obtained by local manipulations of these codes. Finally, a construction of synchronous WOM codes with good properties is proposed to reach higher values of t.	code rate;code word;concatenation;write once, compile anywhere;write once, run anywhere	Nicolas Bitouze;Alexandre Graell i Amat;Eirik Rosnes	2012	2012 IEEE International Symposium on Information Theory Proceedings	10.1109/ISIT.2012.6283487	block code;reed–muller code;concatenated error correction code;binary code;computer science;theoretical computer science;tornado code;locally decodable code;linear code;mathematics;algorithm;statistics	Arch	37.59892517465834	58.95050537149638	7586
acb9aa0df42a078636596a18aed92a44d5811eed	a new chaotic key-based design for image encryption and decryption	image encryption;binary sequence;vlsi image coding chaos cryptography computational complexity binary sequences;image coding;chaos cryptography computer architecture very large scale integration hardware binary sequences computational complexity security costs algorithm design and analysis;chaos;computational complexity;cryptography;binary sequences;vlsi;mpeg2 chaotic key based design image encryption image decryption vlsi architecture chaotic binary sequence gray level computational complexity security hardware cost computing speed hardware utilization efficiency;vlsi architecture	In this paper, an image encryption/decryption algorithm and its VLSI architecture are proposed. According to a chaotic binary sequence, the gray level of each pixel is XORed or XNORed bit-by-bit to one of the two predetermined keys. Its features are as follows: (1) low computational complexity, (2) high security, and (3) no distortion. In order to implement the algorithm, its VLSI architecture with low hardware cost, high computing speed, and high hardware utilization efficiency is also designed. Moreover, the architecture of integrating the scheme with MPEG2 is proposed. Finally, simulation results are included to demonstrate its effectiveness.	cryptography;encryption	Jui-Cheng;Jiun-In Guo	2000		10.1109/ISCAS.2000.858685	real-time computing;computer science;cryptography;theoretical computer science;distributed computing;algorithm	Crypto	10.508219036743661	42.53705618310918	7624
8e1c37d4b464384d128d79a2e97aafde56db2442	quality prediction-based dynamic content adaptation framework applied to collaborative mobile presentations	ssim visualization transform coding transcoding mobile communication image resolution mobile handsets context xhtml dynamic content adaptation image transcoding interactive multimedia applications mobile device openoffice presentations professional documents;groupware;document handling;mobile device;image resolution;image transcoding;openoffice;transform coding;visualization transform coding transcoding mobile communication image resolution mobile handsets context;interactive multimedia applications;visualization;xhtml;dynamic content adaptation;internet;ssim;multimedia communication;mobile communication;xml;mobile handsets;xml document handling groupware internet mobile computing multimedia communication parameter estimation transcoding;presentations;parameter estimation;mobile computing;transcoding;openoffice impress presentations quality prediction based dynamic content adaptation framework collaborative mobile presentations powerpoint word ubiquitous mobile terminals internet googledocs easymeet collaborative web applications static professional document adaptation dynamic professional document adaptation interactive multimedia applications transcoding parameter estimation total delivery time;context;professional documents	Today, professional documents, created in applications such as PowerPoint and Word, can be shared using ubiquitous mobile terminals connected to the Internet. GoogleDocs and EasyMeet are good examples of such collaborative web applications dedicated to professional documents. The static adaptation of professional documents has been studied extensively. Dynamic adaptation can be very useful and practical for interactive multimedia applications, because it allows the delivery of highly customized content to the end user without the need to generate and store multiple transcoded versions. In this paper, we propose a dynamic framework that enables us to estimate transcoding parameters on the fly to generate near-optimal adapted content for each user. The framework is compared to current dynamic methods as well as to static adaptation solutions. We show that the proposed framework provides a better tradeoff between quality and storage compared to other static and dynamic approaches. To quantify the quality of the adapted content, we introduce a measure of the quality of the experience based on the visual quality of the adapted content, as well as on the impact of its total delivery time. The framework has been tested on (but is not limited to) OpenOffice Impress presentations.	content adaptation;dynamic web page;google forms;internet;microsoft word for mac;on the fly;openoffice basic;requirement;static random-access memory;user-generated content;web application	Habib Louafi;Stéphane Coulombe;Umesh Chandra	2013	IEEE Transactions on Mobile Computing	10.1109/TMC.2012.173	xhtml;the internet;xml;transform coding;transcoding;visualization;image resolution;mobile telephony;computer science;operating system;structural similarity;mobile device;multimedia;internet privacy;estimation theory;mobile computing;world wide web	Web+IR	6.071801617212437	33.19015530285584	7633
76c0deb8595448a9b1d10358749c3c8cbb497c27	development of an open-source gsm femtocell and integrated core infrastructure	microcontrollers;femtocellular radio;fpga open source gsm femtocellular radio integrated core infrastructure cellular gsm technology low power embedded processors open source software packages openbts openbsc embedded hardware platform e100 universal hardware radio peripheral usrp e100 heterogeneous processor platform software defined radio embedded base station gsm network software radio transceiver general purpose arm processor dsp;telecommunication computing digital signal processing chips femtocellular radio field programmable gate arrays low power electronics microcontrollers public domain software radio transceivers software radio;gsm program processors digital signal processing field programmable gate arrays hardware standards computer architecture;telecommunication computing;software radio;public domain software;low power electronics;digital signal processing chips;field programmable gate arrays;radio transceivers	Open source development applied to cellular GSM technology is a fairly recent, but growing, concept. Another trend is the continually growing capability of low-power embedded processors, which makes them increasingly suitable for open source GSM applications. This paper applies two open source software packages, OpenBTS and OpenBSC, to an readily available embedded hardware platform, the Universal Hardware Radio Peripheral (USRP) E100. The USRP E100 device is a heterogeneous processor platform designed for software-defined radio use. The result is an embedded base station that can be deployed in standalone configuration or as part of a larger GSM network. A software radio transceiver implementation is presented that leverages optimized capabilities of all available processors: a general purpose ARM processor, DSP, and FPGA. Comparative performance measures are also provided.	arm architecture;accessibility;central processing unit;digital signal processor;embedded system;field-programmable gate array;library (computing);low-power broadcasting;mathematical optimization;multiprocessing;open-source hardware;open-source software;signal processing;toolchain;transceiver;universal software radio peripheral	Thomas Tsou;Thomas Cooper;Robert McGwier;T. Charles Clancy;Jeffrey H. Reed	2012	MILCOM 2012 - 2012 IEEE Military Communications Conference	10.1109/MILCOM.2012.6415849	embedded system;electronic engineering;real-time computing;engineering;software-defined radio;remote radio head;universal software radio peripheral	Embedded	2.942481404871594	48.32836662899425	7643
04da5f6a32d956e8624dac75ab765fea771261ef	independent spanning trees of 2-chordal rings			file spanning	Yukihiro Hamada	2016	IEICE Transactions		discrete mathematics;minimum degree spanning tree;spanning tree;connectivity;mathematics;distributed computing;algorithm;computer network	Theory	26.314199725902725	34.19253524222966	7648
025b72a172a043331d152738f8d1c3fe5244100c	efficient streaming algorithms for submodular maximization with multi-knapsack constraints		Representative subset selection (RSS) is important tool for users to draw insights from massive datasets. Existing literature models RSS as submodular maximization to capture the diminishing returns property of representativeness, but often only has a single constraint, which limits its applications to many real-world problems. To capture the recency issue and support various constraints, we formulate dynamic RSS as maximizing submodular functions subject to generaln $d$ n-knapsack constraints (SMDK) over sliding windows. We propose a KnapWindow framework (KW) for SMDK. KW utilizes KnapStream (KS) for SMDK in append-only streams as a subroutine. It maintains a sequence of checkpoints and KS instances over the sliding window. Theoretically, KW isn $frac{1-varepsilon}{1+d}$ n-approximate for SMDK. Furthermore, we propose a KnapWindowPlus framework (n $KW^{+}$ n) to improve upon KW.n $KW^+$ nbuilds index SubKnapChk to manage the checkpoints. By keeping much fewer checkpoints,n $KW^{+}$ nachieves higher efficiency than KW while guaranteeing an $frac{1-varepsilon^prime}{2+2d}$ n-approximate solution for SMDK. Finally, we evaluate KW andn $KW^{+}$ nin real-world datasets. The experimental results demonstrate that KW achieves more than two orders of magnitude speedups over the batch baseline and preserves high-quality solutions for SMDK.n $KW^{+}$ nfurther runs 5-10 times faster than KW while providing solutions with equivalent or better utilities.	append;approximation algorithm;baseline (configuration management);display resolution;expectation–maximization algorithm;greedy algorithm;microsoft windows;no silver bullet;requirement;streaming algorithm;submodular set function;monotone	Yanhao Wang;Yuchen Li;Kian-Lee Tan	2017	CoRR	10.1109/TKDE.2018.2854182	submodular set function;sliding window protocol;data mining;microsoft windows;computer science;subroutine;discrete mathematics;approximation algorithm;prime (order theory);maximization;knapsack problem	DB	19.203097540944412	16.144771320494655	7669
f0d7a691b9407eafe2fa280e782ce6f37c0cdf5a	multi-objective method for divisible load scheduling in multi-level tree network	multi objective method;multi level tree network;divisible load theory;divisible load scheduling	There is extensive literature concerning the divisible load theory. Based on the divisible load theory (DLT) the load can be divided into some arbitrary independent parts, in which each part can be processed independently by a processor. The divisible load theory has also been examined on the processors that cheat the algorithm, i.e., the processors do not report their true computation rates. According to the literature, if the processors do not report their true computation rates, the divisible load scheduling model fails to achieve its optimal performance. This paper focuses on the divisible load scheduling, where the processors cheat the algorithm. In this paper, a multi-objective method for divisible load scheduling is proposed. The goal is to improve the performance of the divisible load scheduling when the processors cheat the algorithm. The proposed method has been examined on several function approximation problems. The experimental results indicate the proposed method has approximately 66% decrease in finish time in the best case.	approximation algorithm;best, worst and average case;central processing unit;computation;dlt;scheduling (computing);tree network	Shamsollah Ghanbari;Mohamed Othman;Mohd Rizam Abu Bakar;Wah June Leong	2016	Future Generation Comp. Syst.	10.1016/j.future.2015.03.015	parallel computing;real-time computing;computer science;distributed computing	DB	14.734702304455695	10.893433814085933	7672
bb690e18d84ee64295719f7f0d90d2e59bf3ec30	on scale and concentration invariance in entropies	shannon entropy;invariance;technology and engineering;renyi entropy;information;fisher information	Rényi entropies are compared to generalized log-Fisher information and variational entropies in the context of translation, scale and concentration invariance. It is proved that the Rényi entropies occupy a special place amongst these entropies. It is also shown that Shannon entropy is centrally positioned amidst the Rényi entropies.	entropy (information theory);fisher information;rényi entropy;shannon (unit);variational principle	Luc Knockaert	2003	Inf. Sci.	10.1016/S0020-0255(03)00058-6	strong subadditivity of quantum entropy;combinatorics;rényi entropy;information;fisher information;invariant;entropic uncertainty;mathematics;min entropy;statistics;entropy	DB	45.404429453689225	15.693503158646804	7675
3765e1eb47d8f01c8d01d16a3830c26034afdc0a	regular expressions and transducers over alphabet-invariant and user-defined labels		We are interested in regular expressions and transducers that represent word relations in an alphabet-invariant way—for example, the set of all word pairs u,v where v is a prefix of u independently of what the alphabet is. Current software systems of formal language objects do not have a mechanism to define such objects. We define transducers in which transition labels involve what we call set specifications, some of which are alphabet invariant. In fact, we give a more broad definition of automata-type objects, called labelled graphs, where each transition label can be any string, as long as that string represents a subset of a certain monoid. Then, the behaviour of the labelled graph is a subset of that monoid. We do the same for regular expressions. We obtain extensions of a few classic algorithmic constructions on ordinary regular expressions and transducers at the broad level of labelled graphs and in such a way that the computational efficiency of the extended constructions is not sacrificed. For regular expressions with set specs we obtain the corresponding partial derivative automata. For transducers with set specs we obtain further algorithms that can be applied to questions about independent regular languages, in particular the witness version of the independent property satisfaction question.	algorithm;automata theory;automaton;formal language;graph labeling;regular expression;regular language;software system;the witness;transducer	Stavros Konstantinidis;Nelma Moreira;Rogério Reis;Joshua Young	2018		10.1007/978-3-319-94812-6_2	software system;discrete mathematics;combinatorics;regular language;partial derivative;regular expression;mathematics;monoid;formal language;invariant (mathematics);prefix	DB	-4.1370837077425335	17.90559051806435	7681
659cfd5bd6d75a0f5c228d9289d02fe8175e59ac	shortest path under rational constraint	camino mas corto;graph theory;shortest path;teoria grafo;theorie automate;automata estado acabado;regular language;automate etat fini;theorie graphe;lenguaje racional;recherche operationnelle;informatique theorique;chemin plus court;langage rationnel;automata theory;teoria automata;finite automaton;operational research;investigacion operacional;computer theory;informatica teorica	Abstract We make use of finite automata theory in order to solve some shortest path problems under constraint in valuated graphs.	shortest path problem	Jean-François Romeuf	1988	Inf. Process. Lett.	10.1016/0020-0190(88)90198-6	regular language;computer science;artificial intelligence;graph theory;automata theory;mathematics;shortest path problem;algorithm	DB	20.616240507486744	28.647592505454007	7696
13c2bc1c83d422a2953271f62aa85b929a9e2e78	elmore model for energy estimation in rc trees	time varying;time varying voltage sources;interconnect;delay effects;trees mathematics;power supply;interconnect algorithms energy estimation rc trees;rc circuits;integrated circuit design;time varying networks;trees graphs;energy estimation;algorithms;time varying circuits;elmore model;energy estimate;trees mathematics delays rc circuits time varying networks;rc trees;time varying voltage sources energy estimation elmore model rc trees;delays;integrated circuit interconnections delay estimation power supplies clocks voltage computational modeling integrated circuit modeling energy dissipation energy consumption resonance	This paper presents analysis methods for energy estimation in RC trees driven by time-varying voltage sources, e.g., buffers, time-varying power supplies, and resonant clock generators. An Elmore energy model that is the computational analog of the conventional Elmore delay model for RC trees is described. Simulation results indicate that the error in energy estimation is less than 2.5% in the worst-case in comparison to HSPICE simulations, with over a 1000X speed-up.	best, worst and average case;elmore delay;power supply;spice 2;simulation	Quming Zhou;Kartik Mohanram	2006	2006 43rd ACM/IEEE Design Automation Conference	10.1145/1146909.1147154	rc circuit;electronic engineering;real-time computing;telecommunications;computer science;engineering;electrical engineering;elmore delay;interconnection;algorithm;integrated circuit design	EDA	24.00175711982549	58.85258687603828	7719
6067319ebd475b5a87a8dee72ec460e4aa2f953e	on mappings for modular arithmetic, i	modular arithmetic	"""Standard comput ing machine ar i thmet ic performs the operat ions of additio~, mult ipl icat ion and division on the integers modulo m = 25 represented as bi t lary j-tuptes. A ra ther well-known a l te rna t ive is to represent the integers modulo m as ntuples a l , . . . , a, where each a~ is t reated modulo an integer m~ . An addi t ional operat ion t ha t must be provided assigns an integer modulo m to each such ntuple and it is convet~ient to require tha t this assignment be addi t ive and onto. In this note the family of all such mappings is character ized in a simple, explicit way, arid it is shown tha t the number of mappings ~ which preserve the mult ipl icat ive iden t i ty (that is, such t ha t q,(1, 1, . . . , 1) = 1) is g.c.d. (m, mQ . . . g.c.d. (m, m,~)/m if m divides 1.c.m. {ml , . . . , m~} and is zero otherwise. Standard computing machines perform the arithmetic operations on the integers modulo m = 2 j represented as binary j-tuples. An alternative known as modular or residue class arithmetic is to represent integers modulo m as n-tuples a~, • • • , a~ where each a~ is treated modulo an integer m~. The properties and advantages of modular arithmetic are illustrated in earlier work of Garner [1], Svoboda [2] and 3thers [3]. The numbers ml , m2, . . . , m~ are generally called the bases or moduli ~nd m the range of the system. In this paper, representation of integers modulo m are considered using moduli ,n~, m2, .. • , m~ which may n o t be pairwise relatively prime. An additional opera:~ion that must be provided is one that assigns an integer modulo m to each such ~-tuple and it is convenient and natural to require that this assignment be additive, )nto and preserve multiplicative identity. We characterize the family of all such mappings in a simple, explicit way and teduce a formula for their number. The reader who is not familiar with the elenentary notions of number theory involved may refer to [4]. Let Z~ denote the ring of residue classes of the integers modulo k. Let n, m~, • • • , m~ and m all be positive integers, let ~ N = Z m , X • • """" x Z ~ , , and et q, be a function defined on all of N with values in Z ~ . is a d d i t i v e if ¢ ( x A y ) = ~ ( x ) [ -~(y) for all x, y i n N . (1) • The work of this au thor was performed while he was wi th the In format ion Systems Labra tory , the Univers i ty of Michigan, Ann Arbor, Michigan, and was suppor ted by Contract LF33(657)-7811. t The work of this au thor was sponsored by the Air Force Electronic Command, under 3ontract AF19(628)-2290. The au thor ' s present address is the Ins t i t u t e for Defense Analysis, ' r ineeton, N. J. 1 T h a t i s , t h e s e t o f a l l n . t u p l e s x ~ , . . . , x n w i t h x i E Z~i (i = 1 , . . . , n ) . 542 Journal of the Association for Computing Machinery, Vol. 12, No. 4 (October, 1965), pp. 542-544 ON 3IAtPPINGS FOR MODULAR ARITHMETIC, I 5 4 3 is homogeneous if ( cx ) = c~ , (x ) for all eC Z , x C N (2) ~-here cx = c ( z l , . . . , z,~) = ( c x i , . . . , ez,~) with ex~ C Z,~i and c ~ ( x ) ~ Z .... For i = 1, . . . , n let e~ deno t e the element of N with (the residue class of) 1 as ~Jne ith component , and (residue classes) 0 elsewhere; and let r~ = ~(ei) . LEMMA 1. I f ~ i8 additive, t hen it """"is homogeneous and ~ (0 ) = O. PROOF. For any ir~teger c, ~ ( c x ) = ,p((e -1)x -t:x) = g , ( (c -1)x) + e(x) = ~,((c 2 ) x + ~ ) + ~ ( x ) = ~,((c 2 ) x ) + 2~,(x) . . . . . c a ( z ) . I n particular, ¢(0) = ~,(0x) ( fo r every x ~ N) = 0~,(x) = 0. LEMMA 2. 'Z is additive """"if a n d only i f both of the following hold: rn,~'i = 0 (mod m ) ( i = 1, . . . , n ) (3) n ~ ( x ) = ~ x ~ r i for all x ~ N (4) i = l where the equali ty in (3) as well a s (4) m e a n s equality in Z E . (Note tha t the Equat.ion (4) does not define a func t ion ~, if each x~ is an arbitrary member of an equivalence class modulo m~ unless (3) holds.) PI~OOF. Suppose ~ is addi t ive . Then, by Lemma 1, m,~ri =m ~ ( e i ) = q~(mlel) = ~ ( 0 ) = O, which proves (3). To prove (4 ) , observe t h a t ~ ( x ) = ~ ( ( ~ , . . . , ~ ) : ) = ~ ( ~ 2 x,e,) = ~ 2 x ,~(e , ) = ~ 2 ~,r~. Conversely, if (3) holds, so t h a t (4) makes sense when each x~ is an arbi t rary ~ e m b e r of a residue class m o d u l o m/ , and if (4) holds too, then e ( x + y) = (x~ + yl)r4 by definition of add i t ion (x.i + y~ is any member of the appropriate equivalence class) = ~ x~r~ + ~ y ~ = ~(x) """"4~(y) , and g, is additive. LEMMA. 3. Suppose ~, is addit ive. T h e n 9 maps N onto Zm i f and only i f ( r ~ , . , . , r , , m ) = 1. ~ Pnoo~. If ~ is onto, there exists x in N with ~(x) = 1. Hence, for some rat ional ittteger a we can write the fol lowing equat ion in rational integers: ~ x¢'~ = 1 -tam. I t follows tha t any c o m m o n divisor of r ~ , . . . ,r , , and m divides 1; i.e., ( r ~ , . . . , r , , , m ) = 1. Conversely, if @1, ' • • , r~ , m) = 1, the Euclidean algorithm assures us t ha t there exist integers x0, • • • , x,, such t h a t xom + ~ xlr~ = 1. Then by L e m m a 2, ~(x) = g , ( ( x~ , . . . , x~) ) = ~ xirs = 1 xom = I in Z~ . I t follows now t h a t for every integer c, ~ ( e x ) = ~ ( x ) = c l = c in Z ~ , so ~ is onto, as was to be proved. Let u = 1.c.m. {m~, . . ,m~}. LEMM~ 4. Suppose ~ is a n addi t ive m a p p i n g of N on Z ~ . Then m I u . PROOF. There exist integers y~ such tha t m~¢~ = y ,m ( i = 1 , . . . , n ) by L e m m a 2 and integers x0, .. • , x~ such t h a t 1 = xom + ~ x,¢~ by L e m m a 3. Then u = xomu + ~ x,ur, = xomu + ~2 x,v,~ulm, = m(xou + ~ x,v,~lm,) and, since u/m~ is an integer, m ] u. • (y~, y , , . . .) denotes greatest common divisor of the integers y~, y, , . . . throughout this Daper. 544 T . R . N . 14AO AND N. ZIERLER Let 1 denote the element (1, . . , 1) of N. THEOREM. 3 Suppose m ] u. Then the number of additive mappings ~ of N on Zm such that q~(1) = 1 is (m, ml) . . . (m, m~)/m. PROOF. If we set r~ = m / (m , m~) proper ty (3) holds, so the corresponding mapping ~ defined by (4) is addit ive by L e m m a 2. I f some prime p divides all the r~, it divides m, and we let p"""" denote the largest power of p float does. Then p~ I u, so for some i, pr ] m~. But then p~ I (m, m~) so p does not appear as a factor of ~.~ ~mdr = 0. Thus, ( r l , . . . , r , ) = 1 s o , ~ f o r t i o r i , ( r l , . . . , r ~ , m ) = 1 and~xis onto Zm by Lemma 3. Let U denote the set of all v in N such tha t ~ ( v ) = 1. If v C U, clearly viriml ~ O m o d m for all i and ( v l rL , . . . ,v , ,r~,m) = 1 since v ~ ~ 1 modulo m. Hence the mapping ~ defined by ~,~(x) = ~ vgr~c~ is an additive mapping of N on Z~ such tha t 9 , (1 ) = 1. Conversely, if ~ is any additive mapping of N on Zm such tha t ¢ (1 ) = 1, then by (3) there exist integers z~ such tha t m~9(e~) = z,m. Let vi = z~(m, ml) /m~. Then ~ ( e , ) = v~r~ = v~. ,~/(m, ~ , ) = z ~ / m ~ = ~(e~) ,"""	computer;emoticon;euclidean algorithm;existential quantification;fo (complexity);journal of the acm;map;modulo operation;turing completeness;utility functions on indivisible goods;xml object model	T. R. N. Rao;Neal Zierler	1965	J. ACM	10.1145/321296.321303	modular arithmetic;discrete mathematics;arbitrary-precision arithmetic;computer science;saturation arithmetic;pure mathematics;mathematics;algorithm;algebra	Theory	38.694892259888945	39.05854542290743	7720
f6796e07dd5d2cb9b51ccc0d11994900ef2ac527	on the norms of circulant matrices with the fibonacci and lucas numbers	secuencia fibonacci;norm;analisis numerico;matematicas aplicadas;standards;mathematiques appliquees;fibonacci sequence;circulant matrix;nombre lucas;analyse numerique;matrice circulante;numerical analysis;fibonacci number;norma;circulant matrices;lucas number;suite fibonacci;applied mathematics;norme;matriz circulante	"""Let us define A=[a""""i""""j] and B=[b""""i""""j] as nxn matrices, where a""""i""""j=F""""(""""m""""o""""d""""(""""j""""-""""i"""",""""n"""")"""") and b""""i""""j=L""""(""""m""""o""""d""""(""""j""""-""""i"""",""""n"""")""""). We find out some bounds for the A and B matrices concerned with the spectral and Euclidean norms."""	circulant matrix	Süleyman Solak	2005	Applied Mathematics and Computation	10.1016/j.amc.2003.08.126	arithmetic;combinatorics;fibonacci number;circulant matrix;mathematics;algebra	Theory	44.762039548357954	34.85611917747436	7721
462a63ac65235129a876204d128c95515304aa75	reliability improvement of logic and clock paths in power-efficient designs	clock network design;clock tree reliability;signal probability;positive bias temperature instability pbti;logic paths reliability;negative bias temperature instability nbti	Performance degradation due to transistor aging is a significant impediment to high-performance IC design due to increasing concerns of reliability mechanisms such as negative-bias-temperature-instability (NBTI). The concern only grows with technology scaling as the effects of positive bias temperature instability (PBTI) is becoming prominent in future technologies and compounding with the effects of NBTI. Although aging of transistor is inevitable and the magnitude of degradation due to aging varies depending upon the context. Specifically, in power-efficient systems designs, the logic and clock paths are susceptible to static stress resulting in peak degradation due to BTI occurrence when clock is gated. In this article, we present the reliability impact of making systems power efficient and propose a design-for-reliability methodology that can be used in conjunction with low-power design techniques to alleviate the stress conditions caused by rendering circuits in idle state. The technique—BTI-Refresh, is shown to be applicable to both logic and clock paths alike and focuses on preventing prolonged static stress using periodic refreshes to achieve alternating stress. The mechanism is shown to integrate seamlessly into the design at gate-level without requiring any architectural or RT-level changes. Using ISCAS benchmarks and Kogge-Stone-Adder circuits, it is shown to reduce the aging effect in logic path delay due to static stress by up to 50% with negligible area and power overhead. BTI-Refresh is extended to clock-paths to prevent pulse-width degradation due to static aging and with minimal clock-skew.	adder (electronics);btrieve;clock skew;elegant degradation;image scaling;integrated circuit design;kogge–stone adder;low-power broadcasting;negative-bias temperature instability;overhead (computing);transistor	Senthil Arasu;Mehrdad Nourani;Vijay Reddy;John M. Carulli;Gautam Kapila;Min Chen	2014	JETC	10.1145/2543749.2543751	reliability engineering;electronic engineering;real-time computing;engineering	EDA	19.75396201174799	58.29398584167513	7731
67c1639290f6539986f1ceb69fa33ee8f504a365	sdf graphs for performance estimation of migration software task to hardware in mpsoc systems			mpsoc	Kamel Smiri;Abderrazak Jemai	2011			computer architecture;software;parallel computing;mpsoc;computer science;graph	Arch	-0.45257505097728973	50.33492626151808	7736
c671838a922a333c3ad8514449b64a44957bdd91	cad challenges in multimedia computing	vlsi systems-on-chips;system design;new challenge;multimedia computer design;cad perspective;advanced cad synthesis tool;high-volume chip;high computation rates;multimedia computing;multirate computing problem;memory bandwidth;high-volume market;cad challenge;advanced cad synthesis tools;circuit cad;vlsi;cad challenges;chip;system on chip	Abstract: This tutorial surveys the present and future of multimedia computing systems and outlines new challenges for CAD presented by these systems. Multimedia computing is a challenging domain for several reasons: it requires both high computation rates and memory bandwidth; it is a multirate computing problem; and requires low-cost implementations for high-volume markets. As a result, the design of multimedia computing systems introduces new challenges for CAD at all levels of abstraction, ranging from layout to system design. After surveying the nature of the multimedia computing problem, we examine two experiences in multimedia computer design from a CAD perspective: the design of VLSI systems-on-chips for multimedia: and the successive refinement of an application from software to a high-volume chip using advanced CAD synthesis tools.	computation;computer architecture;computer-aided design;memory bandwidth;multimedia computer;principle of abstraction;refinement (computing);system on a chip;systems design;very-large-scale integration	Paul E. R. Lippens;Vijay Nagasamy;Wayne H. Wolf	1995		10.1145/224841.225100	chip;system on a chip;embedded system;computer architecture;electronic engineering;real-time computing;telecommunications;computer science;operating system;very-large-scale integration;memory bandwidth;computer engineering;systems design	EDA	4.806963198346523	53.57800642285483	7740
2b94de45b74b4df82bfef613935f34b2f04c19dd	a systolic vlsi matrix for a family of fundamental searching problems	systolic arrays;database machines;searching;general range queries;vlsi design rule checking;pattern matching;vlsi;rectangle intersections;real time statistics	A simple and general VLSI-architecture, designed to solve a family of basic searching problems, is presented. The actual chip (the H-matrix) may generally be set up to trap requested objects or to detect specific properties in high-rate bit-serial datastreams flowing through the chip. The most important problem for which the design is applicable corresponds to the database operation known as General Range Queries which includes standard String Pattern Matching. The problem of reporting intersecting pairs in large sets of rectilinear rectangles, a crucial step in checking the design rules for VLSI circuitry, is also a member in the family of problems that can be handled. Other possible applications of the design, such as real-time collection of statistics and distribution sorting, are discussed. A hierarchical implementation of the critical cells, described by familiar high-level language notations, is presented. The actual design has been successfully implemented in NMOS.	very-large-scale integration	Arne Halaas	1983	Integration	10.1016/S0167-9260(83)80002-9	embedded system;discrete mathematics;computer science;theoretical computer science;operating system;pattern matching;mathematics;very-large-scale integration;programming language;algorithm	Theory	18.797209258824203	40.16940892544218	7745
43c8cc410b00cb8fda7f9f0b9d5ec21f88b24333	bipartite graphs totally decomposable by canonical decomposition	split decomposition;modular decomposition;canonical decomposition;bicograph;bipartite graph	We describe here a technique of decomposition of bipartite graphs which seems to be as interesting within this context as the well known modular and split techniques for the decomposition of general graphs. In particular, we characterize by forbidden subgraphs the family of bipartite graphs which are totally decomposable (i.e. reducible to single vertices) with respect to our decomposition. This family contains previously known families of graphs such as bicographs and P6-free bipartite graphs. As an application we provide polynomial solutions of optimization problems, some of them being NP-complete for general bipartite graphs.	unicode equivalence	Jean-Luc Fouquet;Vassilis Giakoumakis;Jean-Marie Vanherpe	1999	Int. J. Found. Comput. Sci.	10.1142/S0129054199000368	strong perfect graph theorem;1-planar graph;pathwidth;complete bipartite graph;combinatorics;discrete mathematics;robertson–seymour theorem;cograph;topology;bipartite graph;dense graph;hopcroft–karp algorithm;pancyclic graph;forbidden graph characterization;metric dimension;permutation graph;mathematics;tree-depth;maximal independent set;modular decomposition;biregular graph;chordal graph;indifference graph;matching	Logic	25.647935263531203	26.54765827845263	7746
ee4e91e8546649fd5458205c6308b7b7d90b28c3	a closed form maximum likelihood estimator to end-to-end loss rate estimation	closed form solution;maximum likelihood;internet architecture;maximum likelihood estimate;maximum likelihood principle	Loss tomography has been studied for more than 10 years and a number of estimators have been proposed. The estimators can be divided into two classes: maximum likelihood and non-maximum likelihood. The maximum likelihood estimators rely on the maximum likelihood principle to ensure the accuracy of the estimates obtained by the estimators. Unfortunately, all of the maximum likelihood estimators need to use an iterative procedure to search the solution space for the maximum or to solve a high degree polynomial. An iterative procedure can be computationally expensive and may even converge to a local maximum. On the other hand, the non-maximum likelihood estimators pursue closed form solutions by scarifying the accuracy of estimates. To overcome the pitfalls, we, in this paper, propose a closed form and maximum likelihood estimator to estimate the loss rate of a link in a network. The closed form solution is built on the discovery of a connection between the number of probes passing a link and the number of probes passing its parent. The proposed estimator is applicable to both the tree topology and the general one.	analysis of algorithms;converge;feasible region;iterative method;maxima and minima;polynomial;tomography;tree network	Weiping Zhu	2011	CoRR		econometrics;mathematical optimization;score test;expectation–maximization algorithm;likelihood-ratio test;maximum a posteriori estimation;m-estimator;mathematics;restricted maximum likelihood;maximum likelihood;likelihood function;quasi-maximum likelihood;maximum likelihood sequence estimation;estimation theory;statistics;estimating equations	ML	49.40656862737029	5.5492983038483015	7749
4cd454d5c68652e9cd9a8ee072534331348ea2f0	memory slices: a modular building block for scalable, intelligent memory systems		While reduction in feature size makes computation cheaper in terms of latency, area, and power consumption, performance of emerging data-intensive applications is determined by data movement, which is becoming more costly. These trends have introduced the concept of scalability as reaching a desirable performance per unit cost by using as few number of units as possible. Therefore, many proposals have moved compute closer to the memory, used modular and parallel architectures, and utilized interconnection networks. However, these efforts ignored maintaining a balance between bandwidth and compute rate of an architecture, with those of applications, which is a key principle in designing scalable large systems. This paper proposes the use of memory slices, a modular building block for scalable memory systems integrated with compute, in which performance scales with memory size (and volume of data). The slice architecture utilizes a programmable memory interface feeding a systolic compute engine with high reuse rate. The modularity feature of slice-based systems is exploited with a partitioning and data mapping strategy across allocated memory slices where training performance scales with the data size. These features enable shifting the most pressure to cheap compute units rather than expensive memory accesses or transfers via interconnection network. An application of the memory slices to a scale-out memory system is accelerating the training of recurrent, convolutional, and hybrid neural networks (RNNs and RNNs+CNN) that are forming cloud workloads. The results of our cycle-level simulations show that memory slices exhibits a superlinear speedup when the number of slices increases. Furthermore, memory slices improve power efficiency to 747 GFLOPs/J for training LSTMs. While our current evaluation uses memory slices with 3D packaging, a major value is that slices can also be constructed with a variety of packaging options, for example with DDR-based memory units.		Bahar Asgari;Saibal Mukhopadhyay;Sudhakar Yalamanchili	2018	CoRR		parallel computing;real-time computing;data mapping;speedup;scalability;architecture;latency (engineering);artificial neural network;modular design;computer science;cloud computing	HPC	3.0496871591842147	43.290227104641275	7766
689ec4b44b2ab7b02cdd34e5056ca806bdc2c779	an image compression for embedded eye-tracking applications	image coding;object tracking gaze tracking human computer interaction image coding;codecs;image coding transform coding codecs delays bit rate frequency domain analysis wireless sensor networks;frequency domain analysis;region of interest compression image compression embedded eye tracking human machine interaction hmi human eye movement wearable form factor power consumption heat generation em radiation wireless data transmission image capturing;transform coding;bit rate;wireless data transmission embedded eye tracking human machine interaction fpga image compression;wireless sensor networks;delays	Human-machine interaction is becoming a sufficient part of coming future. Being a bright example of HMI, embedded eye-tracking systems allow user to interact with objects by using human's eye-movements. Due to wearable form-factor, developed eye-tracking system has to conform to low-power consumption, low-heat generation and low EM radiation as well as support wireless data transmission and be space efficient. Image capturing, finding of region of interest (ROI), compression of ROI and wireless transmission of compressed data are very beginning steps of the whole algorithm of finding coordinates of pupil. Therefore, area of concentration is to make them as performant as possible from theoretical point of view to further implementation. Combination of hardware powered ROI-finder coupled with well-tuned and optimized image compression system is aimed to speed-up wireless delivery of ROI-images to processing unit. Details of design of such system are presented and discussed.	algorithm;data compression;embedded system;eye tracking;form factor (design);image compression;low-power broadcasting;point of view (computer hardware company);region of interest;tracking system;user interface;wearable computer	Pavel Morozkin;Marc Swynghedauw;Maria Trocan	2016	2016 International Symposium on INnovations in Intelligent SysTems and Applications (INISTA)	10.1109/INISTA.2016.7571852	data compression;embedded system;computer vision;real-time computing;image compression;computer science	Embedded	-1.2294038814966026	60.23157554486918	7780
7a67a06a1b5032c7ce4a24663eb737d70124667e	towards a computational theory of statistical tests (extended abstract)	computability theory;universal statistical tests;counter machines computational theory statistical tests algorithm universal statistical tests complexity;computational theory;statistical test;testing;complexity;statistical analysis automata theory computational complexity;polynomials;algorithm;counting circuits;statistical analysis;computational complexity;fault detection;statistics;testing polynomials computer science counting circuits computational complexity sampling methods fault detection writing statistics;writing;automata theory;statistical tests;computer science;counter machines;sampling methods	We initiate a computational theory of statistical tests. Loosely speaking, we say that an algorithm is a statistical test if it rejects a “negligible” fraction of strings. We say tha t a statistical test is universal for a class of algori thms if it rejects all (but finitely many) of the strings rejected by each algorithm in the class. We consider the existence and efficiency of universal statistical tests for various classes of statistical tests. We also consider the relation between ensembles passing statistical tests of particular complexity and ensembles which are indistinguishable from uniform by algorithms of the same complexity. Some of our results refer to relatively simple statistical tests (e.g., those implemented by counter machines). In addition to their own merit, we hope that these results will stimulate investigations directed towards results that refer to more complex statistical tests (e.g., those implemented in log-space).	algorithm;counter machine;theory of computation	Manuel Blum;Oded Goldreich	1992		10.1109/SFCS.1992.267749	statistical hypothesis testing;combinatorics;statistical theory;theory of computation;computer science;theoretical computer science;mathematics;algorithm;statistics	Theory	9.297674504670296	21.053043763054113	7788
cacc0e3adb2e5373f592cbc1219937adab59f2bf	introduction to jpdc special issue on computing with future nanotechnology		One of the premier challenges for electronics research in the 21st Century is to build computing systems that can overcome the fundamental limitations of scaled CMOS.With significant advances in the physical sciences on the assembly, manipulation and characterization of nanoscale structures, the vision of achieving computation with emerging materials and technologies is closer to fruition. Consequently, there is a need for exploratory research into new types of nanosystems that can uniquely leverage such nanomaterials to achieve both new capabilities beyond, and orders of magnitude efficiency improvements over conventional CMOSbased solutions. At the same time, there is a need to make both CMOS and emerging technologies resilient to defects, imprecision in manufacturing processes and environmental factors. This special issue on ‘Computing with Future Nanotechnology’ seeks to bring to the forefront research efforts that address several fundamental questions in nanoscale system design, including— what kinds of circuits, logic styles and architectures can we build based on novel materials and devices? Can we use non-charge based physical phenomena (electron spin and optics) in unique ways to achieve computation? How can we design robust systems with critical dimensions of a few nanometers, where high defect rates and a high degree of parameter variation are inevitable? How do we quantify the benefits of such emerging systems over conventional technology? The first four papers in this issue address directions to build logic solutions for reconfigurable computing and applicationspecific circuits using emerging technologies. The first paper proposes to exploit the non-volatility of Resistive RAMs, which are 2-terminal resistive elements, as configuration cells and non-volatile registers in FPGAs for ‘‘normally-off, instantly-on’’ applications. The second paper on Spin-Threshold Logic (STL) proposes non-volatile logic combining conventional MOSFETs with STT-MTJ (Spin Torque Transfer-Magnetic Tunneling Junction) resistive elements to realize extremely compact representations of programmable complex threshold functions for FPGAs. The next paper discusses a new spin-based Emitter-Coupled Logic (ECL) style using bipolar magnetic junction transistors for implementing high-speed low-power application-specific circuits. The last paper in this section explores nanoscale computing using optical devices for implementing digital logic. Optical waveguides are used for communication between logic elements. In addition to efficient logic design, there is also a need to developnovelmemory concepts for future computingwhich is the focus of the second section of the special issue. The first paper in this section explores the design of non-volatile memory systems based on crossbar arrays of resistive memory elements such as RRAMs	boolean algebra;cmos;computation;crossbar switch;electron;emitter-coupled logic;field-programmable gate array;grammar-based code;logic programming;low-power broadcasting;microsoft forefront;non-volatile memory;reconfigurable computing;resistive touchscreen;software bug;systems design;transistor;tunneling protocol;volatile memory;volatility	Csaba Andras Moritz;Santosh Khasanvis;Pritish Narayanan	2014	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2014.02.007	computer engineering;distributed computing;computer science	EDA	11.813763297313892	58.19342406579634	7799
aaa0f841230b1119b5b314ceaa6e65797ba161ba	cramer-rao bounds for estimating range, velocity, and direction with an active array	temporal correlation;doppler shift estimation cramer rao bounds active sonar array active radar array range estimation velocity estimation direction estimation cramer rao bound expressions point target general crb expressions array model narrowband signal space time separable noise model spatial correlation temporal correlation ambiguity function temporally white noise signal shape linear frequency modulated pulse sequence chirp pulse sequence 3d array isotropic sensors spatially white noise array geometry moments of inertia confidence region volume accuracy measure target location accuracy doa estimation time delay estimation;deplacement doppler;time correlation;desigualdad cramer rao;sequences;array processing;reseau capteur;temporally white noise;doppler shift fm radar array signal processing chirp modulation delay estimation direction of arrival estimation radar signal processing sequences sonar signal processing white noise;linear frequency modulated pulse sequence;deteccion blanco;array geometry;observation radar;active sonar array;doppler shift estimation;modelo 3 dimensiones;point target;general crb expressions;correlation temporelle;cramer rao bounds;bepress selected works;spatially white noise;modele 3 dimensions;array model;sequences array signal processing radar signal processing sonar signal processing direction of arrival estimation white noise chirp modulation fm radar doppler shift delay estimation;time delay estimation;signal bande etroite;delay effects;doa estimation;three dimensional model;signal shape;sensor arrays white noise chirp modulation pulse modulation delay effects doppler shift doppler radar sonar narrowband noise shaping;array signal processing;fonction ambiguite;blanco movil;indexing terms;direction estimation;cramer rao inequality;confidence region volume;detection cible;correlacion temporal;correlation spatiale;red sensores;spatial correlation;correlacion espacial;moments of inertia;cramer rao bound expressions;3d array	We derive Cramér–Rao bound (CRB) expressions for the range (time delay), velocity (Doppler shift), and direction of a point target using an active radar or sonar array. First, general CRB expressions are derived for a narrowband signal and array model and a space-time separable noise model that allows both spatial and temporal correlation. We discuss the relationship between the CRB and ambiguity function for this model. Then, we specialize our CRB results to the case of temporally white noise and the practically important signal shape of a linear frequency modulated (chirp) pulse sequence. We compute the CRB for a three-dimensional (3-D) array with isotropic sensors in spatially white noise and show that it is a function of the array geometry only through the “moments of inertia” of the array. The volume of the confidence region for the target’s location is proposed as a measure of accuracy. For this measure, we show that the highest (and lowest) target location accuracy is achieved if the target lies along one of the principal axes of inertia of the array. Finally, we compare the location accuracies of several array geometries.	ambiguity function;broadcast delay;chirp;doppler effect;modulation;sonar (symantec);sensor;velocity (software development);white noise	Aleksandar Dogandzic;Arye Nehorai	2001	IEEE Trans. Signal Processing	10.1109/78.923295	spatial correlation;index term;noise shaping;doppler effect;telecommunications;moment of inertia;sequence;pulse-width modulation;mathematics;white noise;sensor array;sonar;statistics;ambiguity function	Robotics	53.268356807243414	9.172424514626362	7839
b8dff8f491d6dd73764206e59759340bef863cfd	approximation schemes for bin packing	bin packing	In the bin-packing problem, the input consists of a collection of items specified by their sizes. There are also identical bins, which without loss of generality can be assumed to be of size 1, and the goal is to pack these items using the minimum possible number of bins. Bin packing is a classic optimization problem, and hundreds of its variants have been defined and studied under various settings such as average case analysis, worst-case off-line analysis, and worst-case online analysis. This note considers the most basic variant mentioned above under the off line model where all the items are given in advance. The problem is easily seen to be NP-hard by a reduction from the partition problem. In fact, this reduction implies that unless P = NP, it is impossible to determine in polynomial time whether the items can be packed into two bins or whether they need three bins.	approximation;bin packing problem;set packing	Nikhil Bansal	2016		10.1007/978-1-4939-2864-4_31	time complexity;mathematical optimization;without loss of generality;case analysis;bin packing problem;optimization problem;partition problem;mathematics	Theory	15.973297427335588	11.699995088542089	7847
1f3e86f508aa682ad507336d797d8ea75b7db499	piotrowski's infinite series of steiner quadruple systems revisited	steiner systems;quadruple systems;infinite series	The construction of Bays and deWeck [1] of a Steiner Quadruple System SQ S(14) was generalized by Piotrowski in his dissertation ([7], p. 34) to an SQS(2p), p≡ 7mod 12 with a group transitive on the points. However he gave no proof of his construction and his presesntation was open to misinterpretation. So Hanfried Lenz suggested to analysePiotrowski’s construction and to supply it with a proof. In the followingwe will present Piotrowski’s ideas somewhat differently and will furnish a proof of the construction.	quadruple-precision floating-point format;sound quality;steiner tree problem	Helmut Siemon	1996	Des. Codes Cryptography	10.1023/A:1018009715432		Theory	44.4581838840574	29.623733998694398	7848
3dbf554af202cf4861b8fb6466e57a632fc4b4d3	redundant multitrack (d, k) codes	generalizacion;notice of violation;error correction codes;recording;decoding;registro numerico;photonic integrated circuits;modulacion;storage densities;modulation codes;satisfiability;synchronisation block codes encoding modulation recording;codificacion rll;synchronisation;codificacion;generalisation;faulty tracks;digital recording;synchronization;abstracts;modulation coding photonic integrated circuits decoding abstracts block codes information theory error correction codes magnetic modulators optical recording;modulation coding;enregistrement numerique;optical recording;coding;optical recording systems;magnetic modulators;redundant multitrack codes;faulty tracks redundant multitrack codes modulation codes multitrack run length limited codes storage densities magnetic recording systems optical recording systems encoding synchronization;rll encoding;encoding;block codes;magnetic recording systems;generalization;information theory;multitrack run length limited codes;codage;codage rll;run length limited;modulation	Multitrack run-length-limited (d, k) modulation codes were recently introduced as a method to increase storage densities in magnetic and optical recording systems. These codes are a generalization of the usual run-length-limited (d, K) codes and provide for increased storage density by relaxing the k-constraint and encoding multiple tracks in parallel. Previously, n-track (d, K) codes used all n tracks to satisfy the K constraint causing synchronization to be completely intolerant of faulty tracks. The authors present multitrack (d, k) codes which allow for r faulty tracks by mandating that all subsets of n-r tracks satisfy the K constraint. >	code	Edward K. Orcutt;Michael W. Marcellin	1993	IEEE Trans. Information Theory	10.1109/18.259669	generalization;synchronization;telecommunications;information theory;computer science;theoretical computer science;mathematics;statistics	Theory	39.510511025998504	59.38348049539093	7851
5d32298f73c57ca7f18c734ae28f8b47aae48b39	a platform-based methodology for system-level mixed-signal design	signal image and speech processing;circuits and systems;control structures and microprogramming;electronic circuits and devices	The complexity of today’s embedded electronic systems as well as their demanding performance and reliability requirements are such that their design can no longer be tackled with ad hoc techniques while still meeting tight time to-market constraints. In this paper, we present a system level design approach for electronic circuits, utilizing the platform-based design (PBD) paradigm as the natural framework for mixed-domain design formalization. In PBD, a meet-in-the-middle approach allows systematic exploration of the design space through a series of top-down mapping of system constraints onto component feasibility models in a platform library, which is based on bottom-up characterizations. In this framework, new designs can be assembled from the precharacterized library components, giving the highest priority to design reuse, correct assembly, and efficient design flow from specifications to implementation. We apply concepts from design centering to enforce robustness to modeling errors as well as process, voltage, and temperature variations, which are currently plaguing embedded system design in deep-submicron technologies. The effectiveness of our methodology is finally shown on the design of a pipeline A/D converter and two receiver front-ends for UMTS and UWB communications.		Pierluigi Nuzzo;Xuening Sun;Chang-Ching Wu;Fernando De Bernardinis;Alberto L. Sangiovanni-Vincentelli	2010	EURASIP J. Emb. Sys.	10.1155/2010/261583	embedded system;real-time computing;probabilistic design;computer science;operating system	EDA	4.3567854145775895	54.80659151698416	7859
5ed9d76e61c717e50ea50b3eeaedc513ef96d9e7	impact of range and precision in technology on cell-based design	libraries;cmos integrated circuits;logic simulation;delay logic gates libraries threshold voltage system on a chip standards benchmark testing;standards;integrated circuit design cmos integrated circuits delays;system on a chip;signal probability;integrated circuit design;redundancy;logic gates;threshold voltage;gate sizing cell based design nonplanar cmos technology delay performance power suboptimality estimation standard cell library design;sampling methods;monte carlo simulation;benchmark testing;delays	With the introduction of non-planar CMOS technologies in commercial designs, the effects of the range and precision allowed in a technology is an important. The limited range and precision (i.e. granularity) in a technology, and consequently, in a standard cell design, may result in significant penalties in the power and delay performance in a design. In this work, the impact of the range and precision is examined by providing a new framework for estimating the power suboptimality incurred by a design relative to a given library. Methods that predict the suboptimality well, both qualitatively and quantitatively, and the implications on standard cell library design are explored. While no other methods for estimating suboptimality are known, compared to a method derived from literature, our method provides a nearly 2x better estimate for vth assignment and 10x improvement for gate sizing.	cmos;convex function;library (computing);standard cell	John Lee;Puneet Gupta	2012	2012 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	10.1145/2429384.2429426	system on a chip;benchmark;sampling;electronic engineering;real-time computing;logic gate;computer science;engineering;electrical engineering;logic simulation;redundancy;threshold voltage;cmos;monte carlo method;integrated circuit design	EDA	19.994334772187205	58.0904900232422	7864
8ad9638fc14a8e72ae514b99f3a53c5200b9f83d	synthesis of standard functions and generic ex-or module using layered t gate		The quantum-dot cellular automata (QCA) which is the most promising technology in the paradigm of nano electronics has already been claimed to possess ultra-high packing density, high clocking speed and extremely low power dissipation. This work proposes a novel design of high fan-in exclusive-OR gate by using the layered T Gate of QCA. The u0027robustness analysisu0027 of layered T gate has also been done to focus the advantage of layered T architecture in generic sense considering the defects of QCA. The synthesis of u0027three-literal standard functionsu0027 by using layered T gate reports an average 29.31% less area requirement as compared to the best reported design so far. Primarily two-input layered T exclusive OR shows 18.75% less cell requirement and 6.20% less area requirement as compared to the conventional two-input exclusive OR designs. Finally, two-input layered T exclusive OR module extends its design methodology to implement high fan-in exclusive OR gate designs with proper formulation of O-Cost and delay...		Chiradeep Mukherjee;Saradindu Panda;Asish Kumar Mukhopadhyay;Bansibadan Maji	2017	IJHPSA	10.1504/IJHPSA.2017.10008112	robustness (computer science);computer science;cellular automaton;parallel computing;nanoelectronics;architecture;sphere packing;quantum dot cellular automaton;exclusive or;xor gate	Crypto	15.904810535735386	45.844286603042256	7867
0485ae97c51f0e6c522c3ebf786e46a8fd3ed2c8	on algorithms for efficient data migration	verification;edge coloring;edge dominating set;coloring;clique width;data migration;dominating set;theory;algorithms;polynomial algorithms	The data migration problem is the problem of computing an efficient plan for moving data stored on devices in a network from one configuration to another. Load balancing or changing usage patterns could necessitate such a rearrangement of data. In this paper, we consider the case where the objects are fixed-size and the network is complete. The direct migration problem is closely related to edge-coloring. However, because there are space constraints on the devices, the problem is more complex. Our main results are polynomial time algorithms for finding a near-optimal migration plan in the presence of space constraints when a certain number of additional nodes is available as temporary storage, and a 3/2-approximation for the case where data must be migrated directly to its destination.	algorithm;edge coloring;graph coloring;load balancing (computing);time complexity	Joseph Hall;Jason D. Hartline;Anna R. Karlin;Jared Saia;John Wilkes	2001			mathematical optimization;combinatorics;data migration;verification;dominating set;clique-width;edge coloring;mathematics;distributed computing;theory	Theory	18.790439835507804	14.194453498007508	7870
fe111fe1d1f73eb006280f4cda839f868d435f73	an o(n log log n)-time algorithm for triangulating a simple polygon	jordan sorting with error correction;horizontal visibility information;simplicity testing;amortized time;68p05;homogeneous finger search tree;68q25;heterogeneous finger search tree;balanced divide and conquer;51m15	Given a simple n-vertex polygon, the triangulation problem is to partition the interior of the polygon into n-2 triangles by adding n-3 nonintersecting diagonals. We propose an O(n log logn)-time algorithm for this problem, improving on the previously best bound of O (n log n) and showing that triangu-lation is not as hard as sorting. Improved algorithms for several other computational geometry problems, including testing whether a polygon is simple, follow from our result.	algorithm;computational geometry;sorting;time complexity	Robert E. Tarjan;Christopher J. Van Wyk	1988	SIAM J. Comput.	10.1137/0217010	mathematical optimization;combinatorics;amortized analysis;computer science;star-shaped polygon;mathematics;monotone polygon;programming language;polygon covering;polygon triangulation;pick's theorem;algorithm	Theory	30.43726653861744	19.48179396407394	7877
9a8ad00b08f405634d3421fc857689a245ff705b	normalized divide-and-conquer: a scaling technique for solving multi-dimensional problems	informatica;probleme element maximal;mathematics;complexite calcul;complejidad calculo;normalisation;geometrie algorithmique;maximal element problem;reduction;computational geometry;dimension;computing complexity;taille;interseccion;grid;resolucion problema;multi dimensional;natuurwetenschappen;methode diviser pour gagner;dimensions;problema elemento maximo;ordered by external client;probleme rectangle;rejilla;informatique theorique;talla;divide and conquer method;normalizacion;probleme multidimensionnel;grille;problema retangulo;reduccion;problema multimensional;landbouwwetenschappen;intersection;size;rectangle problem;divide and conquer;multidimensional problem;standardization;wiskunde en informatica wiin;problem solving;resolution probleme;computer theory;informatica teorica	Abstract   A new technique, named  normalized divide-and-conquer ,is presented to solve multi-dimensional problems on a grid in a very efficient way. It is also shown that a number of problems concerning objects in arbitrary space can be transformed into problems on a grid by using another form of normalization. In this way, new solutions are obtained for the multi-dimensional maximal elements and rectangle intersection problem that are more efficient than previous solutions.	scalability	Rolf G. Karlsson;Mark H. Overmars	1988	Inf. Process. Lett.	10.1016/0020-0190(88)90188-3	computational geometry;calculus;mathematics;geometry;dimension	PL	29.23587080285722	16.294935686962045	7891
b07baa72e1f61224e1957f5df3db3fe5a1b48b96	near-optimal detection with constant false alarm ratio in varying impulsive interference	biparameter cgm model;nongaussian statistic model;far;varying impulsive interference;near optimal detection;cauchy gaussian mixture model;probability;gaussian processes;cgm model;impulse noise;signal detection;azmnl near optimal detection constant false alarm ratio varying impulsive interference nongaussian statistic model α stable distribution closed form probability density function pdf suboptimal zero memory nonlinearity function locally optimal detector classical cauchy zmnl gaussian tailed zmnl gzmnl cauchy gaussian mixture model cgm model biparameter cgm model classical gaussian mixture model far algebraic tailed zmnl;statistical distributions gaussian processes impulse noise interference signal probability signal detection;constant false alarm ratio;algebraic tailed zmnl;journal;i stable distribution;statistical distributions;interference signal;azmnl;alpha stable distribution;classical gaussian mixture model;closed form probability density function;pdf;locally optimal detector;suboptimal zero memory nonlinearity function;gzmnl;classical cauchy zmnl;gaussian tailed zmnl	As an important class of non-Gaussian statistic model, α-stable distribution has received much attention because of its generality to represent impulsive interference. Unfortunately, it does not have a closed-form probability density function (PDF) except for a few cases. For this reason, suboptimal zero-memory non-linearity (ZMNL) function has to be used as an approximation in designing locally optimal detector, such as classical Cauchy and Gaussian-tailed ZMNL (GZMNL). To enhance the performance of detectors, the authors first investigate the approximate PDFs for the symmetric α-stable. In particular, a simplified version of Cauchy–Gaussian mixture (CGM) model, called bi-parameter CGM (BCGM) model is detailed. This BCGM model has a concise closed-form, and hence is more tractable than the classical Gaussian mixture model and CGM model. Then based on the preset false alarm ratio (FAR), the test threshold is adaptively evaluated by using BCGM to maintain a constant FAR. The authors further devise an algebraic-tailed ZMNL (AZMNL) with a simplified form. Simulation results show that the detector with AZMNL outperforms the ones with classical Cauchy and GZMNL, and achieves near-optimal performance in varying impulsive interference.	interference (communication)	Xutao Li;Jun Sun;Shouyong Wang;Lisheng Fan;Li Chen	2013	IET Signal Processing	10.1049/iet-spr.2013.0024	probability distribution;econometrics;mathematical optimization;impulse noise;probability;gaussian process;mathematics;statistics;detection theory	Theory	50.966695775228715	11.877627534868225	7892
0b268267c30a90c4fe2f79cc1ef4e367b39deb34	gate sizing and device technology selection algorithms for high-performance industrial designs	graph theory;optimisation;power analysis;timing analysis gate sizing algorithm device technology selection algorithm high performance industrial designs lagrangian relaxation based formulation graph model discrete graph problem signoff timing engine industrial optimization flow leakage power reductions microprocessor blocks;design engineering;timing approximation theory design engineering graph theory integrated circuit manufacture microprocessor chips optimisation sizing materials processing;sizing materials processing;leakage power reduction;approximation theory;low power;delay optimization computational modeling logic gates libraries load modeling;trace compaction;timing analysis;trace compression;graph model;high performance;integrated circuit manufacture;microprocessor chips;lagrangian relaxation;industrial design;timing	It is becoming more and more important to design high performance designs with as low power as possible. In this paper, we study the gate sizing and device technology selection problem for today's industrial designs. We first outline the typical practical problems that make it difficult to use the traditional algorithms on high-performance industrial designs. Then, we propose a Lagrangian Relaxation (LR) based formulation that decouples timing analysis from optimization without resulting in loss of accuracy. We also propose a graph model that accurately captures discrete cell type characteristics based on library data. We model the relaxed Lagrangian subproblem as a discrete graph problem, and propose algorithms to solve it. In our experiments, we demonstrate the importance of using the signoff timing engine to guide the optimization. Compared to a state-of-the art industrial optimization flow, we show that our algorithms can obtain up to 38% leakage power reductions and better overall timing for real high-performance microprocessor blocks.	central processing unit;experiment;lr parser;lagrangian relaxation;mathematical optimization;microprocessor;relaxation (approximation);selection algorithm;spectral leakage;static timing analysis	Muhammet Mustafa Ozdal;Steven M. Burns;Jiang Hu	2011	2011 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	10.1109/ICCAD.2011.6105409	mathematical optimization;electronic engineering;real-time computing;industrial design;power analysis;lagrangian relaxation;computer science;graph theory;mathematics;engineering drawing;static timing analysis;statistics;approximation theory	EDA	15.623742932417658	54.57616024319028	7907
e88131367e6559d3b8698edf59d50ac0048bacec	a distributed approach to taming peak demand	distributed processing centralised control demand side management;demand side management;distributed processing;load modeling home appliances power generation protocols electric vehicles schedules;centralised control;centralized control authority distributed approach taming peak demand energy capacity distributed computing principles decentralize management	A significant portion of all energy capacity is wasted in over-provisioning to meet peak demand. The current state-of-the-art in reducing peak demand requires central authorities to limit device usage directly, and are generally reactive. We apply techniques drawn from established distributed computing principles to propose a novel and proactive solution to decentralize management of demand and to provide a more scalable and resilient approach to reducing overall peak demand. We demonstrate that such a system approaches the performance of an ideal centralized control authority, and experimentally demonstrate a 10-25% reduction in peak energy demand under conservative assumptions. Under worst-case demand scenarios, our approach has the potential to reduce peak demand by 65-85%.	best, worst and average case;centralized computing;distributed computing;experiment;provisioning;scalability	Michael Sabolish;Ahmed M Amer;Tom M. Kroeger	2012	2012 International Green Computing Conference (IGCC)	10.1109/IGCC.2012.6322286	real-time computing;simulation;economics;operations management	HPC	2.3294484880881456	5.677092658103406	7910
963c1b196ad1b1971c20c932e933719a4e35185e	the case for a balanced decomposition process	leku examples;experimental method;circuit synthesis upper bound table lookup field programmable gate arrays size measurement digital systems design methodology circuit testing logic circuits combinational circuits;decomposition;network synthesis;bi decomposition;parity;data mining;upper bound;balanced decomposition process;logic synthesis;parity network synthesis;logic synthesis balanced decomposition process synthesis tools leku examples parity examples;leku decomposition bi decomposition example;optimization;synthesis tools;field programmable gate arrays;combinational circuit;switches;leku;table lookup;example;benchmark testing;circuit synthesis;parity examples	We present experiments with synthesis tools using examples which are currently believed to be very hard, namely the LEKU examples by Cong and Minkovich and parity examples of our construction. In both cases, we found a way to produce reasonable results with existing tools. We identify the abilities that are crucial for achieving such results, and also generalize them to avoid similar cases of poor performance in future tools.	and gate;exclusive or;experiment	Jan Schmidt;Petr Fiser	2009	2009 12th Euromicro Conference on Digital System Design, Architectures, Methods and Tools	10.1109/DSD.2009.156	network synthesis filters;embedded system;benchmark;logic synthesis;network switch;parity;computer science;theoretical computer science;combinational logic;upper and lower bounds;decomposition;algorithm;field-programmable gate array	EDA	20.64589938223619	48.40980565080146	7930
280e6c1036f2dae33b2977ff438edc4904cb05cc	burnside monoids, word problem and the conjecture of brzozowski	word problem		free monoid	Jean-François Rey	1993		10.1007/3-540-59340-3_15	word problem;computer science	Theory	45.93466037866654	30.731112259655067	7931
ce4094215e19ebfa77d4904d4a9a6873d5ff7244	chaitin omega numbers and strong reducibilities	turing machine	 We prove that any Chaitin # number (i.e., the halting probability of a universalself-delimiting Turing machine) is wtt-complete, but not tt-complete. In this waywe obtain a whole class of natural examples of wtt-complete but not tt-complete r.e.sets. The proof is direct and elementary.1 IntroductionKucera [8] has used Arslanov's completeness criterion1to show that all random sets ofr.e. T-degree are in fact T-complete. Hence, every Chaitin # number is T-complete. Inthis paper we... 	chaitin's constant;omega	Cristian S. Calude;André Nies	1997	J. UCS	10.3217/jucs-003-11-1162	description number;probabilistic turing machine;reduction (recursion theory);universal turing machine;theoretical computer science;computer science;turing machine;algorithm;algorithmic information theory;chaitin's constant;technical report	Logic	0.7000219679148859	21.814553052424596	7937
01bb9d1ae610888e434d44f23e87dfcf4cd0d102	construction and optimization of csg representations	concepcion asistida;computer aided design;modelo 3 dimensiones;computer graphics;modele 3 dimensions;geometrie solide constructive;geometrie constructive;three dimensional model;problema inverso;boolean algebra;representation frontiere;inverse problem;geometria constructiva;algebre boole;conception assistee;constructive geometry;grafico computadora;probleme inverse;infographie;algebra boole	Boundary representations (B-reps) and constructive solid geometry (CSG) are widely used representation schemes for solids. While the problem of computing a B-rep from a CSG representation is relatively well understood, the inverse problem of B-rep to CSG conversion has not been addressed in general. The ability to perform B-rep to CSG conversion has important implications for the architecture of solid modelling systems and, in addition, is of considerable theoretical interest.#R##N##R##N#The paper presents a general approach to B-rep to CSG conversion based on a partition of Euclidean space by surfaces induced from a B-rep, and on the well known fact that closed regular sets and regularized set operations form a Boolean algebra. It is shown that the conversion problem is well defined, and that the solution results in a CSG representation that is unique for a fixed set of halfspaces that serve as a ‘basis’ for the representation. The ‘basis’ set contains halfspaces induced from a B-rep plus additional non-unique separating halfspaces.#R##N##R##N#An important characteristic of B-rep to CSG conversion is the size of a resulting CSG representation. We consider minimization of CSG representations in some detail and suggest new minimization techniques.#R##N##R##N#While many important geometric and combinatorial issues remain open, a companion paper shows that the proposed approach to B-rep to CSG conversion and minimization is effective in E2, In E3, an experimental system currently converts natural-quadric B-reps in PARASOLID to efficient CSG representations in PADL-2.	constructive solid geometry;mathematical optimization	Vadim Shapiro;Donald L. Vossler	1991	Computer-Aided Design	10.1016/0010-4485(91)90077-A	boolean algebra;combinatorics;inverse problem;computer aided design;mathematics;geometry;computer graphics	EDA	52.70560942193	32.29310176795672	7956
5596698036c26cf171a86707378c701be00faa41	some v(12, t) vectors and designs from difference and quasi-difference matrices		In this paper we provide examples of V(12, t) vectors for 800 ≤ 12t+1 ≤ 5000, and the 3 unknown V(m, t) vectors with m = 8, 9. We also provide other examples of transversal and incomplete designs, coming from difference and quasi-difference matrices. These include a TD(6, 34), a TD(7, v) for v = 28, 42, 44, 52, 54, 62, an updated list of unknown TDλ(9, v) for λ > 1 and 2 ITDs which give (v, 6, 1) BIBDs for v ∈ {496, 526}.	emoticon	R. Julian R. Abel	2008	Australasian J. Combinatorics		mathematical analysis;mathematics;matrix (mathematics)	ML	40.258658991856	35.96048007235991	7972
d9585cd4e42b7dca8fb3e1081819c3b05c3cb5e2	evaluating the damage associated with intentional network disintegration	damage;defense;two dimensional destruction spectrum;complex network;spectrum;vulnerability;network topology;multi dimensional;protection;contest success function;attack;network structure;network;disintegration	This paper presents a method for evaluating an expected damage associated with disintegrating complex networks with a given topology into isolated sub-networks (clusters) as a result of intentional attack on randomly chosen network links. The method is based on a multi-dimensional spectra approach for evaluating the probability of network disintegration into a given number of sub-networks when a fixed number of randomly chosen links is eliminated. It also uses the contest success function that evaluates destruction probability of individual links as a function of per-link attack and defense efforts. It is assumed that the defender has no information about the attacker's actions and the attacker has no information about the network structure. The method allows the analysts to compare different network topologies and to choose one with the minimal expected damage under conditions of uncertainty. Illustrative examples are presented.		Gregory Levitin;Ilya B. Gertsbakh;Yoseph Shpungin	2011	Rel. Eng. & Sys. Safety	10.1016/j.ress.2010.12.022	spectrum;attack;vulnerability;network formation;computer science;engineering;artificial intelligence;network simulation;forensic engineering;computer security;network topology;complex network	Security	-3.7019440118054856	6.2934046918222055	7974
35b72b990ce740506be65bdaa4218162cac1aff3	storing the subdivision of a polyhedral surface	nearest neighbor queries;computational geometry;data structure;planar graph;voronoi diagram	A common structure arising in computational geometry is the subdivision of a plane defined by the faces of a straight-line planar graph. We consider a natural generalization of this structure on a polyhedral surface. The regions of the subdivision are bounded by geodesics on the surface of the polyhedron. A method is given for representing such a subdivision that is efficient both with respect to space and the time required to answer a number of different queries involving the subdivision. For example, given a pointx on the surface of the polyhedron, the region of the subdivision containingx can be determined in logarithmic time. Ifn denotes the number of edges in the polyhedron,m denotes the number of geodesics in the subdivision, andK denotes the number of intersections between edges and geodesics, then the space required by the data structure isO((n +m) log(n +m)), and the structure can be built inO(K + (n +m) log(n +m)) time. Combined with existing algorithms for computing Voronoi diagrams on the surface of polyhedra, this structure provides an efficient solution to the nearest-neighbor query problem on polyhedral surfaces.	polyhedral;polyhedron;subdivision surface	David M. Mount	1987	Discrete & Computational Geometry	10.1007/BF02187877	combinatorics;finite subdivision rule;topology;voronoi diagram;data structure;computational geometry;mathematics;geometry;planar graph	Theory	31.171797448336907	19.214115856384307	7978
1a1570eff81c5b99aa7d0af63302a8dc1de1a4b8	on the fundamental theorem of finite abelian groups		Proof The ifu0027 part follows from Radou0027s theorem. For the converse, suppose that x -u003c y. Let S be the set of distinct vectors among the n! permutations of y. Then all the vectors in S have the same trace, namely, tr(y). Thus S is contained in the hyperplane {z = (zl,... ,Zn)T E Rn : zI + Z2 + + z +n = tr(y)}, whence dim(S) u003c n 1. Since x -u003c y, x belongs to the convex hull of S by Radou0027s theorem, and our theorem follows from Carath6odoryu0027s theorem. a		Gabriel Navarro	2003	The American Mathematical Monthly		cyclic group;topology;calculus;mathematics;abelian group;group theory;algebra	Theory	38.53874936776389	32.70334919394017	7984
be431d7eb9a558532c8327f167911bf914bf4ef7	generation and properties of new fastest linearly independent transforms over gf(2) with reordering	polynomial matrices;transfer function matrices;galois fields polynomial matrices transfer function matrices matrix multiplication;polynomials computational efficiency circuit testing field programmable gate arrays arithmetic adders electrical fault detection signal processing programmable logic arrays logic devices;polynomial expansion nonzero spectral coefficients binary polynomial expansions binary function representations binary function truth vector matrix transposition fastest linearly independent transforms gf 2 reordering li transforms factorized transform matrices multiplication forward transforms inverse transforms;matrix multiplication;reed muller;galois fields	Several fastest linearly independent (LI) transforms over GF(2) as well as their properties have been presented in recent papers. The transforms are able to provide more effective representations than the Reed-Muller transform for some binary functions. In this paper, new fastest LI transforms are introduced which are obtained by multiplying the factorized transform matrices of the previously defined fastest LI transforms in different orderings. This way of generation ensures that the new transforms have the same computational costs as the original fastest LI transforms and that they possess fast forward and inverse transforms. Properties of the new transforms are also investigated and their experimental results for some binary benchmark functions are given. From comparison of experimental results, it is shown that the new transforms are useful as they are able to give polynomial expansions with smaller number of nonzero spectral coefficients than those of the original fastest LI transforms for most binary benchmark functions.	benchmark (computing);coefficient;fast forward;fastest;independent set (graph theory);polynomial;reed–muller code	Bogdan J. Falkowski;Cicilia C. Lozano;Susanto Rahardja	2005	2005 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2005.1465683	arithmetic;discrete mathematics;matrix multiplication;mathematics;finite field;algorithm;algebra	Theory	17.64615460295404	43.99448583595471	7992
d3ca4145bd84d983c6732a354bdb4800ae47cea1	detouring: translating software to circumvent hard faults in simple cores	fabrication;instruction cache;degradation;cmos technology;circuit faults;fault free cores;cmos process;chip;functional units;fault tolerant computing;low power;redundancy;high performance processor cores;multicore processing;fault tolerance;microprocessor chips electronic engineering computing fault tolerant computing;electronic engineering computing;detouring methods;software translation;functional unit;high performance;operand bypass network;multicore chips;detouring;microprocessor chips;throughput;detouring software translation cmos technology high performance processor cores fault tolerance multicore chips detouring methods instruction cache functional units operand bypass network fault free cores;hardware	CMOS technology trends are leading to an increasing incidence of hard (permanent) faults in processors. These faults may be introduced at fabrication or occur in the field. Whereas high-performance processor cores have enough redundancy to tolerate many of these faults, the simple, low-power cores that are attractive for multicore chips do not. We propose Detouring, a software-based scheme for tolerating hard faults in simple cores. The key idea is to automatically modify software such that its functionality is unchanged but it does not use any of the faulty hardware. Our initial implementation of Detouring tolerates hard faults in several hardware components, including the instruction cache, registers, functional units, and the operand bypass network. Detouring has no hardware cost and no performance overhead for fault-free cores.	algorithm;cmos;central processing unit;incidence matrix;low-power broadcasting;machine translation;multi-core processor;operand;overhead (computing);processor register	Albert Meixner;Daniel J. Sorin	2008	2008 IEEE International Conference on Dependable Systems and Networks With FTCS and DCC (DSN)	10.1109/DSN.2008.4630073	chip;multi-core processor;reliability engineering;throughput;fault tolerance;computer architecture;parallel computing;real-time computing;degradation;computer science;redundancy;fabrication;cmos	Arch	7.333436622466019	59.286587146259635	8004
02a527d1f1a15a04a72eb5a47211358a9d25b759	performance enhancement of serial based fpga probabilistic fault emulation techniques	shift registers fault location field programmable gate arrays probability random number generation;circuit faults;clocks;circuit faults emulation clocks field programmable gate arrays fault location shift registers probabilistic logic;emulation;fpga;pseudorandom permutations performance enhancement probabilistic fault emulation serial based fpga fault emulation schemes probabilistic errors random number generator fault bit generation shift register fault location high emulation overhead emulation clock cycle;probabilistic faults;fault emulation;shift registers;sub powered circuits;probabilistic logic;field programmable gate arrays;sub powered circuits fpga fault emulation probabilistic faults;fault location	Serial based FPGA fault emulation schemes for probabilistic errors rely on a random number generator -- which is used for generation of fault bits - and a shift register - used for placing the fault bits to their corresponding fault location. It has two advantages with respect to parallel solutions: lower cost and better accuracy. The main disadvantage is represented by the high emulation overhead: for each emulation clock cycle, a number of clock cycles equal to the number of fault locations is required to load the shift register. This paper presents a technique for FPGA probabilistic fault emulation which reduces the emulation overhead, at the expense of accuracy. It is based on pseudo-random permutations within the shift register, while maintaining the number of active fault bits. We obtain a performance improve of one order of magnitude, while we have a cost increase of 27% and lower fault modeling accuracy.	clock signal;emulator;fault injection;field-programmable gate array;overhead (computing);pseudorandomness;random number generation;shift register	Ioana Mot;Oana Boncalo;Alexandru Amaricai	2015	2015 IEEE 18th International Symposium on Design and Diagnostics of Electronic Circuits & Systems	10.1109/DDECS.2015.49	embedded system;electronic engineering;parallel computing;real-time computing;fault coverage;fault indicator;computer science;stuck-at fault;fault model;field-programmable gate array;hardware emulation	EDA	20.3213989716733	51.25963505695865	8008
40d0b512579a48d84ef8e7b4550ad01fba9b3513	hilbert cube 512	hilbert cube;haptics;visual prosthetics;sensory substitution	“Hilbert Cube” emerged from the challenge of taking the famous 2-dimensional Hilbert curve (Fig.1) and exploring what can be done with this pattern in 3 dimensions. The 3D shape is generated by a recursive procedure that starts with a simple closed path along eight edges of a cube visiting all its eight vertices. Each corner in this structure is then replaced with a copy of this path, scaled down by a factor of 2, and suitably connected to maintain the overall cyclic nature of the path. After three recursion steps, a structure emerges with a total of 512 L-shaped turns. The result resembles a cubist rendering of a brain, split into two distinct lobes that are only loosely connected to one another. These halves are again divided into two loosely connected halves, and so on.	cube;emergence;hilbert curve;recursion	Carlo H. Séquin	2006		10.1145/1179849.1179939	sensory substitution;mathematical analysis;topology;computer science;mathematics;geometry;haptic technology	Theory	35.0046521258843	23.348604116424944	8012
c1630b08f52ccb62d94c5c383f423f9f0e8d3269	a methodology to improve yield in analog circuits by using geometric programming	geometric program;best effort;design space;yield;analog circuits;voltage reference;sensitivity analysis;threshold voltage;optimization;mismatch;geometric programming	A CAD methodology to design analog circuits via geometric programming (GP) involving manufacturing issues is proposed. A functional approach by sensitivity analysis from dimensional variables is used to obtain the design space. A mismatch analysis using the Pelgrom's model defines the minimum area to ensure parametric yield requirements. With the information on the design space and minimum area, performance and yield are optimized with a new strategy called best-effort. This methodology is validated through the design of a sub-threshold voltage reference [1]. In this work a 3.25 ppm/C temperature coefficient is obtained with a deviation nine times lower but occupying the same area than the one using the GP strategy without manufacturing issues. Further, it is shown how an appropriate sizing can improve the yield up to 24%.	analogue electronics;best-effort delivery;coefficient;computer-aided design;functional approach;geometric programming;requirement;voltage reference	Jorge Johanny Sáenz Noval;Elkim Roa;Armando Ayala Pabón;Wilhelmus A. M. Van Noije	2010		10.1145/1854153.1854189	best-effort delivery;reliability engineering;mathematical optimization;yield;electronic engineering;geometric programming;voltage reference;analogue electronics;computer science;engineering;threshold voltage;sensitivity analysis	EDA	24.17523110319351	57.453591849951636	8023
aa41a9ff432203cc781dc9bdfbf4f2732c7e2634	studying the locator polynomials of minimum weight codewords of bch codes	locator;polynomials error correction codes;distance minimale;error correction codes;code cyclique;code reed muller;localisateur;symmetric function;true minimum distance primitive binary cyclic codes locator polynomials minimum weight codewords bch codes symmetric functions power sums newton s identities;codigo ciclico;code bch;teoria newton;newton theory;polynomial;polynomials;minimum distance;muller reed code;theorie newton;polinomio;information theory galois fields;cyclic code;code binaire;codigo binario;codigo bch;code;bch code;polynome;codigo;binary code;localizador	We consider only primitive binary cyclic codes of length n = 2 m ? 1. A BCH-code with designed distance is denoted B(n;). A BCH-code is always a narrow-sense BCH-code. A codeword is identiied with its locator polynomial, whose coeecients are the symmetric functions of the locators. The deenition of the code by its zeros-set involves some properties for the power sums of the locators. Moreover the symmetric functions and the power sums of the locators are related with the Newton's identities. We rst present an algebraic point of view in order to prove or innrm the existence of words of a given weight in a code. The main tool is a symbolic computation software in exploring the Newton's identities. Our principal result is the true minimum distance of some BCH-codes of length 255 and 511, which were not known. In a second part, we study the codes B(n; 2 h ? 1), h 2 3; m ? 2]. We prove that the set of the minimum weight codewords of the BCH-code B(n; 2 m?2 ? 1) equals the set of the minimum weight codewords of the punctured Reed-Muller code of length n and order 2, for any m. We give some Corollaries of this result.	bch code;code word;cyclic code;linear algebra;minimum weight;newton;online locator service;polynomial;reed–muller code;symbolic computation	Daniel Augot;Pascale Charpin;Nicolas Sendrier	1992	IEEE Trans. Information Theory	10.1109/18.135638	arithmetic;polynomial code;combinatorics;discrete mathematics;constant-weight code;maxeksat;linear code;mathematics;bch code;statistics;polynomial	Theory	40.8152364018147	54.18600844757302	8024
71368586dc0252046fe1906df169ee7baacf0b1a	a high performance processor architecture for multimedia applications		Abstract In this paper, an efficient sub-word parallelism (SWP)-enabled Reduced instruction-set Computer (RISC) architecture is proposed. The proposed architecture can perform efficiently for both conventional and multimedia-oriented applications. Speed-up for multimedia applications is achieved by adding the customized SWP instructions in RISC processor core. Rather than operating on a single data, customized instructions perform parallel computations on multiple pixels, packed in word-size registers. The sub-word-sizes in SWP instructions are selected, based upon the pixel sizes (8, 10, 12, 16-bit) in modern multimedia applications. The SWP-RISC processor is designed and implemented on two different CMOS technology nodes (90 nm and 45 nm). The performance of processor is characterized for different multimedia applications and compared with the state-of-the-art TMS320C64X processor.	microarchitecture	Shafqat Khan;Muhammad Rashid;Faraz Javaid	2018	Computers & Electrical Engineering	10.1016/j.compeleceng.2017.09.027	application-specific instruction-set processor;parallel computing;pixel;computer science;architecture;computer architecture;reduced instruction set computing;multimedia;computation;microarchitecture;cmos;instructions per cycle	HPC	2.964001412954094	46.54390828550487	8035
2fac16e5cd562f3f503d3eeeb9c092789ca23ac5	a vlsi chip architecture for the real-time computation of direct kinematics	very large scale integration computer architecture kinematics computer industry defense industry pipeline processing throughput service robots manipulators microprocessors;microprocessors;manipulators;very large scale integration;defense industry;service robots;computer industry;vlsi design;kinematics;fixed point;chip;computer architecture;robot arm;industrial application;real time computing;pipeline processing;throughput	The architecture of a VLSI chip dedicated to the real-time computation of the Direct Kinematic Solution (DKS) is described. The design features fixed-point calculation and on-chip generation of trigonometric functions. The computed output has the resolution required for most industrial applications. Consideration of VLSI design regularity leads to the modification of the homogeneous transformation matrices. Pipelining techniques are applied to improve throughput. The control-store implementation provides adaptability to virtually all robot arms. Transistor and cell counts confirm the feasibility of a semi-custom implementation approach with current technology. Results indicate that the DKS can be obtained in microseconds with this new architecture, which amounts to a speed improvement of three orders of magnitude compared to a similar algorithm implemented on a 16-bit microprocessor.	computation;real-time clock;very-large-scale integration	Steven S. Leung;Michael A. Shanblatt	1986		10.1109/ROBOT.1986.1087486	embedded system;real-time computing;simulation;computer science;engineering;very-large-scale integration	Robotics	5.848193348136056	44.92910530746485	8037
fbc99c7ef3e3c0b625f96f54defba3848c89694d	reconfigurable parallel architecture for genetic algorithms: application to the synthesis of digital circuits	computer architecture;genetic algorithm;parallel architecture;digital circuits;parallel processing	This work presents a proposal and implementation of a re-configurable parallel architecture, using Genetic Algorithms and applied to synthesis of combinational digital circuits. This reconfigurable parallel architecture uses concepts of computer architecture and parallel processing to obtain a scalable performance. It is developed in VHDL and implemented totally in hardware using FPGA devices. The concept of reconfigurable and parallel architecture enables an easy hardware adaptation to different project requirements. This approach allows applies with flexibility different strategies to synthesis of combinational digital circuits problem.		Edson Pedro Ferlin;Heitor Silvério Lopes;Carlos Raimundo Erig Lima;Ederson Cichaczewski	2007		10.1007/978-3-540-71431-6_30	dataflow architecture;reference architecture;parallel processing;space-based architecture;computer architecture;parallel computing;genetic algorithm;reconfigurable computing;computer science;applications architecture;cellular architecture;theoretical computer science;digital electronics	EDA	8.802039147689486	48.721811383790545	8040
be5ef62ce0cd01e7e3b02a2cff3b798ca9154d34	a note on the automatic pretreatment of polynomials			polynomial ring	H. Van de Vel	1970	Comput. J.	10.1093/comjnl/13.3.289	theoretical computer science;polynomial;computer science	Theory	46.59277361931593	33.695689540542	8046
8bf0284224bc22cf2344cfe753849d189f7012c6	highly linked tournaments	connectivity of tournaments;linkage structures;grupo de excelencia;ciencias basicas y experimentales;matematicas;linkedness	A (possibly directed) graph is k-linked if for any two disjoint sets of vertices { x 1 , ? , x k } and { y 1 , ? , y k } there are vertex disjoint paths P 1 , ? , P k such that P i goes from x i to y i . A theorem of Bollobas and Thomason says that every 22k-connected (undirected) graph is k-linked. It is desirable to obtain analogues for directed graphs as well. Although Thomassen showed that the Bollobas-Thomason Theorem does not hold for general directed graphs, he proved an analogue of the theorem for tournaments-there is a function f ( k ) such that every strongly f ( k ) -connected tournament is k-linked. The bound on f ( k ) was reduced to O ( k log ? k ) by Kuhn, Lapinskas, Osthus, and Patel, who also conjectured that a linear bound should hold. We prove this conjecture, by showing that every strongly 452k-connected tournament is k-linked.		Alexey Pokrovskiy	2015	J. Comb. Theory, Ser. B	10.1016/j.jctb.2015.05.005	combinatorics;discrete mathematics;mathematics;tournament	Theory	31.457942477623956	29.352160057249222	8048
88caaf07c665ebfcf439f96c2a480d30db365464	multiplicative complexity of vector valued boolean functions		We consider the multiplicative complexity of Boolean functions with multiple bits of output, studying how large a multiplicative complexity is necessary and sufficient to provide a desired nonlinearity. For so-called ΣΠΣ circuits, we show that there is a tight connection between error correcting codes and circuits computing functions with high nonlinearity. Combining this with known coding theory results, we show that functions with n inputs and n outputs with the highest possible nonlinearity must have at least 2.32n AND gates. We further show that one cannot prove stronger lower bounds by only appealing to the nonlinearity of a function; we show a bilinear circuit computing a function with almost optimal nonlinearity with the number of AND gates being exactly the length of such a shortest code. Additionally we provide a function which, for general circuits, has multiplicative complexity at least 2n − 3. Finally we study the multiplicative complexity of “almost all” functions. We show that every function with n bits of input and m bits √ of output can be computed using at most 2.5(1 + o(1)) m2n AND gates. 1. Definitions and Preliminaries Let F2 be the finite field of order 2 and F 2 the n-dimensional vector space over F2. We denote by [n] the set {1, . . . , n}. An (n, m)-function is a mapping from F 2 to F 2 and we refer to these as the Boolean functions. When m > 1 we say that the function is vector valued. It is well known that every (n, 1)-function f can be written uniquely as a multilinear polynomial over F2 X Y f(x1, . . . , xn) = αX xi. X⊆[n] i∈X This polynomial is called the Zhegalkin polynomial or the algebraic normal form of f . For the rest of this paper most, but not all, arithmetic will be in F2. We trust that the reader will find it clear whether arithmetic is in F2, F2n , or R when not explicitly stated, and will not address it further. The degree of an (n, 1)-function f is the largest |X| such that αX = 1. For an (n, m)-function f , we let fi be the (n, 1)-function defined by the ith output bit of f , and say that the degree of f is the largest degree of fi for i ∈ [m]. A function is affine if it has degree 1, and quadratic if it has degree 2. For T ⊆ [m] we let X fT = fi, i∈T and for v ∈ F we let |v| denote the Hamming weight of v, that is, the 2 number of nonzero entries in v, and let |u + v| be the Hamming distance between the two vectors u and v. Nonlinearity of Boolean Functions We will use several facts on the nonlinearity of Boolean functions. We refer to the two chapters in Carlet (2010a,b) for proofs and references. The nonlinearity of an (n, 1)-function f is the Hamming distance to the closest affine function, more precisely NL(f) = 2 − max |{x ∈ F| ha, xi + b = f(x)}|, 2 a∈F,b∈F2 2 P where ha, xi = ni=1 aixi. For an (n, m)-function f , the nonlinearity is defined as NL(f) = min {NL(fT )}. T ⊆[m],T 6=∅ 2 The nonlinearity of an (n, m)-function is always between 0 and 2n−1 − 2 n −1 . The (n, m)-functions meeting this bound are called bent functions. Bent (n, 1) functions exist if and only if n is even. A standard example of a bent (n, 1)-function is the inner product, on n = 2k variables, defined as: IP2k(x1, . . . , xk, y1, . . . , yk) = hx, yi . This function is clearly quadratic. If we identify F 2 with F2n , a standard example of a bent (2n, n)-function is the finite field multiplication function: (1.1) f(x, y) = x · y	bilinear filtering;code;coding theory;error detection and correction;multilinear polynomial;nonlinear system	Joan Boyar;Magnus Find	2018	Theor. Comput. Sci.	10.1016/j.tcs.2018.02.023	combinatorics;discrete mathematics;mathematics;tc0	Theory	41.20987362436842	40.39487435831008	8060
06b13d6e86a0a21a35d095e5c54841eda8ebb6bc	approximation schemes for minimum 2-connected spanning subgraphs in weighted planar graphs	graphe non oriente;maastricht university;non directed graph;temps polynomial;algorithme glouton;approximation algorithm;arbre maximal;digital archive;connected graph;polynomial time algorithm;graph connectivity;aproximacion polinomial;survivable network design problem;graphe pondere;grafo pondero;arbol maximo;grafo no orientado;graphe planaire;open access;conectividad grafo;approximation polynomiale;algoritmo aproximacion;polynomial time;approximation scheme;greedy algorithm;algoritmo gloton;spanning tree;weighted graph;grafo planario;publication;scientific;algorithme approximation;connectivite graphe;graphe connexe;institutional repository;polynomial time approximation scheme;planar graph;polynomial approximation;tiempo polinomial;grafo conexo	We present new approximation schemes for various classical problems of finding the minimum-weight spanning subgraph in edgeweighted undirected planar graphs that are resistant to edge or vertex removal. We first give a PTAS for the problem of finding minimum-weight 2-edge-connected spanning subgraphs where duplicate edges are allowed. Then we present a new greedy spanner construction for edge-weighted planar graphs, which augments any connected subgraph A of a weighted planar graph G to a (1 + ε)-spanner of G with total weight bounded by weight(A)/ε. From this we derive quasi-polynomial time approximation schemes for the problems of finding the minimum-weight 2-edgeconnected or biconnected spanning subgraph in planar graphs. We also design approximation schemes for the minimum-weight 1-2-connectivity problem, which is the variant of the survivable network design problem where vertices have 1 or 2 connectivity constraints. Prior to our work, for all these problems no polynomial or quasi-polynomial time algorithms were known to achieve an approximation ratio better than 2.	approximation algorithm;biconnected graph;file spanning;graph (discrete mathematics);greedy algorithm;minimum spanning tree;minimum-weight triangulation;network planning and design;ptas reduction;planar graph;polynomial;quasi-polynomial;time complexity	André Berger;Artur Czumaj;Michelangelo Grigni;Hairong Zhao	2002		10.1007/11561071_43	mathematical optimization;combinatorics;discrete mathematics;minimum degree spanning tree;spanning tree;computer science;connectivity;subgraph isomorphism problem;k-minimum spanning tree;mathematics;induced subgraph isomorphism problem;approximation algorithm;algorithm	Theory	21.506957800081008	26.485792282283022	8072
1beede152f308edf19d07c5be706f66d05ecdfe2	a local-global principle for macaulay posets	lexicographic order	We consider the shadow minimization problem (SMP) for cartesian powers Pn of a Macaulay poset P . Our main result is a local-global principle with respect to the lexicographic order Ln. Namely, we show that under certain conditions the shadow of any initial segment of the order Ln for n ≥ 3 is minimal iff it is so for n = 2. These conditions include such poset properties as additivity , shadow increasing , final shadow increasing and being rank-greedy . We also show that these conditions are essentially necessary for the lexicographic order to provide nestedness in the SMP.	greedy algorithm;lexicographical order;macaulay;nestedness	Sergei L. Bezrukov;Xavier Portas;Oriol Serra	1999	Order	10.1023/A:1006381903313	combinatorics;discrete mathematics;topology;lexicographical order;mathematics;algebra	Logic	37.701310283504846	30.826272328622917	8078
74e6712303b606dc7ec0464535046e00b4502839	logic design of multivalued i2l logic circuits	logic design;switching algebra;combinational networks;multivalued logic;multilevel i2l	An algebraic system for designing multi-valued (four-level) I<supscrpt>2</supscrpt>L circuits is presented here. It was necessary to develop this system because the use of existing multi-valued logic formalisms does not result in efficient I<supscrpt>2</supscrpt>L circuits. The close relationship between the algebra and the integrated circuits is stressed throughout the paper.	integrated circuit;integrated injection logic;linear algebra;logic synthesis	Edward J. McCluskey	1978	IEEE Transactions on Computers	10.1109/TC.1979.1675410	dynamic logic;discrete mathematics;logic synthesis;logic optimization;diode–transistor logic;logic level;logic gate;logic family;computer science;intermediate logic;theoretical computer science;sequential logic;combinational logic;digital electronics;substructural logic;register-transfer level;algorithm;resistor–transistor logic	EDA	19.26890525798302	45.87191340742042	8080
be11e2e454a049736b490e0125c4e69f625533da	applying vlsi eda to energy distribution system design	wires planning load management optimization geographic information systems algorithm design and analysis power systems;integrated circuit design;integrated circuit interconnections;vlsi;vlsi design automation area vlsi eda energy distribution system design energy distribution networks electricity network electric vehicles energy sources comprehensive design automation capability power load distribution geospatial aware network optimization outage identification contingency planning loss analysis reduction;vlsi electronic design automation integrated circuit design integrated circuit interconnections;electronic design automation	Energy distribution networks refer to that part of the electricity network that delivers power to homes and business. It is reported that significant amounts of energy are being wasted simply due to inefficiencies in this network. Further, this domain is rapidly changing with new types of loads such as electric vehicles or the spread of new types of energy sources such as photo-voltaic and wind. In this paper, we demonstrate a comprehensive design automation capability for energy distribution networks leading to much more flexible yet effective system. The new system's capabilities include power load distribution and transfers, equipment upgrading, geospatial-aware network optimization, outage identification, contingency planning and loss analysis/reduction. These features are enabled by advanced simulation, analysis and optimization engines that are adapted from those available in the traditional VLSI design automation area. The paper will conclude with potential future research directions that require further innovations in energy distribution networks.	contingency plan;downtime;load balancing (computing);mathematical optimization;simulation;systems design;very-large-scale integration	Sani R. Nassif;Gi-Joon Nam;Jerry Hayes;Sani Fakhouri	2014	2014 19th Asia and South Pacific Design Automation Conference (ASP-DAC)	10.1109/ASPDAC.2014.6742872	embedded system;electronic engineering;electronic design automation;computer science;engineering;design flow;electrical engineering;computer-automated design;very-large-scale integration;power optimization;totally integrated automation;integrated circuit design	EDA	2.2384413090471234	9.304544317107796	8106
7652d24c4d04e110c2d3df7ce27018b691b0dfb9	performance comparison of strategies for static mapping of parallel programs	distributed memory;performance comparison;low complexity;simulated annealing;computational complexity;parallel computer;message passing;greedy algorithm;parallel machines;tabu search;load balance;task assignment;parallel programs;communication pattern;tree ring;regular graph	We address the problem of efficient strategies for mapping arbitrary parallel programs onto distributed memory message-passing parallel computers. An efficient task assignment strategy based on two phases (task clustering and task reassignment) is proposed. This strategy is suitable for applications which could be partitioned into parallel executable tasks and its design is a trade-off between solution quality and computational complexity. It is evaluated by comparison with some representative heuristics from the literature that cover the range of different complexity categories: two simple greedy algorithms (Largest Processing Time First and Largest Global Cost First) with low complexity, two iterative heuristics (Simulated Annealing and Tabu Search) with the highest complexity and a mixed heuristic (Even Distribution and Task Reassignment) with an intermediate complexity between the other two. It is shown to be very effective for computations whose communication topology matches some well-known regular graph families such as trees, rings and meshes, as well as for arbitrary computations with irregular communications patterns. Its solution quality is better than that produced by the other mixed heuristic and as good as (and sometimes better than) that produced by Simulated Annealing.		Miquel A. Senar;Ana Ripoll;Ana Carolina Castro Côrtes;Emilio Luque	1997		10.1007/BFb0031630	greedy algorithm;parallel computing;message passing;distributed memory;simulated annealing;tabu search;computer science;regular graph;load balancing;theoretical computer science;distributed computing;dendrochronology;computational complexity theory	HPC	2.9540322169310627	36.801346317628024	8107
7d3dfafbb6f8722ae5eb0d0f1d8ea88d83a9bbdd	robinson-schensted algorithms for skew tableaux	combinatorics;tableau young;symmetric function;young tableau;combinatoria;funcion simetrica;combinatoire;fonction symetrique;mathematical inversion;algorithme robinson schensted;inversion matematica;permutation;particion;permutacion;partition;forme gauche;inversion mathematique;diagrama young	We introduce several analogs of the Robinson-Schensted algorithm for skew Young tableaux. These correspondences provide combinatorial proofs of various identities involving f&,, the number of standard skew tableaux of shape L/p, and the skew Schur functions So..,,. For example, we are able to show bijectively that and 4 S;&)QdY)=C ~p;p(x)~~,p(Y) n (1-%Y,)Y. P 1. I It is then shown that these new algorithms enjoy some of the same properties as the original. In particular, it is still true that replacing a permutation by its inverse exchanges the two output tableaux. This fact permits us to derive a number of other identities as well. 0 1990 Academic Press. Inc.	algorithm;robinson–schensted correspondence	Bruce E. Sagan;Richard P. Stanley	1990	J. Comb. Theory, Ser. A	10.1016/0097-3165(90)90066-6	partition;young tableau;combinatorics;discrete mathematics;littlewood–richardson rule;mathematics;permutation;algorithm;symmetric function;algebra	ML	39.6312002623986	36.55777736075791	8108
fc858ba892868e642fff69da9cd1be7e2e7fbe0d	impacts of the technological change introduced by smart energy metering in the legal department of an electricity utility		Abstract   Even though intelligent measurements of energy consumption is envisioned by electric utilities as a strategic communication network to create transparency and efficiency in the operation of the energy industry, the transition from traditional to state-of-the-art technologies have induced a significant impact in the legal department of the utilities. Not straightforwardly understood by consumers unfamiliar with the updated innovative technologies, surprisingly, the modernization of the sector has generated complaints and legal processes that are everyday filed in the legal departments of the utilities. In connection with a project developed under the framework of the regulated ANEEL R&D Program (sponsored by the Brazilian Regulatory Agency responsible for controlling the electrical sector), a study was developed (i) to evaluate the litigation impact caused by the replacement of electromechanical to electronic meters and (ii) to estimate the additional operational costs generated by the introduction of smart metering technology. Making use of the time series methodology, forecasting univariate models, exponential smoothing, and dynamic regression, a case study was developed based on real data made available by an electricity utility operating in Brazil. Results of the work confirm the applicability of the dynamic regression model proposed that allowed an estimation of the impact of the new measurement technology introduced on the amount of input processes named billing complaint on the overall general mass litigation handled by the Legal Department of the utility.		Carolina Teixeira Nicolau;Reinaldo C. Souza;Mauricio N. Frota	2015		10.1016/j.procs.2015.07.101	simulation;actuarial science;artificial intelligence;data mining	AI	1.974028148718228	8.27752485165399	8109
c69ee117fa660095c4c3061dbe4d260cc44e2cf3	p, np and the post correspondence problem	morphisme;morfismo;computability and decidability;time complexity;complexite calcul;bounded delay;clase complejidad;formal languages;conjunto recursivamente enumerable;correspondence problem;calculabilite decidabilite;classe p;delai borne;classe complexite;complexity class;probleme correspondance post;computational complexity;space complexity;morphism;code;recursively enumerable set;classe np;codigo;ensemble recursivement enumerable;no reference;langage formel	Abstract   We define a variant of the Post Correspondence Problem, the machine-oriented Post Correspondence Problem or MOPCP, especially suitable for complexity considerations. All recursively enumerable sets can be represented in terms of instances of MOPCP and, moreover, deterministic and nondeterministic time and space complexities have their natural counterpart in the representation. This leads to PCP-related complexity classes; for instance, the time complexity classes PCP-P and PCP-NP. Using a bounded delay injectivity condition on one of the morphisms of a PCP instance, we obtain an exact characterization of P. In this characterization, determinism corresponds exactly to the bounded delay condition and no reference is made to computations of any sort. A weaker bounded delay requirement gives rise to an infinite (possibly collapsing) hierarchy between P and NP.	post correspondence problem	Alexandru Mateescu;Arto Salomaa;Kai Salomaa;Sheng Yu	1995	Inf. Comput.	10.1006/inco.1995.1128	time complexity;complexity class;combinatorics;formal language;discrete mathematics;recursively enumerable set;computer science;mathematics;dspace;correspondence problem;computational complexity theory;code;algorithm;morphism;algebra	Theory	5.612517309162661	20.698208353435877	8134
bd22332855ca55ae247cbfb5dc6b6bd380cdc5fb	optimal recovery of damaged infrastructure network		Natural disasters or attacks may disrupt infrastructure networks on a vast scale. Parts of the damaged network are interdependent, making it difficult to plan and optimally execute the recovery operations. To study how interdependencies affect the recovery schedule, we introduce a new discrete optimization problem where the goal is to minimize the total cost of installing (or recovering) a given network. This cost is determined by the structure of the network and the sequence in which the nodes are installed. Namely, the cost of installing a node is a function of the number of its neighbors that have been installed before it. We analyze the natural case where the cost function is decreasing and convex, and provide bounds on the cost of the optimal solution. We also show that all sequences have the same cost when the cost function is linear and provide an upper bound on the cost of a random solution for an Erdős-Rényi random graph. Examining the computational complexity, we show that the problem is NP-hard when the cost function is arbitrary. Finally, we provide a formulation as an integer program, an exact dynamic programming algorithm, and a greedy heuristic which gives high quality solutions.	computational complexity theory;discrete optimization;display resolution;dynamic programming;erdős number;erdős–rényi model;greedy algorithm;heuristic;integer programming;interdependence;loss function;mathematical optimization;np-hardness;optimization problem;random graph	Alexander Gutfraind;Milan Bradonjic;Tim Novikoff	2012	CoRR		reduced cost;mathematical optimization;simulation	ML	11.92524567308374	8.425299819560351	8139
06a76daede58764e5c77ea5f5280384b2e6e50fb	almost cross-intersecting and almost cross-sperner pairs of families of sets	sperner families;extremalset systems;intersecting families;pairs of families;05d05	For a set G and a family of sets F let DF (G) = {F ∈ F : F ∩ G = ∅} and SF (G) = {F ∈ F : F ⊆ G or G ⊆ F}. We say that a family is l-almost intersecting, (≤ l)-almost intersecting, l-almost Sperner, (≤ l)-almost Sperner if |DF (F )| = l, |DF (F )| ≤ l, |SF (F )| = l, |SF (F )| ≤ l (respectively) for all F ∈ F . We consider the problem of finding the largest possible family for each of the above properties. We also address the analogous generalization of cross-intersecting and cross-Sperner families. AMS subject classification: 05D05	direction finding;vhdl-ams	Dániel Gerbner;Nathan Lemons;Cory Palmer;Dömötör Pálvölgyi;Balázs Patkós;Vajk Szécsi	2013	Graphs and Combinatorics	10.1007/s00373-012-1138-2	mathematics;topology;family of sets	Theory	37.76008216533402	30.696058733669247	8142
fec4799a50c9781a946fefa8a7bae11de41bd9b1	parallel ppi prediction performance study on hpc platforms	parallel computing;cluster computing;protein classification;performance analysis;protein protein interaction	STRIKE is an algorithm which predicts protein–protein interactions (PPIs) and determines that proteins interact if they contain similar substrings of amino acids. Unlike other methods for PPI prediction, STRIKE is able to achieve reasonable improvement over the existing PPI prediction methods. Although its high accuracy as a PPI prediction method, STRIKE consumes a large execution time and hence it is considered to be a compute-intensive application. In this paper, we develop and implement a parallel STRIKE algorithm for high-performance computing (HPC) systems. Using a large-scale cluster, the execution time of the parallel implementation of this bioinformatics algorithm was reduced from about a week on a serial uniprocessor machine to about 16.5 h on 16 computing nodes, down to about 2 h on 128 parallel nodes. Communication overheads between nodes are thoroughly studied.	pixel density	Ali El-Moursy;Wael S. Afifi;Fadi N. Sibai;Salwa M. Nassar	2015	Journal of Circuits, Systems, and Computers	10.1142/S0218126615500747	protein–protein interaction;parallel computing;real-time computing;computer cluster;computer science;bioinformatics	HPC	-1.735507297181271	42.73486933399533	8145
6caedae5b3597ac9151c2e4af78c349ef78fdeeb	on the hull number of triangle-free graphs	camino mas corto;shortest path;mathematiques discretes;capsula convexa;matematicas discretas;vertex;hull number;discrete mathematics;plus court chemin;52a05;enveloppe convexe;connected graph;52a37;graphe sans triangle;graph;ordre n;68r10;chemin plus court;ensemble convexe;orden n;vertice;convex set;cardinalite;geodetic number;n order;convex hull;05c12;graphe connexe;minimum degree;conjunto convexo;grafo conexo	A set of vertices C in a graph is convex if it contains all vertices which lie on shortest paths between vertices in C. The convex hull of a set of vertices S is the smallest convex set containing S. The hull number h(G) of a graph G is the smallest cardinality of a set of vertices whose convex hull is the vertex set of G. For a connected triangle-free graph G of order n and diameter d ≥ 3, we prove that h(G) ≤ (n− d+ 3)/3, if G has minimum degree at least 3 and that h(G) ≤ 2(n− d+ 5)/7, if G is cubic. Furthermore, for a connected graph G of order n, girth g ≥ 4, minimum degree at least 2, and diameter d, we prove h(G) ≤ 2 + (n− d− 1)/ ⌈ g−1 2 ⌉ . All bounds are best possible.	connectivity (graph theory);convex hull;convex set;cubic function;girth (graph theory);shortest path problem;vertex (geometry)	Mitre Costa Dourado;Fábio Protti;Dieter Rautenbach;Jayme Luiz Szwarcfiter	2010	SIAM J. Discrete Math.	10.1137/090751797	vertex;combinatorics;discrete mathematics;topology;graph center;connectivity;convex hull;mathematics;geometry;convex set;graph;shortest path problem	Theory	25.55360798537414	31.07513182866225	8151
ee7d694f481f8e2ac7c6f0eab1b821ed3dcdbf68	processing lstm in memory using hybrid network expansion model		With the rapidly increasing applications of deep learning, LSTM-RNNs are widely used. Meanwhile, the complex data dependence and intensive computation limit the performance of the accelerators. In this paper, we first proposed a hybrid network expansion model to exploit the finegrained data parallelism. Based on the model, we implemented a Reconfigurable Processing Unit(RPU) using Processing In Memory(PIM) units. Our work shows that the gates and cells in LSTM can be partitioned to fundamental operations and then recombined and mapped into heterogeneous computing components. The experimental results show that, implemented on 45nm CMOS process, the proposed RPU with size of 1.51 mm2 and power of 413 mw achieves 309 GOPS/W in power efficiency, and is 1.7 χ better than state-of-the-art reconfigurable architecture.	cmos;computation;data dependency;data parallelism;deep learning;field-programmable gate array;geforce;graphics processing unit;heterogeneous computing;long short-term memory;parallel computing;performance per watt;sigmoid function;throughput	Yu Gong;Tingting Xu;Bo Liu;Wei Ge;Jinjiang Yang;Jun Yang;Longxing Shi	2017	2017 IEEE International Workshop on Signal Processing Systems (SiPS)	10.1109/SiPS.2017.8110011	symmetric multiprocessor system;architecture;real-time computing;parallel computing;data parallelism;deep learning;data modeling;complex data type;logic gate;computer science;artificial intelligence;cmos	Arch	3.9378314385289985	42.878649225470895	8167
b2da311888e0ac43354b86b811f8941ab9634d2e	on minimizing the maximum sensor movement for barrier coverage of a line segment	mobile sensor;optimal solution;mobile sensors;sensors;ptas;optimal movement;efficient algorithm;detection;sensor network;barrier coverage;movement optimization;linear time;approximation scheme;np complete;line segment;coverage;barrier;intruder	We consider n mobile sensors located on a line containing a barrier represented by a finite line segment. Sensors form a wireless sensor network and are able to move within the line. An intruder traversing the barrier can be detected only when it is within the sensing range of at least one sensor. The sensor network establishes barrier coverage of the segment if no intruder can penetrate the barrier from any direction in the plane without being detected. Starting from arbitrary initial positions of sensors on the line we are interested in finding final positions of sensors that establish barrier coverage and minimize the maximum distance traversed by any sensor. We distinguish several variants of the problem, based on (a) whether or not the sensors have identical ranges, (b) whether or not complete coverage is possible and (c) in the case when complete coverage is impossible, whether or not the maximal coverage is required to be contiguous. For the case of n sensors with identical range, when complete coverage is impossible, we give linear time optimal algorithms that achieve maximal coverage, both for the contiguous and non-contiguous case. When complete coverage is possible, we give an O(n) algorithm for an optimal solution, a linear time approximation scheme with approximation factor 2, and a (1 + ) PTAS. When the sensors have unequal ranges we show that a variation of the problem is NP-complete and identify some instances which can be solved with our algorithms for sensors with unequal ranges.	algorithm;approximation;barrier function;circular shift;code coverage;emoticon;graph coloring;karp's 21 np-complete problems;maxima and minima;maximal set;minimax;ptas reduction;perimeter;sensor;the circle (file system);time complexity	Jurek Czyzowicz;Evangelos Kranakis;Danny Krizanc;Ioannis Lambadaris;Lata Narayanan;Jaroslav Opatrny;Ladislav Stacho;Jorge Urrutia;Mohammadreza Yazdani	2009		10.1007/978-3-642-04383-3_15	time complexity;mathematical optimization;wireless sensor network;np-complete;line segment;telecommunications;computer science;sensor;distributed computing	Mobile	30.795930238310927	17.589568925218405	8171
285983238fe276e78d2e77ee1ea1c9ea1edb1903	tasser: a temperature-aware statistical soft-error-rate analysis framework for combinational circuits	temperature 25 degc to 125 degc tasser analysis framework temperature aware statistical soft error rate analysis framework combinational circuits reliability issue nanoscaled cmos design pulse width particle strike system level effect statistical ser analysis cmos technology ser increase ambient temperature design complexity operational temperatures temperature aware sser analysis framework statistical cell modeling temperature variation monte carlo spice simulation size 45 nm;integrated circuit design;statistical analysis;transient analysis circuit faults integrated circuit modeling load modeling logic gates temperature distribution tv;integrated circuit modelling;cmos logic circuits;proceedings paper;statistical analysis cmos logic circuits combinational circuits integrated circuit design integrated circuit modelling integrated circuit reliability radiation hardening electronics;radiation hardening electronics;integrated circuit reliability;combinational circuits	Soft error has become one of the most critical reliability issues for nano-scaled CMOS designs. Many previous works discovered that the pulse width due to a particle strike on the device increases with temperature, but its system-level effect has not yet been investigated with statistical soft-error-rate (SER). Therefore, in this paper, a combinational circuit (c17 from ISCAS'85) using a 45nm CMOS technology is f rst observed under different temperatures for SER. As a result, a SER increase (2.16X more) is found on c17 as the ambient temperature elevates from 25°C to 125°C. Second, along with growing design complexity, the operational temperatures of gates are distributed in a wide range and much higher than the ambient temperature in reality. Therefore, we are motivated to build a temperature-aware SSER analysis framework that integrates statistical cell modeling to consider the ambient temperature (Ta) and the temperature variation (Tv), simultaneously. Experimental result shows that our SSER analysis framework is highly eff cient (with multiple-order speed-ups) and accurate (with only <;4% errors), when compared with Monte-Carlo SPICE simulation.	cmos;combinational logic;computation;gnu nano;logic gate;monte carlo;pulse-width modulation;spice;simulation;soft error;statistical model	Sung S.-Y. Hsueh;Ryan H.-M. Huang;Charles H.-P. Wen	2014	Fifteenth International Symposium on Quality Electronic Design	10.1109/ISQED.2014.6783372	electronic engineering;real-time computing;computer science;engineering;electrical engineering;combinational logic;algorithm;statistics;integrated circuit design	EDA	21.774676107826288	58.294536911606365	8173
1b02a0c6dc0b05fec9e26202ca7c4f74b8ef3575	radiation hardening design for spin-orbit torque magnetic random access memory		Although the magnetic tunnel junction (MTJ) is intrinsically immune to radiation, the read/write operations of magnetic random access memory (MRAM) may be vulnerable to radiation-induced current. In this paper, we investigate the radiation hardening design for spin orbit torque based MRAM (SOT-MRAM). The hardening technique is firstly studied at the device level by optimizing the dimension and magnetic parameters. Then we propose radiation hardening read and write circuits addressing the influence of single event upset (SEU). Based on a physics-based SOT-MTJ compact model and a 65nm CMOS design kit, simulation results show that the proposed MOS-stacked read sensing amplifier and write circuits of six PMOS transistors as a feed-back structure to charge/discharge sensitive nodes can correct soft errors.	amplifier;avionics;cmos;discharger;electronic circuit;feedback;hardening (computing);magnetoresistive random-access memory;pmos logic;radiation hardening;random access;simulation;single event upset;spintronics;transistor	Bi Wang;Zhaohao Wang;Kaihua Cao;Youguang Zhang;Yuanfu Zhao	2018	2018 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2018.8351482	electronic engineering;radiation hardening;pmos logic;single event upset;tunnel magnetoresistance;spin-½;magnetoresistive random-access memory;radiation;computer science;cmos	EDA	17.366537825506086	60.19362944917024	8175
1e823f67c4326159765a7a1190972ed7a229ad34	performance analysis of centralized, distributed and hybrid demand load control architecture for smart power grid	demand side management;smart metering electric energy load management distributed demand response scheme hybrid demand response grid architecture smart grid technology;smart power grids demand side management load regulation;smart power grids;home appliances load management load modeling computer architecture real time systems smart grids performance evaluation;load regulation;hybrid demand response architecture centralized demand load control distributed demand load control hybrid demand load control smart power grid demand response technology demand response policy	Demand Response (DR) technology of future smart grid makes it possible to have two-way communication between utility service providers and home appliances inside the customer premises. This state-of-art technology is implements various smart devices such as: smart meters, smart load controller, smart thermostats, smart switches and home energy consoles. Furthermore, DR technology can reform the electricity system and provide clients with new information and options to manage their electricity use. Customers can reduce or shift their power usage during peak demand periods in response to real time-based rates or other forms of financial incentives. Besides, demand response policy plays a vital role in modernizing several electric energy domains including: grid reliability, pricing, infrastructure planning and design, emergency response, operations, and usage deferral decisions. In previous studies Demand Load for smart power grid is mostly implemented in a centralized approach. The significance of this study is to propose a hybrid Demand response (HDR) architecture. The study investigates the performance of DR in the context of a centralized, fully Distributed and Hybrid fashion. The research results shows that our proposed HDR scheme performances outperform all other existing demand response policies.	centralized computing;double data rate;geographic coordinate system;load management;network switch;performance;profiling (computer programming);simulation;smart tv;smart device;smart meter	Sami S. Al-Wakeel;Musaed A. Alhussein;Muhammad Ammad-uddin	2012	2013 IEEE Energytech	10.1109/EIT.2013.6632718	embedded system;real-time computing;load balancing;load control switch;demand load;dynamic demand;smart grid	Metrics	2.129825532167496	5.27040382887401	8179
67ce601edec7cd6de5eca10c7b8df719c48cea47	an extremal problem in hypergraph coloring	extremal problem	F ( n , r , k ) is defined to be the minimum number of edges in an r graph on n vertices in which there exists a strongly colored edge in every equipartite k -coloring. Approximate values are given for this function in the general case, and the problem is solved in the particular case of graphs.	graph coloring	F. Sterboul	1977	J. Comb. Theory, Ser. B	10.1016/0095-8956(77)90007-7	combinatorics;discrete mathematics;complete coloring;mathematics;extremal combinatorics	Theory	27.58676017536779	26.172587167296665	8187
5fd946f551277ff816942374409b477eef3c1937	fast modular multiplication using booth recoding based on signed-digit number arithmetic	public key cryptography;hardware design languages;digital signal processing;adders signal processing algorithms circuits digital arithmetic computer science pipelines digital signal processing public key cryptography registers hardware design languages;signed digit;multiplying circuits;residue number systems;pipeline architecture;residue number systems pipeline arithmetic adders multiplying circuits;pipeline architecture modular multiplication booth recoding signed digit number arithmetic p digit radix two sd number system adders;booth recoding;signed digit number arithmetic;p digit radix two sd number system;registers;adders;pipelines;digital arithmetic;circuits;computer science;signal processing algorithms;high speed;pipeline arithmetic;modular multiplication	This paper proposes a new algorithm of serial modular multiplication based on Signed-Digit (SD) number system using Booth recoding method. By introducing a p digit radix-two SD number system, a modular addition is easily implemented by using one or two SD adders, so that no carry propagation will not arise during the additions. A modular multiplication can be performed by repeating the modular addition with modular partial products. In order to implement a high speed modular multiplication, a Booth recoding method is used to reduce the partial products to be added for the modular multiplication. We also give a pipeline architecture with two modular SD adders to relalize a faster modular multiplication. The design result by using VHDL shows that a fast modular multiplier can be implemented based on the presented method.	adder (electronics);booth's multiplication algorithm;pipeline (computing);software propagation;vhdl	S. Wei;S. Chen;K. Shimizu	2002		10.1109/APCCAS.2002.1115104	arithmetic;modular arithmetic;electronic circuit;parallel computing;multiplication algorithm;kochanski multiplication;computer science;electrical engineering;theoretical computer science;digital signal processing;pipeline transport;public-key cryptography;processor register;adder	PL	12.919924323832507	44.54870105492115	8193
9fad3fd09e534b92d5c94cf54772e789553d8e17	a modified peg algorithm for construction of ldpc codes with strictly concentrated check-node degree distributions	graph theory;communications society;histograms;check node degree distributions;convergence;progressive edge growth algorithm;iterative decoding;iterative algorithms;parity check codes;irregular codes;parity check codes histograms communications society convergence hardware iterative decoding iterative algorithms tree graphs;degree distribution;low density parity check codes;tree graphs;girth histogram progressive edge growth algorithm peg low density parity check codes check node degree distributions irregular codes;ldpc code;girth histogram;parity check codes graph theory;hardware;peg	Progressive edge-growth (PEG) algorithm is a good approach to construct low-density parity-check (LDPC) codes with large girth at finite block lengths. However, the check-node degrees of PEG codes are usually loosely concentrated for both regular (more than one degree) and irregular codes (more than two degrees). In this paper, the authors propose a modified PEG algorithm for construction of LDPC codes with strictly concentrated check-node degrees, which yields both completely regular codes and strictly right-concentrated irregular codes with two consecutive check-node degrees. Moreover, our algorithm further improves the girth histogram of the codes for better performance. Simulation results show that even under strictly concentrated check-node degrees, our proposed algorithm slightly improves the performance of both regular and irregular PEG codes, especially for irregular codes at high SNR values.	algorithm;degree (graph theory);degree distribution;expectation–maximization algorithm;girth (graph theory);iterative method;low-density parity-check code;parsing expression grammar;qr code;signal-to-noise ratio;simulation	Him Chen;Zhigang Cao	2007	2007 IEEE Wireless Communications and Networking Conference	10.1109/WCNC.2007.109	combinatorics;discrete mathematics;low-density parity-check code;degree distribution;convergence;graph theory;theoretical computer science;linear code;histogram;mathematics;error floor;peg ratio;tree	Theory	41.87017395951854	59.6719720917979	8197
0f8a203ff5a047465384646158641f94d2449842	energy efficient proximity alert on android	ubiquitous location based services;energy efficiency;global positioning system smart phones batteries legged locomotion accelerometers transportation sensors;legged locomotion;sensors;energy efficient proximity alert;smart phones;proximity alert;android;smartphones;energy efficiency proximity alert smartphones;public domain software;gps;global positioning system;batteries;transportation;open source project;middleware;linux;location providers;public domain software global positioning system linux middleware mobile computing;location sensing interval energy efficient proximity alert android ubiquitous location based services location providers gps middleware service open source project;mobile computing;accelerometers;middleware service;location sensing interval	The proximity alert service on Android is important as an enabler of ubiquitous location-based services, however, it is also limited in this role due to its excessive energy expenditure. In this paper, we present the design and implementation of an energy-efficient proximity alert service for Android. Our method utilizes the distance to the point of interest and the user's transportation mode in order to dynamically determine the location-sensing interval and the location providers (GPS, GSM, or Wi-Fi) to be used. We implement our method as a middleware service in the Android open source project. Our service, for a realistic scenario, reduces GPS usage by 96.66% and increases battery life time by 75.71% compared to the baseline proximity alert in Android.	android;baseline (configuration management);experiment;global positioning system;location-based service;middleware;open-source software;point of interest;smartphone	Muhammed Fatih Bulut;Murat Demirbas	2013	2013 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops)	10.1109/PerComW.2013.6529474	embedded system;real-time computing;global positioning system;computer science;operating system;mobile computing;computer security	Mobile	1.4009129392113517	33.97191842724995	8209
0cbf5a3ded22fc10cd8dca2b4bbe59cf2c20c009	bidirectional optimal operation of smart building-to-grid systems	standards;heating;buildings optimization mathematical model load modeling heating capacitors standards;capacitors;bidirectional optimization energy cost saving standard distribution test feeder load factor maximisation load penetration distribution utilities building load management energy cost minimization mathematical model smart distribution grid smart building to grid system bidirectional optimal operation;smart power grids building management systems cost reduction home automation load distribution minimisation power distribution economics;mathematical model;optimization;load modeling;buildings	This paper proposes a novel bidirectional optimization of buildings integrated to the smart distribution grid, which possess potential benefits to the customers and utilities both. Mathematical models required for the optimal operations of buildings and grids are developed and a new method is proposed to obtain the solution of the bidirectional optimization. In this work, minimization of the cost of energy is chosen as an objective for the building load management, while the distribution utilities aim to increase load penetration by maximizing the load factor. Case studies are carried out based on actual data collected from an office building at Michigan Technological University, and using a standard distribution test feeder. Studies demonstrate that the proposed bidirectional optimization is beneficial to both the customer and the distribution grid as it shows significant saving in the energy costs and improvement on the system load factor.	hash table;load (computing);load management;mathematical optimization	Meysam Razmara;Guna R. Bharati;Mahdi Shahbakhti;Sumit Paudyal;Rush D. Robinett	2015	2015 American Control Conference (ACC)	10.1109/ACC.2015.7170750	mathematical optimization;electronic engineering;simulation;capacitor;load balancing;engineering;mathematical model;mathematics;statistics	AI	4.512045156516818	4.9196537948917385	8213
dfd0b1a5a738d11e141cd901e0f5e3bc5e150e80	convexity of degree sequences	degree sequence	We explore the convexity of the set of vectors consisting of degree sequences of subgraphs of a given graph. Results of Katerinis and Fraisse, Hell and Kirkpatrick concerning vertex deleted f-factors are generalized. © 1999 John Wiley & Sons, Inc. J Graph Theory 30: 147–156, 1999	degree (graph theory)	Richard P. Anstee;Yunsun Nam	1999	Journal of Graph Theory	10.1002/(SICI)1097-0118(199902)30:2%3C147::AID-JGT8%3E3.0.CO;2-C	matching;combinatorics;discrete mathematics;degree;frequency partition of a graph;mathematics	Theory	29.423277488021395	29.770839528732445	8215
d92eef6ab20443299249481555f6d33aa498ae34	universal spaces for classes of scattered eberlein compact spaces				Murray Bell;Witold Marciszewski	2006	J. Symb. Log.		mathematical analysis;topology;mathematics;geometry;compact space;scattering	Logic	48.981605416003084	27.289451275274356	8226
486a6254e841c5e8110f88dcbf73afe308238652	simple stochastic games, mean payoff games, parity games	polynomial time;game playing;stochastic games	Simple Stochastic Games (SSGs), Mean Payoff Games (MPGs), and Parity Games (PGs) are three closely related families of infinite-duration games played on finite graphs. The best known algorithms for the solution of these games run in subexponential time and it is a major open problem whether they can be solved in polynomial time. In the talk, I plan to define these games, describe what is known about them and present many intriguing open problems.		Uri Zwick	2008		10.1007/978-3-540-79709-8_6	combinatorial game theory;time complexity;combinatorics;simulation;turns, rounds and time-keeping systems in games;computer science;game mechanics;mathematics;mathematical economics;algorithm	ECom	13.05438713329975	19.192393894337748	8231
ced65bc8c20fb7baa6784ba466a251a3e392b629	the wiener index of simply generated random trees	continuum random tree;brownian excursion;random tree;mean variance;wiener index;generating function;asymptotic distribution;galton watson tree;limit laws;random trees	Asymptotics are obtained for the mean, variance and higher moments as well as for the distribution of the Wiener index of a random tree from a simply generated family (or, equivalently, a critical Galton– Watson tree). We also establish a joint asymptotic distribution of the Wiener index and the internal path length, as well as asymptotics for the covariance and other mixed moments. The limit laws are described using functionals of a Brownian excursion. The methods include both Aldous’ theory of the continuum random tree and analysis of generating functions.	brownian motion;random tree;thomas j. watson research center;triune continuum paradigm;wiener index	Svante Janson	2003	Random Struct. Algorithms	10.1002/rsa.10074	random binary tree;random graph;generating function;combinatorics;mathematical analysis;discrete mathematics;wiener index;loop-erased random walk;mathematics;brownian excursion;reflected brownian motion;asymptotic distribution;statistics;limit of a function	ML	39.909814837509934	16.099891873802058	8246
1336dedda1c39827640905750493a5cdc408d48f	energy-efficient dual-edge-triggered level converting flip flops with symmetry in setup times and insensitivity to output parasitics	power supplies;energy efficiency;circuit declenchement;circuito desenganche;postlayout simulation;veille electrique;dissipation energie;clocks;energy efficient;energy efficient flip flops;circuito secuencial;flip flop circuits;flip flops;circuit integre rapide;dual edge triggered level converting flip flops;dispositif logique;circuit sequentiel;energy dissipation;circuito logico;clock networks;output parasitics;power management mechanisms;data retention;voltage islands;setup time;circuit bistable;power supplies to apparatus flip flops;circuit logique;sleep mode;energy consumption;sequential logic circuits flip flops high speed ics logic devices;power system management;electrical standby;voltage;power delay product energy efficient flip flops dual edge triggered level converting flip flops voltage islands clock networks sleep mode power management mechanisms data retention output parasitics postlayout simulation;low power electronics;power management;power supplies to apparatus;trigger;horloge;disipacion energia;circuits;temps retard;delay time;power delay product;power consumption;consommation energie electrique;energy efficiency flip flops energy consumption voltage clocks circuits energy management power system management power supplies delay;logic circuit;electronique faible puissance;tiempo retardo;clock;high speed;high speed integrated circuits;flip flop;high speed ics;reloj;logic devices;espera electrica;energy management;sequential logic circuits;sequential circuit	Level converting flip-flops (LCFFs) are crucial components for multisupply systems as interfaces between different voltage islands. The proposed energy-efficient LCFFs reduce the power consumption of clock networks with dual-edge triggering, support sleep mode of power management mechanisms with data retention, and have symmetry in setup times and insensitivity to output parasitics. With all these features, the proposed LCFFs have 19% and 38% lower power-delay product than the conventional LCFF, as demonstrated by postlayout simulation results.	context-aware pervasive systems;detection error tradeoff;flops;overhead (computing);power management;power–delay product;simulation;sleep mode	Lih-Yih Chiou;Shien-Chun Luo	2009	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2008.2007959	embedded system;electronic engineering;real-time computing;engineering;electrical engineering;operating system;efficient energy use	Visualization	18.274749931518212	56.025441991813494	8266
3944cd37dbeba905e37df480f92875e35ad58e83	perturbing polynomials with all their roots on the unit circle	mesure mahler;algorithm complexity;zero de polynome;complejidad algoritmo;zero of polynomial;transfinite diameter;cyclotomic polynomial;mahler measure;cercle unite;complexite algorithme;circulo unitario;cero de polinomio;lehmer s problem;unit circle;fonction mathematique;cyclotomic;functions	Given a monic real polynomial with all its roots on the unit circle, we ask to what extent one can perturb its middle coefficient and still have a polynomial with all its roots on the unit circle. We show that the set of possible perturbations forms a closed interval of length at most 4, with 4 achieved only for polynomials of the form x2n + cxn + 1 with c in [−2, 2]. The problem can also be formulated in terms of perturbing the constant coefficient of a polynomial having all its roots in [−1, 1]. If we restrict to integer coefficients, then the polynomials in question are products of cyclotomics. We show that in this case there are no perturbations of length 3 that do not arise from a perturbation of length 4. We also investigate the connection between slightly perturbed products of cyclotomic polynomials and polynomials with small Mahler measure. We describe an algorithm for searching for polynomials with small Mahler measure by perturbing the middle coefficients of products of cyclotomic polynomials. We show that the complexity of this algorithm is O(C √ d), where d is the degree, and we report on the polynomials found by this algorithm through degree 64.	algorithm;coefficient;cyclotomic polynomial;degree (graph theory);mahler measure;monic polynomial;perturbation theory;root of unity	Michael J. Mossinghoff;Christopher G. Pinner;Jeffrey D. Vaaler	1998	Math. Comput.	10.1090/S0025-5718-98-01007-2	gegenbauer polynomials;difference polynomials;laurent polynomial;combinatorics;mathematical analysis;koornwinder polynomials;unit circle;jacobi polynomials;elementary symmetric polynomial;schur polynomial;cyclotomic polynomial;polynomial arithmetic;resultant;mathematics;geometry;macdonald polynomials;minimal polynomial;reciprocal polynomial;power sum symmetric polynomial;function;askey–wilson polynomials;algebra	Theory	42.011420314365125	36.02112477529126	8272
b1a124656d49b23a86d2d6afe154b5caed94b25d	nonlinear and mixed-integer optimization in chemical process network systems		The use of networks allows the representation of a variety of important engineering problems. The treatment of a particular class of network applications, the Process Synthesis problem, is exposed in this paper. Process Synthesis seeks to develop systematically process owsheets that convert raw materials into desired products. In recent years, the optimization approach to process synthesis has shown promise in tackling this challenge. It requires the development of a network of interconnected units, the process superstructure, that represents the alternative process owsheets. The mathematical model-ing of the superstructure has a mixed set of binary and continuous variables and results in a mixed-integer optimization model. Due to the nonlinearity of chemical models, these problems are generally classiied as Mixed-Integer Nonlinear Programming (MINLP) problems. A number of local optimization algorithms for MINLP problems are outlined in this paper: Generalized Benders Decomposition (GBD), Outer Approximation (OA), Generalized Cross Decomposition (GCD), Extended Cutting Plane (ECP), Branch and Bound (BB), and Feasibility Approach (FA), with particular emphasis on the Generalized Benders Decomposition. Recent developments for the global optimization of nonconvex MINLPs are then introduced. In particular, two branch-and-bound approaches are discussed: the Special structure Mixed Integer Nonlinear BB (SMIN-BB), where the binary variables should participate linearly or in mixed-bilinear terms, and the General structure Mixed Integer Nonlinear BB (GMIN-BB), where the continuous relaxation of the binary variables must lead to a twice-diierentiable problem. Both algorithms are based on the BB global optimization algorithm for nonconvex continuous problems. Once some of the theoretical issues behind local and global optimization algorithms for MINLPs have been exposed, attention is directed to their practical use. The algorithmic framework MINOPT is discussed as a computational tool for the solution of process synthesis problems. It is an implementation of a number of local optimization algorithms for the solution of MINLPs. The synthesis problem for a heat exchanger network is then presented to demonstrate the application of some local MINLP algorithms and the global optimization SMIN-BB algorithm.	algorithm;approximation;benders decomposition;bilinear filtering;bitwise operation;branch and bound;cutting-plane method;global optimization;linear programming relaxation;local search (optimization);mathematical model;mathematical optimization;nonlinear programming;optimization problem	Claire S. Adjiman;Carl A. Schweiger;Christodoulos A. Floudas	1997			mathematical optimization;probabilistic-based design optimization;process simulation;nonlinear system;integer;mathematics	ML	28.069449764146267	6.773295576146444	8278
cd5c7ea8da7e65737794fc5dd1f9c5ab7db9089a	comparison of parallel genetic algorithm with depth first search algorithm for solving verbal arithmetic problems	parallel genetic algorithm;search space;constraint satisfaction;verbal arithmetic;design and implementation;tree structure;depth first search;constraint satisfaction problem	Verbal arithmetic's is a class of constraint satisfaction problems which includes making mathematical relations between meaningful words using simple arithmetic operators like '+' in a way that the result is conceptually true, and assigning digits to the letters of these words and generating numbers in order to make correct arithmetic operations as well. In this puzzle, arithmetic operations are simple and of base ten, but are ciphered into letters. A simple way to solve such problems is by depth first search (DFS) algorithm which has a big search space even for quite small problems. DFS is an algorithm for searching a tree, tree structure. Thus going deeper and deeper until a goal node is found. The paper illustrates the design and implementation of parallel genetic algorithm that can find the solution more quickly taking less memory.	cipher;constraint satisfaction problem;depth-first search;genetic algorithm;goal node (computer science);search algorithm;tree (data structure);tree structure	M. M. Naoghare;V. M. Deshmukh	2011		10.1145/1980022.1980095	discrete mathematics;arbitrary-precision arithmetic;theoretical computer science;mathematics;algorithm;difference-map algorithm;hybrid algorithm;backtracking;search algorithm	Theory	10.682906034109545	16.259424508242226	8280
04a4a3e2da8ec8fc43b34ace75a63e764113557d	tree amalgamation of graphs and tessellations of the cantor sphere	ends;tessellation;hnn product;hyperbolic geometry;cantor set;free product;free product with amalgamation;cantor sphere;connected graph;general methods;hyperbolic plane;negative curvature;k connected graph;vertex transitive graph;transitive graph;planar graph	A general method is described which gives rise to highly symmetric tessellations of the Cantor sphere, i.e., the 2-sphere with the Cantor set removed and endowed with the hyperbolic geometry with constant negative curvature. These tessellations correspond to almost vertextransitive planar graphs with infinitely many ends. Their isometry groups have infinitely many ends and are free products with amalgamation of other planar groups, possibly one or two-ended or finite. It is conjectured that all vertex-transitive tessellations of the Cantor sphere can be obtained in this way. Although our amalgamation construction is rather simple, it gives rise to some extraordinary examples with properties that are far beyond expected. For example, for every integer k, there exists a kconnected vertex-transitive planar graph such that each vertex of this graph lies on at least k infinite faces. These examples disprove a conjecture of Bonnington and Watkins [2] that there are no 5-connected vertex-transitive planar graphs with infinite faces. This also disproves another conjecture that in a 4-connected vertex-transitive planar graph each vertex lies on the boundary of at most one infinite face. Further examples give rise to counterexamples of some other conjectures of similar flavor. ∗Supported in part by the Ministry of Science and Technology of Slovenia, Research Program P1–0297 and Research Project J1–6150.	cantor set;connectivity (graph theory);graph theory;isogonal figure;planar graph;tom;tucker decomposition	Bojan Mohar	2006	J. Comb. Theory, Ser. B	10.1016/j.jctb.2006.02.003	combinatorics;discrete mathematics;topology;hyperbolic geometry;mathematics;geometry;algebra	Theory	33.28117611163983	25.65812770390229	8285
c01e2bec80a9bf4f4aed6ada8afff127fdce404a	small embedding characterizations for large cardinals		Abstract We show that many large cardinal notions can be characterized in terms of the existence of certain elementary embeddings between transitive set-sized structures, that map their critical point to the large cardinal in question. As an application, we use such embeddings to provide new proofs of results of Christoph Weis on the consistency strength of certain generalized tree properties. These new proofs eliminate problems contained in the original proofs provided by Weis.		Peter Holy;Philipp Lücke;Ana Njegomir	2019	Ann. Pure Appl. Logic	10.1016/j.apal.2018.10.002	cardinal number;combinatorics;discrete mathematics;mathematics;critical point (thermodynamics);mathematical proof;large cardinal;transitive relation;embedding	Logic	39.861921955196756	27.667110404829312	8300
bc4c28cc2ce9dee3bf45c7030a4adeb7025539c8	surface reconstruction in parallel	dynamic programming;shortest path;parallel algorithm;image processing;directed toroidal graph;parallel programming dynamic programming image processing message passing parallel algorithms parallel architectures;heterogeneous environment;parallel programming;dynamic program;surface reconstruction;computationally intensive problem;parallel dynamic programming;load balancing directed toroidal graph parallel dynamic programming minimum cost path parallel algorithm message passing parallel architecture surface reconstruction best fit surface contours computationally intensive problem interprocessor communication heterogeneous environment;parallel architectures;message passing parallel architecture;minimum cost path;contours;interprocessor communication;surface reconstruction tiles medical diagnostic imaging parallel algorithms surface fitting cost function dynamic programming parallel architectures concurrent computing mathematics;load balancing;message passing;load balance;best fit surface;parallel architecture;planar graph;parallel algorithms	M a n y methods exist for reconstructing threedimensional surfaces given a collection of i t s contours. Surface reconstruction i s used in medical research and diagnosis, geographical sys tems, and geometric design sys tems. O n e traditional method of surface recons truct ion i s contour triangulation. Fuchs, Kedem, and Uselton reduce the triangulation problem t o finding a m i n i m u m cost cycle in a directed toroidal graph. In this paper, we develop a parallel algorithm to f ind the m i n i m u m cost path. The algorithm can be applied t o various problem domains, including s u r f u e recons truct ion. W e discuss our implementat ion choices and show some performance results.	contour line;geometric design;parallel algorithm;problem domain;radio frequency;toroidal graph	Sunjay E. Talele;Theodore Johnson;Panos E. Livadas	1992		10.1109/SPDP.1992.242757	parallel computing;longest path problem;image processing;computer science;load balancing;theoretical computer science;distributed computing;parallel algorithm	Robotics	14.609531851103904	33.82696486462076	8309
eb8d9bbbd2b9a8984484f18c5637c07052b91ef0	double domination critical and stable graphs upon vertex removal	vertex removal stable graphs;vertex removal critical graphs;double domination	In a graph a vertex is said to dominate itself and all its neighbors. A double dominating set of a graph G is a subset of vertices that dominates every vertex of G at least twice. The double domination number of G, denoted γ×2(G), is the minimum cardinality among all double dominating sets ofG. We consider the effects of vertex removal on the double domination number of a graph. A graph G is γ×2-vertex critical graph (γ×2-vertex stable graph, respectively) if the removal of any vertex different from a support vertex decreases (does not change, respectively) γ×2(G). In this paper we investigate various properties of these graphs. Moreover, we characterize γ×2-vertex critical trees and γ×2-vertex stable trees.	critical graph;decision tree;edge dominating set	Mustapha Chellali;Soufiane Khelifi	2012	Discussiones Mathematicae Graph Theory	10.7151/dmgt.1633	vertex;chordal graph;indifference graph;neighbourhood	Theory	28.330812619871054	28.265774593002917	8323
7e6c02732038232c3b795315533125eae21b5014	a definite integral: 10746				Stepan Tersian;Richard Bagby	2000	The American Mathematical Monthly		algebra;mathematics	Vision	47.98205771668419	29.615700686595854	8329
280292033dbc46120400253b0c9f5a021a439ec2	an optimal voltage synthesis technique for a power-efficient satellite application	minimisation;queueing;voltage energy consumption low earth orbit satellites clocks throughput oceans system performance power system modeling remote monitoring permission;oceans;minimisation space vehicle power plants artificial satellites low power electronics queueing theory aerospace simulation;clocks;queueing theory;power efficiency;satellite orbit period partitioning;aerospace simulation;system performance;permission;energy consumption;voltage;low earth orbit satellites;low power electronics;m m 1 k queue optimal voltage synthesis technique power efficient satellite system performance maximization energy budget satellite orbit period partitioning energy consumption periodic energy recharge model;satellite application;artificial satellites;energy budget;remote monitoring;space vehicle power plants;power efficient satellite;power system modeling;system performance maximization;power efficient design;m m 1 k queue;periodic energy recharge model;throughput;optimal voltage synthesis technique;power aware design	This paper presents an optimal voltage synthesis technique for a satellite application to maximize system performance subject to energy budget. A period of a satellite's orbit is partitioned into several independent regions with different characteristics such as type of computation, importance, performance requirements, and energy consumptions. Given a periodic energy recharge model, optimal voltages for the regions are synthesized such that the overall performance is maximized within the energy budget in the period.	computation;rechargeable battery;requirement	Dong-In Kang;Jinwoo Suh;Stephen P. Crago	2002		10.1145/513918.514043	embedded system;electronic engineering;real-time computing;simulation;telecommunications;computer science;engineering;computer performance;queueing theory;statistics	Arch	-3.9442888989013567	58.694816702354736	8338
01adf3d1d1cdf073a2198eb0944543393a5b0a5c	an efficient parallel algorithm for the longest increasing subsequence problem on a larpbs	computational complexity;parallel algorithms;longest increasing subsequence problem;maximal layer problem;optical bus;parallel algorithm;time complexity	In this paper, we give a parallel algorithm for the longest increasing subsequence problem on a LARPBS, one of the recently proposed parallel model based on optical bus. For a sequence of n integers, we solve the longest increasing subsequence problem in O(k) time using n processors where k is the length of the solution. Then, we give an algorithm for the maximal layers problem that runs in O(k+log(n)) time for a set of n points where k is the number of layers on a n-processor array. To our knowledge, this is the fastest algorithm for that problem.	central processing unit;cost efficiency;fastest;longest increasing subsequence;map (parallel pattern);maximal set;parallel algorithm;processor array	David Semé;Sidney Youlou	2007	Eighth International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT 2007)	10.1109/PDCAT.2007.74	parallel computing;longest increasing subsequence;computer science;theoretical computer science;longest common subsequence problem;distributed computing;parallel algorithm;longest alternating subsequence;algorithm	EDA	13.123656546261738	32.804180047997036	8346
abe81a0eebad9d4cbf198841ab7e84151175bd61	fast gpu implementation of large scale dictionary and sparse representation based vision problems	image recognition;paper;concurrent computing;memory management;image resolution;super resolution sparse representation gpu based computing cuda face recognition;large scale systems dictionaries computer architecture face recognition concurrent computing computer vision parallel processing memory management bandwidth graphics processing unit;computer graphic equipment;gpu;coprocessors;computer vision;cuda;gpu based computing;computer architecture;large scale;face recognition;image representation;dictionary computer vision face recognition super resolution sparse representation cpu parallel processing gpu cuda;dictionaries;system level design;scientific computing;dictionary;nvidia geforce 9800 gt;nvidia;bandwidth;super resolution;parallel processing computer graphic equipment computer vision coprocessors dictionaries face recognition image representation image resolution;computer science;cpu;graphics processing unit;sparse representation;off the shelf;parallel processing;large scale systems;massively parallel processing	Recently, Computer Vision problems like Face Recognition and Super-Resolution solved using sparse representation based methods with large dictionaries have shown state-of-the-art results. However such methods are computationally prohibitive for typical CPUs, especially for a large dictionary size. We present fast implementation of these methods by exploiting the massively parallel processing capabilities of a GPU within a CUDA framework, owing to its easy off-the-shelf availability and programmer friendliness. We provide details of system level design, memory management and implementation strategies. Further, we integrate the solution to the preferred scientific computational platform - MATLAB.	cuda;central processing unit;computer vision;dictionary;facial recognition system;graphics processing unit;level design;matlab;memory management;parallel computing;programmer;sparse approximation;sparse matrix;super-resolution imaging	Pradeep Nagesh;Rahul Gowda;Baoxin Li	2010	2010 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2010.5495526	parallel processing;computer vision;parallel computing;image resolution;concurrent computing;computer science;theoretical computer science;massively parallel;central processing unit;sparse approximation;electronic system-level design and verification;bandwidth;coprocessor;superresolution;memory management;computer graphics (images)	HPC	0.8010765935443165	45.32068942701522	8352
93f96ca2b980dafa0f48ea2e285031e2d2eedce0	packing t-joins		A consequence of Seymour’s characterization of binary clutters with the Max Flow Min Cut property is that the minimum cardinality of a T-cut is equal to the largest number of edge-disjoint T-joins in every graph that cannot be T-contracted to an odd K2,3. We give a simple “graphic” proof of this fact.	maxima and minima;set packing	Paolo Codato;Michele Conforti;Claudia Serafini	1996	Journal of Graph Theory	10.1002/(SICI)1097-0118(199608)22:4%3C293::AID-JGT2%3E3.0.CO;2-G		Theory	27.973521543178197	27.05746438339232	8383
7a44733de1da9ddce1ffb902e57e95d8ee279b16	braiding: a scheme for resolving hazards in kernel adaptive filters	kernel;support vector machines;pipeline arithmetic adaptive filters learning artificial intelligence microprocessor chips minimisation;computer architecture;kernel dictionaries pipeline processing hardware support vector machines throughput computer architecture;dictionaries;pipeline processing;throughput;hardware;norma braiding kernel adaptive filters kaf machine learning algorithms naive online regularised risk minimization algorithm	Computational cost presents a barrier in the application of machine learning algorithms to large-scale real-time learning problems. Kernel adaptive filters (KAFs) have low computational cost with the ability to learn online and are hence favoured for such applications. Unfortunately, dependencies of the outputs on the weight updates prohibit pipelining. This paper introduces a combination of parallel execution and conditional forwarding, called braiding, which overcomes dependencies by expressing the output as a combination of the earlier state and other examples in the pipeline. To demonstrate its utility, braiding is applied to the implementation of classification, regression and novelty detection algorithms based on the Naive Online regularised Risk Minimization Algorithm (NORMA). Fixed point, open source implementations are described which can achieve data rates of around 130 MSamples/s with a latency of 10 to 13 clock cycles. This constitutes a two orders of magnitude increase in throughput and one order of magnitude decrease in latency compared to a single core CPU implementation.	algorithm;algorithmic efficiency;braid;central processing unit;clock signal;computation;datapath;dictionary;field-programmable gate array;fixed point (mathematics);kernel (operating system);kernel adaptive filter;machine learning;novelty detection;open-source software;pipeline (computing);real-time locating system;throughput	Stephen Tridgell;Duncan J. M. Moss;Nicholas J. Fraser;Philip Heng Wai Leong	2015	2015 International Conference on Field Programmable Technology (FPT)	10.1109/FPT.2015.7393140	embedded system;support vector machine;throughput;parallel computing;kernel;computer science;theoretical computer science;machine learning;tree kernel	ML	6.244471408228838	41.25927663670334	8392
646bb799cdba5d2058d85b061df3995284799f1a	cmos logic design with independent-gate finfets	libraries;nanoelectronics cmos logic circuits logic design logic gates mosfet;logic design;finfet gates;finfet logic circuits;cmos logic design;independent gate finfets;low leakage logic style cmos logic design independent gate finfets fin type field effect transistors bulk cmos nanoscale circuits finfet logic circuits finfet gates;finfets;logic gates finfets delay transistors libraries power demand threshold voltage;total power;logic gates;threshold voltage;cmos logic circuits;transistors;nanoelectronics;power optimization;field effect transistor;mosfet;fin type field effect transistors;power demand;low leakage logic style;bulk cmos;nanoscale circuits	Fin-type field-effect transistors (FinFETs) are promising substitutes for bulk CMOS in nano-scale circuits. In this paper, it is observed that in spite of improved device characteristics, high active leakage may remain a problem for FinFET logic circuits. Leakage is found to contribute 31.3% of total power consumption in power-optimized FinFET logic circuits. Various FinFET logic design styles, based on independent control of FinFET gates, are studied. A new low-leakage logic style is presented. Leakage (total) power savings of 64.7% (14.5%) under tight delay constraints and 91.2% (37.2%) under relaxed delay constraints, through the judicious use of FinFET logic styles, are demonstrated.	cmos;gnu nano;logic gate;logic synthesis;spectral leakage;transistor	Anish Muttreja;Niket Agarwal;Niraj K. Jha	2007	2007 25th International Conference on Computer Design	10.1109/ICCD.2007.4601953	nanoelectronics;field-effect transistor;and-or-invert;electronic engineering;logic synthesis;logic gate;electrical engineering;pass transistor logic;threshold voltage;power optimization;transistor;computer engineering	EDA	18.085236119412972	58.758116720292634	8398
5a7a034897d2d19b4155069650dbebfbfcdcf59b	a note on sec/aued codes	error detection codes;error correcting code;error correction codes;decodage;decoding;error detecting code;codigo corrector error;codigo detector error;descending tail matrix;unidirectional error detecting codes sec aued codes single error correcting all unidirectional error detecting sec code unidirectional errors codeword weight distribution descending tail matrix error correcting codes;weight distribution;unidirectional error detecting codes;matrix algebra;matrice t;codificacion;error correcting codes;index terms decoding;tail error correction codes sufficient conditions tv hamming weight neodymium encoding decoding;matriz t;error correction;coding;unidirectional errors;matrix algebra error correction codes error detection codes;error detection;code correcteur erreur;encoding;codage;t matrix;code detecteur erreur	A common method of constructing single error correcting/all unidirectional error detecting (SEG/AUED) codes is to choose a SEC code and then to append a tail such that the new code can detect all unidirectional errors. The tail is a function of the weight of the codeword. We present a technique to reduce the weight distribution of the SEC code so that the tail needed is smaller. We also present a new method to construct the tail.	code	Rajendra S. Katti	1996	IEEE Trans. Computers	10.1109/12.485377	error detection and correction;computer science;theoretical computer science;algorithm;statistics	Vision	40.51182284819703	57.52940494620739	8406
c4b9831ae0c7645bf365032dc8f1eda0ec1d32a9	uprooting and rerooting higher-order graphical models		The idea of uprooting and rerooting graphical models was introduced specifically for binary pairwise models by Weller [19] as a way to transform a model to any of a whole equivalence class of related models, such that inference on any one model yields inference results for all others. This is very helpful since inference, or relevant bounds, may be much easier to obtain or more accurate for some model in the class. Here we introduce methods to extend the approach to models with higher-order potentials and develop theoretical insights. In particular, we show that the triplet-consistent polytope TRI is unique in being ‘universally rooted’. We demonstrate empirically that rerooting can significantly improve accuracy of methods of inference for higher-order models at negligible computational cost.	active worlds;algorithmic efficiency;clamping (graphics);computation;computational complexity theory;connected component (graph theory);expectation propagation;graphical model;heuristic;model m keyboard;triplet state;turing institute;turing completeness;universal quantification	Mark Rowland;Adrian Weller	2017			artificial intelligence;machine learning;polytope;equivalence class;pairwise comparison;inference;binary number;mathematics;graphical model	ML	14.137009235385843	17.172250386539577	8413
69768cddad16f7d714a9ec3fec969c73e1184d4d	risk aware net load balancing in micro grids with high der penetration		The rapid transformation of micro grids due to the accelerated integration of renewables, storage systems and IoT enabled monitoring and control has opened up new opportunities as well as challenges. Future micro grids will be characterized by high DER penetration and will require sophisticated net load balancing frameworks which explicitly consider the errors in prediction of load and generation due to uncertainty in weather conditions while making decisions. Traditional techniques for grid net load management which rely on isolated shaping of load and supply curves are inadequate and inefficient. For micro grids with high PV penetration, the intermittent and unpredictable nature of PV based energy generation can lead to dramatic and sudden supply demand imbalances thus requiring a holistic framework for balancing net load over the entire horizon. In this paper, we develop a sequential decision making framework for net load management that optimally balances the usage of storage and energy market transactions as a mechanism for mitigating supply demand imbalances (net load imbalances) over the horizon. Our framework specifically accounts for prediction uncertainty of future net load imbalances and minimizes the tail end risk of storage shortfall at the end of the horizon. Using qualitative analysis, we show that our framework achieves its objective of minimum cost net load balancing while accounting for the tail end risk.	holism;load balancing (computing);load management;noise shaping;procurement;software deployment	Sanmukh R. Kuppannagari;Rajgopal Kannan;Viktor K. Prasanna	2018	2018 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT)	10.1109/ISGT.2018.8403335	renewable energy;energy market;electricity generation;grid;business;microeconomics;energy storage;supply and demand;load management;load balancing (computing)	HPC	2.5042009727046253	6.371703384365099	8433
8868a20ef50874bd603dcbd9aae1a4739e924bcc	the block-oriented computer	processing element;implicit function generation;array processor computer organization high reliability implicit function generation large scale integration lsi wafers undiced modular computer organization parallel computation variable increment computation algorithm;computer organization;array processor;parallel computation;chip;large scale integration;high reliability;modular computer organization;parallel computer;variable increment computation algorithm;lsi wafers undiced	LSI will have a profound effect on the design of computer systems ranging from evolutionary changes in implementation to revolutionary changes in basic architecture. This paper discusses a computer composed of an array of processors. Entire wafers are used, rather than wafers diced into chips. The computer utilizes software to substitute process elements for the purpose of compensating for imperfect yield on the wafer. The computer organization possesses a property called block orientation which permits the use of whole LSI wafers with low yields without requiring a secondary metalization manufacturing step. Through the use of a unique computing algorithm, the parallelism and communication problems inherent to array processors are minimized. Processing systems of the sort discussed can possess a self-healing capability.	algorithm;central processing unit;computer;integrated circuit;microarchitecture;parallel computing;wafer (electronics)	Joseph O. Campeau	1969	IEEE Transactions on Computers	10.1109/T-C.1969.222753	chip;embedded system;parallel computing;microarchitecture;computer science;electrical engineering;theoretical computer science;operating system	Arch	8.932403176020747	49.026961381030894	8435
b3eccc6f0d839f70eb196be684a971f687fe6b7c	module assignment for pin-limited designs under the stacked-vdd paradigm	stacked-vdd paradigm;module assignment approach;power waste;partition-based algorithm;module assignment problem;stacked-vdd circuit paradigm;ic example show;different vdd rail;vdd domain;dlx architecture show;pin-limited design;assigning module;network synthesis;high level synthesis;floorplanning;assignment problem;voltage regulator;signal integrity;chip;bin packing	This paper addresses the module assignment problem in pin-limited designs under the stacked-Vdd circuit paradigm. A partition-based algorithm is presented for efficiently assigning modules at the floorplanning level so as to reuse currents between the Vdd domains, and minimize the power wasted during the operation of the circuit. Experimental results on a DLX architecture show that compared with assigning modules to different Vdd rails using a bin-packing technique, the circuit generated by our algorithm has 32% lower wasted power, on average. In addition, experiments on a 3D IC example show that our module assignment approach is equally effective in reducing the power waste in 3D ICs.	algorithm;assignment problem;bin packing problem;dlx;experiment;floorplan (microelectronics);programming paradigm;set packing;three-dimensional integrated circuit;value-driven design;voltage regulator	Yong Zhan;Tianpei Zhang;Sachin S. Sapatnekar	2007	2007 IEEE/ACM International Conference on Computer-Aided Design	10.1145/1326073.1326211	chip;network synthesis filters;floorplan;mathematical optimization;voltage regulator;electronic engineering;bin packing problem;parallel computing;real-time computing;telecommunications;computer science;signal integrity;engineering;assignment problem;high-level synthesis	EDA	13.717141747972367	53.63708200228066	8443
10b1ce80cca394acfff0f76bafb427993fb144bb	approximation operator based on neighborhood systems		In this paper, we propose a new covering-based set in which the lower and the upper approximation operations are defined by neighborhood systems. We discuss this new type of covering-based set systematically in two steps. First, we study the basic properties of this covering-based set, such as the properties of normality, contraction, and monotone. Second, we discuss the relationship between the new type of covering-based set and the other ten sets proposed.	approximation;hl7publishingsubsection <operations>;new type;normality unit;monotone	Pei Wang;Qingjun Wu;Jiali He;Xiao Shang	2018	Symmetry	10.3390/sym10110539	combinatorics;operator (computer programming);partition (number theory);mathematics;rough set	AI	42.69255659046361	24.777824091872198	8444
0dee2220d37f64e6e82eef5c1a494707968356b0	optimal dimensioning of pipe networks with application to gas transmission networks	equipment planning;institutional repositories;belgica;europa;dimensionnement;analisis sensibilidad;gas distribution network;red gas;fedora;distribution network;reseau distribution;pipe;investment cost;coste inversion;bundle method;dimensioning;capacity expansion;reseau gaz;industries;vital;red distribucion;belgique;algorithme;optimisation combinatoire;belgium;algorithm;nondifferentiable;natural gas;estudio caso;canalizacion;sensitivity analysis;cout investissement;etude cas;optimal design;analyse sensibilite;canalisation;operating cost;cout exploitation;application of the bundle method;nonsmooth optimization;europe;vtls;combinatorial optimization;dimensionamiento;programming;expansion of a gas transmission network;optimal dimensioning of gas transmission networks;ils;optimizacion combinatoria;costo explotacion;algoritmo	We develop an algorithm to solve the problem of the optimal dimensioning of a fluid gas or water transmission network when the topology of the network is known. The pipe diameters must be chosen to minimize the sum of the investment and operating costs. This two stage problem is solved by application of the bundle method for nonsmooth optimization. The validity of the approach is tested on a problem corresponding to a real situation: the optimal design of a reinforcement of the Belgian gas network.		Daniel De Wolf;Yves Smeers	1996	Operations Research	10.1287/opre.44.4.596	canalisation;natural gas;programming;mathematical optimization;simulation;combinatorial optimization;optimal design;operations management;mathematics;pipe;operations research;dimensioning;sensitivity analysis;statistics	ML	18.039577132527054	5.9092798248038445	8448
ffcf8e5fe5a34044f4241a163bce9ff4b122bacc	robustness of interdependent geometric networks under inhomogeneous failures		Complex systems such as smart cities and smart power grids rely heavily on their interdependent components. The failure of a component in one network may lead to the failure of the supported component in another network. Components which support a large number of interdependent components may be more vulnerable to attacks and failures. In this paper, we study the robustness of two interdependent networks under node failures. By modeling each network using a random geometric graph (RGG), we study conditions for the percolation of two interdependent RGGs after in-homogeneous node failures. We derive analytical bounds on the interdependent degree thresholds (k1,k2), such that the interdependent RGGs percolate after removing nodes in Gi that support more than kj nodes in Gj (Vi, j є {1,2},i ≠ j). We verify the bounds using numerical simulation, and show that there is a tradeoff between k1 and k2 for maintaining percolation after the failures.	attack (computing);cascading failure;complex systems;computer simulation;geometric graph theory;geometric networks;interdependence;interdependent networks;numerical analysis;percolation theory;random geometric graph;smart city	Khashayar Kamran;Jianan Zhang;Edmund Yeh;Eytan Modiano	2018	2018 16th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt)	10.23919/WIOPT.2018.8362877	distributed computing;robustness (computer science);telecommunications network;computer science;smart grid;random geometric graph;computer simulation;interdependent networks;percolation;geometric networks	Arch	-2.940353937330083	7.192347342131475	8449
7a984acb49f64c682fb024e07161ccb956514125	reactive clocks with variability-tracking jitter	ring oscillators;thermal management packaging;integrated circuits reliability;nanoelectronica;performance evaluation;info eu repo semantics conferenceobject;clocks;oscillators;circuits integrats fiabilitat;timing jitter clocks integrated circuit reliability nanoelectronics oscillators performance evaluation power aware computing thermal management packaging;arees tematiques de la upc enginyeria electronica microelectronica;nanoelectronic devices systematic analysis timing correctness reactive clocking scheme with variability tracking jitter rclk power reduction clock frequency adjustment guardband margin reduction energy savings thermal management reliability performance loss mitigation power loss mitigation adaptive clocks ring oscillators clock generation;phase locked loops;power aware computing;conference report;nanoelectronics;integrated circuit modeling;info eu repo semantics submittedversion;jitter;timing jitter;clocks delays jitter ring oscillators phase locked loops integrated circuit modeling;delays	The growing variability in nanoelectronic devices, due to uncertainties from the manufacturing process and environmental conditions (power supply, temperature, aging), requires increasing design guardbands, forcing circuits to work with conservative clock frequencies. Various schemes for clock generation based on ring oscillators and adaptive clocks have been proposed with the goal to mitigate the power and performance losses attributable to variability. However, there has been no systematic analysis to quantify the benefits of such schemes and no sign-off method has been proposed for timing correctness. This paper presents and analyzes a Reactive Clocking scheme with Variability-Tracking Jitter (RClk) that uses variability as an opportunity to reduce power by continuously adjusting the clock frequency to the varying environmental conditions, and thus, reduces guardband margins significantly. Power can be reduced between 20% and 40% at iso-performance and performance can be boosted by similar amounts at iso-power. Additionally, energy savings can be translated to substantial advantages in terms of reliability and thermal management. More importantly, the technology can be adopted with minimal modifications to conventional EDA flows.	clock rate;correctness (computer science);heart rate variability;image scaling;no symbol;noise margin;power supply;programming paradigm;spatial variability;thermal management of high-power leds	Jordi Cortadella;Luciano Lavagno;Pedro López;Marc Lupon;Alberto Moreno-Conde;Antoni Roca;Sachin S. Sapatnekar	2015	2015 33rd IEEE International Conference on Computer Design (ICCD)	10.1109/ICCD.2015.7357159	nanoelectronics;embedded system;electronic engineering;real-time computing;phase-locked loop;jitter;telecommunications;computer science;engineering;electrical engineering;oscillation	EDA	19.257699578935892	58.07118641012727	8452
0d4c45c56cbcead04127f81479c0c6a58fcd4f6b	strategyproof approximation of the minimax on networks	minimax;approximation;mechanism design;facility location	We consider the problem of locating a facility on a network, represented by a graph. A set of strategic agents have different ideal locations for the facility; the cost of an agent is the distance between its ideal location and the facility. A mechanism maps the locations reported by the agents to the location of the facility. We wish to design mechanisms that are strategyproof, in the sense that agents can never benefit by lying, and at the same time provide a small approximation ratio with respect to the minimax measure. We design a novel “hybrid” strategyproof randomized mechanism that provides a tight approximation ratio of 3/2 when the network is a circle (known as a ring in the case of computer networks). Furthermore, we show that no randomized SP mechanism can provide an approximation ratio better than 2− o(1) even when the network is a tree, thereby matching a trivial upper bound of two.	approximation algorithm;graph (discrete mathematics);map;minimax;randomized algorithm	Noga Alon;Michal Feldman;Ariel D. Procaccia;Moshe Tennenholtz	2010	Math. Oper. Res.	10.1287/moor.1100.0457	mechanism design;minimax;mathematical optimization;combinatorics;discrete mathematics;facility location problem;approximation;mathematics	ECom	25.508869442502405	17.643446981969237	8459
5cdfee3c2ce73a9c46f3b62c3bbbd5c91da14246	asynchronous state machine synthesis using data driven clocks	asynchronous sequential logic;clocks;encoding;logic design;ssi;vlsi;vmebus requester;arbitrary state encoding;asynchronous state machine synthesis;data driven clocks;latches;master-slave configuration;memory elements;minimum state variables;self-clocked circuits	The classical methods for the design of asynchronous state machines are usually complicated due to critzcal races and hazards, and necessitate special state ass~gnment techniques and hazard free combtnattonal logic leading to extra hardware. The necessity for such special considerations prevents asynchronous de.mgns to take advantage of the CAD tools developed for synchronous machines. The contribution of thm paper is a novel and systematic approach to the design of asynchronous state machines with mtntmum state variables and arbitrary state encoding. Multtple tnput changes are allowed. Simple latches tn master-slave conjiguratton are used as memory elements rendertng the method suitable for tmplementatton in SS1 or VLSI. It avoids extra delay elements often necessary in selfclocked circuits. The method is illustrated by its application to the design of a VMEbus requester.	asynchronous i/o;computer-aided design;finite-state machine;integrated circuit;uml state machine;vmebus;very-large-scale integration	Farhad Aghadasi	1992			embedded system;synchronization;synchronous motor;electronic engineering;parallel computing;logic synthesis;real-time computing;design methods;electronic design automation;telecommunications;hazard;computer science;electrical engineering;sequential logic;very-large-scale integration;finite-state machine;encoding	EDA	18.782426339669374	49.58520490359498	8464
a36b8c3a2bfbab93fa7fe4afb4f7ed8a5ee13555	abstract valuations: a novel representation of plotkin power domain and vietoris hyperspace	topological space	valuations on a topological space X are functions that map open sets to 0, 1, or one value in between. We deene a space of abstract valuations which for a continuous dcpo X is homeomorphic to the Plotkin power domain of X, and for a Hausdorr space X yields the Vietoris hyperspace of X. Thus we obtain a novel concrete representation of the Plotkin power domain. This representation is more similar to the standard representation of the probabilistic power domain than the previously known ones.	plotkin bound;power domains;vietoris–rips complex	Reinhold Heckmann	1997	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(05)80163-X	mathematical analysis;discrete mathematics;topology;computer science;mathematics;topological space	PL	42.702493088766595	25.731419686200613	8466
a729f3b8844dc82c6eeab50991d3ee63e4b97e70	power management techniques in an fpga-based wsn node for high performance applications	microcontrollers;robotica e informatica industrial;energy management systems;sw based solution wireless sensor network ram based fpga high end wsn application complex sensor management video camera image encoding encryption data bandwidth complex processing task low power design requirement extensive hw algorithm mapping power islands smart management technique partial reconfiguration technique energy saving low power microcontroller;energy management fpga based wsn node low power design partial reconfiguration power islands;wireless sensor networks energy management systems field programmable gate arrays low power electronics microcontrollers random access storage;low power electronics;random access storage;field programmable gate arrays;field programmable gate arrays wireless sensor networks power demand microcontrollers random access memory computer architecture;wireless sensor networks	In this work, the power management techniques implemented in a high-performance node for Wireless Sensor Networks (WSN) based on a RAM-based FPGA are presented. This new node custom architecture is intended for high-end WSN applications that include complex sensor management like video cameras, high compute demanding tasks such as image encoding or robust encryption, and/or higher data bandwidth needs. In the case of these complex processing tasks, yet maintaining low power design requirements, it can be shown that the combination of different techniques such as extensive HW algorithm mapping, smart management of power islands to selectively switch on and off components, smart and low-energy partial reconfiguration, an adequate set of save energy modes and wake up options, all combined, may yield energy results that may compete and improve energy usage of typical low power microcontrollers used in many WSN node architectures. Actually, results show that higher complexity tasks are in favor of HW based platforms, while the flexibility achieved by dynamic and partial reconfiguration techniques could be comparable to SW based solutions.	algorithm;atmel avr;bitstream;booting;encryption;field-programmable gate array;microcontroller;power management;requirement;sensor node;shattered world;sleep mode;software deployment;static random-access memory;system on a chip	Miguel Lombardo;Julio A Camarero;Juan Valverde;Jorge Portilla;Eduardo de la Torre;Teresa Riesgo	2012	7th International Workshop on Reconfigurable and Communication-Centric Systems-on-Chip (ReCoSoC)	10.1109/ReCoSoC.2012.6322888	microcontroller;embedded system;real-time computing;wireless sensor network;sensor node;computer science;operating system;key distribution in wireless sensor networks;field-programmable gate array;low-power electronics	EDA	-0.5983222505361564	58.9478258685317	8468
3398199fb5e984f75bc1f761c7a4906ddafaf02b	further results about the cyclicity of generalized goppa codes	lagrange interpolation;code cyclique;interpolation lagrange;code goppa generalise;cyclic code;code;polynome;codigo	Goppa codes are a very important family of linear block codes in the errorcorrecting codes [l, 21. Many researchers have generalized the Goppa codes [3-61. Generalized Goppa codes defined in terms of Lagrange’s interpolation polynomials were given by Tzeng and Zimmermann [7]. The definition of generalized Goppa codes makes the connection to Goppa codes more explicit and direct and also helps simplify their analysis [2]. On the basis of [8], this paper will discuss the cyclicity of generalized Goppa codes more completely. Let L ={a,, (Y~, . . . , (Y,-~} be a subset of GF(q”) and let L(z) = &‘:d (z CY~) and L’(z) be the formal derivative of L(z) with respect to z. Let [A(z)lLCz) denote the residue class of A(z) modulo L(z).	binary goppa code;interpolation;linear code;modulo operation;polynomial	Kenneth K. Tzeng;Gui Liang Feng	1985	Discrete Mathematics	10.1016/0012-365X(85)90035-4	polynomial code;combinatorics;discrete mathematics;lagrange polynomial;cyclic code;mathematics;goppa code;code;algebra	Theory	41.16668637469747	54.066957505564666	8473
bf284ef68fea566e7745c2bb8b4cf3807c41ede1	real zeros and partitions without singleton blocks	normal distribution	We prove that the generating polynomials of partitions of an n-element set into non-singleton blocks, counted by the number of blocks, have real roots only. We apply this information to find the most likely number of blocks. As another application of the real zeros result, we prove that the number of blocks is normally distributed in such partitions. We present a quick way to prove the corresponding statement for cycles of permutations in which each cycle is longer than a given integer r.	polynomial	Miklós Bóna;István Mezö	2016	Eur. J. Comb.	10.1016/j.ejc.2015.07.021	normal distribution;combinatorics;discrete mathematics;mathematics;algebra	Theory	38.10354754026839	36.91412272147557	8476
94fdaca1e4c0b38c5dcfd1988b5c12143187783c	the number of spanning trees in apollonian networks	enumeration;complex networks;small world graphs;spanning trees;lattices;scale free;self similar;apollonian networks;article;maximally planar	In this paper we find an exact analytical expression for the number of spanning trees in Apollonian networks. This parameter can be related to significant topological and dynamic properties of the networks, including percolation, epidemic spreading, synchronization, and random walks. As Apollonian networks constitute an interesting family of maximal planar graphs which are simultaneously small-world, scale-free, Euclidean and space filling, modular and highly clustered, the study of their spanning trees is of particular relevance. Our results allow also the calculation of the spanning tree entropy of Apollonian networks, which we compare with those of other graphs with the same average degree.	apollonian network;file spanning;maximal set;percolation;planar graph;relevance;self-similarity;spanning tree	Zhongzhi Zhang;Bin Wu;Francesc Comellas	2014	Discrete Applied Mathematics	10.1016/j.dam.2014.01.015	apollonian network;combinatorics;discrete mathematics;topology;minimum degree spanning tree;spanning tree;self-similarity;scale-free network;lattice;mathematics;enumeration;complex network	Theory	28.359391381974042	36.53431137885814	8495
74b0fc1fca53fb471e1190bd8f3ccb9117c3c8df	an algorithm for listing all minimal 2-dominating sets of a tree		We provide an algorithm for listing all minimal 2-dominating sets of a tree of order n in time O(1.3248). This implies that every tree has at most 1.3248 minimal 2-dominating sets. We also show that this bound is tight.	algorithm;rough set	Marcin Krzywkowski	2013		10.1007/978-3-642-38756-2_4	k-ary tree;incremental decision tree;mathematics;pattern recognition;artificial intelligence;interval tree	Theory	17.673944464390555	24.692888437139768	8500
37a9452888927675957fa54a489b5a3b58a5046a	an efficient distributed depth-first-search algorithm	distributed system;systeme reparti;recherche profondeur d abord;sistema informatico;reseau ordinateur;search strategy;transmission message;computer system;message transmission;computer network;sistema repartido;algorithme reparti;strategie recherche;red ordenador;systeme informatique;depth first search;busqueda profundidad primer;distributed algorithm;transmision mensaje;estrategia investigacion	Consider a communication network. Our goal is to equip the set of processors in the network with a control algorithm that will allow a processor in the network to effect a depth-first traversal through the graph underlying the network, using messages. The output of the algorithm is a depthfirst-search (DFS) tree of the graph underlying the network, kept in a distributed fashion, i.e., at the end of the algorithm, each node will know its parent and children in the DFS tree [5]. Table 1 contains a chronological list of distributed depth-first-search (DDFS) algorithms and their time and message complexities, considering unbounded message sizes, for an undirected graph with V nodes and E edges. The algorithm presented here achieves its optimal time [6] in a straightforward fashion. We simply distribute the traditional sequential, recursive DFS over the network, letting each processor node handle communication with its father and children. Thus, optimal time and message complexity is achieved by eliminating all real parallelism (and by putting more information in each message and allowing messages of varying size).	central processing unit;depth-first search;graph (discrete mathematics);parallel computing;recursion;search algorithm;telecommunications network;tree traversal	Mohan B. Sharma;S. Sitharama Iyengar	1989	Inf. Process. Lett.	10.1016/0020-0190(89)90041-0	distributed algorithm;breadth-first search;telecommunications;computer science;artificial intelligence;brooks–iyengar algorithm;distributed computing;suzuki-kasami algorithm;distributed minimum spanning tree	Theory	17.593661543985167	31.255254704844397	8504
0d8594ed6d47de6e4665d089e57b0efec908d4df	sharp bounds for nbue distributions	queueing;reliability;new better than used in expectation	Let F be a new better than used in expectation (NBUE) distribution function with mean μ. In a previous paper (Brown in Probab. Eng. Inf. Sci. 20:195–230, 2006), the author derived the following bound. For any t ≥ μ, F(t) = Pr(X ≥ t) ≤ e−[ t μ −1]. The main result of this paper is to show that this bound is sharp. Other sharp bounds for NBUE distributions are also derived.		Mark Brown	2013	Annals OR	10.1007/s10479-012-1151-0	combinatorics;calculus;reliability;mathematics;queueing theory;statistics	Theory	42.07027215080068	12.529214648497405	8506
e3d590412e6bcf52dac483804d364c6148a0babf	a hybrid approach for single-machine tardiness problems with sequence-dependent setup times	sequence dependence;forecasting;swarm intelligence;reliability;project management;information systems;disjunctive programming;ant colony optimization;intelligence en essaim;machine unique;maintenance;competitividad;programmation disjonctive;soft or;benchmark problem;information technology;packing;operations research;location;simulated annealing;algoritmo genetico;investment;journal;journal of the operational research society;inventory;purchasing;upper bound;hybrid approach;history of or;single machine;maquina unica;recuit simule;setup time;logistics;marketing;scheduling;retard;competitiveness;algorithme genetique;scheduling problem;production;communications technology;genetic algorithm;recocido simulado;tabu search;computer science;operational research;tardiness penalties;borne superieure;retraso;competitivite;inteligencia de enjambre;programacion disyuntiva;ordonnancement;applications of operational research;or society;busqueda tabu;reglamento;recherche tabou;jors;management science;infrastructure;cota superior	Scheduling problems in real systems often require sequence-dependent setup times. The topic of sequence-dependent setup times has not been addressed adequately, and improved competitiveness is thus not achieved. This study proposes a hybrid approach that takes advantage of simulated annealing (SA) and tabu search (TS) to solve single-machine tardiness problems with sequence-dependent setup times. To verify the proposed approach, experiments were conducted on benchmark problem sets that included both the weighted and un-weighted tardiness problems. The results show that the performance of the hybrid approach is superior to that of the SA, genetic algorithm, TS and ant colony optimization approaches, and is comparable with the Tabu-VNS approach. And the proposed approach found new upper bound values for many benchmark problems with an acceptable computational time.		Shih-Wei Lin;K.-C. Ying	2008	JORS	10.1057/palgrave.jors.2602434	project management;logistics;simulation;genetic algorithm;inventory;simulated annealing;economics;forecasting;tabu search;investment;swarm intelligence;computer science;marketing;operations management;reliability;mathematics;location;operations research;information technology;scheduling	Vision	18.83151586901945	5.780831001220245	8507
5dfbc151f4e16511c26c51088f63b91bfab9c185	this house proves that debating is harder than soccer	004;cs cc;complexity elimination games soccer debating;computational complexity;computer science	During the last twenty years, a lot of research was conducted on the sport elimination problem: Given a sports league and its remaining matches, we have to decide whether a given team can still possibly win the competition, i.e., place first in the league at the end. Previously, the computational complexity of this problem was investigated only for games with two participating teams per game. In this paper we consider Debating Tournaments and Debating Leagues in the British Parliamentary format, where four teams are participating in each game. We prove that it is NP-hard to decide whether a given team can win a Debating League, even if at most two matches are remaining for each team. This contrasts settings like football where two teams play in each game since there this case is still polynomial time solvable. We prove our result even for a fictitious restricted setting with only three teams per game. On the other hand, for the common setting of Debating Tournaments we show that this problem is fixed parameter tractable if the parameter is the number of remaining rounds k. This also holds for the practically very important question of whether a team can still qualify for the knock-out phase of the tournament and the combined parameter k + b where b denotes the threshold rank for qualifying. Finally, we show that the latter problem is polynomial time solvable for any constant k and arbitrary values b that are part of the input. 1998 ACM Subject Classification F.2.2 Nonnumerical Algorithms and Problems	algorithm;cobham's thesis;computational complexity theory;decision problem;np-hardness;time complexity	Stefan Neumann;Andreas Wiese	2016		10.4230/LIPIcs.FUN.2016.25	simulation;computer science;computational complexity theory;operations research;algorithm	ECom	18.542548717771513	17.758815423108235	8511
45887a0b0e00eadc1a273016f52d643acdbd050f	system architecture of an adaptive reconfigurable dsp computing engine	reconfiguration;processing element;traitement signal;filtro respuesta impulsion inacabada;front end;reconfiguracion;transformation cosinus;architecture systeme;estimation mouvement;cost effective video rate dsp applications system architecture adaptive reconfigurable dsp computing engine numerically intensive front end audio video communications massively parallel architecture low level computationally intensive data processing finite impulse response filtering infinite impulse response filtering fir filter iir filter subband filtering discrete orthogonal transform adaptive filtering motion estimation programmed function computational speed multirate operations processing speed;filtre reponse impulsion finie;video signal processing;adaptive filtering;reconfigurable architectures;filtrado adaptable;estimacion movimiento;finite impulse response filter;iir filter;audio video;data processing;motion estimation;fir digital filter;indexing terms;digital filter;discrete cosine transform;infinite impulse response filter;motion estimation digital signal processing chips video signal processing reconfigurable architectures parallel architectures pipeline processing adaptive filters iir filters fir filters programmable filters transforms;quadrature mirror filter;filtro respuesta impulsion acabada;adaptive filters;finite impulse response;senal video;parallel architectures;signal video;signal processing;transformacion coseno;transforms;filtre reponse impulsion infinie;on the fly;video signal;programmable filters;computer architecture digital signal processing finite impulse response filter concurrent computing iir filters adaptive filters engines filtering parallel architectures data processing;cost effectiveness;infinite impulse response;arquitectura sistema;digital signal processing chips;filtrage adaptatif;orthogonal transformation;systeme parallele;fir filters;parallel system;parallel architecture;cosine transform;system architecture;processing speed;procesamiento senal	Modern digital signal processing (DSP) applications call for computationally intensive data processing at very high data rates. In order to meet the high-performance/lowcost constraints, the state-of-the-art video processor should be a programmable design which performs various tasks in video applications without sacrificing the computational power and the manufacturing cost in exchange for such flexibility. Currently, general-purpose programmable DSP processor and applicationspecific integrated circuit (ASIC) design are the two major approaches for data processing in practical implementations. In order to meet the high-speed/low-cost constraint, it is desirable to have a programmable design that has the flexibility of the general-purpose DSP processor while the computational power is similar to ASIC designs. In this paper, we present the system architecture of an adaptive reconfigurable DSP computing engine for numerically intensive front-end audio/video communications. The proposed system is a massively parallel architecture that is capable of performing most low-level computationally intensive data processing including finite impulse response/infinite impulse response (FIR/IIR) filtering, subband filtering, discrete orthogonal transforms (DT), adaptive filtering, and motion estimation for the host processor in DSP applications. Since the properties of each programmed function such as parallelism and pipelinability have been fully exploited in this design, the computational speed of this computing engine can be as fast as ASIC designs that are optimized for individual specific applications. We also show that the system can be easily configured to perform multirate FIR/IIR/DT operations at negligible hardware overhead. Since the processing elements are operated at half of the input data rate, we are able to double the processing speed on-the-fly based on the same system architecture without using high-speed/fullcustom circuits. The programmable/high-speed features of the proposed design make it very suitable for cost-effective video-rate DSP applications.	adaptive filter;application-specific integrated circuit;data rate units;digital signal processing;finite impulse response;general-purpose markup language;general-purpose modeling;high- and low-level;infinite impulse response;motion estimation;numerical analysis;overhead (computing);parallel computing;reconfigurable computing;systems architecture;video processing	An-Yeu Wu;K. J. Ray Liu;Arun Raghupathy	1998	IEEE Trans. Circuits Syst. Video Techn.	10.1109/76.660829	adaptive filter;embedded system;computer vision;real-time computing;data processing;computer science;finite impulse response;signal processing;infinite impulse response	EDA	11.177849708342752	41.95536057688401	8517
10a9998c079b512c777c579bd8c1897dd8653db3	graphs whose spectrum determined by non-constant coefficients		Let G be a graph and M be a matrix associated with G whose characteristic polynomial is M(G,x) = ∑n i=0 αi(G)x n−i. We say that the spectrum of G is determined by non-constant coefficients (simply M-SDNC), if for any graphH with ai(H) = ai(G), 0 ≤ i ≤ n−1, then Spec(G) = Spec(H) (if M is the adjacency matrix or the Laplacian matrix of G, then G is called an A-SDNC graph or L-SDNC graph). In this Available online at www.sciencedirect.com Electronic Notes in Discrete Mathematics 45 (2014) 29–34 1571-0653/$ – see front matter © 2013 Elsevier B.V. All rights reserved. www.elsevier.com/locate/endm http://dx.doi.org/10.1016/j.endm.2013.11.007 paper, we study some properties of graphs which are A-SDNC or L-SDNC. Among other results, we prove that the path of order at least five is L-SDNC and moreover stars of order at least five are both A-SDNC and L-SDNC. Furthermore, we construct infinitely many trees which are not A-SDNC graphs. More precisely, we show that there are infinitely many pairs (T, T ′) of trees such that A(T, x)−A(T ′, x) = −1.	adjacency matrix;characteristic polynomial;coefficient;discrete mathematics;emoticon;graph (discrete mathematics);laplacian matrix	Saieed Akbari;Dariush Kiani;Maryam Mirzakhah	2014	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2013.11.007	strongly regular graph;combinatorics;discrete mathematics;mathematics;algebra	Theory	30.140818161973293	33.572781165679864	8521
496ce3574ee7687dd16487dd86b8af13f44c27b9	query efficient pcps with perfect completeness	approximate algorithm;probability;query processing;computational complexity query processing formal verification theorem proving probability;probabilistic checking of proofs query efficient pcps perfect completeness pcp characterization np logarithmic randomness verifier correct proof probability false statement optimal amortized query complexity arbitrarily small constant adaptive verifier query bits;theorem proving;formal verification;probabilistically checkable proofs;computational complexity;protocols system testing polynomials time factors equations computer science;correctness proof	For every integerk > 0, and an arbitrarily small constant ε > 0, we present a PCP characterization of NP where the verifier uses logarithmic randomness, non-adaptively queries 4k+ k2 bits in the proof, accepts a correct proof with probability 1, i. e., it has perfect completeness, and accepts any supposed proof of a false statement with probability at most 2−k 2 + ε. In particular, the verifier achieves optimal mortized query complexity of 1+ δ for arbitrarily small constant δ > 0. Such a characterization was already proved by Samorodnitsky and Trevisan (STOC 2000), but their verifier loses perfect completeness and their proof makes an essential use of this feature. By using an adaptive verifier, we can decrease the number of query bits to 2 k+ k2, equal to the number obtained by Samorodnitsky and Trevisan. Finally we extend some of the results to PCPs over non-Boolean alphabets. ∗Work done while visiting the Institute for Advanced Study, supported by NSF grant CCR-9987077. †Work done while the author was at Princeton University. ACM Classification: F 2.2 AMS Classification: 68Q25	acm computing classification system;decision tree model;graph coloring;hardness of approximation;ibm notes;mathematical optimization;np-completeness;np-hardness;pcp theorem;randomness;symposium on theory of computing	Johan Håstad;Subhash Khot	2001	Theory of Computing	10.1109/SFCS.2001.959937	probabilistically checkable proof;interactive proof system;formal verification;computer science;theoretical computer science;probability;automated theorem proving;programming language;computational complexity theory;algorithm	Theory	9.571178788294622	21.578457560713716	8530
979ef97ff504c6aa904786362fb18c6024fafe3e	function-algebraic characterizations of log and polylog parallel time	subrecursion;turing machine;circuit complexity;complexity class	The main results of this paper are recursion-theoretic characterizations of two parallel complexity classes: the functions computable by uniform bounded fan-in circuit families of log and polylog depth (or equivalently, the functions bitwise computable by alternating Turing machines in log and polylog time). The present characterizations avoid the complex base functions, function constructors, anda priori size or depth bounds typical of previous work on these classes. This simplicity is achieved by extending the “tiered recursion” techniques of Leivant and Bellantoni & Cook.	alternating turing machine;bitwise operation;bloch sphere;category theory;complex-base system;complexity class;computable function;computation;fan-in;judy array;linear algebra;p (complexity);polynomial hierarchy;recursion;time complexity	Stephen A. Bloch	1994	computational complexity	10.1007/BF01202288	complexity class;circuit complexity;combinatorics;discrete mathematics;computer science;turing machine;mathematics;computable function;algorithm	Theory	6.6324158507909825	20.966224750350662	8540
88f877981112c8a9350b0bc20bc50fcf4b1a1677	accurate summation, dot product and polynomial evaluation in complex floating point arithmetic	accurate dot product;error free transformations;complex floating point arithmetic;high precision;accurate polynomial evaluation;accurate summation;hornerʼs scheme;horner s scheme	Several different techniques and softwares intend to improve the accuracy of results computed in a fixed finite precision. Here we focus on methods to improve the accuracy of summation, dot product and polynomial evaluation. Such algorithms exist real floating point numbers. In this paper, we provide new algorithms which deal with complex floating point numbers. We show that the computed results are as accurate as if computed in twice the working precision. The algorithms are simple since they only require addition, subtraction and multiplication of floating point numbers in the same working precision as the given data.	algorithm;emoticon;error analysis (mathematics);horner's method;polynomial	Stef Graillat;Valérie Ménissier-Morain	2012	Inf. Comput.	10.1016/j.ic.2011.09.003	arithmetic;kahan summation algorithm;minifloat;discrete mathematics;floating point;theoretical computer science;pairwise summation;mathematics;extended precision	Theory	46.791318149895645	40.203487289704434	8543
0377763c7d0fd146d60ef7ba87e72a202ea6e378	automatic forcing and genericity: on the diagonalization strength of finite automata	computability theory;algorithmique;mathematiques discretes;complexite calcul;matematicas discretas;automata estado finito;context free language;computability;discrete mathematics;chaine caractere;regular language;lenguaje racional;lenguaje cf;complejidad computacion;algorithmics;algoritmica;computational complexity;informatique theorique;contexto;calculabilite;cadena caracter;finite automata;baire category;langage rationnel;contexte;finite automaton;categorie baire;automate fini;context;langage cf;calculabilidad;character string;computer theory;langage regulier;informatica teorica	Algorithmic and resource-bounded Baire category and corresponding genericity concepts introduced in computability theory and computational complexity theory, respectively, have become elegant and powerful tools in these settings. Here we introduce some new genericity notions based on extension functions computable by finite automata which are tailored for capturing diagonalizations over regular sets and functions. We show that the generic sets obtained either by the partial regular extension functions of any fixed constant length or by all total regular extension of constant length are just the sets with saturated (also called disjunctive) characteristic sequence α. Here a sequence α is saturated if every string occurs in α as a substring. We also show that these automatic generic sets are not regular but may be context free. Furthermore, we introduce stronger automatic genericity notions based on regular extension functions of nonconstant length and we show that the corresponding generic sets are bi-immune for the class of regular and context free languages.	automaton;finite-state machine;generic programming	Klaus Ambos-Spies;Edgar Busse	2003		10.1007/3-540-45066-1_7	combinatorics;discrete mathematics;computability theory;regular language;string;mathematics;context-free language;computability;finite-state machine;computational complexity theory;algorithm;algebra	Theory	-1.5700853580038248	20.07068293369513	8555
32583dc57dd48e83966356d70fd916f2a4a544f0	completeness in differential approximation classes	approximate algorithm;optimization problem;polynomial time	HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Completeness in differential approximation classes Giorgio Ausiello, Cristina Bazgan, Marc Demange, Vangelis Paschos	approximation;archive;comefrom;hal;linear algebra	Giorgio Ausiello;Cristina Bazgan;Marc Demange;Vangelis Th. Paschos	2003		10.1007/978-3-540-45138-9_12	time complexity;optimization problem;mathematical optimization;combinatorics;discrete mathematics;computer science;mathematics;matrix polynomial;algorithm	ML	26.42751392714299	37.75105680633305	8593
b14157591f9e0cce67574c3d964ae3d54621a824	stability preserving transformations of graphs	qa mathematics;graph transformation;stability number	Graph transformations proved useful for many algorithmic problems. In the present paper, we study this tool with respect to the maximum stable set problem. We first review available results on this topic and then propose an approach to uniformly describe and systematically develop graph transformations that do not change the size of a maximum stable set in the graph. The approach is illustrated by a number of new transformations.	algorithm;decision problem;graph rewriting;graph theory;mathematical optimization;measure-preserving dynamical system;time complexity	Vadim V. Lozin	2011	Annals OR	10.1007/s10479-008-0395-1	lattice graph;factor-critical graph;combinatorics;discrete mathematics;directed graph;null graph;graph property;computer science;clique-width;forbidden graph characterization;comparability graph;mathematics;voltage graph;distance-hereditary graph;graph;critical graph;complement graph;strength of a graph;graph rewriting	ML	23.976874418765046	26.140412276523005	8596
92236dfc6e86b985d5102f1c99aea976e8ae141b	the euclidean algorithm for generalized minimum distance decoding of reed-solomon codes	reed solomon codes euclidean algorithm generalized minimum distance decoding;generalized minimum distance decoding;complexity theory;iterative decoding;decoding;polynomials decoding complexity theory iterative decoding reed solomon codes mathematical model;reed solomon codes;polynomials;minimum distance;mathematical model;euclidean algorithm;reed solomon code;information theory	This paper presents a method to merge Generalized Minimum Distance decoding of Reed-Solomon codes with the extended Euclidean algorithm. By merge, we mean that the steps performed in Generalized Minimum Distance decoding are similar to those of the extended Euclidean algorithm. The resulting algorithm has a complexity of O(n2).	berlekamp–massey algorithm;extended euclidean algorithm;folded reed–solomon code;generalized minimum-distance decoding	Sabine Kampf;Martin Bossert	2010	2010 IEEE Information Theory Workshop	10.1109/CIG.2010.5592677	euclidean algorithm;list decoding;concatenated error correction code;combinatorics;discrete mathematics;sequential decoding;information theory;mathematical model;mathematics;berlekamp–welch algorithm;reed–solomon error correction;statistics;polynomial;algebra	Theory	41.68000308045732	57.35612557869223	8619
3a89296ce31b0d3078ff8078f67e5cac508bcf27	monochromatic permutation quadruples - a schur thing in sn		Schur proved that for any finite partition of the naturals, some cell contains two numbers and their sum. We use Ramsey’s theorem to prove a noncommutative Schur theorem for permutation quadruples {x, y, xy, yx}. By Schur’s theorem [2], for any r ∈ N, there exists n ∈ N such that for any r-coloring of {1, 2, . . . , n}, one has a monochromatic “Schur triple.” That is, a 3-element set of the form {x, y, x + y}. The simplest proof is via Ramsey’s theorem [3], which states that for every k, n, r ∈ N, if the k-member subsets of a sufficiently large set B are colored in r colors there is an n-member set A ⊂ B whose k-member subsets form a monochromatic family. Indeed, from {1, 2, . . . , n} = ⋃r i=1 Ci one may induce an r-coloring of the 2-subsets of {1, 2, . . . , n} by the rule {i, j} ∈ Dt, i < j, if (j − i) ∈ Ct. For large enough n one may choose by Ramsey’s theorem a set {a, b, c}, a < b < c, with { {a, b}, {b, c}, {a, c} } monochromatic for the induced coloring, so that {b− a, c− b, c− a} is monochromatic for the original coloring. Let now x = b−a and y = c− b. Then x+ y = c−a, so we are done. In a general group G, if xy 6= yx then the 4-member set {x, y, xy, yx} forms what might be called a “Schur quadruple.” There can be no partition theorem for Schur quadruples true of abelian groups, which contain none, while for free groups the matter remains open. It is therefore natural to ask if there are groups for which a version of Schur’s theorem for quadruples holds. The answer is yes; Ramsey’s theorem provides a familiar proof. Theorem. Let r ∈ N. There exists n = n(r) such that for any r-coloring of the symmetric group Sn, there is a monochromatic Schur quadruple. Proof. Choose by Ramsey’s theorem an n such that for any r-coloring of the 3-element subsets of {1, 2, . . . , n}, there is a 4-element set whose 3-element subsets comprise a monochromatic family. Now suppose we are given an r-coloring Sn = ⋃r i=1 Ci. Put {i, j, k} ∈ Dm if and only if (ijk) ∈ Cm, where i < j < k. By choice of n, there is a 4element set {a, b, c, d}, with a < b < c < d, all of whose 3-elements subsets lie in the same cell Dy. This gives {(abc), (acd), (abd), (bcd)} ⊂ Cy. Observe now that (abc)(acd) = (abd) and (acd)(abc) = (bcd). It was recently shown that such a Schur theorem for quadruples holds for a broad class of sufficiently noncommutative amenable groups (see [1]).	binary-coded decimal;color;cylinder-head-sector;graph coloring;monochrome;nibble;pseudorandom permutation;quadruple-precision floating-point format	R. McCutcheon	2012	The American Mathematical Monthly	10.4169/amer.math.monthly.119.04.342	arithmetic;schur's lemma	Theory	36.31890265877738	32.51373565191459	8626
d7bd634175228941d96a08c53cced9fd3aa0a299	vertex contact graphs of paths on a grid		Contact and intersection representations of graphs and particularly of planar graphs have been studied for decades. The by now best known result in the area may be the Koebe-Andreev-Thurston circle packing theorem. A more recent highlight in the area is a result of Chalopin and Gonçalves: every planar graph is an intersection graph of segments in the plane. This boosted the study of intersection and contact graphs of restricted classes of curves. In this paper we study planar graphs that are VCPG, i.e. graphs admitting a representation as Vertex Contact graph of Paths on a Grid. In such a representation the vertices of G are represented by a family of interiorly disjoint grid-paths. Adjacencies are represented by contacts between an endpoint of one grid-path and an interior point of another grid-path. Defining u→ v if the path of u ends on path of v we obtain an orientation on G from a VCPG representation. To get hand on the bends of the grid path the 2-orientation is not enough. We therefore consider pairs (α,ψ): a 2-orientation α and a flow ψ in the angle graph. The 2-orientation describes the contacts of the ends of a grid-path and the flow describes the behavior of a grid-path between its two ends. We give a necessary and sufficient condition for such a pair (α,ψ) to be realizable as a VCPG. Using realizable pairs we show that every planar (2,2)-tight graph can be represented with at most 2 bends per path and that this is tight (i.e. there exist (2,2)-tight graphs that cannot be represented with at most one bend per path). Using the same methodology it is easy to show that loopless planar (2,1)-sparse graphs have a 4-bend representation and loopless planar (2,0)-sparse graphs have 6-bend representation. We do not believe that the latter two are tight, we conjecture that loopless planar (2,0)-sparse graphs have a 3-bend representation.	circle packing theorem;communication endpoint;contact graph;emoticon;execution unit;existential quantification;loopless algorithm;planar (computer graphics);planar graph;set packing	Nieke Aerts;Stefan Felsner	2014		10.1007/978-3-319-12340-0_5	vertex separator;vertex angle;vertex;maximal independent set;chordal graph;indifference graph;neighbourhood	Robotics	30.84256535485824	24.199849693806552	8638
a89f06bee0012e9406dfb0c4ced4bdc77ab3f567	wire-sizing for interconnect performance optimization considering high inductance effects	transfer functions;routing;very large scale integration;interconnect performance optimization;design flow;delay effects;wire;optimization problem;approximation theory;integrated circuit design;high inductance effects;wire sizing;interconnect centric design flow;rlc circuits;equivalent elmore delay metric;integrated circuit interconnections;optimization inductance integrated circuit interconnections wire delay effects rlc circuits capacitance transfer functions routing very large scale integration;two pole approximation model wire sizing interconnect performance optimization high inductance effects wire width planning interconnect centric design flow equivalent elmore delay metric;wire width planning;vlsi;inductance;optimization;capacitance;performance optimization;vlsi approximation theory integrated circuit design;two pole approximation model	In this paper, we study wire width planning for interconnect performance optimization in an interconnect-centric design flow. We first present an equivalent Elmore delay metric for distributed parameter interconnect lines considering high inductance effects based on the two-pole approximation model, and then propose a simplified near-optimal uniform wire-sizing scheme. Based on the closed form delay metric, a delay-area tradeoff is proposed to interconnect optimizations, and the delay metric can be applied to other optimization problems in a similar way. Experimental results show that the method we proposed is of great accuracy and efficiency, and will be very useful for better design convergence and simpler routing architectures.	approximation;elmore delay;mathematical optimization;routing	Xiaopeng Ji;Long Ge;Xiaodong Han;Zhiquan Wang	2008	2008 IEEE International Conference on Networking, Sensing and Control	10.1109/ICNSC.2008.4525383	mathematical optimization;electronic engineering;computer science;engineering;electrical engineering;elmore delay;very-large-scale integration	EDA	16.553023310213256	53.569233471860485	8651
5e8a47fe315bad63dc58ee163162f3607a9a6068	efficient algorithms for clique problems	graph node;complexite;68t20;procesamiento informacion;np completude;subgrafo;nudo grafo;algorithm analysis;combinatorial algorithm;implementation;approximation algorithm;aproximacion;complejidad;resolution math;graph clique;algorithme combinatoire;combinatorial problems;complexity;space time;espacio tiempo;68wxx;approximation;resolucion problema;multiplication matrice;combinatorial problem;probleme combinatoire;problema combinatorio;sous graphe;informatique theorique;68r10;information processing;edge graph;algoritmo aproximacion;graph algorithm;resolucion matematica;arete graphe;algorithms;completitud;analyse algorithme;completeness;clique graphe;subgraph;algorithme graphe;algorithme approximation;implementacion;traitement information;completude;graph algorithms;68w25;solving;clique;analisis algoritmo;espace temps;noeud graphe;arista grafico;problem solving;resolution probleme;computer theory;informatica teorica	The k-clique problem is a cornerstone of NP-completeness and parameterized complexity. When k is a fixed constant, the asymptotically fastest known algorithm for finding a k-clique in an n-node graph runs in O(n) time (given by Nešetřil and Poljak). However, this algorithm is infamously inapplicable, as it relies on Coppersmith and Winograd’s fast matrix multiplication. We present good combinatorial algorithms for solving k-clique problems. These algorithms do not require large constants in their runtime, they can be readily implemented in any reasonable random access model, and are very spaceefficient compared to their algebraic counterparts. Our results are the following: • We give an algorithm for k-clique that runs in O(n/(ε log n)k−1) time and O(n) space, for all ε > 0, on graphs with n nodes. This is the first algorithm to take o(n) time and O(n) space for c independent of k. • Let k be even. Define a k-semiclique to be a k-node graph G that can be divided into two disjoint subgraphs U = {u1, . . . , uk/2} and V = {v1, . . . , vk/2} such that U and V are cliques, and for all i ≤ j, the graph G contains the edge {ui, vj}. We give an Õ(k2n) time algorithm for determining if a graph has a k-semiclique. This yields an approximation algorithm for k-clique, in the following sense: if a given graph contains a k-clique, then our algorithm returns a subgraph with at least 3/4 of the edges in a k-clique.	2.5d;approximation algorithm;clique (graph theory);clique problem;coppersmith–winograd algorithm;fastest;linear algebra;matrix multiplication;np-completeness;parameterized complexity;random access	Virginia Vassilevska Williams	2009	Inf. Process. Lett.	10.1016/j.ipl.2008.10.014	clique;combinatorics;information processing;computer science;mathematics;approximation algorithm;algorithm	Theory	19.380051380182177	27.660333847177206	8653
c3648d5986e8362ea858748e240ce37eb54d5760	hierarchical reconfiguration of fpgas	libraries;memory management;partial reconfiguration;clocks;routing;hierarchical reconfiguration hierarchically reconfigurable custom instruction set reconfigurable softcore cpu additive behavior multiplicative behavior bitstream storage requirement complex system reconfigurable submodule field programmable gate array partial reconfiguration fpga;wires;fpga reconfiguration;field programmable gate arrays;reconfigurable architectures field programmable gate arrays large scale systems modules;routing field programmable gate arrays wires libraries timing memory management clocks;timing	Partial reconfiguration allows some applications to substantially save FPGA area by time sharing resources among multiple modules. In this paper, we push this approach further by introducing hierarchical reconfiguration where reconfigurable modules can have reconfigurable submodules. This is useful for complex systems where many modules have common parts or where modules can share components. For such systems, we show that the number of bitstreams and the bitstream storage requirements can be scaled down from a multiplicative to an additive behavior with respect to the number of modules and submodules. A case study consisting of different reconfigurable softcore CPUs and hierarchically reconfigurable custom instruction set extensions demonstrates a 18.7× lower bitstream storage requirement and up to 10× faster reconfiguration speed when using hierarchical reconfiguration instead of using conventional single-level module-based reconfiguration.	bitstream;central processing unit;complex systems;field-programmable gate array;graphics processing unit;multi-level cell;opencl api;requirement;symmetric multiprocessing;time-sharing;utility functions on indivisible goods	Dirk Koch;Christian Beckhoff	2014	2014 24th International Conference on Field Programmable Logic and Applications (FPL)	10.1109/FPL.2014.6927491	embedded system;routing;parallel computing;real-time computing;computer science;field-programmable gate array;memory management	EDA	1.2717861496371055	49.04101711573474	8667
1d95e6bef0bc76e1992ee05abebe4195bb1db31d	flow lines with regular service times: evolution of delay, state dependent failures and semiconductor wafer fabrication	bridges usa councils automation conferences;resettable monotone channels;flow lines;semiconductor device reliability assembling monolithic integrated circuits semiconductor device manufacture;monolithic integrated circuits;semiconductor device reliability;semiconductor wafer manufacturing tools flow lines regular service semiconductor wafer fabrication state dependent failures deterministic service times resettable monotone channels;bridges;usa councils;state dependence;deterministic service times;semiconductor wafer fabrication;tandem queue;state dependent failures;semiconductor wafer manufacturing tools;assembling;semiconductor device manufacture;regular service;conferences;automation	For the class of flow lines (alternately referred to as tandem queues or assembly lines) possessing deterministic service times, this paper elucidates the evolution of customers within the line. It is shown that a natural decomposition of the servers exists that allows one to express the delay each customer faces without individually assessing the behavior at each server. The decomposition is characterized by successive bottlenecks and leads to a series of resettable monotone channels (RMCs). The delay evolution enables us to characterize state dependent restrictions on when customers may enter service with the flow line. The model is directly applicable to an important class of semiconductor wafer manufacturing tools (serial processing cluster tools). These tools may experience a setup when changing from one recipe to another, and in this case, generally delay the admission of a product lot into the tool until the preceding lot has vacated an initial portion of the cluster and a setup has been conducted.	bottleneck (software);evolution;server (computing);wafer (electronics);wafer fabrication;monotone	James R. Morrison	2008	2008 IEEE International Conference on Automation Science and Engineering	10.1109/COASE.2008.4626466	electronic engineering;engineering;electrical engineering;operations management	Robotics	9.482257832600483	6.164671365578894	8673
d715bc2c0cb0e2e7a32354eaba2d63a9205a52db	dispersing obnoxious facilities on a graph		We study a continuous facility location problem on a graph where all edges have unit length and where the facilities may also be positioned in the interior of the edges. The goal is to position as many facilities as possible subject to the condition that any two facilities have at least distance δ from each other. We investigate the complexity of this problem in terms of the rational parameter δ. The problem is polynomially solvable, if the numerator of δ is 1 or 2, while all other cases turn out to be NP-hard. 2012 ACM Subject Classification Mathematics of computing → Graph theory, Theory of computation → Graph algorithms analysis, Theory of computation → Discrete optimization	algorithm;decision problem;discrete optimization;facility location problem;graph (discrete mathematics);graph theory;mathematical optimization;theory of computation	Alexander Grigoriev;Tim A. Hartmann;Stefan Lendl;Gerhard J. Woeginger	2018	CoRR		discrete mathematics;fraction (mathematics);combinatorics;computer science;facility location problem;graph	Theory	25.46806889645425	19.811478460405198	8693
19c12b03c0be5d5afdbb663975909fd171cacd41	sums of products of binomial coefficients			coefficient	Mourad E. H. Ismail	2011	Ars Comb.		statistics;combinatorics;mathematics;binomial approximation;binomial coefficient;central binomial coefficient;gaussian binomial coefficient	Theory	45.20229528132467	33.43757536378704	8695
59b9c6bca5bd3081eccbb868ecb98acd9bcaad66	voltage-based concatenatable full adder using spin hall effect switching	spin transfer torque stt full adder magnetic tunnel junction mtj spin hall effect she;magnetic tunneling switches mathematical model adders integrated circuit modeling switching circuits mosfet	"""Magnetic tunnel junction (MTJ)-based devices have been studied extensively as a promising candidate to implement hybrid energy-efficient computing circuits due to their nonvolatility, high integration density, and CMOS compatibility. In this paper, MTJs are leveraged to develop a novel full adder (FA) based on 3- and 5-input majority gates. Spin Hall effect (SHE) is utilized for changing the MTJ states resulting in low-energy switching behavior. SHE-MTJ devices are modeled in Verilog-A using precise physical equations. SPICE circuit simulator is used to validate the functionality of 1-bit SHE-based FA. The simulation results show 76% and 32% improvement over previous voltage-mode MTJ-based FA in terms of energy consumption and device count, respectively. The concatanatability of our proposed 1-bit SHE-FA is investigated through developing a 4-bit SHE-FA. Finally, delay and power consumption of an <inline-formula> <tex-math notation=""""LaTeX"""">${ {n}}$ </tex-math></inline-formula>-bit SHE-based adder has been formulated to provide a basis for developing an energy efficient SHE-based <inline-formula> <tex-math notation=""""LaTeX"""">${n}$ </tex-math></inline-formula>-bit arithmetic logic unit."""	1-bit architecture;4-bit;adder (electronics);arithmetic logic unit;cmos;electronic circuit simulation;spice 2;spin hall effect;verilog;verilog-a	Arman Roohi;Ramtin Zand;Deliang Fan;Ronald F. DeMara	2017	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2017.2661800	electronic engineering;computer science;mosfet;electronic circuit;arithmetic logic unit;tunnel magnetoresistance;electronic circuit simulation;adder;spin hall effect;cmos	EDA	16.08373786047398	58.67607357592729	8710
0a765c12400b60e6a231aeb4039ac499e44f35d7	method of controlling reverse power flow of pv system with heat pump water heater	power generation planning battery storage plants electric heating heat pumps load flow control load forecasting photovoltaic power systems power generation control;power generation control;power generation planning;hot water demand forecasting reverse power flow control pv system heat pump water heater optimal management planning method photovoltaic generation system battery storage pv output forecasting electricity demand forecasting;load forecasting;genetic algorithm smart grid distributed generation photovoltaic generation heat pump water heater;heat pumps;battery storage plants;load flow control;heat pumps water heating electricity lead;photovoltaic power systems;electric heating	We have developed an optimal management planning method for the efficient use of a photovoltaic generation system with heat pump water heater and battery storage. This plan can prevent shortage of hot water while minimizing the cost and maximizing customer convenience and can deal with multiple scenarios corresponding to uncertainties in forecasting PV output, hot water and electricity demand. A simulation was performed to analyze daily operation with the proposed planning method in terms of year-round hot water demand, electricity demand, and PV output. An experiment was also conducted using the heat pump water heater to demonstrate the proposed method.	experiment;page view;simulation	Masahiro Asari;Hiromu Kobayashi	2012	2012 3rd IEEE PES Innovative Smart Grid Technologies Europe (ISGT Europe)	10.1109/ISGTEurope.2012.6465793	storage heater;control engineering;electronic engineering;storage water heater;engineering;operations management;stand-alone power system;grid-connected photovoltaic power system	AI	4.393313926199031	5.322257788602832	8718
9cf4c09adc7e4d72b083e2a5dc118a2ba39c7cb6	mole: a sea-of-gates detailed router	novel feature;new detailed router;interior terminal;sea-of-gates detailed router;rectilinear region;yields excellent result;sea-of-gates layout project;physical design;mole;routing;templates;art;chip scale packaging	In this paper we present a new detailed router which was developed as part of a sea-of-gates layout project. It routes nets on two or more layers in a given rectangular or rectilinear region which may contain blockages and interior terminals in addition to terminals on the boundary. It uses a set of templates to perform routing and incorporates several novel features that address sea-of-gates routing issues. The router is very fast, memory efficient and yields excellent results.	regular grid;router (computing);routing	Arvind Srinivasan;Ernest S. Kuh	1990				EDA	14.408224448861592	52.05675521206061	8736
db638efd83a9a92942f4babe36bbf75885135dab	characterizing data analytics workloads on intel xeon phi	data analysis benchmark testing computer architecture google principal component analysis scalability instruction sets;high dimensional matrices data analytics workloads intel xeon phi heterogeneous architectures high parallelism many core coprocessor high performance computing simd instruction multithreading complex memory hierarchy 24 core xeon e5 2620 machine big data bench phi;xeon phi;characterization;data analytics;characterization xeon phi data analytics;software architecture big data data analysis matrix algebra multiprocessing programs multi threading parallel processing	With the growing computation demands of data analytics, heterogeneous architectures become popular for their support of high parallelism. Intel Xeon Phi, a many-core coprocessor originally designed for high performance computing applications, is promising for data analytics workloads. However, to the best of knowledge, there is no prior work systematically characterizing the performance of data analytics workloads on Xeon Phi. It is difficult to design a benchmark suite to represent the behavior of data analytics workloads on Xeon Phi. The main challenge resides in fully exploiting Xeon Phi's features, such as long SIMD instruction, simultaneous multithreading, and complex memory hierarchy. To address this issue, we develop Big Data Bench-Phi, which consists of seven representative data analytics workloads. All of these benchmarks are optimized for Xeon Phi and able to characterize Xeon Phi's support for data analytics workloads. Compared with a 24-core Xeon E5-2620 machine, Big Data Bench-Phi achieves reasonable speedups for most of its benchmarks, ranging from 1.5 to 23.4X. Our experiments show that workloads working on high-dimensional matrices can significantly benefit from instruction- and thread-level parallelism on Xeon Phi.	benchmark (computing);big data;computation;coprocessor;experiment;manycore processor;memory hierarchy;multithreading (computer architecture);parallel computing;simultaneous multithreading;supercomputer;task parallelism;xeon phi	Biwei Xie;Xu Liu;Jianfeng Zhan;Zhen Jia;Yuqing Zhu;Lei Wang;Lixin Zhang	2015	2015 IEEE International Symposium on Workload Characterization	10.1109/IISWC.2015.20	computer architecture;parallel computing;computer science;operating system;xeon phi;hyper-threading;data analysis	HPC	-4.404232070556339	44.696674051101944	8755
131a08a7b929de1554947ca01bddaa76a20ccde6	computing tree-depth faster than $$2^{n}$$ 2 n	2 n 2n barrier;tree depth;exact algorithms	A connected graph has tree-depth at most $$k$$ k if it is a subgraph of the closure of a rooted tree whose height is at most $$k$$ k . We give an algorithm which for a given $$n$$ n -vertex graph $$G$$ G , in time $${\mathcal {O}^*}(1.9602^n)$$ O ∗ ( 1 . 9602 n ) computes the tree-depth of $$G$$ G . Our algorithm is based on combinatorial results revealing the structure of minimal rooted trees whose closures contain $$G$$ G .	computation;connectivity (graph theory);decision problem;directed graph;dynamic programming;exact algorithm;feedback arc set;hamiltonian path;pathwidth;time complexity;tree-depth;treewidth;vertex cover	Fedor V. Fomin;Archontia C. Giannopoulou;Michal Pilipczuk	2013	Algorithmica	10.1007/s00453-014-9914-4	mathematical optimization;combinatorics;discrete mathematics;mathematics;tree-depth	Theory	23.556057864473672	24.84996188192021	8763
c3dddf675f7775e142605752668eb3ea3cee9631	statistical independence and contingency matrix	probability;statistical independence;matrix theory;pearson residuals contingency table matrix theory statistical independence;matrix algebra;data mining;pearson residuals;manganese;statistical distributions matrix algebra series mathematics;statistical distributions;marginal distribution statistical independence contingency matrix pearson residual information granules linear equation;contingency matrix;matrices;marginal distribution;series mathematics;information granules;matrices bismuth data mining probability conferences biomedical informatics equations statistical distributions;mathematical model;odd ratio;contingency table;linear equations;linear equation;pearson residual;conferences	This paper shows the meaning of Pearson residuals as an indicator of statistical independence. While information granules of statistical independence of two variables can be viewed as determinants of 2times2-submatrices, those of three variables consist of several combinations of linear equations which will become residuals for odds ratio (outer products) when they are equal to 0. Interestingly, the residuals can be an expansion series of the product of marginal distributions and the residuals for odds ratio (outer products).	data cube;linear algebra;linear equation;marginal model	Shusaku Tsumoto;Shoji Hirano	2008	2008 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2008.94	econometrics;combinatorics;mathematics;linear equation;matrix;statistics	DB	47.93759665780484	17.818808294047766	8772
1463cf34dc1498d255283a031cdafa1561d05e39	machine cycle cpu simulator for educational use based on squeak environment	programming environments;central processing unit circuit simulation registers hardware clocks knowledge engineering computer languages programming environments software performance educational institutions;object oriented programming;educational aids;smalltalk;object oriented programming smalltalk digital simulation programming environments educational aids educational computing;cpu circuit machine cycle cpu simulator educational use squeak environment hardware behavior system clock simulator component morphic object execution behavior central processing unit high level programming language high level programming environment;educational computing;digital simulation	A machine cycle CPU simulator is developed on the Squeak environment for educational use. The developed simulator is able to show hardware behavior in CPU at each system clock. Any component of the simulator is implemented as a Morphic object in Squeak. The developed simulator is examined by execution of example programs and correct behaviors of their executions are confirmed.	central processing unit;instruction cycle;morphic word;squeak	Takao Kawamura;Yoshio Kawaguchi;Shinji Nakanishi;Kazunori Sugahara;Gen Suzuki	2003	First Conference on Creating, Connecting and Collaborating Through Computing, 2003. C5 2003. Proceedings.	10.1109/C5.2003.1222344	embedded system;computer architecture;real-time computing;computer architecture simulator;computer science;operating system;programming language;object-oriented programming	HPC	6.258823550517236	52.53183351428121	8786
11e794daf6cdab8a1a575d78f3d408c6526f8b9a	from query complexity to computational complexity	list decoding;submodular function;optimization problem;query complexity;computational complexity;inapproximability;submodular functions;combinatorial auction	We consider submodular optimization problems, and provide a general way of translating oracle inapproximability results arising from the symmetry gap technique to computational complexity inapproximability results, where the submodular function is given explicitly (under the assumption that NP ≠ RP). Applications of our technique include an optimal computational hardness of (1/2 + ε)-approximation for maximizing a symmetric nonnegative submodular function, an optimal hardness of (1-(1-1/k)k + ε)-approximation for welfare maximization in combinatorial auctions with k submodular bidders (for constant k), super-constant hardness for maximizing a nonnegative submodular function over matroid bases, and tighter bounds for maximizing a monotone submodular function subject to a cardinality constraint. Unlike the vast majority of computational inapproximability results, our approach does not use the PCP machinery or the Unique Games Conjecture, but relies instead on a direct reduction from Unique-SAT using list-decodable codes.	cardinality (data modeling);code;computation;computational complexity theory;decision tree model;expectation–maximization algorithm;hardness of approximation;mathematical optimization;matroid;rp (complexity);submodular set function;unique games conjecture;monotone	Shahar Dobzinski;Jan Vondrák	2012		10.1145/2213977.2214076	list decoding;optimization problem;mathematical optimization;combinatorics;discrete mathematics;combinatorial auction;submodular set function;mathematics;computational complexity theory	Theory	21.97277481437729	15.67584581439321	8800
1f3efdc20d29c8769750296dc5ddb26a94f08e96	energy-quality scaling in analog mesh computers		The recent push for post-Moore computer architectures has introduced a wide variety of application-specific accelerators. One particular accelerator, the resistance network analog, has been well received due to its ability to efficiently solve partial differential equations, while eliminating the iterative stages required by today’s numerical solvers. However, in the age of programmable integrated circuits, the static nature of the resistance network analog, and other analog mesh computers like it, has relegated it to an academic curiosity. Recent developments in materials, such as the memristor, have made the resistance network analogue viable for inclusion in future heterogeneous computer architectures. However, selection of an appropriate sized mesh to be incorporated into a computer system requires that energy-quality trade-offs are made regarding the problem size and required resolution of the solution. This paper provides an in-depth study of the scaling of analog mesh computer hardware, from the perspective of energy per bit and required resolution, introduces a metric to aid in quantifying analog mesh computers with different parameters, and introduces a method of virtualization which enables an analog mesh computer of a fixed size to approximate the calculations of a larger-sized mesh.	analysis of algorithms;approximation algorithm;computer architecture;computer hardware;error-tolerant design;heterogeneous system architecture;image scaling;integrated circuit;iterative method;mainframe computer;memristor;mesh networking;numerical analysis;programmable logic device;relational operator;resolution (logic);scalability;supercomputer;usability;very-large-scale integration	Jeff Anderson;Engin Kayraklioglu;Vikram K. Narayana;Volker J. Sorger;Tarek A. El-Ghazawi	2018	CoRR		energy quality;scaling;memristor;theoretical computer science;virtualization;partial differential equation;integrated circuit;computer science	Arch	11.202319583028485	56.54735694650794	8804
91c32a42effb5b58a60638b2c458e5bfb9acd997	phase retrieval via reweighted amplitude flow		"""This paper deals with finding an <inline-formula><tex-math notation=""""LaTeX"""">$n$</tex-math></inline-formula> -dimensional solution <inline-formula><tex-math notation=""""LaTeX"""">$\boldsymbol {x}$</tex-math></inline-formula> to a system of quadratic equations of the form <inline-formula><tex-math notation=""""LaTeX"""">$y_i=|\langle \boldsymbol {a}_i,\boldsymbol {x}\rangle |^2$</tex-math></inline-formula> for <inline-formula><tex-math notation=""""LaTeX"""">$1\leq i \leq m$</tex-math></inline-formula>, which is also known as the generalized phase retrieval problem. For this NP-hard problem, a novel approach is developed for minimizing the amplitude-based least-squares empirical loss, which starts with a weighted maximal correlation initialization obtainable through a few power or Lanczos iterations, followed by successive refinements based on a sequence of iteratively reweighted gradient iterations. The two stages (initialization and gradient flow) distinguish themselves from prior contributions by the inclusion of a fresh (re)weighting regularization procedure. For certain random measurement models, the novel scheme is shown to be able to recover the true solution <inline-formula><tex-math notation=""""LaTeX"""">$\boldsymbol {x}$</tex-math></inline-formula> in time proportional to reading the data <inline-formula><tex-math notation=""""LaTeX"""">$\lbrace (\boldsymbol {a}_i;y_i)\rbrace _{1\leq i \leq m}$</tex-math></inline-formula>. This holds with high probability and without extra assumption on the signal vector <inline-formula><tex-math notation=""""LaTeX"""">$\boldsymbol {x}$</tex-math> </inline-formula> to be recovered, provided that the number <inline-formula><tex-math notation=""""LaTeX"""">$m$</tex-math> </inline-formula> of equations is some constant <inline-formula><tex-math notation=""""LaTeX"""">$c>0$</tex-math> </inline-formula> times the number <inline-formula><tex-math notation=""""LaTeX"""">$n$</tex-math></inline-formula> of unknowns in the signal vector, namely <inline-formula><tex-math notation=""""LaTeX"""">$m>cn$</tex-math></inline-formula> . Empirically, the upshots of this contribution are: first, (almost) <inline-formula><tex-math notation=""""LaTeX""""> $\text{100}{\%}$</tex-math></inline-formula> perfect signal recovery in the high-dimensional (say <inline-formula> <tex-math notation=""""LaTeX"""">$n\geq 2000$</tex-math></inline-formula>) regime given only an information-theoretic limit number of noiseless equations, namely <inline-formula><tex-math notation=""""LaTeX"""">$m=2n-1$</tex-math></inline-formula>, in the real Gaussian case; and second, (nearly) optimal statistical accuracy in the presence of additive noise of bounded support. Finally, substantial numerical tests using both synthetic data and real images corroborate markedly improved recovery performance and computational efficiency of the novel scheme relative to the state-of-the-art approaches."""	additive white gaussian noise;computation;detection theory;gradient;information theory;iteration;least squares;manifold regularization;maximal set;np-hardness;numerical analysis;phase retrieval;quadratic equation;synthetic data;utility functions on indivisible goods;with high probability	Gang Wang;Georgios B. Giannakis;Yousef Saad;Jie Chen	2018	IEEE Transactions on Signal Processing	10.1109/TSP.2018.2818077	mathematical optimization;lanczos resampling;quadratic equation;amplitude;phase retrieval;bounded function;correlation;regularization (mathematics);mathematics;weighting	ML	48.90916552979154	9.06427209331758	8807
4cf26a18296858f4a85d51b72000fddd4d2c829c	on the implementation of a smoothed perturbation analysis estimator for a single-server queue with multiple vacations	queueing analysis stochastic systems discrete event systems production systems state estimation;limit distribution;probability;queueing systems;queueing theory;perturbation techniques;state estimation;multiple server vacations;probability law;single server queue;smoothed perturbation analysis;discrete event simulation perturbation techniques queueing theory probability;queueing system;discrete event systems;perturbation analysis;production systems;discrete event simulation smoothed perturbation analysis estimator single server queue multiple server vacations queueing systems probability law;smoothed perturbation analysis estimator;stochastic systems;queueing analysis;discrete event simulation	We consider to apply the perturbation analysis (PA) t a single-server queue with multiple server vacations. major difficulty in the implementation of PA estimator for such queueing systems is that the introduced perturbatio are propagated and accumulated continuously without a resetting. This fact may lead to the divergence of P estimates even if the limiting distribution exists. We show that it is possible to construct a sequence of points o the observed sample path such that the perturbations accumulated only between the two adjacent points. T key idea lies in constructing a perturbed path which is n on the same sample as the observed nominal path bu identical in probability law.	perturbation theory;server (computing);smoothing	Takayuki Tagaki;Naoto Miyoshi	1999		10.1145/324138.324274	mathematical optimization;real-time computing;computer science;discrete event simulation;perturbation theory;probability;mathematics;production system;queueing theory;statistics	Theory	7.538473782823924	10.625676310177663	8828
c048c98871a49cc774484f8c83ebe0bf667f6a85	numerical evaluation of multiple polylogarithms	field theory;feynman graph higher order;higher order;numerical methods;programming	Multiple polylogarithms appear in analytic calculations o f higher order corrections in quantum field theory. In this article we study the numerical evalu ation of multiple polylogarithms. We provide algorithms, which allow the evaluation for arbit rary complex arguments and without any restriction on the weight. We have implemented t hese algorithms with arbitrary precision arithmetic in C++ within the GiNaC framework.	algorithm;arbitrary-precision arithmetic;c++;computer algebra system;download;ginac;numerical analysis;quantum field theory	Jens Vollinga;Stefan Weinzierl	2005	Computer Physics Communications	10.1016/j.cpc.2004.12.009	programming;discrete mathematics;higher-order logic;numerical analysis;pure mathematics;mathematics;field theory;algebra	ML	48.468634394233035	35.40362506819116	8839
13c7a6b58833108a670f55fa95801aefa4d55ac4	equitable colorings of l-corona products of cubic graphs		A graph G is equitably k-colorable if its vertices can be partitioned into k independent sets in such a way that the number of vertices in any two sets differ by at most one. The smallest integer k for which such a coloring exists is known as the equitable chromatic number of G and it is denoted by χ=(G). In this paper the problem of determinig the value of equitable chromatic number for multicoronas of cubic graphs G ◦ H is studied. The problem of ordinary coloring of multicoronas of cubic graphs is solvable in polynomial time. The complexity of equitable coloring problem is an open question for these graphs. We provide some polynomially solvable cases of cubical multicoronas and give simple linear time algorithms for equitable coloring of such graphs which use at most χ=(G ◦ l H) + 1 colors in the remaining cases.	algorithm;color;cubic function;decision problem;equitable coloring;graph coloring;np-hardness;polynomial;time complexity;vertex (geometry);vertex (graph theory)	Hanna Furmanczyk;Marek Kubale	2013	CoRR		combinatorics;mathematics;equitable coloring;chordal graph;discrete mathematics;greedy coloring;fractional coloring;edge coloring;graph coloring;brooks' theorem;complete coloring	Theory	27.733568365558977	26.099402565824892	8840
e7a385f94f76cd87e97074276c2b486bdb43d0f1	on dual minimum cost flow algorithms	metodo caso peor;algorithme dual;duality;simplex algorithm;dual network simplex;key words minimum cost flow problem;optimisation combinatoire;cut cancelling;combinatorial problem;minimizacion costo;dualite;probleme combinatoire;flujo red;problema combinatorio;minimisation cout;cost minimization;transbordo;polynomial algorithm;methode cas pire;dual algorithms;algorithme polynomial;transbordement;dualidad;network flow;combinatorial optimization;worst case method;strongly polynomial algorithm;flot reseau;optimizacion combinatoria;transhipment	We describe a new dual algorithm for the minimum cost flow problem. It can be regarded as a variation of the best known strongly polynomial minimum cost flow algorithm, due to Orlin. Indeed we obtain the same running time of O(m log m(m+n log n)), where n and m denote the number of vertices and the number of edges. However, in contrast to Orlin's algorithm we work directly with the capacitated network (rather than transforming it to a transshipment problem). Thus our algorithm is applicable to more general problems (like submodular flow) and is likely to be more efficient in practice. Our algorithm can be interpreted as a cut cancelling algorithm, improving the best known strongly polynomial bound for this important class of algorithms by a factor of m. On the other hand, our algorithm can be considered as a variant of the dual network simplex algorithm. Although dual network simplex algorithms are reportedly quite efficient in practice, the best worst-case running time known so far exceeds the running time of our algorithm by a factor of n. Copyright Springer-Verlag Berlin Heidelberg 2002	algorithm;minimum-cost flow problem	Jens Vygen	2002	Math. Meth. of OR	10.1007/s001860200202	out-of-kilter algorithm;mathematical optimization;suurballe's algorithm;combinatorics;transshipment;flow network;duality;minimum-cost flow problem;push–relabel maximum flow algorithm;combinatorial optimization;mathematics;dinic's algorithm;simplex algorithm;algorithm;cost efficiency	Theory	22.279018683308657	13.272097955039795	8854
94b83bcc90b7f05a1b442e8f2a8de10ce2d219ba	construction of heuristics for a search-based approach to solving sudoku	search space;constraint satisfaction;latin square;hill climbing	Sudoku is a logic puzzle, consisting of a 9×9 grid and further subdivided into ‘mini-grids’ of size 3×3. Each row, column,  and 3×3 mini-grid contains the numbers 1 to 9 once, with a true Sudoku grid having a unique solution. Sudoku, along with similar  combinatorial structures, has relationships with a range of real-world problems. Much published work on the solution of Sudoku  puzzles has acknowledged the link between Sudoku and Latin Squares, thereby recognising the scale of any search space of possible  solutions and that the generalization of the puzzle to larger grid sizes is NPcomplete. However, most published approaches  to the solution of Sudoku puzzles have focussed on the use of constraint satisfaction algorithms that effectively mimic solution  by hand, rather than directly exploiting features of the problem domain to reduce the size of the search space and constructing  appropriate heuristics for the application of search techniques. This paper highlights important features of the search space  to arrive at heuristics employed in a modified steepest ascent hill-climbing algorithm, and proposes a problem initialization  and neighbourhood that greatly speed solution through a reduction of problem search space. Results shown demonstrate that  this approach is sufficient to solve even the most complex rated puzzles, requiring relatively few moves. An analysis of the  nature of the problem search space is offered.  	heuristic;sudoku	Sian K. Jones;Paul A. Roach;Stephanie Perkins	2007		10.1007/978-1-84800-094-0_4	mathematical optimization;combinatorics;mathematics;algorithm	AI	24.524557448955	4.232071444469096	8866
31231ede372edfc47d063dbf25aebbdb82cbdda2	a constant-factor approximation algorithm for the asymmetric traveling salesman problem		We give a constant-factor approximation algorithm for the asymmetric traveling salesman problem. Our approximation guarantee is analyzed with respect to the standard LP relaxation, and thus our result confirms the conjectured constant integrality gap of that relaxation.   Our techniques build upon the constant-factor approximation algorithm for the special case of node-weighted metrics. Specifically, we give a generic reduction to structured instances that resemble but are more general than those arising from node-weighted metrics. For those instances, we then solve Local-Connectivity ATSP, a problem known to be equivalent (in terms of constant-factor approximation) to the asymmetric traveling salesman problem.	apx;approximation algorithm;decision tree;directed graph;file spanning;hamiltonian path;internet backbone;lagrangian relaxation;linear programming relaxation;social inequality;travelling salesman problem	Ola Svensson;Jakub Tarnawski;László A. Végh	2018		10.1145/3188745.3188824	discrete mathematics;2-opt;combinatorial optimization;linear programming relaxation;approximation algorithm;travelling salesman problem;mathematics;christofides algorithm;bottleneck traveling salesman problem;linear programming;mathematical optimization	Theory	23.01304083554947	19.21943449605823	8879
6148ddf9fe6a835f4f92a591ff135a1c6bba70e1	towards an architecture-independent analysis of parallel algorithms (extended abstract)	parallel algorithm	Harnessing the massively parallel architectures soon to become available into efficient algorithmic cooperation is one of the most important intellectual challenges facing Computer Science today. To the theoretician, the task seems similar to thiat of understanding the issues involved in the performance of sequential algorithms (which motivated Knuth’s books, among other important works), only mfinitely more complex. In sequential computation, th.e design process involves (a) choosing an algorithm and (b) analyzing it (mostly, counting its steps). In the parallel context, however, we have at least four stages: (1) Choose the algorithm (say, a directed acyclic graph (dag) indicating the elementary computations and their interdependence, a model in which evaluation of sequential performance is trivial). (2) Choose a particular multiprocessor architecture. (3) Find a schedule whereby the algorithm is executed on the processors (so that all necessary data a:re available at the appropriate processor at the time of each computation). (4) Only now can we talk about the performance of the algorithm, measured as the makespan of the schedule (elapsed time for computing the last result). In our opinion, it is this multi-layered nature of the problem that lies at the heart of the difficulties encountered in the development of the necessary ideas, principles, and tools for the design of parallel algorithms. Is there a way to shortcut the process, thus improving our chances of finally gaining some insight into parallel algorithms? It would be very interesting if we could combine stages (3) and (4) into a single step whereby the performance of the algorithm cho-	analysis of parallel algorithms;book;central processing unit;computation;computer science;directed acyclic graph;emoticon;genetic algorithm;interdependence;keyboard shortcut;makespan;multiprocessing;parallel algorithm;sequential algorithm	Christos H. Papadimitriou;Mihalis Yannakakis	1988		10.1145/62212.62262	computer science;mathematics;parallel algorithm;cost efficiency	Theory	5.265003812537568	29.750432370830463	8906
cdf0eb7df09f2779eda9bbc000e3eb61cc26dc2e	probably approximately correct learning of horn envelopes from queries		We propose an algorithm for learning the Horn envelope of an arbitrary domain using an expert, or an oracle, capable of answering certain types of queries about this domain. Attribute exploration from formal concept analysis is a procedure that solves this problem, but the number of queries it may ask is exponential in the size of the resulting Horn formula in the worst case. We recall a well-known polynomial-time algorithm for learning Horn formulas with membership and equivalence queries and modify it to obtain a polynomial-time probably approximately correct algorithm for learning the Horn envelope of an arbitrary domain.	algorithm;approximation;association rule learning;best, worst and average case;cognitive dimensions of notations;description logic;formal concept analysis;horn clause;polynomial;probably approximately correct learning;sampling (signal processing);time complexity;turing completeness	Daniel Borchmann;Tom Hanika;Sergei Obiedkov	2018	CoRR		mathematics;ask price;oracle;equivalence (measure theory);discrete mathematics;probably approximately correct learning;recall;formal concept analysis;exponential function	AI	5.140188269682755	18.70705185601313	8917
7ddb1b82b3ffbfcd6c9e718fbd24f4e18209003d	a characterization of line sigraphs	signed graph;line graph	Abstract   A  signed graph  (or in short,  sigraph ) is an ordered pair  S  = ( S   u  ,  s ) where  S u   is a graph  G  = ( V , E ) called the  underlying graph  of  S  and  s  : E(S u ) → {+, -} is a function denned on the edge set  E ( S   u  ) =  E  into set {+, −}, called a  signing  of  G  We let  E  + ( S ) = [e ∈  E ( G ):  s ( e ) = +} and  E  − ( S ) = [ e  ∈  E ( G ) :  s ( e ) = -}. Then the set  E ( S ) =  E  + ( S ) U  E − (S)  is called the edge set of  S , the elements of  E  + ( S )( E  − ( S )) are called positive (negative) edges in  S.  In this way a graph may be regarded as a sigraph in which all the edges are positive; hence we regard graphs as  all-positive sigraph (all-negative sigraphs  are denned similarly). A sigraph is said to be  homogeneous  if it is either all-positive or all-negative and  heterogenous  otherwise.  For a sigraph  S , its  line sigraph  whose vertex set  V(L(S))  is the edge set  E ( S ) =  E ( S   u  ) of S and two vertices of  L(S)  are joined by a negative edge if and only if they correspond to  adjacent negative edges  in  S.   In this paper, we define a given sigraph  S  to be a  line sigraph  if there exists a sigraph  H  such that  L(H)  ≅ S(read as  L(H)  is isomorphic to  S ). We then give the following structural characterization of line sigraphs, extending the well known characterization of line graphs.   Theorem : A signed graph  S  is a line sigraph if and only if  (i)  S u   is a line graph and (ii) If  uv  is a positive edge of S then either there is no negative edge incident at u or there is no negative edge incident at  v.		Mukti Acharya;Deepa Sinha	2003	Electronic Notes in Discrete Mathematics	10.1016/S1571-0653(04)00509-8	arithmetic;combinatorics;discrete mathematics;mathematics;line graph	Theory	30.63407924594735	31.05675668582227	8926
6dd3600830341fd85d9cf5c205c2f300a973172d	smoothed analysis of the 2-opt algorithm for the general tsp	2 opt;qa mathematics;traveling salesperson problem;smoothed analysis;probabilistic analysis;local search	2-Opt is a simple local search heuristic for the traveling salesperson problem that performs very well in experiments with respect to both running time and solution quality. In contrast to this, there are instances on which 2-Opt may need an exponential number of steps to reach a local optimum. To understand why 2-Opt usually finds local optima quickly in experiments, we study its expected running time in the model of smoothed analysis, which can be considered as a less-pessimistic variant of worst-case analysis in which the adversarial input is subject to a small amount of random noise.  In our probabilistic input model, an adversary chooses an arbitrary graph G and a probability density function for each edge according to which its length is chosen. We prove that in this model the expected number of local improvements is O(mnφ ċ 16&sqrt;ln m)=m1+o(1)nφ, where n and m denote the number of vertices and edges of G, respectively, and φ denotes an upper bound on the density functions.	2-opt;adversary (cryptography);best, worst and average case;experiment;heuristic;local optimum;local search (optimization);noise (electronics);randomized algorithm;smoothed analysis;smoothing;time complexity;travelling salesman problem	Matthias Englert;Heiko Röglin;Berthold Vöcking	2016	ACM Trans. Algorithms	10.1145/2972953	smoothed analysis;2-opt;mathematical optimization;combinatorics;probabilistic analysis of algorithms;computer science;local search;mathematics;travelling salesman problem;algorithm	Theory	21.394083420674015	18.667897789981176	8927
e67cf44f6867fa8169ecb9592b1d7582634cfa89	constant factor approximation for the weighted partial degree bounded edge packing problem		In the partial degree bounded edge packing problem (PDBEP), the input is an undirected graph (G=(V,E)) with capacity (c_vin {mathbb {N}}) on each vertex. The objective is to find a feasible subgraph (Gu0027=(V,Eu0027)) maximizing (|Eu0027|), where (Gu0027) is said to be feasible if for each (e={u,v}in Eu0027), (deg _{Gu0027}(u)le c_u) or (deg _{Gu0027}(v)le c_v). In the weighted version of the problem, additionally each edge (ein E) has a weight w(e) and we want to find a feasible subgraph (Gu0027=(V,Eu0027)) maximizing (sum _{ein Eu0027} w(e)). The problem is already NP-hard if (c_v = 1) for all (vin V) [Zhang, FAW-AAIM 2012].	approximation;set packing	Pawan Aurora;Monalisa Jena;Rajiv Raman	2016		10.1007/978-3-319-48749-6_14	mathematical optimization;combinatorics;discrete mathematics;apx;mathematics	Theory	23.520176499277365	19.849598581604695	8935
7cab82a0e9ba237331938ba7bc5922b66980e8d1	scanners for ferroelectric memory capacitors	ferroelectric materials;hysteresis;switching circuits;polarization;pulse circuits;ferroelectric materials capacitors polarization pulse circuits circuit testing switches material storage hysteresis voltage switching circuits;capacitors;material storage;voltage;circuit testing;design for test;switches;random access	Many references are available on the properties and characteristics of ferroelectric materials and their memory application.1-3 The purpose of this paper is to present several scanning systems by which binary information can be stored and recalled from ferroelectric capacitor configurations. The circuitry to be described here was originally designed for testing of ferroelectric elements and employs an ordered or nonrandom scanning pattern. Most of the circuitry presented is, however, adaptable to random access application.	ferroelectric ram	Charles F. Pulvari;G. E. McDuffie	1958	IRE Trans. Electronic Computers	10.1109/TEC.1958.5222093	ferroelectricity;electronic engineering;voltage;ferroelectric capacitor;capacitor;non-volatile memory;hysteresis;network switch;polarization;computer science;electrical engineering;design for testing;physics;random access;quantum mechanics	ECom	51.40560217157037	48.38024042994839	8938
d0b7319fce7e2c8b8c5afd134b854b582c552802	a changing-reference parasitic-matching sensing circuit for 3-d vertical rram		The 3-D vertical array architecture is considered to be a promising technology for emerging nonvolatile memories. But in 3-D vertical emerging nonvolatile memories, planar parasitic elements, vertical parasitic elements, and the sneak currents of the half-selected memory cells result in the delay of the read operation and read errors. This paper refers to the case of the 3-D vertical resistive switching random access memory (RRAM) technology. A read scheme, the memory core design, and the read path are proposed or analyzed. The factors that affect the read operation are concluded. A changing-reference parasitic-matching sensing circuit is, therefore, proposed. In the proposed circuit, the reference side and the read side share similar sneak currents and read paths. Simulated in a 40-nm CMOS process, the sensing time of 128-Mb 3-D vertical RRAM is 8.54 ns compared to the conventional 34.26 ns. Monte Carlo simulations show a 130.21-ns worst sensing time compared to the conventional 401.95 ns. The read errors are reduced by 100% and 95.31% under the regular and the worst RRAM resistance, respectively.	bl (logic);cmos;current mirror;monte carlo method;non-volatile memory;random access;resistive random-access memory;simulation	Yu Lei;Houpeng Chen;Xiaoyun Li;Xi Li;Qian Wang;Qi Zhang;Jie Miao;Zhitang Song	2018	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2018.2816246	capacitor;computer science;electronic engineering;monte carlo method;architecture;non-volatile memory;resistive random-access memory;cmos;random access;resistive touchscreen	EDA	16.97087109395149	60.23406672719579	8939
7edad8c58dc6556a425357a8de9e64b0c20430c1	polynomial time complexity of edge colouring graphs with bounded colour classes	edge colouring;chromatic index;equalized edge colouring	We show that the following fundamental edge-colouring problem can be solved in polynomial time for any given constant B: given a simple graph G, find an edge-colouring of G where each colour is assigned to at most B edges and which, subject to this condition, has the fewest number of colour classes.	edge coloring;graph (discrete mathematics);graph coloring;polynomial;time complexity	Romeo Rizzi;David Cariolaro	2013	Algorithmica	10.1007/s00453-013-9746-7	combinatorics;discrete mathematics;edge cover;edge coloring;mathematics;geometry	Theory	27.65297017971075	26.004831633138014	8947
c084b0c04f25b89c9b8d574fd6ce5ff874726a26	a near-optimal multistage distributed algorithm for finding leaders in clustered chordal rings	distributed system;complexite;systeme reparti;complejidad;complexity;sistema repartido;algorithme reparti;algoritmo repartido;distributed algorithm	A new multistage election algorithm for a clustered chordal ring is proposed in this paper. It is shown that the algorithm uses O(G(n)n) messages for a chordal ring with n processors and G(n) chords at each processor, where G(n) is a function increasing extremely slowly with n. In fact, G(n) 4 5 for all “practical” values of n, i.e., for all n ~2~‘~‘~. Hence, the algorithm is nearly optimal in terms of both messages and links.	central processing unit;distributed algorithm;multistage amplifier	Yi Pan	1994	Inf. Sci.	10.1016/0020-0255(94)90071-X	distributed algorithm;combinatorics;complexity;computer science;mathematics;distributed computing;algorithm	HPC	18.529602709760905	28.945592838474276	8955
35b39c0bc8b428aaede43e33d664abd5f41afd32	explicit bounds for primes in residue classes	galois group;corps fini;finite field;number theory;corps nombres;riemann hypothesis;number field;campo finito;theorie nombre	Let E/K be an abelian extension of number fields, with E 6= Q. Let ∆ and n denote the absolute discriminant and degree of E. Let σ denote an element of the Galois group of E/K. We prove the following theorems, assuming the Extended Riemann Hypothesis: (1) There is a degree-1 prime p of K such that ( p E/K ) = σ, satisfying Np ≤ (1 + o(1))(log ∆ + 2n)2. (2) There is a degree-1 prime p of K such that ( p E/K ) generates the same group as σ, satisfying Np ≤ (1 + o(1))(log ∆)2. (3) For K = Q, there is a prime p such that ( p E/Q ) = σ, satisfying p ≤ (1 + o(1))(log ∆)2. In (1) and (2) we can in fact take p to be unramified in K/Q. A special case of this result is the following. (4) If gcd(m, q) = 1, the least prime p ≡ m (mod q) satisfies p ≤ (1 + o(1))(φ(q) log q)2. It follows from our proof that (1)–(3) also hold for arbitrary Galois extensions, provided we replace σ by its conjugacy class 〈σ〉. Our theorems lead to explicit versions of (1)–(4), including the following: the least prime p ≡ m (mod q) is less than 2(q log q)2.	convex conjugate;discriminant	Eric Bach;Jonathan P. Sorenson	1996	Math. Comput.	10.1090/S0025-5718-96-00763-6	combinatorics;galois group;mathematical analysis;number theory;discrete mathematics;algebraic number field;mathematics;geometry;riemann hypothesis;finite field;algebra	Theory	41.13407970316285	34.89761108289564	8963
e9d9d30ab9aabf9f53666cf750acbd4341b4597f	counterexamples to the unique and cofinal branches hypotheses		We produce counterexamples to the unique and cofinal branches hypotheses, assuming (slightly less than) the existence of a cardinal which is strong past a Woodin cardinal.		Itay Neeman;John R. Steel	2006	J. Symb. Log.		discrete mathematics;counterexample;cofinal;mathematics;woodin cardinal	Theory	38.88666144952132	28.255023800170676	8976
2b74b2cc6d972745192d2891464ff55a2b5b84c1	circuit simplification for the symbolic analysis of analogintegrated circuits	electronic circuits;symbol manipulation;signal generators;signal flow graph;memory management;circuit model reduction circuit simplification symbolic analysis analog integrated circuits linearized analog circuit signal flow graphs frequency intervals poles and zeroes graph manipulation techniques symbolic expressions;circuit model reduction;linearized analog circuit;graph manipulation techniques;signal flow graphs;indexing terms;polynomials;numerical calculation;poles and zeros;analog circuits;analogue integrated circuits;time factors;model reduction;vectors;reduced order systems symbol manipulation analogue integrated circuits signal flow graphs poles and zeros;frequency intervals;analog integrated circuits;performance analysis;pole zero extraction;poles and zeroes;circuit simplification;symbolic analysis;symbolic expressions;frequency;reduced order systems;optimality condition;analog integrated circuits frequency performance analysis analog circuits time factors memory management electronic circuits vectors polynomials signal generators	Presents a circuit simplification method for the symbolic analysis of a linear or linearized (small-signal) analog circuit. Its goal is to generate simplified signal flow graphs describing the circuit's behavior in well-defined frequency intervals. These frequency subranges are automatically constructed based on numerical calculation of the system's poles and zeroes. The circuit reduction has been implemented using graph manipulation techniques. The order in which these manipulations are applied is based on a tradeoff between the error and the level of simplification they introduce. The technique can be used to symbolically localize poles and zeroes and inspect their observability. This allows generating symbolic expressions for poles and zeroes, which in optimal conditions lead to simple, interpretable expressions. The technique can also be used as preprocessor to simplify a circuit before analyzing it with standard approximate symbolic analysis techniques. In that case, it helps overcoming the time and memory constraints related to those techniques. Experimental results show the effectiveness of the approach.	symbolic computation	Walter Daems;Georges G. E. Gielen;Willy M. C. Sansen	2002	IEEE Trans. on CAD of Integrated Circuits and Systems	10.1109/43.992763	pole–zero plot;mathematical optimization;electronic circuit;electronic engineering;index term;analogue electronics;signal-flow graph;computer science;theoretical computer science;frequency;mathematics;symbolic data analysis;symbolic trajectory evaluation;algorithm;polynomial;signal generator;memory management	EDA	21.284666692113934	46.33757857611395	8985
4d30592f773d1592e74e52336dddda971e377ea9	permutations and successions		Abstract   Let  π  = ( π (1),  π (2),…,  π ( n )) be a permutation on {1, 2, …,  n }. A succession (respectively,  ∗ -succession) in π is any pair  π ( i ),  π ( i  + 1), where  π ( i  + 1) =  π ( i ) + 1 (respectively,  π ( i  + 1) ≡  π ( i ) + 1 (mod  n )),  i  = 1, 2, …,  n  − 1. Let  R ( n ,  k ) (respectively,   R     ∗   (n, k)  ) be the number of permutations with  k  successions (respectively,  ∗ -successions). In this note we determine  R ( n ,  k ) and   R     ∗   (n, k)  . In addition, these notions are generalized to the case of circular permutations, where analogous results are developed.		Stephen M. Tanny	1976	J. Comb. Theory, Ser. A	10.1016/0097-3165(76)90063-7	arithmetic;combinatorics;mathematics;algebra	Theory	37.076494623972614	35.458672831127465	8989
2575d55286da3fd708c8b48cb805d29abb544d93	generic-point parallel scalar multiplication without precomputations	parallel scalar multiplication;generic point;elliptic curves cryptosystems;article;scalar multiplication	The first efficient generic-point parallel scalar multiplication method is presented here. The novelty of the proposed method is that the precomputation overhead can be replaced by postcomputations that can be parallelised. This method will be very attractive for use in high-performance end servers that employ parallel elliptic curve cryptoprocessors.	overhead (computing);precomputation	Turki F. Al-Somani;Mohammad K. Ibrahim	2009	IEICE Electronic Express	10.1587/elex.6.1732	discrete mathematics;theoretical computer science;generic point;scalar multiplication;mathematics;scalar;elliptic curve point multiplication;algebra	HPC	9.051771176521989	42.88408943217618	9008
ee6ba3f295614562bd3d66f5956c204710d1aa58	on infinite words determined by indexed languages		We characterize the infinite words determined by indexed languages. An infinite language L determines an infinite word α if every string in L is a prefix of α. If L is regular or context-free, it is known that α must be ultimately periodic. We show that if L is an indexed language, then α is a morphic word, i.e., α can be generated by iterating a morphism under a coding. Since the other direction, that every morphic word is determined by some indexed language, also holds, this implies that the infinite words determined by indexed languages are exactly the morphic words. To obtain this result, we prove a new pumping lemma for the indexed languages, which may be of independent interest.	context-free language;indexed language;morphic (software);morphic word;omega language;pumping (computer systems);pumping lemma for context-free languages	Tim Smith	2014		10.1007/978-3-662-44522-8_43	arithmetic;discrete mathematics;mathematics;algorithm	Theory	-2.0624756077216775	18.35928246275703	9010
b43698d9244a67f3d566b6565c69b5a20542a4a7	lossy compression of dynamic, weighted graphs	social network services;shrinkage graph compression dynamic graphs weighted graphs;approximation algorithms;approximation methods approximation algorithms weight measurement heuristic algorithms social network services noise;weighted graphs;shrinkage;weight measurement;dynamic graphs;heuristic algorithms;graph theory data compression data structures;approximation methods;graph compression;noise;graph compression weighted graph lossy compression	A graph is used to represent data in which the relationships between the objects in the data are at least as important as the objects themselves. Large graph datasets are becoming more common as networks such as the Internet grow, and our ability to measure these graphs improves. This necessitates methods to compress these datasets. In this paper we present a method aimed at lossy compression of large, dynamic, weighted graphs.	approximation error;degree distribution;graph (discrete mathematics);internet;lossy compression;quantization (physics)	Wilko Henecka;Matthew Roughan	2015	2015 3rd International Conference on Future Internet of Things and Cloud	10.1109/FiCloud.2015.64	1-planar graph;pathwidth;graph product;noise;clique-width;theoretical computer science;comparability graph;voltage graph;modular decomposition;partial k-tree;shrinkage;indifference graph;approximation algorithm	DB	35.52060477220587	11.968463919920007	9020
cebf128127e45d118d958b5ef758b8509f3ed922	student cluster competition: parconnect reproducibility task report		Reproducibility is a desirable characteristic of any experimental work in computer science. In this paper, we reproduce the results in the paper, “A parallel connectivity algorithm for de Bruijn graphs in metagenomic applications”, for verifying their claims on the speed and scalability of their algorithm. We first state the claims made in the original paper. Then, we describe our hardware and software setup used for the reproducibility task, followed by the steps taken to setup the proposed algorithm and profiling software. Lastly, we present the results obtained from our experiments and show that we are able to reproduce most of the claims made in the original paper. © 2017 Elsevier B.V. All rights reserved. 1. Claims of the original paper Flick et al. [1] introduced a parallel connectivity (ParConnect) algorithm for de Bruijn graphs in metagenomic applications. This algorithm can compute connected components in undirected graphs or weakly connected components in directed graphs. In the original paper, they claimed that their algorithm performs faster than previous algorithms and is scalable to large sparse graphs and thousands of cores. In this paper, we verify their claims by reproducing their results presented in [1] . Specifically, we verify that: 1. The overhead of communication is higher than the computation time using the algorithm (Fig. 2 in [1] ). 2. The AP_LB variant solves the load imbalance issue introduced by the AP variant (Fig. 3 in [1] ). 3. The runtime of the algorithm scales in an inverse logarithmic manner as the core count increases (Fig. 4 in [1] ). 4. The AP_LB variant has better performance than the AP variant and the AP variant has better performance than the Naive variant (Fig. 4 in [1] ). 2. Hardware setup The specification of the machines we used for the reproducibility task is presented in Table 1 . The specification of the machines used in the original paper is presented in Table 2 . Compared to the hardware used in the original paper, our cluster has faster memory and faster InfiniBand interconnection. Moreover, we have more CPU cores per node and each ∗ Corresponding author. E-mail addresses: c150124@e.ntu.edu.sg (Y.H. Tan), shao0035@e.ntu.edu.sg (Y. Shao), sliu019@e.ntu.edu.sg (S. Liu), ebslee@ntu.edu.sg (B.-S. Lee). 1 The authors contributed equally to the work. http://dx.doi.org/10.1016/j.parco.2017.07.003 0167-8191/© 2017 Elsevier B.V. All rights reserved. Please cite this article as: Y.H. Tan et al., Student cluster competition: ParConnect reproducibility task report, Parallel Computing (2017), http://dx.doi.org/10.1016/j.parco.2017.07.003 2 Y.H. Tan et al. / Parallel Computing 0 0 0 (2017) 1–7 ARTICLE IN PRESS JID: PARCO [m3Gsc; July 20, 2017;2:12 ] Table 1 Machine specification for reproducibility task. Number of nodes 4 CPU per node Intel ® Xeon ® Processor E5-2699 v4 × 2 (44 cores, no Hyper-Threading) Memory per node 128GB DDR4 RAM Operating system CentOS 7.2 Interconnection Mellanox ® EDR Infiniband Table 2 Machine specification in original paper. Number of nodes 80 CPU per node Intel ® Xeon ® Processor E5-2650 × 2 (16 cores, no Hyper-Threading) Memory per node 128GB DDR3 RAM Operating system Red Hat Enterprise Linux 6.4 Interconnection Mellanox ® QDR Infiniband Table 3 Compiler and MPI. Name Version Compiler Intel ® Compiler Intel ® Parallel Studio XE 2017 Cluster Edition MPI Intel ® MPI Intel ® Parallel Studio XE 2017 Cluster Edition core is stronger. Therefore, when running with the same number of cores, our cluster should have a better communication performance because there will be more intra-node communication. 3. Software setup 3.1. Source code The source code is provided by the competition committee. 2 We use the exact same code provided without any modification except for changing the variants of the algorithm mentioned in Section 3.4 . 3.2. Compiler and MPI We use Intel ® Compiler and Intel ® MPI for the reproducibility task. Details are presented in Table 3 . The same compiler and MPI are used in the original paper. However, the versions are not mentioned. 3.3. Profiler We use Allinea MAP 6.0 produced by Allinea Software as our profiling tool. Allinea MAP is widely used in profiling parallel MPI and OpenMP code. It is able to analyze code performance and causes of the bottleneck, such as memory, I/O, and communication. This tool allows us to measure our performance compared to the original paper and analyze the communication cost of the application. 3.4. Compiling ParConnect with Allinea support Overall, we follow the instructions provided by the competition committee. 3 We use CMake for configuring the build process and change the source code to compile with different variants of the algorithm. Specifically, in order to compile the application with Allinea support, we take the following steps: Step 1. Load Intel Parallel Studio XE and Allinea environment module. Step 2. Create an Allinea MPI wrapper using the make-profiler-libraries command provided by Allinea in order to analyze MPI applications. Step 3. Use CMake to configure the build with the following CMake parameters: 2 https://github.com/cjain7/parconnect _ SCC16 . 3 http://www.studentclustercompetition.us/2016/ReproducibilityApplication.pdf . Please cite this article as: Y.H. Tan et al., Student cluster competition: ParConnect reproducibility task report, Parallel Computing (2017), http://dx.doi.org/10.1016/j.parco.2017.07.003 Y.H. Tan et al. / Parallel Computing 0 0 0 (2017) 1–7 3 ARTICLE IN PRESS JID: PARCO [m3Gsc; July 20, 2017;2:12 ] Table 4 Number of edges and connected components for the datasets. Data file large.fastq small.fastq Number of edges 442,461,650 90,665,399 Number of connected components 884,923,301 1,929,553 Table 5 Communication percentage comparison between self-calculated and Allinea-calculated timings. Variant Self-calculated communication percentage Allinea-calculated communication percentage Naive 20.1% 53.5% AP 26.6% 67.4% AP_LB 21.2% 49.7% S S S S S (a) BENCHMARK-ENABLE-CONN = ON (b) CMAKE-CXX-FLAGS = ’’-L/path/to/mpi/wrapper -lmap-sampler-pmpi -lmap-sampler -Wl,--eh-frame-hdr’’ Step 4. Modify the source code to choose a variant of the algorithm in line 55 of src/coloring/labelProp.hpp . Set the class template parameter OPTIMIZATION to: (a) opt-level::loadbalanced for the AP_LB variant (b) opt-level::stable-partition-removed for the AP variant (c) opt-level::naive for the Naive variant Step 5. Compile the chosen variant with make . 3.5. Profiling ParConnect with Allinea After successful compilation, we use the following steps to run the application with Allinea: Step 1. Load Intel Parallel Studio XE and Allinea environment module. tep 2. Start the interactive GUI of Allinea MAP with the map command. tep 3. Select the executable of the variant we need (i.e. Naive/AP/AP_LB). tep 4. Set the flags as --input dbg --file < filename > . tep 5. Set the working directory to the directory where the data file resides. tep 6. Set MPI options (i.e. number of processes and processes per node). Step 7. Execute the program in Allinea MAP. The above steps are equivalent to running Allinea without the interactive GUI with the following command $ map --profile mpirun -np < np > -ppn < ppn > \ ./benchmark-parconnect --input dbg --file < filename > 4. Reproducibility task Two datasets are used for the reproducibility task, 4 large.fastq and small.fastq. Compared to the Iowa Continuous Corn Soil Metagenome dataset from the DOE Joint Genome Institute Genome Portal (Project ID: 402461), which is used in the original paper, the two datasets used for the reproducibility task represent much smaller graphs. The sizes of the datasets used in the original paper range from 6.2 GB to 421 GB. The sizes of the two datasets for reproducibility task are 358.9 MB (small.fastq) and 1.8 GB (large.fastq). We carry out the following tasks using these two datasets. 4.1. Task 1: Number of edges and connected components for the datasets For task 1, we count the number of edges and connected components for the datasets. This is to verify that our executable computes the correct results before we reproduce the results in the original paper. The results for task 1 are presented in Table 4 . 4.2. Task 2: Profiler and program output timings For task 2, we collect the profiler and program output timings on all three variants of the algorithm with the large dataset (i.e. large.fastq). We run with 176 cores and 176 MPI ranks. The results are presented in Fig. 1 , Fig. 2 , and Fig. 3 respectively ( Table 5 ). 4 http://purl.dlib.indiana.edu/iusw/data/2022/21182/ParConnectSCC16.tgz . Please cite this article as: Y.H. Tan et al., Student cluster competition: ParConnect reproducibility task report, Parallel Computing (2017), http://dx.doi.org/10.1016/j.parco.2017.07.003 4 Y.H. Tan et al. / Parallel Computing 0 0 0 (2017) 1–7 ARTICLE IN PRESS JID: PARCO [m3Gsc; July 20, 2017;2:12 ] Fig. 1. Naive communication v.s. computation. Fig. 2. AP communication v.s. computation. Fig. 3. AP_LB communication v.s. computation. Please cite this article as: Y.H. Tan et al., Student cluster competition: ParConnect reproducibility task report, Parallel Computing (2017), http://dx.doi.org/10.1016/j.parco.2017.07.003 Y.H. Tan et al. / Parallel Computing 0 0 0 (2017) 1–7 5 ARTICLE IN PRESS JID: PARCO [m3Gsc; July 20, 2017;2:12 ] Fig. 4. Naive tuple statistics. Fig. 5. AP tuple statistics. The communication v.s. computation graphs largely differ from the graphs reported in [1] . The self-calculated communication percentage is also different from the Allinea reported value. This is because the time spent on MPI barriers outside of the three specified functions for computing communication time (i.e. AllToAll , GetSplitters , and FixPartition ) are not accounted for in self-calculated communication percentage. This may also be caused by the difference between the number of cores used in [1] as compared to the machine configuration used in our reproduc	algorithm;allinea map;bluetooth;bottleneck (engineering);c++;cmake;conn;central processing unit;compiler;computation;computer memory;computer science;connectivity (graph theory);dbg;de bruijn graph;directed graph;directory (computing);emoticon;executable;experiment;fastq format;fractal dimension;graph (discrete mathematics);graph coloring;graphical user interface;hyper-threading;infiniband;input/output;interconnection;library (computing);linux;message passing interface;metagenomics;os-tan;openmp;operating system;overhead (computing);parallel studio;parallel computing;profiling (computer programming);quad data rate sram;random-access memory;sampling (signal processing);scalability;sparse matrix;template (c++);time complexity;working directory;xfig	Ying Hao Tan;Yiyang Shao;Siyuan Liu;Bu-Sung Lee	2017	Parallel Computing	10.1016/j.parco.2017.07.003	de bruijn sequence;computer science;parallel computing;scalability;theoretical computer science;reproducibility;profiling (computer programming);software;graph	ML	-3.410701352692078	45.537478012788746	9039
f14e6a4e5e6f069a574f11d6fa5089a860d47864	existence algorithms for synchronizing/distinguishing sequences	logic arrays;state identification;existence algorithm;uncertainty;helium;signal design;successor tree;tree graphs;synchronizing sequence;power dissipation;displays;tree method distinguishing sequence existence algorithm finite state machine state identification successor tree synchronizing sequence;tree method;circuits;distinguishing sequence;computer science;finite state machine	This correspondence describes two efficient algorithms for determining whether or not a given finite-state machine has a synchronizing sequence and a distinguishing sequence, respectively, and compares them with the well-known tree method. Compared with the tree method, these new algorithms are easier to implement and require less memory size. Since they do not require keeping and searching a look-back directory, they allow significant speed improvements.	algorithm	Sung Je Hong	1981	IEEE Trans. Computers	10.1109/TC.1981.1675761	electronic circuit;combinatorics;discrete mathematics;uncertainty;computer science;dissipation;mathematics;finite-state machine;helium;tree;algorithm;statistics	Vision	21.432459826301876	47.45627805150601	9044
ed7bd07334742ff3cd111ffe311e5dfcf2657686	fpga-based soc for transcoding h264/avc-svc with low latency and high bitrate entropy coding	scalable video coding;entropy coding;hardware accelerator;hardware architecture;video coding;low latency;video coding discrete cosine transforms field programmable gate arrays system on chip transcoding;system on chip;transcoding delay bit rate entropy coding hardware video coding acceleration computer architecture codecs discrete cosine transforms;discrete cosine transforms;content adaptation;field programmable gate arrays;transcoding;hardware implementation;xilinx virtex 5 fpga field programmable gate arrays system on chip soc transcoding h264 avc svc entropy coding scalable video coding h 264 standard cavlc codec discrete cosine transforms dct	Scalable Video Coding extension of H.264 standard is very suitable for content adaptation and addressing different terminals. However, in various cases it is necessary to perform transcoding in video coding layer requiring tremendous computation and hardware acceleration. In this paper, we present an efficient hardware architecture of a CAVLC codec based on a new method that provides a constant and reduced latency. The presented method calculates the 16 DCT coefficients in parallel. The results of hardware implementation targeting a Xilinx Virtex 5 FPGA are presented.	codec;coefficient;computation;content adaptation;context-adaptive variable-length coding;data compression;discrete cosine transform;entropy encoding;field-programmable gate array;h.264/mpeg-4 avc;hardware acceleration;scalable video coding;system on a chip;virtex (fpga)	Michael Guarisco;Hassan Rabah;Yves Berviller;Serge Weber;Said Belkouch	2009	2009 IEEE International SOC Conference (SOCC)	10.1109/SOCCON.2009.5398004	scalable video coding;system on a chip;embedded system;parallel computing;real-time computing;transcoding;hardware acceleration;computer science;entropy encoding;operating system;context-adaptive variable-length coding;coding tree unit;hardware architecture;context-adaptive binary arithmetic coding;h.261;field-programmable gate array;low latency	EDA	11.998387796199841	40.715560872750565	9057
dc0050f633ed2f1fc175ee9f41ce42bc61be903c	on the complexity of omega-automata	decision procedures deterministic automata complexity omega automata buchi automata;deterministic automata;automata h infinity control laser sintering circuits logic mathematics upper bound calculus costs;complexity;buchi automata;decision procedures;omega automata	Automata on infinite words were introduced by Biichi in order to give a decision procedure for SlS, the monadic second-order theory of one successor. Muller suggested deterministic w-automata as a means of describing the behavior of non-stabilizing circuits. McNaughton proved that the classes of languages accepted by nondeterministic Biichi automata and by deterministic Muller automata are the same. His construction and its proof are quite complicated, and the blow-up of the construction is doubly exponential. Our main result is a new determinization construction. The advantages of the construction are that it is simpler and yields a single exponent upper bound for the general case. This construction is essentially optimal. Using the construction we can also obtain an improved complementation construction for Biichi automata, which is aIso optimaI. Both constructions can be used to improve the complexity of decision procedures that use automata-theoretic techniques.	automata theory;chaitin's constant;decision problem;muller automaton;non-functional requirement;powerset construction;time complexity;ω-automaton	Shmuel Safra	1988		10.1109/SFCS.1988.21948	combinatorics;discrete mathematics;büchi automaton;complexity;nondeterministic finite automaton;continuous spatial automaton;quantum finite automata;computer science;nested word;automata theory;ω-automaton;mathematics;dfa minimization;mobile automaton;algorithm	Theory	-1.9771349843547703	23.257471411601124	9060
63a4fe19a3a8b13095084c1110223532a201cc78	capture-pattern-control to address the fault detection degradation problem of multi-cycle test in logic bist		Multi-cycle Test applies more than one capture cycles during the capture operation which is a promising way to reduce the test volume of Logic-BIST (Logic Built-in Self-Test) based POST (Power-on Self-Test) for achieving high fault coverage. However, the randomness loss of the capture patterns due to the large number of capture cycles obstructs the further improvement of fault coverage and pattern reduction. In this paper, we propose a novel approach to control the capture patterns by modifying the captured values of scan Flip-Flops (FFs) during capture operation to enhance the test quality of the capture patterns. In the approach, we insert FF-Control circuits between the scan FFs and the combinational circuit to improve the randomness of the capture patterns by loading toggle vectors/pseudo-random vectors. The experimental results of ISCAS89 and ITC99 benchmarks validated the effectiveness of the proposed methods in fault coverage improvement and random pattern reduction for Logic-BIST.		Senling Wang;Tomoki Aono;Yoshinobu Higami;Hiroshi Takahashi;Hiroyuki Iwata;Yoichi Maeda;Jun Matsushima	2018	2018 IEEE 27th Asian Test Symposium (ATS)	10.1109/ATS.2018.00038	fault coverage;degradation problem;randomness;real-time computing;computer engineering;computer science;electronic circuit;combinational logic;fault detection and isolation	EDA	21.250898039760326	52.26801492189535	9077
4a855ccaab477c53efc847fc9372639065776288	fast distributed construction of k-dominating sets and applications	time complexity;minimum weight spanning tree;distributed networks;distributed data structure;dominating set;graph partitioning;distributed algorithm	This paper presents a fast distributed algorithm to compute a small k-dominating set D (for any fixed k) and its induced graph partition (breaking the graph into radius k clusters centered around the vertices of D). The time complexity of the algorithm is O(k log* n). Small k-dominating sets have applications in a number of areas, including routing with sparse routing tables via the scheme of [P~, the design of distributed data structures [P2], and center selection in a distributed network (cf. [BKP]). The main application described in this paper concerns a fast distributed algorithm for constructing a minimum weight spanning tree (MST). On an n-vertex network of diameter d, the new algorithm constructs an MST in time O(@log* n + d), improving on the results of [GKP]. The new MST algorithm is conceptually simpler than the three-phase algorithm of [GKP]. In addition to exploiting small k-dominating sets, it uses a very simple convergecast protocol to inform a center about graph edges, that avoids forwarding messages about edges that close cycles. This convergecast protocol is similar to the one used in the third phase of the algorithm of [GKP], and most of the novelty lies in a new careful analysis proving that the convergecast process is fully pipelined, and no waiting occurs at intermediate nodes. This enables the new algorithm to skip the complicated second phase of the algorithm of [GKP].	data structure;distributed algorithm;dominating set;file spanning;graph partition;knapsack problem;minimum spanning tree;minimum weight;routing table;sparse matrix;time complexity	Shay Kutten;David Peleg	1995		10.1145/224964.224990	time complexity;distributed algorithm;combinatorics;discrete mathematics;dominating set;spanning tree;computer science;graph partition;minimum spanning tree;connected dominating set;distributed computing;distributed minimum spanning tree;algorithm	Theory	18.819732262180654	33.66129948614588	9081
37c1ecbff564c648dccd59c6c2e2ca6066a7b093	information rates of autoregressive processes	rate distortion;markov source;probability of error;autoregressive process;rate distortion theory;first order;autoregressive processes;mean square error;information rate;distributed generators;rate distortion theory autoregressive processes;time discretization;lower bound	The rate distortion function R(D) is calculated for two time-discrete autoregressive sources-the time-discrete Gaussian autoregressive source with a mean-square-error fidelity criterion and the binary-symmetric first-order Markov source with an average probability-of-error per bit fidelity criterion. In both cases it is shown that R(D) is bounded below by the rate distortion function of the independent-letter identically distributed sequence that generates the autoregressive source. This lower bound is shown to hold with equality for a nonzero region of small average distortion. The positive coding theorem is proved for the possibly nonstationary Gaussian autoregressive source with a constraint on the parameters. Finally, it is shown that the rate distortion function of any timediscrete autoregressive source with a difference distortion measure can be bounded below by the rate distortion function of the independent-letter identically distributed generating sequence with the same distortion measure.	autoregressive model;distortion;eisenstein's criterion;first-order predicate;markov chain;markov information source;mean squared error;rate–distortion theory	Robert M. Gray	1970	IEEE Trans. Information Theory	10.1109/TIT.1970.1054470	econometrics;mathematical optimization;rate–distortion theory;probability of error;star model;first-order logic;mathematics;mean squared error;autoregressive model;upper and lower bounds;nonlinear autoregressive exogenous model;statistics	ML	50.85524005875882	15.318157025552894	9090
1d5f4799df428b9aeabc7fe12dd7046aeac810e5	multiple stereo matching using an extended architecture	field programmable gate array;vision ordenador;concepcion circuito;sum of absolute difference;high density;traitement image stereoscopique;vision estereoscopica;reconfigurable architectures;real time;circuit design;vision stereoscopique;red puerta programable;system performance;reseau porte programmable;computer vision;stereo matching;temps reel;stereo image processing;stereo vision;tiempo real;vision ordinateur;conception circuit;stereopsis;architecture reconfigurable	In this paper, an FPGA based architecture for stereo vision is presented. The architecture provides a high-density disparity map in real time. The architecture is based on area comparison between an image pair using the sum of absolute differences. The architecture scans the input images in partial columns, which are then processed in parallel. The system performs monolithically on a pair of images in real time. An extension to the basic architecture is proposed in order to compute disparity maps on more than 2 images.	binocular disparity;column (database);common criteria;computation;computer stereo vision;field-programmable gate array;map;memory bank;real-time clock;real-time computing;reconfigurability;stereopsis;sum of absolute differences	Miguel Arias-Estrada;Juan M. Xicotencatl	2001		10.1007/3-540-44687-7_21	embedded system;computer vision;simulation;computer science;stereopsis;computer performance;computer graphics (images)	Robotics	11.508382403219677	36.349378313845214	9091
44e1028bac52407bb8501fcd68c4ea82c1e54ff1	behavior dynamics in cognitive radio networks: an interacting particle system approach	wireless channels;cognitive radio sensors mathematical model collaboration numerical models approximation methods topology;cognitive radio;differential equations;wireless channels cognitive radio differential equations;lattice topology behavior dynamics cognitive radio networks interactive particle system approach secondary users channel recommendation channel preferences ergodicity dynamical progress nonequilibrium statistical mechanics ordinary differential equation jackson network	A key feature of cognitive radio network is the intelligence of secondary users which can collaborate to improve the performance. The collaboration in terms of channel recommendation is studied. Via recommendations, the channel preferences of secondary users become dynamic. The corresponding behavior dynamics of secondary users are studied. Particularly, the ergodicity of the dynamical progress is studied using the model of interacting particles in nonequilibrium statistical mechanics, which is important for predicting the long term dynamics of the cognitive radio network. A mean field description using ordinary differential equation for the dynamics is also used to explicitly describe the behavior dynamics. A Jackson network with lattice topology is simulated to demonstrate the conclusions.	approximation;cognitive radio;computer simulation;dynamical system;electronic filter topology;ergodicity;interacting particle system;interaction;jackson	Husheng Li;Ju Bin Song	2012	2012 IEEE International Conference on Communications (ICC)	10.1109/ICC.2012.6363689	cognitive radio;simulation;computer science;artificial intelligence;theoretical computer science;mathematics;differential equation;computer network	Robotics	45.955360380717075	4.908661027055899	9093
1fca807ae2eb32d757509e1b65d655f2ecd8abb5	a local prime factor decomposition algorithm	s prime;strong product graph;s1 condition;combinatorics;mathematiques discretes;subgrafo;matematicas discretas;combinatoria;color;metodo descomposicion;combinatoire;methode decomposition;discrete mathematics;linear time algorithm;algorithme temps lineaire;graphe fini;finite graph;68wxx;prime factor decomposition;grafo finito;connected graph;decomposition method;factorization;probleme recouvrement;factorizacion;problema recubrimiento;producto grafo;sous graphe;graph products;decomposition algorithm;color continuation;reconnaissance graphe;68r10;factorisation;couleur;backbone;covering problem;subgraph;graphe produit;05b40;local covering;graph product;graphe connexe;s;produit graphe;grafo conexo	This work is concerned with the prime factor decomposition (PFD) of strong product graphs. A new quasi-linear time algorithm for the PFD with respect to the strong product for arbitrary, finite, connected, undirected graphs is derived. Moreover, since most graphs are prime although they can have a product-like structure, also known as approximate graph products, the practical application of the well-known ”classical” prime factorization algorithm is strictly limited. This new PFD algorithm is based on a local approach that covers a graph by small factorizable subgraphs and then utilizes this information to derive the global factors. Therefore, we can take advantage of this approach and derive in addition a method for the recognition of approximate graph products.	approximation algorithm;cholesky decomposition;graph (discrete mathematics);graph product;integer factorization;phase frequency detector;time complexity;whole earth 'lectronic link	Marc Hellmuth	2011	Discrete Mathematics	10.1016/j.disc.2011.02.016	block graph;robbins' theorem;combinatorics;discrete mathematics;graph product;mathematics;modular decomposition;factorization;line graph;algebra	Theory	26.45546870282965	32.5148104439644	9104
2c7e46fbed7a0e7284718588b610e276439f5b77	simultaneous packing and covering in sequence spaces	unit ball;qa mathematics;lp sequence space;packings;l p sequence space;coverings;functional analysis;loosest covering;sequence space;closest packing;simultaneous packing and covering constant	We adapt a construction of Klee (1981) to find a packing of unit balls in lp (1 ≤ p < ∞) which is efficient in the sense that enlarging the radius of each ball to any R > 2 covers the whole space. We show that the value 2 is optimal.	set packing;spaces	Konrad J. Swanepoel	2009	Discrete & Computational Geometry	10.1007/s00454-009-9189-8	functional analysis;mathematical optimization;combinatorics;topology;packing dimension;mathematics;sequence space;unit sphere;algebra	Theory	33.55485082041904	22.80686118048669	9115
f5777c986895cea7987e8c2a51075afe8fac82dd	multiscan-based test compression and hardware decompression using lz77	testing hardware very large scale integration costs automatic test pattern generation design automation system on a chip built in self test tellurium wire;integrated circuit testing vlsi automatic test pattern generation data compression boundary scan testing logic testing;data compression;hardware overhead cost multiscan based test compression hardware decompression lz77 data compression technique vlsi lzw bit strings don t cares lempel ziv welch algorithm uncompressed test sets atpg socs on chip boundary scan internal multiple scan chains;test data compression;automatic test pattern generation;boundary scan testing;chip;logic testing;integrated circuit testing;vlsi	In this paper we present a new test data compression technique andan associated decompression scheme for testing VLSI chips. Our method is based on our novel use of the much utilized in sof inre LZX particularly U 7 7 algorithm. We adapt LZ77 tu accommodate bit strings rather than character sets. Moreover; we exploit the large presence of Don't Cares in the uncompressed test sets that we generated using commercial ATPG tools. Our decompression scheme makes effective use of the on chip boundary scan during decompression and then feeding the internal multiple scan chains for testing. The hardware overhead cost for this scheme is minimal. Experimental results are provided.	algorithm;apple multiple scan 14 display;boundary scan;character encoding;data compression;lz77 and lz78;lzx (algorithm);overhead (computing);test compression;test data;very-large-scale integration	Francis G. Wolff;Christos A. Papachristou	2002		10.1109/TEST.2002.1041776	data compression;chip;embedded system;electronic engineering;scan chain;boundary scan;computer hardware;telecommunications;computer science;automatic test pattern generation;test compression;design for testing;very-large-scale integration;statistics	EDA	19.78231673695003	52.36598737764344	9119
5cbcd09424409bb849e7f4e04ff3570d19442b08	testability analysis for test generation in synchronous sequential circuits	synchronous generators;testability analysis tools;circuit faults;time measurement;sequential circuits;testability analysis tools testability analysis test generation synchronous sequential circuits stuck at faults sequential test generation sequential benchmark circuits;sequential analysis;testability analysis;fault location logic testing sequential circuits;circuit testing sequential analysis synchronous generators sequential circuits circuit faults electrical fault detection fault detection system testing integrated circuit testing time measurement;sequential benchmark circuits;sequential test;stuck at faults;synchronous sequential circuits;fault detection;logic testing;integrated circuit testing;system testing;test generation;decision process;circuit testing;high performance;electrical fault detection;sequential test generation;fault location	"""Duc to the compkxity of test generation for stuck-*-faults in synchronous sequential circuits and the pmblem-size, algorithms solving this p J L cannot d amptabl. CPU-time, even on computer systems with very high rm(ulgltly incrcaain tC#tability aDdy& COMiEtS Of W O technique for the detrction of u n t e r IC m k a w , hemintics used to guide the dechion process in test generation CPU-time for sequential test gene"""" &an ohex well-hown algolidlms. Expaimatal results of sr4uaati.l benchmark cimlita testability analysis tools."""	algorithm;benchmark (computing);central processing unit	R. Wolber;Uwe Gläser;Heinrich Theodor Vierhaus	1994		10.1109/ICCD.1994.331924	reliability engineering;electronic engineering;real-time computing;sequential analysis;test compression;sequential logic;system testing;fault detection and isolation;statistics;time	EDA	21.927364317397142	50.88668833619537	9122
5a899d78dbc8e80cdc766b117ff72405de62bf24	new insights on ling adders	microprocessors;topology;floating point unit;complexity theory;floating point units ling adders microprocessor design parallel prefix schemes prefix adder topology;ling adders;building block;adders logic gates topology complexity theory microprocessors multiplexing hardware;parallel prefix schemes;multiplexing;logic gates;adders;prefix adder topology;floating point units;microprocessor design;hardware	Adders are critical for microprocessor design. Current designs use variations of parallel prefix schemes. A method introduced by Ling [7] may improve this kind of adders. However, as recent research publications demonstrate, the use of the Ling scheme in prefix adders is not a mature and clear concept. In this work we show how to easily extend any existing prefix adder topology to use the Ling method. Moreover, we use this methodology to implement the Ling scheme in a flagged prefix adder, which is an interesting building block for floating point units.	binary prefix;carry-lookahead adder;ling adder;logical depth;microprocessor;prefix code;processor design;sparse matrix	Álvaro Vázquez;Elisardo Antelo	2008	2008 International Conference on Application-Specific Systems, Architectures and Processors	10.1109/ASAP.2008.4580183	floating-point unit;parallel computing;logic gate;computer science;theoretical computer science;algorithm;multiplexing;adder	EDA	14.693840547871243	45.98409401129959	9130
2bb47e5aa9bdb715d70fc757669d895ba6d562c5	fluid approach to two-sided reflected markov-modulated brownian motion	60j65;markov modulated linear fluid models;60b10;stationary distribution;reflected two sided markov modulated brownian motion;weak convergence;60j25	We extend to Markov-modulated Brownian motion (MMBM) the renewal approach which has been successfully applied to the analysis of Markov-modulated fluid models. It has been shown recently that MMBM may be expressed as the limit of a parameterized family of Markov-modulated fluid models. We prove that the weak convergence also holds for systems with two reflecting boundaries, one at zero and one at b > 0, and that the stationary distributions of the approximating fluid models converge to the stationary distribution of the two-sided reflected MMBM. In so doing, we obtain a new representation for the stationary distribution. It is factorised into a vector determined by the phase behaviour when the fluid is either at the level 0 or the level b, and a matrix expression characteristic of the process when the fluid is in the open interval (0, b).	brownian motion;converge;emoticon;markov chain;modulation;stationary process	Guy Latouche;Giang T. Nguyen	2015	Queueing Syst.	10.1007/s11134-014-9432-8	mathematical optimization;stationary distribution;mathematical analysis;calculus;mathematics;weak convergence;statistics	ML	43.50579468096424	12.197914859498534	9158
27eda151ba024a3540eb1a367a6d918d04552295	improving a probabilistic 3-sat algorithm by dynamic search and independent clause pairs	probleme satisfiabilite;logica booleana;satisfactoriabilidad;algoritmo busqueda;formule cnf;probleme np complet;algorithme recherche;search algorithm;logique propositionnelle;probabilistic approach;satisfiability;constraint satisfaction;satisfaction contrainte;formula cnf;propositional logic;random walk;enfoque probabilista;approche probabiliste;problema satisfactibilidad;logique booleenne;problema np completo;satisfaisabilite;satisfaccion restriccion;marcha aleatoria;conjunctive normal form;logica proposicional;boolean logic;satisfiability problem;marche aleatoire;np complete problem	The satisfiability problem of Boolean Formulae in 3-CNF (3-SAT) is a well known NP-complete problem and the development of faster (moderately exponential time) algorithms has received much interest in recent years. We show that the 3-SAT problem can be solved by a probabilistic algorithm in expected time O(1, 3290 n ). Our approach is based on Schoning's random walk algorithm for k-SAT, modified in two ways.	algorithm;boolean satisfiability problem	Sven Baumer;Rainer Schuler	2003	Electronic Colloquium on Computational Complexity (ECCC)	10.1007/978-3-540-24605-3_12	boolean algebra;conjunctive normal form;combinatorics;discrete mathematics;probabilistic analysis of algorithms;np-complete;constraint satisfaction;computer science;mathematics;propositional calculus;boolean satisfiability problem;random walk;algorithm;satisfiability;search algorithm	Theory	11.195765596147327	17.33993490278643	9161
203528595fe8871137e181b6161282d1ab400c3d	non-extendible latin parallelepipeds	combinatorial problems;non extendible latin parallelepiped;latin square;codes	We show that for each even mu003e2 and nu003e=4m-2, there exists a latin (nxnx(n-m))-parallelepiped that cannot be extended to a latin (nxnx(n-m+1))-parallelepiped.	extensibility	Martin Kochol	2012	Inf. Process. Lett.	10.1016/j.ipl.2012.08.014	combinatorics;latin square;mathematics;code;algorithm	DB	38.83359458311753	36.381012231870166	9174
f399c1b5b51f20ea35d0a9a02f35bf1253a41d09	turán numbers for forests of paths in hypergraphs	extremal;05c65;turan;hypergraphs;05c35;paths;hyperpaths;05d05	The Turán number of an r-uniform hypergraph H is the maximum number of edges in any r-graph on n vertices which does not contain H as a subgraph. Let P denote the family of r-uniform loose paths on edges, F(k, l) denote the family of hypergraphs consisting of k disjoint paths from P , and L (r) denote an r-uniform linear path on edges. We determine precisely exr(n;F(k, l)) and exr(n; k · L ), as well as the Turán numbers for forests of paths of differing lengths (whether these paths are loose or linear) when n is appropriately large dependent on k, l, r for r ≥ 3. Our results build on recent results of Füredi, Jiang, and Seiver, who determined the extremal numbers for individual paths, and provide more hypergraphs whose Turán numbers are exactly determined.	norm (social);turán number	Neal Bushaw;Nathan Kettle	2014	SIAM J. Discrete Math.	10.1137/130913833	combinatorics;discrete mathematics;constraint graph;mathematics;algorithm	Theory	30.38614887077971	27.95874526563293	9176
7f9ebdc7f6f3a071c1cc4d9abec9817da22d80a4	notes on fractional (1, f )-odd factors of graphs	necessary and sufficient condition;value function;fraction 1	Let G be a simple graph and f an odd integer-valued function defined on V (G). A spanning subgraph F of G is called a fractional (1, f)- odd factor if dF (v) ∈ {1, 3, . . . , f(v)} for all v ∈ V (G), where dF (v) is the fractional degree of v in F. In this paper, we discuss the existence for a graph to have a fractional (1, f)-odd-factor. A necessary and sufficient condition for a tree to have a fractional (1, f)-odd factor is given.		Jiguo Yu;Guizhen Liu	2007		10.1007/978-3-540-73814-5_30	combinatorics;calculus;mathematics;algebra	Vision	34.533188605033104	32.10294372960589	9182
fd6d3cc491ad0cc9e2d12005265fc568d1d20dcf	invention and creativity in automated design by means of genetic programming	automated design;creativity;genetic program;evolutionary computation;genetic programming;analog circuits	Some designs are sufficiently creative that they are considered to be inventions. The invention process is typically characterized by a singular moment when the prevailing thinking concerning a long-standing problem is, in a “flash of genius,” overthrown and replaced by a new approach that could not have been logically deduced from what was previously known. This paper discusses such logical discontinuities using an example based on the history of one of the most important inventions of the 20th century in electrical engineering, namely, the invention of negative feedback by AT&T’s Harold S. Black. This 1927 invention overthrew the then prevailing idiom of positive feedback championed by Westinghouse’s Edwin Howard Armstrong. The paper then shows how this historically important discovery can be readily replicated by an automated design and invention technique patterned after the evolutionary process in nature, namely, genetic programming. Genetic programming employs Darwinian natural selection along with analogs of recombination ~crossover!, mutation, gene duplication, gene deletion, and mechanisms of developmental biology to breed an ever improving population of structures. Genetic programming rediscovers negative feedback by conducting an evolutionary search for a structure that satisfies Black’s stated high-level goal ~i.e., reduction of distortion in amplifiers!. Like evolution in nature, genetic programming conducts its search probabilistically without resort to logic using a process that is replete with logical discontinuities. The paper then shows that genetic programming can routinely produce many additional inventive and creative results. In this regard, the paper discusses the automated rediscovery of numerous 20th-century patented inventions involving analog electrical circuits and controllers, the Sallen–Key filter, and six 21st-century patented inventions. In addition, two patentable new inventions ~controllers! have been created in the same automated way by means of genetic programming. The paper discusses the promising future of automated invention by means of genetic programming in light of the fact that, to date, increased computer power has yielded progressively more substantial results, including numerous human-competitive results, in synchrony with Moore’s law. The paper argues that evolutionary search by means of genetic programming is a promising approach for achieving creative, human-competitive, automated design because illogic and creativity are inherent in the evolu-	armstrong's axioms;distortion;electrical engineering;genetic programming;high- and low-level;moore's law;negative feedback;positive feedback;power supply unit (computer);sallen–key topology;westi	John R. Koza;Martin A. Keane;Matthew J. Streeter;Thomas P. Adams;Lee W. Jones	2004	AI EDAM	10.1017/S089006040404017X	evolutionary programming;genetic programming;analogue electronics;computer science;engineering;artificial intelligence;genetic representation;creativity;algorithm;evolutionary computation;mechanical engineering	AI	7.219494098483274	36.57075033057056	9184
f0ccc700487113fb39a815d8bbc680f1d9af54ec	on the list decodability of burst errors	decoding;geometry;reed solomon codes;linear codes;indexes;redundancy;cyclic codes data communications data storage channels phased burst error single burst error random codes burst list decoding radius singleton bound gilbert varshamov bound algebraic geometry codes;random codes algebraic geometric codes channel coding cyclic codes decoding;phased burst errors algebraic geometry codes burst errors cyclic codes list decoding;decoding linear codes geometry reed solomon codes indexes redundancy	Burst errors are a type of distortion in many data communications and data storage channels. In this paper, we consider the list decodability of codes for single burst error case and phased-burst error case independently. Firstly, we analyze the list decodability of random codes, and we show that the burst list decoding radius and the rate of random codes achieve the Singleton bound and the Gilbert-Varshamov bound for single case and phased case, respectively. Second, we illustrate that cyclic codes and algebraic geometry codes are good burst list-decodable codes for single case and phased case, respectively.	adversary (cryptography);burst error;code;computer data storage;distortion;gilbert cell;gilbert–varshamov bound;linear algebra;list decoding;singleton bound	Yang Ding	2016	IEEE Transactions on Information Theory	10.1109/TIT.2015.2513046	block code;reed–muller code;list decoding;database index;concatenated error correction code;turbo code;combinatorics;discrete mathematics;online codes;burst error-correcting code;sequential decoding;theoretical computer science;serial concatenated convolutional codes;bcjr algorithm;tornado code;linear code;hamming code;expander code;luby transform code;mathematics;forward error correction;redundancy;raptor code;berlekamp–welch algorithm;error floor;reed–solomon error correction	Theory	40.09289788777752	57.42691736336743	9185
2fe68f6da4e7cba7cb9ffe6e3dae10266cd526b7	spc: synthesis of pointers in c: application of pointer analysis to the behavioral synthesis from c	pointer analysis;behavioral synthesis;power dissipation;combinational circuits;signal integrity;asic	As designers may model mixed software-hardware systems using a subset of C or C++, we present SpC, a solution to synthesize and optimize a C model with pointers. In hardware, a pointer is not only the address of data in memory, but it may also reference multiple variables mapped to registers, ports or wires. Pointer analysis is used to find the point-to-set of each pointer in the program. In this paper, we address the problem of synthesizing and optimizing pointers to multiple variables and array elements. Temporary variables are defined to optimize loads and stores by minimizing the number of live variables. The combinational logic can also be reduced by encoding the pointers values. An implementation using the SUIF framework is presented, followed by some case studies such as the synthesis of a 2D IDCT.	c++;combinational logic;discrete cosine transform;high-level synthesis;pointer (computer programming);pointer analysis;processor register	Luc Séméria;Giovanni De Micheli	1998		10.1109/ICCAD.1998.742894	embedded system;opaque pointer;computer architecture;electronic engineering;parallel computing;real-time computing;pointer;computer science;signal integrity;dissipation;operating system;escape analysis;pointer swizzling;application-specific integrated circuit;tagged pointer;combinational logic;c dynamic memory allocation;programming language;pointer analysis;algorithm;pointer aliasing;smart pointer	EDA	-1.7812295693719145	52.58136574729865	9194
d1b604fd38adf201d924c77d9f28c45b2cf797a0	new tsp construction heuristics and their relationships to the 2-opt	traveling salesman problem;2 opt dependency;construction heuristic;edge exchange heuristic	Correction heuristics for the traveling salesman problem (TSP), with the 2-Opt applied as a postprocess, are studied with respect to their tour lengths and computation times. This study analyzes the ’’2-Opt dependency,‘‘ which indicates how the performance of the 2-Opt depends on the initial tours built by the construction heuristics. In accordance with the analysis, we devise a new construction heuristic, the recursive-selection with long-edge preference (RSL) method, which runs faster than the multiple-fragment method and produces a comparable tour when they are combined with the 2-Opt.	heuristic (computer science)	Hiroyuki Okano;Shinji Misono;Kazuo Iwano	1999	J. Heuristics	10.1023/A:1009695129052	mathematical optimization;computer science;lin–kernighan heuristic;machine learning;mathematics;travelling salesman problem;algorithm	AI	23.30923027032547	6.5874537600234255	9213
265a3b981aab52312e176aa405e2b37f971c5d5b	on the permutation capacity of digraphs	natural extension;directed graph;information theory	We extend several results of the third author and C. Malvenuto on graph– different permutations to the case of directed graphs and introduce new open problems. Permutation capacity is a natural extension of Sperner capacity from finite directed graphs to infinite digraphs. Our subject is combinatorial in nature, but can be equally regarded as zero–error information theory. ∗Department of Computer Science, University of Rome, La Sapienza, via Salaria 113, 00198 Rome, ITALY	computer science;directed graph;information theory;linear algebra	Gérard D. Cohen;Emanuela Fachini;János Körner	2008	CoRR		combinatorics;discrete mathematics;directed graph;information theory;permutation graph;mathematics	Theory	34.07594101735162	27.721341671997425	9214
7b59932e40fa1d699e3bb1db55744866e8bedcb7	minimization of chip size and power consumption of high-speed vlsi buffers	floorplanning;very large scale integration;vlsi design;chip;upper bound;heuristic search;slicible floorplans;optimal design;power consumption;planar graphs;graph dualization;constrained optimization problem;high performance;nonslicible floorplans;high speed	In this paper, we study optimal bu er design in high-performance VLSI systems. Speci cally, we design a bu er for a given load such that chip area and power dissipation are minimal while circuit delay is no greater than a given upper bound. The explored direction, i.e., to minimize chip area and power consumption with circuit speed as a constraint, is a more realistic setting in practical VLSI design than conventional design objectives, where minimal circuit delay is usually sought. In fact, an optimal design must achieve an expected circuit speed with minimal system resources: chip area and power consumption. By solving the formulated constrained optimization problem, signi cant improvements in chip area and power consumption are achieved.	constrained optimization;constraint (mathematics);mathematical optimization;optimal design;optimization problem;very-large-scale integration	Dengji Zhou;X. Y. Liu	1997		10.1145/267665.267711	mathematical optimization;combinatorics;heuristic;mathematics;very-large-scale integration	EDA	16.521497721150286	51.620128794658854	9246
b628fce0ad1f005dfac028e9037448e5fe82e5d2	ergodicity and symmetric mathematical programs	economic model;nonnegative matrices;mathematical programming;stochastic matrices	The paper provides new conditions ensuring the optimality of a symmetric feasible point of certain mathematical programs. It is shown that these conditions generalize and unify most of the known results dealing with optimality of symmetric policies (e.g. [2, 4, 6, 11]). The generalization is based on certain ergodic properties of nonnegative matrices. An application to a socio-economic model dealing with optimization of a welfare function is presented.	ergodicity	Arie Tamir	1977	Math. Program.	10.1007/BF01584325	mathematical optimization;combinatorics;discrete mathematics;economic model;mathematics	Theory	35.59139852108065	5.138923606530647	9248
4b10a91fd1446e54ff46de73209d3f5ba036af8a	transducers with programmable input by dna self-assembly	self assembly;finite state machine;wang tile	  Notions of Wang tiles, finite state machines and recursive functions are tied together. We show that there is a natural way  to simulate finite state machines with output (transducers) with Wang tiles and we show that recursive (computable) functions  can be obtained as composition of transducers through employing Wang tiles. We also show how a programmable transducer can  be self-assembled using TX DNA molecules simulating Wang tiles and a linear array of DNA PX-JX2 nanodevices.    	self-assembly;transducer	Natasa Jonoska;Shiping Liao;Nadrian C. Seeman	2004		10.1007/978-3-540-24635-0_16	discrete mathematics;wang tile;self-assembly;recursion;finite-state machine;macrocell array;cellular automaton;transducer;mathematics	Theory	1.361153357248842	24.188360685008668	9255
b9c621936527279be9c9ea242a20bb8fe0213175	a distributed exact algorithm for the multiple resource constrained sequencing problem	traveling salesman problem;resource constraint;cutting plane;branch and bound algorithm;exact algorithm;network of workstation;linear programming relaxation;process scheduling;lower bound	Sequencing problems arise in the context of process scheduling both in isolation and as subproblems for general scenarios. Such sequencing problems can often be posed as an extension of the Traveling Salesman Problem. We present an exact parallel branch and bound algorithm for solving the Multiple Resource Constrained Traveling Salesman Problem (MRCTSP), which provides a platform for addressing a variety of process sequencing problems. The algorithm is based on a linear programming relaxation that incorporates two families of inequalities via cutting plane techniques. Computational results show that the lower bounds provided by this method are strong for the types of problem generators that we considered as well as for some industrially derived sequencing instances. The branch and bound algorithm is parallelized using the processor workshop model on a network of workstations connected via Ethernet. Results are presented for instances with up to 75 cities, 3 resource constraints, and 8 workstations.	exact algorithm	Gautham K. Kudva;Joseph F. Pekny	1993	Annals OR	10.1007/BF02023171	2-opt;mathematical optimization;combinatorics;computer science;linear programming relaxation;mathematics;distributed computing;upper and lower bounds;travelling salesman problem;scheduling;branch and bound;3-opt;branch and cut;bottleneck traveling salesman problem;cutting-plane method	Robotics	21.173935945293955	9.119780791622608	9261
11c74535777f90bb60af06eb054e56903b4c0102	restarted iterated pareto greedy algorithm for multi-objective flowshop scheduling problems	multiobjective programming;optimum pareto;programmation multiobjectif;multiobjective optimisation;multi objective optimisation;tiempo total acabamiento;test statistique;production engineering;methode empirique;gestion production;algorithme glouton;gestion poblacion;pareto front;articulo;test estadistico;metodo empirico;multi objective;empirical method;flowshop;temps total achevement;statistical test;permutation flow shops;flow shop problems;greedy algorithms;production management;permutation;busca local;flow time;flow shop scheduling problem;scheduling algorithms;flow shops;makespan;pareto principle;scheduling;gestion produccion;gestion population;multi objective problem;iterated greedy;permutacion;retard;population management;scheduling problem;greedy algorithm;statistical tests;algoritmo gloton;multiobjective optimization;graphical tools;production scheduling;operations management;retraso;atelier monogamme;pareto optimum;impulse;local search;optimo pareto;ordonnancement;recherche locale;flow shop;reglamento;impulsion;greedy method;programacion multiobjetivo	Multi-objective optimisation problems have seen a large impulse in the last decades. Many new techniques for solving distinct variants of multi-objective problems have been proposed. Production scheduling, as with other operations management elds, is no di erent. The owshop problem is among the most widely studied scheduling settings. Recently, the Iterated Greedy methodology for solving the single-objective version of the owshop problem has produced state-of-the-art results. This paper proposes a new algorithm based on Iterated Greedy technique for solving the multiobjective permutation owshop problem. This algorithm is characterised by an e ective initialisation of the population, management of the Pareto front, and a specially tailored local search, among other things. The proposed multi-objective Iterated Greedy method is shown to outperform other recent approaches in comprehensive computational and statistical tests that comprise a large number of instances with objectives involving makespan, tardiness and owtime. Lastly, we use a novel graphical tool to compare performances of stochastic Pareto fronts based on Empirical Attainment Functions.	algorithm engineering;computation;enterprise architecture framework;experiment;greedy algorithm;iterated function;local search (optimization);makespan;mathematical optimization;pareto efficiency;performance;relevance;scheduling (computing)	Gerardo Minella;Rubén Ruiz;Michele Ciavotta	2011	Computers & OR	10.1016/j.cor.2011.01.010	job shop scheduling;mathematical optimization;greedy algorithm;computer science;mathematics;algorithm	AI	20.25484758136143	6.085489425780661	9266
3d28dd2d85a5c78e96e6fd42009d7b5788d06817	can a randomized binary search have an o(1) complexity at least in practice?	analisis numerico;nombre entier;matematicas aplicadas;mathematiques appliquees;loi probabilite;ley probabilidad;empirical o 1 complexity;analyse numerique;randomized binary search;integer;numerical analysis;probability distribution;entero;binary search;empirical 0 1 complexity;applied mathematics	The note suggests the possibility for a randomized binary search to have an O(1) complexity at least in practice provided only that the element being searched for is a random integer less than or equal to the array size and hence or otherwise when the probability of its presence in the array is a near unity.	binary search algorithm;randomized algorithm	Soubhik Chakraborty	2007	Applied Mathematics and Computation	10.1016/j.amc.2006.12.079	integer;probability distribution;combinatorics;applied mathematics;numerical analysis;mathematics;algorithm;statistics;binary search algorithm;algebra	Theory	14.822152670573814	22.882087218945873	9278
0e3574753e0c3e9a6b0a62be0c916b7dfc837d8b	from cages to trapping sets: a new technique to derive tight upper bounds on the minimum size of trapping sets and minimum distance of ldpc codes		Cages, defined as regular graphs with minimum number of nodes for a given girth, are well-studied in graph theory. Trapping sets are graphical structures responsible for error floor of low-density parity-check (LDPC) codes, and are well investigated in coding theory. In this paper, we make connections between cages and trapping sets. In particular, starting from a cage (or a modified cage), we construct a trapping set in multiple steps. Based on the connection between cages and trapping sets, we then use the available results in graph theory on cages and derive tight upper bounds on the size of the smallest trapping sets for variable-regular LDPC codes with a given variable degree and girth. The derived upper bounds in many cases meet the best known lower bounds and thus provide the actual size of the smallest trapping sets. Considering that nonzero codewords are a special case of trapping sets, we also derive tight upper bounds on the minimum weight of such codewords, i.e., the minimum distance, of variable-regular LDPC codes as a function of variable degree and girth.	code word;coding theory;error floor;girth (graph theory);graph theory;low-density parity-check code;minimum weight	Ali Dehghan;Amir H. Banihashemi	2018	2018 IEEE International Symposium on Information Theory (ISIT)	10.1109/ISIT.2018.8437465	error floor;combinatorics;graph theory;discrete mathematics;mathematics;low-density parity-check code;special case;cage;minimum weight;coding theory;graph	Theory	39.321290135260845	53.486257569242554	9281
1b209810b63d463aa96c6a9f2108bfbfa4c21b49	on 2-factors containing 1-factors in bipartite graphs	bipartite graph	Moon and Moser (Israel J. Math. 1 (1962) 163-165) showed that if G is a balanced bipartite graph of order 2n and minimum degree 0>~(n + 1)/2, then G is hamiltonian. Recently, it was shown that their well-known degree condition also implies the existence of a 2-factor with exactly k cycles provided n~> max{52,2k -~ + 1}. In this paper, we show that a similar degree condition implies that for each perfect matching M, there exists a 2-factor with exactly k cycles including all edges of M. @ 1999 Published by Elsevier Science B.V. All rights reserved	graph factorization;hamiltonian (quantum mechanics);matching (graph theory);moser spindle	Guantao Chen;Ronald J. Gould;Michael S. Jacobson	1999	Discrete Mathematics	10.1016/S0012-365X(99)90061-4	edge-transitive graph;combinatorics;discrete mathematics;topology;bipartite graph;degree;frequency partition of a graph;mathematics;biregular graph	Theory	29.982825924131742	30.621783816372535	9283
d9c144967a03d650c60cf432b474dc672b4221ce	global scheduling independent of control dependencies based on condition vectors	circuit analysis computing;finite state machines;resource allocation;scheduling;circuit analysis computing;condition vectors;control dependencies;finite state machine controller;global parallelism;global scheduling;parallel individual control sequences;semantics	This paper presents a global scheduling method based on condition vectors. The proposed method exploits a more “global parallelism”. That is, it can parallelize multiple nests of conditional branches and optimize across the boundaries of basic blocks thoroughly, and so on. Moreover, it can optimize all possible execution paths. Also proposed is an algorithm which generates a single finite state machine cent roller from parallel individu aJ cent rol sequences derived in the global parallelization process. Experimental results proves that the global parallelization is markedly effective.	algorithm;basic block;courant–friedrichs–lewy condition;dependence analysis;finite-state machine;parallel computing;schedule (project management);scheduling (computing)	Kazutoshi Wakabayashi;Hirohito Tanaka	1992			fair-share scheduling;embedded system;mathematical optimization;real-time computing;dynamic priority scheduling;resource allocation;computer science;theoretical computer science;operating system;distributed computing;finite-state machine;programming language;scheduling;algorithm	HPC	-2.5046990034702272	52.05978016699527	9298
46b7012d59651dffb02e0a83d5c9399ac3ceb25d	ant colony optimization for symmetrical fpga placement	digital circuit;field programmable gate array;symmetrical fpga placement;optimisation;design automation;ant colony optimization;routing;routing congestion;optimisation digital circuits field programmable gate arrays network routing;aco;data mining;network routing;routing channel density;logic gates;place and route;routing channel density symmetrical fpga placement field programmable gate array aco ant colony optimization digital circuit routing congestion;ant colony optimization field programmable gate arrays routing digital circuits logic circuits computer science algorithm design and analysis wire costs prototypes;field programmable gate arrays;digital circuits;algorithm design and analysis	Field programmable gate arrays (FPGAs) are becoming increasingly important implementation platforms for digital circuits. This paper presents a method for symmetrical FPGA placement based on ant colony optimazation (ACO). Also, we take the routing congestion into consideration by introducing a congestion factor in our algorithm. Experimental results show that compared with the state-of-the-art FPGA place and route tool VPR, ACO algorithm achieves promising performance, in terms of routing channel density.	algorithm;ant colony optimization algorithms;digital electronics;field-programmable gate array;mathematical optimization;network congestion;place and route;routing	Kai Wang;Ning Xu	2009	2009 11th IEEE International Conference on Computer-Aided Design and Computer Graphics	10.1109/CADCG.2009.5246838	embedded system;routing;electronic engineering;electronic design automation;computer science;engineering;electrical engineering;theoretical computer science;digital electronics;field-programmable gate array	EDA	14.090186295345132	52.81309450376888	9305
0245094eeae2c3e4e29dbe048176d823cf29750a	programmable parallel arithmetic in cellular automata using a particle model		A bst ract. In thi s paper we show how to embed practical computat ion in one-dimensional cellular automata using a model of computation based on collisions of moving part icles. T he cellular automata have small neighbo rhoods, and state spaces that are bin ary occupancy vecto rs. They can be fabricated in VLSI, and perh aps also in bulk media tha t support appropriate part icle propagation and collisions . The model uses injected part icles to repr esent both data and processors. Consequently, realizations are highly programm able and do not have applicat ion-specific topology, in contras t to systolic arrays . We describe several practical calculations that can be carr ied out in a highly par allel way in a single cellular automaton, including addit ion, subt raction, multipli cat ion , arbit rarily nested combinat ions of these opera t ions, and finite-impulse-response digital filtering of a signal arriving in a cont inuous st ream. T hese are all accomplished in t ime linear in the number of inpu t bits, and wit h fixed-point arithmet ic of arbitrary precision , independent of the har dware.	arbitrary-precision arithmetic;automata theory;biochemical systems theory;carr–benkler wager;cellular automaton;central processing unit;finite impulse response;model of computation;software propagation;unit propagation;very-large-scale integration	Richard K. Squier;Kenneth Steiglitz	1994	Complex Systems		quantum cellular automaton;stochastic cellular automaton;mathematics;discrete mathematics;asynchronous cellular automaton;theoretical computer science;cellular automaton;continuous spatial automaton;quantum dot cellular automaton;arbitrary-precision arithmetic;mobile automaton;arithmetic	Theory	18.234690852304286	42.15849824765479	9306
6f97568ae9621a6250770ebfb53a52c6acda84ef	the gigahertz fpga: design consideration and applications	building block;simulation;reactions;cell;biology;chip;clock distribution;large scale;high speed;reconfigurable hardware	This paper describes the implementation of a large scale SiGe FPGA that serves as a high speed FPGA test platform. In the FPGA core, 20 x 20 building blocks (Basic Cells) are used to implement logic applications. This chip contains 106 devices including SiGe NPNs and MOSFETs. This chip is fabricating with the IBM SiGe 7HP process with cut off frequency of 120GHz. The target running frequency of this FPGA is 10GHz. Clock repeaters are added for improved clock distribution. A test circuit whose building block cell runs up to 10GHz is fabricated and measured by the same process. Future work and some potential applications of the SiGe FPGA are also described.	field-programmable gate array;silicon-germanium	Jong-Ru Guo;Chao You;Michael Chu;Robert W. Heikaus;Kuan Zhou;Okan Erdogan;Jiedong Diao;Bryan S. Goda;Russell P. Kraft;John F. McDonald	2004		10.1145/968280.968326	chip;cell;embedded system;parallel computing;real-time computing;chemical reaction;reconfigurable computing;computer science;fpga prototype	EDA	13.470498325730677	56.86217904528767	9323
c1a007245dbc6208a256af1abd76971f5b511847	a hardware acceleration platform for digital holographic imaging	frames per second;elektroteknik och elektronik;flexible fft;matrix transpose;digital holography;hardware accelerator;chip;burst oriented memory;image reconstruction;hybrid floating point;floating point;digital image;external memory;reconstruction algorithm;computational efficiency;data scaling	This paper presents a hardware acceleration platform for image reconstruction in digital holographic imaging. The hardware accelerator executes a computationally demanding reconstruction algorithm which transforms an interference pattern captured on a digital image sensor into visible images. Focus in this work is to maximize computational efficiency, and to minimize the external memory transfer overhead, as well as required internal buffering. The paper presents an efficient processing datapath with a fast transpose unit and an interleaved memory storage scheme. The proposed architecture results in a speedup with a factor 3 compared with the traditional column/row approach for calculating the two-dimensional FFT. Memory sharing between the computational units reduces the on-chip memory requirements with over 50%. The custom hardware accelerator, extended with a microprocessor and a memory controller, has been implemented on a custom designed FPGA platform and integrated in a holographic microscope to reconstruct images. The proposed architecture targeting a 0.13 µm CMOS standard cell library achieves real-time image reconstruction with 20 frames per second.	hardware acceleration;holography	Thomas Lenart;Mats Gustafsson;Viktor Öwall	2008	Signal Processing Systems	10.1007/s11265-008-0161-2	iterative reconstruction;chip;embedded system;parallel computing;hardware acceleration;computer hardware;computer science;floating point;theoretical computer science;operating system;frame rate;digital image;transpose	EDA	11.063317805516215	40.12334478457978	9324
3cf3570e23522cb816f82e0a56146313e1fdc0b8	searching a polygonal region from the boundary	theoretical computer science;computational mathematics;pursuit evasion;search;polygonal region;visibility;computational theory and mathematics;geometry and topology;applied mathematics	Polygon search is the problem of nding unpredictable mobile intruders in a polygonal region using one or more mobile searchers with various levels of vision, where both the searcher and intruders are allowed to move freely within the region. In this paper we consider a variant of this problem, termed boundary search, in which a single searcher has to nd the intruders from the boundary of the region. Our main result is that the searcher having one ashlight whose vision is limited to a single ray is just as capable as the searcher having a light bulb that gives 360 vision, that is, any polygon that can be searched by the latter from the boundary can also be searched by the former from the boundary. To our knowledge, the equivalence of these searchers, one having a very limited vision and another having the maximum vision, has never been established for any interesting subclass of the polygon search problem. The proof of the equivalence uses another new result, termed Monotonic Extension Theorem, together with a simple topological argument on a 2-dimensional map called p-map that represents the searcher's state during search. A similar topo-logical argument is used also to partially settle a long-standing conjecture on 1 the equivalence of the abilities of two searchers, one having two ashlights and another having full 360 vision, for the general, non-boundary polygon search problem.	search problem;topo;turing completeness	Ichiro Suzuki;Yuichi Tazoe;Masafumi Yamashita;Tiko Kameda	2001	Int. J. Comput. Geometry Appl.	10.1142/S0218195901000638	combinatorics;visibility polygon;numerical analysis;visibility;mathematics;geometry;geometry and topology;algorithm	Vision	31.896021293079034	18.785074096255514	9334
005506898b20fb208b7123a77adbc103f858095c	analogues of the central point theorem for families with d-intersection property in ℝ d	grupo de excelencia;ciencias basicas y experimentales;matematicas;convex set	In this paper we consider families of compact convex sets in R such that any subfamily of size at most d has a nonempty intersection. We prove some analogues of the central point theorem and Tverberg’s theorem for such families.	convex set	Roman N. Karasev	2012	Combinatorica	10.1007/s00493-012-2603-5	combinatorics;mathematical analysis;krein–milman theorem;topology;danskin's theorem;radon's theorem;mathematics;geometry;convex set	Theory	41.39798286802386	27.308459262076262	9338
3a5554fe34de259d82227b27ea773ac97e6c2f89	fast approximation algorithms for fractional packing and covering problems	multicommodity flow;approximate algorithm;approximation algorithms;fractional covering;operations research;approximation algorithms job shop scheduling lagrangian functions parallel machines linear programming algorithm design and analysis cost function contracts uninterruptible power systems sun;approximation theory;general methods;theoretical analysis;computational complexity;approximate solution;fast algorithm;running time fractional covering approximation algorithms fractional packing linear programming multicommodity flow problems lagrangian relaxation;linear programming;linear program;running time;technical report;covering problem;fractional packing;multicommodity flow problems;industrial engineering;operations research approximation theory computational complexity linear programming;lagrangian relaxation	Thii paper presents fast algorithms that find approximate solutions for a general class of problems, which we call fractional packing and covering problems. The only previously known algorithms for solving these problems are based on general linear programming techniiues. The techniques developed in this paper greatly outperform the general methods in many applications, and are extensions of a method previously applied to find approximate solutions to multicommodity flow problems [23,15,18]. Our algorithm is a Lagrangean relaxation technique; an important aspect of our results is that we obtain a theoretical analysis of the running time of a Lagrangean relaxation-based algorithm. We give several applications of our algorithms. The new approach yields several orders of magnitude of improvement over the best previously known running times for the scheduling of unrelated parallel machines in both the preemptive and the non-preemptive models, for the job shop problem, for the cutting-stock problem, and for the minimum-cost multicommodity flow problem. *Research supported by NSF Research Initiation Award CCR-900-8226, by U.S. Army Research Office Grant DAAL-03-91G-0102, by ONR Contract N00014-8~K-0166, and by a grant from Mitsubishi Electric Laboratories. + Research partially supported by an NSF PYI award CCR-89-96272 with matching support from UPS, and Sun Microsystems, and by the National Science Foundation, the Air Force Office of Scientific Research, and the Ofike of Naval Research, through NSF grant DMS-8920550. $Research supported in part by a Packard Research Fellowship and by the National Science Foundation, the Air Force Office of Scientific Research, and the Office of Naval Research, through NSF grant DMS-8920550.	approximation algorithm;covering problems;cutting stock problem;flow network;ibm notes;job shop scheduling;lagrangian relaxation;linear programming relaxation;scheduling (computing);set packing;time complexity;uninterruptible power supply	Serge A. Plotkin;David B. Shmoys;Éva Tardos	1991		10.1109/SFCS.1991.185411	mathematical optimization;combinatorics;discrete mathematics;lagrangian relaxation;multi-commodity flow problem;covering problems;computer science;linear programming;technical report;mathematics;computational complexity theory;approximation algorithm;approximation theory	Theory	19.45398031556127	14.220659419262095	9340
2d92ac550d38eaf92d2df52c77d184bc27a9842c	classical and quantum evaluation codes at the trace roots		We introduce a new class of evaluation linear codes by evaluating polynomials at the roots of a suitable trace function. We give conditions for self-orthogonality of these codes and their subfield-subcodes with respect to the Hermitian inner product. They allow us to construct stabilizer quantum codes over several finite fields which substantially improve the codes in the literature and that are records at [http://www.codetables.de] for the binary case. Moreover, we obtain several classical linear codes over the field $\mathbb{F}_4$ which are records at [http://www.codetables.de].	linear code;polynomial;quantum;roots	Carlos Galindo;Fernando Hernando;Diego Ruano	2017	CoRR		trace (linear algebra);discrete mathematics;hermitian matrix;quantum computer;pure mathematics;polynomial;binary number;quantum;finite field;mathematics	Theory	41.292137278590566	53.80269365654344	9347
36f10df449abe0502f263666191010696ff60d47	disjoint-path facility location: theory and practice		This paper is a theoretical and experimental study of two related facility location problems that emanated from networking. Suppose we are given a network modeled as a directed graph G = (V,A), together with (not-necessarily-disjoint) subsets C and F of V , where C is a set of customer locations and F is a set of potential facility locations (and typically C ⊆ F ). Our goal is to find a minimum sized subset F ′ ⊆ F such that for every customer c ∈ C there are two locations f1, f2 ∈ F ′ such that traffic from c to f1 and to f2 is routed on disjoint paths (usually shortest paths) under the network’s routing protocols. Although we prove that this problem is impossible to approximate in the worst case even to within a factor of 2log 1−ǫ n for any ǫ > 0 (assuming no NP-complete language can be solved in quasipolynomial time), we show that the situation is much better in practice. We propose three algorithms that build solutions and determine lower bounds on the optimum solution, and evaluate them on several large real ISP topologies and on synthetic networks designed to reflect real-world LAN/WAN network structure. Our main algorithms are (1) an algorithm that performs multiple runs of a straightforward randomized greedy heuristic and returns the best result found, (2) a genetic algorithm that uses the greedy algorithm as a subroutine, and (3) a new “Double Hitting Set” algorithm. All three approaches perform surprising well, although, in practice, the most cost-effective approach is the multi-run greedy algorithm. This yields results that average within 0.7% of optimal for our synthetic instances and within 2.9% for our real-world instances, excluding the largest (and most realistic) one. For the latter instance, the other two algorithms come into their own, finding solutions that are more than three times better than those of the multi-start greedy approach. In terms of our motivating monitoring application, where every customer location can be a facility location, the results are even better. Here the above Double Hitting Set solution is 90% better than the default solution which places a monitor at each customer location – such comparisons help justify the proposed alternative monitoring scheme of [8]. Our results also show that, on average for our real-world instances, we could save an additional 18% by choosing the (shortest path) routes ourselves, rather than taking the simpler approach of relying on the network to choose them for us. AT&T Labs – Research, 180 Park Avenue, Florham Park, NJ 07932. Computer Science Department, University of California, Soda Hall, Berkeley, CA 94720. This work was performed when the author was a student at Columbia University, and was partially supported by AT&T. Amazon Web Services, 1200 12th Avenue South, Seattle, WA 98144. This work was performed when the author was a student at the University of Massachusetts, and was partially supported by AT&T.	amazon web services;approximation algorithm;bsd;best, worst and average case;columbia (supercomputer);computer science;dhrystone;directed graph;experiment;facility location problem;genetic algorithm;greedy algorithm;heuristic;np-completeness;quasi-polynomial;randomized algorithm;routing;set cover problem;shortest path problem;subroutine;synthetic intelligence;web service	Lee Breslau;Ilias Diakonikolas;Nick G. Duffield;Yu Gu;Mohammad Taghi Hajiaghayi;David S. Johnson;Howard J. Karloff;Mauricio G. C. Resende;Subhabrata Sen	2011		10.1137/1.9781611972917.7	mathematical optimization;combinatorics;machine learning;mathematics;algorithm	Theory	22.27285161880632	18.6351532656754	9358
35af4b15d9e078bfa2051e0d5e756e4febd87c52	conscep: a configurable soc emulation platform for c-based fast prototyping	c to hardware;fpga emulation;high level synthesis;soc verification	FPGA-based emulation, which is now widely used in the design and verification of System-on-a-Chip (SoC), is applicable only when the RTL design for the whole system is available, thus resulting in a long design turn-around time. In this paper, we present a new design flow based on a C-to-hardware IMPLEmentation tool (CIMPLE) and a CONfigurable SoC Emulation Platform (CONSCEP) that emulates the on-chip bus system prior to the RTL design of each SoC component. With the emulation environment set up in the early stage of the design process, the design and verification task of each functional block in the SoC can be performed not only faster, but also more complete as a more complete set of test vectors can be applied before the integration. CONSCEP consists of (1) configurable bus components for the given on-chip bus standard and (2) a set of transactors to link the HDL models of the pre-verified IP blocks with the C models for the behavioral blocks to be designed, or software blocks. CIMPLE translates the C model for a hardware module to a SystemC code, which can be synthesized and directly attached to the CONSCEP as an IP. CIMPLE allows global variables, nested function calls, and simple pointer access, which significantly reduces the code migration. The proposed design flow is demonstrated using a JPEG encoder/decoder system and successfully applied to a commercial MPEG4 video codec chip.	cimple;codec;design flow (eda);emulator;encoder;field-programmable gate array;global variable;hardware description language;jpeg;pointer (computer programming);register-transfer level;system on a chip;systemc;verification and validation	Woo-Seung Yang;Chong-Min Kyung	2005	Journal of Circuits, Systems, and Computers	10.1142/S0218126605002210	embedded system;computer architecture;real-time computing;computer science;operating system;high-level synthesis;fpga prototype;hardware emulation	EDA	3.631266131658282	51.18877510885748	9362
ece664ce0cadd52ae4dde82b0fd2015baf0e51c7	on some classes of linear spaces embedded in a pappian plane	linear space	Abstract   We deal with the following problem. Let   L   be a suitable finite linear space embedded in a Pappian plane   P   and suppose that   L   is embeddable in a finite projective plane π′ of order  n . It is true that a finite subplane π of   P   isomorphic to π′ containing   L   exists?	embedded system	Paola De Vito;Pia Maria Lo Re	1994	Discrete Mathematics	10.1016/0012-365X(92)00504-K	fano plane;discrete mathematics;topology;mathematics;geometry;linear space	Theory	36.87883657239052	26.668289503828447	9363
b9256ac6a78a28cfb63e7f221632a9afccfcf791	bounds on the number of maximal sum-free sets	upper bound	We show that the number of maximal sum-free subsets of {1,2,...,n} is at most 2^3^n^/^8^+^o^(^n^). We also show that 2^0^.^4^0^6^n^+^o^(^n^) is an upper bound on the number of maximal product-free subsets of any group of order n.	maximal set	Guy Wolfovitz	2009	Eur. J. Comb.	10.1016/j.ejc.2009.03.015	combinatorics;mathematical analysis;discrete mathematics;mathematics;upper and lower bounds	Theory	37.10176449135168	31.160337941681178	9375
136cb989fb0bac74c5dc815de00b86bfe05cd6cc	efficient music retrieval systems design based on reconfigurable hardware	music retrieval;approximate string matching;hardware software codesign;field programmable gate array fpga	A novel ̄eld programmable gate array implementation of content-based music retrieval system is presented in this paper. The system adopts a novel hardware architecture for approximate string matching. The architecture is based on a simple shift-and-or algorithm. It has the advantages of low area cost and high throughput. Numerical results show that the proposed architecture has signi ̄cantly lower CPU time over its software counterpart running on Pentium IV for large database and/or edit distances.	approximate string matching;bitap algorithm;central processing unit;edit distance;field-programmable gate array;string searching algorithm;systems design;throughput	Chien-Min Ou	2011	Journal of Circuits, Systems, and Computers	10.1142/S0218126611007694	embedded system;parallel computing;real-time computing;approximate string matching;computer science;operating system;hardware architecture	Arch	6.30366621039219	44.94512138426123	9386
b3234d5d6420e0ad55ff22ad7b241a9ff964bdab	remarks on blind and partially blind one-way multicounter machines		We consider one-way nondeterministic machines which have counters allowed to hold positive or negative integers and which accept by final state with all counters zero. Such machines are called blind if their action depends on state and input alone and not on the counter configuration. They are partially blind if they block when any counter is negative (i.e., only nonnegative counter contents are permissible) but do not know whether or not any of the counters contain zero. Blind multicounter machines are equivalent in power to the reversal bounded multicounter machines of Baker and Book [1], and for both blind and reversal bounded multicounter machines, the quasirealtime family is as powerful as the full family. The family of languages accepted by blind multicounter machines is the least intersection closed semiAFL containing { a n b n | n ⩾0} and also the least intersection closed semiAFL containing the two-sided Dyck set on one letter. Blind multicounter machines are strictly less powerful than quasirealtime partially blind multicounter machines. Quasirealtime partially blind multicounter machines accept the family of computation state sequences or Petri net languages which is equal to the least intersection closed semiAFL containing the one-sided Dyck set on one letter but is not a principal semiAFL. For partially blind multicounter machines, as opposed to blind machines, linear time is more powerful than quasirealtime. Assuming that the reachability problem for vector addition systems is decidable [16], partially blind multicounter machines accept only recursive sets and do not accept even {a n b n |n⩾0 ∗ , and quasirealtime partially blind multicounter machines are less powerful than general quasirealtime multicounter machines.		Sheila A. Greibach	1978	Theor. Comput. Sci.	10.1016/0304-3975(78)90020-8		ECom	0.4518853396583222	20.99339774386869	9404
fe398157586bf63e6d79260bffe81f4fb5669f81	combinatorial congruences and psi-operators	number theory	The -operator for ( , )-modules plays an important role in the study of Iwasawa theory via Fontaine’s big rings. In this note, we prove several sharp estimates for the -operator in the cyclotomic case. These estimates immediately imply a number of sharp p-adic combinatorial congruences, one of which extends the classical congruences of Fleck (1913) and Weisman [Some congruences for binomial coefficients, Michigan Math. J. 24 (1977) 141–151]. © 2005 Elsevier Inc. All rights reserved.	coefficient;sharp-p	Daqing Wan	2006	Finite Fields and Their Applications	10.1016/j.ffa.2005.08.006	number theory;pure mathematics;mathematics;algebra	AI	41.64962568613203	35.13241211092225	9420
9a2e1fa1a251b0915a03786a47b6a2a5db438455	a test vector inhibiting technique for low energy bist design	switching activity;test vector inhibiting technique;circuit under test;power saving;built in self test circuit testing automatic testing power system reliability energy consumption circuit faults system testing switching circuits very large scale integration power dissipation;circuit faults;low energy;low energy bist design;switching circuits;very large scale integration;automatic testing;logic testing low power electronics built in self test integrated circuit testing vlsi delay estimation digital integrated circuits;high fault coverage test vector inhibiting technique low energy bist design self testing switching activity low power consumption test operation reseeding scheme pseudo random resistant faults system speed testing;self testing;built in self test;system speed testing;digital integrated circuits;energy consumption;generic point;power dissipation;logic testing;low power electronics;integrated circuit testing;normal operator;vlsi;reseeding scheme;system testing;fault coverage;circuit testing;power system reliability;power consumption;test operation;low power consumption;high fault coverage;delay estimation;pseudo random resistant faults	During self-test, the switching activity of the circuit under test is significantly increased compared to normal operation and leads to an increased power consumption which often exceeds specified limits. In the first part of this paper, we propose a test vector inhibiting technique which tackles the increased activity during test operation. Next, a mixed solution based on a reseeding scheme and the vector inhibiting technique is proposed to deal with hard-to-test circuits that contain pseudo-random resistant faults. From a general point of view, the goal of these techniques is to minimize the total energy consumption during test and to allow the test at system speed in order to achieve high fault coverage. The effectiveness of the proposed low energy BIST scheme has been validated on a set of benchmarks with respect to hardware overhead and power savings.	benchmark (computing);built-in self-test;energy minimization;fault coverage;overhead (computing);pseudorandomness;stuck-at fault;test vector	Patrick Girard;Loïs Guiller;Christian Landrault;Serge Pravossoudovitch	1999		10.1109/VTEST.1999.766696	embedded system;electronic engineering;real-time computing;computer science;engineering;electrical engineering;operating system;test compression;very-large-scale integration	EDA	20.380678739116476	53.62717988955096	9443
ca2b5611fef6415088feaf281cecbfe49d2ae254	a search algorithm for linear codes: progressive dimension growth	bepress selected works;new codes;search algorithm;94b05;minimum distance;linear code;progressive dimension growth pdg;minimum distance bounds;new codes minimum distance bounds search algorithm progressive dimension growth pdg 94b05	This paper presents an algorithm, called progressive dimension growth (PDG), for the construction of linear codes with a pre-specified length and a minimum distance. A number of new linear codes over G F(5) that have been discovered via this algorithm are also presented.	linear code;program dependence graph;search algorithm	Tsvetan Asamov;Nuh Aydin	2007	Des. Codes Cryptography	10.1007/s10623-007-9113-2	block code;mathematical optimization;combinatorics;discrete mathematics;linear code;mathematics;statistics;algebra;search algorithm	Theory	39.802730001527856	54.69597888588074	9458
afa4d2d9dbca667e438dd230c5dda27e9c309410	graceful labeling of a family of quasistars with paths in arithmetic progression	arithmetic progression	An extremely low cost, high speed, full stroke keyboard is disclosed which provides momentary impulse operation. N-key rollover protection and standard tactile feedback. The keyboard includes a plurality of depressible keys mounted on respective upright synthetic resin flaps designed to collapse upon key depression and engage and move an underlying, resilient, U-shaped shifting member; the member in turn engages and shifts another U-shaped resilient element which supports one or more upstanding encoding posts. When the U-shaped element reaches a cocked position it is disengaged from the shifting member and allowed to snap back toward the original rest position thereof independently of subsequent return movement of the key and shifting member. The snap back motion is sensed and a corresponding key output signal developed.	color gradient;graceful labeling	Alka V. Kanetkar;S. S. Sane	2007	Ars Comb.		encoding (memory);mathematics;combinatorics;discrete mathematics;rollover;graceful labeling;impulse (physics);arithmetico-geometric sequence;arithmetic progression	Theory	33.69682862415609	40.981389871018514	9465
41578470ffa2d3936b11c29a4ed5f4202749f030	dominator colorings in some classes of graphs	dominator coloring;domination;characterization	A dominator coloring is a coloring of the vertices of a graph such that every vertex is either alone in its color class or adjacent to all vertices of at least one other class. We present new bounds on the dominator coloring number of a graph, with applications to chordal graphs. We show how to compute the dominator coloring number in polynomial time for P4-free graphs, and we give a polynomial-time characterization of graphs with dominator coloring number at most 3.	degeneracy (graph theory);dominator (graph theory);graph coloring;np-completeness;polynomial;time complexity;vertex (geometry)	Mustapha Chellali;Frédéric Maffray	2012	Graphs and Combinatorics	10.1007/s00373-010-1012-z	brooks' theorem;dominator;combinatorics;discrete mathematics;topology;fractional coloring;complete coloring;edge coloring;graph coloring;mathematics;list coloring;chordal graph;greedy coloring;indifference graph	Theory	27.320336012568013	26.808228041319307	9497
afc4a36c9650d56433f89ecac0cc92931997de91	generalized cages		Let 2 6 k1 < k2 < · · · < kt, 3 6 g1 < g2 < · · · < gs < N be integer parameters. A (k1, k2, . . . , kt; g1, g2, . . . , gs;N)-graph is a graph that contains vertices of degrees k1, k2, . . . , kt but no other degrees and cycles of lengths g1, g2, . . . , gs but no other cycles of length < N . For any given set of parameters satisfying the above conditions, we present an explicit construction of (k1, k2, . . . , kt; g1, g2, . . . , gs;N)-graphs and extend the concept of a cage (a smallest graph of given degree and girth) to that of a generalized cage – a smallest (k1, k2, . . . , kt; g1, g2, . . . , gs;N)-graph. We introduce several infinite families of generalized cages and study their basic properties in the context of connected, bipartite, and vertex-transitive graphs, as well as combinatorial configurations (in the context of multilaterals). ∗Dedicated to Branko Grünbaum whose work is a constant source of inspiration for us. †Supported in part by the project P1-0294. ‡Supported in part by the projects VEGA 1/0577/14, VEGA 1/0474/15, NSFC 11371307, and Project: Mobility ITMS code: 26110230082. §Supported in part by the projects P1-0294, J1-6720, N1-0011, and N1-0032. the electronic journal of combinatorics 22(1) (2015), #P1.77 1	girth (graph theory);isogonal figure;vertex-transitive graph	Marko Boben;Robert Jajcay;Tomaz Pisanski	2015	Electr. J. Comb.			Theory	31.500615813453635	30.890932516353953	9515
39c8793d830057e41a1e10396a835c4391ed90a5	probabilistic power estimation for digital signal processing architectures	modelizacion;digital signal processing;diseno circuito;arquitectura circuito;analisis estadistico;integrated circuit;power estimation;estudio comparativo;circuit design;simulation;circuit architecture;simulacion;circuito integrado;simulation circuit;methode calcul;experimental result;metodo calculo;puce traitement signal numerique;statistical properties;modelisation;etude comparative;circuit simulation;statistical analysis;estimacion probabilista;signal processing;analyse statistique;comparative study;architecture circuit;estimacion parametro;resultado experimental;estimation probabiliste;digital signal processing chips;conception circuit;parameter estimation;estimation parametre;power consumption;consommation energie electrique;resultat experimental;modeling;computing method;circuit integre;probabilistic assessment	A method for estimating the power on architecture-level is described. Originally based on simulations with data sequences, the method is extended by an simulation-free approach. The statistical properties required for the underlying Dual-Bit-Type model are propagated through the circuit. The necessary computation formulas are presented. For both approaches, the model accuracy for base modules as for signal processing applications is comparably low.	digital signal processing	Achim Freimann	2002		10.1007/3-540-45716-X_46	systems modeling;telecommunications;computer science;engineering;electrical engineering;integrated circuit;digital signal processing;circuit design;comparative research;signal processing;estimation theory;algorithm	EDA	26.112785543011285	55.75458907842597	9526
455f94b1656212582f5c4ace700895a5bc6a4be7	code coverage-based power estimation techniques for microprocessors	power estimation;code coverage;code decomposition;function level power model;microprocessor cores;source code;program profiling and tracing;power consumption;power modeling	We have developed a function-level power estimation methodology for predicting the power dissipation of embedded software. For a given microprocessor core, we empirically build the “power data bank”, which stores the power information of the built-in library functions and basic instructions. To estimate the average power of an embedded software on this core, we first decompose the machine code into library functions and user-defined functions. We then use program profiling/tracing tools to get the execution information of the target software. Next, we evaluate the total energy consumption and execution time based on the “power data bank”, and their ratio is taken as the average power. High efficiency is achieved because no power simulator is used once the “power data bank” is built. We apply this method to a commercial microprocessor core and get power estimates with an average error of 3%. Using this method, microprocessor vendors can provide users the “power data bank” without releasing details of the core to help users get early power estimates and eventually guide power optimization.	central processing unit;code coverage;compiler;embedded software;embedded system;function-level programming;machine code;mathematical optimization;microprocessor;multi-core processor;power optimization (eda);run time (program lifecycle phase);simulation;superscalar processor	Gang Qu;Naoyuki Kawabe;Kimiyoshi Usami;Miodrag Potkonjak	2002	Journal of Circuits, Systems, and Computers	10.1142/S0218126602000616	embedded system;power-flow study;parallel computing;real-time computing;computer science;operating system;code coverage;power optimization;source code	EDA	-2.4970350404852333	55.10980828928247	9530
bcdc63aef78041a68b7409d47bb87519aa8e7980	architectures and algorithms for image and video processing using fpga-based platform	video signal processing embedded systems field programmable gate arrays logic design object tracking;fpga based design architectures and algorithms image and video processing platform based design;xilinx ml 507 fpga platform video processing system image processing system fpga based platform efficiently configured hardware software system embedded system design techniques field programmable gate arrays software components hardware components kernel based mean shift object tracking algorithm virtex 5 fxt fpga device embedded powerpc processor;field programmable gate arrays algorithm design and analysis hardware computer architecture histograms embedded systems	The work illustrates the use of platform-based design to achieve efficiently-configured hardware-software system solution that can meet the conflicting demands of high performance, low power and quick turnaround time for embedded system development. It presents embedded system design techniques using field-programmable gate arrays (FPGAs) for image and video processing application. Here, by identifying, building and integrating all necessary hardware and software components, an embedded implementation of a kernel-based mean shift (KBMS) object tracking algorithm has been proposed [1]. To fulfill the specific needs of hardware/software implementation Virtex-5 FXT FPGA device (which has an embedded PowerPC processor) available on Xilinx ML-507 platform has been used [2].	algorithm;component-based software engineering;embedded system;field-programmability;field-programmable gate array;mean shift;platform-based design;powerpc;software system;systems design;video processing	Jai Gopal Pandey;Arindam Karmakar;S. Gurunarayanan	2014	18th International Symposium on VLSI Design and Test	10.1109/ISVDAT.2014.6881081	embedded system;computer architecture;real-time computing;reconfigurable computing;computer science;fpga prototype	EDA	3.3481535336118475	49.440097549747875	9531
0f2bb3ac8727919dad85a31b848e7c0167f75354	ote on an art gallery problem	fixed point;art gallery problem	Abstract   It is proved that for  n  > 3,   ⌈  2  5  (n − 3)⌉   guards are enough to monitor any simply connected art gallery room of  n  sides if they are stationed at fixed points and their range of vision is 180°. Furthermore, the position of the guards can be determined by an O( n )-time algorithm.	art gallery problem	György Csizmadia;Géza Tóth	1998	Comput. Geom.	10.1016/S0925-7721(97)00029-1	mathematics;geometry;fixed point;art gallery problem;algorithm	ECom	32.51089978098015	21.565153765628544	9545
20e2f8be4b482ebf1a66cdf88ac87e8de8f95a31	space/time modulation of speckle noise and multiscale speckle tracking in intracardiac echocardiography	space time;speckle noise	A monitor program stored in a ROM of a microcomputer chip of a computer is operated both to (1) save power by disabling all external buses, turning off power to a communication port, deselecting all external memory devices, and turning off a fast clock oscillator and clocking all operations of the microcomputer chip at a slow second frequency, and also to (2) prioritize execution of a plurality of application programs located in external memory devices and/or internal memory of the microcomputer chip while also relying on the monitor program to effectuate normal initialization procedures. The monitor program also allows efficient access to slow external memory devices by dividing down the fast clock rate produced by the oscillator to a slower rate and accessing the slow memory at the slower rate, thereby saving power.	doppler echocardiography;modulation	Robert Azencott;Yipeng Li;Dirar Khoury	2009			modulation;chip;computer hardware;clock rate;auxiliary memory;initialization;speckle pattern;speckle noise;microcomputer;computer science	Vision	32.292256458004175	52.11783449822369	9550
e25a0f92f9cac6475987ed3e1d598bf1441464d5	abacus proofs of schur function identities	prueba;05e05;inverso;movimiento;mathematiques discretes;mathematics applied;matematicas discretas;abaci;discrete mathematics;inverse kostka matrix;motion;polynomial;littlewood richardson rules;tableaux;65f40;preuve;05a19;schur functions;symmetric polynomials;polinomio;mouvement;determinante;determinant;pieri rules;etiqueta;etiquette;label;polynome;proof;article;schur function;inverse	This article uses combinatorial objects called labeled abaci to give direct combinatorial proofs of many familiar facts about Schur polynomials. We use abaci to prove the Pieri rules, the Littlewood–Richardson rule, the equivalence of the tableau definition and the determinant definition of Schur polynomials, and the combinatorial interpretation of the inverse Kostka matrix (first given by Eğecioğlu and Remmel). The basic idea is to regard formulas involving Schur polynomials as encoding bead motions on abaci. The proofs of the results just mentioned all turn out to be manifestations of a single underlying theme: when beads bump, objects cancel.	bump mapping;method of analytic tableaux;polynomial;richardson number;theme (computing);turing completeness	Nicholas A. Loehr	2010	SIAM J. Discrete Math.	10.1137/090753462	combinatorics;discrete mathematics;determinant;symmetric polynomial;etiquette;schur polynomial;motion;pure mathematics;schur's theorem;proof;mathematics;geometry;label;inverse;algorithm;polynomial;algebra	Theory	44.055973526334036	31.619253630808203	9557
5787c9ff247871aecfd2bfbfa100f0e3a230dfc6	hard clusters maximize mutual information		In this paper, we investigate mutual information as a cost function for clustering, and show in which cases hard, i.e., deterministic, clusters are optimal. Using convexity properties of mutual information, we show that certain formulations of the information bottleneck problem are solved by hard clust ers. Similarly, hard clusters are optimal for the information-t heoretic co-clustering problem that deals with simultaneous cluste ring of two dependent data sets. If both data sets have to be clustere d using the same cluster assignment, hard clusters are not optimal in general. We point at interesting and practically relevant special cases of this so-called pairwise clustering proble m, for which we can either prove or have evidence that hard clusters are optimal. Our results thus show that one can relax the otherwise combinatorial hard clustering problem to a real-valued optimization problem with the same global optimum.	biclustering;cluster analysis;global optimization;loss function;mathematical optimization;mutual information;optimization problem;regular language description for xml	Bernhard C. Geiger;Rana Ali Amjad	2016	CoRR		correlation clustering;mathematical optimization;determining the number of clusters in a data set;combinatorics;fuzzy clustering;machine learning;mathematics;brown clustering	ML	22.552354301125046	15.207367680740319	9565
23b5db2064af2e173e8339bc12b9197b59030699	graph coloring with rejection	graphe non oriente;graph theory;claw free graph;coloracion grafo;teoria grafo;non directed graph;subgrafo;grado grafo;graph coloring;theorie graphe;algorithme;algorithm;coloration graphe;sous graphe;grafo no orientado;vertex coloring;degre graphe;subgraph;graph degree;graph colouring;algoritmo	We consider the following vertex coloring problem. We are given an undirected graph G = (V, E), where each vertex v is associated with a penalty rejection cost rv. We need to choose a subset of vertices, V ′, and to find a proper coloring of the induced subgraph of G over V ′. We are interested in both the number of colors used to color the vertices of V ′, and in the total rejection cost of all other vertices. The goal is to minimize the sum of these two amounts. In this paper we consider both the online and the offline versions of this problem. In the online version, vertices arrive one at a time, revealing the rejection cost of the current vertex and the set of edges connecting it to previously revealed vertices. We also consider the classical online coloring problem on bounded degree graphs and on (k + 1)-claw free graphs.	color;graph (discrete mathematics);graph coloring;induced subgraph;online and offline;rejection sampling;vertex (geometry)	Leah Epstein;Asaf Levin;Gerhard J. Woeginger	2006		10.1007/11841036_34	claw-free graph;graph power;brooks' theorem;combinatorics;discrete mathematics;independent set;topology;fractional coloring;level structure;graph center;bipartite graph;graph theory;pseudoforest;complete coloring;edge coloring;cycle graph;graph coloring;vertex;path graph;mathematics;graph homomorphism;induced path;list coloring;distance;greedy coloring;neighbourhood	Theory	22.233449961669557	26.828719801715934	9572
456cb92376ce76e66f9c4611a140853027398d00	a characterization of the number of subsequences obtained via the deletion channel	channel coding;channel coding binary codes;binary codes;extremal strings deletion channel binary strings structural analysis;upper bound equations synchronization educational institutions information theory abstracts	Motivated by the study of deletion channels, this paper presents improved bounds on the number of subsequences obtained from a binary string X of length n under t deletions. It is known that the number of subsequences in this setting strongly depends on the number of runs in the string X; where a run is a maximal substring of the same character. Our improved bounds are obtained by a structural analysis of the family of r-run strings X, an analysis in which we identify the extremal strings with respect to the number of subsequences. Specifically, for every r, we present r-run strings with the minimum (respectively maximum) number of subsequences under any t deletions; we perform an exact analysis of the number of subsequences of these extremal strings; and show that this number can be calculated in polynomial time.	deletion channel;maximal set;structural analysis;substring;time complexity	Yuvalal Liron;Michael Langberg	2012	2012 IEEE International Symposium on Information Theory Proceedings	10.1109/ISIT.2012.6284240	binary code;combinatorics;discrete mathematics;channel code;computer science;theoretical computer science;mathematics;statistics	Theory	38.03537520418858	55.770822645745596	9586
28c4906b901e132d14162f8ca4c108e9c9913127	the formal consequences of using variables in ccg categories	weak generative capacity;linear indexed grammars;formal consequence;ccg category;head grammars;lexical category assignment;lexical category;combinatory categorial grammars;tree-adjoining grammars;combinatory categorial grammar;tree adjoining grammar;indexation	Combinatory Categorial Grammars, CCGs, (Steedman 1985) have been shown by Weir and Joshi (1988) to generate the same class of languages as Tree-Adjoining Grammars (TAG), Head Grammars (HG), and Linear Indexed Grammars (LIG). In this paper, I will discuss the effect of using variables in lexical category assignments in CCGs. It will be shown that using variables in lexical categories can increase the weak generative capacity of CCGs beyond the class of grammars listed above. A Formal Definition for CCGs In categorial grammars, grammatical entities are of two types: basic categories and functions. A basic category such as NP serves as a shorthand for a set of syntactic and semantic features. A category such as SnNP is a function representing an intransitive verb; the function looks for an argument of type NP on its left and results in the category S. A small set of combinatory rules serve to combine these categories while preserving a transparent relation between syntax and semantics. Application rules allow functions to combine with their arguments, while composition rules allow two functions to combine together. Based on the formal definition of CCGs in (Weir-Joshi 1988), a CCG, G, is denoted by (VT ; VN ; S; f;R), where VT is a finite set of terminals, VN is a finite set of nonterminals, S is a distinguished member of VN , f is a function that maps elements of VT [ f g to finite subsets ofC(VN ), the set of categories, where, VN C(VN ) and if c1 and c2 2 C(VN ), then (c1nc2) and (c1=c2) 2 C(VN ): I would like to thank Mark Steedman, Libby Levison, Owen Rambow, and the anonymous referees for their valuable advice. This work was partially supported by DARPA N00014-90-J-1863,ARO DAAL03-89-C-0031, NSF IRI 9016592, Ben Franklin 91S.3078C-1. R is a finite set of combinatory rules where X;Y; Z1; : : : ; Zn are variables over the set of categories C(VN ), and the slash variable ji can bind to n or =. Certain restrictions may be placed on the possible instantiations of the variables in the rules. – Forward Application (>): X=Y Y !X – Backward Application (<): Y XnY !X – Generalized Forward Composition (>B(n) or >Bx(n)): For some n 1, X=Y Y j1Z1j2 : : : jnZn !Xj1Z1j2 : : : jnZn – Generalized Backward Composition (<B(n) or <Bx(n)): For some n 1, Y j1Z1j2 : : : jnZn XnY !Xj1Z1j2 : : : jnZn The derives relation in a CCG is defined as c ) c1c2 if R contains the rule c1c2 ! c. The language generated by this grammar is defined as L(G) = fa1; : : : ; an j S ) c1; : : : ; cn; ci 2 f(ai); ai 2 VT [ f g; 1 i ng Under these assumptions, Weir and Joshi (1988) prove that CCGs are weakly equivalent to TAGs, HGs, and LIGs. Their conversion of a CCG to a LIG1 relies on the fact that the combinatory rules in the CCG are linear. To preserve linearity in CCGs, only the category X in the combinatory rules can be unbounded in size; the variables Y and Z must be bounded in their possible instantiations. In other words, only a finite number of categories can fill the secondary constituent of each combinatory rule. The secondary constituent is the second of the pair of categories being combined in the forward rules and the first of the pair in the backward rules (e.g. Y jZ1:::jZn). Weir and Joshi do not restrict the size of the secondary constituents in the formal definition of the CCG rules, but they prove that the following lemma holds of the grammar. Linear Indexed Grammars are a restricted version of Indexed Grammars in which no rule can copy a stack of unbounded size to more than one daughter (Gazdar 1985). Lemma: There is a bound (determined by the grammar G) on the number of useful categories that can match the secondary constituent of a rule. There are an infinite number of derivable categories in CCGs, however Weir and Joshi show that the number of components that derivable categories have is bounded. The components of a category c = (c0j1c1j2:::jncn) are its immediate components c0; :::; cn and the components of these immediate components. A finite set DC (G) can be defined that contains all derivable components of every useful category where a category c is useful if c ) w for some w in VT : c 2 DC (G) if c is a component of c0 where c0 2 f(a) for some a 2 VT [ f g: Given that every useful category matching the secondary constituents Y and Y jZ1:::jZn in the combinatory rules has components which are in DC(G), the lemma given above holds. However, this lemma does not hold if there are variables in the lexical categories in VT . Variables can bind a category of any size, and thus useful categories containing variables do not necessarily have all of their derivable components in the finite set DC(G). The Use of Variables	carrier-to-noise ratio;combinatory categorial grammar;entity;equivalence (formal languages);head grammar;ibm notes;indexed grammar;map;mark steedman;owen astrachan;slash (cms);tree-adjoining grammar;variable (computer science)	Beryl Hoffman	1993			natural language processing;indexed language;context-sensitive grammar;tree-adjoining grammar;indexed grammar;categorial grammar;l-attributed grammar;phrase structure grammar;computer science;linguistics;definite clause grammar;context-free grammar;stochastic context-free grammar;mildly context-sensitive grammar formalism;combinatory categorial grammar;algorithm;c-command	NLP	-2.408674437956243	15.956121805038439	9587
fe575a1b022bba19155bb975ba81d0bc525a8c1e	is the linear schrödinger propagator turing computable?	sobolev space	In this note we study Turing computability of the linear inhomogeneous Schrodinger propagator S. We prove: (1) S is computable when the initial functions are from sobolev spaces. (2) When acting on Lp(Rd), S is computable, if and only if p = 2.	computable function;propagator;schrödinger;turing	Klaus Weihrauch;Ning Zhong	2000		10.1007/3-540-45335-0_22	combinatorics;mathematical analysis;discrete mathematics;mathematics;utm theorem;computable function;computable number	ML	47.57205881531928	32.639990664543255	9620
9b242745181c6d0dc0c6d7d04dea4cadb2b7f84d	representing a planar straight-line graph using few obstacles		An obstacle representation of a planar straight-line graph (PSLG) G consists of the choice and placement of a set of opaque polygonal obstacles in such a way that the visibility graph on V (G) induced by the obstacles equals G (i.e., u and v are visible to one another iff (u, v) ∈ E(G)). We investigate the problem of computing an obstacle representation of a PSLG, using a minimum number of obstacles. We call this minimum size the obstacle number of the drawing, and the problem of computing it ORPG. First, we show that ORPG is NP-hard by reduction from planar vertex cover, resolving a question posed by Sarıöz (CCCG 2011 [7]). Second, we give a reduction from ORPG to maximum degree 3 planar vertex cover. Since this reduction preserves solution values, it follows that ORPG admits a polynomial-time approximation scheme (PTAS) and is fixed-parameter tractable (FPT).	cobham's thesis;emoticon;line graph;np-hardness;ptas reduction;parameterized complexity;planar straight-line graph;polynomial;polynomial-time approximation scheme;time complexity;vertex cover;visibility graph	Matthew P. Johnson;Deniz Sariöz	2014			combinatorics;discrete mathematics;mathematics;geometry	AI	29.80871372018167	21.537692818395627	9636
34e79eb07d8acc750553b2d812dcd322fb45971e	matroid intersection, base packing and base covering for infinite matroids	05b35;05c63;05b40	As part of the recent developments in infinite matroid theory, there have been a number of conjectures about how standard theorems of finite matroid theory might extend to the infinite setting. These include base packing, base covering, and matroid intersection and union. We show that several of these conjectures are equivalent, so that each gives a perspective on the same central problem of infinite matroid theory. For finite matroids, these equivalences give new and simpler proofs for the finite theorems corresponding to these conjectures. This new point of view also allows us to extend, and simplify the proofs of, some cases where these conjectures were known to be true.	matroid intersection;set packing	Nathan Bowler;Johannes Carmesin	2015	Combinatorica	10.1007/s00493-014-2953-2	matroid;combinatorics;discrete mathematics;graphic matroid;topology;oriented matroid;mathematics;matroid partitioning	Theory	39.04856074976535	29.754592815335723	9641
bea8d4839cee6fe97f07bfad070d008da3603dd4	on plant roots logical gates	plant roots;logical gates;unconventional computing	Theoretical constructs of logical gates implemented with plant roots are morphological computing asynchronous devices. Values of Boolean variables are represented by plant roots. A presence of a plant root at a given site symbolises the logical True, an absence the logical False. Logical functions are calculated via interaction between roots. Two types of two-inputs-two-outputs gates are proposed: a gate 〈x, y〉→〈xy, x+y〉 where root apexes are guided by gravity and a gate 〈x,y〉→〈x¯y,x〉 where root apexes are guided by humidity. We propose a design of binary half-adder based on the gates.	adder (electronics);boolean;logic gate;plant roots	Andrew Adamatzky;Georgios Ch. Sirakoulis;Genaro Juárez Martínez;František Baluška;Stefano Mancuso	2017	Bio Systems	10.1016/j.biosystems.2017.04.002	logic gate;nanotechnology;mathematics;algorithm;unconventional computing	Logic	18.85407513895064	42.193114281724505	9642
be57320b138e9fff80e21c0cccc2ed67d390158a	a power-aware digital feedforward neural network platform with backpropagation driven approximate synapses	feedforward neural networks;power aware computing backpropagation feedforward neural nets;recognition accuracy power aware digital feedforward neural network platform backpropagation driven approximate synapses backpropagation algorithm energy quality trade off quality constraint synaptic weight coupled software full chip design;sensitivity;artificial neural networks;approximation methods artificial neural networks feedforward neural networks hardware neurons power demand sensitivity;digital feedforward neural network approximate computing;approximation methods;neurons;power demand;hardware	This paper proposes a power-aware digital feedforward neural network platform that utilizes the backpropagation algorithm during training to enable energy-quality trade-off. Given a quality constraint, the proposed approach identifies a set of synaptic weights for approximation in a neural network. The approach selects synapses with small impact on output error, estimated by the backpropagation algorithm, for approximation. The approximations are achieved by a coupled software (reduced bit-width) and hardware (approximate multiplication in the processing engine) based design approaches. The full-chip design in 130nm CMOS shows, compared to a baseline accurate design, the proposed approach reduces system power by ~38% with 0.4% lower recognition accuracy in a classification problem.	approximate computing;approximation algorithm;artificial neural network;backpropagation;baseline (configuration management);cmos;computation;dynamic random-access memory;elegant degradation;feedforward neural network;greedy algorithm;input/output;low-power broadcasting;precomputation;synapse;synaptic weight	Jaeha Kung;Duckhwan Kim;Saibal Mukhopadhyay	2015	2015 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED)	10.1109/ISLPED.2015.7273495	rprop;feedforward neural network;probabilistic neural network;types of artificial neural networks;sensitivity;computer science;artificial intelligence;recurrent neural network;theoretical computer science;machine learning;physical neural network;time delay neural network;deep learning;multilayer perceptron;artificial neural network	Arch	4.0661642780015175	42.422899128393865	9656
a5b91eb48bd8684f5ffe550cbbfe7758af90c426	circle graphs and monadic second-order logic	split decomposition;first occurrence;linear order;circle graph;graph transformation;monadic second order;chord diagram;monadic second order transduction;monadic second order logic;intersection graphs;order invariant monadic second order property	A circle graph is the intersection graph of a set of chords of a circle. If a circle graph is prime for the split (or join) decomposition defined by Cunnigham, it has a unique representation as a set of intersecting chords, and we prove that this representation can be defined by monadic second-order formulas. By using the (canonical) split decomposition of a circle graph, one can define in monadic second-order logic all its chord representations formalized as words with two occurrences of each letter. This construction uses the general result that the split decomposition of a graph can be constructed in monadic second-order logic. As a consequence we prove that a set of circle graphs has bounded clique-width if and only if all their chord diagrams have bounded tree-width. We also prove that the order of first occurrences of the letters in a double occurrence word w representing a given connected circle graph determines this word w in a unique way.	chord diagram;clique-width;monadic predicate calculus;split (graph theory);treewidth	Bruno Courcelle	2008	J. Applied Logic	10.1016/j.jal.2007.05.001	outerplanar graph;split graph;combinatorics;discrete mathematics;null graph;graph property;clique-width;comparability graph;cubic graph;mathematics;voltage graph;distance-hereditary graph;circle graph;modular decomposition;monadic predicate calculus;complement graph;intersection graph;line graph;total order;algorithm;string graph;planar graph	Theory	21.59400401304131	32.231729866662675	9663
70fa81883601d8da1957a455df33b3909aecd736	k-piecewise affine model fitting: heuristics based on multiway linear classification				Edoardo Amaldi;Stefano Coniglio;Leonardo Taccari	2012			computer science;piecewise;discrete mathematics;linear classifier;heuristics;affine transformation	Vision	32.112263679728095	6.95681669909078	9673
dc9008d56cd2a00736b4775a302cc5da140ed510	multi-threshold threshold elements	network design;network synthesis;logic design;boolean functions;boolean function;boolean functions circuit synthesis network synthesis power generation economics diodes;diodes;functional requirement;circuit synthesis;power generation economics	A multi-threshold element is one in which several other hand, considerable work has been done with cirthresholds are used to separate the true inputs from the false inputs. cuit realizations of multi-threshold TE's with little Many circuit elements and configurations can be described by this * * * l model. An approach, based on conventional single-threshold threshcocrnaot d oping logical td tehniqe old elements, is developed for the analysis and synthesis of multi[31-[91. This latter work has demonstrated the relative threshold threshold elements. It is shown that the basic properties simplicity of circuits for multi-threshold TE's, and of such elements are similar to conventional threshold elements, and analysis has shown the logical power of these simple cirthat k-threshold threshold-element realizability of an arbitrary cuits. For example, it has been recognized for several n-variable Boolean function can be related to conventional thresholdyears that a tunnel-diode circuit such as shown in Fig. element realizability of a related (n+k -l)-variable Boolean function. y that a e l-diode cicit uc as shown in rig Foundations for two basically different methods for the synthesis of 1(a) could perform mod-2 addition of up to three vana single-element realization of an arbitrary Boolean function are ables, which otherwise requires at least two gates. The developed, as are procedures for transforming such a realization into multi-threshold point of view not only explains why this both two-level and multilevel loop-free networks of k-threshold is true, but also shows how to use such a circuit to threshold elements k>1. Every element in the networks has the realize many other functions, including those observed identical weight vector for the independent variables, which is some. times desirable. The transformation technique is a useful approach by Miro et al [9]. to the synthesis of functions by networks of conventional threshold elements. It is proved that if the given function requires a k-threshold VB threshold element, then at least [k/2 +I] conventional threshold elements in a two-level network or [1 +log2 k] such elements in a multilevel network are required. Transformations are given for YI corresponding minimum-gate networks. Electronic-circuit realizaY2eo tions of multi-threshold elements and some logical-design appliv cations of the multi-threshold approach to network design are discussed. The latter indicate that this approach can be easy to use and can result in economical realizations. (a) SIMPLIFIED TUNNEL DIODE AND TRANSISTOR CIRCUIT HAVING 3 THRESHOLDS AT THE MOST	binary logarithm;diode;electronic circuit;network planning and design;test engineer;transistor	Donald R. Haring	1966	IEEE Trans. Electronic Computers	10.1109/PGEC.1966.264375	boolean circuit;circuit minimization for boolean functions;electronic engineering;discrete mathematics;boolean network;boolean expression;computer science;mathematics;boolean function;algorithm;parity function	Theory	18.88828900137335	44.8053600216137	9712
14e6dc9ed789ee8dfe4a8b8cc085119968f99547	sparse combinatorial group testing for low-energy massive random access		We present random access schemes for machine-type communication where a massive number of low-energy wireless devices want to occasionally transmit short information packets. We focus on the device discovery problem, with extensions to joint discovery and data transmission as well as data transmission without communicating device identities. We formulate this problem as a combinatorial group testing one, where the goal is to exactly identify the set of at most d defective items from a pool of n items. We translate the energy constraint at the physical layer to a constraint on the number of tests each item can participate in, and study the resulting “sparse” combinatorial group testing problem. The celebrated result for the combinatorial group testing problem is that the number of tests t can be made logarithmic in n when d = O(logn). However, state-of-the-art group testing codes require the items to be tested w = Ω( d logn log d+log logn ) times. In our sparse setting, we restrict the number of tests each item can participate in by wmax. It is easy to observe that if wmax ≤ d, then we must have t = n; i.e., testing every item individually is optimal. We show that if wmax = d+ 1, the number of tests decreases suddenly from t = n to t = (d + 1) √ n. More generally, if wmax = ld + 1 for any positive integer l such that ld + 1 ≤ l+1 √ n, we can achieve t = (ld + 1)n1/(l+1) using Kautz and Singleton’s construction with a particular choice of field size. We also prove a nearly matching lower bound which shows that t = Ω(d2/l+1n1/(l+1)). This shows that in the sparse setting t is a fractional power of n, rather than logarithmic in n as in the classical setting. Since encoding and decoding efficiency can be just as important as energy efficiency, we demonstrate that our construction can be decoded in (poly(d) + O(t))-time and each entry in any codeword can be computed in space poly(logn). This shows that our construction not only (nearly) achieves the fundamental lower bound, but also does that with a favorable encoding and decoding complexity.	code word;computer performance;random access;sparse matrix	Huseyin A. Inan;Peter Kairouz;Ayfer Özgür	2017	CoRR		mathematics;discrete mathematics;combinatorics;group testing;binary logarithm;logarithm;singleton;decoding methods;upper and lower bounds;integer;random access	Crypto	34.14234635708947	59.32583090836282	9717
749bb560946d1823167c4be6afb044f8587e7d1d	tiny and autonomous ieee1451 sonic anemometer to deploy in environmental wireless sensor network	experimental tests;ieee 1451 standard;protocols;wireless sensor network wsn;autonomous ieee1451 sonic anemometer;ieee standards;ultrasonic equipment;sonic anemometer;sensor node reliability autonomous ieee1451 sonic anemometer environmental wireless sensor network weather prediction air pollution transport safety structural safety interoperable smart ultrasonic anemometer ieee 1451 standard power management energy consumption low power sampling protocol bmac;sensor node reliability;transducers;anemometers;ieee1451 standardization;fluid flow measurement;energy harvesting;wireless sensor network;interoperable smart ultrasonic anemometer;low power;radiotelemetry;monitoring;energy consumption;wind speed;air pollution;conference report;duty cycle;power management;mathematical model;sensor nodes;structural safety;wireless sensor networks anemometers ieee standards protocols radiotelemetry ultrasonic equipment;wireless sensor network wsn environmental monitoring ieee1451 standardization sonic anemometer;environmental wireless sensor network;weather prediction;wind;transport safety;low power sampling protocol bmac;wireless sensor networks;wireless sensor networks monitoring fluid flow measurement transducers wind mathematical model equations;environmental monitoring	Wind speed and direction are important parameters in the study of applied meteorology, for example, in weather prediction, air pollution, transport safety and structural safety. In this paper, we propose the design and deployment of an interoperable Smart Ultrasonic Anemometer that uses the IEEE 1451 standard and operates in a Wireless Sensor Network (WSN). This standard permits interoperability and introduces self-calibration and self-configuration tasks. We include power management considerations to calculate the energy consumption using a low power sampling protocol BMAC with variable duty cycle. Experimental tests are included to study the current consumption using an energy harvester with solar panel and super capacitors to increase the reliability and lifetime of the sensor node.	autonomous robot;bioinformatic harvester;duty cycle;ieee 1451;interoperability;power management;pulse-width modulation;sampling (signal processing);sensor node;software deployment;sonic the hedgehog 3	Jorge Higuera;Jose Polo	2010	2010 Seventh International Conference on Networked Sensing Systems (INSS)	10.1109/INSS.2010.5572161	embedded system;electronic engineering;telecommunications;engineering;key distribution in wireless sensor networks	Mobile	3.3705808241977646	30.321917547041387	9719
ee6b47143330f5bf572cd4b123bcf3409cbf7203	an integrated mos transistor associative memory system with 100 ns cycle time	cycle time;integrated circuit;associative memory	Since the announcement of the development of a technique for using MOS transistor integrated circuits as associative memory cells, 128 words of 48 bits per word associative memory has been experimented and engineered.	content-addressable memory;integrated circuit;transistor	Ryo Igarashi;Toru Yaita	1967		10.1145/1465482.1465565	electronic engineering;semiconductor memory;parallel computing;dynamic random-access memory;memory refresh;computer hardware;computer science;computer memory;non-volatile random-access memory;registered memory	EDA	15.1789331311835	59.63826976518385	9722
4e84280dd0e47721f322d398729b46457fde28bb	an improved method of moments estimator for toa based localization	method of moments;time of arrival estimation least mean squares methods method of moments;least mean squares methods;crammer rao lower bound method of moments estimator toa based localization time of arrival based system mom estimator least squares estimator range measurement nlls estimator;method of moments noise estimation indexes accuracy computational complexity position measurement;time of arrival estimation;location estimation and method of moments;article	Estimation accuracy and computational complexity are two major areas of consideration for localization system design. For time-of-arrival based systems, the 1st-order method of moments (MOM) least-squares (LS) estimator is simple to implement, but its performance is much worse than that of some computationally more complex estimators such as the MOM weighted LS (WLS) and nonlinear weighted LS (NLLS-WLS) estimators. In this paper, we develop an improved 1st-order MOM estimator to efficiently utilize the variances of the range measurements and the target position that, as the NLLS estimator, has a performance also approaching the Crammer-Rao lower bound but is much simpler than MOM-WLS and NLLS-WLS estimators.	boundary element method;computational complexity theory;iteration;non-linear least squares;nonlinear system;systems design;time of arrival	Tianzhu Qiao;Huaping Liu	2013	IEEE Communications Letters	10.1109/LCOMM.2013.052413.130734	efficient estimator;minimax estimator;econometrics;mathematical optimization;minimum-variance unbiased estimator;estimator;method of moments;mathematics;statistics	Robotics	51.98696314706557	5.236343410889454	9726
212f93ce53c6930aa27792881553b35c5729ddc2	comparative analysis of adiabatic logic challenges for low power cmos circuit designs		Abstract In a deep sub-micrometer regime as the scaling improves (reduction in feature size), gate oxide becomes thin and threshold voltage gets reduced, and thus the contribution in power dissipation due to leakage currents increases. Consequently, leakage currents in small feature size devices become a critical factor for low power applications. As the feature size has been reduced very much already, therefore it becomes very important to identify new techniques for power reduction instead of decreasing the feature size. Energy recovery technique is such a prominent technique which recycles the stored charge at different nodes and reduces power dissipation significantly. This paper reviews various energy recovery techniques based on different adiabatic logics. Analysis and comparison of different adiabatic logic techniques based on various parameters such as, the frequency of operation, µm technology used, supply voltage, the number of devices used has been done successfully in this paper. This paper explores various aspects of energy recovery logics.	cmos	Dinesh Kumar;Manoj Kumar	2018	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/j.micpro.2018.04.008	voltage;real-time computing;gate oxide;adiabatic process;threshold voltage;energy recovery;computer science;leakage (electronics);dissipation;cmos;electronic engineering	EDA	18.372650567868895	59.26186677856351	9727
174c9d69b0a9cc5fa8836440225d7452aaea8864	an efficient method of constructing cell graph in arrangement of quadrics in 3-dimensional space of rotations	graph theory;path planning;computational geometry;path planning computational geometry graph theory;motion planning cell graph quadrics quadric surfaces 3 dimensional space of rotations;generators data structures planning approximation algorithms approximation methods labeling complexity theory	In this paper an efficient method is presented to construct a cell graph in an arrangement of quadric surfaces in 3-dimensional space of rotations. It is particularly useful to motion planning in 3-dimensional space of rotations.	approximation algorithm;motion planning	Przemyslaw Dobrowolski	2013	Proceedings of the 2013 IEEE/SICE International Symposium on System Integration	10.1109/SII.2013.6776602	lattice graph;visibility graph;combinatorics;geometric graph theory;graph embedding;directed graph;topology;graph bandwidth;any-angle path planning;mathematics;voltage graph;geometry;quartic graph	Embedded	32.49960528487249	18.762169040920224	9738
b8c3384d5ff04b18613368d7043d2d9008c4aac5	the edge hamiltonian path problem is np-complete for bipartite graphs	graph theory;graphe biparti;teoria grafo;complexite calcul;complejidad calculo;grafo bipartido;probleme np complet;camino hamiltoniano;computing complexity;theorie graphe;hamiltonian path problem;computational complexity;theory of computation;edge graph;chemin hamiltonien;arete graphe;np complete;problema np completo;bipartite graph;arista grafico;np complete problem;hamiltonian path	L~t G ( V , E) b© an undirected graph ~ t h ver~e~ see V and edge set E. A p~t~ of lcn~h k in G is a sec~uen¢¢ of .k + ~ vor~ico~ (p~, . . . . %, %+ ~) such eha~ (o~, v~+ ~) ¢ E for a~ ~, 1 < ~ < k . ]If in addition v~-v~+~ ~hen the .~~uence is a ~ ea~Hed a cyc~. A H~mi~t~n~n ~ t h of O is a path in ~ ~hat visits every ve~e~ of the ~a~h e ~ l y once. A Sraph is H~m~it~n~n ff it has a H~il~onian p~th. A ~raph is said to be bipa~¢ if its ver~e~ s¢~ c ~ ~e p~r~itioned into ~ o ~ V ~ ~nd ~,'~ such tha~ no edge has ~ t h of i~s e n ~ i ~ h~ ~he ~ e see; i.e., a~ edges go	graph (discrete mathematics);hamiltonian path problem;np-completeness;path (graph theory);vhf omnidirectional range;ver (command)	Ten-Hwang Lai;Shu-Shang Wei	1993	Inf. Process. Lett.	10.1016/0020-0190(93)90191-B	strong perfect graph theorem;1-planar graph;hamiltonian path;pathwidth;complete bipartite graph;combinatorics;discrete mathematics;cograph;np-complete;independent set;topology;theory of computation;bipartite graph;longest path problem;dense graph;computer science;graph theory;3-dimensional matching;pancyclic graph;foster graph;mathematics;blossom algorithm;hamiltonian path problem;maximal independent set;biregular graph;chordal graph;indifference graph;algorithm;matching	DB	24.2313343249951	28.47113978881487	9743
8a3343d9a17d850f6c25d84c74c74e2435abbf15	interconnect bundle sizing under discrete design rules	size 32 nm;dynamic programming;block design;very large scale integrated process technologies;optimization technique;dynamic programming dp;dynamic programming algorithm;continuous variable;resource management;wires;dynamic program;very large scale integrated;interconnect bundle sizing;interconnect sizing and spacing;power delay optimization dynamic programming dp gridded design rules interconnect sizing and spacing;design rules;power delay optimization;vlsi dynamic programming integrated circuit interconnections;size 32 nm interconnect bundle sizing discrete design rules very large scale integrated process technologies continuous variable optimization techniques dynamic programming algorithm optimal power delay tradeoff curve industrial microprocessor blocks post layout optimization step vlsi;total power;weighted sums;heuristic algorithms;integrated circuit interconnections;wires delay optimization integrated circuit interconnections algorithm design and analysis resource management heuristic algorithms;industrial microprocessor blocks;vlsi;post layout optimization step;optimization;discrete design rules;power delay product;optimal power delay tradeoff curve;algorithm design and analysis;gridded design rules;continuous variable optimization techniques	The lithography used for 32 nm and smaller very large scale integrated process technologies restricts the admissible interconnect widths and spaces to a small set of discrete values with some interdependencies, so that traditional interconnect sizing by continuous-variable optimization techniques becomes impossible. We present a dynamic programming (DP) algorithm for simultaneous sizing and spacing of all wires in interconnect bundles, yielding the optimal power-delay tradeoff curve. DP algorithm sets the width and spacing of all interconnects simultaneously, thus finding the global optimum. The DP algorithm is generic and can handle a variety of power-delay objectives, such as total power or delay, or weighted sum of both, power-delay product, max delay, and alike. The algorithm consistently yields 6% dynamic power and 5% delay reduction for interconnect channels in industrial microprocessor blocks designed in 32 nm process technology, when applied as a post-layout optimization step to redistribute wires within interconnect channels of fixed width, without changing the area of the original layout.	davis–putnam algorithm;dynamic programming;electrical connection;global optimization;interdependence;mathematical optimization;maximal set;microprocessor;pareto efficiency;power–delay product;rounding;routing;tab stop;weight function	Konstantin Moiseev;Avinoam Kolodny;Shmuel Wimer	2010	IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems	10.1109/TCAD.2010.2051633	mathematical optimization;electronic engineering;computer science;resource management;dynamic programming;mathematics;engineering drawing;algorithm	EDA	16.196302143058272	52.77184367159203	9764
f2fca12cbdab6055cb08d45fa1e123239a44da17	hadamard minimum storage regenerating code revisited	silicon;error correction codes;systematics;node capacity hadamard minimum storage regenerating code systematic nodes;maintenance engineering;systematics maintenance engineering error correction error correction codes peer to peer computing encoding silicon;hadamard codes;error correction;msr code distributed storage hadamard high rate;peer to peer computing;encoding	In this letter, we revisit the Hadamard minimum storage regenerating code to form a new minimum storage regenerating code. The resultant new code has two more systematic nodes than that of the Hadamard minimum storage regenerating code with the same node capacity. Furthermore, we present simple but efficient repair strategies for all the systematic nodes of the new code.	hadamard transform;resultant	Sina Zhang;Jie Li;Xiaohu Tang	2016	IEEE Communications Letters	10.1109/LCOMM.2016.2518671	maintenance engineering;systematic code;polynomial code;constant-weight code;error detection and correction;computer science;theoretical computer science;cyclic code;linear code;distributed computing;systematics;locally testable code;silicon;hadamard code;algorithm;encoding;statistics	Embedded	36.34261915629714	58.63868299758039	9765
3786d208cc5219274c984cdaf56008b5293a0940	observer-based secure communication using indirect coupled synchronization	generators;chaotic communication;chaotic communication oscillators synchronization transmitters generators receivers;oscillators;chua system chaotic communication systems chaotic synchronization lorenz system;chua system;receivers;lorenz oscillator indirect coupled synchronization observer based secure communication system chaotic oscillator transmitter receiver chaotic keystream generation encryption message decryption chua oscillator;transmitters chaotic communication cryptography oscillators receivers telecommunication security;chaotic communication systems;synchronization;cryptography;transmitters;telecommunication security;chaotic synchronization;lorenz system;h600 electronic and electrical engineering	In this paper, an observer-based secure communication system composed of four chaotic oscillators is proposed. Observer based synchronization is achieved between two of these oscillators and employed as a transmitter and a receiver. The other two oscillators are indirectly coupled and are employed as keystream generators. The novelty lies in the generation of the same chaotic keystream both in the transmitter and receiver side for encryption and decryption purposes. We show, in particular, that it is possible to synchronize the two keystream generators even though they are not directly coupled. So doing, an estimation of the keystream is obtained allowing decrypting the message. The performance of the proposed communication scheme is shown via simulation using the Chua and Lorenz oscillators.	chua's circuit;cryptography;encryption;secure communication;simulation;synchronization (computer science);transmitter	Rupak Kharel;Krishna Busawon;Zabih Ghassemlooy	2012	2012 8th International Symposium on Communication Systems, Networks & Digital Signal Processing (CSNDSP)	10.1109/CSNDSP.2012.6292797	synchronization;telecommunications;computer science;cryptography;lorenz system;control theory	Arch	34.71651947296634	46.89502943172518	9783
3eec3b86704235319273860f12180aed874e4533	ibaw: an implication-tree based alternative-wiring logic transformation algorithm	design automation;redundancy checking reduction;integrated circuit layout;logic transformation algorithm;automatic test pattern generation;tree data structures;ibaw algorithm;high level synthesis;implication tree data structure;redundancy;logic synthesis;atpg based alternative wiring algorithm;vlsi;source node selection;rewiring capability;circuit layout cad;integrated logic circuits;circuit optimisation	The well-known ATPG-based alternative wiring technique, RAMBO, has been shown to be very useful because of its proven powerfulness and flexibility in attacking many design automation problems (e.g. logic optimization, circuit partitioning, and post-layout logic transformation, etc.). Since the ATPG based alternative wire locating procedure is the center engine for all its applications, speeding up of this process should be very crucial and useful, We observe that the bottleneck of the technique lies in the costly redundancy tests among a large number of candidate alternative wires. In this paper, we develop a so-called implication-tree data structure which stores the implication relationship between nodes with determined logic values, and propose a new ATPG-based alternative-wiring algorithm to speed up the engine. The algorithm, Implication-tree Based Alternative-Wiring (IBAW), differs from other ATPG-based algorithms in terms that it selects the source node of alternative wires from the implication-tree, which makes IBAW able to trim out many unnecessary redundancy checking quite easily without calling for complicated procedures. Hence, it produces a steady speeding up of around 3.6 times faster while maintaining the same rewiring capability of the original RAMBO. Our experimental results show that the overall circuit area optimized by IBAW can be slightly better than that by RAMBO, while the runtime is just one-half of the latter.	algorithm;code;data structure;erlang (programming language);error detection and correction;general-purpose markup language;heuristic (computer science);logic optimization;mathematical optimization;memorandum;tree (data structure);whole earth 'lectronic link;wiring	Wangning Long;Yu-Liang Wu;Jinian Bian	2000	Proceedings 2000. Design Automation Conference. (IEEE Cat. No.00CH37106)	10.1109/ASPDAC.2000.835136	embedded system;electronic engineering;logic synthesis;electronic design automation;computer science;electrical engineering;theoretical computer science;automatic test pattern generation;integrated circuit layout;very-large-scale integration;tree;redundancy;high-level synthesis;algorithm	EDA	16.523489308079892	49.27162453020829	9785
fa8290551331bd74ed7b9c0f14be5d4424b40ddf	some relationships between certain multivalently analytic and multivalently meromorphic functions	multivalent meromorphic starlikeness and convexity;principal values;unit disk;multivalently analytic and meromorphic function;complex inequalities;multivalent starlikeness and convexity;punctured unit disk	The aim of this investigation is to reveal some relationships between certain multivalently analytic functions and multivalently meromorphic functions, and then to focus on certain consequences of these which will be important or interesting for analytic or geometric function theory.	analytic signal	Hüseyin Irmak	2013	Mathematical and Computer Modelling	10.1016/j.mcm.2012.06.037	unit disk;mathematical optimization;mathematical analysis;topology;mathematics	Theory	47.19621497864906	24.75807561133775	9813
c066cb351cf0f2dabab111324f6a09b88a4c765f	convergence in homogeneous random graphs	random graph;first order	"""For a sequence p = (p(1), p(2),. . .) let G(n, p) denote the random graph with vertex set {1, 2,. .. , n} in which two vertices i, j are adjacent with probability p(|i − j|), independently for each pair. We study how the convergence of probabilities of first order properties of G(n, p), can be affected by the behaviour of p and the strength of the language we use. 1. Introduction. Random graph theory studies how probabilities of properties of random graphs change when the size of the problem, typically the number of vertices of the random graph, approaches infinity. The most commonly used random graph model is G(n, p) the graph with vertex set [n] = {1, 2,. .. , n}, in which two vertices are joined by an edge independently with probability p. It was shown by Glebskii, Kogan, Liogonkii and Talanov [GKLT 69] and, independently, by Fagin [Fa 76], that in G(n, p), the probability of every property which can be expressed by a first order sentence ψ tends to 0 or 1 as n → ∞. Lynch [Ly 80] proved that even if we add to the language the successor predicate the probability of each first order sentence still converges to a limit. (Here and below the probability of a sentence ψ means the probability that ψ is satisfied.) However it is no longer true when we enrich the language further. Kaufmann and Shelah [KS 85] showed the existence of a monadic second order sentence φ, which uses only the relation of adjacency in G(n, p), whose probability does not converge as n → ∞. Furthermore, Compton, Henson and She-lah [CHS 87] gave an example of a first order sentence ψ containing predicate """" ≤ """" such that the probability of ψ does not converge – in fact in both these cases the probability of sentences φ and ψ approaches both 0 and 1 infinitely many times."""	converge;cylinder-head-sector;graph theory;monadic predicate calculus;rado graph;random graph;vertex (geometry);vertex (graph theory);windows legacy audio components	Tomasz Luczak;Saharon Shelah	1995	Random Struct. Algorithms	10.1002/rsa.3240060402	random graph;combinatorics;discrete mathematics;first-order logic;mathematics	Theory	37.88830714430538	15.779416558529634	9819
52795087b62fb79234bcd785e87dddbd171d0951	a general model for cyclic machine scheduling problems	cyclic scheduling problems;modelizacion;mixed integer linear program;cycle time;68t20;optimisation;temps cycle;nombre entier;problema transporte;transportation problem;combinatorics;optimizacion;generic model;procedimiento;structure programme;robotic cell;probleme transport;68t40;combinatoria;combinatoire;robotics;resolucion problema;modelisation;integer;estructura programa;informatique theorique;scheduling;ciclico;entero;cyclic scheduling;robotica;cyclique;scheduling problem;job shop;machine scheduling;tabu search;optimization;robotique;transportation robots;robot;modeling;program structure;single hoist scheduling problems;ordonnancement;cyclic;busqueda tabu;reglamento;recherche tabou;problem solving;resolution probleme;procedure;computer theory;68m20;informatica teorica	Ageneral framework formodeling and solving cyclic scheduling problems is presented. The objective is to minimize the cycle time. The model covers different cyclic versions of the job-shop problem found in the literature, robotic cell problems, the single hoist scheduling problem and tool transportation between the machines. It is shown that all these problems can be formulated as mixed integer linear programs which have a common structure. Small instances are solved with CPLEX. For larger instances tabu search procedures have been developed. The main ideas of these methods are indicated. © 2008 Elsevier B.V. All rights reserved.	automated planning and scheduling;cplex;javascript syntax;job shop scheduling;linear programming;robot;scheduling (computing);tabu search	Peter Brucker;Thomas Kampmeyer	2008	Discrete Applied Mathematics	10.1016/j.dam.2008.03.029	integer;robot;transportation theory;procedure;mathematical optimization;systems modeling;cyclic group;tabu search;cycle time variation;mathematics;robotics;scheduling;algorithm	AI	18.631554188541894	7.679970078056627	9845
0520ca3a4efbeab24d6fcba7c0a0d476e2793c7c	planar maps as labeled mobiles	labeled tree;statistical mechanics;geodesic distance;recursion relation;generating function;matrix model	We extend Schaeffer’s bijection between rooted quadrangulations and welllabeled trees to the general case of Eulerian planar maps with prescribed face valences to obtain a bijection with a new class of labeled trees, which we call mobiles. Our bijection covers all the classes of maps previously enumerated by either the two-matrix model used by physicists or by the bijection with blossom trees used by combinatorists. Our bijection reduces the enumeration of maps to that, much simpler, of mobiles and moreover keeps track of the geodesic distance within the initial maps via the mobiles’ labels. Generating functions for mobiles are shown to obey systems of algebraic recursion relations. 1. Preliminaries 1.	distance (graph theory);image scaling;linear algebra;list of code lyoko characters;map;maximal set;recursion;scaling limit;transmission coefficient	J. Bouttier;Philippe Di Francesco;E. Guitter	2004	Electr. J. Comb.		generating function;combinatorics;discrete mathematics;geodesic;topology;statistical mechanics;mathematics;algebra	Theory	28.586766258039777	33.7762735770373	9853
5b5bd5a915d01d9413f6ff1543129d30de7f25d2	parallelizing broad phase collision detection for animation in games: a performance comparison of cpu and gpu algorithms	libraries;bullet;broad phase collision detection;physics based digital games broad phase collision detection algorithm parallelization cpu based algorithm gpu based algorithm computer animations three dimensional interactive simulations bullet library cuda heterogeneous algorithm complex unpredictable object movements;bullet performance analysis broad phase collision detection cpu gpu;gpu;physics;graphics processing units collision avoidance instruction sets algorithm design and analysis libraries games physics;graphics processing units;games;performance analysis;collision avoidance;cpu;algorithm design and analysis;software libraries computer animation computer games graphics processing units interactive systems parallel architectures;instruction sets	Games, computer animations and three-dimensional interactive simulations have required the use of realistic and faster than ever before broad phase collision detection algorithms. In this work, we compare the performance of four broad phase algorithms implemented on CPU and GPU, using four different test scenarios. More specifically, one of them is a new GPU-based algorithm that we have developed in the Bullet library using CUDA, and the other three remaining implementations are CPU-based algorithms available in the same library. The experimental results show that the heterogeneous algorithm is competitive when compared to some robust methods available in Bullet, particularly in scenes with a large number of objects whose movements are complex and unpredictable. We believe that initiatives like this, which explore solutions for new implementations of collision algorithms running on GPU and operating asynchronously with the CPU, are extremely important and useful for game designers, especially in the area of digital games based on Physics, considering there are other elements of the animation, e.g., sound and artificial intelligence, which can thus be executed during the broad phase calculation.	algorithm;artificial intelligence;brainfuck;byte;cuda;central processing unit;collision detection;computer animation;control theory;graphics processing unit;parallel computing;proxy server;simulation;video card;xiii	Ygor Rebouças Serpa;Maria Andréia F. Rodrigues	2014	2014 Brazilian Symposium on Computer Games and Digital Entertainment	10.1109/SBGAMES.2014.29	games;algorithm design;simulation;computer science;theoretical computer science;operating system;central processing unit;instruction set;computer graphics (images)	Graphics	-0.010842042015726024	40.669893460907055	9857
01a6b8b734b1d4fd7a29cb6d852d68588ea9fbb2	existence problem of telescopers: beyond the bivariate case	telescoper;reduction;summability;rational function	In this paper, we solve the existence problem of telescopers for rational functions in three discrete variables. We reduce the problem to that of deciding the summability of bivariate rational functions, a problem which has recently been solved. This existence criteria is used, for example, for detecting the termination of Zeilberger's algorithm to the function classes studied in this paper.	algorithm;bivariate data;sensor;turing completeness	Shaoshi Chen;Qing-Hu Hou;George Labahn;Rong-Hua Wang	2016		10.1145/2930889.2930895	rational function;mathematical optimization;mathematical analysis;discrete mathematics;reduction;mathematics;algebra	AI	47.11469742902803	34.63752147615373	9858
9be9483c20094a12d674deed97742cb311d034dd	exploring the diameter and broadcast time of general knödel graphs using extensive simulations	communication properties;knodel graph;interconnection networks	Efficient dissemination of information remains a central challenge for all types of networks. There are two ways to handle this issue. One way is to compress the amount of data being transferred and the second way is to minimize the delay of information distribution. Well-received approaches used in the second way either design efficient algorithms or implement reliable network architectures with optimal dissemination time. Among the well-known network architectures, the Knödel graph can be considered a suitable candidate for the problem of information dissemination. The Knödel graph Wd,n is a regular graph, of an even order n and degree d, 1 ≤ d ≤ ⌊log2 n⌋. The Knödel graph was introduced by W. Knödel almost four decades ago as network architecture with good properties in terms of broadcasting and gossiping in interconnected networks. Although the Knödel graph has a highly symmetric structure, its diameter is only known for, Wd2d. Recently, the general upper and lower bounds on diameter and broadcast time of the Knödel graph have been presented.  In this paper, our motivation is to explore the communication properties of Knödel graph in terms of the diameter, the number of vertices at a particular distance and the broadcast time. Experimentally, we obtain the following results; (a) the diameter of some specific Knödel graphs, (b) the propositions on the number of vertices at a particular distance, and (c) the upper bound on the broadcast time of Knödel graph. We also construct a new graph, denoted as HWd2d by connecting Knödel graph Wd-1,2d-1 to hypercube Hd-1 and experimentally show that HWd2d have even a smaller diameter than Knödel graph Wd2d.	algorithm;diameter (protocol);emoticon;experiment;network architecture;simulation;vertex (geometry);whole earth 'lectronic link	Hovhannes A. Harutyunyan;Gul B. Oad	2014		10.1145/2641483.2641531	graph power;factor-critical graph;combinatorics;graph bandwidth;null graph;degree;regular graph;distance-regular graph;theoretical computer science;simplex graph;cubic graph;mathematics;voltage graph;distributed computing;butterfly graph;complement graph;line graph;coxeter graph	Theory	21.619400157830796	35.950872008438814	9859
49354d482616460d4912bae97740ece3621dbf6f	a parallel scheduler based on acyclic stable matching.	stable matching	Dept. of Mathematics & Computer Science, Salisbury University, Salisbury, MD 21801 Dept. of Electrical and Computer Engineering, University of Nevada, Las Vegas, NV 89154 Dept. of Computer Science, University of Texas at Dallas, Richardson, TX, 75080 School of Informatics, University of Nevada, Las Vegas, NV 89154 Emails: ealu@salisbury.edu , {meiyang, shankarn, jo}egr.unlv.edu, sizheng@utdallas.edu	cmos;computer engineering;computer science;directed acyclic graph;informatics;mathematical optimization;network switch;nv network;parallel algorithm;requirement;richardson number;router (computing);scheduling (computing);simulation;stable marriage problem	Enyue Lu;Mei Yang;Si-Qing Zheng;Shankar N. Neelakrishnan;Ju-Yeon Jo	2007	I. J. Comput. Appl.		stable marriage problem;computer science	Theory	19.034389413882305	31.087649107250854	9860
7cbfc0c8ed3c1ae7f6128bafa547de97208f511a	fpga architectural research: a survey	commercial products fpga architectural research field programmable devices commercial devices research studies fpga architecture total chip area speed performance;reconfigurable architectures;chip;field programmable gate arrays table lookup integrated circuit interconnections design automation logic circuits transistors integrated circuit measurements integrated circuit technology circuit testing flexible printed circuits;fpga architecture;reconfigurable architectures field programmable gate arrays microprocessor chips;field programmable gate arrays;microprocessor chips	A recent article by S. Brown and J. Rose (see ibid., vol.13, no.2, p.42-57, 1996) summarized the classes of field programmable devices currently available and described many of the most important commercial devices. We describe current research studies, evaluating the enhancements to FPGA architecture each recommends and how these architectures affect the two most important metrics: total chip area and speed performance. We also note examples of commercial products possessing features consistent with the recommendations of the research studies.	field-programmable gate array	Stephen Dean Brown	1996	IEEE Design & Test of Computers	10.1109/54.544531	chip;embedded system;electronic engineering;telecommunications;reconfigurable computing;programmable logic array;computer science;engineering;field-programmable gate array;computer engineering	EDA	11.882946072598788	56.04785511058669	9862
2a84b0e0a02c6fc4446a5033f88d04ae0c9598f1	information theoretic limits for standard and one-bit compressed sensing with graph-structured sparsity		In this paper, we analyze the information theoretic lower bound on the necessary number of samples needed for recovering a sparse signal under different compressed sensing settings. We focus on the weighted graph model, a model-based framework proposed by [Hegde et al.(2015)], for standard compressed sensing as well as for one-bit compressed sensing. We study both the noisy and noiseless regimes. Our analysis is general in the sense that it applies to any algorithm used to recover the signal. We carefully construct restricted ensembles for different settings and then apply Fano’s inequality to establish the lower bound on the necessary number of samples. Furthermore, we show that our bound is tight for one-bit compressed sensing, while for standard compressed sensing, our bound is tight up to a logarithmic factor of the number of non-zero entries in the signal.	algorithm;compressed sensing;fano's inequality;social inequality;sparse matrix;theory	Adarsh Barik;Jean Honorio	2018	CoRR			ML	47.697359643316375	9.377110278184333	9864
9fde0f845fc5e7aa0c65ce4fcd6aeec46454d2e5	student research poster: a scalable general purpose system for large-scale graph processing	parallel programming;roads;graph analytics;large scale graph processing;sun;scalable parallel programming;optimization;scalability;general purpose;parallel programming model;polymers;parallel processing	Graph analytics is an important and computationally demanding class of data analytics. It is essential to balance scalability, ease-of-use and high performance in large scale graph analytics. As such, it is necessary to hide the complexity of parallelism, data distribution and memory locality behind an abstract interface.  The aim of this work is to build a scalable graph analytics framework that does not demand significant parallel programming experience based on NUMA-awareness. The realization of such a system faces two key problems: (i)~how to develop a scale-free parallel programming framework that scales efficiently across NUMA domains; (ii)~how to efficiently apply graph partitioning in order to create separate vand largely independent work items that can be distributed among threads.	abstraction layer;graph (abstract data type);graph partition;locality of reference;parallel computing;scalability	Jiawen Sun	2016	2016 International Conference on Parallel Architecture and Compilation Techniques (PACT)	10.1145/2967938.2971465	parallel processing;parallel computing;scalability;computer science;theoretical computer science;operating system;distributed computing;programming language;graph database;parallel programming model	HPC	-3.6875463871689216	43.38218081768803	9878
2ffea15e93b566ffba960287ca0a14957c0a4c91	out-of-order issue logic using sorting networks	high speed circuits;issue queue;out of order processing;out of order;ilp;sorting network;high speed;micro architecture;instructions per cycle	A fundamental property of superscalar architectures is the execution of multiple instructions per cycle. To accomplish this, the issue logic selects and prioritizes the instructions whose operands will be ready in the next cycle, using wakeup, select and queue update logic. By incorporating the issue logic in one pipeline stage, dependent instructions can be issued in consecutive cycles. However, the many serial operations required makes this problematic from a circuit delay perspective. In this paper, we propose an issue queue design that divides the ready signals into groups, sorts the groups in parallel and provides four oldest ready instructions for issue, with single-cycle operation. Static CMOS select and update logic reduces power and low fan-out in many stages improves circuit speed. The complete issue logic requires 30 inversions, allowing simulated circuit operation at over 3 GHz in a foundry 45nm SOI fabrication process.	cmos;fan-out;instructions per cycle;inversion (discrete mathematics);operand;register renaming;requirement prioritization;semiconductor device fabrication;silicon on insulator;sorting network;superscalar processor	Siddhesh S. Mhambrey;Lawrence T. Clark;Satendra Kumar Maurya;Krzysztof S. Berezowski	2010		10.1145/1785481.1785570	embedded system;electronic engineering;parallel computing;real-time computing;logic optimization;logic family;microarchitecture;sorting network;computer science;out-of-order execution;electrical engineering;theoretical computer science;operating system;algorithm;instructions per cycle	EDA	15.052130336800811	59.715137921732605	9882
e62a109eec50a736b4cd11b34a15cf0b9b8cfc87	efficient approximation algorithms for the subset-sums equality problem	approximate algorithm;partial sums;fully polynomial time approximation scheme	We investigate the problem of finding two nonempty disjoint subsets of a set of n positive integers, with the objective that the sums of the numbers in the two subsets be as close as possible. In two versions of this problem, the quality of a solution is measured by the ratio and the difference of the two partial sums, respectively. Answering a problem of G. J. Woeginger and Z. Yu (1992, Inform. Process. Lett.42, 299?302) in the affirmative, we give a fully polynomial-time approximation scheme for the case where the value to be optimized is the ratio between the sums of the numbers in the two sets. On the other hand, we show that in the case where the value of a solution is the positive difference between the two partial sums, the problem is not 2nk-approximable in polynomial time unless P=NP, for any constant k. In the positive direction, we give a polynomial time algorithm that finds two subsets for which the difference of the two sums does not exceed K/n?(logn), where K is the greatest number in the instance.	approximation algorithm;subset sum problem	Cristina Bazgan;Miklos Santha;Zsolt Tuza	2002	J. Comput. Syst. Sci.	10.1006/jcss.2001.1784	mathematical optimization;combinatorics;discrete mathematics;polynomial-time approximation scheme;computer science;mathematics;series;algorithm	Theory	19.332412706660715	15.594311175714441	9898
9999e767415c4d571f07fe9822c3c87fdcb2eae9	a new capacitated vehicle routing problem with split service for minimizing fleet cost by simulated annealing	flotte;modelizacion;urban transportation;transporte urbano;routing;vehicle routing problem;capacitated vehicle routing problem;modele lineaire;trafic urbain;modele mixte;routage;urban traffic;probleme tournee vehicule;modelo lineal;problema ruta vehiculo;simulated annealing;trafico urbano;modelisation;mixed integer program;recuit simule;programacion mixta entera;mixed model;transport urbain;fleet;linear model;programmation partiellement en nombres entiers;mixed integer programming;recocido simulado;mix integer programming;capacity utilization;modelo mixto;split services;modeling;urban transport;enrutamiento	We address a capacitated vehicle routing problem (CVRP) in which the demand of a node can be split on several vehicles celled split services by assuming heterogeneous fixed fleet. The objective is to minimize the fleet cost and total distance traveled. The fleet cost is dependent on the number of vehicles used and the total unused capacity. In most practical cases, especially in urban transportation, several vehicles transiting on a demand point occurs. Thus, the split services can aid to minimize the number of used vehicles by maximizing the capacity utilization. This paper presents a mix-integer linear model of a CVRP with split services and heterogeneous fleet. This model is then solved by using a simulated annealing (SA) method. Our analysis suggests that the proposed model enables users to establish routes to serve all given customers using the minimum number of vehicles and maximum capacity. Our proposed method can also find very good solutions in a reasonable amount of time. To illustrate these solutions further, a number of test problems in small and large sizes are solved and computational results are reported in the paper.	simulated annealing;vehicle routing problem	Reza Tavakkoli-Moghaddam;Nima Safaei;M. M. O. Kah;Masoud Rabbani	2007	J. Franklin Institute	10.1016/j.jfranklin.2005.12.002	mixed model;mathematical optimization;routing;systems modeling;simulated annealing;capacity utilization;engineering;vehicle routing problem;linear model;mathematics;transport engineering	Theory	17.572707157858552	5.419656453390171	9906
420c62e9d910bf0cbc7216beebfa1da1d4405d39	degree sequence and independence in k(4)-free graphs	independence number;degree sequence	We investigate whether K,-free graphs with few repetitions in the degree sequence may have independence number o(n). We settle the cases r = 3 and r >/5, and give partial results for the very interesting case r=4 . In an earl ier art icle I-4] it is shown that t r iangle-free graphs in which no term of the degree sequence occurs more than twice must be bipar t i te , but that there exist t r iangle-free graphs with a rb i t ra r i ly large ch roma t i c number in which no degree occurs more than three times. It is easy to see that the large chromat ic number in such graphs is not due to small independence number , since the ne ighbors of a vertex are independent , and the restr ic t ion on repeated degrees forces there to be vertices of large degree. If one excludes K 4 ra ther than K3, the s i tua t ion is cons iderab ly more myster ious, F o r a g raph G we define f ( G ) to be the m a x i m u m number of occurrences of an e lement of the degree sequence of G. Tha t is, i f f ( G ) = k , then some set of k vertices have the same degree but no set of k + 1 vertices have the same degree. Note that f ( G ) >~ 2 if G has at least two vertices. T h r o u g h o u t the paper we will assume that our graphs have no isola ted vertices so that 6 ~> 1. The number of vertices of G will be deno ted by n or v(G). The number of edges of G will be deno ted by e(G). We shall use /3 to denote the independence number of a graph. We address the fol lowing quest ion in this paper . * Corresponding author. Z This research was partially supported by NSA grant MDA-89-H-2036. 2 This research was partially supported by NSA grant MSPPS-054-91. 0012-365X/95/$09.50 © 1995-Elsevier Science B.V. All rights reserved SSDI 0 0 1 2 3 6 5 X ( 9 3 ) E 0 2 2 6 T 286 P. Erd6s et al. / Discrete Mathematics 141 (1995) 285-290 Question 1. Suppose G is a graph with no Kr and with f(G)<~ k. Is it possible that ~=o(n)? The answer to Quest ion 1 is no if r = 3 or r = 4 and k ~< 3. The answer to Quest ion 1 is yes if r ~> 5. These answers are provided by Theorems 1, 2, 6, and 7. For K4-free graphs w i t h f ( G ) ~> 4 we do not know whether fl = o (n) is possible. This is an interesting open question. Theorem 1. If G contains no K 3 and f(G) <<, k, then fl>~n/k, so fl v~ o(n). Proof. There exists a vertex of degree at least n/k. The neighbors of this vertex form an independent set. [] This settles the case r = 3 of Quest ion 1 with a negative answer. Theorem 1 also raises the following interesting question. Question 2. Suppose G contains n o g 3 a n d f ( G ) ~< k. Is the lower bound fl >~ n/k best possible? We will show next that the lower bound on fl given in Theorem 1 is sharp for k = 2 and asymptot ica l ly sharp for k = 4 before cont inuing our considerat ion of Question 1. Invest igat ing Quest ion 2 is an interesting open p rob lem for k other than 2 or 4. For each positive integer n, let H , be the graph on 4n vertices with vertex classes A={ai}7=l, B={bl}7=l, C={ci}7=1, and D={di}7=l and with edge set defined as follows. Edges {a, bj: i<~j}, {cid/ i>~j}, {a,di: l <~i<~n}, {b,ci: l <~i<<,n}, {bidi+l: ivan}, and {ciai+l: ivan} (see Fig. 1). The subgraph of H . induced by A • B is a bipart i te half-graph, as is the subgraph induced by C w D. If G is a bipart i te half g raph on 2n vertices, then it is easy to see that f ( G ) = 2 and fl=n. Thus the lower bound given in Theorem 1 can be exact for k = 2 . We now consider the case when k = 4. The degrees of the vertices of H . are as follows: d(al)=d(dl)=n+3-i if i~: 1, d(al)=d(dl)=n-~ 1, d(bl)=d(cl)=i+2 if i 4: n, and d(b.)=d(c.)=n+ 1. Hence every degree between 3 and n is repeated 4 times, while degree n + 1 is repeated 8 times, so f (H. ) = 8. The 4 vertices of H . with subscript k are said to be level k of H . and denoted by Lk for each k f rom 1 to n. We note that the vertices in levels 1 through k induce Hk, which will be useful in the induct ion a rgument which follows. We claim that f l (H.)=n+l. This can be checked for n = l and n = 2 . The set A w {c. } is an independent set of n + 1 vertices in H. , so we concentra te on showing f l (H.) ~< n + 1. Suppose this is true for n ~< r and suppose S is an independent set of r + 3 vertices in Hr+ 1. If IS n L,+ 11 ~< 1, then, since the first r levels of H,+ 1 induce H,, we have by induction that ISI ~< (r+ 1)+ 1 < r + 3 ; a contradict ion. Thus S contains 2 elements in L,+ 1. Each level is a 4 cycle, so there are only two possibilities. We assume without loss of generali ty that S contains a,+ 1 and c,+ 1. N o w c,+ 1 is adjacent P. ErdlJs et a l / Discrete Mathematics 141 (1995) 285-290 287	asymptote;degree (graph theory);discrete mathematics;existential quantification;graph (discrete mathematics);invest (mnemonic);image-line fl studio;independent set (graph theory);mathematical induction;new general catalogue;r language;re-order buffer;representation oligonucleotide microarray analysis;vertex (graph theory);xojo	Paul Erdös;Ralph J. Faudree;Talmage James Reid;Richard H. Schelp;William Staton	1995	Discrete Mathematics	10.1016/0012-365X(93)E0226-T	arithmetic;combinatorics;discrete mathematics;degree;mathematics	Theory	31.65468399664942	27.840168499223214	9918
667e6c4dc0c4eda50dd8826e1f23e69d967f466e	approximation algorithms for geometric, caching and scheduling problems	qa mathematics	In this thesis we study approximation algorithms for optimization problems, which is one of the core areas of modern theoretical computer science. We focus on two areas of approximation. First we consider geometric problems, and we present approximation algorithms for the capacitated location routing problem and the capacitated network design problem in the Euclidean plane. Next, we investigate two well known caching and scheduling problems, the generalized caching problem and the reordering buffer management problem. We do this in an online setting, i.e. when instead of getting the whole input data at once, the data arrives in parts,, during the execution of the algorithm.#R##N##R##N#In the capacitated location routing problem a fleet of vehicles with bounded capacity must serve a set of customers. The goal is to choose the depots for the vehicles from a set of possible locations, and fix the routes of the vehicles, to minimize the cost of opening the depots and the length of the routes. We present a quasi-polynomial time approximation scheme for the problem, and a polynomial time approximation scheme for some range of input parameters.#R##N##R##N#In the capacitated geometric network design problem we are given two sets of points in the plane, sources and sinks, where each source wants to send and each sink wants to receive a given amount of flow. The goal is to construct a minimum-length network with bounded edge capacity that allows to route the requested flow from sources to sinks. In addition to the sources and sinks, any other points in the plane can be used as vertices of the network. We present a quasi-polynomial time approximation scheme for the problem, and a polynomial time approximation scheme when the edge capacity is not too large.#R##N##R##N#The generalized caching problem is a classical problem in the area of online algorithms. We are given a set of pages, each page with an arbitrary size and fetching cost, and a cache of bounded size. At each time step a specific page is requested. If the page is not in the cache, it must be fetched into the cache, possibly evicting some other pages. The goal is to design an algorithm that specifies which pages to evict from the cache, minimizing the total cost incurred on the request sequence. We give a randomized online algorithm for the generalized caching problem which is asymptotically optimal, solving a long standing open problem.#R##N##R##N#The reordering buffer management problem is also a well known problem in the area of online algorithms. A stream of colored items arrives at a service station equipped with a reordering buffer of a given capacity. The cost of servicing the items depends on the processing order: servicing an item, when the previous item had a different color, incurs a context switching cost depending on the color of the current item. A scheduling strategy has to decide which item to service next, to minimize the cost of the output sequence. We show lower bounds on the competitive ratio of a deterministic and randomized online algorithm, and a deterministic online algorithm which nearly matches the lower bound.	approximation algorithm;cache (computing);scheduling (computing)	Anna Adamaszek	2012			mathematical optimization;computer science;theoretical computer science;distributed computing;k-server problem;approximation algorithm	Theory	16.76906944407901	15.102193745428577	9950
bbbf9cb32dd3ed5c8f9d5c59b24bf42e1c68796e	parallel dictionaries in 2-3 trees	parallel dictionaries;parallel computer;model of computation;random access	Our model of computation is a parallel computer with k synchronized processors PI,...,Pk sharing a common random access storage, where simultaneous access to the same storage location by two or more processors is not allowed. Suppose a 2-3 tree T with n leaves is implemented in the storage, suppose al,...,a k are data that may or may not be stored in the leaves, and for all i, 1 4 i 4 k, processor Pi knows a i. We show how to search for al,...,a k in the tree T, how to insert these data into the tree and how to delete them from the tree in 0(log n + log k) steps.	2–3 tree;central processing unit;dictionary;model of computation;parallel computing;random access;variable (computer science)	Wolfgang J. Paul;Uzi Vishkin;Hubert Wagener	1983		10.1007/BFb0036940	weight-balanced tree	Theory	12.513820668786215	30.139899935008042	9964
300719f9ab29885171b3a7c8612c5831c9706622	risk assessment and optimization for key services in smart grid communication network		This paper proposes a risk assessment model of key service and optimization methods to reduce service risk in smart grid communication network. Firstly, we analyze the probability of failure of communication link and node which is induced by external factors, like natural disaster, human attack and system disturbances. Then using importance of services, links and nodes, we build the risk model of failure for key services. Further, we propose optimization methods based on Dijkstra algorithms to reduce the risk of key services. Finally, based on part of smart grid communication network topology structure from a Chinese province, the simulation results show that the risk of key services and whole network are reduced.	broadcast delay;dijkstra's algorithm;financial risk modeling;human factors and ergonomics;maintenance mode;mathematical optimization;network topology;risk assessment;simplex algorithm;simulation;telecommunications network	Puyuan Zhao;Xingyu Chen;Peng Yu;Wenjing Li;Xuesong Qiu;Shao-Yong Guo	2017	2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM)	10.23919/INM.2017.7987339	computer network;computer science;distributed computing;telecommunications network;risk management;network topology;smart grid;risk assessment;dijkstra's algorithm	Security	-3.517154829903281	8.25059894467681	9967
35e2d852ad0a0077a02852b6fb47a332b4aaf3fd	lattice-free sets, multi-branch split disjunctions, and mixed-integer programming	90c11;90c60	In this paper we study the relationship between valid inequalities for mixed-integer sets, lattice-free sets associated with these inequalities and the multi-branch split cuts introduced by Li and Richard (2008). By analyzing n-dimensional lattice-free sets, we prove that for every integer n there exists a positive integer t such that every facet-defining inequality of the convex hull of a mixed-integer polyhedral set with n integer variables is a t-branch split cut. We use this result to give a finite cutting-plane algorithm to solve mixed-integer programs. We also show that the minimum value t, for which all facets of polyhedral mixed-integer sets with n integer variables can be generated as t-branch split cuts, grows exponentially with n. In particular, when n = 3, we observe that not all facet-defining inequalities are 6-branch split cuts.	algorithm;convex hull;cutting-plane method;integer programming;linear programming;polyhedron;social inequality	Sanjeeb Dash;Neil B. Dobbs;Oktay Günlük;Tomasz Nowicki;Grzegorz Swirszcz	2014	Math. Program.	10.1007/s10107-013-0654-z	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	25.247805316989258	13.767075227131206	10005
c19d4e7f4ef67c22377c255c75a5a59a23adc105	on the number of overpartitions into odd parts	congruences	Abstract   Let     p  o   ¯    (  n  )    be the number of overpartitions of   n   into odd parts. We prove an identity of     p  o   ¯    (  n  )    and establish many explicit Ramanujan-like congruences for     p  o   ¯    (  n  )    modulo 32 and 64.		Shi-Chao Chen	2014	Discrete Mathematics	10.1016/j.disc.2014.02.015	arithmetic;combinatorics;mathematics;algebra	ML	39.86919988448202	34.55877346358428	10025
a73196b1d6f215c0574dd9919d9b79d3e7aff68b	a unified linear-programming modeling of some topological indices	ga_1 ga1 index;randic index;harmonic index;abc index;sum connectivity index;extremal graph;linear programming;zagreb index	In this paper, we consider an invariant $$I(G)$$I(G) of a graph $$G=(V,E)$$G=(V,E) defined as a summation over all edges, $$I(G) = \sum {c_{ij}x_{ij}}$$I(G)=?cijxij where $$c_{ij}$$cij and $$x_{ij}$$xij is the weight and number, respectively, of edges in $$G$$G connecting vertices of degree $$i$$i and $$j$$j. The graph invariant $$I(G)$$I(G) unifies Randic index, Zagreb index, sum---connectivity index, $$GA_1$$GA1 index, ABC index and harmonic index. Based on linear programming methods, we give the extremal values and extremal graphs of $$I(G)$$I(G) among all simple graphs of order $$n$$n without isolated vertices. Applying this result, we obtain some extremal values of the Randic, Zagreb, sum---connectivity, $$GA_1$$GA1, ABC, and harmonic indices along with the corresponding graphs that obtain these values.	linear programming;topological index	Hanyuan Deng;Guihua Huang;Xiaojuan Jiang	2015	J. Comb. Optim.	10.1007/s10878-013-9672-2	mathematical optimization;combinatorics;discrete mathematics;linear programming;calculus;mathematics	Theory	29.88701600585474	34.96164474752117	10030
b5fc9ea43032883a8b5219c7b47ea6ce96acd4be	concatenated automata in cryptanalysis of stream ciphers	modelizacion;linearity;stream ciphering;linearite;cryptanalyse;approche deterministe;linearidad;deterministic approach;cryptanalysis;modelisation;criptoanalisis;cellular model;stream cipher;criptografia;cryptography;automate cellulaire;linear model;enfoque determinista;cryptographie;cellular automata;modeling;cifrado continuo;cellular automaton;automata celular;cryptage continu	This work shows that sequences generated by a class of linear cellular automata equal output sequences of certain nonlinear sequence generators A simple modelling process for obtaining the automata from a partial description of such generators is here described Furthermore, a method that uses the linearity of these cellular models for reconstructing some deterministic bits of the keystream sequence is presented.	automaton;concatenation;cryptanalysis	Amparo Fúster-Sabater;Pino Caballero-Gil	2006		10.1007/11861201_71	cellular automaton;cryptanalysis;discrete mathematics;computer science;cellular model;cryptography;theoretical computer science;linear model;mathematics;linearity;stream cipher;algorithm;statistics	Crypto	37.30310129958444	45.49933127108205	10037
7ab86ebe61b604c0091fa4e02d656e4dd119db96	cost-effective design of scalable high-performance systems using active and passive interposers		Cutting-edge high-performance systems demand larger and denser processors, but future lithographic nodes are expected to introduce higher manufacturing costs and yield challenges. Die-level integration technologies like passive interposer-based 2.5D have demonstrated the potential for cost reductions through die partitioning and yield improvement, but system performance and scalability may be impacted. Alternatively, active interposer technology, the intersection of 3D and 2.5D methodologies, can provide higher-performance interconnect networks to integrate chiplets, but the active interposer die is itself subject to cost and yield concerns. In this work, we perform a cost and performance comparison between traditional monolithic 2D SoCs, 2.5D passive interposers, and 2.5D/3D active interposers to demonstrate the trade-offs between the interposer types for current and future high-performance systems. This work introduces a multi-die core-binning cost model to demonstrate the yield improvements from interposer-based die partitioning of large multi-core processors. The relative cost and performance scaling trade-offs of passive and active interposer dies are then compared for the target systems, demonstrating that both methodologies can indeed provide cost-effective integration for different system requirements. Finally, this work demonstrates how the extra “prepaid” silicon area of the interposers can be leveraged for fault tolerance to improve yield and cost-effectiveness. In summary, this work concludes that both active and passive interposers can cost-effectively improve the functional and parametric yield of high-performance systems, together providing a cost versus performance space to meet a range of design requirements.	2.5d;analysis of algorithms;capability maturity model;central processing unit;design for manufacturability;desktop computer;die (integrated circuit);fault tolerance;image scaling;interposer;multi-core processor;product binning;requirement;scalability;server (computing);system on a chip;system requirements;throughput	Dylan Stow;Yuan Xie;Taniya Siddiqua;Gabriel H. Loh	2017	2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	10.1109/ICCAD.2017.8203849	computer science;real-time computing;scalability;fault tolerance;interposer;countermeasure;system requirements	EDA	5.9813231644993605	59.70926011320954	10041
5161ace9b9645636f048271a1ca0d94f6413da16	network criticality in vehicular networks	eigenvector centrality;cyber insurance;rebates;bonacich centrality;self defense investment;fines	Network criticality (resistance distance) is a graph-theoretic metric that quantifies network robustness, and that was originally designed to capture the effect of environmental changes in core communication networks. This paper establishes a relationship between information centrality and network criticality and provides a justification for using the average network criticality of a node to quantify the nodes relative importance in a graph.This results provides a basis for designing robust clustering algorithms for vehicular networks.	algorithm;centrality;cluster analysis;graph theory;resistance distance;robustness (computer science);robustness of complex networks;self-organized criticality;semantic network;telecommunications network	Ali Tizghadam;Weiwei Li;Alberto Leon-Garcia	2012	SIGMETRICS Performance Evaluation Review	10.1145/2425248.2425278	network theory;network science;simulation;alpha centrality;centrality;betweenness centrality;computer security	Mobile	-3.4517128583410512	7.167314341613841	10064
a0188c87ef1d17cefb057192bb4dfde6679ea519	evolutionary multiobjective combinatorial optimization (emco)	standard combinatorial optimization problem;multi-objective optimization;black-box optimization technique;genetic algorithm;optimization methods;real-world application;key design consideration;evolutionary algorithm;emo solution;vlsi design;combinatorial optimization;heuristics;emo result;emo technique;interdisciplinary tutorial	Discrete/combinatorial optimization has been an interesting and challenging area to researchers belonging to development of algorithms and OR techniques for real-world applications. Most such problems abstracted/taken from graph theory are NP-complete in single objective, and NP-hard for multiple objectives. There are many applications of such problems in communication topology and VLSI design.  For most such problems, there do not exist good heuristics/algorithms, therefore, black-box optimization techniques, e.g., EAs are usually preferred for getting effective solutions. In this tutorial, we will do a quick review of some of the standard combinatorial optimization problems, and then include the techniques and design of operators to effectively solve EMCO problems taken from real-world applications. This would be followed by some case-studies taken from standard problems. This interdisciplinary tutorial provides a practical foundation for -- (i) an introduction to combinatorial problems and their multiobjective versions, (ii) problem challenges and solution through EMO techniques, (iii) need of designing specialized genetic operators, representation and techniques for embedding of (limited) problem specific knowledge, (iv) few case studies taken form well known EMCO, and comparison of EMO results with the existing heuristics/approximation algorithms, and (v) improvement of the EMO solutions through hybridization using local search and others.  Key design considerations to designing operators/ representations so as to effectively explore the search space will be looked into. In general, the tutorial is aimed at quickly laying a foundation that can be used as the basis for further study, research and development in this emerging area.	approximation algorithm;black box;combinatorial optimization;emoticon;genetic operator;heuristic (computer science);local search (optimization);mathematical optimization;np-completeness;np-hardness;very-large-scale integration	Rajeev Kumar	2008		10.1145/1388969.1389079	optimization problem;mathematical optimization;combinatorics;computer science;multi-objective optimization;machine learning;evolutionary algorithm;mathematics	AI	25.134528236863144	4.753378403262588	10083
0596b7663b783089d644783f8107866c103c3dae	optimal parallel 3-colouring algorithm for rooted trees and its application	maximum degree;parallel algorithm;maximal independent set;rooted tree;optimal algorithm;planar graph	A new optimal parallel algorithm for 3-colouring rooted trees with maximum degree  is presented. The algorithm runs in O( log n/log log n) time on a CRCW PRAM using O( n log log n/log n) processors. This technique is used to develop optimal algorithms for several graph problems including (+1)-colouring of constant degree graphs, 7-colouring of planar graphs or finding a maximal independent set in a planar graph. The technique can be applied to expression tree evaluation as well and yields an optimal logarithmic time algorithm.	algorithm	Peter Rajcáni	1990		10.1007/3-540-53414-8_43	mathematical optimization;combinatorics;discrete mathematics;link/cut tree;reverse-delete algorithm	NLP	18.75958967127837	27.72559714183692	10088
f230c7f010b39d4f3a57c37cea54b887ceb39491	enhancing the performance of symmetric-key cryptography via instruction set extensions	software;reduced instruction set computer;symmetric key cryptography;evaluation performance;procesador risc;algorithm performance;performance evaluation;integrated circuit;logiciel;instruction set extensions;data path;implementation;estudio comparativo;evaluacion prestacion;circuito integrado;endommagement;instruction set architecture;camino datos;coprocessors;deterioracion;software performance;algorithme aes;etude comparative;miniaturisation;jeu instruction;codificacion;instruction set extension;resultado algoritmo;criptografia;cryptography;data encryption standard;international data encryption algorithm;coding;comparative study;risc processor;performance algorithme;symmetric key cryptography software;software algorithms;code size;chemin donnees;cryptographie;logicial;symmetric key;miniaturization;miniaturizacion;processeur risc;advanced encryption standard symmetric key cryptography instruction set extensions data encryption standard international data encryption algorithm;advanced encryption standard;damaging;implementacion;magnetic cores;algoritmo aes;cryptography software algorithms computer aided instruction software standards hardware throughput software performance computer architecture acceleration degradation;circuit integre;instruction sets cryptography;software implementation;codage;instruction sets;throughput;hardware;aes algorithm	In this paper, instruction set extensions for a reduced instruction set computer processor are presented to improve the software performance of the data encryption standard (DES), the triple DES, the international data encryption algorithm (IDEA), and the advanced encryption standard (AES) algorithms. The most computationally intensive operations of each algorithm are off-loaded to a set of newly defined instructions. The additional hardware required to support these instructions is integrated into the processor's data path. For each of the targeted algorithms, comparisons are presented between traditional software implementations and new implementations that take advantage of the extended instruction set architecture. Results show that the utilization of the proposed instructions significantly reduces program code size, and improves encryption and decryption throughput. Moreover, the additional hardware resources required to support the instruction set extensions increase the total area of the processor by less than 65%. Finally, it will be shown that the throughputs for triple DES, IDEA, and AES are approximately the same when accelerated via instruction set extensions. This allows for seamless and transparent algorithm agility as one algorithm may be easily replaced by another algorithm with minimal performance degradation.	byte;central processing unit;clock rate;column-oriented dbms;cryptography;elegant degradation;encryption;field-programmable gate array;leon;run time (program lifecycle phase);seamless3d;software performance testing;symmetric-key algorithm;throughput;triple des	Sean O'Melia;Adam J. Elbirt	2010	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2009.2025171	embedded system;computer architecture;parallel computing;application-specific instruction-set processor;computer science;theoretical computer science;operating system;instruction set;symmetric-key algorithm;aes instruction set;instruction path length;algorithm	Arch	8.182470706526807	45.02718995125806	10089
6b46672e0039bd4a080fdbbdaf815db8f72bb16f	dc micro — grid pricing and market model		The fundamental roots of micro-grids are different types of renewable energy sources. There are two broad and distinctive control set ups for power systems. They are centralized and decentralized (hierarchical) controls. In market models of micro-grids there are normally groups of electricity sources and loads that operate in synch with a centralized grid or macro-grid. This paper studies the functionality and ideas of micro-grids. Then implementing Artificial Neural Network (ANN) model for the proposed micro-grid in very precise manner is established. It proposes general simulation modeling for micro-grid using MATLAB, Simulink and (ANN). Its goal is to connect between the most important parameters in DC-Microgrid and price. This modeling approach proposes general Modeling and simulation at more probable situations for variable values at each bus. The ANN model for the proposed range of Different parametric characteristics is presented for Extended Analysis on IEEE 14-Bus Test System. Finally, algebraic equations for the ANN model are deduced in order to optimize them in the future for optimal micro-gridu0027s performance. The training, testing and validating data for this ANN model is extracted from a real micro-grid to connect between numbers of units at each DG source (Distributed Generation), Loads, Minimum/ Maximum Power, Marginal Loss Factor and Time (Hour) over 24 hours as inputs, with Cost ($), Saving ($), Revenue ($), Profit ($) as outputs. So, it helps the humanity to understand more about renewable energy sources and techniques. Moreover, it presents an excellent model to predict the price and saving with this trend in power systems especially from the side of humans or customers. The work is useful for creating sustainable business model for energy access to energy deprived population. The paperu0027s presentation includes examples and comparisons for approachu0027s validity. Now, there is a running real-time validation for the work via OPAL real-digital-simulator.	algebraic equation;artificial neural network;centralized computing;discontinuous galerkin method;ibm power systems;matlab;marginal model;maximum power transfer theorem;microgrid;real-time clock;simulation;simulink;structural load	Zacakry Minshew;Adel El-Shahat	2017	2017 IEEE Global Humanitarian Technology Conference (GHTC)	10.1109/GHTC.2017.8239282	mathematical optimization;grid;distributed generation;maximum power principle;electric power system;data modeling;modeling and simulation;parametric statistics;population;computer science	Metrics	4.848903187195151	5.875447121872366	10096
06a4f49882e9b9a166b8aa4c8abdccecf5a32119	bicovering: covering edges with two small subsets of vertices	004;bi covering unique games max bi clique	We study the following basic problem called Bi-Covering. Given a graph G(V, E), find two (not necessarily disjoint) sets A subseteq V and B subseteq V such that A union B = V and that every edge e belongs to either the graph induced by A or to the graph induced by B. The goal is to minimize max{|A|, |B|}. This is the most simple case of the Channel Allocation problem [Gandhi et al., Networks, 2006]. A solution that outputs V,emptyset gives ratio at most 2. We show that under the similar Strong Unique Game Conjecture by [Bansal-Khot, FOCS, 2009] there is no 2 - epsilon ratio algorithm for the problem, for any constant epsilon > 0.#R##N##R##N#Given a bipartite graph, Max-bi-clique is a problem of finding largest k*k complete bipartite sub graph. For Max-bi-clique problem, a constant factor hardness was known under random 3-SAT hypothesis of Feige [Feige, STOC, 2002] and also under the assumption that NP !subseteq intersection_{epsilon > 0} BPTIME(2^{n^{epsilon}}) [Khot, SIAM J. on Comp., 2011]. It was an open problem in [Ambuhl et. al., SIAM J. on Comp., 2011] to prove inapproximability of Max-bi-clique assuming weaker conjecture. Our result implies similar hardness result assuming the Strong Unique Games Conjecture.#R##N##R##N#On the algorithmic side, we also give better than 2 approximation for Bi-Covering on numerous special graph classes. In particular, we get 1.876 approximation for Chordal graphs, exact algorithm for Interval Graphs, 1 + o(1) for Minor Free Graph, 2 - 4*delta/3 for graphs with minimum degree delta*n, 2/(1+delta^2/8) for delta-vertex expander, 8/5 for Split Graphs, 2 - (6/5)*1/d for graphs with minimum constant degree d etc. Our algorithmic results are quite non-trivial. In achieving these results, we use various known structural results about the graphs, combined with the techniques that we develop tailored to getting better than 2 approximation.	vertex (geometry)	Amey Bhangale;Rajiv Gandhi;Mohammad Taghi Hajiaghayi;Rohit Khandekar;Guy Kortsarz	2016		10.4230/LIPIcs.ICALP.2016.6	1-planar graph;outerplanar graph;block graph;random regular graph;pathwidth;mathematical optimization;split graph;combinatorics;discrete mathematics;triangle-free graph;cograph;universal graph;interval graph;independent set;bipartite graph;degree;computer science;clique problem;forbidden graph characterization;graph coloring;mathematics;tree-depth;chordal graph;indifference graph;line graph;algorithm	NLP	23.501828780091937	23.040894711744397	10099
2a3ad582ef3cb1f666900d35af22cde5af3c9e65	deterministic cooperating distributed grammar systems	grammar systems;local unambiguity;parser construction;strict deterministic constraint;global unambiguity;strict deterministic restriction;strict deterministic grammar;local variant;entire system;grammar system;total variant	Subclasses of grammar systems that can facilitate parser construction appear to be of interest. In this paper, some syntactical conditions considered for strict deterministic grammars are extended to cooperating distributed grammar systems, restricted to the terminal derivation mode. Two variants are considered according to the level to which the conditions address. The local variant, which introduces strict deterministic restrictions for each component of the system apart, results in local unambiguity of the derivations. Rather unexpected, the total variant, which extends the strict deterministic constraints at the level of the entire system, results in some cases in global unambiguity of the derivations. TUCS Research Group Mathematical Structures of Computer Science	computer science;grammar systems theory	Valeria Mihalache;Victor Mitrana	1997		10.1007/3-540-62844-4_9	grammar systems theory;linguistics	AI	-2.3254867957644403	15.698953589413236	10103
52c430ecb15439997ddc738dbe6b3af84719f0f0	partitioned register files for vliws: a preliminary analysis of tradeoffs	register file	An ideal VLIW architecture requires a large multiport register file that is currently not realizable in practice. We analyze a Limited Connectivity VLIW architecture as a realizable alternative that limits the number of ports. We present a fine-grain code partitioning method for this model. The partitioning scheme was applied to a number of standard benchmarks by varying the number ports on a RF, the number of partitions and the communication bandwidth between partitions. We present these results, along with a preliminary analysis of architectural tradeoffs in the actual implementation of these Limited Connectivity VLIWs.	archi;benchmark (computing);demoscene compo;performance;radio frequency;register file	Andrea Capitanio;Nikil D. Dutt;Alexandru Nicolau	1992		10.1145/144953.145839	chemistry;control register;register file;status register;memory data register	Arch	0.33819409016946733	50.20382864850538	10106
97477afa5843a68bae64b37fc4c28ab8f44bc136	an event-driven massively parallel fine-grained processor array	arrays multicore processing registers synchronization field programmable gate arrays clocks;clocks;parallel processing cmos integrated circuits;arrays;scalable mimd many core event driven fine grained processor array parallel processing;registers;synchronization;multicore processing;field programmable gate arrays;power 75 4 mw event driven massively parallel fine grained processor array multi core event driven parallel processor array design 8 bit processing cores 2d mesh network topology mimd architecture cmos process size 65 nm frequency 80 mhz	A multi-core event-driven parallel processor array design is presented. Using relatively simple 8-bit processing cores and a 2D mesh network topology, the architecture focuses on reducing the area occupation of a single processor core. A large number of these processor cores can be implemented on a single integrated chip to create a MIMD architecture capable of providing a powerful processing performance. Each processor core is an event-driven processor which can enter an idle mode when no data is changing locally. An 8 × 8 prototype processor array is implemented in a 65 nm CMOS process in 1,875 μm × 1,875 μm. This processor array is capable of performing 5.12 GOPS operating at 80 MHz with an average power consumption of 75.4 mW.	8-bit;application-specific integrated circuit;cmos;central processing unit;clock rate;event (computing);event-driven programming;extrapolation;image scaling;integrated circuit;mimd;mesh networking;multi-core processor;network topology;parallel computing;peripheral;processor array;prototype;scalability;tops	Declan Walsh;Piotr Dudek	2015	2015 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2015.7168891	multi-core processor;synchronization;computer architecture;parallel computing;real-time computing;telecommunications;computer science;operating system;processor register;field-programmable gate array	Arch	4.33405717659618	47.00021461217095	10109
b41b52fa67a61bb74683aaa4d05f65de13b11986	does there exist a combinational tsc checker for 1/3 code using only primitive gates?			combinational logic;time stamp counter	Wen-Feng Chang;Cheng-Wen Wu	1997	J. Inf. Sci. Eng.		arithmetic;theoretical computer science;algorithm	Logic	21.381522780359678	48.007302195871176	10121
a1c4e5e62537fca72f3e0fd5c9956265c6e2e98b	energy-reliability limits in nanoscale neural networks	reliability theory;energy consumption;nanoscale devices;neurons;integrated circuit reliability;biological neural networks	New device technologies such as spintronics, carbon nanotubes, and nanoscale CMOS incur random transient failures, where the failure probability is governed by the energy consumption through energy-failure functions. At the same time, there is growing use of deep neural networks for many inference applications, and specialized hardware is being developed with these nanotechnologies as physical substrates. It is important to understand the basic energy-reliability limits. Using Pippenger's mutual information propagation technique (extended to directed acyclic graphs), together with optimization, we obtain a lower bound on energy consumption in multilayer binary neural networks for a given reliability. We also obtain a simple energy allocation rule for neurons in the different layers of the neural network. The mathematical results also provide insight into mammalian neuroenergetics of brain regions involved in sensory processing.	artificial neural network;best, worst and average case;cmos;deep learning;directed acyclic graph;experiment;heuristic (computer science);image scaling;inferential programming;lieb-robinson bounds;logic gate;mathematical optimization;mutual information;programming paradigm;requirement;software propagation;spintronics;symbolic computation	Avhishek Chatterjee;Lav R. Varshney	2017	2017 51st Annual Conference on Information Sciences and Systems (CISS)	10.1109/CISS.2017.7926139	reliability theory;theoretical computer science	EDA	4.861375548083373	40.96957218752204	10138
f60ae4969fd43830d9465a7026bad62d9d365812	isotypic decompositions of lattice determinants	macdonald polynomials	The q; t-Macdonald polynomials are conjectured by Garsia and Haiman to have a representation theoretic interpretation in terms of the Sn-module M spanned by the derivatives of a certain polynomial (x1; x2; : : : ; xn; y1; y2; : : : ; yn). The diagonal action of a permutation 2 Sn on a polynomial P = P (x1; x2; : : : ; xn; y1; y2; : : : ; yn) is de ned by setting P = P (x 1 ; x 2 ; : : : ; x n; y 1 ; y 2 ; : : : ; y n). Since the polynomial alternates under the diagonal action,M is Sn-invariant. We analyze here the diagonal action of Sn onM and show that its decomposition into irreducibles is equivalent to a certain isotypic expansion for the translate (x1+x 0 1 ; x2+x 0 2 ; : : : ; xn+x 0 n ; y1+y 0 1 ; y2+y 0 2 ; : : : ; yn+y 0 n ) of the polynomial .	polynomial;theory	Glenn Tesler	1999	J. Comb. Theory, Ser. A	10.1006/jcta.1998.2913	combinatorics;discrete mathematics;mathematics;macdonald polynomials;algebra	Theory	43.58850062877411	33.790428426125864	10150
143181a2fec39483fa35157997f0e4261438a80d	comparison of multi-objective evolutionary optimization in smart building scenarios		The optimization of operating times and operation modes of devices and systems that consume or generate electricity in buildings by building energy management systems promises to alleviate problems arising in today’s electricity grids. Conflicting objectives may have to be pursued in this context, giving rise to a multi-objective optimization problem. This paper presents the optimization of appliances as well as heating and air-conditioning devices in two distinct settings of smart buildings, a residential and a commercial building, with respect to the minimization of energy costs, CO2 emissions, discomfort, and technical wearout. We propose new encodings for appliances that are based on a combined categorization of devices respecting both, the optimization of operating times as well as operation modes, e.g., of hybrid devices. To identify an evolutionary algorithm that promises to lead to good optimization results of the devices in our real-world lab environments, we compare four state-of-the-art algorithms in realistic simulations: ESPEA, NSGA-II, NSGA-III, and SPEA2. The results show that ESPEA and NSGA-II significantly outperform the other two algorithms in our scenario.	evolutionary algorithm	Marlon Alexander Braun;Thomas Dengiz;Ingo Mauser;Hartmut Schmeck	2016		10.1007/978-3-319-31204-0_29	real-time computing;multi-objective optimization;building automation;categorization;energy management;evolutionary algorithm;energy management system;optimization problem;computer science	AI	5.556028032738792	6.083700532116859	10156
b756d41022c0c2351670982958ecc68daa5946e1	tensor product weight modules over the virasoro algebra	grupo de excelencia;journal;ciencias basicas y experimentales;matematicas	The tensor product of highest weight modules with intermediate series modules over the Virasoro algebra was discussed by Zhang [Z] in 1997. Since then the irreducibility problem for the tensor products has been open. In this paper, we determine the necessary and sufficient conditions for these tensor products to be simple. From non-simple tensor products, we can get other interesting simple Virasoro modules. We also obtain that any two such tensor products are isomorphic if and only if the corresponding highest weight modules and intermediate series modules are isomorphic respectively. Our method is to develop a “shifting technique” and to widely use Feigin-Fuchs’ Theorem on singular vectors of Verma modules over the Virasoro algebra.	irreducibility	Hongjia Chen;Xiangqian Guo;Kaiming Zhao	2013	J. London Math. Society	10.1112/jlms/jdt046	tensor product;symmetric tensor;mathematical analysis;topology;tensor;tensor algebra;virasoro algebra;tensor;pure mathematics;tensor contraction;tensor product of algebras;mathematics;geometry;tensor product of hilbert spaces;current algebra;tensor product of modules;algebra	DB	42.589361991830636	34.19354309110283	10162
9491b2cca1aa882f9c3abe6f5a025e2d5eab2221	classification of the computable approximations by divergence boundings	hierarchy;converging speed;computable real number;rational number;computable approximation	A real number is called computably approximable if there is a computable sequence of rational numbers which converges to it. To investigate the complexity of computably approximable real numbers, we can consider the converging speed of the sequences. In this paper we introduce a natural way to measure the converging speed by counting the jumps of certain size appeared after certain stages. The number of this big jumps can be bounded by a bounding function. For different choice of bounding functions, we introduce various classes of real numbers with different approximation quality and discuss their mathematical properties as well as computability theoretical properties.	approximation;computable function	Xizhong Zheng	2007	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2006.08.019	combinatorics;discrete mathematics;mathematics;computable function;computable number;recursive set;hierarchy;rational number;computable analysis	Theory	40.59458649605027	18.44290839726831	10178
84542e7751f824a68f36777c1dfbc785073b2ad2	memory lower bounds for randomized collaborative search and applications to biology	ants;social insects;speed up;cow path problem;mobile robots;quorum sensing;central place foraging;advice complexity;online algorithms;search algorithms;memory bounds	Initial knowledge regarding group size can be crucial for co llective performance. We study this relation in the context of the Ants Nearby Treasure Search (ANTS) problem [24], which models natural cooperative foraging behavior such as that performed by ant s round their nest. In this problem, k (probabilistic) agents, initially placed at some central l ocation, collectively search for a treasure on the two-dimensional grid. The treasure is placed at a target loc ati n by an adversary and the goal is to find it as fast as possible as a function of both k andD, whereD is the (unknown) distance between the central location and the target. It is easy to see that T = Ω(D + D/k) time units are necessary for finding the treasure. Recently, it has been established that O(T ) time is sufficient if the agents know their total numberk (or a constant approximation of it), and enough memory bits a re available at their disposal [24]. In this paper, we establish lower bounds on the agent memory s ize required for achieving certain running time performances. To the best our knowledge, these bounds a re the first non-trivial lower bounds for the memory size of probabilistic searchers. For example, fo r every given positive constant ǫ, terminating the search by timeO(log k · T ) requires agents to use Ω(log log k) memory bits. Such distributed computing bounds may provide a novel, strong tool for the inv stigation of complex biological systems.	adversary (cryptography);algorithmic number theory symposium;approximation;behavioral pattern;biological system;distributed computing;eusociality;experiment;fo (complexity);information theory;newman's lemma;no-communication theorem;oxford spelling;performance;probabilistic automaton;quorum sensing;randomized algorithm;shot noise;signal-to-noise ratio;time complexity	Ofer Feinerman;Amos Korman	2012		10.1007/978-3-642-33651-5_5	eusociality;mobile robot;foraging;online algorithm;quorum sensing;speedup;computer science;artificial intelligence;machine learning;distributed computing;algorithm;search algorithm	Theory	17.74582738719331	34.01981907369895	10190
f371d4a655e122e6db220c3e60eed27bd05fcbc0	some principles for robotics based on general automata	graph theory;automaton;robotics;theorie graphe;graphe environnement;automate;robotique		automata theory;automaton;robotics	Eldo C. Koenig	1986	Robotica	10.1017/S0263574700002472	computer science;artificial intelligence;graph theory;automaton;robotics;algorithm	Robotics	0.9126737452035896	16.853880973555842	10208
59b555552e566544372b42193170c1deec8ec0ed	correlation robust stochastic optimization	half integral disjoint odd cycles packing;social welfare;game theory;cost function;nearly linear time algorithm;stochastic optimization;random variable;distributed models;s posa property;erd odblac;cost sharing;submodular functions;data structure;steiner tree;facility location	We consider a robust model proposed by Scarf, 1958, for stochastic optimization when only the marginal probabilities of (binary) random variables are given, and the correlation between the random variables is unknown. In the robust model, the objective is to minimize expected cost against worst possible joint distribution with those marginals. We introduce the concept of correlation gap to compare this model to the stochastic optimization model that ignores correlations and minimizes expected cost under independent Bernoulli distribution. We identify a class of functions, using concepts of summable cost sharing schemes from game theory, for which the correlation gap is well-bounded and the robust model can be approximated closely by the independent distribution model. As a result, we derive efficient approximation factors for many popular cost functions, like submodular functions, facility location, and Steiner tree. As a byproduct, our analysis also yields some new results in the areas of social welfare maximization and existence of Walrasian equilibria, which may be of independent interest.	approximation algorithm;bernoulli polynomials;correlation gap;expectation–maximization algorithm;game theory;marginal model;mathematical optimization;program optimization;steiner tree problem;stochastic optimization;submodular set function;walrasian auction	Shipra Agrawal;Yichuan Ding;Amin Saberi;Yinyu Ye	2010		10.1137/1.9781611973075.88	random variable;game theory;mathematical optimization;combinatorics;data structure;steiner tree problem;computer science;facility location problem;stochastic optimization;social welfare;mathematics;mathematical economics;statistics	ML	35.273899955049444	6.393756937041448	10225
5e9d05aa926a13bd2609b029d19aa564a5125aef	spans of lenses		Corresponding to the variety of notions of asymmetric lens, various notions of symmetric lens have been proposed. A common theory of the various asymmetric and symmetric lenses should result from a study of spans of asymmetric lenses. In order to define a category whose arrows are spans of asymmetric lenses, the fact that a cospan of asymmetric lenses may not have a pullback must be dealt with. In this article, after resolving that problem we develop the functors which exhibit a category whose arrows are spans of wellbehaved lenses as a retract of a category whose arrows are the corresponding symmetric lenses. We relate them to the symmetric lenses of Hofmann, Pierce and Wagner.	bidirectional transformation;pierce oscillator;the australian;turing completeness	Michael Johnson;Robert D. Rosebrugh	2014			calculus;mathematics;geometry;optics	PL	42.12047160722636	29.095777468483508	10230
0f0da62f6a2b2d99c4dce026d8b20a567d9ae282	increasing the dependability of vlsi systems through early detection of fugacious faults	circuit faults;clocks;fault diagnosis fugacious faults fault detection;transient analysis;fugacious faults;monitoring;vlsi combinational circuits fault diagnosis integrated circuit reliability;registers;circuit faults clocks transient analysis registers timing monitoring fault tolerance;fault detection;fault tolerance;comunicacion en congreso;classical detection vlsi systems early detection fugacious faults combinational logic fault profiles safety industry failure avoidance mechanisms;fault diagnosis;timing	Technology advances provide a myriad of advantages for VLSI systems, but also increase the sensitivity of the combinational logic to different fault profiles. Shorter and shorter faults which up to date had been filtered, named as fugacious faults, require new attention as they are considered a feasible sign of warning prior to potential failures. Despite their increasing impact on modern VLSI systems, such faults are not largely considered today by the safety industry. Their early detection is however critical to enable an early evaluation of potential risks for the system and the subsequent deployment of suitable failure avoidance mechanisms. For instance, the early detection of fugacious faults will provide the necessary means to extend the mission time of a system thanks to the temporal avoidance of aging effects. Because classical detection mechanisms are not suited to cope with such fugacious faults, this paper proposes a method specifically designed to detect and diagnose them. Reported experiments will show the feasibility and interest of the proposal.	adaptive equalizer;burst transmission;clock rate;combinational logic;dependability;effective method;experiment;field-programmable gate array;foremost;risk management;sequential logic;software deployment;very-large-scale integration	Jaime Espinosa;David de Andrés;Pedro J. Gil	2015	2015 11th European Dependable Computing Conference (EDCC)	10.1109/EDCC.2015.13	reliability engineering;embedded system;fault tolerance;electronic engineering;fault;real-time computing;fault indicator;computer science;engineering;operating system;processor register;fault detection and isolation	SE	9.156685714237977	58.40049190413392	10236
a9afef8a42b3f44960bb60742fc2d01614199ebd	interpolatory integration rules and orthogonal polynomials with varying weights	orthogonal polynomial;zeros of polynomials;asymptotic distribution;weight function;possibility distribution	We investigate which types of asymptotic distributions can be generated by the knots of convergent sequences of interpolatory integration rules. It will turn out that the class of all possible distributions can be described exactly, and it will be shown that the zeros of polynomials that are orthogonal with respect to varying weight functions are good candidates for knots of integration rules with a prescribed asymptotic distribution.	interpolation;polynomial;weight function	T. Bloom;Doron S. Lubinsky;H. Stahl	1992	Numerical Algorithms	10.1007/BF02141915	combinatorics;mathematical analysis;discrete mathematics;weight function;jacobi polynomials;discrete orthogonal polynomials;classical orthogonal polynomials;mathematics;orthogonal polynomials;asymptotic distribution;statistics	Theory	47.826091045706974	23.59059742858398	10245
2cef65bb6d7b647d5ca001d2c0743539738534ad	the new memetic algorithm head for graph coloring: an easy way for managing diversity		This paper presents an effective memetic approach HEAD designed for coloring difficult graphs. In this algorithm a powerful tabu search is used inside a very specific population of individuals. Indeed, the main characteristic of HEAD is to work with a population of only two individuals. This provides a very simple algorithm with neither selec- tion operator nor replacement strategy. Because of its simplicity, HEAD allows an easy way for managing the diversity. We focus this work on the impact of this diversity management on well-studied graphs of the DIMACS challenge benchmarks, known to be very difficult to solve. A detailed analysis is provided for three graphs on which HEAD finds a legal coloring with less colors than reference algorithms: DSJC500.5 with 47 colors, DSJC1000.5 with 82 colors and flat1000 76 0w ith 81 colors. The analysis performed in this work will allow to improve HEAD effi- ciency in terms of computation time and maybe to decrease the number of needed colors for other graphs.	graph coloring;memetic algorithm;memetics	Laurent Moalic;Alexandre Gondran	2015		10.1007/978-3-319-16468-7_15	mathematical optimization;combinatorics;mathematics;greedy coloring;algorithm	Theory	24.84729306165032	4.3263312252304615	10273
853ee1aa8783ca4f8ed03eb7d77edcaeaf07d910	a random model for argumentation framework: phase transitions, empirical hardness, and heuristics		We propose and study, theoretically and empirically, a new random model for the abstract argumentation framework (AF). Our model overcomes some intrinsic difficulties of the only random model of directed graphs in the literature that is relevant to AFs, and makes it possible to study the typical-case complexity of AF instances in terms of threshold behaviours and phase transitions. We proved that the probability for a random AF instance to have a stable/preferred extension goes through a sudden change (from 1 to 0) at the threshold of the parameters of the new model D(n, p, q), satisfying the equation 4q (1+q)2 = p. We showed, empirically, that in this new model, there is a clear easy-hard-easy pattern of hardness (for a typical backtracking-style exact solvers) associated with the phase transition. Our empirical studies indicated that instances from the new model at phase transitions are much harder than those from an Erdös-Renyi-style model with equal edge density. In addition to being an analytically tractable models for understanding the interplay between problems structures and effectiveness of (branching) heuristics used in practical argumentation solvers, the model can also be used to generate, in a systematic way, non-trivial AF instances with controlled features to evaluate the performance of other AF solvers.	anisotropic filtering;argumentation framework;backtracking;best, worst and average case;cobham's thesis;directed acyclic graph;directed graph;heuristic (computer science);proof complexity;time complexity;monotone	Yong Gao	2017		10.24963/ijcai.2017/71	phase transition;argumentation framework;artificial intelligence;machine learning;heuristics;computer science	AI	11.5645954692769	18.356465125560483	10274
c330cff73c85f52fa2d2274b94b43f2d2acbf36f	an estimation and exploration methodology from system-level specifications: application to fpgas	performance estimation;fft;fpga;reconfigurable architecture;matrix multiplicaiton;design space exploration;technology mapping;structural estimation;energy efficient design techniques;delay estimation	Rapid evaluation and design space exploration from early specifications are important issues in the design cycle. We propose an original area vs. delay estimation methodology that targets reconfigurable architectures. Two main steps compose the estimation flow: i) structural estimations where architectural solutions are defined at the RT level, this step is technological independent and performs an automatic design space exploration and ii) physical estimations which perform technology mapping to the target reconfigurable architecture. Experiments conducted on Xilinx (XC4000, Virtex) and Altera (Flex10K, Apex) components for a 2D DWT and a speech coder lead to an average error of about 10% for temporal values and 18% for area estimations. The originality of this work is mainly a complete and realistic cost characterization that takes care of the processing, memory and control units, and supplies architectural information for the design of each solution.		Sébastien Bilavarn;Guy Gogniat;Jean Luc Philippe	2003		10.1145/611817.611858	embedded system;fast fourier transform;parallel computing;real-time computing;matrix multiplication;computer science;operating system;field-programmable gate array	EDA	3.1250627509638975	52.34792137204831	10296
4488ac623254e40f341511cdd47b93ada16c995a	measuring the potential of zonal control in large open areas on reducing the heating/ac energy		This paper represents the measurement of the heat/air-conditioning energy consumption in a large open area using electronic technologies. This work is scoping the measurement and analyses of the energy-saving possibility for large open areas such as critical care units in hospitals that use central heat/AC systems. Zonal control is performed by closing the heat/AC Vents in the unoccupied sections of the open areas during the day. The heat/AC ON time is measured using a monitor circuit, which senses outdoor and indoor temperatures, according to the preferred temperature of the user. Factors that promote open-area zonal heat control systems include personal preferences, the area's dimensions and shape, distribution of Vents, the location of windows and doors, and direct sun exposure. Over a three-and-a-half-month test period in summer and fall, measurement results proved that the zonal control system of the open area could decrease average heating energy from 25.5% with all Vents opened to 18.3% with half of the Vents opened, with a difference of 7.2%, which amounts to 28.2% energy saving. The savings for air-conditioning are 13.57%. The saving varies depending on the temperature of the weather. According to our analysis, the zonal control has a negligible effect on the loading of the machine and on the comfort of the customers. These work results confirm the proposed idea of saving heat/AC energy by controlling the delivery of air on a zone-by-zone basis even in large open areas.	closing (morphology);control system;microsoft windows;scope (computer science)	Mostafa M. A. Mohamed;Mohamed F. Ibrahim;Behrouz Homayoun Far	2017	2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/SMC.2017.8123023	thermostat;control theory;energy consumption;doors;control engineering;temperature measurement;computer science;control system	Robotics	4.6709952030159645	7.8951855362639725	10309
ac798a2f36d0a001cda90932244b55d3eb5a1fac	remarks on matroids and sperner's lemma		There are various known versions and generalizations of Sperner's lemma [5] (see, e.g., the references in [6]). In brief, they describe properties of (particular cases of) labeled simplicial complexes. Until the paper [4], however, the set of labels was never equipped with any special structure, except the structure of a complex, as in [6]. From this point of view, theorems of Lovasz [4] and Lindstrom [3] are essential extensions of Sperner's lemma, since the set of labels being admitted by them is a matroid. Lovasz [4] pointed out that Sperner's lemma [5] can be obtained from his result as a special case. On the other hand, Lindstrom [3] said the same with respect to Lovasz's theorem and his result. We show in this paper that both matroid versions [4] and [3] of Sperner's lemma can be proved directly from earlier, non-matroid ones, contained in [1] and [6], respectively. All concepts used in the sequel are well known from combinatorial topology and matroid theory, and therefore will not be explained in detail. For any set X, #X is its cardinality. For any natural number k, Nk = {I, 2, ... , k}. By S we denote a finite set of vertices. Any subset of S of cardinality d + 1 is called ad-simplex (0 ~ d ~ #S). The symbol Sd denotes the set of all d-simplices in S. Any function f: S ~ X, where X is finite, is called a labeling. In particular we consider X = Nk or X being a matroid. If X = Nd+1 then a d-simplex A E Sd is completely labeled by f if f(A) = Nd +1 •	automated theorem proving;like button;matroid;sequence labeling;simplicial complex;sperner's lemma	Stanislaw Krynski	1990	Eur. J. Comb.	10.1016/S0195-6698(13)80030-3	sperner's lemma;combinatorics;discrete mathematics;mathematics;lemma;algebra	Theory	38.65233530901201	29.68725017743683	10312
747611490832825dc442189691355c16dfacf689	new results on a visibility representation of graphs in 3d	visibility representation;new results;graph representation;visibility;graph drawing	This paper considers a 3-dimensional visibility representation of cliques K n. In this representation, the objects representing the vertices are 2-dimensional and lie parallel to the x; y-plane, and two vertices of the graph are adjacent if and only if their corresponding objects see each other by a line of sight parallel to the z-axis that intersects the interiors of the objects. In particular, we represent vertices by unit discs and by discs of arbitrary radii (possibly diierent for diierent vertices); we also represent vertices by axis-aligned unit squares, by axis-aligned squares of arbitrary size (possibly diierent for diierent vertices), and by axis-aligned rectangles. We present: a signiicant improvement (from 102 to 55) of the best known upper bound for the size of cliques representable by rectangles or squares of arbitrary size; a sharp bound for the representation of cliques by unit squares (K 7 can be represented but K n for n > 7 cannot); a representation of K n by unit discs.	apache axis;optic axis of a crystal;vertex (geometry)	Sándor P. Fekete;Michael E. Houle;Sue Whitesides	1995		10.1007/BFb0021807	visibility graph	Theory	31.785743368558695	22.15249637100386	10315
31ac091f19b5276a946012c1e4fbb5aa9116270a	mapping uniform recurrences onto small size arrays	systolic array;affine transformation	Given a regular application described by a system of uniform recurrence equations, systolic arrays are commonly derived by means of an affine transformation; an affine schedule determines when the computations are performed and an affine processor allocation where they are per­ formed. Circuit transformations are then applied on the resulting circuit when the application needs to be mapped onto a smaller size array. This method is in two steps and thus can hardly be optimized globally. We hereafter present a different method for designing small size arrays. We derive them in one step by means of an affine schedule and a near-affine processor allocation. By doing so, we can generalize the optimization technique for affine mapping to be applicable here. The method is illustrated on the band-matrix multiplication and on the convolution algorithms.	recurrence relation	Vincent Van Dongen	1991		10.1007/BFb0035105	affine space;mathematical optimization;combinatorics;discrete mathematics;affine coordinate system;affine involution;affine arithmetic;affine transformation;mathematics;affine shape adaptation;affine combination	NLP	4.497753845966958	37.6386440283329	10324
8c50290aa5685672a50403624f24bd45818d8254	repeatable words for substitution	repetition;substitution;context free language;lettre cyclique;alfabeto;recurrence;lenguaje cf;informatique theorique;recurrencia;palabra;repetitivite;repeticion;word;langage cf;alphabet;substitucion;mot;computer theory;informatica teorica	A word w is said to be repeatable with respect to a substitution if it is a descendant of w itself. The repeatable language of a substitution system (a substitution with an axiom word) is defined as the set of the repeatable words which are the descendants of the axiom. In this paper, we give the characterizations of the repeatable words and the repeatable languages: The set of repeatable words for a rational (respectively context-free) substitution is a rational (respectively context-free) set. The repeatable language for a rational substitution system is a context-free language and a context-free language is the repeatable language for a finite substitution system.		Taishin Y. Nishida;Youichi Kobuchi	1987	Theor. Comput. Sci.	10.1016/0304-3975(87)90072-7	computer science;word;context-free language;alphabet;programming language;algorithm	ECom	-1.2985688187229694	19.68789071758871	10338
10129009d418ac9909ddcd7f628d57d7ce557147	non-standard analysis and representation of reality	time scale	The aim of this paper is to show that the representation with the help of Nonstandard Analysis of a real phenomenon, presenting different observation scales, allows an important simplification of language. Indeed, it is convenient to have available the concept of infinitely small and infinitely large quantities in dealing with the macroscopic effects of microscopic phenomena. This is illustrated on two examples : the representation of two time scales systems and the representation of noise.	text simplification	Claude Lobry;Tewfik Sari	2008	Int. J. Control	10.1080/00207170701601728	combinatorics;pure mathematics;mathematics	Vision	52.33286916298987	24.660382305214632	10340
1ee29aab1f63e1d129874dd0514087a82bd77b06	explicit expanders and the ramanujan conjectures	explicit expander;ramanujan conjecture	Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission.		Alexander Lubotzky;Ralph Phillips;Peter Sarnak	1986		10.1145/12130.12154	combinatorics;ramanujan's sum;computer science	Theory	34.92839852246833	36.93718953400788	10355
8d6774a2dd2821bd85bab8b3369a41df98ec4867	an exact solution approach based on column generation and a partial-objective constraint to design a cellulosic biofuel supply chain	dynamic programming;partial objective constraint;논문;화학공학;database;embedded generalized flow problem;journal;원문;chemical engineering;reference;material;chemical;chemistry;참고문헌;biomass biofuel supply chain;article;저널;column generation	This study provides an exact solution method to solve a mixed-integer linear programming model that prescribes an optimal design of a cellulosic biofuel supply chain. An embedded structure can be transformed to a generalized minimum cost flow problem, which is used as a sub-problem in a column generation approach, to solve the linear relaxation of the mixed-integer program. This study proposes a dynamic programming algorithm to solve the sub-problem in O(m) time, generating improving path-flows. It proposes an inequality, called the partial objective constraint, which is based on the portion of the objective function associated with binary variables, to underlie a branch-and-cut approach. Computational tests show that the proposed solution approach solves most instances faster than a state-of-the-art commercial solver (CPLEX).	column generation	Heungjo An;Wilbert E. Wilhelm	2014	Computers & Chemical Engineering	10.1016/j.compchemeng.2014.07.011	column generation;mathematical optimization;computer science;engineering;dynamic programming;mathematics;mathematical economics	AI	28.02248979582589	6.917232432332126	10358
c7ef84b94fe711ffb28b7078b3d160d4b0baa26e	on the use of iot sensors for indoor conditions assessment and tuning of occupancy rates models		In the last years, the energy savings policies are affecting several aspects of the everyday life, from the introduction of renewables and the use of Electric Vehicles, down to the adoption of more efficient lightening systems. Considering a typical building, one of the most energy consuming plant is the Heating, Ventilation and Air Conditioning (HV AC) system. This consideration is especially true for large public-access buildings, such as schools, universities and public administrations. In these cases, the energy saving of buildings depends on the capability to optimize the behavior of the HV AC. Typically, the HV AC control system is based on static models of the building, which consider an average occupancy rate of each of the rooms. On the contrary, in this research work, a Cognitive Building approach has been considered. The Energy Management System (EMS) is able to control and to regulate the HV AC system, considering an occupancy rate model able to take into consideration user’ habits and the indoor air quality (IAQ), provided in near real-time by IoT sensors. This approach has been applied to the eLUX lab building of the campus of the University of Brescia, Italy. Data provided by IAQ sensors (temperature, relative humidity, CO2) are used to refine the results of occupancy rate models of rooms of this building. The experimental results show as in the 22.15 % of the samples, the CO2concentration overcame the 1000 ppm threshold of perception of fresh air and good condition.	control system;management system;real-time clock;real-time computing;sensor	Stefano Rinaldi;Alessandra Flammini;Lavinia C. Tagliabue;Angelo Luigi Camillo Ciribini	2018	2018 Workshop on Metrology for Industry 4.0 and IoT	10.1109/METROI4.2018.8428327	renewable energy;occupancy;architectural engineering;air conditioning;ventilation (architecture);indoor air quality;control system;relative humidity;energy management system;environmental science	Robotics	5.001587400004166	7.609495597080882	10362
ee83ab6fab765eeb675ce5a09f746b39b014698d	matroids and a forest cover problem	graph theory;recouvrement graphe;cubierta grafo;forests;matroid;teoria grafo;foret graphe;matchings;forest cover;theorie graphe;matroide;covers;graph covering;matroids;bosque grafo;forest graph	A forest cover of a graph is a spanning forest for which each component has at least two nodes. If K is a subset of nodes, a K-forest cover is a forest cover including exactly one node from K in each component. We show that the weighted two matroid intersection algorithm determines the maximum cost K-forest cover.	file spanning;intersection algorithm;matroid intersection;random forest;spanning tree	Jorge Orestes Cerdeira	1994	Math. Program.	10.1007/BF01581157	matroid;combinatorics;discrete mathematics;topology;graph theory;edge cover;mathematics	Theory	26.061224463349532	29.451587573809654	10367
ad43584dbcaef4050e18cae46f7145757db5e6c2	multi-layer floorplanning for reconfigurable designs	concepcion asistida;field programmable gate array;computer aided design;diseno circuito;cost function;integrated circuit layout;logic design;reconfigurable architectures;reutilizacion;fpga design multilayer sequence pair representation based floorplanner partial dynamic reconfiguration field programmable gate array;circuit design;circuit layout;modele ordre reduit;multicouche;red puerta programable;funcion coste;reseau porte programmable;reuse;multiple layer;algorithme;algorithm;capa multiple;modelo orden reducido;fpga design;partial dynamic reconfiguration;reduced order model;conception assistee;correspondencia bloque;fonction cout;implantation circuit integre;block matching;horloge;conception circuit;correspondance bloc;field programmable gate arrays;multilayer sequence pair representation based floorplanner;clock;architecture reconfigurable;reloj;reutilisation;logic design circuit layout field programmable gate arrays;algoritmo	Partial dynamic reconfiguration is an emerging area in field programmable gate arrays (FPGA) designs, which is used for saving device area and cost. In order to reduce the reconfiguration overhead, two consecutive similar sub-designs should be placed in the same locations to get the maximum reuse of common components. This requires that all the future designs be considered while floorplanning for any given design. A comprehensive framework for floorplanning designs on partial reconfigurable architecture is provided. Several reconfiguration-specific floorplanning cost functions and moves that aim to reduce the reconfiguration overhead are introduced. A new multi-layer sequence pair-representation-based floorplanner that allows overlap of static and non-static components of multiple designs and guarantees a feasible overlapping floorplan with minimal area packing is introduced. A new matching algorithm that covers all possible matchings of static blocks during floorplanning for multiple designs is presented. In our experiments, it is shown that the proposed floorplanner gives more than 50% savings in reconfiguration frames compared with the scheme where no reuse is done. Further, compared with a traditional sequential floorplanner, our floorplanner removes infeasibility in many designs, achieves an improvement of clock period by 12% on average and reduces the place and route time significantly. The proposed floorplanner could be used for finding high-quality floorplans for applications that use partial reconfiguration.	floorplan (microelectronics)	Love Singhal;Elaheh Bozorgzadeh	2007	IET Computers & Digital Techniques	10.1049/iet-cdt:20070012	embedded system;electronic engineering;real-time computing;computer science;engineering;computer aided design;field-programmable gate array	EDA	16.374197578369174	50.65958071267163	10372
9a4789addbc8149760024006d33d3c2a876ef587	computation of spectral information from logic netlists	test vector generation logic netlists spectral information multi valued logic netlists and or graphs verification;multi valued logic;multivalued logic;logic cad;data structure;data structures boolean functions data mining multivalued logic probability circuit synthesis system testing information analysis vectors design automation;multivalued logic logic cad	Spectral information can be used for many CAD system tasks including synthesis, verification and test vector gen eration. We analyze the problem of extracting spectral information from Boolean and multi-valued logic netlists. It is shown that spectral information may be calculated directly from output probabilities and a method for extractin g output probabilities from general graphs is described. As a special case, we consider AND/OR graphs which are a data structure recently proposed as an alternative to decision d iagrams. Experimental results are given to demonstrate the efficiency of our approach.	approximation error;benchmark (computing);central processing unit;coefficient;computation;computer-aided design;data structure;graph (discrete mathematics);input/output;runtime system;test vector;time complexity	Rolf Drechsler;Mitchell A. Thornton	2000		10.1109/ISMVL.2000.848600	discrete mathematics;linear temporal logic;logic synthesis;description logic;logic optimization;data structure;computer science;theoretical computer science;mathematics;sequential logic;signature;programming language;digital electronics;multimodal logic;algorithm	ML	18.803012395433772	46.17811826690329	10375
6c108583a4793d46933eade5588cea838c1ad917	on roots of exponential terms	exponential fields;model theory for exponential fields;modified sturm s theorem;exponential terms;roots of exponential terms;estimation of roots	Abstract#R##N##R##N#In the present paper some tools are given to state the exact number of roots for some simple classes of exponential terms (with one variable). The result were obtained by generalizing Sturm's technique for real closed fields. Moreover for arbitrary non-zero terms t(x) certain estimations concerning the location of roots of t(x) are given. MSC: 03C65, 03C60, 12L12.	roots;time complexity	Helmut Wolter	1993	Math. Log. Q.	10.1002/malq.19930390112	exponential error;exponential growth;mathematical analysis;discrete mathematics;double exponential function;calculus;mathematics;exponential formula;exponential polynomial;exponentially modified gaussian distribution	Logic	51.65501881730701	22.313601295011342	10381
3925383d50ec1caf0a84f1b56e9ab10bb8d999b1	design experience with fine-grained fpgas	design experience;fine-grained fpgas	The performance of fine-grained, cellular FPGAs is improving rapidly. In this paper, the experience of working with two relatively finegrained FPGA architectures, the Atmel 6005 FPGA and the Dynamically Programmable Logic Device (DPLD) from Pilkington Micro-electronics Ltd, is described.	field-programmable gate array;programmable logic device	Patrick Lysaght;David McConnell;Hugh Dick	1994		10.1007/3-540-58419-6_106	field-programmable gate array;parallel computing;logic synthesis;finite-state machine;computer science;programmable logic device	HCI	1.6346343761310662	48.001881053243274	10390
eb7f65de6f7cb064253ac3fd76dce56656870b32	a new discrete filled function method for solving large scale max-cut problems	the max cut problem;filled function;global optimization;combinatorial optimization	The global optimization method based on discrete filled function is a new method that solves large scale max-cut problems. We first define a new discrete filled function based on the structure of the max-cut problem and analyze its properties. Unlike the continuous filled function methods, by the characteristic of the max-cut problem, the parameters in the proposed filled function does not need to be adjusted. By combining a procedure that randomly generates initial points for minimization of the proposed filled function, the proposed algorithm can greatly reduce the computational time and be applied to large scale max-cut problems. Numerical results and comparisons with several heuristic methods indicate that the proposed algorithm is efficient and stable to obtain high quality solution of large scale max-cut problems.	algorithm;central processing unit;combinatorial optimization;computation;display resolution;global optimization;heuristic;heuristic (computer science);loss function;mathematical optimization;maximum cut;np-hardness;numerical method;randomness;the times;time complexity;travelling salesman problem	Ai-fan Ling;Cheng-Xian Xu	2011	Numerical Algorithms	10.1007/s11075-011-9522-1	optimization problem;mathematical optimization;combinatorics;discrete mathematics;combinatorial optimization;mathematics;global optimization	AI	26.03384494701075	4.847435424586137	10401
cc22e8fa2ce6d5144d556dd7f48b4373a7d04292	simulation of computer architectures: simulators, benchmarks, methodologies, and recommendations	modeling of computer architecture;simulation of multiple processor systems simulation modeling of computer architecture measurement techniques modeling techniques measurement evaluation modeling;measurement techniques;modeling technique;design process;measurement;simulation of multiple processor systems;benchmark testing computer architecture simulation multiple processor systems;simulation;modeling techniques;computer architecture;evaluation measure;evaluation;design space exploration;model of computation;modeling;measurement technique;benchmark testing;digital simulation;benchmark testing computer architecture digital simulation	Simulators have become an integral part of the computer architecture research and design process. Since they have the advantages of cost, time, and flexibility, architects use them to guide design space exploration and to quantify the efficacy of an enhancement. However, long simulation times and poor accuracy limit their effectiveness. To reduce the simulation time, architects have proposed several techniques that increase the simulation speed or throughput. To increase the accuracy, architects try to minimize the amount of error in their simulators and have proposed adding statistical rigor to their simulation methodology. Since a wide range of approaches exist and since many of them overlap, this paper describes, classifies, and compares them to aid the computer architect in selecting the most appropriate one.	benchmark (computing);computer architecture;design space exploration;floor and ceiling functions;simulation;throughput	Joshua J. Yi;David. J. Lilja	2006	IEEE Transactions on Computers	10.1109/TC.2006.44	model of computation;benchmark;computer architecture;simulation;systems modeling;design process;computer science;evaluation;object-modeling technique;algorithm;measurement	Arch	1.4657544367918798	56.025956150672506	10403
147fecd6a5c040b54aa1ff43b3f47300d44396a2	efficient simulation of critical synchronous dataflow graphs	design process;wireless communication systems;digital tv;simulation;advanced design system;large scale;scheduling;signal processing;synchronous dataflow;model of computation;data transfer;graph decomposition;model simulation;electronic design automation	System-level modeling, simulation, and synthesis using electronic design automation (EDA) tools are key steps in the design process for communication and signal processing systems, and the synchronous dataflow (SDF) model of computation is widely used in EDA tools for these purposes. Behavioral representations of modern wireless communication systems typically result in  critical SDF graphs : These consist of hundreds of components (or more) and involve complex intercomponent connections with highly  multirate  relationships (i.e., with large variations in average rates of data transfer or component execution across different subsystems). Simulating such systems using conventional SDF scheduling techniques generally leads to unacceptable simulation time and memory requirements on modern workstations and high-end PCs. In this article, we present a novel  simulation-oriented scheduler  (SOS) that strategically integrates several techniques for graph decomposition and SDF scheduling to provide effective, joint minimization of time and memory requirements for simulating critical SDF graphs. We have implemented SOS in the  advanced design system  (ADS) from Agilent Technologies. Our results from this implementation demonstrate large improvements in simulating real-world, large-scale, and highly multirate wireless communication systems (e.g., 3GPP, Bluetooth, 802.16e, CDMA 2000, XM radio, EDGE, and Digital TV).	dataflow;simulation	Chia-Jui Hsu;Ming-Yung Ko;Shuvra S. Bhattacharyya;Suren Ramasubbu;José Luis Pino	2007	ACM Trans. Design Autom. Electr. Syst.	10.1145/1255456.1255458	model of computation;embedded system;mathematical optimization;parallel computing;real-time computing;design process;electronic design automation;telecommunications;computer science;operating system;signal processing;distributed computing;programming language;scheduling;algorithm	EDA	1.922448654208639	53.896976188288924	10422
6e13d5d5fe468a982b5240645d78316624e9eef2	some notes on two lower bound methods for communication complexity		We compare two methods for proving lower bounds on standard two-party model of communication complexity, the Rank method and Fooling set method. We present bounds on the number of functions f(x, y), x, y ∈ {0, 1}n, with rank of size k and fooling set of size at least k, k ∈ [1, 2n]. Using these bounds we give a novel proof that almost all Boolean functions f are hard, i.e., the communication complexity of f is greater than or equal to n, using the field Z2.	communication complexity	Frantisek Duris	2017	Electronic Colloquium on Computational Complexity (ECCC)		mathematics;discrete mathematics;combinatorics;upper and lower bounds;communication complexity	Theory	10.50545973824295	22.459992514759794	10425
e142cd443352e8a2d050f835759cd30620332e5c	development of rain attenuation model for southeast asia equatorial climate	equatorial regions;tropical countries;microwave communication links;rainfall rate;itu r p 618 10 model;elevation angle;standard deviation;rain attenuation model papua new guinea kenya nigeria root mean square standard deviation mean square error prediction errors elevation angle rainfall rate equatorial regions tropical countries itu r p 618 10 model millimeter wave communication links microwave communication links statistical distribution southeast asia equatorial climate;papua new guinea;southeast asia equatorial climate;mean square error;kenya;prediction errors;statistical distributions atmospheric electromagnetic wave propagation mean square error methods rain;millimeter wave communication links;root mean square;nigeria;statistical distribution;rain attenuation model	Statistical distribution of rain attenuation is essential for development of microwave and millimeter-wave communication links. Therefore rain-related statistics are very important for a commercialisation system designer. This study proposes modifications to the International Telecommunication Union (ITU-R P.618-10) model and an appropriate rain attenuation prediction model for tropical countries. The model was developed based on data obtained from tropical and equatorial regions. The proposed model uses rainfall rate and rain attenuation at 0.01% of the time, R 0.01 and A 0.01, elevation angle θ and altitude of site h s, respectively, as input parameters. The proposed model showed remarkable agreement with existing rain attenuation measured data in terms of prediction errors for mean square, standard deviation and root-mean square. The proposed rain attenuation model was used for validation by comparing the model with measured data collected from Nigeria, Kenya and Papua New Guinea, whereby the proposed model gave a percentage error below 12%.	rain fade	Renuka Nalinggam;Widad Ismail;Jit Singh Mandeep;Mohammad Tariqul Islam;P. Susthitha Menon	2013	IET Communications	10.1049/iet-com.2012.0298	root mean square;mathematics;standard deviation;kenya;statistics	NLP	48.397619863543085	59.200883171026135	10427
9710c3fcc656c9f918553de443510de6ed85781e	cyclic interlaced quadtree algorithms for quincunx multiresolution	graph theory;quad tree;image processing;quad arbol;pyramid algorithm;theorie graphe;finite element;algorithme;directed graph;graphe oriente;quad arbre;algorithms;grafo orientado;computational efficiency;binary tree	Recent advances in wavelet theory and in finite element computations draw attention to a well-known, simple, and computationally efficient triangulation method. We take a new look at this triangulation, which is obtained by repeated symmetric bisection, starting with a half square. The cells form the leaves of a binary tree and the nodes of a directed graph consisting of a single simple cycle. Computational speed is facilitated by the binary and quad-digit expression of triangle vertices, which reduce all vertex calculations to simple integer and logical operations. The leaf cycle interlaces a pair of quadtrees whose orientations differ by ?/4. Detailed analysis leads to algorithms which exploit the structure and computational efficiencies in calculations such as pyramid algorithms for image processing with non-separable wavelets.	interlaced video;quadtree	Delma J. Hebert	1998	J. Algorithms	10.1006/jagm.1998.0925	mathematical optimization;combinatorics;discrete mathematics;directed graph;binary tree;image processing;computer science;graph theory;theoretical computer science;finite element method;quadtree;mathematics;algorithm	Theory	34.329613677171615	15.817270834985004	10439
44ca6f631469813de4316c5f06ed0fd588981463	on protocols for the automated discovery of theorems in elementary geometry	algebraic geometry;automatic theorem proving;elementary geometry;computer algebra;automatic theorem discovery;computational algebraic geometry	In this paper we consider the problem of dealing automatically with arbitrary geometric statements (including, in particular, those that are generally false) aiming to find complementary hypotheses for the statements to become true. Our approach proceeds within the framework of computational algebraic geometry. First we argue and propose a plausible protocol for automatic discovery, and then we present some algorithmic criteria, as well as the meaning (regarding the algebraic geometry of the varieties involved in the given statement), for the protocol success/failure. A detailed collection of examples in also included.	algorithm;coefficient;commercial software;degeneracy (graph theory);laptop;linear algebra;polynomial;randomness;verification and validation	Giorgio Dalzotto;Tomás Recio	2009	Journal of Automated Reasoning	10.1007/s10817-009-9133-x	combinatorics;discrete mathematics;algebraic geometry;computer science;dimension of an algebraic variety;mathematics;real algebraic geometry;function field of an algebraic variety;differential algebraic geometry;foundations of geometry;synthetic geometry;algebraic geometry and analytic geometry	Vision	50.677153299777686	35.000105230078965	10445
700dea59f42bcd2d6291c83401dd7daeb7e287e7	on the complexity of some coloring games	graph coloring;complexity;games;graph algorithms	In this paper we consider the following game: players must alternately color the lowest numbered uncolored vertex of a given graph G= ({1, 2,…, n}, E) with a color, taken from a given set C, such that two adjacent vertices are never colored with the same color. In one variant, the first player which is unable to move, loses the game. In another variant, player 1 wins the game if and only if the game ends with all vertices colored. We show that for both variants, the problem of determining whether there is a winning strategy for player 1 is PSPACE-complete for any C with |C|≥3, but the problems are solvable in , and time, respectively, if |C|=2. We also give polynomial time algorithms for the problems with certain restrictions on the graphs and orderings of the vertices. We give some partial results for the versions where no order for coloring the vertices is specified.	graph coloring	Hans L. Bodlaender	1991	Int. J. Found. Comput. Sci.	10.1142/S0129054191000091	graph power;games;combinatorics;discrete mathematics;complexity;independent set;fractional coloring;level structure;graph center;computer science;complete coloring;edge coloring;cycle graph;graph coloring;path graph;mathematics;graph homomorphism;list coloring;bound graph;distance;greedy coloring;neighbourhood;algorithm	ECom	28.513429395746975	24.789525720632927	10446
560ceabc748abea771c81418720270349859bd35	some simplified undecidable and np-hard problems for simple programs	np hard problem	The complexity of the equivalence problem for several classes of simple programs with a fixed number of program variables is investigated. The classes are shown to have undecidable, NP-hard, or polynomial-time decidable equivalence problems.	np-hardness;undecidable problem	Eitan M. Gurari;Oscar H. Ibarra	1982	Theor. Comput. Sci.	10.1016/0304-3975(82)90131-1	combinatorics;discrete mathematics;computer science;post correspondence problem;decision problem;np-hard;mathematics;word problem;algorithm	Theory	6.885956755109182	19.517479192103647	10449
f6390cf93e5d1704ab67c95abcf05487c202d5e8	estimation of phase angles from the cross-spectral matrix	traitement signal;detection acoustique;estimacion;sensor phenomena and characterization;acoustique sous marine;time constant;red lineal;detection signal;reseau lineaire;deteccion de senales;linear array;phase estimation sensor arrays vectors signal processing covariance matrix frequency signal processing algorithms acoustic sensors sensor phenomena and characterization delay effects;signal detection;plane waves;phase;delay effects;linear grating;spectrum;procesamiento de senales;fase;matrice mathematique;algorithme;captador medida;algorithm;algorritmo;measurement sensor;mathematical matrix;capteur mesure;vectors;estimation;onde plane;phase estimation;signal processing;spectre;matriz matematica;subspace method;deteccion acustica;plane wave;onda plana;acoustic sensors;signal processing algorithms;frequency;underwater acoustics;sensor arrays;covariance matrix;espectro;acustica submarina;acoustic detection	where the phase angles 02, . . . , O N are treated as free parameters. This kind of situation occurs, for instance, in the case of randomly distorted wavefronts, andlor flexible antennas of unknown geometry, when the fluctuations of the wavefronts and of the antenna are very slow with respect to the time constants used for the estimation of the cross-spectral matrices. As usual in signal subspace methods, the proposed algorithm works very well when the problem presents a strong degree of overdetermination (many more sensors than sources), and the cross-spectral matrix is estimated with good precision.	algorithm;randomness;sensor;signal subspace	Georges Vezzosi	1986	IEEE Trans. Acoustics, Speech, and Signal Processing	10.1109/TASSP.1986.1164867	electronic engineering;plane wave;telecommunications;signal processing;mathematics;optics;quantum mechanics	Vision	53.16856152910379	9.497987643024462	10452
dff93aa7e9ce18a8c1eb45ff79b5353b6328d8d0	on approximation guarantees for greedy low rank optimization		We provide new approximation guarantees for greedy low rank matrix estimation under standard assumptions of restricted strong convexity and smoothness. Our novel analysis also uncovers previously unknown connections between the low rank estimation and combinatorial optimization, so much so that our bounds are reminiscent of corresponding approximation bounds in submodular maximization. Additionally, we also provide statistical recovery guarantees. Finally, we present empirical comparison of greedy estimation with established baselines on two important real-world problems.	combinatorial optimization;convex function;dictionary;expectation–maximization algorithm;feedback;greedy algorithm;ibm notes;internet information services;low-rank approximation;mathematical optimization;microsoft customer care framework;submodular set function;time complexity	Rajiv Khanna;Ethan R. Elenberg;Alexandros G. Dimakis;Sahand Negahban	2017			greedy randomized adaptive search procedure;mathematical optimization;combinatorics;discrete mathematics;mathematics	ML	33.03150776130847	6.016488349949807	10453
f77ae77db21259ab08d5994b4b68a7a36949eb31	epis need not be dense		In [63 and [7] Meseguer conjectured that in the category Pas(o) of ti-complete poscts and o-continuous maps the epis are exactly the dense maps. This paper exhibits a counter-example to Meseguer’s conjecutre, draws a number of negative conclusions and strengthens another of Meseguer”s results. By embedding Pas(o) in the category of partial algebras of an adequate type, a better understanding is obtained both of these results and of the conjecture.	map	Daniel J. Lehmann;Ana Pasztor	1982	Theor. Comput. Sci.	10.1016/0304-3975(82)90002-0	combinatorics;discrete mathematics;topology;pure mathematics;mathematics;algebra	Theory	39.7722384241807	27.686239472017284	10465
6323c68c070471cada319e630833821fd8750e8e	a finite capacity multi-queueing system with priorities and with repeated server vacations	poisson process;queue length;laplace transform;distribution function;single server queue;queueing system;random variable;steady state	In this paper, we study an M / G / 1 multi-queueing system consisting of M finite capacity queues, at which customers arrive according to independent Poisson processes. The customers require service times according to a queue-dependent general distribution. Each queue has a different priority. The queues are attended by a single server according to their priority and are served in a non-preemptive way. If there are no customers present, the server takes repeated vacations. The length of each vacation is a random variable with a general distribution function. We derive steady state formulas for the queue length distribution and the Laplace transform of the queueing time distribution for each queue.	queueing theory;server (computing);steady state	Chris Blondia	1989	Queueing Syst.	10.1007/BF01225322	random variable;m/m/1 queue;m/d/c queue;pollaczek–khinchine formula;real-time computing;heavy traffic approximation;m/m/c queue;m/m/∞ queue;poisson process;multilevel queue;bulk queue;computer science;m/d/1 queue;distribution function;mathematics;distributed computing;queue management system;m/g/k queue;m/g/1 queue;fork–join queue;d/m/1 queue;queueing theory;steady state;priority queue;g/g/1 queue;laplace transform;statistics	Metrics	8.291673508047209	10.87330275462377	10467
3e2f82d102085013f69a6b4db6dd0c6f73f16f56	asymptotic mmse analysis under sparse representation modeling	mmse asymptotic mmse analysis sparse representation modeling compressed sensing signal processing technique worst case hamming approach statistical mechanism individual sequences gaussian random variables binary random variables random matrix gaussian noise optimum estimation certain partition functions statistical mechanics random matrix theory mean square error;statistical analysis compressed sensing gaussian noise least mean squares methods;magnetization compressed sensing vectors silicon sensors random variables estimation	Compressed sensing is a signal processing technique in which data is acquired directly in a compressed form. There are two modeling approaches that can be considered: the worst-case (Hamming) approach and a statistical mechanism, in which the signals are modeled as random processes rather than as individual sequences. In this paper, the second approach is studied. Accordingly, we consider a model of the form Y = HX +W, where each component of X is given by Xi = SiUi, where {Ui} are i.i.d. Gaussian random variables, and {Si} are binary random variables independent of {Ui{, and not necessarily independent and identically distributed (i.i.d.), H ∈ ℝk×n is a random matrix with i.i.d. entries, and W is white Gaussian noise. Using a direct relationship between optimum estimation and certain partition functions, and by invoking methods from statistical mechanics and from random matrix theory, we derive an asymptotic formula for the minimum mean-square error (MMSE) of estimating the input vector X given Y and H, as k, n → ∞, keeping the measurement rate, R = k/n, fixed. In contrast to previous derivations, which are based on the replica method, the analysis carried in this paper is rigorous. In contrast to previous works in which only memoryless sources were considered, we consider a more general model which allows a certain structured dependency among the various components of the source.	best, worst and average case;compressed sensing;data compression;signal processing;sparse approximation;sparse matrix;stochastic process;window function	Wasim Huleihel;Neri Merhav	2014	2014 IEEE International Symposium on Information Theory	10.1109/ISIT.2014.6875311	gaussian random field;mathematical optimization;multivariate random variable;pattern recognition;gaussian process;mathematics;statistics	Theory	50.26827734093265	15.046685458716341	10472
6d71abe41be014f77c459b25628e16d1a1051926	sensor placement by maximal projection on minimum eigenspace for linear inverse problems	eigenvalues and eigenfunctions;local optimization linear inverse problem sensor placement greedy algorithm rank one modification;sensors;greedy algorithms;mean square error greedy sensor placement algorithms minimum nonzero eigenvalue pursuit maximal projection on minimum eigenspace mpme linear inverse problems sensor nodes dual observation matrix worst case error variance convex relaxation method sparsense method framesense method;estimation;optimization;sensors inverse problems optimization signal processing algorithms eigenvalues and eigenfunctions greedy algorithms estimation;sensor placement convex programming eigenvalues and eigenfunctions inverse problems mean square error methods;signal processing algorithms;inverse problems	This paper presents two new greedy sensor placement algorithms, named minimum nonzero eigenvalue pursuit (MNEP) and maximal projection on minimum eigenspace (MPME), for linear inverse problems, with greater emphasis on the MPME algorithm for performance comparison with existing approaches. In both MNEP and MPME, we select the sensing locations one-by-one. In this way, the least number of required sensor nodes can be determined by checking whether the estimation accuracy is satisfied after each sensing location is determined. For the MPME algorithm, the minimum eigenspace is defined as the eigenspace associated with the minimum eigenvalue of the dual observation matrix. For each sensing location, the projection of its observation vector onto the minimum eigenspace is shown to be monotonically decreasing w.r.t. the worst case error variance (WCEV) of the estimated parameters. We select the sensing location whose observation vector has the maximum projection onto the minimum eigenspace of the current dual observation matrix. The proposed MPME is shown to be one of the most computationally efficient algorithms. Our Monte-Carlo simulations showed that MPME outperforms the convex relaxation method, the SparSenSe method, and the FrameSense method in terms of WCEV and the mean square error (MSE) of the estimated parameters, especially when the number of available sensor nodes is very limited.	algorithmic efficiency;best, worst and average case;government and binding theory;greedy algorithm;linear programming relaxation;mean squared error;relaxation (approximation);relaxation (iterative method);sensor;simulation	Chaoyang Jiang;Yeng Chai Soh;Hua Li	2016	IEEE Transactions on Signal Processing	10.1109/TSP.2016.2573767	mathematical optimization;estimation;combinatorics;greedy algorithm;discrete mathematics;inverse problem;sensor;mathematics;statistics	Mobile	51.01772241139431	6.044946614939141	10479
1a4515bded43896d9a1cc74af7d1b302eb4af973	distributed signal processing techniques for wireless sensor networks	bepress selected works;wireless sensor network;nondestructive evaluation;electrical and computer engineering;nondestructive evaluation electrical and computer engineering;distributed signal processing	Recent advances in micro electromechanical systems (MEMS) technology have enabled the design of low-power low-cost smart sensors equipped with multiple onboard functions such as sensing, computing and communications. Such intelligent devices networked through wireless links have been referred to as wireless sensor networks and recognized as one of the most important technologies for the 21st century. Wireless sensor networks hold the promise to revolutionize the sensing technology for a broad spectrum of applications, including infrastructure monitoring and surveillance, disaster management, monitoring the health status of humans, plants, animals and industrial machines, etc.	low-power broadcasting;microelectromechanical systems;sensor;signal processing	Erchin Serpedin;Hongbin Li;Aleksandar Dogandzic;Huaiyu Dai;Paul Cotae	2008	EURASIP J. Adv. Sig. Proc.	10.1155/2008/540176	wireless sensor network;nondestructive testing;computer science;electrical engineering	Mobile	3.956328083212188	32.396296323459936	10489
d22d3a0c531d786c2ab4e1413513e4ea1f28f2dc	parallel tree traversal for nearest neighbor query on the gpu	paper;tesla k40;yarn;query processing;gpu computing;information retrieval;biology;cuda;indexing;graphics processing units;nvidia;algorithms;nearest neighbour;parallel multi dimensional indexing;computer science;parallel indexing;computational biology;algorithm design and analysis;parallel processing	The similarity search problem is found in many application domains including computer graphics, information retrieval, statistics, computational biology, and scientific data processing just to name a few. Recently several studies have been performed to accelerate the k-nearest neighbor (kNN) queries using GPUs, but most of the works develop brute-force exhaustive scanning algorithms leveraging a large number of GPU cores and none of the prior works employ GPUs for an n-ary tree structured index. It is known that multi-dimensional hierarchical indexing trees such as R-trees are inherently not well suited for GPUs because of their irregular tree traversal and memory access patterns. Traversing hierarchical tree structures in an irregular manner makes it difficult to exploit parallelism since GPUs are tailored for deterministic memory accesses. In this work, we develop a data parallel tree traversal algorithm, Parallel Scan and Backtrack (PSB), for kNN query processing on the GPU, this algorithm traverses a multi-dimensional tree structured index while avoiding warp divergence problems. In order to take advantage of accessing contiguous memory blocks, the proposed PSB algorithm performs linear scanning of sibling leaf nodes, which increases the chance to optimize the parallel SIMD algorithm. We evaluate the performance of the PSB algorithm against the classic branch-and-bound kNN query processing algorithm. Our experiments with real datasets show that the PSB algorithm is faster by a large margin than the branch-and-bound algorithm.	backtrack;binary tree;branch and bound;call stack;computational biology;computer graphics;data parallelism;database;deterministic memory;experiment;graphics processing unit;information retrieval;k-ary tree;k-nearest neighbors algorithm;nearest neighbor search;pacific symposium on biocomputing;parallel computing;r* tree;simd;search problem;similarity search;tree (data structure);tree structure;tree traversal	Moohyeon Nam;Jinwoong Kim;Beomseok Nam	2016	2016 45th International Conference on Parallel Processing (ICPP)	10.1109/ICPP.2016.20	parallel processing;algorithm design;search engine indexing;parallel computing;computer science;theoretical computer science;operating system;machine learning;programming language;tree traversal;general-purpose computing on graphics processing units;algorithm	DB	-0.003420022235673283	41.34486852192962	10505
01e18cd100859fd1e023bf47548f94c9384b4e75	testing hereditary properties of non-expanding bounded-degree graphs	68w40;randomized algorithms;graphe intervalle;subgrafo;grado grafo;interval graph;approximation algorithms;grafo intervalo;property testing;qa mathematics;pregunta documental;nonexpanding graphs;satisfiability;input;hereditary graph properties;qa75 electronic computers computer science;sous graphe;graphe planaire;68r10;entree ordinateur;query;68q25;degre graphe;graph model;subgraph;entrada ordenador;grafo planario;planar graphs;68w25;68w20;bounded degree graphs;planar graph;requete;graph degree;expansion	We study property testing in the model of bounded degree grap hs. It is well known that in this model many graph properties cannot be tested with a constant numbe r of queries and it seems reasonable to conjecture that only few are testable with o( √ n) queries. Therefore in this paper we focus our attention on testing graph properties for special classes of graphs, w ith the aim of proving the testability of general families of graph properties under the assumption that the i nput graph belongs to a (natural) family of graphs. We call a graph family non-expandingif every graph in this family has a weak expansion (its expansion isO(1/ log n), wheren is the graph size). Agraph family is hereditaryif it is closed under vertex removal. Similarly, agraph property is hereditaryif it is closed under vertex removal. We call a graph propertyΠ to betestablefor a graph familyF if for every graphG ∈ F , in time independent of the size ofG we can distinguish between the case when G satisfies propertyΠ and when it is far from every graph satisfying property Π. In this paper we prove that in the bounded degree graph model, any hereditary property i s estable if the input graph belongs to a hereditary and non-expanding family of graphs. Our result implies that, for example, any hereditary proper ty (e.g.,k-colorability,H-freeness, etc.) is testable in the bounded degree graph model for planar grap hs, graphs with bounded genus, interval graphs, etc. No such results have been known before, and prio r to our work, very few graph properties have been known to be testable for general graph classes in th e bounded degree graph model. A preliminary version of this paper, entitled “On Testable P roperties in Bounded Degree Graphs,” authored by the first an d third authors, appeared in the Proc. of 18 Symposium on Discrete Algorithm (SODA), New Orleans, Louis iana, 2007, 494-501. Research supported in part by NSF ITR grant CCR-0313219, Cen tre for Discrete Mathematics and its Applications (DIMAP) and EPSRC grant EP/D063191/1, NSF DMS grant 0354600, and DFG grant Me 872/8-3. Department of Computer Science, University of Warwick, Cov entry, CV4 7AL, U.K. czumaj@dcs.warwick.ac.uk. Microsoft Research. asafico@tau.ac.il. Department of Computer Science, University of Paderborn, 3 3102 Paderborn, Germany. csohler@upb.de. Work done while the author was visiting Rutgers University. 1 Electronic Colloquium on Computational Complexity, Report No. 83 (2007)	algorithm;computer science;discrete mathematics;electronic colloquium on computational complexity;expectation propagation;genus (mathematics);graph property;graph theory;hereditary property;ibm notes;microsoft research;property testing;software testability;time complexity	Artur Czumaj;Asaf Shapira;Christian Sohler	2007	SIAM J. Comput.	10.1137/070681831	1-planar graph;outerplanar graph;block graph;pathwidth;split graph;combinatorics;discrete mathematics;cograph;universal graph;topology;graph product;graph property;clique-width;pancyclic graph;forbidden graph characterization;comparability graph;symmetric graph;mathematics;voltage graph;distance-hereditary graph;vertex-transitive graph;approximation algorithm;line graph;algorithm;coxeter graph;planar graph;algebra	Theory	23.92157738713876	23.562372651297714	10513
a851d0ad9ef48f45347b18d454037f1f39690343	how to compute the chow form of an unmixed polynomial ideal in single exponential time	linear algebra;algebraic variety;polynomial ideal	LetK be a field andF 1,⋯, F m homogeneous polynomials in the indeterminatesX 0 ,⋯, X n with coefficients inK. We describe anefficiently parallelizable single exponential time algorithm which computes the Chow form of the idealI:= (F 1 ,⋯, F m ), provided that I is unmixed. This algorithm requires only linear algebra computations overK.	algorithm;coefficient;computation;linear algebra;polynomial;time complexity	Leandro Caniglia	1990	Applicable Algebra in Engineering, Communication and Computing	10.1007/BF01810845	combinatorics;discrete mathematics;algebraic variety;linear algebra;mathematics;algebra	Theory	46.48071678354962	35.69951402058162	10527
0e716a68650437cde42bdfb752085964d5e05437	matrix completion from a few entries	spectral methods;friedman kahn szemeredi;metodo espectral;optimisation;sparse random matrices;sparse random matrices matrix completion optspace reconstruction algorithm massive data sets friedman kahn szemeredi feige ofek;algorithm performance;motion pictures root mean square sparse matrices mathematical model reconstruction algorithms optimization methods watches collaboration information filtering information filters;optimizacion;manifolds;metodo descenso;feige ofek;gradient method;efficient algorithm;root mean square error;erreur quadratique moyenne;signal reconstruction matrix algebra;spectrum;matrix algebra;algorithme;methode gradient;algorithm;matrice creuse;phase transition;matrix completion;metodo gradiente;gradient descent;matrix decomposition;resultado algoritmo;mean square error;random matrices;image reconstruction;manifold optimization;spectral method;performance algorithme;transition phase;phase transitions;transicion fase;signal reconstruction;methode spectrale;optimization;approximation methods;root mean square;sparse matrix;error medio cuadratico;optspace;reconstruction algorithm;descent method;low rank;sparse matrices;methode descente;cleaning;matriz dispersa;spectral methods gradient descent low rank manifold optimization matrix completion phase transition;algoritmo;massive data sets	Let M be an n¿ × n matrix of rank r, and assume that a uniformly random subset E of its entries is observed. We describe an efficient algorithm, which we call OptSpace, that reconstructs M from |E| = O(rn) observed entries with relative root mean square error 1/2 RMSE ¿ C(¿) (nr/|E|)1/2 with probability larger than 1 - 1/n3. Further, if r = O(1) and M is sufficiently unstructured, then OptSpace reconstructs it exactly from |E| = O(n log n) entries with probability larger than 1 - 1/n3. This settles (in the case of bounded rank) a question left open by Candes and Recht and improves over the guarantees for their reconstruction algorithm. The complexity of our algorithm is O(|E|r log n), which opens the way to its use for massive data sets. In the process of proving these statements, we obtain a generalization of a celebrated result by Friedman-Kahn-Szemeredi and Feige-Ofek on the spectrum of sparse random matrices.	genetic algorithm;kahn process networks;mean squared error;sparse matrix	Raghunandan H. Keshavan;Sewoong Oh;Andrea Montanari	2009	IEEE Transactions on Information Theory	10.1109/TIT.2010.2046205	phase transition;mathematical optimization;combinatorics;sparse matrix;calculus;mathematics;mean squared error;statistics;spectral method	Theory	48.047703313123336	8.189193717073207	10528
20539a992f0bb7d9966c0f0459f1b6c05e62d510	a design for testability of undetectable crosspoint faults in programmable logic arrays	design for testability;control input procedure;crosspoint faults;programmable logic arrays;undetectable crosspoint faults control input procedure covering row sets crosspoint faults crosspoint irredundant pla s programmable logic arrays single fault assumption;undetectable crosspoint faults;ieee computer society;programmable logic array;crosspoint irredundant pla s;covering row sets;single fault assumption	In this paper, the validity of single fault assumption in deriving diagnostic test sets is examined with respect to crosspoint faults in programmable logic arrays (PLA's). The control input procedure developed here can be used to convert PLA's having undetectable crosspoint faults to crosspoint-irredundant PLA's for testing purposes. All crosspoints will be testable in crosspoint-irredundant PLA's. The control inputs are used as extra variables during testing. They are maintained at logic 1 during normal operation. A useful heuristic for obtaining a near-minimal number of control inputs is suggested. Expressions for calculating bounds on the number of control inputs have also been obtained.	design for testing;heuristic;programmable logic array;programmable logic device	K. S. Ramanatha;Nripendra N. Biswas	1983	IEEE Transactions on Computers	10.1109/TC.1983.1676277	embedded system;real-time computing;programmable logic array;computer science;design for testing;mathematics;algorithm	SE	22.40810310989193	48.98562576911528	10534
435212ed7eb403e2313f97a0ef016589faba90ec	low-leakage flip-flops based on dual-threshold and multiple leakage reduction techniques	leakage reduction;dtcmos;mtcmos;low power design;flip flop	The scaling of transistor sizes has resulted in dramatic increase of leakage currents. The sub-threshold and gate leakages have now become a major contributor to total power dissipations. This paper presents two °ip-°ops based on dual-threshold CMOS and multiple leakage reduction techniques to reduce their leakage dissipations. In the DT-TG FF (DualThreshold Transmission Gate Flip-Flop), some transistors on non-critical paths use highthreshold devices to reduce their leakage currents, while the other transistors on critical paths use low-threshold devices to maintain performance. The MLRT FF (Multiple Leakage Reduction Technique Flip-Flop) uses P-type CMOS techniques, MTCMOS (Multi-Threshold CMOS) power-gating and dual-threshold technique to reduce both sub-threshold and gate leakage dissipations. Taken as an example, a practical sequential system realized with the two low-leakage °ip-°ops is demonstrated using a mode-5 5 5 counter. The simulation results show that the two °ip-°ops achieve considerable leakage reductions.	and gate;flops;flip-flop (electronics);image scaling;multi-threshold cmos;power gating;simulation;spectral leakage;transistor;transmission gate	Weiqiang Zhang;Li Su;Yu Zhang;Linfeng Li;Jianping Hu	2011	Journal of Circuits, Systems, and Computers	10.1142/S0218126611007128	embedded system;electronic engineering;engineering;electrical engineering	EDA	18.29620813669664	59.175365100313144	10567
189b6a31ff7df8d07cce1adcdee2850e7f0b8453	5-connected 3-polytopes are refinements of octahedra	graph theory;teoria grafo;theorie graphe;construction graphe;polytope convexe;politope convexo;construccion diagrama;convexe polytope;graph construction	A 3-dimensional convex polytope (hereafter to be called a 3-polytope) P is said to be a refinement of a 3-polytope Q provided there is a homeomorphism of the boundary of P to the boundary of Q such that the inverse image of each face of Q is the union of a set of faces of P. A well-known theorem of convex polytopes (see [3, Chap. 111) in that every d-polytope is a refinement of a d-simplex. Since all d-polytopes have d-connected graphs this is saying that they are all refinements of the polytope whose graph is the smallest d-connected graph. If we consider 3-dimensional polytopes one might guess that the 3-polytopes with 4-connected graphs are refinements of the 3-polytope with the smallest 3-polyhedral 4-connected graph, the octahedron. This becomes more believable in view of the fact that the duals of the 4-connected 3-polytopes are refinements of the dual of the octahedron (i.e., the cube; see PI 1. The conjecture can, however, easily been seen to be false since the antiprisms all have 4-connected graphs and none is a refinement of the octahedron (except for the trivial case of the octahedron which is a refinement of itself). If we consider 5-connected 3-polytopes we can show that they are all refinements of octahedra. 250 0095-8956/87 $3.00	challenge-handshake authentication protocol;connectivity (graph theory);polyhedron;refinement (computing)	David W. Barnette	1987	J. Comb. Theory, Ser. B	10.1016/0095-8956(87)90042-6	edge;combinatorics;geometric graph theory;discrete mathematics;convex polytope;topology;polyhedral combinatorics;graph theory;birkhoff polytope;mathematics;algebra	Theory	34.01899447413079	25.386132139743367	10591
61de8776a03d2680a2447caae6091fee7fa9fce5	nanotechnology and the end of moore's law?		In this letter, I will discuss the evolution of silicon very large scale integration (VLSI) as described by Moore's Law and how and when nanotechnology is likely to impact it. The evolution will be in three phases. In the first, there will be an increasing number of nanotechnologies that will allow conventional complementary metal-oxide semiconductors (CMOS) to continue to scale. In the second phase, nanotechnology will allow unconventional CMOS devices to be introduced. In the final phase, a true, new nanodevice will replace the CMOS transistor.	cmos;integrated circuit;moore's law;semiconductor;transistor;very-large-scale integration	David Bishop	2005	Bell Labs Technical Journal	10.1002/bltj.20117	engineering;electrical engineering	Arch	12.02441802895591	57.7116451181099	10604
1c16edaa2a2b92155536981c979701e4602f1c3e	on mod (2s+1)-orientations of graphs	05c40;group connectivity of graphs;degree conditions;mod 2p 1 orientations;strongly mathbb z_ 2p 1 connectedness;05c15	It is shown that every (2p + 1) log2(|V (G)|)-edge-connected graph G has a mod (2p + 1)orientation, and that a (4p + 1)-regular graph G has a mod (2p + 1)-orientation if and only if V (G) has a partition (V , V −) such that ∀U ⊆ V (G), |∂G(U)| ≥ (2p + 1)||U ∩ V | − |U ∩ V −||. These extend former results by Da Silva and Dahad on nowhere zero 3-flows of 5-regular graphs, and by Lai and Zhang on highly connected graphs with nowhere zero 3-flows.	connectivity (graph theory)	Ping Li;Hong-Jian Lai	2014	SIAM J. Discrete Math.	10.1137/130920435	combinatorics;discrete mathematics;topology;mathematics;geometry;algebra	Theory	30.10465750731452	31.63448999749963	10615
7fae356b183bccf8474ca53f841f93c3e5579ddf	optimal design of a membrane separation process using signomial programming	optimal solution;engineering design;geometric program;satisfiability;process design;mass balance;process optimization;optimal design	A multistage membrane separation process for hydrogen recovery is described and formulated as a signomial programming problem. Two different configurations are examined. A 3-stage and a 5-stage process design problem are solved. The optimal solution to these programs is computed from an initial point that does not satisfy the mass balance or transport constraints of the process, using a primal-based geometric programming code. Also examined is the sensitivity of the optimal solution to changes in purity requirements. In all cases, computation times are very reasonable ranging from 2 to 4 seconds of IBM 370/165 CPU time.	central processing unit;computation;computer programming;geometric programming;hydrogen;multistage amplifier;optimal design;pure function;requirement;signomial	Ron S. Dembo;Mordecai Avriel	1978	Math. Program.	10.1007/BF01608996	process design;mathematical optimization;optimal design;process optimization;mathematics;mass balance;engineering design process;satisfiability	Robotics	28.90232191020405	7.154171165127374	10617
3243350204c14123886eddd901e0eadff5c445a3	computing klee’s measure of grounded boxes	weighted volume;klee s measure;sum of ordered products;hypervolume indicator;grounded boxes	A well-known problem in computational geometry is Klee’s measure problem, which asks for the volume of a union of axis-aligned boxes in d-space. In this paper, we consider Klee’s measure problem for the special case where a 2-dimensional orthogonal projection of all the boxes has a common corner. We call such a set of boxes 2-grounded and, more generally, a set of boxes is k-grounded if in a k-dimensional orthogonal projection they share a common corner. Our main result is an O(n (d−1)/2log2 n) time algorithm for computing Klee’s measure for a set of n 2-grounded boxes. This is an improvement of roughly $O(\sqrt{n})$ compared to the fastest solution of the general problem. The algorithm works for k-grounded boxes, for any k≥2, and in the special case of k=d, also called the hypervolume indicator problem, the time bound can be improved further by a logn factor. The key idea of our technique is to reduce the d-dimensional problem to a semi-dynamic weighted volume problem in dimension d−2. The weighted volume problem requires solving a combinatorial problem of maintaining the sum of ordered products, which may be of independent interest.	algorithm;apache axis;binary logarithm;computation;computational geometry;fastest;semiconductor industry	Hakan Yildiz;Subhash Suri	2013	Algorithmica	10.1007/s00453-013-9797-9	mathematical optimization;combinatorics;discrete mathematics;klee's measure problem;mathematics	Theory	29.316390736614718	18.942347943039803	10628
51a77b7352bfe9a7a65247ab4bca15f67fe007bc	mpeg-2 aac coder on a fixed-point dsp	decoding digital signal processing bit rate filter bank audio coding transform coding signal processing algorithms internet bandwidth shape;digital signal processing;m s stereo decoding;filter bank;decoding;coding algorithm;fixed point arithmetic audio coding digital signal processing chips;mpeg 2 aac decoder;code standards;transform coding;bit rate;high quality multi channel surround audio;mpeg 2 advanced audio coding decoder;fixed point;fixed point dsp;audio coding;advanced audio coding;internet;shape;digital signal processing bit rate transform coding audio coding quantization digital signal processing chips frequency filter bank internet shape;telecommunication standards;hi fi equipment code standards telecommunication standards digital signal processing chips fixed point arithmetic decoding audio coding;aac algorithms mpeg 2 aac coder fixed point dsp mpeg 2 advanced audio coding coder coding algorithm high quality multi channel surround audio implementation porting;fixed point arithmetic;hi fi equipment;bandwidth;digital signal processing chips;signal processing algorithms;aac algorithms;m s stereo decoding mpeg 2 aac decoder fixed point dsp mpeg 2 advanced audio coding decoder coding algorithm high quality multi channel surround audio aac algorithms	This paper presents the implementation of an MPEG-2 advanced audio coding (AAC) coder on a fixed-point DSP. AAC is a powerful coding algorithm and offers high-quality multi-channel surround audio. We also discuss the implementation issue and effort in porting AAC algorithms to the DSP.	advanced audio coding;algorithm;digital signal processor;fixed point (mathematics);mpeg-2;surround sound	Jing Chen;Heng-Ming Tai	1999	1999 Digest of Technical Papers. International Conference on Consumer Electronics (Cat. No.99CH36277)	10.1109/30.809209	embedded system;electronic engineering;real-time computing;the internet;transform coding;shape;advanced audio coding;computer science;operating system;digital signal processing;filter bank;fixed point;fixed-point arithmetic;bandwidth	EDA	11.173939185318543	41.90025349582021	10630
7c228bfe6057a20174f5db933e9aec298463e83e	process-variation and temperature aware soc test scheduling using particle swarm optimization	adaptive testing;process variation;high temperature;temperature sensors;trees mathematics;temperature sensor;power aware computing;temperature aware;trees mathematics integrated circuit testing particle swarm optimisation power aware computing system on chip temperature sensors;particle swarm optimizer;system on chip;optimal scheduling;schedules temperature sensors optimal scheduling particle swarm optimization system on a chip cost function cooling;particle swarm optimization;adaptive method;integrated circuit testing;datavetenskap datalogi;computer science;soc test scheduling;test scheduling;process variation soc test scheduling particle swarm optimization adaptive test temperature aware;particle swarm optimisation;temperature sensor reading process variation temperature aware soc test scheduling particle swarm optimization system on chip thermal safety adaptive test schedule temperature deviation online phase offline phase near optimal schedule tree;adaptive test	High working temperature and process variation are undesirable effects for modern systems-on-chip. It is well recognized that the high temperature should be taken care of during the test process. Since large process variations induce rapid and large temperature deviations, traditional static test schedules are suboptimal in terms of speed and/or thermal-safety. A solution to this problem is to use an adaptive test schedule which addresses the temperature deviations by reacting to them. We propose an adaptive method that consists of a computationally intense offline-phase and a very simple online-phase. In the offline-phase, a near optimal schedule tree is constructed and in the online-phase, based on the temperature sensor readings, an appropriate path in the schedule tree is traversed. In this paper, particle swarm optimization is introduced into the offline-phase and the implications are studied. Experimental results demonstrate the advantage of the proposed method.	care-of address;experiment;genetic algorithm;mathematical optimization;online and offline;particle swarm optimization;schedule (computer science);scheduling (computing);sensor;system on a chip;whole earth 'lectronic link	Nima Aghaee;Zebo Peng;Petru Eles	2011	2011 IEEE 6th International Design and Test Workshop (IDT)	10.1109/IDT.2011.6123092	mathematical optimization;electronic engineering;real-time computing;computer science;computerized adaptive testing	EDA	15.377946553571565	55.47230911218769	10634
6b76badfa9722a8dcadb67a62a5fa5c438f8cc08	seamless electromobility		The existing electromobility (EM) is still in its fledgling stage and multiple challenges have to be overcome to make Electric Vehicles (EVs) as convenient as combustion engine vehicles. Users and Electric Vehicle Fleet Operators (EFOs) want their EVs to be charged and ready for use at all times. This straightforward goal, however, is counteracted from various sides:  The range of the EV depends on the status and depletion of the EV battery which is influenced by EV use and charging characteristics. Also, most convenient charging from the user's point of view, might unfortunately lead to problems in the power grid. As in the case of a power peak in the evening when EV users return from work and simultaneously plug in their EVs for charging. Last but not least, the mass of EV batteries are an untapped potential to store electricity from intermittent renewable energy sources.  In this paper, we propose a novel approach to tackle this multi-layered problem from different perspectives. Using on-board EV data and grid prediction models, we build up an information model as a foundation for a back end service containing EFO and Charging Station Provider (CSP) logic as well as a central Advanced Drivers Assistant System (ADAS). These components connect to both battery management and user interfaces suggesting various routing and driving behaviour alternatives customized and incentivized for the current user profile optimizing above mentioned goals.	architecture design and assessment system;cascading style sheets;cryptographic service provider;dsos;decision problem;depletion region;ecology;experimental factor ontology;extended validation certificate;information model;on-board data handling;point of view (computer hardware company);routing;seamless3d;user interface;user profile	Markus Eider;Diana Sellner;Andreas Berl;Robert Basmadjian;Hermann de Meer;Sonja Klingert;Thomas Schulze;Florian Kutzner;Celina Kacperski;Michal Stolba	2017		10.1145/3077839.3078461	charging station;renewable energy;battery (electricity);grid;electric vehicle;electricity;electrical engineering;user profile;user interface;engineering	HCI	2.5751526455494913	7.822037979467804	10637
5fa98295e954d90386a0ad0cbd5b0ca657a44966	urjar: a device to address energy poverty using e-waste	e waste;sustainability;energy poverty;computing for development;lighting device;discarded laptop battery	A significant portion of the population in India does not have access to reliable electricity. At the same time, is a rapid penetration of Lithium Ion battery-operated devices such as laptops, both in the developing and developed world. This generates a significant amount of electronic waste (e-waste), especially in the form of discarded Lithium Ion batteries. In this work, we present UrJar, a device which uses re-usable Lithium Ion cells from discarded laptop battery packs to power low energy DC devices. We describe the construction of the device followed by findings from field deployment studies in India. The participants appreciated the long duration of backup power provided by the device to meet their lighting requirements. Through our work, we show that UrJar has the potential to channel e-waste towards the alleviation of energy poverty, thus simultaneously providing a sustainable solution for both problems. Mode details of this work are provide in [3].	backup;electronic waste;emergency power system;laptop;requirement;software deployment;solving the e-waste problem	Vikas Chandan;Mohit Jain;Harshad Khadilkar;Zainul Charbiwala;Anupam Jain;Sunil Kumar Ghai;Rajesh Kunnath;Deva P. Seetharam	2015		10.1145/2768510.2770940	simulation;engineering;forensic engineering;waste management	HCI	2.2176107448133737	10.00976489672996	10647
7a75865107354e37f2af0b45d936cbd5e87e3fcd	gap processing for adaptive maximal poisson-disk sampling	power diagram;maximal sampling;remeshing;gaps;regular triangulation;blue noise;adaptive poisson disk sampling;algorithms	In this article, we study the generation of maximal Poisson-disk sets with varying radii. First, we present a geometric analysis of gaps in such disk sets. This analysis is the basis for maximal and adaptive sampling in Euclidean space and on manifolds. Second, we propose efficient algorithms and data structures to detect gaps and update gaps when disks are inserted, deleted, moved, or when their radii are changed. We build on the concepts of regular triangulations and the power diagram. Third, we show how our analysis contributes to the state-of-the-art in surface remeshing.	adaptive sampling;algorithm;data structure;geometric analysis;maximal set;point set triangulation;power diagram;sampling (signal processing)	Dong-Ming Yan;Peter Wonka	2013	ACM Trans. Graph.	10.1145/2516971.2516973	mathematical optimization;combinatorics;power diagram;colors of noise;mathematics;geometry	Graphics	32.406998571914784	19.309179567816425	10659
241e83cc222ee0e1ced24f7003940a21a08c73da	fault-secure parity prediction booth multipliers	complexity theory;multiplying circuits;decoding;security design;booth multipliers;routing;decoding circuit topology system testing digital arithmetic hardware complexity theory routing equations;parity prediction;arithmetic operators;circuit topology;multiplying circuits fault tolerant computing digital arithmetic;operand recoding;fault tolerant computing;fault secure circuits;memory systems;system testing;digital arithmetic;arithmetic operators booth multipliers parity prediction fault secure design operand recoding;self checking circuits;fault secure design;hardware	Parity prediction arithmetic operators are compatible with data paths and memory systems checked by parity codes. The authors extend their theory for achieving fault-secure design of parity prediction multipliers and dividers to Booth multipliers using operand recoding.	booth's multiplication algorithm	Michael Nicolaidis;Ricardo de Oliveira Duarte	1999	IEEE Design & Test of Computers	10.1109/54.785842	topology;routing;parallel computing;computer science;theoretical computer science;system testing	EDA	14.407938987997298	44.98328127865346	10660
8d32d433b51d67217213a81a48b760f7248af760	a novel methodology for design of cyclic combinational circuits			combinational logic	Vinay Kumar;Chandan Kumar Jha;Gaurav Thapa;Anup Dandapat	2016	J. Low Power Electronics	10.1166/jolpe.2016.1439	engineering;electronic engineering;combinational logic	EDA	22.816563215644692	51.633046426332704	10661
43034efa432f55931d0ae00fb6a4eda26ac87f1d	single-chip microprocessor that communicates directly using light	geociencias medio ambiente;electrical and electronic engineering;ciencias biologicas generalidades;grupo de excelencia;integrated optics;ciencias basicas y experimentales generalidades;silicon photonics;ciencias basicas y experimentales;geociencias medio ambiente generalidades;ciencias biologicas;computer science;grupo a	Data transport across short electrical wires is limited by both bandwidth and power density, which creates a performance bottleneck for semiconductor microchips in modern computer systems—from mobile phones to large-scale data centres. These limitations can be overcome by using optical communications based on chip-scale electronic–photonic systems enabled by silicon-based nanophotonic devices8. However, combining electronics and photonics on the same chip has proved challenging, owing to microchip manufacturing conflicts between electronics and photonics. Consequently, current electronic–photonic chips are limited to niche manufacturing processes and include only a few optical devices alongside simple circuits. Here we report an electronic–photonic system on a single chip integrating over 70 million transistors and 850 photonic components that work together to provide logic, memory, and interconnect functions. This system is a realization of a microprocessor that uses on-chip photonic devices to directly communicate with other chips using light. To integrate electronics and photonics at the scale of a microprocessor chip, we adopt a ‘zero-change’ approach to the integration of photonics. Instead of developing a custom process to enable the fabrication of photonics, which would complicate or eliminate the possibility of integration with state-of-the-art transistors at large scale and at high yield, we design optical devices using a standard microelectronics foundry process that is used for modern microprocessors. This demonstration could represent the beginning of an era of chip-scale electronic–photonic systems with the potential to transform computing system architectures, enabling more powerful computers, from network infrastructure to data centres and supercomputers.	arabic numeral 0;architecture as topic;bandwidth (signal processing);computation (action);computer systems;computers;conflict (psychology);integrated circuit;intrauterine devices;microprocessor;mobile phone;niche blogging;parkinson disease;photodetector device component;photonics;semiconductor;silicon;supercomputer;transceiver;transistor	Chen Sun;Mark T. Wade;Yunsup Lee;Jason S. Orcutt;Luca Alloatti;Michael Georgas;Andrew Waterman;Jeffrey M. Shainline;Rimas Avizienis;Sen Lin;Benjamin Moss;Rajesh Kumar;Fabio Pavanello;Amir Atabaki;Henry Cook;Albert J. Ou;Jonathan Leu;Yu-Hsin Chen;Krste Asanovic;Rajeev J. Ram;Milos A. Popovic	2015	Nature	10.1038/nature16454	silicon photonics;physics	Arch	12.832964076099763	58.38381324122403	10683
8a813c76fd4bba02bb6c3de8c873493eceabc179	labelled ospa metric for fixed and known number of targets		Multitarget tracking systems should solve two basic problems. The first one is to estimate the number of targets and their states at the current time. The second one is to connect target state estimates that belong to the same target along t ime to form tracks. The conventional way of building tracks in th e random finite set framework (RFS) [1] is to attach a label to the individual target states [2], [3]. Labels have two important properties: they are unique (no two targets can have the same label) and they are fixed over time. Labels were used for track formation in [4], [5] using a vector-based formulation and in [2], [3] using the RFS frame work. The approaches of [4], [5] and [2], [3] are equivalent d ue to the bijection between the labelled RFS state and the hybri d labelled multitarget state vector [6, Appendix B]. For the s ame reason, for fixed and known number of targets, representing the multitarget state as a vector is equivalent to a labelled set. One way to evaluate performance of tracking algorithms based on labelled set is using the labelled optimal subpatte rn assignment (LOSPA) metric [7]. In some cases, it is convenient to assume that the number of targets is fixed and known [8], [9]. This way we can study some properties of tracking algorithms more easily. In thes e cases, it is usually useful to use vector notation, in which l abe s are implicit in the ordering of the components of a vector, to denote a labelled set. The problem is that the LOSPA metric in [7] is defined with explicit labels. In this paper, we fill this gap and provide an expression for this metric when the number of targets is fixed and known and vector notation is used. This paper is organised as follows. In Section II, we introduce the two equivalent representations of the multit arget state based on a labelled set and a vector. We provide the	algorithm;attribute-based encryption;remote file sharing;tracking system	Ángel F. García-Fernández;Mark R. Morelande;Jesús Grajal	2014	CoRR		combinatorics;discrete mathematics;topology;mathematics	Robotics	32.12435781966336	42.256730923156105	10684
c80a4935ad5c7faf751822438d39d3a796720ba3	a practical shortest path algorithm with linear expected time	distribution;camino mas corto;computadora;recherche largeur;shortest path;68w40;shortest paths;probability;loi probabilite;ley probabilidad;shortest path algorithm;fonction repartition;ordinateur;limitation;implementation;performance;temps lineaire;plus court chemin;tiempo lineal;computer;68wxx;input;moyenne;funcion distribucion;distribution function;algorithme lineaire;limitacion;data structures;promedio;probability distribution;probabilidad;linear time;probabilite;entree ordinateur;palabra;chemin plus court;algorithms;average;68q25;word;recherche largeur d abord;experimental evaluation;rendimiento;entrada ordenador;implementacion;distribucion;mot	We present an improvement of the multilevel bucket shortest path algorithm of Denardo and Fox [Oper. Res., 27 (1979), pp. 161-186] and justify this improvement both theoretically and experimentally. We prove that if the input arc lengths come from a natural probability distribution, the new algorithm runs in linear average time while the original algorithm does not. We also describe an implementation of the new algorithm. Our experimental data suggests that the new algorithm is preferable to the original one in practice. Furthermore, for integral arc lengths that fit into a word of today's computers, the performance is close to that of breadth-first search, suggesting limitations on further practical improvements.	algorithm;shortest path problem	Andrew V. Goldberg	2008	SIAM J. Comput.	10.1137/070698774	distribution;probability distribution;time complexity;suurballe's algorithm;dijkstra's algorithm;ramer–douglas–peucker algorithm;data structure;performance;computer science;artificial intelligence;distribution function;calculus;yen's algorithm;probability;word;mathematics;shortest path problem;implementation;k shortest path routing;shortest path faster algorithm;algorithm;statistics	Theory	14.885298146860908	23.036639202793967	10689
25dcd57ee02dd284567fcbf8df5c3911dabacde6	continuation power flow analysis for pv integration studies at distribution feeders		This paper presents a method for conducting continuation power flow simulation on high-solar penetration distribution feeders. A load disaggregation method is developed to disaggregate the daily feeder load profiles collected in substations down to each load node, where the electricity consumption of residential houses and commercial buildings are modeled using actual data collected from single family houses and commercial buildings. This allows the modeling of power flow and voltage profile along a distribution feeder on a continuing fashion for a 24-hour period at minute-by-minute resolution. By separating the feeder into load zones based on the distance between the load node and the feeder head, we studied the impact of PV penetration on distribution grid operation in different seasons and under different weather conditions for different PV placements.	24-hour clock;continuation;data-flow analysis;page view;simulation	Jiyu Wang;Xiangqi Zhu;David Lubkeman;Ning Lu;Nader Samaan	2017	2017 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT)	10.1109/ISGT.2017.8086036	voltage;continuation;grid;power-flow study;operations management;control engineering;electricity;engineering	HPC	3.3069459939241748	7.4453192896576	10714
2342a0e96ceb6b3fee300dfde662d68da3fe7f71	"""corrections to """"uwb through-wall imaging based on compressive sensing"""" [mar 10 1408-1415]"""	compressed sensing;error correction;remote sensing;error correction equations remote sensing	In the above titled paper (ibid., vol. 48, no. 3, pp. 1408-1415, Mar. 2010), there are two errors in the top line of (13) which we correct here.	compressed sensing;ultra-wideband	Qiong Huang;Lele Qu;Bingheng Wu;Guangyou Fang	2010	IEEE Trans. Geoscience and Remote Sensing	10.1109/TGRS.2010.2041284	error detection and correction;telecommunications;compressed sensing;remote sensing	Mobile	44.5726640238818	56.205456295944664	10716
029f4d65de77635167a753cd31f1278d5498e5b5	envelope theorems in dynamic programming	dynamic programming;resource allocation;envelope theorem;dynamic program;inverse problem;linear quadratic control;optimal value function	The Envelope Theorem is a statement about derivatives along an optimal trajectory. In Dynamic Programming the Envelope Theorem can be used to characterize and compute the Optimal Value Function from its derivatives. We illustrate this here for the Linear-Quadratic Control Problem, the Resource Allocation Problem, and the Inverse Problem of Dynamic Programming.	bellman equation;dynamic programming;envelope theorem;rice's theorem	Fuan Zhao;Adi Ben-Israel	2001	Annals OR	10.1023/A:1010978103974	mathematical optimization;combinatorics;resource allocation;inverse problem;optimal substructure;dynamic programming;mathematics;mathematical economics	Theory	29.442058244543926	11.369948654009004	10723
4f07163b3e037b6503fe0379c8045a6c8619d84f	adjacency, inseparability, and base orderability in matroids	oriented matroid;ordered subsets	Two elements in an oriented matroid are inseparable if they have either the same sign in every signed circuit containing them both or opposite signs in every signed circuit containing them both. Two elements of a matroid are adjacent if there is no M(K4)-minor using them both, and in which they correspond to a matching of K4. We prove that two elements e, { of an oriented matroid are inseparable if and only if e, f are inseparable in every M(K4) or V4 -minor containing them. This provides a link between inseparability in oriented matroids (introduced by Bland and Las Vergnas) and adjacency in binary matroids (introduced by Seymour). We define the concepts of base orderable and strongly base orderable subsets of a matroid, generalizing the definitions of base orderable and strongly base orderable matroids. Strongly base orderable subsets can be used to obtain packing and covering results, generalizing results of Davies and McDiarmid, as was shown in a previous paper. In this paper, we prove that any pairwise inseparable subset of an oriented matroid is base orderable. For binary matroids we derive the following characterization: a subset is strongly base orderable if and only if it is pairwise adjacent.	login;matroid;separable polynomial;set packing	Judith Keijsper;Rudi Pendavingh;Alexander Schrijver	2000	Eur. J. Comb.	10.1006/eujc.1999.0355	matroid;combinatorics;discrete mathematics;graphic matroid;topology;oriented matroid;mathematics;matroid partitioning	Theory	33.42742841858209	30.467388903944304	10735
d5e615cf53077532a0c618792dcfdf79c93f69ce	developmental systems with locally catenative formulas	satisfiability	A locally catenative sequence of strings of letters is such that each string in the sequence, after an initial stretch, is formed by concatenating strings which occurred at some specified distances previously in the sequence. These kinds of structures are frequently encountered in biological development, particularly in the case of compound branching structures or compound leaves. Developmental systems have been formally defined in previous publications. One of the present results is that dependent PDOL systems can produce sequences for every locally catenative formula (PDOL systems are propagating, deterministic developmental systems without interactions). Every dependent PDOL system produces a sequence which satisfies an infinite class of locally catenative formulas. Some of these formulas can be derived from a minimum formula, but a sequence may satisfy more than one minimum formulas.	concatenation;interaction;locally catenative sequence;vieta's formulas	Grzegorz Rozenberg;Aristid Lindenmayer	1973	Acta Informatica	10.1007/BF00289079	combinatorics;discrete mathematics;computer science;mathematics;algorithm;satisfiability	Logic	35.523895184926545	36.243241877089176	10739
05ee3ecc2e39720f79128048405c6f8f5b9cf2c5	on-chip clock error characterization for clock distribution system	erbium;cmos integrated circuits;size 65 nm on chip clock error statistic characterization clock distribution system high speed clocking systems indirect measurement periodic sequence integrity off chip signals picosecond resolution cmos technology test strategy;metastability;clocks;prototypes;clock domains;clock distribution networks;measurement uncertainty;integrated circuit design;integrated circuit testing clock distribution networks cmos integrated circuits gaussian distribution integrated circuit design;static and dynamic error;system on chip;synchronization;integrated circuit testing;delays clocks synchronization measurement uncertainty prototypes erbium system on chip;controlled delay;gaussian distribution;delays;metastability clock domains static and dynamic error controlled delay	In this paper, we investigate a test strategy for characterization of clock error statistics between two clock domains in high-speed clocking systems (gigahertz and more). The method allows an indirect measurement (not based on time interval measurement) of clock error distribution by observing the integrity of a periodic sequence transmitted between two clocking domains. The method is compatible with fully on-chip implementation, and the readout of result to off-chip signals is cadenced at low rate. The strategy aims at picoseconds resolution without complex calibration. The idea was first validated by a discrete prototype at downscaled frequencies, and then a high frequency on-chip prototype was designed using 65 nm CMOS technology. Simulation results predict a measurement precision of less than ±2.5 ps. The article presents the theory, exposes the hardware implementation, and reports the experimental validation and simulation results of two prototypes.	cmos;clock rate;experiment;level of measurement;prototype;ps (unix);simulation;test strategy	Chuan Shan;Dimitri Galayko;François Anceau	2013	2013 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)	10.1109/ISVLSI.2013.6654630	embedded system;electronic engineering;real-time computing;clock domain crossing;clock skew;engineering;clock rate;digital clock manager;cpu multiplier	Embedded	27.82278921603844	55.446522083547485	10742
857cf4d60ca09523990f74b811991cdf7acf286b	finding the smallest image of a set	permutation group;algorithm;smallest image	We describe an algorithm for finding a canonical image of a set of points under the action of a permutation group. Specifically if we order images by sorting them and ordering the resulting sequences lexicographically, we find the first image. This has applications to combinatorial and other search problems, allowing isomorphic results to be eliminated more efficiently.We give worst-case asymptotic running time estimates and practical results obtained with a GAP implementation.	algorithm;best, worst and average case;lexicographical order;sorting;time complexity	Steve Linton	2004		10.1145/1005285.1005319	mathematical optimization;combinatorics;discrete mathematics;mathematics;permutation group;base;cyclic permutation;algebra	Theory	17.35384729244513	23.704305747587696	10765
5bc27aa2ec9940c8bb9ab7a119ba6885d4708933	a characterization of flip-accessibility for rhombus tilings of the whole plane	plane;statistical mechanics;quasicrystal;accesibilidad;rhombus tiling;polygone;plan;de bruijn line;tiling;05b45;polygon;accessibility;informatique theorique;plano;pavage;characterization;flip;poligono;vinculo;51e12;tiling of the plane;caracterisation;link;caracterizacion;accessibilite;lien;computer theory;informatica teorica	It is known that any two rhombus tilings of a polygon are flip-accessible, that is, linked by a finite sequence of local transformations called flips. This paper considers flip-accessibility for rhombus tilings of the whole plane, asking whether any two of them are linked by a possibly infinite sequence of flips. The answer turning out to depend on tilings, a characterization of flip-accessibility is provided. This yields, for example, that any tiling by Penrose tiles is flip-accessible from a Penrose tiling.	accessibility	Olivier Bodini;Thomas Fernique;Eric Rémila	2007		10.1016/j.ic.2008.03.008	arrangement of lines;hexagonal tiling;combinatorics;rhombille tiling;topology;statistical mechanics;penrose tiling;substitution tiling;square tiling;polygon;mathematics;geometry;triangular tiling;tessellation	Theory	33.424537490530675	24.393406740697703	10772
1bbb5ac2194d809fa0b329c63b61bfe5762ac22b	polynomial-time approximation schemes for k-center, k-median, and capacitated vehicle routing in bounded highway dimension		The concept of bounded highway dimension was developed to capture observed properties of road networks. We show that a graph of bounded highway dimension with a distinguished root vertex can be embedded into a graph of bounded treewidth in such a way that u-to-v distance is preserved up to an additive error of times the u-to-root plus v-to-root distances. We show that this embedding yields a PTAS for Bounded-Capacity Vehicle Routing in graphs of bounded highway dimension. In this problem, the input specifies a depot and a set of clients, each with a location and demand; the output is a set of depot-to-depot tours, where each client is visited by some tour and each tour covers at most Q units of client demand. Our PTAS can be extended to handle penalties for unvisited clients. We extend this embedding result to handle a set S of root vertices. This result implies a PTAS for Multiple Depot Bounded-Capacity Vehicle Routing: the tours can go from one depot to another. The embedding result also implies that, for fixed k, there is a PTAS for k-Center in graphs of bounded highway dimension. In this problem, the goal is to minimize d so that there exist k vertices (the centers) such that every vertex is within distance d of some center. Similarly, for fixed k, there is a PTAS for k-Median in graphs of bounded highway dimension. In this problem, the goal is to minimize the sum of distances to the k centers. 2012 ACM Subject Classification Theory of computation → Routing and network design problems	approximation;embedded system;existential quantification;metric k-center;network planning and design;ptas reduction;polynomial;theory of computation;time complexity;treewidth;utility functions on indivisible goods;vehicle routing problem;vertex (geometry);vertex (graph theory)	Amariah Becker;Philip N. Klein;David Saulpic	2018		10.4230/LIPIcs.ESA.2018.8	discrete mathematics;time complexity;vehicle routing problem;computer science;bounded function	Theory	23.54857132134781	19.472746591815646	10793
3bdbc6ed12c5d5a5b048d32f0cc26c167a0d2b46	cross-correlation distribution of $p$ -ary $m$-sequence of period $p^{4k}-1$ and its decimated sequences by $\left({{ p^{2k}+1}\over { 2}}\right)^{2}$	finite element methods;statistical distributions correlation methods correlation theory;cross correlation function;cross correlation;correlation theory;distributed computing;m sequence;correlation methods;systems engineering and theory;cross correlation function cross correlation distribution m sequence decimated sequence odd prime;statistical distributions;large scale integration;cross correlation distribution;three dimensional displays;computer science embedded software distributed computing embedded computing systems engineering and theory large scale integration galois fields;mathematical model;computer science;decimated sequence;correlation;odd prime;galois fields;embedded computing;embedded software	For an odd prime p, n=4k, and d=((p<sup>2k</sup>+1)/2)<sup>2</sup>, there are (p<sup>2k</sup>+1)/2 distinct decimated sequences s(dt+l), 0lesl<(p<sup>2k</sup>+)/2,of a p-ary m-sequence s(t) of period p<sup>n</sup>-1 because gcd(d,p<sup>n</sup>-1)=(p<sup>2k</sup>+1)/2. In this paper, it is shown that the cross-correlation function between s(t) and s(dt+l),0lesl<(p<sup>2k</sup>+1)/2, takes the values in {-1, -1 -radic(p<sup>n</sup>),-1+radic(p<sup>n</sup>),-1+2radic(p<sup>n</sup>)} and their cross-correlation distribution is also derived.	cross-correlation;decimation (signal processing)	Eun-Young Seo;Young-Sik Kim;Jong-Seon No;Dong-Joon Shin	2007	IEEE Transactions on Information Theory	10.1109/ISIT.2007.4557597	combinatorics;discrete mathematics;cross-correlation;mathematics;statistics;algebra	DB	42.5155501945754	48.91972339931799	10798
245461e32dfed57ba6a8f93d2a597df6838e0bb3	a hardware platform for vliw based emulation of digital designs	fault clustering;defect clustering;reject ration;digital design;fault coverage;defect level	In [2] the concept of avery long instruction word (VLIW) processor based system to emulate synthesized RTlevel descriptions has been presented. As described in [2] theRAVE System(RT-Architecture-VLIW-Emulator) overcomes many of the problems common to FPGA based emulation and prototyping systems. Particularly, these are area problems in conjunction with large data paths, long turnaround times and low emulation clock frequencies. This abstract briefly describes the hardware of the RAVE System.	clock rate;emulator;field-programmable gate array;opcode;quickdraw 3d;very long instruction word	Gunter Haug;Udo Kebschull;Wolfgang Rosenstiel	2000		10.1145/343647.344137	embedded system;parallel computing;real-time computing;fault coverage;computer science;engineering	EDA	6.7747394977280155	50.94482001057012	10806
5d8889e98d279349f15e87605443f3355c1f6998	maximum renamable horn and maximum independent sets	graph theory;horn satisfiability;computer science polynomials logic;complexity theory;horn clause set;maximum renamable horn;independent set;computability;horn clauses;testing;set theory;data mining;polynomials;undirected graph;horn satisfiability maximum renamable horn maximum independent set horn clause set part propositional variable np hard problem undirected graph polynomial time;np hard problem;np hardness;vectors;computational complexity;set theory computability computational complexity graph theory horn clauses;linear time;transforms;polynomial time;inapproximability maximum renamable horn set maximum independent set polynomial transformation np hardness;inapproximability;maximum renamable horn set;polynomial transformation;part propositional variable;maximum independent set	A clause set is renamable Horn if the result replacing part propositional variable with its complement is a set of Horn clauses. The renamable Horn problem is solvable in linear time, but the maximum renamable Horn problem (MAX-RHS) is NP-hard. In this paper, we present transformations between clause sets and undirected graphs in polynomial time, such that finding a renamable Horn subset of a clause set is equivalent to finding an independent set of vertices of a graph. Then, the problems MAX-RHS and MAX-IND have the same complexity, and MAX-RHS is inapproximable.	decision problem;graph (discrete mathematics);horn clause;horn-satisfiability;independent set (graph theory);max;polynomial;propositional proof system;propositional variable;time complexity;vertex (geometry)	Yongbin Qin;Daoyun Xu	2009	2009 WRI World Congress on Computer Science and Information Engineering	10.1109/CSIE.2009.690	time complexity;combinatorics;discrete mathematics;independent set;horn-satisfiability;computer science;graph theory;mathematics;algorithm	Theory	23.06992139442866	24.27753220990652	10817
e0b92dcd0c037985825b89e2e1e9c90897e016e6	high-speed rsa hardware based on barret's modular reduction method	circuit vlsi;cle publique;vlsi circuit;arithmetique modulaire;public key;grande vitesse;digital signature;criptografia;cryptography;llave publica;signature numerique;cryptographie;cryptosysteme;gran velocidad;computer hardware;circuito vlsi;materiel informatique;high speed;material informatica	The performance of public-key cryptosystems like the RSA encryption scheme or the Diffie-Hellman key agreement scheme is primarily determined by an efficient implementation of the modular arithmetic. This paper presents the basic concepts and design considerations of the RSAγ crypto chip, a high-speed hardware accelerator for long integer modular exponentiation. The major design goal with the RSAγ was the maximization of performance on several levels, including the implemented hardware algorithms, the multiplier architecture, and the VLSI circuit technique. RSAγ uses a hardware-optimized variant of Barret’s modular reduction method to avoid the division in the modular multiplication. From an architectural viewpoint, a high degree of parallelism in the multiplier core is the most significant characteristic of the RSAγ crypto chip. The actual prototype contains a 1056∗16 bit partial parallel multiplier which executes a 1024-bit modular multiplication in 227 clock cycles. Due to massive pipelining in the long integer unit, the RSAγ crypto chip reaches a decryption rate of 560 kbit/s for a 1024-bit exponent. The decryption rate increases to 2 Mbit/s if the Chinese Remainder Theorem is exploited.	cmos;cathode ray tube;clock rate;clock signal;cryptosystem;data rate units;degree of parallelism;diffie–hellman key exchange;encryption;expectation–maximization algorithm;hardware acceleration;integer (computer science);megabit;modular exponentiation;modulus robot;parallel computing;pipeline (computing);prototype;public-key cryptography;rsa (cryptosystem);scalability;transistor;very-large-scale integration	Johann Großschädl	2000		10.1007/3-540-44499-8_14	embedded system;digital signature;computer science;cryptography;theoretical computer science;operating system;computer security;algorithm	Arch	8.726621864258725	44.25427159134195	10832
0f8599861130d1f7c482d4b3d25fb3d622c6f415	architecture exploration based on tasks partitioning between hardware, software and locality for a wireless vision sensor node	image processing;vision sensor node;reconfigurable architecture;engineering and technology;teknik och teknologier;hardware software partitioning;wireless vision sensor networks	Wireless Vision Sensor Networks WVSNs is an emerging field which consists of a number of Visual Sensor Nodes VSNs. Compared to traditional sensor networks, WVSNs operates on two dimensional data, which requires high bandwidth and high energy consumption. In order to minimize the energy consumption, the focus is on finding energy efficient and programmable architectures for the VSN by partitioning the vision tasks among hardware FPGA, software Micro-controller and locality sensor node or server. The energy consumption, cost and design time of different processing strategies is analyzed for the implementation of VSN. Moreover, the processing energy and communication energy consumption of VSN is investigated in order to maximize the lifetime. Results show that by introducing a reconfigurable platform such as FPGA with small static power consumption and by transmitting the compressed images after pixel based tasks from the VSN results in longer battery lifetime for the VSN.	locality of reference;sensor node	Muhammad Imran Shahzad;Khursheed Khursheed;Abdul Waheed Malik;Naeem Ahmad;Mattias O'Nils;Najeem Lawal;Benny Thörnberg	2012	IJDST	10.4018/jdst.2012040104	embedded system;parallel computing;real-time computing;image processing;computer science;operating system;distributed computing;key distribution in wireless sensor networks;computer network	Mobile	-0.5566707450174794	59.13679321218137	10841
32b8960a9821f3e2d143544e6c618d85f14cdb77	pseudo-telepathy games and genuine ns k-way nonlocality using graph states	nonlocality;pseudo telepathy;paley graph states	We define a family of pseudo-telepathy games using graph states that extends the Mermin games. This family also contains a game used to define a quantum probability distribution that cannot be simulated by any number of nonlocal boxes. We extend this result, proving that the probability distribution obtained by the Paley graph state on 13 vertices (each vertex corresponds to a player) cannot be simulated by any number of 4-partite nonlocal boxes and that the Paley graph states on k222k-2 vertices provide a probability distribution that cannot be simulated by k-partite nonlocal boxes, for any k.	graph state;quantum nonlocality	Anurag Anshu;Mehdi Mhalla	2013	Quantum Information & Computation		graph power;combinatorics;discrete mathematics;topological graph;quantum nonlocality;null graph;regular graph;toroidal graph;paley graph;cycle graph;cubic graph;mathematics;voltage graph;graph state;wheel graph;quartic graph;complement graph;semi-symmetric graph;physics;string graph;strength of a graph;quantum mechanics;circulant graph	Logic	29.843974662255338	25.64892956265579	10871
4db886133e0b6c86dbfd6b0962c5687bb942603e	"""logics for approximate reasoning: approximating classical logic """"from above"""""""	probleme satisfiabilite;problema np duro;approximate reasoning;np hard problem;probleme np difficile;logique ordre 1;problema satisfactibilidad;classical logic;satisfiability problem;first order logic;logica orden 1	Approximations are used for dealing with problems that are hard, usually NP-hard or coNP-hard. In this paper we describe the notion of approximating classical logic from above and from below, and concentrate in the first. We present the family s1 of logics, and show it performs approximation of classical logic from above. The family s1 can be used for disproving formulas (the SAT-problem) in a local way, concentrating only on the relevant part of a large set of formulas.		Marcelo Finger;Renata Wassermann	2002		10.1007/3-540-36127-8_3	discrete mathematics;classical logic;many-valued logic;computer science;intermediate logic;first-order logic;np-hard;mathematics;boolean satisfiability problem;algorithm	AI	5.619298859294289	20.086873371148485	10874
6b9852525b51ce48bef2357cec896ca57ab33aa7	a ramsey theorem on semigroups and a general van der corput lemma	van dercorput;differentiation on semigroups;filter;ramsey;difference lemma	A major theme in arithmetic combinatorics is proving multiple recurrence results on semigroups (such as Szemerédi’s theorem) and this can often be done using methods of ergodic Ramsey theory. What usually lies at the heart of such proofs is that, for actions of semigroups, a certain kind of one recurrence (mixing along a filter) amplifies itself to multiple recurrence. This amplification is proved using a so-called van der Corput difference lemma for a suitable filter on the semigroup. Particular instances of this lemma (for concrete filters) have been proven before (by Furstenberg, Bergelson–McCutcheon, and others), with a somewhat different proof in each case. We define a notion of differentiation for subsets of semigroups and isolate the class of filters that respect this notion. The filters in this class (call them ∂-filters) include all those for which the van der Corput lemma was known, and our main result is a van der Corput lemma for ∂-filters, which thus generalizes all its previous instances. This is done via proving a Ramsey theorem for graphs on the semigroup with edges between the semigroup elements labeled by their ratios.	arithmetic combinatorics;ergodic ramsey theory;ergodicity;mixing (mathematics);ramsey's theorem	Anush Tserunyan	2016	J. Symb. Log.	10.1017/jsl.2015.37	combinatorics;mathematical analysis;discrete mathematics;topology;filter;ramsey theory;mathematics;algebra	Theory	38.32399318162897	28.276012119044267	10887
fb7da9f687d1e1210e794ea493f61525ed6afebf	finite state automation: definition of data communication line control procedures	regular language;data communication;finite state automata;state transition graph	The notions of finite state automata, state transition graphs and tables and the set of regular languages being accepted (generated) by such automata are well known. But for some reason these notions have not been rigorously applied in the definition of data communication line control procedures. It is the objective of this paper to do so and to show the naturalness of this approach. We claim that we thereby arrive at a complete, precise and unambiguous definition. Others have attempted this before us. They have, however, not used the descriptional tool of finite state automata. Any one or all of these references thus form the basis on which we will compete and we shall use essentially the line control procedures which these documents set out to define.	automata theory;automation;computer hardware;context-free grammar;context-free language;finite-state machine;firmware;formal language;principle of abstraction;regular language;state transition table	Dines Bjørner	1970		10.1145/1478462.1478532	state transition table;combinatorics;discrete mathematics;nondeterministic finite automaton;quantum finite automata;deterministic finite automaton;ω-automaton;mathematics;algorithm	PL	-1.3802566582273352	17.235863047086212	10901
a0256d0fb71ca4e0e2b08d77551047eb95898f85	a new method for generation of three-dimensional cubes	chain code;three dimensional;3d pictures;reachability tree;petri net	A chain code for representing three-dimensional (3D) curves was defined in [3]. In this paper we make use of Petri nets to generate a collection of three-dimensional graphs which yield three-dimensional cubes.	chain code;cubes;olap cube;petri net	R. Arumugham;K. Thirusangu;D. Gnanaraj Thomas	2010		10.1007/978-3-642-12712-0_11	combinatorics;discrete mathematics;stochastic petri net;computer science;theoretical computer science;petri net	Robotics	35.75854344948209	20.503446024417986	10917
8271ac188991768142ee567fcf5a70dfea6969ad	a characterization of sturmian morphisms	infinite word;sturmian word	"""A one-sided infinite word is balanced if the difference of the number of occurrences of a letter in two factors of the same length never exceeds one. It is Sturmian if it is balanced and not ultimately periodic. Sturmian words have a long history. A clear exposition of early work by J. Bernoulli, Christoffel, and A. A. Markov is given in the book by Venkov [22]. The term """"Sturmian"""" has been used by Hedlund and Morse in their development of symbolic dynamics [9, 10, 11]. These words are also known as Beatty sequences, cutting sequences, or characteristic sequences. There is a large literature about properties of these sequences (see for example Coven, Hedlund [6], Series [20], Fraenkel et al. [8], Stolarsky [21]). Prom a combinatorial point of view, they have been considered by S. Dulucq and D. Gouyou-Beauchamps [7], Rauzy [16, 17, 18], Brown [3], Ito, Yasutomi [12], Crisp et al. [5] in particular in relation with iterated morphisms, and by Sddbold [19], Mignosi [13]. Sturmian words appear in ergodic theory [15], in computer graphics [2], in crystallography [1], and in pattern recognition. A morphism is Sturmiau if the image of every Sturmian word is a Sturmian word. Sturmian morphisms appear in number theory in connection with the so-called substitutions of characteristic sequences. A recent account of results in this direction is given by T. C. Brown in [4]. In this paper, we show that in order to test whether a morphism f is Sturmian, it suffices to check whether the single word f(ba2ba2baba2bab) is balanced. This is in fact a strengthening of a result by Mignosi, Sddbold [14]. The decidability is an immediate consequence. We also get a simpler proof of a theorem by Crisp et al. [5] characterizing those irrational numbers for which the characteristic sequence is a fixed point of a (Sturmian) morphism."""	bernoulli polynomials;computer graphics;cutting sequence;decision problem;ergodic theory;ergodicity;fixed point (mathematics);free monoid;iteration;markov chain;pattern recognition;programmable read-only memory	Jean Berstel;Patrice Séébold	1993		10.1007/3-540-57182-5_20	arithmetic;sturmian word;discrete mathematics;computer science;mathematics;algebra	Theory	37.32116867824073	38.0237242932581	10921
2e7c0d2606f931df312da9bdaa4a2f839537bcc5	translation planes of order q6 admitting sl(2, q2)		In this paper we will give a simple construction for at least q(q + 1)/6e nondesarguesian translation planes GZ of order q6 whenever q =pe with p a prime. The elations of CY fixing the origin 0 generate a group S = SL(2, q*) having q + 2 orbits on the line L, at infinity. The group (Aut a),, has just two orbits on L,, of lengths q* + 1 and q6 q*. The kernel of LPI is GF(q3), and S acts irreducibly on the underlying four-dimensional GF(q3)-space exactly as it does in the case of the desarguesian plane of order q6. The construction was motivated by Example 8.2 of [2]. However, the plane of order 26 constructed there is not the same as the one obtained here. Variations on the construction are undoubtedly possible. The planes also differ from those in [ 11: the kernel and action on L, are quite different for those planes.	irreducibility;kernel (operating system);linear partial information;netbsd gzip / freebsd gzip	William M. Kantor	1982	J. Comb. Theory, Ser. A	10.1016/0097-3165(82)90028-0	topology;geometry;algebra	Theory	39.9285779086875	32.90783023111658	10922
5487007d8e13aef837c7fa559e83fc4d86892e64	garnir's dream spaces with hamel bases	normed space;banach space;axiom of choice;set theory;linear operator;lebesgue measure	Kurzfassung: Ein Garnir-Raum ist ein normierter Raum X f'tir den jede lineare Abbildung A:X-~ Y in einen lokalkonvexen Raum Y stetig ist. Fiir einen normierten Raum X sind folgende Eigenschaften ~iquivalent: (1) X ist ein Garnir-Raum mit einer Hamel-Basis. (2) X ist ein tonnelierter Banach-Raum mit einer Schauderschen Hamel-Basis. (3) X ist isomorph zu It(D), wobei die Potenzmenge P(D) Dedekind-endlich ist. AMS 1980 subject classification: primary: 03E 25, secondary: 46 B 15 In ZF set theory together with the axiom of choice AC, a normed space is finite dimensional, if every linear operator on it is continuous. The situation changes completely, if one drops AC and instead assumes e.g. the axiom of determinacy AD plus the principle of dependent choices DC. Then every linear map A : X~ Y from a Banach space X into a normed space Y is continuous. In fact, Garnir [4] has shown, that this follows from DC together with the hypothesis, that every set of reals is Lebesgue measurable. The purpose of this note is the investigation of Garnir's class of Banach spaces in the context of ZF without additional axioms. As the author was informed by Professor Isrki, the late Professor Garnir coined the term dream spaces for this class. 1. Definition: A normed space X is a dream space, if every linear mapping A : X ~ Y, Y a normed space, is continuous. 2. Proposition: A normed space X is dream, if and only if Xw=Xu. Proof X u is the norm topology and Xw is the finest locally convex topology on X. Let T be a convex, balanced (= circled) and absorbing (= radial) set (the notation follows [-5]). IfX is dream, then Tis an Xu-neighborhood of zero, whence Xwc_X ~. For let p(x) = inf{2 > 0: x ~ 2T) be the Minkowski-seminorm of T and Y be the quotient X/p-l(O). The norm on Y is induced by p. If the quotient mapping A : X~ Y is continuous, then {x ~ X: p(Ax) < 1 ) is an X,-neighbourhood of zero which is contained in T. For the converse, if Xw = X,, then every linear mapping	basis (linear algebra);knowledge base	Norbert Brunner	1987	Arch. Math. Log.	10.1007/BF02017496	operator space;zermelo–fraenkel set theory;functional analysis;space;basis;mathematical analysis;discrete mathematics;topology;finite-rank operator;measure;reflexive space;schauder basis;interpolation space;mathematics;discontinuous linear map;axiom of choice;linear map;normed vector space;approximation property;banach space;lp space;c0-semigroup;set theory;algebra	Theory	48.065980953741715	23.763466421128292	10936
3410ea5da92b3d234ac41eb4002124dee5b99bf8	experimental comparison of two evolutionary algorithms for the independent set problem	conjunto independiente;independent set;algoritmo genetico;steady state genetic algorithm;ensemble independant;funcion penalidad;computer experiment;algorithme genetique;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;evolutionary algorithm;fonction penalite;penalty function	This work presents an experimental comparison of the steady-state genetic algorithm to the (1+1)-evolutionary algorithm applied to the maximum vertex independent set problem. The penalty approach is used for both algorithms and tuning of the penalty function is considered in the first part of the paper. In the second part we give some reasons why one could expect the competitive performance of the (1+1)-EA. The results of computational experiment are presented.	anton (computer);black box;coefficient;computation;evolutionary algorithm;genetic algorithm;independent set (graph theory);mathematical optimization;np-hardness;penalty method;software release life cycle;steady state;timeline;wikimedia foundation v. nsa	Pavel A. Borisovsky;Marina S. Zavolovskaya	2003		10.1007/3-540-36605-9_15	mathematical optimization;genetic algorithm;computer experiment;independent set;computer science;artificial intelligence;machine learning;evolutionary algorithm;penalty method;mathematics;algorithm	DB	21.404031252743838	6.5606802129857815	10943
a1f2051997af78379bd173b03ee6b27e30ada10c	multi-heuristic scheduling: three approaches to tune compromises	dispatching rules;experimental design;fuzzy expert system;neural network	Most of the available industrial schedulers are based on a simulation approach using dispatching rules. These rules are often dedicated to the satisfaction of a single performance criterion, and are used whatever the characteristics of the workshop or of the set of jobs. An approach which allows one to bring in compromises between rules is set out in this paper. These compromises can be parametered in accordance with the objectives of the workshop and the characteristics of the jobs in order to introduce some reactivity in the decision system. Three ways to set up the parameters are compared: experimental design, fuzzy expert system and neural network. The method allowing one to define compromises can be implemented on each scheduler that uses a simulation approach. Tests have been made with an industrial scheduler called SIPAPLUS, the results of which are developed in this paper.	heuristic;scheduling (computing)	Bernard Grabot;Laurent Geneste;Arnaud Dupeux	1994	J. Intelligent Manufacturing	10.1007/BF00127648	control engineering;real-time computing;computer science;engineering;machine learning;design of experiments;artificial neural network;statistics	Robotics	11.937141905383049	5.883051670146641	10952
4e58e3cfcc599d9f487322e89e26e7302f18b872	edgewise subdivisions, local h-polynomials, and excedances in the wreath product $\mathbb{z}_r \wr \mathfrak{s}_n$	edgewise subdivision;05a05;primary;gamma polynomial;flag excedance;rees product;05e45;06a07;secondary;colored permutation;local h polynomial;derangement;barycentric subdivision	The coefficients of the local $h$-polynomial of the barycentric subdivision of the simplex with $n$ vertices are known to count derangements in the symmetric group $\mathfrak{S}_n$ by the number of excedances. A generalization of this interpretation is given for the local $h$-polynomial of the $r$th edgewise subdivision of the barycentric subdivision of the simplex. This polynomial is shown to be $\gamma$-nonnegative and a combinatorial interpretation to the corresponding $\gamma$-coefficients is provided. The new combinatorial interpretations involve the notions of flag excedance and descent in the wreath product $\mathbb{Z}_r \wr \mathfrak{S}_n$. A related result on the derangement polynomial for $\mathbb{Z}_r \wr \mathfrak{S}_n$, studied by Chow and Mansour, is also derived from results of Linusson, Shareshian, and Wachs on the homology of Rees products of posets.		Christos A. Athanasiadis	2014	SIAM J. Discrete Math.	10.1137/130939948	combinatorics;discrete mathematics;topology;barycentric subdivision;mathematics;geometry;derangement;algebra	Theory	38.239792988229446	31.976444769275204	10958
6c59258be31b6a19c51e81b9b580114c2cf45a8c	a note on first passage time problems for gaussian processes and varying boundaries	gaussian processes;level crossing problems gaussian processes;first passage time;gaussian process;level crossing problems	First and second-order approximations to the first passage time conditional probability density function of a stationary Gaussian process, with differentiable sample paths crossing a time-dependent boundary, are explicitly provided. In the limit of infinitely large time, our results coincide with the well-known results of Kac and Rice for the constant level-crossing problem.	first-hitting-time model;gaussian process	Luigi M. Ricciardi;Shunsuke Sato	1983	IEEE Trans. Information Theory	10.1109/TIT.1983.1056654	gaussian random field;mathematical optimization;combinatorics;gaussian process;mathematics;gaussian filter;gaussian function;statistics	Theory	43.88183817378148	12.39868678368408	10972
5a32fefbed0cfbd6e43a66fb7addddd2f8a0ef29	a stochastic probing problem with applications	chosen element;general constraint;active element;chosen subset;general stochastic;probed element;pe value;element e;k-matroid intersection feasibility constraint;set q	We study a general stochastic probing problem defined on a universe V , where each element e ∈ V is “active” independently with probability pe. Elements have weights {we : e ∈ V } and the goal is to maximize the weight of a chosen subset S of active elements. However, we are given only the pe values—to determine whether or not an element e is active, our algorithm must probe e. If element e is probed and happens to be active, then e must irrevocably be added to the chosen set S; if e is not active then it is not included in S. Moreover, the following conditions must hold in every random instantiation: • the set Q of probed elements satisfy an “outer” packing constraint, • the set S of chosen elements satisfy an “inner” packing constraint. The kinds of packing constraints we consider are intersections of matroids and knapsacks. Our results provide a simple and unified view of results in stochastic matching [12, 3] and Bayesian mechanism design [9], and can also handle more general constraints. As an application, we obtain the first polynomial-time Ω(1/k)-approximate “Sequential Posted Price Mechanism” under k-matroid intersection feasibility constraints, improving on prior work [9, 25, 19].	algorithm;electronic component;matroid intersection;polynomial;set packing;stochastic optimization;time complexity;universal instantiation	Anupam Gupta;Viswanath Nagarajan	2013		10.1007/978-3-642-36694-9_18	mathematical optimization;combinatorics;mathematics;algorithm	Theory	20.638418782688188	16.536359559804527	10985
60d484716f9613d90a73f9e55dcb289e0e6836e8	applying vc-dimension analysis to object recognition	object recognition;perspective projection;data collection;upper bound;affine transformation;combinatorial complexity;quantitative analysis;euclidean space;task complexity;computational learning theory;vc dimension	We analyze the amount of information needed to carry out various model-based recognition tasks, in the context of a probabilistic data collection model. We focus on objects that may be described as semi-algebraic subsets of a Euclidean space, and on a wide class of object transformations, including perspective and affine transformations of 2D objects, and perspective projections of 3D objects. Our approach borrows from computational learning theory. We draw close relations between recognition tasks and a certain learnability framework. We then apply basic techniques of learnability theory to derive upper bounds on the number of data features that (provably) suffice for drawing reliable conclusions. The bounds are based on a quantitative analysis of the complexity of the hypotheses class that one has to choose from. Our central tool is the VC-dimension, which is a well studied parameter measuring the combinatorial complexity of families of sets. It turns out that these bounds grow linearly with the task complexity, measured via the VC-dimension of the class of objects one deals with.	outline of object recognition;vc dimension	Michael Lindenbaum;Shai Ben-David	1994		10.1007/3-540-57956-7_29	combinatorics;discrete mathematics;perspective;vc dimension;quantitative analysis;euclidean space;cognitive neuroscience of visual object recognition;machine learning;affine transformation;mathematics;3d single-object recognition;upper and lower bounds;computational learning theory;data collection	Vision	40.07521029942678	20.980462422910502	10988
28163859bc2367d41da43f6aabe59e7fd47afd42	using mixed-integer programming to solve power grid blackout problems	power transmission;optimization problem;large scale;mixed integer program;power grid;mixed integer programming;power flow;power flows;blackouts	We consider optimization problems related to the prevention of large-scale cascading blackouts in power transmission networks subject to multiple scenarios of externally caused damage. We present computation with networks with up to 600 nodes and 827 edges, and many thousands of damage scenarios. 1 Partially funded by NSF award DMI-0521741.	computation;ibm notes;integer programming;linear programming;mathematical optimization	Daniel Bienstock;Sara Mattia	2007	Discrete Optimization	10.1016/j.disopt.2006.10.007	optimization problem;mathematical optimization;power-flow study;integer programming;power transmission;computer science;theoretical computer science;mathematics	Theory	11.691328275169253	8.357389235817966	10996
4e39a19fc2cef4938f449a433b545d871957aa1f	edge-colorings of graphs avoiding complete graphs with a prescribed coloring	edge coloring;regularity;holder;extremal graph;symmetrization	For any xed graph F , we say that a graph G is F -free if it does not contain F as a subgraph. We denote by ex(n, F ) the maximum number of edges in a n-vertex graph which is F -free, known as the Turán number of F . In 1974, Erd®s and Rothschild considered a related question where we count the number of certain colorings. Given an integer r, by an r-coloring of a graph G we mean any r-edgecoloring of G. In particular, it does not have to be proper and does not have to use all r colors. Let cr,F (G) be the number of r-colorings of G such that every color class is F free. They considered the problem of nding cr,F (n) = max{cr,F (G)} where the maximum is over all n-vertex graphs G. Let us say that G is extremal for cn,F (n) if it realizes the above maximum. Clearly, cr,F (n) ≥ r , as we take G to be the Turán graph and color it arbitrarily. The problem of determining cr,F (n) was investigates by several authors, for various classes of graphs such as: complete graphs [1, 8, 9], odd cycles [1], matchings [4], paths and stars [5]. And for hypergraphs [3, 6, 7]. One common concern is to determine when the Turán Graph is extremal for cr,F (n) (with r xed and n large). Here we consider a natural generalization of the above. Given an r-colored k-vertex graph F̂ , we consider the number of r-edge-colorings of a larger graph G that avoids the `color pattern' of F̂ . More formally, cr,F̂ (G) denote the number or r-colorings of G such there are no k vertices of G that induce a colored graph isomorphic to F̂ . For example, the above problem consists of the case where F̂ is a colouring of F that uses only one of the r colors. We de ne cr,F̂ (n) and extremal graphs as before. We note that Balogh [2] had also considered a related but not analogous colored version of the problem. He considered the number Cr,F̂ (G) of colorings of G which do not have a set of k-vertices colored exactly as in F̂ . In this case, for example, if F̂ has only one color, Cr,H(G) is the number of coloring of G which does not contains F̂ in this particular color class.So cr,F̂ (G) ≤ Cr,F̂ (G). Balogh proved that in the case where r = 2 and F̂ is a 2-coloring of a clique that uses both colors then C2,F̂ (n) = 2 ex(n,F̂ ) for n large enough. Here, we focus on the case where r = 3. Let F̂3 be a 3-colored K3. We proved that if the three colors are used in F̂3 then the complete graph on n vertices is the extremal graph for c3,F̂3(n). And if only two colors are used in F3 then the Turán Graph is extremal for c3,F̂3(n) (whereas this is trivially not true for C3,F̂3(n)). Much more generally we prove the following: with r = 3, let F̂k be a coloring of Kk that uses only two colors one of which induces a graph H whose Ramsey Number is smaller than k, then the Turán Graph is extremal for c3,F̂k (n).	carrier-to-noise ratio;color;extremal graph theory;graph coloring;matching (graph theory);ramsey's theorem;turán graph;turán number;vertex (geometry)	Fabrício Benevides;Carlos Hoppen;Rudini Menezes Sampaio	2017	Discrete Mathematics	10.1016/j.disc.2017.04.011	graph power;split graph;combinatorics;clique graph;extremal graph theory;discrete mathematics;triangle-free graph;independent set;topology;fractional coloring;turán graph;simplex graph;complete coloring;forbidden graph characterization;edge coloring;symmetrization;graph coloring;graph factorization;mathematics;voltage graph;list coloring;graph minor;complement graph;line graph;string graph;algebra	Theory	30.52519072627056	27.077576372662218	11000
396a02fa0bc815957c567a84897bbda5c3a55e48	design of application-specific 3d networks-on-chip architectures	network on chip;routing;3d mesh implementations application specific 3d networks on chip architectures silicon integration technology chip design innovations systems on chip soc networks on chip noc interconnection ripup reroute and router merging power consumption;through silicon via;three dimensional;network routing;chip;network topology;system on chip;three dimensional displays;solid modeling;network optimization;power consumption;power demand;network on chip network routing;network synthesis chip scale packaging design optimization energy consumption silicon technological innovation network on a chip power system interconnection delay power system modeling;algorithm design and analysis	The increasing viability of three dimensional (3D) silicon integration technology has opened new opportunities for chip design innovations, including the prospect of extending emerging systems-on-chip (SoC) design paradigms based on networks-on-chip (NoC) interconnection architectures to 3D chip designs. In this paper, we consider the problem of designing application-specific 3D-NoC architectures that are optimized for a given application. We present novel 3D-NoC synthesis algorithms that make use of accurate power and delay models for 3D wiring with through-silicon vias. In particular, we present a very efficient 3D-NoC synthesis algorithm called ripup-reroute-and-router-merging (RRRM), that is based on a rip-up and reroute formulation for routing flows and a router merging procedure for network optimization. Experimental results on 3D-NoC design cases show that our synthesis results can on average achieve a 74% reduction in power consumption and a 17% reduction in hop count over regular 3D mesh implementations and a 52% reduction in power consumption and a 17% reduction in hop count over optimized 3D mesh implementations.	3d television;algorithm;analysis of algorithms;benchmark (computing);interconnection;mathematical optimization;network on a chip;network topology;requirement;router (computing);routing;system on a chip;via (electronics);wiring	Shan Yan;Bill Lin	2008	2008 IEEE International Conference on Computer Design	10.1109/ICCD.2008.4751853	embedded system;routing;electronic engineering;computer science;engineering;network on a chip;computer network	EDA	13.470304645869701	53.31728336415627	11003
b1aacb857972b8bd11691756787d0c6d49b1f1f7	effitest: efficient delay test and statistical prediction for configuring post-silicon tunable buffers	delays clocks tuning manufacturing frequency measurement semiconductor device measurement;hybrid of x masking and x canceling misr;clocks;control bits;semiconductor device measurement;frequency measurement;tuning;manufacturing;statistical analysis buffer circuits clocks elemental semiconductors integrated circuit testing iterative methods nanoelectronics silicon;si efficient delay test effitest post silicon tunable buffers nanometer manufacturing technology nodes circuit performance post silicon clock tuning buffers timing budgets path delays delay measurement path wise frequency stepping post silicon testing problem statistical delay prediction frequency stepping iterations;test pattern partitioning;delays	At nanometer manufacturing technology nodes, process variations significantly affect circuit performance. To combat them, post-silicon clock tuning buffers can be deployed to balance timing budgets of critical paths for each individual chip after manufacturing. The challenge of this method is that path delays should be measured for each chip to configure the tuning buffers properly. Current methods for this delay measurement rely on path-wise frequency stepping. This strategy, however, requires too much time from expensive testers. In this paper, we propose an efficient delay test framework (EffiTest) to solve the post-silicon testing problem by aligning path delays using the already-existing tuning buffers in the circuit. In addition, we only test representative paths and the delays of other paths are estimated by statistical delay prediction. Experimental results demonstrate that the proposed method can reduce the number of frequency stepping iterations by more than 94% with only a slight yield loss.	benchmark (computing);iteration;multiplexing;performance tuning;statistical model;stepping level;test automation	Grace Li Zhang;Bing Li;Ulf Schlichtmann	2016	2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC)	10.1145/2897937.2898017	control engineering;embedded system;electronic engineering;real-time computing;engineering;manufacturing	EDA	22.373790536831844	56.70641197163669	11008
69e03c991ef9ebc5601560592f2eca15e35db16f	spanning trees in regular graphs	spanning tree;regular graph	"""A walk of length r in a graph X is a sequence v = (vo, 0 1 , . . . , v,) of vertices of X such that is adjacent to vi for l G i S r . We say that v starts at v"""", finishes at vr, and is closed if v, = U"""". Suppose that for some i (0 < i <r) we have = vi+l. Then we can reduce v by deleting the elements vi and The result is clearly a walk of length r -2 which is closed if and only if v is closed. If v cannot be reduced in this way it is called irreducible. Given any walk v there is a unique irreducible walk i5 which can be obtained from v by a sequence of reductions. The uniqueness of 17 is proved in [ 5 ] . If I7 has length 0, we will call v totally reducible. Obviously, totally reducible walks are closed. Our first theorem gives a relationship between the number of walks and the number of irreducible walks between two vertices of X, if X is regular."""	existential quantification;file spanning;irreducibility;universal quantification;vertex (geometry)	Brendan D. McKay	1983	Eur. J. Comb.	10.1016/S0195-6698(83)80045-6	combinatorics;kruskal's algorithm;dual graph;minimum degree spanning tree;spanning tree;regular graph;minimum spanning tree;pancyclic graph;graph factorization;connected dominating set;mathematics;tree-depth;trémaux tree;reverse-delete algorithm;tree;shortest-path tree	Theory	29.86366715866692	28.815278134672422	11014
63a80b39ab62fd9fabbd2d2ca5d4ed1ddad91df8	analysis of pev charging impact on distribution transformer aging for charging station transformer design	transformers design engineering electric vehicles transformer windings;oil insulation power transformer insulation windings temperature measurement charging stations temperature measurement;transformer charging station loss of life plug in electric vehicle power quality;taiwan pev charging impact analysis distribution transformer aging charging station transformer design plug in electric vehicle dynamic thermal energy model transformer winding temperature charging station load profile ansi ieee standard power quality transformer rating pev charging impact transformer loss of life transformer capacity charging station distribution system pilot project	As plug-in electric vehicles (PEVs) are expanding, there is a growing need for widely distributed publicly accessible charging stations that supply electric energy for the recharging of the PEVs. In the charging station design, the proper distribution transformers that delivery reliable power from utility to the station are essential and important. To ensure economic and reliable operation of the charging station, the paper proposes a methodology for the PEVs charging station transformer design. A set of dynamic thermal energy models that describe the relationship between the transformer winding temperature and charging station load profile is derived according to ANSI/IEEE standards. The base load, PEVs demand, power quality, ambient temperature, transformer rating and connection all are taken into account. The models are then used to analyze PEVs charging impact on transformer loss-of-life and determine the proper transformer capacity and connection. The proposed method provides a better knowledge of the transformer effects and can be used for evaluating the level of PEVs that might be accepted on a distribution transformer. The models developed can also be used for determining proper transformers in the design of charging station distribution systems. The field testing results of a practical charging station for PEVs pilot projects in Taiwan confirm the validity of the proposed method.	electric power quality;load profile;plug-in (computing);transformer;transformers	Chun-Lien Su;Chan-Nan Lu;Kai-En Zheng;Jen-Hao Teng;Rong-Ceng Leou;Kuo-Feng Huang	2014	2014 IEEE Industry Application Society Annual Meeting	10.1109/IAS.2014.6978491	isolation transformer;current transformer;electronic engineering;energy efficient transformer;delta-wye transformer;telecommunications;engineering;electrical engineering;transformer effect;distribution transformer	Embedded	3.598504025417471	7.2215458624747715	11023
9b47a5b16a7b3fea38ac98a8985d830709e6870a	real and imaginary truth in complex fuzzy implication	interpolation;standards;defuzzification complex fuzzy sets logic modus ponens;fuzzy sets imaginary truth complex fuzzy implication parameterized family implication operators schweizer sklar t norms truth value complex values binary switching unweighted averaging fuzzy logic;limiting;fuzzy sets;fuzzy set theory fuzzy logic;fuzzy logic;fuzzy logic fuzzy sets standards limiting harmonic analysis cognition interpolation;cognition;harmonic analysis	This paper examines the use of a parameterized family of implication operators based on Schweizer-Sklar T-norms. Removing a restriction imposed by Schweizer and Sklar when the parameter p is negative leads to improper implication operators for which the truth value can take values outside the unit interval, including complex values. Inferences using increasingly positive p produce inferences increasingly biased toward binary switching (“selectivity”), while inferences based on improper implication operators with increasingly negative p produce inferences increasingly biased to unweighted averaging (“consensus”).	imaginary time;selectivity (electronic);t-norm	Thomas Whalen	2015	2015 Annual Conference of the North American Fuzzy Information Processing Society (NAFIPS) held jointly with 2015 5th World Conference on Soft Computing (WConSC)	10.1109/NAFIPS-WConSC.2015.7284137	fuzzy logic;t-norm fuzzy logics;mathematical optimization;discrete mathematics;cognition;membership function;defuzzification;type-2 fuzzy sets and systems;interpolation;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy subalgebra;fuzzy number;neuro-fuzzy;harmonic analysis;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;algorithm;fuzzy control system;limiting	AI	44.53077124065836	21.077499251214398	11033
50306fa4f7fc153873b01179aafc80c4ba5400f3	localsense: an infrastructure-mediated sensing method for locating appliance usage events in homes	green computing;different power line impedance;real time aggregated power consumption;power aware computing;location-aware power usage information;existing home power infrastructure;main power meter;power consumption;aggregated power consumption;power dissipation;power utilisation;locating appliance usage events;local sense;power consumption awareness;power meters;non-intrusive load monitoring system;additional power dissipation;appliance usage event;appliance usage events;different power dissipation;localsense;power cables;sensors;home power infrastructure;infrastructure-mediated sensing method;power line impedances;domestic appliances;household power infrastructure	In this paper, we introduce a novel technique called Local Sense for detecting appliance usage events in a household by leveraging existing home power infrastructure. Specifically, the Local Sense technique works by purely analyzing the records taken from the main power meter. The main power meter is installed in a household to measure the overall real time aggregated power consumption in terms of wattage and voltage for the whole load of appliances in a household. The Local Sense technique requires no additional apparatuses being installed in existing household power infrastructure, which significantly reduces the cost for enabling the location-aware power usage information over existing techniques. The idea behind the Local Sense system is to reflect the fact that different outlets are with different power line impedances, which causes different power dissipation even for the same appliance usage. By identifying the additional power dissipation, detecting the appliance usage events at outlet levels is therefore possible. The proposed technique is validated in a research lab and preliminary results demonstrate the effectiveness of the proposed system.	cpu power dissipation;location awareness;optical power meter;sensor	Hung-Yuan Chen;Chien-Liang Lai;Huan Chen;Lun-Chia Kuo;Hsi-Chuan Chen;Jyh-Shyan Lin;Yao-Chung Fan	2013	2013 International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2013.105	green computing;embedded system;power budget;real-time computing;power usage effectiveness;computer science;sensor;operating system;dynamic demand	EDA	1.5197412382944475	33.22921057608881	11042
196ced193bac6cf74f97e46f471e634fb5ceba20	optimal scheduling of multicluster tools with constant robot moving times, part ii: tree-like topology configurations	arbre graphe;criterio optimalidad;modelizacion;robot movil;topology;pattern clustering;microelectronic fabrication;completion time;fabricacion microelectrica;cluster;multiple machines;productivite;metodo monte carlo;semiconductor manufacturing cluster tools multiple machines performance productivity scheduling;serial cluster tool;algorithm analysis;tree graph;cluster tools;amas;job shop scheduling;tree topology;analisis quimico;algoritmo recursivo;exact solution;topologie;single blade robot;methode monte carlo;temps achevement;performance productivity;chemical analysis;mobile robots;multiple machine;robotics;solucion exacta;trees mathematics;analyse chimique;productividad;closed form formulation;topologia;modelisation;condicion optimalidad;maquina multiple;condition optimalite;closed form formulation optimal scheduling multicluster tool tree topology single blade robot constant robot moving times serial cluster tool monte carlo simulation;algorithme recursif;robot mobile;optimal scheduling;scheduling;industrial robots;monte carlo method;trees mathematics industrial robots mobile robots monte carlo methods pattern clustering scheduling;robots;schedules;robotica;clustering algorithms;optimal scheduling topology job shop scheduling processor scheduling clustering algorithms service robots chemical analysis planarization scheduling algorithm industrial relations;analyse algorithme;optimality criterion;recursive algorithm;robotique;monton;productivity;solution exacte;critere optimalite;machine multiple;arbol grafo;monte carlo simulation;tiempo acabado;modeling;gallium nitride;analisis algoritmo;monte carlo methods;ordonnancement;moving robot;optimality condition;constant robot moving times;reglamento;multicluster tool;semiconductor manufacturing;fabrication microelectronique	In this paper, we analyze optimal scheduling of a tree-like multicluster tool with single-blade robots and constant robot moving times. We present a recursive minimal cycle time algorithm to reveal a multi-unit resource cycle for multicluster tools under a given robot schedule. For a serial-cluster tool, we provide a closed-form formulation for the minimal cycle time. The formulation explicitly provides the interaction relationship among clusters. We further present decomposition conditions under which the optimal scheduling of multicluster becomes much easier and straightforward. Optimality conditions for the widely used robot pull schedule are also provided. An example from industry production is used to illustrate the analytical results. The decomposition and optimality conditions for the robot pull schedule are also illustrated by Monte Carlo simulation for the industrial example.	algorithm;monte carlo method;recursion;robot;scheduling (computing);simulation	Wai Kin Chan;Shengwei Ding;Jingang Yi;Dezhen Song	2011	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2010.2046893	job shop scheduling;mathematical optimization;simulation;computer science;artificial intelligence;operating system;robotics;algorithm;statistics;monte carlo method	Robotics	10.422573055845524	6.228094309746861	11044
3d02038930ff4e208744b435ef851d6b2120c762	stochastic independence, algebraic independence and abstract connectedness	stochastic independence;abstract connectedness;algebraic independence	Abstract   Mutual stochastic independences among σ-algebras and mutual algebraic independences among elements of semimodular lattices are observed to have a very similar behaviour. We suggest abstract independence structures called  I -relations describing it. Presented examination of  I -relations resembles a theory of abstract connectedness: a dual characterization of  I -relations by families of connected sets is found by means of a special Galois connection. Representations of  I -relations in the matroid theory sense by σ-algebras and by elements of lattices are discussed.	algebraic independence	Frantisek Matús	1994	Theor. Comput. Sci.	10.1016/0304-3975(94)90248-8	combinatorics;discrete mathematics;topology;mathematics;algebra	Theory	41.838407189981204	25.977581525845466	11059
280ee12c5f7cffa7cd170db25ba2236adcf8cd78	multiserver queueing system with non-homogeneous customers and sectorized memory space		In the present paper, we investigate a multiserver queueing system with non-homogeneous customers. As non-homogenity, we mean that each customer is characterized by some random l-dimensional volume vector. The arriving customers appear according to a stationary Poisson process. Service time of a customer does not depend on his volume vector and has an exponential distribution. Memory space is composed of l limited parts in accordance with customers volume vectors components. For this system, the steady-state distribution of the number of customers present in the system and loss probability are determined. An analysis of some special cases and some numerical examples are attached as well.	computational resource;queueing theory	Marcin Ziólkowski;Oleg M. Tikhonenko	2018		10.1007/978-3-319-92459-5_22	real-time computing;exponential distribution;homogeneous;poisson process;queueing theory;computer science;distributed computing	Metrics	8.502105384259242	10.58898412269315	11073
90480dc3c58af43a6b262512b195733a9d07dc6f	evaluation of test metrics: stuck-at, bridge coverage estimate and gate exhaustive	system on chip bridge circuits data analysis integrated circuit testing;defective chips test metrics evaluation stuck at bridge coverage estimate gate exhaustive production test data analysis;production test data analysis;chip;bridge coverage estimate;data analysis;stuck at;gate exhaustive;system on chip;integrated circuit testing;defective chips;test metrics evaluation;bridges test pattern generators automatic test pattern generation automatic testing production silicon pattern analysis manufacturing compaction;bridge circuits	Production test data from more than 500,000 chips is analyzed to understand the correlation between the number of defective chips detected by a set of test patterns and the coverage values of these test patterns with respect to various test metrics. Experimental results show that the gate exhaustive metric has the highest correlation when compared to the stuck-at and the bridge coverage estimate metrics, especially for high coverage test patterns. More than 69% of all test patterns can be removed from the test set without reducing the number of detected chips - more than 99% of these patterns are required to obtain high stuck-at coverage. None of the test metrics are very effective in predicting which subset of a given set of test patterns can be removed from the test set without compromising test quality before the patterns are actually applied to manufactured ICs	and gate;fault coverage;test card;test data;test set	Ruifeng Guo;Subhasish Mitra;Enamul Amyeen;Jinkyu Lee;Srihari Sivaraj;Srikanth Venkataraman	2006	24th IEEE VLSI Test Symposium	10.1109/VTS.2006.34	chip;system on a chip;reliability engineering;electronic engineering;real-time computing;fault coverage;telecommunications;computer science;engineering;automatic test pattern generation;test compression;data analysis	SE	22.744146773078167	54.66443363927952	11077
e66e1147d64f57406bc63a10070c02d8c30a4bf8	clustering lines in high-dimensional space: classification of incomplete data	approximate algorithm;high dimensionality;nonparametric statistic;incomplete data;k center;clustering;discrete geometry;euclidean space;missing values;helly theorem;high dimension;lines	A set of <i>k</i> balls <i>B</i><sub>1</sub>, …,<i>B</i><sub><i>k</i></sub> in a Euclidean space is said to cover a collection of lines if every line intersects some ball. We consider the <i>k</i>-<i>center problem for lines</i> in high-dimensional space: Given a set of <i>n</i> lines <i><sup>l</sup></i>= {<i>l</i><sub>1</sub>,…,<i>l</i><sub><i>n</i></sub> in R<sup>d</sup>, find <i>k</i> balls of minimum radius which cover <i>l</i>. We present a 2-approximation algorithm for the cases <i>k</i> = 2, 3 of this problem, having running time quasi-linear in the number of lines and the dimension of the ambient space.  Our result for 3-clustering is strongly based on a new result in discrete geometry that may be of independent interest: a Helly-type theorem for collections of axis-parallel “crosses” in the plane. The family of crosses does not have finite Helly number in the usual sense. Our Helly theorem is of a new type: it depends on ε-contracting the sets.  In statistical practice, data is often incompletely specified; we consider lines as the most elementary case of incompletely specified data points. Clustering of data is a key primitive in nonparametric statistics. Our results provide a way of performing this primitive on incomplete data, as well as imputing the missing values.	algorithm;apache axis;cluster analysis;data point;missing data;time complexity	Jie Gao;Michael Langberg;Leonard J. Schulman	2010	ACM Trans. Algorithms	10.1145/1868237.1868246	discrete geometry;mathematical optimization;combinatorics;discrete mathematics;euclidean space;line;mathematics;geometry;helly's theorem;cluster analysis;algorithm	Theory	34.082807305865906	22.182982630042915	11079
3a74606eaa207827114c2fcebc086a89d30efc87	algorithms for quad-double precision floating point arithmetic	computers;c algorithms quad double precision floating point arithmetic quad double number unevaluated sum ieee double precision numbers significand;general and miscellaneous mathematics computing and information science;object oriented programming;accuracy;floating point arithmetic physics computing computational geometry libraries packaging computer science laboratories mathematics cryptography uncertainty;algorithms;floating point arithmetic;high precision arithmetic;object oriented programming floating point arithmetic;performance high precision arithmetic;99 general and miscellaneous mathematics computing and information science	A quad-double number is an unevaluated sum of four IEEE double precision numbers, capable of representing at least 212 bits of signi cand. We present the algorithms for various arithmetic operations (including the four basic operations and various algebraic and transcendental operations) on quad-double numbers. The performance of the algorithms, implemented in C++, is also presented.	asymptotically optimal algorithm;c++;correctness (computer science);data structure;double-precision floating-point format;emoticon;fortran;function overloading;ieee 754-1985;input/output;linear algebra;numerical aperture;operator overloading;priest;random number generation	Yozo Hida;Xiaoye S. Li;David H. Bailey	2001		10.1109/ARITH.2001.930115	nan;floating-point unit;minifloat;double-precision floating-point format;quadruple-precision floating-point format;arbitrary-precision arithmetic;binary scaling;computer science;floating point;theoretical computer science;operating system;arithmetic logic unit;saturation arithmetic;significand;algebraic operation;mathematics;accuracy and precision;extended precision;unit in the last place;programming language;object-oriented programming;machine epsilon;single-precision floating-point format;algorithm;half-precision floating-point format;statistics;algebra	Theory	16.813151793413454	41.123871177782206	11089
a98de54a9dc24e2b62f2f052c3c7bd83e697a98a	fuzzy acceptors for syntactic pattern recognition	syntactic pattern recognition	Abstract   The behavior of finite fuzzy acceptors over a bounded chain   L   is considered. The approximate (ϵ-) equivalence and ϵ-reduction by inputs are investigated. In the class of all finite fuzzy acceptors over   L  , the problems of ϵ-equivalence and ϵ-reduction are decidable. These results are implemented for pattern recognition of deformed images, as well as for restoration and enhancement of distorted patterns if the measure of the similarity is expressed by ϵ.	syntactic pattern recognition	Ketty Peeva	1991	Int. J. Approx. Reasoning	10.1016/0888-613X(91)90014-D	natural language processing;discrete mathematics;computer science;pattern recognition;mathematics	Vision	-2.9273265083692186	19.29001890844817	11097
7c9227e0b92ec7984313d4cc55ab8441a5196eff	topological recursion for irregular spectral curves		We study topological recursion on the irregular spectral curve xy2 − xy + 1 = 0, which produces a weighted count of dessins d’enfant. This analysis is then applied to topological recursion on the spectral curve xy2 = 1, which takes the place of the Airy curve x = y2 to describe asymptotic behaviour of enumerative problems associated to irregular spectral curves. In particular, we calculate all one-point invariants of the spectral curve xy2 = 1 via a new three-term recursion for the number of dessins d’enfant with one face.		Norman Do;Paul T. Norbury	2018	J. London Math. Society	10.1112/jlms.12112	combinatorics;mathematical analysis;discrete mathematics;mathematics;geometry	Theory	37.82841952146271	22.101477657429392	11101
0c75cf8b4c659756bf0924201a89a01921ecdfc5	split contraction: the untold story		The edit operation that contracts edges, which is a fundamental operation in the theory of graph minors, has recently gained substantial scientific attention from the viewpoint of Parameterized Complexity. In this paper, we examine an important family of graphs, namely the family of split graphs, which in the context of edge contractions, is proven to be significantly less obedient than one might expect. Formally, given a graphG and an integer k, Split Contraction asks whether there exists X ⊆ E(G) such that G/X is a split graph and |X| ≤ k. Here, G/X is the graph obtained from G by contracting edges in X. It was previously claimed that Split Contraction is fixed-parameter tractable. However, we show that Split Contraction, despite its deceptive simplicity, is W[1]-hard. Our main result establishes the following conditional lower bound: under the Exponential Time Hypothesis, Split Contraction cannot be solved in time 2o(`) · nO(1) where ` is the vertex cover number of the input graph. We also verify that this lower bound is essentially tight. To the best of our knowledge, this is the first tight lower bound of the form 2o(`) · nO(1) for problems parameterized by the vertex cover number of the input graph. In particular, our approach to obtain this lower bound borrows the notion of harmonious coloring from Graph Theory, and might be of independent interest. 1998 ACM Subject Classification G.2.2 Graph Algorithms, I.1.2 Analysis of Algorithms	algorithm;analysis of algorithms;cobham's thesis;exptime;edge contraction;exponential time hypothesis;graph coloring;graph minor;graph theory;harmonious coloring;parameterized complexity;vertex cover	Akanksha Agrawal;Daniel Lokshtanov;Saket Saurabh;Meirav Zehavi	2017		10.4230/LIPIcs.STACS.2017.5	graph power;graph toughness;combinatorics;discrete mathematics;strength of a graph;bound graph;edge contraction;voltage graph;semi-symmetric graph;mathematics;graph factorization	Theory	22.79105527737804	23.045951740386645	11103
669bd51b272ffb70a5407ebc8c98cd14c532efb4	on the minimum order of graphs with given semigroup	graph theory;ordre minimum;theorie graphe;semigroupe;semigroup	Abstract   Denote by  M ( n ) the smallest positive integer such that for every  n -element monoid  M  there is a graph  G  with at most  M ( n ) vertices such that End( G ) is isomorphic to  M . It is proved that   2  (1 + o(1))n  log     2   n   ≤M(n)≤n ·   2n   + O(n)  . Moreover, for almost all  n -element monoids  M  there is a graph  G  with at most 12 ·  n  ·  log  2  n  +  n  vertices such that End( G ) is isomorphic to  M .		Václav Koubek;Vojtech Rödl	1984	J. Comb. Theory, Ser. B	10.1016/0095-8956(84)90021-2	combinatorics;discrete mathematics;graph theory;mathematics;semigroup;algebra	Theory	27.728965678135143	32.11724980087649	11105
749efbf1614fb531b1000f1fae9fe616557043fa	semi-online scheduling with bounded job sizes on two uniform machines	semi online;bounded job sizes;uniform machines;scheduling	In this paper, we investigate a semi-online scheduling problem on two uniform machines with the speed ratio  s . It is assumed that all jobs have their processing times between  p  and  tp    (  p>0     p  >  0       ,   t≥1     t  ≥  1       ). The objective is to minimize the makespan. We give the competitive ratio of  LS    algorithm which is a piecewise function on   t≥1     t  ≥  1        and   s≥1     s  ≥  1       . It shows that  LS  is an optimal algorithm for most regions on  s  and  t   . We further present two optimal algorithms. The algorithm   H 1        H    1          with competitive ratio of  s    is optimal for            1.325  ≤  s  ≤    1  +   5    2         and            s    t  ≤      s    2    −  1    1  +  s  −    s    2           . The algorithm   H 2        H    2          with competitive ratio of  s    is optimal for   1.206≤s≤1.5     1.206  ≤  s  ≤  1.5        and            s  ≤  t  ≤  min  ⁡  {  2  s  −  1  ,      2  (    s    2    −  1  )    1  +  s  −    s    2      }       , and it is also optimal for            1  ≤  s  ≤    1  +   17    4         and            max  ⁡  {  2  s  −  1  ,      −  s  +    9    s    2    +  8  s      2  s    }  ≤  t  ≤   2  s         with competitive ratio of              1  +  t   2        .	scheduling (computing);semiconductor industry	Qian Cao;Zhaohui Liu	2016	Theor. Comput. Sci.	10.1016/j.tcs.2016.08.022	combinatorics;discrete mathematics;computer science;machine learning;mathematics;scheduling	Theory	15.937999645286741	10.92813239689639	11111
f202592b76bb9407c12cce8bab3900966f5b6f90	planar maximal covering location problem under block norm distance measure	modelizacion;forecasting;quadratic programming;location problem;reliability;probleme localisation;localisation installation;project management;graphe intervalle;information systems;maximum clique problem;distance measure;programmation quadratique;maintenance;interval graph;clique partitioning;grafo intervalo;soft or;information technology;heuristic method;packing;partitioning;probleme clique maximal;problema np duro;metodo heuristico;operations research;location;algoritmo genetico;investment;journal;journal of the operational research society;inventory;problema clique maxima;purchasing;modelisation;np hard problem;history of or;probleme recouvrement;planar maximal covering;particion;logistics;couverture;problema recubrimiento;probleme np difficile;marketing;facilities location;scheduling;block norms;partition;algorithme genetique;production;communications technology;genetic algorithm;programacion cuadratica;partitionnement;maximal covering location problem;coverage;heuristics;problema localizacion;methode heuristique;subdivision;computer science;operational research;covering problem;modeling;applications of operational research;or society;jors;management science;infrastructure;facility location;cobertura	This paper introduces a new model for the planar maximal covering location problem (PMCLP) under different block norms. The problem involves locating g facilities anywhere on the plane in order to cover the maximum number of n given demand points. The generalization, in this paper, is that the distance measures assigned to facilities are block norms of different types and different proximity measures. First, the PMCLP under different block norms is modelled as a maximum clique partition problem on an equivalent multi-interval graph. Then, the equivalent graph problem is modelled as an unconstrained binary quadratic problem (UQP). Both the maximum clique partition problem and the UQP are NP-hard problems; therefore, we solve the UQP format through a genetic algorithm heuristic. Computational examples are given.	maximal set	Hassan Younies;George O. Wesolowsky	2007	JORS	10.1057/palgrave.jors.2602172	partition;project management;logistics;mathematical optimization;combinatorics;genetic algorithm;interval graph;inventory;economics;forecasting;investment;computer science;marketing;subdivision;heuristics;reliability;mathematics;location;operations research;information technology;scheduling;quadratic programming;algorithm	Theory	21.070786298839774	12.25522309460632	11130
bfb8714f4327ee1d5546bda92f0d9376a7465908	a generalized upper bounding approach to a communications network planning problem	upper bound;community networks	An important network optimization problem i s t o determine the routing of circuits and construction of additional arc capacity i n a comnications network so as t o satisfy forecasted circuit requirements a t minimum cost. single-time-period version of the problem formulated as a linear program i n the arc-chain form. Zinear program i s expZoited t o develop an e f f ic ien t solution procedure. I n particular, the generalized upper bounding technique devised by Dantzig and Van Slyke i s applied. implementation of the procedure i s discussed and computational experience i s reported. Brief mention i s also made of certain extensions that are being pursued. This paper considers the The special structure of t h i s	computation;flow network;linear programming;mathematical optimization;optimization problem;requirement;routing;telecommunications network	Charles J. McCallum	1977	Networks	10.1002/net.3230070102	mathematical optimization;combinatorics;simulation;telecommunications;computer science;mathematics;upper and lower bounds;algorithm;statistics	Theory	22.05710256362926	13.6739685935002	11132
8b0b2f2605e533c40cac32e1a3a989f7aa759841	new generation of predictive technology model for sub-45nm design exploration	predictive technology model;mosfet circuits;silicon;pmos;cmos integrated circuits;process variation;nanoscale cmos;130 to 32 nm;cmos technology;design exploration;mosfets;uncertainty;asu;gate oxide tunneling;circuit design;extrapolation;cmos process;integrated circuit design;accuracy;process variations;predictive models semiconductor device modeling cmos technology mosfet circuits circuit synthesis cmos process extrapolation silicon uncertainty accuracy;nmos;physical correlations;sleep mode;45 nm;semiconductor device modeling;subthreshold leakage current;predictive models;mosfet;si;si predictive technology model design exploration mosfet early circuit design research nanoscale cmos process variations physical correlations nmos pmos 45 nm 130 to 32 nm;physical model;silicon cmos integrated circuits integrated circuit design mosfet;early circuit design research;circuit synthesis;dual threshold voltage;domino logic	Predictive MOSFET model is critical for early circuit design research. To accurately predict the characteristics of nanoscale CMOS, emerging physical effects, such as process variations and physical correlations among model parameters, must be included. In addition, predictions across technology generations should be smooth to make continuous extrapolations. In this work, a new generation of Predictive Technology Model (PTM) is developed to accomplish these goals. Based on physical models and early stage silicon data, PTM of bulk CMOS for 130nm to 32nm technology nodes is successfully generated. By tuning ten parameters, PTM can be easily customized to cover a wide range of process uncertainties. The accuracy of PTM predictions is comprehensively verified: for NMOS, the error of Ion is 2% and for PMOS, it is 5%. Furthermore, the new PTM correctly captures process sensitivities in the nanometer regime. A webpage has been established for the release of PTM (http://www.eas.asu.edu/~ptm).	cmos;circuit design;nmos logic;pmos logic;polynomial texture mapping;web page	Wei Zhao;Yu Cao	2006	7th International Symposium on Quality Electronic Design (ISQED'06)	10.1109/ISQED.2006.91	embedded system;electronic engineering;real-time computing;computer science;engineering;electrical engineering;cmos;statistics	EDA	22.03675573879417	60.31910311134146	11136
4a3566da2ddd1472e4d15ab76288ccaf020ce605	automatic dantzig-wolfe reformulation of mixed integer programs	economie;article accepte pour publication ou publie;generation;regeneration sylviculture;90c11;matrix re ordering;colonne;65k05;reproduction;49m27;sciences de l information;economies et finances;hypergraph partitioning;programmes;block diagonal matrix;dantzig wolfe decomposition;automatic reformulation;column generation;sciences de l information et de la communication	Dantzig-Wolfe decomposition (or reformulation) is well-known to provide strong dual bounds for specially structured mixed integer programs (MIPs). However, the method is not implemented in any state-of-the-art MIP solver as it is considered to require structural problem knowledge and tailoring to this structure. We provide a computational proof-of-concept that the reformulation can be automated. That is, we perform a rigorous experimental study, which results in identifying a score to estimate the quality of a decomposition: after building a set of potentially good candidates, we exploit such a score to detect which decomposition might be useful for Dantzig-Wolfe reformulation of a MIP. We experiment with general instances from MIPLIB2003 and MIPLIB2010 for which a decomposition method would not be the first choice, and demonstrate that strong dual bounds can be obtained from the automatically reformulated model using column generation. Our findings support the idea that Dantzig-Wolfe reformulation may A preliminary version of this paper appeared in [3]. Martin Bergner was supported by the German Research Foundation (DFG) as part of the Priority Program “Algorithm Engineering” under grants no. LU770/4-1 and 4-2. Martin Bergner · Marco E. Lübbecke Operations Research, RWTH Aachen University, Kackertstraße 7, D-52072 Aachen, Germany, E-mail: {martin.bergner, marco.luebbecke}@rwth-aachen.de Alberto Ceselli Dipartimento di Informatica, Università degli Studi di Milano, Via Bramante 65, I-26013 Crema, Italy, E-mail: alberto.ceselli@unimi.it Fabio Furini LAMSADE, Université Paris-Dauphine, Place du Maréchal de Lattre de Tassigny, F-75775 Paris, France, E-mail: fabio.furini@dauphine.fr Enrico Malaguti DEI, Università di Bologna, Viale Risorgimento 2, I-40136 Bologna, Italy, E-mail: enrico.malaguti@unibo.it Emiliano Traversi LIPN, Équipe AOC, Université Paris 13, 99 Avenue Jean-Baptiste Clément, F-93430 Villetaneuse, France, E-mail: emiliano.traversi@lipn.univ-paris13.fr	age of empires ii: the conquerors;algorithm engineering;column generation;computation;dantzig–wolfe decomposition;enrico clementi;experiment;flajolet–martin algorithm;jean;linear programming;operations research;solver	Martin Bergner;Alberto Caprara;Alberto Ceselli;Fabio Furini;Marco E. Lübbecke;Enrico Malaguti;Emiliano Traversi	2015	Math. Program.	10.1007/s10107-014-0761-5	column generation;mathematical optimization;combinatorics;reproduction;generation;computer science;dantzig–wolfe decomposition;mathematics;block matrix;algorithm	Vision	23.703292322992453	10.422440838727521	11139
f9aeebbc04c7ae91b8eb6af828b40d4a5cedd6c3	smart card chip design implementation on arm processor-based fpga	health insurance card smart card chip design implementation arm processor based fpga my ms smart card chip prototype xilinx zynq 7000 xc7020 1 clg484 fpga device design implementation xilinx virtex 4 xc4vlx60 10ff668 smart card embedded operating system smart card embedded os national id;random access memory;xram smart card iso 7816 3 arm cortex a9 xc7z020 xc4vlx60 fpga os eeprom rom ram;prototypes;smart cards;eprom;field programmable gate arrays;smart cards chip scale packaging field programmable gate arrays random access memory prototypes operating systems eprom;chip scale packaging;operating systems;smart cards field programmable gate arrays instruction sets logic design operating systems computers	This paper describes about the design and implementation of My-MS smart card chip's prototype in Xilinx's Zynq-7000 XC7020-1-CLG484 FPGA device. The comparison between the design implementation in this device and in Xilinx's Virtex 4 XC4VLX60-10FF668 is explained in this paper in terms of area and time requirements. The paper explains also some of the basic functions of the smart card embedded operating system (OS), its simulation and implementation. The smart card chip design has been used as a national ID and health insurance card and is going to be incorporated in other applications cards.	arm architecture;embedded operating system;embedded system;field-programmable gate array;prototype;requirement;simulation;smart card;virtex (fpga)	Wira Firdaus Hj Yaakob;Hafizul Hasni Manab;Siti Noorashikin Md Adzmi	2014	2014 IEEE 3rd Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2014.7031183	multos;embedded system;java card;computer hardware;engineering;operating system;smart card application protocol data unit;card reader;open smart card development platform	EDA	6.630948333282764	48.758464372490586	11149
078b4a198dedd9445e5927fbbd9ef597738ab651	from reconfigurable architectures to self-adaptive autonomic systems	reconfiguration;software;inf;runtime adaptability;logic design;dynamic reconfiguration;system on chip logic design reconfigurable architectures;reconfigurable architectures;performance;soc reconfigurable architecture self adaptive system autonomic computing system system on chip;self adaptive system;autonomic computing system;system on a chip;autonomic system;computer architecture;reconfigurable architecture;codesign;system on chip;self adaptive systems performance reconfiguration codesign runtime adaptability;adaptive system;reconfigurable architectures hardware acceleration software performance costs computer architecture computer science artificial intelligence laboratories space exploration;soc;design space exploration;self adaptive systems;field programmable gate arrays;magnetic cores;article;autonomic computing;reconfigurable hardware;context;hardware	Systems on a Chip (SoC) can draw various benefits such as adaptability and efficient acceleration of computeintensive tasks from the inclusion of reconfigurable hardware as a system component. Dynamic reconfiguration capabilities of current reconfigurable devices create an additional dimension in the temporal domain. During the design space exploration phase, overheads associated with reconfiguration and hardware/software interfacing need to be evaluated carefully in order to harvest the full potential of dynamic reconfiguration. In order to overcome the limits deriving by the increasing complexity and the associated workload to maintain such complex infrastructure, one possibility is to adopt self-adaptive and autonomic computing systems [1]. A self-adaptive and autonomic computing system is a system able to configure, heal, optimize and protect itself without the need for human intervention.	autonomic computing;design space exploration;field-programmable gate array;operating system;peer-to-peer;reconfigurable computing;requirement;system on a chip;user requirements document	Marco D. Santambrogio	2009		10.1109/CSE.2009.490	system on a chip;embedded system;computer architecture;real-time computing;computer science;adaptive system;autonomic computing	EDA	2.428774604445436	54.0741832252915	11152
ff4a1688fc4a2758c0cd402125397cd55ccef624	software tool for fpga based mimo radar applications	sensors;vhdl direct data domain d3 fpga high level synthesis tools interference cancellation;computer architecture;graphical user interfaces;system on chip;field programmable gate arrays;signal processing algorithms;algorithm design and analysis;field programmable gate arrays signal processing algorithms sensors graphical user interfaces system on chip algorithm design and analysis computer architecture	Direct Data Domain (D3) algorithm is very useful in Space-Time Adaptive Processing (STAP) algorithms to mitigate the effects of multipath and interference. However, the computation of D3 is computationally intensive. A software tool is developed that is capable of auto-generating a fully optimized VHDL representation of D3 with many user input parameters without having to write a single line of VHDL code. It will provide feedback on various performance parameters such as occupied slices, maximum frequency, and dynamic range performance. So, the designer can focus on the overall SoC performance and make adjustments to the D3 as necessary. Many optimization techniques are used to improve throughput and latency.	algorithm;computation;data domain;dynamic range;field-programmable gate array;interference (communication);mimo;mathematical optimization;multipath propagation;programming tool;space-time adaptive processing;throughput;vhdl	Amin Jarrah;Mohsin M. Jamali	2013	2013 Asilomar Conference on Signals, Systems and Computers	10.1109/ACSSC.2013.6810610	embedded system;electronic engineering;real-time computing;computer science	EDA	30.339840103071136	58.01145502467411	11161
fd5b6b4d1a2daf004b3fa1d003fb6961e27489ff	optimization problems in 3d conformal radiation therapy				Q. Jackie Wu;Claudio H. Sibata;Jie Wang	1999			mathematical optimization;3d conformal radiation therapy;mathematics;optimization problem	Vision	28.89468363266791	5.519756692273325	11168
fb51eb5707274ddf061a11ecfbbd0ecfb5a5702b	two strongly polynomial cut cancelling algorithms for minimum cost network flow	graph theory;teoria grafo;complexite calcul;coupe graphe;reseau;theorie graphe;red;algorithme;objective function;algorithm;corte grafo;complejidad computacion;computational complexity;graph cut;polynomial algorithm;network flow;cout minimum;flot reseau;network;algoritmo	We present two new strongly polynomial algorithms for the minimum cost network flow problem (MCNF). They are dual algorithms based on cancelling positive augmenting cuts, which are the duals of negative augmenting cycles. The first cancels maximum mean cuts, which are cuts whose increase in the dual objective function per arc is maximum. The second, Dual Cancel and Tighten, employs a more tlexible cut selection rule that allows it to be more efficient. These algorithms are duals to the Minimum Mean Cycle Cancelling and (Primal) Cancel and Tighten algorithms of Goldberg and Tarjan. These algorithms do not use explicit scaling to achieve polynomiality.	algorithm;flow network;loss function;negative feedback;optimization problem;polynomial;selection rule;time complexity	Thomas R. Ervolina;S. Thomas McCormick	1993	Discrete Applied Mathematics	10.1016/0166-218X(93)90025-J	mathematical optimization;combinatorics;flow network;cut;graph theory;mathematics;computational complexity theory;algorithm	Theory	21.331467325272822	17.782515015643053	11177
15f237083076aa64071e5e71a7f7d708b4ae447d	guest column: a survey of quantum learning theory		This paper surveys quantum learning theory: the theoretical aspects of machine learning using quantum computers. We describe the main results known for three models of learning: exact learning from membership queries, and Probably Approximately Correct (PAC) and agnostic learning from classical or quantum examples.		Srinivasan Arunachalam;Ronald de Wolf	2017	SIGACT News	10.1145/3106700.3106710	theoretical computer science;combinatorics;computer science;algorithmic learning theory;sample exclusion dimension;probably approximately correct learning;machine learning;computational learning theory;quantum;quantum computer;learning theory;artificial intelligence;stability (learning theory)	Theory	9.934363364862053	19.58177729374636	11183
08e766b0a6dc05b9bb0151db0c5b0b46ea06ceb1	poster: spatio-temporal information correction mechanism for wild animal wearable sensors	environment monitoring;presumption;field survey	This paper presents a Spatio-Temporal Information Correction Mechanism for Wild Animal Wearable Sensors. It is difficult to acquire the positioning information with GPS sensors in forests region. Furthermore, electric power sources and mobile communication infrastructures are often limited, because the provision of such resources is expensive in the wild (e.g., near the ground surface of the forest) and tend to be in areas with limited number of users. In this research, we propose a method, which does not depend on the sensor and a mobile communication, for correcting the acquisition of the time and location information.	global positioning system;sensor;the forest;wearable technology	Yuya Kamma;Kaoru Sezaki;Hill Hiroki Kobayashi	2016		10.1145/2938559.2948794	simulation	Mobile	3.1249450467614164	30.04479556360776	11186
3d8505f122affdebcc5ee70cac498fb3c9669770	inter-instance nogood learning in constraint programming	domain restriction;current problem;constraint programming;magnitude speedup;new clausal;individual problem;powerful approach;inter-instance nogood;similar problem;lazy clause;current implementation	Lazy Clause Generation is a powerful approach to reducing search in Constraint Programming. This is achieved by recording sets of domain restrictions that previously led to failure as new clausal propagators called nogoods. This dramatically reduces the search and provides orders of magnitude speedups on a wide range of problems. Current implementations of Lazy Clause Generation only allows solvers to learn and utilize nogoods within an individual problem. This means that everything the solver learns will be forgotten as soon as the current problem is finished. In this paper, we show how Lazy Clause Generation can be extended so that nogoods learned from one problem can be retained and used to significantly speed up the solution of other, similar problems.	constraint programming;experiment;lazy evaluation;parameterized complexity;propagator;solver;speedup	Geoffrey Chu;Peter J. Stuckey	2012		10.1007/978-3-642-33558-7_19	mathematical optimization;theoretical computer science;machine learning;mathematics;algorithm	AI	1.1677866877730227	13.29500439353053	11192
5b44fd3f10b5c68e0042a9a303ae41da3f536973	energy efficient mapping on manycore with dynamic and partial reconfiguration: application to a smart camera			manycore processor;multi-core processor;smart camera	Robin Bonamy;Sébastien Bilavarn;Fabrice Muller;François Duhem;Sreedevi Koppula;Philippe Millet;Fabrice Lemonnier	2018	I. J. Circuit Theory and Applications	10.1002/cta.2508		EDA	3.9893963880066465	49.4069135317823	11225
863dbce3ba9f4e638bb0b434082d1e79051c9b36	beyond the horizon: the next 10x reduction in power - challenges and solutions	energy efficiency;next generation energy efficient electronics;electronic circuit;process variation;design automation;integrated regulator;cad tool;memory management;bit cell optimization;mobility channel material;highly digital architecture;digital correction;3d through silicon vias;order of magnitude reduction;rf transceiver;digital circuits analogue circuits;next generation energy efficient electronics energy efficiency electronic circuit wireless multimedia device inaugural plenary technology roundtable event order of magnitude reduction energy consumption analog circuit digital correction analog component variability process scaling process variation memory circuit bit cell optimization integrated regulator 3d through silicon vias process optimization rf transceiver highly digital architecture process technology innovation cad tool transistor structure mobility channel material low voltage digital circuit on chip interconnect integrated inductor;through silicon via;integrated inductor;system on a chip;process scaling;analog circuit;on chip interconnect;radio frequency;energy consumption;analog component variability;process optimization;inductors;process technology innovation;analogue circuits;wireless multimedia device;radio frequency design automation through silicon vias memory management system on a chip digital circuits inductors;digital circuits;inaugural plenary technology roundtable event;low voltage digital circuit;memory circuit;transistor structure;through silicon vias	Summary form only given. The energy efficiency of electronic circuits has dramatically improved over the past two decades. At the same time, computation, storage, and communication demands continue to grow with emerging wireless multimedia devices. In this inaugural Plenary Technology-Roundtable event, experts will discuss the opportunities to achieve the next order-of-magnitude reduction in energy consumption across various domains, including analog, digital, RF, and memory. The line between analog and digital continues to blur, as analog circuits are enhanced by applying digital corrections to compensate for increased analog component variability with process scaling. As well, digital will incorporate more analog to become more adaptive; for example, to optimize operating voltages at a fine-grain to match workloads and process variations. Memory circuits will need to use a system-level approach which requires bit-cell optimization, low-voltage operation with integrated regulators, 3D Through-Silicon Vias (TSV), and process optimization. RF transceivers will continue to trend toward highly-digital architectures. The role of process-technology innovation and CAD tools will also be discussed. Future process technology will deliver new transistor structures and higher-mobility channel materials for low-voltage digital circuits. TSVs will be important in reducing I/O power and the length of on-chip interconnects. For RF, integrated inductors and transformers with significantly lower resistance will be the challenge. Future CAD tools optimizing energy will focus on co-design of packaging, architecture, power sources, and antenna to provide the best system solution. Domain experts will challenge the distinguished panelists to suggest directions and help create a roadmap for next-generation energy-efficient electronics.		Jan M. Rabaey;Hugo De Man;Mark Horowitz;Takayasu Sakurai;Jack Sun;Daniel W. Dobberpuhl;Kiyoo Itoh;Philippe Magarshack;Asad A. Abidi;Hermann Eul	2011		10.1109/ISSCC.2011.5746206	system on a chip;embedded system;electronic circuit;electronic engineering;electronic design automation;telecommunications;analogue electronics;computer science;engineering;electrical engineering;process optimization;through-silicon via;efficient energy use;process variation;inductor;digital electronics;radio frequency;memory management	EDA	15.318180179563102	57.29590466315857	11228
bb29aa8953994f55b612d324619c7615a2e1e2d3	"""about polynomial-time """"unpredictable"""" generators"""		"""So-called \perfect"""" or \unpredictable"""" pseudorandom generators have been proposed recently by people from the area of cryptology. Many people got aware of them from an optimistic article in the New York Times (Gleick (1988)). These generators are usually based on nonlinear recurrences modulo some integer m. Under some (yet un-proven) complexity assumptions, it has been proven that no polynomial-time statistical test can distinguish a sequence of bits produced by such a generator from a sequence of truly random bits. In this paper, we give some theoretical background concerning this class of generators and we look at the practicality of using them for simulation applications. We examine in particular their ease of implementation, their eeciency, periodicity, the ease of jumping ahead in the sequence, the minimum size of modulus that should be used, etc."""	computational complexity theory;cryptography;modulo operation;modulus robot;nonlinear system;pseudorandom generator;pseudorandomness;quasiperiodicity;recurrence relation;simulation;the new york times;time complexity	Pierre L'Ecuyer;René Proulx	1989		10.1109/WSC.1989.718716		Crypto	39.92355122966992	42.69034351343415	11233
02dd9bdd18735d98311ab0eae8176d281d40accc	a note on clique-web facets for multicut polytopes	multicuts;no keywords;polyhedra;facets	In this note we provide a previously undiscovered necessary condition for the facet-defining property of clique-web inequalities for the multicut polytope. This condition imposes a minimum cardinality requirement on the node set of the clique, thus implying, in general, that clique-web inequalities associated with relatively small cliques are not facet-defining for multicut polytopes.		Michael Malmros Sørensen	2002	Math. Oper. Res.	10.1287/moor.27.4.740.301	combinatorics;discrete mathematics;topology;mathematics;polyhedron	Theory	32.433384410184075	27.866006848654976	11239
0b107057f37f562566eeca5f77429d5e76c7a8bf	divide and conquer: a new parallel algorithm for the solution of a tridiagonal linear system of equations	parallel algorithm;linear system of equations;right hand side;parallel computer;divide and conquer;cyclic reduction	We describe a divide and conquer algorithm which solves linear tridiagonal systems with one right-hand side, especially suited for parallel computers. The algorithm is very flexible, permits multiprocessing or a combination of vector and multiprocessor implementations, and is adaptable to a wide range of parallelism granularities. This algorithm can also be combined with recursive doubling, cyclic reduction or Wang's partition method, in order to increase the degree of parallelism and vectorizability.		Stefan Bondeli	1990		10.1007/3-540-53065-7_92	parallel computing;divide and conquer algorithms;computer science;akra–bazzi method;theoretical computer science;distributed computing	HPC	-2.5186105790809563	37.52538788501755	11261
3e6880033f6c50baba2174e34a6bcda36eead339	statistical analysis of timing rules for high-speed synchronous vlsi systems	device characteristics;concepcion asistida;eficacia sistema;computer aided design;caracteristique temporelle;integrated circuit;forme onde;clocks;very large scale integration;logic;simulacion numerica;performance systeme;circuit vlsi;circuito integrado;indexing terms;systeme numerique;system performance;statistical model;time curve;experimental result;statistical analysis very large scale integration pipeline processing timing jitter clocks throughput transmitters digital systems integrated circuit interconnections logic;synchronisation;integrated circuit design;digital system;vlsi circuit;timing rules;forma onda;gaussian distributed static skew;statistical analysis;high speed synchronous vlsi systems;threshold behavior;synchronization;timing skew;integrated circuit design statistical analysis timing high speed integrated circuits vlsi pipeline processing logic cad;integrated circuit interconnections;digital systems;simulation numerique;transmitters;random skew;modele statistique;resultado experimental;caracteristica temporal;static skew;vlsi;conception assistee;sistema numerico;maximum throughput;modelo estadistico;self timed vlsi systems;sincronizacion;waveform;gaussian distributed static skew statistical analysis timing rules high speed synchronous vlsi systems timing skew multiple pipelined stages device characteristics maximum throughput wave pipelining threshold behavior;synchronous vlsi systems;circuito vlsi;multiple pipelined stages;resultat experimental;logic cad;wave pipelining;timing jitter;high speed;high speed integrated circuits;gaussian distribution;random times;circuit integre;pipeline processing;throughput;numerical simulation;timing	Timing skew has been the major limitation for high-speed synchronous operation of a VLSI system. In this paper, a statistical timing model that accounts for both static and random timing skew is proposed. Based on this model, we analyze the timing rules of a synchronous VLSI system consisting of multiple pipelined stages, establish the yield of the system as a function of its device characteristics, and derive the relationship between the maximum throughput of such a system and its timing skew. The following timing schemes are evaluated: conventional pipelining, in which the transmitter cannot initiate the next cycle until the receiver has received the data and wave pipelining, in which the transmitter initiates the next cycle as soon as the current data has been sent out. The results show that the yield of a VLSI system using either of the pipelining schemes exhibits threshold behavior for Gaussian distributed static skew. Furthermore, the system throughput is shown to be very sensitive to the random skew.	very-large-scale integration	Chung-Sheng Li;Kumar N. Sivarajan;David G. Messerschmitt	1999	IEEE Trans. VLSI Syst.	10.1109/92.805754	computer simulation;embedded system;synchronization;electronic engineering;real-time computing;telecommunications;computer science;computer aided design;timing failure;computer performance;very-large-scale integration;static timing analysis;statistics	Embedded	26.369806001325838	56.23756079999531	11274
2a49faf31a48d48b55dfe0a8705a40349a19ec5b	high performance parallel computing in residue number system		Residue Number System (RNS) allows performing computation more efficiently. Natural parallelism of representation and processing of numbers makes this number system suitable for applying to high performance computing. We address the main features of application of RNS to high-performance parallel computing. We consider and analyze different stages of data processing in RNS. Based on this analysis, we describe the process of decomposition of algorithms using RNS	parallel computing;residue number system	Maxim Anatolievich Deryabin;Nikolay I. Chervyakov;Andrei Tchernykh;Mikhail G. Babenko;Maria Nikolaevna Shabalina	2018	IJCOPI		parallel computing;computation;residue number system;supercomputer;computer science	HPC	0.08777485954418011	39.03738469067946	11282
3e9a4cbd6a8d6b99a182c556206f086118f48d52	black hole search by mobile agents in hypercubes and related networks	cube connected cycles;black hole;star graph;distributed search;mobile agent;lower bound	Mobile agents operating in networked environments face threats from other agents as well as from the hosts (i.e., network sites) they visit. A black hole is a harmful host that destroys incoming agents without leaving any trace. To determine the location of such a harmful host is a dangerous but crucial task, called black hole search. The most important parameter for a solution strategy is the number of agents it requires (the size); the other parameter of interest is the total number of moves performed by the agents (the cost). Any solution requires moves in general networks; the same lower bound holds for rings. In this paper we show that this lower bound does not hold for hypercubes and related networks. In fact, we present a general strategy which allows two agents to locate the black hole with moves in hypercubes, cube-connected cycles, star graphs, wrapped butterflies, chordal rings, as well as in multidimensional meshes and tori of restricted diameter.	biconnected graph;black hole;cost efficiency;cube-connected cycles;interconnection;mobile agent;tree traversal	Stefan Dobrev;Paola Flocchini;Rastislav Kralovic;Giuseppe Prencipe;Peter Ruzicka;Nicola Santoro	2002			cube-connected cycles;black hole;combinatorics;star;computer science;mobile agent;distributed computing;upper and lower bounds	ECom	17.990177980640283	34.22575720891388	11291
544c565f09bf7527d5d69ea2ba9a85807978f3cf	rich, sturmian, and trapezoidal words	mot sturmien;palabra infinita;complexite;interconnection;comportement;mot infini;palabra finita;complejidad;discrete mathematics;mot fini;complexity;palindromic complexity;sturmian words;infinite word;interconexion;sturmian word;palindromes;terme;conducta;informatique theorique;interconnexion;characterization;rich words rich words;caracterisation;behavior;rich words;caracterizacion;finite word;trapezoidal words;computer theory;informatica teorica	In this paper we explore various interconnections between rich words, Sturmian words, and trapezoidal words. Rich words, first introduced by the se cond and third authors together with J. Justin and S. Widmer, constitute a new class of finite and in finite words characterized by having the maximal number of palindromic factors. Every finite Stur mian word is rich, but not conversely. Trapezoidal words were first introduced by the first author in studying the behavior of the subword complexity of finite Sturmian words. Unfortunately thi s property does not characterize finite Sturmian words. In this note we show that the only trapezoida l palindromes are Sturmian. More generally we show that Sturmian palindromes can be characte rized either in terms of their subword complexity (the trapezoidal property) or in terms of their p alindromic complexity. We also obtain a similar characterization of rich palindromes in terms of a r elation between palindromic complexity and subword complexity.	8b/10b encoding;conditional (computer programming);justin (robot);maximal set;microsoft word for mac;substring;trapezoidal rule	Aldo de Luca;Amy Glen;Luca Q. Zamboni	2008	Theor. Comput. Sci.	10.1016/j.tcs.2008.06.009	arithmetic;sturmian word;discrete mathematics;complexity;computer science;interconnection;mathematics;algorithm;algebra;behavior	Theory	1.0174321829022395	18.655426934882275	11292
696a0d5fcab3047010597b9b18a7603508c01ff6	new lower bounds for constant dimension codes	vectors network coding upper bound educational institutions measurement hamming distance;codes;pending blocks constant dimension codes constructive lower bounds ferrers diagram rank metric codes	This paper provides new constructive lower bounds for constant dimension codes, using Ferrers diagram rank metric codes and pending blocks. Constructions for two families of parameters of constant dimension codes are presented. The examples of codes obtained by these constructions are the largest known constant dimension codes for the given parameters.	code;diagram	Natalia Silberstein;Anna-Lena Horlemann-Trautmann	2013	2013 IEEE International Symposium on Information Theory	10.1109/ISIT.2013.6620279	block code;reed–muller code;concatenated error correction code;combinatorics;discrete mathematics;pure mathematics;linear code;hamming code;expander code;mathematics;forward error correction;error floor;code;statistics	Theory	40.07676275951523	54.64258807898265	11306
0cf6ae99deaf57a4ab4c2ab63961cc890e489698	sketching the order of events		"""We introduce features for massive data streams. These stream features can be thought of as""""ordered moments""""and generalize stream sketches from""""moments of order one""""to""""ordered moments of arbitrary order"""". In analogy to classic moments, they have theoretical guarantees such as universality that are important for learning algorithms."""	algorithm;machine learning;universality probability	Terry Lyons;Harald Oberhauser	2017	CoRR		combinatorics;mathematics;universality (philosophy);data stream mining;analogy	ML	2.123612495639347	22.66795634414147	11323
3e7687f20dec1148d1ee31e9951dbd5b94de47f7	uncore rpd: rapid design space exploration of the uncore via regression modeling		A regression-based design space exploration methodology is proposed that models the impacts of the memory hierarchy and the network-on-chip (NoC) on the overall chip multiprocessor (CMP) performance. Designers cannot explore all possible designs for a NoC without considering interactions with the rest of the uncore, in particular the cache configuration and memory hierarchy which determine the amount and pattern of the traffic on the NoC. The proposed regression model is able to capture the salient design points of the uncore for a comprehensive design space exploration by designing memory and NoC-specific regression models and leveraging recent advances in uncore simulation. To show the utility of our methodology, UncoreRPD, two case studies are presented: i) analyzing and refining regression models for an 8-core CMP and ii) performing a rapid design space exploration to find best performing designs of a NoC-based CMP given area-constraints for CMPs of up to 64 cores. Through these case studies, it is shown that i) simultaneous consideration of the memory and NoC parameters in the NoC design space exploration can refine uncore-based regression models, ii) sampling techniques must consider the dynamic design space of the uncore, and iii) overall, the proposed regression models reduce the amount of simulations required to characterize the NoC design space by up to four orders of magnitude.	design space exploration;interaction;memory hierarchy;multi-core processor;multiprocessing;network on a chip;sampling (signal processing);simulation;uncore	Karthik Sangaiah;Mark Hempstead;Baris Taskin	2015	2015 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)		embedded system;traceability;parallel computing;real-time computing;design methods;computer science;space exploration;operating system;mathematical model;authentication;predictive modelling;computational model;internet of things;statistics;memory management	EDA	1.500557747811614	56.518577332017415	11335
c8129920c2e1569da28996a323c153b225bc36df	one-way cellular automata on cayley graphs	cayley graph;cellular automata	The notion of one-dimensional one-way cellular automata has been introduced to model cellular automata with only a one-way communication between two neighbor cells. In this paper, we generalize this notion to cellular automata working on different communication graphs We present some sufficient conditions for a cellular automaton to be stimulated by a one-way cellular automaton having the same underlying graph, and we give some bounds on the simulation-time of this mimic.	cellular automaton;magma	Zsuzsanna Róka	1993		10.1007/3-540-57163-9_35	cellular automaton;computer science;cayley graph;mathematics;vertex-transitive graph;algorithm	Theory	36.38022957166292	27.288780233145737	11338
5647d19ebdd2eacb6877a193ffb22e1dff5bcf82	optimal management of plug-in electric vehicles in smart distribution systems		This paper investigates optimal operation management of plug-in electric vehicles (PEVs) in distribution systems. In this regard, the high penetration of electric vehicles (EVs) especially in the form of PEVs is another source of energy that can help the grid if optimally managed. In order to make the existence of PEVs to a suitable opportunity for the grid, vehicle-to-grid (V2G) technology is employed to change the PEVs from moving loads into moving sources. We also suggest a novel smart strategy to first manage the operation of PV and PEVs for providing the operator targets and second model the uncertainties generated by both PV and PEV in the system. The proposed method uses particle swarm optimization algorithm (PSO) along with the point estimate method (PEM) to deal with these issues. The 69-bus IEEE test system is employed as the case study to examine the high performance and ability of the proposed algorithm.	algorithm;mathematical optimization;particle swarm optimization;plug-in (computing)	Afsaneh Amiri;Sirus Mohammadi;Reza Khorram-Nia;Soroush Karimi-Khorami	2015	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-151572	simulation	Robotics	2.624649499701067	5.424169961660088	11340
3046a3f4e79b53e04fbe4c5c6e2773ca88967f7e	on the non-degeneracy property of the longest-edge trisection of triangles	iterative method;analisis numerico;trisection;matematicas aplicadas;methode element fini;triangle subdivision;metodo elemento finito;mathematiques appliquees;triangular mesh;mesh quality;finite element method;maillage;analyse numerique;metodo iterativo;empirical evidence;numerical analysis;triangle;celdarada;methode iterative;grid pattern;applied mathematics	The longest-edge (LE) trisection of a triangle t is obtained by joining the two equally spaced points of the longest-edge of t with the opposite vertex. In this paper we prove that for any given triangle t with smallest interior angle s > 0, if the minimum interior angle of the three triangles obtained by the LE-trisection of t into three new triangles is denoted by s1, then s1 P s=c1, where c1 1⁄4 p=3 arctanð ffiffi 3 p =5Þ 3:1403. Moreover, we show empirical evidence on the non-degeneracy property of the triangular meshes obtained by iterative application of the LE-trisection of triangles. If sn denotes the minimum angle of the triangles obtained after n iterative applications of the LE-trisection, then sn > s=c where c is a positive constant independent of n. An experimental estimate of c 6:7052025350 is provided. 2010 Elsevier Inc. All rights reserved.	degeneracy (graph theory);edge dominating set;iterative method;triangulated irregular network;vertex (graph theory)	Angel Plaza;Sergio Falcón;José P. Suárez	2010	Applied Mathematics and Computation	10.1016/j.amc.2010.01.093	combinatorics;empirical evidence;applied mathematics;numerical analysis;triangle mesh;finite element method;calculus;mathematics;geometry;iterative method;algebra	Theory	25.8743138770083	33.26149336636848	11343
315b96ef778a3ad94f2b5be51c2b497dfb7e0eab	tile-packing tomography is $\mathbb{np}$ -hard	discrete tomography;affine independence;mathbb np hardness	Discrete tomography deals with reconstructing finite spatial objects from their projections. The objects we study in this paper are called tilings or tile-packings, and they consist of a number of disjoint copies of a fixed tile, where a tile is defined as a connected set of grid points. A row projection specifies how many grid points are covered by tiles in a given row; column projections are defined analogously. For a fixed tile, is it possible to reconstruct its tilings from their projections in polynomial time? It is known that the answer to this question is affirmative if the tile is a bar (its width or height is 1), while for some other types of tiles $\mathbb {NP}$ -hardness results have been shown in the literature. In this paper we present a complete solution to this question by showing that the problem remains $\mathbb {NP}$ -hard for all tiles other than bars.	ct scan;discrete tomography;set packing;time complexity	Marek Chrobak;Christoph Dürr;Flavio Guiñez;Antoni Lozano;Nguyen Kim Thang	2011	Algorithmica	10.1007/s00453-011-9498-1	combinatorics;discrete mathematics;mathematics;geometry	Theory	32.679900440500404	21.62959917709483	11361
b1de0a42a98b388910bd7890b21ddeadc6afe3cb	an exact algorithm for the elementary shortest path problem with resource constraints: application to some vehicle routing problems	camino mas corto;shortest path;eje troncal;generation colonne;resource constraint;trajectoire optimale;routing;vehicle routing problem;exact solution;time window;routage;vehicle routing;plus court chemin;probleme tournee vehicule;solucion exacta;problema ruta vehiculo;camino optimo;reseau federateur;chemin optimal;optimal path;optimal trajectory;exact algorithm;trayectoria optima;fenetre temporelle;backbone;solution exacte;ventana temporal;contrainte ressource;column generation;shortest path problem;enrutamiento	In this paper, we propose a solution procedure for the Elementary Shortest Path Problem with Resource Constraints (ESPPRC). A relaxed version of this problem in which the path does not have to be elementary has been the backbone of a number of solution procedures based on column generation for several important problems, such as vehicle routing and crew-pairing. In many cases relaxing the restriction of an elementary path resulted in optimal solutions in a reasonable computation time. However, for a number of other problems, the elementary path restriction has too much impact on the solution to be relaxed or might even be necessary. We propose an exact solution procedure for the ESPPRC which extends the classical label correcting algorithm originally developed for the relaxed (non-elementary) path version of this problem. We present computational experiments of this algorithm for our specific problem and embedded in a column generation scheme for the classical Vehicle Routing Problem with Time Windows.	column generation;computation;duality gap;embedded system;exact algorithm;experiment;internet backbone;microsoft windows;shortest path problem;time complexity;unreachable memory;vehicle routing problem	Dominique Feillet;Pierre Dejax;Michel Gendreau;Cyrille Gueguen	2004	Networks	10.1002/net.20033	mathematical optimization;combinatorics;fast path;constrained shortest path first;longest path problem;computer science;vehicle routing problem;mathematics;shortest path problem;k shortest path routing;algorithm	AI	21.086063056887365	8.129906275720007	11368
e0245263e2983b953060ceae870458af55a8c90b	the impact of communication patterns on distributed self-adjusting binary search tree		This paper introduces the problem of communication pattern adaption for a distributed self-adjusting binary search tree. We propose a simple local algorithm that is closely related to the nearly thirty-yearold idea of splay trees and evaluate its adaption performance in the distributed scenario if different communication patterns are provided. To do so, the process of self-adjustment is modeled similarly to a basic network creation game in which the nodes want to communicate with only a certain subset of all nodes. We show that, in general, the game (i.e., the process of local adjustments) does not converge, and convergence is related to certain structures of the communication interests, which we call conflicts. We classify conflicts and show that for two communication scenarios in which convergence is guaranteed, the self-adjusting tree performs well. Furthermore, we investigate the different classes of conflicts separately and show that, for a certain class of conflicts, the performance of the tree network is asymptotically as good as the performance for converging instances. However, for the other conflict classes, a distributed self-adjusting binary search tree adapts poorly.	best, worst and average case;converge;focal (programming language);local algorithm;search tree;splay tree;time complexity;tree network;vergence	Thim Strothmann	2016	J. Graph Algorithms Appl.	10.7155/jgaa.00385	random binary tree;real-time computing;treap;theoretical computer science;order statistic tree;self-balancing binary search tree;k-d tree;distributed computing;ternary search tree;tree traversal;dichotomic search	Web+IR	18.298670666459707	35.57788115408318	11369
3fe71f601c76d5b0ccd332d9938e1a7c4ebed23b	stochastic single machine scheduling to minimize the weighted number of tardy jobs	number of tardy jobs;priority policy;random processing times;single machine;uniform distribution	A single machine stochastic scheduling problems with the jobs' processing times are considered the random of uniform distribution and the objective is to find an optimal schedule to minimize the expectation of the weighted numbers of tardy jobs from a common due date. By theoretical analysis, the problem formulation of the expectation of the weighted numbers of tardy jobs can be given. For the two cases (1) the weights of jobs are equal and (2) the weights of jobs are proportional to their processing times, the SEPT (shortest expected processing time first) is optimal. Joint use solution the SEPT and the LEPT (longest expected processing time first) is optimal in the case of the expected processing time is non-proportional to weighty of the jobs. The optimality of the algorithms is proved. © 2010 Springer-Verlag Berlin Heidelberg.	single-machine scheduling	Yang Li;Rongxi Chen	2010		10.1007/978-3-642-14880-4_38	mathematical optimization;scheduling (computing);single-machine scheduling;uniform distribution (continuous);mathematics	Theory	15.485625104194476	10.672250205014494	11383
90af0bba2a7155bedfc0dc89c99a9c19740307a8	minimum planar multi-sink cuts with connectivity priors		Given is a connected positively weighted undirected planar graph G embedded in the plane, a source vertex s, and a set of sink vertices T. An (s,T)-cut in G corresponds to a cycle or a collection of edge-disjoint cycles in the planar dual graph G * that define a planar region containing s but not T. A cut with a connectivity prior does not separate the vertices in T from each other: we focus on the most natural prior where the cut corresponds to a (simple, i.e., no repeated vertices) cycle in G *. We present an algorithm that finds a minimum simple (s,T)-cut in O(n 4) time for n vertices. To the best of our knowledge, this is the first polynomial-time algorithm for minimum cuts with connectivity priors. Such cuts have applications in computer vision and medical imaging.		Ivona Bezáková;Zachary Langley	2014		10.1007/978-3-662-44465-8_9	combinatorics;discrete mathematics;computer science;dual graph;prior probability;planar graph;vertex (geometry);sink (computing);planar	Vision	29.85664911788171	24.5486179390318	11386
8d66dfc6d816e1214ec25cc3ca743c70390d83c9	renovation of minimum spanning tree algorithms of weighted graph	generic algorithm;time complexity;complexity;algorithm;minimum spanning tree;weighted graph;cycle	In this paper we describe and explain the Minimum Spanning Tree (MST) generation algorithms of a weighted graph with renovated idea. Here, we used a new cycle testing algorithm for testing cycles, if required, in generation of Minimum Spanning Tree. The reason behind this is to optimize the execution time for cycle testing. Also, we describe some Minimum Spanning Tree algorithms for weighted graph with a renovated idea. We applied here new concept for explanation of minimum Spanning tree with better time complexity.	algorithm;file spanning;minimum spanning tree;run time (program lifecycle phase);time complexity	Sanjay Kumar Pal	2008	Ubiquity	10.1145/1353564.1353566	spqr tree;time complexity;edmonds' algorithm;euclidean minimum spanning tree;mathematical optimization;kruskal's algorithm;complexity;feedback arc set;genetic algorithm;minimum degree spanning tree;spanning tree;prim's algorithm;computer science;expected linear time mst algorithm;minimum spanning tree;gomory–hu tree;k-ary tree;connected dominating set;k-minimum spanning tree;reverse-delete algorithm;minimum spanning tree-based segmentation;distributed minimum spanning tree;cycle basis;algorithm;shortest-path tree;depth-first search	Theory	20.077438633646945	26.796726988377998	11390
67cdf8b2b8c5db37ec360d24116a5130dc233f7f	on 2-dimensional simple sets in n-dimensional cubic grids	cubical complexes;simple sets;digital topology;2 dimensional;topological properties;n dimensional spaces;higher dimensions;image analysis;topology preservation;thinning	Preserving topological properties of objects during reduction procedures is an important issue in the field of discrete image analysis. Such procedures are generally based on the notion of simple point, the exclusive use of which may result in the appearance of “topological artifacts.” This limitation leads to consider a more general category of objects, the simple sets, which also enable topology-preserving image reduction. A study of two-dimensional simple sets in two-dimensional spaces has been proposed recently. This article is devoted to the study of two-dimensional simple sets in spaces of higher dimension (i.e., n-dimensional spaces, n ≥ 3). In particular, several properties of minimal simple sets (i.e., which do not strictly include any other simple sets) are proposed, leading to a characterisation theorem. It is also proved that the removal of a two-dimensional simple set from an object can be performed by only considering the minimal ones, thus authorising the development of efficient thinning algorithms.	algorithm;cubic function;image analysis;simple set;thinning	Loïc Mazo;Nicolas Passat	2010	Discrete & Computational Geometry	10.1007/s00454-009-9195-x	category of topological spaces;combinatorics;two-dimensional space;discrete mathematics;image analysis;dimension theory;topology;topological tensor product;mathematics;geometry;topological space;separated sets;digital topology	Theory	40.72839284452172	22.63350391581063	11391
e46c983338d83ff7a4aba125f254bce9f3674cb2	ergodic learning automata capable of incorporating a priori information	automata a estructura variable;probabilistic automaton;time varying automaton;ergodicite;learning;routing;automatic testing;biological system modeling;learning automata;telephony;automate a structure variable;stochastic system;aprendizaje;apprentissage;machine learning;stochastic processes;automate probabiliste;pattern recognition;ergodicidad;councils;system testing;a priori information;ergodicity;automata probabilistico;sistema estocastico;learning automata biological system modeling machine learning pattern recognition automatic testing system testing telephony routing stochastic processes councils;information a priori;systeme stochastique	Learning automata are considered which update their action probabilities on the basis of the responses they get from a random environment. The automata update the probabilities whether the environment responds with a reward or a penalty. Learning automata are said to be ergodic if the distribution of the limiting action probability vector is independent of the initial distribution. An ergodic scheme is presented which can take into consideration a priori information about the action probabilities. This is the only reported scheme in the literature capable of achieving this. The mean and the variance of the limiting distribution of the automaton is derived, and it is shown that the mean is not independent of the a priori information. Further, it is shown that the expressions for the foregoing quantities are general cases of the corresponding quantities derived for the familiar LRP scheme. Finally, it is shown that by constantly updating the parameter quantifying the a priori information, a resultant linear scheme can be obtained. This scheme is of a reward-reward flavor and yet is absolutely expedient. It falls within the class of absolutely expedient schemes presented by Aso and Kimura.	automaton;ergodic theory;ergodicity;gary kimura;knuth reward check;learning automata;resultant;scheme	B. John Oommen	1987	IEEE Transactions on Systems, Man, and Cybernetics	10.1109/TSMC.1987.289367	stochastic process;mathematical optimization;routing;ergodicity;computer science;artificial intelligence;theoretical computer science;probabilistic automaton;machine learning;mathematics;telephony;system testing;algorithm;statistics	Theory	40.71722404703166	10.920587686063419	11402
4af06c7db774294fd02aaf211fcedd6a400c84ce	a fast algorithm to find optimal double-loop networks	directed graphs;minimization;l shaped tile;complexity theory;optimal double loop networks;integral equations;double loop network;double loop digraph;running time complexity;tiles computational intelligence computer security computer science computer architecture local area networks bibliographies;diameter;algorithm;running time complexity fast algorithm optimal double loop networks local area networks double loop digraph;computational complexity;fast algorithm;mathematical model;tiles;tight optimal;algorithm design and analysis;local area networks;algorithm diameter double loop network tight optimal l shaped tile;local area networks computational complexity directed graphs	Double-loop networks have been widely studied as architecture for local area networks. A double-loop digraph G(N; s<sub>1</sub>, s<sub>2</sub>) has N vertices 0, 1,..., N-l and 2N edges of two types: s<sub>1</sub>-edge: i¿1 + s (mod N); i=0, 1,..., N-l, and s<sub>2</sub>-edge: i¿ s + s<sub>2</sub> (modN); i=0, 1,..., N-l, for some fixed steps 1¿ s<sub>1</sub><s<sub>2</sub><N with gcd(N; s<sub>1</sub>, s<sub>2</sub>) = 1. Let D(N; s<sub>1</sub>, s<sub>2</sub>) be the diameter of G and let us define D(N) = min{ D(N; s<sub>1</sub>, s<sub>2</sub>) | 1¿s<sub>1</sub><s<sub>2</sub><N and gcd(N; s<sub>1</sub>, s<sub>2</sub>) = 1} and D(N) = min{D(N; 1, s)| 1<s<N}. Given a fixed number of vertices N, the general problem is to find steps s<sub>1</sub> and s<sub>2</sub>, such that the digraph G(N; s<sub>1</sub>, s<sub>2</sub>) has minimum diameter D(N). A lower bound of this diameter is known to be lb(N)= [¿(3N)]-2. In this work, we give a simple and efficient algorithmic solution of the problem by using a geometrical approach. Given n, the algorithm has outputs s<sub>1</sub>, s<sub>2</sub> and the minimum integer k=k(N), such that D(N; s<sub>1</sub>, s<sub>2</sub> )=D(N)=lb(N)+k. The running time complexity of the algorithm is 0(k<sup>2</sup> )0(N<sup>1/4</sup> logN). Also, some flaws in the bibliography are corrected.	algorithm;diameter (protocol);directed graph;maxima and minima;time complexity;vertex (geometry)	Xiaolin Wang;Zhenxu Bian;Pengfei Wang;Jianqin Zhou	2008	2008 International Conference on Computational Intelligence and Security	10.1109/CIS.2008.217	local area network;algorithm design;mathematical optimization;combinatorics;discrete mathematics;directed graph;computer science;diameter;mathematical model;mathematics;computational complexity theory;integral equation;algorithm	Theory	15.759861459738342	32.60815555134109	11410
fb5fa1987936494489622f8ddf22c08dc1371ecc	general bounding mechanism for constraint programs	automatic bounding;constraint programming;knapsack constraint;regular constraint;lagrangian decomposition	Integer programming (IP) is one of the most successful approaches for combinatorial optimization problems. Many IP solvers make use of the linear relaxation, which removes the integrality requirement on the variables. The relaxed problem can then be solved using linear programming (LP), a very e cient optimization paradigm. Constraint programming (CP) can solve a much wider variety of problems, since it does not require the problem to be expressed in terms of linear equations. The cost of this versatility is that in CP there is no easy way to automatically derive a good bound on the objective. This paper presents an approach based on ideas from Lagrangian decomposition (LD) that establishes a general bounding scheme for any CP. We provide an implementation for optimization problems that can be formulated with knapsack and regular constraints, and we give comparisons with pure CP approaches. Our results clearly demonstrate the benefits of our approach on these problems.	algorithm;cardinality (data modeling);combinatorial optimization;constraint programming;integer programming;knapsack problem;lagrange multiplier;linear equation;linear programming relaxation;mathematical optimization;polynomial;programming paradigm;regular expression;subderivative;subgradient method;time complexity	Minh Hoàng Hà;Claude-Guy Quimper;Louis-Martin Rousseau	2015		10.1007/978-3-319-23219-5_12	constraint logic programming;concurrent constraint logic programming;mathematical optimization;constraint programming;combinatorics;discrete mathematics;binary constraint;constraint satisfaction;computer science;mathematics;programming language;algorithm	AI	24.253983673846538	11.06881714251861	11423
62f677a4babf3c5fdfbbd9c0dd1c297b66e4eddb	the boolean quadric polytope: some characteristics, facets and relatives	quadratic program;polyhedral combinatorics;quadratic form;series parallel graph;extreme point;linear programming relaxation;point of view;series parallel	"""We study unconstrained quadratic zero-one programming problems having n variables from a polyhedral point of view by considering the Boolean quadric polytope QP"""" in n(n+l)/2 dimensions that results from the linearization of the quadratic form. We show that Qpn has a diameter of one, descriptively identify three families of facets of Qpn and show that Qpn is symmetric in the sense that all facets of QPn can be obtained from those that contain the origin by way of a mapping. The naive linear programming relaxation QP]'p of QP"""" is shown to possess the Trubin-property and its extreme points are shown to be {0, 1⁄2, l}-valued. Furthermore, O(n 3) facet-defining inequalities of QP"""" suffice to cut off all fractional vertices of QP~_p, whereas the family of facets described by us has at least 0(3"""") members. The problem is also studied for sparse quadratic forms (i.e. when several or many coefficients are zero) and conditions are given for the previous results to carry over to this case, Polynomially solvable problem instances are discussed and it is shown that the known polynomiality result for the maximization of nonnegative quadratic forms can be obtained by simply rounding the solution to the linear programming relaxation. In the case that the graph induced by the nonzero coefficients of the quadratic form is series-parallel, a complete linear description of the associated Boolean quadric polytope is given. The relationship of the Boolean quadric polytope associated to sparse quadratic forms with the vertex-packing polytope is discussed as well."""	boolean algebra;coefficient;decision problem;expectation–maximization algorithm;independent set (graph theory);linear programming relaxation;polyhedron;rounding;series-parallel graph;set packing;sparse matrix	Manfred W. Padberg	1989	Math. Program.	10.1007/BF01589101	extreme point;mathematical optimization;combinatorics;series and parallel circuits;discrete mathematics;quadratic form;polyhedral combinatorics;linear programming relaxation;mathematics;quadratic programming	Theory	36.811362914219096	25.543206911963367	11434
e6a272572686083be95ffa02a9e5213d30ac6a32	economic analysis of battery energy storage system	power system operators economic analysis grid connected battery energy storage systems transient dynamics power grid;prediction algorithms;batteries;production;discharges electric;economics;wind energy batteries cost benefit analysis energy conversion energy management economics load management renewable energy sources software algorithm;algorithm design and analysis;transients energy storage load management power grids power system economics;batteries economics algorithm design and analysis prediction algorithms discharges electric energy storage	Grid-connected battery energy storage systems (BESS) are essential for improving the transient dynamics of the power grid. There is ongoing research about how BESS integration with renewable energy sources can improve renewable energy deployment in the grid. However, the economic feasibility of BESS is a practical limitation of their integration into power systems. BESS costs include both the start-up costs of building the system and the operating costs. Optimizing the operation of the BESS to maximize operating profit would make the BESS more economically feasible to power system operators, and lead to smoother integration of BESS. This manuscript overviews a program tool that analyses grid connected BESS in real world situations and optimizes the operation of the battery system. Through the use of this tool, a better understanding of the economic feasibility of BESS is achieved.	computer data storage;ibm power systems;mathematical optimization;optimizing compiler;programming tool;simulation;software deployment;sysop	William B. Ray;Anitha Sarah Subburaj;James A. Schrock;Stephen B. Bayne	2015	2015 IEEE Industry Applications Society Annual Meeting	10.1109/IAS.2015.7356781	simulation;engineering;electrical engineering;operations management;intermittent energy source	Embedded	3.626069208153261	6.889482432591209	11441
4a888be89e2d2118b4b4d659e909a8917c300aa8	energy on demand: efficient and versatile energy control system for home energy management	smart apartment room energy on demand energy control system home energy management i energy energy management scheme e power flows decentralized energy generation devices decentralized energy storage devices demand based power supply control best effort power distribution appliance priorities ceiling control power consumption energy consumption utility companies eod systems smart demand response systems power request demands quality of energy appliance priority descriptions demand mediation algorithm;demand response;protocols;demand response energy informationization energy on demand quality of energy priority based power control;resource manager;resource management;energy management systems;home appliances;energy informationization;best effort;power distribution;power supply;control system;servers;mediation;energy consumption;energy on demand;power flow;power consumption;priority based power control;power demand;quality of energy;power control energy management systems power consumption;control method;everyday life;home appliances servers power demand mediation resource management protocols;energy management;power control	We have been proposing the concept of “i-Energy” as a new energy management scheme to realize efficient and versatile control of e-power flows among decentralized energy generation/storage devices and appliances in homes, offices, and neighboring communities. The i-Energy concept is best characterized by a novel energy control method named “Energy on Demand (EoD).” The novelties of EoD rest in (1) the explicit demand-based power supply control, (2) the best-effort power distribution based on appliance priorities, and (3) the ceiling control of power consumption. With EoD, people can attain the guaranteed reduction of energy consumption without damaging their quality of lives. Moreover, when utility companies are allowed to set and modify ceiling values based on contracts with consumers, EoD systems work as smart demand response systems. This paper first describes the protocol for EoD: power request demands named “Quality of Energy (QoEn)” and appliance priority descriptions. Then, the demand mediation algorithm based on appliance priorities for a single power source is introduced. Experiments using real world everyday-life data in a smart apartment room demonstrated the effectiveness of EoD.	algorithm;best-effort delivery;control system;power supply;software appliance	Takekazu Kato;Kenji Yuasa;Takashi Matsuyama	2011	2011 IEEE International Conference on Smart Grid Communications (SmartGridComm)	10.1109/SmartGridComm.2011.6102354	real-time computing;operations management;microeconomics;business	EDA	0.7688043496014294	5.046013080329074	11446
0206862a0d84dd33e05bac2dbd198e5caefeb1a2	technical note - a scheduling problem involving sequence dependent changeover times	scheduling problem	This note discusses a problem of scheduling jobs on a machine using various machine tools in which considerable changing of the tools is necessary, and the changeover time depends critically on the previous jobs. It derives a branch-and-bound algorithm, which has been shown to be computationally restrictive at the present time. Various heuristic methods have been tried and the computational results are very promising.	scheduling (computing)	A. G. Lockett;A. P. Muhlemann	1972	Operations Research	10.1287/opre.20.4.895	fair-share scheduling;job shop scheduling;mathematical optimization;real-time computing;dynamic priority scheduling;computer science;operations management;mathematics;multiprocessor scheduling	DB	15.577424908862268	8.367013912440301	11447
5622431c2d18c6e338ffdc01a478b1116bd444e8	fast doa estimation based on a split subspace decomposition on the array covariance matrix	split decomposition;real valued root multiple signal classification rv root music;array covariance matrix acm;direction of arrival doa estimation	A novel real-valued root multiple signal classification (RV-root-MUSIC) algorithm for estimating the direction-of-arrival (DOA) of multiple narrow-band signals is presented. Compared with the conventional root-MUSIC with a complex subspace decomposition on the entire array covariance matrix (ACM), RV-root-MUSIC exploited a split subspace decomposition on either the real-part of ACM (R-ACM) or the imaginary-part of ACM (I-ACM) with real-valued computations. Unlike the unitary root-MUSIC (U-root-MUSIC) with exploitations on the centro-Hermitian property of ACM, the proposed method developed a new result showing that R-ACM shares the same null subspace with I-ACM, which collides with the intersection of the original noise subspace and its conjugate one. Thanks to the real coefficients, the roots of RV-root-MUSIC appear in conjugate pairs, which allows fast rooting with only real-valued computations. Therefore, both subspace decomposition and polynomial rooting can be implemented with real-valued computations, which hence results in a significant reduction in computational cost as compared to root-MUSIC and U-root-MUSIC. Simulations are conducted to verify the effectiveness of the new technique.	direction of arrival;fast fourier transform	Fenggang Yan;Yi Shen;Ming Jin	2015	Signal Processing	10.1016/j.sigpro.2015.03.008	mathematical optimization;speech recognition;mathematics;statistics	Robotics	51.73005223105956	7.596323265866346	11450
0e55d5981d7a5899e093edb852b5fc4a008441c9	partitioning and ordering of cmos circuits for switch level analysis	cmos transistor networks;switch graphs;graph method;relacion orden;metodo descomposicion;methode decomposition;partitioning;ordering;circuito logico;tecnologia mos complementario;methode graphe;decomposition method;relation ordre;particion;circuit logique;partition;metodo grafico;symbolic analysis;partage;technologie mos complementaire;logic circuit;complementary mos technology;switch level analysis	This paper defines various component types of CMOS circuits that can be determined efficiently. By a proper decomposition of a circuit into its components switch level simulators or symbolic analysers are sped up substantially. Moreover, with the decomposition strategy proposed here a symbolic analysis of certain CMOS structures containing path transistors becomes possible at all. The key step in the partitioning strategy is to divide the set of transistors of a circuit into pass and driver transistors; these transistors are then grouped together to form pass and driver components. The partitioning can be done by efficient graph algorithms based on depth-first search strategies. In some cases a purely combinatorial output function can be computed, even in the presence of feedback. Feedback cycles and the remaining components which are not part of any feedback cycle can be recognised and grouped in linear time. On these groups a topological ordering can be defined which then can be used to schedule a switch level simulation or a symbolic analysis.	cmos	Michael Payer	1991	Integration	10.1016/S0167-9260(06)80011-8	partition;electronic engineering;decomposition method;logic gate;order theory;computer science;electrical engineering;symbolic data analysis;algorithm	EDA	17.610298861273634	49.516949404378096	11455
b257a21f252cc7026cec8a432da45bc3ebcd68a7	the tms32oc4o and it's application development environment: a dsp for parallel processing	parallel processing;application development		digital signal processor;parallel processing (dsp implementation)	Ray Simar	1991			parallel computing;digital signal processing;development environment;computer science;parallel processing	Robotics	3.857387123839344	47.74727156762882	11457
6a15c315161b4529ad7aaa30cd44b985f13febfc	the 2-page crossing number of kn	crossing number;complete graph;topological drawing	Around 1958, Hill conjectured that the crossing number CRg(K<sub>n</sub>) of the complete graph KK<sub>n</sub> is Z(n):=1/4 ⌊ n/2 ⌋ ⌊(n-1)/2⌋ ⌊ (n-2)/2 ⌋ ⌊ (n-3)/2 ⌋ and provided drawings of K<sub>n</sub> with exactly Z(n) crossings. Towards the end of the century, substantially different drawings of K<sub>n</sub> with Z(n) crossings were found. These drawings are <i>2-page book drawings</i>, that is, drawings where all the vertices are on a line l (the spine) and each edge is fully contained in one of the two half-planes (pages) defined by l. The <i>2-page crossing number</i> of K<sub>n</sub>, denoted by ν<sub>2</sub>(K<sub>n</sub>), is the minimum number of crossings determined by a 2-page book drawing of K<sub>n</sub>. Since CRG(K<sub>n</sub>) ≤ ν<sub>2</sub>(K<sub>n</sub>) and ν<sub>2</sub>(K<sub>n</sub>) ≤ Z(n), a natural step towards Hill's Conjecture is the weaker conjecture ν<sub>2</sub>(K<sub>n</sub>) = Z(n), that was popularized by Vrt'o. In this paper we develop a novel and innovative technique to investigate crossings in drawings of K<sub>n</sub>, and use it to prove that ν<sub>2</sub>(K<sub>n</sub>) = Z(n). To this end, we extend the inherent geometric definition of k-edges for finite sets of points in the plane to topological drawings of K<sub>n</sub>. We also introduce the concept of ≤≤k-edges as a useful generalization of ≤k-edges. Finally, we extend a powerful theorem that expresses the number of crossings in a rectilinear drawing of K<sub>n</sub> in terms of its number of k-edges to the topological setting.	crossing number (graph theory);regular grid	Bernardo M. Ábrego;Oswin Aichholzer;Silvia Fernández-Merchant;Pedro Ramos;Gelasio Salazar	2012		10.1145/2261250.2261310	arithmetic;combinatorics;mathematics;geometry;crossing number;complete graph	Theory	31.696304102884863	23.004596449511318	11477
807d9dca70686ae6c5f8df30c8c08534c41e7ac7	linear-time heuristics for minimum weight rectangulation	extended abstract;minimum weight rectangulation;linear-time heuristics;linear time	 We consider the problem of partitioning rectilinear polygons into rectangles, using segments of minimum total length. This problem is NP-hard for polygons with holes. Even for hole-free polygons no known algorithm can nd an optimal partitioning in less than O(n 4 ) time. We present the first linear-time algorithm for computing rectangulations of hole-free polygons, within a constant factor of the optimum. We achieve this result by deriving a linear-time algorithm for producing rectangulations... 	heuristic (computer science);minimum weight;time complexity	Christos Levcopoulos;Anna Pagh	1996		10.1007/3-540-61422-2_138	time complexity;combinatorics;computer science;minimum weight;polygon;heuristics	AI	29.278780743936487	19.10173240883525	11479
9eb5010bb7ce276e8b3fc5242c173f33368b2141	two queries	hemaspaandra and hempel to show that if p p then . we also give a relativized world where pnp pnp but np conp.;locally either np conp or np has polynomial-size circuits. p np p np . . up np rpnp . ph bpp np . moreover we extend work of hemaspaandra	We consider the question whether two queries to SAT are as powerful as one query. We show that if PNP[1℄ = PNP[2℄ then Locally eitherNP= coNPor NP has polynomial-size circuits. PNP = PNP[1℄. p2 p2=1. p2 = UPNP[1℄ \ RPNP[1℄. PH = BPPNP[1℄. Moreover we extend work of Hemaspaandra, Hemaspaandra and H empel to show that if P p2 [1℄ = P p2 [2℄ then p2 = p2. We also give a relativized world where PNP[1℄ = PNP[2℄ but NP 6= coNP.	co-np;legacy plug and play;oracle machine;polynomial;query language	Harry Buhrman;Lance Fortnow	1999	J. Comput. Syst. Sci.	10.1006/jcss.1999.1647	discrete mathematics;theoretical computer science;mathematics;algorithm	Theory	7.522412940782813	20.812656048589503	11497
268ffadc5395db150616ac307019bfd9bfdb5791	ffts on mesh connected computers	distributed memory;divide and conquer strategy;shared memory;difference operator;fast fourier transform;distributed memory multiprocessors;indexation;point of view;mesh connected computers;divide and conquer	"""The most eeective use of mesh connected computers is achieved by paying careful attention to the organization of the storage and movement of data. For an important class of algorithms the formalization of the different operations they perform lead to an uniied treatment for them and may result in important simpliications. In this work we apply this point of view to the Fast Fourier Transform (FFT). In particular, we present a uniied view of a set of FFT algorithms on mesh connected computers with non{shared memory. To this end we use a combination of two techniques, \mapping vector"""" and index{digit permutations, which allow us to deene the organization of the storage and movement of data for any FFT algorithm whose radix is a power of 2. The methodology we have employed is general and can be applied to other algorithms obtained through the divide and conquer strategy."""	algorithm;computer;fast fourier transform;power of two	Francisco Argüello;Margarita Amor;Emilio L. Zapata	1996	Parallel Computing	10.1016/0167-8191(95)00062-3	shared memory;fast fourier transform;parallel computing;divide and conquer algorithms;distributed memory;computer science;theoretical computer science;operating system;distributed computing	Theory	-0.32652799119105197	35.945046924733134	11507
34e4349b37afc37d4c9fc490723264571e11a17b	something about all or nothing (transforms)	data structure;information theory;discrete geometry;short note;simple construction	In this short note, we study all-or-nothing transforms, which were recently proposed by Rivest as a mode of operation for block ciphers. We study transforms of this type that provide unconditional security. A simple construction for linear transforms is given, and some existence and non-existence results for general transforms are derived from a combinatorial characterization of these objects.	block cipher mode of operation;pdf/a	Douglas R. Stinson	2001	Des. Codes Cryptography		mathematical analysis;discrete mathematics;mathematics;linear map;algebra	Crypto	43.57756939873427	41.375050240839435	11509
e4b7c043cf9c1a55ae028243793bba433358062e	on the generation of sentences with their parses by propagating regular-controlled grammars	generation of sentences with their parses;context free grammars;formal languages;regular controlled derivations	The present paper explains how to transform any regular-controlled (context-free) grammar with appearance checking G to a propagating regular-controlled (context-free) grammar with appearance checking G whose language L(G) has sentences of the form wρ, where w ∈ L(G) and ρ is a parse of w in G. Consequently, for every recursively enumerable language K , there exists a propagating regular-controlled grammar with appearance checking G with L(G) of the above form so that K results from L(G) by erasing all rules in L(G). In addition, analogical results are established (a) in terms of these grammars without appearance checking and (b) in terms of these grammars that make only leftmost derivations. In the conclusion, we point out some consequences implied by the results achieved in this paper. © 2013 Elsevier B.V. All rights reserved.	context-free grammar;context-free language;controlled grammar;emoticon;parsing;recursion;recursively enumerable language	Alexander Meduna;Petr Zemek	2013	Theor. Comput. Sci.	10.1016/j.tcs.2012.12.040	natural language processing;formal language;computer science;mathematics;context-free grammar;programming language;algorithm	AI	-4.432266309480673	15.014595134299697	11513
95522cfb36e4139cedf1fe6ad3739a4854c96118	upper bounds for number of removed edges in the erased configuration model		Models for generating simple graphs are important in the study of real-world complex networks. A well established example of such a model is the erased configuration model, where each node receives a number of half-edges that are connected to half-edges of other nodes at random, and then self-loops are removed and multiple edges are concatenated to make the graph simple. Although asymptotic results for many properties of this model, such as the limiting degree distribution, are known, the exact speed of convergence in terms of the graph sizes remains an open question. We provide a first answer by analyzing the size dependence of the average number of removed edges in the erased configuration model. By combining known upper bounds with a Tauberian Theorem we obtain upper bounds for the number of removed edges, in terms of the size of the graph. Remarkably, when the degree distribution follows a power-law, we observe three scaling regimes, depending on the power law exponent. Our results provide a strong theoretical basis for evaluating finite-size effects in networks.	complex network;concatenation;degree distribution;image scaling;multiple edges;rate of convergence	Pim van der Hoorn;Nelly Litvak	2015		10.1007/978-3-319-26784-5_5	combinatorics;discrete mathematics;multiple edges;degree;mathematics;strength of a graph	Metrics	31.583960472465524	26.62895281404983	11522
90e5b8029777a298e03828878c108522df5ad201	progressive sharing of modules among product variants	mass customization;variety;search space;mass production;simulated annealing;common platform;basic platform;layout design;product family;optimal design;modularity;standardization	Recent market transition from mass production to mass customization forces manufacturers to design products that meet individual requirements. In order to address the high cost of this practice, manufacturers develop product families with a common platform, whose variants are designed to meet different customer demands. Parallel to this transition, the dynamics of the market forces designers to develop products composed of modules that are standardized as much as possible across products, thus can be more resilient than complete designs in a changing world. Starting from an original set of different components, our method designs a modular common platform and additional modules, shared by subsets of the designs, from which variants are composed. We applied the method to the layout design of a set of products. Consequently, the geometric aspect of the product family optimization is emphasized, but functional aspects related to the product features and to customer needs are also addressed due to their manifestation in the layout. The design search space is explored using shape grammar rules that alter component geometry and therefore, functionality. The search for optimal design is performed using simulated annealing. Given different objective formulations or parameter settings, the method can be used to explore the solution space. A simple example problem demonstrates the feasibility of the method. q 2003 Elsevier Science Ltd. All rights reserved.	algorithm;common platform;dos;feasible region;graphical user interface;iteration;loss function;mathematical optimization;maximal set;optimal design;optimization problem;requirement;simulated annealing	Gabriel Dobrescu;Yoram Reich	2003	Computer-Aided Design	10.1016/S0010-4485(02)00104-5	page layout;mass production;simulated annealing;mass customization;computer science;systems engineering;engineering;optimal design;modularity;mathematics;variety;engineering drawing;standardization;mechanical engineering	EDA	11.999456605386653	13.10554665363828	11528
255b3243f57b01632a68cfcfbdac4931389c6c84	resource-efficient implementation of blue midnight wish-256 hash function on xilinx fpga platform	random access memory;resource efficient implementation;nist;blue midnight wish compression function;bmw 256;blue midnight wish compression function resource efficient implementation hash function xilinx fpga platform;sha 2;xilinx fpga platform;fpga implementation;conference object;peer reviewed;efficient implementation;blue midnight wish;bmw 256 hash function standard sha 2 blue midnight wish;registers;cryptography;field programmable gate arrays cryptography registers random access memory throughput nist hardware;field programmable gate arrays cryptography;hash function standard;hash function;field programmable gate arrays;throughput;hardware	This paper presents the design and analysis of an area efficient Blue Midnight Wish compression function with digest size of 256 bits (BMW-256) on FPGA platforms. The proposed architecture achieves significant improvements in system throughput with reduced area. We demonstrate the performance of the proposed BMW hash function core using VIRTEX 5 FPGA implementation. The new BMW hash function design allows for 16X speed up in performance while consuming significantly lower area than previously reported (i.e. just 445 slices).	32-bit;application-specific integrated circuit;arithmetic logic unit;barrel shifter;cryptographic hash function;field-programmable gate array;midnight commander;one-way compression function;throughput;virtex (fpga)	Mohamed El-Hadedy;Martin Margala;Danilo Gligoroski;Svein J. Knapskog	2010	2010 Sixth International Conference on Information Assurance and Security	10.1109/ISIAS.2010.5604066	embedded system;real-time computing;computer hardware;engineering	EDA	9.38568625468655	45.17804579012522	11551
128b586559f50835f17403a473efafa7689f809b	a reconfigurable architecture for image processing and computer vision	reconfiguration;tratamiento paralelo;algoritmo paralelo;reconfigurable multi ring system;vision ordenador;reconfiguracion;parallel algorithm;image processing;traitement parallele;procesamiento imagen;traitement image;algorithme parallele;computer vision;computer architecture;reconfigurable architecture;parallel processing computer vision;architecture ordinateur;vision ordinateur;arquitectura ordenador;parallel processing;multi ring system	In this paper we describe a reconfigurable architecture for image processing and computer vision based on a multi-ring network which we call a Reconfigurable Multi-Ring System (RMRS). We describe the reconfiguration switch for the RMRS and also describe its VLSI implementation. The RMRS topology is shown to be regular and scalable and hence well-suited for VLSI implementation. We prove some important properties of the RMRS topology and show that a broad class of algorithms for the n-cube can be mapped to the RMRS in a simple and elegant manner. We design and analyze a class of procedural primitives for the SIMD RMRS and show how these primitives can be used as building blocks for more complex parallel operations. We demonstrate the usefulness of the RMRS for problems in image processing and computer vision by considering two important operations—the Fast Fourier Transform (FFT) and the Hough transform for detection of linear features in an image. Parallel algorithms for the FFT and the Hough transform on the SIMD RMRS are designed using the aforementioned procedural primitives. The analysis of the complexity of these algorithms shows that the SIMD RMRS is a viable architecture for problems in computer vision and image processing.	computer vision;image processing	Suchendra M. Bhandarkar;Hamid R. Arabnia;Jeffrey W. Smith	1995	IJPRAI	10.1142/S0218001495000110	parallel processing;computer vision;parallel computing;image processing;computer science;control reconfiguration;theoretical computer science;parallel algorithm	Vision	10.866313444174596	35.829760439333675	11557
35248cdb39932c88026b33339dc3ba2bcdbdae4d	on some covering graphs of a graph	maximum degree;covering number;independence number;covering set;covering graph;maximum degree minimum covering graph	For a graph G with vertex set V (G) = {v1, v2, . . . , vn}, let S be the covering set of G having the maximum degree over all the minimum covering sets of G. Let NS[v] = {u ∈ S : uv ∈ E(G)} ∪ {v} be the closed neighbourhood of the vertex v with respect to S. We define a square matrix AS(G) = (aij), by aij = 1, if |NS[vi] ∩NS[vj]| ≥ 1, i 6= j and 0, otherwise. The graph G associated with the matrix AS(G) is called the maximum degree minimum covering graph (MDMC-graph) of the graph G. In this paper, we give conditions for the graph G to be bipartite and Hamiltonian. Also we obtain a bound for the number of edges of the graph G in terms of the structure of G. Further we obtain an upper bound for covering number (independence number) of G in terms of the covering number (independence number) of G.	covering graph;hamiltonian (quantum mechanics);independent set (graph theory);the matrix;vertex (graph theory)	Shariefuddin Pirzada;Hilal A. Ganie;Merajuddin Siddique	2016	EJGTA	10.5614/ejgta.2016.4.2.2	covering graph;combinatorics;discrete mathematics;topology;degree;mathematics	Theory	29.882484059277036	29.374068999617965	11558
48bf210958f54613c11e3c7144ce361068aa1008	boxicity of halin graphs	nombre entier;forma planaria;tree;isomorphic graph;05c05;vertex;arbol;box;product;ciclo;integer;cartesian product;planar form;grafo isomorfo;producto;graphe planaire;graphe intersection;entero;68r10;caja;school of automation;halin graphs;graphe isomorphe;arbre;boite;forme planaire;produit;vertice;intersection graphs;grafo planario;cycle;planar graphs;computer science automation formerly;planar graph;plongement graphe;boxicity	A k-dimensional box is the Cartesian product R1 × R2 × · · · ×Rk where each Ri is a closed interval on the real line. The boxicity of a graph G, denoted as box(G) is the minimum integer k such that G is the intersection graph of a collection of k-dimensional boxes. Halin graphs are the graphs formed by taking a tree with no degree 2 vertex and then connecting its leaves to form a cycle in such a way that the graph has a planar embedding. We prove that if G is a Halin graph that is not isomorphic to K4, then box(G) = 2. In fact, we prove the stronger result that if G is a planar graph formed by connecting the leaves of any tree in a simple cycle, then box(G) = 2 unless G is isomorphic to K4 (in which case its boxicity is 1).	boxicity;cycle (graph theory);halin graph;planar graph	L. Sunil Chandran;Mathew C. Francis;Santhosh Suresh	2009	Discrete Mathematics	10.1016/j.disc.2008.09.037	outerplanar graph;block graph;graph power;pathwidth;combinatorics;discrete mathematics;polyhedral graph;dual graph;interval graph;degree;graph toughness;boxicity;pancyclic graph;symmetric graph;mathematics;geometry;tree-depth;halin graph;treewidth;wheel graph;complement graph;line graph;string graph;planar graph;algebra	Theory	25.726219335433676	30.770270798646823	11567
6b1643ff17d9edf58d3b12d8cc468946c837a4ae	topics in monitoring and planning for embedded real-time systems	antichains		embedded system;real-time clock;real-time computing	Hsi-Ming Ho	2015			discrete mathematics;computer science;theoretical computer science;algorithm	EDA	-3.0165083676960283	27.465049702244247	11585
f9033fb46e64997955aa96755ffebb3f5dde86cf	some variants of the take-grant protection model	protection information;controle acces;securite;ressource partagee;computer system;modelisation;cryptography;information protection;safety;cryptographie;systeme informatique;modeling;securidad	The take-grant protection model, as introduced in [3,7,5] and surveyed in [1,2,6], describes the access control facilities for shared resources in computer systems. The current state of the system is given by a finite, directed, loop-free, labelled protection graph G = (S, 0; E) with S n 0 = 8; V := S u 0 is the set of vertices, and E is the set of edges where labels are taken from a finite set of rights R that includes the special rights t (take) and g (grant). A vertex x E S, respectively x E 0, represents a subject, respectively object, of the system. An edge x-a-y E E represents the fact that subject/object x possesses the right a with respect to subject/object y. Graphically, subject vertices are denoted by l and object vertices are denoted by 0, whereas @ indicates that we do not care about the type. A state G, = (S,, 0, ; E,) can be transformed into a state G, = (S,, 0, ; E2) by applying a trunsformation rule:	access control;rule 110;rule 90;take-grant protection model;vertex (computer graphics);vertex (geometry);vertex (graph theory)	Joachim Biskup	1984	Inf. Process. Lett.	10.1016/0020-0190(84)90095-4	computer science;cryptography;mathematics;algorithm	DB	22.7443720782226	32.50514547014783	11594
63f0037d6c2d174062b7e5584c7138a4e0e79e49	connected cutsets of a graph and triangle bases of the cycle space	graph theory;homotopie;teoria grafo;homotopia;homotopy;theorie graphe;conectividad diagrama;graph connectivity;cycle graphe;characterization;cycle graph;caracterisation;connectivite graphe;caracterizacion;ciclo diagrama	The notion of homotopy in graphs was introduced by the authors [3]. Another notion of homotopy in graphs has been considered by Quilliot [4]. Cycles in graphs are viewed algebraically, i.e., they are considered as vectors in GF(2) e, where E is the edge-set of the graph. We say that two cycles C and C' are homotopic in a graph G = (V, E) if there are triangles T~ (i = 1 , . . . , k) such that C = C' + E~=I T~. The relationship between the null-homotopy property (i.e., 'any two cycles are homotopic') and properties relative to connectedness have been considered in the context of topological spaces (see Whyburn [6, chap. XI] for details). Inspired by these concepts we investigate in the present paper some properties of graphs of a similar flavour. We mention that the graph properties we obtain are not reducible to topological properties. In the case of graphs not contractible onto K5, we prove in Section 3 the equivalence between the null-homotopy property and the property that any two induced subgraphs whose union is the whole graph have a connected intersection. This last property is characterized in two ways in Section 1. The equivalence is not true in general (Section 2). Graphs considered in this paper are finite, without loops or multiple edges. For a graph G = (V, E) and A ~_ V, GA denotes the subgraph of G induced by A:GA = (A, E N 2A). For G = (V, E) and G' = (V', E ' ) we write G U G' for the graph (V LI V', E U E'). The graph G f3 G' is defined similarly.	challenge-handshake authentication protocol;cycle space;graph (discrete mathematics);graph property;multiple edges;software release life cycle;turing completeness	Pierre Duchet;Michel Las Vergnas;Henry Meyniel	1986	Discrete Mathematics	10.1016/0012-365X(86)90115-9	1-planar graph;outerplanar graph;block graph;pathwidth;split graph;combinatorics;discrete mathematics;universal graph;topology;connectivity;graph theory;pancyclic graph;forbidden graph characterization;homotopy;cycle graph;symmetric graph;mathematics;voltage graph;modular decomposition;butterfly graph;cycle basis;chordal graph;line graph;coxeter graph;planar graph	Theory	28.333786977099802	31.552725256901365	11627
887f2b75df0a5d129d319fa7b4b54cf820f5e19e	reachability analysis for formal verification of systemc	formal specification;design flow;systemc reachability analysis formal verification design flows simulation approaches design complexity scalable bus arbiter cell;formal verification;reachability analysis formal verification boolean functions data structures circuit simulation binary decision diagrams hardware computer science algorithm design and analysis costs;binary decision diagrams;levels of abstraction;logic testing;reachability analysis;logic testing reachability analysis formal verification binary decision diagrams formal specification	With ever increasing design sizes, verification becomes the bottleneck in modern design flows. Up to 80% of the overall costs are due to the verification task. Formal methods have been proposed to overcome the limitations of simulation approaches. But these techniques have mainly been applied to lower levels of abstraction. With more and more design complexity the need for hardware description languages with a high level of abstraction becomes obvious. We present a formal verification approach for circuits described in SystemC, an extension of C that allows the modeling of hardware. An algorithm for reachability analysis is proposed and a case study of a scalable bus arbiter cell is given.	algorithm;arbiter (electronics);bus mastering;computation;conventional pci;formal methods;formal proof;formal verification;hardware description language;high-level programming language;principle of abstraction;reachability;scalability;simulation;systemc	Rolf Drechsler;Daniel Große	2002		10.1109/DSD.2002.1115387	computer architecture;verification;formal methods;formal verification;computer science;design flow;theoretical computer science;formal specification;formal equivalence checking;high-level verification;programming language;intelligent verification;functional verification	EDA	7.399969896027988	52.46313523266197	11633
5cb8bb1ba1057c2a7c802001686a1a62db4c70d6	complexity classes in models of cellular computing with membranes	p systems;decision problem;complexity class;p system;complexity classes;polynomial time;membrane computing	In this paper we introduce four complexity classes for cellularcomputing systems with membranes: the first and the second ones containall decision problems solvable in polynomial time by a family ofdeterministic P systems, without and with an input membrane,respectively; the third and fourth classes contain all decision problemssolvable in polynomial time by a family of non-deterministic P systems,without and with an input membrane, respectively. We illustrate theusefulness of these classes by solving two NP–completeproblems, namely HPP and SAT, in both variants of Psystems.	boolean satisfiability problem;complexity class;computation;confluence (abstract rewriting);decision problem;finite-state machine;karp's 21 np-complete problems;natural computing;p (complexity);p system;p versus np problem;polynomial;time complexity;turing machine	Mario J. Pérez-Jiménez;Álvaro Romero Jiménez;Fernando Sancho-Caparrini	2003	Natural Computing	10.1023/A:1025449224520	complexity class;p;mathematical optimization;combinatorics;discrete mathematics;fp;polynomial-time reduction;np;ph;quantum complexity theory;computer science;membrane computing;structural complexity theory;2-exptime;mathematics;#p;up;np-easy;algorithm;descriptive complexity theory	Theory	1.6789043209588355	24.209378054291975	11655
dce903b1010eb1dca87b6415d21e1a210a356332	the geo-graph in practice: creating united states congressional districts from census blocks	planar graphs;graph partitioning;geographic districting;graph connectivity	Every 10 years, United States Congressional Districts must be redesigned in response to a national census. While the size of practical political districting problems is typically too large for exact optimization approaches, heuristics such as local search can help stakeholders quickly identify good (but suboptimal) plans that suit their objectives. However, enforcing a district contiguity constraint during local search can require significant computation; tools that can reduce contiguity-based computations in large practical districting problems are needed. This paper applies the geo-graph framework to the creation of United States Congressional Districts from census blocks in four states—Arizona, Massachusetts, New Mexico, and New York—and finds that (a) geo-graph contiguity assessment algorithms reduce the average number of edges visited during contiguity assessments by at least three orders of magnitude in every problem instance when compared with simple graph search, and (b) the assumptions of the geo-graph model are easily adapted to the sometimes-irregular census block geography with only superficial impact on the solution space. These results show that the geo-graph model and its associated contiguity algorithms provide a powerful constraint assessment tool to political districting stakeholders.		Douglas M. King;Sheldon H. Jacobson;Edward C. Sewell	2018	Comp. Opt. and Appl.	10.1007/s10589-017-9936-3	mathematical optimization;connectivity;contiguity;heuristics;census;planar graph;data mining;graph partition;local search (optimization);computer science;graph	HCI	23.385378821292313	8.225768310989993	11672
82a7f085e8133ac2adcc6bacca8bb2f90aa77f3d	accurate robustness assessment of hdl models through iterative statistical fault injection		Simulation-based fault injection is commonly used to assess the robustness of hardware components modelled using Hardware Description Languages (HDL). The current complexity of modern circuits usually makes not feasible the consideration of all possible combinations of fault models, targets, and times. By assuming a confidence interval and error margin, statistical fault injection exploits the principle of statistical sampling to reduce the number of experiments while keeping the results representative of the whole population of fault injections. Since the percentage of injected faults leading to failure is a priori unknown, such number of experiments is usually determined by selecting the value maximizing the sample size. This paper argues that this conservative assumption leads to a worst-case scenario that can be improved. The proposal relies on an iterative algorithm that progressively adjust the number of experiments by estimating the percentage of those leading to failure and the error of the estimation. The considered case study illustrates the feasibility and usefulness of the proposal through the robustness assessment of the LEON3 microprocessor model. Beyond that example, this research provides new means to decide when to stop a fault injection campaign and to estimate the error existing in the results finally reported.	algorithm;best, worst and average case;dependability;experiment;failure cause;fault injection;fault model;hardware description language;iterative method;leon;microprocessor;requirement;robustness testing;sampling (signal processing);simulation;worst-case scenario	Ilya Tuzov;David de Andrés;Juan Carlos Ruiz	2018	2018 14th European Dependable Computing Conference (EDCC)	10.1109/EDCC.2018.00013	a priori and a posteriori;real-time computing;iterative method;algorithm;robustness (computer science);sampling (statistics);sample size determination;fault injection;margin of error;population;computer science	EDA	24.643818381334345	56.01517200621578	11682
567aa97f8ebb75c5fb736f3a429bfb7f057208c3	graphs of maximum diameter	graphe non oriente;graphe critique;non directed graph;maximo;critical graph;graphe restreint;maximum;diametre;diameter;connected graph;grado diagrama;grafo no orientado;diametro;degre graphe;grafo critico;graphe connexe;grafo connexo;graph degree;nombre aretes	Caccetta, L. and W.F. Smyth, Graphs of maximum diameter, Discrete Mathematics 102 (1992) 121-141. A simple undirected connected graph with minimum degree K is said to be K-restrained. Thus the class of K-restrained graphs includes all K-connected and K-edge-connected graphs, as well as all connected K-regular graphs. An upper bound on the diameter of three of these four classes of graphs is known: for K-restrained (hence for connected K-regular) and for K-connected. We complete the picture by determining an upper bound on the diameter of a K-edge-connected graph of order n; and show that, with the exception of certain connected K-regular graphs, the upper bound is attained by some graph in every class. For K-restrained graphs of order n known to contain a vertex of eccentricity d, a maximum edge-count l (n, d, K) is specified and shown to be a monotone decreasing function of d; this result is then used to determine the maximum diameter of a K-restrained graph of order n and size m.	connectivity (graph theory);discrete mathematics;distance (graph theory);graph (discrete mathematics);graph theory;k-edge-connected graph;k-vertex-connected graph;monotone	Lou Caccetta;William F. Smyth	1992	Discrete Mathematics	10.1016/0012-365X(92)90047-J	1-planar graph;block graph;random regular graph;pathwidth;split graph;combinatorics;discrete mathematics;cograph;topology;graph product;dense graph;pancyclic graph;comparability graph;diameter;clique-sum;mathematics;geometry;tree-depth;odd graph;maximal independent set;modular decomposition;treewidth;partial k-tree;chordal graph;indifference graph;line graph	Theory	25.947475537028538	30.857646902011794	11701
459155a632716f5d347b56e3826fa26551d228d6	vlsi architecture for a flexible motion estimation with parameters	vlsi architectures;cmos technology vlsi architectures flexible motion estimation power consumption reduction motion estimation algorithm adapted algorithm reconfigurable architecture address generator unit delay unit parameters block matching algorithm hardware description language synthesis tools low cost real time application vhdl synosys design tools;design tool;cmos technology;image matching motion estimation reconfigurable architectures parallel architectures vlsi digital signal processing chips cmos digital integrated circuits parallel algorithms adaptive signal processing;reconfigurable architectures;very large scale integration;image matching;address generator unit;delay unit;video compression;motion estimation;vhdl synosys design tools;computer architecture;adaptive algorithm;adapted algorithm;reconfigurable architecture;adaptive signal processing;parallel architectures;cmos digital integrated circuits;energy consumption;computational complexity;vhdl;very large scale integration motion estimation hardware energy consumption algorithm design and analysis computer architecture video compression computational complexity field programmable gate arrays reconfigurable architectures;parameters;vlsi;block matching;flexible motion estimation;digital signal processing chips;power consumption;synthesis tools;field programmable gate arrays;hardware description language;motion estimation algorithm;real time application;reconfigurable hardware;algorithm design and analysis;power consumption reduction;low cost real time application;block matching algorithm;hardware;vlsi architecture;parallel algorithms	If motion estimation can choose the most suitable algorithm according to the changing characteristics of input image signals, we can get benefits, which improved quality and performance, reduced power consumption, and an optimized system. In this paper, we propose a reconfigurable approach to motion estimation algorithm. Our algorithm determines motion type and then selects adapted algorithm in order to improve quality and performance of images. We implemented the flexible and reconfigurable hardware architecture by hardware with address generator unit, delay unit, and parameters. Our architecture supports more than one block-matching algorithms and parameters providing to optimize system. We are implementing our architecture by using hardware description language (VHDL) and synthesis design tools. We analyze the performance of the architecture and present adaption to algorithm for a low cost real time application.	address generation unit;algorithm;field-programmable gate array;hardware description language;motion estimation;vhdl	Jinku Choi;Nozomu Togawa;Masao Yanagisawa;Tatsuo Ohtsuki	2002		10.1109/ASPDAC.2002.994962	embedded system;computer architecture;electronic engineering;real-time computing;computer science;very-large-scale integration;algorithm;statistics	EDA	12.176015333692524	41.13318531104694	11705
55017bcaca0e6c2a1fdd7d2d5cfabbc2e3b34ce6	logic circuits operating in subthreshold voltages	100 nm;ultra low power;subthreshold;off current performance design theory subthreshold ultra low power medium to high speed logic styles noise margins body biasing;180 nm logic circuits subthreshold voltages static cmos circuit performance noise margins tunable body biasing scheme nand ring oscillator 100 nm;subthreshold voltages;logic design;nand ring oscillator;logic circuits leakage current logic devices circuit noise threshold voltage logic design mos devices cmos technology circuit simulation tunable circuits and devices;performance;ring oscillator;medium to high speed;logic circuits;180 nm;body biasing;static cmos circuit performance;threshold voltage;nand circuits cmos logic circuits logic circuits logic design low power electronics;cmos logic circuits;theory;nand circuits;logic styles;low power electronics;design;tunable body biasing scheme;noise margins;high speed;off current	In this paper different logic circuit families operating in the subthreshold region are analyzed. Their performance in terms of power and speed are of particular interest. The study complements existing work that has reported static CMOS circuit performance under different body biasing schemes in the subthreshold region. Further it offers assurances on noise margins with scaling going beyond the 100 nm technology node. Simulations have been performed at the 180 nm technology node using a 6 metal layer TSMC process. A tunable body biasing scheme that allows bulk CMOS circuits to operate efficiently at subthreshold as well as above threshold voltages is introduced. The scheme improves a five-stage NAND ring oscillator switching speed 6X better than the static CMOS configuration while dissipating 18 % less power.	biasing;cmos;computer simulation;image scaling;logic gate;noise margin;ring oscillator;semiconductor device fabrication;the 100	Jabulani Nyathi;Brent Bero	2006	ISLPED'06 Proceedings of the 2006 International Symposium on Low Power Electronics and Design	10.1145/1165573.1165604	design;electronic engineering;real-time computing;performance;computer science;engineering;electrical engineering;operating system;ring oscillator;threshold voltage;subthreshold conduction;theory	Arch	18.12892311833811	58.45884809748726	11760
c85e6a65941f33f50ff3d272ebcf03897f5d7b87	extending the stansfield algorithm to three dimensions: algorithms and implementations		The Stansfield algorithm is a well-known geolocation method for two-dimensional (2-D), azimuth-only bearing measurements of a stationary emitter. It is known to suffer from estimation bias, and its performance in terms of optimality criteria is unknown. Strategies that accurately combine both azimuth and elevation measurements for 3-D position estimation are generally required in many applications. This paper introduces two novel bearings-only geolocation algorithms: the weighted Stansfield algorithm in three dimensions (WS3D) and the instrumental variable weighted Stansfield algorithm in three dimensions (IVWS3D). In these two procedures, bearing quality weighting and estimated range weighting are used to minimize the maximum-likelihood cost function in pairs of coupled least-squares procedures. Measurement weighting is shown to be important to obtain best performance. Moreover, the use of updated bearing measurements in the instrumental variable method in IVWS3D is shown to decrease estimation bias. Simulations of the new algorithms show that the WS3D algorithm asymptotically outperforms existing geolocation algorithms, whereas the IVWS3D algorithm provides the least-biased position estimation.	algorithm;geolocation;lambert's cosine law;least squares;loss function;stationary process	Neda Adib;Scott C. Douglas	2018	IEEE Transactions on Signal Processing	10.1109/TSP.2017.2781641	instrumental variable;implementation;common emitter;elevation;mathematical optimization;mathematics;algorithm;azimuth;geolocation;bearing (mechanical);weighting	Metrics	51.80875760588781	5.06987245030511	11770
63591dffceb7d8b4a3950f6f3f4725a68bf4d766	new links between differential and linear cryptanalysis		Recently, a number of relations have been established among previously known statistical attacks on block ciphers. Leander showed in 2011 that statistical saturation distinguishers are on average equivalent to multidimensional linear distinguishers. Further relations between these two types of distinguishers and the integral and zero-correlation distinguishers were established by Bogdanov et al. [6]. Knowledge about such relations is useful for classification of statistical attacks in order to determine those that give essentially complementary information about the security of block ciphers. The purpose of the work presented in this paper is to explore relations between differential and linear attacks. The mathematical link between linear and differential attacks was discovered by Chabaud and Vaudenay already in 1994, but it has never been used in practice. We will show how to use it for computing accurate estimates of truncated differential probabilities from accurate estimates of correlations of linear approximations. We demonstrate this method in practice and give the first instantiation of multiple differential cryptanalysis using the LLR statistical test on PRESENT. On a more theoretical side, we establish equivalence between a multidimensional linear distinguisher and a truncated differential distinguisher, and show that certain zerocorrelation linear distinguishers exist if and only if certain impossible differentials exist.	approximation;block cipher;leander;linear cryptanalysis;lucas–lehmer–riesel test;route distinguisher;saturation arithmetic;truncated differential cryptanalysis;turing completeness;universal instantiation	Céline Blondeau;Kaisa Nyberg	2013		10.1007/978-3-642-38348-9_24	combinatorics;differential cryptanalysis;discrete mathematics;higher-order differential cryptanalysis;mathematics;computer security;algorithm;statistics;algebra;linear cryptanalysis	Crypto	41.79585786952692	44.45410971142594	11791
9255fc77e0cd869d5d4bf2e10fd9ab6e868dc215	differential subordinations involving arithmetic and geometric means	differential subordination;geometric means;subordination;univalent functions;arithmetic means	The paper concerns the differential subordination with the expression combined by arithmetic and geometric means:@a[p(z)]^@d+(1-@a)p(z)+zp^'(z)p(z)^@m@?@f(z),(p(0)=@f(0)=1,|z| , @a@? . For @d@? , @m@? , @a@?  we also study the differential subordination@a[p(z)]^@d+(1-@a)[p(z)]^@mp(z)+zp^'(z)p(z)^1^-^@m@?@f(z),(p(0)=@f(0)=1,|z|<1).Several applications of the studied subordination in the theory of analytic functions are given.		O. Crisan;S. Kanas	2013	Applied Mathematics and Computation	10.1016/j.amc.2013.07.051	arithmetic;discrete mathematics;geometric mean;arithmetic mean;mathematics;statistics;algebra	Theory	47.70186127869725	34.113074925804476	11798
79478ff405625054e63c3f9e37f54d5c30ad57f9	parallelizing the weil and tate pairings	core i7;eta pairing;pairing implementation;speed record;intel core i7;8-core extension;tate pairings;core i7 machine;new weil pairing;intel core i5;general weil pairing construction	In the past year, the speed record for pairing implementations on desktop-class machines has been broken several times. The speed records for asymmetric pairings were set on a single processor. In this paper, we describe our parallel implementation of the optimal ate pairing over Barreto-Naehrig (BN) curves that is about 1.23 times faster using two cores of an Intel Core i5 or Core i7 machine, and 1.45 times faster using 4 cores of the Core i7 than the state-of-the-art implementation on a single core. We instantiate Hess’s general Weil pairing construction and introduce a new optimal Weil pairing tailored for parallel execution. Our experimental results suggest that the new Weil pairing is 1.25 times faster than the optimal ate pairing on 8-core extensions of the aforementioned machines. Finally, we combine previous techniques for parallelizing the eta pairing on a supersingular elliptic curve with embedding degree 4, and achieve an estimated 1.24-fold speedup on an 8-core extension of an Intel Core i7 over the previous best technique.	automatic parallelization;desktop computer;list of intel core i5 microprocessors;markus hess;parallel computing;speedup	Diego F. Aranha;Edward Knapp;Alfred Menezes;Francisco Rodríguez-Henríquez	2011		10.1007/978-3-642-25516-8_17	theoretical computer science;mathematics;distributed computing;algorithm	Security	1.5701884864928926	40.36470715752097	11808
051f15daf941d1483d81b84ea0531099735c86c5	bfp: behavior-free passive motion detection using phy information	wlan;phy;csi;motion detection	Device-free passive motion detection seeks to monitor whether there are people moving in an area of interest -the detected individual neither carrying any device nor actively participating in the detection process. This has a very desirable application in mobile computing, such as smart space, asset security, border protection, etc. Many recent works focus on motion detection via WLAN due to its advantages in deployment flexibility, coverage and energy efficiency. However, these don’t consider the influence of human behavior on detection performance. By comparing and analyzing many experiment results, we have found different behavior factors (such as the number and distribution of people, the walking state, the relative distance to the detection point, etc.) have varying effects on detection accuracy using different WLAN information. To transcend these behavioral limitations, we design and implement Bfp: a Behavior-free passive motion detection system utilizing WLAN physical layer information and MIMO technique. First, Bfp extracts CSI information from the physical layer using an off-the-shelf device. Second, we propose to extract the variance of CSI amplitude feature that is more sensitive to human behaviors. Moreover, to eliminate the noise effects, we employ a truncate-tale filter on the variance and then obtain its distribution profile. The earth mover’s distance algorithm is utilized to distinguish the detection results. Finally, multi-streams of MIMO are leveraged W. Liu X. Gao L. Wang D. Wang School of Information Science and Engineering, Yanshan University, Qinhuangdao, HeBei, China e-mail: wyliu@ysu.edu.cn X. Gao e-mail: gaoxi.yanshan.ust@gmail.com D. Wang e-mail: wdyfantasy@gmail.com W. Liu The Key Laboratory for Computer Virtual Technology and System Integration of HeBei Province, Qinhuangdao 066004, HeBei, China L. Wang (&) Department of Computer Science, Illinois Institute of Technology, Chicago, IL 60616, USA e-mail: wangllinn@gmail.com 123 Wireless Pers Commun DOI 10.1007/s11277-015-2438-7	algorithm;anomaly detection;camera serial interface;computer science;email;fingerprint;information science;instability;mimo;mobile computing;phy (chip);performance evaluation;rss;software deployment;system integration;truncation	Wenyuan Liu;Xi Gao;Lin Wang;Danyang Wang	2015	Wireless Personal Communications	10.1007/s11277-015-2438-7	simulation;telecommunications;computer science;operating system;phy	AI	5.068422589308935	34.16388459042783	11814
b7a0ac361d03d7ab0984ef26afa6c1f20c37e9e2	the alpha-embracing contour	time measurement;clocks;computational geometry;construction industry;size measurement;alpha embracing contour;data visualisation;computational complexity;data visualization;stratification;joining processes;turkey depth;quality illumination alpha embracing contour depth contours data visualization turkey depth delaunay depth;lighting;quality illumination;data visualisation computational complexity computational geometry;delaunay depth;depth contours;lighting data visualization distributed computing shape q measurement	Every notion of depth induces a stratification of the plane in regions of points with the same depth with respect to a given set of points. The boundaries of these regions, also known as depth-contours, are an appropriate tool for data visualization and have already been studied for some depths like Turkey depth [5, 9, 10, 11] and Delaunay depth [3, 8]. The contours also have applications in quality illumination as is the case of good alpha-illumination [2]. The first alpha-depth contour is also known as the alpha-embracing contour. We prove that the first alpha-depth contour has linear size and we give an algorithm to compute it that runs in O(n2 log n) time and O(n2)space.	algorithm;average-case complexity;bathymetry;contour line;data visualization;delaunay triangulation;equal-loudness contour;illumination (image)	Manuel Abellanas;Mercè Claverol;Inês Matos	2008	2008 International Conference on Computational Sciences and Its Applications	10.1109/ICCSA.2008.36	stratification;computer vision;computer science;lighting;mathematics;geometry;computational complexity theory;data visualization;statistics;time	Theory	31.196672722117903	20.285093529379584	11829
237aa4de6f6dbf4e103a38ab842d9dddb370a49d	an improved simulated annealing algorithm for bandwidth minimization	minimisation;evaluation function;minimization;largeur bande;evaluation fonction;simulated annealing algorithm;heuristic method;metodo heuristico;minimizacion;simulated annealing;bandwidth minimization;recuit simule;function evaluation;anchura banda;bandwidth;recocido simulado;heuristics;methode heuristique	In this paper, a simulated annealing algorithm is presented for the bandwidth minimization problem for graphs. This algorithm is based on three distinguished features including an original internal representation of solutions, a highly discriminating evaluation function and an effective neighborhood. The algorithm is evaluated on a set of 113 well-known benchmark instances of the literature and compared with several state-of-the-art algorithms, showing improvements of some previous best results.	agi-plan;algorithm;benchmark (computing);computer science;emoticon;evaluation function;experiment;exploit (computer security);grasp;graph bandwidth;heuristic (computer science);human body weight;information;locality of reference;neighbourhood (graph theory);simulated annealing;test data;turing completeness	Eduardo Rodriguez-Tello;Jin-Kao Hao;José Torres-Jiménez	2008	European Journal of Operational Research	10.1016/j.ejor.2005.12.052	mathematical optimization;simulated annealing;computer science;machine learning;mathematics;adaptive simulated annealing;algorithm;statistics	Vision	24.067201108315263	6.243418308920466	11893
25a4114e03a98e6d50ed143d682c0ea9a64124d1	upper and lower bounding strategies for the generalized minimum spanning tree problem	algorithme rapide;problema arbol steiner;algoritmo aleatorizado;programacion entera;algoritmo busqueda;generalized minimum spanning tree;relaxation lagrange;algorithme glouton;algorithme recherche;arbre maximal;search algorithm;probleme arbre steiner;algorithme randomise;lagrange multiplier;greedy heuristic;algoritmo genetico;programmation en nombres entiers;integer programming;arbol maximo;computer experiment;fast algorithm;multiplicateur lagrange;minimum spanning tree;randomized algorithm;algorithme genetique;multiplicador lagrange;greedy algorithm;algoritmo gloton;genetic algorithm;upper and lower bounds;spanning tree;steiner tree problem;integer program;steiner tree;randomized greedy heuristic;algoritmo rapido;lower bound;lagrange relaxation;lagrangian relaxation	We address the generalized minimum spanning tree problem (GMST) which requires spanning at least one vertex out of every set of disjoint vertices in a graph. We show that the geometric version of this problem is NP-hard, and we propose two stochastic heuristics. The first one is a very fast randomized greedy search algorithm and the second one being a genetic algorithm. Also, we investigate some existing integer programming formulations and present an new one. A new Lagrangian based lower bound is proposed and implemented to assess the performance of the heuristics. Computational experiments performed on a large set of randomly generated instances with up to 1000 vertices and 10,000 edges provide evidence of the good performance of the proposed heuristics. 2004 Elsevier B.V. All rights reserved.	approximation algorithm;computation;degree-constrained spanning tree;experiment;file spanning;genetic algorithm;greedy algorithm;heuristic (computer science);integer programming;linear programming;minimum spanning tree;np-hardness;network planning and design;procedural generation;prototype;randomized algorithm;relevance;search algorithm;steiner tree problem;stochastic optimization;vertex (geometry)	Mohamed Haouari;Jouhaina Chaouachi Siala	2006	European Journal of Operational Research	10.1016/j.ejor.2004.07.072	mathematical optimization;combinatorics;greedy algorithm;discrete mathematics;kruskal's algorithm;integer programming;minimum degree spanning tree;spanning tree;steiner tree problem;computer science;minimum spanning tree;mathematics;upper and lower bounds;reverse-delete algorithm;distributed minimum spanning tree	AI	22.213478347580008	12.345158918592361	11923
b730fabe9309a38429da079753981d69cc62b0c3	one-counter circuits		One-counter nets are nondeterministic one-counter automata without zero-testing (Petri Nets with at most one unbounded place). A one-counter circuit of length ∆ is a strongly connected one-counter net, such that ∆ is a greatest common divisor of effects of all its cycles. A circuit has simple periodic behaviour: for any control state the set of corresponding reachable counter values is an arithmetic progression with difference ∆ (with an exception of a bounded subset). Properties of circuits and general one-counter nets are studied. It is shown that the infinite behaviour of a one-counter net can be represented by a composition of a finite set of circuits.	automata theory;color gradient;nondeterministic algorithm;petri net;program counter;strongly connected component	Vladimir A. Bashkin	2012			discrete mathematics;periodic graph (geometry);nondeterministic algorithm;petri net;greatest common divisor;bounded function;mathematics;strongly connected component;finite set;arithmetic progression	EDA	-1.6756687015947376	22.24765057669195	11924
79f3adac20202e3fddca7e41a3b0b21ac4c32787	on the conjecture about the linear structures of rotation symmetric boolean functions		In this paper, we study the conjecture that n-variable (n odd) rotation symmetric Boolean functions with degree n − 2 have no non-zero linear structures. We show that if this class of RSBFs have non-zero linear structures, then the linear structures are invariant linear structures and the homogeneous component of degree n − 3 in the function’s algebraic normal form has only two possibilities. Moreover, it is checked that the conjecture is true for n = 9, 15, 21, and then a more explicit conjecture is proposed.		Lei Sun;Fang-Wei Fu;Jian Liu	2017	Int. J. Found. Comput. Sci.	10.1142/S0129054117500265	algebraic normal form;conjecture;boolean function;discrete mathematics;mathematics;linear complex structure;hadamard transform;homogeneous;invariant (mathematics)	Logic	39.95034449230384	33.7843940365909	11954
a84501d3277542663a32a5d971d81771bce3cf30	design of multi-residue generators using shared logic	digital signal processing;generators;error correction codes;logic circuitry multiresidue generator design shared logic integer division residue number system arithmetic error control coding cryptography conjugate moduli residue arithmetic hardware;residue number systems;logic circuits;generators adders hardware error correction cryptography computer architecture digital signal processing;computer architecture;residue number systems cryptography error correction codes logic circuits possibility theory;adders;cryptography;error correction;possibility theory;residual generation;hardware	The generation of the remainder of the integer division by one or more moduli is essential in various applications involving residue number system (RNS), arithmetic error control coding, and cryptography. In this paper, we consider the possibility of designing multi-residue generators capable of sharing hardware which, unlike previous designs, are not limited to the pairs of conjugate moduli 2a − 1 and 2a−1 + 1only. We show that logic circuitry can be shared by residue generators modulo any moduli whose period or half-period parameters have common divisors and are at least three times larger than the number of inputs of the generators. For some subsets of moduli, over 40% hardware reduction is observed.	algorithm;central processing unit;computer-aided design;cryptography;digital signal processor;electronic circuit;error detection and correction;modulo operation;overhead (computing);quasiperiodicity;reduction (complexity);residue number system;very-large-scale integration;warez	Stanislaw J. Piestrak	2011	2011 IEEE International Symposium of Circuits and Systems (ISCAS)	10.1109/ISCAS.2011.5937843	arithmetic;possibility theory;discrete mathematics;computer science;cryptography;theoretical computer science;digital signal processing;mathematics;algorithm;statistics	Arch	14.401014303739881	44.78541826950892	11963
209ebc8bfe7c2a2e44f0a823481f9918d67b47bb	some symbolic computing links to the nag numeric library	symbolic computation	This article is a semi-popular account intended to help readers compare the three products, SENAC, InterCall and IRENA. Each of the three is in the genre specified in the title of this paper. This article is not a review, as the authors are too closely associated with individual products. For technical detail, see the references below, which, however, treat individual products and generally provide no comparisons.	semiconductor industry;symbolic computation	Kevin A. Broughan;G. Keady;T. D. Robb;Michael G Richardson;Michael C. Dewar	1991	ACM SIGSAM Bulletin	10.1145/122514.122518	symbolic computation;computer science;theoretical computer science;mathematics;algorithm;algebra	Web+IR	50.90443721026742	36.08080386007519	11970
d6bb537382f15bdd11f86a52b45477d02be888d0	enumeration of snakes and cycle-alternating permutations	differential equation;euler number;increasing trees;signed permutation;generating function	Springer numbers are analogs of Euler numbers for the group of signed permutations. Arnol’d showed that they count some objects called snakes, which generalize alternating permutations. Hoffman established a link between Springer numbers, snakes, and some polynomials related with the successive derivatives of trigonometric functions. The goal of this article is to give further combinatorial properties of derivative polynomials, in terms of snakes and other objects: cycle-alternating permutations, weighted Dyck or Motzkin paths, increasing trees and forests. We obtain some exponential generating functions in terms of trigonometric functions, and some ordinary generating functions in terms of J-fractions. We also define natural q-analogs, make a link with normal ordering problems and the combinatorial theory of differential equations.	dyck language;euler;polynomial;springer (tank);time complexity	Matthieu Josuat-Vergès	2014	Australasian J. Combinatorics		generating function;combinatorics;mathematical analysis;discrete mathematics;mathematics;geometry;euler number;differential equation;algebra	Theory	44.899055900892826	32.68237220537673	11971
347e02a2d00eb5fb17f6a8ae7535a6c15db9c4a5	an improved abstract gpu model with data transfer		GPUs are commonly used as coprocessors to accelerate a compute-intensive task, thanks to their massively parallel architecture. There is study into different abstract parallel models, which allow researchers to design and analyse parallel algorithms. However, most work on analysing GPU algorithms has been software based tools for profiling a GPU algorithm. Recently, some abstract GPU models have been proposed, yet they do not capture all elements of a GPU. In particular, they miss the data transfer between CPU and GPU, which in practice can cause a bottleneck and reduce performance dramatically. We propose a comprehensive model called Abstract Transferring GPU which to our knowledge is the first abstract GPU model to capture data transfer between CPU and GPU. We show via experiments, that existing abstract GPU models cannot sufficiently capture all of the actual running of a GPU algorithm time in all cases, as they do not capture data transfer. We show that by capturing data transfer with our model, we are able to obtain more accurate predictions of the GPU algorithm actual running time. It is expected that our model helps improve design and analysis of heterogeneous systems consisting of CPU and GPU, and will allow researchers to make better informed implementation decisions, as they will be aware how data transfer will affect their programs.	central processing unit;computation;computational problem;coprocessor;experiment;floor and ceiling functions;graphics processing unit;intel hd and iris graphics;memory management;parallel algorithm;parallel computing;pseudocode;requirement;time complexity	Thomas C. Carroll;Prudence W. H. Wong	2017	2017 46th International Conference on Parallel Processing Workshops (ICPPW)	10.1109/ICPPW.2017.28	massively parallel;parallel computing;algorithm design;data modeling;parallel algorithm;profiling (computer programming);software;computer science;bottleneck;computational science;coprocessor	HPC	-3.3347693998997827	44.6204911307999	11972
b9635ca693993a99774ab5c885cfb04ac9928fe6	parallel pipelined vlsi architectures for lifting-based two-dimensional forward discrete wavelet transform	discrete wavelet transforms;lifting based 2d forward discrete wavelet transform;parallel pipelined;vlsi architectures;and parallel vlsi architecture discrete wavelets transform dwt jpeg2000 lifting scheme;histograms;image coding;discrete wavelet transform;image segmentation;discrete wavelets transform dwt;vlsi discrete wavelet transforms;clocks;very large scale integration;and parallel;probability density function;tellurium;lifting scheme;temporary line buffer parallel pipelined vlsi architectures lifting based 2d forward discrete wavelet transform real time applications;data mining;2 dimensional;temporary line buffer;medical services;signal processing;pixel;vlsi;jpeg2000;real time applications;entropy;latches;discrete wavelet transforms very large scale integration entropy breast cancer histograms mammography tellurium image segmentation signal processing medical services;parallel architecture;mammography;real time application;breast cancer;vlsi architecture	In this paper, in order to best meet real-time applications of 2-dimensional discrete wavelet transform (2-D DWT) with demanding requirements in terms of speed and throughput, 2-parallel and 4-parallel pipelined lifting-based VLSI architectures for lossless 5/3 and lossy 9/7 algorithms are proposed. The two proposed parallel architectures achieve speedup factors of 2 and 4 as compared with single pipelined architecture based on the first scan method proposed by Ibrahim et al. The advantage of the proposed architectures is that they only require a total temporary line buffer (TLB) of size N and 3N in 5/3 and 9/7, respectively.	algorithm;computation;computer data storage;computer science;discrete wavelet transform;fourier analysis;image compression;integer factorization;jpeg 2000;lifting scheme;lossless compression;lossy compression;pp (complexity);proceedings of the ieee;processor register;real-time clock;requirement;simulation;source-to-source compiler;speedup;throughput;translation lookaside buffer;vhdl-ams;very-large-scale integration	Ibrahim Saeed Koko;Herman Agustiawan	2009	2009 International Conference on Signal Acquisition and Processing	10.1109/ICSAP.2009.23	computer vision;parallel computing;computer science;theoretical computer science;signal processing;very-large-scale integration;statistics	EDA	11.99193312502233	39.19177747151885	11981
bc51481fc7b144e3276aaa5f9e9819678e64ae13	sylvester's double sums: an inductive proof of the general case	subresultants;sylvester s double sums;algebraic geometry	In 1853 J. Sylvester introduced a family of double sum expressions for two finite sets of indeterminates and showed that some members of the family are essentially the polynomial subresultants of the monic polynomials associated with these sets. In 2009, in a joint work with C. D’Andrea and H. Hong we gave the complete description of all the members of the family as expressions in the coefficients of these polynomials. More recently, M.-F. Roy and A. Szpirglas presented a new and natural inductive proof for the cases considered by Sylvester. Here we show how induction also allows to obtain the full description of Sylvester’s double-sums.	coefficient;mathematical induction;monic polynomial	Teresa Krick;Ágnes Szántó	2012	J. Symb. Comput.	10.1016/j.jsc.2012.01.003	sylvester matrix;combinatorics;discrete mathematics;algebraic geometry;sylvester's law of inertia;sylvester equation;mathematics;algebra	Theory	41.89371398895939	35.20381255200085	11993
6df60553209c2f578f3b864c8c549f48c1181893	source-optimized clustering for distributed source coding	minimisation;source channel decoder;graph theory;iterative decoding;source optimized hierarchical clustering;factor graph;combined source channel coding;large scale sensor network;source channel decoder source optimized hierarchical clustering distributed source coding iterative decoding low complexity distributed quantizer design large scale sensor network factor graph statistical analysis kullback leibler distance minimisation index assignment design;distributed source coding;distributed sensors;quantisation signal;statistical analysis combined source channel coding computational complexity distributed sensors graph theory iterative decoding minimisation quantisation signal;source coding quantization clustering algorithms scalability random variables algorithm design and analysis iterative algorithms sensor phenomena and characterization statistical distributions decoding;statistical analysis;computational complexity;kullback leibler distance minimisation;low complexity distributed quantizer design;index assignment design	Motivated by the design of low-complexity distributed quantizers and iterative decoding algorithms that leverage the correlation in the data picked up by a large-scale sensor network, we address the problem of finding correlation preserving clusters. To construct a factor graph describing the statis tical dependencies between sensor measurements, we develop a hie rarchical clustering algorithm that minimizes the Kullback Leibler Distance between known and approximated source statistics . Finally, we show how the clustering result can be exploited i n the design of index assignments for distributed quantizati on and source-channel decoders of manageable complexity.	approximation algorithm;cluster analysis;distributed source coding;factor graph;iteration;kullback–leibler divergence	Gerhard Maierbacher;João Barros	2006		10.1109/GLOCOM.2006.54	correlation clustering;minimisation;distributed source coding;computer science;graph theory;theoretical computer science;machine learning;factor graph;pattern recognition;cluster analysis;computational complexity theory;statistics	AI	47.58320243722847	7.5654902113672655	11999
5a5609b2b7cb8de13021d2a1fa2162b95d739281	sparse polynomial division using a heap	polynomial data structures;computer algebra system;polynomial division;heaps;sparse polynomials;high performance;data structure;polynomial multiplication	In 1974, Johnson showed how to multiply and divide sparse polynomials using a binary heap. This paper introduces a new algorithm that uses a heap to divide with the same complexity as multiplication. It is a fraction-free method that also reduces the number of integer operations for divisions of polynomials with integer coefficients over the rationals. Heap-based algorithms use very little memory and do not generate garbage. They can run in the cpu cache and achieve high performance. We compare our C implementation of sparse polynomial multiplication and division with integer coefficients to the routines of existing computer algebra systems.	algorithm;artificial neural network;binary heap;cpu cache;central processing unit;coefficient;computer algebra system;data structure;degree of a polynomial;division algorithm;heap (data structure);kernel (operating system);maple;monomial;overhead (computing);polynomial long division;polynomial ring;recursion;sparse matrix	Michael B. Monagan;Roman Pearce	2011	J. Symb. Comput.	10.1016/j.jsc.2010.08.014	fibonacci heap;synthetic division;discrete mathematics;heap;data structure;skew heap;polynomial arithmetic;theoretical computer science;binary heap;resultant;mathematics;polynomial long division;factorization of polynomials;matrix polynomial;reciprocal polynomial;polynomial remainder theorem;square-free polynomial;polynomial;algebra	PL	47.23109211682176	39.183500739640294	12011
2219893dfcd0c9a9c2769530de9898d6868ba25b	parasol and greenswitch: managing datacenters powered by renewable energy	datacenters;renewable energy;cost reduction;model based approach;scheduling;batteries;energy cost;carbon footprint;energy source;peak power;dynamic scheduling	"""Several companies have recently announced plans to build """"green"""" datacenters, i.e. datacenters partially or completely powered by renewable energy. These datacenters will either generate their own renewable energy or draw it directly from an existing nearby plant. Besides reducing carbon footprints, renewable energy can potentially reduce energy costs, reduce peak power costs, or both. However, certain renewable fuels are intermittent, which requires approaches for tackling the energy supply variability. One approach is to use batteries and/or the electrical grid as a backup for the renewable energy. It may also be possible to adapt the workload to match the renewable energy supply. For highest benefits, green datacenter operators must intelligently manage their workloads and the sources of energy at their disposal.  In this paper, we first discuss the tradeoffs involved in building green datacenters today and in the future. Second, we present Parasol, a prototype green datacenter that we have built as a research platform. Parasol comprises a small container, a set of solar panels, a battery bank, and a grid-tie. Third, we describe GreenSwitch, our model-based approach for dynamically scheduling the workload and selecting the source of energy to use. Our real experiments with Parasol, GreenSwitch, and MapReduce workloads demonstrate that intelligent workload and energy source management can produce significant cost reductions. Our results also isolate the cost implications of peak power management, storing energy on the grid, and the ability to delay the MapReduce jobs. Finally, our results demonstrate that careful workload and energy source management can minimize the negative impact of electrical grid outages."""	artificial intelligence;backup;chuck;data center;experiment;heart rate variability;mapreduce;power management;prototype;scheduling (computing)	Iñigo Goiri;William A. Katsak;Kien Le;Thu D. Nguyen;Ricardo Bianchini	2013		10.1145/2451116.2451123	renewable energy;data center;real-time computing;simulation;dynamic priority scheduling;computer science;operating system;scheduling;intermittent energy source	Arch	2.9769362225726375	6.265456080714978	12012
0a871a1e48bebd4cd60891cb9b6d41f4c4350eec	invertible boolean functions	boolean functions;input variables;boolean function;books;affine transformation;linear transformation;boolean functions books input variables;asymptotic approximation;lower bound	A Boolean function has an inverse when every output paper is followed by a correspondence by Ledley [7] is the result of one and only one input. There are 21! Boolean funcreferring to his two papers [8], [9] which solved the tions of n variables which have an inverse. Equivalence classes of problem stated in Rouche's paper. Subsequent to the these functions are sets of equivalent functions in the sense that they . . are identical under a group operation on the input and output work in Lorens [43] is Harrison's work [39]. variables. This paper counts through five variables the number of The first nontrivial application of group theory to equivalence classes of invertible Boolean functions under the group counting the number of Boolean functions was done by operation of complementation, permutation, and complementation Polya [10], [tt] and followed by Slepian's paper [12] and permutation, linear transformations and affine transformations. which is perhaps the most widely known. The applicaLower bounds are given which experimentally give an asymptotic tion of group theory to Boolean functions is treated in approximation. A representative function is given of each of the 52 classes of various forms by Ninomiya [13], McCluskey [14], invertible Boolean functions of three variables under complementaRyser [t5], Gilbert [16], Povarov [17], Smirnov [18], tion and permutation. These are divided into three types of classes, Nechiporuk [19] and Sagolovich [20]. A good reference 21 self-inverting functions, three functions have an inverse in the on group theory is Birkhoff and MacLane [2t] Rior same class and 14 pairs of functions, each function of the pair in a different class. The four representative functions under the affine dan's book [22] also treats the application of group transformation are self-invertible. theory to counting. Recently, Golomb [23]-[25] has published a series of papers which include some interINTRODUCTION esting cube coloring problems as well as material diA BOOLEAN FUNCTION has an inverse when rected at counting Boolean functions. The two papers every output is the result of one and only one inby Kautz [26] and Elspas [27] lead to another by put. The Boolean function F(xi, X2, x3) = (fi,J2,f3) Elspas [28] which introduces an application of group such that theory to counting the number of equivalence classes of fi = X1 self-complementing functions. More recently is Hellerman s tutorial paper [29], which contains some new ref2 = X2 (D X3 sults on the permutation group, and Harrison's work.	approximation;birkhoff interpolation;experiment;gilbert cell;golomb ruler;graph coloring;input/output;turing completeness	C. S. Lorens	1964	IEEE Trans. Electronic Computers	10.1109/PGEC.1964.263724	boolean algebra;and-inverter graph;combinatorics;circuit minimization for boolean functions;mathematical analysis;discrete mathematics;boolean network;boolean domain;boolean expression;product term;standard boolean model;maximum satisfiability problem;stone's representation theorem for boolean algebras;boolean algebras canonically defined;complexity index;mathematics;boolean function;complete boolean algebra;algorithm;two-element boolean algebra;parity function;algebra	Theory	41.83424156464285	39.94413759713054	12024
dc8d001cabf830b4acc2ee40232eb1f3c3bf647d	on vertex neighborhood in minimal imperfect graphs	perfect graph;bipartite graph	Lubiw [11] conjectures that in a minimal imperfect Berge graph, the neighborhood graph N (v) of any vertex v must be connected; this conjecture implies a well known Chvátal’s Conjecture [6] which states that N (v) must contain a P4. In this note we will prove an intermediary conjecture for some classes of minimal imperfect graphs. It is well known that a graph is P4-free if, and only if, every induced subgraph with at least two vertices either is disconnected or its complement is disconnected; this characterization implies that P4-free graphs can be constructed by complete join and disjoint union from isolated vertices. We propose to replace P4-free graphs by a similar construction using bipartite graphs instead of isolated vertices.	emoticon;graph (discrete mathematics);graph operations;induced subgraph	Vincent Barré	2001	Discrete Mathematics	10.1016/S0012-365X(00)00240-5	strong perfect graph theorem;1-planar graph;pathwidth;split graph;factor-critical graph;combinatorics;discrete mathematics;cograph;universal graph;independent set;topology;bipartite graph;perfect graph;pancyclic graph;forbidden graph characterization;graph coloring;symmetric graph;mathematics;distance-hereditary graph;modular decomposition;vertex-transitive graph;chordal graph;indifference graph;line graph;neighbourhood	Theory	28.928122484998465	28.756478427136514	12028
24a46fb24c702627209c6da3cab4b42dce7b0d80	an approximation algorithm for the stack-up problem	discrete algorithms;computational analysis;key words approximability;approximate algorithm;problem complexity;computer analysis	We consider the combinatorial stack-up problem motivated by stacking up bins from a conveyor onto pallets. The stack-up problem is to decide whether a given list q of labeled objects can be processed by removing step by step one of the ®rst s objects of q so that the following holds. After each removal there are at most p labels for which the ®rst object is already removed from q and the last object is still contained in q. We give some NPcompleteness results and we introduce and analyze a polynomial time approximation algorithm for the stack-up problem.	approximation algorithm;polynomial;stacking;time complexity	Jochen Rethmann;Egon Wanke	2000	Math. Meth. of OR	10.1007/s001860050085	computational problem;mathematical optimization;combinatorics;discrete mathematics;bin packing problem;mathematics	Theory	19.019264570533906	17.2363416675774	12037
2a787208b5d5b467dff3328bff772cab54b4d585	optimal dimensionality reduction of sensor data in multisensor estimation fusion	multisensor estimation fusion;eigenvalues and eigenfunctions;optimisation sous contrainte;constrained optimization;eigenvalue technique optimal dimensionality reduction sensor data multisensor estimation fusion communication bandwidth optimally precompress sensor outputs sensor observation linear minimum error variance criterion minimum dimension matrix decomposition pseudo inverse technique;minimum variance;minimum variance estimation;evaluation performance;multisensor;performance evaluation;variance minimale;evaluacion prestacion;variancia minima;optimal estimation;fusion capteur;data fusion;eigenvalues;eigenvalues and eigenfunctions sensor fusion matrix decomposition;reduction donnee;linear compression;eigenvalue;optimizacion con restriccion;descomposicion matricial;inverse matrix;fusion center;decomposition matricielle;sensor fusion bandwidth sensor systems performance loss propagation losses matrix decomposition eigenvalues and eigenfunctions mathematics computer science system performance;matrix decomposition;fusion donnee;matrice inverse;valor propio;reduccion datos;minimal variance;valeur propre;data reduction;estimation optimale;sensor fusion;fusion datos;matriz inversa;dimensional reduction;capteur multiple;multisensor estimation fusion linear compression minimum variance estimation;estimacion optima	When there exists the limitation of communication bandwidth between sensors and a fusion center, one needs to optimally precompress sensor outputs-sensor observations or estimates before the sensors' transmission in order to obtain a constrained optimal estimation at the fusion center in terms of the linear minimum error variance criterion, or when an allowed performance loss constraint exists, one needs to design the minimum dimension of sensor data. This paper will answer the above questions by using the matrix decomposition, pseudo-inverse, and eigenvalue techniques.	dimensionality reduction;lagrangian relaxation;sensor;the matrix;tracing (software)	Yunmin Zhu;Enbin Song;Jie Zhou;Zhisheng You	2005	IEEE Transactions on Signal Processing	10.1109/TSP.2005.845429	computer vision;mathematical optimization;constrained optimization;eigenvalues and eigenvectors;computer science;control theory;mathematics;sensor fusion;statistics	Robotics	50.11530400713934	6.99812602817879	12040
0554bd9b3691e4dfb0e618c084bc6fb4cbd03d43	smart grid volt/var management: challenges of integrating distribution dg	distributed power generation;voltage control;distributed system;power generation control;control systems;reactive power capacitors voltage control regulators substations impedance voltage measurement;impedance;voltage control control systems distributed generation energy management load management power distribution smart grid;power distribution control;smart grid;power distribution;control system;smart power grids;dg location function smart grid volt var management distribution system wm distributed generation sg system equipment intermittent loading effect mitigation dg control;power system management;capacitors;substations;load management;smart power grids distributed power generation power distribution control power generation control power system management;distributed generation;distributed generators;voltage measurement;regulators;energy management;reactive power	The optimum application of SMART GRID (SG) distribution system data will revolutionize the application and effectiveness of integrated distribution volt/var/kw management (VVM). One of the biggest challenges to SG distribution system VVM implementation is the application of distribution system distributed generation (DG)-especially the widespread and differing system voltage effects of the rapidly changing outputs of many DG types.	discontinuous galerkin method;smart;suicidegirls;veritas volume manager	E. Tom Jauch	2012	2012 IEEE PES Innovative Smart Grid Technologies (ISGT)	10.1109/ISGT.2012.6175775	control engineering;electronic engineering;engineering;electrical engineering	HPC	2.136054718126635	6.598415458076885	12063
5eb765dbd1ada6823c244284d97f7ae05d30e501	rankings of directed graphs	graph theory;grafo aciclico;coloracion grafo;teoria grafo;undirected ranking;coloration non oriente;tree;complexite calcul;05c05;np completeness;arbol;graphe acyclique;05c20;theorie graphe;acyclic graph;algorithme;algorithm;complejidad computacion;oriented graph;coloration graphe;ranking;computational complexity;directed graph;graph;coloration par entier positif;graphe oriente;05c85;borne inferieure;arbre;directed ranking;grafo orientado;lower bound;coloration oriente;graph colouring;cota inferior;algoritmo;05c15	A ranking of a graph is a coloring of the vertex set with positive integers such that on every path connecting two vertices of the same color there is a vertex of larger color. We consider the directed variant of this problem, where the above condition is imposed only on those paths in which all edges are oriented in the same direction. We show that the ranking number of a directed tree is bounded by that of its longest directed path plus one, and that it can be computed in polynomial time. Unlike the undirected case, however, deciding whether the ranking number of a directed (and even of an acyclic directed) graph is bounded by a constant is NP-complete. In fact, the 3-ranking of planar bipartite acyclic digraphs is already hard. ∗ Research supported in part by the Czech Research Grants GAUK 194 and GAČR 0194/1996. † Research supported in part by the Hungarian Scientific Research Fund, Grant OTKA T– 016416.	directed acyclic graph;directed graph;graph (discrete mathematics);graph coloring;path (graph theory);time complexity;vertex (graph theory)	Jan Kratochvíl;Zsolt Tuza	1999	SIAM J. Discrete Math.	10.1137/S0895480197330242	gallai–hasse–roy–vitaver theorem;combinatorics;discrete mathematics;feedback arc set;np-complete;directed graph;topology;feedback vertex set;longest path problem;ranking;graph theory;cycle graph;vertex;mathematics;tree-depth;tree;path;graph;upper and lower bounds;arborescence;computational complexity theory;reachability;topological sorting;directed acyclic word graph;strongly connected component;tournament;tree;directed acyclic graph;algorithm	Theory	20.918624431625837	26.90364958168083	12067
5b8d45da304f808496d5d609110d9912acc5dd4f	online, non-preemptive scheduling of equal-length jobs on two identical machines	workload;preemptive scheduling;execution time;gestion labor;competitividad;on line;en linea;online scheduling;preempcion;algorithme deterministe;approche deterministe;deadline;processing time;deterministic approach;deterministic algorithms;nomenclature;gestion tâche;scheduling;estructura datos;enfoque determinista;borne inferieure;charge travail;competitiveness;preemption;competitive analysis;temps traitement;algorithms;temps execution;en ligne;structure donnee;nomenclatura;task scheduling;date limite;tiempo ejecucion;carga trabajo;fechas ultimas;competitivite;data structure;tiempo proceso;online;ordonnancement;lower bound;reglamento;cota inferior;admission control	We consider the non-preemptive scheduling of two identical machines for jobs with equal processing times yet arbitrary release dates and deadlines. Our objective is to maximize the number of jobs completed by their deadlines. Using standard nomenclature, this problem is denoted as ${\it P}2 \mid {p_j = p,r_j} \mid {\sum \overline{U}_j}$. The problem is known to be polynomially solvable in an offline setting#R##N##R##N#In an online variant of the problem, a job's existence and parameters are revealed to the scheduler only upon that job's release date. We present an online, deterministic algorithm for the problem and prove that it is $\frac{3}{2}$-competitive. A simple lower bound shows that this is the optimal deterministic competitiveness		Michael H. Goldwasser;Mark Pedigo	2006		10.1007/11785293_13	real-time computing;data structure;computer science;distributed computing;preemption	Theory	16.617505593812812	11.0495822695605	12071
abb2fca9368ae387dac2a7c2802cf9db8f2a8a5e	efficient runtime support for embedded mpsocs	software runtime systems xilinx ml605 fpga board pragma based annotations task based programming model master embedded processor slave cores reconfigurable shared memory mpsoc lightweight runtime software framework reconfigurable embedded mpsoc automatic task assignment contemporary consumer electronic devices high performance academic processing platform;system on chip field programmable gate arrays scheduling shared memory systems;shared memory systems;system on chip;scheduling;runtime software hardware real time systems field programmable gate arrays processor scheduling programming;field programmable gate arrays;fpgas runtime support embedded mpsocs	Recently, many software runtime systems have been proposed that allow developers to efficiently map applications to contemporary consumer electronic devices and high-performance academic processing platforms. Most of these runtime systems employ advanced scheduling techniques for automatic task assignment to all available processing elements. However, they focus on a particular environment and architecture, and it is not easy to port them to reconfigurable embedded MPSoCs. As a consequence, in the embedded community, researchers implement hardwired application-specific task schedulers, which can not be used by other embedded MPSoCs. To address this problem, in this paper we propose a lightweight runtime software framework for reconfigurable shared-memory MPSoCs, that integrate a master embedded processor connected to slave cores. Similarly to many of the aforementioned advanced runtime systems, we adopt a task-based programming model that uses simple, pragma-based annotations of the application software, in order to dynamically resolve task dependencies. Our runtime system supports heterogeneity in the hardware resources, and is also low-overhead to account for possible limitations in their processing capabilities and available on-chip memory. To evaluate our proposal, we have prototyped an MPSoC with seven slaves to a Xilinx ML605 FPGA board. We run three micro-benchmarks that achieve a performance speedup of 3.8x, 7x and 5.8x, and energy consumption of 27%, 14% and 18% respectively, compared to a single-core baseline system with no runtime support.	baseline (configuration management);central processing unit;compiler;embedded system;field-programmable gate array;java;mpsoc;overhead (computing);programming model;runtime system;scheduling (computing);shared memory;single-core;software framework;speedup	Dimitris Theodoropoulos;Polyvios Pratikakis;Dionisios N. Pnevmatikatos	2013	2013 International Conference on Embedded Computer Systems: Architectures, Modeling, and Simulation (SAMOS)	10.1109/SAMOS.2013.6621119	computer architecture;parallel computing;real-time computing;computer science;runtime verification	EDA	-2.183232396269515	49.90407970757783	12075
b3f42f7365fedb9aa639437eb10b975090029e37	"""erratum to: """"high-speed systolic architectures for finite field inversion"""" [integration 38(3) (2005) 383-398]"""	finite field;cryptography;finite field arithmetic;galois field;high speed	The architecture with distributed control described in this paper does not work as claimed. The correct details are provided in this note.		Zhiyuan Yan;Dilip V. Sarwate;Zhongzhi Liu	2006	Integration	10.1016/j.vlsi.2005.04.002	finite field arithmetic;discrete mathematics;cryptography;theoretical computer science;mathematics;factorization of polynomials over finite fields;finite field;algebra	EDA	44.05712368633334	39.872577935279104	12078
2aa07bcc05f125d06402c599e1ba06cf997074b1	an asynchronous architecture for modeling intersegmental neural communication	vlsi architecture address event representation aer asynchronous circuits central pattern generator cpg neurobiological modeling neuromorphic engineering silicon neuron;estensibilidad;modelizacion;data transmission;intersegmental neural communication modeling;address event representation aer;module multipuce;protocols;neurobiological;aer;spiking envelopes;arquitectura circuito;biological system modeling biological systems very large scale integration communication networks neuromorphics protocols data communication asynchronous circuits circuit synthesis network synthesis;communication networks;network synthesis;protocole transmission;integrated circuit;logic design;neural nets;vlsi neural nets asynchronous circuits integrated circuit design logic design;naturvetenskap;neuromorphics;very large scale integration;modulo multipulga;burst envelopes intersegmental neural communication modeling asynchronous vlsi architecture oscillatory patterns segmented biological systems intersegmental synaptic connectivity communications network address event representation neuromorphic protocol data transmission asynchronous circuits communicating hardware processes multichip communication silicon neuron spiking envelopes;biological system modeling;circuit vlsi;circuit architecture;circuito integrado;neurobiological modeling;data communication;asynchronous circuit;segmented biological systems;modelisation;prototipo;address event representation;natural sciences;integrated circuit design;protocolo transmision;multichip module;vlsi circuit;circuit asynchrone;intersegmental synaptic connectivity;communications network;community networks;transmission donnee;architecture circuit;vlsi;central pattern generator cpg;biological systems;circuito asincrono;asynchronous circuits;circuits;extensibilite;scalability;central pattern generator;circuito vlsi;silicon neuron;reseau neuronal;neuromorphic protocol;multichip communication;modeling;neuromorphic engineering;asynchronous vlsi architecture	This paper presents an asynchronous VLSI architecture for modeling the oscillatory patterns seen in segmented biological systems. The architecture emulates the intersegmental synaptic connectivity observed in these biological systems. The communications network uses address-event representation (AER), a common neuromorphic protocol for data transmission. The asynchronous circuits are synthesized using communicating hardware processes (CHP) procedures. The architecture is scalable, supports multichip communication, and operates independent of the type of silicon neuron (spiking or burst envelopes). A 16-segment prototype system was developed, tested, and implemented; data from this system are presented.	addressing scheme;asynchronous circuit;biological system;central pattern generator;emulator;neuromorphic engineering;neuron;offset (computer science);prototype;scalability;synapse;synaptic package manager;telecommunications network	Girish N. Patel;Michael S. Reid;David E. Schimmel;Stephen P. DeWeerth	2006	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2005.863762	embedded system;electronic engineering;real-time computing;computer science;electrical engineering;theoretical computer science;very-large-scale integration;artificial neural network	HPC	17.797807504134877	40.30022638939732	12081
616b185ca869dcb0588b9e12be19e3f236261bd2	an addressable machine as the interpretation of a free group	free group	Abstract   In this paper we propose a combinatorial approach to the study of addressable machines. As a consequence of such an approach the set of instructions defining our machine is the union of the set of the generators of a free group and of the set of their inverses together with the identity. Moreover the elements of the free group are the programs of the machine and are obtained as the representatives of the equivalence classes containing their execution sequences.		Francesco E. Lauria	1982	Inf. Sci.	10.1016/0020-0255(82)90022-6	combinatorics;discrete mathematics;computer science;free group;mathematics;algorithm	AI	41.22866998959068	30.74407092359362	12104
f881668628a4b4f66cd1e0a55fc281206fb53c1d	the polytope-collision problem		The Orbit Problem consists of determining, given a matrix A ∈ Rd×d and vectors x, y ∈ R, whether there exists n ∈ N such that A = y. This problem was shown to be decidable in a seminal work of Kannan and Lipton in the 1980s. Subsequently, Kannan and Lipton noted that the Orbit Problem becomes considerably harder when the target y is replaced with a subspace of R . Recently, it was shown that the problem is decidable for vector-space targets of dimension at most three, followed by another development showing that the problem is in PSPACE for polytope targets of dimension at most three. In this work, we take a dual look at the problem, and consider the case where the initial vector x is replaced with a polytope P1, and the target is a polytope P2. Then, the question is whether there exists n ∈ N such that AP1 ∩ P2 6= ∅. We show that the problem can be decided in PSPACE for dimension at most three. As in previous works, decidability in the case of higher dimensions is left open, as the problem is known to be hard for long-standing number-theoretic open problems. Our proof begins by formulating the problem as the satisfiability of a parametrized family of sentences in the existential first-order theory of real-closed fields. Then, after removing quantifiers, we are left with instances of simultaneous positivity of sums of exponentials. Using techniques from transcendental number theory, and separation bounds on algebraic numbers, we are able to solve such instances in PSPACE. 1998 ACM Subject Classification F.2.2 Nonnumerical Algorithms and Problems, I.1.2 Algorithms	algorithm;collision problem;first-order logic;first-order predicate;linear algebra;pspace;theory	Shaull Almagor;Joël Ouaknine;James Worrell	2017		10.4230/LIPIcs.ICALP.2017.24	combinatorics;discrete mathematics;mathematics;algorithm	Theory	15.244263208879277	20.268940151127534	12107
c86c15720cc6f6d90e73d003f507d0a4edfa0ad2	dot-product engine as computing memory to accelerate machine learning algorithms	memristor;machine learning memristor dot product operation crossbar computing memory;computing memory;memristors resistance wires programming machine learning algorithms algorithm design and analysis degradation;crossbar;machine learning;vectors learning artificial intelligence mathematics computing matrix multiplication memristors;software level accuracy machine learning algorithms memristor crossbar arrays nonvolatile memory applications memristor crossbars natural dot product operation vectors next generation computing neuromorphic computing heterogeneous computing dot product engine dpe dense matrix computation software trained weight matrices asic;dot product operation	Currently, intense work is underway to develop memristor crossbar arrays for high density, nonvolatile memory applications. However, another capability of memristor crossbars - natural dot-product operation for vectors and matrices - holds even greater potential for next-generation computing, including accelerators, neuromorphic computing, and heterogeneous computing. In this paper, we present a dot-product engine (DPE) based on memristor crossbars optimized for dense matrix computation, which is dominated in most machine learning algorithms. We explored multiple methods to enhance DPE's dot-product computing accuracy. Moreover, instead of training crossbars, we try to directly use existing software-trained weight matrices on DPEs so no heroic effort is needed to innovate learning algorithms for new hardware. Our results show that computations utilizing DPEs can achieve 1000 ~ 10000 times better speed-efficiency product comparing to a state-of-art ASIC [1]. And machine learning algorithm utilizing DPEs can easily achieve software-level accuracy on testing. Both experimental demonstrations and data-calibrated circuit simulations are presented to demonstrate the realistic implementation of a memristor crossbar DPE.	algorithm;application-specific integrated circuit;computation;crossbar switch;heterogeneous computing;machine learning;memristor;multiply–accumulate operation;neuromorphic engineering;nonvolatile bios memory;numerical linear algebra;simulation;sparse matrix	Miao Hu;John Paul Strachan;Zhiyong Li;R. Stanley Williams	2016	2016 17th International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2016.7479230	embedded system;electronic engineering;parallel computing;memristor;computer science;memistor;theoretical computer science;crossbar switch	Arch	4.067480485461242	42.250861575557494	12112
1c17f6ab76a32648cd84c8eef2e47045e8379310	fast kernels for string and tree matching	time complexity;natural language processing;linear time;string kernel	In this chapter we present a new algorithm suitable for matching discrete objects such as strings and trees in linear time, thus obviating dynamic programming with quadratic time complexity. This algorithm can be extended in various ways to provide linear time prediction cost in the length of the sequence to be classified. We demonstrate extensions in the case of position dependent weights, sliding window classifiers for a long sequence, and efficient algorithms for dealing with weights given in the form of dictionaries. This improvement on the currently available algorithms makes string kernels a viable alternative for the practitioner.	approximate string matching;automata theory;computation;dictionary;dynamic programming;dynamical system;finite-state machine;kernel (operating system);string searching algorithm;time complexity;unbalanced circuit;wildcard character	S. V. N. Vishwanathan;Alexander J. Smola	2002			approximate string matching;commentz-walter algorithm;bk tree;string searching algorithm	ML	13.078326953828066	27.74919554733789	12119
a711b3135e71abb0ffda8c6918e875a03c52fab6	oriented interval greedoids	sphericity theorem;oriented matroid;cw sphere;simplicial complex;interval greedoid;antimatroid;convex geometry;oriented matriod	We propose a definition of an oriented interval greedoid that simultaneously generalizes the notion of an oriented matroid and the construction on antimatroids introduced by L. of oriented matroids, associated to each oriented interval greedoid is a spherical simplicial complex whose face enumeration depends only on the underlying interval greedoid.	greedoid;matroid;simplicial complex	Franco Saliola;Hugh Thomas	2012	Discrete & Computational Geometry	10.1007/s00454-011-9383-3	convex geometry;combinatorics;discrete mathematics;topology;oriented matroid;mathematics;geometry;simplicial complex	Theory	37.153821400787386	24.985821117859576	12130
085ebc9bc0fdab4ff19ca39b3c19959cf5c41a9a	faster sorting and routing on grids with diagonals	parallel algorithm	We study routing and sorting on grids with diagonal connections. We show that for so-called h-h problems faster solutions can be obtained than on comparable grids without diagonals. In most of the cases the number of transport steps for the new algorithms are less than half the on principle smallest number given by the bisection bound for grids without diagonals.	algorithm;routing;sorting	Manfred Kunde;Rolf Niedermeier;Peter Rossmanith	1994		10.1007/3-540-57785-8_144	computer science;mathematics;distributed computing;parallel algorithm	Theory	13.82593422835711	32.393337428580885	12131
4f3088c27084ec5456599b08c7325b959e362a19	on choice sets and strongly non-trivial self-embeddings of recursive linear orders	linear order	In [1) DUSHNIK and MILLER prove that every countably infinite linear oder has a non-trivial se]f-embedding. The first part of their argument considers linear orders with an interval of type w orw*. Mapping x to its immediate successor (resp. predecessor) if x is in this interval and the interval is of type w (resp. w*), and to itself otherwise, produces the required non-trivial se]f-embedding. The existence of a~ interval of type w* + w would similarly guarantee a non-trivial automorphism.	graph automorphism;recursion (computer science)	Rodney G. Downey;Michael F. Moses	1989	Math. Log. Q.	10.1002/malq.19890350307	topology;mathematics;total order	Logic	38.7553286593922	29.29513746966484	12144
1206d90d8d261a211c6814bd635aaaaff4cd7e4e	optimal message routing without complete routing tables	shortest path;network topology;optimal algorithm	1. I n t r o d u c t i o n A basic activity in a distributed network is the routing of messages between pairs of nodes. Assuming a cost function on the edges of the network, it is desirable that the routing of each message be along a shortest path. A straightforward approach is to maintain a complete routing table at each of the n nodes, which gives for each potential destination the name of the next node on a shortest path to the destination. This approach * This research was supported in part by the National Science Foundation under grant DCR-8320124. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specfic permission. requires that n 1 items of routing information be stored at each node in the network, with each item being a node name. If the network is dense and of irregular topology, then one would not expect to be able to do appreciably better spacewise than using complete routing tables. However, for sparse networks, is it possible to maintain o(n 2) items of routing information in the network and still achieve shortest path routings? We examine this question in the context of being free to assign logn-bit names to the nodes. We present a node naming and routing scheme that can handle broad classes of networks with arbitrary nonnegative costs on the edges. The scheme groups networks, starting with the class of outerplanar networks, into a natural hierarchy based on the amount of space devoted to storing routing information. Shortest path routing schemes for tree and unit-cost ring networks have been presented in [SKI and later in [vLT1]. The nodes are assigned names from 1 to n, and the end of every edge {v, w} incident with any node v is labelled with a subinterval of [1,hi. The interval represents the set R.,~ of nodes such that there is a shortest path from v to each node in Rv,w with the first edge on this path being {v, w}. In [vLW2] interval labelling schemes are also given for certain highly regular networks with edges of unit cost, including complete graphs, complete bipartite graphs, and grids. We first give an interval labelling scheme for outerplanar networks with arbitrary nonnegative costs on the edges. The scheme stores just d + 1 items of routing information at every node v, of degree d. Thus O(n) items of routing information are stored in total. For arbitrary nonnegative © 1986 ACM 0-89791-198-9/86/0800-0088 75¢ as edge costs, we show that the outerplanar graphs are precisely the graphs for which such an interval property holds. Furthermore we establish a very nice 'reflection' property of outerplanar graphs. Using this property we are able to generate an optimal algorithm for determining the labels of all edges. In [vLT2] a k-interval labelling scheme is proposed, in which each edge is labeled with up to k intervals. It is shown in [vLT2] that a grid with rowand column-wraparound and unit costs has an optimal 2-interval labelling. We present an incomparable but still stronger result, in that it is applicable to graphs with arbitrary nonnegative edge costs. We show that k-interval labelling schemes, for k > 1, can handle classes of graphs much richer than the class of outerplanar graphs. In particular, we establish that any graph that can be embedded in the plane such that all but q of the vertices are on p faces has a [(3p + q)/2J-interval property. Alternatively, the number of items of routing information required at a node of degree d is at most 3p+q+d-2. If the p faces form s connected components, we show that the graph has a [(2p + s + q)/2J-interval labelling, with a total of at most 2p+ s + q+ d 2 intervals at any node. Our approach can also be applied to graphs that can be embedded on a surface of positive genus g. We show that such graphs possess a [ (2p+ s + q + 4g)/2J-interval labelling, and use a total of at most 2p + s + q + 4g + d 2 intervals at any node. In addition, our labelling scheme can be adapted naturally to planar graphs in which we wish to route messages to vertices on only a selected subset of the faces. This technique can then be applied in a scheme for near-shortest path routings in general planar graphs IF J]. 2. R o u t i n g in o u t e r p l a n a r n e t w o r k s We first summarize the interval routing method presented in [SKI for trees and rings. Assume that the nodes are named in an appropriate manner with the integers from 1 to n. Let v be any node, and let the degree of v be d. Each edge incident with v is labelled by an interval, with the intervals from all edges incident with v forming a partition of [1, hi v. Wraparound is allowed in the intervals. For instance, the interval [ i , j ) , i > j , contains { i , i+ 1, . . . ,n, 1 , . . . , j 1}. Denote the intervals by [li, l~+x), for i = 1, 2 , . . . , d, where ld+l = v. Without loss of generality, assume that interval [/,,/,+1) labels edge {v,w,}. The values li, i = 1 ,2 , . . . ,d, are stored in a table at node v, each with a pointer to associated edge {v, wi). When a message arrives at node v, if its destination u is not equal to v, then the table is searched for the entry li such that li _< u < li+l. The message is then sent out on edge {v, wi). Since the values li, i = 1, 2 , . . . , d + 1 form a rota ted list [MS, F2], the table can be searched in O(log d) time using a modified binary search. The interval labelling method also works for outerplanar networks if the nodes are named appropriately. An outerplanar network is a network that can be embedded in the plane such that all nodes lie on one face [H]. Throughout the paper, we consider outerplanar networks in the context of such an embedding, called an outerplane embedding. We assign as names to the nodes the integers from 1 to n in consecutive order starting at an arbi trary node and proceeding clockwise around the exterior face. If any node v is visited more than once in this traversal, i.e., v is an articulation point of the network, then v may be named on any one of the visits. We call such a naming of the nodes a suitable node naming. An outerplanar network with a suitable node naming is shown in Figure 1. We first show that for any assignment of costs to edges, each end of every edge can be labelled with an interval such that routing is along shortest paths. Such a labelling of the edges of the network of Figure 1 is shown	apollonian network;biconnected component;binary search algorithm;embedded system;genus (mathematics);google+;loss function;norm (social);outerplanar graph;planar graph;pointer (computer programming);routing table;shortest path problem;sparse matrix;tree traversal;wraparound (video games)	Greg N. Frederickson;Ravi Janardan	1986		10.1145/10590.10598	policy-based routing;private network-to-network interface;wireless routing protocol;routing table;mathematical optimization;routing;enhanced interior gateway routing protocol;static routing;hierarchical routing;constrained shortest path first;zone routing protocol;equal-cost multi-path routing;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;distributed computing;routing protocol;link-state routing protocol;shortest path problem;path vector protocol;geographic routing;k shortest path routing;network topology;routing information protocol;computer network	Theory	21.058708748918765	33.50978446464365	12145
585d36f2f76c44b0306e18f5970577bc555d1a29	symmetric rendezvous with advice: how to rendezvous in a disk		In the classic Symmetric Rendezvous problem on a Line (SRL), two robots at known distance 2 but unknown direction execute the same randomized algorithm trying to minimize the expected rendezvous time. A long standing conjecture is that the best possible rendezvous time is 4.25 with known upper and lower bounds being very close to that value. We introduce and study a geometric variation of SRL that we call Symmetric Rendezvous in a Disk (SRD) where two robots at distance 2 have a common reference point at distance ρ. We show that even when ρ is not too small, the two robots can meet in expected time that is less than 4.25. Part of our contribution is that we demonstrate how to adjust known, even simple and provably non-optimal, algorithms for SRL, effectively improving their performance in the presence of a reference point. Special to our algorithms for SRD is that, unlike in SRL, for every fixed ρ the worst case distance traveled, i.e. energy that is used, in our algorithms is finite. In particular, we show that the energy of our algorithms is O ( ρ ) , while we also explore time-energy tradeoffs, concluding that one may be efficient both with respect to time and energy, with only a minor compromise on the optimal termination time.	average-case complexity;best, worst and average case;randomized algorithm;robot	Konstantinos Georgiou;Jay Griffiths;Yuval Yakubov	2018		10.1007/978-3-030-01325-7_14	rendezvous problem;robot;combinatorics;mathematics;discrete mathematics;conjecture;rendezvous;randomized algorithm;upper and lower bounds	Theory	16.586588671275287	16.605522093251356	12150
a9bb77a7f67fa0cc21ea5ff1a160e6288febcce2	efficiently decodable codes meeting gilbert-varshamov bound for low rates	quasimonotone permutations;rectangular partitions;guillotine partitions;polynomial time algorithm;baxter permutations;schroder numbers;linear code	We demonstrate a probabilistic construction of binary linear codes meeting the GV bound (with overwhelming probability) for rates up to about 10-4 together with polynomial time algorithms to perform encoding and decoding up to half the distance. The only previous result of this type (for rates up to about 0.02) suffered from sub-exponential time decoding [3].	algorithm;code;gilbert–varshamov bound;polynomial;time complexity	Venkatesan Guruswami;Piotr Indyk	2004			combinatorics;discrete mathematics;linear code;mathematics;algorithm;statistics	Theory	37.83488730496551	55.48825475660879	12157
560a0eda159ba21dd77d35a5d7609b68023fd33d	decoding characteristics of d/a converters based on spiking neurons	a d converter;spiking neurons	This paper studies spike-based D/A converters and effects of a control parameter on the worst error for the encoding. First, we introduce spike-based A/D converters and analyze their dynamics through 1-D linear map. Next, we present spike-based D/A converters whose architectures is based on inverse operation of the A/D converters. We consider effects of a parameter for decoding function. A simple circuit model of the D/A converter is also presented.		Masao Takiguchi;Toshimichi Saito	2009		10.1007/978-3-642-10677-4_13	computer science;theoretical computer science	ML	44.57995553666531	58.47781025914871	12170
60e3a7a1801bf423516a3413949485ae4af6c449	reduce 3.2 on iapx 86/286-based personal computers	286-based personal computer;process capability	An implementation of de facto standard algebraic system into personal computers and its performance measurements were shown. Of course, this implementation has major limitation of small data space, however its algebraic processing capability is very close to 32 bit machine's one. We hope that our implementation could boost the population of algebraic system user in many fields where the cost of such system was too expensive.	personal computer;reduce	Tsuyoshi Yamamoto;Yoshinao Aoki	1987		10.1007/3-540-51517-8_101	embedded system;computer hardware;computer science;computer engineering	NLP	1.4266203631798562	44.5158157533025	12173
0723de26c66dde59a654e7812790b4dbe42781c8	simultaneous matchings	decision problem;corresponding optimisation problem;bipartite graph;constraint programming;k subsets;c-perfect matching;x-perfect matching;subseteq x;simultaneous matchings;x-perfect matching problem;subset m	Given a bipartite graph G = (X ∪̇ D, E ⊆ X × D), an Xperfect matching is a matching in G that saturates every node in X. In this paper we study the following generalisation of the X-perfect matching problem, which has applications in constraint programming: Given a bipartite graph as above and a collection F ⊆ 2 of k subsets of X, find a subset M ⊆ E of the edges such that for each C ∈ F , the edge set M ∩ (C × D) is a C-perfect matching in G (or report that no such set exists). We show that the decision problem is NP-complete and that the corresponding optimisation problem is in APX when k = O(1) and even APX-complete already for k = 2. On the positive side, we show that a 2/(k + 1)-approximation can be found in O(2poly(k, |X ∪ D|)) time.	apx;constraint programming;decision problem;matching (graph theory);mathematical optimization;np-completeness	Khaled M. Elbassioni;Irit Katriel;Martin Kutz;Meena Mahajan	2005		10.1007/11602613_12	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	24.282608231790814	23.17684208737986	12175
c78a0b5d7262f160f7ff76da34436130196d86d0	evolfir: evolving redundancy-free fir structures	attribute grammars;redundancy free design;finite impulse response structures;genetic program;finite impulse response filter design optimization constraint optimization hardware digital filters genetic programming delay chip scale packaging logic design engines;fir structures;search space;tree representation form;trees mathematics fir filters genetic algorithms;trees mathematics;attribute grammar;digital filter;evolfir system;finite impulse response;derivation tree based genetic programming;digital filters;genetic algorithms;fir filters;tree representation form evolfir system fir structures finite impulse response structures digital filters redundancy free design attribute grammars derivation tree based genetic programming;everyday life	Finite impulse response (FIR) structures are the most commonly used digital filters and can be found in various areas of everyday life. In this paper a novel approach is proposed to optimize the redundancy-free design of such filter structures. Relying on attribute grammars and derivation-tree based genetic programming, the evolFIR system can restrict the search space to exactly those filter descriptions which are fully compliant to all specified constraints. Furthermore, due to the sophisticated tree representation form, the resulting filter descriptions are not only valid, but also free of redundancy.	algorithm;attribute grammar;digital filter;finite impulse response;genetic programming;parallel computing;parse tree;physical design (electronics);redundancy (engineering);requirement;transfer function;tree (data structure);tree traversal;turned a;virtex (fpga)	Szilvia Zvada;Gabriella Kókai;Róbert Ványi;Hans Holm Frühauf	2007	Second NASA/ESA Conference on Adaptive Hardware and Systems (AHS 2007)	10.1109/AHS.2007.50	adaptive filter;digital filter;computer science;electrical engineering;theoretical computer science;machine learning;finite impulse response;algorithm	EDA	11.8411854272614	49.654749444756774	12196
c5e4414e3bb4a359e8c4043db410d0f73c0cf3d1	two-spinors, oscillator algebras, and qubits: aspects of manifestly covariant approach to relativistic quantum information	lie algebra;quantization;oscillations;qubits;sl 2;quantum information;electromagnetic field;irreducible representation;spectral properties;c;two spinors;sl 2 c;minkowski space;unitary representation;harmonic oscillator	The first part of the paper reviews applications of 2-spinor methods to relativistic qubits (analogies between tetrads in Minkowski space and 2-qubit states, qubits defined by means of null directions and their role for elimination of the Peres-Scudo-Terno phenomenon, advantages and disadvantages of relativistic polarization operators defined by the Pauli-Lubanski vector, manifestly covariant approach to unitary representations of inhomogeneous SL(2,C)). The second part deals with electromagnetic fields quantized by means of harmonic oscillator Lie algebras (not necessarily taken in irreducible representations). As opposed to non-relativistic singlets one has to distinguish between maximally symmetric and EPR states. The distinction is one of the sources of `strange' relativistic properties of EPR correlations. As an example, EPR averages are explicitly computed for linear polarizations in states that are antisymmetric in both helicities and momenta. The result takes the familiar form ±p cos 2(? ? β) independently of the choice of representation of harmonic oscillator algebra. Parameter p is determined by spectral properties of detectors and the choice of EPR state, but is unrelated to detector efficiencies. Brief analysis of entanglement with vacuum and vacuum violation of Bell's inequality is given. The effects are related to inequivalent notions of vacuum states. Technical appendices discuss details of the representation I employ in field quantization. In particular, M-shaped delta-sequences are used to define Dirac deltas regular at zero.	quantum information;qubit;spinor	Marek Czachor	2010	Quantum Information Processing	10.1007/s11128-010-0163-4	lie algebra;quantum information;minkowski space;irreducible representation;electromagnetic field;quantization;harmonic oscillator;pure mathematics;mathematics;qubit;oscillation;physics;quantum mechanics;algebra	HPC	50.88121886106699	21.761555861207075	12197
3d72321f92b4c1835992c287d8bf4fdae0fe6ec9	on cycle lengths in claw-free graphs with complete closure	graphe infini;claw free graph;closure;combinatorics;mathematiques discretes;graphe sans griffe;matematicas discretas;combinatoria;combinatoire;discrete mathematics;pancyclicity;graph connectivity;infinite graph;cycle graphe;conectividad grafo;grafo infinito;cycle graph;cerradura;cycle length;connectivite graphe;fermeture;ciclo diagrama	We show a construction that gives an infinite family of claw-free graphs of connectivity κ = 2, 3, 4, 5 with complete closure and without a cycle of a given fixed length. This construction disproves a conjecture by the first author, A. Saito and R.H. Schelp.	claw-free graph;claw-free permutation;itakura–saito distance	Zdenek Ryjácek;Zdzislaw Skupien;Petr Vrána	2010	Discrete Mathematics	10.1016/j.disc.2009.03.053	claw-free graph;combinatorics;discrete mathematics;topology;connectivity;cycle graph;closure;mathematics	Theory	26.59927738367449	32.21330062601165	12200
d5c591d9414557a8fae1a185ed68d1ec99683d2f	concrete multiplicative complexity of symmetric functions	parite;fonction booleenne;fractals;puerta logica;complexite calcul;symmetric function;hamming weight;coefficient binomial;funcion simetrica;clase complejidad;fonction symetrique;boolean function;parity;binary number;porte logique;complejidad computacion;numero binario;hamming distance;classe complexite;complexity class;computational complexity;close relationships;funcion booliana;informatique theorique;distance hamming;coeficiente binomial;fractal;paridad;fractale;binomial coefficient;logic gate;distancia hamming;computer theory;nombre binaire;informatica teorica	The multiplicative complexity of a Boolean function f is defined as the minimum number of binary conjunction (AND) gates required to construct a circuit representing f , when only exclusive-or, conjunction and negation gates may be used. This article explores in detail the multiplicative complexity of symmetric Boolean functions. New techniques that allow such exploration are introduced. They are powerful enough to give exact multiplicative complexities for several classes of symmetric functions. In particular, the multiplicative complexity of computing the Hamming weight of n bits is shown to be exactly n−HN(n), where HN(n) is the Hamming weight of the binary representation of n. We also show a close relationship between the complexity of symmetric functions and fractals derived from the parity of binomial coefficients.	binary number;coefficient;exclusive or;fractal;hamming weight;window function	Joan Boyar;René Peralta	2006		10.1007/11821069_16	combinatorics;discrete mathematics;fractal;multiplicative order;complexity index;mathematics;algorithm	Theory	6.453371412101676	23.42962877493336	12229
21e21a991a1b501dfd11a1dcf0bc01d7dd2ee079	adaptive precision lll and potential-lll reductions with interval arithmetic		Lattice reduction is fundamental in computational number theory and in computer science, especially in cryptography. The celebrated Lenstra–Lenstra–Lovász reduction algorithm (called LLL or L) has been improved in many ways through the past decades and remains one of the central tool for reducing lattice basis. In particular, its floating-point variants — where the long-integer arithmetic required by Gram–Schmidt orthogonalization is replaced by floating-point arithmetic — are now the fastest known. Yet, the running time of these floating-point versions is mostly determined by the precision needed to perform sound computations: theoretical lower bounds are large whereas the precision actually needed on average is much lower. In this article, we present an adaptive precision version of LLL and one of its variant Potential-LLL. In these algorithms, floating-point arithmetic is replaced by Interval Arithmetic. The certification property of interval arithmetic enables runtime detection of precision defects in numerical computations and accordingly, makes it possible to run the reduction algorithms with guaranteed nearly optimal precision. As such, these adaptive reduction algorithms run faster than the state-of-the-art implementations, while still being provable.	arjen lenstra;computation;computational number theory;computer science;cryptography;fastest;integer (computer science);interval arithmetic;lattice reduction;lenstra–lenstra–lovász lattice basis reduction algorithm;numerical analysis;provable security;schmidt decomposition;time complexity	Thomas Espitau;Antoine Joux	2016	IACR Cryptology ePrint Archive		interval arithmetic;statistics;mathematics	Crypto	12.186110795475921	23.09084341986177	12239
617602c7e231ff3adef07e26936c277940f0d05a	fuzzy scheduling on two-machine flow shop	two-machine flow shop;johnson algorithm;processing time;fuzzy johnson algorithm;processing time membership function;uncertain scheduling;final completion time;scheduling result;fuzzy concept;job processing time;conventional johnson algorithm;fuzzy scheduling	Scheduling consists mainly of allocating resources to jobs over time under necessary constraints. In the past, the processing time for each job was usually assigned or estimated as a fixed value. In many real-world applications, however, job processing time may vary dynamically with the situation. In this paper, fuzzy concepts are applied to Johnson algorithm for managing uncertain scheduling. Given a set of jobs, each having two tasks that must be executed on two machines, and their processing time membership functions, the fuzzy Johnson algorithm can yield a scheduling result with a membership function for the final completion time, thus helping managers gain a broader overall view of scheduling. Also, the conventional Johnson algorithm is shown as a special case of the fuzzy Johnson algorithm with special membership functions being assigned. The fuzzy Johnson algorithm is thus a feasible solution for both deterministic and uncertain scheduling.	scheduling (computing)	Tzung-Pei Hong;Tzung-Nan Chuang	1998	Journal of Intelligent and Fuzzy Systems		fair-share scheduling;real-time computing;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;artificial intelligence;fuzzy number;genetic algorithm scheduling;two-level scheduling;least slack time scheduling;round-robin scheduling	Robotics	12.779364866454687	7.10003200787122	12242
3dd900b0c8449b97842b8cfefeb13e9c105e02c4	maximum likelihood bounded tree-width markov networks	performance guarantee;entropy decomposition;approximate algorithm;maximum likelihood;undirected graphical models;combinatorial optimization problem;markov random fields;tree width;hardness;markov random field;markov network;graphical model;hyper trees;markov networks	We study the problem of projecting a distribution onto (or finding a maximum likelihood distribution among) Markov networks of bounded tree-width. By casting it as the combinatorial optimization problem of finding a maximum weight hypertree, we prove that it is NP-hard to solve exactly and provide an approximation algorithm with a provable performance guarantee.	approximation algorithm;combinatorial optimization;markov chain;markov random field;mathematical optimization;np-hardness;optimization problem;provable prime;treewidth	Nathan Srebro	2001		10.1016/S0004-3702(02)00360-0	variable elimination;markov chain;mathematical optimization;maximum-entropy markov model;markov kernel;combinatorics;discrete mathematics;expectation–maximization algorithm;markov property;continuous-time markov chain;examples of markov chains;balance equation;machine learning;markov blanket;mathematics;markov renewal process;additive markov chain;maximum likelihood;graphical model;markov algorithm;markov process;markov chain mixing time;markov model;treewidth;hardness;hidden markov model;variable-order markov model	ML	34.052591099248126	7.106669700322676	12249
6ed71f44e2bc6f185dc553db337c182c9513e185	k-pair delay constrained minimum cost routing in undirected networks	undirected network;si-ti path;k-pair delay;minimum cost network;ith source node;k-pair routing request;minimum cost routing;ith destination node;ith delay tolerance;manufacturing;covering;approximation algorithms;np completeness	We study a problem related to QoS routing in an undirected network where each edge has a <i>delay</i> and a <i>cost</i>. Given a <i>k</i>-pair routing request {(<i>s<subscrpt>i</subscrpt></i>, <i>t<subscrpt>i</subscrpt></i>, <i>d<subscrpt>i</subscrpt></i>)¦<i>i</i> = l,…,<i>k</i>} where <i>s<subscrpt>i</subscrpt></i> is <i>i</i>th <i>source node</i>, <i>t<subscrpt>i</subscrpt></i> is <i>i</i>th <i>destination node</i>, and <i>d<subscrpt>i</subscrpt></i>, is the <i>i</i>th <i>delay tolerance</i>, we want to compute a minimum cost network which contains an <i>s<subscrpt>i</subscrpt></i>-<i>t<subscrpt>i</subscrpt></i> path whose delay is at most <i>d<subscrpt>i</subscrpt></i> for every <i>i</i>. We present an FPTAS for this problem when <i>k</i> is a constant.	graph (discrete mathematics);polynomial-time approximation scheme;quality of service;routing	Guangting Chen;Guoliang Xue	2001				Theory	23.30315872518319	18.625024702727117	12259
ce837ab8694b6f5c79cec7684633d47dbcc5b290	hardware implementation of a sub-pixel algorithm for real-time saw blade deflection monitoring	dispositivo carga acoplada;field programmable gate array;centre of gravity;charge coupled device;algorithm performance;technologie puce sur verre;diminution cout;chip on glass packaging;imageur;implementation;efficient algorithm;real time;imager;fpga;red puerta programable;reseau porte programmable;dispositif ccd;algorithme;captador medida;algorithm;measurement sensor;integrated circuit bonding;capteur mesure;ccd;resultado algoritmo;assemblage circuit integre;performance algorithme;horloge;tecnologia cog;laser triangulation sensor;0707d;implementacion;reduccion costes;clock;high speed;hardware implementation;cost lowering;reloj;algoritmo	Deflections of saw blades during timber sawing process due to tension loss lead to downgrading and value loss of timber. In this paper a CCD-type laser triangulation sensor is used to monitor the saw blade deflections. Deflections monitoring has to be done in real-time which compels the necessity to use efficient algorithm with low computational cost. High speed algorithm that makes use of an approximated centre of gravity (COG) and an overall peak-to-peak amplitude methods has been designed and implemented in a Field Programmable Gate Array (FPGA). The approximated COG method tracks the position of the saw blade in real-time. It generates results at 7000 frames/s at the sensor's maximum clock rate of 2 MHz. It also provides a sub-pixel resolution of 1/8 pixel. The overall peak-to-peak amplitude method determines the deflection level of the saw blade based on its recorded positions. Both methods are simple to implement and require low resource usage, while providing reliable real-time results.	algorithm;pixel;real-time clock	Joanna C. K. Lai;Waleed H. Abdulla;Stephan Hussmann	2006	Integration	10.1016/j.vlsi.2005.07.004	embedded system;electronic engineering;telecommunications;computer science;engineering;charge-coupled device;engineering drawing;field-programmable gate array	Embedded	51.32361410053031	51.037283734111924	12260
b27c3f57e40d05c397622eba325c96b90ed6c8a9	an algorithm to compute the primitive elements of an embedding dimension three numerical semigroup	primitive elements;numerical semigroup;tame degree;l shapes;article	We give an algorithm to compute the set of primitive elements for an embedding dimension three numerical semigroups. We show how we use this procedure in the study of the construction of L-shapes and the tame degree of the semigroup.	algorithm;numerical analysis;tame	F. Aguiló;Pedro A. García-Sánchez;David Llena	2014	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2014.08.025	combinatorics;discrete mathematics;bicyclic semigroup;cancellative semigroup;mathematics;algebra	Theory	44.220843655789956	32.67078370415454	12263
1c60cd96118d02748b6024a6095bd25a733da707	the design and analysis of the parallel prefix computation algorithm			algorithm;computation	Tack-Don Han;David A. Carlson	1990			parallel computing;computation;theoretical computer science;computer science;prefix	Logic	0.8577475270658259	37.19370129514101	12280
fea4594b6f8e437307edc0cc2d83ce4e62740fdf	analysis of retention time under multi-configuration on a dorga	logic gates optical diffraction holographic optical components holography field programmable gate arrays optical arrays vertical cavity surface emitting lasers;junction capacitances;holographic storage;programmable gate array;programmable logic arrays;retention time;dynamic optically reconfigurable architecture;reconfigurable architecture;photodiodes;logic gates;dynamic memory;optical arrays;vlsi holographic storage photodiodes programmable logic arrays;vlsi;optical diffraction;holographic optical components;holography;field programmable gate arrays;junction capacitances optically reconfigurable gate arrays virtual gate count holographic memory programmable gate array vlsi dynamic optically reconfigurable architecture photodiodes dynamic memory;holographic memory;virtual gate count;vertical cavity surface emitting lasers;optically reconfigurable gate arrays	Optically reconfigurable gate arrays (ORGAs) have been developed to realize a large virtual gate count by adding a holographic memory onto a programmable gate array VLSI. Up to now, dynamic optically reconfigurable architecture has been proposed to increase the gate count of the ORGA-VLSI part, which uses photodiodes as dynamic memory to store a configuration context and perfectly removes static configuration memories. Consequently, extremely high gate count ORGAs have been realized. However, in this architecture, since background diffraction light of configuration contexts reduces the retention time of circuit information stored in junction capacitances of photodiodes, it has remained a concern that under multi-configuration, an optical configuration can reduce the retention time of other circuits that have already been programmed before the configuration and are functioning on a gate array. This paper clarifies that the dynamic optically reconfigurable architecture is effective even under multi-configuration.	field-programmable gate array;gate count;holographic data storage;holography;memory management;very-large-scale integration	Daisaku Seto;Minoru Watanabe	2008	2008 IEEE International SOC Conference	10.1109/SOCC.2008.4641495	embedded system;photodiode;electronic engineering;dynamic random-access memory;logic gate;computer hardware;computer science;engineering;electrical engineering;operating system;very-large-scale integration;holography;field-programmable gate array	EDA	15.25158873670369	59.66231147818112	12286
b03df482b62c2113f23b6daddd1f6341dc82e9dc	guest editorial special section on built-in-test	software testing;circuit faults;built in self test circuit testing system testing circuit faults very large scale integration software testing condition monitoring automatic testing hardware jitter;very large scale integration;automatic testing;built in self test;condition monitoring;built in test;system testing;circuit testing;jitter;hardware			Robert W. Gao	2005	IEEE Trans. Instrumentation and Measurement	10.1109/TIM.2005.850322	non-regression testing;embedded system;electronic engineering;jitter;software performance testing;white-box testing;manual testing;telecommunications;integration testing;computer science;engineering;software reliability testing;software testing;real-time testing;very-large-scale integration;system testing;computer engineering	Embedded	9.756923569647777	53.885847039111624	12293
81c8b7c44c89b139da939a6b568bdcc66646ca53	novel evolutionary algorithm with set representation scheme for truss design	topology;evolutionary computation;design engineering;gaussian mutation evolutionary algorithm set representation scheme truss design truss geometry;evolutionary computation algorithm design and analysis topology genetic mutations genetic algorithms design optimization computational modeling biological cells geometry search methods;structural engineering;cross sectional area;evolutionary algorithm;supports;topology design engineering evolutionary computation structural engineering supports	Presented in this paper is a novel scheme of representation for truss geometry. Trusses are represented as a set of elements having a collection of properties (e.g. cross-sectional area, type of material). These sets can be of varying cardinality representing truss structures with different numbers of elements and hence distinctly different topologies. A recombination operator to handle a set representation that can generate offspring topologies that can be different from the parents is also proposed. Depending on the physical problem being solved, one can introduce specific operators which will aid the optimization process. One such mutation operator is used for the truss design to reduce the number of elements, hence finding the smallest feasible topology for the truss structure. Another mutation operator perturbs the properties of the elements using the Gaussian mutation.	cross-sectional data;definition;evolutionary algorithm;fold (higher-order function);genetic algorithm;ieee congress on evolutionary computation;loss function;mathematical optimization;optimal design;optimization problem;perturbation theory (quantum mechanics);random seed;topology optimization;vergence	Amitay Isaacs;Tapabrata Ray;Warren Smith	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424979	mathematical optimization;combinatorics;human-based evolutionary computation;computer science;artificial intelligence;machine learning;evolutionary algorithm;genetic representation;mathematics;cross section;evolutionary computation	Vision	29.216448123101575	4.274441304425447	12296
0e4bf6079ae9a6de076cc54e0b7a7904596a36e5	a probabilistic upper bound on differential entropy	algorithme rapide;cumulative distribution function probabilistic upper bound differential entropy one dimensional distribution;cumulative distribution function;entropia;absolute continuity;entropy bound;differential entropy;convex programming;variable aleatoire;fonction repartition;variable aleatoria;statistical distributions entropy codes;convex optimization;programmation convexe;probabilistic approach;upper bound;funcion distribucion;distribution function;statistical distributions;statistical learning;upper bound entropy distribution functions random variables statistical learning computer science pervasive computing physics probability distribution engineering profession;enfoque probabilista;approche probabiliste;entropy codes;fast algorithm;entropie;random variable;string tightening algorithm convex optimization differential entropy entropy entropy bound;entropy;borne superieure;algoritmo rapido;information theory;cota superior;string tightening algorithm;programacion convexa	A novel probabilistic upper bound on the entropy of an unknown one-dimensional distribution, given the support of the distribution and a sample from that distribution, is presented. No knowledge beyond the support of the unknown distribution is required. Previous distribution-free bounds on the cumulative distribution function of a random variable given a sample of that variable are used to construct the bound. A simple, fast, and intuitive algorithm for computing the entropy bound from a sample is provided.	algorithm;differential entropy	Joseph DeStefano;Erik G. Learned-Miller	2008	IEEE Transactions on Information Theory	10.1109/TIT.2008.929937	exponential distribution;entropy;mathematical optimization;combinatorics;convex optimization;binary entropy function;maximum entropy probability distribution;log-cauchy distribution;principle of maximum entropy;calculus;inverse-chi-squared distribution;mathematics;compound probability distribution;uniform distribution;chi-squared distribution;statistics	Theory	41.034337898318135	11.485530791190332	12304
5ca5ebcd249e5c7ae45e973fff6eb754d65a0530	expressiveness and computational complexity of geometric quantum logic	satisfiability;quantum logic;computational complexity;polynomial time;model of computation	Quantum logic generalizes, and in dimension one coincides with, Boolean logic. We show that the satisfiability problem of quantum logic formulas is NP-complete in dimension two as well. For higher higher-dimensional spaces R and C with d ≥ 3 fixed, we establish quantum satisfiability to be polynomial time equivalent to the real feasibility of a multivariate quartic polynomial equation: a problem well-known complete for the counterpart of NP in the Blum-Shub-Smale model of computation lying (probably strictly) between classical NP and PSPACE. We finally investigate the problem over indefinite finite dimensions and relate it to the real feasibility of quartic noncommutative ∗-polynomial equations.	algebraic equation;blum blum shub;blum axioms;blum–shub–smale machine;boolean algebra;boolean satisfiability problem;computational complexity theory;karp's 21 np-complete problems;logical connective;model of computation;pspace;polynomial;polynomial-time reduction;quantum logic;quartic function	Christian Herrmann;Martin Ziegler	2010	CoRR		model of computation;complete;complexity class;parameterized complexity;combinatorics;discrete mathematics;average-case complexity;ph;decision tree model;bqp;quantum complexity theory;theoretical computer science;structural complexity theory;computational resource;mathematics;fair computational tree logic;computational learning theory;asymptotic computational complexity;quantum algorithm;descriptive complexity theory	Theory	6.588664047820062	20.636200409653746	12309
41b910f9d4d37563818bb93abe6e958fb845da31	an improved algorithm for assessing the overall quantisation error in fpga based cordic systems computing a vector magnitude	cordic;vector magnitude;fpga;arithmetic function;fpga implementation;arithmetic;electrical engineering electronics nuclear engineering	The CORDIC (coordinate rotation digital computer) algorithm is an iterative technique that can be used to compute many arithmetic functions using mainly shifts and additions making it ideal for FPGA implementation. In the early 1990s, Yu Hen Hu developed an equation for the overall quantisation error (OQE) experienced by the CORDIC algorithm when computing a vector magnitude. This equation could be used to find the most efficient architecture that would give a desired level of accuracy thus avoiding a trial and error approach. In this paper, we note that in fact the OQE overestimates the error in many cases, thus yielding inefficient architectures. Hence, this paper presents an updated equation for the OQE which is more accurate in predicting the error. To illustrate the improved accuracy of the new OQE expression, comparisons are made between CORDIC systems found using both versions of the OQE algorithm and Direct systems computing a vector magnitude. This comparison is of interest as it shows that CORDIC systems based on the new OQE expression use considerably fewer FPGA resources than CORDIC systems found using the original algorithm or equivalent direct designs. Given the widespread use of CORDIC in FPGA designs, particularly in DSP, this is significant.	algorithm;cordic;field-programmable gate array;quantization (image processing);quantization (signal processing)	Steven W. Alexander;Eugen Pfann;Robert W. Stewart	2007	Microprocessors and Microsystems	10.1016/j.micpro.2006.02.017	embedded system;parallel computing;euclidean vector;computer science;theoretical computer science;arithmetic function;field-programmable gate array;cordic	EDA	13.391526598835188	44.117744818156964	12330
3a9a26319d13adea2b9d805b8a91663b7bca0c95	a taxonomy of gpgpu performance scaling	kernel bandwidth benchmark testing hardware graphics processing units performance evaluation programming;performance evaluation graphics processing units multiprocessing systems;memory bandwidth gpgpu performance scaling taxonomy graphics processing units high powered discrete cards graphics workload performance	Graphics processing units (GPUs) range from small, embedded designs to large, high-powered discrete cards. While the performance of graphics workloads is generally understood, there has been little study of the performance of GPGPU applications across a variety of hardware configurations. This work presents performance scaling data gathered for 267 GPGPU kernels from 97 programs run on 891 hardware configurations of a modern GPU. We study the performance of these kernels across a 5× change in core frequency, 8.3× change in memory bandwidth, and 11× difference in compute units. We illustrate that many kernels scale in intuitive ways, such as those that scale directly with added computational capabilities or memory bandwidth. We also find a number of kernels that scale in non-obvious ways, such as losing performance when more processing units are added or plateauing as frequency and bandwidth are increased. In addition, we show that a number of current benchmark suites do not scale to modern GPU sizes, implying that either new benchmarks or new inputs are warranted.	benchmark (computing);clock rate;embedded system;general-purpose computing on graphics processing units;graphics processing unit;memory bandwidth;numerical taxonomy	Abhinandan Majumdar;Gene Y. Wu;Kapil Dev;Joseph L. Greathouse;Indrani Paul;Wei Huang;Arjun-Karthik Venugopal;Leonardo Piga;Chip Freitag;Sooraj Puthoor	2015	2015 IEEE International Symposium on Workload Characterization	10.1109/IISWC.2015.22	cuda pinned memory;computer architecture;parallel computing;real-time computing;computer hardware;computer science;operating system;general-purpose computing on graphics processing units	Arch	-4.12132429787789	47.01091106146259	12339
5db3bb29d8199f970cd15c2e63054501efdceec6	families of convolutional codes over finite fields: a survey		The goal of this work is to give explicit interconnections between control theory and coding. It is well-known the existence of a closed relation between linear systems over finite fields and convolutional codes that allow to understand some properties of convolutional codes and to construct them. The connection between convolutional codes and linear systems permit to consider control as well as analyze observability of convolutional codes under linear systems point of view.	convolutional code	María Isabel García-Planas	2017		10.1007/978-3-319-55589-8_2	computer science;discrete mathematics;theoretical computer science;convolutional code;block code;real-time computing;turbo code;serial concatenated convolutional codes;online codes;quantum convolutional code;linear code;expander code	Crypto	41.37063919103442	54.96984722197997	12342
4129477cf3cc2e16446629cc41834dbf368a5323	isomorphism of degree four cayley graph and wrapped butterfly and their optimal permutation routing algorithm	parallel and distributed system;multiprocessor interconnection networks;graph theory;computational complexity multiprocessor interconnection networks graph theory parallel algorithms;permutation routing;wrapped butterfly;cayley graph;isomorphism;topological properties;computational complexity;topological properties degree four cayley graph wrapped butterfly optimal permutation routing algorithm edge preserving bijective mapping;routing multiprocessor interconnection networks hypercubes availability algorithm design and analysis;parallel algorithms	In this paper, we first show that the degree four Cayley graph proposed in a paper appearing in the January 1996 issue of IEEE Transactions on Parallel and Distributed Systems is indeed isomorphic to the wrapped butterfly. The isomorphism was first reported by Muga and Wei in the proceedings of PDPTA '96. The isomorphism is shown by using an edge-preserving bijective mapping. Due to the isomorphism, algorithms for the degree four Cayley graph can be easily developed in terms of wrapped butterfly and topological properties of one network can be easily derived in terms of the other. Next, we present the first optimal oblivious one-to-one permutation routing scheme for these networks in terms of the wrapped butterfly. Our algorithm runs in time O(/spl radic/N), where N is the network size.	magma;routing	David S. L. Wei;Felix P. Muga;Sagar Naik	1999	IEEE Trans. Parallel Distrib. Syst.	10.1109/71.819950	graph canonization;graph theory;theoretical computer science;cayley graph;voltage graph;distributed computing;parallel algorithm;graph isomorphism;isomorphism;computational complexity theory;butterfly graph;vertex-transitive graph	Arch	22.68359827597668	35.068009254515935	12351
f7924486d9f159c036fa5ddf06aeae6ec9ee2167	on the matrix feedback shift register synthesis for matrix sequences	berlekamp massey algorithm minimal partial realization multisequences lfsr	In this paper, a generalization of the linear feedback shift register synthesis problem is presented for synthesizing minimum-length matrix feedback shift registers (MFSRs for short) to generate prescribed matrix sequences and so a new complexity measure, that is, matrix complexity, is introduced. This problem is closely related to the minimal partial realization in linear systems and so can be solved through any minimal partial realization algorithm. All minimum-length MFSRs capable of generating a given matrix sequence with finite length are characterized and a necessary and sufficient condition for the uniqueness issue is obtained. Furthermore, the asymptotic behavior of the matrix complexity profile of random vector sequences is determined. (1) 提出并解决了矩阵序列的矩阵反馈移位寄存器综合问题; (2) 利用对偶格的性质, 对于有限长的矩阵序列, 给出了所有生成该序列的最短的矩阵反馈移位寄存器及其唯一的充要条件。 (3) 提出了矩阵序列的矩阵复杂度并给出了向量序列的矩阵复杂度轮廓的渐进性质。 提出并解决了矩阵序列的矩阵反馈移位寄存器综合问题; 利用对偶格的性质, 对于有限长的矩阵序列, 给出了所有生成该序列的最短的矩阵反馈移位寄存器及其唯一的充要条件。 提出了矩阵序列的矩阵复杂度并给出了向量序列的矩阵复杂度轮廓的渐进性质。	algorithm;blum axioms;computational complexity theory;linear system;linear-feedback shift register;the matrix	Liping Wang;Guang Zeng	2015	Science China Information Sciences	10.1007/s11432-015-5302-1	feedback with carry shift registers;gaussian elimination;combinatorics;discrete mathematics;berlekamp–massey algorithm;eight-point algorithm;sparse matrix;realization;computer science;generator matrix;convergent matrix;mathematics;logical matrix;state-transition matrix;augmented matrix;block matrix;algorithm	Theory	42.70575288763736	45.19227877161192	12354
c7a8374b8f19a27eb6621e81fcd931dd6f3598af	panel: increasing test coverage in a vlsi desgin course	very large scale integration;test coverage		fault coverage;very-large-scale integration	Vishwani D. Agrawal	1999			computer science;engineering;electrical engineering;software engineering;very-large-scale integration;code coverage;mechanical engineering	EDA	9.675875259025517	53.43270056457358	12365
082aa54541e60e666f356f125d4f9189d1c735fc	a wireless sensor network-based approach to large-scale dimensional metrology	experimental tests;coordinate measuring systems;wireless network;large volume metrology;measurement system;mobile measuring system;physical sciences;work environment;system performance;large scale metrology;wireless sensor network;large scale;product cycle;dimensional metrology;wireless sensor networks	In many branches of industry, dimensional measurements have become an important part of the production cycle, in order to check product compliance with specifications. This task is not trivial especially when dealing with largescale dimensional measurements: the bigger the measurement dimensions are, the harder is to achieve high accuracies. Nowadays, the problem can be handled using many metrological systems, based on different technologies (e.g. optical, mechanical, electromagnetic). Each of these systems is more or less adequate, depending upon measuring conditions, user’s experience and skill, or other factors such as time, cost, accuracy and portability. This article focuses on a new possible approach to large-scale dimensional metrology based on wireless sensor networks. Advantages and drawbacks of such approach are analysed and deeply discussed. Then, the article briefly presents a recent prototype system – the Mobile Spatial Coordinate-Measuring System (MScMS-II) – which has been developed at the Industrial Metrology and Quality Laboratory of DISPEA – Politecnico di Torino. The system seems to be suitable for performing dimensional measurements of large-size objects (sizes on the order of several meters). Owing to its distributed nature, the system – based on a wireless network of optical devices – is portable, fully scalable with respect to dimensions and shapes and easily adaptable to different working environments. Preliminary results of experimental tests, aimed at evaluating system performance as well as research perspectives for further improvements, are discussed.	centralisation;data acquisition;distributed computing;prototype;scalability;sensor web;software portability	Maurizio Galetto;Luca Mastrogiacomo;Barbara Pralio	2010	Int. J. Computer Integrated Manufacturing	10.1080/0951192X.2010.518322	simulation;dimensional metrology;wireless sensor network;computer science;engineering;electrical engineering;database;computer performance;mechanical engineering	Robotics	3.1881392340051407	31.916577111365726	12370
2c4230b1f232da825828a7d0bbe7fd4e062d70d3	k-connectivity of random key graphs		Random key graphs represent topologies of secure wireless sensor networks that apply the seminal Eschenauer – Gligor random key predistribution scheme to secure communication between sensors. These graphs have received much attention and also been used in diverse application areas be yond secure sensor networks; e.g., cryptanalysis, social netwo rks, and recommender systems. Formally, a random key graph withn nodes is constructed by assigning each node Xn keys selected uniformly at random from a pool of Yn keys and then putting an undirected edge between any two nodes sharing at least one key. Considerable progress has been made in the literature t o analyze connectivity andk-connectivity of random key graphs; e.g., Yăgan and Makowski [ISIT ’09, Trans. IT’12] on connectivity under Xn = Ω( √ lnn ), Rybarczyk [Discrete Mathematics ’11] on connectivity under Xn ≥ 2, and our recent work [CDC ’14] on k-connectivity under Xn = Ω( √ lnn ), where k-connectivity of a graph ensures connectivity even after the removal of k nodes ork edges. Yet, it still remains an open question fork-connectivity in random key graphs underXn ≥ 2 and Xn = o( √ lnn ) (the case of Xn = 1 is trivial). In this paper, we answer the above problem by providing an exact analysis ofk-connectivity in random key graphs under Xn ≥ 2.	cdc 6000 series;cryptanalysis;discrete mathematics;graph (discrete mathematics);ork;recommender system;secure communication;sensor	Jun Zhao;Osman Yagan;Virgil D. Gligor	2015	CoRR		random regular graph;random graph;combinatorics;theoretical computer science;mathematics;distributed computing	Crypto	20.00327626840895	36.5004363318311	12382
afc5d80d9646903065bc94a53a14cf645b283eb4	a mapping and scheduling algorithm for parallel sparse fan-in numerical factorization	tratamiento paralelo;traitement parallele;sparse;factorization;scheduling algorithm;matrice creuse;factorizacion;scheduling;factorisation;ordonamiento;sparse matrix;parallel processing;ordonnancement;matriz dispersa	We present and analyze a general algorithm which computes efficient static schedulings of block computations for parallel sparse linear factorization. Our solver, based on a supernodal fan-in approach, is fully driven by this scheduling. We give an overview of the algorithms and present performance results on a 16-node IBM-SP2 with 66 MHz Power2 thin nodes for a collection of grid and irregular problems.	algorithm;scheduling (computing);sparse	Pascal Hénon;Pierre Ramet;Jean Roman	1999		10.1007/3-540-48311-X_148	parallel processing;mathematical optimization;parallel computing;computer science;theoretical computer science;operating system;sparse approximation;scheduling;factorization	HPC	-2.7066369230806737	37.65490040626592	12391
631935ce58592524da4a7434802b5e9712a456cc	distributed averaging in the presence of a sparse cut	stochastic dominance;distributed algorithm;averaging	We consider the question of averaging on a graph that has one sparse cut separating two subgraphs that are internally well connected. We exhibit a decentralized algorithm for such graphs that uses updates involving negative weights and has an averaging time that can be significantly shorter than the averaging time of known distributed averaging algorithms.	algorithm;sparse matrix	Hariharan Narayanan	2008		10.1145/1400751.1400836	distributed algorithm;mathematical optimization;computer science;stochastic dominance;machine learning;distributed computing	NLP	21.077867477919803	33.79352263633659	12399
396fd48756714ace2fdaa4656be114a375644d66	why the usual candidates of reducibility do not work for the symmetric lamba-my-calculus	reducibility;λμ calculus	The symmetric λμ-calculus is the λμ-calculus introduced by Parigot in which the reduction rule μ′, which is the symmetric of μ, is added. We give examples explaining why the technique using the usual candidates of reducibility does not work. We also prove a standardization theorem for this calculus.	lambda-mu calculus	René David;Karim Nour	2005	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2005.06.020	combinatorics;computer science;pure mathematics;mathematics	Logic	43.63618228489177	29.045465370045456	12404
e6c70c9d84be69dc2501ac8674cb7806918217fc	on the reconstruction of locally finite trees		We prove a theorem saying, when taken together wi th previous results of Bondy. Hemminger, and Thomassen, that every locally finite, infinite tree not containing a subdivision of the dyadic tree (i.e., the regular tree of degree 3) is uniquely determined, up to isomorphism, from its collection of vertex-deleted subgraphs. Furthermore, as another partial result concerning the reconstruct ion of locally finite trees, we show that the same is true for locally finite trees whose set of vertices of degree s is nonempty and finite (for some positive integers).	binary tree;carsten thomassen;finite element method;nondeterministic finite automaton;regular tree grammar;subdivision surface	Thomas Andreae	1981	Journal of Graph Theory	10.1002/jgt.3190050202	combinatorics;discrete mathematics;topology;mathematics	Theory	37.673306231387365	26.90941197737059	12415
a1835044548b20f051afb8de4a3288785e1e0998	on the intractability of task allocation in distributed systems	distributed system;task allocation	The fast progress of large integration technology has made distributed computing economically attractive for many computer applications. Task allocation is one of the most important and challenging problems in distributed computing systems that has received considerable attention in recent years. Several researchers have introduced different heuristics to solve this problem with the assumption that it is computationally intractable. These researchers have been referring to an early work by Stone and some private communication as their sources of the problem’s intractability. However, neither Stone’s paper nor any other related work in the literature provided a formal proof of intractability. Due to the importance of the task allocation problem, we believe that a formal proof of its complexity must be provided. In this paper we provide a proof that the problem of task allocation is intractable even in the restricted case when there are only two values of the the communication cost: zero or one. We introduce a new model to represent the problem of allocating tasks on heterogeneous distributed systems using split graphs. This model allows us to relate the task allocation problem with the problem of weighted clique partitioning in complete split graphs. We provide a two-step reduction method to prove the intractability of task allocation in the restricted case mentioned above. In the first step, we prove that the problem of weighted clique partitioning in complete split graph is NP-complete using a transformation from the problem of partition into triangles. In the second step, we show that the task allocation problem is NP-complete using a transformation from the weighted clique partitioning problem.	distributed computing	Hesham H. Ali;Hesham El-Rewini	1994	Parallel Processing Letters	10.1142/S0129626494000168	combinatorics;computer science;theoretical computer science;mathematics;distributed computing;algorithm	HPC	15.070960054495057	15.200268519357587	12428
5189cd909b46576ccc8a3a8c9cbfcd132701f4a8	cuts for mixed 0-1 conic programming	conic programming;traveling salesman problem;mixed programming;quadratic programming;zero one programming;programmation conique;programmation semi definie;programmation quadratique;convex programming;travelling salesman problem;combinatorial optimization problem;programmation zero un;programmation convexe;programmation mixte;linear relaxation;optimisation combinatoire;problema viajante comercio;programmacion cero uno;programacion lineal;programacion mixta;relajacion lineal;computer experiment;mathematical programming;probleme commis voyageur;linear programming relaxation;linear programming;programmation lineaire;linear program;programacion cuadratica;relaxation lineaire;semideflnite programming;programacion semi definida;generalized convexity;combinatorial optimization;programmation mathematique;programacion matematica;optimizacion combinatoria;semi definite programming;programacion convexa	In this we paper we study techniques for generating valid convex constraints for mixed 0-1 conic programs. We show that many of the techniques developed for generating linear cuts for mixed 0-1 linear programs, such as the Gomory cuts, the lift-and-project cuts, and cuts from other hierarchies of tighter relaxations, extend in a straightforward manner to mixed 0-1 conic programs. We also show that simple extensions of these techniques lead to methods for generating convex quadratic cuts. Gomory cuts for mixed 0-1 conic programs have interesting implications for comparing the semidefinite programming and the linear programming relaxations of combinatorial optimization problems, e.g. we show that all the subtour elimination inequalities for the traveling salesman problem are rank-1 Gomory cuts with respect to a single semidefinite constraint. We also include results from our preliminary computational experiments with these cuts.	combinatorial optimization;computation;conic optimization;cutting-plane method;disjunctive normal form;experiment;gomory–hu tree;linear programming relaxation;mathematical optimization;semidefinite programming;travelling salesman problem	Mehmet Tolga Çezik;Garud Iyengar	2005	Math. Program.	10.1007/s10107-005-0578-3	mathematical optimization;conic optimization;combinatorics;linear programming;mathematics;travelling salesman problem;algorithm;cutting-plane method	Theory	23.614337320361333	12.345899491709844	12441
73fc0d2ad6e41c5dab06b09f708f5911260f30ad	how to use metaheuristics for design of symmetric-key primitives		The ultimate goal of designing a symmetric-key cryptographic primitive often can be formulated as an optimization problem. So far, these problems mainly have been solved with trivial algorithms such as brute force or random search. We show that a more advanced and equally versatile class of search algorithms, called metaheuristics, can help to tackle optimization problems related to design of symmetrickey primitives. We use two nature-inspired metaheuristics, simulated annealing and genetic algorithm, to optimize in terms of security the components of two recent cryptographic designs, SKINNY and AES-round based constructions. The positive outputs of the optimization suggest that metaheuristics are non-trivial tools, well suited for automatic design of primitives.	brute-force search;cryptographic primitive;cryptography;genetic algorithm;mathematical optimization;metaheuristic;optimization problem;random search;search algorithm;simulated annealing;symmetric-key algorithm	Ivica Nikolic	2017		10.1007/978-3-319-70700-6_13	cryptographic primitive;genetic algorithm;computer science;theoretical computer science;symmetric-key algorithm;simulated annealing;metaheuristic;random search;search algorithm;optimization problem	EDA	27.400781696435548	4.287133969832679	12446
7620868ce52f583954f9b9528beef4ac9be8f0ba	a novel systolic gf(2k) field multiplication-inversion arithmetic unit	complexity theory;multiplication inversion arithmetic unit;extended euclidean algorithm;physics computing;computer architecture;gf 2 k field operations;one hardware module;logic gates;critical path;euclidean algorithm;signal processing algorithms;algorithm design and analysis;one hardware module multiplication inversion arithmetic unit gf 2 k field operations extended euclidean algorithm;hardware;computer architecture algorithm design and analysis logic gates delay complexity theory signal processing algorithms hardware	In this paper a systolic Multiplication-Inversion architecture is proposed that can be extended to perform all GF(2k) field operations. This architecture is based on a proposed Modified version of the Extended Euclidean Algorithm that through appropriate reusability and initialization it can perform multiplication and inversion. Therefore, while other known designs need two hardware components for multiplication and inversion, in the proposed design only one hardware module for both operations is used that give very interesting results in terms of Area complexity, critical path delay, latency and throughput.	arithmetic logic unit;critical path method;extended euclidean algorithm;throughput	Apostolos P. Fournaris;Odysseas G. Koufopavlou	2005	2005 12th IEEE International Conference on Electronics, Circuits and Systems	10.1109/ICECS.2005.4633450	discrete mathematics;multiplication algorithm;theoretical computer science;mathematics;algorithm	EDA	10.172350308217112	44.6445467094861	12457
d075395cdeabef251a7e90ccfcb4e8440ca0ec4d	a tight -approximation for linear 3-cut		We investigate the approximability of the linear 3-cut problem in directed graphs, which is the simplest unsolved case of the linear k-cut problem. The input here is a directed graph D = (V,E) with node weights and three specified terminal nodes s, r, t ∈ V , and the goal is to find a minimum weight subset of non-terminal nodes whose removal ensures that s cannot reach r and t, and r cannot reach t. The problem is approximation-equivalent to the problem of blocking rooted inand out-arborescences, and it also has applications in network coding and security. The approximability of linear 3-cut has been wide open until now: the best known lower bound under the Unique Games Conjecture (UGC) was 4/3, while the best known upper bound was 2 using a trivial algorithm. In this work we completely close this gap: we present a √ 2-approximation algorithm and show that this factor is tight assuming UGC. Our contributions are twofold: (1) we analyze a natural two-step deterministic rounding scheme through the lens of a single-step randomized rounding scheme with non-trivial distributions, and (2) we construct integrality gap instances that meet the upper bound of √ 2. Our gap instances can be viewed as a weighted graph sequence converging to a “graph limit structure”.	approximation algorithm;blocking (computing);directed graph;graphon;linear network coding;linear programming relaxation;minimum k-cut;minimum weight;randomized rounding;unique games conjecture;user-generated content	Kristóf Bérczi;Karthekeyan Chandrasekaran;Tamás Király;Vivek Madan	2018		10.1137/1.9781611975031.92	combinatorics;computer science;discrete mathematics	Theory	23.348852217578475	21.097211914403356	12463
a64ae3e59928ca43f5f3e5b51bed68487a1cb420	model theory of special subvarieties and schanuel-type conjectures	11j81;zariski geometries;shimura varieties;03c45;11j89;14g35;period conjecture	1.1 The first part of the paper (section 2) is essentially a survey of developments around the program outlined in the talk to the European Logic Colloquium 2000 and publication [22]. It then continues with new research which aims, on the one hand side, to extend the model-theoretic picture of [22] and of section 2 to the very broad mathematical context of what we call here special coverings of algebraic varieties, and on the other hand, to use the language and the tools available in model theory to redefine and clarify the rather involved notion of a special subvariety known from the theory of Shimura varieties (mixed and pure) and some extensions of this theory. Our definition of special coverings of algebraic varieties includes semi-abelian varieties, Shimura varieties (definitely the pure ones, and we also hope but do not know if the mixed ones in general satisfy all the requirement) and much more, for example, the Lie algebra covering a simple complex of Lie group SL(2,C). Recall from the discussion in [22] that our specific interest in these matters arose from the connection to Hrushovski’s construction of new stable structures (see e.g. [21]) and their relationship with generalised Schanuel conjectures. This subject is also closely related to the Trichotomy Principle and Zariski geometries. In the current paper we establish that the geometry of an arbitrary special covering of an algebraic variety is controlled by a Zariski geometry the closed subsets of which we call (weakly) special. The combinatorial type of simple (i.e. strongly minimal) weakly special subsets are classifiable by the Trichotomy Principle. Using this geometry and related dimension notions we can define a corresponding very general analogue of “Hrushovski’s predimension” and formulate corresponding “generalised Schanuel’s conjecture” as well as a very general forms of André-Oort, the CIT and Pink’s conjectures (Zilber-Pink conjectures). Note that in this generality one can see a considerable overlap of the generalised Schanuel conjectures with the André conjecture on periods [1] (generalising the Grothendieck period conjecture) which prompt further questions on the modeltheoretic nature of fundamental mathematics.	antimatroid;cit program tumor identity cards;kazhdan–lusztig polynomial;linear algebra;semiconductor industry;theory	Boris Zilber	2016	Ann. Pure Appl. Logic	10.1016/j.apal.2015.02.002	mathematical analysis;discrete mathematics;topology;shimura variety;mathematics;algebra	Theory	42.29271535636385	27.50608921733564	12465
b24bee687253ffad2cbc30feddaff410c2463389	comparison of high level fpga hardware design for solving tri-diagonal linear systems	tri diagonal linear systems;100603 logic design;high level hardware design;010301 numerical analysis;100606 processor architectures;field programmable gate arrays;opencl;080205 numerical computation;vivado high level synthesis	Reconfigurable computing devices can increase the performance of compute intensive algorithms by implementing application specific co-processor architectures. The power cost for this performance gain is often an order of magnitude less than that of modern CPUs and GPUs. Exploiting the potential of reconfigurable devices such as Field-Programmable Gate Arrays (FPGAs) is typically a complex and tedious hardware engineering task. Recently the major FPGA vendors (Altera, and Xilinx) have released their own high-level design tools, which have great potential for rapid development of FPGA based custom accelerators. In this paper, we will evaluate Altera’s OpenCL Software Development Kit, and Xilinx’s Vivado High Level Sythesis tool. These tools will be compared for their performance, logic utilisation, and ease of development for the test case of a tri-diagonal linear system solver.	algorithm;central processing unit;coprocessor;field-programmable gate array;graphics processing unit;high- and low-level;level design;linear system;opencl api;reconfigurable computing;software development kit;solver;test case;triangular function	David J. Warne;Neil Kelson;Ross Hayward	2014		10.1016/j.procs.2014.05.009	computer architecture;parallel computing;real-time computing;reconfigurable computing;computer science;operating system;field-programmable gate array	EDA	-0.22848989005111678	45.98711715061738	12486
499b97a1cb39287c46b41161d9a97edf6827b195	randomized self-assembly for exact shapes	molecular computation;self assembly;relative tile concentration;construction industry;randomised algorithms;tile concentration programming randomized self assembly exact shape winfree abstract tile assembly model constant size tile assembly system relative tile concentration;self assembly shape tiles assembly systems temperature computer science mathematical model dna usa councils computational modeling;assembly;constant size tile assembly system;shape;tile concentration programming self assembly molecular computation randomized algorithm;randomized algorithm;assembly systems;molecular computing;approximation methods;tiles;tile concentration programming;randomized self assembly;cellular automata;randomised algorithms cellular automata geometric programming;programming;geometric programming;exact shape;winfree abstract tile assembly model	Working in Winfree's abstract tile assembly model, we show that a constant-size tile assembly system can be programmed through relative tile concentrations to build an n x n square with high probability, for any sufficiently large n. This answers an open question of Kao and Schweller (Randomized Self-Assembly for Approximate Shapes, ICALP 2008), who showed how to build an *approximately* n x n square using tile concentration programming, and asked whether the approximation could be made *exact* with high probability.	approximation;icalp;randomized algorithm;self-assembly;with high probability	David Doty	2009	2009 50th Annual IEEE Symposium on Foundations of Computer Science	10.1109/FOCS.2009.13	programming;combinatorics;geometric programming;shape;computer science;theoretical computer science;mathematics;assembly;randomized algorithm;self-assembly;algorithm	Theory	9.447122401114608	22.49873569162796	12504
bf4e09fde01dabb52784f72696dc361c25485ebc	two-dimensional range minimum queries	range minimum query;2 dimensional;computational biology	We consider the two-dimensional Range Minimum Query problem: for a static (m × n)-matrix of size N = mn which may be preprocessed, answer on-line queries of the form “where is the position of a minimum element in an axis-parallel rectangle?”. Unlike the onedimensional version of this problem which can be solved in provably optimal time and space, the higher-dimensional case has received much less attention. The only result we are aware of is due to Gabow, Bentley and Tarjan [1], who solve the problem in O(N log N) preprocessing time and space and O(log N) query time. We present a class of algorithms which can solve the 2-dimensional RMQ-problem with O(kN) additional space, O(N log N) preprocessing time and O(1) query time for any k > 1, where log denotes the iterated application of k + 1 logarithms. The solution converges towards an algorithm with O(N log∗ N) preprocessing time and space and O(1) query time. All these algorithms are significant improvements over the previous results: query time is optimal, preprocessing time is quasi-linear in the input size, and space is linear. While this paper is of theoretical nature, we believe that our algorithms will turn out to have applications in different fields of computer science, e.g., in computational biology.	algorithm;cartesian closed category;computation;computational biology;computer science;information;iteration;long division;maximal set;minimum-weight triangulation;online and offline;optic axis of a crystal;preprocessor;range minimum query;sorting;time complexity	Amihood Amir;Johannes H Fischer;Moshe Lewenstein	2007		10.1007/978-3-540-73437-6_29	combinatorics;two-dimensional space;computer science;theoretical computer science;mathematics;algorithm	Theory	15.28263930750137	25.229854179362288	12510
b9a08ec3cd6daccb8af9afab10658f0a63c7140a	on the connectivity and the conditional diameter of graphs and digraphs		Recently, it was proved that if the diameter D of a graph G is small enough in comparison with its girth, then G is maximally connected and that a similar result also holds for digraphs. More precisely, if the diameter D of a digraph G satisfies D 5 21 1, then G has maximum connectivity ( K = 6 ) . and if D 5 21, then it attains maximum edge-connectivity ( A = 6 ) , where I is a parameter which can be thought of as a generalization of the girth of a graph. In this paper, we study some similar conditions for a digraph to attain high connectivities, which are given in terms of what we call the conditional diameter or P-diameter of G. This parameter measures how far apart can be a pair of subdigraphs satisfying a given property P, and, hence, it generalizes the standard concept of diameter. As a corollary, some new sufficient conditions to attain maximum connectivity or edge-connectivity are derived. It is also shown that these conditions can be slightly relaxed when the digraphs are bipartite. The case of (undirected) graphs is managed as a corollary of the above results for digraphs. In particular, since I 2 1, some known results of Plesnik and Znhm are either reobtained or improved. For instance, it is shown that any graph whose line graph has diameter D = 2 (respectively, D	diameter (protocol);directed graph;girth (graph theory);graph (discrete mathematics);k-edge-connected graph;line graph	Camino Balbuena;Angeles Carmona;Josep Fàbrega;Miguel Angel Fiol	1996	Networks	10.1002/(SICI)1097-0037(199609)28:2%3C97::AID-NET3%3E3.0.CO;2-7		Theory	30.246860394854885	28.067823577777816	12511
60e8066fddb76197bf987f31483c78d56bc1a068	multi-valued functions in computability theory	multi valued functions;degree structure;category theory;weihrauch reducibility;many one reduction	Multi-valued functions are common in computable analysis (built upon the Type 2 Theory of Effectivity), and have made an appearance in complexity theory under the moniker search problems leading to complexity classes such as PPAD and PLS being studied. However, a systematic investigation of the resulting degree structures has only been initiated in the former situation so far (the Weihrauch-degrees). A more general understanding is possible, if the category-theoretic properties of multi-valued functions are taken into account. In the present paper, the category-theoretic framework is established, and it is demonstrated that many-one degrees of multi-valued functions form a distributive lattice under very general conditions, regardless of the actual reducibility notions used (e.g. Cook, Karp, Weihrauch). Beyond this, an abundance of open questions arises. Some classic results for reductions between functions carry over to multi-valued functions, but others do not. The basic theme here again depends on categorytheoretic differences between functions and multi-valued functions.		Arno Pauly	2012		10.1007/978-3-642-30870-3_57	mathematical optimization;combinatorics;discrete mathematics;mathematics;computable function;algorithm;category theory;many-one reduction	Theory	-3.2135188526784946	11.925490501547234	12519
c0b675900bb64172b7d77b92b1ec7ebf5bd70454	fast and efficient circuit topologies forfinding the maximum of n k-bit numbers	topology;complexity theory;hardware description languages;binary trees;network topology;logic gates;high speed arithmetic;integrated circuit modeling;network topology computational complexity digital arithmetic hardware description languages;automatic synthesis;atp circuit topologies maximum k bit numbers arithmetic operation circuit generators hardware description language timing complexity power timing product ptp area timing product;parallel circuits;topology network topology timing complexity theory logic gates binary trees integrated circuit modeling;timing	Finding the value and/or index of the maximum (or minimum) element of a set of n numbers (each with k-bits) is a fundamental arithmetic operation and is needed in many applications. This paper proposes several maximum-finder (or minimum-finder) circuit topologies, which are parallel. We wrote circuit generators at hardware description language level for our topologies and previous works. Then we synthesized these circuits for 20 different (n, k) cases (with values up to 64) and compared their efficiency in timing (latency), area, and energy. The timing complexity of our fastest topology is O(log n + log k), whereas the fastest in the literature is O(log n log k). The synthesis results showed that our fastest topology is 1.2-2.2 times (1.6 times on the average) faster than the state-of-the-art. In this paper, we argue that a more fair metric of area efficiency is area-timing product. In terms of ATP, our proposed topologies are better than the state-of-the-art in 19 out of the 20 cases. In terms of energy (i.e., power-timing product, abbreviated as PTP), we are better in 11 cases out of 20.	automated theorem proving;fastest;hardware description language	Bilgiday Yuce;H. Fatih Ugurdag;Sezer Gören;Günhan Dündar	2014	IEEE Transactions on Computers	10.1109/TC.2014.2315634	series and parallel circuits;discrete mathematics;parallel computing;logic gate;binary tree;computer science;theoretical computer science;mathematics;hardware description language;network topology;algorithm;computer network	EDA	15.77696862275208	48.7454222002769	12524
fc16115025ec51519b40ac27316059cd8eb83591	minimal embeddings in the projective plane	graph embedding;projective plane	We show that if G is a graph embedded on the projective plane in such a way that each noncontractible cycle intersects G at least n times and the embedding is minimal with respect to this property (i.e., the representativity of the embedding is n), then G can be reduced by a series of reduction operations to an n × n × n projective grid. The reduction operations consist of changing a triangle of G to a triad, changing a triad of G to a triangle, and several others. We also show that if every proper minor of the embedding has representativity < n (i.e., the embedding is minimal), then G can be obtained from an n × n × n projective grid by a series of the two reduction operations described above. Hence every minimal embedding has the same number of edges. c © 1997 John Wiley & Sons, Inc. J Graph Theory 25: 153–163, 1997	embedded system;graph theory;john d. wiley	Scott P. Randby	1997	Journal of Graph Theory	10.1002/(SICI)1097-0118(199706)25:2%3C153::AID-JGT7%3E3.0.CO;2-L	projective plane;combinatorics;graph embedding;topology;blocking set;mathematics;geometry	Theory	25.801461072985298	34.28257007027797	12530
c6124f9db317c5b5ae23f1cca40c01305213927d	multi chip modules	integrated circuit interconnections integrated circuit technology printed circuits electronics packaging integrated circuit packaging joining processes costs permission lithography commercialization;printed circuits;multi chip module;lithography;permission;integrated circuit technology;integrated circuit interconnections;joining processes;integrated circuit packaging;electronics packaging;commercialization	For the past 30 years the electronics industry has driven integrated circuit (IC) technology toward higher levels of integration for increased functionality. Modern systems are pushing the limits of the underlying connection technologies as circuit gate content and bandwidth requirements increase pin count. Although the technology for connecting these ICs has improved, the improvements have not come as quickly as required to meet the needs of modern systems (Figure 1)1. These need� include: high speed, high density and low cost.	integrated circuit;requirement	R. H. Bruce;W. P. Meuli;J. Ho	1989	26th ACM/IEEE Design Automation Conference	10.1145/74382.74447	lithography;mixed-signal integrated circuit;embedded system;electronic engineering;tape-out;integrated circuit packaging;computer science;engineering;electrical engineering;integrated circuit;circuit design;electronic packaging;printed circuit board;electronic circuit simulation;pin compatibility	EDA	12.565346918507371	56.35315276565501	12539
50a5ab5198c35c098860d7fd1260ac22c84a2bc9	séparateurs dans les mots infinis engendrés par morphismes	infinite word	Let x be an infinite word on a finite alphabet A. For each position n, the separator of x at n is the smallest factor of x which begins at index n and that does not appear before in x. Let S, be the function such that S,(n) is the length of the separator of x at index n if it exists and otherwise 0. We consider the problem of computing S, in the case where x is generated by iterating a morphism o : A* + A*. We prove the following theorem: Theorem. Let x be an injinite word on a finite alphabet A. If x is generated by iterating a q-uniji>rm morphism o : A* + A* and ifx is circular then the application S, above is q-regular. Details Note that the theorem holds if x is ultimately periodic since, in this case, there is only a finite set of separators. From now on, we suppose that x is an infinite not ultimately periodic word on a finite alphabet A. Some notations (1) x[i j] is the factor of x that begins at index i and that ends at index j. (2) Let u E A*, IuI is the length of U. If u # a, U* is u minus its last letter and l U is u minus its first letter. * Correspondence address: BP 62 35002 Rermes Cedex, France. E-mail: emmanuelle.garel@litp. ibp.fr. 0304-3975/97/$17.00 @ 1997-Elsevier Science B.V. All rights reserved PII SO304-3975(96)000109-O 82 E. GarellTheoretical Computer Science 180 (1997) 81-113 (3) For any n E N, &(n) is the separator of x at index n. It is easy to establish the following property: Proposition. &(n + l)>&(n) 1 for any n E N and thus ‘I!& is a prejix of&(n + 1). (4) We say that there is a jump between n and n + 1 if &(n + l)>&(n). In this case *19,(n) is a prefix of &(n + 1)‘. We say that there is no jump between n and n + 1 or S, is monotone in [n,n + l] if &(n + 1) = S,(n) 1. In this case &(n + 1) = ‘6,(n). About circularity Our references are Mignosi and Seebold in their article “If a DOL language is k-power free then it is circular”. The essential property used is the following: Proposition. Let x be an injinite word on a finite alphabet A that is generated by q-untjorm morphism a : A* --) A*. (1) Zf x is circular then a constant D > 0 exists such that, for any factor w and for any couple of indices n and m such that w begins in n and begins in m, if w factorizes as w = ua(x[i. . j])v in n with Iu] >D and Iv] aD, then a couple of indices i’ and j’ exists such that w factorizes us w = uo(x[i’ . . . j’])v in m and x[i . j] = x[i’ . . . j’]. (2) Zf x is circular and tf the morphism o is injective then a constant C > 0 exists such that, for any factor w and for any couple of indices n and m such that w begins in n and begins in m, if /WI > C and if w factorizes as w = ua(x[i . . . j])v with u # E and u a sufix of o(x[i 11) and with v # E and v a prefix of a(x[j + I]), then a couple of indices i’ and j’ exists such that w factorizes as w = uo(x[i’ . j’])v in m and x[i.. . j] = x[i’ j’]. In particular, in these both cases, we have n s m module q. About q-regularity Our references are Allouche and Shallit in their article “The ring of k-regular sequences”. Let us go into a few details. A subset of N is said to be q-recognizable if its elements in base q are recognized by a q-automaton, (i.e. by a deterministic and finite automaton labelled in (0,. ,q 1) with an output function in a finite set). A function & : N + N is q-regular if the sequence (l(n)) is calculated with a q-transductor, (i.e. by a transductor labelled in (0,. . , q 1) with an output function in (0,. . . , q l}* ). Let H be a subset of N and let 8 : N -+ N be a function. We say that the restriction of & over H is q-regular if the function [H defined by f,(n) = {y) 2,; E H, is q-regular. First, we prove the theorem in the case where the morphism c is injective and to do that, we construct a finite partition (Hi)ict of N such that the restriction of S, over each Hi, i E I, is q-regular. Let C > 0 be a constant that is associated with the circularity of x. We establish the following properties. (1) Let n be an index such that &(n) > C. Denote by n the last letter of 19,(n). We have the factorisation &(qn) = a(&(n)‘) z with z a prefix of a(a) and z # E. In particular that implies &(qn) = 4(&(n) 1) + 121. E. GarellTheoretical Computer Science 180 (1997) 81-113 83 (2) Let n E kJ such that S,(n) > C. Denote by qk, k E N, the last letter of &(qkn) and by zk+l the prefix of (T(qk) such that &(qk+’ n) = a(t&(qkn)*)zk+l. Then the sequence (zk) iS proved ultimately periodic. For any k which is large enough the values &(qkm) verify recurrent formula. Thus we can conclude that the restriction of S, over the set {qkm, k E N} is qregular. (3) The sequence (A$), where Nk is the number of jumps in the interval [qkno,qk(no + I )], k E N, is stationary. (4) For any n E N, denote by H(n) the set H(n) = {m E N/qkn<mQqk(n + I), k E N}. Then, an integer s exists such that, for any n E [qS,#+‘], H(n) verifies: (i) either S, is monotone in each interval [qkn,qk(n + l)], k E N, and in this case, the restriction of S, over H(n) is q-regular. (Use the recurrent formula giving the values &(qkm)), (ii) or, there is a unique jump in each interval [qkno,qk(no + 1) l] at index mk, qkno <mk < qk(no $~ 1) 1. In this case, it is proved that the set {mk}&N is q-recognizable and thus the restriction map of S, over H(n) is q-regular too. Now, consider the partition of N consisting of (1) the finite set H’ = {m EN, m <qko}, (2) the sets H(n), n E [qS,qS+‘]. The restriction map of S, over each set of this partition is q-regular and we conclude that S, is q-regular. Consider now the general case and let x be an infinite, not ultimately periodic, word on a finite alphabet A that is generated by iterating a morphism o : A* + A*. We get a reduction to the injective case by considering the equivalence relations wm, m E N, defined over A by V(a,b) E A*, a~~ b W a”(a)=a”(b). Then the sequence of quotient sets (A,&,) is stationary. Let s be an integer such that A/w, is equal to the limit of (A/N,). Denote by n, the canonical projection of A* on A: and let n5 : A: + A: the morphism defined by ~(rc~(a)) = ns(as(a)) Va E A. Then Q is injective. So, changing q to qs we can suppose the following situation. (1) x = lim o”(uo) for some aa in A, c(2) IY is tie equivalence relation defined by a,~ b H a(a) = o(b), V(u,b) E A*, (3) Let B = A/--, let 7-t : A* -+ B* be the canonical projection, and let q : B* + B* be the morphism defined by q(rc(u)) = x(o(u)) Vu E A. (4) Let y = l@ $(7c(ao)). n The infinite word y is generated by iterating the q-uniform and injective morphism q. It is proved that x circular implies y is circular. Thus the application S, such that S,(n) is the length of the separator of y at index n, is q-regular. Finally, using the relations connecting the separators of x and the separators of y, it is proved that S, q-regular implies that S, is q-regular too.	a* search algorithm;automaton;computer science;emoticon;essence;existential quantification;expanded memory;finite-state machine;iterated function;large eddy simulation;m-module;monoid factorisation;omega language;personally identifiable information;stationary process;stellar classification;turing completeness;iui;monotone	Emmanuelle Garel	1997	Theor. Comput. Sci.	10.1016/S0304-3975(97)83808-X	mathematics;algorithm	Theory	35.0903508863519	38.40356973250183	12565
a8bf0d9b2d8f10959629227936e5e88ba502e4c2	automatic synthesis of efficient regular strategies in adversarial patrolling games		We give a polynomial-time algorithm for synthesizing efficient regular strategies in adversarial patrolling games with general topology. Regular strategies use finite memory to gather some relevant information about the history of Defenderu0027s moves which results in substantially better protection of the targets. So far, the scope of automatic strategy synthesis was limited to positional strategies (which ignore the history) or to regular strategies where the underlying finite-memory observer had to be supplied manually. Furthermore, the existing methods do not give any information on how far are the constructed strategies from being optimal. In this paper, we try to overcome these limitations. We develop a novel gradient-based algorithm for synthesizing regular strategies where the underlying finite-memory observers are constructed algorithmically. The running time of our algorithm is polynomial which makes the algorithm applicable to instances of realistic size. Furthermore, we develop an algorithm for computing an upper bound on the best achievable protection, and compare the quality of the constructed strategies against this bound. Thus, we can effectively measure the distanceu0027u0027 of the constructed strategies from optimal strategies, and our experiments show that this distance is often quite small.	algorithm;computation;convergence insufficiency;experiment;gradient;optimal design;polynomial;time complexity	David Klaska;Antonín Kucera;Tomás Lamser;Vojtech Rehák	2018			adversarial system;patrolling;computer science;observer (quantum physics);artificial intelligence;machine learning;distributed computing;upper and lower bounds;polynomial;general topology	AI	30.348720224588554	8.989773346444636	12588
1889dc416e9a0035f61aed8975e5b8448242ebe6	generalized latin squares and their defining sets	prueba;05b15;minimum defining set;cuadrado latino;red;latin square;preuve;symbole;symbol;reseau arrangement;array;cardinalite;simbolo;proof;carre latin	Abstract   A generalized Latin square of type   (  n  ,  k  )   is an   n  ×  n   array of symbols   1  ,  2  ,  …  ,  k   such that each of these symbols occurs at most once in each row and each column. Let   d  (  n  ,  k  )   denote the cardinality of the minimal set  S  of given entries of an   n  ×  n   array such that there exists a unique extension of  S  to a generalized Latin square of type   (  n  ,  k  )  . In this paper we discuss the properties of   d  (  n  ,  k  )   for   k  =  2  n  -  1   and   k  =  2  n  -  2  . We give an alternate proof of the identity   d  (  n  ,  2  n  -  1  )  =    n    2    -  n  , which holds for even   n  , and we establish the new result   d  (  n  ,  2  n  -  2  )  ⩾    n    2    -  ⌊    8  n    5    ⌋  . We also show that the latter bound is tight for   n   divisible by 10.		Karola Mészáros	2008	Discrete Mathematics	10.1016/j.disc.2006.10.025	combinatorics;mathematics;symbol;algorithm	Theory	38.53972446592616	35.21596398195459	12602
698a1ec30956a0bb1a9bca06e39b6975bd0f0b7a	precision-energy-throughput scaling of generic matrix multiplication and discrete convolution kernels via linear projections	convolution;image matching;matching precision precision energy throughput scaling generic matrix multiplication kernels discrete convolution kernels linear projections gemm kernels 1d discrete convolution cross correlation 1d conv kernels compute intensive processing memory intensive processing image recognition audio recognition image matching system processing throughput input matrix signal data top level gemm blocking conv blocking conv reordering error tolerant multimedia applications energy saving processing cycles voltage scaling frequency scaling arm cortex a15 processor face recognition energy consumption recognition precision;embedded systems generic matrix multiplication discrete convolution multimedia recognition and matching energy and throughput scaling;multimedia computing;power aware computing;power aware computing convolution face recognition fault tolerant computing image matching matrix multiplication multimedia computing operating system kernels;fault tolerant computing;face recognition;matrix multiplication;operating system kernels;kernel convolution throughput multimedia communication signal processing algorithms acceleration vectors	Generic matrix multiplication (GEMM) and one-dimensional discrete convolution/cross-correlation (CONV) kernels perform the bulk of the compute- and memory-intensive processing within image/audio recognition and matching systems. We propose a novel method to scale the energy and processing throughput of GEMM and CONV kernels for such error-tolerant multimedia applications by adjusting the precision of computation. Our technique employs linear projections to the input matrix or signal data during the top-level GEMM and CONV blocking and reordering. The GEMM and CONV kernel processing then uses the projected inputs and the results are accumulated to form the final outputs. Throughput and energy scaling takes place by decreasing the number of projections computed by each kernel, which in turn produces approximate results, i.e. lowers the precision of the performed computation. Existing realizations of error-tolerant multimedia applications can opt to utilize a small number of the input projections (typically just one) in order to save energy and processing cycles, while all error-intolerant systems can compute all input projections and obtain full-precision outputs. Results derived from a voltage- and frequency-scaled ARM Cortex A15 processor running face recognition demonstrate that the proposed approach allows for 5-fold to 10-fold increase of processing throughput and more than 80% decrease of energy consumption against optimized GEMM and CONV kernels without any impact in the expected recognition and matching precision.	arm cortex-a15;arm architecture;approximation algorithm;blocking (computing);coefficient;computation;convolution;cross-correlation;discrete cosine transform;dynamic voltage scaling;elegant degradation;error-tolerant design;facial recognition system;frequency scaling;haar wavelet;image scaling;kernel (operating system);matrix multiplication;online and offline;principal component analysis;prototype filter;seamless3d;testbed;throughput	Mohammad Ashraful Anam;Paul N. Whatmough;Yiannis Andreopoulos	2013	The 11th IEEE Symposium on Embedded Systems for Real-time Multimedia	10.1109/ESTIMedia.2013.6704499	facial recognition system;parallel computing;real-time computing;matrix multiplication;computer science;theoretical computer science;operating system;machine learning;convolution;kernel	Embedded	6.427480691847311	42.56978352484147	12605
98330ff48c900c96889f665439e85021b98132b3	connectivity properties of dimension level sets	constructive dimension;dimension level sets;computable analysis;computability;level set;dimension level set;randomness;hausdor dimension;kolmogorov complexity;euclidean space	This paper initiates the study of sets in Euclidean space R (n ≥ 2) that are defined in terms of the dimensions of their elements. Specifically, given an interval I ⊆ [0, 1], we are interested in the connectivity properties of the set DIM consisting of all points in R whose (constructive Hausdorff) dimensions lie in the interval I. It is easy to see that the sets DIM and DIM(n−1,n] are totally disconnected. In contrast, we show that the sets DIM and DIM[n−1,n] are path-connected. Our proof of this fact uses geometric properties of Kolmogorov complexity in Euclidean space.	hausdorff dimension;kolmogorov complexity	Jack H. Lutz;Klaus Weihrauch	2008	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2008.03.022	inductive dimension;combinatorics;discrete mathematics;dimension theory;topology;effective dimension;hausdorff dimension;level set;euclidean space;mathematics;computability;randomness;minkowski–bouligand dimension;computable analysis	Theory	38.58433813892013	26.05657841066697	12612
1541e3d768727d05adf23b3d4b8ec0f5273e4ac2	two parallel implementations of ehrlich-aberth algorithm for root-finding of polynomials on multiple gpus with openmp and mpi		Finding the roots of polynomials is a very important part of solving real-life problems but the higher the degree of the polynomials is, the less easy it becomes. In this paper, we present two different parallel algorithms of the Ehrlich-Aberth method to find roots of sparse and fully defined polynomials of high degrees. Both algorithms are based on CUDA technology to be implemented on multi-GPU computing platforms but each use different parallel paradigms: OpenMP or MPI. The experiments show a quasi-linear speedup by using up-to 4 GPU devices compared to 1 GPU to find the roots of polynomials of degree up-to 1.4 million. Moreover, other experiments show it is possible to find the roots of polynomials of degree up-to 5 million.	aberth method;cuda;distributed memory;experiment;general-purpose computing on graphics processing units;graphics processing unit;load balancing (computing);message passing interface;multi-core processor;openmp;parallel algorithm;parallel computing;parallel programming model;polynomial;real life;shared memory;sparse matrix;speedup;video card	Kahina Ghidouche;Abderrahmane Sider;Lilia Ziane Khodja;Raphaël Couturier	2016	2016 IEEE Intl Conference on Computational Science and Engineering (CSE) and IEEE Intl Conference on Embedded and Ubiquitous Computing (EUC) and 15th Intl Symposium on Distributed Computing and Applications for Business Engineering (DCABES)	10.1109/CSE-EUC-DCABES.2016.196	parallel computing;kernel (linear algebra);root-finding algorithm;theoretical computer science;parallel algorithm;instruction set;speedup;algorithm;cuda;polynomial;computer science;convergence (routing)	HPC	-2.5078528780444658	39.901955698370195	12623
bbd40c6cc1614d01284fc6a51604886eeda359f0	on the number of acute triangles in a straight-line embedding of a maximal planar graph	planar graph	In this paper we show that any maximal planar graph withmtriangles except the unbounded face can be transformed into a straight-line embedding in which at least ?m/3? triangles are acute triangles. Moreover, we show that any maximal outer-planar graph can be transformed into a straight-line embedding in which all faces are acute triangles except the unbounded face.	planar graph	Atsushi Kaneko;Hiroshi Maehara;Mamoru Watanabe	1999	J. Comb. Theory, Ser. B	10.1006/jctb.1998.1869	outerplanar graph;graph power;combinatorics;discrete mathematics;polyhedral graph;graph embedding;topology;null graph;slope number;nested triangles graph;distance-regular graph;linkless embedding;planar straight-line graph;mathematics;voltage graph;cpctc;butterfly graph;graph minor;complete graph;complement graph;book embedding;planar graph	Theory	28.04586965178297	31.055634756401464	12650
2db9d11b24df15c726f2fc6405f710e4b074eeff	type i codes over gf(4)		It was shown by Gaborit el al. [10] that a Euclidean self-dual code over GF (4) with the property that there is a codeword whose Lee weight ≡ 2 (mod 4) is of interest because of its connection to a binary singly-even self-dual code. Such a self-dual code over GF (4) is called Type I. The purpose of this paper is to classify all Type I codes of lengths up to 10 and extremal Type I codes of length 12, and to construct many new extremal Type I codes over GF (4) of ∗The present study was supported by Com2MaC-KOSEF, POSTECH BSRI research fund, and grant No. R01-2006-000-11176-0 from the Basic Research Program of the Korea Science & Engineering Foundation. †corresponding author, supported in part by a Project Completion Grant from the University of Louisville.	code word;dual code;enumerator polynomial;existential quantification;grammatical framework;graph coloring;quadratic residue code	Hyun Kwang Kim;Dae-Kyu Kim;Jon-Lark Kim	2012	Ars Comb.		mathematics;combinatorics;code word;binary number;euclidean geometry	Theory	39.966585192033065	52.676153610885706	12664
5b76340e9b2b1de475470f60fd5922e0fcd036ba	on minimal imperfect graphs with circular symmetry		Results of Lovász and Padberg entail that the class of so-called partitionable graphs contains all the potential counterexamples to Berge’s famous Strong Perfect Graph Conjecture, which asserts that the only minimal imperfect graphs are the odd chordless cycles with at least five vertices (”odd holes”) and their complements (”odd antiholes”). Only two constructions (due to Chvátal, Graham, Perold and Whitesides) are known for making partitionable graphs. The first one does not produce any counterexample to Berge’s Conjecture, as shown by Sebő. Here we prove that the second one does not produce any counterexample either. This second construction is given by near-factorizations of cyclic groups based on the so-called ”British number systems” introduced by De Bruijn. All the partitionable graphs generated by this second construction (in particular odd holes and odd antiholes) have circular symmetry. No other partitionable graph with circular symmetry is known, and we conjecture that none exists; in this direction we prove that any counterexample must contain a clique and a stable set with at least six vertices each. Also we prove that every minimal imperfect graph with circular symmetry must have an odd number of vertices. ∗The second and third authors gratefully acknowledge the partial support by the Office of Naval Research (Grants N0001492F1375 and N0001492F4083) and by the Air Force Office of Scientific Research (Grant F49620-93-1-0041). The second author was also supported by NSF (grant INT 9321811) and NATO (grant CRG 931531). †Computer and Automation Institute, Hungarian Academy of Sciences, Kende u., Budapest, Hungary. E-mail: bacso@luna.aszi.sztaki.hu ‡RUTCOR, Rutgers University, 640 Bartholomew Road, Piscataway NJ 08854-8003, USA. E-mail: boros@rutcor.rutgers.edu §RUTCOR, Rutgers University, 640 Bartholomew Road, Piscataway NJ 08854-8003, USA; On leave from the International Institute of Earthquake Prediction Theory and Mathematical Geophysics, Moscow, Russia. E-mail: gurvich@rutcor.rutgers.edu ¶CNRS, Laboratoire Leibniz, 46 avenue Félix Viallet, 38031 Grenoble Cedex, France. E-mail: frederic.maffray@imag.fr ‖CNRS, Laboratoire Leibniz, 46 avenue Félix Viallet, 38031 Grenoble Cedex, France. E-mail: myriam.preissmann@imag.fr	academy;automation;classification research group;de bruijn graph;disk partitioning;graham scan;graph (discrete mathematics);ibm notes;strong perfect graph theorem;sue whitesides	Gábor Bacsó;Endre Boros;Vladimir Gurvich;Frédéric Maffray;Myriam Preissmann	1998	Journal of Graph Theory	10.1002/(SICI)1097-0118(199812)29:4%3C209::AID-JGT1%3E3.0.CO;2-V		Theory	27.456311612596284	34.98784836560935	12667
2d693c19d29e7a7670aff0784ab2f2bbf8134f35	wasserstein distributionally robust stochastic control: a data-driven approach		Standard stochastic control methods assume that the probability distribution of uncertain variables is available. Unfortunately, in practice, obtaining accurate distribution information is a challenging task. To resolve this issue, we investigate the problem of designing a control policy that is robust against errors in the empirical distribution obtained from data. This problem can be formulated as a zero-sum dynamic game problem, where the action space of the adversarial player is a Wasserstein ball centered at the empirical distribution. We develop a computationally tractable dynamic programming (DP) approach by using Kantorovich duality to alleviate the infinite dimensionality issue inherent in the inner maximization problem in the Bellman equation. We show that the contraction property of associated DP operators extends a single-stage out-of-sample performance guarantee, obtained using a measure concentration inequality, to the corresponding multi-stage guarantee without any degradation in the confidence level. In addition, we characterize an explicit form of the optimal distributionally robust control policy and the worst-case distribution policy for linear-quadratic problems with Wasserstein penalty. Our study indicates that DP and Kantorovich duality play a critical role in solving and analyzing the Wasserstein distributionally robust stochastic control problems.		Insoon Yang	2018	CoRR			ML	36.5121930397553	4.514877346617562	12688
1b64db2b79ba523eb938c99af82c0452e495c947	speculative lookahead for energy-efficient microprocessors	cmos integrated circuits;clocks;voltage 1 1 v speculative lookahead energy efficient microprocessors adaptive voltage scaling timing speculation mechanisms dynamic timing fault detection dynamic timing fault correction cmos technology arm cortex m0 like microprocessor unit latency tolerant instructions delay variation tolerance size 40 nm;delays fault detection optical wavelength conversion registers cmos integrated circuits;registers;power aware computing cmos integrated circuits field programmable gate arrays microprocessor chips;fault detection;optical wavelength conversion;delays;variable latency delay variation timing speculation	In addition to being the in situ performance monitor for adaptive voltage scaling (AVS), timing speculation mechanisms (e.g., razor) featuring dynamic timing fault detection and correction help to relax timing constraints for simple logic structures and low-power cells. Conventional timing fault detection mechanisms require substantial buffers to prevent race conditions on short paths for double sampling, which can overwhelm energy savings from timing relaxation and voltage scaling. This paper proposes a novel timing speculation scheme, speculative lookahead (SL), comprising duplicate timing-relaxed datapaths, the short paths of which do not introduce race conditions and thus require no additional buffer insertion. In experiments using a 40-nm CMOS technology, SL consumed a 54.89% area of a razor-based 32-bit multiplier, and conserved 59.77% energy per operation at nominal 1.1 V and 53.49% when AVS was applied. An ARM Cortex M0-like microprocessor unit (MPU) was designed using an SL-based datapath, the timing fault detection and correction mechanism of which can be dynamically deactivated for latency-tolerant instructions [i.e., on-demand timing speculation (ODTS)] to further conserve up to 31.08% energy in the execution unit. In addition, an field-programmable gate array prototype of the SL/ODTS MPU was constructed to demonstrate the effectiveness of delay variation tolerance and implementation flexibility.	32-bit;arm architecture;cmos;critical path method;datapath;dynamic voltage scaling;execution unit;experiment;fault detection and isolation;field-programmability;field-programmable gate array;function prototype;image scaling;linear programming relaxation;lookahead carry unit;low-power broadcasting;mpu-401;microprocessor;parsing;race condition;razor;sl (complexity);sampling (signal processing);speculative execution;write combining	Tay-Jyi Lin;Ting-Yu Shyu	2016	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2015.2397954	embedded system;electronic engineering;parallel computing;real-time computing;computer science;operating system;processor register;cmos;fault detection and isolation	Arch	18.564359900213237	58.02056221690302	12694
1f0a6a4e95c59d8f72dac5416d4788d46fccff85	a new secure communication technique using a novel chaos-based nonlinear cryptography function	lyapunov methods;parameter estimation;private key cryptography;telecommunication security;lyapunov function;rikitake model;adaptive parameter identifier;analog hardware;chaos-based nonlinear cryptography function;chaotic encryption;chaotic system;digital hardware;message encryption/decryption;nonlinear function;receiver;secret key;secure communication technique;synchronization-based states observer;transmitter	A new secure communication technique is proposed using a novel chaotic encryption method. A chaotic system with a single adjustable parameter, which has a structure that is similar to the Rikitake model, is used to construct the communication link between the receiver and the transmitter. The nonlinear function used for the encryption/decryption of the message utilizes a single time series of the receiver system along with a synchronization-based states observer and an adaptive parameter identifier. A Lyapunov function is used to design the parameter identifier that functions as an embedded secret key. The proposed technique is demonstrated to have improved security as the signal could be efficiently retrieved only if the secret key is known, even when both the receiver and the transmitter are in perfect synchronization. In addition, the proposed technique is shown to be easily implementable using both analog and digital hardware while being capable of transmitting signals with variable bandwidth.	chaos theory;cryptography;digital electronics;embedded system;identifier;key (cryptography);lyapunov fractal;nonlinear system;secure communication;time series;transmitter	Ashraf A. Zaher	2008	2008 16th European Signal Processing Conference		computer science;theoretical computer science;distributed computing;computer security;encryption;probabilistic encryption	EDA	34.725402090726725	46.88798593182392	12695
5201be12b1da7a11cc49ee37673bb377c8641ac9	a deterministic methodology for identifying functionally untestable path-delay faults in microprocessor cores	program testing built in self test fault diagnosis instruction sets microprocessor chips;microprocessors;fault diagnosis microprocessors automatic testing software testing delay built in self test process control performance evaluation performance analysis guidelines;memory management;processor control unit;circuit faults;microprocessor core;software based self test method;processor instruction set architecture;flip flops;sbst methodology;software based self test;instruction set architecture;assembly;microprocessor testing;untestable path delay fault;built in self test;program testing;registers;software based self test microprocessor testing path delay fault;performance analysis;path delay fault;deterministic methodology;generating test program;generating test program deterministic methodology untestable path delay fault microprocessor core software based self test method sbst methodology processor instruction set architecture functional testability processor control unit;functional testability;fault diagnosis;microprocessor chips;instruction sets;timing	Delay testing is crucial for most microprocessors. Software-based self-test (SBST) methodologies are appealing, but devising effective test programs addressing the true functionally testable paths and assessing their actual coverage are complex tasks. In this paper, we propose a deterministic methodology, based on the analysis of the processor instruction set architecture, for determining rules arbitrating the functional testability of path-delay faults in the data path and control unit of processor cores. Moreover, the performed analysis gives guidelines for generating test programs. A case study on a widely used 8-bit microprocessor is provided.	8-bit;algorithm;control unit;microprocessor	Paolo Bernardi;Michelangelo Grosso;Ernesto Sánchez;Matteo Sonza Reorda	2008	2008 Ninth International Workshop on Microprocessor Test and Verification	10.1109/MTV.2008.9	computer architecture;parallel computing;real-time computing;computer science;operating system;instruction set	SE	20.343542226345786	50.58216412310035	12696
a7fa9486ac928892e0e5494dc5f189e6475665c8	a multiobjective memetic ant colony optimization algorithm for the 1/3 variant of the time and space assembly line balancing problem	minimisation;optimisation;approximate algorithm;joint optimization;space assembly line balancing problem;approximation algorithms;resource allocation;ant colony;realistic multiobjective versions;fixed cycle time limit multiobjective memetic ant colony optimization algorithm space assembly line balancing problem time space assembly realistic multiobjective versions assembly line balancing industrial problem joint optimization joint minimisation;assembly line balancing;memetics;memetic algorithm;assembly;memetics algorithm design and analysis assembly proposals production approximation algorithms probability distribution;joint minimisation;assembling;probability distribution;assembly line balancing industrial problem;production;resource allocation assembling minimisation optimisation;multiobjective memetic ant colony optimization algorithm;proposals;algorithm design and analysis;fixed cycle time limit;ant colony optimization algorithm;time space assembly	Time and space assembly line balancing considers realistic multiobjective versions of the classical assembly line balancing industrial problems, involving the joint optimization of conflicting criteria such as the cycle time, the number of stations, and/or the area of these stations. The aim of this contribution is to present a new multiobjective memetic algorithm based on ant colony optimization for the 1/3 variant of this family of industrial problems. This variant involves the joint minimisation of the number and the area of the stations, given a fixed cycle time limit. The good behaviour of the proposal is shown in nine problem instances.	ant colony optimization algorithms;mathematical optimization;memetic algorithm;memetics;production leveling	Manuel Chica;Oscar Cordón;Sergio Damas;Joaquín Bautista	2011	2011 IEEE Workshop On Computational Intelligence In Production And Logistics Systems (CIPLS)	10.1109/CIPLS.2011.5953354	mathematical optimization;engineering;operations management;machine learning	Theory	14.649155894502853	4.998425893957467	12702
6e87ffc4723d6179719b5ee4be11e4831da928d6	frame: fast and realistic attacker modeling and evaluation for temporal logical correlation in static noise.		We propose a method called Fast and Realistic Attacker Modeling and Evaluation (FRAME) that can reduce pessimism in static noise analysis by exploiting temporal logical correlation of attackers and using novel techniques termed envelopes and σ functions. Unlike conventional pruningbased approaches, FRAME efficiently considers all relevant attackers, thereby producing more realistic results. FRAME was tested with complex industrial design and successfully reduced the pessimism of conventional techniques by 30.4% on average, with little computational overhead.	overhead (computing)	Sungroh Yoon;Nahmsuk Oh;Peivand F. Tehrani;Eui-Young Chung;Giovanni De Micheli	2015	CoRR		noise (radio);computer science;overhead (computing);theoretical computer science;real-time computing;correlation	EDA	25.82906264956694	54.68781504001833	12716
7c5ad6113b41d856846298f3781090695cac0d97	physical-hybrid simulation for in-situ evaluation of energy storage system	power generation control;batteries battery charge measurement load flow discharges electric load modeling current measurement;control algorithm physical hybrid simulation in situ evaluation grid size battery energy storage system grid interaction grid location scaling factor physical installation capacity power rating grid size storage battery physical behavior;battery storage plants;power grids battery storage plants power generation control;power grids;smart grid energy storage batteries battery management systems power system analysis computing power system management load flow power system simulation	This paper presents a method for testing of a grid-size battery energy storage system and its interaction with the grid. The method uses a real installation with relatively small storage capacity which is combined with a simulation model of the grid. The storage is cycled based on measurements from the potential grid location and desired application. A scaling factor is used to relate the physical installation capacity and power ratings with the grid-size storage in the simulation model. Such a hybrid method allows evaluating grid-size storage installations without disturbing the grid. The physical behavior of the battery and control algorithm can be evaluated under realistic conditions without the need to construct a full grid-size storage installation. An experiment is described in this paper were the method is applied to an actual grid and battery storage installation.	algorithm;computer data storage;experiment;image scaling;simulation	Nicholas Etherden;Leopold Weingarten;Math H. J. Bollen	2012	2012 3rd IEEE PES Innovative Smart Grid Technologies Europe (ISGT Europe)	10.1109/ISGTEurope.2012.6465763	embedded system;electronic engineering;base load power plant;load balancing;engineering;electrical engineering;stand-alone power system;smart grid;distributed generation;grid-connected photovoltaic power system	HPC	4.468674647734439	5.963059098190444	12725
2d7680513dca55529d2a35c06883a6af0aed1fd5	decidability of string graphs	string graph recognition;nondeterministic exponential time;artificial intelligence;j. combin;long-standing open problem;fundamental problem;string graph;old open problem;general theory;euler diagram;artificial intelligent;second order;upper bound	We show that string graphs can be recognized in nondeterministic exponential time by giving an exponential upper bound on the number of intersections for a minimal drawing realizing a string graph in the plane. This upper bound confirms a conjecture by Kratochvíl and Matousek (J. Combin. Theory. Ser. B 53 (1991).) and settles the long-standing open problem of the decidability of string graph recognition (Bell System Tech. J. 45 (1996) 1639; Open Problem at Fifth Hungarian Collogium on Combinatories, 1976). Finally we show how to apply the result to solve another old open problem: deciding the existence of Euler diagrams, a fundamental problem of topological inference (Proceedings of the 14th International Joint Conference on Artificial Intelligence, 1995, p. 901). The general theory of Euler diagrams turns out to be as hard as second-order arithmetic.		Marcus Schaefer;Daniel Stefankovic	2004	J. Comput. Syst. Sci.	10.1016/j.jcss.2003.07.002	combinatorics;discrete mathematics;mathematics;upper and lower bounds;finite field;second-order logic;algorithm;algebra	Theory	26.439573338004006	24.09316536572585	12733
6db88b482cc4261f8f44f2db2934128e0890e3f3	hybrid digital/analog computer systems	control systems;concurrent computing;application software;cost saving;hybrid digital analog;spectrum;analog computation;analog computers mathematical model concurrent computing computer interfaces application software control systems;operating system;analog computers;hybrid system;mathematical model;computer interfaces;processing speed	In contrast to the crude analog-digital combinations of the 1960's, today's hybrids are true multiprocessors supported by realtime operating systems. Their solid-state analog computing elements loaded digitally in microseconds, together with their equation-oriented compilers, provide efficient, automatic setup and high productivity. Teamed with flexible, low-cost alphanumeric/graphic displays, modern hybrids are being applied over the full spectrum of scientific and engineering studies. Since the average hybrid system has an equivalent digital processing speed of over 10 million operations per second, at less than one-tenth the cost of large digital data processors, typical users realize cost savings of over 100/1.	analog computer;central processing unit;compiler;computation;computer program;digital data;electronic data processing;flops;flip-flop (electronics);hybrid computer;hybrid system;operating system;programming language;requirement;simulation	J. Paul Landauer	1976	Computer	10.1109/C-M.1976.218640	spectrum;analog computer;application software;real-time computing;concurrent computing;computer science;theoretical computer science;operating system;software engineering;mathematical model;hybrid computer;hybrid system	Arch	5.101449776512878	47.65528249070693	12765
f283078df3653e1e5d487234bcd127226f54c0e1	the monadic quantifier alternation hierarchy over grids and graphs	second order;theorie automate;hierarchie polynomiale;funcion exponencial;fonction exponentielle;quantifier;exponential function;clase complejidad;orden 2;logica monadica;graphe fini;finite graph;reducibility;reductibilidad;monadic second order;grafo finito;two dimensional grids;codificacion;first order;classe complexite;complexity class;monadic hierarchy;monadic second order logic;polynomial hierarchy;informatique theorique;directed graph;quantificateur;graphe oriente;logique monadique;coding;automata theory;monadic logic;grille 2 dimensions;grafo orientado;teoria automata;ordre 2;cuantificador;hierarchie monadique;codage;computer theory;reductibilite;informatica teorica	"""The monadic second-order quantiier alternation hierarchy over the class of nite graphs is shown to be strict. The proof is based on automata theoretic ideas and starts from a restricted class of graph-like structures, namely nite two-dimensional grids. Considering grids where the width is a function of the height, we prove that the diierence between the levels k +1 and k of the monadic hierarchy is witnessed by a set of grids where this function is (k + 1)-fold exponential. We then transfer the hierarchy result to the class of directed (or undirected) graphs, using an encoding technique called \strong reduction"""". It is notable that one can obtain sets of graphs which occur arbitrarily high in the monadic hierarchy but are already deenable in the rst-order closure of existential monadic second-order logic. We also verify that these graph properties even belong to the complexity class NLOG, which indicates a profound diierence between the monadic hierarchy and the polynomial hierarchy."""	automata theory;complexity class;graph (discrete mathematics);graph property;like button;polynomial hierarchy;quantifier (logic);time complexity	Oliver Matz;Nicole Schweikardt;Wolfgang Thomas	2002	Inf. Comput.	10.1006/inco.2002.2955	complexity class;combinatorics;discrete mathematics;directed graph;computer science;exponential function;first-order logic;automata theory;mathematics;coding;monadic predicate calculus;analytical hierarchy;second-order logic;algorithm;algebra	Logic	-4.532835510343261	20.78271936118547	12767
cfd424695d6b65970c964dc8687193adccdc0185	an fpga-based multi-core approach for pipelining computing stages	task level pipelining;fpga;producer consumer data communication;multi core processors	In recent years, there has been increasing interest on using task-level pipelining to accelerate the overall execution of applications mainly consisting of Producer-Consumer tasks. This paper proposes an approach to achieve pipelining execution of Producer-Consumer pairs of tasks in FPGA-based multi-core architectures. Our approach is able to speedup the overall execution of successive, data-dependent tasks, by using multiple cores and specific customization features provided by FPGAs. An important component of our approach is the use of customized inter-stage buffer schemes to communicate data and to synchronize the cores associated to the Producer-Consumer tasks. In order to improve performance, we propose a technique to optimize out-of-order Producer-Consumer pairs where the consumer uses more than once each data element produced, a behavior present in many applications (e.g., in image processing). All the schemes and optimizations proposed in this paper were evaluated with FPGA implementations. The experimental results show the feasibility of the approach in both in-order and out-of-order Producer-Consumer tasks. Furthermore, the results using our approach to task-level pipelining and a multi-core architecture reveal noticeable performance improvements for a number of benchmarks over a single core implementation without using task-level pipelining.	data dependency;data element;field-programmable gate array;image processing;intel core (microarchitecture);multi-core processor;pipeline (computing);producer–consumer problem;speedup	Ali Azarian;João M. P. Cardoso;Stephan Werner;Jürgen Becker	2013		10.1145/2480362.2480647	multi-core processor;software pipelining;computer architecture;parallel computing;real-time computing;computer science;operating system;field-programmable gate array	Embedded	-2.2101701668023193	49.74240940188027	12771
d7811a4c24f0d960b48e11389d057d5910579b3d	simultaneous orthogonal planarity		We introduce and study the OrthoSEFE-k problem: Given k planar graphs each with maximum degree 4 and the same vertex set, do they admit an OrthoSEFE, that is, is there an assignment of the vertices to grid points and of the edges to paths on the grid such that the same edges in distinct graphs are assigned the same path and such that the assignment induces a planar orthogonal drawing of each of the k graphs? We show that the problem is NP-complete for k ≥ 3 even if the shared graph is a Hamiltonian cycle and has sunflower intersection and for k ≥ 2 even if the shared graph consists of a cycle and of isolated vertices. Whereas the problem is polynomial-time solvable for k = 2 when the union graph has maximum degree five and the shared graph is biconnected. Further, when the shared graph is biconnected and has sunflower intersection, we show that every positive instance has an OrthoSEFE with at most three bends per edge.	biconnected graph;decision problem;hamiltonian path;karp's 21 np-complete problems;planarity;polynomial;time complexity	Patrizio Angelini;Steven Chaplick;Sabine Cornelsen;Giordano Da Lozzo;Giuseppe Di Battista;Peter Eades;Philipp Kindermann;Jan Kratochvíl;Fabian Lipp;Ignaz Rutter	2016		10.1007/978-3-319-50106-2_41	outerplanar graph;block graph;graph power;combinatorics;discrete mathematics;independent set;topology;multiple edges;graph bandwidth;degree;regular graph;hypercube graph;cycle graph;path graph;mathematics;geometry;biconnected graph;circle graph;complement graph;chordal graph;indifference graph;book embedding;line graph;string graph;planar graph	Theory	26.536684021405158	27.326129232348887	12781
af813309a3d8543dad9b558144cfaba31b794601	subtraction of two 2d polygons with some matching vertices		Cutting Stock Problem (CSP) is an important industrial problem. In this paper we focus on the variant arising in building construction, where a set of plates needs to be cut from rectangular stock, minimizing the waste. The CSP is known to be NP-hard combinatorial problem. The goal of this work is to propose an efficient way for subtracting of two polygons with some matching vertices.		Georgi Evtimov;Stefka Fidanova	2018		10.1007/978-3-030-10692-8_9	combinatorics;subtraction;polygon;cutting stock problem;vertex (geometry);computer science	Robotics	27.723609029079263	16.591008408183153	12786
2dd76ffa5ca7643598d66735a1755365c2e15af0	on constacyclic codes over z4[u]/〈u2-1〉 and their gray images		We first define a new Gray map from R = Z4+uZ4 to Z 2 4, where u 2 = 1 and study (1 + 2u)-constacyclic codes over R. Also of interest are some properties of (1 + 2u)constacyclic codes over R. Considering their Z4 images, we prove that the Gray images of (1+2u)-constacyclic codes of length n over R are cyclic codes of length 2n over Z4. In many cases the latter codes have better parameters than those in the online database of Aydin and Asamov. We also give a corrected version of a table of new cyclic R-codes published by Özen et al. in Finite Fields and Their Applications, 38, (2016) 27-39.	code;open research;z4 (computer)	Minjia Shi;Liqin Qian;Lin Sok;Nuh Aydin;Patrick Solé	2017	Finite Fields and Their Applications	10.1016/j.ffa.2016.11.016	arithmetic;mathematics	Theory	42.57521977178501	55.131755966108564	12788
b39cc63b5f982e32f40190d0ebc16690f4341527	infinite graphs with finite dominating sets		In this paper, we study the infinite graphs which admit a finite dominating set. The main contribution of the work is two folds: (i) characterization of infinite trees and hence infinite connected graphs with a finite dominating set, (ii) it is shown that apart from a family of graphs, all infinite graphs or their complements possess a finite dominating set. Moreover, some conditions of existence of finite dominating sets in product graphs are studied.	dominating set	Angsuman Das	2017	Discrete Math., Alg. and Appl.	10.1142/S1793830917500537	mathematics;combinatorics;discrete mathematics;pathwidth;chordal graph;indifference graph;dominating set;infinite set;bidimensionality;maximal independent set;spanning tree	Theory	33.00645852746809	27.573576116225667	12792
a6274abba92ab8cfc7549a74a059aca2f06ffef8	parallel algorithms for the domination problems in trapezoid graphs	parallel algorithm;interval graph;total domination;independent domination;domination;permutation graph;connected domination;trapezoid graph	Trapezoid graphs are a superclass of permutation graphs and interval graphs. This paper presents first parallel algorithms for the independent domination, total domination, connected domination and domination problems in weighted trapezoid graphs. All these algorithms take O(log’n) time on a EREW PRAM. The number of processors required is O(max{n3/log2 n,n2.376}) for th e independent domination problem, and O(max {nm2/log2 n, m2.376 }) for the other domination problems, where m is the number of edges in a trapezoid graph of n vertices.	central processing unit;dominating set;parallel algorithm;parallel random-access machine	Y. Daniel Liang	1997	Discrete Applied Mathematics	10.1016/S0166-218X(96)00052-2	combinatorics;discrete mathematics;interval graph;topology;domination analysis;permutation graph;trapezoid graph;mathematics;parallel algorithm	Theory	24.109828847092047	28.009125257800555	12809
dbba3a94379ade6c93dfecad28b7822a539b3f91	coverage of irrelevant components in systems with imperfect fault coverage	fault tree;fault tolerance		fault coverage;relevance	Jianwen Xiang;Fumio Machida;Kumiko Tadano;Yoshiharu Maeno;Kazuo Yanoo	2013	IEICE Transactions		fault tolerance;fault;real-time computing;fault tree analysis;fault coverage;distributed computing	EDA	23.38453311330609	49.387751259812866	12835
fea015038476af8f42dc81060ab9b0870e9de15f	synchronizing triple modular redundant designs in dynamic partial reconfiguration applications	triple modular redundant;fault tolerant;dynamic partial reconfiguration;partial reconfiguration;fpga;fault tolerance;tmr;fault recovery	This paper presents an innovative method that allows the use of dynamic partial reconfiguration combined with triple modular redundancy (TMR) in SRAM-based FPGAs fault-tolerant designs. The method uses large grain TMR with special voters capable of signalizing the faulty module, and check point states that allow the sequential synchronization of the recovered module. As a result, only the faulty domain is reconfigured, minimizing time and energy spent in the process. In addition, the use of check-point states avoids system downtime, since the synchronization of the recovered module is performed while the others are kept running. Experimental results show that the method has a reduced fault recovery time compared to the standard TMR implementation, maintaining the compatible area overhead and performance.	algorithm;cyclic redundancy check;downtime;fault tolerance;field-programmable gate array;internet protocol suite;overhead (computing);static random-access memory;triple modular redundancy	Conrado Pilotto;José Rodrigo Azambuja;Fernanda Gusmão de Lima Kastensmidt	2008		10.1145/1404371.1404426	embedded system;fault tolerance;parallel computing;real-time computing;computer science;engineering	EDA	7.1868099069001214	58.30528130718759	12843
2ef154c82f27c2014fa3f578c5a4e98af0230393	comparison of floating gate neural network memory cells in standard vlsi cmos technology	silicon;analogue storage;cmos integrated circuits;memoire;concepcion circuito;implantation topometrie;transistor efecto campo;programmation;integrated circuit;polycristal;neural nets;transistor effet champ;floating gate;implementation;circuit design;circuit vlsi;circuito integrado;layout;tecnologia mos complementario;polycrystal;inyeccion portador carga;programacion;ejecucion;vlsi analogue storage cmos integrated circuits content addressable storage neural nets;vlsi circuit;memoria;cmos technology nonvolatile memory neural networks intelligent networks very large scale integration computer architecture tunneling cmos process analog memory circuits;policristal;field effect transistor;vlsi;conception circuit;circuito vlsi;2 micron double polysilicon process charging characteristics floating gate neural network memory cells vlsi cmos technology floating gate mosfet structures analog memory elements programming characteristics discharging characteristics voltage magnitudes geometric field enhancement techniques diffusion oxide coupling capacitor capacitor ratios;reseau neuronal;silicium;technologie mos complementaire;transistor mos grille flottante;content addressable storage;programming;charge carrier injection;red neuronal;silicio;circuit integre;complementary mos technology;memory;floating gate mos transistor;injection porteur charge;neural network;transistor mos rejilla flotante;implantacion topometria	Several floating gate MOSFET structures, for potential use as analog memory elements in neural networks, have been fabricated in a standard 2 mum double-polysilicon CMOS process. Their physical and programming characteristics are compared with each other and with similar structures reported in the literature. None of the circuits under consideration require special fabrication techniques. The criteria used to determine the structure most suitable for neural network memory applications include the symmetry of charging and discharging characteristics, programming voltage magnitudes, the area required, and the effectiveness of geometric field enhancement techniques. This work provides a layout for an analog neural network memory based on previously unexplored criteria and results. The authors have found that the best designs (a) use the poly1 to poly2 oxide for injection; (b) need not utilize ;field enhancement' techniques; (c) use poly1 to diffusion oxide for a coupling capacitor; and (d) size capacitor ratios to provide a wide range of possible programming voltages.	analog;artificial neural network;biological neural networks;cmos;capacitor device component;emoticon;neural network simulation;semiconductor device fabrication;very-large-scale integration;voltage	David A. Durfee;F. S. Shoucair	1992	IEEE transactions on neural networks	10.1109/72.129407	layout;field-effect transistor;embedded system;programming;computer science;integrated circuit;machine learning;circuit design;very-large-scale integration;silicon;memory;implementation;cmos;artificial neural network	EDA	50.861981512211734	47.464260609146486	12844
fa20d7f824f97b36c44ad28626dea75a1b82c56a	maximum distance separable codes over z4 and z2 ×\mathbbz4	94b25;94b60;minimum distance bounds;additive codes;maximum distance separable codes	Known upper bounds on the minimum distance of codes over rings are applied to the case of Z2Z4-additive codes, that is subgroups of Zα2 × Zβ4 . Two kinds of maximum distance separable codes are studied. We determine all possible parameters of these codes and characterize the codes in certain cases. The main results are also valid when α = 0, namely for quaternary linear codes.	code;mds matrix;singleton bound;z2 (computer);z4 (computer)	Muhammad Bilal;Joaquim Borges;Steven T. Dougherty;Cristina Fernández-Córdoba	2011	Des. Codes Cryptography	10.1007/s10623-010-9437-1	combinatorics;discrete mathematics;topology;mathematics	Theory	40.22153608222826	53.62120271853937	12859
03cb6fd80fc114742ddd86b1a7d87a8caac24cf7	an l(1/3) algorithm for discrete logarithm computation and principality testing in certain number fields		We analyse the complexity of solving the discrete logarithm problem and of testing the principality of ideals in a certain class of number fields. We achieve the subexponential complexity in O(L(1/3, O(1))) when both the discriminant and the degree of the extension tend to infinity by using techniques due to Enge, Gaudry and Thomé in the context of algebraic curves over finite fields.	algorithm;computation;discrete logarithm;discriminant;kolmogorov complexity;linear algebra	Jean-François Biasse	2012	CoRR		combinatorics;discrete mathematics;mathematics;geometry;algebra	Crypto	44.323133630809984	38.64272533513685	12860
917638282652846c6996b2ed850bb5074e31041f	searching a polygonal room with one door by a 1-searcher	search strategy;pursuit evasion;visibility;motion planning;graph algorithm	The 1-searcher is a mobile guard whose visibility is limited to a ray emanating from his position, where the direction of the ray can be changed continuously with bounded angular rotation speed. Given a polygonal region P with a specified boundary point d, is it possible for a 1-searcher to eventually see a mobile intruder that is arbitrarily faster than the searcher within P, before the intruder reaches d? We decide this question in O(n log n)-time for an n-sided polygon. Our main result is a simple characterization of the class of polygons (with a boundary point d) that admits such a search strategy. We also present a simple O(n)-time algorithm for constructing a search schedule, if one exists. Finally, we compare the search capability of a 1-searcher with that of two guards.	algorithm;angularjs	Jae-Ha Lee;Sang-Min Park;Kyung-Yong Chwa	2000	Int. J. Comput. Geometry Appl.	10.1142/S0218195900000127	mathematical optimization;combinatorics;simulation;visibility;computer science;mathematics;geometry;motion planning	Theory	31.471510175396013	18.322798118348814	12886
21461f2e3a3b9730cee32b0bd0188194b9bbbed8	stabbing horizontal segments with vertical rays	ray stabbing;segment intersection;external memory;data structure;dynamic	We consider maintaining a dynamic set S of N horizontal segments in R2 such that, given a vertical ray Q in R2, the segments in S intersecting Q can be reported efficiently. In the external memory model, we give a structure that consumes O(N/B) space, answers a query in O(logB N + K/B) time (where K is the number of reported segments), and can be updated in O(logB N) amortized time per insertion and deletion. With B set to a constant, the structure also works in internal memory, consuming space O(N), answering a query in O(log N + K) time, and supporting an update in O(log N) amortized time.	amortized analysis;computer data storage	Yufei Tao	2012		10.1145/2261250.2261298	arithmetic;auxiliary memory;data structure;mathematics;programming language;algorithm	Theory	13.950559951112153	28.27027726396954	12890
47eaa57930475c61f48649c9f4cc336ebe9cf430	lower bounds of isoperimetric functions for nilpotent groups			isoperimetric inequality	José Burillo	1994			isoperimetric inequality;nilpotent group;algebra;mathematics;topology;nilpotent	Logic	45.18799697166577	30.369460825975438	12936
175adde7050f4545aef1b5e31d443add8e3705cf	distance type and common fixed point theorems in menger probabilistic metric type spaces	54e40;fixed point theorem;menger space;54e35;complete probabilistic metric type space;54h25;nonlinear probabilistic contractive mapping	In this paper, we introduce the concept of rt-distance on a Menger probabilistic metric type space. Further we prove some fixed point theorems in a complete Menger probabilistic metric type space which generalizes some famous fixed point theorems.	fixed point (mathematics);menger sponge	Afrah A. N. Abdou;Yeol Je Cho;Reza Saadati	2015	Applied Mathematics and Computation	10.1016/j.amc.2015.05.052	convex metric space;mathematical analysis;discrete mathematics;injective metric space;topology;intrinsic metric;menger's theorem;mathematics;fixed-point theorem	Theory	45.376385406596555	23.670436400638387	12957
f3666146774a8a38e2f8aaedaf8ff408df809805	acyclic colorings of products of trees	code hamming;coloracion grafo;procesamiento informacion;hamming codes;tree;algorithm analysis;arbol;coloring;interconnection network;trees;codigo hamming;coloration graphe;producto grafo;graph products;informatique theorique;information processing;interconnection networks;arbre;analyse algorithme;hamming code;traitement information;graphe produit;graph product;analisis algoritmo;red interconexion;produit graphe;graph colouring;computer theory;reseau interconnexion;informatica teorica	We obtain bounds for the coloring numbers of products of trees for three closely related types of colorings: acyclic, distance 2, and L(2,1).	directed acyclic graph;graph coloring	Robert E. Jamison;Gretchen L. Matthews;John Villalpando	2006	Inf. Process. Lett.	10.1016/j.ipl.2005.11.023	combinatorics;discrete mathematics;information processing;computer science;hamming code;mathematics;greedy coloring;algorithm	DB	24.099344465452027	30.020429413670545	12959
7058c0d8593591bb73555b97e89577bb41ee2a3e	toward an uncertainty principle for weighted graphs	eigenvalues and eigenfunctions;uncertainty principle;weighted graphs signal processing on graphs uncertainty principle;uncertainty;uncertainty europe symmetric matrices eigenvalues and eigenfunctions spectral analysis context;signal processing graph theory;weighted graphs;symmetric matrices;signal processing uncertainty principle weighted graphs spectral domains graph domains graph structure inverse similarity matrix distance function;signal processing on graphs;europe;spectral analysis;context	The uncertainty principle states that a signal cannot be localized both in time and frequency. With the aim of extending this result to signals on graphs, Agaskar & Lu introduce notions of graph and spectral spreads. They show that a graph uncertainty principle holds for some families of unweighted graphs. This principle states that a signal cannot be simultaneously localized both in graph and spectral domains. In this paper, we aim to extend their work to weighted graphs. We show that a naive extension of their definitions leads to inconsistent results such as discontinuity of the graph spread when regarded as a function of the graph structure. To circumvent this problem, we propose another definition of graph spread that relies on an inverse similarity matrix. We also discuss the choice of the distance function that appears in this definition. Finally, we compute and plot uncertainty curves for families of weighted graphs.	computable function;lu decomposition;reflections of signals on conducting lines;similarity measure;uncertainty principle	Bastien Pasdeloup;Réda Alami;Vincent Gripon;Michael G. Rabbat	2015	2015 23rd European Signal Processing Conference (EUSIPCO)	10.1109/EUSIPCO.2015.7362633	1-planar graph;outerplanar graph;pathwidth;topological graph theory;mathematical optimization;split graph;combinatorics;discrete mathematics;uncertainty principle;cograph;universal graph;uncertainty;graph product;forbidden graph characterization;comparability graph;mathematics;modular decomposition;partial k-tree;vertex-transitive graph;chordal graph;indifference graph;line graph;adjacency matrix;statistics;symmetric matrix	AI	53.26474588521073	19.187557057834784	12976
2fa451b6e2164e0df421101a987a61fca7129cfd	minimum depth arcs-disjoint spanning trees for broadcasting on wrap-around meshes	spanning tree		file spanning	Philippe Michallon;Denis Trystram	1995			distributed computing;arc (geometry);polygon mesh;minimum spanning tree;minimum degree spanning tree;disjoint sets;computer science;spanning tree;broadcasting	Theory	25.95169999191913	33.95696428755147	12981
8b41ca5d078d47bef6415334e97d383fa907549a	swift: software implemented fault tolerance	instruction level resource;error correction codes;software technique;clocks;redundancy software fault tolerance error correction codes storage management program processors fault diagnosis;storage management;resource management;reliable system;software fault tolerance;control flow checking mechanism;software implemented fault tolerance;program execution;process design;noise level;redundancy;noise reduction;single threaded approach;transient fault detection technique;fault tolerance;voltage;control flow;memory system swift software implemented fault tolerance reliable system hardware technique soft errors software technique transient fault detection technique redundancy instruction level resource program execution control flow checking mechanism single threaded approach;transient fault;fault tolerance process design voltage noise reduction noise level clocks power system reliability hardware resource management redundancy;memory systems;fault coverage;power system reliability;soft errors;hardware technique;memory system;swift;program processors;soft error;fault diagnosis;hardware	To improve performance and reduce power, processor designers employ advances that shrink feature sizes, lower voltage levels, reduce noise margins, and increase clock rates. However, these advances make processors more susceptible to transient faults that can affect correctness. While reliable systems typically employ hardware techniques to address soft-errors, software techniques can provide a lower-cost and more flexible alternative. This paper presents a novel, software-only, transient-fault-detection technique, called SWIFT. SWIFT efficiently manages redundancy by reclaiming unused instruction-level resources present during the execution of most programs. SWIFT also provides a high level of protection and performance with an enhanced control-flow checking mechanism. We evaluate an implementation of SWIFT on an Itanium 2 which demonstrates exceptional fault coverage with a reasonable performance cost. Compared to the best known single-threaded approach utilizing an ECC memory system, SWIFT demonstrates a 51% average speedup.	central processing unit;clock rate;control flow;correctness (computer science);ecc memory;fault coverage;fault tolerance;high-level programming language;itanium;noise margin;redundancy (engineering);speedup;swift (programming language);thread (computing)	George A. Reis;Jonathan Chang;Neil Vachharajani;Ram Rangan;David I. August	2005	International Symposium on Code Generation and Optimization	10.1109/CGO.2005.34	process design;embedded system;fault tolerance;parallel computing;real-time computing;voltage;fault coverage;soft error;computer science;resource management;operating system;noise reduction;swift;redundancy;programming language;control flow;software fault tolerance	Arch	7.236554273154382	59.64371039033272	12988
244284d0af48b53423cfe229437fbe662b191c71	an efficient method to transform sat problems to binary integer linear programming problem		In computational complexity theory, a decision problem is NP-complete when it is both in NP and NP-hard. Although a solution to a NP-complete can be verified quickly, there is no known algorithm to solve it in polynomial time. There exists a method to reduce a SAT (Satifiability) problem to Subset Sum Problem (SSP) in the literature, however, it can only be applied to small or medium size problems. Our study is to find an efficient method to transform a SAT problem to a mixed integer linear programming problem in larger size. Observing the feature of variable-clauses constraints in SAT, we apply linear inequality model (LIM) to the problem and propose a method called LIMSAT. The new method can work efficiently for very large size problem with thousands of variables and clauses in SAT tested using up-to-date benchmarks. keywords: SAT(Satisfiability problem); BinaryILP(Integer Linear programing); 3SAT; Reduction	algorithm;benchmark (computing);boolean satisfiability problem;computational complexity theory;decision problem;integer programming;linear inequality;linear programming;np (complexity);np-completeness;np-hardness;polynomial;social inequality;subset sum problem;time complexity	Wenxia Guo;Zhongjing Wang;Majun He;Xiaoqin Ren;Wenhong Tian;Qingxian Wang	2018	CoRR		discrete mathematics;subset sum problem;time complexity;binary integer decimal;computational complexity theory;mathematics;linear inequality;decision problem;integer programming;linear programming	AI	25.89414353015339	9.020199418437738	12989
3490892729c5f1327c1ef1690331889458fe66d4	computation of diagnosable fault-occurrence indices for systems with repeatable faults	repeated failures;fault diagnosis delay fault detection discrete event systems logic safety filling production facilities communication networks routing;fault occurrence diagnosis;systeme evenement discret;communication networks;algorithm complexity;routing;intermittent faults;complejidad algoritmo;logic;filling;diagnosability;integer partition;repeated faults discrete event systems fault diagnosis fault occurrence diagnosis integer partitioning problem intermittent faults;sistema acontecimiento discreto;discrete event system;diagnosable fault occurrence indices;intermitencia;failure diagnosis;complexite algorithme;diagnostic panne;repeated faults;computational complexity;fault diagnostic;indexation;fault detection;safety;fault diagnosis computational complexity discrete event systems;diagnostico pana;production facilities;discrete event systems;intermittency;fault occurrence index diagnosable fault occurrence indices repeatable faults discrete event systems cubic complexity;repeatable faults;intermittence;repeated failures discrete event systems failure diagnosis;integer partitioning problem;diagnostiquabilite;fault diagnosis delay discrete event systems system testing fault detection production facilities communication networks routing polynomials logic;cubic complexity;fault occurrence index;fault diagnosis	Certain faults, such as intermittent or non-persistent faults, may occur repeatedly. For discrete-event systems prone to repeated faults, Jiang, Kumar, and Garcia in 2003 introduced the notion of l-diagnosability requiring the diagnosis of the l th occurrence of a fault within a bounded delay. The present paper studies the identification of the set of all indices l for which the system is not l-diagnosable. (These are precisely the occurrence indices for which a repeatable-fault cannot be diagnosed.) We present an algorithm of cubic complexity to determine whether a system is diagnosable for every fault-occurrence index. For those systems for which the answer is negative, we show that the set of indices for which the system is non-diagnosable possesses the property that it is either finite or consists of a finite number of eventually periodic sets.	algorithm;automaton;computation;computational complexity theory;cryptanalysis of the lorenz cipher;cubic function;obedience (human behavior);software bug	Changyan Zhou;Ratnesh Kumar	2005	Proceedings of the 44th IEEE Conference on Decision and Control	10.1109/TAC.2009.2022093	reliability engineering;routing;real-time computing;computer science;mathematics;distributed computing;logic	EDA	23.94120506229866	43.7103809152495	13009
22234a239e763012023adbd546fba48c66378602	5t sram with asymmetric sizing for improved read stability	stability criteria;topology;random access memory;sram chips circuit stability;measurement;sensors;circuit stability;inverters;static noise margin;single ended bitcell;5t sram;5t sram asymmetric sizing single ended bitcell static noise margin;transistors;asymmetric sizing;voltage 0 5 v 5 transistor sram 6 transistor sram read stability sram design sizing asymmetry test chip write assists single ended bitcell size 45 nm voltage 0 7 v;transistors random access memory measurement inverters sensors stability criteria topology;sram chips	Conventional 6-transistor (6T) SRAM scaling to newer technologies and lower supply voltages is difficult due to a complex trade-off space involving stability, performance, power, and area. Local and global variation make SRAM design even more challenging. We present a 5-transistor (5T) bitcell that uses sizing asymmetry to improve read stability and to provide an efficient knob for trading off the aforementioned metrics. In this paper, we compare the 5T with the conventional 6T and the 8T and show how it can be a flexible, intermediate alternative between the two. We also investigate single-ended sensing for the 5T. Finally, we present measurement results in a 45 nm test chip that demonstrate the functionality of the 5T. Through a combination of write assists, the 5T can demonstrate comparable writability down to 0.7 V, while showing no read errors down to 0.5 V.	best, worst and average case;bit cell;cmos;control knob;heart rate variability;image scaling;inverter (logic gate);single-ended signaling;spectral leakage;static random-access memory	Satyanand Nalam;Benton H. Calhoun	2011	IEEE Journal of Solid-State Circuits	10.1109/JSSC.2011.2160812	electronic engineering;real-time computing;engineering;sensor;electrical engineering;transistor;measurement	Arch	18.20075708722077	59.32235376859226	13040
59a87fa3767e0e84dca0d02d76efe329928b3769	synthèse comportementale sous contraintes de communication et de placement mémoire pour les composants du tdsi		The design of complex Digital Signal Processing systems implies to minimize architectural cost and to maximize timing performances while taking into account communication and memory accesses constraints for the integration of dedicated hardware accelerator. Unfortunately, the traditional Matlab/ Simulink design flows gather not very flexible hardware blocs. In this paper, we present a methodology and a tool that permit the High-Level Synthesis of DSP applications, under both I/O timing and memory constraints. Based on formal models and a generic architecture, our tool GAUT helps the designer in finding a reasonable trade-off between the circuit’s performance and its architectural complexity. The efficiency of our approach is demonstrated on the case study of a FFT algorithm.	algorithm;digital signal processing;fast fourier transform;hardware acceleration;high-level synthesis;input/output;linear algebra;performance;simulink	Gwenolé Corre;Philippe Coussy;Pierre Bomel;Eric Senn;Eric Martin	2005	CoRR		matlab;architecture;fast fourier transform;real-time computing;digital signal processing;design flow;computer science;hardware acceleration;high-level synthesis	EDA	1.912758927230039	52.59624305511074	13046
f43063626ef55186982faa6b958b6c0817e3171e	split decomposition over an abelian group, part 2: group-valued split systems with weakly compatible support	05xx;split decomposition;abelian group;optimisation;metric system;groupoide;combinatorics;optimizacion;phylogenetic combinatorics;grupo abeliano;combinatoria;teoria sistema;metodo descomposicion;group valued split systems;combinatoire;methode decomposition;transformation farris;weakly compatible split systems;splits;conceptual framework;decomposition systeme;systeme metrique;decomposition method;farris transformation;systems theory;groupoid;grupoide;group valued set systems;informatique theorique;theorie systeme;20kxx;system decomposition;split group;optimization;split systems;abelian groups;point of view;groupe abelien;68r05;descomposicion sistema;groupoids;sistema metrico;20l05;phylogenetic diversity;computer theory;groupe deploye;informatica teorica	Split-decomposition theory deals with relations between R-valued split systems and metrics. In a previous publication (the first of a series of papers on split decomposition over an abelian group), a general conceptual framework has been set up to study these relationships from an essentially algebraic point of view, replacing metrics by certain more general, appropriately definedmultivariatemaps, and considering group-valued split systems that take their values in an arbitrary abelian group. Here, we make use of this set up and establish the principal results of split-decomposition theory regarding split systems with weakly compatible support within this new algebraic framework. © 2008 Elsevier B.V. All rights reserved. 1. Why is decomposition theory of interest in phylogenetic analysis? Given a collection X of (biological) species, it is one of the most basic tasks in phylogenetic analysis to identify all monophyletic clades in X , i.e., all subsets C of X that consist of all species in X that are offspring of a single ancestral species while none of the species in the complement X − C of C have evolved from that ancestral species. However, as Charles Darwin put it in his treatise THE DESCENT OF MAN, as we have no record of the lines of descent, the pedigree can be discovered only by the degrees of resemblance between the beings which are to be classed. That is, all that we commonly can rely on to identify the collection of all monophyletic clades in X is information about how distinct, or how similar, the present-day species are that make up the set X . Consequently, a standard assumption in phylogenetic analysis is that, together with a finite set X of species, we are given a metric D defined on X1 that quantifies that degree of resemblance between the species contained in X . And the task one has to address can then be described as that of designing a method for deriving a phylogenetic X-tree T = T (D) from these data that – at least approximatively – represents themetric D. That is, one wants to find a finite edge-weighted and X-labeled tree T = (V , E, `;φ) consisting of ∗ Corresponding address: Department for Combinatorics and Geometry, CAS-MPG Partner Institute for Computational Biology, Shanghai Institutes for Biological Sciences, Chinese Academy of Sciences, Shanghai, China. Tel.: +86 21 549 204 58; fax: +86 21 549 204 51. E-mail addresses: dress@sibs.ac.cn, dress@mis.mpg.de, andreas@picb.ac.cn. 1 That is, a map D : X × X → R for which D(x, x) = 0 and D(x, y) ≤ D(x, z)+ D(y, z) hold for all x, y, z ∈ X . 0166-218X/$ – see front matter© 2008 Elsevier B.V. All rights reserved. doi:10.1016/j.dam.2008.06.041 Please cite this article in press as: A. Dress, Split decomposition over an abelian group, Part 2: Group-valued split systems with weakly compatible support, Discrete Applied Mathematics (2008), doi:10.1016/j.dam.2008.06.041		Andreas W. M. Dress	2009	Discrete Applied Mathematics	10.1016/j.dam.2008.06.041	combinatorics;discrete mathematics;topology;elementary abelian group;mathematics;abelian group;algorithm;algebra	Theory	33.60406935849314	39.78095379650487	13057
6f49383b56f5dd2756feb9ba92ee9d5606eab232	mapping of an automated target recognition application from a graphical software environment to fpga-based reconfigurable hardware	manuals;software development system;field programmable gate arrays reconfigurable architectures;application software;convolution;reconfigurable architectures;automated target recognition;graphical software environment;multiple fpga based architectures;fpga;target recognition application software field programmable gate arrays computer architecture manuals convolution hardware microelectronics software tools programming;fpga design tools;multiple fpga based architectures automated target recognition reconfigurable hardware graphical software environment fpga based configurable computing hardware mapping applications champion software development system khoros;champion;computer architecture;fpga based;khoros;target recognition;mapping applications;software development;automatic target recognition;software tools;microelectronics;configurable computing;configurable computing hardware;field programmable gate arrays;programming;reconfigurable hardware;high level design tools;hardware	A significant obstacle to the widespread adoption of FPGAbased configurable computing hardware has been the difficulty of mapping applications onto this hardware. We are developing a software development system called CHAMPION to automate the process of mapping applications in the graphical software environment Khoros to multiple FPGA-based architectures. The work described here consists of the development of requirements for the library primitives used by CHAMPION and the manual mapping of an automatic target recognition algorithm onto FPGA hardware.	algorithm;automatic target recognition;computer hardware;field-programmable gate array;graphical user interface;reconfigurable computing;requirement;software development	Benjamin A. Levine;Senthil Natarajan;Chandra Tan;Danny F. Newport;Donald W. Bouldin	1999		10.1109/FPGA.1999.803702	embedded system;computer architecture;reconfigurable computing;computer science;fpga prototype;field-programmable gate array	HCI	3.458027698134514	49.93951405850978	13058
1f2517b47c0831ae7d9b2b4f009649248cfa4e9c	algebraic degree of the inverse of linearized polynomials	algebraic degree;computacion informatica;linearized polynomial;boolean function;upper bound;ciencias basicas y experimentales;linear code;grupo a;vector boolean function	The inverse of linearized polynomials might be a good candidate of vector Boolean functions for cryptographic applications since it is a generalization of the inverse function that is widely used in cryptographic primitives. In Crypto 2001, a construction method of vector resilient functions was proposed using linearized polynomials and linear codes. Unfortunately, the analysis of the algebraic degree of the inverse of linearized polynomials was wrong. In this paper, we correct the inexact result. More precisely, we give the exact maximal algebraic degree and an upper bound of the minimal algebraic degree.	algebraic equation;polynomial	Dong Hoon Lee	2008	J. Symb. Comput.	10.1016/j.jsc.2007.07.009	combinatorics;discrete mathematics;algebraic fraction;linear code;mathematics;real algebraic geometry;boolean function;upper and lower bounds;function field of an algebraic variety;algebraic expression;algebraic function;algebraic cycle;algorithm;algebra	Theory	45.28355384701049	40.36141202706842	13061
81357d6fe60262fba4f6e6bd50ccc02990dcfc59	effective communicating optimization for v2g with electric bus	v2g communications;sensors;companies;v2r communications;roads;data aggregation;batteries;vehicles;delays;ev	The number of connected devices — also known as Internet of Things (IoT) — is exponentially increasing. Such sensors and devices also appear in transportation systems giving some intelligence to roads, equipment and vehicles. Nowadays, it is possible to communicate with the environment in order to have better everyday services. Furthermore, the number of registered — public or private — Electric Vehicle (EVs) is continuously increasing. These vehicles, equipped with large battery, need to be charged and so, have a significant impact on power grids. However, these EVs can also be seen as energy sources. It is therefore important to be able to plan both the charge and discharge of EVs. Including these vehicles into Vehicle-to-Grid technology is a way to efficiently manage such pools of batteries. But, as a consequence, grid requires to have almost real-time data on these vehicles and especially their battery status. This paper studies an optimized data aggregation method for a fleet of electric buses. Each bus provides different type of information with different priority level. The efficiency of the studied method was evaluated with a simulation platform developed with ns-3. Simulation results — based on real route and bus stop positions — show that an optimal buffer size has been found to both satisfy transmission delays and optimize communications.	application programming interface;byte;data aggregation;data retrieval;discharger;internet of things;mathematical optimization;real-time data;sensor;simulation;vehicle-to-vehicle	Toshichika Shiobara;Guillaume Habault;Jean-Marie Bonnin;Hiroaki Nishi	2016	2016 IEEE 14th International Conference on Industrial Informatics (INDIN)	10.1109/INDIN.2016.7819306	simulation;engineering;operations management;transport engineering	EDA	1.849853892331774	33.72936673321093	13088
54bec5d286d5e31235ac745b8499f88750ee0f61	a new uart controller		The paper presents a new UART (Universal Asynchronous Receiver/Transmitter) controller which differs from traditional UARTs by providing a user defined data path width of 8 ,16, or 32 bits; by using a one bit error detection and correction algorithm (Hamming); and by permitting a large range of baud rates without the need of adding chips. By using the Hamming code, the communication throughput is increased, especially when a large data path width is defined. This new UART better responds to modern microprocessors’ requirements, and was successfully implemented in an FPGA circuit.	32-bit;algorithm;bit error rate;error detection and correction;field-programmable gate array;front-side bus;hamming code;requirement;throughput;transmitter	Nonel Thirer;Radu Florescu	2007			control engineering;error detection and correction;real-time computing;baud;control theory;field-programmable gate array;universal asynchronous receiver/transmitter;throughput;engineering;asynchronous communication;hamming code	EDA	30.12981557281233	55.50322456859954	13089
07d76c5dca442194ebfe6fb46ccc6945870e10c5	a methodology for plane tree enumeration	plane tree;satisfiability;functional equation;generating function	Abstract   In this paper, we illustrate a method (called the ECO method) for enumerating some classes of combinatorial objects. By means of an operator, able to satisfy two particular conditions, we give some recursive descriptions of these subclasses. We use these descriptions to deduce the functional equations satisfied by the classes' generating functions. We then illustrate some applications of the method to the whole class of plane trees, to right-leafed trees and to tipaugmented trees, and determine their generating functions according to the number of their internal nodes, the number of their leaves, their right branch length and their internal path length.		Elena Barcucci;Alberto Del Lungo;Elisa Pergola;Renzo Pinzani	1998	Discrete Mathematics	10.1016/S0012-365X(97)00122-2	functional equation;generating function;combinatorics;discrete mathematics;topology;mathematics;satisfiability	Theory	36.23862909953505	32.771414544633245	13091
8e6959cfc8c684c640cca57f358f920a8ba73889	stochastic control via entropy compression		We consider an agent trying to bring a system to an acceptable state by repeated probabilistic action. Several recent works on algorithmizations of the Lovász Lo cal Lemma (LLL) can be seen as establishing sufficient conditions for the agent to succeed. Here we study whether such stochastic control is also possible in a noisy environment, where both the proce ss of state-observation and the process of state-evolution are subject to adversarial perturbatio n (noise). The introduction of noise causes the tools developed for LLL algorithmization to break down sinc e the key LLL ingredient, the sparsity of the causality (dependence) relationship, no longer holds. To overcome this challenge we develop a new analysis where entropy plays a central role, both to measure the rate at which progress towards an acceptable state is made and the rate at which noise undoes this progress. The end result is a sufficient condition that allows a smooth tradeoff between the intensi y of the noise and the amenability of the system, recovering an asymmetric LLL condition in the noise le s case. Research supported by NSF grant CCF-1514128. Research supported by NSF grant CCF-1514434. Part of of this work was done while at Adobe Research.	causality;entropy (information theory);entropy compression;ibm notes;lenstra–lenstra–lovász lattice basis reduction algorithm;sinc function;sparse matrix;stochastic control	Dimitris Achlioptas;Fotis Iliopoulos;Nikos Vlassis	2017		10.4230/LIPIcs.ICALP.2017.83	mathematical optimization;combinatorics;discrete mathematics;artificial intelligence;mathematics;algorithm;statistics	Theory	46.313659078564434	9.631647044498763	13096
8d22cf8ded94b6c3baa917a3bb7ae04ed0bb189a	impact of the rt-level architecture on the power performance of tunnel transistor circuits		Tunnel field-effect transistors (TFETs) are one of the most attractive steep subthreshold slope devices currently being investigated as a means of overcoming the power density and energy inefficiency limitations of CMOS technology. In this paper, we analyze the relationship between devices and RT-Level architecture choices. We claim that architectural issues should be considered when evaluating this type of transistors because of the differences in delay versus supply voltage behavior exhibited by TFET logic gates with respect to CMOS gates. More specifically, the potential of pipelining and parallelism, both of which rely on lowering supply voltage, as power reduction techniques is evaluated and compared for CMOS and TFET technologies. The results obtained show significantly larger savings in power and energy per clock cycle for the TFET designs than for their CMOS counterparts, especially at low voltages. Pipelining and parallelism make it possibly to fully exploit the distinguishing characteristics of TFETs, and their relevance as competitive TFET circuit design solutions should be explored in greater depth. Keywords— Tunnel transistors, Steep subthreshold slope, Low power, Concurrency, Pipelining, Parallelism.		Maria J. Avedillo;Juan Núñez	2018	I. J. Circuit Theory and Applications	10.1002/cta.2398		Arch	15.176246044430961	57.10085468925538	13102
9203e7b6ebd7c8dabd49d89b93de048a59154559	a simple randomized sieve algorithm for the closest-pair problem	closet pair problem;approximate algorithm;algorithm analysis;temps lineaire;tiempo lineal;probleme paire plus proche;algorithme;algorithm;linear time;analyse algorithme;analisis algoritmo;algoritmo	We present a linear time randomized sieve algorithm for the closest-pair problem. The algorithm and its analysis are simple. The algorithm is extended to obtain a randomized linear time approximation algorithm for the closest bichromatic pair problem.	closest pair of points problem;randomized algorithm	Samir Khuller;Yossi Matias	1995	Inf. Comput.	10.1006/inco.1995.1049	time complexity;computer science;calculus;mathematics;algorithm	Theory	18.09998118769167	26.13180656302178	13105
c9c915ab62423fead97de236d404865d110c9bbd	determinization of transducers over finite and infinite words	palabra infinita;analyse sequentielle;transducteur sequentiel;transducer determinization;secuencial;sequential;determinization;determinisation transducteur;mot infini;fonction;palabra finita;transducers;transition;sequential analysis;mot fini;automaton;result;algorithme;state;infinite word;algorithm;automata;sequentiel;transicion;sequential tranducer;automate;etat;characterization;infinite words;resultado;transductor;resultat;caracterisation;transducer;analisis secuencial;transducteur;functions;caracterizacion;finite word;algoritmo	We study the determinization of transducers over finite and infinite words. The first part of the paper is devoted to finite words. We recall the characterization of subsequential functions due to Choffrut. We describe here a known algorithm to determinize a transducer.In the case of infinite words, we consider transducers with all their states final. We give an effective characterization of sequential functions over infinite words. We describe an algorithm to determinize transducers over infinite words. This part contains the main novel results of the paper.	powerset construction;transducer	Marie-Pierre Béal;Olivier Carton	2002	Theor. Comput. Sci.	10.1016/S0304-3975(01)00271-7	speech recognition;transducer;computer science;mathematics;automaton;algorithm	Logic	-2.6143440020786013	20.675959341096462	13121
421f4bf2ccd19e51ea78609e2614705d600561d2	design and implementation of embedded computer vision systems based on particle filters	transition state;reconfigurable platforms;vision system;developpement logiciel;modelizacion;embedding;filtre particule;field programmable gate array;conception conjointe;diseno circuito;vision ordenador;pistage;arquitectura circuito;systeme intelligent;methode particulaire;calculateur embarque;metodo monte carlo;metodologia;tracking system;memory management;hardware software co design;multipurpose;diseno conjunto;complexite calcul;particles;etude experimentale;reconfigurable architectures;reutilizacion;real time;sistema inteligente;circuit design;arquitectura reconfigurable;rastreo;methode monte carlo;technique video;circuit architecture;parameterization;metodo particula;filtro particulas;red puerta programable;tecnica video;reseau porte programmable;methodologie;system on a chip;reuse;parametrizacion;computer applications;computer programs;computer vision;identificacion sistema;particle method;modelisation;multi dimensional;computer architecture;complejidad computacion;senal video;signal video;system identification;codesign;sistema sobre pastilla;design and implementation;system on chip;computational complexity;particle filter;system design;desarrollo logicial;estado transitorio;efecto memoria;monte carlo method;temps reel;effet memoire;object tracking;chips electronics;software development;poursuite cible;application sharing;boarded computer;parameters;architecture circuit;intelligent system;software component;traza particula;particle tracks;seguimiento de blanco;video signal;tiempo real;video technique;memory effect;vision ordinateur;conception circuit;systeme sur puce;design space exploration;particle filters;target tracking;methodology;filtration;modeling;estudio experimental;architecture reconfigurable;calculador embarque;trace particule;identification systeme;parametrisation;etat transition;state transition;tracking;embedded computing;reutilisation;software implementation;design methodology;gates circuits	1077-3142/$ see front matter 2010 Elsevier Inc. A doi:10.1016/j.cviu.2010.03.018 * Corresponding author. E-mail addresses: sankalita.saha@nasa.gov (S. S (N.K. Bambha), ssb@umd.edu (S.S. Bhattacharyya). Particle filtering methods are gradually attaining significant importance in a variety of embedded computer vision applications. For example, in smart camera systems, object tracking is a very important application and particle filter based tracking algorithms have shown promising results with robust tracking performance. However, most particle filters involve vast amount of computational complexity, thereby intensifying the challenges faced in their real-time, embedded implementation. Many of these applications share common characteristics, and the same system design can be reused by identifying and varying key system parameters and varying them appropriately. In this paper, we present a System-on-Chip (SoC) architecture involving both hardware and software components for a class of particle filters. The framework uses parameterization to enable fast and efficient reuse of the architecture with minimal re-design effort for a wide range of particle filtering applications as well as implementation platforms. Using this framework, we explore different design options for implementing three different particle filtering applications on field-programmable gate arrays (FPGAs). The first two applications involve particle filters with one-dimensional state transition models, and are used to demonstrate the key features of the framework. The main focus of this paper is on design methodology for hardware/software implementation of multi-dimensional particle filter application and we explore this in the third application which is a 3D facial pose tracking system for videos. In this multi-dimensional particle filtering application, we extend our proposed architecture with models for hardware/software co-design so that limited hardware resources can be utilized most effectively. Our experiments demonstrate that the framework is easy and intuitive to use, while providing for efficient design and implementation. We present different memory management schemes along with results on trade-offs between area (FPGA resource requirement) and execution speed. 2010 Elsevier Inc. All rights reserved.	algorithm;component-based software engineering;computation;computational complexity theory;computer vision;embedded system;experiment;field-programmability;field-programmable gate array;key;mpsoc;memory management;norm (social);particle filter;real-time transcription;reconfigurable computing;resampling (statistics);run time (program lifecycle phase);smart camera;state transition table;system on a chip;systems design;tracking system	Sankalita Saha;Neal K. Bambha;Shuvra S. Bhattacharyya	2010	Computer Vision and Image Understanding	10.1016/j.cviu.2010.03.018	system on a chip;embedded system;real-time computing;simulation;particle filter;machine vision;computer science;statistics	EDA	-0.025984818334711675	54.29241296744798	13122
379b3ea3a9b01d49faf63dec376ac9c98671ccfa	search and strategies in opl	it strategy;modeling languages;modeling language;search;search trees;mathematical programming;constraint programming;mathematical model;combinatorial optimization	OPL is a modeling language for mathematical programming and combinatorial optimization. It is the first language to combine high-level algebraic and set notations from mathematical modeling languages with a rich constraint language and the ability to specify search procedures and strategies that are the essence of constraint programming. This paper describes the facilities available in OPL to specify search procedures. It describes the abstractions of OPL to specify both the search tree (search) and how to explore it (strategies). The paper also illustrates how to use these high-level constructs to implement traditional search procedures in constraint programming and scheduling.	combinatorial optimization;constraint programming;high- and low-level;linear algebra;mathematical model;mathematical optimization;modeling language;open programming language (opl);optimization problem;scheduling (computing);search tree	Pascal Van Hentenryck;Laurent Perron;Jean-François Puget	2000	ACM Trans. Comput. Log.	10.1145/359496.359529	first-generation programming language;constraint programming;very high-level programming language;constraint satisfaction;combinatorial optimization;computer science;theoretical computer science;machine learning;modeling language;fifth-generation programming language;algorithm	PL	19.957378896757334	8.003175665502399	13130
ddd89867e9e7d662980868dd579d00b9817d17af	the context-freeness problem is conp-complete for flat counter systems		Bounded languages have recently proved to be an important class of languages for the analysis of Turing-powerful models. For instance, bounded context-free languages are used to under-approximate the behaviors of recursive programs. Ginsburg and Spanier have shown in 1966 that a bounded language L ⊆ a1 · · · ad is context-free if, and only if, its Parikh image is a stratifiable semilinear set. However, the question whether a semilinear set is stratifiable, hereafter called the stratifiability problem, was left open, and remains so. In this paper, we give a partial answer to this problem. We focus on semilinear sets that are given as finite systems of linear inequalities, and we show that stratifiability is coNP-complete in this case. Then, we apply our techniques to the context-freeness problem for flat counter systems, that asks whether the trace language of a counter system intersected with a bounded regular language is context-free. As main result of the paper, we show that this problem is coNP-complete.	approximation algorithm;co-np;commutation theorem;context-free language;decision problem;linear inequality;petri net;polyhedron;recursion;regular language;semilinear response;trace monoid;turing completeness	Jérôme Leroux;Vincent Penelle;Grégoire Sutre	2014		10.1007/978-3-319-11936-6_19	combinatorics;discrete mathematics;mathematics;algorithm	Theory	-2.7053484043896314	20.81938126520731	13133
b3be5ffc939cb26ee39b0cd88dfbd17b33ceafcd	rekursive funktionen in mehrsortigen peano-algebren			peano axioms	Ulrich L. Hupbach	1978	Elektronische Informationsverarbeitung und Kybernetik		algebra;peano axioms;combinatorics;mathematics	NLP	46.571247243527466	29.926820711982913	13141
12916156cb15e5924c41903ee3f9893496445bfc	estimation and marginalization using the kikuchi approximation methods	optimisation sous contrainte;constrained optimization;iterative method;partition function;calcul neuronal;neural computation;tecnologia electronica telecomunicaciones;computacion informatica;approximation numerique;complexite calcul;approximation method;relacion convergencia;message passing algorithms;grupo de excelencia;optimization method;taux convergence;convergence rate;fonction partition;metodo optimizacion;iterative algorithm;aproximacion numerica;product distribution;metodo iterativo;optimizacion con restriccion;optimization problem;complejidad computacion;approximation kikuchi;computational complexity;propagation croyance;belief propagation;ciencias basicas y experimentales;methode iterative;cycle graphe;edge graph;methode optimisation;arete graphe;cycle graph;numerical approximation;tecnologias;grupo a;constrained optimization problem;computacion neuronal;arista grafico;kikuchi approximation;funcion particion;ciclo diagrama	In this letter, we examine a general method of approximation, known as the Kikuchi approximation method, for finding the marginals of a product distribution, as well as the corresponding partition function. The Kikuchi approximation method defines a certain constrained optimization problem, called the Kikuchi problem, and treats its stationary points as approximations to the desired marginals. We show how to associate a graph to any Kikuchi problem and describe a class of local message-passing algorithms along the edges of any such graph, which attempt to find the solutions to the problem. Implementation of these algorithms on graphs with fewer edges requires fewer operations in each iteration. We therefore characterize minimal graphs for a Kikuchi problem, which are those with the minimum number of edges. We show with empirical results that these simpler algorithms often offer significant savings in computational complexity, without suffering a loss in the convergence rate. We give conditions for the convexity of a given Kikuchi problem and the exactness of the approximations in terms of the loops of the minimal graph. More precisely, we show that if the minimal graph is cycle free, then the Kikuchi approximation method is exact, and the converse is also true generically. Together with the fact that in the cycle-free case, the iterative algorithms are equivalent to the well-known belief propagation algorithm, our results imply that, generically, the Kikuchi approximation method can be exact if and only if traditional junction tree methods could also solve the problem exactly.	algorithm;approximation;belief propagation;computational complexity theory;constrained optimization;constraint (mathematics);convergence (action);graph - visual representation;hl7publishingsubsection <operations>;iteration;mathematical optimization;message passing;newton's method;optimization problem;partition function (mathematics);rate of convergence;software propagation;solutions;stationary process;tree decomposition;whole earth 'lectronic link	Payam Pakzad;Venkat Anantharam	2005	Neural Computation	10.1162/0899766054026693	mathematical optimization;constrained optimization;combinatorics;computer science;calculus;mathematics;iterative method	ML	33.79524874682499	7.579800201195561	13144
91d0a0613f328f8258a7bc3d19fb1a583717d811	regular factors of regular graphs from eigenvalues	eigenvalues;upper bound;largest eigenvalue;regular graph	Let r and m be two integers such that r > m. Let H be a graph with order |H|, size e and maximum degree r such that 2e > |H|r−m. We find a best lower bound on spectral radius of graph H in terms of m and r. Let G be a connected r-regular graph of order |G| and k < r be an integer. Using the previous results, we find some best upper bounds (in terms of r and k) on the third largest eigenvalue that is sufficient to guarantee that G has a k-factor when k|G| is even. Moreover, we find a best bound on the second largest eigenvalue that is sufficient to guarantee that G is k-critical when k|G| is odd. Our results extend the work of Cioabă, Gregory and Haemers [J. Combin. Theory Ser. B, 1999] who obtained such results for 1-factors.	graph (discrete mathematics);graph factorization	Hongliang Lu	2010	Electr. J. Comb.		strongly regular graph;integral graph;combinatorics;discrete mathematics;eigenvalues and eigenvectors;regular graph;distance-regular graph;mathematics;upper and lower bounds;line graph;algebra	Theory	30.99305601066366	29.079272921372382	13147
fb436bb584034274942a128458e7e21c606acd5b	brief announcement: the synergy of finite state machines		What can be computed by a network of n randomized finite state machines communicating under the stone age model [4] (a generalization of the beeping model’s communication scheme)? The inherent linear upper bound on the total space of the network implies that its global computational power is not larger than that of a randomized linear space Turing machine, but is this tight? The reported reseach answers this question affirmatively for bounded degree networks by introducing a stone age algorithm (operating under the most restrictive form of the model) that given a designated I/O node, constructs a tour in the network that enables the simulation of the Turing machine’s tape. To construct the tour, it is first shown how to 2-hop color the network concurrently with building a spanning tree, with high probability. 1998 ACM Subject Classification C.2.1 Distributed networks	computation;file spanning;finite-state machine;input/output;randomized algorithm;simulation;spanning tree;synergy;turing machine;with high probability	Yehuda Afek;Yuval Emek;Noa Kolikant	2017		10.4230/LIPIcs.DISC.2017.42	theoretical computer science;finite-state machine;computer science	Theory	17.32902532360682	33.90148017285501	13153
23456bdc00de8f32e74c9dc5b4902aff45a869c5	location of multiple obnoxious facilities	location theory	This problem deals with the location of facilities that are obnoxious in the sense that nearness of the facility to fixed points, which may represent population centers or other installations, is undesirable. Two model formulatons are given. In the first formulation we minimize the maximum weighted distance in the system subject to constraints which require that the distances between the facilities and fixed points must exceed specified values. In the second formulation, the smallest weighted “facility-to-fixed-point” distance in the system must be maximized, given that every fixed point must be within “reach” of the closest facility. Certain useful duality relationships are established between these problems. A one-dimensional problem is solved using an algorithm that incorporates a version of the set covering problem.		Zvi Drezner;George O. Wesolowsky	1985	Transportation Science	10.1287/trsc.19.3.193	mathematical optimization;combinatorics;location theory;computer science;mathematics;welfare economics;1-center problem	NLP	21.840847136142695	11.129411817623463	13157
bc31c19f3bfae425c2a41c1fcd04b325ebd54f54	finding simple paths on given points in a polygonal region		Given a set X of points inside a polygonal region P, two distinguished points s, t ∈ X, we study the problem of finding the simple polygonal paths that turn only at the points of X and avoid the boundary of P, from s to t. We present an O((n 2 + m) logm) time, O(n 2 + m) space algorithm for computing a simple path or reporting no such path exists, where n is the number of points of X and m is the number of vertices of P. This gives a significant improvement upon the previously known O(m 2 n 2) time and space algorithm, and O(n 3 logm + m n) time, O(n 3 + m) space algorithm.		Xuehou Tan;Bo Jiang	2014		10.1007/978-3-319-08016-1_21	polygonal chain	Theory	30.86994973285712	19.151141373722893	13162
1863e45f2e427060c7bd9a2d3a44c007b4df08d6	binary matroids without prisms, prism duals, and cubes	binary matroids;prism dual	Abstract In this paper we determine completely the class of binary matroids with no minors isomorphic to the cycle matroid of the prism graph M * ( K 5 e ), its dual M ( K 5 e ), and the binary affine cube AG (3,2).	graphic matroid;greedoid;olap cube;prism graph	Sandra R. Kingan	1996	Discrete Mathematics	10.1016/0012-365X(94)00269-O	combinatorics;discrete mathematics;branch-decomposition;graphic matroid;mathematics;geometry	Theory	28.27186405998442	32.49190391511378	13171
c41437e7590f775f74bf5c335dae9c46a52ae142	signal strength based switching activity modeling and estimation for dsp applications	switching activity;signal strength	We present an effective switching activity modeling and estimation technique for components under resource sharing. The model uses word-level signal statistics to generate a single parameter, called signal strength. By using the signal strength, we can construct power models for the both cases of sharing and non-sharing of computing resources. The model enables us to effectively estimate switching activity at higher level of design abstraction. We have conducted several experiments using both synthetic and real data to evaluate our method. We have compared competing architectures for their relative power consumption for different components. The results show that average difference between the proposed method and very accurate power simulation (as opposed to switching estimation) using PowerMill is up to 12&#37;.		Lih-Yih Chiou;Khurram Muhammad;Kaushik Roy	2001	VLSI Design	10.1155/2001/35832	signal strength;embedded system;electronic engineering;real-time computing;telecommunications;computer science;electrical engineering	EDA	14.978070391817509	54.90193005006852	13189
20226d90e0ea8f203805ace22ea30d1b88fa4f9f	maps: mapping concurrent dataflow applications to heterogeneous mpsocs	composability;job shop scheduling;data flow graphs;real time;multimedia systems;schedules estimation synchronization programming hardware job shop scheduling;system on chip data flow graphs multimedia systems multiprocessing systems scheduling;heterogeneous;estimation;system on chip;synchronization;hardware scheduler;scheduling;scheduling configuration maps concurrent dataflow application mapping heterogeneous mpsoc multiprocessor systems on chip multimedia baseband processing dataflow models high level models mapping heuristics performance estimation virtual platform heterogeneous processing elements multiapplication component real time constraints random walk;schedules;mapping;multiprocessing systems;programming;dataflow graphs;mpsoc;scheduling composability dataflow graphs hardware scheduler heterogeneous mapping mpsoc real time;hardware	Processor Systems on Chip (MPSoCs) in order to cope with the increasing applications demands and the tight energy budget of portable devices. The complexity of these systems makes them difficult to program, which has caused academia and industry to look for alternative methodologies and models. In the particular case of multimedia and baseband processing, dataflow models are being proposed and appear to be a sensible choice to represent applications. While high-level models, like dataflow, increase programmers' productivity, new, powerful tools are badly required that lower the abstract specification into an efficient implementation. In this paper, a framework is presented that provides support for mapping multiple dataflow applications onto heterogeneous MPSoCs. The framework is aware of design constraints, provides different means for performance estimation and supports a variety of mapping heuristics. The tool is showcased on three applications on a virtual platform containing heterogeneous processing elements. The heuristics for single applications reported a speedup of up to 40% when compared against random walk. The multi-application component helped to find an appropriate scheduling configuration that met real-time constraints when the three applications were running simultaneously.	baseband;dataflow;heuristic (computer science);high- and low-level;mobile device;programmer;real-time clock;scheduling (computing);speedup;system on a chip;virtual machine	Jerónimo Castrillón;Rainer Leupers;Gerd Ascheid	2013	IEEE Transactions on Industrial Informatics	10.1109/TII.2011.2173941	system on a chip;embedded system;job shop scheduling;synchronization;programming;estimation;parallel computing;real-time computing;schedule;computer science;operating system;distributed computing;scheduling;statistics	Arch	-0.9539425988481443	51.0026763458719	13201
d377f210bb2dccdcc32912cd8ccd840e3f0b1f3f	new algorithms for k -sat based on the local search principle	articulo sintesis;article synthese;probleme np complet;derandomisation;heuristic method;derandomization;metodo heuristico;logique propositionnelle;probabilistic approach;constraint satisfaction;satisfaction contrainte;propositional logic;enfoque probabilista;approche probabiliste;problema np completo;methode heuristique;satisfaccion restriccion;logica proposicional;review;local search;recherche locale;np complete problem	Recently, several algorithms for the NP-complete problem k- SAT have been proposed and rigorously analyzed. These algorithms are based on the heuristic principle of local search. Their deterministic and their probabilistic versions and variations, have been shown to achieve the best complexity bounds that are known for k-SAT (or the special case 3-SAT). We review these algorithms, their underlying principles and their analyses.	algorithm;local search (optimization)	Uwe Schöning	2001		10.1007/3-540-44683-4_9	randomized algorithms as zero-sum games;probabilistic analysis of algorithms;np-complete;constraint satisfaction;computer science;artificial intelligence;local search;mathematics;propositional calculus;algorithm	AI	15.24739227645301	19.234081020480545	13205
5186788cf2028a60a20c0761a90b06c2367ecbdb	on sum of powers of the laplacian and signless laplacian eigenvalues of graphs		Let G be a graph of order n with signless Laplacian eigenvalues q1, . . . , qn and Laplacian eigenvalues μ1, . . . , μn. It is proved that for any real number α with 0 < α 6 1 or 2 6 α < 3, the inequality qα 1 + · · · + qα n > μ1 + · · · + μn holds, and for any real number β with 1 < β < 2, the inequality q 1 + · · · + q n 6 μβ1 + · · · + μ β n holds. In both inequalities, the equality is attained (for α 6∈ {1, 2}) if and only if G is bipartite.	graph (discrete mathematics);social inequality	Saieed Akbari;Ebrahim Ghorbani;Jacobus H. Koolen;Mohammad Reza Oboudi	2010	Electr. J. Comb.		combinatorics;calculus;mathematics;algebra	Theory	30.092223756290423	33.41615237666829	13215
79844af4f98af808971a7e524d6955766f6ad672	feasible sampling of non-strict turnstile data streams		We present the first feasible method for sampling a dynamic data stream with deletions, where the sample consists of pairs (k,Ck) of a value k and its exact total count Ck. Our algorithms are for both Strict Turnstile data streams and the most general Non-strict Turnstile data streams, where each element may have a negative total count. Our method improves by an order of magnitude the known processing time of each element in the stream, which is extremely crucial for data stream applications. For example, for a sample of size O( −2 log (1/δ)) in Non-strict streams, our solution requires O((log log(1/ ))2 + (log log(1/δ))2) operations per stream element, whereas the best previous solution requires O( −2 log2(1/δ)) evaluations of a fully independent hash function per element. Here 1− δ is the success probability and is the additive approximation error. We achieve this improvement by constructing a single data structure from which multiple elements can be extracted with very high success probability. The sample we generate is useful for calculating both forward and inverse distribution statistics, within an additive error, with provable guarantees on the success probability. Furthermore, our algorithms can run on distributed systems and extract statistics on the union or difference between data streams. They can be used to calculate the Jaccard similarity coefficient as well. 1998 ACM Subject Classification G.3 Probability and Statistics, E.1 Data Structures	algorithm;approximation error;coefficient;data structure;distributed computing;dynamic data;gibbs sampling;hash function;jaccard index;provable security;sampling (signal processing);strict function;turnstile;utility functions on indivisible goods	Neta Barkay;Ely Porat;Bar Shalem	2012	CoRR		computer science;theoretical computer science;distributed computing;statistics	DB	12.08395897792349	25.551945891389718	13225
a72b0a32cf22133ce86211a8c7dd647d9c52b019	fast algorithms for even/odd minimum cuts and generalizations	minimisation;algorithme rapide;qa75 electronic computers computer science szamitastechnika;minimization;temps polynomial;szamitogeptudomany;coupe graphe;minimizacion;optimisation combinatoire;corte grafo;fonction modulaire;graph cut;directed graph;fast algorithm;polynomial time;combinatorial optimization;submodular functions;algoritmo rapido;minimum cut;optimizacion combinatoria;tiempo polinomial	We give algorithms for the directed minimum odd or even cut problem and certain generalizations. Our algorithms improve on the previous best ones of Goemans and Ramakrishnan by a factor of O(n) (heren is the size of the ground vertex set). Our improvements apply among others to the minimum directed Todd or T-even cut and to the directed minimum Steiner cut problems. The (slightly more general) result of Goemans and Ramakrishnan shows that a collection of minimal minimizers of a submodular function (i.e. minimum cuts) contains the odd minimizers. In contrast our algorithm selects an n-times smaller class of not necessarily minimal minimizers and out of these sets we construct the odd minimizer. If M(n,m) denotes the time of au–v minimum cut computation in a directed graph withn vertices andm edges, then we may find a directed minimum – odd or T-odd cut withV (or T ) even inO(nm+ n ·M(n,m)) time; – even or T-even cut inO(nm+ n ·M(n,m)) time. The key of our construction is a so-called parity uncrossingstep that, given an arbitrary set system with odd intersection, finds an odd set with value not more than the maximum of the initial system.	algorithm;computation;directed graph;fast fourier transform;maximum cut;minimum cut;pipeline (computing);speedup;steiner tree problem;submodular set function	András A. Benczúr;Ottilia Fülöp	2000		10.1007/3-540-45253-2_9	time complexity;minimisation;mathematical optimization;combinatorics;discrete mathematics;directed graph;minimum cut;cut;combinatorial optimization;mathematics;algorithm	Theory	23.415105990357112	20.310240280959917	13229
2f1d47d5dc61983cf0b1097e0e16813f5d21323f	towards autonomous energy-wise robjects	autonomous robjects;mobots;robotic vacuum cleaner;energy scavenging;power awareness	In this article, the RObject concept is first introduced. This is followed by a survey of applicable energy scavenging technologies. Energy is a key issue for the large scale deployment of robotics in daily life, as recharging the batteries places a considerable burden on the end-user and is a waste of energy which has an overall negative impact on the limited resources of our planet. We show how the energy obtained from light, water flow, and human work, could be promising sources of energy for powering low-duty devices. To assess the feasibility of powering future RObjects with technologies, tests were conducted on commonly available robotic vacuum cleaners. These tests established an upper-bound on the power requirements for RObjects. Finally, based on these results, the feasibility of powering RObjects using scavenged energy is discussed.	autonomous robot;requirement;robotic vacuum cleaner;robotics;software deployment	Florian Vaussard;Michael Bonani;Philippe Rétornaz;Alcherio Martinoli;Francesco Mondada	2011		10.1007/978-3-642-23232-9_28	simulation;engineering;electrical engineering;mechanical engineering	HCI	2.8189428547853104	32.46052633513729	13240
e0d0a37fde810492bf27bf6856713c2955a48da6	solving combinatorial games using products, projections and lexicographically optimal bases		In order to find Nash-equilibria for two-player zero-sum games where each player plays combinatorial objects like spanning trees, matchings etc, we consider two online learning algorithms: the online mirror descent (OMD) algorithm and the multiplicative weights update (MWU) algorithm. The OMD algorithm requires the computation of a certain Bregman projection, that has closed form solutions for simple convex sets like the Euclidean ball or the simplex. However, for general polyhedra one often needs to exploit the general machinery of convex optimization. We give a novel primal-style algorithm for computing Bregman projections on the base polytopes of polymatroids. Next, in the case of the MWU algorithm, although it scales logarithmically in the number of pure strategies or experts N in terms of regret, the algorithm takes time polynomial in N ; this especially becomes a problem when learning combinatorial objects. We give a general recipe to simulate the multiplicative weights update algorithm in time polynomial in their natural dimension. This is useful whenever there exists a polynomial time generalized counting oracle (even if approximate) over these objects. Finally, using the combinatorial structure of symmetric Nash-equilibria (SNE) when both players play bases of matroids, we show that these can be found with a single projection or convex minimization (without using online learning).	approximation algorithm;bregman divergence;computation;convex optimization;file spanning;lexicographical order;machine learning;mathematical optimization;matroid;nash equilibrium;polyhedron;polynomial;regret (decision theory);simulation;time complexity	Swati Gupta;Michel X. Goemans;Patrick Jaillet	2016	CoRR		mathematical optimization;combinatorics;discrete mathematics;machine learning;mathematics	ML	22.11084664600656	15.776416236785714	13267
69935c3d814b9c965345a31516a3748b6c23ca6d	an extensible real-time signal processing environment for max	real time;signal processing	MSP is a set of additions to the Macintosh version of MAX for synthesis, signal processing, sampling, and harddisk recording/playback directly on a PowerPC processor. It is based on ideas from MAX/FTS developed by Miller Puckette at IRCAM, and incorporates software from Puckette's cross-platform Pd (Pure Data) program.	fleet telematics system;hard disk drive;max;powerpc;pure data;real-time clock;sampling (signal processing);signal processing	David Zicarelli	1998			embedded system;c signal handling;real-time computing;computer science;operating system;digital signal processing;signal	EDA	4.8542469194503335	47.871850317597094	13274
0851cb1586cec02395b447d1efef3c77ef39e3c3	a linear-time randomized algorithm for the bounded voronoi diagram of a simple polygon	delaunay triangulation;minimal spanning tree;linear time;randomized algorithm;voronoi diagram	For a polygon <italic>P</italic>, the bounded Voronoi diagram of <italic>P</italic> is a partition of <italic>P</italic> into regions assigned to the vertices of <italic>P</italic>. A point <italic>p</italic> inside <italic>P</italic> belongs to the region of a vertex <italic>v</italic> if and only if <italic>v</italic> is the closest vertex of <italic>P</italic> visible from <italic>p</italic>. We present a randomized algorithm that builds the bounded Voronoi diagram of a simple polygon in linear expected time. Among other applications, we can construct within the same time bound the generalized Delaunay triangulation of <italic>P</italic> and the minimal spanning tree on <italic>P's</italic> vertices that is contained in <italic>P</italic>.	average-case complexity;delaunay triangulation;expected linear time mst algorithm;file spanning;minimum spanning tree;randomized algorithm;vertex (geometry);voronoi diagram	Rolf Klein;Andrzej Lingas	1993		10.1145/160985.161008	time complexity;combinatorics;discrete mathematics;weighted voronoi diagram;power diagram;topology;delaunay triangulation;voronoi diagram;pitteway triangulation;minimum spanning tree;point set triangulation;mathematics;geometry;randomized algorithm;polygon triangulation;bowyer–watson algorithm;algorithm	Theory	31.270029284690196	20.057259605292586	13285
7ef0d3556c0d2be18ba5e5ff85158d4927f9cf90	linear time approximation schemes for vehicle scheduling	online algorithm;approximation lineaire;tiempo total acabamiento;approximate algorithm;approximation algorithm;temps lineaire;competitive algorithms;temps total achevement;linear approximation;tiempo lineal;multiple vehicle scheduling problem;algorithme competitif;makespan;scheduling;linear time;aproximacion lineal;algoritmo aproximacion;approximation scheme;scheduling problem;ordonamiento;algorithme approximation;cladding;placage par soudage;ordonnancement	We consider makespan minimization for vehicle scheduling problems on trees with release and handling times. 2-approximation algorithms were known for several variants of the single vehicle problem on a path [16]. A 3/2-approximation algorithm was known for the single vehicle problem on a path where there is a fixed starting point and the vehicle must return to the starting point upon completion [13]. Karuno, Nagamochi and Ibaraki give a 2-approximation algorithm for the single vehicle problem on trees. We develop a linear time PTAS for the single vehicle scheduling problem on trees which have a constant number of leaves. This PTAS can be easily adapted to accommodate various starting/ending constraints. We then extended this to a PTAS for the multiple vehicle problem where vehicles operate in disjoint subtrees. For this problem, the only previous result is a 2-approximation algorithm for paths [10]. Finally, we present competitive online algorithms for some single vehicle scheduling problems.	approximation;scheduling (computing);time complexity	John E. Augustine;Steven S. Seiden	2002		10.1007/3-540-45471-3_4	time complexity;job shop scheduling;online algorithm;mathematical optimization;combinatorics;cladding;computer science;mathematics;scheduling;algorithm;linear approximation	Theory	17.875745795322793	12.033656761315596	13287
cdeb8d68a49acfd287e55f13425a85f3953a9bbe	implementing string-to-string correction and longest common subsequence problems on the sequent symmetry multiprocessor	dna;sequences;parallel algorithm;concurrent computing;shared memory;performance evaluation;parallel algorithms string to string correction longest common subsequence problems sequent symmetry multiprocessor performance;performance evaluation parallel algorithms multiprocessing systems;performance;parallel programming;phase change random access memory;longest common subsequence;performance analysis;sequent symmetry multiprocessor;signal processing algorithms sequences parallel algorithms concurrent computing phase change random access memory parallel programming computer science performance analysis algorithm design and analysis dna;longest common subsequence problems;multiprocessing systems;computer science;signal processing algorithms;algorithm design and analysis;string to string correction;parallel algorithms	This paper implements and analyzes the performance of parallel algorithms for the string-to-string correction and the longest common subsequence (LCS) problems, on the shared-memory Sequent Symmetry multiprocessor machine. The speedup of the first algorithm is 12.686 with 15 processors for a sequence of length 800, while the speedup of the LCS algorithm is 3.227 employing 8 processors for a sequence of length 128.	longest common subsequence problem;multiprocessing	Sajal K. Das;Ajoy Kumar Datta;Surendra Pothuru	1996		10.1109/HIPC.1996.565843	parallel computing;longest increasing subsequence;concurrent computing;computer science;theoretical computer science;longest common subsequence problem;distributed computing;parallel algorithm;programming language;longest alternating subsequence;algorithm	Logic	2.3523002256743624	38.90986866691357	13305
82546f50364b766d47670341638d296f5c2e5b63	an efficient block encryption cipher based on chaotic maps for secure multimedia applications	performance evaluation;chaos;block cipher;real time;multimedia application;logistic map;data dependence;algorithm design;symmetric encryption;chaos theory	This paper presents an efficient chaotic-based block encryption cipher (CBBEC), which is a symmetric encryption algorithm designed with the potential of increasing security and improving performance. It is a hybrid mixture from chaos theory and cryptography. Its salient features include the use of eight working registers providing capability to handle 256-bits plaintext/ciphertext block sizes, employing a chaotic logistic map in key scheduling to generate session key used in encryption/decryption, the essential heavy use of data-dependent rotations and the inclusion of integer multiplication as an additional primitive operation. The use of multiplication with eight working registers greatly increases the diffusion achieved per round, allowing for greater security, fewer rounds and increased throughput. Comparative performance evaluation of the proposed chaotic-based block encryption cipher CBBEC with Rijndael, RC6 and RC5 is addressed. Experimental results show that the proposed CBBEC is a fast block cipher, showing its great potential in real-time encryption applications.	block cipher;encryption;list of chaotic maps	Osama S. Faragallah	2011	Information Security Journal: A Global Perspective	10.1080/19393555.2011.560926	multiple encryption;key;algorithm design;block cipher;transposition cipher;triple des;residual block termination;disk encryption theory;40-bit encryption;logistic map;two-square cipher;ciphertext stealing;block cipher mode of operation;computer science;theoretical computer science;symmetric-key algorithm;distributed computing;chaos theory;stream cipher;deterministic encryption;computer security;cbc-mac;encryption;probabilistic encryption;ciphertext;56-bit encryption	Crypto	8.831821407604378	44.323430711204516	13316
9488a1fcd6eacdb4e448a9287e210af6ac23a8f5	hardness of classically sampling one clean qubit model with constant total variation distance error		Abstract The one clean qubit model (or the DQC1 model) is a restricted model of quantum computing where only a single input qubit is pure and all other input qubits are maximally mixed. In spite of the severe restriction, the model can solve several problems (such as calculating Jones polynomials) whose classical efficient solutions are not known. Furthermore, it was shown that if the output probability distribution of the one clean qubit model can be classically efficiently sampled with a constant multiplicative error, then the polynomial hierarchy collapses to the second level. Is it possible to improve the multiplicative error hardness result to a constant total variation distance error one like other sub-universal quantum computing models such as the IQP model, the Boson Sampling model, and the Fourier Sampling model? In this paper, we show that it is indeed possible if we accept a modified version of the average case hardness conjecture. Interestingly, the anticoncentration lemma can be easily shown by using the special property of the one clean qubit model that each output probability is so small that no concentration occurs.	best, worst and average case;boson sampling;computational hardness assumption;gibbs sampling;jones calculus;jones polynomial;numerical stability;polynomial hierarchy;quantum computing;qubit;sampling (signal processing)	Tomoyuki Morimae	2017	CoRR		combinatorics;discrete mathematics;mathematics;qubit;quantum mechanics	Theory	10.927834963875064	20.910820909645466	13333
dff4e5b041ebcc2e53da70bd0087dc11f5781fc6	a novel high-density single-event upset hardened configurable sram applied to fpga	microprocessors;hspice;configurable sram;heavy ions;random access memory;high density single event upset;high density;hspice heavy ion fpga csram medici;medici;fpga;computer architecture;heavy ion;integrated circuit modeling;mixed mode;mix mode radiation hardened verification method;radiation hardening electronics;dice;csram;single event upset;field programmable gate arrays;radiation hardening;seu hardened csram;sram chips field programmable gate arrays radiation hardening electronics;dice fpga configurable sram high density single event upset mix mode radiation hardened verification method seu hardened csram;sram chips;random access memory field programmable gate arrays single event upset radiation hardening manufacturing microelectronics aerospace industry space technology frequency sun	This paper has investigated present radiation hardened FPGA manufacturers and SEU hardened method of configurable SRAM (CSRAM) applied to FPGA. A novel high-density single-event upset hardened CSRAM applied to BQV 300 FPGA is proposed, and this paper uses the mix-mode radiation hardened verification method to simulate the SEU hardened CSRAM. The proposed SEU-hardened CSRAM applied to FPGAs is SEU immune up to 22.49 MeVŸcm2/mg, under the angle for incident ion of 0°. But the area of proposed CSRAM only increases 12% than traditional 6-T SRAM, and the area of DICE will increase 69% than proposed CSRAM. Using the proposed CSRAM makes BQV 300 FPGA able to be fabricated. The SEU LETth is much higher than SEU LETth of CSRAM for Xilinx’s FPGA.	antifuse;data scrubbing;field-programmable gate array;radiation hardening;simulation;single event upset;static random-access memory;transistor	Lei Wang;Lei Chen;Zhiping Wen;Huabo Sun;Shuo Wang	2009	2009 International Conference on Reconfigurable Computing and FPGAs	10.1109/ReConFig.2009.13	embedded system;real-time computing;computer science;field-programmable gate array	EDA	9.109662508344156	59.64411259882673	13336
51a7383629ca60f4e7a18c1d52c1a14dd862b7aa	hierarchical coordination of a community microgrid with ac and dc microgrids	distributed power generation;power distribution faults distributed power generation load flow power distribution economics;microgrids power markets power system economics power system reliability islanding distributed power generation;power markets;microgrid islanding ac and dc microgrids community microgrid droop function economics and reliability hierarchical control hybrid microgrid;power system economics;microgrid flows coordination hierarchical coordination ac microgrid dc microgrid islanded community microgrid economic operation grid connected community microgrid;islanding;microgrids;power system reliability	In this paper, a community microgrid with multiple ac and dc microgrids is introduced and analyzed. Individual microgrids with different frequency and voltage requirements would operate as self-controlled entities, which could also cooperate with neighboring microgrids for providing back-up operations in the community microgrid. A hierarchical coordination strategy with primary, secondary, and tertiary coordination is proposed for the economic operation of an islanded community microgrid. The hierarchical strategy is also applied to a grid-connected community microgrid and the results are discussed. The simulation results verify that the proposed hierarchical coordination strategy is an effective and efficient way for coordinating microgrid flows in an islanded community microgrid, while maintaining the rated frequency and voltage with each microgrid. The simulation results also demonstrate the economic operation of a grid-connected community microgrid in which individual microgrids operate as autonomous agents, while satisfying the community objectives.	autonomous robot;backup;centralized computing;entity;microgrid;requirement;simulation	Liang Che;Mohammad Shahidehpour;Ahmed Alabdulwahab;Yusuf Al-Turki	2015	IEEE Transactions on Smart Grid	10.1109/TSG.2015.2398853	control engineering;electronic engineering;economics;control theory	Visualization	1.6209350264215714	5.552603546287623	13342
10abc28bc5d4a598e9842de148d6721687516f1c	improved bounds on the stretch factor of $y_4$	theta;spanner;cone graph;yao;four cones	We establish an upper bound of 13 + 8 √ 2 . 4.931 on the stretch factor of the Yao graph Y∞ 4 defined in the L∞-metric, improving upon the best previously known upper bound of 6.31. We also establish an upper bound of (11 + 7 √ 2) √ 4 + 2 √ 2 . 54.62 on the stretch factor of the Yao graph Y4 defined in the L2-metric, improving upon the best previously known upper bound of 662.16.	algorithm;bose wave system;bose–hubbard model;computation;delaunay triangulation;diagram;dolev–yao model;file spanning;hoc (programming language);international journal of computational geometry and applications;jit bose;joseph o'rourke (professor);minimum spanning tree;springer (tank);stani michiels;symposium on computational geometry;yao graph	Mirela Damian;Naresh Nelavalli	2017	Comput. Geom.	10.1016/j.comgeo.2016.12.001	combinatorics;topology;wrench;mathematics;geometry	Theory	28.272245069876135	22.502598434938047	13351
38195d367b0dc56fbc1129ec2296055af7a70bb4	relating the time complexity of optimization problems in light of the exponential-time hypothesis	computer and information science;data och informationsvetenskap	Obtaining lower bounds for NP-hard problems has for a long ti me been an active area of research. Recent algebraic technique s introduced by Jonsson et al. (SODA 2013) show that the time complexity of the pa rameterized SAT(·) problem correlates to the lattice of strong partial clones. With this ordering they isolated a relation Rsuch that SAT(R) can be solved at least as fast as any other NP-hard SAT (·) problem. In this paper we extend this method and show that such languages also exist for the max ones problem(MAX -ONES(Γ )) and the Boolean valued constraint satisfaction problem over finite-valued constraint languages (VCSP (∆ )). With the help of these languages we relate M AX -ONESand VCSP to the exponential time hypothesis in several differen t ways.	boolean satisfiability problem;exponential time hypothesis;linear algebra;np-hardness;time complexity;weighted constraint satisfaction problem	Peter Jonsson;Victor Lagerkvist;Johannes Schmidt;Hannes Uppman	2014		10.1007/978-3-662-44465-8_35	computer science;theoretical computer science;mathematics;algorithm;information and computer science	AI	8.325386918062714	19.45113985119341	13352
35a3916395873840a376af1425882871b2fbe887	sojourn time approximations for a discriminatory processor sharing queue	interpolation;sojourn time;light traffic;discriminatory processor sharing;heavy traffic	We study a multiclass time-sharing discipline with relative priorities known as discriminatory processor sharing (DPS), which provides a natural framework to model service differentiation in systems. The analysis of DPS is extremely challenging, and analytical results are scarce. We develop closed-form approximations for the mean conditional (on the service requirement) and unconditional sojourn times. The main benefits of the approximations lie in its simplicity, the fact that it applies for general service requirements with finite second moments, and that it provides insights into the dependency of the performance on the system parameters. We show that the approximation for the mean conditional and unconditional sojourn time of a customer is decreasing as its relative priority increases. We also show that the approximation is exact in various scenarios, and that it is uniformly bounded in the second moments of the service requirements. Finally, we numerically illustrate that the approximation for exponential, hyperexponential, and Pareto service requirements is accurate across a broad range of parameters.	approximation;ergodic theory;numerical analysis;pareto efficiency;pictbridge;requirement;time complexity;time-sharing	Ane Izagirre;Urtzi Ayesta;Maaike Verloop	2016	TOMPECS	10.1145/2812807	real-time computing;simulation;interpolation;computer science;operations management;mathematics;statistics	Metrics	6.94761962211278	10.871292527649667	13357
29dfb1fd7bd1c9caa1898aeb617a7ba017f9f657	distributed tree decomposition with privacy	art bucket elimination;jointree quality;initial network architecture;graphical models;centralized case;depth-first traversal;local election;privacy rule;tree decomposition;clever heuristic	Tree Decomposition of Graphical Models is a well known method for mapping a graph into a tree, that is commonly used to speed up solving many problems. However, in a distributed case, one may have to respect the privacy rules (a subset of variables may have to be kept secret in a peer), and the initial network architecture (no link can be dynamically added). In this context, we propose a new distributed method, based on token passing and local elections, that shows performances (in the jointree quality) close to the state of the art Bucket Elimination in a centralized case (i.e. when used without these two restrictions). Until now, the state of the art in a distributed context was using a Depth-First traversal with a clever heuristic. It is outperformed by our method on two families of problems sharing the small-world property.	algorithm;centralized computing;compiler;depth-first search;distributed computing;graph (discrete mathematics);graphical model;heuristic;local consistency;local variable;network architecture;performance;privacy;small-world experiment;token ring;tree decomposition	Vincent Armant;Laurent Simon;Philippe Dague	2012		10.1007/978-3-642-33558-7_10	mathematical optimization;computer science;theoretical computer science;database;distributed computing;algorithm	AI	13.66703924492073	15.027377328513762	13362
087aae8c0927e2e4b59da8ceeb0ecd6fbb8e527f	optimal intensity control of a multi-class queue	optimal solution;control problem;single server queue;generic point;optimal scheduling;infinite horizon	We study a mixed problem of optimal scheduling and input and output control of a single server queue with multi-classes of customers. The model extends the classical optimal scheduling problem by allowing the general point processes as the arrival and departure processes and the control of the arrival and departure intensities. The objective of our scheduling and control problem is to minimize the expected discounted inventory cost over an infinite horizon, and the problem is formulated as an intensity control. We find the well-knowncμ is the optimal solution to our problem.		H. Chen	1989	Queueing Syst.	10.1007/BF01225320	mathematical optimization;real-time computing;earliest deadline first scheduling;multilevel queue;dynamic priority scheduling;computer science;generic point;mathematics	Metrics	9.811083611841195	8.018128865353603	13363
5d8bd70ed1ce7f20841fb4dcc3348736acf29873	self-assembly of strings and languages	qa75 electronic computers computer science szamitastechnika;self assembly;combinatorics;szamitogeptudomany;combinatoria;combinatoire;generador;generator;informatique theorique;base;palabra;word;auto assemble;generateur;mot;computer theory;informatica teorica	Self-assembly is the process in which simple objects autonomously aggregate into large structures and it has become one of the major tools for nano-scale engineering. We propose in this paper a string-based framework inspired by the principle of selfassembly: two strings with a common overlap, say uv and vw, yield a string uvw; we say that string uvw has been assembled from strings uv and vw. The operation may be extended in a natural way also to sets of strings. We answer several questions: what is the assembly power of a given set of strings, can a given set of strings be generated through assembly and if so, what is a minimal generator for it?	aggregate data;gnu nano;self-assembly;string (computer science)	Erzsébet Csuhaj-Varjú;Ion Petre;György Vaszil	2007	Theor. Comput. Sci.	10.1016/j.tcs.2006.12.004	combinatorics;string kernel;computer science;theoretical computer science;word;mathematics;base;string metric;self-assembly;electric generator;algorithm;algebra	Theory	0.7335682089573006	20.098540396797137	13375
4a6fb9331a55b459cbbf1d81af924971bdd4aacd	distributed backup placement in networks	distributed algorithms;approximation algorithms;load balancing	We consider the backup placement problem, defined as follows. Some nodes (processors) in a given network have objects (e.g., files, tasks) whose backups should be stored in additional nodes for increased fault resilience. To minimize the disturbance in case of a failure, it is required that a backup copy should be located at a neighbor of the primary node. The goal is to find an assignment of backup copies to nodes which minimizes the maximum load (number or total size of backup copies) over all nodes in the network. It is known that a natural selfish local improvement policy has approximation ratio $$\varOmega (\log n/\log \log n)$$ Ω ( log n / log log n ) ; we show that it may take this policy $$\varOmega (\sqrt{n})$$ Ω ( n ) time to reach equilibrium in the distributed setting. Our main result in this paper is a randomized distributed algorithm which finds a placement in polylogarithmic time and achieves approximation ratio $$O\left(\frac{\log n}{\log \log n}\right)$$ O log n log log n . We obtain this result using a randomized distributed approximation algorithm for f-matching in bipartite graphs that may be of independent interest.	approximation algorithm;backup;central processing unit;decision problem;distributed algorithm;graph (discrete mathematics);graph coloring;np-hardness;polylogarithmic function;polynomial;randomized algorithm;time complexity;with high probability	Magnús M. Halldórsson;Sven Köhler;Boaz Patt-Shamir;Dror Rawitz	2017	Distributed Computing	10.1007/s00446-017-0299-x	distributed algorithm;binary logarithm;approximation algorithm;bipartite graph;backup;computer science;distributed computing	Theory	17.549473460542362	33.94022421396134	13378
0d21e7b7d9c79c7666318dee019fc9df00e5f90e	a continuous characterization of maximal cliques in k-uniform hypergraphs	maximum clique problem;dynamic system;maximum clique;continuous optimization	In 1965 Motzkin and Straus established a remarkable connection between the local/global maximizers of the Lagrangian of a graph G over the standard simplex ∆ and the maximal/maximum cliques of G. In this work we generalize the Motzkin-Straus theorem to k-uniform hypergraphs, establishing an isomorphism between local/global minimizers of a particular function over ∆ and the maximal/maximum cliques of a k-uniform hypergraph. This theoretical result opens the door to a wide range of further both practical and theoretical applications, concerning continuous-based heuristics for the maximum clique problem on hypergraphs, as well as the discover of new bounds on the clique number of hypergraphs. Moreover we show how the continuous optimization task related to our theorem, can be easily locally solved by mean of a dynamical system.	baum–welch algorithm;clique (graph theory);clique problem;continuous optimization;dynamical system;experiment;extremal graph theory;heuristic (computer science);mathematical optimization;maxima and minima;maximal independent set;maximal set;optimization problem;performance	Samuel Rota Bulò;Marcello Pelillo	2007		10.1007/978-3-540-92695-5_17	clique;mathematical optimization;combinatorics;clique graph;discrete mathematics;dynamical system;mathematics;continuous optimization	ML	24.856583704769033	16.521940909004943	13380
e49f9c2916e622c34ce582a6889d6e04f9cf1972	robust relative location estimation in wireless sensor networks with inexact position problems	convex semidefinite program;robust min max optimization method;wsn topology;numerical techniques;wireless sensor networks convex programming mathematical programming maximum likelihood estimation minimax techniques numerical analysis;relative location estimation;sensors wireless sensor networks robustness optimization maximum likelihood estimation convex functions;inexact position problem;numerical technique;maximum likelihood;sensors;convex programming;socp relaxation methods robust relative location estimation wireless sensor networks inexact position problems location unaware sensors position estimation robust min max optimization method relative location estimation problem worst case estimation error convex semidefinite program sdp numerical techniques wsn topology modified maximum likelihood estimation modified ml estimation second order cone programming relaxation methods;location estimation;optimal method;modified ml estimation;wireless sensor networks wsns;maximum likelihood estimation;robust optimization;wireless sensor network;convex functions;optimization problem;minimax techniques;maximum likelihood ml estimation;numerical analysis;maximum likelihood estimate;second order cone program;mathematical programming;convex function;semidefinite program sdp;position estimation;modified maximum likelihood estimation;socp relaxation methods;location unaware sensors;sdp;semidefinite program sdp relative location estimation inexact position problem wireless sensor networks wsns maximum likelihood ml estimation second order cone program socp;robustness;relative location estimation problem;optimization;robust relative location estimation;location awareness;second order cone program socp;estimation error;worst case estimation error;second order cone programming relaxation methods;wireless sensor networks;inexact position problems;semidefinite program	In this paper, the relative location estimation problem, a prominent issue faced by several applications in wireless sensor networks (WSNs), is considered. Sensors are classified into two categories: location-aware and location-unaware sensors. To estimate the positions of location-unaware sensors, exact positions are often assumed for location-aware sensors. However, in practice, such precise data may not be available. Therefore, determining the positions of location-unaware sensors in the presence of inexact positions of location-aware sensors is the primary focus of this study. A robust min-max optimization method is proposed for the relative location estimation problem by minimizing the worst-case estimation error. The corresponding optimization problem is originally nonconvex, but after it is transformed into a convex semidefinite program (SDP), it can be solved by existing numerical techniques. In the presence of inexact positions of location-aware sensors, the robustness of the proposed approach is validated by simulations under different WSN topologies. Modified maximum-likelihood (ML) estimation and second-order cone programming (SOCP) relaxation methods have been used for localization in comparison with the proposed approach.	best, worst and average case;convex optimization;estimation theory;experiment;internationalization and localization;linear programming relaxation;location awareness;location-based service;mathematical optimization;maxima and minima;numerical analysis;optimization problem;second-order cone programming;semidefinite programming;sensor;simulation;software deployment	Wei-Yu Chiu;Bor-Sen Chen;Chang-Yi Yang	2012	IEEE Transactions on Mobile Computing	10.1109/TMC.2011.111	mathematical optimization;robust optimization;computer science;maximum likelihood;statistics	Mobile	51.13950305996594	4.964498189370817	13381
a102419584cb83d53cfb188dac2ce67ab03e2427	z4-linear perfect codes	perfect code	For every n = 2k ≥ 16 there exist exactly ⌊(k + 1)/2⌋ mutually nonequivalent Z4-linear extended perfect codes with distance 4. All these codes have different ranks. Certain of known nonlinear binary codes such as Kerdock, Preparata, Goethals, Delsarte-Goethals codes can be represented, using some mapping Z4 → Z 2 2 (in this paper, following [5], we use the mapping 0 → 00, 1 → 01, 2 → 11, 3 → 10) as linear codes over the alphabet {0, 1, 2, 3} with modulo 4 operations (see [14, 10, 11, 12, 5]). Codes represented in such a manner are called Z4-linear. In [5] it is shown that the extended Golay code and the extended Hamming (n, 22 , 4)-codes (of length n and cardinality 22 , with distance 4) for every n > 16 are not Z4-linear. Also, in [5] for every n = 2 a Z4-linear (2, 2 n−log2 , 4)-code is described (the codes C2, in the notations of § 2, are presented as cyclic codes in [5]). The goal of this work is a complete description of Z4-linear perfect and extended perfect codes. It is known [23, 22] that there are no nontrivial perfect binary codes except the Golay (23, 2, 7)-code and the (2−1, 2 k−k−1, 3)-codes. The perfect (23, 2, 7)-code is unique up to equivalence. The linear (Hamming) (2 − 1, 2 k−k−1, 3)-code is also unique for every k, but for n = 2 − 1 ≥ 15 there exist more than 2 (n+1)/2−k (for the last lower bound, see [6]) nonlinear codes with the same parameters (see, e.g., [19, 3] for a survey of some constructions). The class of all (2 − 1, 2 k−k−1, 3)-codes is not described yet. In this paper we show that not great, but increasing as k → ∞, number of extended perfect (2, 2 k−k−1, 4)-codes can be represented as linear codes over the ring Z4. In § 2, in terms of check matrices, we define ⌊(log2 n + 1)/2⌋ Z4-linear extended perfect (n, 2/2n, 4)-codes. In § 3 we show that the codes constructed are Original Russian text was published in Diskretn. Anal. Issled. Oper., Ser. 1, 7(4):78-90, 2000.	binary golay code;binary code;comstock–needham system;cyclic code;existential quantification;hamming bound;modulo operation;nonlinear system;preparata code;qr code;ternary golay code;turing completeness;window function;z4 (computer)	Denis S. Krotov	2007	CoRR		combinatorics;discrete mathematics;mathematics;algebra	Theory	40.51375266084158	53.31190594766139	13394
02e299f521d85c6844702d9c98342682d10f976f	network flow-based refinement for multilevel hypergraph partitioning		We present a refinement framework for multilevel hypergraph partitioning that uses max-flow computations on pairs of blocks to improve the solution quality of a k-way partition. The framework generalizes the flow-based improvement algorithm of KaFFPa from graphs to hypergraphs and is integrated into the hypergraph partitioner KaHyPar. By reducing the size of hypergraph flow networks, improving the flow model used in KaFFPa, and developing techniques to improve the running time of our algorithm, we obtain a partitioner that computes the best solutions for a wide range of benchmark hypergraphs from different application areas while still having a running time comparable to that of hMetis. 1998 ACM Subject Classification G.2.2 Graph Theory, G.2.3 Applications	algorithm;benchmark (computing);binary space partitioning;computation;flow network;graph partition;maximum flow problem;refinement (computing);time complexity	Tobias Heuer;Peter Sanders;Sebastian Schlag	2018		10.4230/LIPIcs.SEA.2018.1	discrete mathematics;flow network;combinatorics;hypergraph;mathematics;computation;partition (number theory);constraint graph;graph	EDA	20.443658367857445	21.052970997725694	13398
a3990af6bae2a7265ecc329292d04c56db12fc10	performance analysis of 3d-ic for multi-core processors in sub-65nm cmos technologies	cmos integrated circuits;multi core processor;cmos technology;performance evaluation;integrated circuit;three dimensional integrated circuits cmos integrated circuits integrated circuit design multiprocessing systems performance evaluation;cmos technology performance analysis three dimensional integrated circuits multicore processing cmos process integrated circuit interconnections delay integrated circuit technology through silicon vias large scale integration;three dimensional;integrated circuit design;performance improvement;size 65 nm performance analysis 3d ic three dimensional integrated circuit multicore processor cmos technology interconnect delay;three dimensional displays;integrated circuit interconnections;performance analysis;3d ic;multicore processor;multiprocessing systems;program processors;size 65 nm;interconnect delay;three dimensional integrated circuit;three dimensional integrated circuits;through silicon vias	Three-dimensional integrated circuits (3D-IQ have the potential to reduce interconnect length and improve performance especially in sub-65nm CMOS technologies. This paper describes design and performance analysis of the 3D-IC in sub-65nm CMOS technologies based on the accurate calculation of interconnects delays using 16-core processors as case studies. Performance improvement of the 3D-IC vs. 2D-IC is increased as CMOS scales down, which is consistent with the expected trend. The performance improvement is over 20%. Furthermore, performance of the 3D-IC in 65 nm (or 45 nm) CMOS technology is superior to that of the 2D-IC in 45 nm (or 32 nm) CMOS technology. It indicates that design conversion from 2D-IC to 3D-IC is superior to the CMOS technology migration according to COMS scaling. Reduction in repeater buffers and area overhead is also estimated.	application-specific integrated circuit;cmos;cpu cache;central processing unit;image scaling;integrated circuit design;multi-core processor;overhead (computing);processor design;profiling (computer programming);speaker wire;three-dimensional integrated circuit;through-silicon via	Kumiko Nomura;Keiko Abe;Shinobu Fujita;Yasuhiko Kurosawa;Atsushi Kageshima	2010	Proceedings of 2010 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2010.5536963	three-dimensional integrated circuit;multi-core processor;embedded system;computer architecture;electronic engineering;computer science;engineering;fo4;cmos	EDA	14.30732859598795	57.450244721578045	13399
c13aa86f3b874664e20979c1adccd8225d5cc8f3	modification of weak structures via hereditary classes	hereditary class;weak structure	In this paper, we introduce and study the properties of some new kinds of generalized closed subsets with respect to a weak structure modified by a hereditary class. Then some already established results are generalized. Also, we define a new kind of continuity depending on the new class of generalized closed subsets.		Ahmed M. Zahran;Kamal El-Saady;Abd El-Nasser Ghareeb	2012	Appl. Math. Lett.	10.1016/j.aml.2011.10.034	combinatorics;discrete mathematics;topology;mathematics	Logic	42.712186630636545	25.893555790764804	13413
28ea8ba46a9ef46b3a3632c12a50366deb0fef17	a generic c++ toolkit for the development of real-time-capable software defined radio applications	decoding;automatic code generation generic c toolkit real time capable software defined radio applications sdr tx rx frontend hf baseband signal demodulation decoding baseband signal communication systems research and development generic platform independent c toolkit data dominated systems multicore architectures multiple processing blocks packet based input output data streams graphical user interface;telecommunication computing;software radio;c language;transmitting antennas c language decoding demodulation receiving antennas software radio telecommunication computing;demodulation;digital video broadcasting ports computers baseband real time systems receivers data models graphical user interfaces;receiving antennas;transmitting antennas	Software-Defined-Radio (SDR) describes the approach of realizing communication systems as far as possible in software. Ideally, the antenna and the TX/RX frontend, converting the baseband signal to HF or vice versa, are the only remaining hardware components. The algorithms for the (de-)modulation and (de-)coding of the baseband signal are implemented in software. In conjunction with a powerful processor, this is a flexible and cheap possibility to develop communication systems. Due to the low development costs compared to the development in hardware and the high flexibility, SDRs have become popular in research and development. In order to ease the development of SDR applications, a generic platform-independent C++ toolkit has been developed. It supports data-dominated systems using multi-core architectures. The toolkit represents the system under development as a model consisting of multiple processing blocks with packet-based input and output data streams. A graphical user interface providing automatic code generation eases the use of the toolkit.	algorithm;automatic programming;baseband;c++;code generation (compiler);etsi satellite digital radio;graphical user interface;input/output;multi-core processor;network packet;real-time transcription	Jan Zöllner;Joerg Robert;Daniel Rother;Mariem Slimani	2014	2014 IEEE International Conference on Consumer Electronics (ICCE)	10.1109/ICCE.2014.6776092	embedded system;electronic engineering;real-time computing;telecommunications;computer science;electrical engineering;operating system;software-defined radio;demodulation	Robotics	30.28798712091525	59.59471919981863	13439
2cee32b16d10bf33c3cb1a9513d7d9609c3e7c2f	sharpening occam's razor	complexite kolmogorov;theorem proving;demonstration theoreme;complexity measure;mesure complexite;demostracion teorema;medida complexidad;theoreme occam s razor	We provide a new representation-independent formulation of Occam’s razor theorem, based on Kolmogorov complexity. This new formulation allows us to: (i) Obtain better sample complexity than both length-based [4] and VC-based [3] versions of Occam’s razor theorem, in many applications; and (ii) Achieve a sharper reverse of Occam’s razor theorem than that of [5]. Specifically, we weaken the assumptions made in [5] and extend the reverse to superpolynomial running times.	algorithm;enumerated type;kolmogorov complexity;model of computation;occam's razor;requirement;sample complexity;time complexity;occam	Ming Li;John Tromp;Paul M. B. Vitányi	2002		10.1007/3-540-45655-4_44	computer science;artificial intelligence;calculus;mathematics;automated theorem proving;programming language;algorithm	Theory	5.884203737196209	22.317496343322347	13448
1a2d4ed45cd7421c1da4c8c92d5b046d95f9deb6	some results on geometric independency trees	spanning tree	A plane spanning tree is a tree drawn in the plane so that its edges are closed straight line segments and any two edges do not intersect internally, and no three of its vertices are collinear. In this paper, we present several results on a plane spanning tree such that the graph which is obtained from the tree by adding a line segment between any two end-vertices of the tree is self-intersecting.	file spanning;spanning tree;vertex (geometry)	Atsushi Kaneko;Yoshiaki Oda;Kiyoshi Yoshimoto	1999			combinatorics;line (geometry);vertex (geometry);line segment;minimum degree spanning tree;computer science;graph;spanning tree	Theory	31.207599674390202	22.694403731116928	13449
068622333bc1112e093279c393c9ad687c612f8d	stochastic bounds for switched bernoulli batch arrivals observed through measurements		We generalise to non stationary traffics an approach that we have previously proposed to derive performance bounds of a queue under histogram-based input traffics. We use strong stochastic ordering to derive stochastic bounds on the queue length and the output traffic. These bounds are valid for transient distributions of these measures and also for the steady-state distributions when they exist. We provide some numerical techniques under arrivals modelled by a Switched Batch Bernoulli Process (SBBP). Unlike approximate methods, these bounds can be used to check if the Quality of Service constraints are satisfied or not. Our approach provides a tradeoff between the accuracy of results and the computational complexity and it is much faster than the histogram-based simulation proposed in the literature.	bernoulli polynomials	Farah Aït-Salaht;Hind Castel-Taleb;Jean-Michel Fourneau;Nihal Pekergin	2017		10.1007/978-3-319-61428-1_1	computer science;real-time computing;quality of service;computational complexity theory;bernoulli's principle;stochastic ordering;mathematical optimization;queue;histogram;bernoulli process	ECom	7.6477469581817905	12.193288838126975	13450
c0944e803934fdd3a5523d53c33f07bf1929e36f	reversible computation with quantum-dot cellular automata (qca)	quantum dot cellular automata;electric field;energy dissipation;reversible computing;nearest neighbor;coulomb interaction;binary data;molecular electronics	Quantum-dot cellular automata (QCA) is a strategy in which binary data is represented by charge configuration within a multi-dot cell. Data is transmitted to nearest neighbors by the Coulombic interaction. An electric field acts as a clock and imposes directionality on circuits. We have explored the connection between logical reversibility and physical reversibility in the context of a QCA system, explicitly calculating the energy dissipated by performing an erasure as a function of the time over which it is performed [1]. Further, we present a Bennett-style clocking scheme to implement reversible computation that is natural to the circuits to minimize the amount of information that is erased. Molecular QCA may provide a practical implementation of reversible computing	automata theory;binary data;clock rate;computation;qualitative comparative analysis;quantum cellular automaton;quantum dot cellular automaton;reversible computing	Craig S. Lent;Sarah E. Murphy;Peter M. Kogge	2005		10.1145/1062261.1062327	electronic engineering;quantum cellular automaton;theoretical computer science;mathematics;algorithm	EDA	17.284999411368805	44.353271218489574	13466
2393b650ef5fe66c434c50608daf56747ead5fbe	product constructions for perfect lee codes	nonlinear codes;perfect code;manhattan metric;hamming scheme;anticode;measurement;lattices;periodic code;manganese;hamming distance;shape;linear code;lattices linear code hamming distance;product construction anticode diameter perfect code hamming scheme lee metric manhattan metric perfect code periodic code;zinc;product construction;diameter perfect code;nonlinear diameter perfect codes golomb conjecture welch conjecture lee metrics manhattan metrics diameter perfect lee codes;lee metric	A well-known conjecture of Golomb and Welch is that the only nontrivial perfect codes in the Lee and Manhattan metrics have length two or minimum distance three. This problem and related topics were subject for extensive research in the last 40 years. In this paper, two product constructions for perfect Lee codes and diameter perfect Lee codes are presented. These constructions yield a large number of nonlinear perfect codes and nonlinear diameter perfect codes in the Lee and Manhattan metrics. A short survey and other related problems on perfect codes in the Lee and Manhattan metrics are also discussed.	code (cryptography);golomb ruler;hamming bound;nonlinear system;welch's method	Tuvi Etzion	2011	IEEE Transactions on Information Theory	10.1109/TIT.2011.2161133	block code;combinatorics;discrete mathematics;hamming distance;shape;manganese;pure mathematics;zinc;linear code;mathematics;measurement;statistics	Theory	40.08503893586842	54.193608353325075	13472
c75cca3073f667aec44e0d216950089bc83d3aa7	multiple-valued logic and optimization of programmable logic arrays	state space methods;clocks;availability;state space abstraction;strong firing semantics;state zone graph time arc petri nets strong and weak semantics state space abstraction;semantic networks;data mining;language emptiness problems;time arc petri nets;assembly;time petri net;state space abstraction techniques;state space;zone graphs;state zone graph;strong and weak semantics;petri nets fires state space methods clocks sociotechnical systems application software concurrent computing system analysis and design design engineering delay effects;petri nets;strong firing semantics time arc petri nets state space abstraction techniques zone graphs k boundedness marking reachability language emptiness problems weak firing semantics;k boundedness;petri net;state space methods petri nets semantic networks;weak firing semantics;marking reachability	Shows a method of designing programmable logic arrays (PLAs) using multiple-valued input, two-valued output functions (MVITVOFs). A MVITVOF is an extension of the two-valued logic function. An expression for a MVITVOF directly represents a multiple-output PLA with decoders. Each product of the expression corresponds to each column of the PLA, so the number of products; in the expression equals the number of columns of the PLA. The array size of the PLA is proportional to the number of products; the PLA can thus be minimized by minimizing the expression.<<ETX>>	boolean algebra;column (database);logic gate;mathematical optimization;programmable logic array;programmable logic device	Hind Rakkay;Hanifa Boucheneb;Olivier H. Roux	1988	Computer	10.1109/ACSD.2009.21	stochastic petri net;computer science;theoretical computer science;process architecture;petri net;algorithm	EDA	19.72536615065373	46.01435195882896	13481
e2f83732048a31500c8fe4fe03a18ab1c4a27d4b	the worst order in not always the lexicographic order	maximum degree;lexicographic order	Consider <i>I</i> an homogeneous ideal in <i>S</i> = <i>k</i>[<i>x</i><inf>0</inf>,..., <i>x</i><inf><i>n</i></inf>], where <i>k</i> is a field of characteristic zero. For any multiplicative order &gt; on <i>S</i> with <i>x</i><inf>0</inf> &gt; <i>x</i><inf>1</inf> &gt; ... &gt; <i>x</i><inf><i>n</i></inf>, denote by <i>M</i><inf>&gt;</inf> (<i>I</i>) the maximum degree of a generator of the Gr&ouml;bner basis for <i>I</i> with respect to the order &gt;. It is known [BaSt87] that if <i>I</i> is in generic coordinates, then <i>M</i><inf><i>rev. lex.</i></inf>(<i>I</i>) is minimal among all orders.	geographic coordinate system;gröbner basis;lexicographical order;rev	Alyson A. Reeves	1991	ACM SIGSAM Bulletin	10.1145/122508.122512	mathematical optimization;combinatorics;discrete mathematics;lexicographical order;mathematics;algebra	Theory	35.175440518856576	32.837629359800566	13483
19bf6e71c7e07d5c27cab78e47a184b19a3588c9	average degrees of critical graphs				Xuechao Li	2005	Ars Comb.		combinatorics;mathematics;discrete mathematics;graph	ML	31.63669565833587	33.595392307987765	13497
0dd2449497908c56cbf32bc5e6034a08f6dfac94	modern wireless sensor implementation for indoor tracking, transport and power grid monitoring	wi fi rfid;transportation radar smart grid monitoring wi fi rfid tracking;wireless communication wireless sensor networks ieee 802 11 standards radar antennas radar detection graphical user interfaces;wireless sensor networks smart power grids;power chipsets modern wireless sensor implementation indoor tracking grid monitoring transport monitoring power monitoring ws technology wireless sensor technology regional industries wireless networks reliable wireless sensor applications observe situation monitor condition central processing unit pedestrian sensing indoor individual tracking remote smart probe power grid feeders remote sensors;tracking;smart grid monitoring;transportation radar	Wireless Sensor (WS) technology is emerging from indoor application to regional industries nowadays. Demand arises due to the expanding wireless networks and technical requirement in sensing and automation. Awareness from technology leaders have stimulated the trend to research and develop reliable wireless sensor applications to observe situation, monitor condition, harvest information and then feedback to central processing unit for analysis and archival. Wireless sensor is the promising technology with great potential. This article describes trending wireless sensor applications in three areas, ranging from personal service to regional application. These applications include pedestrian sensing for transportation, indoor individual tracking and remote smart probe for power grid feeders. Remote sensors are the key component. It operates remotely with the supports from limited intelligence within the associated low power microprocessor. With technological advancement in nano-sensors and low power chipsets, the potential of wireless sensor technology implementation is broadening.	algorithm;archive;central processing unit;chipset;demo (computer programming);gnu nano;image sensor;internationalization and localization;microprocessor;numerical analysis;pedestrian detection;sensor web;smart transducer;time of arrival	W. S. Yeoh;Qiang Li;C. E. Png;K. L. Wong	2015	2015 IEEE Tenth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP)	10.1109/ISSNIP.2015.7106977	embedded system;electronic engineering;wireless sensor network;wireless site survey;telecommunications;engineering;key distribution in wireless sensor networks;wi-fi array;fixed wireless;mobile wireless sensor network	Mobile	3.9526602610290236	32.38600538215817	13502
8aa55fa28c33c494cf553abc8da4969ddcef4642	a construction of t-fold perfect splitting authentication codes with equal deception probabilities	05b15;94a62;t-fold perfect splitting authentication code;transversal splitting t-design;orthogonal multi-array	Orthogonal multi-arrays were first formulated by Brickell in investigation of authentication codes. In this article, we will prove that t-fold perfect splitting authentication codes with equal deception probabilities can be characterized in terms of orthogonal multi-arrays. We will also investigate the existence of orthogonal multi-arrays, and show that the existence of orthogonal multi-arrays OMA (t,k×c,n)s is equivalent to the existence of transversal splitting t-designs splitting TD (t,k×c,n)s. Further, we obtain some new infinite classes of t-fold perfect splitting authentication codes with equal deception probabilities.	authentication;code;oma	Mingchao Li;Miao Liang;Beiliang Du	2014	Cryptography and Communications	10.1007/s12095-014-0107-4	combinatorics;discrete mathematics;mathematics	Crypto	38.4854484690733	54.075424907319395	13524
1e0e2d2208b18c993e4bcc2f0cd29359a99431a8	performance analysis of coarray-based music in the presence of sensor location errors		Sparse linear arrays, such as co-prime and nested arrays, can resolve more uncorrelated sources than the number of sensors by applying the MUtiple SIgnal Classification (MUSIC) algorithm to their difference coarray model. We aim at statistically analyzing the performance of the MUSIC algorithm applied to the difference coarray model, namely, the coarray-based MUSIC, in the presence of sensor location errors. We first introduce a signal model for sparse linear arrays in the presence of deterministic unknown location errors. Based on this signal model, we derive a closed-form expression of the asymptotic mean-squared error of a commonly used coarray-based MUSIC algorithm, SS-MUSIC, in the presence of small sensor location errors. We show that the sensor location errors introduce a constant bias that depends on both the physical array geometry and the coarray geometry, which cannot be mitigated by only increasing the signal-to-noise ratio. We next give a short extension of our analysis to cases when the sensor location errors are stochastic and investigate the Gaussian case. Finally, we derive the Cramér–Rao bound for joint estimation of direction-of-arrivals and sensor location errors for sparse linear arrays, which can be applicable even if the number of sources exceeds the number of sensors. Numerical simulations show good agreement between empirical results and our theoretical results.	algorithm;computational fluid dynamics;mean squared error;numerical linear algebra;profiling (computer programming);sensor;signal-to-noise ratio;simulation;sparse matrix	Mianzhi Wang;Zhen Zhang;Arye Nehorai	2018	IEEE Transactions on Signal Processing	10.1109/TSP.2018.2824283	mathematical optimization;multiple signal classification;mathematics;uncorrelated;gaussian	Vision	52.115000502138145	6.407755740876253	13529
f9ffdad77bf754f272d35e7555594e1ddf21af56	isolated d.r.e. degrees are dense in r.e. degree structure		A degreed is d.r.e. if and only if it contains some difference of r.e. sets A− B. It is an important class of degrees other than that of r.e. degrees. G. E. Sacks [4] showed that the r.e. degrees are dense. But S. B. Cooper, H. Harrington, A. H. Lachlan, S. Lempp and R. I. Soare [2] proved that the d.r.e. degrees are not dense. Recently S. B. Cooper and X. Yi [1] made a progress in this respect by introducing a new notion of isolated d.r.e. degree .		Decheng Ding;Lei Qian	1996	Arch. Math. Log.	10.1007/s001530050053	beam (structure);combinatorics;nut;macadamia nut;mathematics;wavelength;laser;optics	Theory	33.62373937086579	27.75495466829745	13535
c514d0cafd55343ca229a81f3ab88300638cb4c3	design, analysis and test of logic circuits under uncertainty	probabilistic behavior;probabilistic reformulation;process variation;key challenge;external radiation;ic design;cmos scaling;logic circuit;logic circuits;probabilistic quantum;testing logic circuit;soft error;logic design;electronic design automation	Design, Analysis and Test of Logic Circuits under Uncertainty by Smita Krishnaswamy Co-Chairs: John P. Hayes and Igor L. Markov Integrated circuits (ICs) are increasingly susceptible to uncertainty caused by soft errors, inherently probabilistic devices, and manufacturing variability. As device technologies scale, these effects become detrimental to circuit reliability. In order to address this, we develop methods for analyzing, designing, and testing circuits subject to probabilistic effects. Our main contributions are: 1) a fast, soft-error rate (SER) analyzer that uses functional-simulation signatures to capture error effects, 2) novel design techniques that improve reliability using little area and performance overhead, 3) a matrixbased reliability-analysis framework that captures many types of probabilistic faults, and 4) test-generation/compaction methods aimed at probabilistic faults in logic circuits. SER analysis must account for the three main error-masking mechanisms in ICs: logic, timing, and electrical masking. We relate logic masking to node testability of the circuit and utilize functional-simulation signatures, i.e., partial truth tables, to efficiently compute estability (signal probability and observability). To account for timing masking, we compute error-latching windows (ELWs) from timing analysis information. Electrical masking is incorporated into our estimates through derating factors for gate error probabilities. The SER of a circuit is computed by combining the effects of all three masking mechanisms within our SER analyzer called AnSER. Using AnSER, we develop several low-overhead techniques that increase reliability, including: 1) an SER-aware design method that uses redundancy already present within the circuit, 2) a technique that resynthesizes small windows of logic to improve area and reliability, and 3) a post-placement gate-relocation technique that increases timing masking by decreasing ELWs. We develop the probabilistic transfer matrix (PTM) modeling framework to analyze effects beyond soft errors. PTMs are compressed into algebraic decision diagrams (ADDs) to improve computational efficiency. Several ADD algorithms are developed to extract reliability and error susceptibility information from PTMs representing circuits. We propose new algorithms for circuit testing under probabilistic faults, which require a reformulation of existing test techniques. For instance, a test vector may need to be repeated many times to detect a fault. Also, different vectors detect the same fault with different probabilities. We develop test generation methods that account for these differences, and integer linear programming (ILP) formulations to optimize test sets.	and gate;algorithm;antivirus software;approximation algorithm;bitwise operation;boolean satisfiability problem;combinational logic;computation;data compaction;diagram;digital signature;electronic signature;emoticon;error analysis (mathematics);error-tolerant design;fan-in;fault tolerance;hardening (computing);hayes microcomputer products;heart rate variability;integer programming;integrated circuit;john p. hayes;lexicographical order;lexicography;linear programming;logic gate;logic level;logic simulation;markov chain;microsoft windows;or gate;observable;overhead (computing);physical design (electronics);polynomial texture mapping;propagation of uncertainty;reconvergent fan-out;recursion;redundancy (engineering);relocation (computing);rewriting;runtime system;self-replicating machine;signature block;simulation;single event upset;soft error;software propagation;solver;sorting algorithm;static timing analysis;test vector;time complexity;transfer matrix;triple modular redundancy;type signature;verification and validation;with high probability;xor gate	Smita Krishnaswamy;Igor L. Markov;John P. Hayes	2013		10.1007/978-90-481-9644-9	probabilistic-based design optimization;logic synthesis;logic optimization;probabilistic design;logic family;computer science;artificial intelligence;algorithm	EDA	19.465709963859172	48.85419684176889	13549
b736cd90e66317425f14a9b85a181d8fe05a4f53	algorithms for computing the double cut and join distance on both gene order and intergenic sizes	dcj;intergenic regions;genome rearrangements;algorithms	Combinatorial works on genome rearrangements have so far ignored the influence of intergene sizes, i.e. the number of nucleotides between consecutive genes, although it was recently shown decisive for the accuracy of inference methods (Biller et al. in Genome Biol Evol 8:1427–39, 2016; Biller et al. in Beckmann A, Bienvenu L, Jonoska N, editors. Proceedings of Pursuit of the Universal-12th conference on computability in Europe, CiE 2016, Lecture notes in computer science, vol 9709, Paris, France, June 27–July 1, 2016. Berlin: Springer, p. 35–44, 2016). In this line, we define a new genome rearrangement model called wDCJ, a generalization of the well-known double cut and join (or DCJ) operation that modifies both the gene order and the intergene size distribution of a genome. We first provide a generic formula for the wDCJ distance between two genomes, and show that computing this distance is strongly NP-complete. We then propose an approximation algorithm of ratio 4/3, and two exact ones: a fixed-parameter tractable (FPT) algorithm and an integer linear programming (ILP) formulation. We provide theoretical and empirical bounds on the expected growth of the parameter at the center of our FPT and ILP algorithms, assuming a probabilistic model of evolution under wDCJ, which shows that both these algorithms should run reasonably fast in practice.	approximation algorithm;cobham's thesis;computability in europe;computation (action);countercurrent electrophoresis measurement;dna sequence rearrangement;denture, partial, fixed, resin-bonded;generalization (psychology);hybrid genome assembly;inference;integer (number);integer programming;lecture notes in computer science;linear iga bullous dermatosis;linear programming;models of dna evolution;np-completeness;note (document);nucleotides;parameterized complexity;population parameter;springer (tank);statistical model;whole earth 'lectronic link;xiap gene	Guillaume Fertin;Géraldine Jean;Eric Tannier	2017		10.1186/s13015-017-0107-y	bioinformatics;gene;approximation algorithm;intergenic region;genome;integer programming;computability;algorithm;inference;statistical model;mathematics	Comp.	17.88973906486674	21.860972204765595	13551
307d486442f2ea38edb45aab410214681dea0c35	graphs determined by polynomial invariants	numero cromatico;graph theory;complexite;acoplamiento grafo;chromatic graph;graphe biparti;matroid;characteristic;teoria grafo;tutte polynomial;grafo bipartido;chromatic polynomial;complejidad;nombre chromatique;chromatic number;complexity;caracteristica;time;result;theorie graphe;graph matching;matroide;informacion;polynome caracteristique;couplage graphe;graph invariant;enquete;graphe chromatique;temps;matrice adjacence;superficie;caracteristique;invariant graphe;resultado;invariante;polynome tutte;area;resultat;encuesta;matriz adyacencia;adjacency matrix;polynome chromatique;characteristic polynomial;bipartite graph;survey;invariant;information;polinomio caracteristico;grafo cromatico;tiempo	Many polynomials have been de'ned associated to graphs, like the characteristic, matchings, chromatic and Tutte polynomials. Besides their intrinsic interest, they encode useful combinatorial information about the given graph. It is natural then to ask to what extent any of these polynomials determines a graph and, in particular, whether one can 'nd graphs that can be uniquely determined by a given polynomial. In this paper we survey known results in this area and, at the same time, we present some new results. c © 2003 Elsevier B.V. All rights reserved.	encode;graph (discrete mathematics);matching (graph theory);polynomial	Marc Noy	2003	Theor. Comput. Sci.	10.1016/S0304-3975(03)00225-1	1-planar graph;difference polynomials;matroid;pathwidth;chromatic polynomial;combinatorics;discrete mathematics;complexity;topology;information;bipartite graph;graph product;elementary symmetric polynomial;graph property;graph theory;forbidden graph characterization;invariant;algebraic graph theory;lévy family of graphs;graph coloring;mathematics;area;tutte polynomial;critical graph;modular decomposition;characteristic;characteristic polynomial;partial k-tree;chordal graph;indifference graph;tutte 12-cage;tutte theorem;adjacency matrix;matching	Theory	25.362173923921592	32.08411371881131	13562
449bca4de87ebaa56c4092d6cfecc3ca480ccec0	the optimal system design of the online electric vehicle utilizing wireless power transmission technology	wireless power transmission electric vehicle optimization particle swarm optimization pso transportation system design;inductive power transmission;underground transmission systems battery powered vehicles inductive power transmission numerical analysis particle swarm optimisation;south korea;numerical analysis;numerical analysis optimal system design online electric vehicle wireless power transmission technology olev korea advanced institute of science and technology kaist underground power transmitter battery powered vehicle next generation electric public transportation system south korea daejon mathematical model particle swarm optimization algorithm pso;underground transmission systems;particle swarm optimization;electric vehicles;electric power transmission;algorithms;optimization;particle swarm optimisation;battery powered vehicles;online electric vehicle	The Online Electric Vehicle (OLEV) is an innovative electric transportation system developed by the Korea Advanced Institute of Science and Technology (KAIST), Daejon, Korea, which remotely picks up electricity from power transmitters buried underground. Unlike a conventional electric vehicle that requires significant recharging downtime, the battery in the OLEV can be charged while the vehicle is in motion. Selected as one of “the 50 Best Innovations of 2010” by TIME Magazine, the OLEV is considered as a potential solution for the next-generation electric public transportation system in South Korea. The prototype of the OLEV has been developed, and the commercialization process is now in progress. One of the main tasks to achieve the successful commercialization of the system is to determine economically how to allocate the power transmitters on the given routes and how to evaluate the right battery capacity for the vehicle. The allocation of the power transmitters and the size of the battery capacity directly affect the initial infrastructure cost. In this paper, we first introduce the system design issues of the mass transportation system operating with OLEV. We then present a mathematical model and an optimization method to allocate economically the power transmitters and to determine the battery capacity of the OLEV-based mass transportation system. The particle swarm optimization (PSO) algorithm is used as the solution method for the optimization problem. Numerical problems with sensitivity analysis are presented to show the validity of the mathematical model and solution procedure.	algorithm;battery charger;decision theory;downtime;heart rate variability;mathematical model;mathematical optimization;numerical analysis;numerical method;numerical partial differential equations;optimization problem;particle swarm optimization;prototype;requirement;systems design;transmitter;velocity (software development)	Young Dae Ko;Young Jae Jang	2013	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2013.2259159	mathematical optimization;electronic engineering;simulation;numerical analysis;computer science;engineering;electrical engineering;mathematics;electric power transmission;particle swarm optimization	Embedded	4.23001682845603	7.92990254655496	13566
d4da9692f2e24cfc8d39b5b336eed1edd4343d60	efficient emulation of single-hop radio network with collision detection on multi-hop radio network with no collision detection	radio networks;maximum degree;probability of failure;multi hop network;collision detection;polynomial algorithm;randomized algorithm	This paper presents an efficient randomized emulation ofsingle-hop radio networkwith collision detection onmulti-hop radio networkwithout collision detection. Each step of the single-hop network is emulated by\(O\left( {\left( {D + \log \frac{n}{\varepsilon }} \right)\log \Delta } \right)\) rounds of the multi-hop network and succeeds with probability ≥1−e. (n is the number of processors,D the diameter and Δ the maximum degree). It is shown how to emulate any polynomial algorithm such that the probability of failure remains ≦e. A consequence of the emulation is an efficient randomized algorithm for choosing a leader in a multi-hop network.	collision detection;emulator;hop	Reuven Bar-Yehuda;Oded Goldreich;Alon Itai	1989		10.1007/3-540-51687-5_29	telecommunications;computer science;distributed computing;computer network	Mobile	18.163505240905355	33.00433165873083	13571
b0a588fe366f03f1a4fa26e9f3273f1e2c719783	dimension 4 and dimension 5 graphs with minimum edge set		The dimension of a graph G is defined to be the minimum n such that G has a representation as a unit-distance graph in R. A problem posed by Paul Erdős asks for the minimum number of edges in a graph of dimension 4. In a recent article, R. F. House showed that the answer to Erdős’ question is 9. In this article, we give a shorter (and we feel more straightforward) proof of House’s result, and then extend our methods to answer the question for dimension 5 as well. It is ultimately shown that a dimension 5 graph has at least 15 edges, and that this lower bound is realized only by two graphs: K6 and K1,3,3.	amd k6;erdős number	Joe Chaffee;Matt Noble	2016	Australasian J. Combinatorics		graph power;pathwidth;combinatorics;geometric graph theory;discrete mathematics;effective dimension;degree;clique-width;forbidden graph characterization;metric dimension;packing dimension;dimension;cycle graph;graph factorization;mathematics;voltage graph;order dimension;complement graph;line graph;string graph;strength of a graph;coxeter graph;planar graph	Theory	29.183596289806662	27.511638248100276	13584
718d20773ff53c19f1b2e1cda3cc687a6ba40ff7	maximum genus of regular graphs	regular graph	Abstract This paper provides tight lower bounds on the maximum genus of a regular graph in terms of its cycle rank. The main tool is a relatively simple theorem that relates lower bounds with the existence (or non-existence) of induced subgraphs with odd cycle rank that are separated from the rest of the graph by cuts of size at most three. Lower bounds on the maximum genus are obtained by bounding from below the size of these odd subgraphs. As a special case, upper-embeddability of a class of graphs is caused by an absence of such subgraphs. A well-known theorem stating that every 4-edge-connected graph is upper-embeddable is a straightforward corollary of the employed method.		Michal Kotrbcík	2011	Electronic Notes in Discrete Mathematics	10.1016/j.endm.2011.09.087	pathwidth;strongly regular graph;perfect graph theorem;petersen graph;split graph;combinatorics;discrete mathematics;cograph;topology;perfect graph;regular graph;forbidden graph characterization;trivially perfect graph;comparability graph;mathematics;tree-depth;odd graph;graph minor;line graph;planar graph	Theory	29.73075018451959	28.64489866823137	13590
fcc98c7f87013bd0a8675402a443f9a8f1be7f27	partitioning euclidean space	euclidean space	There is a partition of Euclideann-space into countably many sets none of which contains the vertices of a regularn-simplex.		James H. Schmerl	1993	Discrete & Computational Geometry	10.1007/BF02573966	euclidean domain;seven-dimensional space;euclidean group;affine space;combinatorics;eight-dimensional space;topology;point;distance from a point to a plane;euclidean space;euclidean shortest path;translation;euclidean distance;euclidean plane isometry;mathematics;geometry;magnitude;euclidean distance matrix;set function	Theory	36.91095499841252	21.39000516566488	13630
3d0b4d0fb11b15c31eff0c031b2f60d31655d928	parallel solutions to the k-difference primer problem		This paper presents parallel solutions to the k-difference primer problem, targeting multicore processors and GPUs. This problem consists of finding the shortest substrings of one sequence with at least k differences from another sequence. The sequences found in the solution are candidate regions to contain primers used by biologists to amplify a DNA sequence in laboratory. To the authors’ knowledge, these are the first parallel solutions proposed for the k-difference primer problem. We identified two forms, coarseand fine-grained, of exploiting parallelism while solving the problem. Several optimizations were applied to the solutions, such as synchronization overhead reduction, tiling, and speculative prefetch, allowing the analysis of very long sequences in a reduced execution time. In an experimental performance evaluation using real DNA sequences, the best OpenMP (in a quad-core processor) and CUDA solutions produced speedups up to 5.6 and 72.8, respectively, when compared to the best sequential solution. Even when the sequences length and the number of differences k increase, the performance is not affected. The best sequential, OpenMP, and CUDA solutions achieved the throughput of 0.16, 0.94, and 11.85 billions symbol comparisons per second, respectively, emphasizing the performance gain of the CUDA solution, which reached 100% of GPU occupancy.	algorithm;cuda;central processing unit;graphics processing unit;memory hierarchy;multi-core processor;openmp;overhead (computing);primer;parallel computing;performance evaluation;run time (program lifecycle phase);speculative execution;substring;throughput;tiling window manager	Leandro Feuser;Nahri Moreano	2018		10.1007/978-3-319-93698-7_39	distributed computing;throughput;instruction prefetch;synchronization;cuda;computer science;primer (molecular biology);multi-core processor;substring;supercomputer	HPC	-0.4765184446261149	42.077548777611526	13636
ead5e60187efa9aafffb4f2ab71e7aa9f76b256f	the drawability problem for minimum weight triangulations	graph drawing;computational geometry;linear time algorithm;line drawings;minimum weight triangulation;triangulations	A graph is minimum weight drawable if it admits a straight-line drawing that is a minimum weight triangulation of the set of points representing the vertices of the graph. We study the problem of characterizing those graphs that are minimum weight drawable. Our contribution is twofold: We show that there exist infinitely many triangulations that are not minimum weight drawable. Furthermore, we present non-trivial classes of triangulations that are minimum weight drawable, along with corresponding linear time algorithms that take as input any graph from one of these classes and produce as output such a drawing. One consequence of our work is the construction of triangulations that are minimum weight drawable but not Delaunay drawable - that is, not drawable as a Delaunay triangulatio	minimum weight;minimum-weight triangulation	William J. Lenhart;Giuseppe Liotta	2002	Theor. Comput. Sci.	10.1016/S0304-3975(00)00383-2	combinatorics;discrete mathematics;computational geometry;mathematics;geometry;graph drawing	ECom	31.771665768242087	22.228139249903723	13644
110ba9d540f3acfa934ab14a215dae03aebf7255	searching for an evader in an unknown graph by an optimal number of searchers		The graph search problem is the problem of searching a graph G for a mobile evader by mobile searchers. The edge search is an offline and centralized version, and es(G) denotes the number of searchers necessary and sufficient to edge search G. An online and distributed setting assumes a port numbering of G, a distinct homebase and a whiteboard in each node. Search algorithms typically respect the monotone and connected search strategy to protect the information on whiteboards; however, (varOmega ( frac{n}{log n} es (G))) searchers are necessary even for trees, where n is the order of G. We investigate the problem under a new online and distributed setting: We assume that searchers can exchange information wherever they meet, instead of assuming a port numbering, a homebase and whiteboards. Under this setting, we propose a search algorithm for es(G) searchers, which is optimal.		Takahiro Yakami;Yukiko Yamauchi;Shuji Kijima;Masafumi Yamashita	2016		10.1007/978-3-319-49259-9_31	combinatorics;theoretical computer science;machine learning	Vision	17.987896120178895	33.95591915288029	13646
af310ab260911e762e10d9ec3e6d85ec695026d6	a heuristic algorithm for the auto-carrier transportation problem	entrega;programacion entera;transportation problem;truck lines;new vehicles;case studies;vehiculo caminero;vehicule routier;gestion trafic;simulacion numerica;approche heuristique;auto carriers trucking;portador;traffic management;programmation en nombres entiers;transporte mercaderia;algorithme;loading and unloading;livraison;algorithm;transport marchandise;integer programming;heuristic methods;truck routes;simulation numerique;enfoque heuristico;gestion trafico;italy;algorithms;carrier;encaminamiento;porteur;delivery good;heuristic approach;forwarding;automobile dealers;freight transportation;road vehicle;tractor trailer combinations;automobile industry;nondeterministic polynomial;heuristic algorithm;acheminement;numerical simulation;algoritmo	The delivery of vehicles to dealers is one of the major tasks in the vehicle production industry. It has relied on transportation companies that use special tractor-trailer trucks called auto-carriers. One of the main problems these companies have to solve is the optimal loading and routing of the auto-carriers, referred to as the Auto-Carrier Transportation (ACT) problem. In this paper we provide an integer programming formulation of the ACT problem and show that the problem isNP-hard in the strong sense. A three-step heuristic procedure stronglybased on the IP formulation, which considers loading, vehicle selection, and routing aspects, is proposed. An application to a real case studyof a vehicle transportation company located in northern Italyis given, with an average deviation lower than 3% from an upper bound on the optimal solution value.	algorithm;heuristic (computer science)	Roberto Tadei;Guido Perboli;Federico Della Croce	2002	Transportation Science	10.1287/trsc.36.1.55.567	heuristic;transportation theory;mathematical optimization;active traffic management;simulation;np;integer programming;computer science;engineering;operations management;mathematics;transport engineering	Theory	17.739524835822134	5.626648707050266	13647
b0829c9f04200f569afc476955c3a1ddf85a8b75	maximum cut problem, max-cut		The MAXIMUM CUT problem (MAX -CUT) is one of the simplest graph partitioning problems to conceptualize, and yet it is one of the most diffic ult combinatorial optimization problems to solve. The objective of MAX -CUT is to partition the set of vertices of a graph into two subsets, such that the sum of the weights of the edges having one endpoint in each of the subsets is maximum. This problem is known to be NP-complete [18, 27]; however, it is interesting to note that the inverse problem, i.e., tha t of looking for the minimum cut in a graph is solvable in polynomial time using network flow te chniques [1].MAX -CUT is an important combinatorial problem and has applications in many fields including VLSI circuit design [9, 32] and statistical physics [5]. For othe r applications, see [16, 21]. For a detailed survey of MAX -CUT, the reader can refer to [33].	circuit design;combinatorial optimization;communication endpoint;decision problem;flow network;graph partition;mathematical optimization;max;maximum cut;minimum cut;np-completeness;polynomial;time complexity	Clayton W. Commander	2009		10.1007/978-0-387-74759-0_358	minimum cut	Theory	24.171818787736964	22.833348703994538	13653
e0110b32fe19854e4cadc90f70e116bca80e6bfd	the maximum size of dynamic data structures	file attente;chaine markov;cadena markov;priority queues;algorithmique;algorithm analysis;queueing theory;computational geometry;circuit vlsi;file histories;queue;maximum;symbol tables;analysis of algorithms;vlsi circuit;hashing;lists;algorithmics;algoritmica;data structures;dynamic data structure;estructura datos;dictionaries;hash coding;markov process;vlsi;structure donnee;circuito vlsi;sweepline;data structure;article;fila espera;occupancy distribution;lazy deletion;markov chain	"""This paper develops two probabilistic methods that allow the analysis of the maximum data structure size encountered during a sequence of insertions and deletions in data structures such as priority queues, dictionaries, linear lists, and symbol tables, and in sweepline structures for geometry and Very-LargeScale-Integration (VLSI) applications. The notion of the """"maximum"""" is basic to issues of resource preallocation. The methods here are applied to combinatorial models of file histories and probabilistic models, as well as to a non-Markovian process (algorithm) for processing sweepline information in an efficient way, called """"hashing with lazy deletion"""" (HwLD). Expressions are derived for the expected maximum data structure size that are asymptotically exact, that is, correct up to lower-order terms; in several cases of interest the expected value of the maximum size is asymptotically equal to the maximum expected size. This solves several open problems, including longstanding questions in queueing theory. Both of these approaches are robust and rely upon novel applications of techniques from the analysis of algorithms. At a high level, the first method isolates the primary contribution to the maximum and bounds the lesser effects. In the second technique the continuous-time probabilistic model is related to its discrete analog--the maximum slot occupancy in hashing. Key words, analysis of algorithms, hashing, lazy deletion, maximum, queueing theory, Markov process, occupancy distribution, data structures, file histories, priority queues, dictionaries, lists, symbol tables, sweepline, computational geometry, VLSI"""	ampersand;analysis of algorithms;computational geometry;cryptographic hash function;data structure;dictionary;dynamic data;dynamization;high-level programming language;lazy deletion;lazy evaluation;mike lesser;priority queue;queueing theory;statistical model;sweep line algorithm;symbol table;very-large-scale integration	Claire Mathieu;Jeffrey Scott Vitter	1991	SIAM J. Comput.	10.1137/0220050	markov chain;mathematical optimization;combinatorics;hash function;lazy deletion;data structure;computer science;analysis of algorithms;theoretical computer science;database;mathematics;very-large-scale integration;markov process;programming language;queueing theory;queue;priority queue;algorithm	Theory	10.67806192328327	30.00834468282588	13656
1f82957bcbe8664a71b4e24dc62649782ed51dcc	nonextensive analysis on the local structure entropy of complex networks		The local structure entropy is a new method which is proposed to identify the influential nodes in the complex networks. In this paper a new form of the local structure entropy of the complex networks is proposed based on the Tsallis entropy. The value of the entropic index q will influence the property of the local structure entropy. When the value of q is equal to 0, the nonextensive local structure entropy is degenerated to a new form of the degree centrality. When the value of q is equal to 1, the nonextensive local structure entropy is degenerated to the existing form of the local structure entropy. We also have find a nonextensive threshold value in the nonextensive local structure entropy. When the value of q is bigger than the nonextensive threshold value, change the value of q will has no influence on the property of the local structure entropy, and different complex networks have different ∗Corresponding author: Yong Deng, School of Computer and Information Science, Southwest University, Chongqing, 400715, China. Email address: ydeng@swu.edu.cn, prof.deng@hotmail.com (Yong Deng) Preprint submitted to Physica A February 3, 2015 nonextensive threshold value. The results in this paper show that the new nonextensive local structure entropy is a generalised of the local structure entropy. It is more reasonable and useful than the existing one.	centrality;complex network;email;entropy (information theory);information and computer science;information science;tsallis entropy	Qi Zhang;Meizhu Li;Yuxian Du;Yong Deng;Sankaran Mahadevan	2015	CoRR		joint entropy;combinatorics;binary entropy function;rényi entropy;transfer entropy;maximum entropy probability distribution;mathematics;joint quantum entropy;configuration entropy;entropy rate;conditional entropy;tsallis entropy;min entropy	ML	46.49429673987377	17.39366693717368	13682
51b79269bef437f29bab749c2835e543e8f98913	mapping dsp algorithms into fpga	digital signal processing;field programmable gate array;data flow graphs;field programmable gate array dsp algorithm fpga device synchronous data flow graph pipelined data path multidimensional index space event subspace multiplexer input digital signal processing;pipeline processing data flow graphs digital signal processing chips field programmable gate arrays;digital signal processing field programmable gate arrays signal processing algorithms processor scheduling digital signal processing chips flow graphs multidimensional systems clocks hardware multiplexing;null;synchronous data flow;pipelined data path;fpga device;multidimensional index space;indexation;dsp algorithm;digital signal processing chips;field programmable gate arrays;multiplexer input;synchronous data flow graph;pipeline processing;event subspace	A method of mapping DSP algorithms into FPGA devices is considered. Algorithms are represented by synchronous data flow graphs, and are mapped into pipelined data path. The method consists of placing the algorithm graph in the multidimensional index space and mapping it into structure and event subspaces. The special limitations, which are injected to the mapping process, minimize both clock time and hardware volume including multiplexer inputs.	algorithm;digital signal processor;field-programmable gate array	Oleg Maslennikov;Anatoli Sergyienko	2006		10.1109/PARELEC.2006.51	parallel computing;computer science;theoretical computer science;field-programmable gate array	EDA	5.268235888998942	46.35524295589136	13683
fbc253a456e4f1d57e669d747b57f39046994f87	general algorithms for the address calculation of lexicographically ordered tuples	generic algorithm;lexicographic order	Recently, Nishihara and Ikeda [2] gave an algori thm for calculating the addresses of tuples (U~, U 2 . . . . . UN) where the Ui's are drawn from the set (1, 2 . . . . . M} and are assumed to be in ascending order. In this paper, we give general algorithms for calculating the addresses of tuples without assuming any specific order among the entities of the tuple. The tuples are assumed to be ordered in lexicographic order. Given tuples U = (U 1, U 2 . . . . . U N) and V = (V1, V 2 . . . . . V N ), we say that U > V in the lexicographic order if and only if there exists an integer i such that U, = V, for 1 ~< t ~<i and Ui+~> Vi+l. The names in a telephone directory, for iristance, can be thought of as ordered tuples of letters padded with blanks. The letters in a name are in no specific order while the names themselves are arranged lexicographically. Here, we also present a generalization where the U~'s may be drawn from different sets. -We give a very fast algori thm based on binary digits to compute the addresses when M is a power of 2. Finally, some examples are presented to illustrate the different algorithms proposed. Assume that the domain set is S = {0, 1, 2 . . . . . M l } . We denote the tuples U as U = ( U 1 , U 2 . . . . . UN) where N ~< M and U, ~ S for all i. These tuples are assumed to be addressed starting f rom zero. The symbols E and 1--I are used for summat ion and product respectively. The product is one and the sum is zero when the indexing set is empty.	algorithm;directory (computing);entity;ikeda map;lexicographical order;ordered pair;power of two;sorting	Suresh C. Kothari;K. V. S. Ramarao	1985	Inf. Process. Lett.	10.1016/0020-0190(85)90014-6	combinatorics;discrete mathematics;genetic algorithm;computer science;lexicographical order;mathematics;algorithm	DB	37.225271046927595	34.57646420172264	13698
a11bb14fa09b4cf94d58d214a5c151b72fffccda	vertex disjoint equivalent subgraphs of order 3	extremal graph theory	Let k be a fixed integer at least 3. It is proved that every graph of order (2k − 1 − 1/k)n + O(1) contains n vertex disjoint induced subgraphs of order k such that these subgraphs are equivalent to each other and they are equivalent to one of four graphs: a clique, an independent set, a star, or the complement of a star. In particular, by substituting 3 for k, it is proved that every graph of order 14n/3 + O(1) contains n vertex disjoint induced subgraphs of order 3 such that they are equivalent to each other. © 2007 Wiley Periodicals, Inc. J Graph Theory 56: 159–166, 2007	a* search algorithm;graph theory;independent set (graph theory);induced subgraph;john d. wiley	Tomoki Nakamigawa	2007	Journal of Graph Theory	10.1002/jgt.20263	loop;perfect graph theorem;split graph;combinatorics;clique graph;extremal graph theory;discrete mathematics;cograph;topology;null graph;degree;regular graph;simplex graph;comparability graph;cycle graph;vertex;graph factorization;mathematics;voltage graph;windmill graph;complement graph;line graph;string graph;circulant graph;planar graph	Theory	28.90411972842022	29.56169399590268	13699
171e686072dc534007e59dd7f0eb0c1f60d2a0a0	study of methods for constructing families of odd-periodic perfect complementary sequence pairs	odd-periodic complementary sequence;perfect signal theory;sequence pairs	Some characteristics of the families of oddperiodic perfect complementary sequence pairs (OPCSPF) are discussed. The methods for constructing an OPCSPF are given and proved. The families of periodic perfect complementary sequence pairs can be constructed correspondingly by using the equivalent relationships, which further expanded the existence space of the complementary sequence.	complementary sequences	Huilong Jin;Jiaxing Chen	2013	JDIM		periodic graph (geometry);discrete mathematics;data mining;complementary sequences;computer science	Vision	39.49101742633546	33.75899746187919	13700
05d45c8fa97056232c92f18875fe2cff3b3561e7	novel probabilistic combinational equivalence checking	detection erreur;evaluation performance;deteccion error;diagrama binaria decision;combination equivalence checking;diagramme binaire decision;test pattern generation;probability;performance evaluation;circuit faults;boolean functions;aliasing;estudio comparativo;evaluacion prestacion;automatic test pattern generation;logic;modelo hibrido;satisfiabilite;probabilistic equivalence checking peach;probabilistic approach;exact approach;probabilistic equivalence checking peach aliasing free assignment aliasing rate combination equivalence checking cec error detection probabilistic approach;satisfiability;modele hybride;generacion automatica prueba;hybrid model;essai circuit integre;combination equivalence checking cec;algorithme;etude comparative;aliasing rate;algorithm;signal probability;error detection probabilistic combinational equivalence checking exact approach signal probability probability calculation process approximate approach benchmark circuits virtually zero aliasing rate;probability calculation process;hybrid approach;test pattern generators;approximate approach;data structures;benchmark circuits;enfoque probabilista;approche probabiliste;logic testing;comparative study;virtually zero aliasing rate;integrated circuit testing;generation vecteur test;generation automatique test;data structures boolean functions probability automatic test pattern generation circuit faults logic test pattern generators councils computer science fault diagnosis;automatic test generation;councils;aliasing free assignment;computer science;error detection;probability error detection logic testing;probabilistic combinational equivalence checking;automatic test pattern generator;equivalence checking;generacion vector prueba;probabilistic equivalence checking;combinational equivalence checking;fault diagnosis;satisfactibilidad;repliegue espectro;algoritmo;binary decision diagram;repliement spectre	Exact approaches to combinational equivalence checking, such as automatic test pattern generation-based, binary decision diagrams (BDD)-based, satisfiability-based, and hybrid approaches, have been proposed over the last two decades. Recently, we proposed another exact approach using signal probability. This probability-based approach assigns probability values to the primary inputs and compares the corresponding output probability of two networks via a probability calculation process to assert if they are equivalent. The shortcoming of all these exact approaches is that if two networks are too complex to be handled, their equivalence cannot be determined, even with tolerance. An approximate approach, named the probabilistic approach, is a suitable way to give such an answer for those large circuits. However, despite generally being more efficient than exact approaches, the probabilistic approach faces a major concern of a non zero aliasing rate, which is the possibility that two different networks have the same output probability/signatures. Thus, minimizing aliasing rate is substantial in this area. In this paper, we propose a novel probabilistic approach based on the exact probability-based approach. Our approach exploits proposed probabilistic equivalence checking architecture to efficiently calculate the signature of network with virtually zero aliasing rate. We conduct experiments on a set of benchmark circuits, including large and complex circuits, with our probabilistic approach. Experimental results show that the aliasing rate is virtually-zero, e.g., 10-6013. Also, to demonstrate the effectiveness of our approach on error detection, we randomly inject errors into networks for comparison. As a result, our approach more efficiently detects the error than a commercial tool, Cadence LEC, does. Although our approach is not exact, it is practically useful. Thus, it can effectively complement exact methods to improve the efficiency and effectiveness of combination equivalence checking algorithms.	aliasing;antivirus software;approximation algorithm;benchmark (computing);binary decision diagram;combinational logic;error detection and correction;experiment;formal equivalence checking;preprocessor;probabilistic automaton;randomness;test card;turing completeness	Shih-Chieh Wu;Chun-Yao Wang;Yung-Chih Chen	2008	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2008.917397	aliasing;discrete mathematics;data structure;computer science;theoretical computer science;automatic test pattern generation;probability;mathematics;binary decision diagram;logic;algorithm;statistics;satisfiability	EDA	21.271150813776835	48.818014801660205	13709
2000ae393e82b4c085cf90105b32cee7602e792b	three-dimensional graph drawing	graph drawing;algorithms;three-dimensional.;three dimensional;binary tree	A three-dimensional straight-line grid drawing of a graph, henceforth called a 3D drawing, represents the vertices by distinct grid-points in Z and represents each edge by the line segment between its end vertices, such that no two edges cross. In contrast to the case in the plane, it is folklore that every graph has a 3D drawing. For example, the “moment curve” algorithm places the i th vertex at .i; i ; i /. It is easily seen that no four vertices are coplanar, and thus no two edges cross. Since every graph has a 3D drawing, we are interested in optimizing certain measures of their aesthetic quality. If a 3D drawing is contained in an axis-aligned box with side lengths X 1, Y 1, and Z 1, then we speak of an X Y Z drawing with volume X Y Z. This entry considers the problem of producing a 3D drawing of a given graph with small volume.	algorithm;apache axis;graph drawing;vertex (geometry)	David R. Wood	2016		10.1007/978-1-4939-2864-4_656	three-dimensional space;combinatorics;discrete mathematics;systems modeling;tracing;vector calculus;binary tree;image processing;computational geometry;computer science;mathematics;graph;automated theorem proving;graph;graph drawing;computational complexity theory;user interface;algorithm	ML	31.785288688373722	22.51998666569703	13720
5b4f695e42e5ab0eb53653fdff4cabfb6dd0d6b9	partially balanced incomplete block designs from weakly divisible nearrings	experimental design;block design;schema association;partially balanced design;plan experiencia;esquema asociacion;plan bloc;nearring;plan bloque;plan partiellement equilibre;plan parcialmente equilibrado;plan experience;balanced incomplete block design;plan bloc incomplet;conexion;raccordement;near ring;association scheme;incomplete block design;anneau proche;connection;plan bloque incompleto	In [[6] Riv. Mat. Univ. Parma 11 (2) (1970) 79-96] Ferrero demonstrates a connection between a restricted class of planar nearrings and balanced incomplete block designs. In this paper, bearing in mind the links between planar nearrings and weakly divisible nearrings (wd-nearrings), first we show the construction of a family of partially balanced incomplete block designs from a special class of wd-nearrings; consequently, we are able to give some formulas for calculating the design parameters.		Anna Benini;Fiorenza Morini	2005	Discrete Mathematics	10.1016/j.disc.2005.03.026	block design;combinatorics;mathematics;geometry;algorithm	Crypto	37.78018677882296	34.88405654172074	13728
42c291e6cb0fe7eb0c8568599f93c29d959c8fe3	pseudoexhaustive tpg with a provably low number of lfsr seeds	test pattern generation;linear feedback shift registers;linear feedback shift register;feedback circuits;satisfiability;strontium;polynomials;built in self test;test pattern generators;logic testing built in self test shift registers;shift registers;logic testing;irreducible polynomial;lfsrs;circuit testing;test pattern generator;characteristic polynomial;pseudoexhaustive approach;benchmark testing;polynomials circuit testing strontium hardware linear feedback shift registers built in self test shift registers benchmark testing feedback circuits test pattern generators;hardware;pseudoexhaustive approach test pattern generation linear feedback shift registers lfsrs	Linear Feedback Shift Registers (LFSRs) are the most efficient and popular pseudo-exhaustive test pattern generation (TPG) mechanism. The goal is to minimize the required test length with low hardware overhead while obtaining pseudo-exhaustive TPG. Primitive characteristic polynomials are widely used because they require only one seed but the candidate polynomials are few and our experiments show that often the pseudoexhaustive test length is prohibitive. In this paper, we present a novel pseudoexhaustive approach with provably low number of seeds where the characteristic polynomial is the product of a primitive and an irreducible polynomial satisfying certain conditions. Our experimental results on the ISCAS'85 benchmarks show that using the proposed method requires very low hardware overhead. The list of characteristic polynomials for pseudoexhaustive TPG is greatly enhanced and our experiments show that pseudoexhaustive TPG is more feasible.	linear-feedback shift register	Dimitrios Kagaris;Spyros Tragoudas	2000		10.1109/ICCD.2000.878267	irreducible polynomial;benchmark;electronic engineering;strontium;computer science;shift register;linear feedback shift register;characteristic polynomial;algorithm;polynomial;satisfiability	Crypto	20.09775683252157	50.44369042174914	13730
54647ffeb5897b362d7a67c59e7a5fa94d6284e8	lower bounds on the complexity of multidimensional searching	databases;silicon;q measurement;generators;complexity theory;multidimensional systems data structures computer science databases graphics computational modeling;partial sums;density measurement;biological system modeling;upper bound;computational modeling;data structures;transforms;position measurement;mathematical model;terminology;approximation methods;search problems;computer science;tin;graphics;multidimensional systems;lower bound	We establish new lower bounds on the complexity of several searching problems. We show that the time for solving the partial sum problem on n points in d dimensions is at least proportional to (log n/log 2m/n)d-1 in both the worst and average cases; m denotes the amount of storage used. This bound is provably tight for m = Ω(nlogcn) and any c ≫ d- 1. We also prove a lower bound of Ω(n(log n/log log n)d) on the time required for executing n inserts and queries. Other results include a lower bound on the complexity of orthogonal range searching in d dimensions (in report-mode). We show that on a pointer machine a query time of O(s+polylog(n)) time can only be achieved at the expense of Ω(n(log n/log log n)d-1) space, which is optimal; n and s denote respectively the input and output sizes.	input/output;pointer (computer programming);pointer machine;range searching;range tree	Bernard Chazelle	1986	27th Annual Symposium on Foundations of Computer Science (sfcs 1986)	10.1109/SFCS.1986.29	combinatorics;discrete mathematics;data structure;computer science;theoretical computer science;mathematics;upper and lower bounds;algorithm;statistics;algebra	Theory	12.433933762311971	24.979633610358285	13738
93c8b92259f7df6c2cbb03dcb7d8a82c890a8993	multiple hamilton cycles in bipartite cubic graphs: an algebraic method	cubic;51e99;94b05;finite field;hamilton cycle;graph;determinant;05c45;gf 2;bipartite;14g15	Many important graphs are bipartite and cubic (i.e. bipartite and trivalent, or “bicubic”). We explain concisely how the Hamilton cycles of this type of graph are characterized by a single determinantal condition over   GF(2)      GF   (  2  )       . Thus algebra may be used to derive results such as those of Bosak, Kotzig, and Tutte that were originally proved differently.	cubic function;linear algebra	Adel Alahmadi;David G. Glynn	2017	Finite Fields and Their Applications	10.1016/j.ffa.2016.11.006	hamiltonian path;complete bipartite graph;combinatorics;discrete mathematics;determinant;bipartite graph;foster graph;mathematics;graph;gf(2);finite field;biregular graph;algebra	Theory	32.2231089520235	32.53468386911085	13740
edef35eea594a76f87136c029ab7a54b066ac39e	paint batching problem on m-to-1 conveyor systems	m to 1 conveyor system;setup minimization;dynamic programming;paint batching problem;re sequencing;genetic algorithm	An M-to-1 conveyor system consists of multiple upstream conveyors and a single downstream conveyor. In this paper, we investigate the paint batching problem on M-to-1 conveyor systems with the objective of minimizing setup costs. Our research is motivated by a vehicle re-sequencing problem at a major Korean automotive manufacturer. Setup costs are incurred when two consecutive jobs in the downstream conveyor do not share the same feature. Re-sequencing flexibility is limited by the precedence relationship among jobs in the upstream conveyors. First, we develop a mixed integer linear programming model and propose an efficient dynamic programming (DP) algorithm for a 2-to-1 conveyor system. However, because the suggested DP cannot guarantee optimality in general settings, we propose two efficient genetic algorithms (GAs) to find near optimal solutions. Specifically, we design the reordering operation for making offspring to satisfy the precedence condition. We show that the proposed GAs perform prominently with respect to optimality gap and computation time; thus, they are amenable to environments where solutions must be obtained within tight time constraints. & 2016 Elsevier Ltd. All rights reserved.	computation;davis–putnam algorithm;downstream (software development);dynamic programming;experiment;genetic algorithm;integer programming;job stream;linear programming;numerical linear algebra;programming model;software release life cycle;time complexity;upstream (software development)	Sung-Seok Ko;Yong-Hee Han;Jin Young Choi	2016	Computers & OR	10.1016/j.cor.2016.04.019	mathematical optimization;simulation;genetic algorithm;computer science;dynamic programming	AI	14.345393856354777	5.193611960687225	13742
a4760634b1347324fb5767bcbcf2dba7b2501879	minimizing the average number of inspections for detecting rare items in finite populations	dna;national security;analytical models;probability sampling inspections rare item detection finite populations;probability;inspection analytical models presses indexes dna manganese stochastic processes;sampling methods government inspection national security probability;profiling;government;presses;inspection;universiteitsbibliotheek;manganese;search;indexes;stochastic processes;rare items;sampling methods;profiling probability sampling search rare items;probability sampling	Frequently one has to search within a finite population for a single particular individual or item with a rare characteristic. Whether an item possesses the characteristic can only be determined by inspection. The availability of additional information about the items in the population opens the way to more effective inspection than just random or complete inspection of the population. We will assume that the available information allows for the assignment to all items within the population of a prior probability on whether or not it possesses the rare characteristic. This is consistent with the practice of using profiling to select high risk items for inspection. The objective is to find the specific item with a minimal number of inspections. We will determine the optimal inspection strategies for several models according to the average number of inspections needed to find the specific item. Furthermore, an ordering of these models by their average number of inspections is derived. Finally, the use, some discussion, extensions, and examples of the results and conclusions are presented.	population;profiling (computer programming);software inspection;tag (game)	Andre J. Hoogstrate;Chris A. J. Klaassen	2011	2011 European Intelligence and Security Informatics Conference	10.1109/EISIC.2011.22	stochastic process;inspection;computer science;national security;manganese;probability;data mining;profiling;law;dna;government;statistics	Vision	40.66739716163066	10.195962173949425	13744
61c5bc6c055639c1d27d0c12b07ab46777fa5d71	a performability solution method for degradable nonrepairable systems	reward models degradable performance fault tolerance performability evaluation performance evaluation reliability evaluation;computer systems design;performance evaluation;reliability evaluation;probability distribution functions;degradable performance;stochastic processes;circuit reliability;mathematical models;systems analysis;reward models;numerical integration;fault tolerance;algorithms;performance prediction;reliability analysis;system effectiveness;performability evaluation	"""An algorithm is developed for solving a broad class of performability models wherein system performance is identified with """"reward."""" More precisely, for a system S and a utilization period T, the performance variable of the model is the reward derived from using S during T. The state behavior of S is represented by a finite-state stochastic process (the base model); reward is determined by reward rates associated with the states of the base model. Restrictions on the base model assume that the system in question is not repaired during utilization. It is also assumed that the corresponding reward model is a nonrecoverable process in the sense that a future state (reward rate) of the model cannot be greater than the present state. For this model class, we obtain a general method for determining the probability distribution function of the performance (reward) variable and, hence the performability of the corresponding system. Moreover, this is done for bounded utilization periods. The result is an integral expression which can be solved either analytically or numerically."""	algorithm;numerical analysis;stochastic process	David G. Furchtgott;John F. Meyer	1984	IEEE Transactions on Computers	10.1109/TC.1984.1676479	stochastic process;systems analysis;fault tolerance;real-time computing;simulation;reward-based selection;numerical integration;mathematical model;statistics	Metrics	5.975004538173684	12.481726417915766	13749
0debe82c97ca088b754cda7b64de96d3de6e3019	timing optimization of interconnect by simultaneous net-ordering, wire sizing and spacing	cross capacitances;integrated circuit layout;sorting;delay effects;nanotechnology;wire;90 nm timing optimization wire sizing wire spacing parallel wires elmore delay model cross capacitances optimal wire ordering balanced monotonic interleaved heuristic technique;wire sizing;elmore delay model;heuristic technique;integrated circuit interconnections;noise reduction;timing optimization;90 nm;optimal wire ordering;timing delays integrated circuit interconnections integrated circuit layout nanotechnology;driver circuits;wire spacing;capacitance;space technology;balanced monotonic interleaved;timing wire integrated circuit interconnections delay driver circuits capacitance space technology noise reduction throughput sorting;parallel wires;delays;throughput;timing	This paper addresses the problem of ordering and sizing parallel wires in a single metal layer within an interconnect channel of a given width, such that cross-capacitances are optimally shared for circuit timing optimization. Using an Elmore delay model including cross capacitances for a bundle of wires, we show that an optimal wire ordering is uniquely determined, such that best timing can be obtained by proper allocation of wire widths and inter-wire spaces. The optimal order, called BMI (balanced monotonic interleaved) depends only on the size of drivers for a wide range of cases. Heuristics are presented for simultaneous ordering, sizing and spacing of wires. Examples for 90-nanometer technology are analyzed and discussed	brain–computer interface;device driver;elmore delay;experiment;global optimization;heuristic (computer science);mathematical optimization;numerical method;wiring	Konstantin Moiseev;Shmuel Wimer;Avinoam Kolodny	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1692589	computer vision;throughput;electronic engineering;computer science;sorting;engineering;electrical engineering;noise reduction;capacitance;space technology;integrated circuit layout;engineering drawing	EDA	14.568473130149664	52.642233018481534	13752
001845a0e2d578c1cd0bb3b321b743da1c1240b9	fixed-width multiplier for dsp application	digital signal processing;multiplying circuits;hardware complexity;hardware overhead fixed width multiplier dsp application compensation method digital signal processing array multiplier booth multiplier hardware complexity;multiplying circuits digital signal processing chips computational complexity;array multiplier;error analysis;booth multiplier;statistical analysis;compensation method;computational complexity;digital signal processing hardware error analysis digital signal processing chips statistical analysis circuits log periodic antennas proposals;dsp application;hardware overhead;digital signal processing chips;circuits;fixed width multiplier;proposals;log periodic antennas;hardware	A new compensation method that reduce the error of fixed-width multiplier for digital signal processing (DSP) application is proposed. The designs of using this inputnumber based compensation method are carried out on array multiplier and Booth multiplier. The hardware complexity is reduced to about 50% of the original multiplier. Design results show that the new architectures have lower hardware overhead, lower error and fast operation speed as compared with other proposed architectures.	booth's multiplication algorithm;digital signal processing;overhead (computing)	Shyh-Jye Jou;Hui-Hsuan Wang	2000		10.1109/ICCD.2000.878302	electronic circuit;electronic engineering;parallel computing;computer science;booth's multiplication algorithm;electrical engineering;theoretical computer science;digital signal processing;computational complexity theory;analog multiplier	EDA	12.857198888042928	44.55043551250356	13753
433d81828be7b29970a4aedce804e808050ea815	a theorem about a contractible and light edge	graph theory;splitting;teoria grafo;05c10;mathematiques discretes;matematicas discretas;discrete mathematics;05c40;theorie graphe;connected graph;light graph theory;politope;extremite;end;contractible edge;graphe planaire;contractible edges;edge graph;extremidad;arete graphe;grafo planario;planar graphs;bord contractible;graphe connexe;planar graph;arista grafico;polytope;grafo conexo	In 1955 Kotzig proved that every planar 3-connected graph contains an edge such that sum of degrees of its endvertices is at most 13. Moreover, if the graph does not contain 3-vertices, then this sum is at most 11. Such an edge is called light. The well-known result of Steinitz that the 3-connected planar graphs are precisely the skeletons of 3-polytopes, gives an additional trump to Kotzig’s theorem. On the other hand, in 1961, Tutte proved that every 3-connected graph, distinct from K4, contains a contractible edge. In this paper, we strengthen Kotzig’s theorem by showing that every 3-connected planar graph distinct from K4 contains an edge which is both light and contractible. A consequence is that every 3-polytope can be constructed from the Tetrahedron by a sequence of splittings of vertices of degree at most 11. ∗Supported in part by project LN00A056 of the Czech Ministry of Education. †Supported in part by Ministry of Science and Technology of Slovenia, Research Project Z13129.	planar graph;polyhedron;whole earth 'lectronic link	Zdenek Dvorak;Riste Skrekovski	2006	SIAM J. Discrete Math.	10.1137/05062189X	combinatorics;discrete mathematics;polyhedral graph;topology;graph theory;mathematics;steinitz's theorem;planar graph	Theory	28.568464698891322	30.06165719860131	13765
45906cfb51b5d2c045c7c4f6f908dd292de53a6f	randomized weighted caching with two page weights	caching algorithm;competitive algorithms;randomised algorithms;cache memory;algorithme deterministe;algorithme randomise;antememoria;algorithme competitif;aleatorizacion;deterministic algorithms;antememoire;randomized algorithm;randomisation;competitive analysis;randomization;algoritmo optimo;algorithme optimal;optimal algorithm;competitive ratio	We consider a special case of the weighted caching problem where the weight of every page is either 1 or some fixed number M > 1 . We present a randomized algorithm which achieves a competitive ratio which is O( log k) where k is the number of pages which can fit in the cache.	cache (computing);competitive analysis (online algorithm);randomized algorithm	Sandy Irani	2001	Algorithmica	10.1007/s00453-001-0095-6	competitive analysis;mathematical optimization;parallel computing;computer science;theoretical computer science;algorithm	Theory	16.669439530810035	13.06968428557953	13766
21b709804de6e93488bc5d39c7d03bde264cdaa3	sensor placement for triangulation-based localization	robot sensing systems;unfolding;integer linear programming;reseau capteur;constant factor performance guarantee;palier;deteccion blanco;red local;approximate algorithm;programacion entera;uncertainty modeling;protocole transmission;sensors;deploiement;incertidumbre;sensors approximation theory computational complexity integer programming linear programming robots;approximation algorithms;incendie;estimation etat;uncertainty;triangulation based state estimation;position transducteur;approximation algorithm;localization;despliegue;problema np duro;metric;mobile robots;localizacion;robotics;indexing terms;state estimation;programmation en nombres entiers;sensor network;detection cible;identificacion sistema;approximation theory;captador medida;dominio trabajo;bearing mechanics;localization uncertainty;local network;np hard problem;protocolo transmision;systeme incertain;measurement sensor;red sensores;capteur mesure;localisation;programacion lineal;triangulacion;system identification;integer programming;probleme np difficile;computational complexity;sensor placement;domaine travail;robots;constant factor performance guarantee sensor placement triangulation based localization localization uncertainty triangulation based state estimation np hard problem integer linear programming bearing only localization approximation algorithm;algoritmo aproximacion;sensor array;linear programming;incendio;robotica;programmation lineaire;descansillo;robot sensing systems state estimation robustness fires robot vision systems cameras robotics and automation integer linear programming approximation algorithms mobile robots;metrico;robustness;workspace;bearing only localization;triangulation;robotique;incertitude;sensor network deployment;algorithme approximation;sistema incierto;triangulation based localization;reseau local;fires;posicion transductor;target detection;estimacion estado;sensor network deployment approximation algorithms localization;uncertain system;robot vision systems	Robots operating in a workspace can localize themselves by querying nodes of a sensor-network deployed in the same workspace. This paper addresses the problem of computing the minimum number and placement of sensors so that the localization uncertainty at every point in the workspace is less than a given threshold. We focus on triangulation-based state estimation, where measurements from two sensors must be combined for an estimate. This problem is NP-hard in its most general from. For the general version, we present a solution framework based on integer linear programming and demonstrate its application in a fire-tower placement task. Next, we study the special case of bearing-only localization and present an approximation algorithm with a constant factor performance guarantee.	approximation algorithm;integer programming;linear programming;np-hardness;sensor;workspace	Onur Tekdas;Volkan Isler	2010	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2009.2037135	local area network;robot;mobile robot;mathematical optimization;wireless sensor network;integer programming;index term;internationalization and localization;uncertainty;metric;system identification;triangulation;computer science;sensor;artificial intelligence;np-hard;mathematics;computational complexity theory;sensor array;approximation algorithm;algorithm;workspace;robustness;approximation theory	Robotics	33.864544407355595	10.178612234041497	13782
db16a71cebe0b359b4ba17be9f7959041f283667	test solution selection using multiple-objective decision models and analyses	decision models;semiconductor technology;electronic engineering computing automatic test equipment automatic testing semiconductor technology decision making;automatic testing;automatic test equipment;multiple objectives;semiconductor technology test solution selection multiple objective decision model automatic test equipment;electronic engineering computing;system testing environmental economics benchmark testing semiconductor device testing decision making costs personnel optimization methods availability marketing and sales;figure of merit	Designing new automatic test equipment (ATE) frameworks in alignment with the advances in semiconductor technology remains one of the most difficult challenges in the test community. This article presents an elegant methodology for analyzing different models for ATE operation. The methodology ultimately provides a single figure of merit for evaluation and comparison.	built-in test equipment;semiconductor	Daniel T. Hamling	2005	IEEE Design & Test of Computers	10.1109/MDT.2005.47	reliability engineering;embedded system;automatic test equipment;decision model;figure of merit;electronic engineering;computer science;systems engineering;engineering;management science;test management approach	EDA	23.890119645176327	55.971840088823065	13784
0a3467f6de40ab99d10501b27df473aaf788a4cf	improved constructions for quantum maximum distance separable codes	quantum code;cyclic code;mds code	In this work, we further improve the distance of the quantum maximum distance separable (MDS) codes of length \(n=\frac{q^2+1}{10}\). This yields new families of quantum MDS codes. We also construct a family of new quantum MDS codes with parameters \([[\frac{q^2-1}{3}, \frac{q^2-1}{3}-2d+2, d]]_{q}\), where \(q=2^m\), \(2\le d\le \frac{q-1}{3}\) if \(3\mid (q+2)\), and \(2\le d\le \frac{2q-1}{3}\) if \(3\mid (q+1)\). Compared with the known quantum MDS codes, these quantum MDS codes have much larger minimum distance.	code;mds matrix;singleton bound	Jianfa Qian;Lina Zhang	2017	Quantum Information Processing	10.1007/s11128-016-1490-x	combinatorics;discrete mathematics;pure mathematics;mathematics	Theory	40.464945202092956	54.35756011868801	13787
267a16c2f7ccd99c71a06c1908602c6dbe953b74	limitations of efficient reducibility to the kolmogorov random strings	polynominal time reducibility;universal machine;turing reduction;kolmogorov random strings	We show the following results for polynomial-time reducibility to RC, the set of Kolmogorov random strings. 1. If P 6= NP, then SAT does not dtt-reduce to RC. 2. If PH does not collapse, then SAT does not n--reduce to RC for any α < 1. 3. If PH does not collapse, then SAT does not n-T-reduce to RC for any α < 2 . 4. There is a problem in E that does not dtt-reduce to RC. 5. There is a problem in E that does not n--reduce to RC, for any α < 1. 6. There is a problem in E that does not n-T-reduce to RC, for any α < 2 . These results hold for both the plain and prefix-free variants of Kolmogorov complexity and are also independent of the choice of the universal machine.	kolmogorov complexity;polynomial;polynomial-time reduction;time complexity;turing machine	John M. Hitchcock	2012	Computability	10.3233/COM-2012-006	kolmogorov structure function;combinatorics;discrete mathematics;mathematics	Theory	9.166020053578226	21.278598398275427	13795
db869d8e264e7c74c96beac692b1aa5201db3e7c	six hypotheses in search of a theorem	uniform resource locators computer science polynomials usa councils analog computers helium;computational complexity;k approximable set p np truth table reducible p selective set	z Sir, we are truly six special and interesting characters. Believe us. However we have gone lost. Abstract We consider the following six hypotheses: P = NP. SAT is truth-table reducible to a P-selective set. SAT is truth-table reducible to a k-approximable set for some k.	ibm ssec;p versus np problem	Harry Buhrman;Lance Fortnow;Leen Torenvliet	1997		10.1109/CCC.1997.612295	combinatorics;discrete mathematics;computer science;mathematics;computational complexity theory;algorithm	Theory	8.185970832122365	21.835544777992972	13816
8cac07536631f2df7154e493f1f67a7c062e1380	determinantal complexity of iterated matrix multiplication polynomial			iterated function;matrix multiplication;polynomial	Suryajith Chillara;Partha Mukhopadhyay	2013	CoRR		polynomial matrix;combinatorics;discrete mathematics;determinantal point process;mathematics;matrix polynomial;algebra	Theory	46.277546872463624	34.92760006877055	13837
ea3d2b5210dd22640aff8f7275dfa9c2da0568e6	sneak-path testing of memristor-based memories	emerging memory technologies;memory testing;memristors;fault modeling;testing;memristors testing circuit faults resistance current measurement nanoscale devices integrated circuit modeling;memory subsystem sneak path testing memristor based memories high defect densities nondeterministic nature nanoscale fabrication;testing memristors;emerging memory technologies memory testing metal oxide memristors fault modeling;metal oxide memristors	Memristors are an attractive option for use in future memory architectures due to their non-volatility, low power operation and compactness. Notwithstanding these advantages, memristors and memristor-based memories are prone to high defect densities due to the non-deterministic nature of nanoscale fabrication. As a first step, we will examine the defect mechanisms in memristors and develop efficient fault models. Next, the memory subsystem has to be tested. The typical approach to testing a memory subsystem entails testing one memory element at a time. This is time consuming and does not scale for dense, memristor-based memories. We propose an efficient testing technique to test memristor-based memories. The proposed scheme uses sneak-paths inherent in crossbar memories to test multiple memristors at the same time and thereby reduces the test time by ~32%.	crossbar switch;fault model;memristor;model-based testing;non-volatile memory;scalability;software bug;volatility	Sachhidh Kannan;Jeyavijayan Rajendran;Ramesh Karri;Ozgur Sinanoglu	2013	2013 26th International Conference on VLSI Design and 2013 12th International Conference on Embedded Systems	10.1109/VLSID.2013.219	electronic engineering;parallel computing;memristor;resistive random-access memory;computer science;engineering;electrical engineering;memistor;software testing	EDA	20.96461085504376	59.18319106219198	13844
48c3d79490dd378d29ad1b2de66237bd59f437a6	lexicographic listing and ranking of t-ary trees	arbre graphe;generation;graph theory;teoria grafo;tree graph;generacion;theorie graphe;algorithme;algorithm;algorritmo;informatique theorique;lexicographic order;orden lexicografico;arbol grafo;ordre lexicographique;computer theory;informatica teorica	This paper presents three simple and efficient algorithms for generating, ranking and unranking t-ary trees in a lexicographic order. The simplest idea of encoding a t-ary tree with n nodes as a bit-string of length t*n is exploited to its full advantages. It is proved that the lexicographic order in the set of t-ary trees with n nodes is preserved in the set of bit-strings of length t*n, using the above encoding scheme. Thus by generating all bit-strings in the lexicographic order, a simple decoding algorithm can convert them to t-ary trees in the same order. Finally, the theoretical basis for ranking a lexicographic listing of bit-strings is discussed, and the ranking and the unranking algorithms are derived.	algorithm;lexicographical order;lexicography;line code	M. C. Er	1987	Comput. J.	10.1093/comjnl/30.6.569	combinatorics;generation;graph theory;lexicographical order;mathematics;tree;algorithm	Web+IR	15.873490825985485	28.406092555128254	13862
ccc051e11d68fb432b9ad556da5764c33976a89a	an improved dna computing method for elevator scheduling problem	connecting strand;elevator scheduling problem;dna computing;encoding;shortest path problem	"""In the paper, an algorithm based on DNA computing which can solve the elevator scheduling problem is improved. Considering the inefficiency of the existing algorithm caused by the large scale of the initial solution space, the author introduces a new conception ---""""connecting strand"""" to help produce the initial solution space in the new algorithm. """"Connecting strand"""" can connect those rational DNA strands encoding different elevators' running routes into one and the strand obtained just stands for the """"sum-route"""" of the elevator system. With the help of """"connecting strand"""", the size of initial solution space is largely reduced and the performance of the algorithm is thus improved. In the end, the author proves the effectiveness of the algorithm by a simulation."""	dna computing;scheduling (computing)	Hong-Chao Zhao;Xi-Yu Liu	2012		10.1007/978-3-642-37015-1_76	simulation;computer science;distributed computing;shortest path problem;dna computing;algorithm;encoding	Theory	23.28739510663723	5.869909119640251	13865
34dfd5254967147666b5c85c373b2ea48a211756	vertex heaviest paths and cycles in quasi-transitive digraphs	graph theory;hamiltonian cycle;longest path;polynomial algorithm;polynomial time;hamiltonian path	A digraph D is called a quasi-transitive digraph (QTD) if for any triple x, y, z of distinct vertices of D such that (x, y) and (y, z) are arcs of D there is at least one arc from x to z or from z to x. Solving a conjecture by J. Bang-Jensen and J. Huang (J. Graph Theory, to appear), G. Gutin (Australas. J. Combin., to appear) described polynomial algorithms for finding a Hamiltonian cycle and a Hamiltonian path (if it exists) in a QTD. The approach taken in that paper cannot be used to find a longest path or cycle in polynomial time. We present a principally new approach that leads to polynomial algorithms for finding vertex heaviest paths and cycles in QTD’s with non-negative weights on the vertices. This, in particular, provides an answer to a question by N. Alon on longest paths and cycles in QTD’s.	arcs (computing);algorithm;bang file;cycle (graph theory);directed graph;graph theory;hamiltonian path;jensen's inequality;longest path problem;polynomial;time complexity;vertex (geometry)	Jørgen Bang-Jensen;Gregory Gutin	1997	Discrete Mathematics	10.1016/0012-365X(95)00318-Q	hamiltonian path;combinatorics;discrete mathematics;topology;longest path problem;graph theory;mathematics;hamiltonian path problem	Theory	28.69076878640627	28.76355139801648	13868
b1bdde64986b4cbfdce1cd7a0541d8d4e4c3dcaa	a class of distance-regular graphs that are q-polynomial	graph theory;distance regular graph;classification;theorie graphe;eigenvalue;matrice adjacence;valeur propre;graphe regulier;adjacence matrix;clasificacion;regular graph	Abstract   We consider a class of distance-regular graphs Γ with diameter  d  whose intersection numbers take the form    k = hxyd(t − 1)     −1       b     i    = h(i − t)(i − x)(i − y)(i − d)(2i − t)     −1   (2i − t + 1)     −1   , (1⩽i⩽d−1)      c     i    = hi(i − t + x)(i − t + y)(i − t + d)(2i − t)(2i − t − 1)     −1   , (1⩽i⩽d−1)      c     d    = hd(d − t + x)(d − t + y)(2d − t + 1)     −1     for some complex constants  h ,  t ,  x , and  y . We show the eigenvalues of Γ are integers if  d ≥4, and that  d ≥14 implies Γ is either   •   (i) the antipodal quotient of the Johnson graph  J (2 d , 4 d ) or  J (2 d  + 1, 4 d  + 2)   •   (ii) the halved graph   1  2  H(2d + 1, 2)   of the 2 d  + 1-cube   •   (iii) the antipodal quotient of   1  2  H(4d, 2)   or   1  2  H(4d + 2, 2)     •   (iv) a graph not listed above, but with the same intersection numbers as (i) or (iii)   #N# In particular, for  d ≥14, the list of known graphs of type 2 in Theorem 5.1 of Bannai and Ito (Benjamin-Cummings Lecture Note Series, Vol. 58) is complete if and only if there are no graphs satisfying (iv) above.	distance-regular graph;polynomial	Paul Terwilliger	1986	J. Comb. Theory, Ser. B	10.1016/0095-8956(86)90078-X	combinatorics;discrete mathematics;biological classification;eigenvalues and eigenvectors;regular graph;distance-regular graph;graph theory;mathematics;1 − 1 + 2 − 6 + 24 − 120 + ...;algebra	Theory	30.325002018210824	32.58432014112137	13870
d04c0bdf818bad3866305cc955d37f39d61b6d3e	case study: constraint handling in evolutionary optimization of catalytic materials	discrete optimization;genetic operator;inequality constraints;continuous variable;mixed optimization;equality constraints;inequality constraint;continuous optimization;cardinality constraints;constraint handling;system development;evolutionary algorithm;evolutionary optimization	The paper presents a case study in an industrially important application domain the optimization of catalytic materials. Though evolutionary algorithms are the by far most frequent approach to optimization tasks in that domain, they are challenged by mixing continuous and discrete variables, and especially by a large number of constraints. The paper describes the various kinds of encountered constraints, and explains constraint handling in GENACAT, one of evolutionary optimization systems developed specifically for catalyst optimization. In particular, it is shown that the interplay between cardinality constraints and linear equality and inequality constraints allows GENACAT to efficienlty determine the set of feasible solutions, and to split the original optimization task into a sequence of discrete and continuous optimization. Finally, the genetic operations employed in the discrete optimization are sketched, among which crossover is based on an assumption about the importance of the choice of sets of continuous variables in the cardinality constraints.	application domain;continuous optimization;discrete optimization;evolutionary algorithm;linear equation;mathematical optimization;social inequality	Martin Holena;David Linke;Lukás Bajer	2011		10.1145/2001858.2002015	probabilistic-based design optimization;discrete optimization;optimization problem;mathematical optimization;multi-swarm optimization;combinatorics;discrete mathematics;test functions for optimization;meta-optimization;combinatorial optimization;nonlinear programming;computer science;artificial intelligence;stochastic optimization;shape optimization;multi-objective optimization;genetic operator;machine learning;evolutionary algorithm;mathematics;continuous optimization;constraint;vector optimization;bilevel optimization;random optimization;metaheuristic;global optimization	AI	27.60020007938976	6.41670043101742	13880
3c7edfd254db2546e696d106cde7745a7836d2d9	parallel processing architectures for reconfigurable systems	novel reconfigurable computing architecture;processor architecture;reconfigurable architecture;on-chip memory;instruction multiplexing;future system-on-a-chip platform;reconfigurable systems;computer architecture;alu-like structure;novel reconfigurable architecture exploration;corresponding instruction;silicon;concurrent computing;chip;system on a chip;system on chip;computer languages;fpga;field programmable gate arrays;hardware;parallel processing;reconfigurable computing;signal processing	Novel reconfigurable computing architectures exploit the inherent parallelism available in many signal-processing problems. These architectures often consist of networks of compute elements that have an ALU-like structure with corresponding instructions. This opens opportunities for rapid dynamic reconfiguration and instruction multiplexing. The field of computer architectures has significantly contributed to the systematic and quantified exploration of architectures. Novel reconfigurable architecture exploration should learn from this approach. Future System-on-a-Chip platforms will consist of a combination of processor architectures, on-chip memories, and reconfigurable architectures. The real challenge is to design those architectures that can be programmed efficiently. This requires that first a programming environment and benchmarks be created and then that the reconfigurable architectures be systematically explored.	arithmetic logic unit;benchmark (computing);computer architecture;integrated development environment;multiplexing;parallel computing;parallel processing (dsp implementation);reconfigurable computing;signal processing;system on a chip	Kees A. Vissers	2003			system on a chip;agent architecture;embedded system;parallel processing;computer architecture;parallel computing;concurrent computing;computer science;signal processing;field-programmable gate array	Arch	1.0513747718687665	49.73930731236616	13901
4101d8c524fc95caaa7148bc6a564a621fa0708d	simple and fast blockquicksort using lomuto's partitioning scheme		This paper presents simple variants of the BlockQuicksort algorithm described by Edelkamp and Weiss (ESA 2016). The simplification is achieved by using Lomuto’s partitioning scheme instead of Hoare’s crossing pointer technique to partition the input. To achieve a robust sorting algorithm that works well on many different input types, the paper introduces a novel two-pivot variant of Lomuto’s partitioning scheme. A surprisingly simple twist to the generic two-pivot quicksort approach makes the algorithm robust. The paper provides an analysis of the theoretical properties of the proposed algorithms and compares them to their competitors. The analysis shows that Lomuto-based approaches incur a higher average sorting cost than the Hoarebased approach of BlockQuicksort. Moreover, the analysis is particularly useful to reason about pivot choices that suit the two-pivot approach. An extensive experimental study shows that, despite their worse theoretical behavior, the simpler variants perform as well as the original version of BlockQuicksort.	correctness (computer science);esa;experiment;hoare logic;pointer (computer programming);quicksort;simd;sorting algorithm;symbolic computation;time complexity	Martin Aumüller;Ali Abdi Kordani	2018	CoRR		pointer (computer programming);mathematical optimization;partition (number theory);computer science;algorithm;quicksort;sorting;sorting algorithm	Vision	1.2926914548805115	39.68651635461815	13902
0d241de580be15d099a93203a76426479b55ee51	word problem in distributed magmas	word problem			Jean Marcel Pallo	1981	Fundam. Inform.		discrete mathematics;combinatorics;mathematics;word problem (mathematics education)	Theory	45.863659771182064	31.571711658082418	13907
9624927530fea72daf3b5617779d5d98e7189a04	efficient deblocking filter architecture for h.264 video coders	0 18 micron deblocking filter architecture h 264 video coders h 264 video coding system data arrangement group of pixel arrangement on chip memory gop arrangement pixel data filtering umc technology 100 mhz;group of pixel arrangement;video coding adaptive filters;h 264 video coders;data arrangement;real time;data filtering;filtering video coding automatic voltage control adaptive filters quantization random access memory decoding low pass filters hardware acceleration;deblocking filter architecture;chip;video coding;adaptive filters;pixel data filtering;umc technology;gop arrangement;0 18 micron;100 mhz;h 264 video coding system;on chip memory	In this paper, an efficient in-loop deblocking filter architecture for H.264 video coding system is proposed. The deblocking filter usually need perform both vertical and horizontal directions. A novel data arrangement, called the group-of-pixel (GOP), is designed to efficiently arrange the pixel data stored in on-chip memory. With the proposed GOP arrangement, we do not need the transpose memory, which often occupies excessive chip area, to transpose the direction of the pixel data filtering. Furthermore, the number of total cycles required for GOP-based deblocking filter is reduced significantly. The proposed in-loop GOP-based deblocking filter architecture synthesized with UMC 0.18 mum technology could process real-time video in 720p HD (1280times720) format operated at 100 MHz	data compression;deblocking filter;h.264/mpeg-4 avc;pixel;real-time clock	Heng-Yao Lin;Jwu-Jin Yang;Bin-Da Liu;Jar-Ferr Yang	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1693160	chip;adaptive filter;electronic engineering;real-time computing;computer hardware;telecommunications;computer science;deblocking filter	Arch	12.5505139698756	40.345629290647956	13914
f7efea4e536740045423236fa11047e672b66ca9	the linzertorte problem, or a unified approach to painting, baking and weaving	graph theory;art decoratif;algorithm complexity;theorie graphe;coloration graphe;complexite algorithme;vertex graph;decorative art;algorithme optimal;optimal algorithm;graph coloration;sommet graphe	We present complexity models for measuring the complexity of painting, baking and weaving. In the application to painting our aim is to color the vertices of a bipartite graph acccording to some proper 2-coloring while using operations that permit the simultaneous coloring of certain#R##N##R##N#We establish lower bounds on the complexity of the painting problem for general 2-colorable graphs (bipartite) and for the special cases of trees and grid graphs. We then describe algorithms that exactly achieve the lower bounds for grip grahs, Trees anf problems related to baking and weaving.		Dorit S. Hochbaum;Edna Wigderson	1986	Discrete Applied Mathematics	10.1016/0166-218X(86)90004-1	mathematical optimization;combinatorics;graph theory;vertex;mathematics;algorithm	Theory	23.340978041214058	25.366538598867283	13928
d5c3ff56ab473dff9bcb45e161f33830104bd6cf	finding robust vertices for 3d synchronization based on euclidean minimum spanning tree	data hiding;euclidean minimum spanning tree;algorithms	Synchronization in 3D data hiding is one of the main problems. We need to know where we can embed information, and be able to find this space in order to extract the message. Various algorithms propose synchronization techniques by triangle or vertex path in a 3D mesh. In this paper, we proposed a new synchronization technique based on Euclidean minimum spanning tree computing (EMST) and the analysis of the displacement of the vertices without moving the connections in the tree. Based on the analysis of the vertices, we select the most robust vertices and synchronize these areas by computing a new EMST called ”robust EMST”. Then, we analyze the robustness of the technique, i.e. the stability of the most robust vertices selection; and demonstrate the consistence of the criterion selection with the vertex displacement.	algorithm;displacement mapping;file spanning;minimum spanning tree;need to know;vertex (geometry);vertex (graph theory)	Nicolas Tournier;William Puech;Gérard Subsol;Jean-Pierre Pedeboy	2011		10.1117/12.872384	euclidean minimum spanning tree;telecommunications;theoretical computer science;distributed computing;information hiding	Theory	25.590641891017643	34.48441429873923	13964
2c0410f0323ee005ba6b7a7a940b526d48080c7f	dytest: a self-learning algorithm using dynamic testability measures to accelerate test generation	generation;learning algorithm;integrated circuit;generacion;etude experimentale;automatic testing heuristic algorithms life estimation circuit testing circuit faults logic testing observability benchmark testing decision trees algorithm design and analysis;accelerated testing;circuito integrado;circuito logico;test;acceleration;ensayo;algorithme;algorithm;essai;circuit logique;k limited backtracks backtracks reduction self learning algorithm dynamic testability measures accelerate test generation dytest full logic value label backward implication;logic testing;test generation;logic circuit;estudio experimental;aceleracion;circuit integre;algoritmo	This paper presents a self-learning algorithm using a dynamic testability measure to accelerate test generation. It also introduces the concepts of full logic value label backward implication, the dependent backtrack and K-limited backtracks. Results indicating a high fault coverage are also presented for ten benchmark combinational circuits.	algorithm;backtracking;benchmark (computing);combinational logic;fault coverage	Weiwei Mao;Michael D. Ciletti	1988		10.1109/43.57782	acceleration;electronic engineering;simulation;generation;logic gate;computer science;artificial intelligence;integrated circuit;mathematics;software testing;algorithm;quantum mechanics	EDA	20.698428010334244	49.333461969145446	14029
04528c1abdc16740e4c77d65c2b77c4cba23df6c	graph coloring on coarse grained multicomputers	graph theory;algoritmo paralelo;complexite;maximum degree;coloracion grafo;teoria grafo;parallel algorithm;maximo;color;complejidad;graph coloring;maximum;complexity;time;theorie graphe;costo;algorithme parallele;moyenne;algorithme;coloriage de graphes;grafo;algorithm;modelo;coloration graphe;temps;coarse grained multicomputers;promedio;graph;graphe;68r10;algorithmes paralleles;graph algorithm;communication cost;couleur;average;modele;procesador;algorithme graphe;processeur;communication;graph algorithms;comunicacion;models;processor;graph colouring;tiempo;coarse grained multicomputer;cout;algoritmo;parallel algorithms	We present an efficient and scalable Coarse Grained Multicomputer (CGM) coloring algorithm that colors a graph G with at most ∆+1 colors where ∆ is the maximum degree in G. This algorithm is given in two variants: a randomized and a deterministic. We show that on a p-processor CGM model the proposed algorithms require a parallel time of O( |G| p ) and a total work and overall communication cost of O(|G|). These bounds correspond to the average case for the randomized version and to the worst case for the deterministic variant.	best, worst and average case;color;graph coloring;independent set (graph theory);isabelle;maximal independent set;maximal set;p-complete;parallel algorithm;parallel computing;polynomial;randomized algorithm;relevance;scalability;scheduling (computing);speedup;time complexity	Assefaw Hadish Gebremedhin;Isabelle Guérin Lassous;Jens Gustedt;Jan Arne Telle	2003	Discrete Applied Mathematics	10.1016/S0166-218X(02)00424-9	combinatorics;graph theory;theoretical computer science;mathematics;parallel algorithm;algorithm	Theory	18.426442411621377	28.358240572059017	14040
72c7b7cc1226f03dbf6ff1c47a4fdc69aede3354	a simple algorithm for undirected hamiltonicity		We develop a new algebraic technique that gives a simple randomized algorithm for the simple k-path problem with the same complexity O∗(1.657k) as in [1] and [3].	graph (discrete mathematics);hamiltonian path;randomized algorithm;simple algorithm	Hasan Abasi;Nader H. Bshouty	2013	Electronic Colloquium on Computational Complexity (ECCC)		algebraic number;discrete mathematics;mathematics;combinatorics;randomized algorithm;simple algorithm	Theory	25.107253284113625	28.008154151963698	14042
360777878fffd5627af324da844382aa853a73a8	integer programming and combinatorial optimization: 11th international ipco conference, berlin, germany, june 8-10, 2005, proceedings (lecture notes in computer science)	computer science;lecture notes;international ipco conference;combinatorial optimization;integer programming			Michael Jünger;Volker Kaibel	2005		10.1007/b137143	optimization problem;integer programming;combinatorial optimization;branch and price;weapon target assignment problem;branch and cut;semidefinite programming;global optimization;quadratic assignment problem;cutting-plane method	EDA	23.121639183352986	9.153351208158869	14044
e36c40c9eb1866aa1fa35036eec2dadaa807aaa9	clock delayed domino logic with efficient variable threshold voltage keeper	dependance temperature;evaluation performance;circuito polarizacion;70 nm;commande multivariable;leakage current;clocks delay threshold voltage logic circuits cmos technology leakage current very large scale integration logic design pulse inverters nanoelectronics;combinational logic circuits;performance evaluation;voltage threshold;integrated circuit;dissipation energie;logic design;clocks;implementation;corriente escape;evaluacion prestacion;logique combinatoire;circuit integre rapide;velocidad muy grande;acoplamiento electrostatico;circuit vlsi;variable strength voltage keeper;circuito integrado;energy dissipation;circuito logico;tecnologia mos complementario;bias circuit;very high speed;temperature dependence;power supply;capacitive coupling;multivariable control;combinatory logic;vlsi circuit;control multivariable;logica combinatoria;vlsi systems;cmos digital integrated circuits;alimentation electrique;circuit logique;courant fuite;leakage currents;circuit integre ultra rapide;threshold voltage;vlsi systems cmos digital integrated circuits combinational logic circuits leakage currents very high speed integrated circuits;cmos logic circuits;0 18 micron;tres grande vitesse;carry generator circuit;horloge;clock delayed domino logic;variable threshold voltage keeper;couplage capacitif;seuil tension;disipacion energia;70 nm clock delayed domino logic variable threshold voltage keeper variable strength voltage keeper cross coupled capacitive body bias generator carry generator circuit cmos digital integrated circuits combinational logic circuits leakage currents very high speed integrated circuits vlsi systems 0 18 micron;very high speed integrated circuits;temps retard;delay time;power delay product;circuito vlsi;circuit integre numerique cmos;implementacion;technologie mos complementaire;alimentacion electrica;logic circuit;tiempo retardo;circuit polarisation;clock;high speed integrated circuits;logic design clocks cmos logic circuits combinational circuits;reloj	In this paper, efficient clock delayed domino logic with variable strength voltage keeper is proposed. The variable strength of the keeper is achieved through applying two different body biases to the keeper. The circuits used to generate the body biases are called capacitive body bias generator and cross-coupled capacitive body bias generator. Compared to a previous work, the body bias generator circuits presented in this paper are simpler and do not require double or triple power supply while consuming less area and power. To show the efficiency of the proposed technique, the implementation of a carry generator circuit by the proposed techniques and the previous work are compared. The simulation results for standard CMOS technologies of 0.18 mum and 70 nm show considerable improvements in terms of power and power delay product. In addition, the proposed technique shows much less temperature dependence when compared to that of previous work	cmos;domino logic;keeper (password manager);low-power broadcasting;noise margin;power glove;power supply;simulation	A. Amirabadi;Ali Afzali-Kusha;Y. Mortazavi;Mehrdad Nourani	2007	IEEE Transactions on Very Large Scale Integration (VLSI) Systems	10.1109/TVLSI.2007.891097	clock;embedded system;electronic engineering;logic synthesis;combinatory logic;logic gate;capacitive coupling;computer science;engineering;electrical engineering;dissipation;integrated circuit;leakage;combinational logic;threshold voltage;programming language;implementation	EDA	18.30736706998561	55.80287254079911	14094
0fc0daecd64fe8ef14da0338e2d89ba960715d81	single-machine scheduling and slack due-date assignment with aging effect and deteriorating maintenance	scheduling;slack due-date assignment;aging effect;deteriorating maintenance	We consider single-machine scheduling and slack due-date assignment problems simultaneously with the position-dependent aging effect and deteriorating maintenance. In order to counteract the aging effect on the machine, we assume that at most one maintenance is allowed throughout the planning horizon and the maintenance can be performed immediately after the processing of any job is completed. The maintenance duration is dependent on its starting time. The objective is to find jointly the optimal common slack time, the optimal maintenance position, and the optimal schedule such that the sum of the total earliness, the total tardiness, and the common slack time costs is minimized. We propose polynomial time algorithms for all the problems studied.	algorithm;loss function;optimal maintenance;scheduling (computing);single-machine scheduling;slack variable;time complexity	Suh-Jenq Yang;Chou-Jung Hsu;Dar-Li Yang	2012	Optimization Letters	10.1007/s11590-011-0382-3	real-time computing;least slack time scheduling;operations research	Theory	15.12225154340899	9.430259886490754	14100
1d2119e5ba13f595b41392523cbdfd671e8880af	a new common subexpression elimination algorithm for implementing low complexity fir filters in software defined radio receivers	linear phase;nonlinear filters;wireless channels;complexity theory;radio receivers;common subexpression elimination algorithm;software defined radio;canonic signed digit;finite impulse response filter receivers adders channel bank filters software algorithms nonlinear filters digital filters mobile handsets sampling methods narrowband;finite impulse response filter;communication complexity;low complexity;digital advanced mobile phone systems;software defined radio receivers;fir digital filters;linear phase fir filters;software radio;mobile phone;receivers;wireless channels communication complexity fir filters mobile radio radio receivers software radio;personal digital cellular receivers;finite impulse response;canonical signed digit coefficients;adders;channel bank filters;fir filter;mobile radio;digital filters;common subexpression elimination;mobile handsets;software algorithms;fir filters;personal digital cellular receivers common subexpression elimination algorithm linear phase fir filters software defined radio receivers finite impulse response canonical signed digit coefficients digital advanced mobile phone systems;sampling methods;narrowband	The complexity of linear phase finite impulse response (FIR) filters used in the channelizer of a software defined radio (SDR) receiver is dominated by the complexity of coefficient multipliers. It is well known that common subexpression elimination (CSE) methods based on canonical signed digit (CSD) coefficients produce low complexity FIR filter coefficient multipliers. A new CSE algorithm based on the binary representation of filter coefficients is presented in the paper. Design examples of channel filters employed in the digital advanced mobile phone systems (D-AMPS) and personal digital cellular (PDC) receivers show that the proposed method offers an average adder reduction of 23% over the conventional CSD-based CSE method	adder (electronics);algorithm;binary number;cambridge structural database;coefficient;common subexpression elimination;etsi satellite digital radio;finite impulse response;linear phase;mobile phone;programme delivery control	Raveendranatha P. Mahesh;A. Prasad Vinod	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1693633	electronic engineering;real-time computing;telecommunications;computer science;electrical engineering;finite impulse response	EDA	31.941204176354187	57.57102958787504	14102
42fe4fbe37d81a046b074195c1ff11bf647cb068	quantifying double mccormick		When using the standard McCormick inequalities twice to convexify trilinear monomials, as is often the practice in modeling and software, there is a choice of which variables to group first. For the important case in which the domain is a nonnegative box, we calculate the volume of the resulting relaxation, as a function of the bounds defining the box. In this manner, we precisely quantify the strength of the different possible relaxations defined by all three groupings, in addition to the trilinear hull itself. As a by product, we characterize the best double McCormick relaxation. We wish to emphasize that, in the context of spatial branch-and-bound for factorable formulations, our results do not only apply to variables in the input formulation. Our results apply to monomials that involve auxiliary variables as well. So, our results apply to the product of any three (possibly complicated) expressions in a formulation.	branch and bound;convex hull;linear programming relaxation;monomial;thinking outside the box	Emily Speakman;Jon Lee	2017	Math. Oper. Res.	10.1287/moor.2017.0846	mathematical optimization;calculus;mathematics;algorithm;statistics;algebra	ML	26.84493768147829	12.246477810143219	14132
0f2860f6effc1e3c481c89e8f6d6e509319d6108	integer multipliers with overflow detection	computer arithmetic array integer multiplier design tree integer multiplier design overflow detection technique overflow detection circuit;multiplying circuits;combinational logic;high speed arithmetic algorithms;computer arithmetic;multiplying circuits digital arithmetic;multiplication computer arithmetic high speed arithmetic algorithms combinational logic overflow detection;digital arithmetic;multiplication;overflow detection;high speed	This paper presents a general approach for designing array and tree integer multipliers with overflow detection. The overflow detection techniques are based on an analysis of the magnitudes of the input operands. The overflow detection circuits operate in parallel with a simplified multiplier to reduce the overall area and delay	array data structure;operand;requirement;system requirements;two's complement	Mustafa Gök;Michael J. Schulte;Mark G. Arnold	2006	IEEE Transactions on Computers	10.1109/TC.2006.126	arithmetic;integer overflow;arbitrary-precision arithmetic;binary scaling;theoretical computer science;saturation arithmetic;mathematics;combinational logic;multiplication;algorithm	EDA	13.30995598423115	44.94796488292676	14150
31c3d808e53e61bee0427dde78cbcb8f576ba2c9	deriving tidy drawings of trees	efficient algorithm;satisfiability	The tree-drawing problem is to produce a `tidy' mapping of elements of a tree to points in the plane. In this paper, we derive an eecient algorithm for producing tidy drawings of trees. The speciication, the starting point for the derivations, consists of a collection of intuitively appealing criteria satissed by tidy drawings. The derivation shows constructively that these criteria completely determine the drawing. Indeed, the criteria completely determine a simple but ineecient algorithm for drawing a tree, which can be transformed into an eecient algorithm using just standard techniques and a small number of inventive steps. The algorithm consists of an upwards accumulation followed by a downwards accumulation on the tree, and is further evidence of the utility of these two higher-order tree operations.	algorithm;html tidy;tree accumulation	Jeremy Gibbons	1996	J. Funct. Program.	10.1017/S0956796800001842	computer science;algorithm;satisfiability	PL	-1.5137749431334238	13.905421335541128	14151
5316dd75fad8327be7f1abec4f57dbba301c3c1d	optimizing bull-free perfect graphs	algorithm complexity;mathematiques discretes;temps polynomial;algorithm analysis;analysis of algorithms and problem complexity;analisis estructural;combinatorial algorithm;matematicas discretas;complejidad algoritmo;metodo descomposicion;graphe parfait;methode decomposition;discrete mathematics;algorithme combinatoire;perfect graphs;graphe perfait;perfect graph;05c60;analysis of algorithm;68wxx;optimisation combinatoire;decomposition method;complexite algorithme;90c27;68r10;05c85;polynomial time;graph algorithm;algorithme polynomial;68q25;analyse algorithme;analyse structurale;algorithme graphe;combinatorial optimization;algoritmo optimo;algorithme optimal;structural analysis;optimal algorithm;graph algorithms;analisis algoritmo;structure analysis;optimizacion combinatoria;tiempo polinomial	A bull is a graph obtained by adding a pendant vertex at two vertices of a triangle. Here we present polynomial-time combinatorial algorithms for the optimal weighted coloring and weighted clique problems in bull-free perfect graphs. The algorithms are based on a structural analysis and decomposition of bull-free perfect graphs.	algorithm;graph (discrete mathematics);graph coloring;optimizing compiler;polynomial;structural analysis;time complexity;vertex (graph theory)	Celina M. H. de Figueiredo;Frédéric Maffray	2004	SIAM J. Discrete Math.	10.1137/S0895480198339237	strong perfect graph theorem;1-planar graph;block graph;pathwidth;perfect graph theorem;mathematical optimization;split graph;combinatorics;discrete mathematics;cograph;interval graph;independent set;perfect graph;combinatorial optimization;clique problem;trivially perfect graph;graph coloring;clique-sum;trapezoid graph;mathematics;structural analysis;modular decomposition;treewidth;chordal graph;indifference graph;algorithm	Theory	21.5977923041313	27.249018180032518	14154
b7b5f612917a625a9711a6a4dbec232ec649b0ae	universal profinite domains	proyeccion;operator;operador;virgule fixe;reunion;coma fija;fixed point;conjunto parcialmento ordenado;domain;partially ordered set;domaine;category theory;resolucion ecuacion;informatique theorique;theorie categorie;junction;projection;operateur;ensemble partiellement ordonne;resolution equation;equation resolution;information system;sistema de informacion;jonction;teoria categoria;completion;systeme information;computer theory;informatica teorica	We introduce a bicartesian closed category of what we call pro nite domains. Study of these domains is carried out through the use of an equivalent category of pre-orders in a manner similar to the information systems approach advocated by Dana Scott and others. A class of universal pro nite domains is de ned and used to derive su cient conditions for the pro nite solution of domain equations involving continuous operators. As a special instance of this construction, a universal domain for the category SFP is demonstrated. Necessary conditions for the existence of solutions for domain equations over the pro nites are also given and used to derive results about solutions of some equations. A new universal bounded complete domain is also demonstrated using an operator which has bounded complete domains as its xed points.	cartesian closed category;information system;simulated fluorescence process algorithm	Carl A. Gunter	1987	Inf. Comput.	10.1016/0890-5401(87)90048-4	partially ordered set;topology;completion;projection;domain;operator;calculus;fundamental resolution equation;mathematics;fixed point;profinite group;information system;algorithm;category theory;algebra	Logic	43.80168592437875	23.301550960689855	14156
dcf13fbe8aaf2c44cc7a812e6bed3a572f581fd3	wide format floating-point math libraries	libraries;network simulation;mathematics computing;software libraries;ibm system 6000 math libraries mathematical functions machine instructions 64 bit floating point formats 128 bit floating point formats crayy mp ibm 3090e vf convex c 240 hewlett packard 9000 720;64 bit floating point formats;software libraries floating point arithmetic mathematics computing;mathematical functions;data parallel model;data mining;hardware and software cache coherence;ibm 3090e vf;128 bit floating point formats;scalable multiprocessors;ibm system 6000;convex c 240;math libraries;hewlett packard;floating point;floating point arithmetic;crayy mp;machine instructions;hewlett packard 9000 720	Math libraries are considered an extension of the hardware, providing common mathematical functions not supplied in hardware. Users expect these func­ tions to be as accurate as the basic machine instruc­ tions, whether or not these expe ctations are always justified. Presented in this paper are the performance and accuracy evaluations of eleven transcendental func­ tions found in 64 and 128 bitfloating-poin tf ormats in math libraries on the CRAY Y-MP, the IBM 3090EIVF, the Convex C-240, the Hewlett Packard 90001720 and the IBM Systeml6000. Both architecture and algo­ rithms are shown to impact the results.	library (computing)	Vicky Markstein;Peter W. Markstein;Tung Nguyen;Steve Poole	1991	Proceedings of the 1991 ACM/IEEE Conference on Supercomputing (Supercomputing '91)	10.1145/125826.125903	computer architecture;parallel computing;computer hardware;computer science;floating point;operating system;programming language	HPC	-0.8246180160132522	45.103370663145064	14165
d502a8abde4700636a06a8e75e2393e7c26b8796	a hierarchy of random-context grammars and automata	grammar;grammaire tableau;grammaire contexte aleatoire;language theory;formal languages;automaton;teoria lenguaje;automata;thesis;grammaire;automate;artificial intelligence;array grammar;gramatica;lenguaje formal;machine theory;theorie langage;formal language;langage formel	Abstract   Random-context grammars are progressively extended to three dimensions. Random-context structure grammars that generate three-dimensional digital structures are introduced. The characterization of random-context array grammars and random-context structure grammars by two-dimensional random-context array automata and three-dimensional random-context structure automata respectively is investigated. A possible practical application of random-context structure grammars and automata in the modeling of chemical molecules is speculated on.	automata theory;automaton	Elizabeth Marie Ehlers;Sebastiaan H. von Solms	1987	Inf. Sci.	10.1016/0020-0255(87)90013-2	natural language processing;indexed language;context-sensitive grammar;tree-adjoining grammar;indexed grammar;formal language;l-attributed grammar;deterministic context-free grammar;computer science;nested word;artificial intelligence;automaton;context-free grammar;ambiguous grammar;stochastic context-free grammar;embedded pushdown automaton;algorithm	Logic	-2.8720185748896645	20.459157888376385	14169
a2c0f9ed05eca845103dea0a9240362bf2bc9886	a cutting plane algorithm for graph coloring	optimisation;coloracion grafo;plane;programacion entera;combinatorics;optimizacion;05bxx;combinatoria;color;coupe graphe;cutting;combinatoire;plan;conception;graph coloring;68wxx;programmation en nombres entiers;cutting plane algorithm;decoupage;permutation;52bxx;politope;corte grafo;coloration graphe;graph coloring problem;integer programming;informatique theorique;graph cut;cutting plane algorithms;plano;permutacion;diseno;graph algorithm;design;couleur;facets of polyhedra;troquelado;optimization;algorithme graphe;point of view;integer program;graph colouring;computer theory;polytope;graphe colore;informatica teorica;05c15	We present an approach based on integer programming formulations of the graph coloring problem. Our goal is to develop models that remove some symmetrical solutions obtained by color permutations. We study the problem from a polyhedral point of view and determine some families of facets of the 0/1-polytope associated with one of these integer programming formulations. The theoretical results described here are used to design an efficient Cutting Plane algorithm. © 2007 Elsevier B.V. All rights reserved.	algorithm;cutting-plane method;graph coloring;integer programming;polyhedron	Isabel Méndez-Díaz;Paula Zabala	2008	Discrete Applied Mathematics	10.1016/j.dam.2006.07.010	mathematical optimization;combinatorics;discrete mathematics;integer programming;fractional coloring;complete coloring;edge coloring;graph coloring;mathematics;geometry;list coloring	Theory	23.116352891189763	13.170331832209948	14172
9a9a52fc3fb54e5fc4311840f5dc004ddf91a2a8	full and quarter plane complete infinite latin squares	latin square	Abstract   Given any countably infinite group  G  there exists a sequence  a  1 ,  a  2 , … containing each element of  G  exactly once such that given any  g  ∈  G  there is a unique  k  with  a  1 ,  a  2  …  a   k   =  g . Thus any countably infinite group is sequenceable. This sequence gives rise to an infinite  quarter plane  latin square  C  with the property that, given any ( g   i  , g   j  ) ∈  G  ×  G  there exists a unique   (r, s) ∈   Z     +    ×   Z     +    such that  c   rs   =  g   i   and  c   rs +1  =  g   j  ; moreover, there exists a unique   (t, u) ∈   Z     +    ×   Z     +    such that  c   tu   =  g   i   and  c   t +1 u   =  g   j  . Thus,  C  is a complete infinite latin square. A similar result is given for an infinite  full plane  latin square  D .		Michael J. Caulfield	1996	Discrete Mathematics	10.1016/0012-365X(95)00115-D	combinatorics;discrete mathematics;latin square;mathematics;geometry;latin square property	Theory	38.29107008120699	32.513268440939456	14174
c093b9b4577e72a992700cddcd16d7d0eb7110e8	structure of linear codes over the ring bk		We study the structure of linear codes over the ring Bk which is defined by Fpr [v1, v2, . . . , vk]/〈v 2 i = vi, viv j = v jvi〉 k i, j=1. In order to study the codes, we begin with studying the structure of the ring Bk via a Gray map which also induces a relation between codes over Bk and codes over Fpr . We consider Euclidean and Hermitian self-dual codes, MacWilliams relations, as well as Singleton-type bounds for these codes. Further, we characterize cyclic and quasi-cyclic codes using their images under the Gray map, and give the generators for these type of codes.	film-type patterned retarder;linear code	Irwansyah;Djoko Suprijanto	2017	CoRR			Theory	41.035337075779715	53.02640524219141	14179
a1daa117a7d757c064c4d178195709d7bfb6d159	using row operation unit to realize reconfigurable ternary optical processor	row operation unit based reconfigurable ternary optical processor row operation decrease radix design principle two input ternary logic operator basic operation units reconstruction instruction ternary optical computer reconstruction process;logic design;reconfigurable architectures;optical polarization hardware optical computing optical diffraction optical interferometry computers optical design;optical computing;reconfigurable ternary optical processor;ternary logic;row operation unit;ternary logic digital arithmetic logic design optical computing reconfigurable architectures;digital arithmetic;ternary optical computer;reconfigurable ternary optical processor ternary optical computer row operation unit	When we follow decrease-radix design principle to construct a two-input ternary logic operator, six basic operation units are needed at most. Accordingly, six reconstruction instructions are needed at most too. Ternary optical computer based on basic operation unit and decrease-radix design principle, to some extent, is hard to be controlled due to its massive basic operation units. To address this issue, a row operation unit is proposed in this paper. Based on row operation unit, a new reconfigurable ternary optical processor is designed, which can make the reconstruction process easier and the hardware simplified sharply. Experiment result shows that the row-operation-unit-based reconfigurable ternary optical processor is feasible and efficient.	optical computing;optical disc authoring;reconfigurable computing;three-valued logic	Shan Ouyang;Yi Jin	2012	2012 IEEE 12th International Conference on Computer and Information Technology	10.1109/CIT.2012.206	logic synthesis;ternary operation;computer science;theoretical computer science;optical computing	Vision	14.888806918828104	43.126732745859634	14185
22ff0337d4001abc95502d16ff95d090a5886c6a	faster homomorphic linear transformations in helib		HElib is a software library that implements homomorphic encryption (HE), with a focus on effective use of “packed” ciphertexts. An important operation (which is used in bootstrapping, as well as in other applications) is applying a known linear map to a vector of encrypted data. In this paper, we describe several algorithmic improvements that significantly speed up this operation: in our experiments, our new algorithms were 30–75 times faster than those currently implemented in HElib for typical parameters. Our techniques also reduce the size of the large public evaluation key, often using 33%-50% less space than the previous HElib implementation. We also implemented a new tradeoff that enables a drastic reduction in size, maybe a 25x factor or more for some parameters, paying only a 2-4x factor in runtime (and giving up some parallelization opportunities).	algorithm;bootstrapping (compilers);experiment;homomorphic encryption;library (computing);parallel computing	Shai Halevi;Victor Shoup	2018		10.1007/978-3-319-96884-1_4	theoretical computer science;discrete mathematics;speedup;encryption;software;computer science;linear map;homomorphic encryption	Crypto	7.866424196332923	43.76189604766032	14187
c862addf8c705244431fdd33d8775e89256e912b	a compiler-blockable algorithm for qr decomposition.	qr decomposition	Because of an imbalance between computation and memory speed in modern processors, programmers are explicitly restructuring codes to perform well on particular memory systems, leading to machine-speciic programs. This paper describes a block algorithm for QR decomposition that is derivable by the compiler and has good performance on small matrices | sizes that are typically run on nodes of a massively parallel system or workstation. The advantage of our algorithm over the one found in LAPACK is that it can be derived by the compiler and needs no hand optimization.	algorithm;central processing unit;code;compiler;computation;lapack;mathematical optimization;programmer;qr decomposition;workstation	Steve Carr;Richard B. Lehoucq	1995			parallel computing;compiler;qr decomposition;theoretical computer science;computer science	HPC	-4.2419609337408435	41.34129944311101	14199
034e74a71fc23f9e6cf43264b6e027af907e24c6	bastion: board and soc test instrumentation for ageing and no failure found		This is an overview paper that motivates and describes performed work done in the European Commission funded research project BASTION, which focuses on two critical problems of modern electronics: the No-Fault-Found (NFF) and CMOS ageing. New defect classes contributing to NFF have been identified, including timing related faults (TRF) at board level and intermittent resistive faults (IRF) at IC level. BASTION has addressed the mechanisms of ageing and developed several techniques to improve the longevity of electronic products. Embedded Instrumentation, monitors, and IEEE 1687 standard for reconfigurable scan networks (RSN) are seen as an important leverage that helped mitigating the impact of the above listed problems by facilitating a low-latency, scalable online system health monitoring and error localization infrastructure as well as integration of all heterogeneous technologies into a homogeneous demonstration platform. This paper helps the reader to get a general overview of the work performed and provides a collection of references to publications where the respective research results are described in detail.	bastion;cmos;embedded instrumentation;embedded system;failure analysis;ieee 802.11i-2004;information retrieval facility;scalability;software bug;on-line system	Artur Jutman;Christophe Lotz;Erik Larsson;Matteo Sonza Reorda;Maksim Jenihhin;Jaan Raik;Hans G. Kerkhoff;Rene Krenz-Baath;Piet Engelke	2017	Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017		embedded system;electronic engineering;telecommunications;computer science;engineering;electrical engineering;operating system;forensic engineering;network topology;measurement;computer network	EDA	9.778582239545864	58.08841788158336	14202
dd1342c132866c19bfe54874bed171c0a16f49d6	eco based placement and routing framework for 3d fpgas with micro-fluidic cooling	three dimensional displays field programmable gate arrays cooling benchmark testing routing system on chip delays;routing;system on chip;three dimensional displays;3d fpga thermal aware placement and routing engineering change order;onchip temperature uniformity eco based placement and routing 3d fpga microfluidic cooling thermal problem nonuniform heat removal capacity cooling aware engineering change order;field programmable gate arrays;thermal management packaging cooling field programmable gate arrays logic cad;benchmark testing;delays;cooling	Integrated micro-fluidic (MF) cooling is a promising technique to solve the thermal problems in 3D FPGAs [1] (As shown in Figure 1). However, this cooling method has some nonideal properties such as non-uniform heat removal capacity along the flow direction. Existing 3D FPGA placement and routing (P&R) tools are unaware of micro-fluidic cooling, thus leading to large on-chip temperature variation which is harmful to the reliability of 3D FPGAs. In this paper we demonstrate that we can incorporate micro-fluidic cooling considerations in existing 3D FPGA P&R tools simply with a cooling-aware Engineering Change Order (ECO) based placement framework. Taking the placement result of an existing P&R tool, the framework modifies the node positions to improve the on-chip temperature uniformity accounting for fluidic cooling structures. Hence we do not need to invest in a stand alone fluidic cooling aware 3D FPGA CAD framework.	circuit complexity;computer cooling;computer-aided design;engineering change order;field-programmable gate array;place and route;routing	Zhiyuan Yang;Caleb Serafy;Ankur Srivastava	2016	2016 IEEE 24th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)	10.1109/FCCM.2016.57	system on a chip;embedded system;benchmark;routing;parallel computing;real-time computing;computer science;field-programmable gate array	EDA	14.115315390206934	54.54994843632244	14208
9cc6e13eb4c79ba76a82afc9a9d41068a8e85e1b	ramsey algebras and the existence of idempotent ultrafilters	hindman s theorem;idempotent ultrafilter;strongly reductible ultrafilter;ramsey algebra;05d10;05a17;03e05	Hindman's Theorem says that every finite coloring of the positive natural numbers has a monochromatic set of finite sums. Ramsey algebras, recently introduced, are structures that satisfy an analogue of Hindman's Theorem. It is an open problem posed by Carlson whether every Ramsey algebra has an idempotent ultrafilter. This paper develops a general framework to study idempotent ultrafilters. Under certain countable setting, the main result roughly says that every nondegenerate Ramsey algebra has a nonprincipal idempotent ultrafilter in some nontrivial countable field of sets. This amounts to a positive result that addresses Carlson's question in some way.	idempotence;ramsey's theorem	Wen Chean Teh	2016	Arch. Math. Log.	10.1007/s00153-016-0475-x	combinatorics;mathematical analysis;discrete mathematics;topology;ramsey theory;mathematics;algebra	Theory	38.18167283321455	28.340453123995633	14220
158804e3a341e59930cc1bb46957ec3d6a1f7f93	comparing cost functions in resource analysis	informatica	Cost functions provide information about the amount of resources required to execute a program in terms of the sizes of input arguments. They can provide an upper-bound, a lower-bound, or the average-case cost. Motivated by the existence of a number of automatic cost analyzers which produce cost functions, we propose an approach for automatically proving that a cost function is smaller than another one. In all applications of resource analysis, such as resource-usage verification, program synthesis and optimization, etc., it is essential to compare cost functions. This allows choosing an implementation with smaller cost or guaranteeing that the given resource-usage bounds are preserved. Unfortunately, automatically generated cost functions for realistic programs tend to be rather intricate, defined by multiple cases, involving non-linear subexpressions (e.g., exponential, polynomial and logarithmic) and they can contain multiple variables, possibly related by means of constraints. Thus, comparing cost functions is far from trivial. Our approach first syntactically transforms functions into simpler forms and then applies a number of sufficient conditions which guarantee that a set of expressions is smaller than another expression. Our preliminary implementation in the COSTA system indicates that the approach can be useful in practice.	best, worst and average case;exponential polynomial;loss function;mathematical optimization;nonlinear system;numerical method;program synthesis;time complexity	Elvira Albert;Puri Arenas;Samir Genaim;Israel Herraiz;Germán Puebla	2009		10.1007/978-3-642-15331-0_1	mathematical optimization;operations management;mathematics;algorithm	Logic	7.121977051408431	16.91857428957077	14225
9adf2eba8ec240b9ae2a56c7cffa9fac7129f9bd	zero-nonzero and real-nonreal sign determination	complexity	We consider first the zero-nonzero determination problem, which consists in determining the list of zero-nonzero conditions realized by a finite list of polynomials on a finite set Z ⊂ C with C an algebraic closed field. We describe an algorithm to solve the zero-nonzero determination problem and we perform its bit complexity analysis. This algorithm, which is in many ways an adaptation of the methods used to solve the more classical sign determination problem, presents also new ideas which can be used to improve sign determination. Then, we consider the real-nonreal sign determination problem, which deals with both the sign determination and the zero-nonzero determination problem. We describe an algorithm to solve the real-nonreal sign determination problem, we perform its bit complexity analysis and we discuss this problem in a parametric context.	algorithm;analysis of algorithms;context of computational complexity;linear algebra;polynomial	Daniel Perrucci;Marie-Françoise Roy	2013	CoRR		mathematical optimization;combinatorics;discrete mathematics;complexity;mathematics	AI	46.91167623623085	37.356310334900634	14241
095dc18290efe1dd0ac09bedec4af899c247f48f	strictly positive definite functions on a real inner product space	positive definite function;inner product space;indexation	Abstract. If f(t) = ∑∞ k=0 akt k converges for all t ∈ IR with all coefficients ak ≥ 0, then the function f(< x,y >) is positive definite on H ×H for any inner product space H. Set K = {k : ak > 0}. We show that f(< x,y >) is strictly positive definite if and only if K contains the index 0 plus an infinite number of even integers and an infinite number of odd integers.	coefficient	Allan Pinkus	2004	Adv. Comput. Math.	10.1023/A:1027362918283	mathematical analysis;discrete mathematics;inner product space;mathematics;positive-definite function;statistics;algebra	Theory	44.86872042909675	33.99315117441829	14253
ab7cd9b48649d4ed43335872af34e2e55860f8a2	on the distinctness of primitive sequences over z/(p e q) modulo 2	integer residue rings;94a55;primitive polynomials;94a60;linear recurring sequences;modular reductions;期刊论文;11b50;primitive sequences	Let N be an integer greater than 1 and Z/(N) the integer residue ring modulo N. Extensive experiments seem to imply that primitive sequences of order n≥2 over Z/(N) are pairwise distinct modulo 2. However, efforts to obtain a formal proof have not been successful except for the case when N is an odd prime power integer. Recent research has mainly focussed on the case of square-free odd integers with several special conditions. In this paper we study the problem over Z/(p e q), where p and q are two distinct odd primes, e is an integer greater than 1. We provide a sufficient condition to ensure that primitive sequences generated by a primitive polynomial over Z/(p e q) are pairwise distinct modulo 2.	experiment;formal proof;modulo operation;primitive polynomial (field theory);square-free polynomial	Yuan Cheng;Wen-Feng Qi;Qun-Xiong Zheng;Dong Yang	2015	Cryptography and Communications	10.1007/s12095-015-0151-8	combinatorics;discrete mathematics;multiplicative order;primitive root modulo n;mathematics;root of unity modulo n;primitive element;algebra	Crypto	41.925239198234735	39.141481212131644	14256
6aea4a64ea134a534c935c83b4f6c61b79812bab	analysis and optimization of sequential circuit element to combat single-event timing upsets	analytical models;sequential circuits cmos digital integrated circuits flip flops;master slave cmos flip flop sequential circuit elements single event timing upsets energetic particle hits setup timing constraints hold timing constraints;clocks;sequential circuits;setup timing constraints;flip flops;sequential circuits timing flip flops latches clocks single event upset cmos technology very large scale integration logic integrated circuit technology;single event timing upsets;energetic particles;energetic particle hits;cmos digital integrated circuits;transistors;integrated circuit modeling;master slave cmos flip flop;sequential circuit elements;latches;flip flop;hold timing constraints;timing;time constraint	This paper presents the analysis and optimization of a flip-flop while considering the effect of energetic particle hits on its setup and hold times. First it is shown that the particle hit tightens the setup and hold timing constraints imposed on the flip-flop. Next it is shown how to size transistors of a clocked master-slave CMOS flip-flop to make it more robust against single-event timing upsets. Experimental results to assess the effectiveness of transistor sizing step are provided and discussed.1	cmos;clock rate;electrical element;flops;flip-flop (electronics);mathematical optimization;sequential logic;transistor	Hamed Abrishami;Safar Hatami;Massoud Pedram	2010	Proceedings of 2010 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2010.5537377	embedded system;electronic engineering;real-time computing;engineering;electrical engineering;sequential logic;transistor	EDA	18.88788987550652	56.268470931399065	14273
24927b2f416b297688800008fbbf87e78980557b	synthesis of on-line testing control units: flow graph coding/monitoring approach	control systems;signal generators;on line testing;information science;paper technology;testing;testing flow graphs monitoring paper technology control systems information science materials science and technology built in self test signal generators logic devices;flow graphs;materials science and technology;built in self test;program testing;monitoring;concurrency control;concurrency control microprogramming instruction sets flow graphs program testing;microprogramming;micro program type;concurrently self testing control units;logic devices;on line testing control units;micro program type on line testing control units flow graph coding concurrently self testing control units;instruction sets;flow graph coding	The paper deals with design of concurrently (on-line) self-testing control units. The control units of the micro-program type are considered. At the same time, the material can easily be extended and is applicable to cover other control unit architectures.		Serge N. Demidenko;Eugene M. Levine;Vincenzo Piuri	2000		10.1109/DFTVS.2000.887166	embedded system;electronic engineering;real-time computing;information science;computer science;theoretical computer science;operating system;concurrency control;instruction set;distributed computing;microcode;software testing;algorithm;signal generator;computer engineering	SE	8.704644375658294	50.94040236573547	14277
b085dcafaf99d4012bff59c82a27929e0e443868	design of an asic to implement a new data tranfer protocol for high energy physics	data transmission;application specific integrated circuits protocols data acquisition buffer storage data communication physics image storage laboratories hardware design languages detectors;high energy physics instrumentation computing;protocols;building block;data collection;nuclear electronics;detector circuits;chip;cmos digital integrated circuits;daq system asic data transfer protocol imaging push data transmission high speed data acquisition high energy physics experiments data collection chip;high energy physics;application specific integrated circuits;high energy physics instrumentation computing application specific integrated circuits protocols data acquisition detector circuits nuclear electronics cmos digital integrated circuits;data acquisition;high speed;data transfer	"""A new data transfer protocol, named """"Imaging Push"""", is described for data transmission between a pair of source and consumer chips in a high-speed data acquisition (DAQ) system for high energy physics experiments. Further, a data collection chip (DCC) is designed as a fundamental building block for the data collection network in the DAQ system. >"""	application-specific integrated circuit	V. K. Raj;R. V. Idate;A. W. Booth;M. Botlo;J. Dorenbosch;E. C. Milner;E. M. Wang	1994		10.1109/ISCAS.1994.409191	embedded system;electronic engineering;computer hardware;telecommunications;computer science;data transmission	Mobile	53.491394855539404	50.574165002480015	14281
c27744606a13c669a2abc23ee9e1d3257bbd0d86	traitor-tracing on binary strings	satisfiability;watermarking;upper and lower bounds;data transmission	Codes with the Identifiable Parent Property (IPP) have been studied in the context of traitor tracing; such codes can be used to enable a data supplier to determine the origin of pirated data. We consider an analogous property for a set of binary strings S: if a new string τ is formed by concatenating substrings of members of S, we should be able to identify at least one original string which must have been used to generate τ . We prove upper and lower bounds for the size of sets which satisfy this property.	code;concatenation;substring;traitor tracing	Michael J. Collins	2009	IACR Cryptology ePrint Archive		traitor tracing;data transmission;cryptography;sheet metal;binary number;satisfiability;algorithm;topology;upper and lower bounds;electrical conductor;mathematics	Theory	37.87866117979468	54.520298099330866	14308
d65d792f288e8d7ed4020d86bfb4cc1b337e081f	latchup current self-stop circuit for whole-chip latchup prevention in bulk cmos integrated circuits	power supplies;silicon;cmos integrated circuits;mos devices;thyristors;1p3m bulk cmos process;cmos integrated circuits switches thyristors voltage power supplies circuit synthesis costs cmos process mos devices silicon;circuit design;fault currents;0 5 micron;cmos process;latchup sensitive core circuit blocks;latchup current self stop circuit design;fabrication cost;chip;parasitic scr path holding voltage;process modification;integrated circuit design;bulk cmos integrated circuits;latchup current self stop methodology;bulk cmos chip;voltage;proceedings paper;integrated circuit testing;0 5 micron latchup current self stop circuit design whole chip latchup prevention bulk cmos integrated circuits latchup current self stop methodology circuit damage prevention bulk cmos chip latchup sensitive core circuit blocks parasitic scr path holding voltage process modification fabrication cost 1p3m bulk cmos process;circuit damage prevention;integrated circuit reliability;switches;integrated circuit testing cmos integrated circuits integrated circuit reliability integrated circuit design fault currents;circuit synthesis;whole chip latchup prevention	A latchup current self-stop methodology and circuit design, which are used to prevent damage in the bulk CMOS integrated circuits due to latchup, are proposed in this paper. In a bulk CMOS chip, the core circuit blocks are always latchup sensitive due to a low holding voltage of the parasitic SCR path. The proposed latchup prevention methodology and circuit design can detect and stop the occurrence of latchup without any process modification or extra fabrication cost. It is suitable for whole-chip latchup prevention of bulk CMOS integrated circuits. This proposed latchup current self-stop methodology and circuit have been verified in a 0.5-μm 1P3M bulk CMOS process.	cmos;circuit design;integrated circuit;latch-up	Jeng-Jie Peng;Ming-Dou Ker;Hsin-Chin Jiang	2002		10.1109/ISCAS.2002.1010759	chip;thyristor;embedded system;electronic engineering;voltage;telecommunications;network switch;computer science;engineering;electrical engineering;circuit design;silicon;cmos;integrated circuit design	EDA	18.98992309324522	56.327152161603635	14309
372223ad536000d8431940f60d21d18b355d0521	congruences of models of elliptic curves	grupo de excelencia;ciencias basicas y experimentales;matematicas	Let OK be a discrete valuation ring with field of fractions K and perfect residue field. Let E be an elliptic curve over K, let L/K be a finite Galois extension and let OL be the integral closure of OK in L. Denote by X ′ the minimal regular model of EL over OL. We show that the special fibers of the minimal Weierstrass model and the minimal regular model of E over OK are determined by the infinitesimal fiber X ′ m together with the action of Gal(L/K), when m is big enough (depending on the minimal discriminant of E and the different of L/K).	discriminant;successive over-relaxation;value (ethics)	Qing Liu;Huajun Lu	2013	J. London Math. Society	10.1112/jlms/jdt049	mathematical analysis;topology;mathematics;geometry;algebra	Vision	41.66161279408409	34.168535684801746	14315
e85442537266b36c3cfe931777a99e1b619bbb7b	a multiagent solution to overcome selfish routing in transportation networks	social network services;electronic mail;routing;oscillators;vehicles;real time systems	It is well-known that selfish routing, where individual agents make uncoordinated greedy routing decisions, does not produce a socially desirable outcome in transport and communication networks. In this paper, we address this general problem of the loss of social welfare that occurs due to uncoordinated behavior in networks and model it as a multiagent coordination problem. Specifically we study strategies to overcome selfish routing in traffic networks with multiple routes where a subset of vehicles are part of a social network that exchanges traffic related data. We investigate classic traffic flow paradoxes that are ubiquitous in various types of networks leading to severe congestion. We present a novel distributed traffic coordination algorithm that alleviates congestion by harnessing the real-time information available through the driver's online social network. We also propose a utility computation mechanism for route choice that generates near-optimal flows. Our extensive simulation results show that social network based multiagent traffic route coordination contributes to mitigate the effects of these paradoxes and significantly reduces congestion.	agent-based model;computation;greedy algorithm;machine learning;nash equilibrium;network congestion;pareto efficiency;real-time data;real-time transcription;routing;simulation;social network;telecommunications network	Mohammad Rashedul Hasan;Ana L. C. Bazzan;Eliyahu Friedman;Anita Raja	2016	2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2016.7795856	routing;static routing;simulation;hierarchical routing;engineering;distributed computing;computer security;geographic routing	Robotics	-2.389286153946768	4.695451731548805	14320
bd457673545e8d3c92dacf85965d5dba2269ad0c	automatic test generation using genetically-engineered distinguishing sequences	genetic engineering;sequences;genetic algorithm automatic test generation distinguishing sequence sequential circuit two phase algorithm fault effects flip flops digate;automatic testing;sequential circuits;flip flops;fault effects;two phase algorithm;sequences fault diagnosis logic testing sequential circuits automatic testing genetic algorithms;automatic testing circuit testing circuit faults sequential analysis iron sequential circuits flip flops genetic algorithms benchmark testing circuit synthesis;logic testing;digate;automatic test generation;test generation;genetic algorithm;genetic algorithms;distinguishing sequence;flip flop;fault diagnosis;sequential circuit	A fault-oriented sequential circuit test generator is described in which various types of distinguishing sequences are derived, both statically and dynamically, to aid the test generation process. A two-phase algorithm is used during test generation. The rst phase activates the target fault, and the second phase propagates the fault eeects (FE's) from the ip-ops with assistance from the distinguishing sequences. This strategy improves the propagation of FE's to the primary outputs, and the overall fault coverage is greatly increased. In our new test generator, DIGATE, genetic algorithms are used to derive both activating and distinguishing sequences during test generation. Our results show very high fault coverages for the ISCAS89 sequential benchmark circuits and several synthesized circuits. The task of test generation is to nd a sequence which is capable of distinguishing the fault-free machine from the faulty machine resulting from the presence of a fault. Determinis-tic test generators for sequential circuits attempt to do this but are prone to large numbers of backtracks and complex scheduling algorithms 1-11]. Simulation-based test generators , on the other hand, avoid the complexity of backtracking altogether by processing in the forward direction only. Several novel approaches to test generation using genetic algorithms (GA's) have been proposed in the past 12-19]. Fitness functions were used to guide the GA to nd a test vector or sequence that maximizes given objectives for a single fault or group of faults. In GATEST 15], the objective of the tness function was to maximize the number of faults detected and the number of fault eeects (FE's) propagated to ip-ops, and in CRIS 12] and GATTO 16], increasing the circuit activity was a dominant objective. The objectives of propagating FE's to ip-ops and increasing circuit activity have been shown to increase the probability of detecting faults at the primary outputs (PO's). Although the fault detection probability improves , propagating a FE from a ip-op to a PO remains a diicult problem. Without the knowledge of distinguishing sequences, propagation of FE's to the ip-ops is usually done indiscriminately, resulting in much wasted eeort, since propagation of FE's from certain ip-ops may not be possible. As a result, many faults are unable to reach the PO's, yielding a lower fault coverage. This phenomenon suggests that the tness functions used in the past do not exploit the knowledge of fault propagation. For example, the tness function objectives fail to avoid fault propagation to …	backtracking;benchmark (computing);fault coverage;fault detection and isolation;fitness function;genetic algorithm;internet protocol suite;open-source hardware;scheduling (computing);sensor;sequential logic;simulation;software propagation;software release life cycle;test vector;two-phase commit protocol	Michael S. Hsiao;Elizabeth M. Rudnick;Janak H. Patel	1996		10.1109/VTEST.1996.510860	electronic engineering;real-time computing;genetic algorithm;fault coverage;computer science;stuck-at fault;automatic test pattern generation;sequential logic;algorithm	EDA	21.82316534268484	50.49983676810322	14327
9113dd33acbdebb464c289bb6eb2d0131c1f561f	bipartite powers of k-chordal graphs	info info dm computer science cs discrete mathematics cs dm;school of automation;computer science automation formerly	Let k be an integer and k ≥ 3. A graph G is k-chordal if G does not have an induced cycle of length greater than k. From the definition it is clear that 3-chordal graphs are precisely the class of chordal graphs. Duchet proved that, for every positive integer m, if G is chordal then so is G. Brandstädt et al. in [Andreas Brandstädt, Van Bang Le, and Thomas Szymczak. Duchet-type theorems for powers of HHD-free graphs. Discrete Mathematics, 177(1-3):9-16, 1997.] showed that if G is k-chordal, then so is G.	discrete mathematics;induced path	L. Sunil Chandran;Rogers Mathew	2013	Discrete Mathematics & Theoretical Computer Science		strong perfect graph theorem;outerplanar graph;graph power;pathwidth;edge-transitive graph;complete bipartite graph;combinatorics;triangle-free graph;bipartite graph;dense graph;pancyclic graph;forbidden graph characterization;foster graph;mathematics;distance-hereditary graph;tree-depth;blossom algorithm;vertex-transitive graph;crossing number;biregular graph;line graph;algorithm;matching;algebra	Theory	29.485889639718657	30.04761492960671	14342
818a7dbebbb5b2987b7705082e67152130e702a2	complete analytic and computational analyses of the discrete-time bulk-arrival infinite-server system: gix/geom/	infinite servers;geometric distribution;discrete time;size distribution;queueing system;bulk arrivals;discrete time queue;steady state	In this paper, we consider the discrete-time queueing system with bulk arrivals, generally distributed inter-batch times, geometrically distributed service times, and infinite number of servers: the GIX/Geom/∞ queue. Under the assumptions of early arrival system (EAS) and late arrival system (LAS), we derive the system size distributions at two different epochs--prearrival and random. In addition, simple relations among the binomial moments of the steady-state system-size distributions of the two systems are derived. Special cases, such as the GIX/Geom/∞ or GI/D/∞ queues, are also presented. Some numerical results are included at the end.	server (computing)	Mohan L. Chaudhry;Jin D. Kim	2004	Computers & OR	10.1016/S0305-0548(03)00167-9	mathematical optimization;geometric distribution;discrete time and continuous time;discrete mathematics;real-time computing;m/m/c queue;m/m/∞ queue;bulk queue;mathematics;m/g/k queue;steady state;statistics	NLP	8.459732687309097	11.583226075446323	14359
4280cbe9de3fe72f3c2a71304140d5a0a10d316d	collective test generation and test set compaction	boolean functions;observability;binary decision diagram	We present here a scheme of collective test pattern generation (CTPG) in which all tests for each fault in a network are generated as a by-product of the minimization process. This is done efficiently with the use of Binary Decision Diagrams (BDDs), known to provide compact representation and fast algorithms. The test patterns are obtained concurrently with the observability donu0027t care sets through a semi-algebraic method, the extended BDD-based Observability Analysis (BBOA). This kind of collective test generation, potentially, allows good test set compaction since all the possible tests are considered. The compaction is performed by a series of steps consisting of: fault graph construction, maximal independent fault sets extraction and test sets matching. Results on test set size and coverage are presented and discussed.	data compaction;test set	Wang Jiang Chau;Edward P. Stabler	1995			discrete mathematics;observability;computer science;stuck-at fault;theoretical computer science;automatic test pattern generation;mathematics;boolean function;binary decision diagram;algorithm	EDA	18.956949996204035	47.20616161062815	14363
8a28a7a3d5be7b895e61c62833c0f4daf3820e3e	a fast methodology for first-time-correct design of plls using nonlinear phase-domain vco macromodels	reconfiguration;design process;network synthesis;design methodology phase locked loops voltage controlled oscillators jitter transceivers clocks predictive models cities and towns process design productivity;networks on chips;frequency scaling;behavior modeling;use cases;best effort;phase locked loops;first time correct design phase locked loop design voltage controlled oscillators nonlinear phase domain vco macromodels nonlinear behavioral simulations;circuit simulation;systems on chips;jitter phase locked loops voltage controlled oscillators network synthesis circuit simulation;guaranteed throughput;voltage controlled oscillators;jitter;voltage scaling;dynamic;multiple application platforms;design methodology	We present a novel methodology suitable for fast, correct design of modern PLLs. The central feature of the methodology is its use of accurate, nonlinear behavioral models for the VCO within the PLL, thus removing the need for many time-consuming SPICE-level simulations during the design process. We apply the new methodology to design a novel injection-aided PLL that acquires lock 3 x faster than prior designs, without trading off other design metrics such as jitter. We demonstrate how existing design methodologies based on behavioral simulation are incapable of leading to our new PLL design. The nonlinear behavioral simulations employed in our methodology are about 2 orders of magnitude faster than transistor-level ones, resulting in an overall design productivity gain of an order of magnitude.	nonlinear system;phase-locked loop;spice;simulation;transistor;voltage-controlled oscillator	Prashant Goyal;Xiaolue Lai;Jaijeet S. Roychowdhury	2006	Asia and South Pacific Conference on Design Automation, 2006.	10.1145/1118299.1118373	behavioral modeling;use case;control engineering;network synthesis filters;best-effort delivery;frequency scaling;electronic engineering;real-time computing;phase-locked loop;design process;jitter;design methods;computer science;engineering;control reconfiguration	EDA	23.608911702501096	58.10929175127128	14371
e20d00ebf2656b4a3dd15bcd33d1b3e536c3ccfe	deciding the sequentiality of a finitely ambiguous max-plus automaton	secuencial;sequential;hierarchized structure;automata estado finito;language theory;structure hierarchisee;teoria lenguaje;semianneau;weighted automata;sequentiel;semiring;finite automata;ambiguity;decidibilidad;finite automaton;automate fini;decidabilite;ambiguedad;estructura jerarquizada;theorie langage;ambiguite;decidability;automate pondere	Finite automata with weights in the max-plus semiring are considered. The main result is: it is decidable in an effective way whether a series that is recognized by a finitely ambiguous max-plus automaton is sequential. A collection of examples is given to illustrate the hierarchy of max-plus series with respect to ambiguity.	automaton	Ines Klimann;Sylvain Lombardy;Jean Mairesse;Christophe Prieur	2003		10.1007/3-540-45007-6_30	decidability;combinatorics;discrete mathematics;büchi automaton;computer science;philosophy of language;two-way deterministic finite automaton;semiring;deterministic automaton;mathematics;finite-state machine;algorithm;algebra	Logic	-3.2069360171350696	20.555933913966847	14400
1255b1e611c6413fe4b9a19430f798bf45fef106	a presentation of general multipersistence modules computable in polynomial time?		Multipersistence homology modules were introduced by G.Carlsson and A.Zomorodian [1] which gave, together with G.Singh [4], an algorithm to compute their Gröbner bases. Although their algorithm has polynomial complexity when the chain modules are free, i.e. in the one-critical case, it might be exponential in general. We give a new presentation of multipersistence homology modules, which allows us to design an algorithm to compute their Gröbner bases always in polynomial time by avoiding the mapping telescope. Mathematics Subject Classification (2010): 55U99, 55N99, 13P10.	algorithm;computable function;gröbner basis;homology (biology);mathematics subject classification;polynomial;time complexity	Antonio Patriarca;Martina Scolamiero;Francesco Vaccarino	2012	CoRR			Theory	43.56657431439332	32.75892868801475	14404
0fd45bdb30a71bdd6243327f003ca883f6f8774c	quantification and analysis of interdependency in cyber-physical systems	computers;topology;smart grid real time embedded systems cyber infrastructure cyber physical system analytic network process inspired method failure sequence identification graph theoretical representation functional dependencies ieee 14 bus power system;measurement;cyber physical systems;smart power grids cyber physical systems failure analysis graph theory power engineering computing;smart grids;eee 14 bus system cyber physical system interdependency smart grid;mathematical model;smart grids mathematical model topology measurement computers cyber physical systems	Cyber-physical systems are differentiated from other real-time embedded systems based on the tight intertwining of the cyber infrastructure with the physical components upon which it exerts control. This close interaction manifests as interdependence in operation and failure. This paper aims to determine and quantify the type and extent of dependency in a cyber-physical system using a method inspired by the analytic network process. The method incorporates several steps, namely, identification of failures sequences, and graph-theoretical representation of functional dependencies between components, and finally, calculating dependency indices. We illustrate the proposed approach through application to the IEEE 14-bus power system.	computer simulation;cyber-physical system;embedded system;functional dependency;graph theory;interdependence;real-time clock;reliability engineering;software propagation;synergy;whole earth 'lectronic link	Koosha Marashi;Sahra Sedigh Sarvestani;Ali R. Hurson	2016	2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshop (DSN-W)	10.1109/DSN-W.2016.47	real-time computing;computer science;theoretical computer science;operating system;mathematical model;distributed computing;smart grid;cyber-physical system;computer security;measurement;statistics;computer network	Embedded	-3.2958692308498025	7.627950571051834	14416
4cc84dd76e8f2d679853ec38f3d3028688a75cc0	the classical/linear hanoi hybrid problem: regular configurations	analysis of algorithm;analysis of algorithms;recursion;towers of hanoi	"""We continue our study, begun in [3], of the classical/linear Towers of Hanoi """"hybrid"""" problem, in which there are three pegs arranged in a row, and the rules governing ring movement depend on ring color. Whereas [3] dealt with perfect to perfect configuration problems in a very straightforward manner, the current paper discusses deterministic and dynamic algorithms for regular to regular problems, which turn out to be far more complicated than perhaps might be expected."""	deterministic algorithm;dynamic problem (algorithms);regular expression;tower of hanoi	Steven Minsker	2009	SIGCSE Bulletin	10.1145/1709424.1709446	recursion;computer science;analysis of algorithms;algorithm	Theory	0.24472686463290355	23.069962813159748	14430
a0fbbdd108c87f87c0ca8ea70f043f4688d7ba24	complexity of symbolic and numerical problems (dagstuhl seminar 15242)	004;symbolic computation algorithms in real algebraic geometry complexity lower bounds geometry of numerical algorithms	This report documents the program and the outcomes of Dagstuhl Seminar 15242 rnComplexity of Symbolic and Numerical Problems.	numerical analysis	Peter Bürgisser;Felipe Cucker;Marek Karpinski;Nicolai Vorobjov	2015	Dagstuhl Reports	10.4230/DagRep.5.6.28	combinatorics;discrete mathematics;theoretical computer science;mathematics	HPC	49.624402572653636	35.82133549684382	14439
324426070c0032e4f1e9a04b634dd50700760d4d	optimization with stochastic dominance constraints	optimality conditions;stochastic dominance;duality;91b06;60e15;90c15;partial orders;90c46;stochastic programming;46n10;90c48	We introduce stochastic optimization problems involving stochastic dominance constraints. We develop necessary and sufficient conditions of optimality and duality theory for these models and show that the Lagrange multipliers corresponding to dominance constraints are concave nondecreasing utility functions. The models and results are illustrated on a portfolio optimization problem.	concave function;constraint (mathematics);lagrange multiplier;mathematical optimization;optimization problem;program optimization;stochastic optimization	Darinka Dentcheva;Andrzej Ruszczynski	2003	SIAM Journal on Optimization	10.1137/S1052623402420528	stochastic programming;mathematical optimization;duality;continuous-time stochastic process;stochastic dominance;stochastic optimization;mathematics;mathematical economics	ML	35.861728914288975	4.832381729731357	14464
5b7965e50faafcd86dca11c409ddf21660fe3c11	fpga implementation of energy efficient multiplication over gf(2m) for ecc	fpga ecc multiplication itmia;public key cryptography digital arithmetic field programmable gate arrays power aware computing;fpga implementation nist recommended binary field xilinx virtex 6 fpga implementation kma iterative karatsuba offman multiplication algorithm modular squaring operations modular multiplication multiplicative inverse inversion operation point addition operations point doubling scalar point multiplication hardware implementation modular multiplicative rsa elliptic curve cryptography skc symmetric key cryptography pkc public key cryptography ecc energy efficient multiplication;polynomials elliptic curve cryptography hardware elliptic curves logic gates algorithm design and analysis	Public key cryptography (PKC) is highly secure against threats compared to symmetric key cryptography (SKC). One of the PKC techniques, Elliptic curve cryptography has been gaining wider attention as compared to the popular RSA due to its lesser key size requirements in order to provide a similar security level. This paper details the hardware implementation modular multiplicative over binary field GF(2m). Efficient scalar point multiplication is a crucial part in elliptic curve cryptography. A scalar point multiplication consists of point doubling and point addition operations. Both of these operations inherently depend on addition, multiplication, squaring and inversion. Among these, the inversion operation is the most time consuming one. The computation of multiplicative inverse primarily consists of modular multiplication and modular squaring operations. This paper proposes an efficient scalar multiplication using iterative Karatsuba-Offman multiplication algorithm (KMA) over GF(2m). The performance comparison is based on the Xilinx Virtex-6 FPGA implementation for the NIST recommended binary field.	computation;ecc memory;elliptic curve cryptography;field-programmable gate array;iterative method;key size;mike lesser;multiplication algorithm;numerical integration;pkc (conference);period-doubling bifurcation;public-key cryptography;requirement;symmetric-key algorithm	Ravi Kishore Kodali;Lakshmi Boppana	2014	2014 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2014.6968425	arithmetic;parallel computing;multiplication algorithm;kochanski multiplication;elliptic curve digital signature algorithm;theoretical computer science;mathematics;elliptic curve cryptography	Crypto	9.53802516011379	43.88867225969627	14478
1b2bc1f8129d495a433752d509ba1724bfa11e92	a combinatorial theorem on p-power-free words and an application to semigroups		Some combinatorial properties of infinité words having a subword complexity which is linearly upper-bounded are considered. The main resuit is a theorem giving a characterization of infinité words having a linear subword complexity in terms of the number of complétions of the factors which do not contain multiple overlaps. An interesting application of this theorem is that the monoid of the factors of an infinité p-overlap-free word is weakly-permutable. This generalizes previous results obtained by Restivo and the authorsfor the Fibonacd and the Thue-Morse monoids respectively. Résumé. — On considère certaines propriétés combinatoires des mots infinis ayant une croissance linéaire du nombre des facteurs. Le résultat principal est un théorème caractérisant les mots infinis possédant une croissance linéaire en termes de nombres de prolongements des facteurs qui ne contiennent pas de chevauchements multiples. Une application intéressante de ce théorème est que le monoïde des facteurs d'un mot infini sans chevauchement d'ordre p>0 possède la propriété de permutation faible. Ceci généralise les résultats précédents obtenus par Restivo et les auteurs pour les mots de Fibonacd et de Thue-Morse respectivement.	bibliothèque de l'école des chartes;large eddy simulation;linear algebra;sans institute;substring;thue–morse sequence	Aldo de Luca;Stefano Varricchio	1990	ITA		combinatorics;philosophy of language;calculus;mathematics;semigroup;algorithm;algebra	Crypto	37.319914620130476	37.67302778110905	14482
