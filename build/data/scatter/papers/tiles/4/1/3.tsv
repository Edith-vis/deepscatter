id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
5f5ace2fb042369dd231267ce6e41e02df3a3222	software-defined networking (sdn): layers and architecture terminology		Software-Defined Networking (SDN) refers to a new approach for network programmability, that is, the capacity to initialize, control, change, and manage network behavior dynamically via open interfaces. SDN emphasizes the role of software in running networks through the introduction of an abstraction for the data forwarding plane and, by doing so, separates it from the control plane. This separation allows faster innovation cycles at both planes as experience has already shown. However, there is increasing confusion as to what exactly SDN is, what the layer structure is in an SDN architecture, and how layers interface with each other. This document, a product of the IRTF Software-Defined Networking Research Group (SDNRG), addresses these questions and provides a concise reference for the SDN research community based on relevant peer-reviewed literature, the RFC series, and relevant documents by other standards organizations. Haleplidis, et al. Informational [Page 1] RFC 7426 (IRTF). Documents approved for publication by the IRSG are not a candidate for any level of Internet Standard; see Section 2 of RFC 5741. Information about the current status of this document, any errata, and how to provide feedback on it may be obtained at	control plane;forwarding plane;information retrieval specialist group;operand forwarding;software-defined networking	Evangelos Haleplidis;Kostas Pentikousis;Spyros G. Denazis;Jamal Hadi Salim;David Meyer;Odysseas G. Koufopavlou	2015	RFC	10.17487/RFC7426	computer science;distributed computing;world wide web;computer network	Networks	-24.436053515608926	89.68816631966534	5622
5d6a03b674a692d0dc9182af156809be7684fbfd	a secure and efficient multi-device and multi-service authentication protocol (semmap) for 3gpp-lte networks	protocols;authenticating servers secure multidevice efficient multidevice multiservice authentication protocol semmap 3gpp lte networks eap aka protocol mobile users performance analysis authentication vector;authentication;long term evolution;servers;3g mobile communication;protocols 3g mobile communication long term evolution;licenses;mobile communication;servers authentication protocols licenses delay mobile communication tin;tin	3GPP-LTE networks use the EAP-AKA protocol to authenticate and negotiate session keys with mobile users. However, with the popular trend of single user owning multiple devices and subscribing to multiple services, the EAP-AKA protocol appears inefficient because its authentication is device-oriented. In this paper, we propose a secure and efficient multi-device and multi-service authentication protocol, called SEMMAP, for 3GPP-LTE networks. SEMMAP makes use of a key hierarchy and an authority-issued license to enable an authenticating server to quickly verify the legitimacy of multiple devices belonging to the same mobile user and conduct a fast key negotiation between the server and the mobile user. Performance analysis shows that SEMMAP is more efficient than the current EAP-AKA protocol under the multi-device, multi-service scenario in terms of authentication delay and storage overhead for Authentication Vector (AV) at authenticating servers.	compaq lte;extensible authentication protocol;mobile device;overhead (computing);server (computing)	Jie Huang;Chin-Tser Huang	2012	2012 21st International Conference on Computer Communications and Networks (ICCCN)	10.1109/ICCCN.2012.6289229	data authentication algorithm;otway–rees protocol;communications protocol;ipsec;chip authentication program;mobile telephony;challenge–response authentication;tin;computer science;authentication protocol;operating system;lightweight extensible authentication protocol;authentication;internet privacy;protected extensible authentication protocol;ssliop;computer security;challenge-handshake authentication protocol;server;computer network	Mobile	-47.56475785095123	72.61240819694407	5643
66ca6ec0c9485078e0d64300450c1b9f9dfd9bb0	secure consolidation of charging information over smart grid using id federation	smart power grids computational complexity data privacy invoicing power engineering computing security of data;electricity power demand manganese power industry smart grids public key;charging information secure consolidation computational complexity security requirements consumer contract electric utility power consumption electricity bill current power system id federation smart grid	In the current power system, a bill for electricity used through an outlet is not charged to a consumer but to the manager of the outlet. This research presents schemes in which the bill for electricity is charged to the consumer. Even if a consumer uses outlets at outside the home, all bills for the power consumption at home and the outside are consolidated in an electric utility the consumer contracts with. In this paper, we define security requirements and evaluate that the proposed schemes satisfy the requirements. We suppose the privacy for consumer and the accuracy of billing as the security requirements and use an identity federation and digital signatures to satisfy the requirements. We propose a basic scheme first, and improve the efficiency of the scheme. We prove that the number of verifications and computational complexity are reduced in the improved scheme.	antivirus software;authentication;computational complexity theory;digital signature;electronic billing;federated identity;hash function;privacy;requirement;semiconductor consolidation	Hikaru Kishimoto;Shingo Okamura	2014	2014 International Symposium on Information Theory and its Applications		smart grid;computer security	Security	-44.96512811453357	66.57085018311646	5648
20d42a25e5a0cecfc96b1a0b7f4446ad48ea9914	providing differentiated service from an internet server	priority levels;performance evaluation;web and internet services;performance estimation;queueing theory;bandwidth allocation;differentiated service;response time;best effort;internet server;companies;server system;performance evaluation queueing theory internet bandwidth allocation telecommunication traffic quality of service;telecommunication traffic;network servers;web and internet services web server network servers scheduling delay bandwidth companies ip networks communication channels world wide web;internet;shortest queue first task assignment;high priority;scheduling;server system differentiated service internet server bandwidth allocation next generation internet near saturation high priority tasks quantitative performance estimation priority levels shortest queue first task assignment response time;high priority tasks;service differentiation;bandwidth;world wide web;ip networks;task assignment;near saturation;web server;quality of service;communication channels;quantitative performance estimation;next generation internet	Differentiated service has been proposed as a potential solution for bandwidth allocation and expected to be supported in the next generation Internet. However, a servi c differentiating Internet with best-effort servers may not meet the overall goals of the differentiated service. In this pap er, approaches and performance issues on providing differenti at d services from an Internet server are studied. Experimental study and analyses prove that under near-saturation of serv er utilization, differentiating service provides significan tly better performance to high priority tasks compared to a traditiona l service mode. Quantitative performance estimation of diff erent priority levels of tasks is presented. It is also observed th at an enhanced shortest queue first task assignment scheme helps i n decreasing the average response time of the server system.	best-effort delivery;diff utility;differentiated service;internet;next-generation network;response time (technology);server (computing)	Xiangping Chen;Prasant Mohapatra	1999		10.1109/ICCCN.1999.805520	best-effort delivery;service level requirement;real-time computing;the internet;quality of service;differentiated service;computer science;distributed computing;queueing theory;scheduling;response time;bandwidth;web server;computer network;bandwidth allocation;channel	Metrics	-6.04408848459745	95.15126520333911	5669
04191f58e1f433bbd3180f67aa709aca096acb57	efficient tweakable enciphering schemes from (block-wise) universal hash functions	block ciphering;hachage;tabla codificacion;cryptage bloc;cryptography output feedback polynomials privacy information security chromium statistics;disk encryption pseudorandom permutations strong pseudorandom permutation block cipher electronic codebook mode invertible blockwise universal hash function output feedback mode counter like mode polynomial;cle privee;blocage appel;probability density function;block cipher;radiation detectors;construction industry;modes of operations;counter like mode;polynomial;securite donnee;data mining;polynomials;output feedback;disk encryption;algorithme;algorithm;call blocking;hashing;clave privada;private key;tweakable encryption;bernstein polynomial;codebook;cryptography;table codage;electronic codebook mode;polynomials cryptography;cifrado en bloque;pseudorandom permutations;output feedback mode;invertible blockwise universal hash function;hash function;multiplicacion;multiplication;modes of operation;strong pseudorandom permutation;polinomio bernstein;polynome bernstein;tweakable encryption disk encryption modes of operations strong pseudorandom permutation;security of data;bloqueo llamada;algoritmo	This paper describes several constructions of tweakable strong pseudorandom permutations (SPRPs) built from different modes of operations of a block cipher and suitable universal hash functions. For the electronic codebook (ECB) mode based construction, an invertible blockwise universal hash function is required. We simplify an earlier construction of such a function described by Naor and Reingold. The other modes of operations considered are the output feedback (OFB) mode and a counter-like mode. All the constructions make the same number of block cipher calls and the same number of multiplications. Combined with a class of polynomials defined by Bernstein, the new constructions provide the currently best known algorithms for the important practical problem of disk encryption.	algorithm;block cipher mode of operation;codebook;cryptographic hash function;disk encryption;phil bernstein;polynomial;pseudorandomness;universal hashing	Palash Sarkar	2008	IEEE Transactions on Information Theory	10.1109/TIT.2009.2027487	double hashing;discrete mathematics;hash function;theoretical computer science;hash chain;mathematics;distributed computing;cryptographic hash function;statistics;polynomial;mdc-2	Crypto	-41.025009460620105	79.49459996544432	5680
b5ebf797e200e0a45f927e8ca455f7784153c89d	mhs use of the x.500 directory to support mhs routing		 This document specifies an approach for X.400 Message Handling Systemsto perform application level routing using the OSI Directory [18, 1].Use of the directory in this manner is fundamental to enabling large scaledeployment of X.400.This draft document will be submitted to the RFC editor as a protocol standard.Distribution of this memo is unlimited. Please send comments to theauthor or to the discussion group &lt;mhs-ds@mercury.udev.cdc.com&gt;.INTERNET--DRAFT MHS Routing using Directory... 	routing;x.500	Steve Kille	1995	RFC	10.17487/RFC1801	computer network;x.500;directory;computer science	EDA	-25.63072389625756	88.80263911753309	5686
a4f0574334f6318e089a861cccc688331cbce6bf	scheduling for a share of the machine	scheduling;priority;queues;deadline scheduling	Abstract#R##N##R##N#This paper describes the mechanism used to schedule jobs and control machine use on the IBM 370/165 at Cambridge University, England. The same algorithm is currently being used in part at the University of Bradford, and implementations are in progress at the Universities of Leeds, Salford and Liverpool for the ICL 1900 series machines. The mechanism relies on allocating a share of the machine to each user (or project), and then varying the turnround time for jobs according to whether the project in question is over- or under-using its share of the machine. The approach is believed to be an original one, having a number of advantages over more conventional scheduling and control algorithms.	schedule (project management)	J. Larmouth	1975	Softw., Pract. Exper.	10.1002/spe.4380050105	fair-share scheduling;real-time computing;earliest deadline first scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;programming language;operations research;scheduling;queue	AI	-14.464043244275278	60.64341422246644	5690
84abaa97715fd3683f8b3155f4ba24a2d3c307df	exploring alternatives to scale ftt-se to large networks	protocols;complexity theory;communication systems;embedded systems;switches synchronization protocols logic gates scalability complexity theory real time systems;engineering and technology;protocols local area networks;teknik och teknologier;logic gates;synchronization;kommunikationssystem;scalability;inbaddad systemteknik;switches;logic gate;local area networks;protocol scalability ftt se flexible time triggered communication switched ethernet complex embedded systems time triggered communication methods event triggered communication methods;real time systems	Nowadays, most complex embedded systems follow a distributed approach in which a network interconnects potentially large numbers of nodes. One technology that is being increasingly used is switched Ethernet, but real-time variants of this protocol typically limit scalability. In this paper, we focus on the scalability of the Flexible Time Triggered communication over Switched Ethernet (FTT-SE), which has been proposed to support hard real-time applications in a flexible and predictable manner. Moreover, time-triggered and event-triggered communication methods are supported in this protocol. FTT-SE has already been explored and investigated for small scale networked applications. In this paper we address the protocol scalability and suggest three different solutions with a qualitative assessment.	electrical connection;embedded system;real-time clock;real-time computing;real-time locating system;scalability	Farahnaz Yekeh;Mostafa Pordel;Luis Fernando de Almeida;Moris Behnam;Paulo Portugal	2011	2011 6th IEEE International Symposium on Industrial and Embedded Systems	10.1109/SIES.2011.5953692	embedded system;real-time computing;logic gate;telecommunications;computer science;operating system;distributed computing;computer network	Embedded	-22.45865045349621	79.52847592723984	5695
68f4bb022c0ec38dcd28e808e5afbffd41f176b2	amdahl's law in the datacenter era: a market for fair processor allocation		We present a processor allocation framework that uses Amdahl's Law to model parallel performance and a market mechanism to allocate cores. First, we propose the Amdahl utility function and demonstrate its accuracy when modeling performance from processor core allocations. Second, we design a market based on Amdahl utility that optimizes users' bids for processors based on workload parallelizability. The framework uses entitlements to guarantee fairness yet outperforms existing proportional share algorithms.	algorithm;amdahl's law;central processing unit;data center;fairness measure;multi-core processor;utility	Seyed Majid Zahedi;Qiuyun Llull;Benjamin C. Lee	2018	2018 IEEE International Symposium on High Performance Computer Architecture (HPCA)	10.1109/HPCA.2018.00011	real-time computing;resource management;workload;market mechanism;parallel computing;task analysis;amdahl's law;computer science;multi-core processor;entitlement;server	Arch	-21.264554984312536	60.813791975410005	5715
41a0defc8d96c264390b22e3baf6b0c8eaaf0434	detecting distributed denial of service attack traffic at the agent machines	computer crime internet floods recruitment computer worms telecommunication traffic proposals monitoring web server multimedia communication;ddos attack;ddos;transport protocols;telecommunication traffic;internet;traffic monitoring internet security ddos;distributed denial of service;telecommunication security;transport protocols internet security of data telecommunication security telecommunication traffic;traffic monitoring;internet security;false positive;security of data;tcp connections distributed denial of service attack thwart agent machines financial losses defence mechanisms target server packet traffic rate monitoring	Due to financial losses caused by distributed denial of service (DDoS) attacks, most defence mechanisms have been deployed at the network where the target server is located. We believe this paradigm should change in order to tackle the DDoS threat in its basis: thwart agent machines participation in DDoS attacks. Our proposal consists of developing an agent to monitor the packet traffic rate (outgoing packets/incoming packets). Our first deployment is based upon characterizing TCP connections; normal TCP connections can be characterized by the ratio of the sent packets to the received packets from a given destination. Preliminary results have shown that the traffic ratio values usually present larger values at the beginning of the run when there are not enough packets to make a decision on whether or not traffic is legitimate. A low value for threshold allows for faster attack detection, but it also increases the number of false-positives	denial-of-service attack;false precision;network packet;programming paradigm;sensor;server (computing);software deployment	Vicky Laurens;Abdulmotaleb El-Saddik;Pulak Dhar;Vineet Srivastava	2006	2006 Canadian Conference on Electrical and Computer Engineering	10.1109/CCECE.2006.277826	trinoo;computer science;engineering;internet security;internet privacy;application layer ddos attack;computer security;denial-of-service attack;computer network	Metrics	-59.40167794041568	66.91753351329662	5723
6679638fe42f1229b8e81047447a5f82b0e71ba7	detecting malicious web servers with honeyclients	honeyclient;crawler;client side attacks;malicious website;0 day attack	Using malicious sites to launch attacks against client user applications is a growing threat in recent years. This led to emergence of new technologies to counter and detect attacks against end user. One of these technologies is honeyclient (aka client honeypot). Honeyclients crawl the Internet to find and identify web servers that exploit clientside vulnerabilities. In this paper, we address honeyclients by studying and analyzing low-interaction and highinteraction honeyclients. We introduce a comparison attributes to evaluate honeyclients by comparing between the two types. Moreover, we present techniques can be used by malicious websites to evade and fingerprint honeyclients, and we make recommendations to overcome these evasion techniques. By analyzing characteristics of honeyclients, we introduce factors to define and measure honeyclients	client honeypot;client-side;emergence;evasion (network security);fingerprint recognition;honeypot (computing);malware;web server	Mahmoud T. Qassrawi;Hongli Zhang	2011	JNW	10.4304/jnw.6.1.145-152	computer science;web crawler;internet privacy;zero-day attack;world wide web;computer security	Security	-56.757709679610755	62.744432421596855	5752
e1abea8d2c304d3604410b461c4bb188831b6861	one-out-of-many proofs: or how to leak a secret and spend a coin		We construct a 3-move public coin special honest verifier zero-knowledge proof, a so-called Sigma-protocol, for a list of commitments having at least one commitment that opens to 0. It is not required for the prover to know openings of the other commitments. The proof system is efficient, in particular in terms of communication requiring only the transmission of a logarithmic number of commitments. We use our proof system to instantiate both ring signatures and zerocoin, a novel mechanism for bitcoin privacy. We use our Sigma-protocol as a (linkable) ad-hoc group identification scheme where the users have public keys that are commitments and demonstrate knowledge of an opening for one of the commitments to unlinkably identify themselves (once) as belonging to the group. Applying the Fiat-Shamir transform on the group identification scheme gives rise to ring signatures, applying it to the linkable group identification scheme gives rise to zerocoin. Our ring signatures are very small compared to other ring signature schemes and we only assume the users’ secret keys to be the discrete logarithms of single group elements so the setup is quite realistic. Similarly, compared with the original zerocoin protocol we rely on a weak cryptographic assumption and do not require a trusted setup. A third application of our Sigma protocol is an efficient proof of membership of a secret committed value u belonging to a public list L = {λ1, . . . , λN}.	antivirus software;bitcoin;cryptography;discrete logarithm;hoc (programming language);identification scheme;proof calculus;ring signature;type signature;zero-knowledge proof;zerocoin	Jens Groth;Markulf Kohlweiss	2014	IACR Cryptology ePrint Archive	10.1007/978-3-662-46803-6_9	computer science;theoretical computer science;ring signature;mathematical proof;gas meter prover;logarithm;zero-knowledge proof	Crypto	-39.063493956897595	74.92538375106473	5770
c5147fbe61fffefbfeb61937fd4e99b5317888af	fast computation method for privacy-preserving data aggregation protocol			computation;data aggregation	Yuan Jiangjun;Wang Jie	2018	IJWMC	10.1504/IJWMC.2018.10015854	computation;distributed computing;data aggregator;computer science	Robotics	-49.48203467770415	77.52227113027043	5790
edbc30f4fec1df7a647ba426ef10fee986d0d535	considerations on the osi reliable transfer service	reliable transfer service;osi reliable transfer service;reliability;open systems interconnection;information systems	The Reliable Transfer Service claims reliable transfer of an application protocol data unit (APDU) in an open systems interconnection environmenL In order to comply with this requirement, the service has to cope with crashes of different kinds and to compensate for them via recovery mechanisms. The main subjects of this paper are aspects of reliability, of Reliable Transfer Service as an information system, and of recovery, taking into account conditions of real open systems.	information system;interconnection;osi model;smart card application protocol data unit	Winfried Blumann;Dietmar Fauth;Heribert Zok	1990	Computer Communications	10.1016/0140-3664(90)90099-3	computer security;computer network	Metrics	-23.638438564059435	85.10389592431326	5795
030785a495a22bd319d67f1b7e2a24ef9cb3c337	net neutrality... seriously this time	protocols;standards;comcast;technology and society;distributed computing;comcast internet service provider internet neutrality internet communications protocol bittorrent gnutella peer to peer protocol lotus notes enterprise collaboration software traffic;internet neutrality;telecommunication traffic;telecommunication traffic internet peer to peer computing protocols;lotus notes enterprise collaboration software traffic;internet;technology and society internet net neutrality comcast bittorrent protocol blocking standards;network neutrality internet protocols collaborative software rhetoric government peer to peer computing history law legal factors;bittorrent;calculo repartido;bandwidth;communication protocol;communities;peer to peer computing;internet communications protocol;peer to peer;net neutrality;gnutella peer to peer protocol;comcast internet service provider;broadband communication;calcul reparti;protocol blocking	The net neutrality debate began a few years ago, prematurely, with overheated rhetoric about potential disasters for the Internet but little in the way of real threats requiring immediate government action. Beginning around May 2007, one of the largest ISPs in the US, Comcast, began a program of discriminatory blocking of certain Internet communications protocols. The blocking has focused on BitTorrent and Gnutella peer-to-peer protocols but also included, for a time, Lotus Notes enterprise collaboration software traffic. Comcast hasn't disputed the blocking, and a variety of independent, although perhaps not entirely unbiased, investigations have verified it. So, for the first time in the Internet's modern history, we have selective discrimination against a particular type of traffic that's widely used and presumptively legal.	bittorrent;blocking (computing);collaborative software;communications protocol;gnutella;ibm notes;internet;lotus 1-2-3;net neutrality;peer-to-peer	Daniel J. Weitzner	2008	IEEE Internet Computing	10.1109/MIC.2008.59	communications protocol;computer science;database;distributed computing;net neutrality;internet privacy;world wide web;computer security;computer network	Metrics	-56.770649313073214	66.7360114110036	5803
d57461a3c8c06c689298332a2d4550889618673e	addressing internet security vulnerabilities: a benchmarking study	internet security			A. Alayed;Steven Furnell;I. M. Barlow	2002			cloud computing security;web application security;common vulnerabilities and exposures;the internet;security through obscurity;security information and event management;security association;computer science;information security;internet security;security service;internet privacy;security analysis;secure coding;network security policy;computer security;computer network	Security	-49.26470152271377	61.63596773045371	5805
9871ff3a1a123b09a1fffd59e0aeb8cd99198468	a cost-effective criticality-aware virtual machine placement approach in clouds		Virtual Machine (VM) placement is a key issue for addressing problems improving resources utilization, increasing customer satisfaction, reducing implementation cost, minimizing power consumption. Existing works on availability-aware VM placement deal with VM allocation task based on taking VM resource demand as constraints. In this paper, we present a novel Cost-Effective Criticality-Aware VM Placement (CECAVMP) approach based on criticality feature of VM, which has not been considered in previous works. A critical server free capacity controlling method is proposed to make a trade-off between availability and cost. We simulated VM placement using CECAVMP and other compared algorithms in different scale clouds. The experimental results show that CECAVMP keeps cloud application in higher availability range without loss of VM request satisfaction.	self-organized criticality;virtual machine	Na Wu;De-Cheng Zuo;Zhan Zhang;Yan Zhao	2016		10.1007/978-3-319-49145-5_27	real-time computing;criticality;customer satisfaction;cloud computing;virtual machine;computer science	PL	-19.80269399711945	62.6109848878673	5856
47dd4785165de25c23f91c7de9bc0219438a9408	wormhole attack prevention using clustering and digital signatures in reactive routing	hop difference;cluster algorithm;routing protocols;pattern clustering;cluster;resource constraint;route discovery;centralized monitoring;routing;reactive routing;digital signatures;global position system;wormhole attack prevention;private key ad hoc networks wormhole cluster public key;ad hoc network;data packet routing;wormhole;infrastructure absence;telecommunication security ad hoc networks digital signatures pattern clustering radiotelemetry routing protocols telecommunication network topology;public key;radiotelemetry;open medium;private key;global positioning system;clustering;mobile ad hoc networks;digital signature;time difference;telecommunication security;wormhole nodes;dynamic network topology;routing algorithm;route topology information;clustering algorithms;ad hoc networks;mobile ad hoc network;global positioning system routing protocols routing public key clustering algorithms mobile ad hoc networks;routing protocol;telecommunication network topology;route discovery phase;time synchronisation;dynamic networks;resource constraints;hop difference wormhole attack prevention clustering digital signatures reactive routing open medium infrastructure absence dynamic network topology cooperative algorithms ad hoc networks resource constraints centralized monitoring route discovery phase route topology information time synchronisation data packet routing wormhole nodes time difference;cooperative algorithms	Owing to features of open medium, absence of infrastructure, dynamic network topology, cooperative algorithms, lack of centralized monitoring and resource constraints, ad hoc networks are vulnerable to many kinds of attacks, among which wormhole attack is chosen as the topic of discussion. This attack, when launched during route discovery phase can percolate wrong route/topology information into the network thereby, defeating the purpose of routing algorithms. In this paper we propose a novel technique based on clustering and digital signatures for prevention against wormhole attacks without use of special hardware, time synchronisation or dependency on time or hop difference between colluding nodes to identify attacked routes. We employ independent algorithms to form clusters and to implement intra-cluster and inter-cluster routing of data packets. Simulation Results show that the method achieved high level of efficiency in isolating wormhole nodes in the network.	algorithm;antivirus software;centralized computing;cluster analysis;computer cluster;data security;digital signature;high-level programming language;hoc (programming language);network packet;network topology;percolation;requirement;routing;simulation	Amarjit Malhotra;Deepti Bhardwaj;Ankush Garg	2012	Proceedings of 2012 9th IEEE International Conference on Networking, Sensing and Control	10.1109/ICNSC.2012.6204903	wireless ad hoc network;digital signature;mobile ad hoc network;computer science;distributed computing;public-key cryptography;routing protocol;cluster analysis;computer security;computer network	Mobile	-54.45376263376567	76.0458455462627	5870
60b1f7794e5989409030616cffd3818ef9dda6f7	on trees, chains and fast transactions in the blockchain		A fundamental open problem in the area of blockchain protocols is whether the Bitcoin protocol is the only solution for building a secure transaction ledger. A recently proposed and widely considered alternative is the GHOST protocol which, notably, was proposed to be at the core of Ethereum as well as other recent proposals for improved Bitcoin-like systems. The GHOST variant is touted as o ering superior performance compared to Bitcoin (potentially o ering block production speed up by a factor of more than 40) without a security loss. Motivated by this, in this work, we study from a provable security point of view the GHOST protocol. We introduce a new formal framework for the analysis of blockchain protocols that relies on trees (rather than chains) and we showcase the power of the framework by providing a uni ed description of the GHOST and Bitcoin protocols, the former of which we extract and formally describe. We then prove that GHOST implements a robust transaction ledger (i.e., possesses liveness and persistence) and hence it is a provably secure alternative to Bitcoin; moreover, our bound for the liveness parameter is superior to that proven for the bitcoin backbone in line with the original expectation for GHOST. Our proof follows a novel methodology for establishing that GHOST is a robust transaction ledger compared to previous works, which may be of independent interest and can be applicable to other blockchain variants.	bitcoin;ethereum;internet backbone;liveness;persistence (computer science);provable security;speedup	Aggelos Kiayias;Giorgos Panagiotakos	2016	IACR Cryptology ePrint Archive		blockchain;distributed computing;computer science	Crypto	-39.01584112750889	76.97740125676721	5900
f41024d73022b700a460311832064cdcb6649f11	turning small to big: efficient mobile advertisement propagation with local information		"""We investigate how to leverage limited local information for mobile advertisement popularization, where users are motivated to propagate advertisements with rewards or credits distributed from a centralized platform. Previous solutions on social networks failed to be applicable for mobile advertisement propagation because of the mobility, which would lead to extremely high overhead and low propagation efficiency. Participants need to be selected carefully and efficiently in dealing with the highly dynamic network and uncertain contacts among users. Even worse, the propagation effects are difficult to quantify with the increased number of mobile users. In tackling these difficulties, we propose <inline-formula> <tex-math notation=""""LaTeX"""">$\alpha $ </tex-math></inline-formula>MAP (<inline-formula> <tex-math notation=""""LaTeX"""">$\alpha $ </tex-math></inline-formula> here means efficient mobile advertisement popularization with local information), a lightweight but effective propagation user selection scheme with local information. Two key technologies inspire us to achieve efficient and effective mobile advertisement propagation. First, we advocate propagation effects instead of influence for user selection, where mobile users with strong information dissemination ability could be selected. Second, we use local information instead of the global information to achieve near optimal performance for propagation. In our proposed scheme, the information potentials proposed by Loukas <italic>et al.</italic> are leveraged to find the influential users with local information. With extensive experimental study, we find that <inline-formula> <tex-math notation=""""LaTeX"""">$\alpha $ </tex-math></inline-formula>MAP could effectively improve the mobile advertisements delivery ratio. Using the propagation instead of popularization is validated with different aspects of investigations when the budget is constrained. To evaluate the impact of mobility, we leverage the mobile trace data set for comprehensive evaluations. <inline-formula> <tex-math notation=""""LaTeX"""">$\alpha $ </tex-math></inline-formula>MAP performs fairly well when more realistic experimental settings are incorporated."""	centralized computing;experiment;map;overhead (computing);social network;software propagation;spectral efficiency	Wanru Xu;Panlong Yang;Maotian Zhang;Yiwei Xu	2017	IEEE Access	10.1109/ACCESS.2017.2728601	mobile database;leverage (finance);mobile search;distributed computing;computer network;dynamic network analysis;computer science;advertising;mobile technology;social network;mobile computing;mobile telephony	Mobile	-22.448220311569216	75.539159011895	5915
653f0c519a5f010a9227823082fae353f2c1f9f6	a new protocol for route discovery in multiple-ring networks. ii. multicast, recovery and high-speed processing	protocols;token networks telecommunication network routing protocols;red local;protocole transmission;route discovery;routing;mac protocol;ring network;source routing;telecommunication network;anneau;local network;protocolo transmision;controle acces support;telecommunication network routing;grande vitesse;media access control;red telecomunicacion;reseau telecommunication;token networks;gran velocidad;encaminamiento;multicast protocols intelligent networks bridges routing protocols media access protocol local area networks communication switching communications society computer science paper technology;high speed processing mac protocol route discovery multiple ring networks ftrd protocol multicast destination group independent recovery protocol source routing bridges feedback tree route discovery protocol;feedback tree route discovery protocol;ring;reseau local;high speed;anillo;acheminement;transmission protocol	A new MAC protocol for route discovery in multiple-ring network, called the ERD-protocol, has been presented in Part I. The present paper introduces some extensions of this protocol. The first extension indicates how the ERD-protocol can support multicast source routing, where a station seeks routes to multiple destinations. The ERD-protocol supplies the source with a description of a collection of routes. The route collection forms a tree that spans the source and the destination group. This leads to an important advantage of source routing multicasting over transparent spanning tree multicasting, since multicast data-frames are sent on part of the network rather than on the entire network. Another addition presents a recovery mechanism from transmission errors and station failures. Finally it is shown how the ERD-protocol can be applied in networks with very high speed rings, where bridges do not have sufficient time, after recognizing the route identity, to look in the local table and decide whether the relevant fields in the received frame need to be altered.	entity–relationship model;file spanning;multicast;ring network;source routing;spanning tree	Reuven Cohen;Adrian Segall	1994	IEEE Trans. Communications	10.1109/TCOMM.1994.580220	local area network;communications protocol;ring network;routing;source routing;media access control;telecommunications;computer science;distributed computing;ring;telecommunications network;computer network	Networks	-5.843446160910431	79.43084343725822	5923
28c1bbc188b3c6d67cf580a95be527b795bf1b50	handover optimization for host and network mobility	network mobility	Mobile IP and NEMO (network mobility) provide continuous connectivity to the Internet to a node or a mobile network when moving from one access router to another. Because of link switching delay and IP protocol operation, packets destined to mobile nodes or mobile networks can be delayed or lost during the handover period. This paper proposes solutions to improve the performance of handover in the context of Mobile IPv6 and NEMO. We introduce a new control entity for both MIPv6 and NEMO to manage the traffic between access routers and mobile nodes or mobile routers, to provide low-latency and low packet loss for real-time services during the handover.	attachments;entity;halt and catch fire;linux mint;mobile ip;network packet;physical review a;proxy mobile ipv6;quality of service;real-time clock;real-time transcription;router (computing);simulation;wireless access point	Hai Lin;Houda Labiod;Guozhi Wei;Anne Wei	2006			computer science	Mobile	-11.200274969178082	89.73228423471373	5949
5443863fec240a6ba2632a3044fc9cbd1397a51b	on expected constant-round protocols for byzantine agreement	point to point;secure computation;byzantine agreement;distributed computing;broadcast;signature scheme;cryptography;public key infrastructure	In a seminal paper, Feldman and Micali show an n-party Byzantine agreement protocol in the plain model that tolerates t		Jonathan Katz;Chiu-Yuen Koo	2009	J. Comput. Syst. Sci.	10.1016/j.jcss.2008.08.001	computer science;cryptography;quantum byzantine agreement;theoretical computer science;public key infrastructure;distributed computing;byzantine fault tolerance;computer security	Crypto	-42.269215982154	76.4547554213862	6003
0fadd82f79e4d885ec4cf735fda9ca63654382ac	fast emergency paths schema to overcome transient link failures in ospf routing	network protocols;ospf	A reliable network infrastructure must be able to sustain traffic flows, even when a failure occurs and changes the network topology. During the occurrence of a failure, routing protocols, like OSPF, take from hundreds of milliseconds to various seconds in order to converge. During this convergence period, packets might traverse a longer path or even a loop. An even worse transient behaviour is that packets are dropped even though destinations are reachable. In this context, this paper describes a proactive fast rerouting approach, named Fast Emergency Paths Schema (FEP-S), to overcome problems originating from transient link failures in OSPF routing. Extensive experiments were done using several network topologies with different dimensionality degrees. Results show that the recovery paths, obtained by FEPS, are shorter than those from other rerouting approaches and can improve the network reliability by reducing the packet loss rate during the routing protocols convergence caused by a failure.	algorithm;ar (unix);converge;equal-cost multi-path routing;experiment;network interface;network packet;network topology;radio frequency;router (computing);shortest path problem;traverse	Fernando Barreto;Emílio C. G. Wille;Luiz Nacamura	2012	CoRR	10.5121/ijcnc.2012.4202	real-time computing;convergence;distributed computing;computer network	Networks	-8.782938286836208	79.97083631742522	6055
f23e26075d9b24e8e4e092d853cfa0bccd1cbf8e	toward practical private access to data centers via parallel oram		Recent events have shown online service providers the perils of possessing private information about users. Encrypting data mitigates but does not eliminate this threat: the pattern of data accesses still reveals information. Thus, we present Shroud, a general storage system that hides data access patterns from the servers running it, protecting user privacy. Shroud functions as a virtual disk with a new privacy guarantee: the user can look up a block without revealing the block’s address. Such a virtual disk can be used for many purposes, including map lookup, microblog search, and social networking. Shroud aggressively targets hiding accesses among hundreds of terabytes of data. We achieve our goals by adapting oblivious RAM algorithms to enable large-scale parallelization. Specifically, we show, via new techniques such as oblivious aggregation, how to securely use many inexpensive secure coprocessors acting in parallel to improve request latency. Our evaluation combines large-scale emulation with an implementation on secure coprocessors and suggests that these adaptations bring private data access closer to practicality.	algorithm;computer data storage;coprocessor;data access;disk image;emulator;encryption;information privacy;lookup table;oblivious ram;online service provider;parallel computing;personally identifiable information;random-access memory;secure cryptoprocessor;social network aggregation;terabyte	Jacob R. Lorch;James W. Mickens;Bryan Parno;Mariana Raykova;Joshua Schiffman	2012	IACR Cryptology ePrint Archive			OS	-40.672932924585226	66.4719208502114	6058
24c16ffc99616a256580e37b5b3d09ab902f4314	the progress of tactical radios from legacy systems to cognitive radios	broadband networks;ip networks cognitive radio military communication tutorials time division multiple access radio communication ports computers;military communication;jamming;tactical radio war theatre software based waveform u s department of defense program wideband networking waveform software defined radio link 16 system jamming resistance frequency hopping capability spread spectrum communication cognitive radio legacy radio system;software radio;spread spectrum communication;cognitive radio;waveform analysis broadband networks cognitive radio frequency hop communication jamming military communication software radio spread spectrum communication;waveform analysis;frequency hop communication	This article gives a tutorial about some critical milestones regarding the journey of tactical radios from legacy systems to cognitive radios. Although tactical radios have been in use for over 100 years, this tutorial focuses on the post- Vietnam War radios and uses examples from the U.S. Department of Defense major acquisition programs. The article considers legacy radios to be the generation of radios that was initiated by the U.S. Department of Defense in the 1970s that had spread-spectrum and frequency-hopping capabilities to resist jamming. The Link-16 system is covered in this article as a benchmark for legacy radios. Two major technological leaps came after these legacy radios. First was the software defined radios initiative, which brought about the ability to develop waveforms entirely in software in the absence of a defined hardware platform. As a result, different waveforms can be ported into the same hardware platform. This article presents the Wideband Networking Waveform, which is a complex waveform developed under a U.S. Department of Defense program, as a software-based waveform that can be downloaded into different hardware platforms. The next technological leap came with cognitive radios, which have the ability to sense their environments and adapt intelligently to the dynamics of the war theatre.	algorithm;benchmark (computing);cognitive radio;frequency-hopping spread spectrum;legacy system;radio jamming;waveform	George F. Elmasry	2013	IEEE Communications Magazine	10.1109/MCOM.2013.6619565	cognitive radio;telecommunications;computer science;software-defined radio;spread spectrum;computer security;computer network;broadband networks	Networks	-20.146739360970795	95.96757001084092	6060
972a74b620c7dcb2f8d34dce3d202d933d1089f3	parallel and distributed computing techniques, selection of papers from ispdc 2008		The workload on a cluster system can be highly variable, increasing the difficulty of balancing the load across its nodes. The general rule is that high variability leads to wrong load balancing decisions taken with out-of-date information and difficult to correct in real-time during applications execution. In this work the workload variability is studied from the perspective of the load balancing performance, focusing on the design of algorithms capable of dealing with this variability. In this paper an exhaustive analysis is presented to help users and administrators to understand if their load balancing mechanisms are sensitive to variability and to what degree. Furthermore, solutions to deal with variability in load balancing algorithms are proposed and their utilization is exemplified on a real load balancing algorithm.	algorithm;distributed computing;heart rate variability;load balancing (computing);real-time locating system;spatial variability	Marek Tudruj	2009	Scalable Computing: Practice and Experience		symmetric multiprocessor system;subroutine;virtualization;computational model;parallel random-access machine;load balancing (computing);server;data flow diagram;distributed computing;computer science	HPC	-17.22858390817506	60.95411048303261	6073
3c127d6171ae1ce9d0ae764eab4790993b019bdb	an energy-efficient source-anonymity protocol in surveillance systems	dynamic mix ring;degree of anonymity;source location anonymity;surveillance system;global attacker	Source-location privacy is a critical security property in event-surveillance systems. However, due to the characteristics of surveillance systems, e.g., resource constraints, diverse privacy requirements and large-scale network, the existing anonymity mechanisms cannot effectively deal with the problem of source-location privacy protection. There is an imbalance on network load and transmission latency for most of the existing anonymity schemes, which causes “funnel effect” and conflicts with anonymity. This paper proposes the dynamic optimal mix-ring-based source-location anonymity protocol, DORing. In this scheme, we first set the dynamic optimal mix-ring to collect and mix the network traffic, which can satisfy the diverse QoS requirements for all the packets. Secondly, we propose the sector-based anonymity assess to control the process of mixing in order to filter out the dummy packets and deliver the authentic packets to sink. Finally, the location of mix-ring is adjusted to balance network energy consumption, prolong the lifetime of the network and resist global attack. The simulation results demonstrate that DORing is very efficient in balancing energy consumption and transmission latency and can significantly prolong survival period of the network and ensure security as well as latency to satisfy the packets’ requirements.	dummy variable (statistics);network traffic control;quality of service;requirement;simulation;snoop	Xiaoguang Niu;Yihao Zhang;Yalan Yao;Xu Chen;Josep Miquel Jornet;Jin Liu	2016	Personal and Ubiquitous Computing	10.1007/s00779-016-0949-1	internet privacy;computer security;computer network	Security	-53.07882291812024	77.08224531978085	6117
ff4e7c7c68f8cc28a3bb2e6ed3612e205c7e7cba	practical two-dimensional correlation power analysis and its backward fault-tolerance		Side-channel analysis was introduced by Kocher et al. [1, 2] which marked the outbreak of this new research field in the applied cryptography area. Subsequently, many side-channel analysis methods have been published, for example, correlation power analysis (CPA) [3], template attack [4], collision attack [5,6], mutual information analysis [7] and so on, among which CPA is most widely applied in practical attacks.	collision attack;cryptography;fault tolerance;mutual information;side-channel attack	An Wang;Wenjing Hu;Weina Tian;Guoshuang Zhang;Liehuang Zhu	2016	Science China Information Sciences	10.1007/s11432-016-0398-y	power analysis;mathematical optimization;control theory;fault tolerance;mathematics;correlation	Crypto	-42.45921308495428	81.2213090775099	6165
092747c0b441b7e61b577751abd783d8efba12ca	enhancing grid security using trusted virtualization	grid applications;trusted computing;security requirements;grid computing;grid security	Grid applications have increasingly sophisticated functi onal and security requirements. However, current techniques mostly protect only the resource provid er from attacks by the user, while leaving the user comparatively dependent on the well-behavior of the resour ce p ovider. In this paper, we take the first steps towards addressing the t rust asymmetry by using a combination of trusted computing and virtualization technologies. We present the key components for a trustworthy Grid architecture and propose an implementation. By providing multilateral s ecurity, i.e., security for both the Grid user and the Grid provider, our architecture increases the confidence th at can be placed on the correctness of a Grid computation and on the protection of user-provided assets. In ord er to maintain important scalability and performance aspects, our proposal aims to minimize overhead. Towards th is end, we propose a scalable offline attestation protocol, which allows selection of partners in the Grid wit h minimal overhead.		Hans Löhr;HariGovind V. Ramasamy;Ahmad-Reza Sadeghi;Stefan Schulz;Matthias Schunter;Christian Stüble	2007		10.1007/978-3-540-73547-2_39	semantic grid;computer science;data grid;distributed computing;trustworthy computing;world wide web;computer security;drmaa;grid computing	HPC	-43.26091387360963	68.88946780625986	6180
aef4d9be180edb3e92ae5ff5f1326525da373133	space efficient elephant flow detection		Identifying the large flows in terms of byte volume, known as elephant flows, is a fundamental capability that many network algorithms require. While optimal solutions that find the largest flows in terms of packet-count are known [5], constant update time algorithms for byte-volume were only recently discovered [1, 2]. Here, we propose an improved variant of the DIMSUM algorithm [2] that reduces the space requirement by 50% while allowing O(1) update time.	byte;elephant flow;genetic algorithm;network packet	Ran Ben-Basat;Gil Einziger;Roy Friedman	2018		10.1145/3211890.3211919	parallel computing;elephant flow;byte;computer science	Theory	-12.554944817805842	80.55472001226364	6188
ae3612df0ffb4870e043e8da7035fb5c4a3fce23	coding for a believable specification to implementation mapping	authentication;semantics;specification languages;data structures;cryptography;optimization;encoding;semantics data structures cryptography optimization authentication encoding specification languages	"""Abstract: One criterion for """"Beyond Al"""" certification according to the DoD Trusted Computer Systems Evaluation Criteria will be code-level verification. We argue that, while verification at the actual code level may be infeasible for large secure systems, it is possible to push the verification to a low level of abstraction and then map the specification in an intuitive manner to the source code. Providing a suitable mapping requires adhering to a strict discipline on both the specification and code sides. We discuss the issues involved in this problem, particularizing the discussion to a mapping from Gypsy specifications to C code."""	hardware description language;trusted computer system evaluation criteria	William D. Young;John McHugh	1987	1987 IEEE Symposium on Security and Privacy	10.1109/SP.1987.10003	computer science;cryptography;theoretical computer science;operating system;authentication;database;semantics;programming language;computer security;encoding	Security	-35.14946826245251	74.09965936760085	6194
cbe2fba2da2ade35d23189e5f039ba972b8ecbe1	secure multi-hop routing protocols in wireless sensor networks: requirements, challenges and solutions	wireless sensor networks routing protocols telecommunication security;routing protocols;wireless sensor networks routing routing protocols security energy efficiency bandwidth;multihop wsn secure multihop routing protocols wireless sensor networks data gathering sensing activities sink node relay nodes confidential information sensor nodes network lifetime secure energy efficient route discovery forwarding mechanisms energy aware secure routing resource constraints security threats trust based energy efficient secure routing protocol teesr;telecommunication security;teesr wsn multi trust secure routing insens seer;wireless sensor networks	Wireless Sensor Networks (WSNs) have been a subject of extensive research and have undergone explosive growth in the last few years. WSNs utilize collaborative measures such as data gathering, aggregation, processing, and management of sensing activities for enhanced performance. In order to communicate with the sink node, node having low power may have to traverse multi-hops. This requires neighbors' nodes to be used as relays. However, if the relay nodes are compromised or malicious, they may leak confidential information to unauthorized nodes in the WSN. Moreover, in many WSN applications, the deployment of sensor nodes is carried out in an ad-hoc fashion without careful examination. In such networks it is desirable to ensure the source to sink privacy and maximize the lifetime of the network, by finding secure energy-efficient route discovery and forwarding mechanisms. Careful management is also necessary, as processing required for secure routing is distributed over multiple nodes. An important consideration in this regard is energy-aware secure routing, which is significant in ensuring smooth operation of WSNs. As, these networks deal in sensitive data and are vulnerable to attack, it is important to make them secure against various types of threats. However, resource constraints could make the design, deployment and management of large WSNs a challenging proposition. The purpose of this paper is to highlight routing based security threats, provide a detailed assessment of existing solutions and present a Trust-based Energy Efficient Secure Routing Protocol (TEESR). The paper also highlights future research directions in of secure routing in multi-hop WSNs.	authorization;confidentiality;hoc (programming language);malware;privacy;relay;routing;software deployment;traverse;threat (computer)	Nouman M. Durrani;Nadeem Kafi Khan;Jawwad Shamsi;Waleej Haider;Asad M. Abbsi	2013	Eighth International Conference on Digital Information Management (ICDIM 2013)	10.1109/ICDIM.2013.6694001	policy-based routing;wireless routing protocol;routing table;routing domain;optimized link state routing protocol;routing;enhanced interior gateway routing protocol;static routing;wireless sensor network;zone routing protocol;equal-cost multi-path routing;computer science;interior gateway protocol;dynamic source routing;multipath routing;destination-sequenced distance vector routing;distributed computing;key distribution in wireless sensor networks;routing protocol;link-state routing protocol;mobile wireless sensor network;computer security;geographic routing;routing information protocol;computer network	Mobile	-52.27974145312461	76.10823705447942	6196
0e4af03d7379603014d1bdab34cd4801f37f8e4a	vconf: a reinforcement learning approach to virtual machines auto-configuration	configural processing;virtual machine;resource allocation;reinforcement learning;virtual machines;system management;autonomic computing;cloud computing	Virtual machine (VM) technology enables multiple VMs to share resources on the same host. Resources allocated to the VMs should be re-configured dynamically in response to the change of application demands or resource supply. Because VM execution involves privileged domain and VM monitor, this causes uncertainties in VMs' resource to performance mapping and poses challenges in online determination of appropriate VM configurations. In this paper, we propose a reinforcement learning (RL) based approach, namely VCONF, to automate the VM configuration process. VCONF employs model-based RL algorithms to address the scalability and adaptability issues in applying RL in systems management. Experimental results on both controlled environments and a testbed of clouds with Xen VMs and representative server workloads demonstrate the effectiveness of VCONF. The approach is able to find optimal (near optimal) configurations in small scale systems and shows good adaptability and scalability.	algorithm;auto-configuration;cpu cache;central processing unit;centralized computing;cloud computing;ibm notes;iteration;openvms;reinforcement learning;scalability;server (computing);state space;systems management;testbed;virtual machine	Jia Rao;Xiangping Bu;Cheng-Zhong Xu;Le Yi Wang;Gang George Yin	2009		10.1145/1555228.1555263	real-time computing;computer science;virtual machine;operating system;database;distributed computing;reinforcement learning;autonomic computing	HPC	-22.899338189350164	61.75301971801199	6205
5c5fd20b1263f26a6a2b46feca55fad8e3512b11	a channel configuration problem for access-point communications in wireless mesh networks	access network;wireless channels;network interface card;access point;channel assignments channel configuration problem access point communications wireless mesh networks large scale access network internet multihop wireless connections wireless distribution system;wireless distribution system;wireless mesh network;large scale;telecommunication traffic;telecommunication network routing;wireless mesh networks ip networks internet wireless communication access protocols telecommunication traffic wireless lan heuristic algorithms bridges network interfaces;wireless channels telecommunication network routing telecommunication traffic;heuristic algorithm;channel assignment	For a flexible and inexpensive large-scale access network to the Internet, we have studied the wireless mesh network composed of access points (APs) as wireless routers. Each AP has multihop wireless connections with the others by the wireless distribution system (WDS). In this network, communications around Internet gateways are usually very crowded and become the bottleneck of performance, because most traffic go through there for access to the Internet. To avoid this problem, the proper channel configurations of APs concerning multiple network interface cards (NICs) and their channel assignments are essential, where for the given network and traffics, the throughput should be maximized while the cost for channel configurations be minimized. In this paper, we formulate this channel configuration problem for AP communications in the wireless mesh network, and present its two-stage heuristic algorithm. The effectiveness of our approach is verified through extensive simulations.	access network;algorithm;heuristic (computer science);internet;mesh networking;network interface controller;remote desktop services;simulation;throughput;wireless access point;wireless mesh network;wireless router	Nobuo Funabiki;Toru Nakanishi;Walaa Hassan;Kanako Uemura	2007	2007 15th IEEE International Conference on Networks	10.1109/ICON.2007.4444093	wireless mesh network;heuristic;wireless ad hoc network;service set;wi-fi;wireless wan;heterogeneous network;wireless site survey;telecommunications;computer science;wireless network;distributed computing;order one network protocol;wireless distribution system;wireless lan controller;key distribution in wireless sensor networks;base transceiver station;network interface controller;municipal wireless network;wi-fi array;rogue access point;fixed wireless;hidden node problem;computer network;access network;network access device	Mobile	-4.547742440074015	82.74843832277296	6215
2234308e73f21fcd533d20a99f8cc39a60702e7d	adaptive frame synchronization for surveillance system across a heterogeneous network	surveillance system;playback liveness;heterogeneous network;frame synchronization	As mobile techniques are booming, the surveillance function is extended from a stationary mode to a mobile mode. In a heterogeneous network environment, cameras and viewers are located in different networks so that frame synchronization may span across diverse network domains with different transmission capabilities. The mismatch of transmission capabilities may affect the viewing continuity and playback liveness between cameras and viewers. In the article, we propose an adaptive frame synchronization mechanism for frame capturing at cameras based on the network condition to improve the frame synchronization between two sides across a heterogeneous network. Based on a brief theoretical analysis of the asynchronization effect for video communication in a heterogeneous network environment, the proposed adaptive pause time mechanism can be an effective solution to relieve the asynchronization effect in the unmatched transmission rate situation. The evaluation results show that the proposed scheme can achieve a shorter time delay between the captured frames at the camera site and the viewer site.	synchronization (computer science)	Jenq-Shiou Leu;Wei-Hsiang Lin;Hung-Jie Tzeng;Chi-Feng Chen;Mu-Sheng Lin	2012	Eng. Appl. of AI	10.1016/j.engappai.2012.02.001	frame;embedded system;real-time computing;simulation;heterogeneous network;frame synchronization;computer science;frame synchronization	AI	-7.8991140899762415	105.65607766015499	6237
20abea7156104c815aed6584a4d039dcafbc34f6	svm-based detection of ad hoc flooding attacks	disaster recovery;support vector machines svm based detection ad hoc flooding attacks ad hoc networks tactical operations disaster recovery operations wired networks denial of service eavesdropping spoofing dos attacks intrusion detection model;wireless networks;support vector machines;wireless network;telecommunication computing;dynamic system;computer crime;intrusion detection;telecommunication security ad hoc networks security of data support vector machines telecommunication computing;ad hoc network;mobile ad hoc networks;denial of service;telecommunication security;ad hoc networks;mobile ad hoc network;mobility pattern;support vector machine;intrusion detection conferences computer crime support vector machines mobile ad hoc networks wireless networks;security of data;conferences;dos attack	In recent years ad hoc networks have become very attractive for many applications such as tactical and disaster recovery operations. However they are vulnerable to many attacks. The vulnerabilities of wired networks such as denial of service (DoS), eavesdropping, spoofing and the like, becomes more acute in these networks. Especially it is hard to differentiate DoS attacks in these highly dynamic systems. In this research, we design an intrusion detection model using Support Vector Machines (SVM) in order to detect a popular DoS attack on these networks, namely ad hoc flooding attacks. We evaluate its performance on simulated networks with varying traffic and mobility patterns.	denial-of-service attack;disaster recovery;dynamical system;hoc (programming language);intrusion detection system;spoofing attack;support vector machine	Zeynep Dogmus;Sevil Sen	2012	2012 20th Signal Processing and Communications Applications Conference (SIU)	10.1109/SIU.2012.6204730	wireless ad hoc network;support vector machine;robust random early detection;mobile ad hoc network;computer science;wireless network;internet privacy;computer security;denial-of-service attack;disaster recovery;computer network	Mobile	-60.48841236968937	66.68124178208119	6288
6d029ed902a41392b887efc5263c632f105c020d	secure multi-party sorting and applications	datavetenskap datalogi;computer science	Sorting is among the most fundamental and well-studied problems within computer science and a core step of many algorithms. In this article, we consider the problem of constructing a secure multi-party computing (MPC) protocol for sorting, building on previous results in the field of sorting networks. Apart from the immediate uses for sorting, our protocol can be used as a building-block in more complex algorithms. We present a weighted set intersection algorithm, where each party inputs a set of weighted elements and the output consists of the input elements with their weights summed. As a practical example, we apply our protocols in a network security setting for aggregation of security incident reports from multiple reporters, specifically to detect stealthy port scans in a distributed but privacy preserving manner. Both sorting and weighted set intersection use O ` n log n ́ comparisons in O ` log n ́ rounds with practical constants. Our protocols can be built upon any secret sharing scheme supporting multiplication and addition. We have implemented and evaluated the performance of sorting on the Sharemind secure multi-party computation platform, demonstrating the real-world performance of our proposed protocols.	anomaly detection;computer science;intersection algorithm;intrusion detection system;mpc-mlq;network security;secret sharing;secure multi-party computation;sorting algorithm;sorting network;synaptic weight;time complexity	Kristján Valur Jónsson;Gunnar Kreitz;Misbah Uddin	2011	IACR Cryptology ePrint Archive		real time streaming protocol;computer science;internet privacy;world wide web;computer security;algorithm	Theory	-39.01212923955032	73.30972748458623	6313
a5366d1e0ab2ff7877a110fc30a2909269412061	characteristics of wap traffic	wap;self similarity;mobile data;network dimensioning;traffic modelling;electrical engineering electronics nuclear engineering	This paper considers the characteristics of WAP traffic. We start by constructing a model of WAP traffic based on a number of user scenarios. One traffic characteristic which is of particular interest in network dimensioning is the degree of self-similarity, so the paper looks at the characteristics of aggregated traffic with WAP, web and packet speech components to estimate its self-similarity. The results indicated that, while WAP traffic alone does not exhibit a significant degree of self-similarity, a combined load from various traffic sources retains almost the same degree of selfsimilarity as the most self-similar individual source.	network packet;scenario (computing);self-similarity	Irene C. Y. Ma;James Irvine	2004	Wireless Networks	10.1023/A:1026244914743	traffic generation model;mobile broadband;wireless application protocol;telecommunications;self-similarity;computer science;operating system;world wide web;computer network	Metrics	-12.294098571363705	97.67355298131471	6324
cc98157b70d7cf464b880668d7694edd12188157	an implementation of intrusion detection system using genetic algorithm		Nowadays it is very important to maintain a high level security to ensure safe and trusted communication of information between various organizations. But secured data communication over internet and any other network is always under threat of intrusions and misuses. So Intrusion Detection Systems have become a needful component in terms of computer and network security. There are various approaches being utilized in intrusion detections, but unfortunately any of the systems so far is not completely flawless. So, the quest of betterment continues. In this progression, here we present an Intrusion Detection System (IDS), by applying genetic algorithm (GA) to efficiently detect various types of network intrusions. Parameters and evolution processes for GA are discussed in details and implemented. This approach uses evolution theory to information evolution in order to filter the traffic data and thus reduce the complexity. To implement and measure the performance of our system we used the KDD99 benchmark dataset and obtained reasonable detection rate.	benchmark (computing);color gradient;fitness function;genetic algorithm;heuristic;high-level programming language;intrusion detection system;network security;sensor;software release life cycle;trusted operating system	Mohammad Sazzadul Hoque;Md. Abdul Mukit;Md. Abu Naser Bikas	2012	CoRR	10.5121/ijnsa.2012.4208	anomaly-based intrusion detection system;intrusion detection system;computer science;data mining;distributed computing;computer security;intrusion prevention system	Security	-62.14341984178639	64.33395406813635	6328
40e4f15cb8cd35df580a4e8b27900cfccdce36ec	dynamic reconstruction of multiple overlay network for next generation network services with distributed components	next generation network;simulation experiment;overlay network;network services	Because of rapid improvement in information and network technologies, many kinds of network services are created. In this paper, the concept of a new service platform is presented. Services are organized by components, and replications of components are distributed to many computers. Thanks to these replications, users can continue services by using another component as a substitute in case of failure. It is necessary to ask another component to fnd a substitute when a component fails. However, depending on which component to ask, the original version of the proposed method has a possibility to find only low-performance components. It is caused by constructing overlay network only once and keeping it as it is. We propose a new dynamic reconstruction method for overlay networks. Simulation experiments show how proposed method improves performance of our framework.	distributed element model;next-generation network;overlay network	Naosuke Yokoe;Wataru Miyazaki;Kazuhiko Kinoshita;Hideki Tode;Koso Murakami;Shinji Kikuchi;Satoshi Tsuchiya;Atsuji Sekiguchi;Tsuneo Katsuyama	2009		10.1007/978-3-642-04492-2_58	intelligent computer network;overlay network;network architecture;next-generation network;network formation;computer science;network simulation;distributed computing;world wide web;computer security;computer network	Networks	-17.2216116060717	81.65773001070998	6346
62bd51f26e97de21055e127b6bfef2bca7b12459	online aggregation of the forwarding information base: accounting for locality and churn	ip networks;algorithm design and analysis;switches;image color analysis;ports (computers);memory management	This paper studies the problem of compressing the forwarding information base FIB, but taking a wider perspective. Indeed, FIB compression goes beyond sheer compression, as the gain in memory use obtained from the compression has consequences on the updates that will have to be applied to the compressed FIB. We are interested in the situation where forwarding rules can change over time, e.g., due to border gateway protocol BGP route updates. Accordingly, we frame FIB compression as an online problem and design competitive online algorithms to solve it. In contrast to prior work which mostly focused on static optimizations, we study an online variant of the problem where routes can change over time and where the number of updates to the FIB is taken into account explicitly. The reason to consider this version of the problem is that leveraging temporal locality while accounting for the number of FIB updates helps to keep routers CPU load low and reduces the number of FIB updates to be transferred, e.g., from the network-attached software-defined network controller to a remote switch. This paper introduces a formal model which is an interesting generalization of several classic online aggregation problems. Our main contribution is an Ow-competitive algorithm, where ${w}$ is the length of an IP address. We also derive a lower bound which shows that our result is asymptotically optimal within a natural class of algorithms, based on so-called sticks.	asymptotically optimal algorithm;benchmark (computing);border gateway protocol;central processing unit;competitive analysis (online algorithm);firmware;locality of reference;model of computation;network interface controller;network packet;network switch;online aggregation;online algorithm;online and offline;p (complexity);polynomial;requirement;software-defined networking	Marcin Bienkowski;Nadi Sarrar;Stefan Schmid;Steve Uhlig	2018	IEEE/ACM Transactions on Networking	10.1109/TNET.2017.2787419	asymptotically optimal algorithm;locality of reference;online algorithm;online aggregation;distributed computing;computer science;accounting;memory management;algorithm design;border gateway protocol;forwarding information base	Metrics	-14.041319457865455	79.91467333712906	6368
46e30d669f7e19374a5da162784a1d4ae2e5182c	outsourcing private machine learning via lightweight secure arithmetic computation		In several settings of practical interest, two parties seek to collaboratively perform inference on their private data using a public machine learning model. For instance, several hospitals might wish to share patient medical records for enhanced diagnostics and disease prediction, but may not be able to share data in the clear because of privacy concerns. In this work, we propose an actively secure protocol for outsourcing secure and private machine learning computations. Recent works on the problem have mainly focused on passively secure protocols, whose security holds against passive (“semi-honest”) parties but may completely break down in the presence of active (“malicious”) parties who can deviate from the protocol. Secure neural networks based classification algorithms can be an seen as an instantiation of an arithmetic computation over integers. We showcase the efficiency of our protocol by applying it to real-world instances of arithmetized neural network computations, including a network trained to perform collaborative disease prediction.		Siddharth Garg;Zahra Ghodsi;Carmit Hazay;Yuval Ishai;Antonio Marcedone;Muthuramakrishnan Venkitasubramaniam	2018	CoRR			Security	-37.10372574023437	65.55620857527732	6375
4444a10ae35395d146ede23584abe495556a6ba7	asymmetric communication protocols via hotlink assignments	assignment problem;asynchronous communication;communication protocol;performance bounds	We exhibit a relationship between the asymmetric communication problem of Adler and Maggs and the hotlink assignment problem of Bose et al. By generalizing previous results on the hotlink problem and then exploiting this relationship we present a new asymmetric communication protocol with different performance bounds than previous protocols.	assignment problem;binary tree;communications protocol;inline linking;server (computing);trie	Prosenjit Bose;Danny Krizanc;Stefan Langerman;Pat Morin	2002	Theory of Computing Systems	10.1007/s00224-003-1126-2	communications protocol;computer science;theoretical computer science;asynchronous communication;mathematics;distributed computing;assignment problem	Theory	-13.435096194884975	65.82715701438674	6384
a7854fac418fade1531a243f433a4cb482a8615f	high-definition video streams analysis, modeling, and prediction		High-definition video streams’ unique statistical characteristics and their high bandwidth requirements are considered to be a challenge in both network scheduling and resource allocation fields. In this paper, we introduce an innovative way to model and predict high-definition (HD) video traces encoded with H.264/AVC encoding standard. Our results are based on our compilation of over 50 HD video traces. We show that our model, simplified seasonal ARIMA (SAM), provides an accurate representation for HD videos, and it provides significant improvements in prediction accuracy. Such accuracy is vital to provide better dynamic resource allocation for video traffic. In addition, we provide a statistical analysis of HD videos, including both factor and cluster analysis to support a better understanding of video stream workload characteristics and their impact on network traffic. We discuss our methodology to collect and encode our collection of HD video traces. Our video collection, results, and tools are available for the research community.	akaike information criterion;ar (unix);autoregressive integrated moving average;cluster analysis;encode;factor analysis;h.264/mpeg-4 avc;hdmi;k-means clustering;mpeg-1;network packet;requirement;scheduling (computing);simulation;streaming media;tracing (software)	Abdel Karim Al Tamimi;Raj Jain;Chakchai So-In	2012	Adv. in MM	10.1155/2012/539396	real-time computing;simulation;computer science;operating system;database;world wide web	Metrics	-10.980385899103295	98.70696606812076	6398
77500536bf5f3dfc89f921182cdd3d04a1c2cdaa	the dcs as a universal digital cross-connect system	switching;central office;reseau transmission donnee;distributed control bit rate central office integrated circuit interconnections subscriber loops manufacturing dsl telecommunications;cross connect;digital transmission;data transmission network;switching communication;connexion croisee;digital commutation;conmutacion;red transmision datos;connexion croisee dcs;transmision numerica;communication switching;functional requirement;transmission numerique;switching communication communication switching;commutation numerique;commutation;telecommunication networks	Existing DCS (digital cross-connect system) technology performs a subset of the digital cross-connect functions required in telecommunications networks. It must be used in tandem with other cross-connection systems such as DSX's (digital signal cross-connect systems) and DF's (distributing frames). It is these two technologies which provide most of the interconnection functions for digital facilities and equipment from the interoffice, subscriber loop, and central office parts of a network. Hence, if the DCS is to serve as a more universal digital cross-connect system, it must be enhanced to provide functions now performed by DSX's and DF's. This paper proposes expansion of DCS functions to incorporate some (or all) of the capabilities of the DSX and DF at discrete bit rates of the digital transmission hierarchy. Functional requirements, technology alternatives, planning/engineering issues, and operations/maintenance considerations are discussed.	digital cross connect system	Edward Kovac;William Mitchell	1987	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.1987.1146505	digital cross connect system;telecommunications;computer science;functional requirement;computer network	Networks	-20.22220171739288	92.42958144389758	6427
915841f7c78764d40396de4c1215a167c7627080	celerity: a low-delay multi-party conferencing solution	protocols;teleconferencing;network coding peer to peer video conferencing utility maximization;delays receivers network topology algorithm design and analysis peer to peer computing loss measurement bandwidth;internet low delay multi party conferencing end to end delays celerity peer to peer p2p adaptive rate control protocol adaptive link rate control source video encoding rates video quality;peer to peer computing;teleconferencing peer to peer computing protocols	In this paper, we revisit the problem of multi-party conferencing from a practical perspective, and to rethink the design space involved in this problem. We believe that an emphasis on low end-to-end delays between any two parties in the conference is a must, and the source sending rate in a session should adapt to bandwidth availability and congestion. We present Celerity, a multi-party conferencing solution specifically designed to achieve our objectives. It is entirely Peer-to-Peer (P2P), and as such eliminating the cost of maintaining centrally administered servers. It is designed to deliver video with low end-to-end delays, at quality levels commensurate with available network resources over arbitrary network topologies where bottlenecks can be anywhere in the network. This is in contrast to commonly assumed P2P scenarios where bandwidth bottlenecks reside only at the edge of the network. The highlight in our design is a distributed and adaptive rate control protocol, that can discover and adapt to arbitrary topologies and network conditions quickly, converging to efficient link rate allocations allowed by the underlying network. In accordance with adaptive link rate control, source video encoding rates are also dynamically controlled to optimize video quality in arbitrary and unpredictable network conditions. We have implemented Celerity in a prototype system, and demonstrate its superior performance over existing solutions in a local experimental testbed and over the Internet.	celerity computing	Xiangwen Chen;Minghua Chen;Baochun Li;Yao Zhao;Yunnan Wu;Jin Li	2013	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2013.SUP.0513014	communications protocol;real-time computing;teleconference;telecommunications;computer science;distributed computing;dead peer detection;computer network	Vision	-8.209456511369394	97.11068763588372	6465
84fcd4c630e8cf3327feffd47c1124d8c9e812a5	reconsideration on the security of the boneh-franklin identity-based encryption scheme	encryption;identity based encryption;securite;cifrado;it security;cryptage;criptografia;cryptography;safety;cryptographie;seguridad	The Boneh-Franklin identity-based encryption (BF-IBE) scheme [6] is well-known as a fully functional identity-based encryption (IBE) scheme. Recently, Galindo [13] pointed out a flaw in the original proof of the security of the BF-IBE scheme. He claims that its security can be fixed without changing both the scheme and the underlying assumption if the efficiency of the security reduction is sacrificed. This result would be bad news for many cryptographic schemes [1,7,10,15] that are based on the BF-IBE scheme because an inefficient security reduction would imply either the lower security level or the use of larger key sizes to attain a given security level. In this paper, we give a new proof of the security of the BF-IBE scheme, showing that it has a tighter security reduction than had been previously believed.	franklin electronic publishers;id-based encryption	Mototsugu Nishioka	2005		10.1007/11596219_22	40-bit encryption;computer science;cryptography;theoretical computer science;concrete security;provable security;mathematics;internet privacy;computer security;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption	Crypto	-39.326552833281895	77.70570350868677	6488
316753094c64669d72fffc5ae396257f0524544f	officer: a general optimization framework for openflow rule allocation and endpoint policy enforcement	rule allocation;openflow;telecommunication traffic computational complexity computer centres optimisation polynomials software defined networking telecommunication network routing telecommunication network topology;under provisioned networks officer general optimization framework openflow rule allocation endpoint policy enforcement software defined networking rule allocation matrix high level policy network constraints memory capacity limitations link capacity limitations data center networks network resources linear optimization openflow networks relaxing routing policy np hard problem polynomial time heuristic carried traffic;routing resource management topology optimization control systems network topology linear programming;optimization	The Software-Defined Networking approach permits to realize new policies. In OpenFlow in particular, a controller decides on behalf of the switches which forwarding rules must be installed and where. However with this flexibility comes the challenge of the computation of a rule allocation matrix meeting both high-level policies and the network constraints such as memory or link capacity limitations. Nevertheless, in many situations (e.g., data-center networks), the exact path followed by packets does not severely impact performances as long as packets are delivered according to the endpoint policy. It is thus possible to deviate part of the traffic to alternative paths so to better use network resources without violating the endpoint policy. In this paper, we propose a linear optimization model of the rule allocation problem in resource constrained OpenFlow networks with relaxing routing policy. We show that the general problem is NP-hard and propose a polynomial time heuristic, called OFFICER, which aims to maximize the amount of carried traffic in under-provisioned networks. Our numerical evaluation on four different topologies shows that exploiting various paths allows to increase the amount of traffic supported by the network without significantly increasing the path length.	approximation algorithm;communication endpoint;computation;data center;heuristic (computer science);high- and low-level;integer programming;linear programming;mathematical optimization;np-hardness;network switch;network topology;numerical analysis;openflow;performance;polynomial;regular language description for xml;routing;simulation;software-defined networking;time complexity;tracing (software)	Xuan Nam Nguyen;Damien Saucez;Chadi Barakat;Thierry Turletti	2015	2015 IEEE Conference on Computer Communications (INFOCOM)	10.1109/INFOCOM.2015.7218414	openflow;telecommunications;computer science;operating system;distributed computing;computer security;computer network	Networks	-11.205163506456474	81.9460841610905	6506
45385be2f18596ba8cc4a4c697c53aae98a3ad39	applying ptf/vtf routing policies in multilayer ip/mpls-based ason/gmpls multi-domain networks	dwdm;ip/mpls;multi-domain multilayer;ason/gmpls	The IP/MPLS-based ASON/GMPLS hybrid network architecture enables the interaction between the IP layer and the optical dense wavelength division multiplexing (DWDM) layer. This architecture makes it possible to transfer huge amounts of traffic data on DWDM networks, while supporting Internet Protocol (IP)-based service applications. Additionally, this architecture provides a unified routing scenario, which allows the dynamic routing in both the IP layer and/or optical layer. Cross- layer routing has been addressed in single domain networks scenarios, where the routing policies Physical Topology First (PTF) and Virtual Topology First (VTP) have been proposed and applied. However, applying cross-layer routing using both routing topology policies PTF and VTF has not been investigated in a multi-domain networks scenario yet. In this study, we address this issue and propose a routing scheme to establish traffic connections in the optical WDM layer and the IP layer, which makes the applicability of PTF and VTF in multilayer multi-domain network feasible.	algorithm;automatically switched optical network;blocking (computing);fm broadcasting;generalized multi-protocol label switching;inter-domain;internet protocol suite;link-state routing protocol;multiprotocol label switching;network architecture;network packet;opto-electronic oscillator;packet switching;quality of service;scalability;simulation;switched fabric;test automation;upwind scheme;wavelength-division multiplexing	Wajdi Halabi;Kris Steenhaut;Marnix Goossens	2012	Photonic Network Communications	10.1007/s11107-012-0387-6	policy-based routing;wireless routing protocol;routing table;virtual routing and forwarding;routing;enhanced interior gateway routing protocol;loose source routing;static routing;hierarchical routing;supernetwork;zone routing protocol;telecommunications;dynamic source routing;multipath routing;optical ip switching;ip forwarding;distributed computing;routing protocol;link-state routing protocol;triangular routing;network layer;computer network	Networks	-9.110006777743301	85.76415348357156	6513
a5bc5c874e08931b920c67ba83bc8bbcac9df432	management driven hybrid multicast framework for content aware networks	topology;context awareness;multicast communication;hybrid multicast framework;video streaming;multimedia;content aware networks;management driven hybrid multicast framework;internet tv management driven hybrid multicast framework content aware networks network aware applications multimedia content oriented services iptv video streaming video on demand;network aware applications;ubiquitous computing multicast communication multimedia communication;video on demand;multimedia communication;telecommunication services;static var compensators;ubiquitous computing;ip networks quality of service topology context awareness unicast telecommunication network management static var compensators telecommunication services multicast communication;ip networks;content oriented services;quality of service;article;iptv;internet tv;unicast;telecommunication network management	The need for better adaptation of networks to transported flows has led to research on new approaches such as content aware networks and network aware applications. In parallel, recent developments of multimedia and content oriented services and applications such as IPTV, video streaming, video on demand, and Internet TV reinforced interest in multicast technologies. IP multicast has not been widely deployed due to interdomain and QoS support problems; therefore, alternative solutions have been investigated. This article proposes a management driven hybrid multicast solution that is multi-domain and media oriented, and combines overlay multicast, IP multicast, and P2P. The architecture is developed in a content aware network and network aware application environment, based on light network virtualization. The multicast trees can be seen as parallel virtual content aware networks, spanning a single or multiple IP domains, customized to the type of content to be transported while fulfilling the quality of service requirements of the service provider.	algorithm;broadcast domain;embedded system;emoticon;file spanning;forwarding plane;iptv;inter-domain;internet television;multicast;non-functional requirement;overlay network;performance evaluation;quality of service;routing;signalling system no. 7;streaming media	Radu-Dinel Iorga;Eugen Borcoci;Radu-Dinel Miruta;António Pinto;Gustavo Carneiro;Tânia Calçada	2014	IEEE Communications Magazine	10.1109/MCOM.2014.6710078	real-time computing;multicast;overlay network;ip multicast;inter-domain;quality of service;reliable multicast;mbone;protocol independent multicast;computer science;telecommunications service;pragmatic general multicast;internet group management protocol;distributed computing;distance vector multicast routing protocol;source-specific multicast;multimedia broadcast multicast service;ubiquitous computing;xcast;computer network;multicast address;unicast	Metrics	-13.776710233075413	93.38845533974809	6520
50f36be1e5accda9448f8a9fc945545d7b0bee9e	on the privacy of private browsing - a forensic approach	private browsing;system security;user privacy;web security	Private browsing has been a popular privacy feature built into all mainstream browsers since 2005. However, despite its prevalent use, the security of this feature has received little attention from the research community. In this paper, we present an up-to-date and comprehensive analysis of private browsing across four most popular web browsers: IE, Firefox, Chrome and Safari. We report that all browsers under study suffer from a variety of vulnerabilities, many of which have not been reported or known before. Our work highlights the complexity of the subject and calls for more attention from the security community.	browsing;crash (computing);edge case;features of the opera web browser;firefox;google chrome;interference (communication);privacy;safari (web browser);threat model;vulnerability (computing)	Kiavash Satvat;Matthew Forshaw;Feng Hao;Ehsan Toreini	2013		10.1007/978-3-642-54568-9_25	engineering;internet privacy;world wide web;computer security	Security	-55.972897763795785	62.06875538139757	6524
2667e85f444f03fab34ba3cdb44d21b3daf5de40	hierarchical storage system based on wireless mesh network	radio networks;microprocessors;high availability;wireless multi hop network infrastructure hierarchical storage system wireless mesh network massive data storage;wireless mesh networks mesh generation algorithm design and analysis land mobile radio cellular systems bandwidth condition monitoring computer networks computer science telecommunication computing computer architecture;storage system;metadata;massive data storage;wireless multi hop network infrastructure;wireless network;metadata wireless mesh network hierarchical storage system hss architecture;wireless mesh network;computer networks;computer architecture;data storage;servers;logic gates;hierarchical storage system;wireless mesh networks;radio networks computer networks digital storage;self organization;load balance;digital storage;peer to peer computing;security;architecture;hss	Wireless mesh network is emerging as a new generation of wireless network architecture, attracting much research on MAC, routing, application, etc. Widen applied in wide areas, there will produce massive data storage requirements. The paper presents a Hierarchical Storage System on wireless mesh network, with high availability, scalability, self-heal, self-organizing, load balanced. Key technologies and algorithms and performances of the hierarchical storage system are discussed and analyze. The Hierarchical Storage System can be applied in enterprises, campuses, and metropolitan areas. It is built over current technology and can make useful of current assets.	algorithm;computer data storage;data access;fault tolerance;gateway (telecommunications);hierarchical storage management;high availability;high-speed serial interface;load balancing (computing);mesh networking;network architecture;organizing (structure);performance;prototype;requirement;router (computing);routing;scalability;self-organization;serializability;simulation;wireless mesh network	Wenying Zeng;Yuelong Zhao;Junwei Zeng	2008	2008 The 9th International Conference for Young Computer Scientists	10.1109/ICYCS.2008.294	wireless mesh network;switched mesh;embedded system;wireless wan;hierarchical routing;computer science;information security;architecture;operating system;wireless network;computer data storage;distributed computing;order one network protocol;municipal wireless network;wi-fi array;high availability;metadata;computer network	HPC	-19.492460632805628	86.74011902134936	6546
4487efc7586a7e186e272e173ae01af2cc497441	revisiting the accuracy of the biohashing algorithm on fingerprints	performance evaluation authorisation cryptography fingerprint identification image watermarking;biohashing algorithm accuracy performance evaluation original template storage avoidance original template misuse avoidance biometric data security template protection methods biometric authentication schemes biometric template protection fingerprints;accuracy performance evaluation;template protection methods;original template misuse avoidance;original template storage avoidance;biometric template protection;biometric authentication schemes;fingerprints;biometric data security;biohashing algorithm	Biometric template protection is suitable with the widespread deployment of biometric authentication schemes. Template protection methods are used to ensure the diversity and the security of biometric data, by avoiding storage and misuse of the original template. This study provides an evaluation of the accuracy performance of biometric template protection methods, by revisiting experiments on the biohashing algorithm on fingerprints. It is shown how and why experimental results can be completely falsified with only five random bits.	algorithm;authentication;biometrics;experiment;fingerprint;software deployment	Patrick Lacharme	2013	IET Biometrics	10.1049/iet-bmt.2012.0041	fingerprint;computer science;data mining;internet privacy;computer security	DB	-45.92988985916642	69.56368482234298	6548
60387cbf04e7d452a68053f9a6e0da6da8350236	verifier-key-flexible universal designated-verifier signatures	universal design;verifier key flexible;ecdsa;public key;random oracle model;random oracle;public key infrastructure;universal designated verifier signature	Universal Designated-Verifier Signatures (UDVS) are proposed to protect the privacy of a signature holder. Since UDVS schemes reduce to standard signatures when no verifier designation is performed, from the perspective of a signer, it is natural to ask if a UDVS can be constructed from widely used standardized-signatures so that the existing public key infrastructures for these schemes can be used without modification. Additionally, if designated-verifiers already have their own private/public key-pairs (which may be of a different type from the signer’s), then, for the convenience of designated-verifiers, it is also natural to ask if designated-verifiers can use their own private keys to verify designated signatures instead of using a new key compatible with the UDVS system. In this paper, we address these problems and propose a new UDVS scheme. In our scheme, the signature is generated by a signer using DSA/ECDSA, and the designated-signature can be verified using the original private key (RSA-based or DL-based) of the designated-verifier instead of using a new key. We call this new property verifier-key-flexible. The security of the scheme is proved in the random oracle model.	antivirus software;asiacrypt;blind signature;communications of the acm;designated verifier signature;digital signature;end-user computing;entity–relationship model;eurocrypt;icalp;ingo wegener;journal of cryptology;lecture notes in computer science;pkc (conference);public-key cryptography;rsa (cryptosystem);random oracle;sako (programming language);schnorr group;signature;smart card;springer (tank);ueli maurer (cryptographer);yang	Raylin Tso;Juan Manuel González Nieto;Takeshi Okamoto;Colin Boyd;Eiji Okamoto	2007		10.1007/978-3-540-77272-9_24	computer science;internet privacy;world wide web;computer security	Crypto	-41.683801499691256	75.74937150801371	6549
326bb49d3ae9e1e1551028200916192e50004105	privacy-preserving deep learning	neural networks;gradient descent;deep learning;privacy	Deep learning based on artificial neural networks is a very popular approach to modeling, classifying, and recognizing complex data such as images, speech, and text. The unprecedented accuracy of deep learning methods has turned them into the foundation of new AI-based services on the Internet. Commercial companies that collect user data on a large scale have been the main beneficiaries of this trend since the success of deep learning techniques is directly proportional to the amount of data available for training. Massive data collection required for deep learning presents obvious privacy issues. Users' personal, highly sensitive data such as photos and voice recordings is kept indefinitely by the companies that collect it. Users can neither delete it, nor restrict the purposes for which it is used. Furthermore, centrally kept data is subject to legal subpoenas and extra-judicial surveillance. Many data owners--for example, medical institutions that may want to apply deep learning methods to clinical records--are prevented by privacy and confidentiality concerns from sharing the data and thus benefitting from large-scale deep learning.  In this paper, we design, implement, and evaluate a practical system that enables multiple parties to jointly learn an accurate neural-network model for a given objective without sharing their input datasets. We exploit the fact that the optimization algorithms used in modern deep learning, namely, those based on stochastic gradient descent, can be parallelized and executed asynchronously. Our system lets participants train independently on their own datasets and selectively share small subsets of their models' key parameters during training. This offers an attractive point in the utility/privacy tradeoff space: participants preserve the privacy of their respective data while still benefitting from other participants' models and thus boosting their learning accuracy beyond what is achievable solely on their own inputs. We demonstrate the accuracy of our privacy-preserving deep learning on benchmark datasets.	algorithm;artificial neural network;benchmark (computing);confidentiality;deep learning;image;internet;mathematical optimization;network model;parallel computing;privacy;stochastic gradient descent	Reza Shokri;Vitaly Shmatikov	2015	2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)	10.1145/2810103.2813687	semi-supervised learning;gradient descent;computer science;data science;online machine learning;machine learning;data mining;deep learning;privacy;computer security	Security	-37.032986669896296	65.33362085074917	6553
d15cfc53eaec91050e38344bd46c865ff2527148	a secure and efficient group key management protocol with cooperative sensor association in wbans	chinese remainder theorem (crt);authentication;coded cooperative data exchange (ccde);group key management;wireless body area networks	The wireless body area network (WBAN) is considered as one of the emerging wireless techniques in the healthcare system. Typical WBAN sensors, especially implantable sensors, have limited power capability, which restricts their wide applications in the medical environment. In addition, it is necessary for the healthcare center (HC) to broadcast significant notifications to different patient groups. Considering the above issues, in this paper, the novel practical WBAN system model with group message broadcasting is built. Subsequently, a secure and efficient group key management protocol with cooperative sensor association is proposed. In the proposed protocol, the Chinese remainder theorem (CRT) is employed for group key management between HC and the personal controller (PC), which also supports batch key updating. The proposed sensor association scheme is motivated by coded cooperative data exchange (CCDE). The formal security proofs are presented, indicating that the proposed protocol can achieve the desired security properties. Moreover, performance analysis demonstrates that the proposed protocol is efficient compared with state-of-the-art group key management protocols.		Haowen Tan;Ilyong Chung	2018		10.3390/s18113930		Security	-49.820341462642446	75.03721718951171	6567
faadd82a7ffc25e151524870b4cdca33439fc911	bandwidth‐aware divisible task scheduling for cloud computing	task scheduling algorithm;nonlinear programming model;cloud computing	Task scheduling is a fundamental issue in achieving high efficiency in cloud computing. However, it is a big challenge for efficient scheduling algorithm design and implementation (as general scheduling problem is NP-complete). Most existing task-scheduling methods of cloud computing only consider task resource requirements for CPU and memory, without considering bandwidth requirements. In order to obtain better performance, in this paper, we propose a bandwidth-aware algorithm for divisible task scheduling in cloudcomputing environments. A nonlinear programming model for the divisible task-scheduling problem under the bounded multi-port model is presented. By solving this model, the optimized allocation scheme that determines proper number of tasks assigned to each virtual resource node is obtained. On the basis of the optimized allocation scheme, a heuristic algorithm for divisible load scheduling, called bandwidth-aware task-scheduling (BATS) algorithm, is proposed. The performance of algorithm is evaluated using CloudSim toolkit. Experimental result shows that, comparedwith the fair-based task-scheduling algorithm, the bandwidthonly task-scheduling algorithm, and the computation-only task-scheduling algorithm, the proposed algorithm (BATS) has better performance. Copyright © 2012 John Wiley & Sons, Ltd.	algorithm design;central processing unit;cloud computing;cloudsim;computation;correctness (computer science);data center;heuristic (computer science);ibm notes;john d. wiley;lingo (programming language);mathematical optimization;np-completeness;nonlinear programming;nonlinear system;programming model;requirement;run time (program lifecycle phase);scheduling (computing);virtual machine manager	Weiwei Lin;Chen Liang;James Zijun Wang;Rajkumar Buyya	2014	Softw., Pract. Exper.	10.1002/spe.2163	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;cloud computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;operating system;two-level scheduling;distributed computing;round-robin scheduling;proportionally fair	HPC	-18.199284575740574	63.22228500748119	6581
5195433861bf92a127fca22744506efab95fb6b6	a mobile device-based mobile ap detection scheme using nat behavior	mobile communication ports computers wireless networks communication system security mobile computing security;public wireless network environment mobile device mobile ap detection scheme nat behavior security configuration rogue ap evil twin;mobile communication;telecommunication security;wireless lan mobile communication telecommunication security;wireless lan	This paper proposes the scheme to detect the Mobile AP from mobile devices independently without the help of additional nodes. The proposed scheme is for detecting the Mobile AP that does not have any security configuration which is highly likely to occur as the Rogue AP in real wireless network environment. The device inspects the NAT Behavior and Open Port at the time of specific AP connection to detect the presence of Mobile AP, and reduces the security threat for the Rogue AP. The Rogue AP detection scheme s presented previously are generally based on the detection of Rogue AP in the form of Evil Twin, and the Rogue AP of various forms cannot be detected easily with such techniques. In addition, such techniques require regular monitoring or additional network infrastructure, thus making it difficult to apply to mobile devices, and are not suitable in real public wireless network environment. The proposed technique enables detection of mobile AP, which does not have any security configuration, from mobile devices in public wireless network environment independently without the help of additional nodes, and therefore, represents the detection scheme that is easily applicable and proved its performance in the experiment under real wireless network environment.	encryption;mobile device;rogue access point;sensor;server (computing);smart device	Minuk Kim;Jiman Mun;Souhwan Jung;Younghan Kim	2013	2013 International Conference on IT Convergence and Security (ICITCS)	10.1109/ICITCS.2013.6717778	mobile identification number;telecommunications;engineering;mobile station;rogue access point;mobile computing;computer security;computer network	Mobile	-52.666449231160236	70.88577885906832	6591
338ae4ec718d2e16810c9f08df81bf088388dd8e	comments on mutual authentication and key exchange protocols for low power wireless communications	protocolo acceso;protocols;linear protocol mutual authentication and key exchange protocols low power wireless communications unknown key share attacks server specific protocol;securite;telecommunication sans fil;cryptanalyse;authentication;echange cle;indexing terms;access protocol;cryptography protocols telecommunication security radiocommunication message authentication;authentification;cryptanalysis;wireless communication;criptoanalisis;autenticacion;low power;key exchange;telecomunicacion sin hilo;cryptography;mutual authentication;safety;telecommunication security;radiocommunication;message authentication;protocole acces;seguridad;authentication wireless application protocol wireless communication public key cryptographic protocols communication system security base stations public key cryptography information security scalability;wireless telecommunication	"""Shim (2003) describes """"unknown key-share"""" attacks on the two protocols, server-specific MAKEP and linear MAKEP, proposed by Wong and Chan (2001). In this letter, we point out an error in one of the attacks and demonstrate further undesirable properties in the protocols of Wong and Chan."""	key exchange;key-agreement protocol;mutual authentication;server (computing);shim (computing)	Siaw-Lynn Ng;Chris J. Mitchell	2004	IEEE Communications Letters	10.1109/LCOMM.2004.825724	telecommunications;computer science;authentication;computer security;computer network	Security	-44.8304395523196	76.27538781702494	6638
53e16b39bf392bc83ccc3b6430e5211fb3a41c22	a protocol for packet-switching voice communication	packet switched	Abstract   This paper discusses the issues associated with real-time voice communication over packet switched networks. It suggests an approach for the design of a protocol to support this application. The ARPA Network Voice Protocol is presented as an example of such a protocol. In addition, two extensions to it are discussed. Most of the issues which are discussed in the context of the NVP, like separation of control from data, device independence, and performance monitoring are not unique only to voice application, but apply equally to any other real-time protocol. The major virtue of the real-time voice communication as far as networking is concerned is the real-time, not the voice, aspect of this communication.	packet switching	Dan Cohen	1978	Computer Networks	10.1016/0376-5075(78)90010-7	voice activity detection;radio link protocol;speech recognition;telecommunications;computer science;link control protocol;internetwork protocol	Theory	-21.638071586072247	93.7772226966296	6654
32c19786d14488c2ecbccf83b8e84bd5fc92783c	scalability and accuracy in a large-scale network emulator	terminal emulation;network emulation;network operating systems;network topology;large scale;internet;virtual machines;datavetenskap datalogi;computer science	This paper presents ModelNet, a scalable Internet emulation environment that enables researchers to deploy unmodified software prototypes in a configurable Internet-like environment and subject them to faults and varying network conditions. Edge nodes running user-specified OS and application software are configured to route their packets through a set of ModelNet core nodes, which cooperate to subject the traffic to the bandwidth, congestion constraints, latency, and loss profile of a target network topology.This paper describes and evaluates the ModelNet architecture and its implementation, including novel techniques to balance emulation accuracy against scalability. The current ModelNet prototype is able to accurately subject thousands of instances of a distrbuted application to Internet-like conditions with gigabits of bisection bandwidth. Experiments with several large-scale distributed services demonstrate the generality and effectiveness of the infrastructure.	ap computer science;aggregate data;bisection bandwidth;co-ment;emulator;experiment;full scale;gigabit;hoc (programming language);internet;map;multiplexing;naruto shippuden: clash of ninja revolution 3;network congestion;network emulation;network packet;network topology;operating system;peer-to-peer;prototype;router (computing);scalability;software prototyping;web service	Amin Vahdat;Ken Yocum;Kevin M Walsh;Priya Mahadevan;Dejan Kostic;Jeffrey S. Chase;David Becker	2002		10.1145/844128.844154	embedded system;real-time computing;the internet;computer science;virtual machine;operating system;distributed computing;computer security;network topology	OS	-15.673933927535867	81.04730070953624	6673
36e39b9661a235636f9ca37156d240404b9c2a6b	plm: fast convergence for cumulative layered multicast transmisson schemes	available bandwidth;multicast congestion control;audio video;cumulative layers;fs paradigm;capacity inference;mulitcast;congestion control;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;packet pair;cumulant;convergence time;multicast	A major challenge in the Internet is to deliver live audio/video content with a good quality and to transfer files to large number of heterogeneous receivers. Multicast and cumulative layered transmission are two mechanisms of interest to accomplish this task efficiently. However, protocols using these mechanisms suffer from slow convergence time, lack of inter-protocol fairness or TCP-fairness, and loss induced by the join experiments. In this paper we define and investigate the properties of a new multicast congestion control protocol (called PLM) for audio/video and file transfer applications based on a cumulative layered multicast transmission. A fundamental contribution of this paper is the introduction and evaluation of a new and efficient technique based on packet pair to infer which layers to join. We evaluated PLM for a large variety of scenarios and show that it converges fast to the optimal link utilization, induces no loss to track the available bandwidth, has inter-protocol fairness and TCP-fairness, and scales with the number of receivers and the number of sessions. Moreover, all these properties hold in self similar and multifractal environment.	benchmark (computing);digital video;experiment;fairness measure;file transfer;internet;multicast;multifractal system;multiplexing;network congestion;network packet;programming paradigm;scalability;self-similarity;simulation	Arnaud Legout;Ernst W. Biersack	2000		10.1145/339331.339340	real-time computing;multicast;ip multicast;inter-domain;reliable multicast;telecommunications;protocol independent multicast;computer science;operating system;pragmatic general multicast;distance vector multicast routing protocol;source-specific multicast;network congestion;xcast;statistics;computer network;cumulant	Networks	-4.99792085495835	95.8109440562294	6680
e2fb89c7e6965ec4d13beeb4d873030bce52a2e7	inter-domain security for mobile ipv6	securite;protocole interner;comptabilite;authentification;adressage itinerance;service mobile terrestre	"""Mobile IPv6 is a macro-mobility """"universal"""" solutio n and is only adapted to the mobile's movements wit hin its own administrative domain. As Mobile IPv6 is expected t o be the basis for the third generation cellular ph one networks, a solution for inter-domain security is required. What is need d is that the visited domain should be able to aut henticate the mobile to grant it access, and the mobile should identify sec urely the visited domain so that its communications are protected in an appropriate manner. To solve those inter-domain security problems, new concepts known as AAA for Authentication, Authoriza t on, Accounting were defined by the IETF. The IETF is currently def ining the Diameter protocol to support those three functions in a Mobile IPv4 environment. Today's difficulty is to adapt th e Diameter protocol to Mobile IPv6. After introducing the Mobile IPv6, IPsec/IKE and Di ameter protocols, this paper presents our solution and an alternative for adapting Diameter to Mobile IPv6, and gives a compa rison. Both of them were published as IETF drafts i n December 2001 at the Salt Lake City meeting."""	aaa (video game industry);administrative domain;authentication;diameter (protocol);ipsec;inter-domain;internet key exchange;mobile ip	Maryline Laurent-Maknavicius;Julien Bournelle	2003	Annales des Télécommunications	10.1007/BF03001869	telecommunications;computer science;authentication;computer security	Mobile	-24.44554626150864	87.00771560278416	6713
da04ff21372c941e964671cc3efa40c48fd45bd2	measurement of transaction-based end-to-end response time in un-armed environments			end-to-end principle;response time (technology)	Mike Tsykin;James P. Bouhana;Christofer D. Langshaw	2006			real-time computing;end-to-end principle;response time;database transaction;business	OS	-10.035612300192724	93.26384307498985	6737
045296419941f0e66ff6982ba8af6b20934e7177	concurrent zero-knowledge	interactive proofs;zero knowledge	Concurrent executions of a zero-knowledge protocol by a ainSle prover (with one or more verifiers) may leak information and may not be zero-knowledge in toto; for example, in the case of zero-knowledge interactive proofs or arguments, the interactions remain proofs but may fail to remain zeroltnowlcd~e, This paper addresses the problem of achieving concurrent zero-knowledge, We introduce timing in order to obtain zero-knowledge in concurrent executions. We assume that the adversary is conntrained in its control over processors’ clocks by what we call an (cr,j+constroint for some o < p: for any two processors Pr and Pa, if A measures (Y elapsed time on its local clock nnd Pz measures /3 elapsed time on its local clock, and Pz atarts ajtcr PI does, then P2 will finish after PI does. We obtain four-round almost concurrent zero-knowledge interactive proofs and perfect concurrent zero-knowledge arguments for every language in NP. We also address the more apccific problem of Deniable Authentication, for which we propose efilcicnt solutions.	adversary (cryptography);central processing unit;deniable authentication;interaction;interactive proof system;np (complexity);performance rating;zero-knowledge proof	Cynthia Dwork;Moni Naor;Amit Sahai	1998		10.1145/276698.276853	discrete mathematics;computer science;mathematics;algorithm;zero-knowledge proof	Theory	-37.66628062570406	75.11778926376063	6770
7eaffd57c0775fb94623e437707ca96e0e6bfd7c	an autonomous system based security mechanism for network coding applications in content-centric networking	content-centric networking;network coding;security	Content-Centric Networking (CCN), is built on the notion of content-based security. With the integration of Network Coding (NC) into CCN to contribute to the best performance, security, one of the key features of CCN has been left behind. Though the permission for encoding/recoding content packets at producers and intermediate routers provides performance benefits, it also introduces additional security issues and disables existing security practices. In this paper, we fill the gap by analyzing new security challenges brought accordingly and proposing an Autonomous Systems (AS-s) based security mechanism for NC applications in CCN. It can not only guarantee the optimal performance of NC, but also offer the assurance for Integrity, Origin Authentication and Correctness of content packets, together with proving trustworthiness among border routers. More importantly, we also shed light on the performance issues and implementation problems of the mechanism. © 2017, Springer International Publishing AG.	autonomous system (internet);linear network coding	Li Xu;Hui Li;Jiawei Hu;Yunmin Wang;Huayu Zhang	2017		10.1007/978-3-319-67807-8_3	linear network coding;networking hardware;software-defined networking;content centric networking;network access control;authentication;active networking;computer science;delay-tolerant networking;distributed computing	Networks	-25.14109477460388	86.01060474972647	6776
95529880059ebba104b474167ed189aaff8b562f	on optimizing overlay topologies for search in unstructured peer-to-peer networks	topology;performance guarantee;protocols;peer to peer network;telecommunication traffic overlay networks peer to peer computing telecommunication network topology;peer to peer systems;overlay networks;semantics;p2p;power law property overlay topology construction algorithm unstructured peer to peer network p2p network file sharing network network traffic overlay formation algorithm;peer to peer system;network topology;search;telecommunication traffic;peer to peer computing proposals semantics protocols network topology search problems topology;theoretical analysis;network traffic;unstructured overlay networks;search peer to peer systems unstructured overlay networks;overlay network;search problems;file sharing;p2p networks;power law;peer to peer computing;telecommunication network topology;peer to peer;proposals	Unstructured peer-to-peer (P2P) file-sharing networks are popular in the mass market. As the peers participating in unstructured networks interconnect randomly, they rely on flooding query messages to discover objects of interest and thus introduce remarkable network traffic. Empirical measurement studies indicate that the peers in P2P networks have similar preferences, and have recently proposed unstructured P2P networks that organize participating peers by exploiting their similarity. The resultant networks may not perform searches efficiently and effectively because existing overlay topology construction algorithms often create unstructured P2P networks without performance guarantees. Thus, we propose a novel overlay formation algorithm for unstructured P2P networks. Based on the file sharing pattern exhibiting the power-law property, our proposal is unique in that it poses rigorous performance guarantees. Theoretical performance results conclude that in a constant probability, 1) searching an object in our proposed network efficiently takes O(lnc N) hops (where c is a small constant), and 2) the search progressively and effectively exploits the similarity of peers. In addition, the success ratio of discovering an object approximates 100 percent. We validate our theoretical analysis and compare our proposal to competing algorithms in simulations. Based on the simulation results, our proposal clearly outperforms the competing algorithms in terms of 1) the hop count of routing a query message, 2) the successful ratio of resolving a query, 3) the number of messages required for resolving a query, and 4) the message overhead for maintaining and formatting the overlay.	algorithm;approximation algorithm;computation;distributed algorithm;emoticon;file sharing;network topology;network traffic control;optimizing compiler;overhead (computing);overlay network;peer-to-peer;polynomial;randomness;resultant;routing;simulation	Hung-Chang Hsiao;Hong-Wei Su	2012	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2011.241	overlay network;computer science;distributed computing;semantics;world wide web;computer network	DB	-12.252656450520714	74.75014735471724	6779
8d9c93cb1c7a16e9ab0959dec76dfb2bb56bc952	forwarding-loop-free configuration for ibgp networks	routing protocols;optimisation;and forward;internet border gateway protocol ibgp networks forwarding loop free configuration intercluster routing deflection forwarding loops ibgp cluster misconfiguration np hard heuristic algorithm loop free ibgp network;optimisation internet internetworking routing protocols;internet;network configuration;internetworking;routing protocols network topology heuristic algorithms convergence computer science stability analysis proposals delay;heuristic algorithm	forwarding path between a node and its local egress node, if Absfrad We investieate the inter-cluster routine anv. does not go throueh another cluster. , I .  deflection and forwarding IoGps in IBGP networks. In more detail, we define and explore the two causes of deflection, and consecutively, forwarding loops which might happen due to IBGP cluster misconfieuratioa We studv the methods that can Then, we study different methods for eliminating forwarding loops, if detected, and we show that detecting he used to remove fo&rding loops, if diteeted. Unfortunately, we show that detecting forwarding loops in a given IBGP network configuration is “-hard. However, we propose a simple heuristic algorithm with complexity of O(d) to configure deflectionand loopfree IBGP network. such loops is NP-hard. Finally, we propose a simple heuristic algorithm with complexity of O(n2) that guarantees deflectionand loop-free configuration for IBGP.	algorithm;border gateway protocol;egress filtering;heuristic (computer science);sensor	Hassan Gobjuka	2003		10.1109/ICON.2003.1266163	heuristic;virtual routing and forwarding;routing;real-time computing;the internet;computer science;distributed computing;routing protocol;computer network	ML	-8.068388660414774	80.01100390627069	6798
45513cbc83ffaba16b748140e9c4dfd11383033a	an mmas-ga for resource allocation in multi-cloud systems	pricing;monitoring;genetic algorithms	Delivering computing resources from multiple cloud providers to satisfy the users' needs, known as multi-cloud, gives the possibility for cloud consumers to get access to a wide variety of performing resources with competing costs. The main challenge of this infrastructure is the providers' systems interoperability. In this paper, cloud broker architecture is proposed, which aims on finding a providers coalition to satisfy a user's request with the minimal execution time and cost. The request is a set of independent tasks where no communication is considered. To solve this problem, a Max-Min Ant system (MMAS) and a Genetic Algorithm (GA) were developed as well as their hybrid, and a comparative study was established.	ant colony optimization algorithms;cloud computing;genetic algorithm;interoperability;no-communication theorem;run time (program lifecycle phase);software release life cycle	Lotfi Hajjem;Salah Benabdallah	2016	2016 11th International Conference for Internet Technology and Secured Transactions (ICITST)	10.1109/ICITST.2016.7856745	simulation;operations management;distributed computing;business	HPC	-18.91632544289945	63.81230357199978	6836
09fa35269fa68bc21ef3ad11aca68b0e5fe4bea6	zero-knowledge-like proof of cryptanalysis of bluetooth encryption	conference;meeting	This paper presents a protocol aiming at proving that an encryption system contains structural weaknesses without disclosing any information on those weaknesses. A verifier can check in a polynomial time that a given property of the cipher system ou tput has been effectively realized. This property has been chose n by the prover in such a way that it cannot been achieved by known atta cks or exhaustive search but only if the prover indeed knows some un disclosed weaknesses that may effectively endanger the crypto system security. This protocol has been denoted zero-knowledge-like proof of cryptanalysis. In this paper, we apply this protocol to the Bluetooth core encryption algorithm E0, used in many mobile environme ts and thus we suggest that its security can seriously be put into qu estion. Keywords— Bluetooth encryption, Bluetooth security, Bluetooth protocol, Stream cipher, Zero-knowledge, Cryptanalysis	algorithm;bluetooth;brute-force search;cryptanalysis;cryptosystem;encryption;stream cipher;time complexity;tput;zero-knowledge proof	Eric Filiol	2006	IACR Cryptology ePrint Archive		computer science;internet privacy;computer security;computer network	Crypto	-44.36355189070545	75.19587769467603	6872
0ca209994a700f64f6ec4610b9eea0d8a1b0f96e	routing, security, resource management, and monitoring in ad hoc networks: implementation and integration	key management;internet protocol;extraction information;gestion de claves;red sin hilo;eje troncal;link quality;routing protocols;topology control;protocolo ipv6;mobile radiocommunication;procesamiento informacion;protocole transmission;protocolo internet;reseau sans fil;network monitoring;information extraction;securite telecommunication;telecommunication sans fil;routing;implementation;wireless network;resource manager;resource management;protocole internet;protocole ipv6;reseau ad hoc mobile;test bench;wireless ad hoc network;ad hoc network;banco prueba;centralized system;red ad hoc;relais;integration;radiocommunication service mobile;routage reseau;network routing;reseau federateur;decentralized system;secure routing;red movil ad hoc;gestion recursos;protocolo transmision;rele;reseau ad hoc;monitoring;lessons learned;telecomunicacion sin hilo;information processing;telecommunication security;sistema descentralizado;ipv6 protocol;systeme centralise;gestion ressources;conexidad;ad hoc networks;mobile ad hoc network;protocole routage;mobile node;systeme decentralise;monitorage;connexite;backbone;routing protocol;implementacion;radiocomunicacion servicio movil;traitement information;connectedness;monitoreo;banc essai;sistema centralizado;experimentation;security;gestion cle;ad hoc routing;extraccion informacion;core network;relay;wireless telecommunication;transmission protocol	In this paper we present the implementation and integration of core network functions, including routing, security, resource management, and network monitoring that are critical to the efficient operation of a mobile ad hoc network (MANET). The integration of the aforementioned functionalities enables them to support one another, forming a cohesive system. We design and implement a new ad hoc routing protocol that can relay connectivity, link quality, or any other information that is globally available to the underlying routing mechanism and use such information to improve routing decisions. Our implementation of resource management and topology control utilizes the connectivity information from the routing protocol to derive topologies that consume less energy and cause less interference. Our key management solution supports IPsec deployment and establishes secure paths enabling secure information propagation for routing and topology control messages, as well as for application data. Moreover, it provides an integrated trust component that can guide trust decisions among nodes in a network. To debug and monitor these core functionalities we implement both centralized and decentralized network monitoring solutions, which in turn extract and display information, such as connectivity and secure tunnels, from our security, routing, and topology control solutions. Routing, security, and monitoring mechanisms support concurrent use of IPv6 and IPv4 addresses. We briefly describe each component of the solution and discuss the integration of these components into a unified system to support mobile nodes. We describe experiments conducted on a wireless ad hoc network testbed and thus illustrate the interaction between the various technologies. Concluding, we discuss lessons learned and how we make available our implementations to enable further experimentation by the wireless network	centralized computing;data security;experiment;hoc (programming language);ipsec;interference (communication);key management;relay;routing;software deployment;software propagation;testbed;topology control	George C. Hadjichristofi;Luiz A. DaSilva;Scott F. Midkiff;Unghee Lee;Waltemar De Sousa	2011	Computer Networks	10.1016/j.comnet.2010.09.001	policy-based routing;wireless routing protocol;wireless ad hoc network;routing table;routing domain;optimized link state routing protocol;routing;enhanced interior gateway routing protocol;static routing;adaptive quality of service multi-hop routing;hierarchical routing;zone routing protocol;telecommunications;computer science;dynamic source routing;resource management;multipath routing;destination-sequenced distance vector routing;ad hoc wireless distribution service;routing protocol;link-state routing protocol;computer security;hazy sighted link state routing protocol;geographic routing;computer network	Mobile	-4.766889794342857	75.74030381533518	6926
a49f5af996040dc41b8a00fd7448a46b2944130a	on symmetry for network virtual topology	virtual topology;performance;overlay;cayley graph;network topology;principle of symmetry	General networks such as Internet are complex heterogeneous networks, which are constructed by many different organizations, and so become non-effective ones. Therefore one constructed a level of software over networks which is called overlay or virtual topology. In this paper we present principle of symmetry for general network topology by using Cayley graph models and show its necessity to improving network performance. We explain the main conclusions of the paper by many examples in optical, wireless and peer-to-peer networks.	internet;magma;network performance;network topology;peer-to-peer;semantic network	Wenjun Xiao;Weibing Wang	2010	JNW	10.4304/jnw.5.6.732-739	strong topology;topology;weak topology;computational topology;overlay network;product topology;performance;computer science;operating system;hierarchical network model;cayley graph;spatial network;extension topology;overlay;particular point topology;geometric topology;euclidean topology;initial topology;network topology;computer network;logical topology	Networks	-9.073551452408605	78.25354361177365	6930
5c929f265daaf98a135bb0eb404dad34c49d5935	risk-resilient heuristics and genetic algorithms for security-assured grid job scheduling	graph theory;resource utilization;distributed supercomputing grid computing job scheduling heuristics genetic algorithm replication scheduling risk resilience nas and psa benchmarks performance metrics;space time genetic algorithm;replication scheduling;risk analysis;grid computing environment;resource allocation;security assured grid job scheduling;resource management;genetic algorithms scheduling data security resource management graph theory;space time;indexing terms;distributed supercomputing;performance metric;scheduling algorithm;grid resource utilization;security of data genetic algorithms graph theory grid computing resource allocation risk analysis scheduling;scheduling;grid computing services;failure rate;genetic algorithm;genetic algorithms;risk resilient heuristics;kiviat graph;delay tolerant min min job scheduling;risk resilience;job scheduling heuristics;risk resilient scheduling algorithms;nas and psa benchmarks;replicated job scheduling;security policy;grid computing;performance metrics;job failure rate;job scheduling;article;grid computing services risk resilient heuristics security assured grid job scheduling risk resilient scheduling algorithms grid resource utilization job failure rate space time genetic algorithm delay tolerant min min job scheduling replicated job scheduling kiviat graph;security of data;grid system;data security	In scheduling a large number of user jobs for parallel execution on an open-resource grid system, the jobs are subject to system failures or delays caused by infected hardware, software vulnerability, and distrusted security policy. This paper models the risk and insecure conditions in grid job scheduling. Three risk-resilient strategies, preemptive, replication, and delay-tolerant, are developed to provide security assurance. We propose six risk-resilient scheduling algorithms to assure secure grid job execution under different risky conditions. We report the simulated grid performances of these new grid job scheduling algorithms under the NAS and PSA workloads. The relative performance is measured by the total job makespan, grid resource utilization, job failure rate, slowdown ratio, replication overhead, etc. In addition to extending from known scheduling heuristics, we developed a new space-time genetic algorithm (STGA) based on faster searching and protected chromosome formation. Our simulation results suggest that, in a wide-area grid environment, it is more resilient for the global job scheduler to tolerate some job delays instead of resorting to preemption or replication or taking a risk on unreliable resources allocated. We find that delay-tolerant min-min and STGA job scheduling have 13-23 percent higher performance than using risky or preemptive or replicated algorithms. The resource overheads for replicated job scheduling are kept at a low 15 percent. The delayed job execution is optimized with a delay factor, which is 20 percent of the total makespan. A Kiviat graph is proposed for demonstrating the quality of grid computing services. These risk-resilient job scheduling schemes can upgrade grid performance significantly at only a moderate increase in extra resources or scheduling delays in a risky grid computing environment	aggregate data;align (company);authentication;benchmark (computing);data integrity;design rationale;digital signature;experiment;failure rate;firewall (computing);fuzzy logic;game theory;genetic algorithm;grid computing;heuristic (computer science);job scheduler;job stream;makespan;maxima and minima;network-attached storage;overhead (computing);performance;polar surface area;preemption (computing);real life;requirement;scalability;schedule (project management);scheduling (computing);secure digital;simulation;software propagation;transform, clipping, and lighting;trust management (information system);trusted execution technology;vulnerability (computing);ws-trust	Shanshan Song;Kai Hwang;Yu-Kwong Kwok	2006	IEEE Transactions on Computers	10.1109/TC.2006.89	fair-share scheduling;fixed-priority pre-emptive scheduling;job shop scheduling;parallel computing;real-time computing;genetic algorithm;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;graph theory;resource management;job scheduler;operating system;two-level scheduling;distributed computing;job queue;lottery scheduling;scheduling	HPC	-18.9625650295024	61.966686250124305	6941
4a5028e5e04c27fdc3edc79dd1ee453355955812	search ranges efficiently and compatibly as keywords over encrypted data	encrypted data range queries searchable encryption cloud privacy;encryption servers indexes data privacy cloud computing	With recent studies in Searchable Symmetric Encryption (SSE), a client can efficiently perform keyword queries over its outsourced data on a remote but untrusted server (e.g., a public cloud), and correctly retrieve associated files without revealing the confidentiality of his/her data. Besides keyword search, many recent schemes also studied range queries on encrypted data, where range search is also one of the most extensively used queries in databases and information retrieval. However, most of these previous works supporting range search are neither efficient nor compatible with existing keyword SSE schemes. In this paper, we propose two range SSE schemes to enable range queries on encrypted data. Both of our schemes are not only efficient, but also highly compatible with existing keyword SSE schemes. Specifically, the search time of our first scheme is extremely efficient when the values in a range query are sparsely presenting in a dataset; while our second design can achieve an optimal token size and significantly save token generation costs. Moreover, we rigorously define and analyze the security of our schemes, and also conduct extensive experiments with a real dataset to demonstrate the performance of our schemes.	client-side;cloud computing;confidentiality;database;encryption;experiment;information retrieval;range query (data structures);range query (database);range searching;search algorithm;server (computing);sparse matrix;symmetric-key algorithm	Boyang Wang;Xinxin Fan	2018	IEEE Transactions on Dependable and Secure Computing	10.1109/TDSC.2016.2634013	40-bit encryption;computer science;privacy software;database;on-the-fly encryption;client-side encryption;range query (data structures);encryption;filesystem-level encryption;bus encryption	Security	-40.37734639012198	67.22094390043908	6953
f931e3ae19c536e99cdf8276c1f20cbc55a24ac6	es2: aiming at an optimal virtual i/o event path		Improving the performance of I/O virtualization is a key issue for cloud and datacenter infrastructures, especially with the rapid increase of network interconnection speeds. Previous efforts have made the performance overhead associated with the virtual I/O data path largely negligible. The remaining bottlenecks mainly lie in the event path: hypervisor interventions trigger costly virtual machine (VM) exits and lead to dramatical performance degradation. Aiming at an optimal virtual I/O event path, we propose ES2, a comprehensive scheme that simultaneously improves bidirectional I/O event delivery between guest VMs and their devices. ES2 can provide efficient I/O request delivery, non-exit interrupt delivery and enhanced I/O responsiveness. Moreover, it does not require any modification to guest operating system (OS) or compromise any virtualization benefit. We demonstrate that ES2 greatly reduces VM exit rate with the time in guest (TIG) for I/O processing above 96% for TCP streams and 99% for UDP streams, increases guest throughput by 1.8x for Memcached and 2x for Apache, and keeps guest latency at a very low level.	data center;elegant degradation;experiment;hypervisor;interconnection;interrupt;memcached;operating system;operating-system-level virtualization;overhead (computing);performance;prototype;responsiveness;scalability;single-root input/output virtualization;throughput;virtual machine	Xiaokang Hu;Wang Zhang;Jian Li;Ruhui Ma;Feng Wu;Haibing Guan	2017	2017 46th International Conference on Parallel Processing (ICPP)	10.1109/ICPP.2017.23	full virtualization;parallel computing;virtualization;streams;distributed computing;computer science;real-time computing;hypervisor;cloud computing;virtual machine;computer network;input/output;compromise	HPC	-13.691948146206947	80.8866356465686	6962
066254b91a8e39a6ec6a2f943e15d9a9dde60f74	p2pns: a secure distributed name service for p2psip	decentralized voice over ip networks;dns;sip aors;routing protocols;telematics;service provider;pervasive computing;voice over ip;internet telephony;peer to peer p2psip name service;security mechanisms;p2pns;two stage name resolution;network servers;name service;security of data internet telephony peer to peer computing;cryptography;secure distributed name service;mobile communication;ad hoc networks;two stage name resolution p2pns secure distributed name service p2psip decentralized voice over ip networks server based sip networks p2p sip sip aors dns centralized sip servers security mechanisms;peer to peer computing;peer to peer computing network servers routing protocols proposals pervasive computing telematics internet telephony ad hoc networks mobile communication cryptography;peer to peer;proposals;p2p sip;security of data;centralized sip servers;p2psip;identity theft;server based sip networks	Decentralized voice over IP networks are a promising alternative to classical server-based SIP networks especially in disaster areas or areas without centralized infrastructure. This paper presents P2PNS, a secure distributed name service for P2P SIP. P2PNS can be used to resolve SIP AoRs to contact URIs without using DNS or centralized SIP servers. The name service provides several security mechanisms to efficiently prevent identity theft and to ensure the uniqueness of SIP AoRs in a completely decentralized and untrusted network. The proposed two-stage name resolution mechanism allows to efficiently handle frequent IP address changes. Because P2PNS provides a generic name service it is not limited to P2PS1P but can also be used e.g. to build a distributed DNS system.	centralized computing;directory service;distributed hash table;high-level programming language;key-based routing;login;modular design;peer-to-peer sip;protocol stack;public key infrastructure;seamless3d;server (computing)	Ingmar Baumgart	2008	2008 Sixth Annual IEEE International Conference on Pervasive Computing and Communications (PerCom)	10.1109/PERCOM.2008.91	root name server;telecommunications;computer science;voice over ip;internet privacy;name server;computer security;ubiquitous computing;nsupdate;computer network	Networks	-48.169847497695585	70.76723965022704	6974
020dc9f2cf8917bc8412be966ad89ee3dc882c40	some remarks on a receipt-free and universally verifiable mix-type voting scheme	universally verifiable mix-type voting	At Eurocrypt'95 Sako and Kilian presented the rst Mix-type voting scheme which is receipt-free and universally veriiable. In this contribution we analyze this scheme and show that the coercer must not collude with any center. Otherwise its robustness is lost. As a result, the assumed coercer model is clariied. More seriously, it is further pointed out that the privacy of votes can't be guaranteed, if only one Mix-center is honest. Hence, under the commonly used assumption that only one Mix-center must be honest, the voting scheme is insecure unless modiied.	privacy;sako (programming language)	Markus Michels;Patrick Horster	1996		10.1007/BFb0034841	discrete mathematics	Crypto	-38.54480060949429	74.10677558321976	6993
764315acf031076fe556eb3156f2497df4c64099	parameter selection for real-time controllers in resource-constrained systems	control systems;systems;resource constraint;real time controllers;real time control;embedded systems parameter selection real time controllers resource constrained systems delay jitter controlled system stability real time schedulability analysis;real time;controlled system stability;real time systems control performance embedded systems real time control;control performance;embedded system;resource constrained systems;stability;embedded systems;reglerteknik;parameter selection;scheduling;controllers;real time scheduling;integrated control;stability controllers delays embedded systems jitter parameter estimation scheduling;optimization;parameter estimation;jitter;real time schedulability analysis;real time systems control systems interference delay jitter degradation stability performance analysis embedded system time factors;delays;constrained system;real time systems	In resource-constrained systems, the interference generated by the concurrent execution of multiple controller tasks leads to extra delay and jitter, which degrade control performance and may even jeopardize the stability of the controlled system. This work presents a general methodology that integrates control issues and real-time schedulability analysis to improve the control performance in embedded systems with time and resource constraints. The performance increase is achieved by properly selecting task periods and deadlines under feasibility constraints.	approximation;earliest deadline first scheduling;embedded system;interference (communication);mathematical optimization;real-time clock;real-time operating system;real-time transcription;scheduling analysis real-time systems;simulation	Yifan Wu;Giuseppe M. Buttazzo;Enrico Bini;Anton Cervin	2010	IEEE Transactions on Industrial Informatics	10.1109/TII.2010.2053378	control engineering;embedded system;real-time computing;jitter;real-time control system;stability;computer science;control system;control theory;system;estimation theory;scheduling;statistics	Embedded	-8.189707600619132	61.71682791709895	6995
78e7477d402d51459dddb708db772eb4809a2e87	telnet remote flow control option		"""Telnet Remote Flow Control Option Status of This Memo This RFC specifies an IAB standards track protocol for the Internet community, and requests discussion and suggestions for improvements. Please refer to the current edition of the """"IAB Official Protocol Standards"""" for the standardization state and status of this protocol. Distribution of this memo is unlimited."""	flow control (data);internet architecture board	Charles L. Hedrick	1988	RFC	10.17487/RFC1080	file transfer protocol;resource reservation protocol;ipv6;internet protocol suite;business;internet privacy;computer security;private network;computer network	Networks	-25.433047473998293	88.41997724815968	7005
b67bd4c16d790d13f230af5096ba48424c898fdc	mobile ip handoffs among multiple internet gateways in mobile ad hoc networks	seamless data services;internet protocol;metodo adaptativo;routing protocols;protocols;mobile ip protocol;mobile radiocommunication;protocole transmission;sintesis control;protocolo internet;telecommunication sans fil;mobile ip protocol mobile ip handoffs multiple internet gateways mobile ad hoc networks seamless data services dynamic source routing;simulation;protocole internet;reseau ad hoc mobile;simulacion;methode adaptative;service unifie;radiocommunication service mobile;telecommunication network routing ad hoc networks internet mobile computing protocols;red movil ad hoc;protocolo transmision;handover;internet;telecommunication network routing;mobile ad hoc networks;telecomunicacion sin hilo;synthese commande;adaptive method;multiple internet gateways;seamless service;ad hoc networks;mobile ad hoc network;information gateway;protocole routage;servicio sin costuras;radiocomunicacion servicio movil;transfert intercellulaire;mobile computing;pasarela informacion;passerelle d information;mobile ip handoffs;control synthesis;transferencia entre celdas;mobile ip;dynamic source routing;wireless telecommunication;transmission protocol	In a mobile ad hoc network (MANET) with multiple Internet gateways, efficient management of mobile IP functionality supporting seamless data services is a major challenge. The inadequacy of existing mobile IP schemes applicable to MANETs motivated the search for more efficient gateway discovery/handoff schemes. A solution for mobile IP-based gateway discovery/handoff in dynamic source routing (DSR)-based MANET is formulated. Enhanced mobile IP protocol suitable for MANET environment, i.e. the mobile IP registration controller, is designed. In particular, one of the most significant contributions deals with the mobile IP handoff triggering mechanism which is adaptively assisted by the DSR route maintenance mechanism. Simulation results are provided to support the idea.	ansi escape code;end-to-end principle;hoc (programming language);mobile ip;overhead (computing);seamless3d;simulation;source routing	Shuo Ding	2009	IET Communications	10.1049/iet-com.2008.0275	optimized link state routing protocol;loose source routing;mobile ad hoc network;next-generation network;telecommunications;computer science;ip tunnel;triangular routing;mobile computing;mobile communications over ip;computer security;mobile ip;computer network	Mobile	-13.330465975551924	95.50621512851397	7012
9f34760bdd2072e9c5b7f2d7f63ad81a846ff47b	worry-free encryption: functional encryption with public keys	bob;public key cryptography;non interactive zero knowledge;public key encryption;satisfiability;public key;random oracle model;polynomial time;functional encryption	In this work, we put forward the notion of Worry-Free Encryption. This allows Alice to encrypt confidential information under Bob's public key and send it to him, without having to worry about whether Bob has the authority to actually access this information. This is done by encrypting the message under a hidden access policy that only allows Bob to decrypt if his credentials satisfy the policy. Our notion can be seen as a functional encryption scheme but in a public-key setting. As such, we are able to insist that even if the credential authority is corrupted, it should not be able to compromise the security of any honest user.  We put forward the notion of Worry-Free Encryption and show how to achieve it for any polynomial-time computable policy, under only the assumption that IND-CPA public-key encryption schemes exist. Furthermore, we construct CCA-secure Worry-Free Encryption, efficiently in the random oracle model, and generally (but inefficiently) using simulation-sound non-interactive zero-knowledge proofs.	access control;alice and bob;ciphertext indistinguishability;computable function;confidentiality;credential;functional encryption;interactivity;polynomial;public-key cryptography;random oracle;simulation;time complexity;zero-knowledge proof	Amit Sahai;Hakan Seyalioglu	2010		10.1145/1866307.1866359	multiple encryption;disk encryption theory;40-bit encryption;plaintext-aware encryption;client-side encryption;computer science;theoretical computer science;link encryption;on-the-fly encryption;internet privacy;public-key cryptography;deterministic encryption;computer security;encryption;probabilistic encryption;three-pass protocol;56-bit encryption;attribute-based encryption;key encapsulation;keyfile	Security	-40.36059859408296	74.38157711006109	7016
dddb6f5957084afe1e7ccbfa034a9b8b4a42e3e0	openfunction: an extensible data plane abstraction protocol for platform-independent software-defined middleboxes		The data plane abstraction is central to software-defined networking SDN. Currently, SDN data plane abstraction has only been realized for switches but not for middleboxes. A data plane abstraction for middleboxes is needed to realize the vision of software-defined middleboxes SDMs. Such a data plane abstraction should be both platform independent and fully extensible. The match-action abstractions in OpenFlow/P4 have limited expression power to be applicable to middleboxes. Modular abstraction approaches have been proposed to implement middlebox data plane but are not fully extensible in a platform-independent manner. In this paper, we propose OpenFunction, an extensible data plane abstraction protocol for platform-independent software-defined middleboxes. The main challenge is how to abstract packet operations, flow states, and event generations with elements. The key decision of OpenFunction is: actions/states/events operations should be defined in a uniform pattern and independent from each other. We implemented a working SDM system including one OpenFunction controller and three OpenFunction boxes based on Netmap, DPDK, and FPGA, respectively, to verify OpenFunction abstraction.	dpdk / dpdk.org;field-programmable gate array;forwarding plane;middlebox;network packet;network switch;openflow;software-defined networking;stateful firewall;stateless protocol	Chen Tian;Ali Munir;Alex X. Liu;Jie Yang;Yangming Zhao	2018	IEEE/ACM Transactions on Networking	10.1109/TNET.2018.2829882	openflow;computer science;distributed computing;software-defined networking;extensibility;middlebox;forwarding plane;network packet;abstraction;server	Networks	-14.86844266951825	82.33942772217051	7026
5ed8cdf9760e865f1df5544ac5eefc811e1e9b48	extending erlang for safe mobile code execution	informatica;langage fonctionnel;protection information;controle acces;language use;encryption;securite;implementation;lenguaje funcional;prototipo;ejecucion;cryptage;proteccion informacion;criptografia;cryptography;execution environment;information protection;safety;mobile code;cryptographie;informatique;source code;access control;erlang;computer science;functional language;seguridad;prototype;system safety	This paper discusses extensions to the functional language Erlang which provide a secure execution environment for remotely sourced code. This is in contrast to much existing work which has focused on securing procedural languages. Using a language such as Erlang provides a high degree of inherent run-time safety, which means e ort can be focused on providing a suitable degree of system safety. We found that the main changes needed were the use of unforgeable (capability) references with access rights to control the use of system resources; the provision of a hierarchy of execution nodes to provide custom views of the resources available and to impose utilisation limits; and support for remote module loading. We then discuss prototype implementations of these changes, used to evaluate their utility and impact on visibility for the users of the language, and mention work in progress using this foundation to specify safety policies by ltering messages to server processes.	erlang (programming language);functional programming;open road tolling;prototype;server (computing);system safety	Lawrie Brown;Dan Sahlin	1999		10.1007/978-3-540-47942-0_5	erlang;real-time computing;computer science;cryptography;artificial intelligence;access control;operating system;database;distributed computing;prototype;programming language;functional programming;implementation;system safety;computer security;encryption;algorithm;source code	Security	-35.10476378132347	60.734429379653186	7049
2f74a0f126ce1315cce84a1695bcb7781148ce49	secure key loss recovery for network broadcast in single-hop wireless sensor networks	time varying;key chain;sensor network;wireless sensor network;network broadcast;base station;sensor nodes;key loss recovery;wireless sensor networks;privacy;symmetric encryption;authenticity	Symmetric encryption of data at the base-station using time-varying keys has been proposed as an attractive method for securing broadcasts in wireless sensor networks: symmetric decryption keeps computational costs at sensor nodes low, while time-varying group keys protect the network against key compromise at any of the receivers. However, a significant problem is that interference or disconnections may cause a receiver to miss broadcast packets and the dynamic keys contained therein, rendering it unable to participate in subsequent broadcasts. In this paper, we develop a scheme which allows receivers to recover from key loss in a secure, efficient, and scalable manner. Our scheme appends recovery information to each broadcast message to help out-of-sync receivers re-attach probabilistically using an older key. We analyze our scheme to quantify the recovery probability as a function of system parameters, and deduce fundamental asymptotic bounds on recovery. We further prototype our scheme on the MicaZ mote platform and show that it is light-weight and efficient. Our solution offers a highly configurable, efficient and scalable method for key recovery in large sensor networks that require secure broadcasts. This submission is an extended version of a paper presented at the 19th Annual IEEE Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC’08), Cannes, Sep. 2008. ∗Corresponding author: Syed Taha Ali, School of Electrical Engineering and Telecommunications, UNSW, Sydney, NSW 2052, Australia. Email: taha@student.unsw.edu.au, Tel: +61 2 9385 4477, Fax: +61 2 9385 5993. Email addresses: taha@student.unsw.edu.au (Syed Taha Ali), vijay@unsw.edu.au (Vijay Sivaraman), ashay@unsw.edu.au (Ashay Dhamdhere), diet.ostry@csiro.au (Diethelm Ostry) Preprint submitted to Ad Hoc Networks June 30, 2009	computation;computational resource;confidentiality;electrical engineering;email;encryption;fax;interference (communication);key escrow;message authentication;prototype;robustness of complex networks;scalability;sensor node;simulation;symmetric-key algorithm;transmitter;uniform resource identifier	Syed Taha Ali;Vijay Sivaraman;Ashay Dhamdhere;Diethelm Ostry	2010	Ad Hoc Networks	10.1016/j.adhoc.2010.01.003	embedded system;wireless sensor network;telecommunications;computer science;key distribution in wireless sensor networks;key distribution;computer security;computer network	Mobile	-50.17686246574921	76.99846229248918	7055
eb9e8ba2254d1e4fa10e5c3e18d383c44bd76189	a review on remote data auditing in single cloud server: taxonomy and open issues	proof of ownership;t technology;provable data possession;proof of retrievability;remote data auditing;cloud computing	Cloud computing has emerged as a computational paradigm and an alternative to the conventional computing with the aim of providing reliable, resilient infrastructure, and with high quality of services for cloud users in both academic and business environments. However, the outsourced data in the cloud and the computation results are not always trustworthy because of the lack of physical possession and control over the data for data owners as a result of using to virtualization, replication and migration techniques. Since that the security protection the threats to outsourced data have become a very challenging and potentially formidable task in cloud computing, many researchers have focused on ameliorating this problem and enabling public auditability for cloud data storage security using remote data auditing (RDA) techniques. This paper presents a comprehensive survey on the remote data storage auditing in single cloud server domain and presents taxonomy of RDA approaches. The objective of this paper is to highlight issues and challenges to current RDA protocols in the cloud and the mobile cloud computing. We discuss the thematic taxonomy of RDA based on significant parameters such as security requirements, security metrics, security level, auditing mode, and update mode. The state-of-the-art RDA approaches that have not received much coverage in the literature are also critically analyzed and classified into three groups of provable data possession, proof of retrievability, and proof of ownership to present a taxonomy. It also investigates similarities and differences in such framework and discusses open research issues as the future directions in RDA research. & 2014 Elsevier Ltd. All rights reserved.	access control;cp/m;computation;computer data storage;data access;data integrity;data validation;display resolution;dynamic data;evolutionary taxonomy;hardware virtualization;mobile cloud computing;open research;outsourcing;privacy;programming paradigm;provable security;remote database access;replication (computing);requirement;retrievability;server (computing);storage security;system migration;taxonomy (general);trust (emotion);virtual private server	Mehdi Sookhak;Hamid Talebian;Ejaz Ahmed;Abdullah Gani;Muhammad Khurram Khan	2014	J. Network and Computer Applications	10.1016/j.jnca.2014.04.011	cloud computing security;cloud computing;computer science;operating system;data mining;world wide web;computer security;computer network	Security	-41.89948467727957	66.57091828807032	7060
ab9f11eb22d4a6e5c36e5be2ed9da68b0799838b	dynamic outsourced proofs of retrievability enabling auditing migration for remote storage security		Remote data auditing service is important for mobile clients to guarantee the intactness of their outsourced data stored at cloud side. To relieve mobile client from the nonnegligible burden incurred by performing the frequent data auditing, more and more literatures propose that the execution of such data auditing should be migrated from mobile client to third-party auditor (TPA). However, existing public auditing schemes always assume that TPA is reliable, which is the potential risk for outsourced data security. Although Outsourced Proofs of Retrievability (OPOR) have been proposed to further protect against the malicious TPA and collusion among any two entities, the original OPOR scheme applies only to the static data, which is the limitation that should be solved for enabling data dynamics. In this paper, we design a novel authenticated data structure called bv23Tree, which enables client to batch-verify the indices and values of any number of appointed leaves all at once for efficiency. By utilizing bv23Tree and a hierarchical storage structure, we present the first solution for Dynamic OPOR (DOPOR), which extends the OPOR model to support dynamic updates of the outsourced data. Extensive security and performance analyses show the reliability and effectiveness of our proposed scheme.		Lu Rao;Tengfei Tu;Hua Zhang;Qiaoyan Wen;Jia Xiao	2018	Wireless Communications and Mobile Computing	10.1155/2018/4186243	computer science;distributed computing;collusion;cloud computing;storage security;data security;retrievability;audit;data structure;authentication	DB	-42.174960411645074	67.89214735219727	7067
001dc0e96172432d40f6a514e1b623e20d0381f8	pacemakers and implantable cardiac defibrillators: software radio attacks and zero-power defenses	protocols;pacemakers software radio security privacy protocols software safety cardiology programming profession frequency oscilloscopes;zero power defenses;terrorism cardiovascular system defibrillators health and safety pacemakers programmable circuits security software radio;human perceptible mitigation techniques;partial reverse engineering;pervasive computing;cardiology;software radio attacks;pacemakers;patient privacy;radiocommunications protocol;implantable medical devices;software radio;defibrillators;implantable cardioverter defibrillators;software safety;programming profession;programmable circuits;health and safety;rf power harvesting;cardiovascular system;patient safety;medical safety;power consumption;pacemaker technology;frequency;oscilloscope;security;security aspects;privacy;pervasive computing medical safety implantable medical devices security privacy;human perceptible mitigation techniques pacemaker technology implantable cardioverter defibrillators software radio attacks zero power defenses patient safety patient privacy partial reverse engineering radiocommunications protocol oscilloscope security aspects power consumption rf power harvesting implantable medical devices;terrorism;oscilloscopes	Our study analyzes the security and privacy properties of an implantable cardioverter defibrillator (ICD). Introduced to the U.S. market in 2003, this model of ICD includes pacemaker technology and is designed to communicate wirelessly with a nearby external programmer in the 175 kHz frequency range. After partially reverse-engineering the ICD's communications protocol with an oscilloscope and a software radio, we implemented several software radio-based attacks that could compromise patient safety and patient privacy. Motivated by our desire to improve patient safety, and mindful of conventional trade-offs between security and power consumption for resource-constrained devices, we introduce three new zero-power defenses based on RF power harvesting. Two of these defenses are human-centric, bringing patients into the loop with respect to the security and privacy of their implantable medical devices (IMDs). Our contributions provide a scientific baseline for understanding the potential security and privacy risks of current and future IMDs, and introduce human-perceptible and zero-power mitigation techniques that address those risks. To the best of our knowledge, this paper is the first in our community to use general-purpose software radios to analyze and attack previously unknown radio communications protocols.	access control;artificial cardiac pacemaker;authentication;authorization;baseline (configuration management);communications protocol;cryptography;denial-of-service attack;firewall (computing);frequency band;general-purpose modeling;implantable cardioverter-defibrillator;internet;key exchange;malware;medical privacy;norm (social);programmer;prototype;radio frequency;rechargeable battery;reverse engineering;signal processing;trusted computing base;usc interactive media & games division;zero	Daniel Halperin;Thomas S. Benjamin;Benjamin Ransford;Shane S. Clark;Benessa Defend;Will Morgan;Kevin Fu;Tadayoshi Kohno;William H. Maisel	2008	2008 IEEE Symposium on Security and Privacy (sp 2008)	10.1109/SP.2008.31	computer science;information security;occupational safety and health;computer security;ubiquitous computing;oscilloscope	Security	-51.07938061691745	72.12129703013714	7068
975f45280937b71979951d71949851e824097d1b	sp-aelm: sponge based authenticated encryption scheme for memory constrained devices		In authenticated encryption schemes, there are two techniques for handling long ciphertexts while working within the constraints of a low buffer size: Releasing unverified plaintext (RUP) or Producing intermediate tags (PIT). In this paper, in addition to these two techniques, we propose another way to handle a long ciphertext with a low buffer size by storing and releasing only one (generally, or only few) intermediate state, without releasing or storing any part of an unverified plaintext and without need of generating any intermediate tag. In this paper we explain this generalized technique using our new construction sp-AELM. sp-AELM is a sponge based authenticated encryption scheme that provides support for limited memory devices. We also provide its security proof for privacy and authenticity in an ideal permutation model, using a code based game playing framework. Furthermore, we also present two more variants of sp-AELM that serve the same purpose and are more efficient than sp-AELM.	authenticated encryption;authentication	Megha Agrawal;Donghoon Chang;Somitra Kumar Sanadhya	2015		10.1007/978-3-319-19962-7_26	theoretical computer science;sponge function;distributed computing;filesystem-level encryption;on-the-fly encryption;authenticated encryption;computer security;encryption	Crypto	-38.274833912518964	77.65236368051892	7073
bb6f7b08de37cadee42d0440da14b7dbe9232c66	analysis of vbr coded voip for traffic classification	belief networks;variable rate codes belief networks internet telephony learning artificial intelligence neural nets telecommunication network management telecommunication traffic;codecs accuracy payloads entropy training media streaming media;neural nets;internet telephony;entropy voip rtp traffic classification;variable rate codes;telecommunication traffic;learning artificial intelligence;naive bayes vbr coded voip analysis voice over internet protocol voip traffic classification network management operations media traffic real time transport protocol variable bit rate codecs vbr codecs vbr voice codecs dynamic payload type isac silk speex rtp flow entropy values packet content rtp traffic machine learning techniques machine learning algorithms 1 nn c4 5;telecommunication network management	Classification of Voice over Internet Protocol (VoIP) traffic is important for network management operations. The media traffic, which carries the voice on Real-time Transport Protocol (RTP), is subjected to variation in transmitted packet sizes and content due to the usage of Variable Bit Rate (VBR) codecs. In the absence of session level information, the RTP header does not uniquely identify the VBR voice codecs defined as dynamic payload type. In this paper we present a method to classify VoIP traffic coded with three VBR codecs - iSAC, SILK and Speex. We first formulate features to characterize an RTP flow based on packet size and entropy values of the packet content. The features are used for classification of RTP traffic based on codec using machine learning techniques. The paper reports classification results using the three machine learning algorithms, namely 1-NN, C4.5 and Naive Bayes. The results show an accuracy of over 98% for offline classification with the reduced feature set. The paper also presents the performance of the classifiers with varying size of available traffic.	c4.5 algorithm;codec;entropy (information theory);machine learning;naive bayes classifier;network packet;online and offline;real-time transcription;silk;traffic classification;volume boot record	Paromita Choudhury;K. R. Prasanna Kumar;G. Athithan;Sukumar Nandi	2013	2013 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2013.6637152	speech recognition;telecommunications;computer science;artificial intelligence;machine learning;voice over ip;artificial neural network;computer network	Metrics	-4.775355169523955	99.23858943957023	7074
c1549bd8f33edb5638698efae7d61d617bc7ff44	a framework for semantic in-network caching and prefetching in 5g mobile networks		Recent popularity of mobile devices increased the demand for mobile network services and applications that require minimal delay. 5G mobile networks are expected to provide much lesser delay than the present mobile networks. One of the conventional ways for decreasing latency is caching content closer to end users. However, currently deployed methods are not effective enough. In this paper, we propose a new astute in-network caching framework that is able to smartly predict subsequent user requests and prefetch necessary contents to remarkably decrease the end-to-end latency in 5G mobile networks. We employ semantic inference by edge computing, deduce what the end-user may request in the sequel and prefetch the content. We validate the proposed technique by emulations, compare it with the state of the art and present impressive gains.	cpu cache;cache (computing);cylinder-head-sector;edge computing;emoticon;emulator;end-to-end principle;gw-basic;hit (internet);iso 8601;internet;interrupt latency;link prefetching;mike lesser;mobile device;test case	Can Mehteroglu;Yunus Durmus;Ertan Onur	2017	CoRR		latency (engineering);computer network;instruction prefetch;end user;computer science;distributed computing;inference;mobile device;popularity;edge computing;cellular network	Mobile	-18.49427895531878	77.67234466405827	7076
7269aeccdfd564651a1ba20e9066c531ab3a5ca4	possibility and impossibility results for selective decommitments	provable security;parallel composition;commitments;interactive proofs;black box separations;zero knowledge;commitment scheme	The selective decommitment problem can be described as follows: assume that an adversary receives a number of commitments and then may request openings of, say, half of them. Do the unopened commitments remain secure? Although this question arose more than twenty years ago, no satisfactory answer could be presented so far. We answer the question in several ways: 1. If simulation-based security is desired (i.e., if we demand that the adversary’s output can be simulated by a machine that does not see the unopened commitments), then security is not provable for noninteractive or perfectly binding commitment schemes via black-box reductions to standard cryptographic assumptions. However, we show how to achieve security in this sense with interaction and a non-black-box reduction to one-way permutations. 2. If only indistinguishability of the unopened commitments from random commitments is desired, then security is not provable for (interactive or noninteractive) perfectly binding commitment schemes, via black-box reductions to standard cryptographic assumptions. However, any statistically hiding scheme does achieve security in this sense. Our results give an almost complete picture when and how security under selective openings can be achieved. Applications of our results include: Essentially, an encryption scheme must be non-committing in order to achieve provable security against an adaptive adversary. When implemented with our secure commitment scheme, the interactive proof for graph 3-coloring due to becomes zero-knowledge under parallel composition. On the technical side, we develop a technique to show very general impossibility results for black-box proofs. If simulation-based security is desired (i.e., if we demand that the adversary’s output can be simulated by a machine that does not see the unopened commitments), then security is not provable for noninteractive or perfectly binding commitment schemes via black-box reductions to standard cryptographic assumptions. However, we show how to achieve security in this sense with interaction and a non-black-box reduction to one-way permutations. If only indistinguishability of the unopened commitments from random commitments is desired, then security is not provable for (interactive or noninteractive) perfectly binding commitment schemes, via black-box reductions to standard cryptographic assumptions. However, any statistically hiding scheme does achieve security in this sense. Essentially, an encryption scheme must be non-committing in order to achieve provable security against an adaptive adversary. When implemented with our secure commitment scheme, the interactive proof for graph 3-coloring due to becomes zero-knowledge under parallel composition.	adversary (cryptography);black box;commitment scheme;cryptography;encryption;interactivity;one-way function;provable security;resource bounded measure;simulation	Dennis Hofheinz	2008	Journal of Cryptology	10.1007/s00145-010-9066-x	commitment scheme;computer science;provable security;mathematics;distributed computing;computer security;algorithm;zero-knowledge proof	Crypto	-37.81470343595343	75.03543643108489	7083
8a6311f78f695ac6a96f2788187f2617f14e6c41	a survey and taxonomy of name systems in mobile ad hoc networks	replication;name space;name resolution;name system;conflict resolution	Name systems are one of the main components of each network that delivers services such as name registration and name resolution for network users and applications. On the Internet, DNS is used to provide easy communications and automatic name to address translations, but because of special characteristics of mobile ad hoc networks it cannot be used on the MANETs. Therefore, various special purpose solutions have been designed to provide name services in different types of MANETs. In this paper, we present taxonomy of MANET name systems based on their architecture and specify the operations that each category of name systems should support. We discuss about the properties and capabilities of each kind of name systems and compare the overheads of each scheme. This survey clarifies the advantages and disadvantages of each name system and is of high importance to understand the weakness of existing name systems and designing effective and complete name systems. Finally, we conclude with open research issues.	hoc (programming language);taxonomy (general)	Mohammad Masdari;Mehdi Maleknasab;Moazam Bidaki	2012	J. Network and Computer Applications	10.1016/j.jnca.2012.02.012	root name server;replication;fully qualified name;name resolution;telecommunications;computer science;conflict resolution;distributed computing;programming language;name server;computer security;domain name system	Mobile	-26.571441154524887	85.00276416297352	7085
3f26761fe7f0699174ad89c81ce1f60426294d02	a review of black hole attack on aodv routing in manet		Mobile ad hoc network (MANET) is a collection of wireless mobile nodes dynamically forming a temporary network without the use of any existing network infrastructure or centralized access point such as a base station. MANET has potential applications in very unpredictable and dynamic environments. The nodes, which act as a host as well as a router, communicate to each other through multi hops due to limited transmission ranges. MANETs pose new kinds of security problems, caused by their nature of collaborative, open systems and by limited availability of resources. Unlike other types of network, MANETs are usually deployed without a centralized control unit. Hence, mutual cooperation amongst the participating entities forms the basis for determining the routes to the destination. This aspect makes MANETs vulnerable to various communication security related attacks including Black Hole attack. Therefore, the direct application of the conventional routing algorithms is infeasible. Black Hole attacks are launched by participating malicious nodes that agree to forward data packets to destination but eavesdrop or drop the packets intentionally, which not only compromise the network, but also degrade network performance. Routing protocols, which act as the binding force in these networks, are a common target of these nodes. According to our analysis, none of the existing attempts to secure MANETs is complete by itself. In this paper, a survey on secure Ad-hoc On-Demand Distance Vector (AODV) routing in MANET against Black Hole attack is presented. AODV is a prominent on-demand reactive routing protocol for MANETs based on distance vector routing. The route updates are shared not on a periodic but on an as requirement basis. The control packets create a potential vulnerability that is frequently exploited by malicious nodes. The paper further analyses the impact of Black Hole attack in AODV performance. KeywordsMobile ad hoc network (MANET); Secure AODV Routing; Black Hole attack	algorithm;anomaly detection;black hole;centralized computing;communications security;control unit;distance-vector routing protocol;entity;hoc (programming language);limited availability;malware;network congestion;network packet;network performance;router (computing);sensor;throughput;wireless access point	Elisha O. Ochola;Mariki M. Eloff	2011			computer security;packet drop attack;mobile ad hoc network;computer science;computer network;distance-vector routing protocol;ad hoc on-demand distance vector routing;network packet;routing protocol;wireless ad hoc network;compromise	Security	-54.41492505554662	76.26450902624455	7097
291605a4879364e091a80a9da248a7394f94407b	attacks on authentication and signature schemes involving corruption of public key (modulus)	public key cryptography;corruption of public key modulus;smart card;protocols;private key cryptography;cryptography smart cards protocols authentication elliptic curves public key elliptic curve cryptography;public key cryptography authorisation private key cryptography protocols;elliptic curves;elliptic curve;asymmetric cryptographic schemes;authorisation;fault injection attacks authentication attacks signature schemes public key corruption asymmetric cryptographic schemes elliptic curves signature protocol private key guillou quisquater authentication;elliptic curve cryptography fault injection attacks corruption of public key modulus attacks on signature and authentication schemes smart cards;public key corruption;authentication;authentication attacks;signature protocol;signature scheme;elliptic curve cryptography;public key;attacks on signature and authentication schemes;private key;smart cards;guillou quisquater authentication;cryptography;fault injection attacks;fault injection;signature schemes	Brier et al (2006) showed how to attack RSA by induction of faults in public modulus n. We propose to use the same kind of technique to attack other asymmetric cryptographic schemes. The most interesting case in which we use a somewhat different approach is the attack on Elliptic Curves based signature protocol (namely ECDSA). Here we also take advantage of the short keys to offer a nontrivial practical attack that enables us to fully recover the private key. Different idea is used to attack Guillou-Quisquater authentication scheme (GQ). This demonstrates how the difference between schemes influences the details of the modulus corruption attacks. Special efforts were devoted to calculate the amount of corrupted data to perform the attack on each scheme. Various ways of protection against fault injection attacks on public key elements are discussed.	authentication;fault injection;mathematical induction;modulus of continuity;modulus robot;public-key cryptography	Michael Kara-Ivaniov;Eran Iceland;Aviad Kipnis	2008	2008 5th Workshop on Fault Diagnosis and Tolerance in Cryptography	10.1109/FDTC.2008.20	chosen-ciphertext attack;reflection attack;pre-play attack;challenge–response authentication;birthday attack;mathematics;internet privacy;brute-force attack;computer security;computer network	Security	-41.36676304191487	75.90119295519955	7100
bf0e84935d3b9e44fd9390883a9ba8b4331f9c31	gaming the game: defeating a game captcha with efficient and robust hybrid attacks	object tracking authorisation computer games image colour analysis;light emitting diodes high definition video;online human intelligence dynamic cognitive game captcha interactive captcha security improvement automated human solver relay attacks dcg captcha semantic gap synchronization issues hybrid attack framework offline human intelligence automated program static ai problem dcg object tracking algorithm color code histogram computer algorithms;multi object tracking captcha web security hybrid attack visual processing	Dynamic Cognitive Game (DCG) CAPTCHAs are a promising new generation of interactive CAPTCHAs aiming to provide improved security against automated and human-solver relay attacks. Unlike existing CAPTCHAs, defeating DCG CAPTCHAs using pure automated attacks or pure relay attacks may be challenging in practice due to the fundamental limitations of computer algorithms (semantic gap) and synchronization issues with solvers. To overcome this barrier, we propose two hybrid attack frameworks. which carefully combine the strengths of an automated program and offline/online human intelligence. These hybrid attacks require maintaining the synchronization only between the game and the bot similar to a pure automated attack, while solving the static AI problem (i.e., bridging the semantic gap) behind the game challenge similar to a pure relay attack. As a crucial component of our framework, we design a new DCG object tracking algorithm, based on color code histogram, and show that it is simpler, more efficient and more robust compared to several known tracking approaches. We demonstrate that both frameworks can effectively defeat a wide range of DCG CAPTCHAs.	algorithm;bridging (networking);captcha;definite clause grammar;distributed common ground system;online and offline;relay attack;solver;two-hybrid screening	Song Gao;Manar Mohamed;Nitesh Saxena;Chengcui Zhang	2014	2014 IEEE International Conference on Multimedia and Expo (ICME)	10.1109/ICME.2014.6890287	computer science;multimedia;world wide web;computer security	Security	-49.222132223689854	69.08898335087174	7111
010d3d0c0cf19d655039335235d2fd3e8dd06e88	intra-site automatic tunnel addressing protocol (isatap)	link layer;non broadcast multiple access	"""This document specifies a method for connecting IPv6 hosts and routers (nodes) within predominantly IPv4-based sites. This method is based on an IPv6-IPv4 compatibility aggregatable global unicast address format (described herein) that embeds the IPv4 address of a node within the EUI-64 format interface identifier of an IPv6 address. This document assumes that, during the IPv4 to IPv6 coexistence and transition phase, many sites will deploy IPv6 incrementally within their IPv4 interior routing domains; especially those sites which have large and complex pre-existing IPv4 infrastructures. Within such sites, the address format and methods described in this document will enable IPv6 deployment for nodes that do not share a common multiple access datalink with an IPv6 gateway within their site. While other works in progress in the NGTRANS working group propose mechanisms for assigning globally-unique IPv6 address prefixes to sites and methods for inter-domain routing between such sites, the approach outlined in this memo enables large-scale incremental deployment of IPv6 for nodes within a site’s pre-existing IPv4 infrastructure without incurring aggregation scaling issues at the border gateways nor requiring site-wide deployment of special IPv4 services such as multicast. The approach proposed by this document supports IPv6 routing within both the site-local and global IPv6 routing domains as well as automatic IPv6 in IPv4 tunneling across portions of a site’s IPv4 infrastructure which have no native IPv6 support. Moreover, this approach supports automatic tunneling within sites which use non globally-unique IPv4 address assignments, such as when Network Address Translation [NAT] is used. Status of this Memo This document is an Internet-Draft and is in full conformance with all provisions of Section 10 of RFC2026. Templin Expires 12 October 2001 [Page 1] INTERNET-DRAFT Intra-Site Automatic Tunnel Addressing 12 March 2001 Internet-Drafts are working documents of the Internet Engineering Task Force (IETF), its areas, and its working groups. Note that other groups may also distribute working documents as InternetDrafts. Internet-Drafts are draft documents valid for a maximum of six months and may be updated, replaced, or obsoleted by other documents at any time. It is inappropriate to use InternetDrafts as reference material or to cite them other than as """"work in progress."""" The list of current Internet-Drafts can be accessed at http://www.ietf.org/ietf/1id-abstracts.txt The list of Internet-Draft Shadow Directories can be accessed at http://www.ietf.org/shadow.html."""	classless inter-domain routing;coexist (image);conformance testing;document;identifier;image scaling;internet;layer 2 tunneling protocol;mac address;multicast;network address translation;router (computing);software deployment;unicast	Fred L. Templin;Tim Gleeson;Mohit Talwar;David Thaler	2005	RFC	10.17487/RFC4214	computer science;distributed computing;computer security;computer network	Metrics	-24.871180493613497	89.08214394700559	7182
50e8acd1aceb99fcb8ba677714545b40644f3074	orthogonal expansion of port-scanning packets	port scan;sensor systems;sensor phenomena and characterization;approximate algorithm;data compression;approximation algorithm;principal component analysis internet sensor phenomena and characterization statistical distributions telecommunication traffic information systems electronic mail data mining statistical analysis approximation algorithms;orthogonal factors;pca port scan;packet data compression port scanning packets internet distributed sensors orthogonal factors approximation algorithm;distributed sensors;internet;estimation;principal component analysis;port scanning packets;grippers;approximation methods;security of data data compression distributed sensors internet;packet data compression;pca;security of data	Observation of port-scan packets performed over the Internet is involved with so many parameters including time, port numbers, source and destination addresses. There are some common port numbers to which many malicious codes likely use to scan, but a relationship between port numbers and the malicious codes are not clearly identified. In this paper, we propose a new attempt to figure characteristics of port-scans observed from distributed many sensors. Our method allows 1) analysis of sensors with few significant factors extracted from an orthogonal expansion of port-scan packets, rather than taking care of all possible statistics of port numbers, 2) compression of packets data, computed by linear combination of limited number of orthogonal factors, and 3) approximation of number of scanning packets at arbitrarily specified sensor and ports, made from statistical correlation between port numbers. We also evaluate the accuracy of our proposed approximation algorithm based on actually observed packets.	approximation algorithm;care-of address;code;port scanner;sensor	Hiroaki Kikuchi;Tomohiro Kobori;Masato Terada	2009	2009 International Conference on Network-Based Information Systems	10.1109/NBiS.2009.82	telecommunications;computer science;theoretical computer science;approximation algorithm;statistics;computer network;principal component analysis	DB	-61.44254943598996	68.30481416767705	7189
d30454569811ce701cd72aee6f22e203e5ee3376	attack on the edon-k key encapsulation mechanism		The key encapsulation mechanism EDON-K was proposed in response to the call for post-quantum cryptography standardization issued by the National Institute of Standards and Technologies (NIST). This scheme is inspired by the McEliece scheme but uses another family of codes defined over F2128 instead of F2 and is not based on the Hamming metric. It allows significantly shorter public keys than the McEliece scheme. In this paper, we give a polynomial time algorithm that recovers the encapsulated secret. This attack makes the scheme insecure for the intended use. We obtain this result by observing that recovering the error in the McEliece scheme corresponding to EDON-K can be viewed as a decoding problem for the rankmetric. We show that the code used in EDON-K is in fact a super-code of a Low Rank Parity Check (LRPC) code of very small rank (1 or 2). A suitable parity-check matrix for the supercode of such low rank can be easily derived from for the public key. We then use this parity-check matrix in a decoding algorithm that was devised for LRPC codes to recover the error. Finally we explain how we decapsulate the secret once we have found the error.	algorithm;code;encapsulation (networking);hamming distance;key encapsulation;mceliece cryptosystem;p (complexity);parity-check matrix;post-quantum cryptography;public-key cryptography;quantum cryptography	Matthieu Lequesne;Jean-Pierre Tillich	2018	CoRR			Crypto	-37.42520462112723	79.68472820736001	7210
9f42cfa77c097ad88c24f24eed3db2320c5dc1f2	efficient replication for vehicular content distribution		Abstract We consider a vehicular content replication system which makes use of the deployed Access Points (APs) to maximize the vehicular download progress of delay-tolerant contents through replication in the APsu0027 local storage. The replication system for vehicular users is quite different from the traditional system for static Web users. The transient connection period between the vehicle and the AP makes it difficult for the vehicle to download the entire file requested and thus the content retrieval is usually across several APs. Such characteristic poses two problems: (1) replication in units of entire file may be inefficient in terms of resource utilization; (2) the actual contribution of an individual AP can be affected by the other correlated APs during the content retrieval. To deal with these challenges, we formulate the vehicular content retrieval into an offline optimization model that helps establish the performance bounds of replication algorithms in maximizing vehicular download progress. A real vehicular trace is also thoroughly analyzed. Then we propose an efficient and distributed replication algorithm explicitly taking into account the content popularity, vehicle-AP contact pattern and content availability among correlated APs. Simulation based on real vehicular trace proves the effectiveness of the proposed replication system. The performance in terms of download rate and completion ratio has at least 15% to 20% improvement against the algorithms under comparison.		Da Zhang;Chai Kiat Yeo	2018	Vehicular Communications	10.1016/j.vehcom.2018.04.004	computer science;distributed computing;download	Mobile	-15.268338904521482	71.83060432894311	7219
c1268810ade2ca741fa42c9d60a928a9a2a678d8	user-empowered programmable network support for collaborative environment	virtual private network;virtual multicast;evaluation performance;multicast communication;performance evaluation;routing;evaluacion prestacion;reseau ordinateur;routage;communication groupe;group communication;computer network;collaborative environment;programmable udp packet reflector;synchronous distribution networks;overlay network;red informatica;communication protocol;communication multidestinataire;programmable networks;reseau prive virtuel;enrutamiento	We introduce a user-empowered UDP packet reflector to create virtual multicasting environments as an overlay on top of current unicast networks. The end-users’ ability to fully control this environment by a specific communication protocol is the main advantage of our approach. Serializing the parallel communication schema for group communication allows us to introduce special features that are possible in unicast communication only. Similar to working with programmable routers, users can submit their own modules, which can be linked into the reflector and perform user-specific operations (filtering, transcoding etc.). The reflector is the basic element of the overlay network support for the user-empowered group communication in collaborative environments.	communications protocol;multicast;network packet;overlay network;serialization;unicast	Eva Hladká;Petr Holub;Jirí Denemark	2004		10.1007/978-3-540-30197-4_37	communications protocol;routing;overlay network;telecommunications;communication in small groups;computer science;operating system;distributed computing;computer network	Networks	-21.001899573508787	90.19255562453445	7227
7e11ad6dee5967eac42ad5d2d72b34ad5f8db27d	minimal backups of cryptographic protocol runs	fault tolerant;programming language;cryptographic protocols;coq;protocol design;cryptographic protocol;cppl;strand spaces;coq proof assistant	As cryptographic protocols execute they accumulate information such as values and keys, and evidence of properties about this information. As execution proceeds, new information becomes relevant while some old information ceases to be of use. Identifying what information is necessary at each point in a protocol run is valuable for both analysis and deployment.  We formalize this necessary information as the minimal backup of a protocol. We present an analysis that determines the minimal backup at each point in a protocol run. We show that this minimal backup has many uses: it serves as a foundation for job-migration and other kinds of fault-tolerance, and also assists protocol designers understand the structure of protocols and identify potential flaws.  In a cryptographic context it is dangerous to reason informally. We have therefore formalized and verified this work using the Coq proof assistant. Additionally, Coq provides a certified implementation of our analysis. Concretely, our analysis and its implementation consume protocols written in a variant of the Cryptographic Protocol Programming Language, CPPL.	authentication;backup;communications protocol;coq (software);cryptographic protocol;cryptography;denotational semantics;fault tolerance;formal proof;mathematical optimization;programming language;proof assistant;replay attack;scalability;software deployment;spore	Jay A. McCarthy;Shriram Krishnamurthi	2008		10.1145/1456396.1456398	cryptographic primitive;universal composability;computer science;theoretical computer science;key management;cryptographic protocol;distributed computing;programming language;algorithm	Security	-51.665314913250825	79.30795505388355	7244
2725462b5933ab19770c4ad2004d0ea8b278d995	datagram congestion control protocol (dccp) simultaneous-open technique to facilitate nat/middlebox traversal		"""This document specifies an update to the Datagram Congestion Control Protocol (DCCP), a connection-oriented and datagram-based transport protocol. The update adds support for the DCCP-Listen packet. This assists DCCP applications to communicate through middleboxes (e.g., a Network Address Port Translator or a DCCP server behind a firewall), where peering endpoints need to initiate communication in a near-simultaneous manner to establish necessary middlebox state. Status of This Memo This document specifies an Internet standards track protocol for the Internet community, and requests discussion and suggestions for improvements. Please refer to the current edition of the """"Internet Official Protocol Standards"""" (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. in effect on the date of publication of this document. Please review these documents carefully, as they describe your rights and restrictions with respect to this document. Code Components extracted from this document must include Simplified BSD License text as described in Section 4.e of the Trust Legal Provisions and are provided without warranty as described in the BSD License."""	bsd;connection-oriented communication;datagram;document;firewall (computing);internet;middlebox;network address;network packet;peering;std bus;server (computing);tree traversal	Godred Fairhurst	2009	RFC	10.17487/RFC5596	real-time computing;distributed computing;computer network	Networks	-25.144632155555332	88.75371741226853	7257
87082c806c13ee0898a99eac1e868ebcf2926001	demo abstract: wnos: software-defined generation of distributed optimal control programs for wireless networks		We demonstrate Wireless Network Operating System (WNOS), a radically different approach to software-defined networking (SDN) for infrastructure-less wireless networks. Departing from well-understood approaches inspired by OpenFlow, WNOS provides the network designer with an abstraction hiding (i) the lower-level details of the wireless protocol stack and (ii) the distributed nature of the network operations. Based on this abstract representation, the WNOS takes network control programs written on a centralized, high-level view of the network and automatically generates distributed cross-layer control programs based on distributed optimization theory that are executed by each individual node on an abstract representation of the radio hardware. We prototype WNOS on software-defined radio devices and test its effectiveness by considering specific cross-layer control problems. We demonstrate how the global network behavior can be controlled by modifying a few lines of code on a centralized abstraction.	centralized computing;global network;high- and low-level;mathematical optimization;network operating system;openflow;optimal control;protocol stack;prototype;software-defined networking;source lines of code	Zhangyu Guan;Lorenzo Bertizzolo;Emrecan Demirors;Tommaso Melodia	2018	IEEE INFOCOM 2018 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2018.8406925	wireless network;distributed computing;software;wireless application protocol;network operations center;global network;openflow;optimal control;source lines of code;computer science	Networks	-16.760990170010555	81.83271268471368	7279
58f62a15d5517c630a8fdf7749a3d895ecfdc275	exploring privacy preservation in outsourced k-nearest neighbors with multiple data owners	kernel density estimation;privacy preserving;nearest neighbors;outsourced cloud computation;k nn	The k-nearest neighbors (k-NN) algorithm is a popular and effective classification algorithm. Due to its large storage and computational requirements, it is suitable for cloud outsourcing. However, k-NN is often run on sensitive data such as medical records, user images, or personal information. It is important to protect the privacy of data in an outsourced k-NN system. Prior works have all assumed the data owners (who submit data to the outsourced k-NN system) are a single trusted party. However, we observe that in many practical scenarios, there may be multiple mutually distrusting data owners. In this work, we present the first framing and exploration of privacy preservation in an outsourced k-NN system with multiple data owners. We consider the various threat models introduced by this modification. We discover that under a particularly practical threat model that covers numerous scenarios, there exists a set of adaptive attacks that breach the data privacy of any exact k-NN system. The vulnerability is a result of the mathematical properties of k-NN and its output. Thus, we propose a privacy-preserving alternative system supporting kernel density estimation using a Gaussian kernel, a classification algorithm from the same family as k-NN. In many applications, this similar algorithm serves as a good substitute for k-NN. We additionally investigate solutions for other threat models, often through extensions on prior single data owner systems.	cloud computing;computation;framing (world wide web);information privacy;k-nearest neighbors algorithm;kernel density estimation;medical privacy;outsourcing;personally identifiable information;requirement;threat model	Frank Li;Richard Shin;Vern Paxson	2015		10.1145/2808425.2808430	kernel density estimation;computer science;data mining;internet privacy;computer security;statistics	Security	-40.300704515323105	64.91847454002091	7286
df5939bb09c69b663236c11c84236390b49e839f	caractérisation des délais dans les applications de supervision de réseaux et de services	modelizacion;data transmission;evaluation performance;multiagent system;control de calidad;analisis estadistico;performance evaluation;gestion;gestion red;evaluacion prestacion;langage java;probabilistic approach;delai;modelisation;plazo;statistical analysis;monitoring;enfoque probabilista;approche probabiliste;transmission donnee;analyse statistique;retard;time lag;gestion reseau;controle qualite;delais;jmx;lenguaje java;network management;monitorage;variation;caracterisation;sistema multiagente;monitoreo;quality control;retraso;management;modeling;supervision;transmision datos;delays;systeme multiagent;java language	HAL is a multidisciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L'archive ouverte pluridisciplinaire HAL, est destinée au dépôt età la diffusion de documents scientifiques de niveau recherche, publiés ou non, ´ emanant desétablissements d'enseignement et de recherche français oú etrangers, des laboratoires publics ou privés. ABSTRACT. The quality of monitoring activities within a manager-agent model is challenging when monitoring large-scale environments. The size of these environments is becoming more and more large and has a considerable impact on the performance of monitoring systems. In particular, the temporal synchronisation between the real and inferred views of a monitored system. The inferred view is provided by the manager from the collected monitoring data of agents. In this paper, we analyse the delays that experiences monitoring data when they are transferred from agents to the manager. These delays may altere the inferred view since monitoring data becomes out-of-date. Therefore, we investigate the statistical properties of these delays and their variations when the number of monitoring agents increases. Monitoring delays are measured from our benchmarking platform dedicated to the JMX monitoring framework.	archive;comefrom;hal;java management extensions;linear algebra	Abdelkader Lahmadi;Laurent Andrey;Olivier Festor	2009	Technique et Science Informatiques	10.3166/tsi.28.479-502	network management;quality control;systems modeling;telecommunications;computer science;artificial intelligence;theme and variations;computer network;data transmission	ML	-27.309256073225697	82.22877590448712	7287
188282380cb790686b2bc6dc3a5cf9e32c6a62b8	your data center is a router: the case for reconfigurable optical circuit switched paths		The rising tide of data-intensive, massive scale cluster computing is creating new challenges for traditional, hierarchical data center networks. In response to this challenge, the research community has begun exploring novel interconnect topologies to provide high bisection bandwidth—examples include Fat trees [2, 12, 8], DCell [9], and BCube [10], among a rapidly growing set of alternatives, many adapted from earlier solutions from the telecom and supercomputing areas. We argue that these solutions may provide too much— full bisection bandwidth on packet timescales—at too high a cost—literally tons of wiring and thousands of switches. In this work, we suggest that research should take a look back not only at historical topologies, but also historical technologies. More specifically, we suggest that a hybrid packet-switched/circuit-switched network can provide the functions and ease-of-use of today’s allpacket networks, while providing high bandwidth for a large class of applications at lower cost and lower network complexity. Taking advantage of this network requires, however, a philosophical change to the design of data center networks. We propose to augment the electrical switch architecture with an optical circuit-switched network. Implementing this approach requires a network re-design to provide substantial pre-optical queueing at the nodes, treating the entire data center as one large virtually output-queued router. We explain this argument briefly, and expand upon our proposed solution in the sections that follow.	bisection bandwidth;circuit switching;computer cluster;data center;data-intensive computing;file allocation table;hierarchical database model;network packet;network switch;packet switching;router (computing);supercomputer;wiring	Guohui Wang;David G. Andersen;Michael Kaminsky;Michael A. Kozuch;T. S. Eugene Ng;Konstantina Papagiannaki;Madeleine Glick;Lily B. Mummert	2009			circuit switching;data center;computer network;architecture;network packet;network complexity;network topology;computer cluster;computer science;bisection bandwidth;distributed computing	Networks	-10.804556494439884	80.01304936995632	7308
99084d5584d37d66e7bd48ce666d65bcab192df9	strengthening the known-key security notion for block ciphers		We reconsider the formalization of known-key attacks against ideal primitive-based block ciphers. This was previously tackled by Andreeva, Bogdanov, and Mennink (FSE 2013), who introduced the notion of known-key indifferentiability. Our starting point is the observation, previously made by Cogliati and Seurin (EUROCRYPT 2015), that this notion, which considers only a single known key available to the attacker, is too weak in some settings to fully capture what one might expect from a block cipher informally deemed resistant to known-key attacks. Hence, we introduce a stronger variant of known-key indifferentiability, where the adversary is given multiple known keys to “play” with, the informal goal being that the block cipher construction must behave as an independent random permutation for each of these known keys. Our main result is that the 9-round iterated Even-Mansour construction (with the trivial key-schedule, i.e., the same round key xored between permutations) achieves our new “multiple” known-keys indifferentiability notion, which contrasts with the previous result of Andreeva et al. that one single round is sufficient when only a single known key is considered. We also show that the 3-round iterated Even-Mansour construction achieves the weaker notion of multiple known-keys sequential indifferentiability, which implies in particular that it is correlation intractable with respect to relations involving any (polynomial) number of known keys.	adversary (cryptography);block cipher;eurocrypt;fast software encryption;iteration;key schedule;known-key distinguishing attack;polynomial;random permutation	Benoit Cogliati;Yannick Seurin	2016	IACR Cryptology ePrint Archive	10.1007/978-3-662-52993-5_25	computer security	Crypto	-37.65211818165754	77.91857096850812	7322
ca75ce3e3b0e729ee896f701913f8c1c8ef70fa1	nasdi - naming and service discovery for dtns in internet backbones		Delay Tolerant Networking (DTN) approaches based on the Bundle Protocol are commonly used within mobile IP based networks. Instead of being isolated applications, the Internet is often used to provide additional services or to route through other parts of the DTN network. A major drawback is that current DTN routing and discovery protocols are not generally applicable in the Internet as there is no common protocol to resolve DTN node names to convergence layer addresses outside a local network. We present Nasdi, an approach based on Distributed Hash Tables which can support naming, routing, notifications and service discovery in a heterogeneous DTN linked by the Internet. We present the architecture and initial evaluations of a Nasdi prototype system we built for the	bittorrent;coexist (image);delay-tolerant networking;distributed hash table;embedded system;event (computing);experiment;file sharing;image-based modeling and rendering;internet backbone;mobile ip;peripheral;prototype;routing;service discovery;uptime;emule	Sebastian Schildt;Wolf-Bastian Pöttner;Oliver Ohneiser;Lars C. Wolf	2012		10.1007/978-3-642-36660-4_8	internet privacy;world wide web;computer network	Networks	-23.38795308734389	87.51391355734548	7353
bbeef73f1209754c002323869464074276fed060	a new lightweight rfid grouping authentication protocol for multiple tags in mobile environment		Radio Frequency Identification (RFID) is a promising technology in logistics management of mobile environment. Due to the practical prospects of low-cost RFID tags, multiple tags authentication remains an interesting topic. However, because of the resource restriction of low-cost tags, security and privacy risks remain crucial issues. Lots of research findings have been made emphasizing on the arrangement where single object to be verified is combined with only one tag, while the scenario that one object is attached with multiple tags is out of consideration, especially the authentication of large-size objects. In this paper, a new lightweight RFID grouping authentication protocol for multiple tags in mobile environment is proposed. A number of tags are attached to different parts of the large-size object. The proposed protocol can tolerate missing tags. The tags that do not respond will not disturb the entire authentication process, which guarantees that the object can be timely verified. Moreover, the security analysis shows that this protocol can offer sufficient security assurances and resist various attacks. Besides, the proposed protocol has better performance in terms of the execution time compared to previous studies.	authentication protocol;feedback;interrupt;logistics;malware;radio frequency;requirement;run time (program lifecycle phase)	Jian Shen;Haowen Tan;Yan Zhang;Xingming Sun;Yang Xiang	2017	Multimedia Tools and Applications	10.1007/s11042-017-4386-6	computer science;radio-frequency identification;authentication protocol;security analysis;computer security;authentication	Mobile	-46.869506226490095	73.98467119457622	7373
3b7d8fa788e755dfa5231fdc8e4199ba1880146d	secure provenance-based auditing of personal data use	qa75 electronic computers computer science;hv social pathology social and public welfare;k law general	In recent years, an increasing number of personalised services that require users to disclose personal information have appeared on the Web (e.g. social networks, governmental sites, on-line selling sites). By disclosing their personal information, users are given access to a wide range of new functionality and benefits. However, there exists a risk that their personal information is misused.  To strike a balance between the advantages of personal information disclosure and protection of information, governments have created legal frameworks, such as the Data Protection Act, Health Insurance Portability & Accountability Act (HIPAA) or Safe Harbor, which place restrictions on how organisations can process personal information. By auditing the way in which organisations used personal data, it is possible to determine whether they process personal information in accordance with the appropriate frameworks.  The traditional way of auditing collects evidence in a manual way. This evidence is later analysed to assess the degree of compliance to a predefined legal framework. These manual assessments are long, since large amounts of data need to be analysed, and they are unreliable, since there is no guarantee that all data is correctly analysed. As several cases of data leaks and exposures of private data have proven, traditional audits are also prone to intentional and unintentional errors derived from human intervention.  Therefore, this thesis proposes a provenance-based approach to auditing the use of personal information by securely gathering and analysing electronic evidence related to the processing of personal information. This approach makes three contributions to the state of art.  The first contribution is the Provenance-based Auditing Architecture that defies a set of communication protocols to make existing systems provenance-aware. These protocols specify which provenance information should be gathered to verify the compliance with the Data Protection Act. Moreover, we derive a set of Auditing Requirements by analysing a Data Protection Act case study and demonstrate that provenance can be used as electronic evidence of past processing.   The second contribution is the Compliance Framework, which is a provenance-based auditing framework for automatically auditing the compliance with the Data Protection Act's principles. This framework consist of a provenance graph representation (Processing View), a novel graph-based rule representation expressing processing rules (Usage Rules Definition) and a novel set of algorithms that automatically verify whether information was processed according to the Auditing Requirements by comparing the Processing View against the Usage Rules Definition.  The third contribution is the Secure Provenance-based Auditing Architecture that ensures any malicious alteration on provenance during the entire provenance life cycle of recording, storage, querying and analysis can be detected. This architecture, which relies on cryptographic techniques, guarantees the correctness of the audit results	personally identifiable information	Rocío Aldeco-Pérez	2012			engineering;data mining;world wide web;computer security	DB	-43.80036782905275	62.484553214502554	7387
1f49243a44dbb92fab0f24e71736fe17cb0dc035	detection of malicious node in wireless ad hoc network by using acknowledgement based approach		Providing secure communication in different environments is very vital in an adhoc network. One of the important security threats in wireless adhoc networks are routing attacks. These attacks are used to disconnect a sensor network from its central base station. Ad hoc on-demand distance vector (AODV) is a dynamic routing protocol that is not designed to consider security as a goal. In this research, a novel solution AODV Malicious node Detection and Removal (AODV- MDR) has been proposed. During route discovery of AODV-MDR, every intermediate node who claims that it has a fresh path to destination, must send Gratuitous Route Reply to the destination and destination sends acknowledgement back to the source through the same intermediate node. Based on the received acknowledgement, source node confirms the authenticity of claimed path and also applies hop count verification. Results revealed that the proposed scheme detect malicious node with great accuracy. Moreover, AODV-MDR works without any overhead of encryption and hashing.	cryptographic hash function;distance-vector routing protocol;encryption;hoc (programming language);memory data register;multifactor dimensionality reduction;overhead (computing);secure communication	Khurram Gulzar Rana;Yongquan Cai;Muhammad Azeem;Allah Ditta;Haiyang Yu	2017		10.1145/3163058.3163062	hop (networking);wireless sensor network;computer network;encryption;distance-vector routing protocol;secure communication;acknowledgement;ad hoc on-demand distance vector routing;computer science;wireless ad hoc network	Mobile	-54.31949599528852	76.30043800516178	7407
6389398ca997691158e95733a099105d58b42e80	computational verification of network programs for several openflow switches in coq		OpenFlow is a network technology that enables to control network equipment centrally, to realize complicated forwarding of pack- ets and to change network topologies flexibly. In OpenFlow networks, network equipment is separated into OpenFlow switches and OpenFlow controllers. OpenFlow switches do not have controllers that usual net- work equipment has. OpenFlow controllers control OpenFlow switches. OpenFlow controllers are configured by programs. Therefore, network configurations are realized by software. This kind of software can be cre- ated by several kinds of programming languages. NetCore is one of them. The verification method of NetCore programs has been introduced. This method uses Coq, which is a formal proof management system. This method, however, deals with only networks that consist of one Open- Flow switch. This paper proposes a methodology that verifies networks that consist of several OpenFlow switches.	coq (software);network switch;openflow	Hiroaki Date;Noriaki Yoshiura	2016		10.1007/978-3-319-42108-7_17	openflow;real-time computing;computer science;distributed computing;computer network	Logic	-18.887497504997434	83.75251811896109	7410
e0f4c5c338f4daa843f48a0a2d5d8be25fda6d0c	machine learning based optimized live virtual machine migration over wan links	live migration;wide area network;virtual machine;hypervisor	Live virtual machine migration is one of the most promising features of data center virtualization technology. Numerous strategies have been proposed for live migration of virtual machines on local area networks. These strategies work perfectly in their respective domains with negligible downtime. However, these techniques are not suitable to handle live migration over wide area networks and results in significant downtime. In this paper we have proposed a Machine Learning based Downtime Optimization (MLDO) approach which is an adaptive live migration approach based on predictive mechanisms that reduces downtime during live migration over wide area networks for standard workloads. The main contribution of our work is to employ machine learning methods to reduce downtime. Machine learning methods are also used to introduce automated learning into the predictive model and adaptive threshold levels. We compare our proposed approach with existing strategies in terms of downtime observed during the migration process and have observed improvements in downtime of up to 15%.	algorithm;data center;downtime;machine learning;mega man network transmission;seamless3d;virtual machine;x86 virtualization	Moiz Arif;Adnan K. Kiani;Junaid Qadir	2017	Telecommunication Systems	10.1007/s11235-016-0173-3	embedded system;real-time computing;simulation;computer science;operating system	HPC	-13.185344571511777	80.97800484423439	7419
7d25a0c6feb9f1436bbb33851313225d2b1a33d9	fof-r ant-based survivable routing using distributed resilience matrix	integer linear programming formulation;heuristic;survivable routing;topology;attraction repulsion;distributed resilience matrix;ant colony optimization;telecommunication network reliability;repulsion functions;routing;friend or foe resilient ant based survivable routing algorithm;telecommunication network routing integer programming linear programming matrix algebra telecommunication network reliability;resource management;network capacity;attraction repulsion survivable routing protection cycle heuristic ilp resilience matrix ant colony optimization;matrix algebra;data mining;ilp;network topology;omnet tool;network survivability;resilience;telecommunication network routing;integer programming;protection cycle;optimal protection cycle;shared backup path protection;routing algorithm;linear programming;headroom dependent attraction;routing resilience protection scanning probe microscopy bandwidth integer linear programming ant colony optimization next generation networking costs matrix decomposition;bandwidth;capacity utilization;np hard;omnet tool friend or foe resilient ant based survivable routing algorithm distributed resilience matrix shared backup path protection integer linear programming formulation np hard optimal protection cycle headroom dependent attraction repulsion functions;integer linear program;disjoint paths;resilience matrix	Fast recovery from failures and overall high utilization of network capacity are two primary goals of network survivability design. Shared backup path protection has been shown to be efficient in terms of capacity utilization, due to the sharing capability among protection paths. However, the resulting integer linear programming (ILP) formulation of the problem is known to be NP-hard. This paper tackles the survivable routing problem using a new distributed matrix-based structure, termed Resilience Matrix (RM), for capturing the local bandwidth usage information. Additionally, a heuristic ant-based routing algorithm, named Friend-or-Foe Resilient (FoF-R), is proposed for finding the optimal protection cycle (i.e., two node-disjoint paths between a source-destination node pair) and for exploring the sharing ability among protection paths using a headroom-dependent attraction and repulsion functions. Simulation results based on the OMNeT++ tool show that the FoF-R scheme with the distributed RM structure is a promising approach to solve the survivable routing problem and it gives a good trade off between solution's optimality and the time needed for finding a solution.	backup;computation;distributed control system;headroom (audio signal processing);heuristic;integer programming;linear programming;mobile agent;np-hardness;next-generation network;path protection;pollard's rho algorithm for logarithms;requirement;routing;simulation	William Liu;Harsha Sirisena;Krzysztof Pawlikowski	2009	2009 21st International Teletraffic Congress		mathematical optimization;routing;ant colony optimization algorithms;heuristic;integer programming;capacity utilization;computer science;engineering;linear programming;resource management;np-hard;distributed computing;network topology;bandwidth;computer network	Arch	-5.753918776031121	81.70217545826135	7425
72cecaca8bd7c41a229c4f71699bc31436a30adf	improvement of hölbl et al. user authentication protocol and password change protocol	remote authentication;key exchange;diffie hellmen;hash functions;password;denial of service;hash function;user authentication;dos attack	Many remote authentication and key exchange protocols have been published in recent years. In 2008 Hölbl et al. proposed a password-based protocol for remote user authentication and password changing. This protocol protects message transmission between senders and receivers over insecure networks. In this paper we will show that the Hölbl et al. protocol remains vulnerable to stolen-verifier attack, off-line password guessing attack, and Denial-of-Service (DoS) attack. In addition, we proposed an improve protocol to withstand such security flaws.	authentication protocol;communications protocol;cryptographic hash function;denial-of-service attack;key exchange;key-agreement protocol;one-way function;online and offline;password cracking	Fuw-Yi Yang;Tzung-Da Wu;Ming-Huei Hsu	2009		10.1145/1806338.1806372	zero-knowledge password proof;otway–rees protocol;password policy;reflection attack;s/key;pass the hash;rainbow table;challenge–response authentication;interlock protocol;authentication protocol;hash chain;internet privacy;key derivation function;one-time password;key stretching;password;computer security;challenge-handshake authentication protocol;hmac-based one-time password algorithm;computer network;password strength	Security	-44.919845222191974	74.6073229751429	7453
36c6312958dbc75ebd4b1ea61b071c6994d598c6	managing traffic demand uncertainty in replica server placement with robust optimization	content management;distributed system;optimal solution;content distribution network;location problem;optimisation;solution optimale;probleme localisation;networks;systeme reparti;information systems;optimizacion;technology;gestion trafic;network performance;gestion contenido;traffic management;theory methods;robust optimization;qualite service;service utilisateur;scenario;sistema repartido;distribution costs;science technology;content distribution;argumento;solucion optima;script;gestion trafico;gestion contenu;optimization;problema localizacion;computer science;servicio usuario;quality of service;user service;service quality;demand uncertainty;telecommunications;calidad servicio	The replica server placement problem determines the optimal location where replicated servers should be placed in content distribution networks, in order to optimize network performance. The estimated traffic demand is fundamental input to this problem and its accuracy is essential for the target performance to be achieved. However, deriving accurate traffic demands is far from trivial and uncertainty makes the target performance hard to predict. We argue that it is often inappropriate to optimize the performance for only a particular set of traffic demands that is assumed accurate. In this paper, we propose a scenario-based robust optimization approach to address the replica server placement problem under traffic demand uncertainty. The objective is to minimize the total distribution cost across a variety of traffic demand scenarios while minimizing the performance deviation from the optimal solution. Empirical results demonstrate that robust optimization for replica server placement can achieve good performance under all the traffic demand scenarios while non-robust approaches perform significantly worse. This approach allows content distribution providers to provision better and predictable quality of service for their customers by reducing the impact of inaccuracy in traffic demand estimation on the replica server placement optimization.	content delivery network;digital distribution;integer programming;mathematical optimization;network performance;overlay network;quality of service;robust optimization;routing;server (computing);software performance testing;usb on-the-go	Kin-Hon Ho;Stylianos Georgoulas;Mina Amin;George Pavlou	2006		10.1007/11753810_61	robust optimization;simulation;quality of service;content management;computer science;scenario;network performance;computer security;service quality;technology	Metrics	-20.30276455865577	67.85178300599772	7467
838798a7040b6949c2a93ad80b64f04a52f11bc8	a live system for wavelet compression of high speed computer network measurements	long period;high speed networks;computer network;data analysis;other;high speed	Monitoring high-speed networks for a long period of time produces a high volume of data, making the storage of this information practically inefficient. To this end, there is a need to derive an efficient method of data analysis and reduction in order to archive and store the enormous amount of monitored traffic.	wavelet transform	Konstantinos G. Kyriakopoulos;David J. Parish	2007		10.1007/978-3-540-71617-4_27	embedded system;telecommunications;computer science;data analysis;computer network	Arch	-12.441945727792481	69.7999587826278	7470
fa5525adeee56c7cec0eec194905ec7da56ca63d	a novel rsa-like cryptosystem based on a generalization of the rédei rational functions		In this paper we present a novel RSA-like cryptosystem. Specifically, we define a novel product that arises from a cubic field connected to the cubic Pell equation. We discuss some interesting properties and remarks about this product that can also be evaluated through a generalization of the Redei rational functions. We then exploit these results to construct a novel RSA-like scheme that is more secure than RSA in broadcast applications. Moreover, our scheme is robust against the Wiener attack and against other kind of attacks that exploit the knowledge of a linear relation occurring between two plaintexts.	cryptosystem	Nadir Murru;Francesco M. Saettone	2017		10.1007/978-3-319-76620-1_6	discrete mathematics;cubic field;cryptosystem;exploit;pell's equation;rational function;mathematics	Crypto	-39.73974068930692	80.48435120282613	7471
c318af6e5fbbddbf715a91598d9954ae36e41a95	novel framework of integrated security and safety system using hybrid network technology	sensor systems;hybrid network technology;wireless embedded system;design and development;hybrid network;surveillance;security of data embedded systems network operating systems;network operating systems;security and safety system;conceptual model;actuators;ip based network;safety system;network operating center;electrical equipment industry;data communication;embedded system;computer security;qa75 electronic computers computer science;micro electro mechanical system;embedded systems;micromechanical devices;air safety;microembedded system;mechanical sensors;safety;wireless data communication;computer based system;automation system;ip networks;wireless data communication hybrid network technology microelectromechanical system automation system safety system microembedded system computer based system network operating center ip based network;microelectromechanical system;security and safety system wireless embedded system hybrid network;mechanical systems communication system security micromechanical devices mechanical sensors sensor systems actuators automation computer security air safety electrical equipment industry;wireless data;mechanical systems;security;security of data;cameras;tk electrical engineering electronics nuclear engineering;communication system security;automation	Advancement in Micro-Electro Mechanical System (MEMS) that integrate mechanical system, sensor, actuator, and electronics has contributed to significant improvement of automation system including security and safety system. This paper will propose a framework of integrated security and safety system that combines Micro Embedded System and Computer Based System. The framework is designed and developed based on conceptual model of security and safety system for enclosed area such as campus, industrial complex, airport, and oil/gas platform. As infrastructure for connecting the security and safety devices, control panels, and Network Operating Center (NOC), the framework will use Hybrid Networking Technology. Such technology interconnects IP-based and non IP network in form of wired and wireless data communication.	access control;closed-circuit television;control system;electrical connection;embedded system;high-level programming language;interference (communication);microelectromechanical systems;multitier architecture;network on a chip;network security;rs-485;radio jamming;scalability	Edi Saputra;Kamalrulnizam Abu Bakar;Herman Herman;Suhaidi Hassan	2009	2009 11th International Conference on Computer Modelling and Simulation	10.1109/UKSIM.2009.100	embedded system;engineering;security service;network access control;computer security;computer engineering	EDA	-50.648933519749676	68.31553723124284	7505
312df05f782feb7ba897f73612407301bcfac97a	high-performance forward error correction: enabling multi-gigabit flows and beyond on commodity gpu and cpu hardware in presence of packet loss	ultragrid;forward error correction;lowlatency transmissions;low density generation matrix;high definition video;low latency transmissions;graphics processing unit gpu	In demanding real-time multimedia transmissions, even a small packet loss might significantly degrade the visual quality. As retransmission is not an option in real-time transfers especially when transmitting the data over long distances, it is necessary to employ mechanisms of Forward Error Correction (FEC). Low-Density Generator Matrix (LDGM) codes are known to be suitable for coding on large block sizes, however, high bitrates of currently used video formats (FullHD, 4K) also require high throughput of FEC coding and decoding. We propose a parallel design of LDGM encoding and decoding algorithms suitable for off-the-shelf, (massively) parallel platforms, such CPUs with vector units or GPUs, and evaluate our approach in real-world scenarios of high-definition and 4K video transmissions. Our results show that offloading FEC computation to such platform is beneficial for low-latency, high-quality multimedia transmissions and may even enable transmissions beyond 10Gbps once the commodity network interfaces reach this speed. We propose parallel design of FEC coding applicable to both CPU and GPU architectures.Our scheme can manage multi-gigabit flows.We deploy our scheme in low-latency real-time multimedia transmissions over IP networks.We provide extensive evaluation in realistic scenarios.	central processing unit;error detection and correction;forward error correction;gigabit;graphics processing unit;network packet	Milan Kabát;Vojtech David;Petr Holub;Martin Pulec	2016	Future Generation Comp. Syst.	10.1016/j.future.2015.04.007	embedded system;parallel computing;real-time computing;computer science;theoretical computer science;forward error correction	Arch	-7.828864061817106	101.68087899646402	7526
a5b5717624cddbfa62a9cadd9327d5b19d296150	behavioural network traffic analytics for securing 5g networks		The analysis of the network traffic in 5G networks is of high significance to the network security administrator, since it could allow for the identification of different behavioural groups and the distinction of anomalous from normal activity. The problem is the multi-dimensional nature of the data, e.g. SMS, call, Internet, services etc. that makes it difficult to analyse. This is even more challenging in 5G networks, compared to previous generation networks, since one more dimension is added to the traffic, representing different network slices. In this respect, activity that is normal in one slice can be anomalous in another. This paper presents a graph-based method for network mining and visualization of user activities in a mobile network. The raw multi- dimensional network traffic data are used for the construction of multiple multi-dimensional graph- based features that capture specific behavioural aspects for each user. Within each feature, graph matching techniques are applied in order to identify groups of users with similar behaviour. The dissimilarity results for each feature are combined using a multi-objective visualization method. The outcome is a data visualization in which users with similar behaviour are depicted as points close to each other. The network analyst is able to select the desired trade-off among the multiple features, and visually detect groups of users with similar behaviours, as well as possible anomalous clusters or outliers. Experimental evaluation of the proposed approach in several application scenarios verify its efficiency.	behavioral pattern;data visualization;encode;feature extraction;internet;matching (graph theory);network packet;network security;pareto efficiency	Stavros Papadopoulos;Anastasios Drosou;Ilias Kalamaras;Dimitrios Tzovaras	2018	2018 IEEE International Conference on Communications Workshops (ICC Workshops)	10.1109/ICCW.2018.8403674	telecommunications network;visualization;computer science;computer network;data mining;data visualization;analytics;the internet;network security;matching (graph theory);cellular network	Visualization	-61.80199345534331	64.26590415671427	7550
bbb9c1c4352ff2d0a63642f2401a7da71ccea93a	olc: open-level control plane architecture for providing better scalability in an sdn network		The Internet has changed the world, regarding how we lead our daily lives and in recent years, with new technologies, such as the Internet of Things and wireless sensor networks escalating this change. However, these technologies bring with them a rapid increase in traffic, thereby putting more load on networks. It is hard to extend the traditional fully distributed architecture and distributed aggregation mechanism to a large scale, because they suffer several drawbacks by using the data plane as a bus to transfer the control discovery messages, which increases the traffic on that plane. Consequently, to solve this issue, a general architecture and discovery mechanism are introduced in this paper with open-level control (OLC) plane architecture, thus providing better scalability in an software defined networking (SDN) network. Regarding OLC, the backbone for different domains and the discovery process for providing a network general view are considered. OLC can scale up the network with high performance even during high traffic. In particular, it has high transparency, with there being no need to change the hardware, software, or protocols on the host side. Finally, the results from a 22 PC testbed verify that OLC offers a reduction in the number of discovery packets in the data plane of 84.2%, 55.2% faster discovery time and scaling up the number of subnets in an SDN network 3.2 times more than with the traditional distributed architecture and mechanism. Moreover, it provides an approximately steady rediscovery time of 4.34 secs even with very high load.	control plane;distributed computing;forwarding plane;image scaling;internet backbone;internet of things;scalability;software-defined networking;subnetwork;testbed	Emad Alasadi;Hamed S. Al-Raweshidy	2018	IEEE Access	10.1109/ACCESS.2018.2848638	computer network;wireless sensor network;the internet;scalability;software-defined networking;network packet;distributed computing;distributed management;testbed;computer science;forwarding plane	Networks	-13.934743492042267	82.17262323284714	7551
59d0af021c3441d0097eeea1b54296afb391b08d	energy budget analysis for signature protocols on a self-powered wireless sensor node		The Internet of Things will include many resource-constrained wireless sensing devices, hungry for energy, bandwidth and compute cycles. The sheer amount of devices involved will require new solutions to handle issues such as identification and power provisioning. In this contribution, we analyze the energy needs of several public-key based authentication protocols, taking into account the energy cost of communication as well as of computation. We have built an autonomous, energy-harvesting sensor node which includes a micro-controller, RFunit, and energy harvester. We investigate the Elliptic Curve Digital Signature Algorithm (ECDSA), the Lamport-Diffie one-time hash-based signature scheme (LD-OTS) and the Winternitz one-time hash-based signature scheme (W-OTS). We demonstrate that there’s a trade-off between energy used for communication, energy used for computation, and security level. However, when we consider the energy needs for the overall system, we show that all schemes are within one order of magnitude from each another.	algorithm;authentication protocol;autonomous robot;bioinformatic harvester;computation;digital signature;ecc memory;electronic signature;end-to-end encryption;expect;internet of things;mathematical optimization;microcontroller;overhead (computing);pkc (conference);precomputation;printed circuit board;prototype;provisioning;public-key cryptography;sensor node	Krishna Chaitanya Pabbuleti;Deepak Hanamant Mane;Patrick Schaumont	2014		10.1007/978-3-319-13066-8_8	sensor node;key distribution in wireless sensor networks;computer network	Mobile	-50.44703640244228	74.98090427965516	7572
1d26802eb7f1a4986152b9fe7ecf3ba1aa32238b	task- and network-level schedule co-synthesis of ethernet-based time-triggered systems	switched networks integer programming local area networks;schedules optimization time factors synchronization switches topology;switched networks;integer programming;mip task level schedule co synthesis network level schedule co synthesis time triggered distributed systems switched ethernet network mixed integer programming;local area networks	In this paper, we study time-triggered distributed systems where periodic application tasks are mapped onto different end stations (processing units) communicating over a switched Ethernet network. We address the problem of application level (i.e., both task- and network-level) schedule synthesis and optimization. In this context, most of the recent works [10], [11] either focus on communication schedule or consider a simplified task model. In this work, we formulate the co-synthesis problem of task and communication schedules as a Mixed Integer Programming (MIP) model taking into account a number of Ethernet-specific timing parameters such as interframe gap, precision and synchronization error. Our formulation is able to handle one or multiple timing objectives such as application response time, end-to-end delay and their combinations. We show the applicability of our formulation considering an industrial size case study using a number of different sets of objectives. Further, we show that our formulation scales to systems with reasonably large size.	distributed computing;end-to-end principle;integer programming;linear programming;mathematical optimization;response time (technology);task parallelism	Licong Zhang;Dip Goswami;Reinhard Schneider;Samarjit Chakraborty	2014	2014 19th Asia and South Pacific Design Automation Conference (ASP-DAC)	10.1109/ASPDAC.2014.6742876	local area network;mathematical optimization;real-time computing;integer programming;computer science;distributed computing	EDA	-8.02479395113198	60.85799432190087	7575
079ed087a34db86f2523bd8dd778ca2fa5c2da88	visualization of actionable knowledge to mitigate drdos attacks	computer crime;visualization;servers;internet;data visualization;ip networks	Distributed Reflective Denial of Service attacks (DRDoS) represent an ever growing security threat. These attacks are characterized by spoofed UDP traffic that is sent to genuine machines, called amplifiers, whose response to the spoofed IP, i.e. the victim machine, is amplified and could be 500 times larger in size than the originating request. In this paper, we provide a method and a tool for Internet Service Providers (ISPs) to assess and visualize the amount of traffic that enters and leaves their network in case it contains innocent amplifiers. We show that amplified traffic usually goes undetected and can consume a significant bandwidth, even when a small number of amplifiers is present. The tool also enables ISPs to simulate various rule-based mitigation strategies and estimate their impact, based on real-world data obtained from amplification honeypots.	amplifier;bandwidth (signal processing);client honeypot;denial-of-service attack;domain driven data mining;gigabit;honeypot (computing);logic programming;simulation;spoofing attack;tree accumulation	Michaël Aupetit;Yury Zhauniarovich;Giorgos Vasiliadis;Marc Dacier;Yazan Boshmaf	2016	2016 IEEE Symposium on Visualization for Cyber Security (VizSec)	10.1109/VIZSEC.2016.7739577	the internet;visualization;computer science;data mining;internet privacy;world wide web;computer security;data visualization;server;computer network	Security	-59.621870246340315	65.10929286591734	7597
afb62b48265d98a00e5db522c151f290f5f53da1	an efficient pairwise key predistribution scheme for wireless sensor networks	key management;security level;wirless sensor networks	Key management plays fundamental role in research on security service in wireless sensor networks (WSNs). However, due to the resource constraints, establishing pairwise keys in WSNs is not a trivial tasks. Several exiting key management schemes have been proposed in literature to establish pairwise keys between sensor nodes, but they either can not offer strong resilience against node capture attacks or have overly large memory requirement to achieve high degree of connectivity. In this paper, we prose an efficient pairwise key management scheme. In the proposed scheme, the sensor nodes are given different security level and the compromised sensor nodes cannot disclose the key information in the sensor nodes which have higher security level The analysis indicates that compared with existing approaches, this proposed scheme offers a stronger resilience against node capture attack.	key management;security service (telecommunication);sensor	Kun Mu;Li Li	2014	JNW	10.4304/jnw.9.2.277-282	computer science;key management;key distribution in wireless sensor networks;internet privacy;computer security;computer network	Mobile	-50.825867734815816	76.29269381093758	7610
983ee379c6f4599079aae40b172bc138bb435f8c	twelve random access strategies for the fiber optic networks	protocols;time dependent;fibra optica;standards;protocole transmission;unslotted system csma cd random access strategies fiber optic networks protocols timing arrangements network access devices aloha lcsma lcsma cd linear unidirectional networks slotted system;acceso directo;code division access;telecommunication network;estrategia;fiber optic;strategy;protocolo transmision;telecomunicacion optica;telecommunication optique;acces multiple code;taux transmission;optical fiber networks optical fibers optical transmitters optical switches optical propagation protocols optical pulse generation signal generators throughput optical fiber devices;red telecomunicacion;relacion transmision;signal processing;acces direct;multiple access protocols;multi access systems;strategie acces direct;norma;protocols multi access systems optical communication optical links;reseau telecommunication;optical links;direct access;optical telecommunication;optical communication;transmission rate;optical fiber;acceso multiple codificado;strategie;random access;detection collision;norme;fibre optique;timing;transmission protocol	Twelve random-access strategies that do not constrain the distance or transmission rate of a network, and can use the capabilities of fiber-optic components, are described and compared. The twelve strategies consist of three protocols, each of which can use two timing arrangements and two network-access devices. The three protocols are the standard ALOHA protocol, LCSMA, and LCSMA/CD. The last two protocols operate on linear-unidirectional networks and use local information at the transmitter to increase the throughput of the system. The networks considered have a common point that all transmitted signals pass through before being received. This makes two timing arrangements possible; a slotted system or an unslotted system. The taps on the network can be either passive or active. >	optical fiber;random access	Nicholas F. Maxemchuk	1988	IEEE Trans. Communications	10.1109/26.3774	electronic engineering;telecommunications;computer science;engineering;optical fiber;signal processing;random access;optical communication;computer network	Mobile	-5.656311732161554	87.88706794188548	7667
81507c346ca02dbfc0d39ace5ee8ee5c39a4df45	the qos-rwp mobility and user behavior model for public area wireless networks	channel access;access point;wireless network;wireless mesh network;movement pattern;random waypoint mobility;wireless mesh networks;wireless lan;user behavior;quality of service;mobility modeling;mobility model;wireless data;mobile user	Congestion is expected to become a prominent problem to deal with as the popularity of wireless data networks continues to increase. However, this problem can in principle be mitigated if a fraction of the network users could decide to move to another location in case their perceived QoS degrades. To account for this, we propose an extension of the well-known RWP model called QoS-RWP, in which users are divided into mobile users displaying constrained movement patterns, and QoS-driven users who are mainly stationary, but they can decide to move to a better location to improve their QoS level. Another enhancement of QoS-RWP with respect to the original RWP model is that waypoints are chosen according to an access point (AP) popularity metric, which reflects the recently observed phenomenon that different APs in a wireless data network display very different degrees of popularity among users. The QoS-RWP model also accounts for different classes of load offered to the network by the users, and for different channel access methods. Based on QoS-RWP, we perform a simulation-based analysis of network usage under different combinations of network parameters such as the number of users, number of APs, relative fraction of QoS-driven users, and channel access method. Our investigation discloses interesting insights on network usage, and shows that our model is able to capture important properties observed in real-world network deployments.	behavior model;network congestion;quality of service;simulation;stationary process;whole earth 'lectronic link;wireless access point	Giovanni Resta;Paolo Santi	2006		10.1145/1164717.1164781	wireless mesh network;service set;wireless wan;heterogeneous network;quality of service;wireless site survey;telecommunications;computer science;wireless network;wireless lan controller;municipal wireless network;wi-fi array;mobility model;computer security;computer network;network access point;network access device	Mobile	-12.557476205441324	98.12192059275482	7677
a82a5de3f123f10e6e6692e515b226a2263d91c5	on privacy preserving collaborative filtering: current trends, open problems, and new issues	databases;ppcf method privacy preserving collaborative filtering automatic recommender systems e commerce web 2 0 internet users information extraction taxonomy cf family;protocols;electronic commerce;recommender systems privacy preserving collaborative filtering electronic commerce;companies;internet;data privacy;collaborative filtering;cryptography;privacy preserving collaborative filtering;privacy databases companies data privacy cryptography protocols recommender systems;information analysis;recommender systems;privacy;recommender systems collaborative filtering data privacy electronic commerce information analysis internet	Automatic recommender systems have become a cornerstone of e-commerce, especially after the great welcome of Web 2.0 based on participation and interaction of Internet users. Collaborative Filtering (CF) is a recommender system that is becoming increasingly relevant for the industry due to the growth of the Internet, which has made it much more difficult to effectively extract useful information. In this paper, we introduce a taxonomy of the different CF families and we discuss the most relevant Privacy Preserving Collaborative Filtering (PPCF) methods in the literature. To understand the inherent challenges of the PPCF, we also conduct an overview of the current tendencies and major drawbacks of this kind of recommender systems, and we propose several strategies to overcome the shortcomings.	centralisation;collaborative filtering;computation;distributed computing;e-commerce;internet;overhead (computing);privacy;recommender system;sparse matrix;web 2.0;while	Fran Casino;Constantinos Patsakis;Domenec Puig;Agusti Solanas	2013	2013 IEEE 10th International Conference on e-Business Engineering	10.1109/ICEBE.2013.37	e-commerce;information privacy;computer science;cryptography;collaborative filtering;data mining;database;internet privacy;privacy;world wide web;computer security	DB	-41.91520282225936	62.40088416968851	7680
f9feff95bc1d68674d5db426053f417bd2c8786b	deep content: unveiling video streaming content from encrypted wifi traffic		The proliferation of smart devices has led to an exponential growth in digital media consumption, especially mobile video for content marketing. The vast majority of the associated Internet traffic is now end-to-end encrypted, and while encryption provides better user privacy and security, it has made network surveillance an impossible task. The result is an unchecked environment for exploiters and attackers to distribute content such as fake, radical and propaganda videos. Recent advances in machine learning techniques have shown great promise in characterising encrypted traffic captured at the end points. However, video fingerprinting from passively listening to encrypted traffic, especially wireless traffic, has been reported as a challenging task due to the difficulty in distinguishing retransmissions and multiple flows on the same link. We show the potential of fingerprinting videos by passively sniffing WiFi frames in air, even without connecting to the WiFi network. We have developed Multi-Layer Perceptron (MLP) and Recurrent Neural Networks (RNNs) that are able to identify streamed YouTube videos from a closed set, by sniffing WiFi traffic encrypted at both Media Access Control (MAC) and Network layers. We compare these models to the state-of-the-art wired traffic classifier based on Convolutional Neural Networks (CNNs), and show that our models obtain similar results while requiring significantly less computational power and time (approximately a threefold reduction).	access control;artificial neural network;biological neural networks;computation;computational resource;computer and network surveillance;convolutional neural network;dash (cryptocurrency);data collection;digital media;digital video fingerprinting;end-to-end encryption;fingerprint (computing);flow;frame (physical object);machine learning;memory-level parallelism;multilayer perceptron;neural tube defects;next-generation network;propaganda;prototype;quad flat no-leads package;recurrent neural network;reference implementation;smart device;streaming media;transport layer security;wi-fi protected access;anatomical layer;exponential;videocassette	Ying Li;Yi Huang;Richard Xu;Suranga Seneviratne;Kanchana Thilakarathna;Adriel Cheng;Darren Webb;Guillaume Jourjon	2018	2018 IEEE 17th International Symposium on Network Computing and Applications (NCA)	10.1109/NCA.2018.8548317	media access control;digital media;computer network;perceptron;the internet;internet traffic;convolutional neural network;encryption;computer science;distributed computing;recurrent neural network	Metrics	-59.287699891570306	63.3986762977621	7684
7ed54470462b04d48fde4304d7cee5c12632fd89	cuckoo sampling: robust collection of flow aggregates under a fixed memory budget	complex algorithms;reservoirs;memory management;network condition;sampling rates;telecommunication congestion control;adaptive scheme;synthetic network traffic cuckoo sampling robust collection fixed memory budget flow aggregates high speed link traffic sampling packet sampling rates complex algorithms data structure adaptive sampling routers flow sampling based measurement scheme epoch measurement per packet operation cpu cost;packet sampling;packet switching;high speed links;traffic mix;arrays;orders of magnitude;telecommunication traffic;monitoring;data structures;aggregates;conference report;telecommunication traffic data structures packet switching sampling methods telecommunication congestion control;adaptive sampling;resource usage;sampling methods;traffic sampling;monitoring aggregates memory management reservoirs arrays hardware;algorithms and data structure;high speed;fixed memory budget;hardware	Collecting per-flow aggregates in high-speed links is challenging and usually requires traffic sampling to handle peak rates and extreme traffic mixes. Static selection of sampling rates is problematic, since worst-case resource usage is orders of magnitude higher than the average. To address this issue, adaptive schemes have been proposed in the last few years that periodically adjust packet sampling rates to network conditions. However, such proposals rely on complex algorithms and data structures of costly maintenance. As a consequence, adaptive sampling is still not widely implemented in routers.	adaptive sampling;best, worst and average case;data structure;denial-of-service attack;dhrystone;experiment;network packet;pseudocode;randomized algorithm;requirement;router (computing);sampling (signal processing);webserver directory index	Josep Sanjuàs-Cuxart;Pere Barlet-Ros;Nick G. Duffield;Ramana Rao Kompella	2012	2012 Proceedings IEEE INFOCOM	10.1109/INFCOM.2012.6195693	sampling;real-time computing;data structure;telecommunications;traffic mix;computer science;orders of magnitude;packet switching;computer network;memory management;reservoir	Metrics	-5.7337281392535235	90.1597894324507	7704
17d152ccfcd22fb38ba2459680acbc2f424a2641	time-lined tcp for the tcp-friendly delivery of streaming media	communication system traffic control;user level;api;application software;telecommunication congestion control;udp;protocol design;tcp friendly streaming data delivery;robust control;streaming media players;sockets;data communication;time lined tcp;bandwidth sharing time lined tcp tcp friendly streaming data delivery protocol time sensitive data loss tolerant applications streaming media players unicast delivery internet udp congestion control user level transport level deadlines api tltcp streaming media applications encoding mpeg 1 simulations time lined data delivery;transport protocols;telecommunication traffic;internet;deadlines;transport level;streaming media;time sensitive data;congestion control;application program interfaces;encoding transport protocols internet telecommunication traffic telecommunication congestion control data communication application program interfaces;loss tolerant applications;bandwidth;time lined data delivery;streaming media applications;computer science;encoding;unicast delivery;bandwidth sharing;tltcp;mpeg 1;streaming media internet bandwidth communication system traffic control transport protocols robust control computer science application software unicast sockets;unicast;protocol	This paper introduces Time-lined TCP (TLTCP). TLTCP is a protocol designed to provide TCP-friendly delivery of timesensitive data to applications that are loss-tolerant, such as streaming media players. Previous work on unicast delivery of streaming media over the Internet proposes using UDP and performs congestion control at the user level by regulating the application’s sending rate (attempting to mimic the behavior of TCP in order to be TCP-friendly). TLTCP, on the other hand, is intended to be implemented at the transport level, and is based on TCP with modifications to support time-lines. Instead of treating all data as a byte stream TLTCP allows the application to associate data with deadlines. TLTCP sends data in a similar fashion to TCP until the deadline for a section of data has elapsed; at which point the now obsolete data is discarded in favor of new data. As a result, TLTCP supports TCP-friendly delivery of streaming media by retaining much of TCP’s congestion control functionality. We describe an API for TLTCP that involves augmenting the recvmsg and sendmsg socket calls. We also describe how streaming media applications that use various encoding schemes like MPEG-1 can associate data with deadlines and use TLTCP’s API. We use simulations to examine the behavior of TLTCP under a wide range of networks and workloads. We find that it indeed performs timelined data delivery and under most circumstances bandwidth is shared equally among competing TLTCP and TCP flows. Moreover, those scenarios under which TLTCP appears to be unfriendly are those under which TCP flows competing only with other TCP flows do not share bandwidth equitably.	application programming interface;bitstream;internet;interoperability;network congestion;requirement;simulation;software deployment;streaming media	Biswaroop Mukherjee;Tim Brecht	2000		10.1109/ICNP.2000.896301	robust control;compound tcp;embedded system;tcp congestion-avoidance algorithm;protocol;real time streaming protocol;application software;tcp delayed acknowledgment;real-time computing;the internet;user datagram protocol;tcp global synchronization;application programming interface;computer science;tcp hole punching;operating system;transmission control protocol;zeta-tcp;hstcp;tcp tuning;network congestion;tcp acceleration;tcp friendly rate control;slow-start;transport layer;bandwidth;encoding;computer network;out-of-order delivery;unicast	Networks	-5.6701375081446015	98.71486900491296	7705
84264e471ac19cd69d5f80f33e33b9a0453d9744	load balancing optimization in lte/lte-a cellular networks: a review		During the past few decades wireless technology has seen a tremendous growth. The recent introduction of high-end mobile devices has further increased subscribers’ demand for high bandwidth. Current cellular systems require manual configuration and management of networks, which is now costly, time consuming and error prone due to exponentially increasing rate of mobile users and nodes. This leads to introduction of self organizing capabilities for network management with minimum human involvement. It is expected to permit higher end user Quality of Service (QoS) along with less operational and maintenance cost for telecom service providers. Self organized cellular networks incorporate a collection of functions for automatic configuration, optimization and maintenance of cellular networks. As mobile end users continue to use network resources while moving from a cell boundary to other, traffic load within a cell does not remain constant. Thus Load balancing as a part of self organized network solution, has become one of the most active and emerging fields of research in Cellular Network. It involves transfer of load from overloaded cells to the neighbouring cells with free resources for more balanced load distribution in order to maintain appropriate end-user experience and network performance. In this paper, review of various load balancing techniques currently used in mobile networks is presented, with special emphasis on techniques that are suitable for self optimization feature in future cellular networks.	cognitive dimensions of notations;compaq lte;load balancing (computing);mathematical optimization;mobile device;mobile phone;network performance;offset binary;organizing (structure);quality of service;self-organization;user experience	Sumita Mishra;Nidhi Mathur	2014	CoRR		real-time computing;telecommunications;computer science;distributed computing;computer network	Mobile	-13.846992362789138	87.48154351569622	7711
f8d8a81c6cdd1764ae2d5cfa01fdc639b306965a	experimental evaluation of fog computing techniques to reduce latency in lte networks		The changes in new mobile networks toward a full Internet protocol–based architecture have led to opportunities for service-oriented optimizations based on emergent technologies like fog computing, software-defined networking, or network function virtualization. This paper explores 2 ways of using these new technologies to reduce the latency in Long-Term Evolution (LTE) networks. Both solutions reduce the path that the data packets should follow from the base station (evolved Node B [eNB]) to the network components that connect to the servers. The first solution, called Fog Gateway, is based on the interception of the packets in the tunnel at the eNB and their redirection to local servers running the fog services. This solution is fully compliant with the current LTE architecture and only requires new components. The second solution, called General Packet Radio Service Tunneling Protocol Gateway (GTP), is based on splitting the eNBu0027s functionality to avoid unnecessary GTP encapsulation of the packets geared toward the fog services. This paper includes an analysis of the latency split in LTE networks, the evaluation of both solutions with experiments in an end-to-end LTE network testbed, and a discussion around their applicability in future fifth-generation networks. The results confirm that they are feasible to provide low-latency services and that they are compatible with some of the emergent paradigms (software-defined networking and network function virtualization) as well as with the studies on fifth-generation networks from the standardization bodies.	compaq lte;fog computing	Cesar A. García-Pérez;Pedro Merino	2018	Trans. Emerging Telecommunications Technologies	10.1002/ett.3201	architecture;general packet radio service;internet protocol;standardization;computer network;tunneling protocol;default gateway;network packet;server;engineering	HCI	-14.606908447636972	85.60634445886308	7714
f377875ed499262e40ac977ae6371c422caaaff0	an aggregation-based raw reputation generation approach	email server;spam;electronic mail;distributed processing;simulation;unsolicited e mail distributed processing;aggregation based raw reputation generation approach;raw reputation;data mining;distributed spam processing technology;ratio based approach;reputation mechanism;accuracy;servers;internet;aggregation based approach;theoretical analysis;internet information filtering information filters computer architecture computer science analytical models algorithm design and analysis;reputation mechanism aggregation based raw reputation generation approach anti spam area distributed spam processing technology;unsolicited e mail;aggregation based approach spam email server raw reputation ratio based approach;algorithm design and analysis;anti spam area	In the anti-spam area, distributed spam processing technology that based on reputation mechanism is a currently main focus in research. The raw reputation plays an important role in computing the finial reputation of the target node. In this paper, we analyze the ratio-based raw reputation generation approach in detail, point out its problems, and propose an aggregation-based raw reputation generation approach. Furthermore, we discuss how the number of evaluations and the method using to choose these evaluations impact on the result of raw reputation. Theoretical analysis and simulation results demonstrate that aggregation-based approach is much more effective and accurate than ratio-based approach. As long as we choose the proper number of evaluations, the results can accurately reflect behavior of the target node.	anti-spam techniques;feedback;rationality;reputation;reputation system;simulation;spamming	Jianzhong Zhang;Tianyan Zhang;Xiaofeng Lan;Jingdong Xu	2009	2009 IEEE International Conference on Networking, Architecture, and Storage	10.1109/NAS.2009.22	spam;algorithm design;the internet;computer science;operating system;accuracy and precision;internet privacy;world wide web;computer security;server	Robotics	-60.18999289845361	72.22158441444424	7760
18f18f0e8288a3c775ea8b0a8d7c3027750b1469	periodic schedules for bounded timed weighted event graphs	schedules throughput polynomials computational modeling vectors encoding steady state;timed weighted event graphs twegs periodic schedule;periodic schedule;computer model;production system;polynomials;embedded system;computational modeling;production control;batch processing industrial;vectors;scheduling;polynomial algorithm;schedules;timed event graph;petri nets;timed weighted event graphs twegs;batch arrival;encoding;scheduling batch processing industrial petri nets polynomials production control;timed weighted circuits periodic schedules bounded timed weighted event graphs timed event graphs multiple arc cardinalities automated production systems tweg teg batch flows modeling polynomial algorithms optimal throughput computation;throughput;steady state	Timed event graphs (TEGs) and timed weighted event graphs (TWEGs), which have multiple arc cardinalities, have been widely used for automated production systems such as robotic work cells or embedded systems. TWEGs are useful for modeling batch flows of entities such as batch arrivals or processing of jobs. Periodic schedules, that combine an explicit description of starting times and an easy implementation, are particularly interesting, and have been proved to be optimal for ordinary timed event graphs (TEGs). In this paper, we present polynomial algorithms to check the existence of periodic schedules of bounded TWEGs and to compute their optimal throughput. These results can be considered as generalizations of those for ordinary timed event graphs. We then establish that periodic schedules are suboptimal for TWEGs and may not exist even for a live TWEG. The gap between optimal throughput and throughput of an optimal periodic schedule is experimentally investigated for a subclass of TWEGs, namely timed weighted circuits.	algorithm;computation;embedded system;entity;experiment;item unique identification;liveness;polynomial;robot;schedule (computer science);throughput	Abir Benabid;Claire Hanen;Olivier Marchetti;Alix Munier Kordon	2012	IEEE Transactions on Automatic Control	10.1109/TAC.2012.2191871	computer simulation;throughput;discrete mathematics;real-time computing;schedule;computer science;distributed computing;production system;steady state;computational model;scheduling;petri net;encoding;polynomial	Embedded	-9.638395448813661	62.101858982447354	7793
ec987eebc7392a9fdfe4fea67a4f236882631461	brutus: identifying cryptanalytic weaknesses in caesar first round candidates		This report summarizes our results from security analysis covering all 57 CAESAR first round candidates and over 210 implementations. We have manually identified security issues with three candidates, two of which are more serious, and these ciphers been withdrawn from the competition. We have developed a testing framework, BRUTUS, to facilitate automatic detection of simple security lapses and susceptible statistical structures across all ciphers. From this testing we have security usage notes on four submissions and statistical notes on a further four. We highlight that some of the CAESAR algorithms pose an elevated risk if employed in real-life protocols due to a class of adaptive chosen plaintext attacks. Although AEADs are often defined (and are best used) as discrete primitives that authenticate and transmit only complete messages, in practice these algorithms are easily implemented in a fashion that outputs observable ciphertext data when the algorithm has not received all of the (attacker-controlled) plaintext. For an implementor, this strategy appears to offer seemingly harmless and compliant storage and latency advantages. If the algorithm uses the same state for secret keying information, encryption, and integrity protection, and the internal mixing permutation is not cryptographically strong, an attacker can exploit the ciphertext-plaintext feedback loop to to reveal secret state information or even keying material. We conclude that the main advantages of exhaustive, automated cryptanalysis is that it acts as a very necessary sanity check for implementations and gives the cryptanalyst insights that can be used to focus more specific attack methods on given candidates.	algorithm;authentication;caesar;cipher;ciphertext;cryptanalysis;data integrity;encryption;feedback;key (cryptography);observable;plaintext;real life;sanity check;strong cryptography	Markku-Juhani O. Saarinen	2014	IACR Cryptology ePrint Archive			Security	-37.661197722828014	73.88403497840854	7795
aaff8337f314e0b775b345f9c38e66a39dbf1147	a novel sdn controller based on ontology and global optimization for heterogeneous iot architecture		Today, our modern living world is covered by ubiquitous systems that offer the ability to assess, understand and handle the environmental indicators of our urban environment as well as our delicate ecology and natural resources. The sudden increase of such systems creates the notion of Internet of Things (IoT). However, the variety of components and wide-area deployments in IoT create a disadvantage point: the heterogeneity problem. Such system has multiple heterogeneous wireless communication solutions with multiple access technologies such as bluetooth, wifi, zigbee, cellular, MANET, etc. Concretely, the effectiveness is revealed by a variety of access technologies that are working on a common core network with a common policy for every type of access network. The challenge is how to manage this heterogeneous network in a dynamic context with an open and distributed infrastructure. One of the most efficiency solutions for this issue is the Software-Defined Network approach (SDN). This paper proposed a new SDN-based architecture with a centralized controller that has a capacity of self-observing and adapting. The SDN controller has the ability to incorporate and support user requests to classify flow scheduling over task-level. Besides, the paper creates an Ontology for analyzing user's request and based on the Lagrange relaxation theory for a heuristic routing algorithm. The experimental works showed that the proposed solution yielded impressive and good results.	access network;algorithm;bluetooth;centralized computing;ecology;global optimization;heuristic routing;high-level programming language;internet of things;linear programming relaxation;network switch;openflow;scheduling (computing);software-defined networking;testbed	Hai Anh Tran;Duc Tran;Linh Giang Nguyen;Abdelhamid Mellouk;Hieu Mac;Van T Tong	2017		10.1145/3155133.3155143	mobile ad hoc network;heuristic routing;architecture;software-defined networking;heterogeneous network;bluetooth;access network;core network;distributed computing;computer science	Mobile	-13.54512689436003	85.07120820780024	7804
1200d7e9d7f3415317ded9bf94d310e15ef74163	the fasttrack overlay: a measurement study	teletrafic;design principle;network measurement;cortafuego;encryption;par a par;fasttrack;securite informatique;reseau ordinateur;p2p;overlay;transmission message;cifrado;securite donnee;message transmission;computer network;partage des ressources;computer security;pare feu reseau;teletrafico;internet;poste a poste;cryptage;seguridad informatica;indexation;resource sharing;particion recursos;teletraffic;overlay network;red informatica;peer to peer;security of data;reseau prive virtuel;transmision mensaje;firewall;virtual private networks	Both in terms of number of participating users and in traffic volume, FastTrack is one of the most important applications in the Internet today. Nevertheless, because FastTrack is proprietary and uses encryption, little is understood about FastTrack s overlay structure and dynamics, its messaging protocol, and its index management. We have built two measurement apparatus—the FastTrack Sniffing Platform and the FastTrack Probing Tool—to unravel many of the mysteries behind FastTrack. We deploy the apparatus to study FastTrack s overlay structure and dynamics, its neighbor selection, its use of dynamic port numbers to circumvent firewalls, and its index management. Although this study does not fully solve the FastTrack puzzle, it nevertheless leads to a coherent description of FastTrack and its overlay. Furthermore, we leverage the measurement results to set forth a number of key principles for the design of a successful unstructured P2P overlay. The measurement results and resulting design principles in this paper should be useful for future architects of P2P overlay networks as well as for engineers managing ISPs. 2005 Elsevier B.V. All rights reserved.	algorithm;centralized computing;coherence (physics);encryption;fasttrack;file sharing;firewall (computing);internet backbone;linked list;locality of reference;maxima and minima;multitier architecture;napster;organizing (structure);overlay network;pre-installed software;server (computing);server farm;supernode (circuit)	Jian Liang;Rakesh Kumar;Keith W. Ross	2006	Computer Networks	10.1016/j.comnet.2005.07.014	shared resource;firewall;the internet;overlay network;telecommunications;computer science;operating system;peer-to-peer;overlay;world wide web;computer security;encryption;computer network	Networks	-5.646066325130286	75.84199405504275	7832
b968414a49c006a010aeff99cf74834e629731ce	ntru-ke: a lattice-based public key exchange protocol		Public key exchange protocol is identified as an important application in the field of public-key cryptography. Most of the existing public key exchange schemes are Diffie-Hellman (DH)-type, whose security is based on DH problems over different groups. Note that there exists Shor’s polynomial-time algorithm to solve these DH problems when a quantum computer is available, we are therefore motivated to seek for a non-DHtype and quantum resistant key exchange protocol. To this end, we turn our attention to lattice-based cryptography. The higher methodology behind our roadmap is that in analogy to the link between ElGamal, DSA, and DH, one should expect a NTRU lattice-based key exchange primitive in related to NTRU-ENCRYPT and NTRU-SIGN. However, this excepted key exchange protocol is not presented yet and still missing. In this paper, this missing key exchange protocol is found, hereafter referred to as NTRU-KE, which is studied in aspects of security and key-mismatch failure. In comparison with ECDH (Elliptic Curve-based Diffie-Hellman), NTRU-KE features faster computation speed, resistance to quantum attack, and more communication overhead. Accordingly, we come to the conclusion that NTRU-KE is currently comparable with ECDH. However, decisive advantage of NTRU-KE will occur when quantum computers become a reality.	authentication;computation;computational diffie–hellman assumption;computer;cryptosystem;diffie–hellman key exchange;entity;knowledge engineering;lattice-based cryptography;man-in-the-middle attack;ntru;overhead (computing);password;polynomial;public-key cryptography;quantum computing;shared secret;shor's algorithm;time complexity	Xinyu Lei;Xiaofeng Liao	2013	IACR Cryptology ePrint Archive		ntru;theoretical computer science;public-key cryptography;cryptography;computation;elgamal encryption;analogy;key exchange;mathematics;quantum computer	Crypto	-40.39475831447353	77.43915639156104	7865
b52f9aed31b40bf29d6521e536e91f03fe1022da	an adaptive cache invalidation technique for wireless environments	wireless networks;cooperative caching;cache invalidation;cache hit ratio	With an evolution of Internet and related technologies such as 4G, and 5G, there is a need of fast response time for various queries raised by intermediate nodes and mobile terminals from infra structured-based/less networks. Although there has been many efforts in the past to address this issue by using an invalidation report (IR)-based cache management schemes which reduce the bandwidth requirements, and battery consumptions, but when the update rate of data at the server is high, then most of the existing approaches have long query latency due to large and fixed size of IRs, and broadcast time (BT) interval. To address these issues, in this paper, an adaptive cache invalidation technique (ACIT) is proposed. In comparison to the previous approaches, the proposed scheme uses different thresholds update rates for adaptive IR, and BT intervals. In the proposed scheme, only hot data updates in IR are recorded which results a less query delay, and bandwidth consumption. The performance of the proposed scheme was studied by extensive simulations by comparing it with the other state-of-the-art schemes using various metrics. The proposed scheme yields 1.5 times enhancement in query response time with a reduction in IR size to 25 % in comparison to other existing techniques. Moreover, there is a reduction of 119.89 % in broadcast time interval using the proposed scheme.	cache invalidation	Rajeev Tiwari;Neeraj Kumar	2016	Telecommunication Systems	10.1007/s11235-015-0070-1	real-time computing;computer science;cache invalidation;operating system;wireless network;distributed computing;cache algorithms;computer network	EDA	-15.071454919382115	68.79314363620612	7868
3fd736e7083b1cbf846506eaaea303d0670ab2b2	characterizing high-bandwidth real-time video traffic in residential broadband networks	broadband networks;psnr;broadband network;packet loss;real time;wireless network;video quality;active measurement;wireless communication;telecommunication traffic;internet;broadband links high bandwidth real time video traffic characterizion residential broadband networks multimedia content internet wi fi networks;streaming media;multimedia communication;wireless lan broadband networks internet multimedia communication telecommunication traffic;video transmission;bandwidth;wireless lan;broadband communication;telecommunication traffic broadband communication streaming media delay ip networks traffic control internet bit rate wireless networks dsl	Users are generating and uploading multimedia content to the Internet at an unprecedented rate. Residential broadband networks, however, have low upload capacities and large packet latencies. Wi-Fi networks that are used to access the Internet can suffer from high packet losses and contention latencies. All of these factors can result in poor video quality for residential users. Using packet traces and active measurements from houses, we study video quality in residential scenarios. We analyze the primary factors that contribute to poor performance and compare the performance over both the wireless and the broadband hop. Our measurements show that the upload capacities on the broadband links restrict the video bitrate (and hence the resolution) that can be transmitted. Residential wireless networks, however, have much higher capacities than the broadband links and, despite being densely deployed, do not see extended periods of high utilization. Our measurements shed light on the video transmission quality that is typically achievable from residences and are used to characterize the reasons behind quality deterioration.	bandwidth (signal processing);image resolution;internet;network packet;real-time clock;tracing (software);upload;video	Ramya Raghavendra;Elizabeth M. Belding-Royer	2010	8th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks		embedded system;telecommunications;computer science;computer network;broadband networks	Metrics	-8.209372350124733	98.87405754478469	7878
7419a365f130694c7c2d8331b2f3a159a286e6c8	distributing blackbox data to multiple vehicles in a secure and privacy-preserving manner	vehicles cryptography vehicular ad hoc networks accidents roads vehicle crash testing;conference_paper;trusted authority distributing blackbox data multiple vehicles privacy preserving manner secure preserving manner vehicle blackbox data aeroplane car accidents traffic accidents vehicular ad hoc network vanet road side units;authentication;simulation;privacy preserving;vehicular ad hoc networks computer networks;vehicular ad hoc networks telecommunication security;crash data;accidents;roads;cryptography;vehicular ad hoc networks;vehicle crash testing;vehicle to vehicle communications;vehicular ad hoc network;vehicles;traffic crashes;authentication event data recorder vehicular ad hoc network privacy preserving;security;event data recorders;event data recorder;privacy	In addition to information such as the track of wheels, vehicle blackbox data (like a blackbox in an aeroplane) provides another major source of information for the study of the cause of car accidents. However, according to a study, 5% of blackboxes were destroyed in traffic accidents and about 35% data inside a blackbox could not be retrieved. With the setup of vehicular ad hoc network (VANET), it is motivated to store the blackbox data in a distributed manner in the road-side units of such a network. This scheme works well provided that there are enough road-side units installed. But this assumption is not valid in rural areas and also may impose a large overhead to road-side units. In this paper, we propose a distributed scheme that allows vehicles to periodically broadcast blackbox data to nodes nearby (other vehicles) as extra backup. And the trusted authority can reveal those data from recipients. The proposed scheme will ensure the integrity and confidentiality of messages as well as the privacy of drivers. We show that our scheme is secure and the performance is reasonable through simulation.	backup;black box;confidentiality;hoc (programming language);information source;numerical analysis;overhead (computing);simulation;wheels	C. Y. Yeung;W. C. Law;Tat Wing Chim;Siu-Ming Yiu;Victor O. K. Li;Lucas Chi Kwong Hui	2014	2014 International Conference on Connected Vehicles and Expo (ICCVE)	10.1109/ICCVE.2014.7297663	engineering;internet privacy;computer security;computer network	Mobile	-49.14470328430708	74.31507336845283	7884
12c4efed75f1fa4954ba898c91ef6214ff165fe4	iso-level caft: how to tackle the combination of communication overhead reduction and fault tolerance scheduling	fault tolerant;low complexity;scheduling algorithm;load balance;task graphs	To schedule precedence task graphs in a more realistic framework, we introduce an efficient fault tolerant scheduling algorithm that is both contention-aware and capable of supporting ε arbitrary fail-silent (failstop) processor failures. The design of the proposed algorithm which we call Iso-Level CAFT, is motivated by (i) the search for a better loadbalance and (ii) the generation of fewer communications. These goals are achieved by scheduling a chunk of ready tasks simultaneously, which enables for a global view of the potential communications. Our goal is to minimize the total execution time, or latency, while tolerating an arbitrary number of processor failures. Our approach is based on an active replication scheme to mask failures, so that there is no need for detecting and handling such failures. Major achievements include a low complexity, and a drastic reduction of the number of additional communications induced by the replication mechanism. The experimental results fully demonstrate the usefulness of Iso-Level CAFT.	algorithm;computational complexity theory;fault tolerance;load balancing (computing);mathematical optimization;optimization problem;overhead (computing);replication (computing);run time (program lifecycle phase);schedule (project management);scheduling (computing);sensor;simulation;throughput;triangular function	Mourad Hakem	2009		10.1007/978-3-642-03644-6_20	fault tolerance;parallel computing;real-time computing;computer science;load balancing;operating system;distributed computing;scheduling;computer security	HPC	-14.857488070309287	60.6822948299445	7901
fa1a5f0100d976fb32bc703a20f75716a8d07747	a new hard problem over non-commutative finite groups for cryptographic protocols	finite group;public key cryptography;commutative encryption;finite non commutative groups;public encryption;non commutative;cryptographic protocol;public key;difficult problem;public key distribution	A new computationally difficult problem defined over noncommutative finite groups is proposed as cryptographic primitive. The problem is used to construct public key agreement protocol and algorithms for public and commutative encryption. Finite non-commutative groups of the four-dimension vectors over the ground field are constructed and investigated as primitives for implementing the protocols and algorithms based on the proposed difficult problem.		Dmitriy N. Moldovyan;Nikolay A. Moldovyan	2010		10.1007/978-3-642-14706-7_14	cryptographic primitive;key exchange;computer science;theoretical computer science;key wrap;cryptographic protocol;cryptographic key types;public-key cryptography;computer security;probabilistic encryption;key encapsulation	Theory	-40.007396228606176	76.91639354225009	7903
5aa90212b1b791d1ffd2919e5be6ae437db30e61	multiparty quantum group signature scheme with quantum parallel computation	entangled state;security analysis;digital signatures;quantum computation;group signature;signature scheme;quantum fourier transform;quantum fourier transform quantum signature group signature quantum computation;quantum computer;quantum computing digital signatures discrete fourier transforms;parallel computer;logic gates quantum computing fourier transforms entropy educational institutions security quantum entanglement;security analysis multiparty quantum group signature scheme quantum parallel computation quantum message discrete quantum fourier transform epr sequence;quantum signature;quantum computing;discrete fourier transforms;quantum group	A novel (n, n) scheme of multiparty quantum group signature of classical or quantum message is proposed based on the discrete quantum Fourier transform. The generation and verification of the signature can be processed only if all the n participants work in concert. Moreover, a new verification manner, in which the message owner and the signing group separately verify the signature on both side by using the entangled state of EPR sequence, is involved in this paper. Security analysis shows that it is feasible to achieve a secure quantum group signature with the secure quantum computation.	computation;epr paradox;group signature;parallel computing;quantum fourier transform;quantum computing;quantum entanglement	Ronghua Shi;Jinjing Shi;Ying Guo;Moon Ho Lee	2011	2011IEEE 10th International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2011.124	ring signature;discrete mathematics;quantum information;theoretical computer science;quantum network;quantum capacity;mathematics;quantum channel;quantum computer;schnorr signature;quantum algorithm;quantum cryptography;one-way quantum computer;quantum mechanics;quantum phase estimation algorithm;quantum sort	Crypto	-40.6615267483912	78.57116199292612	7922
423228a99d589f784ac0d3087532358dba485b3d	a workflow scheduling algorithm for optimizing energy-efficient grid resources usage	energy efficiency;green products energy efficiency air pollution benchmark testing algorithm design and analysis scheduling algorithm educational institutions;optimisation;green computing grid computing scheduling scientific workflow;computational grid;energy efficient;green products;workflow management software computer centres grid computing optimisation power aware computing scheduling;scientific workflow;dynamic voltage scaling;hgreen algorithm workflow scheduling algorithm energy efficient grid resource usage optimization heterogeneous resource global grid computing power consumption data center dynamic voltage scaling hgreen heuristic;computer centres;power aware computing;data center;scheduling algorithm;application profile;scheduling;air pollution;workflow management software;power consumption;grid computing;algorithm design;algorithm design and analysis;benchmark testing;green computing	Grid computing represents the main solution to integrate distributed and heterogeneous resources in global scale. However, the infrastructure necessary for maintaining a global grid in production is huge. Such fact has led to excessive power consumption. On the other hand, most green strategies for data centers are DVS (Dynamic Voltage Scaling)-based and become difficult to implement them in global grids. This paper proposes the HGreen heuristic (Heavier Tasks on Maximum Green Resource) and defines a workflow scheduling algorithm in order to implement it on global grids. HGreen algorithm aims to prioritize energy-efficient resources and explores workflow application profiles. Simulation results have shown that the proposed algorithm can significantly reduce the power consumption in global grids.	algorithm;benchmark (computing);data center;dynamic voltage scaling;grid computing;heuristic (computer science);meta-scheduling;optimizing compiler;randomness;scheduling (computing);simulation;verification and validation	Fábio Gonçalves Coutinho;Luís Alfredo V. de Carvalho;Renato Santana	2011	2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing	10.1109/DASC.2011.115	algorithm design;real-time computing;computer science;theoretical computer science;operating system;distributed computing;efficient energy use;scheduling;workflow management system	HPC	-18.747575117618222	62.532376923384334	7934
31de5abc5cf42b3f21a5f781e5f4c283af50d3ea	new results on multi-receiver authentication codes	confidencialidad;securite;point to point;authentication;cle publique;confidentiality;authentification;confidentialite;controle acces support;autenticacion;public key;criptografia;media access control;cryptography;safety;signature;llave publica;cryptographie;message authentication;signing;seguridad;firma	Multi-receiver authentication is an extension of traditional point-to-point message authentication in which a sender broadcasts a single authenticated message such that all the receivers can independently verify the authenticity of the message, and malicious groups of up to a given size of receivers can not successfully impersonate the transmitter, or substitute a transmitted message. This paper presents some new results on unconditionally secure multi-receiver authentication codes. First we generalize a polynomial construction due to Desmedt, Frankel and Yung, to allow multiple messages be authenticated with each key. Second, we propose a new flexible construction for multi-receiver A-code by combining an A-code and an (n, m, k)-cover-free family. Finally, we introduce the model of multi-receiver A-code with dynamic sender and present an efficient construction for that.	code;message authentication;point-to-point protocol;polynomial;stan frankel;transmitter	Reihaneh Safavi-Naini;Huaxiong Wang	1998		10.1007/BFb0054151	data authentication algorithm;telecommunications;computer science;authentication;internet privacy;message broker;computer security	Crypto	-43.14566983737146	75.87536526723781	7980
79011ae4ac801c73e2828d48fab387af3eaeea93	on the leakage resilience of ideal-lattice based public key encryption		We consider the leakage resilience of the Ring-LWE analogue of the Dual-Regev encryption scheme (R-Dual-Regev for short), originally presented by Lyubashevsky et al. (Eurocrypt ’13). Specifically, we would like to determine whether the R-Dual-Regev encryption scheme remains IND-CPA secure, even in the case where an attacker leaks information about the secret key. We consider the setting where R is the ring of integers of the m-th cyclotomic number field, for m which is a power-of-two, and the Ring-LWE modulus is set to q ≡ 1 mod m. This is the common setting used in practice and is desirable in terms of the efficiency and simplicity of the scheme. Unfortunately, in this setting Rq is very far from being a field so standard techniques for proving leakage resilience in the general lattice setting, which rely on the leftover hash lemma, do not apply. Therefore, new techniques must be developed. In this work, we put forth a high-level approach for proving the leakage resilience of the R-Dual-Regev scheme, by generalizing the original proof of Lyubashevsky et al. (Eurocrypt ’13). We then give three instantiations of our approach, proving that the R-Dual-Regev remains IND-CPA secure in the presence of three natural, non-adaptive leakage classes.	ciphertext indistinguishability;encryption;eurocrypt;high- and low-level;key (cryptography);learning with errors;leftover hash lemma;modulus of continuity;power of two;public-key cryptography;spectral leakage	Dana Dachman-Soled;Huijing Gong;Mukul Kulkarni;Aria Shahverdi	2017	IACR Cryptology ePrint Archive		psychological resilience;lattice (order);computer network;public-key cryptography;leakage (electronics);mathematics	Crypto	-37.83677545938491	77.58457226588843	7990
33655eee856da3483669b0a988387ab5bf7b686f	on the design of aggregation networks for fast moving users	technology and engineering	In this paper, the focus is on the enabling platform for delivery of multimedia services to fast moving users (e.g., users in trains or cars). Moreover, a study on the aggregation part of this platform is presented. This aggregation network preserves the connection between the service provider domain and the access networks. The fast moving users are connected to the access network via a wireless connection. In the aggregation part of the architecture, users are taken together into tunnels, and as these users move from access network to another access network, tunnels have to move with them. It has already been proven that a dynamic tunnel management system radically reduces the network cost. This paper investigates the possibilities or splitting the big tunnel of each train into several smaller ones and shows that there is a optimal value for the number of tunnels.		Frederic Van Quickenborne;Frederik Greve;Ingrid Moerman;Filip De Turck;Piet Demeester	2005			telecommunications;computer science;computer security;computer network	ML	-14.635149234693316	86.40676512760639	8000
0c799263bf08951b81b1f9352b05d33c22e48d8b	simulation-based performance study of youtube service in 3g lte	packet loss;tcp;long term evolution;lte interface simulation based performance study youtube service 3g lte 3g long term evolution dynamic network simulation tcp traffic traffic generation model youtube flash videos personal computer tcp cubic congestion control algorithm youtube media servers video download packet loss tcp adaptation throttling phase radio link quality maximum data rate achievable;tcp youtube long term evolution;transport protocols;servers;3g mobile communication;youtube;internet;multimedia communication;social networking online;transport protocols 3g mobile communication internet long term evolution multimedia communication social networking online;youtube videos long term evolution servers packet loss throughput;videos;throughput	In this paper, we study the performance of the YouTube service over 3G Long Term Evolution (LTE) by means of dynamic network simulations. We consider a typical configuration of an LTE network for TCP traffic and the traffic generation model for YouTube `Flash' videos downloaded onto a personal computer (PC). Furthermore, in order to achieve more reliable results in the simulations, the main configuration parameters are obtained for TCP Cubic congestion control algorithm used by YouTube media servers. The results obtained show that: the number of pauses experimented by users during video download are heavily influenced by the cell load, but the same is not true for pause duration; most of the packet losses occur during initial burst due to the TCP adaptation to the BDP of the link, and, unlike packet losses during throttling phase, these are not depend on radio link quality; and in most cases the user do not use the maximum data rate achievable in the LTE interface.	adobe flash;algorithm;bandwidth-delay product;compaq lte;cubic function;download;network congestion;network packet;personal computer;simulation;uncompressed video	Jonathan Prados-Garzon;Pablo Ameigeiras;Jorge Navarro-Ortiz;Juan M. López-Soler	2013	"""2013 IEEE 14th International Symposium on """"A World of Wireless, Mobile and Multimedia Networks"""" (WoWMoM)"""	10.1109/WoWMoM.2013.6583422	throughput;the internet;computer science;transmission control protocol;internet privacy;packet loss;world wide web;transport layer;server;computer network	Metrics	-5.798334457026657	96.33864208915865	8026
b57625054a1416a4456b677683837d499497e603	a geometric approach for shared secrets, a refinement	k;secret sharing;threshold scheme;n threshold scheme;geometric approach	A refinement to the (k,n) threshold scheme proposed by Wu and He [1] is presented. It has been found that usable primes p need not be confined to the form p = +/-3 (mod 8) as suggested originally. Our constructive proof also lead to a different algorithm for implementation. This implementation dispenses with the directory file suggested in [1] which can be prohibitively large when the scheme is implemented with large p using the original proposal.	refinement (computing);shared secret	Peng-Chor Leong;Wen-Jing Hsu;Peng-Chong Tan	1998	Computers & Security	10.1016/S0167-4048(98)80102-8	computer science;theoretical computer science;secret sharing;computer security;algorithm	Crypto	-39.231669837637845	74.0370841784815	8028
a4eda0ecbce230091725e6409d39686e317fee78	privacy-preserving business process outsourcing	bpaas cloud computing privacy preserving;outsourcing business process re engineering cloud computing cost reduction data privacy;outsourcing;bpaas;privacy preserving;cost reduction;cloning;data privacy;abstracts;web services;cloning abstracts organizations web services outsourcing privacy;organizations;business process re engineering;privacy;organization process fragment privacy preserving business process outsourcing cloud provider business process as a service bpaas cost saving cloud reuse privacy risk anonymization based approach client business activity;cloud computing	Many cloud providers offer on demand applications as Business Process as a Service (BPaaS), allowing companies to outsource their processes. For cost saving, some process fragments can be reused on the cloud regardless of privacy risks. In this paper, we propose an anonymization-based approach to preserve client business activity while sharing process fragments between organizations on the cloud.	business process;data anonymization;outsourcing;privacy	Mehdi Bentounsi;Salima Benbernou;Mikhail J. Atallah	2012	2012 IEEE 19th International Conference on Web Services	10.1109/ICWS.2012.34	web service;cloud computing;information privacy;computer science;organization;cloning;process management;internet privacy;business process discovery;privacy;law;world wide web;computer security;outsourcing	DB	-43.0925994416282	61.84751363060811	8032
24c5bade9d8c98da833244197a9c5b22cea88a52	security issues in ipv6	transport protocols internet quality of service telecommunication security;internet space technology data security network address translation computer networks ip networks mobile computing protocols tcpip robustness;ike;ipsec;real time;cga;nat;ipv4 ipv6 internet qos network security transport protocol;transport protocols;internet;pki ipv6 tcp ip nat ipsec ike cga;tcp ip;ipv6;telecommunication security;internet engineering task force;pki;quality of service	The current generation of IP, version 4 (IPv4), has been in use for more than 20 years, since its inception in 1980 and has supported the Internet's rapid growth during that time. IPv4 has proven to be robust, easily implemented and interoperable. This is a tribute to its initial design. However, the current Internet has grown much bigger than was anticipated. There are several problems such as impending exhaustion of the IPv4 address space, configuration complexities, and poor security at the IP level and inadequate QoS support for real-time delivery of data. To address these and other concerns, the Internet engineering task force (IETF) has developed a suite of protocols and standards known as IP version 6 (IPv6). The new features introduced such as auto-address configuration, end to end connectivity, mandatory support for security and mobility pose a great challenge on security for future networks based on IPv6. This paper identifies and examines security threats relating to the new features introduced in IPv6.	address space;internet;interoperability;real-time transcription;robustness (computer science)	R. Radhakrishnan;Majid Jamil;Shabana Mehfuz;Moinuddin Moinuddin	2007	International Conference on Networking and Services (ICNS '07)	10.1109/ICNS.2007.106	ipsec;the internet;color graphics adapter;quality of service;security association;telecommunications;ip address management;computer science;engineering;nat;public key infrastructure;operating system;ipv6;internet protocol suite;world wide web;computer security;transport layer;computer network	Metrics	-13.885129928906826	91.15386488040278	8079
1406886fcebb5b14d5faf9a92e0c9bb1c4327048	provoking the adversary by dual detection techniques: a game theoretical framework		Establishing a secret and reliable wireless communication is a challenging task that is of paramount importance. In this paper, we investigate the physical layer security of a legitimate transmission link between a user that assists an Intrusion Detection System (IDS) in detecting eavesdropping and jamming attacks in the presence of an adversary that is capable of conducting an eavesdropping or a jamming attack. The user is being faced by a challenge of whether to transmit, thus becoming vulnerable to an eavesdropping or a jamming attack, or to keep silent and consequently his/her transmission will be delayed. The adversary is also facing a challenge of whether to conduct an eavesdropping or a jamming attack that will not get him/her to be detected. We model the interactions between the user and the adversary as a two-state stochastic game. Explicit solutions characterize some properties while highlighting some interesting strategies that are being embraced by the user and the adversary. Results show that our proposed system outperform current systems in terms of communication secrecy.	adversary (cryptography);game theory;interaction;intrusion detection system;radio jamming;sensor	Ahmed Salem;Xuening Liao;Yulong Shen;Xiang Lu	2017	2017 International Conference on Networking and Network Applications (NaNA)	10.1109/NaNA.2017.41	distributed computing;computer network;secrecy;computer science;physical layer;adversary;stochastic game;wireless;jamming;intrusion detection system;eavesdropping	Security	-53.64702781754499	70.44356504423851	8082
05633658159b4dce0824374fa0e085c0982a710b	cyber-insurance in internet security: a dig into the information asymmetry problem		Internet users such as individuals and organizations are subject to different types of epidemic risks such as worms, v iruses, spams, and botnets. To reduce the probability of risk, an Internet user generally invests in traditional security mechanisms like anti-virus and anti-spam software, sometimes also known aself-defense mechanisms. However, according to security experts, such software (and their sub sequent advancements) will not completely eliminate risk. Recent r esearch efforts have considered the problem of residual risk elimination byproposing the idea of cyber-insurance. In this regard, an important research problem is resolving information asymmetry issues associa ted with cyberinsurance contracts. In this paper we proposethree mechanisms to resolve information asymmetry in cyber-insurance. Our mechanismsare based on the Principal-Agent (PA) model in microeconomic theory. We show that (1) optimal cyber-insurance contracts induced by our mechanisms only provide partial coverage to the insureds. This ensuresgreater selfdefense efforts on the part of the latter to protect their computing systems, which in turn increases overall network security,(2) the level of deductible per network user contract increases in a conca ve manner with the topological degree of the user, and (3) a market for c yberinsurance can be made to exist in the presence of monopolisti c nsurers under effective mechanism design. Our methodology is appli cable to any distributed network scenario in which a framework for cyber-insurance can be implemented.	andi gutmans;anti-spam techniques;antivirus software;botnet;cyber-insurance;internet security;network security;risk management;spamming;telecommunications network	Ranjan Pal	2012	CoRR		internet privacy;world wide web;computer security	Security	-61.62901074305072	72.79545269558362	8084
4cf8b941f72078b616635dbb7ea5270104f97cc3	protocols for real-time multimedia data transmission over the internet	internet protocol;real time data transmission;protocols;coding systems;network protocol;web and internet services;signal design;real time;real time systems transport protocols multimedia communication internet data communication encoding;real time data;data communication;transport protocols;internet;data communication streaming media transport protocols ip networks web and internet services quality of service signal design signal processing payloads access protocols;streaming media;signal processing;multimedia data;signal compression;multimedia communication;access protocols;coding systems multimedia data transmission internet non guaranteed quality of service networks real time data transmission protocols signal compression;payloads;ip networks;quality of service;multimedia data transmission;encoding;multimedia services;non guaranteed quality of service networks;real time systems	The explosive growth of the Internet and the intranets have attracted a great deal of attention to the implementation and performance of networked multimedia services. which involve the transport of real-time multimedia data streams over nonguaranteed quality of service (QoS) networks based on the Internet Protocol (IP). In this paper, I present an overview of the existing architectural elements supporting real-time data transmission over the Internet. Effective implementations of such systems require a thorough understanding of both the network protocols and the coding systems used for compressing the signals to be transmitted in real-time. The paper includes a section discussing the issues to be considered in designing signal compression applications suitable for network use.	communications protocol;internet;intranet;quality of service;real-time clock;real-time computing;real-time data;real-time transcription;signal compression	M. Reha Civanlar	1998		10.1109/ICASSP.1998.679714	communications protocol;real-time computing;next-generation network;internet layer;computer science;signal processing;world wide web;ip multimedia subsystem;computer network	Embedded	-14.240945222215217	92.62991121849501	8099
4ce9f64dac7f9b27a537f501f7dec219f32d53a3	sdn/nfv-based mobile packet core network architectures: a survey	software defined networking network function virtualization mobile packet core evolved packet core future mobile networking 5g networking network slicing;mobile computing wireless sensor networks wireless lan network architecture 5g mobile communication 3gpp	The emergence of two new technologies, namely, software defined networking (SDN) and network function virtualization (NFV), have radically changed the development of network functions and the evolution of network architectures. These two technologies bring to mobile operators the promises of reducing costs, enhancing network flexibility and scalability, and shortening the time-to-market of new applications and services. With the advent of SDN and NFV and their offered benefits, the mobile operators are gradually changing the way how they architect their mobile networks to cope with ever-increasing growth of data traffic, massive number of new devices and network accesses, and to pave the way toward the upcoming fifth generation networking. This survey aims at providing a comprehensive survey of state-of-the-art research work, which leverages SDN and NFV into the most recent mobile packet core network architecture, evolved packet core. The research work is categorized into smaller groups according to a proposed four-dimensional taxonomy reflecting the: 1) architectural approach, 2) technology adoption, 3) functional implementation, and 4) deployment strategy. Thereafter, the research work is exhaustively compared based on the proposed taxonomy and some added attributes and criteria. Finally, this survey identifies and discusses some major challenges and open issues, such as scalability and reliability, optimal resource scheduling and allocation, management and orchestration, and network sharing and slicing that raise from the taxonomy and comparison tables that need to be further investigated and explored.	categorization;emergence;fifth generation computer;network architecture;network function virtualization;network packet;scalability;scheduling (computing);software deployment;software-defined networking;taxonomy (general);transfer function	Van-Giang Nguyen;Anna Brunstrom;Karl-Johan Grinnemo;Javid Taheri	2017	IEEE Communications Surveys & Tutorials	10.1109/COMST.2017.2690823	radio access network;embedded system;active networking;access point name;wireless wan;mobile web;packet analyzer;public land mobile network;computer science;mobile technology;delay-tolerant networking;distributed computing;networking hardware;mobile station;mobile computing;network processor;computer network	Mobile	-14.590037475160237	86.70164338759984	8101
c5160dafd7618b0913597ec6a99b280fbaa1f8b4	exploiting jtag and its mitigation in iot: a survey		Nowadays, companies are heavily investing in the development of “Internet of Things(IoT)” products. These companies usually and obviously hunt for lucrative business models. Currently, each person owns at least 3–4 devices (such as mobiles, personal computers, Google Assistant, Alexa, etc.) that are connected to the Internet 24/7. However, in the future, there might be hundreds of devices that will be constantly online behind each person, keeping track of body health, banking transactions, status of personal devices, etc. to make one’s life more efficient and streamlined. Thus, it is very crucial that each device should be highly secure since one’s life will become dependent on these devices. However, the current security of IoT devices is mainly focused on resiliency of device. In addition, less complex node devices are easily accessible to the public resulting in higher vulnerability. JTAG is an IEEE standard that has been defined to test proper mounting of components on PCBs (printed circuit boards) and has been extensively used by PCB manufacturers to date. This JTAG interface can be used as a backdoor entry to access and exploit devices, also defined as a physical attack. This attack can be used to make products malfunction, modify data, or, in the worst case, stop working. This paper reviews previous successful JTAG exploitations of well-known devices operating online and also reviews some proposed possible solutions to see how they can affect IoT products in a broader sense.		Gopal Vishwakarma;Wonjun Lee	2018	Future Internet	10.3390/fi10120121	computer security;computer network;computer science;the internet;backdoor;exploit;vulnerability;internet of things;business model	ECom	-51.14804321543408	61.41314491823036	8146
0f717667fb2b15fdfa3727cefd5d9ab60514b3f5	subset membership encryption and its applications to oblivious transfer	protocols;transfer;data privacy cryptographic protocols;encryption;receivers;its;subset;games;oblivious;membership;encryption protocols receivers privacy games;applications;privacy;rpot subset membership encryption cryptographic notion sme scheme alice encryptor bob decryptor randomized privacy preserved attribute token attribute set ciphertext k out of n oblivious transfer two round ot priced oblivious transfer pot protocol zero knowledge proof restricted priced oblivious transfer	In this paper, we propose a novel cryptographic notion called subset membership encryption (SME), and provide a very efficient SME scheme. Given a system parameter generated by an encryptor (Alice), a decryptor (Bob) generates a randomized privacy-preserved attribute token P(G) from a set of attributes G. A message is encrypted using an attribute set A chosen by Alice and P(G) provided by Bob. It requires that A is a subset of G for Bob to decrypt the message. We propose a very efficient SME scheme, where both the size of P(G) and ciphertext are short and independent of G and A. In particular, it has three useful and practical applications to oblivious transfer as follows. 1) k-Out-of-n Oblivious Transfer (OT): SME can be naturally applied to a two-round OT, which features a great communication efficiency especially for the receiver, where the receiver only sends two group elements to the message sender. 2) Priced Oblivious Transfer (POT): Our POT protocol allows a buyer to purchase any number of items in each transaction and hide selected items, price and balance from the vendor. In comparison with previous POT protocols, our protocol is more flexible and eliminates the restriction that a buyer can only purchase one item in a transaction. Our POT scheme is very efficient since it does not require any zero-knowledge proof or homomorphic encryption. 3) Restricted Priced Oblivious Transfer (RPOT): We introduce a novel POT named RPOT where a vendor can set restrictions on items or prices in POT. For example, a seller could offer a discounted price to those buyers who have purchased some specific items previously from the same seller.	alice and bob;ciphertext;cryptography;homomorphic encryption;oblivious transfer;randomized algorithm;zero-knowledge proof	Fuchun Guo;Yi Mu;Willy Susilo	2014	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2014.2322257	games;communications protocol;subset and superset;computer science;theoretical computer science;mathematics;internet privacy;privacy;information technology;computer security;encryption	Crypto	-40.33299927702336	73.73753239979088	8153
283255e69cb1b7906634b1530a895da57a82643c	disavowable public key encryption with non-interactive opening	pkeno;groth sahai proof;disavowability	We propose the notion of disavowable public key encryption with non-interactive opening (disavowable PKENO) where, for a ciphertext and a message, the receiver of the ciphertext can issue a proof that the plaintext of the ciphertext is NOT the message, and give a fairly practical construction.	ciphertext;encryption;interactivity;plaintext;public-key cryptography	Ai Ishida;Keita Emura;Goichiro Hanaoka;Yusuke Sakai;Keisuke Tanaka	2015	IEICE Transactions	10.1145/2714576.2714642	semantic security;plaintext-aware encryption;key clustering;theoretical computer science;ciphertext indistinguishability;symmetric-key algorithm;internet privacy;malleability;deterministic encryption;computer security;encryption;ciphertext;attribute-based encryption	Crypto	-40.263205414346864	75.80681477384876	8186
ce9ef19643798cf255e41e2acf9966d67eec4e3a	on the security of non-invertible fingerprint template transforms	template security;kernel;security analysis;gaussian processes;minutiae;image matching;fingerprint recognition biometrics authentication data security bioinformatics protection cryptography information security humans computer security;authentication;biometrics;non invertibility;feature matching;data mining;transforms fingerprint identification gaussian processes image matching;fingerprint minutiae distribution noninvertible fingerprint template transforms transformation functions noninvertible biometric templates security analysis biometric features feature matching coverage effort curve partial recovery gaussians based feature transform;information measure;fingerprint recognition;transforms;fingerprint;mixture of gaussians;entropy;fingerprint identification;minutiae biometrics template security non invertibility information measure fingerprint	Many transformation functions have been proposed for generating revocable or non-invertible biometric templates. However, their security analysis either ignores the distribution of biometric features or uses inefficient feature matching. This usually leads to unrealistic estimates of security. In this paper we introduce a new measure of non-invertibility, called the Coverage-Effort (CE) curve which measures the number of guesses (Effort) required by an adversary to recover a certain fraction (Coverage) of the original biometric data. In addition to utilizing the feature distribution, the CE curve allows estimation of security against partial recovery of biometric features. We analyze the CE curves obtained using different instances of a mixture of Gaussians based feature transform for fingerprint templates. Our analysis shows that knowledge of the fingerprint minutiae distribution reduces the effort required to obtain a specified coverage.	adversary (cryptography);biometric device;biometrics;fingerprint recognition;minutiae;mixture model	Abhishek Nagar;Anil K. Jain	2009	2009 First IEEE International Workshop on Information Forensics and Security (WIFS)	10.1109/WIFS.2009.5386477	computer vision;pattern recognition;data mining;mathematics	Vision	-37.419288153872856	69.7457087600842	8195
ac908311ee2836fe31c73200534bbd64da48471c	a hybrid solution to support multiuser 3d virtual simulation environments in peer-to-peer networks	3d virtual environment;technological innovation;peer to peer network;collaboration;collaborative editing;multi user;communication model;shared virtual environment;protection;client server;mpeg 4 standard;interactive application;broadcasting;peer to peer computing;virtual environment;communication system control;peer to peer;peer to peer computing virtual environment mpeg 4 standard delay collaboration technological innovation distributed control communication system control broadcasting protection;distributed control;simulation environment	One of the challenges for 3D multi-user virtual simulation environments (3D MUVEs) developers is to keep the shared virtual simulation environment synchronized among all the participating users´ terminals. Support to 3DMUVEs through traditional client-server communication model offers simpler management but can lead to bottlenecks and higher latencies. Peer-to-peer communication model, on the other hand, offers no central coordination but are more complex to manage. Current peer-to-peer networks, such as KaZaA and Gnutella, provide multimedia sharing services but do not support multiuser 3D virtual environment applications. This paper describes a solution to support 3D MUVEs in a hybrid peer-to-peer Gnutella network, which provides session control and distributed shared virtual environment synchronization. As a result of this work, two components specified by the ongoing multi-user extension to the MPEG-4 standard were implemented and integrated to the Gnutella network for control and synchonization. This solution minimizes the disadvantages of client-server, pure peer-to-peer and proxy-based models. The results show the number of users per session that can be supported with acceptable delays for tasks such as collaborative editing and for highly interactive applications such as action games.	client–server model;gnutella;multi-user;peer-to-peer;server (computing);simulation;virtual reality;virtual world	Azzedine Boukerche;Regina Borges de Araujo;Marcelo Laffranchi	2004	Eighth IEEE International Symposium on Distributed Simulation and Real-Time Applications	10.1109/DS-RT.2004.2	computer science;distributed computing;multimedia;world wide web	Visualization	-22.694816682382882	71.87255470631757	8199
df965705ba84c9cc0d4b75391309e3b99de98e49	secure location verification using radio broadcast	teoria demonstracion;distributed system;red sin hilo;reseau capteur;senal compleja;systeme reparti;theorie preuve;reseau sans fil;proof theory;protected area;localization;complex signal;wireless network;distributed computing;mesure position;localizacion;indexing terms;onde acoustique;signal complexe;medicion posicion;wireless sensor network;network topology;captador medida;emetteur recepteur;measurement sensor;red sensores;sistema repartido;capteur mesure;localisation;sensor placement;wireless sensor net work;position measurement;emisor receptor;sensor array;acoustic wave;calculo repartido;radio wave;location verification;security;topologie circuit;calcul reparti;transceiver;wireless sensor networks;onda radio;onda acustica;onde radioelectrique	Secure location verification is a recently stated problem that has a number of practical applications. The problem requires a wireless sensor network to confirm that a potentially malicious prover is located in a designated area. The original solution to the problem, as well as solutions to related problems, exploits the difference between propagation speeds of radio and sound waves to estimate the position of the prover. In this paper, we propose a solution that leverages the broadcast nature of the radio signal emitted by the prover and the distributed topology of the network. The idea is to separate the functions of the sensors. Some sensors are placed such that they get the signal from the prover if it is inside the protected area. The others are positioned so that they can only get the signal from the prover outside the area. Hence the latter sensors reject the prover if they hear its signal. Our solution is versatile and deals with provers using either omni-directional or directional propagation of radio signals without requiring any special hardware besides a radio transceiver. We estimate the bounds on the number of sensors required to protect the areas of various shapes and extend our solution to handle complex radio signal propagation, optimize sensor placement and operate without precise topology information.	broadcast domain	Adnan Vora;Mikhail Nesterenko	2004		10.1007/11516798_27	wireless sensor network;telecommunications;computer science;information security;distributed computing	HCI	-51.74894433898185	78.91744257250464	8221
ef17a1b8b2f3fff805e77c50aed350d21fe47fcb	ddos attacks detection using ga based optimized traffic matrix	computers;ddos attack;computer model;telecommunication traffic genetic algorithms security of data;ddos attacks;computer crime;intrusion detection;lawrence berkeley laboratory;genetic algorithm ddos attacks intrusion detection traffic matrix;telecommunication traffic;computational modeling;monitoring;lawrence berkeley laboratory distributed denial of service attacks detection genetic algorithm based optimized traffic matrix computer infrastructures network infrastructures mass traffics packet based window size darpa 2000 dataset lbl pkt 4 dataset;ip networks computer crime genetic algorithms computational modeling delay monitoring computers;distributed denial of service;genetic algorithm;ip networks;genetic algorithms;traffic matrix;security of data	Threat of Distributed Denial of Service (DDoS) attacks has been increasing with growth of computer and network infrastructures. DDoS attacks generating mass traffics make network bandwidth and/or system resources depleted. Therefore, it is significant to detect DDoS attacks in early stage. Our previous approach used a traffic matrix to detect DDoS attack. However, it is hard to tune up the parameters of the matrix including (i) size of traffic matrix, (ii) packet based window size, and (iii) threshold value of variance from packets information with respect to various monitoring environments and DDoS attacks. In this paper, we propose an enhanced DDoS attacks detection approach which (i) improves the traffic matrix building operation and (ii) optimizes the parameters of the traffic matrix using Genetic Algorithm (GA). We perform experiments with DARPA 2000 dataset and LBL-PKT-4 dataset of Lawrence Berkeley Laboratory to show its performance in terms of detection accuracy and speed.	denial-of-service attack;experiment;genetic algorithm;hash function;inbound marketing;network packet;packet switching;real-time clock;real-time computing;requirement;software release life cycle;the matrix;time of arrival	Je Hak Lee;Dong Seong Kim;Sang Min Lee;Jong Sou Park	2011	2011 Fifth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing	10.1109/IMIS.2011.116	computer simulation;genetic algorithm;telecommunications;computer science;application layer ddos attack;world wide web;computer security;denial-of-service attack;computer network	Metrics	-60.173412178833324	66.93082035798953	8291
f20a0264cb24dca0606046c8419304e918c34965	a fair energy resource allocation strategy for micro grid	micro grid;cost saving opportunity;smart grid;fairness index;fair energy resource allocation	The design of smart grid systems have been proposed in several literature. However, the actual commercial feasibility of smart grids or micro grids still faces several problems including technical infrastructure related issues and market economy issues. One critical issue in the design of commercially feasible smart grids is how the electricity trading can be performed fairly among micro grids. In existing works, this issue has been mainly addressed by using some sort of priority scheme among buyers and sellers in electricity trading, which obviously does not guarantee a fair trading scheme. As a result, the commercial feasibility of existing works is at stake and will not work as proposed. This work tries to address this issue by proposing a Fair Energy Resource Allocation (FERA) method for smart grids. The proposed method has been implemented in a FIPA-compliant Multi-Agent System (MAS) based smart grid control system and evaluated against state-of-the-art round robin and priority based allocation methods. For trading among 30 micro grids, it is demonstrated that the proposed method results in a high fairness index of 96.22% even in the worst case, while the round robin scheme and the priority scheme result in a worst-case fairness index of only 57.8% and 11.29%, respectively. Thus, in the long term under different ratios of buyers and sellers, the proposed method is the only method that can achieve a very high fairness index in the worst case. Averaging over different ratios of buyers and sellers, the proposed method results in a fairness index of 99.57%, which is much higher that achieved by the round robin method (84.04%) and the priority scheme (63.56%). As far as cost saving is concerned, based on the cost saving opportunity (CSO) metric, in the long term (10,000 rounds of trading), the proposed method results in a CSO of 51.48%, which is much higher than that by the other two methods; round robin method results in 14.07% and priority-based method results in 34.44%. (C) 2016 Elsevier B.V. All rights reserved.		Hung-Lin Chao;Pao-Ann Hsiung	2016	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/j.micpro.2016.02.011	telecommunications;computer science;smart grid	EDA	-21.807746411440657	64.96186053252517	8336
811d4e3e9ec50fef1a19d7ab4a344f894cfba597	hierarchical hypercube-based pairwise key establishment schemes for sensor networks	distributed system;red sin hilo;hierarchical system;hypercube;reseau capteur;systeme reparti;reseau sans fil;wireless network;systeme hierarchise;key distribution center;sensor network;wireless sensor network;captador medida;sistema jerarquizado;measurement sensor;red sensores;sistema repartido;capteur mesure;theoretical analysis;criptografia;cryptography;security key;sensor array;cryptographie;key predistribution;cle securite;key establishment;llave seguridad;hipercubo	Security schemes of pairwise key establishment, which enable sensors to communicate with each other securely, play a fundamental role in research on security issue in wireless sensor networks. A general framework for key predistribution is presented, based on the idea of Key Distribution Center and polynomial pool schemes. By utilizing nice properties of Hierarchical Hypercube model, a new security mechanism for key predistribution based on such model is also proposed. Theoretic analysis and experimental figures show that the new algorithm has better performance and provides higher possibilities for sensors to establish pairwise key, compared with previous related works.		Lei Wang;Junyi Li;J. M. Yang;Yaping Lin;Jia-Guang Sun	2006		10.1007/11610496_24	wireless sensor network;telecommunications;computer science;computer security	Mobile	-46.73975770264578	79.10984659542248	8419
be8d83ea04c1c472521a1ae92be19be7c8cc6fca	cim-based connectivity model for bus-branch topology extraction and exchange	topology;hierarchical structure;maharasthra;cim based connectivity model;equipment parameter information;voltage 400 kv;power control center;time varying systems;common information model;power system dynamics;transmission networks;time varying system;network topology;node breaker representation;information transfer;voltage 400 kv cim based connectivity model common information model node breaker representation topologybranch equipment parameter information time varying system transmission network maharasthra india;unified modeling language;topology computer integrated manufacturing network topology unified modeling language power system dynamics merging;merging;bus branch model;power control center bus branch model common information model network topology processing node breaker model;transmission networks time varying systems;network topology processing;computer integrated manufacturing;topologybranch;node breaker model;india;transmission network;power control	In terms of scope and granularity of data, two kinds of connectivity models are broadly in vogue for representing power network data, namely, node-breaker model and bus-branch model. This paper examines both the connectivity models from the perspective of common information model (CIM). Although CIM is primarily designed for most detailed node-breaker representation, with certain extensions CIM can be leveraged to achieve a standard, interoperable bus-branch model representation and exchange format. To facilitate this, it is proposed to introduce new class called TopologyBranch. By decoupling the connectivity information and the equipment parameter information, a mechanism for efficient exchange of time varying system models with minimum information transfer between the power control centers is described in this paper. The proposed CIM bus-branch connectivity model has wide applications in an interoperable, decentralized, hierarchical structure of control centers. Three illustrative examples including one on a practical 20-substation model of the 400 kV transmission network of Maharasthra state, India, are then presented for demonstrating the benefits.	agent-based model;computer-integrated manufacturing;coupling (computer programming);information exchange;information model;interoperability;online and offline;real-time clock;real-time computing;sysop;traction substation	Yemula Pradeep;P. Seshuraju;Shrikrishna A. Khaparde;Rushikesh K. Joshi	2011	IEEE Transactions on Smart Grid	10.1109/TSG.2011.2109016	control engineering;unified modeling language;simulation;information transfer;telecommunications;power control;computer science;operations management;computer-integrated manufacturing;network topology	Visualization	-21.3527880083623	80.88902032995162	8428
07d5f9262a1a8afeba7f4848de5504f1d7011701	an independent h-tcp implementation under freebsd 7.0: description and observed behaviour	swinburne;tcp;freebsd;high performance networks;tcp congestion control;congestion control;h tcp;dynamic behavior	A key requirement for IETF recognition of new TCP algorithms is having an independent, interoperable implementation. This paper describes our BSD-licensed implementation of H-TCP within FreeBSD 7.0, publicly available as a dynamically loadable kernel module. Based on our implementation experience we provide a summary description of the H-TCP algorithm to assist other groups build further interoperable implementations. Using data from our live testbed we demonstrate that our version exhibits expected H-TCP behavior, and describe a number of implementation-specific issues that influence H-TCP's dynamic behavior. Finally, we illustrate the actual collateral impact on path latency of using H-TCP instead of NewReno. In particular we illustrate how, compared to NewReno, H-TCP's cwnd growth strategy can cause faster fluctuations in queue sizes at, yet lower median latency through, congestion points. We believe these insights will prove valuable predictors of H-TCP's potential impact if deployed in consumer end-hosts in addition to specialist, high-performance network environments.	algorithm;bsd;freebsd;interoperability;loadable kernel module;network congestion;testbed	Grenville J. Armitage;Lawrence Stewart;Michael Welzl;James Healy	2008	Computer Communication Review	10.1145/1384609.1384613	compound tcp;tcp congestion-avoidance algorithm;real-time computing;simulation;tcp global synchronization;computer science;operating system;transmission control protocol;h-tcp;zeta-tcp;tcp tuning;network congestion;tcp acceleration;computer security;tcp friendly rate control;slow-start;computer network	Networks	-5.537611030373982	94.46335320928532	8442
972f2d9d0b79f7db15b8cfd42265c326b7d95b9d	fixed-alternate routing and wavelength-routed optical networks	blocking probability;wdm;optical network;sparse wavelength conversion;wavelength routing;probability;optical network units;fixed alternate routing;wavelength channel;blocking probability fixed alternate routing sparse wavelength conversion optical networks wavelength routing crossconnects wavelength division multiplexing wdm connections wavelength channel blocking performance network topology adaptive routing;optical fiber networks;optical switches;optical networks;network topology;blocking performance;alternate routing;optical fibre networks;telecommunication network routing;probability telecommunication network routing optical wavelength conversion optical fibre networks wavelength division multiplexing network topology telecommunication channels;wdm connections;lightpath;simulation study;adaptive routing;intelligent networks;computer science;optical wavelength conversion;wavelength routing optical wavelength conversion intelligent networks optical fiber networks optical switches optical network units wavelength division multiplexing network topology computer science wavelength conversion;telecommunication channels;wavelength conversion;wavelength routing crossconnects;analytical model;wavelength division multiplexing;wavelength division multiplex	Consider an optical network which employs wavelength-routing crossconnects that enable the establishment of wavelength-division-multiplexed (WDM) connections between node pairs. In such a network, when there is no wavelength conversion, a connection is constrained to be on the same wavelength channel along its route. Alternate routing can improve the blocking performance of such a network by providing multiple possible paths between node pairs. Wavelength conversion can also improve the blocking performance of such a network by allowing a connection to use different wavelengths along its route. This work proposes an approximate analytical model that incorporates alternate routing and sparse wavelength conversion. We perform simulation studies of the relationships between alternate routing and wavelength conversion on three representative network topologies. We demonstrate that alternate routing generally provides significant benefits, and that it is important to design alternate routes between node pairs in an optimized fashion to exploit the connectivity of the network topology. The empirical results also indicate that fixed-alternate routing with a small number of alternate routes asymptotically approaches adaptive routing in blocking performance.	approximation algorithm;blocking (computing);network topology;routing;simulation;sparse matrix;wavelength-division multiplexing	Ramu S. Ramamurthy;Biswanath Mukherjee	2002	IEEE/ACM Trans. Netw.	10.1109/TNET.2002.1012367	routing table;routing domain;routing;static routing;hierarchical routing;dsrflow;telecommunications;equal-cost multi-path routing;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;routing protocol;link-state routing protocol;geographic routing;routing information protocol;wavelength-division multiplexing;computer network	Networks	-5.353693940201604	84.11322837047663	8455
d3888454c51923e5de37219938fb3bf17966edea	efficient semiquantum key distribution		Quantum cryptography has attracted much attention in recent years. In most existing quantum cryptographic protocols, players usually need the full quantum power of generating, manipulating or measuring quantum states. Semiquantum cryptography was proposed to deal with the issue that some players require only partial quantum power, such as preparing or measuring quantum states in the classical basis, which simplifies the implementations of quantum cryptography. However, the efficiency of the existing semiquantum cryptographic protocols was relatively low from a practical point of view. In this paper, we devise some new semiquantum key distribution (SQKD) protocols which highly improve the efficiency of the most well-known SQKD protocols [Phys. Rev. Lett. 99, 140501 (2007) & Phys. Rev. A 79, 052312 (2009)]. By letting players select their actions asymmetrically, the efficiency of our new protocols can be made asymptotically close to 100%. Besides, one of our proposed protocols also utilizes the discarded X-SIFT bits in the original SQKD protocol, which further improves the efficiency of SQKD. We prove that the proposed SQKD protocols are completely robust against the most general attack.	cryptographic protocol;key distribution;quantum cryptography;quantum state	Ming-Ming Wang;L B Gong;L. Shao	2018	CoRR			Crypto	-40.3157658710578	74.46677395985981	8462
3fb2a21c4fced11a57e4565692ed7d58fe844602	breaking '128-bit secure' supersingular binary curves - (or how to solve discrete logarithms in f24 1223 and f212 367)		In late 2012 and early 2013 the discrete logarithm problem (DLP) in finite fields of small characteristic underwent a dramatic series of breakthroughs, culminating in a heuristic quasipolynomial time algorithm, due to Barbulescu, Gaudry, Joux and Thomé. Using these developments, Adj, Menezes, Oliveira and Rodŕıguez-Henŕıquez analysed the concrete security of the DLP, as it arises from pairings on (the Jacobians of) various genus one and two supersingular curves in the literature, which were originally thought to be 128-bit secure. In particular, they suggested that the new algorithms have no impact on the security of a genus one curve over F21223 , and reduce the security of a genus two curve over F2367 to 94.6 bits. In this paper we propose a new field representation and efficient general descent principles which together make the new techniques far more practical. Indeed, at the ‘128-bit security level’ our analysis shows that the aforementioned genus one curve has approximately 59 bits of security, and we report a total break of the genus two curve.	128-bit;algorithm;concrete security;digital light processing;discrete logarithm;genus (mathematics);heuristic;quasi-polynomial	Robert Granger;Thorsten Kleinjung;Jens Zumbrägel	2014	IACR Cryptology ePrint Archive	10.1007/978-3-662-44381-1_8	discrete mathematics;mathematics;computer security;algorithm;statistics;algebra	Crypto	-38.52372754452383	79.71189149122164	8465
5d0c560c74c03d1888bbb63254755c00632f9ef1	trust enhanced cryptographic role-based access control for secure cloud data storage	cloud storage service trust enhanced cryptographic role based access control secure cloud data storage data privacy data protection data access trust models security improvement cryptographic rbac schemes trustworthiness inheritance risk reduction decision making quality enhancement data owners;history;encryption;trusted computing authorisation cloud computing cryptography data protection;access control;cloud computing access control history encryption data models;cloud computing;data models	Cloud data storage has provided significant benefits by allowing users to store massive amount of data on demand in a cost-effective manner. To protect the privacy of data stored in the cloud, cryptographic role-based access control (RBAC) schemes have been developed to ensure that the data can only be accessed by those who are allowed by access policies. However, these cryptographic approaches do not address the issues of trust. In this paper, we propose trust models to reason about and to improve the security for stored data in cloud storage systems that use cryptographic RBAC schemes. The trust models provide an approach for the owners and roles to determine the trustworthiness of individual roles and users, respectively, in the RBAC system. The proposed trust models consider role inheritance and hierarchy in the evaluation of trustworthiness of roles. We present a design of a trust-based cloud storage system, which shows how the trust models can be integrated into a system that uses cryptographic RBAC schemes. We have also considered practical application scenarios and illustrated how the trust evaluations can be used to reduce the risks and to enhance the quality of decision making by data owners and roles of cloud storage service.	cloud computing;cloud storage;computer data storage;control system;cryptography;encryption;role-based access control;trust (emotion);ws-trust	Lan Zhou;Vijay Varadharajan;Michael Hitchens	2015	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2015.2455952	cryptographic primitive;cloud computing security;data modeling;cloud computing;client-side encryption;computer science;access control;database;internet privacy;computer security;encryption	Security	-42.089788803861744	66.38073170070088	8470
05f7323c9e2333dd1223c00287b22dd4d962b278	smart tunnel union for nat traversal	naming services;protocols;network address translation internet information security data security proposals communication system control protocols web server ip networks network servers;information security;application server;client server systems;network address translation;network address translator;network servers;internet;ipv4 address depletion problem;telecommunication security;end to end security mechanism;ip networks;internet clients;smart tunnel union for nat traversal;web server;communication system control;telecommunication security client server systems internet ip networks naming services;proposals;end to end security mechanism network address translator ipv4 address depletion problem internet clients smart tunnel union for nat traversal application server;data security	Network address translator (NAT) is the well-known, transitional method to mitigate the problem of IPv4 address depletion in today's Internet. However, the assignment, translation, and export of address/port in a NAT at run time affect application functions. Accordingly, application servers behind the NAT cannot accept requests directly from public networks. Sensitive applications cannot hold their end-to-end security mechanisms. Applications lose connections after the NAT reboots or changes the binding address/port. However, current proposals for NAT traversal hardly solve the problems. Against the problems, we propose Smart Tunnel Union for NAT Traversal (STUNT) in the paper. STUNT permits applications behind the NAT to be actively contacted by Internet clients, keeps end-to-end security mechanisms, and avoids the risk of exporting binding information of the NAT to connection endpoints. Meanwhile, it permits applications to traverse the NAT and keeps the NAT intact	application server;client (computing);depletion region;end-to-end encryption;end-to-end principle;ipv4 address exhaustion;internet;mac address;mobile computing;nat traversal;network address translation;peer-to-peer;relay;run time (program lifecycle phase);server (computing);traverse;tree traversal;whole earth 'lectronic link	Tzu-Chi Huang;Ce-Kuen Shieh;Wen-Huang Lai;Yu-Ben Miao	2005	Fourth IEEE International Symposium on Network Computing and Applications	10.1109/NCA.2005.50	communications protocol;the internet;computer science;information security;tcp hole punching;operating system;network address translation;data security;nat port mapping protocol;world wide web;computer security;web server;application server;nat traversal;computer network	Arch	-27.188183440493052	85.29579761978582	8479
0bb2cac57a91d2495c0e163473c34bbb98e27ce0	real datasets for file-sharing peer-to-peer systems	estensibilidad;distributed system;song;filtering;filtrage;systeme reparti;analisis estadistico;chant;metadata;query processing;availability;disponibilidad;par a par;traitement requete;xml language;filtrado;interrogation base donnee;interrogacion base datos;p2p;partage fichier;probabilistic approach;peer to peer system;particion fichero;sistema repartido;col;statistical analysis;poste a poste;enfoque probabilista;approche probabiliste;diffusion donnee;analyse statistique;metadonnee;difusion dato;communication cost;file sharing;extensibilite;tratamiento pregunta;metadatos;scalability;p2p networks;data broadcast;peer to peer;disponibilite;trace driven simulation;database query;langage xml;lenguaje xml;canto	The fundamental drawback of unstructured peer-to-peer (P2P) networks is the flooding-based query processing protocol that seriously limits their scalability. As a result, a significant amount of research work has focused on designing efficient search protocols that reduce the overall communication cost. What is lacking, however, is the availability of real data, regarding the exact content of users’ libraries and the queries that these users ask. Using trace-driven simulations will clearly generate more meaningful results and further illustrate the efficiency of a generic query processing protocol under a real-life scenario. Motivated by this fact, we developed a Gnutella-style probe and collected detailed data over a period of two months. They involve around 4,500 users and contain the exact files shared by each user, together with any available metadata (e.g., artist for songs) and information about the nodes (e.g., connection speed). We also collected the queries initiated by these users. After filtering, the data were organized in XML format and are available to researchers. Here, we analyze this dataset and present its statistical characteristics. Additionally, as a case study, we employ it to evaluate two recently proposed P2P searching techniques.	algorithm;benchmark (computing);database;file sharing;gnutella;library (computing);peer-to-peer;real life;scalability;simulation;xml	Shen-Tat Goh;Panos Kalnis;Spiridon Bakiras;Kian-Lee Tan	2005		10.1007/11408079_19	filter;availability;scalability;xml;canto;computer science;artificial intelligence;operating system;peer-to-peer;data mining;database;distributed computing;metadata;world wide web;computer security;file sharing;algorithm	DB	-11.345256386514665	70.23636756880796	8483
2a8b11ccdbf2c78229f047a9ca3c4adf90602a38	low-cost mitigation of privacy loss due to radiometric identification	vehicular network;vanet;physical layer;simulation;theory;vehicular networks;radiometric identification;privacy;line of sight	Recently, there has been much interest in using radiometric identification (also known as wireless fingerprinting) for the purposes of authentication. Previous work has shown that using radiometric identification can discriminate among devices with a high degree of accuracy when simultaneously using multiple radiometric characteristics. Additionally, researchers have noted the potential for wireless fingerprinting to be used for more devious purposes, specifically that of privacy invasion or compromise. In fact, any such radiometric characteristic that is useful for authentication is useful for privacy compromise. To date, there has not been any proposal of how to mitigate such privacy loss for many of these radiometric characteristics, and specifically no such proposal for how to mitigate such privacy loss in a low-cost manner.  In this paper, we investigate some limits of an attacker's ability to compromise privacy, specifically an attacker that uses a transmitter's carrier frequency. We propose low-cost mechanisms for mitigating privacy loss for various radiometric characteristics. In our development and evaluation, we specifically consider a vehicular network (VANET) environment. We consider this environment in particular because VANETs will have the potential to leak significant, long-term information that could be used to compromise drivers' personal information such as home address, work address, and the locations of any businesses the driver frequents. While tracking a vehicle using visually observable information (e.g., license plates) to obtain personal information is possible, such means require line-of-sight, whereas radiometric identification would not. Finally, we evaluate one of our proposed mechanisms via simulation. Specifically, we evaluate our carrier frequency switching mechanism, comparing it to the theory we develop, and we show the precision with which vehicles will need to switch their physical layer identities given our parameterization for VANETs.	authentication;carrier frequency;fingerprint (computing);line-of-sight (missile);metric;observable;personally identifiable information;privacy;simulation;transmitter	Jason J. Haas;Yih-Chun Hu;Nicola Laurenti	2011		10.1145/2030698.2030704	vehicular ad hoc network;embedded system;telecommunications;computer science;internet privacy;computer security;computer network	Security	-53.46518004583262	70.95014244422336	8484
fe1f0722d76690047e184b4c69f598c2b135c9cf	distributed packet processing in p2p networks	resource sharing distributed load processing distributed packet processing p2p networks peer to peer network;resource allocation;resource allocation peer to peer computing;simulation experiment;resource sharing;p2p networks;peer to peer computing;peer to peer;intelligent networks peer to peer computing distributed computing network servers bandwidth resource management telecommunication traffic streaming media scheduling algorithm computer science	In this paper, we propose a distributed packet processing algorithm on a peer-to-peer (P2P) network with the objective to minimize the total processing time. We consider an arbitrary P2P network comprising heterogeneous nodes interconnected via heterogeneous links. Each node on the network has its own local workload to be processed and is ready to share its extra processing power among other peer nodes upon request. We distribute the workload of a host to its peers by organizing them into an efficient resource tree. Since the key idea of this algorithm is to effectively share the available resources on the network by processing the load in a distributed manner, we refer to this approach as resource sharing distributed load processing (RSDLP) algorithm. We evaluate the performance with rigorous simulation experiments under generic system parameters.	algorithm;central processing unit;distributed computing;experiment;load balancing (computing);network packet;organizing (structure);peer-to-peer;requirement;simulation	Jingnan Yao;Laxmi N. Bhuyan	2005	GLOBECOM '05. IEEE Global Telecommunications Conference, 2005.	10.1109/GLOCOM.2005.1577369	shared resource;distributed algorithm;real-time computing;resource allocation;computer science;distributed computing;dead peer detection;computer network	HPC	-14.18343681120619	72.56664666469747	8520
a6c304506a8b8cef9a66ad13ef4f05dcd19e858d	optimization of workload scheduling for multimedia cloud computing	minimisation;scheduling cloud computing greedy algorithms minimisation multimedia computing;greedy algorithm workload scheduling optimization multimedia cloud computing cloud based multimedia application large scale workload time varying workload multimedia application provider response time minimization problem resource cost minimization problem;greedy algorithms;multimedia computing;time factors optimal scheduling multimedia communication minimization greedy algorithms processor scheduling cloud computing;scheduling;cloud computing	The cloud based multimedia applications have been widely adopted in recent years. Due to the large-scale and time-varying workload, an effective workload scheduling scheme is becoming a challenge faced by multimedia application providers. In this paper, we study the workload scheduling schemes for multimedia cloud. Specifically, we examine and solve the response time minimization problem and the resource cost minimization problem, respectively. Moreover, we propose a greedy algorithm to efficiently schedule workload for practical multimedia cloud. Simulation results demonstrate that the proposed workload scheduling schemes can optimally balance workload to achieve the minimal response time or the minimal resource cost for multimedia application providers.	cloud computing;greedy algorithm;response time (technology);scheduling (computing);simulation	Xiaoming Nan;Yifeng He;Ling Guan	2013	2013 IEEE International Symposium on Circuits and Systems (ISCAS2013)	10.1109/ISCAS.2013.6572478	minimisation;greedy algorithm;real-time computing;cloud computing;computer science;theoretical computer science;operating system;distributed computing;scheduling	Embedded	-18.776741516759625	65.58935375100477	8542
50e5c2f1f6be5a2603c0d1329a2cf146482909cb	improving the flexibility of the ethernet powerlink pollresponse chaining mechanism	protocols;telecommunication standards local area networks protocols telecommunication network topology;standards;manganese standards time factors protocols automation network topology delays;manganese;network topology;time factors;delays;epl protocol stack ethernet powerlink industrial ethernet networking solution distributed control automation system complex motion control application prc mechanism poll response chaining mechanism software implementation;automation	Ethernet Powerlink (EPL) is an industrial Ethernet networking solution commonly used as a communication network in distributed control and automation systems ranging from simple I/O to highly complex motion control applications. The PollResponse Chaining (PRC) mechanism is a new EPL standard feature aimed at increasing the network performance when nodes exchange small amount of data, especially if they are connected in line topology. However, the efficiency of the mechanism is affected by the network structure, which limits the scope of its applicability in real installations. In this paper, we propose a modification of the original PRC mechanism to improve its flexibility while allowing the same level of performance. This modification requires only minor changes to the available software implementation of the EPL protocol stack. The paper also presents some experimental results that prove the functionality of the proposed solution.	complex network;distributed control system;esoteric programming language;forward chaining;input/output;multiplexing;network performance;propagation delay;protocol stack;software propagation;telecommunications network	Mladen Knezic;Branko Dokic;Zeljko Ivanovic	2016	2016 IEEE World Conference on Factory Communication Systems (WFCS)	10.1109/WFCS.2016.7496513	embedded system;real-time computing;synchronous ethernet;ethernet flow control;engineering;ata over ethernet;industrial ethernet;carrier ethernet;ethernet powerlink;computer network	HPC	-12.0276362232544	84.0204435707091	8630
c5aeccbd168a7d58d21bfbd4268ad338a1afb1a4	realization of a push service for media points based on sip	wireless access;protocols;broadband networks;intranets;session initiation protocol;cellular radio;3g mobile communication land mobile radio cellular systems communication networks ip networks access protocols cellular networks telecommunication network management telecommunication traffic web and internet services gsm;3g mobile communication;internet;multimedia communication;broadband wireless access;managed push services media points sip broadband wireless access systems internet intranet 2g mobile system 3g mobile system fragmented islands public cellular infrastructure session initiation protocol;quality of service;mobile systems;intranets protocols cellular radio broadband networks radio access networks multimedia communication 3g mobile communication telecommunication network management quality of service internet;telecommunication network management;radio access networks;mobile user	AbssfrctBroadband wireless access systems provide a mobile user with wireless access to a fixed infrastructure, e.g. the Internetllntranet. In general, such systems provide only fragmented islands of coverage. Media Point is a service concept which enhances the capabilities of such broadband wireless access systems in combination with a 2G or 3G mobile system. This paper analyzes how fragmented islands of Media Points can he integrated into the public cellular infrastructure and thus make applications and services accessible to the public. The components that can together form a Media Point network are identified and their functionalities are defined. Finally, SIP (Session Initiation Protocol) as a means to provide managed push-services to the public is described.	code coverage	G. Plitsis;Ralf Keller;Joachim Sachs	2002		10.1109/MWCN.2002.1045732	communications protocol;the internet;quality of service;telecommunications;computer science;session initiation protocol;computer security;computer network;broadband networks	Mobile	-15.61584844676515	91.54985987744743	8642
8f183527f1ae39c93c8ef6600a169abe0f76f00f	secure shell (ssh) traffic analysis with flow based features using shallow and deep networks		The primary objective of this work is to evaluate the effectiveness of various shallow and deep networks for characterizing and classifying the encrypted traffic such as secure shell (SSH). The SSH traffic statistical feature sets are estimated from various private and public traces. Private trace is NIMS (Network Information Management and Security Group) and public traces are MAWI (Measurement and Analysis on the WIDE Internet), NLANR's (National Laboratory for Applied Network Research) Active Measurement Project (AMP). To select optimal deep networks, experiments are done for various network parameters, network structures and network topologies. All the experiments are run up to 1000 epochs with learning rate in the range [0.01-0.5]. The various shallow and deep networks are trained using public traces and evaluated on the private trace and vice-versa. Results indicate that there is a possibility to detect SSH traffic with acceptable detection rate. The deep network has performed well in comparison to the shallow networks. Moreover, the performance of various shallow networks is comparable.	deep learning;encryption;epoch (reference date);experiment;information management;machine learning;network topology;tracing (software);traffic analysis	R. Vinayakumar;K. P. Soman;Prabaharan Poornachandran	2017	2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2017.8126143	traffic analysis;cryptography;control engineering;computer science;feature extraction;the internet;encryption;network topology;recurrent neural network;secure shell;computer network	Metrics	-61.330134454407855	67.51557228716128	8681
1359291595aff6368b275a145655a6f39517c8b1	mac-forced forwarding: a method for subscriber separation on an ethernet access network		"""Status of This Memo This memo provides information for the Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Abstract This document describes a mechanism to ensure layer-2 separation of Local Area Network (LAN) stations accessing an IPv4 gateway over a bridged Ethernet segment. The mechanism-called """"MAC-Forced Forwarding""""-implements an Address Resolution Protocol (ARP) proxy function that prohibits Ethernet Media Access Control (MAC) address resolution between hosts located within the same IPv4 subnet but at different customer premises, and in effect directs all upstream traffic to an IPv4 gateway. The IPv4 gateway provides IP-layer connectivity between these same hosts."""	access control;access network;internet;subnetwork	Torben Melsen;Steven Blake	2006	RFC	10.17487/RFC4562	media access control;gateway address;synchronous ethernet;forwarding information base;ethernet flow control;telecommunications;computer science;ata over ethernet;metro ethernet;carrier ethernet;link-local address;computer security;ethernet over pdh;h.248;computer network;arp spoofing	Networks	-23.760802877902528	88.11211678191795	8682
0e580f41f42591e96ee1465745d9e31164d75e28	an evaluation of tcp splice benefits in web proxy servers	tcp splice;packet loss;proxy caching;experimental evaluation;web proxy;proxy server;data transfer	This study is the first to evaluate the performance benefits of using the recently proposed TCP Splice kernel service in Web proxy servers. Previous studies show that splicing client and server TCP connections in the IP layer improves the throughput of proxy servers like firewalls and content routers by reducing the data transfer overheads. In a Web proxy server, data transfer overheads represent a relatively large fraction of the request processing overheads, in particular when content is not cacheable or the proxy cache is memory-based. The study is conducted with a socket-level implementation of TCP Splice. Compared to IP-level implementations, socket-level implementations make possible the splicing of connections with different TCP characteristics, and improve response times by reducing recovery delay after a packet loss. The experimental evaluation is focused on HTTP request types for which the proxy can fully exploit the TCP Splice service, which are the requests for non-cacheabl.content and SSL tunneling. The experimental testbed includes an emulated WAN environment and benchmark applications for HTTP/1.0 Web client, Web server, and Web proxy running on AIX RS/6000 machines. Our experiments demonstrate that TCP Splice enables reductions in CPU utilization of 10-43% of the CPU, depending on file sizes and request rates. Larger relative reductions are observed when tunneling SSL connections, in particular for small file transfers. Response times are also reduced by up to 1.8sec.	aix;benchmark (computing);central processing unit;emulator;experiment;firewall (computing);hypertext transfer protocol;internet protocol suite;network packet;proxy server;rs/6000;server (computing);splice (system call);testbed;throughput;transport layer security;tunneling protocol;web cache;web server	Marcel-Catalin Rosu;Daniela Rosu	2002		10.1145/511446.511449	compound tcp;tcp global synchronization;computer science;tcp hole punching;operating system;database;zeta-tcp;tcp tuning;packet loss;world wide web;tcp acceleration;computer network	Metrics	-18.396131931460015	71.12710566941546	8687
27b330c64e2a6ad80f980b3d75d49125c0948ac5	cross-layer handover scheme for multimedia communications in next generation wireless networks	signal image and speech processing;information systems applications incl internet;wireless network;multimedia communication;cross layer;article;communications engineering networks	In order to achieve seamless handover for real-time applications in the IP Multimedia Subsystem (IMS) of next generation network, a multiprotocol combined handover mechanism is proposed in this paper. We combine SIP (Session Initiation Protocol), FMIP (Fast Mobile IPv6 Protocol), and MIH (Media Independent Handover) protocols by cross-layer design and optimize those protocols’ signaling flows to improve the performance of vertical handover. Theoretical analysis and simulation results illustrate that our proposed mechanism performs better than the original SIP and MIH combined handover mechanism in terms of service interruption time and packet loss.	care-of address;end-to-end principle;ip multimedia subsystem;interrupt;lu decomposition;mii;mobile ip;nar 2;network packet;next-generation network;openstreetmap;real-time clock;real-time transcription;router (computing);seamless3d;semantic network;server (computing);simulation;terms of service;traffic collision avoidance system;uniform resource identifier	Yuliang Tang;Chun-Cheng Lin;Guannan Kou;Der-Jiunn Deng	2010	EURASIP J. Wireless Comm. and Networking	10.1155/2010/390706	real-time computing;telecommunications;computer science;wireless network;computer network	Mobile	-11.610310470569873	90.06611115503465	8775
1b6fe767385d28a9d38b394aa3a9f998d39ae6e2	an ipv6 routing header for source routes with the routing protocol for low-power and lossy networks (rpl)		"""In Low power and Lossy Networks (LLNs), memory constraints on routers may limit them to maintaining at most a few routes. In some configurations, it is necessary to use these memory constrained routers to deliver datagrams to nodes within the LLN. The Routing for Low Power and Lossy Networks (RPL) protocol can be used in some deployments to store most, if not all, routes on one (e.g. the Directed Acyclic Graph (DAG) root) or few routers and forward the IPv6 datagram using a source routing technique to avoid large routing tables on memory constrained routers. This document specifies a new IPv6 Routing header type for delivering datagrams within a RPL domain. Status of this Memo This Internet-Draft is submitted in full conformance with the provisions of BCP 78 and BCP 79 . Internet-Drafts are working documents of the Internet Engineering Task Force (IETF). Note that other groups may also distribute working documents as Internet-Drafts. The list of current InternetDrafts is at http://datatracker.ietf.org/drafts/current/ . Internet-Drafts are draft documents valid for a maximum of six months and may be updated, replaced, or obsoleted by other documents at any time. It is inappropriate to use Internet-Drafts as reference material or to cite them other than as """"work in progress."""" This Internet-Draft will expire on September 30, 2011."""	bsd;datagram;directed acyclic graph;document;lossy compression;low-power broadcasting;router (computing);routing table;source routing	Jonathan W. Hui;Jean-Philippe Vasseur;David E. Culler;Vishwas Manral	2012	RFC	10.17487/RFC6554	policy-based routing;wireless routing protocol;routing table;routing domain;routing;enhanced interior gateway routing protocol;static routing;source routing;real-time computing;hierarchical routing;convergence;dsrflow;zone routing protocol;equal-cost multi-path routing;engineering;dynamic source routing;destination-sequenced distance vector routing;distributed computing;routing protocol;link-state routing protocol;interior gateway routing protocol;path vector protocol;routing information protocol;computer network	Networks	-24.77867832637316	89.35347749280805	8778
c4f7d2ca3105152e5be77d36add2582977649b1d	uninvited connections: a study of vulnerable devices on the internet of things (iot)	scada;shodan;iot;internet of things;shodan iot scada internet of things;insecure devices uninvited connections vulnerable devices internet of things iot internet;databases internet of things object recognition ip networks cameras security;security of data internet internet of things	The Internet of Things (IoT) continues to grow as uniquely identifiable objects are added to the internet. The addition of these devices, and their remote connectivity, has brought a new level of efficiency into our lives. However, the security of these devices has come into question. While many may be secure, the sheer number creates an environment where even a small percentage of insecure devices may create significant vulnerabilities. This paper evaluates some of the emerging vulnerabilities that exist and puts some figures to the scale of the threat.	computer security;internet of things;shodan;security through obscurity;uninvited;vulnerability (computing)	Mark W. Patton;Eric Gross;Ryan Chinn;Samantha Forbis;Leon Walker;Hsinchun Chen	2014	2014 IEEE Joint Intelligence and Security Informatics Conference	10.1109/JISIC.2014.43	the internet;web of things;computer science;internet security;internet privacy;internet appliance;world wide web;computer security;internet of things	Security	-51.12781263009309	62.03849332782681	8782
49e64f040cad753c8157a37bc5fa4bc73a4f3d71	one round group key exchange with forward security in the standard model		Constructing a one round group key exchange (GKE) protocol that provides forward secrecy is an open problem in the literature. In this paper, we investigate whether or not the security of one round GKE protocols can be enhanced with any form of forward secrecy without increasing the number of rounds. We apply the key evolving approach used for forward secure encryption/signature schemes and then model the notion of forward security for the first time for key exchange protocols. This notion is slightly weaker than forward secrecy, considered traditionally for key exchange protocols. We then revise an existing one round GKE protocol to propose a GKE protocol with forward security. In the security proof of the revised protocol we completely avoid reliance on the random oracle assumption that was needed for the proof of the base protocol. Our security proof can be directly applied to the base protocol, making it the most efficient one round GKE protocol secure in the standard model. Our one round GKE protocol is generically constructed from the primitive of forward secure encryption. We also propose a concrete forward secure encryption scheme with constant size ciphertext that can be used to efficiently instantiate our protocol.	ciphertext;encryption;forward secrecy;group key;key exchange;key-agreement protocol;provable security;random oracle	M. Choudary Gorantla;Colin Boyd;Juan Manuel González Nieto	2010	IACR Cryptology ePrint Archive		ciphertext;open problem;forward secrecy;group key;random oracle;encryption;key exchange;computer science;distributed computing	Crypto	-40.31931884478465	75.75855656065202	8810
0aa40852ccd0281ec3ba677d0fabfbec91371517	towards realistic modeling of ip-level routing topology dynamics		Many works have studied the Internet topology, but few have investigated the question of how it evolves over time. This paper focuses on the Internet routing IP-level topology and proposes a first step towards realistic modeling of its dynamics. We study periodic measurements of routing trees from a single monitor to a fixed destination set and identify invariant properties of its dynamics. Based on those observations, we then propose a model for the underlying mechanisms of the topology dynamics. Our model remains simple as it only incorporates load-balancing phenomena and routing changes. By extensive simulations, we show that, despite its simplicity, this model effectively captures the observed behaviors, thus providing key insights on relevant mechanisms governing the Internet routing dynamics. Besides, by confronting simulations over different kinds of topology, we also provide insights on which structural properties play a key role to explain the properties of the observed dynamics, which therefore strengthens the relevance of our model.	alain fournier;computer simulation;depth perception;internet topology;linear algebra;link-state routing protocol;load balancing (computing);project euler;random graph;relevance;routing;shortest path problem;simulation	Clémence Magnien;Amelie Medem Kuatse;Fabien Tarissan	2013	CoRR	10.1007/s13119-013-0023-5	simulation;computer science;artificial intelligence;theoretical computer science	Networks	-9.584529825816247	77.95897526451294	8818
658422780120599b81714d4e18a91081a4964c6a	peer-to-peer solutions for cellular networks	content distribution network;protocols;mobile device;peer to peer network;incentive;cellular radio;cell phones;peer to peer computing cellular radio mobile computing mobile handsets;mobile peer to peer approaches cellular networks peer to peer content distribution networks mobile devices cell phones;cellular networks;mobile peer to peer approaches;peer to peer content distribution networks;computer architecture;indexes;servers;mobile service;mobile peer to peer;mobile services mobile peer to peer incentive cellular networks;peer to peer computing land mobile radio cellular systems protocols computer networks hardware batteries mobile communication distributed computing cellular phones application software;mobile communication;cellular network;mobile handsets;peer to peer computing;mobile services;mobile computing;peer to peer;mobile devices;mobile network	The participation of stationary computers with high-bandwidth links in peer-to-peer content-distribution networks is highly popular. Mobile devices (e.g. cell phones), however, could not yet be launched into the field to a satisfactory extent. This paper discusses mobile peer-to-peer approaches that cover this issue and compares two promising approaches in detail. The first approach supports mobile devices by adding new infrastructure elements to the mobile network operator's domain. In the second approach, voluntary peers provide support for mobile devices. Both approaches are able to foster the integration of mobile devices into peer-to-peer networks with a large user community.		Andreas Berl;Hermann de Meer;Tobias Hoßfeld	2009	2009 First International Conference on Advances in P2P Systems	10.1109/AP2PS.2009.17	mobile search;computer science;mobile technology;distributed computing;internet privacy;mobile computing;computer network	Mobile	-14.963364436624145	90.45734964420781	8832
6f4e4cda79918557b9d16cebb8c95b34e150dd25	on the role of key schedules in attacks on iterated ciphers	distributed system;ley uniforme;approximation lineaire;systeme reparti;metodo diferencial;modelo markov;securite;cryptanalyse;modele lineaire;linear approximation;modelo lineal;probabilistic approach;differential method;cryptanalysis;criptoanalisis;scheduling algorithm;markov model;sistema repartido;enfoque probabilista;approche probabiliste;differential cryptanalysis;safety;linear model;aproximacion lineal;methode differentielle;modele markov;seguridad;loi uniforme;uniform distribution;markov chain	This paper considers iterated ciphers and their resistance against linear and differential cryptanalysis. In the theory of these attacks one assumes independence of the round keys in the ciphers. Very often though, the round keys are computed in a key schedule algorithm from a short key in a nonrandom fashion. In this paper it is shown by experiments that ciphers with complex key schedules resist both attacks better than ciphers with more straightforward key schedules. It is well-known that by assuming independent round keys the probabilities of differentials and linear hulls can be modeled by Markov chains and that for most such ciphers the distribution of the probabilities of these converge to the uniform distribution after some number of rounds. The presented experiments illustrate that some iterated ciphers with very simple key schedules will never reach this uniform distribution. Also the experiments show that ciphers with well-designed, complex key schedules reach the uniform distribution faster (using fewer rounds) than ciphers with poorly designed key schedules. As a side result it was found that there exist ciphers for which the differential of the highest probability for one fixed key is also the differential of the highest probability for any other key. It is believed that this is the first such example provided in	algorithm;cipher;converge;differential cryptanalysis;existential quantification;experiment;iterated function;iteration;key schedule;linear cryptanalysis;markov chain;schedule (computer science)	Lars R. Knudsen;John Erik Mathiassen	2004		10.1007/978-3-540-30108-0_20	cryptanalysis;contact analysis;markov chain;differential cryptanalysis;discrete mathematics;calculus;block size;linear model;key schedule;avalanche effect;correlation attack;symmetric-key algorithm;mathematics;s-box;markov model;uniform distribution;t-function;scheduling;algorithm;statistics;linear approximation;linear cryptanalysis	Crypto	-39.567701593836915	83.50704054031469	8833
073bcc1f9a14662522ad7e8409cb129b85ccbeeb	p2p iptv measurement: a comparison study	p2p;internet architecture;network traffic;file sharing;p2p networks	With the success of P2P file sharing, new emerging P2P applications arise on the Internet for streaming content like voice (VoIP) or live video (IPTV). Nowadays, there are lots of works measuring P2P file sharing or P2P telephony systems, but there is still no comprehensive study about P2P IPTV, whereas it should be massively used in the future. During the last FIFA world cup, we measured network traffic generated by P2P IPTV applications like PPlive, PPstream, TVants and Sopcast. In this paper we analyze some of our results during the same games for the applications. We focus on traffic statistics and churn of peers within these P2P networks. Our objectives are threefold: we point out the traffic generated to understand the impact they will have on the network, we try to infer the mechanisms of such applications and highlight differences, and we give some insights about the users’ behavior.	download;file sharing;iptv;network packet;network traffic control;pps.tv;peer-to-peer;streaming media;web traffic	Thomas Silverston;Olivier Fourmaux	2006	CoRR		telecommunications;computer science;peer-to-peer;internet privacy;world wide web;file sharing;computer network	Metrics	-10.224168937147777	97.6991920027719	8856
a9722d821e72dece34a3727f99eea1f51d813e8a	an analytical study of a structured overlay in the presence of dynamic membership	functional form;steady state;master equation	In this paper, we present an analytical study of dynamic membership (aka churn) in structured peer-to-peer networks. We use a fluid model approach to describe steady-state or transient phenomena and apply it to the Chord system. For any rate of churn and stabilization rates and any system size, we accurately account for the functional form of the probability of network disconnection as well as the fraction of failed or incorrect successor and finger pointers. We show how we can use these quantities to predict both the performance and consistency of lookups under churn. All theoretical predictions match simulation results. The analysis includes both features that are generic to structured overlays deploying a ring as well as Chord-specific details and opens the door to a systematic comparative analysis of, at least, ring-based structured overlay systems under churn.		Supriya Krishnamurthy;Sameh El-Ansary;Erik Aurell;Seif Haridi	2008	IEEE/ACM Trans. Netw.	10.1145/1453698.1453704	qualitative comparative analysis;simulation;computer science;theoretical computer science;distributed computing;predictive modelling;steady state;master equation;higher-order function;network topology;computer network;fluid dynamics	HCI	-7.724055136314279	72.88454151021368	8881
f4b8921240f90c102e143fce68f86f82000db8f7	implications of theoretic derivations on empirical passive measurements for effective cyber threat intelligence generation		Cyber space continues to be threatened by various debilitating attacks. In this context, executing passive measurements by analyzing Internet-scale, one- way darknet traffic has proven to be an effective approach to shed the light on Internet-wide maliciousness. While typically such measurements are solely conducted from the empirical perspective on already deployed darknet IP spaces using off-the-shelf Intrusion Detection Systems (IDS), their multidimensional theoretical foundations, relations and implications continue to be obscured. In this paper, we take a first step towards comprehending the relation between attackers' behaviors, the width of the darknet vantage points, the probability of detection and the minimum detection time. We perform stochastic modeling, derivation, validation, inter-correlation and analysis of such parameters to provide numerous insightful inferences, such as the most effective IDS and the most suitable darknet IP space, given various attackers' activities in the presence of detection time/probability constraints. One of the outcomes suggests that the widely-deployed Bro IDS is ideal for inferring slow, stealthy probing activities by leveraging passive measurements. Further, the results do not recommend deploying the Snort IDS when the available darknet IP space is relatively small, which is a typical scenario when darknets are operated and employed on organizational sub-networks. We concur that the generated derivations and mathematical relations put forward a first-of-akind formal and an accurate characterization of darknet-centric notions, which possess significant implications on Internet and passive measurements. This is especially factual with the advent of evolving paradigms such as IPv6 deployments and the proliferation of highly-distributed, orchestrated, large-scale and stealthy probing botnets.	botnet;bro;darknet;snort;stochastic modelling (insurance);theory	Morteza Safaei Pour;Elias Bou-Harb	2018	2018 IEEE International Conference on Communications (ICC)	10.1109/ICC.2018.8422720	computer network;the internet;microsoft windows;statistical power;ipv6;botnet;intrusion detection system;computer science;stochastic process;darknet	Metrics	-59.92667204551532	63.991673611257006	8921
c4b86ff1514d21fddd18afbe5935abee6e0b534a	multi-user signals combined with quadratic residue code for monitoring system	simulink;model combination;quadratic residue code;mobile device;decoding;qr code generation;database;code generation;multi user;source separation computerised monitoring cyclic codes decoding mobile computing;amplitude lock loop separation model;multiuser signals;monitoring system;information embedding;cyclic code multiuser signals quadratic residue code industrial information tagging database amplitude lock loop separation model qr code generation decode mobile device monitoring system matlab simulink;decode;cyclic codes;cyclic code;middleware;computerised monitoring;mobile computing;source separation;matlab;monitoring mathematical model decoding tagging databases robustness signal generators cameras middleware phase locked loops;industrial information tagging	Quadratic residue code (QR code) was designed to carry significantly more data than its ID counterpart. These codes are general used in industrial information tagging applications where database high data capacity, mobility, and data robustness are required. In this paper, we have developed the amplitude-lock loop (ALL) separation model combined with application of quadratic residue code. The separated multi-user signal information embedded in QR code through QR code generation. Then, we can decode to obtain the information of multi-user signals by mobile device with camera. The mobile device must embed to decode the middleware for QR code. The multi-user signals combined with quadratic residue code for monitoring system, which includes five functions. The system composed of FM model, PLL model, ALL model, QR code generation and mobile device. We adopted the MATLAB/Simulink to simulate this system then reached the purpose of monitor.	code generation (compiler);embedded system;fm broadcasting;matlab;middleware;mobile device;multi-user;phase-locked loop;qr code;quadratic residue code;simulation;simulink	Chien-Jung Ho;Wen-Hao Hsieh;Gwo-Jia Jong	2008	2008 Eighth International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2008.257	systematic code;embedded system;real-time computing;constant-weight code;computer science;theoretical computer science;cyclic code;code rate;middleware;mobile device;dual code;mobile computing;code generation	Robotics	-30.168075716602846	83.03535645147232	8972
1a54e66ebf11910c4c317af0b65e66bc0cdb44f5	learning of personalized security settings	indium phosphide;privacy indium phosphide cryptography;machine learning cybersecurity;user interfaces learning artificial intelligence security of data;machine learning;cryptography;computer users learning personalized security settings cybersecurity tools;cybersecurity;learning artificial intelligence;user interfaces;security of data;privacy	While many cybersecurity tools are available to computer users, their default configurations often do not match needs of specific users. Since most modern users are not computer experts, they are often unable to customize these tools, thus getting either insufficient or excessive security. To address this problem, we are developing an automated assistant that learns security needs of the user and helps customize available tools.	applications of artificial intelligence;computer security;personalization;user (computing)	Mehrbod Sharifi;Eugene Fink;Jaime G. Carbonell	2010	2010 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2010.5642461	computer science;cryptography;data mining;privacy;world wide web;computer security	DB	-53.12953740541807	63.54272181532381	8977
1bf6fc53b086fd55007f98652b06de60a1433dec	taylor series prediction: a cache replacement policy based on second-order trend analysis	second order;cache storage;performance evaluation;trend analysis;cache storage internet performance evaluation;system performance;internet;cache replacement;web access traces taylor series prediction cache replacement policy second order trend analysis internet systems performance page replacement gdsf caching;taylor series internet heart system performance costs frequency web pages performance analysis algorithm design and analysis computer science;web caching;prediction;taylor series;replacement policy	Caching is one of the most e ective techniques for improving the performance of Internet systems. The heart of a caching system is its page replacement policy, which decides which page to replace in a cache by a new one. Di erent caching policies have dramatically di erent e ects on the system performance. In this paper, we extend the well-known GDSF caching policies to include not only access trend information, but also the dynamics of the access trend itself to the trends on access trends. The new trend policy that we propose, called Taylor Series Prediction (TSP) policy, provides more accurate prediction on future accessing trends when the access patterns vary greatly. We back up our claims through a series of experiments using web access traces.	application domain;backup;cache (computing);experiment;internet access;page replacement algorithm;tracing (software);whole earth 'lectronic link;world wide web	Qiang Yang;Henry Haining Zhang;Hui Zhang	2001		10.1109/HICSS.2001.926537	real-time computing;the internet;prediction;trend analysis;cache;computer science;taylor series;cache invalidation;database;adaptive replacement cache;computer performance;smart cache;cache algorithms;world wide web;second-order logic;statistics	DB	-17.69922105184786	71.18875819395242	8979
7c260ad0ef866e318b15cfee6249bca45de51506	simplifying network management using software defined networking and openflow	telecommunication traffic cryptography graphical user interfaces local area networks telecommunication network management;telecommunication traffic;graphical user interfaces;cryptography;middleboxes network management software defined networking openflow choke points traffic flows data planes data flows encryption processing unit dynamic traffic isolation virtual local area networks vlan gui;middlebox software defined networking openflow network management encryption waypoint services vlan dynamic traffic isolation;local area networks;telecommunication network management	As the complexity of deployments increases, network managers face two problems that we address in this paper. First, the deployment of middleboxes in choke points (between two routers through which all traffic flows), raises concerns regarding robustness, correctness and efficiency. Second, dynamically managing traffic isolation in a network is a very tedious task. In this paper we propose using Software Defined Networks (SDN) and OpenFlow to simplify network management by addressing these two challenges. SDN consists of decoupling the control and data planes of a network. OpenFlow standardizes the way that the controller communicates with the network devices in an SDN architecture. To overcome the challenge faced by deploying middleboxes in choke points, we show how these appliances can be deployed at waypoints. In this architecture, a waypoint is only traversed by traffic that needs further processing. The remaining data flows through the network without being processed by the middlebox. We have developed an application that implements an encryption processing unit that works as a waypoint and we show how OpenFlow can be used to route through the encryption unit only the traffic that requires encryption. To overcome the challenge of dynamic traffic isolation, we show how a network manager can use an application to create, delete and modify virtual local area networks (VLANs) in a dynamic way to achieve traffic isolation. Our implementation provides a GUI to the user so that the administration of the VLANs is greatly simplified.	correctness (computer science);coupling (computer programming);encryption;graphical user interface;middlebox;openflow;regular expression;software deployment;software-defined networking;virtual lan;waypoint	Adrian Lara;Anisha Kolasani;Byrav Ramamurthy	2012	2012 IEEE International Conference on Advanced Networks and Telecommunciations Systems (ANTS)	10.1109/ANTS.2012.6524222	traffic generation model;network traffic control;engineering;distributed computing;software-defined networking;computer security;computer network	Mobile	-15.16220311759558	82.32343982038812	8980
0d4661ca3e3da352b8ca5a0ddb84a6923c6ef9eb	multimedia proxy caching mechanism for quality adaptive streaming applications in the internet	available bandwidth;cache storage;multimedia streaming;streaming media internet bandwidth web server network servers prefetching intersymbol interference explosives pipelines mirrors;application server;telecommunication congestion control;proxy caching;internet;congestion control;telecommunication congestion control multimedia communication cache storage quality of service internet;multimedia communication;end to end congestion control;quality of service;replacement algorithm multimedia proxy caching mechanism quality adaptive streaming applications internet web based streaming applications end to end congestion control quality adaptation average available bandwidth delivered quality bottleneck bandwidth layered encoded multimedia streams quality variable cached stream prefetching mechanism fine grain replacement algorithm layered encoded streams	The Internet has witnessed a rapid growth in deployment of Web-based streaming applications during recent years. I n these applications, server should be able to perform end-to-end con gestion control and quality adaptation to match the delivered stream quality to the average available bandwidth. Thus the delivered quality islimited by the bottleneck bandwidth on the path to the client. This paper proposes a proxy caching mechanism for layered-e ncoded multimedia streams in the Internet to maximize the delivered quality of popular streams to interested clients. The main challeng e is to replay a quality-variable cached stream while performing quality adaptation effectively in response to the variations in available bandwidth. We present a prefetching mechanism to support higher qualit y cached streams during subsequent playbacks and improve the qualit y of the cached stream with its popularity. We exploit inherent properties of multimedia streams to extend the semantics of popularity an d capture both level of interest among clients and usefulness of a laye r in the cache. We devise a fine-grain replacement algorithm suited for laye red-encoded streams. Our simulation results show that the interaction between the replacement algorithm and prefetching mechanism causes th e state of the cache to converge to an efficient state such that the quali ty of a cached stream is proportional to its popularity, and the variations in quality of a cached stream are inversely proportional to itspopularity. This implies that after serving several requests for a strea m, the proxy can effectively hide low bandwidth paths to the original ser ver from interested clients. Keywords— Multimedia Proxy Caching, Streaming Applications, Congestion Control, Quality Adaptation, Internet.	cpu cache;cache (computing);converge;end-to-end principle;internet;naruto shippuden: clash of ninja revolution 3;network congestion;page replacement algorithm;server (computing);simulation;software deployment;ver (command)	Reza Rejaie;Haobo Yu;Mark Handley;Deborah Estrin	2000		10.1109/INFCOM.2000.832273	real-time computing;the internet;quality of service;computer science;operating system;network congestion;world wide web;application server;computer network	OS	-6.897608877295674	98.04970969821453	8984
2deaf9e8807c9283d03e773a3cd4ffc247d1ef1f	towards a basic dht service: analyzing network characteristics of a widely deployed dht	distributed application;protocols;distributed hash table;peer to peer computing protocols europe logic gates crawlers asia;data storage;logic gates;bittorrent dht service network characteristics distributed hash tables distributed architectures distributed information lookup routing data storage file sharing end user behavior dht protocol;bittorrent;crawlers;file sharing;user behavior;europe;peer to peer computing;point of view;logic gate;geographic distribution;asia;distributed architecture	Distributed Hash Tables (DHTs) prove valuable for distributed architectures by providing distributed information lookup, routing, and data storage while promising good scalability and robustness at the same time. From this point of view, a DHT could be seen as a basic service that can be used to build distributed applications. Whereas today no widely deployed and publicly accessible basic DHT service exists and thus DHT- based applications have to deploy their very own DHT networks, DHTs consisting of millions of peers are formed by file sharing clients. Although the interfaces of typical DHTs used for file sharing are too narrow, a basic DHT service could probably be created by bundling a suitable client implementation with file sharing software. In this paper, we evaluate whether a basic DHT service could suit the needs of DHT- based applications in terms of stability, number of participating peers, the peers'' session lengths, geographical distribution and peer connectivity when deployed similar to DHTs driven by file sharing. As these metrics mostly depend on end user behavior rather than on the DHT protocol, we report on measurement results gathered from monitoring of the BitTorrent Mainline client''s DHT over six months. We analyze which metrics would fit a basic DHT service and which could prove problematic. Furthermore, we discuss resulting technical requirements for an appropriate DHT protocol.	bittorrent (software);computer data storage;distributed computing;distributed hash table;file sharing;locality of reference;lookup table;multistage interconnection networks;point of view (computer hardware company);requirement;routing;scalability;user interface	Konrad Jünemann;Philipp Andelfinger;Hannes Hartenstein	2011	2011 Proceedings of 20th International Conference on Computer Communications and Networks (ICCCN)	10.1109/ICCCN.2011.6005906	logic gate;computer science;operating system;distributed computing;world wide web;computer network	HPC	-13.892247454783856	76.79471583679666	8987
ebf935e2b59feeafd21d4da0dc501e26ca6deddf	mobility support for ipv6-based vanet	mobility handover;coa;ipv6;vehicular ad hoc network;home address	Taylor & Francis makes every effort to ensure the accuracy of all the information (the “Content”) contained in the publications on our platform. However, Taylor & Francis, our agents, and our licensors make no representations or warranties whatsoever as to the accuracy, completeness, or suitability for any purpose of the Content. Any opinions and views expressed in this publication are the opinions and views of the authors, and are not the views of or endorsed by Taylor & Francis. The accuracy of the Content should not be relied upon and should be independently verified with primary sources of information. Taylor and Francis shall not be liable for any losses, actions, claims, proceedings, demands, costs, expenses, damages, and other liabilities whatsoever or howsoever caused arising directly or indirectly in connection with, in relation to or arising out of the use of the Content.	francis;network packet;primary source;ruby document format;scott continuity	Xiaonan Wang;Hongbin Cheng;Yufeng Yao	2015	IJPEDS	10.1080/17445760.2014.920841	vehicular ad hoc network;telecommunications;computer science;ipv6;computer security;computer network	Robotics	-23.1189123442692	90.30527563582626	9003
f269b43cf53768f4a469247cc575cb75321e1e86	madam: a multi-level anomaly detector for android malware	android;intrusion detection;classification;security	Currently, in the smartphone market, Android is the platform with the highest share. Due to this popularity and also to its open source nature, Android-based smartphones are now an ideal target for attackers. Since the number of malware designed for Android devices is increasing fast, Android users are looking for security solutions aimed at preventing malicious actions from damaging their smartphones. In this paper, we describe MADAM, a Multi-level Anomaly Detector for Android Malware. MADAM concurrently monitors Android at the kernel-level and user-level to detect real malware infections using machine learning techniques to distinguish between standard behaviors and malicious ones. The first prototype of MADAM is able to detect several real malware found in the wild. The device usability is not affected by MADAM due to the low number of false positives generated after the learning phase.	android;anomaly detection;high-level programming language;kernel (operating system);machine learning;malware;open-source software;prototype;smartphone;tracing (software);usability;user experience;user space	Gianluca Dini;Fabio Martinelli;Andrea Saracino;Daniele Sgandurra	2012		10.1007/978-3-642-33704-8_21	computer science;information security;internet privacy;world wide web;computer security;android	Security	-57.356240134593136	60.66323835149503	9005
ee6af5a07ef34030cb60d0887a6476f7e83171f6	network delay analysis of ethercat and profinet irt protocols	protocols;real time systems access protocols electronic data interchange local area networks networked control systems;networked control systems performance analysis real time ethernet protocols communication networks;mac layer design network delay analysis ethercat profinet irt protocols real time protocol standard ethernet technology real time ethernet protocol beckhoff and siemens data link layer ethernet like network ieee 802 3 real time capability critical communication data transfer time industrial network control system performance asynchronous system configuration;delays real time systems protocols payloads synchronization data transfer field programmable gate arrays;synchronization;payloads;field programmable gate arrays;data transfer;delays;real time systems	Real-time protocols originated from standard Ethernet technology have been gradually developed over the last decade. Candidates of real-time Ethernet protocols are EtherCAT and PROFINET IRT from Beckhoff and Siemens, respectively. In contrast to standard Ethernet, data-link layers of both Ethernet-like networks are modified from IEEE 802.3 in order to improve real-time capabilities for critical communications. Network delay refers to data transfer time on a network. It is of great importance to assess this parameter for industrial networks as it can possibly make significant impact to the control system performance. This paper gives network delay analysis on EtherCAT and PROFINET IRT in the context of industrial applications. Delays are formulated and then evaluated under both synchronous and asynchronous system configurations. Simulation results demonstrate that both protocols are of realtime guarantees in data transfer. However, each protocol has its own characteristics and strong points due to different MAC layer design.	asynchronous i/o;asynchronous system;communications protocol;control system;item response theory;network computing system;network planning and design;real-time clock;real-time computing;real-time transcription;requirement;scheduling (computing);simulation;synchronization (computer science);systems architecture;throughput	Xuepei Wu;Lihua Xie;Freddy Lim	2014	IECON 2014 - 40th Annual Conference of the IEEE Industrial Electronics Society	10.1109/IECON.2014.7048872	embedded system;real-time computing;ethercat;media access control;synchronous ethernet;ethernet flow control;computer science;ata over ethernet;industrial ethernet;connection-oriented ethernet;carrier ethernet;ethernet over sdh;profinet;ethernet powerlink;computer network	Embedded	-6.372722839605073	69.91262937929338	9016
15abaad2e23f4d5960cb9816c1b5b1c2d944486d	denial of service attack mitigation addressing all the security attributes in olsr manet			denial-of-service attack;manet database;optimized link state routing protocol	R. Bhuvaneswari;Ravikumar Ramachandran	2018	IJWMC	10.1504/IJWMC.2018.10015862	computer network;mobile ad hoc network;optimized link state routing protocol;denial-of-service attack;computer science	Security	-54.54230191023253	75.27749948087411	9035
97e7178d70c8e93c8211e7ffaf1528d8d7306921	decentralized media streaming infrastructure (demsi): an adaptive and high-performance peer-to-peer content delivery network	decentralised systems;content delivery networks;distributed computing;journal article;scheduling algorithm;resource sharing;media streaming;content delivery network;peer to peer computing;peer to peer;high performance;network congestion	Hosting an on-demand media content streaming service has been a challenging task mainly because of the outrageously enormous network and server bandwidth required to deliver large amount of content data to users simultaneously. We propose an infrastructure that helps online media content providers offload their server and network resources for media streaming. Using application level resource diversity together with the peer-to-peer resource-sharing model is a feasible approach to decentralize the content storage, server and network bandwidth. Each subscriber is responsible for only a small fraction of such resources. Most importantly, the cost of maintaining the service can also be shared amongst subscribers, especially when the subscriber base is large. As a result, subscribers can be benefit from lower subscription cost. There have been a few solutions out there that focused only on sharing the load of network bandwidth by division of a streaming task to be carried out by multiple sources. However, existing solutions require that the content to be replicated in full and stored in each source, which is impractical for a subscriber as the owner of the storage resource that is of consumer capacity. Our solution focuses on the division of responsibility on both the network bandwidth and content storage such that each subscriber is responsible for only a small portion of the content. We propose a light-weighted candidate peer selection strategy based on avoidance of network congestion and an adaptive re-scheduling algorithm in order to enhance smoothness of the aggregated streaming rate perceived at the consumer side. Experiments show that the performance of our peer-selection strategy out performs the traditional strategy based on end-to-end streaming bandwidth. 2006 Elsevier B.V. All rights reserved.	algorithm;bandwidth management;digital distribution;digital media;end-to-end principle;holography;network congestion;out there;peer-to-peer;scheduling (computing);server (computing)	Alan Kin Wah Yim;Rajkumar Buyya	2006	Journal of Systems Architecture	10.1016/j.sysarc.2006.05.001	multi-frequency network;shared resource;real-time computing;computer science;operating system;distributed computing;network congestion;scheduling;world wide web;computer network	Networks	-16.49346045133278	73.9662313022339	9054
4d385116cf2eb77f767d188cbcbea49a495f4764	analysis tool for web hosting service providers	service provider	"""As the popularity of the Web grows, an increasing number of businesses are wishing to seize the potential market opportunities that it o ers. The shared Web hosting service uses the possibility to create a set of virtual servers on the same physical server. Each virtual server is set-up to write its own access log. Such implementation and set-up splits the \whole picture"""" of web server usage into multiple independent pieces, making it di cult for the service provider to understand and analyze the \aggregate"""" tra c characteristics. Web Hosting Analysis Tool (WHAT) aims to provide the information which is of interest to system administrators and service providers; the information which provides insight into the system's resource requirements and tra c access patterns."""	requirement;server (computing);shared web hosting service;system administrator;virtual private server;web server;world wide web	Ludmila Cherkasova;Mohan DeSouza;James Jobin	2000			service provider;service delivery framework;world wide web;service level objective;application service provider;computer network;service level requirement;business service provider;online charging system;service design;business	Metrics	-13.495904303917678	99.42094612148753	9085
821df0cf3b1244f984015e9a28975e271e6145c8	mesh network firewalling with bloom filters	radio networks;filtering;routing protocols;compact data structure;probability;packet filtering;bloom filter;authorisation;information filtering;filters;probabilistic membership queries;unwanted traffic;wireless mesh network;bloom filters;backhaul network;mesh network firewalling;telecommunication traffic;spread spectrum communication;compact data structure mesh network firewalling bloom filters multi hop wireless mesh network terminal traffic backhaul network unwanted traffic network subtracting authorized terminals packet filtering distributed firewalling probabilistic membership queries;telecommunication security;mesh networks peer to peer computing wireless mesh networks telecommunication traffic filtering spread spectrum communication routing protocols filters communication system security measurement standards;wireless mesh networks;mesh networks;mesh network;distributed firewalling;telecommunication traffic authorisation information filtering probability radio networks telecommunication security;peer to peer computing;terminal traffic;measurement standards;multi hop wireless mesh network;data structure;network subtracting;communication system security;authorized terminals	The nodes of a multi-hop wireless mesh network often share a single physical media for terminal traffic and for the backhaul network, so that the available resources are extremely scarce. Under these conditions it is important to avoid that unwanted traffic may traverse the network subtracting resources to authorized terminals. Packet filtering in wireless mesh networks is an extremely challenging task, since the number of possible connections is quadratic with respect to the number of the terminals of the network; for each connection a rule is needed and the time needed for filtering grows linearly with the number of rules. Moreover nodes can be in possession of end users and the administrator might want to keep the explicit ruleset as much secret as possible while giving the nodes enough data to behave as a firewall. In this article we present a solution for distributed firewalling in multi-hop mesh networks based on the use of Bloom Filters, a powerful but compact data structure allowing probabilistic membership queries.	authorization;backhaul (telecommunications);bloom filter;data structure;firewall (computing);hash function;mesh networking;network packet;overhead (computing);particle filter;peer-to-peer;traverse;wireless mesh network	Leonardo Maccari;Romano Fantacci;Pablo Neira Ayuso;Rafael M. Gasca	2007	2007 IEEE International Conference on Communications	10.1109/ICC.2007.259	wireless mesh network;switched mesh;data structure;telecommunications;computer science;bloom filter;mesh networking;shared mesh;distributed computing;order one network protocol;computer network	HPC	-56.25847963292289	72.69481645218877	9124
bf1af8f30c2856640a92f903f74c537aa1f4bf13	sla management and service composition of virtualized applications in mobile networking environments	monitoring mobile communication business mobile computing computer architecture cloud computing quality of service;computer architecture;monitoring;distributed services sla cloud services mobile networking service orchestration;business;mobile communication;quality of service;mobile computing;cloud computing	Cloud computing is a promising solution for the flexible, on-demand delivery of communication services and infrastructures. The European Union funded project Mobile Cloud Networking is developing a cloud-based mobile communication service platform where service providers deliver virtualized wireless infrastructures integrated with high-level applications running on top of them. Mobile networks are redesigned, placed upon and operated on cloud computing platforms. These then are available with the on-demand, elastic and pay-as-you-go characteristics derived from the cloud principles. In this platform, a variety of services including heterogeneous radio networking, federated computing resources, virtualized network functions, support services and high-level applications are automatically and seamlessly orchestrated in composite end-to-end services delivered to enterprise end-users. The management of Service Level Agreements (SLAs) for these cloud-based composite services requires a dedicated framework to combine and jointly manage the multiple SLAs associated to the different service components. This paper presents an architecture for the enforcement and validation of SLAs for mobile cloud services, discussing its positioning in the overall mobile cloud networking platform and its role across the different phases of the service lifecycle.	content delivery network;end-to-end encryption;end-to-end principle;high- and low-level;mobile cloud computing;network function virtualization;network packet;prototype;radio access network;reference architecture;service composability principle;service-level agreement	Giada Landi;Pedro Neves;Andy Edmonds;Thijs Metsch;Julius Mueller;Paolo Secondo Crosta	2014	2014 IEEE Network Operations and Management Symposium (NOMS)	10.1109/NOMS.2014.6838413	cloud computing security;mobile search;mobile qos;mobile web;quality of service;mobile telephony;cloud computing;computer science;operating system;mobile technology;cloud testing;distributed computing;utility computing;mobile business development;services computing;mobile computing;world wide web;provisioning;computer network	Mobile	-18.390903852532237	82.96978796427364	9171
88f88eb596d9f50d05e3afc34e2ccb5850ab4429	an overview of virtual machine placement schemes in cloud computing	virtual machine;migration;placement;power efficiency	In cloud computing, Virtual Machine (VM) placement is a critical operation which is conducted as part of the VM migration and aimed to find the best Physical Machine (PM) to host the VMs. It has a direct effect on the performance, resource utilization and power consumption of the data centers and can reduce the maintenance cost of the data centers for cloud providers. Numerous VM placement schemes are designed and proposed for VM placement in the cloud computing environment aimed to improve various factors affecting the data centers, the VMs and their executions. This article provides a complete survey and analyses of the existing state of the art VM placement schemes proposed in the literature for the cloud computing and data centers. Furthermore, it classifies the VM placement schemes based on the type of the placement algorithm and assesses their capabilities and objectives. Moreover, the properties, advantages and limitations of the VM placement schemes are compared. Finally, the concluding remarks and future research directions are provided.	cloud computing;virtual machine	Mohammad Masdari;Sayyid Shahab Nabavi;Vafa Ahmadi	2016	J. Network and Computer Applications	10.1016/j.jnca.2016.01.011	embedded system;real-time computing;electrical efficiency;computer science;human migration;virtual machine;operating system;placement	HPC	-25.968618193732002	66.0525529391043	9172
76ff4470b81fbd6f32573b20c40e3eeea7027c82	public key cryptosystems based on free partially commutative monoids and groups	public key cryptography;desciframiento;morphisme;morfismo;free monoid;cryptographie cle publique;finitely presented group;encryption;thue system;problema np duro;word problem;decryptage;cifrado;public key cryptosystem;np hard problem;cryptage;probleme np difficile;grupo libre;protocole zero connaissance;decryption;groupe libre;monoide libre;zero knowledge protocol;systeme thue;decidibilidad;morphism;free group;decidabilite;zero knowledge;decidability	A public key cryptosystem based on free partially commutative monoids is constructed. The encryption of a message to create the cryptotext uses a Thue system which is formed from the free partially commutative monoid with the help of a trapdoor morphism. The decidability of the word problem for free partially commutative monoids can be used for decryption. Finding the trapdoor morphism of this system is shown to be NP-hard. But, a zero - knowledge protocol to convince a verifier that there is such a trapdoor morphism is provided. A related but different public key cryptosystem based on free partially commutative groups is also proposed.	cryptosystem;public-key cryptography	P. J. Abisha;D. Gnanaraj Thomas;K. G. Subramanian	2003		10.1007/978-3-540-24582-7_16	decidability;free monoid;word problem;discrete mathematics;computer science;np-hard;free group;mathematics;monoid;public-key cryptography;encryption;algorithm;zero-knowledge proof;morphism;algebra	Crypto	-42.464278524105744	77.92543989253873	9275
fca4c9b929d7bbf330d0e71331c1aad5421f1c9e	utilizing bloom filters for detecting flooding attacks against sip based services	voice over ip voip;service provider;bloom filter;experimental test bed;session initiation protocol;service utilization;voice over ip;internet architecture;flooding attacks;design and implementation;denial of service;session initiation protocol sip;security	Any application or service utilizing the Internet is exposed to both general Internet attacks and other specific ones. Most of the times the latter are exploiting a vulnerability or misconfiguration in the provided service and/or in the utilized protocol itself. Consequently, the employment of critical services, like Voice over IP (VoIP) services, over the Internet is vulnerable to such attacks and, on top of that, they offer a field for new attacks or variations of existing ones. Among the various threats–attacks that a service provider should consider are the flooding attacks, at the signaling level, which are very similar to those against TCP servers but have emerged at the application level of the Internet architecture. This paper examines flooding attacks against VoIP architectures that employ the Session Initiation Protocol (SIP) as their signaling protocol. The focus is on the design and implementation of the appropriate detection method. Specifically, a bloom filter based monitor is presented and a new metric, named session distance, is introduced in order to provide an effective protection scheme against flooding attacks. The proposed scheme is evaluated through experimental test bed architecture under different scenarios. The results of the evaluation demonstrate that the required time to detect such an attack is negligible and also that the number of false alarms is close to zero. a 2009 Elsevier Ltd. All rights reserved.	bloom filter;internet;sensor;signaling protocol;testbed;the times;vulnerability (computing)	Dimitris Geneiatakis;Nikos Vrakas;Costas Lambrinoudakis	2009	Computers & Security	10.1016/j.cose.2009.04.007	service provider;sip trunking;computer science;information security;bloom filter;voice over ip;session initiation protocol;internet privacy;computer security;denial-of-service attack;computer network	Security	-58.302359745325816	68.19081330734984	9309
1837b5dec1f5bb0b068d1282812d7d709783c431	adaptive management of qos requirements for wireless multimedia communications	multimedia;wireless;case base reasoning;real time;audio video;web agent;adaptive;adaptive management;multimedia communication;application sharing;quality of service management;quality of service;management;article;feedback control	We present a control model, which provides response time and bandwidth requirement adaptation in audio, video, and application sharing multipoint IP teleconferences for emerging wireless multimedia communications. The model is based on revealing feedback controls for multimedia call preparation and subsequent real time connection control. Case-based reasoning memory is used to associate real time congestion (connection) controls with call preparation controls and user QoS profiles. Web agents are used to capture user and application multimedia call profiles observed at the application layer and transfer them into the case memory. RTP statistics are used to identify the connection management feedback controls for the network layer. Real-time adaptation at the network layer and above is made possible by using hierarchical coding techniques. The proposed adaptive management architecture is illustrated by a case memory representation of call preparation feedback controls, RTP feedback control tests for providing audio stream bandwidth adaptation, and configuration of integrated experiments.	quality of service	Alexander B. Bordetsky;Kevin Q. Brown;Leann Christianson	2003	Information Technology and Management	10.1023/A:1021872332173	real-time computing;quality of service;computer science;adaptive behavior;feedback;database;multimedia;management;world wide web;wireless;computer network	Embedded	-5.325071265595821	98.28000733256238	9310
ea6b73447b165ec992041c472b168b7c75a408d2	side-channel assisted malware classifier with gradient descent correction for embedded platforms			gradient descent;malware	Manaar Alam;Debdeep Mukhopadhyay;Sai Praveen Kadiyala;Siew Kei Lam;Thambipillai Srikanthan	2018				ML	-49.81058468390093	62.591026407129725	9317
7d76a49af25b8645aba8ebb037b028d8f061cecb	fine-grained sharing of encrypted sensor data over cloud storage with key aggregation		We consider a sensor network setting in which the sensed samples are encrypted individually using different keys before being streamed to a cloud storage. For large systems with high capacity, e.g. generating several millions of samples per day, fine-grained sharing of encrypted samples is challenging. The straightforward solution is to send to a user all decryption keys of each and every shared samples. This approach does not scale up, for the number of keys to be shared would overwhelm the data owner’s network resources. Existing solutions, such as Attribute-Based Encryption (ABE) and Key Aggregation Cryptosystem (KAC), can aggregate a number of keys into a single key of small size, addressing the problem to a certain extent. However, ABE generally incurs large overhead in ciphertext size, while KAC requires quadratic reconstruction time with respect to the number of keys to be reconstructed. These limitations render them impractical in our applications. In this paper, we first present an algorithmic enhancement for KAC that reduces its reconstruction time for the combination of range and down-sampling queries from quadratic to linear. Further, we generalize such enhancement and discuss various heuristics to boost the reconstruction time for arbitrary (general) queries. We also give a clustering-based method to trade-off the reconstruction time with the number of aggregated keys to be issued. These improvements address the main hurdle in adopting KAC for practical applications with large datasets. Our experimental studies show that given the query asking for 2 keys, the proposed enhancement outperforms the original KAC by at least 90 times on range and down-sampling queries, and achieves 8 times speed up for general queries. It also shows that splitting the query into 16 sub-queries, each of which is associated with a separate aggregated key, can further reduce the reconstruction cost by 19 times.	aggregate data;attribute-based encryption;ciphertext;cloud storage;cluster analysis;cryptography;cryptosystem;heuristic (computer science);overhead (computing);sampling (signal processing);scalability;speedup;streaming media	Hung Dang	2015	IACR Cryptology ePrint Archive		cloud storage;encryption;internet privacy;computer science	Security	-39.578025072217166	66.62375552811206	9326
6c60edaa919c7a238345f866d7e20bee2897fb6c	the evolution of network configuration: a tale of two campuses	language understanding;longitudinal analysis;network evolution;version control system;network configuration	Studying network configuration evolution can improve our understanding of the evolving complexity of networks and can be helpful in making network configuration less error-prone. Unfortunately, the nature of changes that operators make to network configuration is poorly understood. Towards improving our understanding, we examine and analyze five years of router, switch, and firewall configurations from two large campus networks using the logs from version control systems used to store the configurations. We study how network configuration is distributed across different network operations tasks and how the configuration for each task evolves over time, for different types of devices and for different locations in the network. To understand the trends of how configuration evolves over time, we study the extent to which configuration for various tasks are added, modified, or deleted. We also study whether certain devices experience configuration changes more frequently than others, as well as whether configuration changes tend to focus on specific portions of the configuration (or on specific tasks). We also investigate when network operators make configuration changes of various types. Our results concerning configuration changes can help the designers of configuration languages understand which aspects of configuration might be more automated or tested more rigorously and may ultimately help improve configuration languages.	cognitive dimensions of notations;control system;firewall (computing);router (computing);version control	Hyojoon Kim;Theophilus Benson;Aditya Akella;Nick Feamster	2011		10.1145/2068816.2068863	simulation;computer science;revision control;systems engineering;artificial intelligence;operating system;distributed computing	Metrics	-16.854893250123563	79.12472566097925	9331
ea2194e8ae53e4b0d7f5b12c5c84879adc408ae1	cryptanalysis of rsa with private key d less than n0.292	public key cryptography;public key cryptosystem;telecommunication security public key cryptography;telecommunication security;wiener attack insecure system private key cryptanalysis private exponent rsa public key cryptosystem rsa system	We show that if the private exponent d used in the RSA (Rivest-Shamir-Adleman (1978)) public-key cryptosystem is less than N/sup 0.292/ then the system is insecure. This is the first improvement over an old result of Wiener (1990) showing that when d is less than N/sup 0.25/ the RSA system is insecure. We hope our approach can be used to eventually improve the bound to d less than N/sup 0.5/.	cryptanalysis;public-key cryptography	Dan Boneh;Glenn Durfee	2000	IEEE Trans. Information Theory	10.1109/18.850673	computer science;pkcs #1;threshold cryptosystem;cryptosystem;internet privacy;public-key cryptography;computer security;computer network	Crypto	-42.098845647918424	76.70448076950065	9372
5b4d44669dd1a1da63ba817304e25f6b6a1f5f39	on the interplay between rpl and address autoconfiguration protocols in llns	routing protocols;formal specification;route aggregation rpl address autoconfiguration protocol lln low power and lossy network internet of things iot interoperability ip network standard specification embedded device ietf standard ipv6 routing network address assignment contiki operating system t daap lisaa addressing scheme t daap addressing scheme daam addressing scheme tree based network topology route aggregation address hierarchy;routing routing protocols network topology monitoring resource management internet;emulation internet of things lln hierarchical addressing ietf roll rpl ipv6 contiki os;trees mathematics;internet of things;embedded systems;internet;trees mathematics embedded systems formal specification internet internet of things ip networks open systems operating systems computers routing protocols telecommunication network topology;ip networks;telecommunication network topology;open systems;operating systems computers	Low-Power and Lossy Networks (LLNs) are an enabling technology for many Internet of Things (IoT) applications. To allow LLNs to interoperate with the Internet the IETF is specifying IP-compatible standards that are specifically designed for embedded devices with small memory and limited computing capabilities. The purpose of this paper is to investigate the interplay between the recently proposed IETF standard for IPv6 routing in LLNs, called RPL, with state-of-the-art autoconfiguration algorithms that assign network addresses in a hierarchical manner. To this end, we have extended the default RPL implementation available in Contiki operating system to support T-DAAP, LISAA and DAAM addressing schemes. Our experimental results clearly show that the mechanisms used by RPL to configure and maintain a tree-based network topology frequently break address hierarchy, limiting the opportunities for route aggregation. Furthermore, classical techniques used to reduce network instability significantly increase the network set-up times and, in same cases, degrade path qualities.	algorithm;auto-configuration;contiki;digital audio access protocol;embedded system;experiment;instability;internet of things;interoperability;lossy compression;low-power broadcasting;network switch;network topology;operating system;routing;supernetwork	Emilio Ancillotti;Raffaele Bruno;Marco Conti	2013	2013 9th International Wireless Communications and Mobile Computing Conference (IWCMC)	10.1109/IWCMC.2013.6583740	the internet;hierarchical routing;computer science;operating system;formal specification;distributed computing;routing protocol;open system;computer security;internet of things;computer network	Mobile	-9.356789900835834	81.82529658640172	9418
dcf2c6b0b278118193214ffab8fc30814bfa2761	a dot net framework based physical testbed for ad hoc network routing protocols	windows mobile 5 0;ad hoc network routing protocols;routing protocols;routing protocols ad hoc networks personal digital assistants mobile communication xml;windows mobile 5 devices;wireless devices;aodv based implementation;personal digital assistant;routing protocols mobile ad hoc networks;dot net;net framework;ad hoc network;ad hoc network routing;personal digital assistants;dot net framework;mobile ad hoc networks;mobile ad hoc routing protocols;laptops;mobile communication;xml;ad hoc networks;ad hoc routing protocol;routing protocol;windows mobile 5 devices dot net framework physical testbed ad hoc network routing protocols mobile ad hoc routing protocols osi model aodv based implementation laptops;ad hoc routing;osi model;physical testbed;ad hoc networks dot net ad hoc routing protocol windows mobile 5 0	This paper proposes a novel physical implementation model for mobile ad hoc routing protocols, in the form of a Dot Net framework based testbed architecture, which follows the OSI model and is extensible enough to support different protocols at each layer. Our architecture can be used to deploy and test ad hoc routing protocols on real wireless devices such as Laptops, PDAs, or any other device supporting the Dot Net framework. An AODV-based implementation of this architecture is provided and validated through experiments using Laptops and Windows Mobile 5 devices.	.net framework;application programming interface;connection-oriented communication;experiment;file transfer;hoc (programming language);laptop;microsoft windows;osi model;personal digital assistant;routing;scalability;tora - toolkit for oracle;testbed;windows mobile	Sanjay Kumar Dhurandher;Isaac Woungang;Ishan Uppal;Hitesh Bhanushali;Deepank Gupta	2011	2011 24th Canadian Conference on Electrical and Computer Engineering(CCECE)	10.1109/CCECE.2011.6030444	vehicular ad hoc network;wireless routing protocol;wireless ad hoc network;optimized link state routing protocol;adaptive quality of service multi-hop routing;mobile ad hoc network;computer science;dynamic source routing;ad hoc wireless distribution service;geocast;distributed computing;routing protocol;link-state routing protocol;computer security;computer network	Mobile	-18.05967596515904	88.8695304539992	9433
51c46656070e1efea821451ea2ff7715fcadad37	extensible messaging and presence protocol (xmpp): core		"""The Extensible Messaging and Presence Protocol (XMPP) is an#N#application profile of the Extensible Markup Language (XML) that#N#enables the near-real-time exchange of structured yet extensible data#N#between any two or more network entities. This document defines#N#XMPP's core protocol methods: setup and teardown of XML streams,#N#channel encryption, authentication, error handling, and communication#N#primitives for messaging, network availability (""""presence""""), and#N#request-response interactions. This document obsoletes RFC 3920.#N#[STANDARDS-TRACK]"""		Peter Saint-Andre	2004	RFC	10.17487/RFC3920	bosh;computer science;operating system;database;world wide web	Crypto	-25.588543824531328	87.53661013615668	9435
7b3412c951cebe71cd2cddac5fda164fb2138a44	circumventing ip-address pseudonymization		This paper presents an attack that circumvents anonymization of IP addresses in IP network traffic data in O(n) time, or O(n) time under certain circumstances. The attack is based on packet injection, and circumvents all anonymization techniques that assign a static and unique pseudonym to an IP address. It turns out that the packet injection itself, as well as the extraction of the corresponding anonymized header data, are the most time-consuming steps.	data anonymization;network packet;network traffic control;packet switching;quality of service;traffic analysis	Tønnes Brekne;André Årnes	2005			pseudonymization;computer network;computer science	Metrics	-57.88708769393546	69.01190384558744	9444
76ee6c3fc69b31f309de6f7112277d122a310636	a fast pattern-match engine for network processor-based network intrusion detection system	national security;engineering design;parallel pattern matching;nids multipattern matching algorithm performance pattern match engine network processor based network intrusion detection system network security packet string matching signature collection signature based nids fnp sup 2 pattern matching engine parallel pattern matching hashing engine snort signatures memory accesses searching patterns shortest pattern length;searching patterns;search engines;network security;storage management;network processor;buffer storage;intrusion detection;shortest pattern length;signature collection;computer networks;computer security;memory access;telecommunication security message authentication computer networks string matching cryptography storage management;engines;pattern matching;cryptography;memory accesses;fnp 2 pattern matching engine;telecommunication security;network processor based network intrusion detection system;pattern match engine;algorithms;optimization;packet string matching;message authentication;nids multipattern matching algorithm performance;signature based nids;computer hardware;computer science;string matching;network intrusion detection system;security of data;engines intrusion detection pattern matching hardware delay automation computer science communication system security computer security national security;snort signatures;hashing engine;problem solving;communication system security;hardware;automation	Network intrusion detection systems (NIDS) are one of the latest developments in security. The matching of packet strings against collected signatures dominates signature-based NIDS performance. This work presents FNP/sup 2/, an efficient pattern-matching engine designed for Network Processor platform which conducts matching sets of patterns in parallel. This work shows that combining our string matching methodology, hashing engine supported by most network processors, and characteristics of current Snort signatures frequently improves performance and reduces number of memory accesses compared to current NIDS pattern matching algorithms. Another contribution is to highlight that, besides total number of searching patterns, shortest pattern length is also a major influence on NIDS multi-pattern matching algorithm performance.	antivirus software;central processing unit;fnp (complexity);intrusion detection system;most bus;network packet;network processor;pattern matching;snort;string searching algorithm	Rong-Tai Liu;Nen-Fu Huang;Chia-Nan Kao;Chih-Hao Chen;Chi-Chieh Chou	2004	International Conference on Information Technology: Coding and Computing, 2004. Proceedings. ITCC 2004.	10.1109/ITCC.2004.1286432	real-time computing;computer science;theoretical computer science;distributed computing	HPC	-7.42115779150683	67.01169244005234	9449
92bac8acadb20a1af52801cf16f9f968eb154842	a secure deniable authentication protocol based on bilinear diffie-hellman algorithm		This paper describes a new deniable authentication protocol whose security is based Diffe-Hellman (CDH) Problem of type Decisional Diffie-Hellman(DDH) and the Hash Diffie-Hellman (HDDH) problem.This protocol can be implemented in low power and small processor mobile devices such as smart card, PDA etc which work in low power and small processor. A deniable authentication protocol enables a receiver to identify the true source of a given message, but not to prove the identity of the sender to a third party. This property is very useful for providing secure negotiation over the internet. Our proposed protocol will be achieving the most three security requirement like deniable authentication, Confidentialities and also it is resistant against Man-in middle Attack.	algorithm;authentication protocol;bilinear transform;computational diffie–hellman assumption;decisional diffie–hellman assumption;deniable authentication;diffie–hellman key exchange;diffie–hellman problem;man-in-the-middle attack;mobile device;personal digital assistant;smart card	Jayaprakash Kar;Banshidhar Majhi	2010	IACR Cryptology ePrint Archive		computer science;deniable encryption;authentication protocol;internet privacy;computer security;challenge-handshake authentication protocol;computer network	Security	-45.24275208036846	73.5228503618851	9478
67dc8c9259cf6e6711c12638db0946333e4db26b	streaming of continuous media for distance education systems	distance education;online searching;search engines;information retrieval;continuous media;multimedia materials;computer system design;information storage;foreign countries;streaming media;cm;scheduling;information processing;sm;search strategies;computer software evaluation;programming;delivery systems	Distance education created new challenges regarding the delivery of large size isochronous continuous streaming media (SM) objects. In this paper, we consider the design of a framework for customized SM presentations, where each presentation consists of a number of SM objects that should be retrieved and displayed to the user in a coherent fashion. We describe a retrieval optimizer (Prime) that captures the flexibilities and requirements imposed by the user query, user profile, and session profile. Then, it determines how this query script should be imposed against the continuous media (CM) server to reduce contention. We also provide a cost model to evaluate each proposed plan. Finally, we explain the role of memory buffering in alleviating the server bandwidth fragmentation problem. Our preliminary experimental results show the feasibility and effectiveness of our proposed model and techniques in generating near optimal retrieval.	analysis of algorithms;coherence (physics);fragmentation (computing);mathematical optimization;requirement;server (computing);streaming media;user profile	Ali Dashti;Maytham Safar	2007	IJDET	10.4018/jdet.2007070104	distance education;programming;information processing;computer science;theoretical computer science;centimeter;multimedia;scheduling;world wide web	DB	-15.372017779990479	70.87751390442516	9485
88d67a33b180649f252823bdc015cde68f0be1a9	enhancing the performance of metadata service for cloud computing	look up table;random access memory;cloud computing master metadata server metadata look up table dynamic hash lazy hybrid;metadata management;resource allocation;servers heart beat file systems random access memory cloud computing hardware table lookup;client server systems;metadata look up table server;dynamic hash;hot spot;telecommunication traffic;servers;internet;network traffic metadata service cloud computing metadata management distributed file system master metadata server metadata look up table server load balancing;lazy hybrid;metadata look up table;network traffic;distributed databases;load balancing;distributed file system;meta data;master metadata server;load balance;table lookup;metadata service;telecommunication traffic client server systems distributed databases internet meta data resource allocation table lookup;file systems;heart beat;cloud computing;hardware	Efficient metadata management is critical for distributed file system in cloud computing. In this paper we propose a new metadata management scheme which employs master metadata server (MMDS) and metadata look-up table server between the metadata servers and clients. The MMDS checks the state of MDSs for load-balancing, and thereby avoids hot spot. The proposed scheme significantly reduces the network traffic as well.	cloud computing;clustered file system;dce distributed file system;load balancing (computing);lookup table;molecular dynamics;multichannel multipoint distribution service;network packet;petabyte;server (computing)	Myung Jin Hwang;Dae-Gun Kim;Hee Yong Youn	2010	2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2010.188	computer science;load balancing;operating system;database;world wide web;distributed database;data element;meta data services;metadata repository	HPC	-17.805414553392968	68.60996577176391	9496
d45e82c4431b6af4a9b2db871fc06b1dafdc5e99	a framework for mobile handset detection	user agent;mobile;wurfl;handset detection;framework	Due to the increase in social media and mobile media in general, access to these platforms from a number of different mobile devices must be catered for. Mobile Device Detection (MDD) refers to software that identifies the type of mobile device visiting the mobile web and either redirects the end user to a dedicated mobile web site or adapts the rendered output from a web server to best suit the capabilities of the end user's mobile device. Furthermore, handset credentials are, in some cases, used for the purpose of correctly identifying the mobile operating system, which in turn is used to redirect to a mobile application download. In any web server request, identification of the user is transmitted in a header field known as the User-Agent (UA). Identifiable information present in the request header allows for unique browser identification and the device used in making the request for a web page. A lookup table, comprising of the all known handset capabilities, is the core functionality of a MDD. Our aim in this paper is to survey the distribution of mobile User-Agents so as to establish an attribution of mobile browsing detections. In particular, assessing details of mobile User-Agents, proxy requests (intermediary for requests from users seeking resources from other servers), emulated requests (software program that imitates a real handset), perpetuates our ability to census mobile traffic with some degree of accuracy. The approach is to make use of a sample set of realworld mobile aggregated requests. We will analyze and filter these requests by origin, User-Agent, geo-location and sometimes non-industry standard (inserted by mobile network operators, which might contain personally identifiable information) to build our mobile browsing framework. In doing so, we encompass description, identification, nomenclature, and classification of end user mobile handset detections. Finally, we will investigate the significance of our framework to see how unique requests are given nothing other than identifiable browser information.	categorization;computer program;credential;download;emulator;geolocation;lookup table;mobile app;mobile device;mobile media;mobile operating system;mobile phone;model-driven engineering;personally identifiable information;sensor;server (computing);social media;technical standard;user agent;web page;web server	Neil Croft	2016			mobile station	Mobile	-54.0457348449284	61.14215326499	9499
32edd3e08bc95051063071bcfe077980c99f35cb	patient-centric authorization framework for electronic healthcare services	policy composition;electronic health records ehrs;continuity of care;patient centric authorization;electronic health record;privacy protection;access control policy;data aggregation;access control;policy anomaly analysis;point of care;selective sharing	In modern healthcare environments, a fundamental requirement for achieving continuity of care is the seamless access to distributed patient health records in an integrated and unified manner, directly at the point of care. However, Electronic Health Records (EHRs) contain a significant amount of sensitive information, and allowing data to be accessible at many different sources increases concerns related to patient privacy and data theft. Access control solutions must guarantee that only authorized users have access to such critical records for legitimate purposes, and access control policies from distributed EHR sources must be accurately reflected and enforced accordingly in the integrated EHRs. In this paper, we propose a unified access control scheme that supports patient-centric selective sharing of virtual composite EHRs using different levels of granularity, accommodating data aggregation and privacy protection requirements. We also articulate and address issues and mechanisms on policy anomalies that occur in the composition of discrete access control policies from different data sources. a 2010 Elsevier Ltd. All rights reserved.	access control;authorization;data aggregation;data theft;information sensitivity;medical privacy;requirement;scott continuity;seamless3d	Jing Jin;Gail-Joon Ahn;Hongxin Hu;Michael J. Covington;Xinwen Zhang	2011	Computers & Security	10.1016/j.cose.2010.09.001	data aggregator;point of care;computer access control;computer science;access control;data mining;internet privacy;computer security	Security	-44.34079676821914	62.09485311056614	9514
6677a354be4a0052d5e9c68b282872483517f7b7	sla-based energy aware scheduling of precedence-constrained applications on dvfs-enabled clusters	dynamic voltage frequency scaling;randomly generated graphs sla based energy aware scheduling algorithm high performance clusters energy consumption reduction dynamic voltage frequency scaling precedence constrained applications service level agreement dvfs enabled cluster systems makespan extension easla algorithm scale frequencies energy consumption minimization total energy reduction;energy aware scheduling;cluster computing;dag;workstation clusters energy consumption graph theory power aware computing;service level agreement cluster computing dynamic voltage frequency scaling dag energy aware scheduling;energy consumption scheduling computational modeling schedules algorithm design and analysis radio spectrum management processor scheduling;service level agreement	The energy aware scheduling problem has been a critical issue in high-performance clusters owing to their high operation cost, environmental impact, and low reliability. An existing technique to reduce energy consumption of applications is dynamic voltage/frequency scaling (DVFS). In this paper, we develop an energy aware scheduling algorithm called EASLA for precedence-constrained applications in the context of Service Level Agreement (SLA) on DVFS-enabled cluster systems. Due to the dependencies among tasks and makespan extension, there may be some slacks under used. The main idea of the EASLA algorithm is to distribute each slack to a set of tasks and scale frequencies down to try to minimize energy consumption. Specifically, it first finds the maximum set of independent tasks for each task, and then iteratively allocates each slack to the maximum independent set whose total energy reduction is the maximal. Randomly generated graphs and two real-world applications are tested in our experiments. The experimental results show that our scheduling algorithm can save up to 22.68% and 12.01% energy consumption compared with GreedyDVS and EvenlyDVS algorithms, respectively.	algorithm;clustered file system;digital signal processor;dynamic voltage scaling;experiment;frequency scaling;gaussian elimination;image scaling;independent set (graph theory);makespan;maximal set;sonar (symantec);scheduling (computing);service-level agreement;slack variable;supercomputer	Xuedi Chen;Keqin Li;Chubo Liu;Keqin Li	2014	2014 20th IEEE International Conference on Parallel and Distributed Systems (ICPADS)	10.1109/PADSW.2014.7097826	fair-share scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer cluster;computer science;operating system;distributed computing;least slack time scheduling	EDA	-15.469109205138167	61.86213899410241	9517
6d63bf9b835a2bd403d5dbe44443b303cad9ad90	optical routing of asynchronous, variable length packets	buffer storage;packet switching;buffer storage telecommunication network routing scheduling computational complexity synchronisation optical fibre networks packet switching internet sonet;synchronisation;optical fibre networks;scheduling algorithm;internet;telecommunication network routing;computational complexity;scheduling;buffer dimensioning optical routing asynchronous variable length packets optical ip routers scheduling algorithm void filling complexity optical synchronization packets over sonet ip centric scenario self similar traffic conditions optical buffering;routing optical packet switching optical buffering optical sensors optical switches wavelength division multiplexing bandwidth hardware delay lines scheduling algorithm;self similar traffic;sonet	We discuss the introduction/implementation of optical IP routers, then we introduce a novel scheduling algorithm incorporating void filling and aimed at optical routing of asynchronous, variable packet length packets. We describe its structure and discuss the complexity issues. Albeit introduced with the purpose of cancelling expensive optical synchronization, we argue that this approach represents the most viable all-optical approach for implementing packets-over-SONET (IP-centric scenario). We also present simulations under self-similar traffic conditions which point to the inefficiency of optical buffering to combat the effects of self-similarity, and we outline alternative strategies for proper buffer dimensioning.	algorithm;network packet;routing;scheduling (computing);self-similarity;simulation;synchronous optical networking	Ljubisa Tancevski;S. Yegnanarayanan;Gerardo A. Castañón;Lakshman Tamil;Francesco Masetti-Placci;Tom McDermott	2000	IEEE Journal on Selected Areas in Communications	10.1109/49.887927	optical transport network;routing;real-time computing;optical burst switching;multiwavelength optical networking;telecommunications;computer science;operating system;optical ip switching;distributed computing;scheduling;optical performance monitoring;computer network	Networks	-5.491219750563963	85.17051871784616	9519
4a00e0233a14f744fb9278e08aff82c398ec1b93	towards an optimized energy consumption of resources in cloud data centers		Over the last few years, cloud computing has become a prominent paradigm. It promises to offer to users cost-effective and on-demand decentralized services, in terms of computing, memory, storage, etc., without the need for large infrastructure investments. Moreover, with the growing number of data centers resources, much higher levels of energy are being consumed. Also, the increasing level of associated carbon dioxide is emitted in the air, which consequently, raises the costs. Considering that there is an extreme growth in demand for Data Centers cloud computing requiring high computational complexity, there is an utmost need to take sufficient measures to lower the risk of energy demand. Hence, efficient energy-aware techniques are required to assure proper performance with regards to Service Level Agreements (SLA). In this work, we highlighted the issue of Virtual Machines (VMs) allocation in cloud computing data centers, and how to better manage the placement of VMs in order to optimize performance and reduce energy consumption. In our proposed solution, we will focus on minimizing the number of Physical Machines (PMs) hosting the VMs and utilize them as sufficient as possible.		Sara Diouani;Hicham Medromi	2018		10.1007/978-3-030-02849-7_16	virtualization;computational complexity theory;energy consumption;data center;virtual machine;cloud computing;resource allocation;distributed computing;service level;computer science	HPC	-20.97340421374263	62.72849056179345	9590
615358e3da6b5a6bd3d85833c0627c7496ec44dc	turning the tables: using wireless communication against an attacker	wireless sensor network;wireless communication	  In this paper, we propose a system leveraging the peculiarities of the wireless medium, such as the broadcast nature of wireless  communication and the unpredictability of indoor signal propagation to achieve effective protection against attacks based  on the injection of fake data in wireless sensor networks (WSNs). Using a real-world WSN deployment and a realistic implementation  of an attacker, we analyze this protection scheme and demonstrate that neither position change, transmission power manipulation,  nor complete knowledge of wireless parameters can help an attacker to successfully attack the network. As a result, this work  demonstrates how the chaotic nature of radio communication, which is often considered a disadvantage in regard to security  objectives, can be exploited to enhance protection and support implementation of lightweight security mechanisms.      		Ivan Martinovic;Jens B. Schmitt	2009		10.1007/978-3-540-92666-5_17	wi-fi;wireless wan;wireless sensor network;heterogeneous network;wireless site survey;computer science;wireless network;distributed computing;wireless distribution system;wireless lan controller;key distribution in wireless sensor networks;base transceiver station;capwap;wi-fi array;rogue access point;fixed wireless;ant;computer security;wireless;computer network	Mobile	-52.704630987510846	74.75283483019102	9628
ec0e21287cc9308f90c7f76c0ab55a7173cee8f9	exploiting regularities in web traffic patterns for cache replacement	politica optima;regularite;web pages;red www;regularidad;fonction repartition;regularity;reseau web;serveur informatique;proxy caching;optimal policy;funcion distribucion;distribution function;operating system;cache replacement;distribution temporelle;caching web page;servidor informatico;world wide web;experimental evaluation;politique optimale;web caching;proxy server;distribucion temporal;computer server;time distribution;replacement policy	Abstract. Caching web pages at proxies and in web servers' memories can greatly enhance performance. Proxy caching is known to reduce network load and both proxy and server caching can significantly decrease latency. Web caching problems have different properties than traditional operating systems caching, and cache replacement can benefit by recognizing and exploiting these differences. We address two aspects of the predictability of traffic patterns: the overall load experienced by large proxy and web servers, and the distinct access patterns of individual pages. We formalize the notion of ``cache load'' under various replacement policies, including LRU and LFU, and demonstrate that the trace of a large proxy server exhibits regular load. Predictable load allows for improved design, analysis, and experimental evaluation of replacement policies. We provide a simple and (near) optimal replacement policy when each page request has an associated distribution function on the next request time of the page. Without the predictable load assumption, no such online policy is possible and it is known that even obtaining an offline optimum is hard. For experiments, predictable load enables comparing and evaluating cache replacement policies using partial traces , containing requests made to only a subset of the pages. Our results are based on considering a simpler caching model which we call the interval caching model . We relate traditional and interval caching policies under predictable load, and derive (near)-optimal replacement policies from their optimal interval caching counterparts.	cache (computing);experiment;interval arithmetic;least frequently used;online and offline;operating system;proxy server;server (computing);tracing (software);web cache;web page;web server;web traffic	Edith Cohen;Haim Kaplan	2002	Algorithmica	10.1007/s00453-001-0121-8	real-time computing;cache stampede;false sharing;cache;computer science;distribution function;web page;database;smart cache;world wide web;server	Theory	-17.232639868346887	70.95884227699811	9637
e7f8c3f8bef3617fe9977c8adde4a1b16d6add8f	on the security of a unified countermeasure	elliptic curves security elliptic curve cryptography cryptography equations computational modeling book reviews;elliptic curves;elliptic curve;elliptic curve implementations;differential power attacks;countermeasures elliptic curve cryptography fault attacks differential power attacks;computational modeling;elliptic curve cryptography;implementation attacks;cryptography;fault attack;fault coverage;book reviews;countermeasures;security;cryptographic applications;unified countermeasure security;fault coverage unified countermeasure security implementation attacks cryptographic applications elliptic curve implementations differential power attacks;fault attacks	Implementation attacks are a major threat for cryptographic applications. Recently, Baek and Vasyltsov (ISPEC 2007) proposed a unified countermeasure for protecting elliptic curve implementations against a variety of implementation attacks, including differential power attacks and fault attacks. This paper studies the security of this countermeasure. In particular, it shows that the fault coverage is less than what was anticipated. Further security weaknesses are also pointed out.	cryptography;differential fault analysis;fault coverage	Marc Joye	2008	2008 5th Workshop on Fault Diagnosis and Tolerance in Cryptography	10.1109/FDTC.2008.8	countermeasure;theoretical computer science;mathematics;distributed computing;computer security	Security	-40.99200594412497	81.81997198800437	9659
e6f3eaaa551c17247b72239d3466205efd7cfc56	fast accumulated hashing	pseudorandom sequence;cumulant	"""1 I n t r o d u c t i o n The management of a cryptographic security system involves creating, timestamping, maintaining and updating of a diversity of security related lists. Typical examples are public key directories and lists for certificate revocation, system configuration, access control and software integrity. The existing solutions are based on the use of digital signatures of a trusted third party. In 1993 J. Benaloh and M. de Mare presented an alternative to digital signatures by introducing the principle of accumulated hashing [1]. In accumulated hashing the items are hashed together to a hash code in such a way that afterwards it is possible, for each item separately, to prove its membership in the accumulation. Benaloh and de Mare also proposed a concrete design for an accumulator based on a commutat ive t rapdoor one-way function. But the trusted third par ty was still needed, although off-line, to provide the t rapdoor function. A further analysis of the requirements and the definition of accumulator was performed by K. Nyberg in [2]. Instead of commutat ive functions an equivalent algebraic setting for accumulators in terms of commutat ive semigroups was introduced. Also a construction for a new accumulator was presented. This accumulator is """" absolute"""" in the sense that it is provably secure and not based on a t rapdoor known to some third party. Consequently, it offers a fully decentralized alternative to digital signatures. The purpose of this contribution is to improve the accumulator given in [2] and make it more efficient while preserving the good properties of the previous construction. The new accumulator has fast implementations using certain modes of operation of existing algorithms for hashing and pseudorandom sequence generation. The requirement for secure memory is less than what is needed to store an itemized list of digital signatures."""	access control;accumulator (computing);algorithm;antivirus software;block cipher mode of operation;certificate authority;cryptographic hash function;digital signature;kaisa nyberg;linear algebra;memory protection;one-way function;online and offline;provable security;pseudorandom number generator;pseudorandomness;public-key cryptography;requirement;system configuration;tree accumulation;trusted third party;type signature	Kaisa Nyberg	1996		10.1007/3-540-60865-6_45	pseudorandom binary sequence	Crypto	-41.09964394773969	76.29699058460324	9669
39060249448ee444d4535bfa33e6a8f03b253d13	improving the efficiency of direct-memory-access output operations	direct memory access;input output;buffer	The improvements in throughput expected from direct-memory-scum ch.nnclr arc not r e M with simple input/output routines. For output operadona, the improvements cnn be realized through the provision of a separate data butter area in memory that may be accessed by the peripheral while the primary bder area ia being manipulated by the program. The method may be extended to peripherals that require error checking after output.	direct memory access;input/output;peripheral;throughput	Charles Erwin Cohn	1973	Softw., Pract. Exper.	10.1002/spe.4380030211	input/output;real-time computing;buffer;computer hardware;computer science;direct memory access	DB	-4.872047161661055	64.0702770422906	9700
6d52cd9919e512df94768d7aeeee8d5b7506f8ca	symmetric-key encryption scheme based on the strong generating sets of permutation groups	encryption tin quality of service indexes equations conferences;message authentication cryptography;authentication method symmetric key encryption scheme generating sets permutation groups computational group theory sims algorithm symmetric block encryption scheme secret key strong generators;cryptography;message authentication	In this article we expose a new field of application of such a classical method of computational group theory as the Sims' algorithm. We introduce a symmetric block encryption scheme based on a secret key which is a table of strong generators of a permutation group. We discuss how the proposed scheme can be adopted to be used as an authentication method.	algorithm;analysis of algorithms;authentication;block cipher;computation;computational complexity theory;computational group theory;computational resource;encryption;key (cryptography);strong generating set;the sims	Ara Alexanyan;Hakob Aslanyan;José D. P. Rolim	2013	2013 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops)	10.1109/PerComW.2013.6529543	multiple encryption;key;disk encryption theory;40-bit encryption;computer science;cryptography;theoretical computer science;symmetric-key algorithm;distributed computing;cryptographic key types;filesystem-level encryption;on-the-fly encryption;deterministic encryption;encryption;probabilistic encryption;three-pass protocol;statistics;56-bit encryption;attribute-based encryption	EDA	-40.41432631561876	76.85889590065868	9751
3f05eaccd26efa4f336ca079dc143980e61d8704	improved fully homomorphic public-key encryption with small ciphertext size.		A cryptosystem which supports both addition and multiplication (thereby preserving the ring structure of the plaintexts) is known as fully homomorphic encryption (FHE) and is very powerful. Using such a scheme, any circuit can be homomorphically evaluated, effectively allowing the construction of programs which may be run on ciphertexts of their inputs to produce a ciphertext of their output. Since such a program never decrypts its input, it can be run by an untrusted party without revealing its inputs and internal state. The existence of an efficient and fully homomorphic cryptosystem would have great practical implications in the outsourcing of private computations, for instance, in the context of cloud computing. In previous work I proposed the fully homomorphic public-key encryption scheme with the size of ciphertext which is not small enough. In this paper the size of ciphertext is one-eighth of the size in the previously proposed scheme. Because proposed scheme adopts the medium text with zero norm, it is immune from the the “p and -p attack”. As the proposed scheme is based on computational difficulty to solve the multivariate algebraic equations of high degree, it is immune from the Gröbner basis attack, the differential attack, rank attack and so on. keywords: fully homomorphic public-key encryption, multivariate algebraic equation, Gröbner basis, non-associative ring	algebraic equation;ciphertext;cloud computing;computation;cryptosystem;differential cryptanalysis;gröbner basis;homomorphic encryption;outsourcing;public-key cryptography	Masahiro Yagisawa	2018	IACR Cryptology ePrint Archive		theoretical computer science;public-key cryptography;ciphertext;homomorphic encryption;computer science	Crypto	-38.50755943717972	76.11533471220525	9754
e729e5349fce398f0df4a08b354b1b25302e88bc	a hybrid rogue access point protection framework for commodity wi-fi networks	software;commodity wi fi networks;detection probability;software tool;centralized wired end socket level traffic fingerprinting;ieee standards;access point;wireless media surveillance;turning;surveillance;network security;protection sockets telecommunication traffic fingerprint recognition software standards surveillance turning mechanical factors hardware resilience;indexing terms;sockets;wireless security;hybrid rogue access point protection framework;mechanical factors;network intrusion detection;wireless communication;open architecture;protection;telecommunication traffic;resilience;monitoring;fingerprint recognition;ieee 802 11 standards;cost effectiveness;software standards;wireless lan;ieee 802 11 standard hybrid rogue access point protection framework commodity wi fi networks wireless media surveillance centralized wired end socket level traffic fingerprinting wi fi network security;ieee 802 11 standard;security;security of data;wireless sensor networks;wireless lan ieee standards security of data;communication system security;hardware;wi fi network security	"""We develop a practical and comprehensive hybrid rogue access point (AP) detection framework for commodity Wi- Fi networks. It is the first scheme that combines the distributed wireless media surveillance and the centralized wired end socket level traffic """"fingerprinting"""" The former is designed not only to detect various types of rogue APs, but also to discover suspicious activities so as to prevent the adversaries from turning victim APs into rogue devices. Moreover, the socket level traffic fingerprinting helps our frame work to achieve a finer granularity on rogue AP detection among the existing schemes. This framework has the following nice properties: i) it requires neither specialized hardware nor modification to existing standards; ii) the proposed mechanism greatly improves the rogue AP detection probability so that network resilience is improved; iii) it provides a cost-effective solution to Wi-Fi network security enhancement by incorporating free but mature software tools; iv) it can protect the network from adversaries capable of using customized equipment and/or violating the IEEE 802.11 standard; v) its open architecture allows extra features to be easily added on in the future. Our analysis and evaluation demonstrate that this hybrid rogue AP protection framework is capable of reliably revealing rogue devices and preempting potential attacks."""	centralized computing;client honeypot;emoticon;fingerprint (computing);html5 in mobile devices;honeypot (computing);network security;open architecture;plug-in (computing);rogue access point;sensor;wireless access point	Liran Ma;Amin Y. Teymorian;Xiuzhen Cheng	2008	IEEE INFOCOM 2008 - The 27th Conference on Computer Communications	10.1109/INFOCOM.2008.178	wireless sensor network;cost-effectiveness analysis;index term;telecommunications;open architecture;computer science;network security;operating system;rogue access point;computer security;fingerprint recognition;wireless;computer network	Mobile	-58.18563761850111	66.8692911470356	9794
5452cc288c4220084d0b581eff1ee901e98ecc97	effects of c/u plane separation and bearer aggregation in mobile core network		In response to the growing demand for cellular networks, it is essential to improve the capacity of mobile core networks. Especially, in terms of accommodating machine-to-machine/Internet-of-Things (M2M/IoT) terminals into cellular networks, the load on the control and the user planes of the mobile core network increases massively. To deal with this problem, it is possible to apply virtualization technologies, such as software-defined network and network function virtualization. However, few existing studies evaluate such solutions for mobile core networks numerically and in detail. In this paper, we first evaluate mobile core network architectures with virtualization technologies and control/user (C/U) plane separation using the mathematical analysis. We also propose a novel bearer aggregation method to reduce the control plane load to accommodate massive M2M/IoT terminals. The result of numerical evaluation shows that the capacity of the mobile core network can be increased by up to 32.8% with node virtualization and C/U plane separation, and further by 201.4% by using bearer aggregation. Moreover, to maintain the performance of the mobile core network, we should carefully determine where the bearer aggregation is applied and when the shared bearer for each terminal is determined based on application characteristics and the number of accommodated M2M/IoT terminals.	control plane;machine to machine;multi-core processor;network function virtualization;numerical analysis;software-defined networking;transfer function	Shuya Abe;Go Hasegawa;Masayuki Murata	2018	IEEE Transactions on Network and Service Management	10.1109/TNSM.2018.2797301	virtualization;computer network;network functions virtualization;network architecture;internet of things;mobile computing;core network;cloud computing;distributed computing;computer science;cellular network	Mobile	-13.844932900813433	85.23455887874003	9799
96ffd4b45ee3e5ca33602549b530737b9d51b656	research on anomaly detection algorithm based on generalization latency of telecommunication network		Abstract With the rapid development of Mobile Internet and the 4th Generation mobile communication technology, data service has exceeded voice service, which has also become the important means for mobile operators to promote shares in the communication market. Therefore, the service quality of data service business will directly influence mobile user perception and satisfaction to network. With complicated process networking procedure is long in the data service process and the fundamental reasons of problems are relatively more difficult to position. During voice communication in mobile networks, there are relatively unitary important factors which can accept user perception such as call drop, network congestion and signal interference, etc. However, users’ perception towards data services is somewhat different, which shows strong association with the usage scenarios of the various applications of users. For example, in the data browsing service, if terminal connection fails, the background will start the function of automatic repeated connections, during which, latency is increased, so as to influence user perception of data service latently. Besides, in the video service, initialization delay, stalling during the play and times of stalling are also the factors which could affect video quality. The above analysis shows the latency in the various data service processes and the usual network latency indicators, such as TCP three-way handshake and DNS, etc. gathered and mapped into a total latency, which is the latency perception from the perspective of user experience. In the current work, it is defined as generalization latency, which is also known as the total latency covering latency for users to establish connection on the signaling control plane and latency of user plane. The first innovation of this paper is to establish a mapping model, where, generalization latency, which is from the perspective of user using perception, is related to performance indicators of telecommunication network, under different data service characteristic scenarios, so as to forecast the inflection point of network performance anomaly. The second innovation is to introduce the abnormally detection model for generalization latency, so as to detect the performance stability of the application layer of the application service plane.	algorithm;anomaly detection;telecommunications network	Yan Wang;Zhensen Wu;Yuanjian Zhu;Pei Zhang	2018	Future Generation Comp. Syst.	10.1016/j.future.2018.02.022	latency (engineering);telecommunications network;real-time computing;network congestion;user experience design;computer science;data as a service;video quality;service quality;network performance	Metrics	-11.543506281538741	98.12028596800684	9814
f3733e120e09331a2494e23dc91930225866d5a5	a brief overview of intelligent mobility management for future wireless mobile networks				Ilsun You;Yuh-Shyan Chen;Sherali Zeadally;Fei Song	2017	EURASIP J. Wireless Comm. and Networking	10.1186/s13638-017-0972-6	computer network;computer science;cloud computing;wireless;software-defined networking;mobility management	Mobile	-16.227604731888917	88.57516572903766	9841
9e9d5203776534483968125b6ba7616041737a54	dynamic skewed tree for fast memory integrity verification		Memory authentication techniques often employ an integrity tree as a countermeasure against replay, spoofing and splicing attacks. However, the balanced memory integrity trees used in existing approaches lead to excessive memory access overheads for runtime verification. In this paper, we propose a framework to dynamically construct a customized integrity tree based on the data access patterns to reduce the overhead of runtime verification. The proposed framework can adapt the memory integrity tree structure at runtime such that the nodes that correspond to frequently accessed data are placed closer to the root. We validated the effectiveness of our approach on the Altera NIOS II processor with an external DRAM. Experimental results based on applications from widely used CHStone and SNU Real-Time benchmarks demonstrate that the proposed approach can lead to an average performance gain of 30% compared to the conventional means of using balanced memory integrity trees. In addition, to preserve data confidentiality, we implemented the encryption/decryption operations using custom instructions on the NIOS II processor to notably reduce the overall overhead of memory security.	algorithm;authentication;best, worst and average case;confidentiality;data access;dynamic random-access memory;encryption;memory protection;node (computer science);overhead (computing);real-time clock;replay attack;run time (program lifecycle phase);runtime verification;self-balancing binary search tree;spoofing attack;tree structure	Saru Vig;Guiyuan Jiang;Siew Kei Lam	2018	2018 Design, Automation & Test in Europe Conference & Exhibition (DATE)	10.23919/DATE.2018.8342089	computer science;embedded system;parallel computing;cryptography;tree structure;nios ii;encryption;spoofing attack;data access;runtime verification;authentication	EDA	-36.16742111722553	66.47998138660087	9848
66a9e25b76e8640450270e3038e1f7d5392dbd20	proof of retrieval and ownership protocols for images through spiht compression	protocols;proof of ownership;image coding;encryption;compression algorithms;image encoding proof of retrieval protocols proof of ownership protocols spiht compression algorithm cloud storage provider;merkle hash tree;proof of retrieval;error correcting codes;image compression;merkle hash tree cloud computing image compression spiht compression algorithm proof of retrieval proof of ownership error correcting codes;spiht compression algorithm;protocols image coding image retrieval;image coding protocols cloud computing encryption compression algorithms;cloud computing	In this paper, novel proof of retrieval (POR) and proof of ownership (POW) protocols for images based on the use of the SPIHT compression algorithm are proposed. The POR protocol can be run by the users to ensure that their images are stored securely in the cloud, and the POW protocol can be run by the cloud storage provider (CSP) to authenticate the true owner of the images. The efficiency of our scheme relies on the fact that only a fraction of the compressed data is used for encoding the images. Experimental results are provided to validate the stated goals.	algorithm;authentication;cloud computing;cloud storage;data compression;data deduplication;image compression;set partitioning in hierarchical trees;simulation	Fatema Rashid;Ali Miri;Isaac Woungang	2014	2014 IEEE Intl Conf on High Performance Computing and Communications, 2014 IEEE 6th Intl Symp on Cyberspace Safety and Security, 2014 IEEE 11th Intl Conf on Embedded Software and Syst (HPCC,CSS,ICESS)	10.1109/HPCC.2014.140	data compression;communications protocol;merkle tree;cloud computing;image compression;computer science;theoretical computer science;operating system;data mining;internet privacy;encryption	Embedded	-41.00420909299596	69.23446370825097	9852
8864d12e411068069e68fd1335e04e6d949ec976	software-defined networking in cyber-physical systems: a survey		Cyber-Physical Systems (CPSs) rely on networks that interconnect sensors and actuators to perform measurement, supervision and protection functions in different domains, such as transportation and industrial automation control systems. These networks must be able to support mobile wireless CPSs that are demanding new requirements related to flexibility and heterogeneity without compromising the Quality of Service (QoS). However, it is hard to determine, for example, the optimal resource allocation or the most reliable paths without global network information. In this way, the Software-Defined Networking paradigm is being considered as key to overcome such emerging needs. In particular, an SDN controller is able to establish paths between sensors and actuators according to bandwidth, latency, redundancy, and safety considerations. Thus, the goal of this paper is to review the state of the art of SDN approaches applied to mission-critical applications by identifying trends, challenges and opportunities for the potential development of software-defined cyber-physical networks. © 2017 Elsevier Ltd. All rights reserved.	as-interface;automation;control system;cyber-physical system;global network;mission critical;mobile phone;programming paradigm;quality of service;redundancy (engineering);requirement;sensor;software-defined networking	Elias Molina;Eduardo Jacob	2018	Computers & Electrical Engineering	10.1016/j.compeleceng.2017.05.013		Embedded	-20.14600826032501	80.58066689795932	9871
f6d01e3bac2c14ae5282d1257a816fbe0a2a6647	frame relay and smds services on a common atm-based platform	common atm-based platform;smds service	Abstract The evolution to broadband networking in the world market has started, enabled by the evolution of the transmission infrastructure and new switching techniques. The market is being driven by the high-speed requirements imposed by the unprecedented penetration of LAN technology and associated high-speed applications as well as the integration of voice, data, image and video requirements. The rapid deployment of more reliable, often fiber-based, facilities migrating to the Synchronous Digital Hierarchy (SDH) and the introduction of switching techniques such as Frame Relay and Asynchronous Transfer Mode (ATM) make possible the introduction of networking capabilities to satisfy emerging requirements. Frame Relay services rely on a stream-lined protocol implementation that makes advantage of end-to-end error control strategies to simplify network processing and enable higher throughput and lower delay. Frame Relay services are being targeted at the 64 Kbps to E1 range. The Asynchronous Transfer Mode (ATM) has been accepted as the transport mechanism for the future Broadband Integrated Services Digital Network (B-ISDN). Metropolitan Area Networks (MANs), based on IEEE 802.6 ATM principles, represent the first commercial application of ATM technology. An early MAN service is the Switched Multimegabit Data Service (SMDS) 1 which has been specified to provide efficient high-speed data transport in the E1 to 34 Mbps range with future extensions to incorporate isochronous transport for the addition of constant-bit rate services such as voice and video services. Similar to SMDS, Connectionless Broadband Networking Services (CBDS) are being defined by ETSI for the European Market with input from the European SMDS Interest Group (ESIG). This paper presents an ATM-based architectural approach, as implemented in Atu0026Tu0027s Broadband Networking System 2000 (BNS-2000), to provide Frame Relay as well as SMDS services on the sam platform. The BNS-2000 represents a growable and modular architecture that has been built to comply with international standards such as ANSI, CCITT and ETSI to support the emerging needs of the market.	atm turbo;frame relay	Daniel Martínez	1992	Computer Networks and ISDN Systems	10.1016/0169-7552(92)90027-N	real-time computing;smds;telecommunications;atm adaptation layer;asynchronous transfer mode;computer network;broadband networks	Metrics	-17.075532818918052	92.07875190758017	9902
812a34cc1d94004d582bbd37d29e46e88b510372	benchmarking privacy-abc technologies - an evaluation of storage and communication efficiency	benchmark testing cryptography protocols inspection computer architecture smart cards;protocols;idemix attribute based credentials privacy privacy abc efficiency u prove;efficiency;inspection;computer architecture;idemix;smart cards;privacy abc;cryptography;storage management cryptography data privacy;attribute based credentials;benchmarking privacy abc technologies idemix u prove cryptographic building blocks authentication identity management systems security mechanisms privacy enhancing attribute based credentials communication efficiency storage efficiency;u prove;benchmark testing;privacy	Privacy-enhancing attribute-based credentials (Privacy-ABC) technologies represent a particular category of security mechanisms that enable privacy-friendly identity management systems. In order to provide privacy for users and strong authentication for service providers, they rely on a number of different cryptographic building blocks, which increase their complexity. Hence, efficiency of these technologies becomes an important challenge and a factor that can determine their suitability for deployment in different platforms and services. In this paper, we focus on the storage and communication efficiency. We used a common framework to compare two prominent examples of Privacy-ABC technologies, U-Prove and Idemix, and evaluate the cost of a number of advanced Privacy-ABC features on the chosen efficiency aspects. Our results suggest that for storage, Idemix is more efficient than U-prove, since a single credential provides multiple-presentation unlink ability. In terms of communication efficiency, Idemix is more efficient for issuance, whereas U-Prove is more efficient for presentation of credentials. Independently of these two technologies, revocation and inspection represent a strong, constant impact on the efficiency of presentation.	credential;cryptography;identity management system;privacy;software deployment;strong authentication;u-prove	Fatbardh Veseli;Jetzabel Serna-Olvera	2015	2015 IEEE World Congress on Services	10.1109/SERVICES.2015.37	computer science;internet privacy;world wide web;computer security	Security	-44.450052285784146	67.5837742231601	9925
79d7b527b0416117743a20f4a5d98a8e6714b13b	conditional access module systems for digital contents protection based on hybrid/fiber/coax catv networks	cable television;modele reference;carte a puce;langage description materiel informatique;reduced instruction set computer;analisis contenido;unfolding;memory card;smart card;microprocessor;computadora personal;arquitectura circuito;ordinateur personnel;memoire associative;systeme protection;norme iso;digital protection;iso;personal computer;deploiement;recherche image;reference model;norma iso;despliegue;circuit architecture;module system;iso standard;interface ordinateur;hardware architecture;interfaces computer;content analysis;tarjeta memoria;carte memoire;computer hardware description languages;smart cards;digital content;filter;criptografia;cryptography;data encryption standard;architecture circuit;teledistribution;protection numerique;associative memory;filtre;memoria asociativa;protection system;cryptographie;microprocesseur;analyse contenu;sistema proteccion;article;content based retrieval;microprocesador;filtro;proteccion numerica;teledistribucion;recherche par contenu;hybrid fiber coax;modelo referencia;image retrieval	In this paper, we have proposed the merging of the OpenCable reference model with the smart card interface defined by ISO/IEC 7816-3 and have implemented a new Conditional Access System (CAS) using this interface along with a Personal Computer Memory Card International Association (PCMCIA) interface. In addition, we have also designed the hardware architecture of the Point-of-Deployment (POD) security module, designed with the Verilog HDL, using the above two interfaces. The designed POD security module has an embedded 32-bit Reduced Instruction Set Computer (RISC) microprocessor that manages applications, such as an MPEG-2 filter, descrambler, and Data Encryption Standard (DES). We have tested this modeled and designed system using a prototype and show satisfactory simulation results.	conditional access;hybrid fibre-coaxial	Won Jay Song;Won Hee Kim;Bo Gwan Kim;Byung-Ha Ahn;Mun Kee Choi;Minho Kang	2003		10.1007/978-3-540-39737-3_20	embedded system;smart card;content analysis;telecommunications;image retrieval;computer science;operating system;hardware architecture;computer security	EDA	-34.69177167701019	66.54952731570548	9926
ed9591df2565f50110a28c2c2655cb7cb0debe71	semfs: secure and efficient multi-keyword fuzzy search for cloud storage		Cloud computing has become a popular technology for outsourcing data and providing reliable data services. Encryption is essential to preserve privacy of the outsourced sensitive data. Keyword search over encrypted data would enhance the effective utilization of outsourced storage. In this work, we propose an efficient Searchable Symmetric Encryption (SSE) scheme called SEMFS (Secure u0026 Efficient Multi-keyword Fuzzy Search Scheme) to allow the cloud to search over outsourced encrypted data. SEMFS uses quotient filter for efficient indexing and faster searching. The most attractive feature of this scheme is to allow update the entries of index file dynamically (to achieve better performance) preserving data privacy. Experimental analysis shows that SEMFS achieves higher throughput than the bloom filter based scheme, when implemented. Security of SEMFS has been analyzed against known ciphertext and known plaintext attack models.	approximate string matching;cloud storage	Sanjeet Kumar Nayak;Somanath Tripathy	2017		10.1007/978-3-319-72598-7_4	data mining;cloud computing;ciphertext;symmetric-key algorithm;cloud storage;computer science;encryption;search engine indexing;distributed computing;data as a service;quotient filter	Crypto	-40.252453179509395	67.69896220132892	9935
b5b564c52616032d1f07445109ef17221f575f65	tightly secure encryption schemes against related-key attacks			encryption;related-key attack	Shuai Han;Shengli Liu;Lin Lyu;Dawu Gu	2018	Comput. J.	10.1093/comjnl/bxy074	theoretical computer science;distributed computing;encryption;computer science	Crypto	-41.10673115326817	79.15419051609547	9973
567641c6c816ce3146246cba2a8357c03e03863e	online bi-objective scheduling for iaas clouds ensuring quality of service	energy efficiency;iaas;multi objective scheduling;service level agreement;provider income;cloud computing	This paper focuses on a bi-objective experimental evaluation of online scheduling in the Infrastructure as a Service model of Cloud computing regarding income and power consumption objectives. In this model, customers have the choice between different service levels. Each service level is associated with a price per unit of job execution time, and a slack factor that determines the maximal time span to deliver the requested amount of computing resources. The system, via the scheduling algorithms, is responsible to guarantee the corresponding quality of service for all accepted jobs. Since we do not consider any optimistic scheduling approach, a job cannot be accepted if its service guarantee will not be observed assuming that all accepted jobs receive the requested resources. In this article, we analyze several scheduling algorithms with different cloud configurations and workloads, considering the maximization of the provider income and minimization of the total power consumption of a schedule. We distinguish algorithms depending on the type and amount of information they require: knowledge free, energy-aware, and speed-aware. First, to provide effective guidance in choosing a good strategy, we present a joint analysis of two conflicting goals based on the degradation in performance. The study addresses the behavior of each strategy under each metric. We assess the performance of different scheduling algorithms by determining a set of non-dominated solutions that approximate the Pareto optimal set. We use a set coverage metric to compare the scheduling algorithms in terms of Pareto dominance. We claim that a rather simple scheduling approach can provide the best energy and income trade-offs. This scheduling algorithm performs well in different scenarios with a variety of workloads and cloud configurations.	approximation algorithm;best, worst and average case;cloud computing;computational complexity theory;elegant degradation;emoticon;expectation–maximization algorithm;experiment;greedy algorithm;job stream;mathematical optimization;maximal set;multi-objective optimization;open-shop scheduling;pareto efficiency;quality of service;response time (technology);run time (program lifecycle phase);scheduling (computing);simulation;slack variable;test case	Andrei Tchernykh;Luz Lozano;Uwe Schwiegelshohn;Pascal Bouvry;Johnatan E. Pecero;Sergio Nesmachnow;Alexander Yu. Drozdov	2015	Journal of Grid Computing	10.1007/s10723-015-9340-0	fair-share scheduling;fixed-priority pre-emptive scheduling;real-time computing;earliest deadline first scheduling;flow shop scheduling;cloud computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;operating system;stride scheduling;distributed computing;scheduling;efficient energy use;least slack time scheduling;lottery scheduling;round-robin scheduling	Metrics	-19.19082874983622	62.67433776563842	10029
823e231c4097830030a0bdff29d3ff168dbc7bb3	improvement on tzeng et al.'s nonrepudiable threshold multi-proxy multi-signature scheme with shared verification	verification;matematicas aplicadas;mathematiques appliquees;seuil;multi proxy multi signature scheme;threshold;signature scheme;threshold proxy signature;signature par procuration;proxy multi signature scheme;proxy signature;distribution center;umbral;verificacion;applied mathematics;threshold multi proxy multi signature scheme;multisignature	Tzeng et al. proposed a novel variation of proxy signature scheme called threshold multi-proxy multi-signature scheme with shared verification. However, their scheme has some security weaknesses. In this paper, by identifying some concrete instances and analyses, we will show that their scheme cannot resist frame attacks. That is, after intercepting a valid proxy signature generated by a subset of a proxy group, an adversary can frame new signatures, which can be authenticated as if they were generated by the subset of the proxy group on behalf of the adversary. Furthermore, their scheme needs a trusty share distribution center (SDC) for setting some parameters and initialization of the scheme. To overcome these weaknesses, we also propose our improvement with no SDC in this paper.	digital signature	Haiyong Bao;Zhenfu Cao;Shengbao Wang	2005	Applied Mathematics and Computation	10.1016/j.amc.2004.10.075	verification;applied mathematics;mathematics;distributed computing;internet privacy;computer security	Crypto	-42.72805020382338	75.91629340890738	10070
e4c21d5a8581eed35f176e34810436ed6cdffa5f	communications, collaborations and services in networks of embedded devices		Abstract The core of many IoT systems is based on a network of electronic devices and connected sensors. In this special issue many researchers have proposed solutions to improve different aspects of communication and collaboration among connected devices. Some proposals improve physical aspects of the communication network, especially wireless networks. Other proposals are focused on improving the communication and allocation algorithms used by the IoT networks. There are also some critical services that could affect communications processes and can be optimized for different scenarios, like DNS. Related to services of connected devices, some researchers have proposed notable improvements to design new kind services. The interoperability among heterogeneous devices is one of the classic problems for many IoT systems, some authors have proposed frameworks which try to simplify the communication processes among heterogeneous devices. Including new kind of devices in IoT systems is nowadays an important challenge, which could extend the applicability of IoT in many new Industrial environments, some new ideas about this topic are proposed in this special issue. Finally, there is an important research line related to privacy and security in communications, there are some specific security and privacy problems when IoT networks related to sensitive sensor data and connected devices security.		Jordán Pascual Espada;Ronald R. Yager;Zhiyong Yu	2019	Future Generation Comp. Syst.	10.1016/j.future.2018.11.017	wireless network;telecommunications network;electronics;interoperability;distributed computing;computer science;internet of things	Arch	-22.855498854796735	80.73567411551616	10076
8089cdc166c983afeca1ad7acaf6b8f229ebf475	performance analysis of load-aware anycasting based on openflow	performance evaluation;routing;switches routing servers ip networks network topology delays;network topology performance analysis load aware anycasting service discovery internet openflow technology;network topology;servers;internet;ip networks;switches;performance evaluation internet;delays	Anycast is a practical solution for service discovery among replication of multiple instances in the Internet. OpenFlow is a good candidate to solve the problems of non-awareness of topology changes, costly address translation and low flexibility resulting from anycast service. This paper presents a new anycast mechanism based on OpenFlow technology using the controller to make anycast routing decisions. The controller possesses the knowledge of network topology and link status to realize load-aware anycasting. The effectiveness and accuracy of the proposed scheme is validated by extensive simulation experiments. The results show that the performance of the presented load-aware anycasting outperforms that of existing anycast schemes.	algorithm;anycast;emulator;experiment;internet;network topology;openflow;profiling (computer programming);routing;server (computing);service discovery;simulation	Jingguo Ge;Chuan Du;Yulei Wu;E Yuepeng;Junling You	2013	2013 12th IEEE International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2013.231	real-time computing;computer science;distributed computing;computer network	Mobile	-11.315367770477094	83.18504978911338	10079
7e76ecd2df391109bfe9aaf34cf1f43b3b0215ad	evaluation of forwarding efficiency in nfv-nodes toward predictable service chain performance		The concept of network functions virtualization (NFV) has been embodied in commercial networks over the past years. Software-based virtual network functions have forwarding performance concerns in general, and various acceleration technologies have been developed so far, such as DPDK and vhost-user. Existence of several alternatives requires network engineers or operators to select appropriate technologies; however, no pragmatic criterion exists for constructing high-performance NFV-nodes. From their points of view, a lack of common benchmark and understanding of performance characteristics makes it difficult to predict hop-by-hop performance in a service chain, which results in prevention of NFV deployment in mission-critical networks. In this paper, we clarify performance characteristics of packet forwarding in NFV nodes focusing on three types of acceleration technologies; packet I/O architecture, virtual network I/O, and forwarding engine in a practical stage. We examined three packet I/O architectures (NAPI, netmap, and DPDK), three virtual I/O mechanisms (vhost-net, vhost-user, and SR-IOV), and four practical forwarding programs (Open vSwitch, OVS-DPDK, xDPd-DPDK, and Lagopus) with three referential programs (Linux Bridge, VALE, and L2FWD-DPDK). The experiment was conducted on a 40 GbE environment and we examined two device-under-test machines having different CPU performance. We argue performance characteristics of each technology and give quantitative analyses of the result. The key findings are: 1) CPU core speed has impact on both throughput and latency/jitter; 2) DPDK can allow performance prediction; 3) vhost-user is appropriate for real environment; and 4) OVS-DPDK provides a good combination of performance and functionality.	benchmark (computing);central processing unit;clock rate;control theory;dpdk / dpdk.org;data center;device under test;forwarding plane;full scale;giove;hop-by-hop transport;jsp model 2 architecture;linux;mission critical;network function virtualization;network packet;network switch;open vswitch;openflow;performance prediction;pipeline (computing);single-root input/output virtualization;software deployment;throughput;vii;virtual hosting	Ryota Kawashima;Hiroki Nakayama;Tsunemasa Hayashi;Hiroshi Matsuo	2017	IEEE Transactions on Network and Service Management	10.1109/TNSM.2017.2734560	throughput;computer performance;performance prediction;architecture;computer network;packet forwarding;virtual network;real-time computing;network packet;benchmark (computing);computer science	Networks	-13.371112133307808	82.3916916624176	10082
604d108e9b872af4c7ee07b739f652d812f02d8e	performance and service delay guarantees for web servers: a robust control approach	robust control	This paper applies the Feedback Error Learing and H framework to develop a robust model and adaptive architecture for web server performance control and service delay guarantees. Web server model is approximated with a two tank system that includes many uncertainly components. In contrast with web server delay control that only control delay, our architecture based on H robust control and queuing model predictor enforce server utilization and delay guarantees for different classes on virtual servers. A simulation evaluation demonstrates that H robust control can provide robust request utilization and request response time for Internet servers.	adaptive architecture;approximation algorithm;control theory;kerrison predictor;performance evaluation;queueing theory;response time (technology);robust control;server (computing);simulation;virtual machine;web server;web service	Bing Du;David C. Levy	2006			web server;computer science;robust control;computer network	Metrics	-19.621001490552153	68.1328568564972	10092
994c11c467ca40e0303e66f540efcfae21bc9dfc	erpc: an edge-resources based framework to reduce bandwidth cost in the personal cloud		Personal Cloud storage and file synchronization services, such as Dropbox, Google Drive, and Baidu Cloud, are increasingly prevalent within the Internet community. It is estimated that subscriptions of personal cloud storage are projected to hit 1.3 billion in 2017. In order to provide high rates of data retrieving, cloud providers require huge amounts of bandwidth. As an attempt to reduce their bandwidth cost and, at the same time, guarantee the quality of service, we propose a novel cloud framework based on distributed edge resources (i.e., voluntary peers in P2P Networks and edge servers in Content Delivery Networks).	personal cloud	Shaoduo Gan;Jie Yu;Xiaoling Li;Jun Ma;Lei Luo;Qingbo Wu;Shasha Li	2016		10.1007/978-3-319-39958-4_35	embedded system;real-time computing;computer network	EDA	-18.349299449103416	73.93695931939538	10113
603787f3ef06689be3a5739bc6cd83ec6c0205b3	performance management of larger distributed systems based on windows ntt and ethernet networks	performance management;distributed system		distributed computing;microsoft windows	Adam Grummitt	1998			performance management;embedded system;carrier ethernet;ata over ethernet;ethernet;distributed computing;engineering	HPC	-20.68358143902686	87.70758835354982	10129
983324eb74252caa1a6e728bf790f516a3000122	federating websites with the google wave protocol	content management;site web;google;agregacion;protocols;protocole transmission;busqueda por contenidos;real time;web sites content management protocols software architecture synchronisation;operational transformation social networks federation protocol wave;usuario;arquitectura logicial;utilisateur;wave;google wave federation protocol websites software architecture communication protocol user generated content synchronization;aggregation;metasearch;synchronisation;social network;software architecture;protocolo transmision;federation protocol;social networks;synchronization;temps reel;web sites;agregation;user generated content synchronization;tiempo real;communication protocol;user;google wave federation protocol;sincronizacion;operational transformation;near real time;sitio web;metasearch protocols web sites synchronization google real time systems software architecture;user generated content;websites;content based retrieval;recherche par contenu;web site;architecture logiciel;real time systems;transmission protocol	This article presents a software architecture and communication protocol for synchronizing user-generated content across websites in near real time. The technique builds on the Google Wave Federation Protocol, allowing websites to mashup and cooperate in ways that are difficult to achieve with other mashup techniques. The authors also present a set of requirements for modern federated websites, along with an extensive scenario walkthrough to illustrate how to use the proposed approach.	apache wave;cognitive walkthrough;communications protocol;mashup (web application hybrid);real-time computing;requirement;software architecture;user-generated content	Torben Weis;Arno Wacker	2011	IEEE Internet Computing	10.1109/MIC.2011.28	communications protocol;synchronization;metasearch engine;computer science;operating system;database;distributed computing;multimedia;internet privacy;world wide web;computer security;computer network;social network	Security	-35.07553950563796	61.52537544190895	10140
01d5bdff5760c477c0b82e2c72f9b4557fcd002a	integrated simulation of power and communication networks for smart grid applications	topology;protocols;innovative architectures;communication networks;power integrated simulation;communication network integrated simulation;grid applications;power systems;network technologies;power networks;network topology;smart grid applications;smart grids;technology and engineering;smart power grids;power networks power integrated simulation communication network integrated simulation smart grid applications innovative architectures network technologies communication networks power systems;community networks;telecommunication networks smart power grids;smart grids communication networks topology network topology protocols load modeling;load modeling;telecommunication networks	Innovative architectures, control mechanisms and network technologies are being proposed to realize the future smart grid. To assess their impact and effectiveness, simulation is key. Simulation in both areas of communication networks as well as power systems has been widely adopted. However, the coupling of those two worlds calls for tools able to address both. In this paper, we propose an innovative integrated framework that models and simulates both the communication network and power networks. We discuss the design and operation of the simulation environment, and illustrate this by means of a case study that employs it.	algorithm;control system;extensibility;ibm power systems;intelligent control;key (cryptography);load profile;matlab;simulation;telecommunications network	Kevin Mets;Tom Verschueren;Chris Develder;Tine L. Vandoorn;Lieven Vandevelde	2011	2011 IEEE 16th International Workshop on Computer Aided Modeling and Design of Communication Links and Networks (CAMAD)	10.1109/CAMAD.2011.5941119	embedded system;communications protocol;computer science;distributed computing;smart grid;electric power system;network topology;computer network	Arch	-21.302460300597062	80.71583401940617	10142
8d5e3ef8868b1aa95da1c2eb0319d8945a8b1425	component-based security system (comsec) with qos for wireless sensor networks	key management;sybil attack;secure data aggregation;quality of service;security in wireless sensor network;wireless sensor networks	ABSTRACT#R##N##R##N#In the last decade, many security solutions have been proposed to fulfil the security requirements of wireless sensor networks (WSNs). However, these solutions are specifically designed for particular security issues, based on different assumptions, and limited to certain WSNs applications. Can these security solutions work together to handle multiple problems at the same time? It is an interesting and difficult question. We believe good solutions in various security areas do not mean they can work together and deliver similar results, i.e. occurrence of any security weakness or attack in a particular security solution could expose the vulnerabilities of other solutions. Using these solutions together might also degrade WSN quality of service. To deal with the aforementioned issues, we therefore propose a novel component-based security system (COMSEC) based on proactive and reactive components. Each component looks after a particular security issue and is integrated with others. The proposed system provides better secure communication, Sybil attack detection, secure data aggregation and resilience against node capture attacks and replication attacks. COMSEC has been evaluated and compared against existing schemes. Evaluation results show a significant improvement in resilience against node capture attacks, Sybil attack detection data confidentiality, privacy, memory overhead and connectivity. Copyright © 2012 John Wiley & Sons, Ltd.		Kashif Kifayat;Madjid Merabti;Qi Shi;Sohail Abbas	2013	Security and Communication Networks	10.1002/sec.634	computer security model;cloud computing security;countermeasure;security through obscurity;wireless sensor network;quality of service;security information and event management;covert channel;asset;computer science;key management;security service;internet privacy;security testing;computer security;computer network	Mobile	-52.41716934973141	74.7271546420939	10154
9e41d71e0099851f74bf2116af0a2f9aa9e04b60	faster pairings using an elliptic curve with an efficient endomorphism	pairing based cryptosystem;protocole transmission;curva ennegrecimiento;encryption;elliptic curve;identity based encryption;pairing based cryptography;cryptographic protocol;characteristic curve;cifrado;courbe elliptique;supersingular elliptic curve;protocolo transmision;cryptage;curva eliptica;criptografia;cryptography;courbe noircissement;cryptographie;tate pairing;transmission protocol	The most significant pairing-based cryptographic protocol to be proposed so far is undoubtedly the Identity-Based Encryption (IBE) protocol of Boneh and Franklin. In their paper [6] they give details of how their scheme might be implemented in practise on certain supersingular elliptic curves of prime characteristic. They also point out that the scheme could as easily be implemented on certain special nonsupersingular curves for the same level of security. An obvious question to be answered is – which is most efficient? Motivated by the work of Gallant, Lambert and Vanstone [12] we demonstrate that, perhaps counter to intuition, certain ordinary curves closely related to the supersingular curves originally recommended by Boneh and Franklin, provide better performance. We illustrate our technique by implementing the fastest pairing algorithm to date (on elliptic curves of prime characteristic) for contemporary levels of security. We also point out that many of the nonsupersingular families of curves recently discovered and proposed for use in pairing-based cryptography can also benefit (to an extent) from the same technique.	algorithm;cryptographic protocol;fastest;franklin electronic publishers;id-based encryption;pairing-based cryptography	Michael Scott	2005	IACR Cryptology ePrint Archive	10.1007/11596219_21	arithmetic;supersingular elliptic curve;discrete mathematics;computer science;cryptography;counting points on elliptic curves;cryptographic protocol;mathematics;elliptic curve;computer security;encryption;algebra	Crypto	-39.49561518142154	78.12844056106553	10164
45705fdff7b565e231be06b5a8c751b9cee4dfb6	identity-based steganography and its applications to censorship resistance	message in a bottle;collage;steganography;identity based cryptography;censorship resistance;key distribution	The use of public-key steganography has been proposed for several censorship-resistance systems. However, distribution of the employed public keys presents an availability, scalability, and security challenge in many of these. To mitigate this problem, we introduce the notion of identity-based steganography. In particular, we define identity-based steganographic tagging (IBST), which allows a sender to produce a steganographic tag for a recipient's identity such that the tag can only be recognized by the intended recipient using her (identity-based) private key. We instantiate our definition by an efficient IBST scheme, provably secure under the bilinear decisional Diffie-Hellman assumption. We find IBST to be particularly useful when the censors are able to impede distribution of cryptographic keys or break forward security by compromising system agents. As two representative applications of IBST to censorship resistance systems, we first present an efficient and dynamic solution for the key distribution problem in Collage and second, we demonstrate that IBST can improve the scalability of Message in a Bottle.	bilinear filtering;decisional diffie–hellman assumption;diffie–hellman problem;key (cryptography);key distribution;provable security;public-key cryptography;scalability;steganography	Tim Ruffing;Jonas Schneider;Aniket Kate	2013		10.1145/2508859.2512526	steganography tools;computer science;steganography;internet privacy;world wide web;key distribution;computer security	Security	-41.96823703613426	74.93957721958172	10173
1d8236248c3283a63c4560220ed48b946f7c7b63	performance evaluation of mpeg-4 video transmission with the adaptive smooth multicast protocol (asmp)	joint evaluation;video signal processing data compression multicast protocols;performance evaluation;psnr;data compression;ns 2;video signal processing;component;simulation;multimedia application;video quality metric;streaming media receivers jitter psnr delay throughput multimedia communication;simulation component multicast congestion control multimedia transmission ns 2;receivers;multicast protocols;streaming media;congestion control;multimedia data;multimedia communication;video transmission;video quality metric mpeg 4 video transmission adaptive smooth multicast protocol performance evaluation bandwidth utilization smooth transmission rate;adaptive smoothing;jitter;multimedia transmission;simulation environment;multicast;throughput	We present in this work the performance evaluation of MPEG-4 video transmission with our proposed single rate multicast protocol named Adaptive Smooth Multicast Protocol (ASMP). ASMP key attributes are: a) adaptive scalability to large sets of receivers, b) TCP-friendly behavior, c) high bandwidth utilization, and finally d) smooth transmission rates which are suitable for multimedia applications. We evaluate the performance of ASMP under an integrated simulation environment which extends ns-2 and Evalvid-RA to the multicast domain with the use of the RTP/RTCP protocols. Simulations conducted under this environment combine the measurements of network-centric along with video quality metrics. This “joint” evaluation process provides a better understanding of the benefits and limitations of any proposed protocol for multimedia data transmission.	computer simulation;emoticon;multicast;performance evaluation;scalability;traffic collision avoidance system	Christos Bouras;Georgios Kioumourtzis;Apostolos Gkamas	2010	The IEEE symposium on Computers and Communications	10.1109/ISCC.2010.5546815	data compression;throughput;real-time computing;multicast;jitter;peak signal-to-noise ratio;telecommunications;computer science;component;network congestion;xcast;computer network	Networks	-6.193859316162806	101.47277993333712	10181
785b0eb2a6f590be3116c99d3a21f346b720a0a5	a quantitative study of authentication and qos in wireless ip networks	data transmission;mobility management mobile radio;traffic pattern;wireless networks;probability;data integrity;quantitative study secure communication high quality communication public access wireless ip networks quality of service qos data transmission system performance mobile environment data integrity resource availability traffic pattern mobility pattern authentication delay call dropping probability;high quality communication;information security;system modeling;authentication;wireless network;call dropping probability;secure communication;system performance;data communication;qos;protection;mobility management mobile radio telecommunication security message authentication radio access networks ip networks quality of service telecommunication traffic delays probability;mobile environment;telecommunication traffic;public access wireless ip networks;telecommunication security;authentication delay;mobility pattern;ip networks;resource availability;message authentication;quality of service;authentication ip networks communication system security data security quality of service information security data communication system performance wireless networks protection;delays;communication system security;radio access networks;quantitative study;data security	With the increasing demand for secure and high-quality communications in public access wireless IP networks, it is very important to have an in-depth understanding of the relationship between the security and quality of service (QoS). In wireless networks, authentication can provide secure communications by preventing unauthorized usage and negotiating the credentials for data transmission. Nevertheless, it induces heavy overhead to data transmission, further deteriorating overall system performance. Thus, we analyze the impact of authentication on the security and QoS quantitatively in this paper. First, we introduce a system model based on a challenge/response authentication, which is widely used in many mobile environments. Then, a concept of security level is proposed to describe the protection of communications according to the nature of security, i.e., information secrecy, data integrity, and resource availability. By taking traffic and mobility patterns into account, our approach establishes a direct and quantitative connection between the security and QoS through the authentication. Finally, numerical results are provided to demonstrate the impact of security levels, mobility and traffic patterns on overall system performance in terms of authentication delay and call dropping probability.	authorization;challenge–response authentication;credential;data integrity;internet protocol suite;numerical analysis;overhead (computing);quality of service;secure communication	Wei Liang;Wenye Wang	2005	Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.	10.1109/INFCOM.2005.1498383	quality of service;computer science;information security;access control;authentication protocol;wireless network;security service;distributed system security architecture;internet privacy;network access control;computer security;computer network	Mobile	-8.772557498771091	91.3183049794708	10189
83ccf3066aa3013ebc6e5b0f664dbd5374012701	a novel statistic-based relaxed grid resource reservation strategy	resource utilization;reservation strategy;grid environments;grid applications;processor scheduling;resource allocation;resource management;conditional probability advance reservation grid computing reservation violation;contracts;resource reservation;computational modeling;scheduling;reservation violation;advance reservation mechanism;scheduling grid computing resource allocation;advance reservation;quality of service;resource co allocation;resource management grid computing processor scheduling information science reliability engineering application software system performance computational modeling middleware availability;grid computing;conditional probability;statistic based relaxed grid resource reservation strategy;reservation strategy statistic based relaxed grid resource reservation strategy grid environments advance reservation mechanism resource co allocation scheduling resource utilization;conferences	In grid environments, advance reservation mechanism is to provide reliable resource co-allocation and scheduling for applications. However, excessive advance reservation will bring about many negative effects for system's performance, such as lower resource utilization and higher rejection rate. To mitigate these negative effects of advance reservation, a relaxed reservation strategy is proposed, in which the reservation admission criteria is more relaxing than that of conventional reservation. The strategy is based on the facts that grid applications tend to overestimate reservation duration to ensure their completion. In the proposed relaxed reservation strategy, reservation manager might accept those reservations that are overlapping with existing ones. Experimental results show that the strategy can bring about remarkably higher resource utilization and lower rejection rate at the price of a slightly increasing of reservation violations.	clock rate;grid computing;rejection sampling;reservation station;resource reservation protocol;scheduling (computing);simulation;time complexity	Peng Xiao;Zhigang Hu;Xi Li;Liu Yang	2008	2008 The 9th International Conference for Young Computer Scientists	10.1109/ICYCS.2008.117	in situ resource utilization;real-time computing;quality of service;conditional probability;resource allocation;computer science;resource management;operating system;distributed computing;computational model;scheduling;grid computing;statistics;computer network	HPC	-23.969649249391132	64.70364624598855	10196
51c1650b442e41d4e259e864a78763be261e0273	efficient big brother networks	universal mobile telecommunication system;context mobile communication multimedia communication mobile computing forward error correction sensors cognition;multicast communication;multimedia broadcast multicast service;context information;grouping;location based information multimedia group communications rich media content 3gpp multimedia broadcast multicast service umts networks long term evolution service architecture evolution evolved packet system;sensors;mobile computer;long term evolution;group communication;service architecture;3g mobile communication;forward error correction;user experience;multimedia communication;cognition;content delivery;mobile communication;mbms;sensors context e mbms grouping mbms;e mbms;system architecture;mobile computing;context;mobile network;3rd generation partnership project;multimedia communication 3g mobile communication multicast communication	The growing popularity of multimedia group communications requires evolved networking technologies to provide rich-media content to groups of users in the most effective way. 3GPP (3rd Generation Partnership Project) has specified MBMS (Multimedia Broadcast Multicast Service) to enable broadcasting and multicasting packet data in UMTS (Universal Mobile Telecommunication System) networks to large user groups. Furthermore, the LTE/SAE (Long Term Evolution / Service Architecture Evolution) specification has evolved MBMS in order to provide broadcast connections over the EPS (Evolved Packet System) architecture. Context, understood as any information that modifies over time, can be used to improve systems' efficiency. Mobile Operators already use location-based information to deliver more accurate content to their clients. But context may have an emphasized role when dealing with communications' groups. Context information shall be used to increase the system effectiveness while augmenting the user experience. This paper introduces the required evolutions towards an architecture where context information is taken into account to improve MBMS and E-MBMS (Evolved MBMS) services allowing an effective multimedia content delivery to mobile users' communities. But are the clients willing to let Mobile Operators know everything about them even if this knowledge is used to meet their needs? Are we ready to have a Big Brother Mobile Network which is always watching us?	compaq lte;digital distribution;encapsulated postscript;interactive media;monetization;multimedia broadcast multicast service;network packet;personally identifiable information;selective area epitaxy;user experience	Filipe Cabral Pinto;Antonio Videira;Athen Ma;Laurie G. Cuthbert	2011	2011 IEEE EUROCON - International Conference on Computer as a Tool	10.1109/EUROCON.2011.5929265	telecommunications;computer science;operating system;multimedia;multimedia broadcast multicast service;mobile computing;computer network	Mobile	-15.357367588102514	91.94527247648705	10198
2dec3ea33ac2658dd9b2875504d6e8b5ccf4ed8b	towards text communication services	protocols;standardization facsimile broadcasting open systems telematics standards development telecommunication standards silicon telecommunication computing frequency;teletext videotex france protocols;france;teletext videotex;communication service	Standards are important for the widespread and economical introduction of many text and image-based communication services. The role of standards in the policies and developments of the French Post Telecommunication and Telediffusion Administration for a variety of telematic services is discussed.		Bernhard Marti	1983	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.1983.1145915	communications protocol;telecommunications;computer science;multimedia;computer network	Mobile	-17.76048002033695	92.07077760043364	10222
5793f293030a72200f4ef2327257df5b76b3463d	software defined networks based 5g backhaul architecture	enodeb;virtualization;lte;5g;mme;sdn	In this paper, we propose the usage of Software Defined Network as mobile backhaul for 5G networks. Mobile networks are facing major challenges to handle the increasing traffic demand. The mobile operators need to improve the effectiveness of their infrastructure. Moreover, they need to enable new business models with their existing network. In this paper we propose Software Defined Networks to be integrated as part of the mobile backhaul to address these two requirements. Firstly, we completely virtualize and move the core mobile network, as it is known today, directly to the cloud. Secondly we integrate Software Define network technology in the mobile backhaul. Adding SDN simplifies the access network formed by base stations i.e. eNodeBs, interconnected through a backhaul network composed by SDN forwarding planes managed from the cloud. Each access network will be managed from the SDN controller and rest of the network element in the cloud, thus reducing the Operative Expenses (OPEX). Finally, we present the benefits of using SDN in mobile networks to support multiple Mobile Virtual Network Operators (MVNO) in their network infrastructure.	access network;backhaul (telecommunications);cloud computing;requirement;software-defined networking;virtualize	José Costa-Requena;Vicent Ferrer Guasch;Jesus Llorente Santos	2015		10.1145/2701126.2701180	radio access network;real-time computing;virtualization;public land mobile network;telecommunications;computer science;lte advanced;operating system;5g;software-defined networking;mobile computing;computer network	Mobile	-14.826123273612604	85.74616157204004	10227
5f18d3b90941b787ff1931ee942c8574f15558b7	securing password file using bezier curves	science and technology;dictionary attack;system security;password authentication;bezier curve	Password security has emerged as a promising field in the Computer science and technology. The innovative strategies are found to be costly and also require expertise to use them. The widely used methods of password secu- rity are pass-faces and biometrics password authentication schemes. Though they serve their purpose but are found to be cost ineffective.This paper looks at the new concepts of password security based on text-based authentication, ensuring the security from dictionary attacks. It is based on the principle of con- version of the characters of password in some control points, an unrecognizable form for intruders.	bézier curve;password	Sunil Khurana;Sunil Kumar Khatri	2010		10.1007/978-3-642-15766-0_119	zero-knowledge password proof;cognitive password;password policy;s/key;rainbow table;challenge–response authentication;computer science;bézier curve;password psychology;passphrase;password authentication protocol;salt;microsoft office password protection;internet privacy;key derivation function;one-time password;key stretching;syskey;world wide web;password;computer security;dictionary attack;hmac-based one-time password algorithm;password strength;password cracking;science, technology and society	Crypto	-46.399984273760666	68.64013240225019	10229
5082ac930b80e64e8b0fb3703cbba5a6e1badc80	towards ieee 802.1 ethernet avb for advanced driver assistance systems: a preliminary assessment	local area networks driver information systems;traffic patterns ieee 802 1 ethernet avb advanced driver assistance systems automotive network technologies in car network ieee audio video bridging standard adas multimedia infotainment;driver information systems;local area networks	Advanced Driver Assistance Systems involving cameras and the multimedia domain are both quite challenging for automotive network technologies, due to the bandwidth requirements and latency/jitter constraints they impose. Ethernet as in-car network is expected to breakthrough in both domains and the IEEE Audio Video Bridging (AVB) standard is a promising candidate. This paper reports preliminary performance assessments of AVB for ADAS, multimedia and infotainment, obtained through the simulation of realistic traffic patterns.	architecture design and assessment system;bridging (networking);device driver;requirement;simulation	Giuliana Alderisi;Giancarlo Iannizzotto;Lucia Lo Bello	2012	Proceedings of 2012 IEEE 17th International Conference on Emerging Technologies & Factory Automation (ETFA 2012)	10.1109/ETFA.2012.6489775	local area network;embedded system;real-time computing;ethernet flow control;advanced driver assistance systems;telecommunications;computer science;engineering;computer network	Embedded	-12.717133067835405	94.10789572248495	10251
24b13eb9171bb7a8a04ef70f4adc7578e37943d1	efficient rational proofs with strong utility-gap guarantees		As modern computing moves towards smaller devices and powerful cloud platforms, more and more computation is being delegated to powerful service providers. Interactive proofs are a widely-used model to design efficient protocols for verifiable computation delegation. Rational proofs are payment-based interactive proofs. The payments are designed to incentivize the provers to give correct answers. If the provers misreport the answer then they incur a payment loss of at least 1/u, where u is the utility gap of the protocol. In this work, we tightly characterize the power of rational proofs that are super efficient, that is, require only logarithmic time and communication for verification. We also characterize the power of single-round rational protocols that require only logarithmic space and randomness for verification. Our protocols have strong (that is, polynomial, logarithmic, and even constant) utility gap. Finally, we show when and how rational protocols can be converted to give the completeness and soundness guarantees of classical interactive proofs.	computation;formal verification;interactive proof system;l (complexity);nl (complexity);platform as a service;polynomial;randomness;time complexity	Jing Chen;Samuel McCauley;Shikha Singh	2018		10.1007/978-3-319-99660-8_14	mathematical optimization;verifiable secret sharing;service provider;cloud computing;mathematical proof;theoretical computer science;computation;delegation;computer science	Theory	-39.602675395041814	70.48532810660613	10258
4df86026582bb21dbf10a98507ac53e6969d7bcd	protection of multicast scalable video by secret sharing: simulation results	estensibilidad;key management;partage secret;networks;scalable video;multimedia;secret sharing;encryption;multidestinatario;video compression;low complexity;multimedia application;cifrado;compression image;image compression;cryptage;arbre repartition cle hierarchique;extensibilite;scalability;video;secure multicast;multidestinataire;multicast;key distribution;compresion imagen	Security is an increasingly important attribute for multimedia applications that require prevention of unauthorized access to copyrighted data. Two approaches have been used to protect scalable video content in distribution: Partial encryption and progressive encryption. Partial encryption provides protection for only selected portions of the video. Progressive encryption allows transcoding with simple packet truncation, and eliminates the need to decrypt the video packets at intermediate network nodes with low complexity. Centralized Key Management with Secret Sharing (CKMSS) is a recent approach in which the group manager assigns unique secret shares to the nodes in the hierarchical key distribution tree. It allows the reconstruction of different keys by communicating different activating shares for the same prepositioned information. Once the group key is established, it is used until a member joins/leaves the multicast group or periodic rekeying occurs. In this paper, we will present simulation results regarding the communication and processing requirements of the CKMSS scheme applied to scalable video. In particular, we have measured the rekey message size and the processing time needed by the server for each join/leave request and periodic rekey event.	access control;algorithm;authorization;centralized computing;computation;computational complexity theory;digital video;encryption;extrapolation;group key;key distribution;key management;multicast;network packet;nonlinear system;overhead (computing);population;real life;requirement;scalability;secret sharing;server (computing);simulation;truncation	Ahmet M. Eskicioglu;Scott D. Dexter;Edward J. Delp	2003		10.1117/12.479731	computer science;distributed computing;on-the-fly encryption;internet privacy;encryption;attribute-based encryption;computer network	Security	-41.417669207020076	71.29621695695667	10267
016ffdd4d76e23a7fe66c64e946d9cb7cfaa9b41	inhibiting card sharing attacks	carte a puce;television;smart card;largeur bande;fabricacion asistida por computador;legacy software;emulateur;contre mesure electronique;programming environment;securite informatique;satelite;computer security;medio ambiente programacion;fabrication assistee;logiciel patrimonial;internet;contra medida electronica;smart cards;satellite;seguridad informatica;computer aided manufacturing;logicial herencia;anchura banda;bandwidth;emulador;electronic countermeasure;emulator;environnement programmation	The satellite TV industry relies heavily on the use of smart card technology at the very heart of broadcasted services that are protected by legacy conditional access systems. The process of Satellite TV signal protection is distributed amongst a number of system components, e.g. smart cards, receivers, Conditional Access Modules (CAM) and the content provider. However, the introduction of “Open” Satellite Receivers, providing a highly configurable environment with software emulation of conditional access systems, enabled the implementation of whole range of new attacks. A widely deployed attack is often referred to as the “card sharing” attack, by which one legitimate user colludes to provide protected content to a larger group of unauthorised users. This paper proposes a countermeasure that increases the bandwidth requirements of this attack to the point where it is no longer practical with a standard internet connection, with a minimal impact on existing protocols and architectures.	authorization;communications satellite;conditional access;emulator;internet access;memory management controller;requirement;smart card;television;usb	Michael Tunstall;Konstantinos Markantonakis;Keith Mayes	2006		10.1007/11908739_17	embedded system;smart card;telecommunications;computer science;operating system;database;computer security;satellite;computer-aided manufacturing	Security	-34.697187889479714	66.54815903427583	10270
4524cd3e25d1c965a087e60d60930b8adc34e326	pro-oram: constant latency read-only oblivious ram		Oblivious RAM is a well-known cryptographic primitive to hide data access patterns. However, the best known ORAM schemes require a logarithmic computation time in the general case which makes it infeasible for use in real-world applications. In practice, hiding data access patterns should incur a constant latency per access. In this work, we present PRO-ORAM— an ORAM construction that achieves constant latencies per access in a large class of applications. PRO-ORAM theoretically and empirically guarantees this for read-only data access patterns, wherein data is written once followed by read requests. It makes hiding data access pattern practical for read-only workloads, incurring sub-second computational latencies per access for data blocks of 256 KB, over large (gigabyte-sized) datasets. PRO-ORAM supports throughputs of tens to hundreds of MBps for fetching blocks, which exceeds network bandwidth available to average users today. Our experiments suggest that dominant factor in latency offered by PRO-ORAM is the inherent network throughput of transferring final blocks, rather than the computational latencies of the protocol. At its heart, PRO-ORAM utilizes key observations enabling an aggressively parallelized algorithm of an ORAM construction and a permutation operation, as well as the use of trusted computing technique (SGX) that not only provides safety but also offers the advantage of lowering communication costs.	algorithm;cloud computing;computation;cryptographic primitive;cryptography;data access;data rate units;experiment;gigabyte;hardware restriction;interrupt latency;oblivious ram;parallel computing;random-access memory;read-only memory;throughput;time complexity;trusted computing	Shruti Tople;Yaoqi Jia;Prateek Saxena	2018	IACR Cryptology ePrint Archive		parallel computing;latency (engineering);oblivious ram;computer science	Security	-36.8389466806668	66.57583171435058	10287
43e956c1374cdeec8c056f9651aacea1cf0477c1	privacy preserving biometrics-based and user centric authentication protocol	privacy security biometrics authentication	We propose a privacy preserving biometrics-based authentication protocol by which users can authenticate to different service providers from their own devices without involving identity providers in the transactions. Authentication is performed through a zero-knowledge proof of knowledge protocol which is based on a cryptographic identity token created using the unique, repeatable and revocable biometric identifier of the user and a secret provided by the user which enables two-factor authentication as well. Our approach for generating biometric identifiers from the user’s biometric image is based on the support vector machine classification technique in conjunction with a mechanism for feature extraction from the biometric image. The paper includes experimental results on a dataset of iris images and a security and privacy analysis of the protocol.	authentication protocol;biometrics;cryptography;feature extraction;identifier;multi-factor authentication;privacy;proof of knowledge;support vector machine;zero-knowledge proof	Hasini Gunasinghe;Elisa Bertino	2014		10.1007/978-3-319-11698-3_30	computer science;authentication protocol;internet privacy;world wide web;computer security;challenge-handshake authentication protocol	Security	-45.420288361995425	70.46495219991293	10316
d1c660e99c1e81838a922d0561d437992fbad0f1	an architecture for automated replacement of qos policies	policy of policies;standard policy replacement strategies;mission critical systems;computer networks automated replacement qos policies pop policy of policies standard policy replacement strategies policy based network architecture pdps policy decision points policy replacement task policy based network management;application software;policy based networking;policy decision point;computer networks;automata;computer architecture;automated replacement;policy decision points;condition monitoring;policy based network management;information management;computer network management;pop;pdps;informatics;meta policies;automation computer architecture computer network management application software switches informatics mission critical systems information management condition monitoring automata;quality of service;switches;policy based network;quality of service computer network management;architecture;business planning;qos policies;policy replacement automation;policy definition;automation;policy replacement task	This paper introduces the notion of PoP (Policy of Policies) used to define standard policy replacement strategies in a policy-based network. We also propose an architecture to support PoP within PDPs (Policy Decision Points originally defined by the IETF). The notion of PoP, and the proposed architecture allow the automation of the policy replacement task currently manually executed by the network administrator based on the network business plan.	quality of service	Lisandro Zambenedetti Granville;Gustavo Augusto Faraco de Sá Coelho;Maria Janilce Bosquiroli Almeida;Liane Margarida Rockenbach Tarouco	2002		10.1109/ISCC.2002.1021764	application software;simulation;quality of service;computer science;architecture;automation;information management;informatics;computer security;computer network	DB	-18.878195508790043	84.34204485616945	10327
c6c8717b8124531e0025c566ebd97bc6dfe92386	a traffic burstiness-based offload scheme for energy efficiency deliveries in heterogeneous wireless networks	energy efficiency;wireless lan decision making energy conservation internet telephony long term evolution online front ends power consumption quality of service smart phones telecommunication traffic transport protocols video streaming wireless channels;energy efficiency ieee 802 11 standards streaming media mobile communication multimedia communication mobile handsets energy consumption;burst traffic pattern multipath tcp traffic offloading energy efficiency;streaming media;energy consumption;multimedia communication;ieee 802 11 standards;mobile communication;mobile handsets;ieee 802 11 interfaces heterogeneous wireless networks traffic burstiness energy efficiency deliveries mobile multimedia applications smartphone energy consumption quality of service qos multimedia traffic emtcp bt energy efficiency oriented offloading scheme mptcp delivery decision making process voice over ip service voip service video streaming file downloading web browsing multipath tcp content delivery wireless network interfaces long term evolution lte	Latest mobile multimedia applications have important impact on smartphone usage in terms of both energy consumption and Quality of Service (QoS) levels. This impact is dependent on the level of burstiness of the multimedia traffic. This paper proposes eMTCP-BT, a novel energy-efficiency-oriented offloading scheme for multipath TCP (MPTCP) deliveries which considers traffic burstiness level in its decision making process. Mobile applications traffic is categorized according to its burstiness level, including some most widely-used services such as Voice over IP (VoIP) service, video streaming, large file downloading and web browsing. eMTCP-BT increases the energy efficiency of the multipath TCP content deliveries by performing an innovative distribution of the overall traffic for its delivery via the available wireless network interfaces (and paths) based on the traffic burstiness level. Real traffic trace-based simulation experiments have been conducted involving a mobile device receiving traffic over the Long Term Evolution (LTE) and IEEE 802.11 interfaces. Result analysis demonstrates how eMTCP-BT outperforms both eMTCP and the original MPTCP in terms of energy efficiency by up to 91.68%.	categorization;compaq lte;download;experiment;haplogroup bt;mobile device;quality of service;smartphone;streaming media;topbt;trace-based simulation	Shengyang Chen;Zhenhui Yuan;Gabriel-Miro Muntean	2013	2013 IEEE Globecom Workshops (GC Wkshps)	10.1109/GLOCOMW.2013.6825043	real-time computing;mobile telephony;telecommunications;computer science;efficient energy use;computer network	Metrics	-9.658321364523651	99.59469978577778	10356
26176ef6e5f4e093bf8aac8d6dc97ebfd2952ce6	signalling optimisation for voip service in all-ip network	internet protocol;simulation;m services;resource management;voice over ip;mobile voip services;fmc;signalling optimisation;mobile services;ip multimedia subsystem;call processing;fixed mobile convergence	As the needs of the convergence service are increasing, the IP multimedia subsystem (IMS) becomes an essential service platform to realise various types of new emerging services. The application areas for the services through the IMS are now diversified and the voice over IP (VoIP) is one of the widespread services. In this paper, an optimisation method is proposed for the special purpose VoIP call procedure when it is implemented based on the standardised IMS protocol. The signalling optimisation is discussed for the efficient realisation of the VoIP through the detailed investigation of the overall call procedures. Simulation results are also presented to show the quantitative effect on the system resource management that can be also utilised for the decision making for the future investment in the network systems.	mathematical optimization	Jongdeug Kim;Taehyun Jeon	2014	IJSN	10.1504/IJSN.2014.065721	internet protocol;real-time computing;next-generation network;telecommunications;computer science;resource management;voice over ip;mobile communications over ip;ip multimedia subsystem;computer security;computer network	Networks	-13.929341714419559	92.24398327890997	10368
80e1311b7019f0c6c8834c0daef950c5b86598b2	differential identifiability	differential privacy;identifiability	A key challenge in privacy-preserving data mining is ensuring that a data mining result does not inherently violate privacy. ε-Differential Privacy appears to provide a solution to this problem. However, there are no clear guidelines on how to set ε to satisfy a privacy policy. We give an alternate formulation, Differential Identifiability, parameterized by the probability of individual identification. This provides the strong privacy guarantees of differential privacy, while letting policy makers set parameters based on the established privacy concept of individual identifiability.	data mining;differential privacy;privacy policy	Jaewoo Lee;Chris Clifton	2012		10.1145/2339530.2339695	identifiability;computer science;machine learning;data mining;mathematics;internet privacy;differential privacy;statistics	ML	-39.57446036078461	63.02425507646041	10406
ef1b368b86d55b6f3a2a02a4f1a123913a459b94	service-level agreement aggregation for quality of service-aware federated cloud networking	network resources;quality of service cloud computing contracts;sla protocol;quality of service aware federated cloud networking;sla language;qos constrains;qos network resources service level agreement aggregation quality of service aware federated cloud networking dynamic resources allocation network services network resources cloud infrastructure sla protocol sla language qos constrains;cloud infrastructure;network services;qos network resources;dynamic resources allocation;service level agreement aggregation	Since the cloud paradigm becomes increasingly popular for dynamic resources allocation, the flexibility of a cloud is still limited regarding network services and their autonomous federation between different providers. The following architectural approach introduces a generic layered model to orchestrate and federate heterogeneous networks. In particular, an architecture is presented that enables quality of service (QoS) aware parameterisation of network resources in a cloud infrastructure of a single data-centre as well as for a federation. Furthermore, this architecture uses a service-level agreement (SLA) protocol and language to expose key performance indicators and to negotiate appropriate QoS constrains that are applied to the virtually sliced underlying network substrate. In this way, capabilities of the orchestration and the current utilisation of the network are building the foundation for dynamic negotiated SLAs and the within-guaranteed QoS network resources. Therefore an aggregation mechanism is illustrated for merging service-level objectives and for guaranteeing a single SLA that specifies obligations and responsibilities of all participants.	autonomous robot;cloud computing;data center;federated identity;orchestration (computing);programming paradigm;quality of service;service-level agreement	Alexander Stanik;Marc Körner;Odej Kao	2015	IET Networks	10.1049/iet-net.2014.0104	distributed computing;business;world wide web;computer network	Networks	-28.379371434694775	61.03276020025511	10436
43e389ca7154402d2e4904918968b7c00c790939	compiling packet forwarding rules for switch pipelined architecture	network calculus packet forwarding rules switch pipelined architecture openflow network functions control plane forwarding plane device targets semantic based approach flow classification switch device rule compiling frequent pattern mining;switches computer architecture semantics protocols heuristic algorithms algorithm design and analysis;software defined networking data mining pipeline processing	Openflow is a key step in abstracting network functions by separating the control and the forwarding plane. However, even with continuous innovation and evolution of the protocol, its adoption on forwarding device targets remains laborious and time consuming. In this paper, we present a semantic-based approach to packet forwarding design that tailors flow classification to the underlying switch device. Its key idea consist in streamlining flow classification through rule compiling and thus to optimize forwarding operations and improve switch resources usage. The compiling itself exploits a rule grouping gleaned through Frequent Pattern Mining and Network Calculus in optimizing flow classification w.r.t. the switch pipelined architecture.	algorithm;border gateway protocol;compiler;control plane;data mining;end-to-end principle;forwarding plane;lisp;network calculus;network packet;network switch;openflow;parsing	Salaheddine Hamadi;Khalil Blaiech;Petko Valtchev;Omar Cherkaoui;Radu State	2016	IEEE INFOCOM 2016 - The 35th Annual IEEE International Conference on Computer Communications	10.1109/INFOCOM.2016.7524421	real-time computing;computer science;operating system;distributed computing;packet forwarding;forwarding plane;packet switch;computer network	Visualization	-6.825005390409531	65.82218162259419	10498
bf733c7255b06b4f0bfdc1afa1c7142fc3986837	driving software defined networks with xsp	protocols;authorisation;protocols software switches authentication authorization topology computer architecture;software radio;telecommunication network routing authorisation protocols software radio;telecommunication network routing;router platforms software defined networks extensible session protocol sdn xsp model application driven configuration protocol framework xsp application openflow enabled network devices dynamic forwarding rule management	This paper presents the eXtensible Session Protocol (XSP), which provides a control plane for driving Software Defined Networks (SDNs). The XSP model supports proactive, application-driven configuration of dynamic network resources with support for authentication and authorization, within an extensible protocol framework. We describe XSP application use cases in SDNs using OpenFlow enabled network devices as well as dynamic forwarding rule management that can be implemented on existing router platforms.	authentication;authorization;control plane;device driver;firewall (computing);future internet;openflow;overhead (computing);router (computing)	Ezra Kissel;Guilherme Fernandes;Matthew Jaffee;D. Martin Swany;Miao Zhang	2012	2012 IEEE International Conference on Communications (ICC)	10.1109/ICC.2012.6364805	communications protocol;computer science;software-defined radio;distributed computing;authorization;computer security;computer network	DB	-16.789203074962867	83.57536890753323	10501
9f8e98be8a50adab5b8dea259d72cccd84d5b395	metadata hiding tightly binding information to content	content management;digital watermarking;intellectual property rights ipr;metadata	"""The future dramatic development of telecommunications infrastructures (next generation Internet and wide-band mobile networks) will strongly push forward the diffusion of multimedia communication services. Anyway the real effective development of such services will strongly depend on the availability of a reliable platform for managing all the issues related to the exchange of multimedia items among users through heterogeneous networks and systems. Such a need is also witnessed by the ISO MPEG21 initiative whose goal is to achieve """"an environment that is capable of supporting the delivery and use of all content types by different categories of users in multiple application domains"""". In particular some important elements which are considered by MPEG-21 still to be addressed for achieving its goal are Digital Items Identification and Description and Intellectual Property Management and Protection. Some calls have been already issued regarding the identification and description schemes: although it seems that metadata (and XML) will have an important role for addressing this issue, anyway it is evident that much work has still to be done. Future coming watermarking technologies will have thus to consider this kind of metadata, and how these will influence their behaviour. It is possible, for example, to suppose that some particular type of metadata should be hidden inside the data themselves for security/ confidentiality reasons: these metadata would be known only to those who have knowledge of them (any other person neither would notice their presence) presence) and are authorised to access them. In general this approach would make the embedded metadata independent from the particular format used for storing the image (being this requirement no satisfied if the metadata would have been embedded solely into the image header which is obviously format dependent), and resistant to format changes. In particular metadata embedding is attractive because offer the possibility to make metadata persistent through digital-to-analogue transformations. Of course the need to embed metadata inside the image raises a issue which is beginning to be addressed by watermarking research and regards the technologies to be developed for increasing the watermarking payload given a certain degree of robustness. It is presently emerging with evidence that many of the watermarking techniques developed until now are able to grant payloads that are strongly inferior to what can be theoretical estimated as the capacity limit. These results are encouraging researchers to attempt to design more powerful coding and decoding strategies.#R##N##R##N#In this paper an application for embedding, inside a digital image, metadata for identifying its IPR status is presented; this insertion has been achieved by means of a digital watermarking technique. This technology has been developed within the IST 21031 Tradex European Project. The metadata have been constructed according to the indications contained in the JPEG standard."""		Roberto Caldelli;Franco Bartolini;Vito Cappellini	2002			computer science;multimedia;internet privacy;world wide web	HCI	-31.896271284154352	87.16232091212939	10517
2f1610804ac35e71153b98817ada7442f4bd7802	network softwarization and parallel networks: beyond software-defined networks	base stations;training;maintenance engineering;telecommunication traffic software defined networking telecommunication computing telecommunication control;computational modeling;complex systems;optimization;complex networks cloud computing telecommunications traffic software defined networking resource management;network traffic flow control network softwarization parallel network software defined network complex network systems cloud computing big data service visualization application artificial networks network system operation optimization acp theory artificial society computational experiment parallel execution network resource allocation resource utilization resource management network performance network scalability network security;acp;cloud computing	The coexistence of various protocols for current network equipment leads to extremely complex network systems, which not only limit the development of network technologies, but also cannot meet the growing demands for cloud computing, big data, and service visualization applications, just to name a few. As a new network architecture, parallel networks are expected to revolutionize this situation and meet the evolving demands for network services. The main idea of a parallel network is to leverage upon software-defined networking to construct artificial networks, and then effectively optimize the network system operations via the interactions between actual and artificial networks. The foundation of the parallel network is the theory of ACP, composed of artificial societies, computational experiments, and parallel execution. By the computational experiments and analysis of the artificial network, a control strategy based on network traffic flow can be continuously updated and tracked on a real-time basis; meanwhile, the collected operating status of the actual network can also be used to optimize the model of the artificial network. These strategies can be applied to all types of network equipment to control network operations at various levels; thus, it is possible to allocate the network resources more effectively, improve the management and utilization of resources, and then provide new network solutions to effectively address the constantly evolving network demands for network performance, scalability, and security.	airline control program (acp);big data;cloud computing;coexist (image);complex network;control theory;experiment;interaction;network architecture;network performance;network traffic control;parallel computing;real-time clock;scalability;software-defined networking	Fei-Yue Wang;Liuqing Yang;Xiang Cheng;Shuangshuang Han;Jian Yang	2016	IEEE Network	10.1109/MNET.2016.7513865	maintenance engineering;element management system;network planning and design;complex systems;network traffic control;real-time computing;intelligent computer network;overlay network;network architecture;core network;heterogeneous network;open network architecture;network management station;cloud computing;computer science;base station;network information system;operating system;network simulation;distributed computing;network management application;network operations center;network access control;computational model;computer security;computer network	HPC	-14.23009115288201	84.70895468134307	10549
c4da9310c82efff91ca20f9dc0167c77f288e375	a lightweight end-side user experience data collection system for quality evaluation of multimedia communications		A lightweight evaluation system, which can be deployed on common user equipment in commercial mobile networks, is proposed for measuring the user experience of multimedia services. The user experience evaluation system can measure the key quality indicators of traditional and emerging services in different scenarios. In contrast to traffic models, this system models typical user behavior to construct complex scenarios of communication networks. In commercial network experiments, the proposed evaluation system achieves stable and efficient performance in complex scenarios, which consist of different types of services and typical user behaviors.	experiment;telecommunications network;user experience evaluation	Lei Chen;Dingde Jiang;Houbing Song;Ping Wang;Rong Bao;Kailiang Zhang;Yi Li	2018	IEEE Access	10.1109/ACCESS.2018.2794354	telecommunications network;distributed computing;computer network;type of service;user equipment;computer science;wireless;user experience design;multimedia;mobile telephony;user experience evaluation;mobile computing	Mobile	-10.265282870360373	99.44966250583437	10564
dc2abfa34490e2d3fea99913df4368121db63570	a study on secure sdp of rfid using bluetooth communication	red sin hilo;service discovery protocol;technologie communication;radiofrecuencia;radiofrequency;informatique mobile;radiofrequence;protocole transmission;reseau sans fil;maintenance;pervasive computing;wireless network;distributed computing;ad hoc network;rfid tag;red ad hoc;etiquetage;etiquetaje;informatica difusa;wireless communication;protocolo transmision;reseau ad hoc;identification radiofrequence;informatique diffuse;rfid;labelling;mantenimiento;calculo repartido;radio frequency identification;ubiquitous computing;bluetooth;wireless lan;communication technology;mobile computing;reseau local sans fil;calcul reparti;tecnologia comunicacion;transmission protocol	Recently, much research has been actively conducted for a new kind of network environment ubiquitous computing. This paper will define the essential technology called “ad hoc network” and the smart-tag technology required by a ubiquitous environment. We will describe how to apply smart-tag-related Radio Frequency Identification(RFID) research for Bluetooth, a local-area wireless-communication technology. In order to implement RFID technology for the ubiquitous-computing infrastructure, a number of important technology factors and structures should be considered. These include the realization of low-priced tags and the provision of technical service for the tag’s security. For the passive RFID tags, the functions of each RFID tag and maintenance service should be considered to guarantee the price efficiency. As for the active RF tags’ support of local-area wireless communication, one of the main issues is enhancing the level of security. This paper will present secured RF-tag service for the RF and Bluetooth modes for local-area wireless communication. A method of applying the generated service to the EPC code developed by MIT will also be suggested.	bluetooth	Dae-Hee Seo;Im-Yeong Lee;Hee-Un Park	2005		10.1007/11424826_13	radio-frequency identification;telecommunications;computer science;operating system;computer security;ubiquitous computing;computer network	HCI	-46.25694616862658	78.85383954374858	10566
b4c838e896a56e650d19f530e2edfca98a83ea1a	fault monitoring in ad-hoc networks based on information theory	medida informacion;distributed system;red sin hilo;movilidad;systeme reparti;reachability;reseau sans fil;detection panne;network monitoring;routing;surveillance;mobility;mesure information;failure detection;wireless network;routage;mobilite;ad hoc network;red ad hoc;vigilancia;sistema repartido;detection defaut;reseau ad hoc;monitoring;information measure;asequibilidad;fault detection;atteignabilite;ad hoc networks;network management;monitorage;theorie information;monitoreo;deteccion falla;information theoretic;deteccion imperfeccion;fault management;information theory;defect detection;enrutamiento;teoria informacion	Fault detection is a well-known issue in fixed wired networks. Ad-hoc networks provide new challenges towards detecting network failures: the detection task may be hindered by the impossibility to observe a given node. We propose in this paper to monitor the intermittence of network nodes in order to infer network failures. Intermittence can be caused in ad-hoc networks by benign causes due to node mobility and to time-limited out of reachability situations. Abnormal intermittence is however due to faults or malicious network activities. This paper shows how information theoretic measures can identify abnormal intermittence over the routing layer, and proposes a lightweight and distributed intermittence monitoring scheme including several fault detection methods.	abnormal end;auto-configuration;bandlimiting;fault detection and isolation;hoc (programming language);information theory;malware;optimized link state routing protocol;piggybacking (security);reachability;routing;semantic network;sensor;thresholding (image processing)	Remi Badonnel;Radu State;Olivier Festor	2006		10.1007/11753810_36	wireless ad hoc network;telecommunications;information theory;computer science;computer security;computer network	Mobile	-54.969824001888654	77.08712492400029	10581
2366e071e723880591b0ed2efdd438b216838a7b	the methodology for the selection of ict technologies for smart grids	ict technology;reliability;implementation operating parameters;smart grids availability delay quality of service resistance security;quality parameters;availability;resistance;smart power grids reliability;smart grids;smart power grids;implementation operating parameters ict technology smart power grids reliability quality parameters;quality of service;security;reliability smart grids ict technology quality parameters implementation operating parameters availability	The paper introduces Smart Grids and the methodology for the selection of ICT technologies for them. It describes the quality and implementation-operating parameters for evaluation ICT technologies and services and applications running in Smart Grids. The methodology is based on a comparison of these parameters. This methology is also based on the availability and reliability of ICT technologies. Selection of ICT technologies is demonstrated at the end of the paper.	norm (social);requirement;smart tv	Lukas Cepa;Zbynek Kocur;Jiri Vodrazka	2012	2012 35th International Conference on Telecommunications and Signal Processing (TSP)	10.1109/TSP.2012.6256186	embedded system;availability;quality of service;computer science;information security;reliability;smart grid;resistance;computer security	EDA	-29.741468444325147	62.482193250620895	10646
43acf0af51c2015605f03d303c4ea5ee1fadd5e7	on error correction in the exponent	list;desciframiento;lista;decodage;decoding;correction erreur;analyse fonctionnelle;logarithme discret;discrete logarithm;functional analysis;code reed solomon;criptografia;cryptography;error correction;cyclic group;borne inferieure;liste;cryptographie;problema diffie hellman;logaritmo discreto;codigo reed solomon;correccion error;groupe cyclique;grupo ciclico;reed solomon code;lower bound;probleme diffie hellman;diffie hellman problem;cota inferior;analisis funcional	Given a corrupted word w = (w1, . . . , wn) from a ReedSolomon code of distance d, there are many ways to efficiently find and correct its errors. But what if we are instead given (g1 , . . . , gn) where g generates some large cyclic group — can the errors still be corrected efficiently? This problem is called error correction in the exponent, and though it arises naturally in many areas of cryptography, it has received little attention. We first show that unique decoding and list decoding in the exponent are no harder than the computational Diffie-Hellman (CDH) problem in the same group. The remainder of our results are negative: – Under mild assumptions on the parameters, we show that boundeddistance decoding in the exponent, under e = d − k1− errors for any > 0, is as hard as the discrete logarithm problem in the same group. – For generic algorithms (as defined by Shoup, Eurocrypt 1997) that treat the group as a “black-box,” we show lower bounds for decoding that exactly match known algorithms. Our generic lower bounds also extend to decisional variants of the decoding problem, and to groups in which the decisional Diffie-Hellman (DDH) problem is easy. This suggests that hardness of decoding in the exponent is a qualitatively new assumption that lies “between” the DDH and CDH assumptions.	antivirus software;black box;boolean algebra;computational diffie–hellman assumption;cryptographic primitive;cryptology eprint archive;cryptosystem;decisional diffie–hellman assumption;decoding methods;diffie–hellman key exchange;diffie–hellman problem;digital signature;discrete logarithm;error detection and correction;eurocrypt;folded reed–solomon code;generic programming;graph coloring;ieee transactions on information theory;institute of electronics, information and communication engineers;list decoding;np-hardness;one-way function;polynomial;pseudorandomness;public-key cryptography;randomized algorithm;reed–solomon error correction;secret sharing;shared secret;symposium on foundations of computer science;what if	Chris Peikert	2005		10.1007/11681878_9	arithmetic;functional analysis;discrete logarithm;cyclic group;list;cryptography;mathematics;algorithm;statistics;algebra	Crypto	-38.55996850030185	80.05173073292542	10680
e47bbb9e08f6051b6c6cf6cbd62cef800086e794	temporal privacy in wireless sensor networks: theory and practice	theory and practice;sensor network;temporal information;wireless sensor network;base station;sensor networks;mean square error;temporal pattern;routing algorithm;temporal privacy;security;information theoretic;privacy	Although the content of sensor messages describing “events of interest” may be encrypted to provide confidentiality, the context surrounding these events may also be sensitive and therefore should be protected from eavesdroppers. An adversary armed with knowledge of the network deployment, routing algorithms, and the base-station (data sink) location can infer the temporal patterns of interesting events by merely monitoring the arrival of packets at the sink, thereby allowing the adversary to remotely track the spatio-temporal evolution of a sensed event. In this paper we introduce the problem of temporal privacy for delay-tolerant sensor networks, and propose adaptive buffering at intermediate nodes on the source-sink routing path to obfuscate temporal information from the adversary. We first present the effect of buffering on temporal privacy using an information-theoretic formulation, and then examine the effect that delaying packets has on buffer occupancy. We observe that temporal privacy and efficient buffer utilization are contrary objectives, and then present an adaptive buffering strategy that effectively manages these tradeoffs. Finally, we evaluate our privacy enhancement strategies using simulations, where privacy is quantified in terms of the adversary's mean square error.	adversary (cryptography);algorithm;confidentiality;encryption;information theory;mean squared error;privacy;routing;simulation;software deployment	Pandurang Kamat;Wenyuan Xu;Wade Trappe;Yanyong Zhang	2009	TOSN	10.1145/1614379.1614380	embedded system;wireless sensor network;computer science;information security;internet privacy;computer security;computer network	Security	-52.86652035304665	75.82957497812603	10685
be9b81f41b56b675245001f73c992fe37497957e	a secure and effective scheme providing comprehensive forward security to lte/sae x2 handover key management			compaq lte;key management;selective area epitaxy	Bangyi Sun;Jianfen Chu;Liang Hu;Hongtu Li;Guangkun Shi	2017	TIIS	10.3837/tiis.2017.09.023	forward secrecy;handover;computer network;key management;computer science;computer security	Security	-46.14603881985605	75.6176237970845	10690
0bf5e7b5d1b3549e86d10a9fdfb268cadff332bc	comparison of the discriminatory processor sharing policies	sojourn time;internet architecture;discriminatory processor sharing	Discriminatory Processor Sharing (DPS) policy introduced by Kleinrock [5] is of a great interest in many application areas, including telecommunications, web applications and TCP flow modelling. Under the DPS policy the jobs priority is controlled by a vector of weights. Verifying the vector of weights, it is possible to control the service rates of the jobs and optimize system characteristics. The proper vector weights selection is an important and difficult task because of the system complexity. The previously achieved results on DPS model are of Kleinrock [5], Fayolle et al. [3]. Most of the results obtained for the DPS model were collected together in the survey paper of of Altman et al. [1]. The problem of weights selection in the DPS policy when the job size distributions are exponential was studied by Avrachenkov et al. in [2] and by Kim and Kim in [4]. In [4] it was shown that the DPS policy reduces the expected sojourn time in comparison with PS policy when the weights increase in the opposite order with the means of job classes. Also in [4] the authors formulate a conjecture about the monotonicity of the expected sojourn time of the DPS policy. The idea of conjecture is that comparing two DPS policies, one which has a weight vector closer to the optimal strict priority policy vector has smaller expected sojourn time. Using the method described in [4] we prove this conjecture with some restrictions on system parameters. The proofs can be found in the technical report [6].	ergodic theory;job stream;osi model;pictbridge;time complexity;web application	Natalia Osipova	2008	CoRR		real-time computing;simulation;computer science;computer network	Metrics	-15.416988419057269	65.42926309094345	10700
3a9727d3c8424929d91cfdc58098a327bedcd945	autonomic networking: theory and practice	computer networks service oriented architecture computer network management data models computer interfaces computer architecture automation;computer networks;computer architecture;computer network management;network theory;service oriented architecture;computer interfaces;data models;automation	Summary form only given. A new genre of management applications is required to accommodate current and future uses of network services. The key to solving this problem is to realize that currently, network operation is divorced from how the business operates, and that current approaches do not address this problem. This tutorial discusses the four key foundational elements of solving this problem - use of standard information models, the transformation of these information models to a set of data models to suit the characteristics of different management data, the holistic combination of policy and process management, and a distributed interface oriented architecture that can realize the power of the previous three elements. The foundation for this tutorial lies in work done in the Telemanagement Forum's NGOSS program and the DEN-ng information model, tempered by current research in autonomic computing. After briefly covering these areas, the tutorial concentrates on new research that focuses on implementing an autonomic network - an area that has been overlooked in current research. New enhancements on the OMG's Model Driven Architecture initiative is described that enables code to be generated from formal models. This is supplemented with work on holistically combining process and policy management, and implementing this in a distributed service-oriented architecture. Real-life examples are used to reinforce the contents of this tutorial. In addition, a case study that follows the development of an MPLS VPN is used in each section to show how the concepts presented in this tutorial can be used to solve today's business problems.	autonomic computing;autonomic networking;data model;holism;information model;mpls vpn;model-driven architecture;multiprotocol label switching;service-oriented architecture;virtual private network	John Strassner	2004	2004 IEEE/IFIP Network Operations and Management Symposium (IEEE Cat. No.04CH37507)	10.1109/INM.2005.1440861	network theory;dataflow architecture;enterprise architecture framework;reference architecture;data modeling;enterprise private network;computer architecture;computing;intelligent computer network;open network architecture;computer science;applications architecture;theoretical computer science;automation;service-oriented architecture;mobile agent;solution architecture;abstract machine;computer network programming;computer network operations;data architecture;computer network	DB	-16.49400859035338	84.44987257939489	10752
49239c4f46274cb7475b84d47e202e945ad518a6	practical applications of improved gaussian sampling for trapdoor lattices		Lattice trapdoors are an important primitive used in a wide range of cryptographic protocols, such as identitybased encryption (IBE), attribute-based encryption, functional encryption, and program obfuscation. In this paper, we present software implementations of the Gentry-Peikert-Vaikuntanathan (GPV) digital signature, IBE and ciphertextpolicy attribute-based encryption (CP-ABE) schemes based on an efficient Gaussian sampling algorithm for trapdoor lattices, and demonstrate that these three important cryptographic protocols are practical. One important aspect of our implementation is that it supports prime moduli, which are required in many cryptographic schemes. Also, our implementation uses bases larger than two for the gadget matrix whereas most previous implementations use the binary base. We show that the use of higher bases significantly decreases execution times and storage requirements. We adapt IBE and CP-ABE schemes originally based on learning with errors (LWE) hardness assumptions to a more efficient Ring LWE (RLWE) construction. To the best of our knowledge, ours are the first implementations employing the Gaussian sampling for non-binary bases of the gadget matrix. The experimental results demonstrate that our lattice-based signature, IBE and CP-ABE implementations, which are based on standard assumptions with post-quantum security, provide a performance comparable to the recent state-of-the-art implementation works based on stronger/non-post-quantum assumptions.	access control;algorithm;attribute-based encryption;broadcast encryption;correctness (computer science);cryptographic primitive;cryptographic protocol;digital signature;disk encryption software;fastest;functional encryption;gaussian elimination;key generation;lattice-based cryptography;learning with errors;multi-user;obfuscation (software);oddworld: abe's oddysee;pixel;polynomial ring;post-quantum cryptography;requirement;sampling (signal processing);trapdoor function;vii	Kamil Doruk Gür;Yuriy Polyakov;Kurt Rohloff;Gerard W. Ryan;Hadi Sajjadpour;Erkay Savas	2017	IACR Cryptology ePrint Archive		computer science;functional encryption;parallel computing;cryptography;learning with errors;cryptographic protocol;encryption;digital signature;theoretical computer science;public-key cryptography;gaussian	Security	-38.31038716418653	77.57811371093067	10787
3be9c984358136fe246c3a5e24b12da403d881e1	a prototype bridge between automotive and the iot	vanet obdii can coap 6lowpan eb resources etsi cam ieee802 11p;in vehicle can obd network ieee 802 15 4 network sensor resources 6lowpan ipv6 interoperability ip communications geonetworking transport layer networking layer mac layers physical layers g5 ready module vehicular communication cam cooperative awareness message periodic transmission technical committee etsi intelligent transport system wireless devices iot network;coap;vanet;vehicles standards wireless sensor networks protocols computer aided manufacturing containers computer architecture;6lowpan;ieee802 11p;can;etsi cam;obdii;eb resources;zigbee controller area networks cooperative communication intelligent transportation systems internet of things ip networks on board communications	We present a new system integrating the in-vehicle CAN/OBD network and an IoT network of wireless devices with an Intelligent Transport System deployed following the standards released by ETSI within the Technical Committee on ITS. More specifically we have implemented periodic transmission complying with the Facilities layer of the ITS Station communication stack making use of the Cooperative Awareness Message (CAM). For vehicular communication we have integrated a fully compliant G5-ready module implementing the full stack from Physical and MAC layers (i.e. IEEE802.11p standard) to the Networking & Transport Layer supporting Geonetworking and IP communications. For the IoT we have implemented an IEEE802.15.4 network with the extension for a full IPv6 interoperability (i.e. the 6LoWPAN suite of standards) in order to allow the addressability of sensor resources on a worldwide basis.	computation;hackathon;internet of things;interoperability;logistics;prototype;service innovation;smart city	Michele Carignani;Silvia Ferrini;Matteo Petracca;Mariano Falcitelli;Paolo Pagano	2015	2015 IEEE 2nd World Forum on Internet of Things (WF-IoT)	10.1109/WF-IoT.2015.7389019	vehicular ad hoc network;embedded system;6lowpan;telecommunications;computer science;computer network	Mobile	-23.915970350904146	84.24459048746607	10834
ab931daa1ba24e524bbe85d48d0b0cd32e3b4839	an optimal resources scheduling strategy on multimedia cloud computing under multi- device constraint	cloud resources;multi-device;high dimension;regression dimensionality reduction	In view of the problem of inaccurate scheduling by using traditional resource scheduling method, because the method is mainly based on extracting and classifying the resource features to make scheduling, ignoring the effect of the feature relevance between the resources on the scheduling results. This paper presents a model for multimedia cloud resource scheduling based on multi- device constraint. In this method the objective function is no longer constrained only by the CPU computing capacity and the minimized completion time, but to achieve a minimum time-consuming of CPU, memory and other peripherals operation are considered as the scheduling objectives. Then the utilization of solving constrained jointly is employed to obtain the mapping relationship of the optimal virtual and physical machine. Moreover, a regressive dimensionality reduction algorithm is designed for this scheduling model to solve the high dimensional problems aroused by multi-device constraints. Simulation results show that the improved algorithm has a better performance than the traditional algorithm, has a good efficiency and has a certain convergence.	algorithm;central processing unit;cloud computing;dimensionality reduction;loss function;optimization problem;peripheral;relevance;scheduling (computing);simulation	Wenzhong Zhu;Hualong Jiang;Shuwen Zhou;Mike Addison	2015	Multimedia Tools and Applications	10.1007/s11042-015-3140-1	fair-share scheduling;nurse scheduling problem;fixed-priority pre-emptive scheduling;mathematical optimization;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;foreground-background;two-level scheduling;deadline-monotonic scheduling;stride scheduling;distributed computing;scheduling;least slack time scheduling;lottery scheduling;round-robin scheduling;multiprocessor scheduling;proportionally fair	HPC	-18.45108105717282	62.63673059739172	10838
43cb27e31e91cdce39dd6d6a06ae55feb4f2cd22	expected traffic reduction by content-oriented incentive in peer-assisted content delivery networks	servers peer to peer computing content distribution networks bandwidth computational modeling optimization educational institutions;telecommunication traffic incentive schemes peer to peer computing;traffic flow optimization expected traffic reduction content oriented incentive peer assisted content delivery networks large volume content files service provider traffic volume network infrastructure traffic localization network traffic altruistic client source servers traffic engineering scheme peer assisted cdn models content oriented incentive mechanism;telecommunication traffic;incentive schemes;peer to peer computing	Content services that deliver large-volume content files have been growing rapidly. In these services, it is crucial for the service provider and the network operator to minimize traffic volume in order to lower the cost charged for bandwidth and the cost for network infrastructure, respectively. To reduce the traffic, traffic localization has been discussed; network traffic is localized when requested content files are served by an other nearby altruistic client instead of the source servers. With this mechanism, the concept of the peer-assisted content delivery network (CDN) can localize the overall traffic and enable service providers to minimize traffic without deploying or borrowing distributed storage. To localize traffic effectively, content files that are likely to be requested by many clients should be cached locally. We present a traffic engineering scheme for peer-assisted CDN models. Its key idea is to control the behavior of clients by using a content-oriented incentive mechanism. This approach optimizes traffic flows by letting altruistic clients download content files that are most likely to contribute to localizing network traffic. To let altruistic clients request the desired files, we combine content files while keeping the price equal to that for a single content. We discuss the performance of our proposed algorithm considering the cache replacement algorithms.	algorithm;cache (computing);clustered file system;content delivery network;digital distribution;download;network traffic control;page replacement algorithm;simulation	Naoya Maki;Takayuki Nishio;Ryoichi Shinkuma;Tatsuro S Takahashi;Tatsuya Mori;Noriaki Kamiyama;Ryoichi Kawahara	2013	The International Conference on Information Networking 2013 (ICOIN)	10.1109/ICOIN.2013.6496421	traffic generation model;traffic policing;network traffic control;internet privacy;traffic shaping;computer security;computer network	Metrics	-16.23993256939377	74.52693725821891	10862
63145ad4318413d2e6d3444140c07cd49f815f78	scalable and secure access control policy update for outsourced big data		Abstract Ciphertext Policy Attribute-based Encryption (CP-ABE) is proven to be one of the most effective approaches to data access control in data outsourcing environment such as cloud computing since it provides efficient key management based on user attributes of multiple users in accessing shared data. However, dealing with policy update limits the efficiency of the CP-ABE. In CP-ABE scheme, the access policy is used as a core element for data encryption. Hence, if the policy is updated, the data owner needs to re-encrypt files and send them back to the cloud. This incurs overheads including computation, communication, and maintenance cost at the data owner side. The computation and communication cost are very expensive if the outsourcing environment is devoted to “big data”. In this paper, we extend the capability of our access control scheme: C-CP-ARBE to be capable of supporting secure and flexible policy updates in the big data outsourcing environment. We develop a secure policy updating algorithm and propose a very lightweight proxy re-encryption (VL-PRE) technique to enable the policy updating to be done in the cloud in an efficient and computationally cost effective manner. Finally, we demonstrate the efficiency and performance of our proposed scheme through the implementation.	access control;big data	Somchart Fugkeaw;Hiroyuki Sato	2018	Future Generation Comp. Syst.	10.1016/j.future.2017.06.014	real-time computing;access control;encryption;big data;computer science;distributed computing;outsourcing;scalability;cloud computing;data access;proxy re-encryption	Security	-41.707198754561794	67.44460008904251	10907
36aada2198e9fbbcdde3efedc6e1e5dd967d9cc3	the session token protocol for forensics and traceback	digital forensics;digital investigations;auditing and intrusion detection;intrusion detection;tcp traceback;data association;privacy	In this paper we present the Session Token Protocol (STOP), a new protocol that can assist in the forensic analysis of a computer involved in malicious network activity. It has been designed to help automate the process of tracing attackers who log on to a series of hosts to hide their identity. STOP utilizes the Identification Protocol infrastructure, improving both its capabilities and user privacy. On request, the STOP protocol saves user-level and application-level data associated with a particular TCP connection and returns a random token specifically related to that session. The saved data are not revealed to the requester unless the token is returned to the local administrator, who verifies the legitimacy of the need for the release of information. The protocol supports recursive traceback requests to gather information about the entire path of a connection. This allows an incident investigator to trace attackers to their home systems, but does not violate the privacy of normal users. This paper details the new protocol and presents implementation and performance results.	login;privacy;recursion;session id;user space	Brian D. Carrier;Clay Shields	2004	ACM Trans. Inf. Syst. Secur.	10.1145/1015040.1015041	intrusion detection system;stateless protocol;computer science;digital forensics;internet privacy;privacy;world wide web;computer security	Security	-57.11475043028263	67.84542865666168	10908
7c2b26ff2e8f79a4c87df93392f25c80242bbb19	a note on the protection level of biometric data in electronic passports	chip;radio frequency	Following regulations of the EU Council in 2004, the member states have deployed electronic passports according to ICAO standards. Such documents contain an embedded radio frequency chip for storing personal data. The chip of a first generation German passport only duplicates the information which is already printed on the passport. In the current second version there are now also two fingerprints as additional biometric attributes apart from the digital facial image of the document owner. The note at hand concentrates on attack vectors of biometric characteristics contained in the RF chip and discusses which threats towards fingerprints are thwarted. Our gist is to point to the low protection level of the facial image on the one hand and the high protection level of fingerprints on the other hand although both biometric characteristics are easy to gather.	biometric passport;biometrics;embedded system;fingerprint;gist;personally identifiable information;printing;radio frequency	Harald Baier;Tobias Straub	2009			chip;computer security;gist;computer science;biometrics	Security	-49.91753516312282	66.62158231004152	10909
62e98f9dc6a2be0efb4b86e2e04dddd7719c021e	a vector sift operator for interest point detection in hyperspectral imagery	telecommunication security ad hoc networks mobile radio telecommunication network topology;wireless devices;network security;ebatman;wireless network;wireless device;wireless environment attribute;network topology;wireless communication;computer architecture;graphical user interfaces;mobile ad hoc network security;mobile ad hoc networks;network attack ebatman emulator based testbed mobile ad hoc network security manet security wireless environment attribute bandwidth delay network topology wireless device network behavior virtual wireless network;security communication system security wireless communication mobile ad hoc networks graphical user interfaces computer architecture;mobile radio;network behavior;telecommunication security;bandwidth;ad hoc networks;mobile ad hoc network;layer 2;manet security;telecommunication network topology;security;virtual wireless network;emulator based testbed;communication system security;network attack	An algorithm for automated extraction of interest points (IP) in hyperspectral images is presented. IP are features of the image that capture information from its neighbors and are distinctive and stable under translation and rotation. IP operators for gray level images were proposed more than a decade ago and have since been studied extensively. IP are helpful in data reduction to reduce the computational burden of various algorithms by replacing an exhaustive search over the entire image domain by a probe into a concise set of highly informative points. The vector SIFT approach extends Lowe's IP operator that uses local extrema of Difference of Gaussian at multiple scales to detect interest point in gray level images by direct conversion of scalar operations such as scale-space generation, and extreme point detection into operations that take the vector nature of the image into consideration. Vector anisotropic diffusion is used for scale-space generation which enhances edges and improves IP detection. Experiments with hyperspectral images of different spatial resolutions and evaluation of IP found based on image registration is presented.	algorithm;anisotropic diffusion;brute-force search;computation;difference of gaussians;grayscale;image registration;information;interest point detection;maxima and minima;scale space;scale-invariant feature transform	Trung Nguyen;Hoai-Nam Nguyen;Yoichi Shinoda	2010	2010 2nd Workshop on Hyperspectral Image and Signal Processing: Evolution in Remote Sensing	10.1109/RIVF.2010.5632442	computer science;distributed computing;computer security;computer network	Vision	-51.13912647248351	80.16883671720521	10924
a8d96329d535ed4f791a55e25116daf36aee6383	interactive video coding and transmission over wired-to-wireless ip networks using an edge proxy	passive error-recovery;video transmission;rcpc codes;udp/ip;interactive video coding;rtp;error-control;fec;heterogeneous wired-to-wireless ip network;wired-to-wireless ip networks;acceptable video delivery quality;reed-solomon codes;robust interactive video coding;h.263+.;channel impairments;bit error;rs codes;error correction codes;differential error protection;joint source-channel coding;rate-compatible punctured convolutional codes;end-to-end architecture;packet radio networks;mobile radio;packet loss;video data;variable rate codes;video coding;mobile support station;forward error correction;fec-based error-control technique;fec coding scheme;edge proxy;combined source-channel coding;bit errors;error statistics;effective video throughput;multimedia communication;convolutional codes;appropriate joint source-channel;channel coding;computer networks;wireless networks;error control;fading;source coding;visual communication	In this paper, we address the problem of enabling robust interactive video coding and transmission over heterogeneous wired-towireless IP networks. We propose the use of an FEC coding scheme employing Reed-Solomon (RS) codes and rate-compatible punctured convolutional (RCPC) codes to protect the video data from packet loss and bit errors, respectively. Furthermore, we apply an end-to-end architecture using an edge proxy in a mobile support station to implement differential error protection for the corresponding channel impairments expected on the two networks. Results indicate that with an appropriate joint source-channel coding approach and the use of an edge proxy, FEC-based error-control techniques together with passive error-recovery techniques can significantly improve the effective video throughput and lead to acceptable video delivery quality over time-varying heterogeneous wired-to-wireless IP networks.	channel capacity;code;data compression;elegant degradation;end-to-end principle;forward error correction;internet protocol suite;network packet;reed–solomon error correction;serial experiments lain;throughput	Yong Pei;James W. Modestino	2003		10.1109/ICASSP.2003.1202624	convolutional code;real-time computing;h.263;channel code;telecommunications;computer science;wireless network;forward error correction;packet loss;fading;reed–solomon error correction;statistics;visual communication;computer network;source code	Mobile	-6.372430639657472	102.33178389357722	10948
724f60f18f64d1646ca4d62a391783f11fd74ceb	studying the effectiveness of android application permissions requests	end user license agreement;authorisation;system recovery authorisation operating systems computers;user study;information access;system recovery;privacy policy;execution environment;visual cues;privacy software facebook smart phones visualization androids humanoid robots;visual indicator android application permissions request facebook permissions based model model application user information access amazon mechanical turk text warning app download count app installation failure;operating systems computers;user acceptance	Popular platforms including Android and Facebook have adopted a permissions-based model. Under this model applications (apps) are required to declare specific access to user information required for functionality. We conducted two user studies on Amazon's Mechanical Turk to test the efficacy of these permissions requests on the Android platform. We found permissions were ineffective, even with the addition of an additional text warning. Conversely, we found that an app's download count had a strong effect on app installations. In order to determine if it was a failure of our text-based warning, we ran a second experiment with a previously proven visual indicator.	amazon mechanical turk;android;download;file system permissions;regret (decision theory);text-based (computing);the turk;usability testing	Kevin Benton;L. Jean Camp;Vaibhav Garg	2013	2013 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops)	10.1109/PerComW.2013.6529497	embedded system;privacy policy;sensory cue;computer science;operating system;authorization;internet privacy;world wide web;computer security;computer network	SE	-55.42829817326019	60.62924295644778	10965
1e613617c36385bd3404c8609dd83e222618ce1b	ntp-siot: a test tool for advanced mobile services	oma multimedia messaging service ntp siot advanced mobile services open mobile alliance service interoperability test platform 4g mobile applications;open mobile alliance;tellurium codecs encoding decoding system testing message service;mobile service;system design;multimedia communication;electronic messaging;4g mobile communication;multimedia messaging service;article;mobile application;multimedia communication 4g mobile communication electronic messaging	This article describes system design for an Open Mobile Alliance Service Interoperability Test Platform called NTP-SIOT. Based on the TTCN-3 specifications, we show how 4G mobile applications such as OMA multimedia messaging service can be tested in this platform	interoperability;mobile app;ntp server misuse and abuse;oma;systems design;ttcn-3;test automation	Yi-Bing Lin;Ching-Feng Liang;Kuei-Hui Chen;Hsin-Yu Liao	2007	IEEE Network	10.1109/MNET.2007.314534	mobile identification number;mobile search;mobile qos;3g;mobile web;imt advanced;gsm services;computer science;freedom of mobile multimedia access;mobile technology;multimedia;mobile station;mobile computing;world wide web;computer network;systems design;mobile payment	Mobile	-16.384850235472246	91.77133433746313	10966
474299e32df7336bd0cbb517874ed105080a03c1	synchronization protocol for high quality and single-point playout multimedia applications	synchronization protocol;multimedia;multimedia application;single point playout	A primary requirement in multimedia applications is the guarantee of user level services performance, such as data stream synchronization and service quality control. Necessary control mechanisms and network strategies have to be installed to satisfy this requirement. However, applications with a different user emphasis require different controlling strategies, which in turn set up the requirements for both the underlying network and upper layer application control. How to analyse various user demands and effectively implement them is the key to success. This paper describes some concerns in multimedia synchronization, and arising from the discussion, a synchronization protocol for high quality and single-point playout applications is proposed.	display resolution;playout	G. F. Zhao;K. M. Lye	1994	Computer Communications	10.1016/0140-3664(94)90095-7	real-time computing;computer science;distributed computing;data synchronization;synchronization;computer network	HPC	-14.89468408273265	93.72662275570379	10991
45fadfd157850e948d8a4e0044423f7d74b83668	malware encryption schemes - rerandomizable ciphertexts encrypted using environmental keys.		Protecting malware using encryption prevents an analyst, defending some computer(s) in the network, from analyzing the malicious code and identifying the intentions of the malware author [4, 5]. We discuss malware encryption schemes that use environmental encryption keys [11], generated from some computer(s) the malware author intends to attack, and is able to rerandomize [2, 8] ciphertexts, to make each malware sample in the network indistinguishable. We are interested in hiding the intentions and identity of the malware author, not in hiding the existence of malware.	encryption;malware	Herman Galteland;Kristian Gjøsteen	2017	IACR Cryptology ePrint Archive		computer security;encryption;key (lock);malware;computer science	Security	-54.21508507937325	65.909651780991	10992
08de57135dfd5a73f779486e28f611ade2883cd2	anonymous and secured communication using olsr in manet		Mobile ad hoc network termed as MANET is an adhoc net- work with self configuring mobile devices connected by wireless links. Currently, MANET had a greater impact on secured communication as it is a part of the ubiquitous network. Each node in the MANET is act- ing as a router itself. Routing in wireless ad hoc networks are vulnerable to traffic analysis, link spoofing, wormhole attacks and denial of service attacks as it is of infrastructure less and having highly dynamic topology. Anonymity mechanisms is used to protect the nodes against these attacks by concealing identification information of the nodes, links, traffic flows and network topology information etc. For a secured communication, se- cured routing and anonymity to the nodes is essential in adhoc networks. MANET security issues includes provisions and policies adopted to pre- vent and monitor unauthorized access to the network and to the data. Several efficient protocols are proposed specifically for MANET, from these, optimised link state routing protocol is suited for large and huge dense network. The current OLSR scheme assumes the nodes are to be trusted nodes and the anonymity is not achieved yet through OLSR. The proposed solution is for achieving anonymity and security in MANET by implementing four way handshaking between two nodes using Host Iden- tity Protocol and integrate it with OLSR for secured routing. The tech- nique expected to have a less message overhead by compared to classical flooding mechanisms and increase the security level with a preferrable bit rate. Overall, the technique provides anonymity and security in the MANET environment.	optimized link state routing protocol	A. A. Arifa Azeez;Elizabeth Isaac;Sabu M. Thampi	2011		10.1007/978-3-642-22726-4_16	optimized link state routing protocol;engineering;ad hoc wireless distribution service;internet privacy;computer security;computer network	Robotics	-54.42569913976667	75.26353918724615	11017
1576673677d9f5eef3808aa2f4b5f9437a97ca84	unguessable atoms: a logical foundation for security	event structures	We propose a new foundation for security based on a logical concept of protected information that can be enforced in the mathematical structure of a computation system. We describe a computation system based on event structures and a logic of events, and we show how to model all limitations on the capabilities of adversaries using a theory of atoms.	computation;mathematical structure;new foundations;theory	Mark Bickford	2008		10.1007/978-3-540-87873-5_7	computer science;algorithm	AI	-33.982536721693315	71.37369145995129	11046
9380b8f89bf2288a5279d7c76894c93c15348ef2	ubiquitous qos communications using scalable satellite networking	available bandwidth;satellite communication;satellite network;communication system;bandwidth allocation;sensor network;communication technologies;artificial satellites;information rate;geostationary earth orbit;low earth orbit;bandwidths;design methodology	Purpose – Satellite networking will be an important component of future ubiquitous communications systems. Satellite networks will be especially useful to interconnect remote sensor networks. Therefore, satellite networks should provide the needed QoS, differentiation of services and at the same time keep the required scalability. The purpose of this paper is to propose a new Diffserv‐based scheme of bandwidth allocation during congestion, called proportional allocation of bandwidth (PAB).Design/methodology/approach – The paper suggests a method for implementing PAB without storing per‐flow state, which makes the scheme scalable and simple and shows, by simulation, the advantages of using PAB in IP satellite networks.Findings – The paper finds that PAB can be used in geostationary earth orbit, MEO and low earth orbit satellite networks. In PAB, during congestion all flows get a share of IP available bandwidth, which is in proportion to their subscribed information rate.Originality/value – The simulations ...		Arjan Durresi;Leonard Barolli;Akio Koyama;Makoto Takizawa	2010	Int. J. Pervasive Computing and Communications	10.1108/17427371011066428	wireless sensor network;design methods;telecommunications;computer science;communications satellite;satellite;communications system;computer network;bandwidth allocation	HPC	-10.934473800979747	94.18669938971931	11058
f4c79bf09c2fecc491111b5d43d6cb0320494607	griddatabus: information-centric platform for scalable secure resilient phasor-data sharing	power quality assurance;data sharing;information centric platform;power quality;renewable energy sources;resilient phasor data sharing security;grid applications;authentication;data sharing bus security;phasor measurement unit;supply demand balance;griddatabus;phasor measurement units servers authentication delay middleware extraterrestrial measurements;smart grid applications;servers;grid operation monitoring;smart power grids;data access latency;smart power grids phasor measurement power system security;gdb;data access;information centric networking concepts;middleware;phasor measurement;pmu technology;electric vehicle;extraterrestrial measurements;data access latency griddatabus information centric platform resilient phasor data sharing security smart grid applications supply demand balance power quality assurance phasor measurement units grid operation monitoring pmu technology information centric networking concepts gdb data sharing bus security;phasor measurement units;power system security	The advent of new Smart Grid applications such as electric vehicles and renewable energy sources are imposing challenging requirements on the stability and operation of the grid. This challenge is critical in the areas of supply-demand balance and power quality assurance. To address this challenge, phasor measurement units (PMUs) are being deployed to monitor grid operations. A major impediment to the widespread use of this PMU technology is a lack of secure, scalable, and resilient data sharing infrastructure. Applying information-centric networking concepts we have designed GridDataBus (GDB), a secure data sharing bus. Through evaluation, we show the scalability and performance of GDB in terms of data access latency.	data access;electric power quality;gnu debugger;phasor;power management unit;requirement;scalability	Young-Jin Kim;Jae Hwan Lee;Gary Atkinson;Marina Thottan	2012	2012 Proceedings IEEE INFOCOM Workshops	10.1109/INFCOMW.2012.6193471	renewable energy;data access;embedded system;computer science;operating system;middleware;authentication;computer security;server;computer network	HPC	-29.29834823858669	62.058768902441955	11082
1800fd7c75b3a17de1b6212316764a0817a39816	qos class mapping over heterogeneous networks using application service map	quality of service next generation networking diffserv networks application software sun computer networks telecommunication services standardization concatenated codes delay;end to end qos;next generation network;application software;computer networks;sun;diffserv networks;telecommunication services;concatenated codes;quality of service;next generation networking;standardization;heterogeneous network	Each network has its own distinct quality of service (QoS) class. To support end-to-end QoS QoS class interwoking between different network technologies is very important function especially in Next Generation Networks (NGN). QoS mapping between different networks technologies are broadly categorized as mapping between parameters and mapping between classes in each different networks. However, these methods have some problems that the the former is too complicated to implement or the latter may execute uncetrain mapping between networks because of granularity QoS class. So in this paper we present two QoS class mapping methodologies over heterogenous networks to provide end-to-end QoS support for application services. And we propose a QoS class mapping method in different transport techonologies mixed circumstance using Application Service Map (ASM) which classifies application services based on performance requirements. Ths mapping method is based on location information of ASM to determine QoS class according to underlying techonology. The proposed mapping method can easy to accept new coming application services without alternation or modification and it can provide users with the more refined QoS.	categorization;end-to-end principle;next-generation network;quality of service;requirement	Mi-Sun Ryu;Hong-Shik Park;Sang-Chul Shin	2006	International Conference on Networking, International Conference on Systems and International Conference on Mobile Communications and Learning Technologies (ICNICONSMCL'06)	10.1109/ICNICONSMCL.2006.177	real-time computing;mobile qos;next-generation network;computer science;distributed computing;computer network	Robotics	-12.465260374870724	93.1815662949253	11100
bec2531e9112dd5372484cd39eb9859204c0c828	gang scheduling in a two-cluster system implementing migrations and periodic feedback	gang scheduling;performance;simulation;scheduling policies;cluster system;distributed systems;modeling	In order to maximize the efficiency of a complex distributed system such as a grid, a proper scheduling algorithm is necessary. The scheduling algorithm is responsible for allocating the available system resources to the existing jobs. In this paper, we consider scheduling gangs in a multi-cluster system in the presence of critical jobs which arrive in a sporadic manner. We examine an adaptive grid scheduler with periodic feedback which allocates the existing jobs to the available clusters. A migration scheme is implemented in order to alleviate the impact of critical sporadic jobs on the performance of gang scheduling. A simulation model is used to provide results on the performance of the system.	gang scheduling;scheduling (computing)	Zafeirios C. Papazachos;Helen D. Karatza	2011	Simulation	10.1177/0037549710371218	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;simulation;systems modeling;gang scheduling;flow shop scheduling;performance;dynamic priority scheduling;computer science;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;deadline-monotonic scheduling;distributed computing;scheduling;lottery scheduling;round-robin scheduling;multiprocessor scheduling	Arch	-13.117487582925387	63.43006651370203	11113
0fa6d77e01de48d1e1fa20c0b47e90506c3e184c	distributed computing jobs scheduling improvement using simulated annealing optimizer	computers;scientific application;concurrent computing;processor scheduling;resource allocation;distributed processing;performance;delayed job;biological system modeling;distributed computing;simulated annealing;computer networks;qa75 electronic computers computer science;total tardiness distributed computing job scheduling simulated annealing optimizer load balancing scientific application scheduling algorithm delayed job makespan time;scheduling algorithm;computational modeling;performance scheduling grid computing simulated annealing;distributed computing system;optimal scheduling;distributed computing processor scheduling computational modeling simulated annealing scheduling algorithm computer networks grid computing concurrent computing biological system modeling optimal scheduling;scheduling;load balancing;schedules;tabu search;total tardiness;load balance;makespan time;grid computing;simulated annealing optimizer;job scheduling;simulated annealing distributed processing resource allocation scheduling;dynamic scheduling	Over the past decade, scheduling in distributed computing system has been an active research. However, it is still difficult to find an optimal scheduling algorithm to achieve load balancing for a specific scientific application which is executed in an unpredictable environment. This is due to the complex nature of the application which changes during runtime and due to the dynamic nature and unpredictability of the computational environment. This paper addresses these issues by presenting a Simulated Annealing (SA) approach as an optimizer which is an improved version of EG-EDF with Tabu Search optimizer. Instead of using Tabu Search, this work used SA to optimize the scheduling algorithm. The scheduling algorithms have been evaluated using three main criteria; number of delayed jobs, makespan time and total tardiness. Our results show the improvements to the main criteria mentioned.	algorithm;computation;distributed computing;earliest deadline first scheduling;environment variable;eurographics;heuristic (computer science);load balancing (computing);makespan;mathematical optimization;particle swarm optimization;scheduling (computing);simulated annealing;tabu search	Zafril Rizal M. Azmi;Kamalrulnizam Abu Bakar;Abdul Hanan Abdullah;Mohd Shahir Shamsir	2009	2009 11th International Conference on Computer Modelling and Simulation	10.1109/UKSIM.2009.76	fair-share scheduling;nurse scheduling problem;parallel computing;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;distributed computing;round-robin scheduling	HPC	-16.154596462755478	61.20640314327848	11157
d0ee1e945ffa711c1c37dd07c1856c252ee1602f	dynamic packet scheduling for cdma2000 1×ev-do broadcast and multicast services	slot based static scheduling algorithm;multicast communication;multicast algorithms;cdma2000;mpeg 4 fine granular scalability dynamic packet scheduling cdma2000 1 spl phi ev do scheduling broadcast services multicast services bcmcs multimedia data services slot based static scheduling algorithm retransmission scheme earliest deadline first real time scheduling;earliest deadline first;earliest deadline first real time scheduling;real time;mobile communication system;multicast services;packet radio networks;packet scheduling algorithm;satisfiability;multimedia systems;multimedia communication 3g mobile communication packet radio networks broadcast channels multicast communication;scheduling algorithm multimedia communication dynamic scheduling streaming media multicast algorithms 3g mobile communication digital multimedia broadcasting multimedia systems heuristic algorithms mpeg 4 standard;dynamic environment;scheduling algorithm;digital multimedia broadcasting;mpeg 4 standard;fine granular scalable;1φev do scheduling;3g mobile communication;streaming media;broadcast channels;heuristic algorithms;multimedia data services;real time scheduling;multimedia data;multimedia communication;packet scheduling;broadcast services;mpeg 4 fine granular scalability;retransmission scheme;bcmcs;dynamic scheduling;dynamic packet scheduling	cdma2000 1xEV-DO, one of the prominent thirdgeneration mobile communication systems, provides Broadcast and Multicast Services (BCMCS) to meet increasing demand for multimedia data services. Currently, 1xEV-DO schedules broadcast streams using a slot-based static algorithm, which fails to support dynamic environments where broadcast content is added or removed on-line. We propose a dynamic packetscheduling algorithm that works with a retransmission scheme for the BCMCS scheduler. Integrated with Earliest Deadline First (EDF) real-time scheduling, the proposed algorithm not only adapts to dynamic contexts efficiently but also satisfies the real-time requirements of broadcast streams. Furthermore, by exploiting the fine granular scalable (FGS) characteristics of the MPEG-4 Part 2 standard, our scheme can avoid abrupt degradation of playback quality by protecting the most important data. Extensive simulations have quantitatively validated the efficiency of our approach.	algorithm;bit error rate;earliest deadline first scheduling;elegant degradation;folded reed–solomon code;multicast;network packet;online and offline;real-time clock;reed–solomon error correction;requirement;retransmission (data networks);scalability;scheduling (computing);simulation;slack variable;streaming media;unicast;whole genome sequencing	Kyungtae Kang;Jinsung Cho;Heonshik Shin	2005		10.1109/WCNC.2005.1424889	broadcast radiation;real-time computing;earliest deadline first scheduling;atomic broadcast;dynamic priority scheduling;computer science;operating system;distributed computing;multimedia broadcast multicast service;scheduling;computer network;cdma2000;satisfiability	Mobile	-6.540613256694767	101.00466033745082	11162
0a268e13cb061b619bf62907bb2c51913cd1cf16	is sha-1 conceptually sound?	block cipher;minimum distance;linear code;hash function	We argue that if the message expansion code of SHA-1 is replaced by a linear code with a better minimum distance, then the resulting hash function is collision resistant. To support this argument, we characterize the disturbance vectors which are used to build local collision attacks as a linear code. This linear code is the xor-sum of two codes, the message expansion code and a linear code representing the underlying block cipher in SHA-1. We also show that the following constraint satisfaction problem is NP-hard. The constraints are restricted to being XOR constraints, or Majority constraints on at most three variables each. The instances are further restricted by requiring that the constraints can be listed in a sequence C 1 ; C 2 ; ; C m , such that for every constraint C i , two of the variables in it occur only in constraints C j , with jj ? ij < 48. This problem is similar to the problem modeling the one-way function property of SHA-1.	algebraic modeling language;block cipher;collision attack;collision resistance;constraint satisfaction problem;exclusive or;hash function;linear code;np-hardness;one-way function;sha-1	Charanjit S. Jutla;Anindya C. Patthak	2005	IACR Cryptology ePrint Archive		arithmetic;transposition cipher;double hashing;residual block termination;hash function;perfect hash function;ciphertext stealing;block cipher mode of operation;theoretical computer science;skein;hash chain;hash buster;mathematics;rolling hash;stream cipher;affine cipher;cbc-mac;algorithm;cryptographic hash function;fowler–noll–vo hash function;mdc-2;hash filter	Crypto	-37.146169592335326	81.43770266043066	11197
56b87153e300037ca97668025352e230f6812ab1	structural identity-based encryption	hibe;sibe	In this paper, we introduce the concept of structural identitybased encryption (SIBE). Similar to hierarchical identity-based encryption (HIBE), entities in the system are organized into hierarchy. An entity in SIBE can decrypt ciphertext for all its ancestors. It can be seen as an opposite of HIBE, where an entity can decrypt the ciphertext for all its descendants. We formalize the notion and security requirements, propose an efficient construction and show that our construction is secure under appropriate assumptions in the random oracle model.	advanced tactical center;authentication;call of duty: black ops;ciphertext;copy protection;cryptanalysis;edward wegman;entity;eurocrypt;hash function;id-based encryption;mark n. wegman;random oracle;requirement;victor shoup	Man Ho Au;Siu-Ming Yiu	2007	IACR Cryptology ePrint Archive		theoretical computer science;56-bit encryption;ciphertext;encryption;watermarking attack;deterministic encryption;plaintext-aware encryption;probabilistic encryption;computer science;multiple encryption	Crypto	-40.93656407542503	76.54719968530976	11207
984c930183e24486d3a2e1d76f8a052d28ea64bc	towards cost efficient mobile service and information management in ubiquitous environment with cloud resource scheduling	service composition;cost efficient;mobile service;68 06;68m01;cloud computing	The past few years have witnessed an explosive popularity of mobile services, especially in the form of smart phone applications. To cope with the limited batteries and computational capacities of mobile devices, prior studies suggest to deploy service instances in clouds for accomplishing most of the computation-intensive tasks. Service composition, which compensates for the simplicity of single service, is an effective way to utilize the plentiful services on the clouds all over the world. In this paper, we focus on the problem of service instance selection with service instance replica limitation constraint. The objective is to select the optimal set of service instances, which composes the integrated service and brings out the optimal QoS (quality of service), in terms of service response time. To characterize the problem, we establish a new QoS model, which considers the comprehensive quality over all users, not just for any single user or service instance. We prove that the problem is NP-hard, since many functionally equivalent service instances spread all over the distributed clouds. To address the problem, we classify the problem into three cases, including two special cases and the general case. We present two effective heuristic algorithms to determine the service instances selection for the two special cases, which are still NP-hard. The two special cases provide empirical bounds for the general case. We propose an algorithm that simulates a vote procedure for the users in the general case. The selected service instances, which come from the vote procedure, can satisfy a majority of users. We conduct extensive simulations for all of the algorithms. The simulation results show that our algorithms work efficiently on service response time reduction.	cost efficiency;information management;scheduling (computing)	Xin Li;Zhuzhong Qian;Ilsun You;Sanglu Lu	2014	Int J. Information Management	10.1016/j.ijinfomgt.2013.11.007	best-effort delivery;mobile qos;simulation;cloud computing;computer science;knowledge management;distributed computing;data as a service;world wide web;cost efficiency	DB	-20.02618454772011	65.12069771270014	11220
e52065137a2ee7f586abb8f74ad1d77cfcf6c565	rent to pwn: analyzing commodity booter ddos services		Distributed denial-of-service (DDoS) attacks, the practice by which a malicious party attempts to disrupt a host or network service, has become an increasingly common and effective method of attack. In this article, we summarize what we have learned while investigating the phenomenon of what are called booter or stresser services. These booter services began as a tool used by video-game players to gain an advantage by slowing or disrupting their opponents network connection for a short period of time; however, as these services have become increasingly commercialized, they have morphed into powerful, reliable, and easy to use general purpose DDoS services that can be linked to several attacks against non-gamer Web sites. We begin with an overview of DDoS techniques. We then outline the common capabilities and infrastructure used by these booter services supported with information found on underground forums that market and review such services. Finally, we present empirical measurements of one particular booter, known as TwBooter, based on a publicly leaked dump of their operational database and our own measurements of their attack capabilities.		Mohammad Karami	2013	;login:			Security	-58.09607894527584	63.78897844530268	11227
6651eeb17bea8a7fd083d2102562875b4488a752	resource-aware allocation strategies for divisible loads on large-scale systems	silicon;preemptive scheduling;single machine scheduling;approximation algorithms;divisible loads;processor scheduling;resource allocation;probability density function;resource management;large scale system;data mining;resource management large scale systems costs laboratories approximation algorithms heuristic algorithms single machine scheduling scheduling algorithm grid computing context;preemptive scheduling resource aware allocation divisible loads large scale systems;large scale;scheduling algorithm;servers;single machine;scheduling;heuristic algorithms;scheduling resource allocation;grid computing;resource aware allocation;context;large scale systems	In this paper, we deal with the large-scale divisible load problem studied in [12]. We show how to reduce this problem to a classical preemptive scheduling problem on a single machine, thereby establishing new complexity results, and providing new approximation algorithms and heuristics that subsume those presented in [12]. We also give some hints on how to extend the results to a more realistic framework where communication costs are taken into account.	approximation algorithm;heuristic (computer science);scheduling (computing)	Anne Benoit;Loris Marchal;Jean-Francois Pineau;Yves Robert;Frédéric Vivien	2009	2009 IEEE International Symposium on Parallel & Distributed Processing	10.1109/IPDPS.2009.5160912	parallel computing;real-time computing;computer science;resource management;operating system;distributed computing;scheduling	Arch	-16.480521732088086	61.156962676049694	11232
9f03e8a09cbc80b67119df595257e48c85d98bc2	anonymous signcryption in ring signature scheme over elliptic curve cryptosystem	and anonymity;ring signature;elliptic curve cryptosystem;signcryption	This study presents an anonymous signcryption scheme based on the elliptic curve cryptosystem, which combines the properties of elliptic curve cryptosystem and ring signature. While the signers are endowed with anonymity through the technique of ring signature, the elliptic curve cryptosystem achieves the advantages of high security, low computation load, and small bandwidth requirements. To integrate the advantages of these two applications, the resulting system reaches a highly secure and efficient anonymous signcryption scheme. Signcryption makes a session key unnecessary to be established in advance for each session; hence, transmission load is reduced, and efficiency of performance and transmission is enhanced.	antivirus software;computation;cryptosystem;digital signature;ecc memory;encryption;national supercomputer centre in sweden;requirement;ring signature;session key;signcryption;symmetric-key algorithm	Yu-Fang Chung;Zhen Yu Wu;Feipei Lai;Tzer-Shyong Chen	2006		10.2991/jcis.2006.235	elliptic curve digital signature algorithm;signcryption;elliptic curve cryptography	Security	-47.156251833815894	76.0545385205813	11245
b6382f3d5b894afb92d85f18aa27b1d6dbae5aaa	multi-objective optimization based virtual resource allocation strategy for cloud computing	energy efficiency;energy conservation;optimisation;servers cloud computing resource management power demand optimization energy efficiency energy consumption;energy efficient;resource allocation;virtual resource allocation;resource manager;resource management;multi objective optimization;computer centres;power aware computing;large scale;data center;servers;virtual machines;energy consumption;vm cloud computing large scale data centers energy consumption energy efficiency virtual resource allocation multiobjective optimization problem intelligent optimization algorithm;optimization;virtual machines cloud computing computer centres energy conservation optimisation power aware computing resource allocation;optimal algorithm;power demand;multi objective optimization problem;multi objective optimization cloud computing virtual resource allocation green computing energy efficiency;green computing;cloud computing	The increasing requirements on cloud computing entail building up large numbers of large-scale data centers which require a surprising amount of energy. With the gradual depletion and price escalation of traditional energy, operating data center in an energy efficient way is an emerging urgent problem. However, most existing researches of resource allocation in datacenter did not take into full consideration how to decrease energy consumption. In this paper, we formulate the energy efficiency virtual resource allocation for cloud computing as a multi-objective optimization problem, which is then solved by intelligent optimization algorithm. The simulation results reveal that the strategy can successfully generate schedule scheme of different numbers of servers-VMs with diverse characteristics in a reasonable time period and decrease the total operating energy of data center effectively.	algorithm;cloud computing;data center;depletion region;mathematical optimization;multi-objective optimization;optimization problem;privilege escalation;requirement;simulation	Li Xu;Zhibin Zeng;Xiucai Ye	2012	2012 IEEE/ACIS 11th International Conference on Computer and Information Science	10.1109/ICIS.2012.74	real-time computing;simulation;computer science;distributed computing	HPC	-20.460523671714046	62.937307027505675	11267
b3858a7df9087a9a9104551e8aa8cf5dc1e3e093	evaluation analysis of the performance of ieee 802.11b and ieee 802.11g standards	isolation technology;spine;routing;performance analysis wireless lan mobile communication isolation technology wireless application protocol wireless communication local area networks spine routing access protocols;wireless application protocol;wireless communication;apel applied electronics laboratory;mobile communication;performance analysis;access protocols;wireless lan;simulation tool;local area networks	The IEEE 802.11 Wireless LAN standard is one of the most popular wireless standards in the market today. Since 1997 when the first version of the IEEE 802.11 was launched in the market, a lot of different versions has been announced and developed. In this paper, a comprehensive evaluation analysis of the IEEE 802.11b and IEEE 802.11g has been carried out, examining the performance of both standards at the MAC sub-layer, in terms of QoS, using two different simulation tools. Finally, the comparison for both cases is discussed.	quality of service;simulation	Antonis Athanasopoulos;Evangelos Topalis;Christos P. Antonopoulos;Stavros A. Koubias	2006	International Conference on Networking, International Conference on Systems and International Conference on Mobile Communications and Learning Technologies (ICNICONSMCL'06)	10.1109/ICNICONSMCL.2006.92	local area network;ieee 802.11s;xpress technology;service set;wi-fi;routing;neurfon;ieee 802.11;ieee 802.11w-2009;spine;ieee 802.1x;mobile telephony;ieee 802;wireless application protocol;telecommunications;inter-access point protocol;ieee 802.11b-1999;computer science;operating system;ieee 802.11u;ieee 802.11h-2003;wireless lan controller;capwap;ieee 802.11r-2008;wi-fi array;computer security;wireless;computer network;ieee 802.11e-2005	Visualization	-17.762106226698293	91.00055047906503	11283
9a17808a77e82b48688f33790cc54f7a1a0f66ee	kd-trees and the real disclosure risks of large statistical databases	attribute disclosure;statistical disclosure control;kd trees;article;real disclosure risk;record linkage	Estimating the disclosure risk of a Statistical Disclosure Control (SDC) protection method by means of (distance-based) record linkage techniques is a very popular approach to analyze the privacy level offered by such a method. When databases are very large, some particular record linkage techniques such as blocking or partitioning are usually applied to make this process reasonably efficient. However, in this case the record linkage process is not exact, which means that the disclosure risk of a SDC protection method may be underestimated. In this paper we propose the use of kd-trees techniques to apply exact yet very efficient record linkage when (protected) datasets are very large. We describe some experiments showing that this approach achieves better results, in terms of both accuracy and running time, than more classical approaches such as record linkage based on a sliding window. We also discuss and experiment on the use of these techniques not to link a whole protected record with its original one, but just to guess the value of some confidential attribute(s) of the record(s). This fact leads to concepts such as k-neighbor l-diversity or k-neighbor p-sensitivity, a generalization (to any SDC protection method) of l-diversity or p-sensitivity, which have been defined for SDC protection methods ensuring k-anonymity, such as microaggregation.	database	Javier Herranz;Jordi Nin;Marc Solé	2012	Information Fusion	10.1016/j.inffus.2011.03.001	record linkage;computer science;k-d tree;data mining;database;computer security;statistics	DB	-39.724836813353896	64.00590402198041	11294
12a0352149c7cdaecdb7741b2a61ffcbad567ced	modeling fixed priority non-preemptive scheduling with real-time calculus	controller area network can;preemptive scheduling;real time systems calculus time factors computational modeling processor scheduling titanium bismuth;can bus;processor scheduling;bismuth;real time;controller area networks;real time embedded system;controller area network;fixed priority;schedulability analysis;real time embedded systems;field buses;rtc toolbox;embedded systems;computational modeling;time factors;controller area network can real time scheduling non preemptive fixed priority scheduling real time calculus;complex system;scheduling;calculus;real time scheduling;non preemptive fixed priority scheduling;can bus fixed priority nonpreemptive scheduling real time calculus real time embedded systems complex systems compositional analysis holistic scheduling analysis controller area network rtc toolbox;real time calculus;holistic scheduling analysis;complex systems;scheduling calculus controller area networks embedded systems field buses large scale systems real time systems;fixed priority scheduling;compositional analysis;fixed priority nonpreemptive scheduling;titanium;large scale systems;real time systems	Modern real-time embedded systems are highly heterogeneous and distributed. As a result, compositional methods play an important role in the design and analysis of such complex systems. One such compositional analysis method is based on real-time calculus. In this paper, we present an analysis of fixed priority non-preemptive scheduling with the real-time calculus. Although fixed priority non-preemptive scheduling was modeled with the real-time calculus previously, we show that the model gives overly pessimistic results. We also compare our analysis with the existing holistic scheduling analysis through an example of a system using a controller area network (CAN) bus. The proposed method can be automated by incorporating it in the RTC toolbox.	can bus;complex systems;embedded system;holism;preemption (computing);real-time clock;real-time computing;real-time operating system;scheduling (computing)	Devesh B. Chokshi;Purandar Bhaduri	2008	2008 14th IEEE International Conference on Embedded and Real-Time Computing Systems and Applications	10.1109/RTCSA.2008.28	fair-share scheduling;priority inheritance;embedded system;complex systems;real-time computing;can bus;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;distributed computing;round-robin scheduling	Embedded	-9.18451607982042	61.040028943452704	11312
27841037038911f523991bca6c01537885b2b3f2	service level agreements in a rental-based system	service level;measurement;cost effective scheduling;cost effective scheduling service level agreements grid computing cloud computing;high performance computing;processor scheduling;contract law;service level agreements;rental based policies;contracts;satisfiability;runtime;contract duration;software architecture;sla parameters service level agreement system scheduling rental decision high performance computing application driven requirement load estimation contract duration rental based policies;system scheduling;sla parameters;business data processing;scheduling;rental decision;high performance computer;load estimation;application driven requirement;cost effectiveness;service level agreement;organizations;contracts runtime quality of service processor scheduling scheduling measurement organizations;rental;quality of service;grid computing;software architecture business data processing contract law rental scheduling;cloud computing	In this paper, we investigate how Service Level Agreeements (SLAs) can be incorporated as part of the system’s scheduling and rental decisions to satisfy the different performance promises of high performance computing (HPC) applications. Such SLAs are contracts which specify a set of application-driven requirements such as the estimated total load, contract duration, total utility value and the estimated total number of generated jobs. We present several scheduling and rental based policies that make use of these SLA parameters and demonstrate the effectiveness of such policies to accurately predict and plan for resource levels in a rental-based system.	job stream;optimistic concurrency control;quality of service;requirement;run time (program lifecycle phase);scheduling (computing);service-level agreement;supercomputer	Amril Nazir;Hao Liu;Søren-Aksel Sørensen	2010	2010 10th IEEE International Conference on Computer and Information Technology	10.1109/CIT.2010.460	software architecture;supercomputer;real-time computing;cost-effectiveness analysis;quality of service;service level;cloud computing;computer science;organization;operating system;distributed computing;utilization;scheduling;grid computing;measurement;satisfiability	HPC	-22.907232207195854	62.803280736131626	11326
7138fd589291d0aeb69e73f051b4fda219a367af	a game-theoretic approach for cooperation stimulation in peer-to-peer streaming networks	video streaming client server systems cooperative communication game theory internet multimedia communication peer to peer computing resource allocation;bandwidth games peer to peer computing resource management streaming media channel allocation multimedia communication;game theory;video streaming;resource allocation;client server systems;internet;cooperative communication;resource allocation scheme game theoretic approach cooperation stimulation peer to peer streaming networks video streaming quality bandwidth requirement server client based counterparts multimedia content internet current p2p streaming systems credit based incentive mechanism service differentiation biased resource allocation stackelberg game optimal resource allocation strategy utility functions;multimedia communication;peer to peer computing	With high scalability, high video streaming quality, and low bandwidth requirement, peer-to-peer (P2P) streaming systems are gradually replacing their server-client-based counterparts in the realm of delivering multimedia content over the internet. However, current P2P streaming systems are suffering from “free-riding” due to the peers' selfish nature. In this paper, we propose a credit-based incentive mechanism to encourage peers to cooperate with each other. The proposed mechanism provides service differentiation for peers with different credits and connection types through biased resource allocation. A Stackelberg game is formulated to obtain the optimal resource allocation strategy, which can jointly maximize the revenue of the uploader and the utilities of the downloaders. Especially, the selfish nature of peers is taken into consideration when designing the utility functions of the Stackelberg game. It is shown that the proposed resource allocation scheme is effective in providing service differentiation for peers and stimulating them to make contribution to the P2P streaming system.	game theory;peer-to-peer;scalability;server (computing);streaming media;upload	Xin Kang;Yongdong Wu	2013	2013 IEEE International Conference on Communications (ICC)	10.1109/ICC.2013.6654869	game theory;the internet;resource allocation;distributed computing;multimedia;computer network	HPC	-9.22736937484173	97.9077417668881	11327
7d9f5331cf86022fc1fd8cabd601f084e8628b30	reconfiguration of virtual network mapping considering service disruption	resource allocation computer networks integer programming linear programming;resource allocation;computer networks;service disruption ilp problem integer linear programming virtual network request virtual network reconfiguration virtual network mapping problem efficient resource allocation virtual network operator network virtualization;integer programming;linear programming;dynamic network reconfiguration network virtualization virtual network mapping;decision support systems manganese next generation networking	Network Virtualization (NV) offers an efficient usage of resource by sharing the infrastructure with different virtual network operators while deploying new services. However, it also raises new challenges for network operators and researchers [1]. One of the main challenges is the efficient resource allocation, known as virtual network (VN) mapping problem. In a dynamic scenario, where VN requests come and leave dynamically, the ability to reallocate the currently-mapped networks allows to enhance the resource utilization. But it also leads to the service disruption of reconfigured virtual networks. In this paper, we study the problem of virtual network reconfiguration taking into account the cost incurred by the disrupted services. Most of the recent research on this topic just focused on the acceptance ratio of the virtual networks but didn't address the possible service disruption during the reconfiguration. This paper proposes a reconfiguration mechanism, which is triggered whenever a new coming virtual network request cannot be mapped on the current network. The mechanism re-allocates the currently-mapped networks to accommodate the new request, provided that the minimized cost of reconfiguration doesn't not exceed the gain from mapping the new request. The approach is mathematically formulated as Integer Linear Programming (ILP) problem that maximizes the net gain of the reconfiguration. Its performance is then evaluated and analysed thoroughly through extensive simulations. Finally, a heuristic is proposed to shorten the solving time of the ILP problem while maintaining its performance.	denial-of-service attack;heuristic;integer programming;linear programming;network mapping;nv network;simulation	Phuong Nga Tran;Andreas Timm-Giel	2013	2013 IEEE International Conference on Communications (ICC)	10.1109/ICC.2013.6655090	real-time computing;intelligent computer network;integer programming;resource allocation;computer science;linear programming;theoretical computer science;operating system;network simulation;distributed computing;computer network	HPC	-11.064802920648683	82.18718067266906	11337
064dffb17036b3bcbb23503963ed94b6ccc76536	can we sniff wi-fi?: implications of joffe v. google	google;ecpa;802 11;surveillance;wireless lan computer network security computer science education law;law;joffe v google;wireless communication;ieee 802 11 standards google cryptography wireless communication communication system security legal aspects surveillance computer security ieee 802 11 standards;cryptography;privacy wi fi 802 11 joffe v google surveillance electronic communications privacy act ecpa;ieee 802 11 standards;electronic communications privacy act;wi fi;privacy;student exercise unencrypted wireless local area networks wi fi sniffing us wiretap act google street view vehicles unencrypted wi fi frame radio communications interception computer security education;communication system security	On 27 December 2013, the US Court of Appeals for the Ninth Circuit issued an opinion that intercepting data from unencrypted wireless local area networks - Wi-Fi sniffing - can violate the US Wiretap Act. The case centers on a Wi-Fi sniffer that was present in Google Street View vehicles that roamed the US between 2008 and 2010 and that were permanently recording every unencrypted Wi-Fi frame that they intercepted. Although the Wiretap Act has a broad exemption for intercepting radio communications that are generally accessible to the public, the Court ruled that Wi-Fi is not a radio communication. The ruling, if it stands, will significantly impact computer security education, in which Wi-Fi sniffing is a common student exercise; security practitioners, who frequently sniff for security assessments; and computer security research, which has traditionally used collection in the wild as a way of finding vulnerabilities.	computer security;google street view;packet analyzer;plaintext;vulnerability (computing)	Simson L. Garfinkel;Michael McCarrin	2014	IEEE Security & Privacy	10.1109/MSP.2014.64	telecommunications;computer science;cryptography;internet privacy;privacy;computer security	Security	-53.90814691260069	67.94535955399655	11355
028a5485b01a1214749ce6354ccee1cda37da702	performance of peer-to-peer networks: service capacity and role of resource sharing policies	p2p system;fairness;peer to peer network;incentive;resource allocation;p2p;service capacity;performance improvement;resource sharing;file sharing;peer to peer	In this paper we model and study the performance of peer-to-peer (P2P) file sharing systems in terms of their ‘service capacity’. We identify two regimes of interest: the transient and stationary regimes. We show that in both regimes, the performance of P2P systems exhibits a favorable scaling with the offered load. P2P systems achieve this by efficiently leveraging the service capacity of other peers, who possibly are concurrently downloading the same file. Therefore to improve the performance, it is important to design mechanisms to give peers incentives for sharing/cooperation. One approach is to introduce mechanisms for resource allocation that are ‘fair’, such that a peer’s performance improves with his contributions. We find that some intuitive ‘fairness’ notions may unexpectedly lead to ‘unfair’ allocations, which do not provide the right incentives for peers. Thus, implementation of P2P systems may want to compromise the degree of ‘fairness’ in favor of maintaining system robustness and reducing overheads.	convex set;download;eisenstein's criterion;fairness measure;feasible region;file sharing;image scaling;peer-to-peer;proportionally fair;stationary process;system dynamics;upload;x window system	Xiangying Yang;Gustavo de Veciana	2006	Perform. Eval.	10.1016/j.peva.2005.01.005	shared resource;incentive;resource allocation;computer science;peer-to-peer;distributed computing;computer security;file sharing;computer network	Metrics	-25.314951357510207	73.53296803437625	11370
540d7c8fd071212c3697f4b7c0b685e92587f461	measuring data and voip traffic in wimax networks	satisfiability;internet architecture;quality of service;high speed;mac layer	Due to its large coverage area, low cost of deployment and high speed data rates, WiMAX is a promising technology for providing wireless last-mile connectivity. Physical and MAC layer of this technology refer to the IEEE 802.16e standard, which defines 5 different data delivery service classes that can be used in order to satisfy Quality of Service (QoS) requirements of different applications, such as VoIP, videoconference, FTP, Web, etc. The main aim of the paper is to examine a case of QoS deployment over a cellular WiMAX network. In particular, the paper compares the performance obtained using two different QoS configurations differing from the delivery service class used to transport VoIP traffic, i.e. UGS or ertPS. Results indicate that for delay-sensitive traffic that fluctuates beyond its nominal rate, having the possibility to give back some of its reserved bandwidth, ertPS has the advantage to permit the transmission of BE traffic.	last mile;quality of service;requirement;scheduling (computing);software deployment;throughput	Iwan Adhicandra	2010	CoRR		real-time computing;quality of service;telecommunications;computer science;computer network;satisfiability	Mobile	-11.616334237111603	93.38331370938326	11373
899cd2467f1de331a935d362ad43e777a613c6c6	are ndn congestion control solutions compatible with big data traffic?		Big Data refers to analyzing the massive volume of data by combining different applications in order to save time, efficiency and quality when interpreting data. Controlling the data transfer along the network is a fundamental question in Big Data. In this context, the transport model of the Named Data Networking (NDN) architecture introduces several new features, especially name-based retrieval policy and smaller data transfer time thanks to the interest aggregation and in-network caching. These distinguishing features make the NDN a suitable communication model for Big Data transfer. But, since in NDN content can be retrieved from multiple caches and through multiple paths, the traditional host-to-host congestion control schemes become inconsistent. Hence there is a need for an efficient congestion control scheme that takes into account the tremendous volume of data generated by Big Data processing and NDN characteristics. In this paper, we give a detailed understanding of NDN benefits over traditional TCP/IP stack for Big Data transfer, then we focus on efficient control of Big Data transfer over NDN. We give a comprehensive overview of recent Named Data congestion control solutions and evaluate and discuss their relevance for Big Data applications.	algorithm;big data;control system;data deduplication;data infrastructure;data-centric security;fairness measure;finalize (optical discs);icn gps;internet protocol suite;multi-source;multipath propagation;network congestion;protocol stack;relevance;requirement	Safa Mejri;Haifa Touati;Farouk Kamoun	2018	2018 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCS.2018.00154	the internet;interest aggregation;internet protocol suite;architecture;network congestion;big data;distributed database;data modeling;distributed computing;computer science	ML	-15.133165663045585	76.91512107978616	11384
78245145fea8f9e14b0f4cc7ffade4d08bddb379	implementing a covert timing channel based on mimic function	network security;covert timing channel;mimic function;detection resistance	Covert timing channel is a mechanism that can be exploited by an attacker to conceal secrets in timing intervals of transmitted packets. With the development of detection techniques against such channel, it has become increasingly difficult to exploit a practical covert timing channel that is both detection-resistant and of high capacity. In this paper, we introduce a new type of covert timing channel. Our novel encoding technique uses mimic functions as the basis to accomplish the mimicry of legitimate traffic behaviors. We also design and implement a mimicry framework for automatically creating this new type of covert timing channel. In the end, we utilize the state-of-the-art detection tests to validate the effectiveness of our mimicry approach. The experimental results show that the created covert timing channel can successfully evade the detection tests while achieving a considerable channel capacity.	academy;channel capacity;covert channel;filter (signal processing);huffman coding;internet;interpupillary distance;map;mimic function;software framework;string (computer science);timing channel	Jing Wang;Le Guan;Limin Liu;Daren Zha	2014		10.1007/978-3-319-06320-1_19	computer science;network security;internet privacy;computer security	Security	-54.12080025063451	69.68594042073066	11395
f4c75d2857c1ee5949ea687ba3c804a9e6ff0a22	sensor bandwidth assignment through video annotation	sensor systems;video surveillance;surveillance;surveillance system;real time;distributed processing;video compression;transform coding;bit rate;computer architecture;large scale;bandwidth surveillance computer architecture bit rate cameras sensor systems video compression transform coding video sharing object detection;video transmission;video sharing;video annotation;bandwidth;ip networks;cameras;object detection;innovation system	The state of the art of surveillance systems include a large set of techniques for both low level and high level tasks. In particular, the research community has witnessed in the last decade a high proliferation of techniques that span from object detection and tracking to object recogni- tion and event understanding. Although some techniques have been proven to be very effective those tasks cannot be considered solved. Although more effort is needed in the event analysis field, a new problem arises from the develop- ment of large scale networked surveillance systems: infor- mation sharing. The way information is shared between the nodes of the surveillance network today represents a key- point issue. To provide a first and novel solution to such a problem, we propose an innovative system architecture for a video surveillance system with distributed processing over multiple processing units and with distributed communica- tion over multiple heterogeneous channels (wireless, satel- lite, local IP networks, etc.). In particular, a new real-time technique for changing the video transmission parameters (e.g., frame rate, spatial/color resolution, etc.) according to the bandwidth available will be here presented.	bandwidth (signal processing);closed-circuit television;co-ment;distributed computing;glossary of computer graphics;high-level programming language;internet protocol suite;mpeg-7;multiprocessing;object detection;propagation constant;real-time clock;robustness (computer science);streaming media;systems architecture	Christian Micheloni;Lauro Snidaro;Ingrid Visentini;Gian Luca Foresti	2006	2006 IEEE International Conference on Video and Signal Based Surveillance	10.1109/AVSS.2006.102	data compression;computer vision;real-time computing;transform coding;simulation;computer science;video tracking;bandwidth;statistics	Robotics	-8.877981514516277	102.9942669195782	11425
4f844ac2cf5db077aca89104a944be4c6e3d4117	qos driven parallelization of resources to reduce file download delay	distributed application;performance measure;available bandwidth;file transfer approach qos driven parallelization file download delay internet parallelized file transport protocol p ftp bandwidth allocation file server selection technique;file servers;mirrors;parallelized file transport protocol;file download delay;internet distributed applications performance measurements;resource allocation;bandwidth allocation;delay effects;p ftp;distributed applications;file server selection technique;transport protocols;adverse effect;large scale;network servers;server selection;internet;performance measurements;sensitivity analysis;qos driven parallelization;transport protocols bandwidth allocation file servers internet quality of service resource allocation;file transfer approach;transport protocol;bandwidth;web server;quality of service;file servers web server internet quality of service network servers delay effects mirrors bandwidth large scale systems transport protocols;large scale systems	In this paper, we propose a novel approach for reducing the download time of large files over the Internet. Our approach, known as parallelized file transport protocol (P-FTP), proposes simultaneous downloads of disjoint file portions from multiple file servers. P-FTP server selects file servers for the requesting client on the basis of a variety of QoS parameters, such as available bandwidth and server utilization. The sensitivity analysis of our file server selection technique shows that it performs significantly better than random selection. During the file transfer, P-FTP client monitors the file transfer flows to detect slow servers and congested links and adjusts the file distributions accordingly. P-FTP is evaluated with simulations and real-world implementation. The results show at least 50 percent reduction in download time when compared to the traditional file-transfer approach. Moreover, we have also carried out a simulation-based study to investigate the issues related to large scale deployment of our approach on the Internet. Our results demonstrate that a large number of P-FTP users has no adverse effect on the performance perceived by non-P-FTP users. In addition, the file servers and network are not significantly affected by large scale deployment of P-FTP	automatic parallelization;download;file server;file transfer;internet;parallel computing;quality of service;server (computing);simulation;software deployment;transfer-based machine translation	Shaleeza Sohail;Sanjay Jha;Salil S. Kanhere;Chun Tung Chou	2006	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2006.144	self-certifying file system;torrent file;device file;computer science;stub file;operating system;ssh file transfer protocol;journaling file system;database;bittorrent tracker;open;distributed file system;file system fragmentation;global namespace;transport layer;server;computer network	Metrics	-18.47387491414915	70.33065697840509	11469
461d3cd180728065b753bb454343e17d5e2a3587	a novel service scheduling policy based on logical subnet partitioning in bio-grid environments	file attente;distributed system;grid service scheduling;raisonnement base sur cas;razonamiento fundado sobre caso;haute performance;systeme reparti;logical subnet partition;distributed computing;priorite;service web;bioinformatique;queue;metric;logical programming;web service;2 level scheduling;qualite service;qos;grid;bio grid;sistema repartido;multi priority queue;programmation logique;rejilla;scheduling;alto rendimiento;grille;calculo repartido;lsp;metrico;bioinformatica;multi priority queues;case based reasoning;quality of service;priority;prioridad;programacion logica;grid computing;high performance;fila espera;calcul reparti;service scheduling;service quality;ordonnancement;metrique;reglamento;servicio web;calidad servicio;bioinformatics	In this paper, we present a method called SP2SP, 2-level Grid Service Scheduling Policy based on Logical Subnet Partitioning (LSP), which tackles the service scheduling problem in Bio-Grid environments through three steps: (a) a similarity-based logical subnet partitioning algorithm which classifies individual services into different subsets according to similarity constraints that are based on performance metrics; (b) the employment of a requirement-based prediction algorithm that maps the bioinformatics applications that are composed of multiple subtasks into optimal subnet and (c) multi-priority queue-based service scheduling algorithm used inside individual subnet taking charge of allocating each sub-task to an optimal physical service within the subnet. Based on the sub-grid platform of NPPC, experimental results have shown that SP2SP outperforms other scheduling algorithms. In particular, SP2SP performs best for scenarios where a group of tasks has similar resource requirements or need to cooperate with each other to obtain better performance as a whole.	algorithm;binary space partitioning;bioinformatics;british informatics olympiad;emoticon;grid computing;optimal matching;overhead (computing);priority queue;requirement;scheduling (computing);subnetwork;throughput	Wenchao Jiang;Yanhong Zhou;Hai Jin;Matthias Baumgarten	2011	IJGUC	10.1504/IJGUC.2011.040596	real-time computing;quality of service;computer science;operating system;database;distributed computing;computer network	HPC	-14.66197132970642	63.46095504760456	11508
9b4eb5f01e8dce8013b39e5b915472696fbdcda2	task scheduling using nsga ii with fuzzy adaptive operators for computational grids	multi objective optimization;load balancing;task scheduling;non dominated sorting genetic algorithm ii;variance based fuzzy operators;grid computing	Scheduling algorithms have an essential role in computational grids for managing jobs, and assigning them to appropriate resources. An efficient task scheduling algorithm can achieve minimum execution time and maximum resource utilization by providing the load balance between resources in the grid. The superiority of genetic algorithm in the scheduling of tasks has been proven in the literature. In this paper, we improve the famous multi-objective genetic algorithm known as NSGA-II using fuzzy operators to improve quality and performance of task scheduling in the market-based grid environment. Load balancing, Makespan and Price are three important objectives for multi-objective optimization in the task scheduling problem in the grid. Grid users do not attend load balancing in making decision, so it is desirable that all solutions have good load balancing. Thus to decrease computation and ease decision making through the users, we should consider and improve the load balancing problem in the task scheduling indirectly using the fuzzy systemwithout implementing the third objective function. We have used fuzzy operators for this purpose and more quality and variety in Pareto-optimal solutions. Three functions are defined to generate inputs for fuzzy systems. Variance of costs, variance of frequency of involved resources in scheduling and variance of genes values are used to determine probabilities of crossover and mutation intelligently. Variance of frequency of involved resources with cooperation of Makespan objective satisfies load balancing objective indirectly. Variance of genes values and variance of costs are used in the mutation fuzzy system to improve diversity and quality of Pareto optimal front. Our method conducts the algorithm towards best and most appropriate solutions with load balancing in less iteration. The obtained results have proved that our innovative algorithm converges to Pareto-optimal solutions faster and with more quality. © 2014 Elsevier Inc. All rights reserved.	computation;crossover (genetic algorithm);experiment;fuzzy control system;genetic algorithm;genetic operator;iteration;job stream;load balancing (computing);makespan;mathematical optimization;multi-objective optimization;mutation (genetic algorithm);optimization problem;pareto efficiency;run time (program lifecycle phase);scheduling (computing)	Reza Salimi;Homayun Motameni;Hesam Omranpour	2014	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2014.01.006	fair-share scheduling;mathematical optimization;real-time computing;dynamic priority scheduling;computer science;load balancing;multi-objective optimization;distributed computing;grid computing	HPC	-18.201161858695304	63.64262466673548	11511
1c3dfc7fdeb334f699878b7a2006ab2bd223d040	generalized mmm-algorithm secure against spa, dpa, and rpa	smart card;dpa;power analysis;elliptic curve;spa;rpa;simple power analysis;computational complexity;differential power analysis;side channel attacks;point of view;elliptic curve cryptosystem;scalar multiplication	In the execution on a smart card, elliptic curve cryptosystems have to be secure against side channel attacks such as the simple power analysis (SPA), the differential power analysis (DPA), and the refined power analysis (RPA), and so on. MMM-algorithm proposed by Mamiya, Miyaji, and Morimoto is a scalar multiplication algorithm secure against SPA, DPA, and RPA, which can decrease the computational complexity by increasing the size of a pre-computed table. However, it provides only 4 different cases of pre-computed tables. From the practical point of view, a wider range of time-memory tradeoffs is usually desired. This paper generalizes MMM-algorithm to improve the flexibility of tables as well as the computational complexity. Our improved algorithm is secure, efficient and flexible for the storage size.	algorithm	Atsuko Miyaji	2007		10.1007/978-3-540-76788-6_23	arithmetic;power analysis;computer science;theoretical computer science;mathematics;computer security;statistics	Crypto	-34.97166186270915	79.16275502876243	11526
7cecec42c1345789482e04a9b4374c028710360a	designated group credentials	designated group credentials;pairing based cryptography;bepress selected works;credentials;credential;security proof;random oracle model;signature;bilinear pairings;bilinear pairing;group;designated	Consider a situation where a secret agent wants to authenticate herself to the other secret agents. This secret agent must be able to convince the others of her identity. She cannot convince any other people other than those predetermined secret agents. This is to avoid problems that might occur if this secret agent would like to 'betray' her group. On the whole we would like to allow the agent to convince a predetermined group of people by showing that she holds a credential and so she is a member of the group. However we would like to prohibit this agent from convincing any other people outside the group. We also need to ensure that the party who has been convinced by the credential cannot use this information to convince any third party. We call this type of scheme as Designated Group Credential. In this paper, we first show a model of designated group credential systems followed by an efficient construction based on pairing-based cryptography. We also provide security proof of our scheme based on the random oracle model.	authentication;bilinear filtering;credential;pairing-based cryptography;provable security;random oracle;secret sharing;software agent	Ching Yu Ng;Willy Susilo;Yi Mu	2006		10.1145/1128817.1128829	random oracle;digital credential;signature;group;internet privacy;pairing-based cryptography;world wide web;computer security	Crypto	-41.61010342216555	73.29613123565129	11544
742f528b8c5306f286cb928b398f679ee7a3425e	addressing new challenges by building security protocols around graphs	graph theory;extended capabilities;secret sharing;security protocols;quantum computer;quantum computing;graph colouring;security protocol;data security	We propose the use of graphs as basic objects in security protocols. While having all the functionality of their number based counterparts; such protocols can have extended capabilities, especially useful in the field of verification and analysis. The scalability and transitivity for graph related properties allow for addressing protocols of increasing complexity. These features also cater for new challenges in the future, for instance ones resulting from a quantum computing paradigm.	abstract type;complex systems;graph (discrete mathematics);graph coloring;graph theory;programming paradigm;quantum computing;scalability;vertex-transitive graph	Kamil Kulesza;Zbigniew Kotulski	2003		10.1007/11542322_36	computer security model;computer science;graph theory;theoretical computer science;distributed computing;quantum computer;computer security	DB	-33.28964412228244	70.75787350980153	11574
8d517998b1df6225fe13e50138a088b896b96ce5	on the feasibility of attribute-based encryption for wlan access control		User authentication at Wi-Fi Access Points (APs) is becoming an important issue. Wi-Fi APs are indeed ubiquitous, but existing authentication methods such as WPA/WPA2 static pre-shared secret key (PSK), or 802.1X-based online authentication services (e.g., RADIUS servers/proxies) have their theoretical or practical limitations. In a previous work, we proposed WI-FAB, a new authentication mechanism which neither requires online backend access control infrastructure, nor relies on a static pre-shared secret key. In this paper, we extend WI-FAB by removing the need for having a central authority for user authentication and credential issuing. Our main contribution is twofold: (i) adopting decentralized multi-authority CP-ABE, we support the users who have authentication/authorization credentials from multiple authorities. We decouple the user credentials issuing from the management of the WPA2-PSK, so that neither the credential issuing authority can track the users, nor the AP can access the real identity of the users. Considering an extensive attack model, we show that the proposed approach is secure and preserves the privacy of the users. (ii) We provide a real-world implementation of the proposed approach on off-the-shelf embedded hardware to demonstrate its feasibility and efficiency.	access control;attack model;attribute-based encryption;authentication;authorization;credential;embedded system;ieee 802.11i-2004;ieee 802.1x;key (cryptography);pre-shared key;radius;shared secret;wi-fi protected access	Claudio Pisa;Tooska Dargahi;Alberto Caponi;Giuseppe Bianchi;Nicola Blefari-Melazzi	2017	2017 IEEE 13th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)	10.1109/WiMOB.2017.8115806	access control;radius;encryption;computer network;client-side encryption;credential;attribute-based encryption;computer science;computer security;attack model;authentication	Mobile	-47.39868462614996	72.16068813085111	11620
85ec6f7311bf27cbd3615003c414427817437152	a p2p content authentication protocol based on byzantine agreement	p2p system;distributed system;acces contenu;controle acces;systeme reparti;protocole transmission;certificate authority;redundancia;par a par;localization;juego de funciones;authentication;securite informatique;byzantine agreement;p2p;localizacion;comportamiento bizantino;jeu role;comportement arbitraire;authentification;computer security;byzantine behavior;protocolo transmision;it security;sistema repartido;autenticacion;content access;localisation;redundancy;poste a poste;seguridad informatica;trusted third party;acceso contenido;access control;role playing;peer to peer;authentication protocol;redondance;transmission protocol	One of the main advantages of peer-to-peer (P2P) systems is their capability to offer replicas of the same content at various locations. This allows to access contents even when some nodes are disconnected. However, this high degree of redundancy implies that it is necessary to apply some security mechanisms in order to avoid attacks based on non-authorized content modification. In this paper, we propose a content authentication protocol for pure P2P systems. Under certain restrictions, our scheme provides guarantees that a content is authentic, i.e. it has not been altered, even if it is a replica of the original and the source has lost control over it. Our proposal relies on a set of peers playing the role of a certification authority, for it is unrealistic to assume that appropriate trusted third parties can be deployed in such environments. Finally, we discuss some of its security properties through several attack scenarios.	access control;authentication protocol;authorization;bittorrent;byzantine fault tolerance;certificate authority;cryptography;digital distribution;distrust;download;malware;multisignature;overhead (computing);peer-to-peer;proof-of-work system;public key certificate;redundancy (engineering);trusted third party;emule	Esther Palomar;Juan E. Tapiador;Julio César Hernández Castro;Arturo Ribagorda	2006		10.1007/11766155_5	telecommunications;computer science;authentication;world wide web;computer security	Security	-45.01833935771788	78.06644303739719	11626
06f1186aa5f52a0cf236ce47d17c09ee3461331c	definitions of managed objects for smds interfaces using smiv2		This memo defines a portion of the Management Information Base (MIB) for use with network management protocols in TCP/IP-based internets. In particular, it defines objects for managing objects for SMDS access interfaces. This includes the following access protocols: SIP [13] SIP/DXI [18] and [20] SIP/FR [19] SIP/ATM [24] This memo replaces RFC 1304 [12], and defines a MIB module which is both compliant to the SNMPv2 SMI and semantically-identical to the existing RFC 1304-based definitions. This memo also assumes application of the MIB II Interfaces group as defined in [9].	atm turbo;directx plugin;internet protocol suite;mebibyte	Tracy A. Brown;Kaj Tesink	1994	RFC	10.17487/RFC1694	database;distributed computing;computer network	Mobile	-24.66894977268429	87.97081366881753	11629
9e6ee5314ca09576950f7283e8f9f7da12d24b15	one new research about ipsec communication based on http tunnel	virtual private network;protocols;performance test;ipsec protocol architecture;authorisation;ipsec;http;local area network ipsec communication http tunnel firewall devices ipsec protocol architecture http protocol freeswan internet development lan gateway virtual private network;ipsec communication;freeswan http covert communication ipsec;transport protocols;virtual private networks authorisation internet ip networks local area networks telecommunication security transport protocols;internet;lan gateway;cryptography;telecommunication security;freeswan;ip networks;internet development;data security communication system control protocols communication channels virtual private networks protection cryptography educational institutions computer science paper technology;http protocol;http tunnel;fires;firewall devices;local area networks;local area network;virtual private networks;covert communication	This paper first discusses the classic methods of covert communication to traverse the firewall devices which control the network communication. And based on the analysis of IPSec protocol architecture, that the worse of network compatibility of IPSec is got. So the new IPSec over HTTP protocol based on IPSec tunnel and HTTP tunnel is exposed including its structure and procedure. The soft structure of FreeSWAN is improved and the performance test data are presented in order to validate this new protocol. Finally, the performance of the new system is analyzed detailedly	firewall (computing);http tunnel;hypertext transfer protocol;ipsec;network address translation;network security;traverse;test data;virtual private network	Mei Song;Zhang Yun-he	2009	2009 IEEE International Symposium on Parallel and Distributed Processing with Applications	10.1109/ISPA.2009.44	local area network;hypertext transfer protocol;computer science;ip tunnel;world wide web;computer security;computer network	Embedded	-58.100858942918805	67.01421048177824	11638
b35cc4e4ae11811fa73520cb1134fa8d79b9de0e	schedulability analysis of edf-scheduled embedded real-time systems with resource sharing	control and reliability;earliest deadline first;schedulability analysis;scheduling;resource sharing;algorithms;embedded and real time systems	Earliest Deadline First (EDF) is the most widely studied optimal dynamic scheduling algorithm for uniprocessor real-time systems. In the existing literature, however, there is no complete exact analysis for EDF scheduling when both resource sharing and release jitter are considered. Since resource sharing and release jitter are important characteristics of embedded real-time systems, a solid theoretical foundation should be provided for EDF scheduled systems. In this paper, we extend traditional processor demand analysis to let arbitrary deadline real-time tasks share non-preemptable resources and suffer release jitter. A complete and exact schedulability analysis for EDF scheduled systems is provided. This analysis is incorporated into QPA (Quick Processor-demand Analysis) which provides an efficient implementation of the exact test.	algorithm;earliest deadline first scheduling;embedded system;real-time clock;real-time computing;scheduling (computing);scheduling analysis real-time systems;uniprocessor system	Fengxiang Zhang;Alan Burns	2013	ACM Trans. Embedded Comput. Syst.	10.1145/2442116.2442117	shared resource;parallel computing;real-time computing;earliest deadline first scheduling;computer science;operating system;distributed computing;scheduling	Embedded	-9.907742273203313	60.78376645145585	11644
f5d5e4c7705c36cd00119495e6b326291d77bc5c	optimal task placement with qos constraints in geo-distributed data centers using dvfs	dynamic voltage frequency scaling;silicon;engineering;minimization;portals;optimisation;servers electricity power demand quality of service portals silicon minimization;operational expenditure;electricity prices;technology;performance;qos constraints;resizing scheme;optimal task placement;computer centres;optimization problem;data center providers;cloud computing computer centres optimisation quality of service;data center;servers;electricity consumption;geo distributed data centers;science technology;optimal task placement resizing scheme cost efficiency quality of service optimization problem dynamic frequency scaling technique electricity prices geographical heterogeneity data center providers opex operational expenditure electricity consumption cloud services dvfs geo distributed data centers qos constraints;cost minimization;request mapping;cost efficiency;electricity;quality of service cloud computing computer centres optimisation;geographical heterogeneity;computer science;quality of service;dynamic frequency scaling technique;cloud services;dvfs;power demand;engineering electrical electronic;opex;resizing scheme cost efficiency quality of service optimization problem dynamic frequency scaling technique electricity prices geographical heterogeneity data center providers opex operational expenditure electricity consumption cloud services dvfs geo distributed data centers qos constraints optimal task placement;power;cloud computing;computer science hardware architecture	With the rising demands on cloud services, the electricity consumption has been increasing drastically as the main operational expenditure (OPEX) to data center providers. The geographical heterogeneity of electricity prices motivates us to study the task placement problem over geo-distributed data centers. We exploit the dynamic frequency scaling technique and formulate an optimization problem that minimizes OPEX while guaranteeing the quality-of-service, i.e, the expected response time of tasks. Furthermore, an optimal solution is discovered for this formulated problem. The experimental results show that our proposal achieves much higher cost-efficiency than the traditional resizing scheme, i.e, by activating/deactivating certain servers in data centers.	cloud computing;data center;dynamic frequency scaling;dynamic voltage scaling;experiment;image scaling;iterative method;mathematical optimization;optimization problem;polynomial;quality of service;response time (technology);scheduling (computing);search algorithm;server (computing);time complexity	Lin Gu;Deze Zeng;Ahmed Barnawi;Song Guo;Ivan Stojmenovic	2015	IEEE Transactions on Computers	10.1109/TC.2014.2349510	embedded system;real-time computing;simulation;operating expense;cloud computing;computer science;operating system;computer network	Embedded	-20.984027224156762	63.32249988761377	11653
4d3c84b7230e05c04e7b266058a233e71edc6861	scheduling divisible loads on a chain of processors			microprocessor;scheduling (computing)	Wlodzimierz Glazek	1997			scheduling (computing);fair-share scheduling;computer science;distributed computing	Arch	-11.539694877952522	62.14251943947776	11712
9cb04ecd3008b6b4592a469fc7e65e168d4e3c06	secure multi-party computation with security modules	fault tolerant;secure multi party computation;004 informatik;330 wirtschaft;it security;byzantine generals problem	We consider the problem of secure multi-party computation (SMC) in a new model where individual processes contain a tamper-proof security module. Security modules can be trusted by other processes and can establish secure channels between each other. However, their availability is restricted by their host, i.e., a corrupted party can stop the computation of its own security module as well as drop any message sent by or to its security module. In this model we show that SMC is solvable if and only if a majority of processes is correct. We prove this by relating SMC to the problem of Uniform Interactive Consistency among security modules (a variant of the Byzantine Generals Problem from the area of fault-tolerance). The obtained solutions to SMC for the first time allow to compute any function securely with a complexity which is polynomial only in the number of processes (i.e., the complexity does not depend on the function which is computed). We conclude that adding secure hardware does not improve the resilience of SMC but can effectively improve the efficiency.	byzantine fault tolerance;decision problem;linux security modules;polynomial;secure multi-party computation;tamper resistance	Zinaida Benenson;Felix C. Freiling;Dogan Kesdogan	2005			quantum byzantine agreement;secure two-party computation;distributed computing;byzantine fault tolerance;computer security;computer network	Crypto	-42.10550481957005	72.76803024687312	11721
152ecb776601608373f03539d626056a79ea28e5	linear cryptanalysis of spectr-h64 with higher order differential property	algebraic degree;securite;cryptanalyse;ecuacion lineal;higher order;permutation;cryptanalysis;linear cryptanalysis;criptoanalisis;permutacion;safety;linear equations;linear equation;seguridad;equation lineaire;differential algebra;exhaustive search	In this paper, we find linear equations of SPECTR-H64 using the property of controlled permutation boxes. Also, we construct the fourth-order differential structure using the property that the algebraic degree of the function G is 3, which is the only non-linear part of SPECTR-H64. These linear equations and structures enable us to attack the reduced 6 round SPECTR-H64. So, we can recover the 6-th round subkey with about 2 44  chosen plaintexts and 2 229.6  steps which are lower than the exhaustive search 2 256 .	linear cryptanalysis	Youngdai Ko;Deukjo Hong;Seokhie Hong;Sangjin Lee;Jongin Lim	2003		10.1007/978-3-540-45215-7_25	combinatorics;discrete mathematics;differential algebra;mathematics;linear equation;algorithm;algebra	Crypto	-39.94390467410617	80.95825112195679	11766
ec8bfcbde5a0505130892eb069bd1870d23525ed	a qos management system for multimedia applications in ieee 802.11 wireless lan	run time monitoring;management system;wireless network;multimedia application;qos;digital content;qos management;wireless lan;admission control;upnp	Wireless networks are becoming increasingly popular in professional environments as well as in the home. The success of IEEE 802.11 has cut down equipment costs and people are now building their own residential wireless networks, connecting PCs, MP3 players, broadband gateways and Hi-Fi systems.However, such dramatic growth is creating problems in crowded areas, as the Wi-Fi bandwidth is limited and interference effects start to limit the technology usability.This paper describes a management system for handling the quality of the overall home wireless network, so that interference or bulk noise effects can be alleviated allowing users to enjoy digital content with the reliability they expect. By means of Universal Plug 'n Play, events that may deteriorate the quality of existing services can be propagated to all interested devices so that a smart allocation of network resources can be applied. A simple Admission Control scheme is also used to regulate the admission of real-time streams.	algorithm;bandwidth (signal processing);data compression;digital recording;emoticon;home automation;interference (communication);mp3;middleware;plug computer;quality of service;real-time transcription;requirement;universal plug and play;usability	Andrea Palmieri;Francesco Sigona	2006		10.1145/1186655.1186662	multi-frequency network;universal plug and play;real-time computing;wireless wan;quality of service;wireless site survey;telecommunications;computer science;operating system;wireless network;management system;wireless lan controller;municipal wireless network;wi-fi array;fixed wireless;computer network;ieee 802.11e-2005	Mobile	-11.39242471167094	99.77789790664106	11778
40f430cc1c394f6150adf2f6324726d811d1c72f	dual system encryption: realizing fully secure ibe and hibe under simple assumptions	identity based encryption;hierarchical identity based encryption	We present a new methodology for proving security of encryption systems using what we call Dual System Encryption. Our techniques result in fully secure Identity-Based Encryption (IBE) and Hierarchical Identity-Based Encryption (HIBE) systems under the simple and established decisional Bilinear Diffie-Hellman and decisional Linear assumptions. Our IBE system has ciphertexts, private keys, and public parameters each consisting of a constant number of group elements. These results are the first HIBE system and the first IBE system with short parameters under simple assumptions. In a Dual System Encryption system both ciphertexts and private keys can take on one of two indistinguishable forms. A private key or ciphertext will be normal if they are generated respectively from the system’s key generation or encryption algorithm. These keys and ciphertexts will behave as one expects in an IBE system. In addition, we define semifunctional keys and ciphertexts. A semi-functional private key will be able to decrypt all normally generated ciphertexts; however, decryption will fail if one attempts to decrypt a semi-functional ciphertext with a semi-functional private key. Analogously, semi-functional ciphertexts will be decryptable only by normal private keys. Dual System Encryption opens up a new way to prove security of IBE and related encryption systems. We define a sequence of games where we change first the challenge ciphertext and then the private keys one by one to be semi-functional. We finally end up in a game where the challenge ciphertext and all private keys are semi-functional at which point proving security is straightforward.	algorithm;bilinear transform;ciphertext;diffie–hellman problem;id-based encryption;key generation;public-key cryptography;semiconductor industry	Brent Waters	2009		10.1007/978-3-642-03356-8_36	multiple encryption;40-bit encryption;plaintext-aware encryption;client-side encryption;computer science;theoretical computer science;ciphertext indistinguishability;symmetric-key algorithm;link encryption;mathematics;on-the-fly encryption;internet privacy;deterministic encryption;computer security;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption	Crypto	-40.25260404717955	75.51899429534326	11802
d72d88765ed3728946e558d51c8f126526df3873	a dynamic buffer management technique for minimizing the necessary buffer space in a continuous media server	minimisation;storage allocation;file servers;data compression;continuous media;storage management;buffer management;buffer storage;client server systems;multimedia systems;round robin;buffer utilization wbm dynamic buffer management technique necessary buffer space minimization continuous media server window based buffer management variable bit rate compression client service duration periodic buffer space reallocation run time overhead round robin client group management case study;storage allocation multimedia systems buffer storage storage management minimisation file servers client server systems data compression;runtime network servers mpeg standards streaming media video compression computer science information retrieval scheduling algorithm displays;variable bit rate	A dynamic buffer management technique is developed, called WBM (window-based buffer management), which considers VBR (variable bit-rate) compression in a continuous media server. WBM divides the service duration of clients into several small time intervals called windows, and reallocates the buffer space every window period. WBM could incur a relatively high run-time overhead because it reallocates the buffer space periodically. To reduce the run-time overhead, WBM maintains the admitted clients by groups and manages the groups in a round-robin fashion. We present a case study which shows a significant improvement in the buffer utilization and in the necessary amount of buffer space.	media server	Yeonseung Ryu;Kern Koh	1996		10.1109/MMCS.1996.534972	data compression;file server;minimisation;real-time computing;computer science;operating system;buffer underrun;variable bitrate;write buffer;statistics;computer network	DB	-15.346816794895158	70.95444045808578	11815
47b4c1c0e52d61404b0a48fb9f43d93be8662c14	a nyberg-rueppel signature for multiple messages and its batch verification	signature scheme;reconnaissance caractere;digital signature;verification signature;verification message multiple;signature numerique;firma numerica;signature recuperation message nyberg rueppel;digital signature scheme;character recognition;reconocimiento caracter	We propose a Nyberg-Rueppel message recovery signature scheme for multiple messages which produces one signature for multiple messages and has its batch verification of the signature for multiple messages. The length of the signature is shorter than the sum of length of corresponding signatures produced by the ordinary digital signature scheme, separately. In the signature generation and the verification of our scheme, the number of exponentiations is constant independent of the number of messages.	antivirus software;cryptography;cryptosystem;digital signature;discrete logarithm;electronic signature;information theory;kaisa nyberg;lecture notes in computer science;mihir bellare;modular exponentiation;software distribution;springer (tank);type signature	Shunsuke Araki	2002		10.1007/3-540-45811-5_17	ring signature;digital signature;merkle signature scheme;computer science;theoretical computer science;mathematics;distributed computing;blind signature;schnorr signature;elgamal signature scheme;computer security;algorithm	Crypto	-41.048510878611594	79.07482705344184	11817
883c0b6f034d4a6c48827af224dc2fc2321f733d	improving biometric-based authentication schemes with smart card revocation/reissue for wireless sensor networks	smart card;biometric;user authentication;wireless sensor networks	User authentication in wireless sensor networks is more difficult than in traditional networks owing to sensor network characteristics such as unreliable communication, limited resources, and unattended operation. For these reasons, various authentication schemes have been proposed to provide secure and efficient communication. In 2016, Park et al. proposed a secure biometric-based authentication scheme with smart card revocation/reissue for wireless sensor networks. However, we found that their scheme was still insecure against impersonation attack, and had a problem in the smart card revocation/reissue phase. In this paper, we show how an adversary can impersonate a legitimate user or sensor node, illegal smart card revocation/reissue and prove that Park et al.'s scheme fails to provide revocation/reissue. In addition, we propose an enhanced scheme that provides efficiency, as well as anonymity and security. Finally, we provide security and performance analysis between previous schemes and the proposed scheme, and provide formal analysis based on the random oracle model. The results prove that the proposed scheme can solve the weaknesses of impersonation attack and other security flaws in the security analysis section. Furthermore, performance analysis shows that the computational cost is lower than the previous scheme.	adversary (cryptography);algorithmic efficiency;authentication;biometrics;computation;node - plant part;profiling (computer programming);random oracle;sensor node;sensor web;smart card;vulnerability (computing);weakness	Jongho Moon;Donghoon Lee;Youngsook Lee;Dongho Won	2017		10.3390/s17050940	smart card;wireless sensor network;computer science;engineering;internet privacy;computer security;biometrics;computer network	Security	-46.43731683644115	74.77473200049883	11826
470308f217e9dcb7a5a2cedfa32be604ce56dc32	statistically indifferent quality variation: an approach for reducing multimedia distribution cost for adaptive video streaming services	bit rate;crowdsourcing data communication internet minimisation multimedia systems statistical analysis video streaming;quality assessment;streaming media;mpeg dash adaptive video streaming quality of experience;multimedia communication;video recording;streaming media bit rate quality assessment video recording multimedia communication optimization;optimization;statistically indifferent quality variation multimedia distribution cost reduction adaptive video streaming services internet traffic multimedia streaming quality of experience bit rate maximization mobile environments data plan bandwidth usage minimization data transmission high bit rate representations video quality adjacent video representations standard objective quality metric adoptation qoe models bandwidth consumption crowdsourcing;adaptive video streaming mpeg dash quality of experience	Forecasts predict that Internet traffic will continue to grow in the near future. A huge share of this traffic is caused by multimedia streaming. The quality of experience (QoE) of such streaming services is an important aspect and in most cases the goal is to maximize the bit rate which—in some cases—conflicts with the requirements of both consumers and providers. For example, in mobile environments users may prefer a lower bit rate to come along with their data plan. Likewise, providers aim at minimizing bandwidth usage in order to reduce costs by transmitting less data to users while maintaining a high QoE. Today's adaptive video streaming services try to serve users with the highest bit rates that consequently results in high QoE. In practice, however, some of these high bit rate representations may not differ significantly in terms of perceived video quality compared to lower bit rate representations. In this paper, we present a novel approach to determine the statistically indifferent quality variation of adjacent video representations for adaptive video streaming services by adopting standard objective quality metrics and existing QoE models. In particular, whenever the quality variation between adjacent representations is imperceptible from a statistical point of view, the representation with higher bit rate can be substituted with a lower bit rate representation. As expected, this approach results in savings with respect to bandwidth consumption while still providing a high QoE for users. The approach is evaluated subjectively with a crowdsourcing study. Additionally, we highlight the benefits of our approach, by providing a case study that extrapolates possible savings for providers.	crowdsourcing;extrapolation;internet;point of view (computer hardware company);requirement;streaming media;transmitter;video	Benjamin Rainer;Stefan Petscharnig;Christian Timmerer;Hermann Hellwagner	2017	IEEE Transactions on Multimedia	10.1109/TMM.2016.2629761	real-time computing;computer science;video quality;multimedia;pevq;computer network	Metrics	-9.79298530422199	100.08512847386201	11837
9ef36e89dbe3f3cca649c4439e30b5f14f42af86	combined coherence and prefetching mechanisms for effective web caching	prefetching mechanisms;effective web caching;measurement;storage management;prefetching;coherence mechanisms;collaboration;delay effects;intelligent control;systems engineering and theory;http head request coherence mechanisms prefetching mechanisms effective web caching cache coherence response latency dns lookup tcp connection;http head request;internet;response latency;cache coherence;bandwidth;internet storage management;coherence;tcp connection;web server;prefetching web server algorithm design and analysis measurement collaboration bandwidth delay effects intelligent control systems engineering and theory industrial engineering;web caching;dns lookup;algorithm design and analysis;industrial engineering	The cache coherence and prefetching are both important mechanisms of web caching. The coherence is for updating the stale documents, and prefetching is for reducing the response latency. Based on the analysis of major algorithms of coherence and prefetching, we have identified the difference and commonness of the two mechanisms. Both mechanisms need the collaboration of proxy client and web server. Therefore, if coherence and prefetching are combined, the number of requests the web server receives will decrease, as well as the corresponding connecting time (e.g. DNS lookup, TCP connection, HTTP head request). In addition, this combination will save the network bandwidth.	cpu cache;web cache	Jingquan Li;Z. X. Wang;Daniel Dajun Zeng;Fei-Yue Wang	2001		10.1109/ICSMC.2001.971981	algorithm design;cache coherence;real-time computing;the internet;coherence;computer science;world wide web;bandwidth;web server;measurement;statistics;computer network;intelligent control;collaboration	Theory	-17.70333879383832	70.50800293714167	11842
0cbf024552352ce0721dd4ef3dba11eafabf4389	automatic detection for online games bot with app		With the growing of the popularity of online games, the potential risks are also increasing. Attacks usually take various means to defraud players in order to get the players' virtual property or personal data. Currently, robot online game plug detection is running in many ways. However, related studies are still unable to make a truly effective and comprehensive preventing mechanism especially with the fact that criminal behaviors for online games are difficult to curb effectively. The main reasons lies in spreading viruses by sharing other players' account via illegal plugin, Trojans, exploiting security vulnerabilities game or other malicious virtual property illegally acquired players. In this study, we proposed a new way to scan and resist bot. The APP we developed can scan, detect, and filter out the bot that needs to be shut down, so as to delete online game bot effectively.	computer virus;correctness (computer science);malware;massively multiplayer online role-playing game;personally identifiable information;plug-in (computing);requirement;robot;vulnerability (computing)	Chin-Ling Chen;Chang-Cheng Ku;Yong-Yuan Deng;Woei-Jiunn Tsaur	2018	2018 Third International Conference on Fog and Mobile Edge Computing (FMEC)	10.1109/FMEC.2018.8364081	computer security;the internet;plug-in;popularity;server;computer science;vulnerability;edge computing	SE	-56.1955658787231	62.63490654006464	11888
279e8e05d21daf4209de97868cb2958e3bf2d52f	adaptive emergency scenery video communications using hevc for responsive decision support in disaster incidents	computer communication networks;telemedicine;encoding streaming media quality assessment bit rate video recording wireless communication optimization;decision support techniques;video recording;algorithms;emergency medicine;video quality space adaptive emergency scenery video communications responsive decision support disaster incidents m health video communication systems video quality encoding time bitrate demands video modality hevc encoding configurations emergency scenery;humans;video communication decision support systems emergency management optimisation;wireless technology;disasters	This study proposes a unifying framework for m-Health video communication systems that provides for the joint optimization of video quality, bitrate demands, and encoding time. The framework is video modality and infrastructure independent and facilitates adaptation to the best available encoding mode that satisfies underlying technology and application imposed constraints. The scalability of the proposed algorithm is demonstrated using different HEVC encoding configurations and realistic modelling of 802.11× wireless infrastructure for emergency scenery and response videos. Extensive experimentation shows that a jointly optimal solution in the encoding time, bitrate, and video quality space is feasible.	acclimatization;algorithm;decision support systems, clinical;decision support system;high efficiency video coding;ieee 802.1x;mhealth;mathematical optimization;modality (human–computer interaction);scalability	Zinonas C. Antoniou;Andreas S. Panayides;Marios S. Pattichis;S. Stavrou;Edward Kyriacou;Andreas Spanias;Anthony G. Constantinides;Constantinos S. Pattichis	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7318328	computer vision;disaster;simulation;medicine;computer science;video tracking;multimedia	Embedded	-8.442229024333859	104.57104303380262	11898
15c71537a05ac76fb6bfb7a9e804a992d7b1f21e	mobile converged networks [guest editorial]	convergence;special issues and sections mobile communication computer architecture multimedia communication resource management convergence mobile computing;resource management;computer architecture;mobile communication;editorials;mobile computing	Driven by the ever increasing popularity and demand of multimedia contents, wireless traffic is expected to increase 1000 times in the next 10 years. A looming problem is how to identify a frequency band, from the already scarce spectrum resources, to fulfill this requirement. A feasible cost-efficient solution is to integrate several existing network resources, which have been allocated for different services, to form a single mobile converged network. These existing networks operate independently on different frequency bands, including the cellular network, video broadcast, wireless sensor network (WSN), and wireless local area network (WLAN). Each of them, alone, has its own historic justification, but suffers certain drawbacks in one way or another. For instance, the cellular network was originally designed to offer voice service, lacking an efficient means of broadcasting multimedia contents. Clearly, integrating these heterogeneous networks will constitute a much more powerful unified framework able to fully exploit the capability and radio resources of all the individual networks, provide a platform for the Internet of Things, and enable users to enjoy a uniform service everywhere by using a software-defined radio device. The benefits of converged networks are promising; however, the road to success is filled with challenges. The networks integration necessitates a harmonious interaction among heterogeneous networks at different levels, thus requiring a careful design of network architecture, coordination protocols, and resource allocation algorithms for efficient operation of the converged network.		Honglin Hu;Yun Rui;Riku Jäntti;Kari Pehkonen	2014	IEEE Wireless Commun.	10.1109/MWC.2014.7000966	multi-frequency network;radio access network;wireless wan;heterogeneous network;convergence;mobile telephony;public land mobile network;telecommunications;computer science;radio resource management;resource management;operating system;wireless network;distributed computing;mobile computing;computer security;computer network	Embedded	-14.271056659078372	87.36964709708667	11915
41e568cf1883a2589ae1bb97e12283efc2a0e148	interface board for pcs providing so interface with voice and data communications capabilities		Executive Summary Monitoring applications serve various important roles, such as network management and for providing subscriber services. This application note provides an introduction to monitoring applications using example cases that include the Dialogic ® DSI SS7HD Network Interface Boards, and provides an overview of operating a monitoring application. Introduction This application note provides an introduction to monitoring applications using use cases as examples that include Dialogic ® DSI SS7HD Network Interface Boards. It also provides an operational overview describing what a user can do to configure a monitoring application and obtain feedback, and provides configuration requirements to assists users in understanding some of the equipment that is needed for doing so.	datasheet;network interface;requirement	Yvonnick David	1988			personal communications service;computer network;computer science;distributed computing	SE	-20.18078439214766	89.87971539373129	11918
2a8645060966aed63d0de5b91175444d053de8ef	framework for characterizing hardware deployed in wireless mesh networking testbeds	radio networks;assessment methodology;hardware decision;experimental approach wireless mesh network deployment assessment methodology hardware decision;wireless mesh network;experimental approach;cpu processing power wireless mesh networking testbeds target equipment equivalent scenarios power constraints;hardware wireless communication system testing telecommunications irrigation central processing unit mesh networks algorithm design and analysis wireless application protocol plugs;wireless mesh network deployment	Experimental systems introduce a variable in the analyzed system which is not present in theoretical ones, i.e. real equipment from different vendors. Given a certain standard, different vendors might take different design choices depending on the target equipment being devised. As a consequence, though this equipment fulfills the same functionality, it shows different behavior in equivalent scenarios due to parameters such as power constraints, degree of standard compliance, or CPU processing power. In this paper, we identify and explain the implications that these parameters have on the performance of wireless equipment, with particular emphasis on building a wireless mesh networking testbed. Moreover, this paper outlines techniques and recommended practices to use when selecting equipment in order to assess its behavior. It presents also practical quantitative results illustrating the type of results obtained and the validity of the techniques and procedures proposed.	central processing unit;exemplification;experiment;mesh networking;norm (social);standards-compliant;subroutine;testbed;unfolding (dsp implementation);wireless mesh network	Marc Portoles-Comeras;Manuel Requena-Esteso;Josep Mangues-Bafalluy	2007	2007 3rd International Conference on Testbeds and Research Infrastructure for the Development of Networks and Communities	10.1109/TRIDENTCOM.2007.4444730	ieee 802.11s;wireless mesh network;service set;simulation;wireless wan;wireless site survey;telecommunications;computer science;mesh networking;wireless network;order one network protocol;networking hardware;key distribution in wireless sensor networks;wi-fi array;fixed wireless;computer security;computer network	Robotics	-19.518704245004564	78.57781766606884	11922
e01a4e73c3ae7c471b77499d81b5ea923cf71ecc	do mobile data plans affect usage? results from a pricing trial with isp customers		The growing amount of traffic in mobile data networks is causing concern for Internet service providers (ISPs), especially smaller ISPs that need to lease expensive links to Tier 1 networks. Large amounts of traffic in “peak” hours are of especial concern, since network capacity must be provisioned to accommodate these peaks. In response, many ISPs have begun trying to influence user behavior with pricing. Timedependent pricing (TDP) can help reduce peaks, since it allows ISPs to charge higher prices during peak periods. We present results from the first TDP trial with a commercial ISP. In addition to analyzing applicationspecific mobile and WiFi traffic, we compare changes in user behavior due to monthly data caps and time-dependent prices. We find that monthly data caps tend to reduce usage, while TDP can increase usage as users consume more data during discounted times. Moreover, unlike data caps, TDP reduces the network’s peak-to-average usage ratio, lessening the need for network over-provisioning and increasing ISP profit.	java caps;multitier architecture;provisioning;thermal design power;tier 1 network;variable pricing	Carlee Joe-Wong;Sangtae Ha;Soumya Sen;Mung Chiang	2015		10.1007/978-3-319-15509-8_8	real-time computing;the internet;computer network;service provider;mobile broadband;lease;tier 1 network;computer science;bandwidth cap;provisioning	Metrics	-15.430350693546316	100.01765793058583	11928
833dcd5a235dee2382a11e9b69626dfcf7cacf37	a new forward secure content extraction signature scheme	short signature;random oracle model forward secure content extraction signature scheme short signature multiparty interaction secret key public key existential forgery message attack;content extraction signature;public key cryptography digital signatures private key cryptography;public key forgery generators games computer science writing;short signature forward secure content extraction signature;forward secure	We design a content extraction signature with a forward secure based on short signature. The scheme can cut the risk of the key leakage to the lowest degree, and get verifiable content extraction with minimal multi-party interaction. The secret key in this new scheme is updated automatically with different period time while the public key is fixed in the all lifetime, even if the secret key of current time period is compromised, the attacker cannot forge the secret key and the signature of the past period time. We also prove that our scheme is existential forgery on adaptively chosen message attack in the random oracle model.	digital signature forgery;forge;formal verification;forward secrecy;key (cryptography);public-key cryptography;random oracle;spectral leakage	Caifen Wang;Yahong Li;Shih Yen Huang;Ting Xu;Chiou-Kou Tung	2015	2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2015.7382201	ring signature;key;digital signature;commitment scheme;merkle signature scheme;computer science;internet privacy;pre-shared key;blind signature;schnorr signature;world wide web;key distribution;elgamal signature scheme;computer security	Crypto	-42.48855804457088	73.83574785723641	11933
ed2229e4863927c98dff0b0dd54559c65d78df42	obfuscating re-encryption algorithm with flexible and controllable multi-hop on untrusted outsourcing server		An outsourcing re-encryption program can help a ciphertext owner (delegator) transform his/her ciphertext into another ciphertext of delegatee. For example, an e-mail receiver can re-transfer an encrypted e-mail to his secretary while allowing the e-mail to be readable for her. For a multi-hop re-encryption, the delegatee can re-encrypt the ciphertext to another user in delegation chain, repeatedly. Traditionally, this transformation is usually conducted by a proxy or an outsourcing server. However, the proxy or outsourcing server needs a re-encryption key (i.e., re-key) and the re-encryption program must execute in a black-box manner (cannot trace into or debug and monitor the program), and thus the outsource server must be semi-trusted. Actually, as the outsource program was run and fully controlled by the server, in this paper, we consider a stronger attack in the case that the re-encryption program was run on an untrusted/malicious server and even the server can trace into the codes and monitor the variables during the executing. We design a secure multi-hop re-encryption scheme, and then convert the re-encryption program into an obfuscated version with constant-hiding to ensure no sensitive information be revealed. The obfuscator of multi-hop re-encryption is to faithfully hide the program and its sensitive data that takes a re-encryption program/circuit as input and outputs another program with the same functionality, while revealing no more sensitive information (i.e., sensitive key and plaintext) than learns from the black-box oracle access to the original program. We also present a flexible and controllable construction of re-encryption scheme, functionality model and its obfuscation version in leveled multilinear groups, and exemplify some scenarios to deploy in various applications. Finally, we provide the performance analysis of the obfuscator, such as functionality preservation of consistency, polynomial slowdown of performance, and average-case virtual black-box of security, and show that the obfuscator is efficient and practical in use.	algorithm;best, worst and average case;black box;ciphertext;code;email encryption;exemplification;hop;human-readable medium;information sensitivity;key (cryptography);obfuscation (software);outsourcing;plaintext;polynomial;proxy server;semiconductor industry;server (computing)	Mingwu Zhang;Yan Jiang;Yi Mu;Willy Susilo	2017	IEEE Access	10.1109/ACCESS.2017.2771335	obfuscation (software);distributed computing;oracle;ciphertext;encryption;outsourcing;computer science;delegation;server;plaintext	Security	-41.51227133512438	68.92608977732621	11950
23e235e41b1c247fcc71b82d9da38d14544fcf27	priority-based job scheduling in distributed systems	distributed system;image processing;queuing model;weather forecasting;global computing;distributed scheduling;large scale;load sharing;resource availability;distributed algorithm;job scheduling	Global computing systems like SETI@home tie together the unused CPU cycles, buffer space and secondary storage resources over the Internet for solving large scale computing problems like weather forecasting, and image processing that require high volume of computing power. In this paper we address issues that are critical to distributed scheduling environments such as job priorities, length of jobs, and resource heterogeneity. However, researchers have used metrics like resource availability at the new location, and response time of jobs in deciding upon the job transfer. Our load sharing algorithms use dynamic sender initiated approach to transfer a job. We implemented distributed algorithms using a centralized approach that improves average response time of jobs while considering their priorities. The job arrival process and the CPU service times are modeled using M/M/1 queuing model. We compared the performance of our algorithms with similar algorithms in the literature. We evaluated our algorithms using simulation and presented the results that show the effectiveness of our approach.	auxiliary memory;central processing unit;centralized computing;computer data storage;distributed algorithm;distributed computing;image processing;job scheduler;job shop scheduling;job stream;queueing theory;response time (technology);run time (program lifecycle phase);seti@home;scalability;scheduling (computing);simulation	Sunita Bansal;Chittaranjan Hota	2009		10.1007/978-3-642-00405-6_15	fair-share scheduling;generalized processor sharing;fixed-priority pre-emptive scheduling;distributed algorithm;parallel computing;real-time computing;earliest deadline first scheduling;flow shop scheduling;weather forecasting;dynamic priority scheduling;image processing;computer science;rate-monotonic scheduling;job scheduler;two-level scheduling;distributed computing;lottery scheduling;round-robin scheduling	HPC	-15.762534143006189	60.95129294826665	11965
9de3b0767a364a654121e75a30451193c94e4bdd	secret-sharing hardware improves the privacy of network monitoring	hardware acceleration;field programmable gate array;secret sharing;network monitoring;network service provider;field programmable gate array fpga;gigabit ethernet;threshold cryptography;secret sharing scheme;data flow;high speed	Network service providers monitor the data flow to detect anomalies and malicious behavior in their networks. Network monitoring inspects the data flow over time and thus has to store packet data. Storing of data impedes the privacy of users. A radically new approach counteracts such privacy concerns by exploiting threshold cryptography. It encrypts all monitored traffic. The used symmetric keys are made available to monitoring entities only if they collect enough evidence of malicious behavior. This new approach overcomes weaknesses of packet anonymization. It calls for dedicated hardware that is able to encrypt packets and generate key-share information for gigabit networks. This article proves that the application of Shamir's secret sharing scheme is possible. The presented hardware is able to protect up to 1.8 million packets per second. The creation of such a high-speed hardware required innovations on the algorithmic, the protocol, and on the architectural level. The outcome is a surprisingly small circuit that fits commercially available FPGA cards. It was tested under real-world conditions. It proved to protect the users' privacy while monitoring gigabit networks.	secret sharing	Johannes Wolkerstorfer	2010		10.1007/978-3-642-19348-4_5	data flow diagram;real-time computing;hardware acceleration;computer science;secret sharing;computer security;network monitoring;field-programmable gate array;computer network	Crypto	-55.67027229170356	70.11270840809438	11990
22e81370fa2bf2356861e9ab947bae2abb721670	universal forgery on a group signature scheme using self-certified public keys	verification;procesamiento informacion;signature verification;group signature scheme;forgery;cle publique;signature electronique;group signature;public key;digital signature;criptografia;informatique theorique;cryptography;signature groupe;information processing;llave publica;cryptographie;firma numerica;verificacion;traitement information;computer theory;informatica teorica	A group signature scheme allows any group member to sign messages on behalf of the group in an anonymous and fashion. In the event of a dispute, a designated group manager can reveal the identity of the signer. In 1999, Tsen proposed a group signature scheme using self-certified public keys. By attacking their signature verification equa demonstrate that their scheme is universally forgeable, i.e., anybody can forge a valid group signature on any message that the group manager is unable to determine the identity of the signer.  2003 Elsevier B.V. All rights reserved.	antivirus software;digital signature forgery;forge;group signature;i/o controller hub;jan bergstra;local interconnect network;manufacturing execution system;proxy server;rete algorithm;scheme	Guilin Wang	2004	Inf. Process. Lett.	10.1016/j.ipl.2003.11.014	ring signature;information processing;telecommunications;computer science;mathematics;group signature;blind signature;computer security;algorithm	Security	-43.25731119877203	77.772120728662	11998
4be2aabf82726af44760a592947f480e1c56085a	sdn management layer: design requirements and future direction	control systems;protocols;telecommunication network management computer networks software radio;process control control systems ip networks computer architecture protocols ports computers programming;sdn networks;software defined networking sdn management layer design requirements computer networks flexible network management;computer networks;computer architecture;process control;ip networks;technical report;ports computers;programming	Computer networks are becoming increasingly complex and difficult to manage. The research community has been expending a lot of efforts to come up with a general management paradigm that is able to hide the details of the physical infrastructure and enable flexible network management. Software Defined Networking (SDN) is such a paradigm that simplifies network management and enables network innovations. In this survey paper, by reviewing existing SDN management layers (platforms), we identify the general common management architecture for SDN networks, and further identify the design requirements of the management layer that is at the core of the architecture. We also point out open issues and weaknesses of existing SDN management layers. We conclude with a promising future direction for improving the SDN management layer.	experiment;programming paradigm;quality of service;recursion;requirement;software-defined networking	Yuefeng Wang;Ibrahim Matta	2014	2014 IEEE 22nd International Conference on Network Protocols	10.1109/ICNP.2014.89	communications protocol;programming;network management station;computer science;technical report;process control;distributed computing;network management application;computer network	DB	-16.135849624617176	84.42679580031816	12010
10b2b37bfb98d71f31125c01b2a39bb58b113207	proxiable designated verifier signature	proxy;voltage control;strong unforgeability;strong unforgeability designated verifier signature proxy;government;satisfiability;designated verifier signature;public key;security requirements;voltage control public key algorithm design and analysis computational efficiency government privacy;computational efficiency;algorithm design and analysis;privacy	Designated Verifier Signature (DVS) guarantees that only a verifier designated by a signer can verify the “validity of a signature”. In this paper, we propose a new variant of DVS; Proxiable Designated Verifier Signature (PDVS) where the verifier can make a third party (i.e. the proxy) substitute some process of the verification. In the PDVS system, the verifier can reduce his computational cost by delegating some process of the verification without revealing the validity of the signature to the proxy. In all DVS systems, the validity of a signature means that a signature satisfies both properties that (1) the signature is judged “accept” by a decision algorithm and (2) the signature is confirmed at it is generated by the signer. So in the PDVS system, the verifier can make the proxy substitute checking only the property of (1). In the proposed PDVS model, we divide verifier's secret keys into two parts; one is a key for performing the decision algorithm, and the other is a key for generating a dummy signature, which prevents a third party from convincing the property (2). We also define security requirements for the PDVS, and propose a PDVS scheme which satisfies all security requirements we define.	algorithm;algorithmic efficiency;designated verifier signature;dummy variable (statistics);dynamic voltage scaling;proxy server;requirement	Mebae Ushida;Yutaka Kawai;Kazuki Yoneyama;Kazuo Ohta	2010	2010 International Conference on Security and Cryptography (SECRYPT)	10.1007/978-3-642-25206-8_14	proxy;computer science;internet privacy;privacy;world wide web;computer security;government;satisfiability	Security	-42.88014695221609	72.7595402961058	12033
81c834fb583e2b36ad500d3837bb63cd42e1d44d	the qoe evaluation method through the qos-qoe correlation model	network delivery capacity;service provider;evaluation method;correlation model;qoe measurement;qos;customer satisfaction;multimedia service qos qoe correlation;quality of experience;quality of service delay correlation streaming media bandwidth real time systems ip networks;streaming media;qoe;bandwidth;quality of service customer satisfaction ip networks;ip network;ip networks;resource availability;correlation;quality of service;multimedia service;multimedia services;user satisfaction;ip network user satisfaction service provider qoe measurement qos parameter quality of service network delivery capacity resource availability correlation model;qos parameter;real time systems	Currently, the satisfaction of user is becoming one of the most important topics concerned by the service providers. So we propose the approach method for the objective QoE measurement through the QoS parameters. The measurements and provisioning of the quality of service (QoS) are generally defined in terms of network delivery capacity and resource availability, not in terms of satisfaction to the end-user. The fundamental assumption behind such traditional provisioning is that the measured quality of service is closely related to the quality of experience (QoE) for the end-user. In the paper, we describe the QoS and QoE correlation model, and the QoE evaluation method using QoS parameter in the converged network environment is studied.	network convergence;provisioning;quality of service	Hyun-Jong Kim;Dong Hyeon Lee;Jong Min Lee;Kyoung Hee Lee;Won Lyu;Seong Gon Choi	2008	2008 Fourth International Conference on Networked Computing and Advanced Information Management	10.1109/NCM.2008.202	real-time computing;mobile qos;quality of service;computer science;multimedia;computer network	HPC	-10.055479660106514	100.39301070663933	12048
749d7bfe1bcdd36ec1f4b689bc9feee7fd100e7f	end-to-end optimization in heterogeneous distributed real-time systems	systeme temps reel;distributed system;non linear programming;systeme reparti;nonlinear programming;processor scheduling;programacion no lineal;sistema informatico;computer system;programmation non lineaire;optimizacion compiladora;satisfiability;objective function;optimization problem;sistema repartido;distributed real time system;compiler optimization;linear program;real time system;systeme informatique;sistema tiempo real;ordonnancement processeur;optimisation compilateur	In this paper we address an end-to-end optimization problem in a distributed real-time system when a set of pipelined task chains are given. End-to-end deadlines and end-to-end jitter constraints are assumed to be given for task chains, in addition to an objective function to be optimized throughout the optimization process. The objective of the optimization process is to obtain local deadlines and other system parameters that not only satisfy all the given end-to-end constraints but also minimize a given objective function. A separable programming technique is used to solve the resulting nonlinear programming problems. If an objective function and constraints satisfy a certain condition, it is shown that those problems can be solved by using a linear programming technique which already has well-established theories and results. Also, it is shown that the condition is general enough that a wide class of optimization problems can be solved in designing distributed real-time systems by using this technique.		Seonho Choi	1998		10.1007/BFb0057794	stochastic programming;optimization problem;mathematical optimization;real-time computing;nonlinear programming;computer science;multi-objective optimization;optimizing compiler;active set method;vector optimization;algorithm;satisfiability	Embedded	-8.3426089737876	62.3416335287265	12060
cb7afe6a53595c5710f0d9aa4f02f142c23ad870	abnormal flow detection technology in gpu network based on statistical classification method		Domain Name System (DNS), as the Internet “hub system” of basic resources services, mainly provides the basic services of domain name and IP address mapping. Abnormal flow detection technology plays an important role in the security service quality of Internet basic services, and it is also one of the important contents of Internet security research. The existing research mainly focuses on the analysis of network flow and other technologies at the data level, but in the context of network attacks, especially in the case of DDoS attacks, the accuracy and detection performance need to be improved. Based on the statistical method of high-performance abnormal flow detection technology, in this paper, the flow data are used for real-time statistical fitting, and the difference is made with the historical log data statistics. GPU parallel technology is used to improve the detection performance, which improves the accuracy and detection performance in the case of DDoS attacks on the network.		Huifeng Yang;Liandong Chen;Boyao Zhang;Haikuo Zhang;Peng Zuo;Ningming Nie	2018		10.1007/978-3-030-05755-8_29		EDA	-62.043223238983494	66.79289868558108	12068
6211e4b93783a4958ab7870eb0d2ff759dd89219	the technical exploration of implementing hybrid tv with cloud computing in radio and tv industry	tv cloud computing media computer architecture computational modeling broadband communication;multi screen integration cloud computing hybrid broadcast broadband tv interaction mechanism;terminal requirement hybrid tv implementation radio industry tv industry it resource integration public communication network service product delivery model broadcast institution full service provider cloud computing characteristic hybrid architecture large scale data transmission system interaction;television broadcasting cloud computing telecommunication industry;media;computer architecture;computational modeling;tv;broadband communication;cloud computing	Cloud computing is a new method, which provides computing capabilities on demand, integrates IT resources and services through public communication network, and offers users new types of service product and delivery model. In radio and TV industry, one important development area is hybrid TV during the transition from the mere broadcast institution to full-service provider. This paper based on the characteristic of cloud computing, tentatively proposes the solution provided by clouding computing for some problems in the implementation of hybrid TV, such as hybrid architecture, large-scale data, interaction of transmission system, and the variety of terminal requirement.	cloud computing;computer cluster;digital distribution;iptv;internet television;mobile television;software deployment;telecommunications network;video clip	Xiang Zheng;Fang Xiong;YaoNan Dai	2014	2014 IEEE Computers, Communications and IT Applications Conference	10.1109/ComComAp.2014.7017201	embedded system;simulation;cloud computing;computer science;utility computing;computer network	HPC	-16.664385047598927	94.47696540038919	12088
9b8593778fac50545686edfd84e247925328b6c5	network provisioning using multimedia aggregates	traffic aggregate;multimedia traffic;network resources reservation;network topology;ant network;multimedia transmission;multimedia traffic aggregation;network resource;multimedia aggregate;network utilisation	Multimedia traffic makes network provisioning a key issue. Optimal provisioning of network resources is crucial for reducing the service cost of multimedia transmission. Multimedia traffic requires not only provisioning bandwidth and buffer resources in the network but also guaranteeing a given maximum end-to-end delay. In this paper we present methods and tools for the optimal dimensioning of networks based on multimedia aggregates. The proposed method minimises the network resources reservations of traffic aggregates providing a bounded delay. The paper also introduces several methods to generate multimedia traffic aggregation using real video traces. The method is evaluated using a network topology based on the European GÉANT network. The results of these simulations allow us to discover the relationship between a required delay and the necessary bandwidth reservation (or the achievable utilisation limit). An interesting conclusion of these scenarios is that, following several recommendations, the network utilisation can reach values of around 80% or higher.		Enrique Hernández-Orallo;Joan Vila i Carbó	2007	Adv. in MM	10.1155/2007/30893	multi-frequency network;network traffic control;real-time computing;telecommunications;computer science;distributed computing;network delay;computer network	HPC	-4.615696224337094	96.86752771397913	12092
5da94ae4d7ef4a7928b92b4d17acf7339415b610	cryptographic algorithms - successes, failures and challenges		A computer-based hand-held translator device for use in relation to preparing a numeric message for sending from a telephone having a telephone keypad to a numeric pager and also in relation to displaying an alpha message originally received as a numeric message on a numeric pager. Keystroke entry of alpha and numeric keys create alpha mode and numeric mode messages on a display. Entry of a translator actuator on the keyboard accesses a chip that translates an alpha mode message on the display to a numeric mode message on the display and that translates a numeric mode message on the display to an alpha mode message in accordance with an algorithm loaded into the chip. At the sender side the alpha message on the display is translated into a numeric mode that is entered onto a telephone keypad targeted to a pager. At the receiver side, the numeric message is entered onto the translator device and then translated to an alpha message. A personal notebook system is optionally included in the translator device.	algorithm;cryptographic protocol;data mining;digital rights management;failure;online and offline	Bart Preneel	2008			computer network;cryptographic primitive;chip;keystroke logging;cryptography;algorithm;computer science;keypad;cryptographic protocol;communication source;pager	ML	-50.22027963049015	67.04998888127207	12101
d76ef3232642587a12a138e22a3e711ba59ad286	introducing perfect forward secrecy for an.on	330 wirtschaft;ddc 330;perfect forward secrecy	In this paper we discuss AN.ON’s need to provide perfect forward secrecy and show by an estimation of the channel build up time that the straight forward solution is not a practical solution. In the remaining paper we propose an improvement which enables AN.ON to provide perfect forward secrecy with respect to their current attacker model. Finally, we show that the delay, caused by our improvement, does not decrease the performance significantly.	cryptography;diffie–hellman key exchange;forward secrecy;p (complexity);session key;uptime	Benedikt Westermann;Dogan Kesdogan	2010		10.1007/978-3-642-13971-0_13	telecommunications;engineering;internet privacy;computer security	AI	-44.907448565246675	73.16995797763404	12126
a3fe940a8c337955a4aa57c03cd4a28bb99f8c31	intelligent routing for global broadband satellite internet	systeme intelligent;simulation systeme;systeme multimedia;sistema inteligente;multimedia systems;systeme conversationnel;interactive application;interactive system;heavy traffic;intelligent system;sistema conversacional;information system;system simulation;simulacion sistema;systeme information;sistema informacion	With the fast development of intemet, the multicasting applications (such as Distant Learning) have become more and more important. Since multicasting multimedia information over the wired links might generate heavy traffic streams to cause congestion, the utilization of internet will be reduced dramatically. The satellite with broadcasting capability and high bandwidth could provide an alternate transmission way. Most of applications using satellite are unidirectional. However, the bi-directional interactive applications will be needed to provide instant interaction. However the transmission latency through satellite is considerably long and might lead to the loss of interactive ability. Therefore, we propose an intelligent routing strategy to overcome the high latency and enhance the interactive capability over satellite links. Especially, this routing method is compatible with Mbone. We compare this routing method with one-to-one and one-to-many transmission and analyze the result. The results show transmission efficiency has improved.	routing	Chao-Hsu Chang;Eric Hsiao-Kuang Wu;Ming-Hui Jin;Yueh-O Tseng	1999		10.1007/BFb0100568	embedded system;simulation;telecommunications;information system	Theory	-15.466385432619044	97.60400505971381	12129
230b5479f85197559167732ec63c4004e14c77d9	model-based quantitative security analysis of mobile offloading systems under timing attacks		Mobile offloading systems have been proposed to migrate complex computations from mobile devices to powerful servers. While this may be beneficial from the performance and energy perspective, it certainly exhibits new challenges in terms of security due to increased data transmission over networks with potentially unknown threats. Among possible security issues are timing attacks which are not prevented by traditional cryptographic security. Metrics on which offloading decisions are based must include security aspects in addition to performance and energy-efficiency. This paper aims at quantifying the security attributes of mobile offloading systems. The offloading system is modeled as a stochastic process. The security quantification analysis is carried out for steady-state behaviour as to optimise a combined security and cost trade-off measure.		Tianhui Meng;Qiushi Wang;Katinka Wolter	2015		10.1007/978-3-319-18579-8_11	simulation;telecommunications	EDA	-52.84275891044264	72.32067606561276	12137
4582299a4a7d1ef0dce9323910bcb191f62b55b7	modelling and analyzing passive worms over unstructured peer-to-peer networks	basic reproduction number;equilibrium;passive worms;peer-to-peer networks;propagation model	Passive worm have posed serious security threats to the functioning of unstructured P2P networks. A delayed SEIRS epidemic model with death, off line and online rate is constructed based on the actual situation of P2P users. The basic reproduction number that governs whether a passive worm is extinct or not is obtained. In this model, time delay consists of latent and temporary immunity periods. The impact of different parameters on this model is studied with simulation results, especially the effect of time delay, which can provide an important guideline in the control of unstructured P2P networks as well as passive worm defense.	antivirus software;broadcast delay;common platform;embedded system;peer-to-peer;simulation;software propagation;transistor–transistor logic	Fangwei Wang;Yunkai Zhang;Jianfeng Ma	2010	I. J. Network Security		basic reproduction number;simulation;computer security	Metrics	-57.59881940460006	74.44525243222341	12138
a6043a742128a17fd9b772855a6408801aad0ab8	additional hash algorithms for http instance digests		[RFC3230] created the IANA registry named Hypertext Transfer Protocoln(HTTP) Digest Algorithm Values which defines values for digestnalgorithms used in HTTP. This draft adds new values to the registry.	algorithm;cryptographic hash function;hypertext transfer protocol	Anthony Bryan	2010	RFC	10.17487/RFC5843	double hashing;hash function;merkle tree;hash list;programming language;cryptographic hash function;hash tree	Theory	-26.5419321916359	87.8679923693246	12162
ad4238c1dbc55c3b3c4383a3dbc204efa529e37a	lps for lbs: location-privacy scheme for location-based services	anonymity;vehicular ad hoc networks data privacy mobility management mobile radio telecommunication security;location based service lbs;attacks vehicular ad hoc networks vanet privacy anonymity location based service lbs;public key;roads;vehicular ad hoc networks;attacks;lps infotainment driving comfort road safety ns2 network simulator physical location tracking manet mobile ad hoc network vanet vehicular ad hoc network location based services lbs location privacy protection scheme;vehicles;vehicular ad hoc networks vanet;privacy;vehicles privacy public key vehicular ad hoc networks roads	A Vehicular Ad-hoc Network (VANET) is a type of Mobile Ad-hoc Network (MANET) that is used to provide communications between nearby vehicles on a hand, and between vehicles and fixed infrastructure on the roadside on the other hand. VANET is not only used for road safety and driving comfort but also for infotainment. An application area which is expected to greatly benefit from this advanced technology is Location Based Service (LBS): a service which helps users in finding nearby places. However, this application raises a privacy issue for these users since it can profile them and track their physical location. Therefore, to successfully deploy LBS, user's privacy is one of major challenges that must be addressed. In this paper, we propose a location privacy protection scheme to encourage drivers to use this service without any risk of being pursued. Our system was implemented using NS2 network simulator and found to achieve high values of anonymity.	hoc (programming language);lightweight portable security;location-based service;privacy;simulation	Salam Doumiati;Tarek Al Choikani;Hassan Artail	2014	2014 IEEE/ACS 11th International Conference on Computer Systems and Applications (AICCSA)	10.1109/AICCSA.2014.7073233	vehicular ad hoc network;mobile ad hoc network;anonymity;computer science;ad hoc wireless distribution service;internet privacy;public-key cryptography;privacy;computer security;computer network	Mobile	-48.82719235544779	74.17607739202145	12164
feac12ad3695e6082839f86bc021fa36db0857fa	automated verification methodology of security events based on heuristic analysis		We present an automated verification methodology of the security events, that is, IDS alerts, based on heuristic analysis. The proposed verification methodology aims to automatically identify real cyberattacks from the security events and filter out false positive, so that the security analyst is able to conduct security monitoring and response more effectively. For the proposed verification methodology, we used the 1,528,730,667 security events that were obtained from Science and Technology Security Center (S&T-SEC). We then extracted the core security events that were caused by the real cyberattacks. Among the core security events, we selected the top 20 types of the security events in the number of the real attacks that they raised. By analyzing the top 20 types of the security events, we discovered essential elements and optional elements for using in the automated verification of the security events. The evaluation results showed that the proposed verification methodology could contribute to the reduction (about 67%) of the meaningless security events. Furthermore, we demonstrated that the proposed verification methodology contributed to the detection of 140 true negatives that were not identified by the security analyst and the total accuracy of the proposed verification methodology was 96.1%.	formal verification;heuristic analysis	Jungsuk Song;Younsu Lee;Kyuil Kim;Seokhun Kim;Sookyun Kim;Sang-Soo Choi	2015	IJDSN	10.1155/2015/817918	computer science;data mining;computer security	Logic	-61.77853223864468	61.53718705132125	12168
703bb9890ae9c06696f56970e181a706843c2662	a study on a management interface for vp protection switching	synchronous digital hierarchy;protection switching asynchronous transfer mode virtual colonoscopy synchronous digital hierarchy prototypes telegraphy telephony laboratories electronic mail bandwidth;switched system;electronic mail;telecommunication management network;management system;prototype systems vp protection switching management interface atm network services virtual path management system high reliability telecommunications management network tmn managed objects itu t recommendations protection switching models sdh paths standard models;tmn;vp protection switching;itu t recommendations;prototypes;protection switching models;telegraphy;telephony;atm networks;sdh paths;network interfaces;management interface;standard model;high reliability;standard models;managed objects;virtual colonoscopy;association scheme;bandwidth;atm network services;prototype systems;point of view;protection switching;requirement specification;telecommunications management network;virtual path;asynchronous transfer mode;network interfaces asynchronous transfer mode telecommunication network management synchronous digital hierarchy;telecommunication network management	With advances in various ATM network services, the ATM network is expected to grow larger and larger. An ATM VP (virtual path) protection switching system and management system will be required to ensure high reliability of this large ATM network. Models of management interfaces are being studied based on a TMN (telecommunications management network). These interfaces are called managed objects. For example, there are some ITU-T recommendations for simple protection switching models such as various kinds of equipment and SDH paths. Although these models are well implemented, study has started on the VP protection model and associated scheme. This paper first lists requirements specific to this VP protection from the management point of view. It also explains why existing standard models do not meet the requirements. Our proposed new model not only solves these problems but is also easy to implement, based on our experience of ATM-network management prototype systems.	management interface	T. Kimura;T. Yoshida	1998		10.1109/ICCCN.1998.998810	real-time computing;telecommunications;computer science;operating system;telecommunications management network;computer network	DB	-19.52228328353466	92.16609777628632	12180
1570141f259442faa0e6a9546be3ca631258d3b8	a case study in power substation network dynamics		The modern world is becoming increasingly dependent on computing and communication technology to function, but unfortunately its application and impact on areas such as critical infrastructure and industrial control system (ICS) networks remains to be thoroughly studied. Significant research has been conducted to address the myriad security concerns in these areas, but they are virtually all based on artificial testbeds or simulations designed on assumptions about their behavior either from knowledge of traditional IT networking or from basic principles of ICS operation. In this work, we provide the most detailed characterization of an example ICS to date in order to determine if these common assumptions hold true. A live power distribution substation is observed over the course of two and a half years to measure its behavior and evolution over time. Then, a horizontal study is conducted that compared this behavior with three other substations from the same company. Although most predictions were found to be correct, some unexpected behavior was observed that highlights the fundamental differences between ICS and IT networks including round trip times dominated by processing speed as opposed to network delay, several well known TCP features being largely irrelevant, and surprisingly large jitter from devices running real-time operating systems. The impact of these observations is discussed in terms of generality to other embedded networks, network security applications, and the suitability of the TCP protocol for this environment.	algorithm;align (company);control system;critical infrastructure protection;embedded system;network congestion;network security;network traffic control;real-time clock;real-time computing;real-time operating system;recovery time objective;relevance;retransmission (data networks);simulation;traction substation	David Formby;Anwar Elwalid;Raheem A. Beyah	2017	POMACS	10.1145/3084456	industrial control system;real-time computing;network delay;distributed computing;transmission control protocol;generality;network security;jitter;scada;computer science;network dynamics	Metrics	-6.152397884053434	91.91760917510092	12185
ec5d7f91a9010eb9b2306e2cd73b532d135235a3	access-controlled resource discovery for pervasive networks	naming services;resource allocation authorisation ubiquitous computing naming services;resource discovery;information security;authorisation;resource allocation;pervasive computing;computer architecture;access controlled resource discovery;design and implementation;access protocols;ubiquitous computing;access control;scalability;communication channels;service location system;algorithm design and analysis;access protocols access control communication system security pervasive computing computer architecture communication channels scalability information security algorithm design and analysis hardware;proxy based security framework;dynamic networks;pervasive networks access controlled resource discovery intentional naming system service location system proxy based security framework dynamic networks;intentional naming system;communication system security;pervasive networks;hardware	Served as a red team, introducing and exploiting security flaws to test a software self-healing environment. June 2000-September 2000 Intern, MIT Project Oxygen. Designed and implemented a peer-to-peer network for secure resource discovery and event routing to enable wireless home/office automation. Designed and implemented a caching system for certificate revocation lists in a distributed VeriSign, Inc.-based public key infrastructure. group. Implemented a controller for a mechanical ventilator by interfacing the ventilator manager with a patient monitoring system.	controller (computing);peer-to-peer;pervasive informatics;project oxygen;public key infrastructure;public-key cryptography;routing;self-management (computer science)	R. S. Sarath Babu;P. Govindaraj	2003		10.1109/ICDCSW.2003.1203646	algorithm design;scalability;resource allocation;computer science;access control;database;authorization;world wide web;access network discovery and selection function;computer security;ubiquitous computing;computer network;channel	Mobile	-48.96279088100711	70.84610730054649	12188
51d1326509f31872d3b43084929f82f80cb2ef2a	execution-driven simulation of ip router architectures	instruction level parallel;performance evaluation;branch prediction;queueing theory;simulation;transport protocols internet telecommunication network routing digital simulation multiprocessing systems queueing theory;router arbitration policies execution driven simulation ip router architectures next generation internet router architectures high performance network processor forwarding engine rsim internet traces cache replacement policies;high performance networks;line card;transport protocols;internet;telecommunication network routing;cache replacement;internet router;execution driven simulation;ip router;internet computer architecture computer science analytical models aggregates bandwidth hardware telecommunication traffic traffic control delay;multiprocessing systems;forwarding engine;table lookup;processing speed;digital simulation;next generation internet	A number of approaches have been recently proposed by different vendors for the next generation Internet router architectures, capable of processing millions of packets per second. Most of this processing speed stems from employing latest high-performance network processor or multiprocessors as the forwarding engine of the router. However, all these improvements have been proposed without any detailed study in performance evaluation. The impact of instruction level parallelism, branch prediction, multiprocessing, and cache architectures on the performance of routers is not known. In this paper, a methodology is proposed, which extends an execution-driven simulator to evaluate router architectures. We incorporate the exact model of an IP router into RSIM to analyze its performance and also develop a framework for feeding real internet traces to the simulator. Our work enables us to vary system parameters to simulate and analyze designs of realistic system with a range of traces. It is shown that the performance of internet routers can be dramatically enhanced by using multiprocessor architectures. The router design also considers various cache replacement policies and router arbitration policies.	algorithm;branch predictor;cas latency;cpu cache;communications protocol;crossbar switch;instruction-level parallelism;internet backbone;lookup table;multiprocessing;network packet;network processor;next-generation network;parallel computing;performance evaluation;router (computing);routing table;scheduling (computing);simulation;speculative execution;throughput;tracing (software)	Laxmi N. Bhuyan;Hu-Jun Wang	2001		10.1109/NCA.2001.962526	core router;parallel computing;real-time computing;the internet;line card;computer science;operating system;one-armed router;queueing theory;transport layer;virtual router redundancy protocol;branch predictor;computer network	Metrics	-4.884097154247694	66.34234366250497	12212
2c51fe5460bd5e5d3d927993b9d50ee6395d48c5	advances in cryptology - eurocrypt 2006		Let g be an element of prime order p in an abelian group and α ∈ Zp. We show that if g, g, and gαd are given for a positive divisor d of p − 1, we can compute the secret α in O(log p · ( p/d + √d)) group operations using O(max{ p/d, √d}) memory. If gαi (i = 0, 1, 2, . . . , d) are provided for a positive divisor d of p + 1, α can be computed in O(log p · ( p/d + d)) group operations using O(max{ p/d, √d}) memory. This implies that the strong Diffie-Hellman problem and its related problems have computational complexity reduced by O( √ d) from that of the discrete logarithm problem for such primes. Further we apply this algorithm to the schemes based on the DiffieHellman problem on an abelian group of prime order p. As a result, we reduce the complexity of recovering the secret key from O( √ p) to O( p/d) for Boldyreva’s blind signature and the original ElGamal scheme when p − 1 (resp. p + 1) has a divisor d ≤ p (resp. d ≤ p) and d signature or decryption queries are allowed.	blind signature;computational diffie–hellman assumption;computational complexity theory;cryptography;diffie–hellman problem;discrete logarithm;eurocrypt;key (cryptography);pollard's p − 1 algorithm	Gerhard Goos;Juris Hartmanis;Jan van Leeuwen;Serge Vaudenay	2006		10.1007/11761679	computational biology;computer science	Crypto	-39.11440522230587	80.14305809039499	12224
37546a1eb54f0bebd1a10413dc67a70555da2660	resource scheduling and load balancing fusion algorithm with deep learning based on cloud computing		With the wide application of the cloud computing, the contradiction between high energy cost and low efficiency becomes increasingly prominent. In this article, to solve the problem of energy consumption, a resource scheduling and load balancing fusion algorithm with deep learning strategy is presented. Compared with the corresponding evolutionary algorithms, the proposed algorithm can enhance the diversity of the population, avoid the prematurity to some extent, and have a faster convergence speed. The experimental results show that the proposed algorithm has the most optimal ability of reducing energy consumption of data centers.	algorithm;cloud computing;deep learning;load balancing (computing);schedule (project management)	Xiaojing Hou;Guozeng Zhao	2018	IJITWE	10.4018/IJITWE.2018070104	computer science;evolutionary algorithm;deep learning;energy consumption;scheduling (computing);cloud computing;algorithm;load balancing (computing);population;artificial intelligence;convergence (routing)	HPC	-19.02955723602548	63.3921613232818	12238
7466597100402839ba5df237399901ffe80bfead	enabling campus edge computing using geni racks and mobile resources	software;topology;network slicing;network topology;wireless communication;geni racks;connected automated vehicles cav;mobile communication;distributed testbeds;vehicular networks;vehicles;mobile edge computing;4g small cell;virtual basestation	This paper presents the architecture of GENI edge cloud computing network in the form of compute and storage resources, a mobile 4G cellular edge and a high speed campus network connecting these components. This deployment is available across fifty campuses in the US, all interconnected via a nationwide Layer-2 network. We present these capabilities in the context of vehicular sensing and control applications running on police patrol cars on the Wayne State University campus allowing end-users and researchers to collect rich datasets for public safety surveillance, vehicle internal-state sensing and modeling, and emulating next generation connected vehicle technologies. In particular, the paper provides insights about the usefulness of local edge computing cloud infrastructure for novel connected vehicle applications with high sensitivity to latency and bandwidth.	application programming interface;cloud computing;compaq lte;computer aided verification;connected car;edge computing;electronic product code;emulator;experiment;graceful exit;hardening (computing);interoperation;next-generation network;requirement;software deployment;testbed	Abhimanyu Gosain;Mark Berman;Marshall Brinn;Thomas Mitchell;Chuan Li;Yuehua Wang;Hai Jin;Jing Hua;Hongwei Zhang	2016	2016 IEEE/ACM Symposium on Edge Computing (SEC)	10.1109/SEC.2016.24	vehicular ad hoc network;embedded system;simulation;mobile telephony;computer science;operating system;computer security;network topology;wireless;computer network	Mobile	-17.179452136172756	86.72056407730251	12252
16a027150983d142eea0b4395d5d7e448e97824f	efficient power management of heterogeneous soft real-time clusters	workload distribution power management heterogeneous soft real time clusters server clusters ordered server list server activation threshold;workstation clusters computer network management;heterogeneous systems;server clusters;soft real time;server activation threshold;ordered server list;heterogeneous soft real time clusters;servers;time factors;computer network management;power management;workload distribution;mathematical model;clustering algorithms;energy management power system management clustering algorithms real time systems hardware engineering management mathematical model measurement cost function energy consumption;approximation methods;web server;workstation clusters;power demand;cost of electricity	With growing cost of electricity, the power management of server clusters has become an important problem. However, most previous researchers only address the challenge in homogeneous environments. Considering the increasing popularity of heterogeneous systems, this paper proposes an efficient algorithm for power management of heterogeneous soft real-time clusters. It is built on simple but effective mathematical models. When deployed to a new platform, the software incurs low configuration cost because no extensive performance measurements and profiling are required. To strive for efficiency, a threshold-based approach is adopted. In this paper, we systematically study this approach and its design decisions.	algorithm;mathematical model;overhead (computing);power management;profiling (computer programming);real-time clock;real-time computing;real-time transcription;server (computing);simulation	Leping Wang;Ying Lu	2008	2008 Real-Time Systems Symposium	10.1109/RTSS.2008.31	embedded system;real-time computing;computer science;operating system;cost of electricity by source;mathematical model;distributed computing;cluster analysis;web server;server	Embedded	-20.117749388866855	61.639179348152474	12256
6ca0cb97a9209bf1f8c0c26891ac99c972380ccd	an efficient identity-based proxy signature scheme in the standard model with tight reduction		Identity-based proxy signature (IDPS) is a special signature. It has many applications, such as distribution networks, mobile communication, etc. Numerous IDPS schemes have been proposed. However, most existing IDPS schemes suffer the following shortcoming: loose security reduction. This problem is very important because loose security reduction weakens the security of IDPS and makes IDPS more vulnerable to attack. In this study, based on Kang et al.’s proof technical, we propose a new identity-based proxy signature scheme with a detailed security proof in the standard model. We also reduce the security of our scheme to the hardness assumption of computational Diffie-Hellman. In order to present the advance of our scheme, we make a theory comparison between our scheme with other identity-based proxy signature schemes in terms of security reduction and computational cost. The comparison shows that our scheme has tightest security reduction. What’s more, our scheme needs less computational cost that is almost half of other schemes.		Xiaoming Hu;Hong Lu;Huajie Xu;Jian Wang;Yinchun Yang	2015		10.1007/978-3-319-19713-5_27	information security;distributed computing;computer science	Crypto	-40.171519858273605	77.21950474684797	12285
ccb0dc1c81daa84c50e7d2f68470d2d20e98dae0	a dynamic network access identifier used for location privacy	wireless access;ban logic;dynamic network access identifier;telecommunication security data privacy message authentication mobile radio;data privacy;mobile radio;telecommunication security;privacy authentication network servers wireless networks communication system security information security body sensor networks logic performance analysis roaming;message authentication;location privacy;ban logic dynamic network access identifier location privacy wireless access authentication mechanisms;dynamic networks;wireless access authentication mechanisms	Current wireless access authentication mechanisms are mostly based on the network access identifier. It may lead to the location privacy problem. This paper brings out the concept of dynamically generated network access identifier, and gives an example of authentication using the dynamically generated network access identifier. Also this paper proves the security of the authentication procedure using the BAN logic and analyzes the performance of the authentication mechanism based on DNAI.	access network;authentication;burrows–abadi–needham logic;identifier	Changsheng Wan;Aiqun Hu	2007	Future Generation Communication and Networking (FGCN 2007)	10.1109/FGCN.2007.10	data authentication algorithm;network service access point identifier;wireless wan;computer access control;computer science;access control;authentication protocol;lightweight extensible authentication protocol;multi-factor authentication;network access identifier;internet privacy;network access control;computer security;computer network;network access point	Security	-47.98386256480767	71.97546318573968	12290
027716399e3e45f6e853fbc8b7b923e2a8cfd741	a generic construction of identity-based group signature	public key cryptography;random processes digital signatures public key cryptography;digital signatures;public key cryptography protocols educational institutions digital signatures;random oracle model identity based public key cryptosystem generic construction identity based group signatures id based group signature scheme group signature scheme;security signature identity based;random processes;signature;security;identity based	Identity-based public key cryptosystem allows the user to use his identity as the public key, which can be a good alternative for certificate-based public key setting. Group signature allows any member of a group to sign on behalf of the group without revealing his identity. In this paper, we give a generic construction of identity based group signatures. Then, we construct an efficient ID-based group signature scheme. We also show that the group signature scheme is provably secure in the random oracle model.	cryptosystem;digital signature;group signature;provable security;public-key cryptography;random oracle	Liqiong Ma	2013	2013 Fourth International Conference on Emerging Intelligent Data and Web Technologies	10.1109/EIDWT.2013.109	ring signature;digital signature;self-signed certificate;threshold cryptosystem;internet privacy;group signature;blind signature;schnorr signature;world wide web;computer security;id-based cryptography	Crypto	-41.64556892174514	74.8719573256507	12292
3e3478c15414e103b4221135e7492ef643f5f452	potential performance bottleneck in linux tcp	linux;tcp;networking;process scheduling;performance analysis;protocol stack	TCP is the most widely used transport protocol on the Internet today. Over the years, especially recently, due to requirements of high bandwidth transmission, various approaches have been proposed to improve TCP performance. The Linux 2.6 kernel is now preemptible. It can be interrupted mid-task, making the system more responsive and interactive. However, we have noticed that Linux kernel preemption can interact badly with the performance of the networking subsystem. In this paper we investigate the performance bottleneck in Linux TCP. We systematically describe the trip of a TCP packet from its ingress into a Linux network end system to its final delivery to the application; we study the performance bottleneck in Linux TCP through mathematical modeling and practical experiments; finally we propose and test one possible solution to resolve this performance bottleneck in Linux TCP.	algorithm;disk space;end system;experiment;fairness measure;heart rate variability;internet;interrupt;kernel preemption;kinetic data structure;linux;mathematical model;network packet;preemption (computing);requirement;response time (technology);scheduling (computing);throughput	Wenji Wu;Matt Crawford	2007	Int. J. Communication Systems	10.1002/dac.872	tcp westwood;compound tcp;tcp congestion-avoidance algorithm;computing;tcp delayed acknowledgment;tcp global synchronization;tcp pacing;performance;telecommunications;computer science;bic tcp;tcp hole punching;operating system;transmission control protocol;mathematical model;distributed computing;h-tcp;zeta-tcp;hstcp;tcp tuning;protocol stack;tcp acceleration;computer security;tcp friendly rate control;linux kernel;computer network	Metrics	-5.241760887663065	93.57568154990169	12311
0a8e59e2d5a7b128d8b80f4676d8f7390ebb6a39	quantum information processing: the good, the bad and the ugly	protection information;procesamiento informacion;quantum information processing;proteccion informacion;quantum mechanics;criptografia;cryptography;information protection;information processing;cryptographie;theorie information;traitement information;information theory;teoria informacion	Quantum mechanics has the potential to play a major role in the future of cryptology. On the one hand, it could bring to its knees most of the current trends in contemporary cryptography. On the other hand, it offers an alternative for the protection of privacy whose security cannot be matched by classical means.	information processing;quantum information science	Gilles Brassard	1997		10.1007/BFb0052246	information processing;information theory;computer science;cryptography;artificial intelligence;mathematics;computer security;algorithm;statistics	HPC	-42.81428789458184	79.83774182680683	12372
233a7ef250e3969f6e7a688b9284bea3e9dc7650	enhanced communications transport protocol for multicast transport	local group;한국정보과학회 international conference on information networking icoin 2002;shin gak kang;vol 2;application program interface;group communication;eunsook kim;enhanced communications transport protocol for multicast transport;error control;korea information science society;transport protocol;seok joo koh;juyoung park;한국정보과학회	This paper proposes a new multicast transport protocol, called the Enhanced Communications Transport Protocol (ECTP). The proposed protocol is currently being standardized in the ITU-T SG7 and ISO/IEC JTC 1/SC 6. The ECTP is designed to support tightly controlled multicast connections. The sender is at the heart of one-to-many multicast group communications. The sender is responsible for overall connection management such as connection creation, termination, pause, resumption, and the join and leave operations. For tree-based reliability control, ECTP configures a hierarchical tree during connection creation. Error control is performed within each local group defined by a control tree. Each parent retransmits lost data in response to retransmission requests from its children. ECTP has been implemented and tested on Linux machine, along with Application Programming Interfaces based on Berkeley sockets.	berkeley sockets;error detection and correction;linux;linux;multicast;one-to-many (data model);retransmission (data networks);virtual economy	Seok Joo Koh;Juyoung Park;Eunsook Kim;Shin-Gak Kang	2002		10.1007/3-540-45803-4_6	multicast;session announcement protocol;ip multicast;application programming interface;telecommunications;communication in small groups;protocol independent multicast;computer science;operating system;pragmatic general multicast;internet group management protocol;distributed computing;distance vector multicast routing protocol;computer security;transport layer;computer network	Mobile	-23.497864702457225	88.72223854195724	12381
29cc9e7bfb98fdd71baf065ccb5be57cfe5083b7	ipstash: a set-associative memory approach for efficient ip-lookup	iterative method;cache storage;ternary content addressable memory;random access memory;power saving;longest prefix matching;ipstash;telecommunication links;information security;routing;space exploration;longest prefix match;cacti 3 2 access time;lpm;tree data structures;design space;iterative methods;telecommunication network routing;network link;energy consumption;memory architecture;indexation;associative memory;set associative caches;ip networks;network architecture;ip lookup;power consumption;content addressable storage ip networks table lookup telecommunication network routing telecommunication links iterative methods memory architecture cache storage power consumption;iteration method;content addressable storage;table lookup;routing table;simulation tool;high power;cacti 3 2 access time ip lookup routing table network link power consumption memory architecture ipstash set associative caches longest prefix match lpm iterative method;hardware;routing delay space exploration ip networks random access memory hardware energy consumption iterative methods information security tree data structures	IP-lookup is a challenging problem because of the increasing routing table sizes, increased traffic and higher speed links. These characteristics lead to the prevalence of hardware solutions such as TCAMs (ternary content addressable memories), despite their high power consumption, low update rate and increased board area requirements. We propose a memory architecture called IPStash to act as a TCAM replacement, offering at the same time, high update rate, higher performance and significant power savings. The premise of our work is that full associativity is not necessary for IP-lookup. Rather, we show that the required associativity is simply a function of the routing table size, Thus, we propose a memory architecture similar to set-associative caches but enhanced with mechanisms to facilitate IP-lookup and in particular longest prefix match (LPM). To reach a minimum level of required associativity we introduce an iterative method to perform LPM in a small number of iterations. This allows us to insert route prefixes of different lengths in IPStash very efficiently, selecting the most appropriate index in each case. Orthogonal to this, we use skewed associativity to increase the effective capacity of our devices. We thoroughly examine different choices in partitioning routing tables for the iterative LPM and the design space for the IPStash devices. The proposed architecture is also easily expandable. Using the Cacti 3.2 access time and power consumption simulation tool we explore the design space for IPStash devices and we compare them with the best blocked commercial TCAMs.	access time;cpu cache;comparator;content-addressable memory;disk array;embedded system;iteration;iterative method;longest prefix match;lookup table;multiprotocol label switching;network address translation;operator associativity;point-to-point protocol;requirement;routing table;simulation;telecommunications access method;ternary numeral system;throughput	Stefanos Kaxiras;Georgios Keramidas	2005	Proceedings IEEE 24th Annual Joint Conference of the IEEE Computer and Communications Societies.	10.1109/INFCOM.2005.1498328	parallel computing;computer science;information security;theoretical computer science;operating system;distributed computing;iterative method;computer network	Arch	-5.542480436759863	66.7883185866706	12419
06b9cdb02a7ba41fa5e94390d5f0d0dc8232e222	parq: a privacy-preserving range query scheme over encrypted metering data for smart grid	parq scheme;requester range query;cloud server;security analysis;range query;encryption;query processing;financial auditing;parq scheme query privacy security analysis requester range query hidden vector encryption range query tokens authorized requester financial auditing cloud server smart grid encrypted metering data privacy preserving range query scheme;power system measurement;smart grid;meter reading;metering data range query privacy smart grid encrypted data;smart grids;servers;hidden vector encryption;power engineering computing;metering data;vectors;encrypted metering data;smart power grids;data privacy;range query tokens;cryptography;期刊论文;privacy preserving range query scheme;smart power grids cloud computing cryptography data privacy power engineering computing power system measurement query processing smart meters;authorized requester;encrypted data;smart meters;privacy meter reading smart grids encryption data privacy query processing real time systems;privacy;cloud computing;query privacy;real time systems	Smart grid, envisioned as an indispensable power infrastructure, is featured by real-time and two-way communications. How to securely retrieve and audit the communicated metering data for validation testing is, however, still challenging for smart grid. In this paper, we propose a novel privacy-preserving range query (PaRQ) scheme over encrypted metering data to address the privacy issues in financial auditing for smart grid. Our PaRQ allows a residential user to store metering data on a cloud server in an encrypted form. When financial auditing is needed, an authorized requester can send its range query tokens to the cloud server to retrieve the metering data. Specifically, the PaRQ constructs a hidden vector encryption based range query predicate to encrypt the searchable attributes and session keys of the encrypted data. Meanwhile, the requester's range query can be transferred into two query tokens, which are used to find the matched query results. Security analysis demonstrates that in the PaRQ, only the authorized requesters can obtain the query results, while the data confidentiality and query privacy are also preserved. The simulation results show that our PaRQ can significantly reduce communication and computation costs.	authorization;computation;confidentiality;encryption;privacy;range query (database);real-time transcription;server (computing);simulation;virtual private server	Mi Wen;Rongxing Lu;Kuan Zhang;Jingsheng Lei;Xiaohui Liang;Xuemin Shen	2013	IEEE Transactions on Emerging Topics in Computing	10.1109/TETC.2013.2273889	query optimization;information privacy;computer science;operating system;database;smart grid;internet privacy;world wide web;computer security	DB	-41.26311641937988	67.46230529653725	12423
11129c0616f847f92bab819c7605b6c4c63c276b	improving media sensitivity of tcp-friendly rate control for multimedia streaming applications	tcp friendly congestion control;video streaming;multimedia streaming;best effort;computer network;rate control;tcp congestion control;congestion control;tcp friendly rate control;optimized congestion control;bandwidth sharing	In this paper, we present a TCP-friendly congestion control that is at the same time media-friendly (i.e. sensitive to media characteristics). These types of rate controls are more suitable for multimedia streaming applications than the classical TCP congestion control and smooth TCP-friendly rate controls. We build our media-friendly rate control by combining the notion of TCP-friendliness with a general optimization framework for bandwidth sharing in computer networks. The resulting control is sensitive to network conditions (i.e. TCP-friendly) and also to multimedia stream characteristics (i.e. media-friendly) which makes it more suitable for controlling the transmission rate of multimedia streaming applications and should improve the perceived quality of video streams in best-effort network conditions.	best-effort delivery;mathematical optimization;network congestion;streaming media;tcp congestion control	Adrian Sterca	2008		10.1145/1497185.1497258	best-effort delivery;tcp congestion-avoidance algorithm;network traffic control;real-time computing;tcp global synchronization;tcp westwood plus;computer science;explicit congestion notification;distributed computing;h-tcp;scalable tcp;hstcp;tcp tuning;network congestion;tcp acceleration;tcp friendly rate control;slow-start;computer network	Networks	-6.657187207607002	98.18297392470117	12435
310d4fd8eace90bbc3ea04c797a97a91eb5bad77	the design of the seer predictive caching system	libraries;computers;cache storage;overall design seer predictive caching system portable computer support disconnected environment persistent file caching semantic information user disconnection algorithms;computational linguistics portable computers cache storage file organisation;distance measurement prediction algorithms libraries marine vehicles clustering algorithms program processors computers;prediction algorithms;distance measurement;marine vehicles;portable computers;clustering algorithms;portable computers marine vehicles prediction algorithms statistics computer science algorithm design and analysis computer networks costs inference algorithms availability;computational linguistics;program processors;file organisation	Supporting portable computers in a disconnected environment will require persistent caching of files without user intervention. SEER is a system that uses semantic information to predict which files the user is likely to work on, and arranges to transparently cache them on the portable platform prior to disconnection. We present the overall design of the SBBn system and the algorithms used to determine semantic relationships.	algorithm;cache (computing);portable computer	Geoffrey H. Kuenning	1994	1994 First Workshop on Mobile Computing Systems and Applications	10.1109/WMCSA.1994.38	computer science;theoretical computer science;database;cache algorithms;world wide web	Web+IR	-17.176391369240054	68.81864199625052	12479
1eadca950f4dd1f7bdb5d60beca7ae03dbeed6dd	lightweight application level multicast tunnelling using mtunnel	packet and header compression;ip multicast;web interface;automatic media transcoding;rate control;tunnelling;internet;mbone;application level multicast;java	This paper presents a system, called mTunnel, for application level tunneling of IPmulticast traffic in a lightweight manner, where the end-user is responsible for deciding which MBone-sessions and which IP-multicast groups to tunnel. mTunnel has primarily been designed for easy deployment and easy-to-manage tunneling. Information about currently tunneled sessions and control of mTunnel is provided through a Web-interface. To save bandwidth, tunneled streams can be transcoded on the data-level; and traffic sent through the tunnel can be compressed by grouping several packets together and using statistical compression. The overall bandwidth reduction achieved can be between 5 and 14% depending on the traffic type.	accessibility;computer;eclipse;encapsulation (networking);estimation of signal parameters via rotational invariance techniques;file spanning;freedom of information laws by country;identifier;intranet;mbone;multicast;network packet;operating system;software deployment;tunneling protocol;user (computing)	Peter Parnes;Kåre Synnes;Dick Schefström	1998	Computer Communications	10.1016/S0140-3664(98)00197-2	the internet;ip multicast;telecommunications;mbone;computer science;quantum tunnelling;user interface;java;world wide web;xcast;computer network	Networks	-24.228978208720694	86.91641721001614	12481
ffb723423dd45a0293b68cd097fd32844ab72494	small business-oriented index construction of cloud data	index construction;cloud computing;lucene	With the development of cloud computing, data owners (businesses and individuals) are motivated to outsource their local complex database systems to public cloud for flexibility and economic savings. But for the consideration of user's privacy, personal data has to be special treatment locally before outsourcing to the cloud server. Considering the large number of data users and documents in cloud, it is crucial for data owner to construct an index for their data collection, which increases the cost of the data owner. Related works focus on the searches on encrypted database but rarely consider the overhead of the index construction for data owner and the extensions of the index. Although traditional index construction methods of information retrieval have been widely studied, direct application of these methods would not be necessarily suitable for our scenario. Thus, enabling an efficient index construction service is of paramount. In this paper, we define and solve the problem of index construction on small business (SBIC). Among various index methods, we choose inverted index method. An inverted index is an index data structure storing a mapping from content to its locations in a set of documents. The purpose of it is to allow fast full text searches.We firstly propose a basic SBIC scheme using Lucene (an open source project for web search engine), and then significantly improve it to meet efficient keyword extraction requirement and multi-type files demand. Thorough analysis design goals(see section 2.3) of proposed schemes is given, extensive experimental results on the dataset further show proposed scheme indeed introduce low overhead on time and space.		Kai Peng;Hua Zou;Rongheng Lin;Fangchun Yang	2012		10.1007/978-3-642-33065-0_17	inverted index;cloud computing;computer science;operating system;data mining;database;distributed computing;world wide web;computer security	Theory	-40.944962375966064	66.40792844352096	12509
2a636e316ccc2f30297d598ead6f96ac7be7313a	improving performance of a dynamic load balancing system by using number of effective tasks	dynamic load balancing;performance evaluation;processor scheduling;resource allocation;resource allocation performance evaluation interrupts processor scheduling workstation clusters;interrupts processor scheduling resource management;cluster system;interrupts;historical behavior based estimates dynamic load balancing system effective tasks resource usage cluster systems initial job placement system scheduling novel load metric;load balance;workstation clusters	Efficient resource usage is a key to achieving better performance in cluster systems. Previously, most research in this area has focused on balancing the load of each node to use the resources of an entire system more effectively. However, we can achieve further improvement in performance when the load balancing system considers the resource requirement according to the task being assigned. This kind of load balancing system, known as an initial job placement system, requires knowledge of the resource usage of a task in order to fit the job to the most suitable node. Since the initial placement requires that the tasks be scheduled before execution, all resource usage must be provided in terms of the prediction. This approach can severely affect the execution time when it uses an inaccurate prediction. We propose a novel load metric termed number of effective tasks in order to resolve the problem arising from inaccurate predictions. Thus, the initial job placement system can work without knowing job resource usage in priori. Simulation results show that the system incurs 11% shorter execution time than the conventional approach using historical behavior-based estimates.	clustered file system;elegant degradation;load (computing);load balancing (computing);node (computer science);run time (program lifecycle phase);simulation	Min Choi;Jung-Lok Yu;Hojoong Kim;Seung Ryoul Maeng	2003		10.1109/CLUSTR.2003.1253344	parallel computing;real-time computing;resource allocation;computer science;load balancing;operating system;interrupt;distributed computing	HPC	-16.971541411735068	60.801861603033096	12515
f6f8cd0976928066cd38315dfb8a07cd70ae678d	aperiodic event communication process for wearable p2p computing		Wearable computing has been proposed as an alternative to the best computing interfaces and devices for the ubiquitous computing. A digital wear can be a main element of wearable computers. This study shall apply digital yarn as a material of data communications for the purpose to take advantage a digital garment. Wearable P2P application communications are consisted of periodic or aperiodic methods. This paper proposes an aperiodic event process for wearable P2P computing. It shows the transmission process that collects from a digital garment at random time. Specially, the process supports the recovery transfer process when the aperiodic event messages are failed.		Tae-Gyu Lee;Gi-Soo Chung	2013		10.1007/978-94-007-6738-6_66	embedded system;real-time computing;distributed computing	HPC	-9.609459509591339	67.97598622453121	12522
b5e97c48a637af7c76870012e439b44f40cc06ba	the design of a secure, extensible, and deployable-programmable network platform	active network;scalability hardware web and internet services information technology communication industry physics information security heart communication system control customer service;internet;telecommunication security;telecommunication security internet telecommunication services;telecommunication services;programmable networks;conference proceeding;extensible control plane deployable programmable network platform secure network extensible network active networks network customization service deployment	Active Networks present a novel approach to network cnstomization and semce deployment. However, they introduce serious security, scalability, and performance compromises at the heart of networks that render their use onto commercial platform impractical. In this paper, we present a programmable architecture that is capable of deployment onto commercial platforms, while proriding service accommodation with secnre user separation in an extensible control plane and verified access to a realtime forwarding plane. We envision the architecture as an enabling framework that facilitates the transfer of programmable network technology to the real world.	active networking;control plane;forwarding plane;scalability;software deployment	Doan B. Hoang;Bushar Yousef;Glynn Rogers	2003		10.1109/ICON.2003.1266168	active networking;the internet;network architecture;computer science;telecommunications service;operating system;security service;network access control;world wide web;computer security;computer network	Networks	-18.09035748450406	85.09553134895074	12536
b9fd921896a4e6d197b7491dbbfd7a520a255852	multi-layer virtual transport network design	multi layer network design;virtual transport network;technical report;network management	Service overlay networks and network virtualization enable multiple overlay/virtual networks to run over a common physical network infrastructure. They are widely used to overcome deficiencies of the Internet (e.g., resiliency, security and QoS guarantees). However, most overlay/virtual networks are used for routing/tunneling purposes, and not for providing scoped transport flows (involving all mechanisms such as error and flow control, resource allocation, etc.), which can allow better network resource allocation and utilization. Most importantly, the design of overlay/virtual networks is mostly single-layered, and lacks dynamic scope management, which is important for application and network management. In response to these limitations, we propose a multi-layer approach to virtual transport network (VTN) design. This design is a key part of VTN-based network management, where network management is done via managing various VTNs over different scopes (i.e., ranges of operation). We explain the details of the multi-layer VTN design problem as well as our design algorithms, and focus on leveraging the VTN structure to partition the network into smaller scopes for better network performance. Our simulation and experimental results show that our multi-layer approach to VTN design can achieve better performance compared to the traditional single-layer design used for overlay/virtual networks.	algorithm;layer (electronics);network performance;overlay network;quality of service;routing;scope (computer science);simulation;tunneling protocol	Yuefeng Wang;Ibrahim Matta	2017	Journal of Network and Systems Management	10.1007/s10922-017-9442-z	computer network;network virtualization;intelligent computer network;computer science;element management system;network management;network architecture;network management station;open network architecture;distributed computing;overlay network	Networks	-9.901820186217936	84.12613700503798	12544
67f3e64ffe148abc032931ded0c5eec340333fc0	modeling resource-aware virtualized applications for the cloud in real-time abs	resource-aware virtualized application;cloud provider;virtualized software;real-time abs;resource management strategy;paper resource;resource availability;virtualized application;executable model;virtualized application leases resource;real-time abs model	An application’s quality of service (QoS) depends on resource availability; e.g., response time is worse on a slow machine. On the cloud, a virtualized application leases resources which are made available on demand. When its work load increases, the application must decide whether to reduce QoS or increase cost. Virtualized applications need to manage their acquisition of resources. In this paper resource provisioning is integrated in high-level models of virtualized applications. We develop a Real-Time ABS model of a cloud provider which leases virtual machines to an application on demand. A case study of the Montage system then demonstrates how to use such a model to compare resource management strategies for virtualized software during software design. RealTime ABS is a timed abstract behavioral specification language targeting distributed object-oriented systems, in which dynamic deployment scenarios can be expressed in executable models.	central processing unit;client (computing);cloud computing;computation;distributed object;executable;high- and low-level;provisioning;quality of service;real-time clock;real-time transcription;response time (technology);scenario (computing);service-level agreement;simulation;software deployment;software design;software developer;specification language;virtual machine	Einar Broch Johnsen;Rudolf Schlatte;Silvia Lizeth Tapia Tarifa	2012		10.1007/978-3-642-34281-3_8	embedded system;real-time computing;simulation	Embedded	-24.258603312550186	62.37823388983163	12575
65cdc27858b9ed916b10c09a0ce597821764e7f5	an efficient multi-user searchable encryption scheme without query transformation over outsourced encrypted data		Searchable Encryption (SE) schemes provide security and privacy to the cloud data. The existing SE approaches enable multiple users to perform search operation by using various schemes like Broadcast Encryption (BE), Attribute-Based Encryption (ABE), etc. However, these schemes do not allow multiple users to perform the search operation over the encrypted data of multiple owners. Some SE schemes involve a Proxy Server (PS) that allow multiple users to perform the search operation. However, these approaches incur huge computational burden on PS due to the repeated encryption of the user queries for transformation purpose so as to ensure that users' query is searchable over the encrypted data of multiple owners. Hence, to eliminate this computational burden on PS, this paper proposes a secure proxy server approach that performs the search operation without transforming the user queries. This approach also returns the top-k relevant documents to the user queries by using Euclidean distance similarity approach. Based on the experimental study, this approach is efficient with respect to search time and accuracy.	attribute-based encryption;broadcast encryption;euclidean distance;experiment;key (cryptography);list of java keywords;multi-user;privacy;proxy server;server (computing)	Deepthi Rao;D. V. N. Siva Kumar;P. Santhi Thilagam	2018	2018 9th IFIP International Conference on New Technologies, Mobility and Security (NTMS)	10.1109/NTMS.2018.8328677	broadcast encryption;computer network;public-key cryptography;multi-user;encryption;cloud computing;information privacy;distributed computing;computer science;proxy server;server	Security	-40.499210514589116	67.33372588970225	12581
4f6cd65648f528d69f8d4389286b434904ff5d5a	privacy preserving disclosure of authenticated energy usage data	protocols;companies;noise measurement;data authenticity privacy preserving disclosure authenticated energy usage data fine grained energy usage data smart grid technology electricity usage data third party service providers noninteractive zero knowledge proof systems noise addition;data privacy;energy consumption;games;data privacy noise games noise measurement energy consumption companies protocols;smart power grids cryptographic protocols data privacy power engineering computing;noise	Fine-grained energy usage data made available by recent advancement of smart grid technologies benefit not only electricity utility companies but also customers. Nowadays customers can utilize various services by sharing their own energy usage data. At the same time, such utilization and sharing of electricity usage data with a variety of third party service providers may cause privacy concerns. In this paper, we discuss a privacy preserving mechanism for customers' sharing of energy usage data with third parties using non-interactive zero-knowledge proof systems. Under our scheme, a customer can, for each data sharing and disclosure, add noise to her electricity usage data without entirely losing verifiability of data authenticity, thereby retaining utility of data at third parties even for billing or accounting purposes.	approximation algorithm;electronic billing;formal verification;image noise;interactivity;message authentication;non-interactive zero-knowledge proof;performance evaluation;privacy;usability;usage data	Daisuke Mashima;Arnab Roy	2014	2014 IEEE International Conference on Smart Grid Communications (SmartGridComm)	10.1109/SmartGridComm.2014.7007757	privacy software;information privacy;business;internet privacy;world wide web;computer security	Mobile	-44.88349997692901	66.36206804118234	12601
2886c81bc3f71b3a9945c8825bbdb4405947a717	securenn: efficient and private neural network training		Neural Networks (NN) provide a powerful method for machine learning training and prediction. For effective training, it is often desirable for multiple parties to combine their data – however, doing so conflicts with data privacy. In this work, we provide novel three-party and four-party secure computation protocols for various NN building blocks such as matrix multiplication, Rectified Linear Units, MaxPool, normalization etc. This enables us to construct three-party and four-party information-theoretically secure protocols for training and prediction of CNNs, DNNs and a number of other NN architectures such that no single party learns any information about the data. Experimentally, we build a system and train a (A) 3-layer DNN (B) 4-layer CNN from MiniONN, and (C) 4-layer LeNet network. Compared to the state-of-the-art prior work SecureML (Mohassel and Zhang, IEEE S&P 2017) that provided (computationally-secure) protocols for only the network A in the 2 and 3-party setting, we obtain 93X and 8X improvements, respectively. In the WAN setting, these improvements are more drastic for example, we obtain an improvement of 407X. Our efficiency gains come from a > 8X improvement in communication, coupled with the complete elimination of expensive oblivious transfer protocols. In fact, our results show that the overhead of executing secure training protocols is only between 17-33X of the cleartext implementation even for networks that achieve > 99% accuracy.	activation function;algorithm;benchmark (computing);byte;c++;convolutional neural network;deep learning;end-to-end principle;epoch (reference date);experiment;extrapolation;information privacy;information-theoretic security;iteration;mnist database;machine learning;matrix multiplication;neural networks;neural network software;oblivious transfer;online and offline;overhead (computing);pixel;plaintext;prototype;rectifier (neural networks);run time (program lifecycle phase);secure multi-party computation;surround sound;tensorflow	Sameer Wagh;Divya Gupta;Nishanth Chandran	2018	IACR Cryptology ePrint Archive		artificial neural network;machine learning;computer science;artificial intelligence	Security	-37.0171287115223	65.61615852957607	12613
d5f41d0116fc963698197912727f5199836c9aa9	routing and wavelength assignment in multi-segment wdm optical networks using clustering techniques	optical network;wavelength routing;wavelength assignment;service provider;wdm optical network;large scale;routing and wavelength assignment;network model;resource availability	This paper studies the routing and wavelength assignment (RWA) problem in multi-segment optical networks. The notion of network segment is referred to any part of the network that requires special consideration of wavelength routing such as separate administrative domains in a large scale optical network, sub-networks run by various service providers, etc. In multi-segment optical networks, each segment has different resource availability or hardware characteristics. The differences between multi-segment optical networks and homogeneous optical networks are discussed. We then present a resource abstraction technique called blocking island and define a multi-segment blocking island graph (BIG) network model. Using a minimum splitting routing heuristic introduced in the context of the blocking island paradigm in conjunction with the multi-segment BIG model, we propose a general RWA algorithm that takes a combined view of the network resource to integrate routing, wavelength assignment and gateway selection in a single routing framework. In the simulation, we demonstrate the effectiveness of our proposed algorithm by comparing it with other state-of-the-art heuristics in this area.	algorithm;blocking (computing);heuristic (computer science);network model;network segment;programming paradigm;routing and wavelength assignment;simulation;wavelength-division multiplexing	Zhemin Ding;Mounir Hamdi	2004	Photonic Network Communications	10.1023/B:PNET.0000031618.73418.a4	policy-based routing;service provider;wireless routing protocol;routing table;routing domain;routing;enhanced interior gateway routing protocol;shared risk resource group;static routing;hierarchical routing;multi-commodity flow problem;telecommunications;equal-cost multi-path routing;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;network model;distributed computing;routing protocol;link-state routing protocol;triangular routing;hazy sighted link state routing protocol;geographic routing;routing information protocol;computer network	Networks	-6.503068159380685	83.70667245621276	12618
ed84930a462b1abac0c8b626fccd4e9b008ef6cc	rings: lookup service for peer-to-peer systems in mobile ad hoc networks	distributed data;p2p system;p2p;peer to peer system;mobile environment;overlay network;mobile ad hoc network;peer to peer	A Peer-to-Peer (P2P) system consists of a set of nodes in which every node shares its own resources and services among other nodes in the system. These peer-to-peer systems are basically overlay networks, work on top of fixed network infrastructure. With the increasing popularity of mobile ad-hoc networks, it becomes necessary to think of P2P systems that can efficiently work in mobile environments.#R##N##R##N#Putting current P2P applications into mobile environments, results in multiple layer flooding because these applications will maintain different peer routes than that of by network layer. Also, routes at the application layer may not be necessarily optimal at the network layer. Here, we address this problem and propose a novel, controlled-flooding based protocol named RINGS which works at network layer and helps P2P systems to work in mobile environment efficiently. RINGS reduces query lookup cost by evenly distributing data indices throughout the network, thus reducing network layer routing overhead.	hoc (programming language);lookup table;peer-to-peer	Kalpesh Patel;Sridhar Iyer;Krishna Paul	2004		10.1007/978-3-540-30536-1_51	mobile search;mobile ad hoc network;overlay network;network architecture;mobile database;computer science;distributed computing;mobile computing;world wide web;network layer;computer network	Mobile	-13.167651237502193	74.84565193190141	12633
914b2aed80227696febc7df944596a7c7f4b3cf8	how well does file size predict wide-area transfer time?	cache storage;file servers;packet loss;network effect;cache storage wide area networks file servers internet hypermedia packet switching;packet switching;hypermedia;internet;size measurement processor scheduling computer science bandwidth delay time measurement admission control predictive models context modeling marine vehicles;shortest remaining processing time;30 kb file size wide area transfer time web servers connections scheduling transmission duration scheduling discipline srpt shortest remaining processing time packet loss heterogeneous end to end bandwidth latency transfer time cache access logs ircache nlanr web caching project http traffic network awareness end system scheduling disciplines admission control;web caching;wide area networks	In scheduling connections at busy web servers, it is commonl y assumed that transmission duration (or time in system) is di rectly proportional to the size of the file transferred. For example, a scheduling discipline such as SRPT (shortest remaining pro cessing time) could use this assumption to order connections acc ording to the residual size of the transfer. However, with a diverse client population, network effects such as packet loss, het rogeneous end-to-end bandwidths and latencies render this assu mption invalid. In this measurement study, we explore this rel ationship and investigate the predictive value of file size in dete rmining transfer time. We use the publicly available sanitized cach e access logs which are collected on a daily basis as a part of IRCache [ 16], the NLANR Web caching project, to explore this relationshipfor HTTP traffic serviced by the NLANR caches over a weeklong interval. Over this dataset, we first confirm an earlier finding: that for small transfers of up to 30KB, there is virtually no correlation between file size and transfer time; moreover, transfertimes vary over 5 orders of magnitude. For larger files, we find that file size and transfer time are increasingly well correlated as fi le size increases, but we still find that predictions of transfer time from file size alone are not highly accurate. Our findings motivate f urther investigation of incorporating network-awareness into endsystem scheduling disciplines.	end-to-end principle;hall-effect thruster;hypertext transfer protocol;network packet;scheduling (computing);shortest remaining time;web cache;web server	Manish R. Sharma;John W. Byers	2002		10.1109/GLOCOM.2002.1189014	self-certifying file system;file server;real-time computing;the internet;computer science;operating system;network effect;distributed computing;packet loss;packet switching;computer network	Metrics	-8.05072583541858	96.87021494313721	12677
23b95716166219900fdfbe8f5dc4efcbe458f711	principles for optimizing corba internet inter-orb protocol performance	protocols;optimisation;object oriented methods;performance evaluation;richly typed data transfer;application software;high speed networks;abstract data types;distributed computing;client server systems;real time systems corba internet inter orb protocol middleware protocol performance optimization heterogeneous corba compliant object request brokers interoperability tcp ip networks sunsoft iiop common data representation cdr transfer syntax interface definition language idl data types portable network format marshaling demarshaling overhead data copying function call overhead distributed multimedia applications software architecture static invocation interface public domain implementation richly typed data transfer high speed atm network dynamic skeleton interface tao;high speed atm network;data type;tao;software engineering;data representation;atm networks;public domain;transport protocols;sunsoft iiop;software architecture;distributed multimedia applications;tcp ip networks;internet;marshaling demarshaling overhead;common data representation;multimedia communication;corba internet inter orb protocol;aerospace electronics;protocol performance optimization;data copying;interface definition language;distributed object computing;middleware;network formation;ip networks;static invocation interface;internet protocols distributed computing middleware optimization methods ip networks high speed networks aerospace electronics computer science application software;interoperability;computer science;function call overhead;idl data types;internet inter orb protocol;dynamic skeleton interface;open systems;portable network format;cdr transfer syntax;high speed;object request broker;heterogeneous corba compliant object request brokers;asynchronous transfer mode;real time systems;optimization methods;public domain implementation	The Internet Inter-ORB Protocol (IIOP) enables heterogeneous CORBA-compliant Object Request Brokers (ORBs) to interoperate over TCP/IP networks. The IIOP uses the Common Data Representation transfer syntax to map CORBA Interface Definition Language (IDL) data types into a portable network format. Due to the excessive marshaling/demarshaling overhead, data copying, and high-levels of function call overhead, conventional implementations of IIOP protocols have yielded relatively poor performance over high-speed networks. To meet the demands of emerging distributed multimedia applications, however, CORBAcompliant ORBs must support interoperable and highly efficient IIOP implementations. This paper provides three contributions to the study and design of efficient CORBA IIOP implementations. First, we outline the software architecture of a typical IIOP protocol engine. Second, we pinpoint the key sources of overhead in the SunSoft IIOP implementation (which is a standard reference implementation of IIOP written in C++) by measuring its performance for transferring richly-typed data over a high-speed ATM network. Third, we empirically demonstrate the benefits of systematically applying protocol optimizations to SunSoft IIOP. These optimizations include: optimizing for the common case; eliminating gratuitous waste; replacing general purpose methods with specialized, efficient ones; precomputing values; storing redundant state to speed up expensive operations; passing information between layers; and optimizing for better processor cache performance. The results of applying these optimizations to SunSoft IIOP improved its performance substantially for all data types. The resulting optimized IIOP implementation is competitive with existing commercial ORBs using CORBA’s static invocation interface and 2 to 4.5 times (depending on the data type) faster than commercial ORBs using the dynamic skeleton interface. We have integrated the optimized IIOP implementation into TAO, which is a CORBA ORB targeted for real-time systems.	atm turbo;c++;cpu cache;common data representation;common object request broker architecture;general inter-orb protocol;interface description language;internet protocol suite;interoperability;optimizing compiler;overhead (computing);precomputation;rmi-iiop;real-time clock;real-time computing;reference implementation;software architecture;tao	Aniruddha S. Gokhale;Douglas C. Schmidt	1998		10.1109/HICSS.1998.649232	communications protocol;interoperability;common data representation;interface description language;software architecture;application software;public domain;real-time computing;the internet;data type;network formation;computer science;object request broker;operating system;software engineering;asynchronous transfer mode;middleware;database;distributed computing;external data representation;open system;programming language;abstract data type;world wide web;transport layer	PL	-20.75121899555195	71.00647040368621	12691
9aef9611907182f9655dd31b556967ea5aa24fa8	self-synchronizing communication protocols	conflicting messages;self synchronizing communication protocols;distributed system;synchronization errors;control systems;protocols;sna message transmission collisions detection collisions resolution self synchronizing communication protocols ssps synchronization problems synchronization errors process collision conflicting messages synchronization mechanism standardization protocol design operating protocols ccitt x 21 session control protocol ibm system network architecture;collisions resolution;systeme reparti;protocole transmission;synchronization mechanism;process collision;session control protocol;operating protocols;sistema informatico;reseau ordinateur;protocol design;ssps;transmission message;computer system;runtime;message transmission;computer network;sna;synchronisation;automata;protocolo transmision;sistema repartido;system recovery;protocols reachability analysis standardization control systems communication system control runtime delay automata system recovery explosions;collisions detection;synchronization;synchronization problems;red ordenador;communication protocol;explosions;systeme informatique;network architecture;sincronizacion;ccitt x 21;synchronisation protocols;communication system control;synchronous communication;reachability analysis;standardization;ibm system network architecture;transmision mensaje;transmission protocol	Abstruct-This paper presents a new approach called selfsynchronizing communication protocols (SSP’s) for handling synchronization problems in communication protocols. It is found that many synchronization errors are caused by process collision, which arises when two or more processes simultaneously transmit conflicting messages. A synchronization mechanism that allows processes to detect and resolve collisions during operation is proposed. Advantages of this approach are the simplification and standardization of protocol design. This paper then discusses the alternate design of two operating protocols, the CCITT’s X.21 and a session control protocol in the IBM’s System Network Architecture (SNA), using SSP’s. It is found that all the errors in a previous version of X.21 result directly from process collision making the protocol a suitable candidate for the application of SSP’s. The design of an abbreviated version of the SNA session control protocol using SSP’s shows the applicability of the method to protocols with more than two processes and the resulting simplification of the design.	communications protocol;ibm systems network architecture;level of detail;synchronization (computer science);text simplification	H. Paul Lin;Harry E. Stovall	1989	IEEE Trans. Computers	10.1109/12.24265	embedded system;communications protocol;synchronization;parallel computing;real-time computing;telecommunications;computer science;control system;operating system;distributed computing;computer network	Networks	-5.949492503974341	70.81458674822905	12704
85ef917ec874f897bc5877a86ebd39ec60843a59	a research on high-performance sdn controller	carrier grade networks;control systems network topology topology process control message systems computer architecture protocols;topology;control systems;protocols;software defined networking c language computer network management multi threading;china telecom cloud computing key laboratory carrier grade sdn controller software defined networking programmable network construction technology static memory allocation multithread technique stick package processing c programming language communication mechanism processing logic openflow based switch controller cluster management system east west interface large scale network management cbench testing program;controller;software defined networking;network topology;computer architecture;message systems;process control;carrier grade networks software defined networking controller	Software Defined Networking (SDN) is a new programmable network construction technology that enables centrally management and control, which is considered to be the future evolution trend of networks. A modularized carrier-grade SDN controller according to the characteristics of carrier-grade networks is designed and proposed, resolving the problem of controlling large-scale networks of carrier. The modularized architecture offers the system flexibility, scalability and stability. Functional logic of modules and core modules, such as link discovery module and topology module, are designed to meet the carrier's need. Static memory allocation, multi-threads technique and stick-package processing are used to improve the performance of controller, which is C programming language based. Processing logic of the communication mechanism of the controller is introduced, proving that the controller conforms to the OpenFlow specification and has a good interaction with OpenFlow-based switches. A controller cluster management system is used to interact with controllers through the east-west interface in order to manage large-scale networks. Furthermore, the effectiveness and high performance of the work in this paper has been verified by the testing using Cbench testing program. Moreover, the SDN controller we proposed has been running in China Telecom's Cloud Computing Key Laboratory, which showed the good results is achieved.	algorithm;carrier grade;cloud computing;cluster manager;distributed computing;distributed database;emoticon;futures studies;global network;graph theory;midi controller;mathematical optimization;memory management;multi-core processor;network switch;openflow;programming language;routing;scalability;static variable	Feng Wang;Heyu Wang;Baohua Lei;Wenting Ma	2014	2014 International Conference on Cloud Computing and Big Data	10.1109/CCBD.2014.41	communications protocol;real-time computing;controller;computer science;operating system;process control;distributed computing;software-defined networking;nc-si;network topology;computer network	HPC	-17.25349582309566	81.2163223491972	12715
777f12b0c2d25095084a4c63128ebc4f647c339e	a cpk-based security scheme at network layer	public key cryptography;computers;cpk;network security solutions cpk based security scheme network layer combined public key algorithm identity based cryptosystem packet level nonrepudiation elliptic curve digital signature algorithm rsa asymmetric cipher symmetric cipher;computer network security;public key cryptography computer network security digital signatures;network security;authentication;digital signatures;rsa;packet level nonrepudiation;combined public key algorithm;network layer;identity based cryptosystem;cpk based security scheme;public key;asymmetric cipher;mutual authentication;symmetric cipher;payloads;signal to noise ratio;elliptic curve digital signature algorithm;data security public key protocols computer security authentication identity based encryption elliptic curve cryptography ip networks national security public key cryptography;network security solutions;authentication cpk security connection;security connection	A novel security scheme at network layer is proposed. It provides mutual authentication between the communication partners by adopting the effective combined public key (CPK) algorithm, which is an identity-based cryptosystem. And each outgoing packet can be digitally signed with CPK-based signature, which uses elliptic curve digital signature algorithm (ECDSA) and may offer equal security with a far smaller key size than RSA’ s, to provide packet-level nonrepudiation when necessary. In addition, the data transmitted over the network can be encrypted for better security via a symmetric or asymmetric cipher. Compared to similar network security solutions, the proposed scheme is easier to configure and more flexible. The experimental results show that the scheme owns better efficiency.	algorithm;cipher;cryptosystem;digital signature;encryption;key size;mutual authentication;network packet;network security;non-repudiation;public-key cryptography;transmitter;unique key	Zhiyuan Xie;Junhui He;Shaohua Tang	2009	2009 International Conference on Computational Intelligence and Security	10.1109/CIS.2009.109	computer science;network security;internet privacy;public-key cryptography;computer security;computer network	Security	-47.0352898680199	72.57302704999566	12722
2ff8f4cb9ca735ccf1e7ff78e5d4505d21919bd4	sidmap: a service-oriented mapping system for loc/id split internet naming	locator;service composition;naming system;identifier;service migration	While locator/identifier split makes Internet routing more scalable, the promise of a mapping system that resolves a service to corresponding location is yet to be realized. Part of the challenge is due to most current approaches only focusing on how to find the location of a host, not the location of a service, which make these systems rely on extra naming system to provide applications the requested service’s location and introduce complex load interactions between the locator/identifier mapping system and naming system. Another challenge is due to the vast majority of current Internet usage changed from host-centric applications to data retrieval and service access, traditional domain name system (DNS) is unable to support today’s Internet needs such as service migration and composition. We introduce SIDMAP–a novel,efficient service-oriented naming scheme for incorporating service identifier/identifier mapping system that returns appropriate locators in response to mapping requests for specific service identifiers,service migration and service composition into one system. According to the result of evaluations, our mechanism has good scalability and low resolution latency.	cache (computing);communication endpoint;coupling (computer programming);data retrieval;identifier;image resolution;interaction;internet;lookup table;online locator service;routing;scalability;server (computing);service composability principle;service-oriented device architecture;service-oriented software engineering	Daochao Huang;Dong Hee Yang;Fei Song;Hongke Zhang	2011	JCM	10.4304/jcm.6.8.601-609	embedded system;identifier;telecommunications;computer science;operating system;database;world wide web;computer security;computer network;service locator pattern	Networks	-19.3096457615628	72.59186579111358	12729
eec271730248de24eeff9f7f98e73110ba82cc13	towards the introduction of the asymmetric cryptography in gsm, gprs, and umts networks	public key cryptography;third party attacks;universal mobile telecommunication system;intelligent networks gsm ground penetrating radar 3g mobile communication public key cryptography public key authentication decoding packet radio networks computer networks;mobile station;home location register;decoding;subscriber authentication;general packet radio services;cellular radio;vlr hlr link;network authentication;authentication;packet radio networks;visitor location register;umts networks;ms vlr link;asymmetric cryptography procedures;computer networks;ground penetrating radar;data ciphering;3g mobile communication;public key;asymmetric cryptography;telecommunication security;visitors location register;public private key pairs asymmetric cryptography general packet radio services gprs umts networks user authentication network authentication data ciphering gsm architecture universal mobile telecommunication system network nodes mobile station visitors location register third party attacks home location register asymmetric cryptography procedures subscriber authentication vlr hlr link ms vlr link;public private key pairs;intelligent networks;message authentication;gsm;general packet radio service;user authentication;gprs;radio links;radio links public key cryptography message authentication cellular radio packet radio networks telecommunication security;network nodes;gsm architecture	The logic ruling the user and network authentication as well as the data ciphering in the GSM architecture has been inherited by the General Packet Radio Services (GPRS) and the Universal Mobile Telecommunication System (UMTS) as well. So, in all these systems, three nodes are involved in the corresponding processes; namely, the Mobile Station (MS), the Visitors Location Register (VLR), and the Home Location Register (HLR). Moreover, the methods of the conventional cryptography have been adopted by all the three systems. In this paper a description of the subscriber authentication is given, as well as of the data ciphering, as they are recommended by the Specifications regarding the aforementioned systems. Based on this analysis, we pinpoint the vulnerable points of the VLRHLR and MSVLR links, exposed to third par& attacks, and we propose for their coverage asymmetric cryptography procedures, consisting of the introduction of public-private key pairs for the transactions between the VLR-HLR, as well as the MS-VLR.	authentication;cipher;hidden line removal;public-key cryptography	Constantinos F. Grecas;Sotiris Maniatis;Iakovos S. Venieris	2001		10.1109/ISCC.2001.935349	telecommunications;computer science;public-key cryptography;computer security;computer network;general packet radio service	Security	-48.069932021654566	71.96652552433683	12741
d7c889e6d6869fb67d354ea18110b6bbc04d4485	design of virtualized network coding functionality for reliability control of communication services over satellite		Network coding (NC) is a novel coding technology that can be seen as a generalization of classic point-to-point coding. As with classic coding, both information theoretical and algebraic views bring different and complementary insights of NC benefits and corresponding tradeoffs. However, the multiuser nature of NC and its inherent applicability across all layers of the protocol stack, call for novel design approaches towards efficient practical implementation of this technology. In this paper, we present a possible way forward to the design of NC as a virtual network functionality offered to the communication service designer. Specifically, we propose the integration of NC and Network Function Virtualization (NFV) architectural designs. The integration is realized as a toolbox of NC design domains that the service designer can use for flow engineering. Our proposed design framework combines network protocoldriven design and system modular-driven design approaches. In particular, the adaptive choice of the network codes and its use for a specific service can then be tailored and optimized depending on the ultimate service intent and underlying (virtualized) system or network. We work out a complete use case where we design geo-network coding, an application of NC for which coding rate is optimized using databases of geo-location information towards an energyefficient use of resources. Our numerical results highlight the benefits of both the proposed NC design framework and the specific application.	code;database;geolocation;information theory;linear network coding;multi-user;network function virtualization;numerical analysis;point-to-point (telecommunications);protocol stack	Tan Do-Duy;M. A. Vazquez-Castro	2018	CoRR		linear network coding;protocol stack;coding (social sciences);virtual network;computer science;distributed computing;network functions virtualization;service design;code rate	Networks	-11.108261751256652	93.55324208765522	12742
81143a4c61048fef9ef9b4b59a9f7b5d24447d0b	an iot endpoint system-on-chip for secure and energy-efficient near-sensor analytics		Near-sensor data analytics is a promising direction for internet-of-things endpoints, as it minimizes energy spent on communication and reduces network load - but it also poses security concerns, as valuable data are stored or sent over the network at various stages of the analytics pipeline. Using encryption to protect sensitive data at the boundary of the on-chip analytics engine is a way to address data security issues. To cope with the combined workload of analytics and encryption in a tight power envelope, we propose Fulmine, a system-on-chip (SoC) based on a tightly-coupled multi-core cluster augmented with specialized blocks for compute-intensive data processing and encryption functions, supporting software programmability for regular computing tasks. The Fulmine SoC, fabricated in 65-nm technology, consumes less than 20mW on average at 0.8V achieving an efficiency of up to 70pJ/B in encryption, 50pJ/px in convolution, or up to 25MIPS/mW in software. As a strong argument for real-life flexible application of our platform, we show experimental results for three secure analytics use cases: secure autonomous aerial surveillance with a state-of-the-art deep convolutional neural network (CNN) consuming 3.16pJ per equivalent reduced instruction set computer operation, local CNN-based face detection with secured remote recognition in 5.74pJ/op, and seizure detection with encrypted data collection from electroencephalogram within 12.7pJ/op.	aerial photography;artificial neural network;autonomous robot;communication endpoint;convolution;convolutional neural network;coupled cluster;data security;dynamic voltage scaling;electroencephalography;encryption;face detection;image scaling;low-power broadcasting;multi-core processor;real life;sensemaking;sensor;system on a chip	Francesco Conti;Robert Schilling;Pasquale Davide Schiavone;Antonio Pullini;Davide Rossi;Frank Ka&#x011F;an G&#x00FC;rkaynak;Michael Muehlberghuber;Michael Gautschi;Igor Loi;Germain Haugou;Stefan Mangard;Luca Benini	2017	IEEE Transactions on Circuits and Systems I: Regular Papers	10.1109/TCSI.2017.2698019	disk encryption;40-bit encryption;encryption;embedded system;data security;disk encryption hardware;client-side encryption;data analysis;analytics;computer science	Arch	-27.21640345780157	67.99970969972085	12759
8f2639212106215f20e32db49723a47c2813517a	algorithms for high performance, wide-area distributed file downloads	caracteristica funcionamiento;streaming;haute performance;storage system;algorithm performance;replicated storage;telecarga;redundancia;algoritmo adaptativo;red larga distancia;scalable storage;reseau longue distance;stockage donnee;adaptive algorithm;data storage;transmission en continu;algorithme adaptatif;redundancy;resultado algoritmo;replicated data;systeme memoire;caracteristique fonctionnement;performance algorithme;alto rendimiento;peer to peer storage;almacenamiento datos;downloading;performance characteristic;peer to peer;sistema memoria;adaptive downloads;high performance;wide area network;telechargement;redondance;wide area storage	This paper explores three algorithms for high-performance downloads of wide-area, replicated data. The storage model is based on the Network Storage Stack, which allows for flexible sharing and utilization of writable storage as a network resource. The algorithms assume that data is replicated in various storage depots in the wide area, and the data must be delivered to the client either as a downloaded file or as a stream to be consumed by an application, such as a media player. The algorithms are threaded and adaptive, attempting to get good performance from nearby replicas, while still utilizing the faraway replicas. After defining the algorithms, we explore their performance downloading a 50 MB file replicated on six storage depots in the U.S., Europe and Asia, to two clients in different parts of the U.S. One algorithm, called progress-driven redundancy, exhibits excellent performance characteristics for both file and streaming downloads.	algorithm;download;megabyte;replication (computing);storage model	James S. Plank;Scott Atchley;Ying Ding;Micah Beck	2003	Parallel Processing Letters	10.1142/S0129626403001240	parallel computing;computer science;operating system;computer data storage;database;distributed computing;redundancy;world wide web	HPC	-12.959011166389315	70.31753084632204	12761
89ae2dd5cdd2f66736b40c1efc8b540b487d5d8f	simulation study on the propagation law of sina micro-blog for tianjin event based on improved sir model		This paper studied the SIR model and had made the improvement to the model combining with the characteristics of sina micro-blog data. Based on this improved SIR model, this paper gived the simulation research on the propagation law of Sina micro-blog for Tianjin event, and it pointed out that the forwarding information of public security events presented heavy tailed characteristics.	blog;mathematical model;simulation;software propagation	Gang Liu;Guodong Ye;Haitao Tang;Ke Liu;Yongzhong Sha	2017		10.1145/3149572.3149573	microblogging;law;epidemic model;social media;computer science	NLP	-58.054707289079765	74.40106740850557	12796
21313b2aead41fb6562fd4fa2b43f4f080b2966c	applying similarities between immune systems and mobile agent systems in intrusion detection	immune system;computer security;mobile agent;intrusion detection;intrusion detection system;human immune system;command and control	"""Nearly all present-day commercial intrusion detection systems are based on a hierarchical architecture. Nodes at the bottom of the hierarchy collect information, which is passed to higher nodes in the hierarchy until the root node is reached. The root node is a command and control system that evaluates attack signatures and issues responses. Many single points of failure exist in an intrusion detection system (IDS) based on a hierarchical architecture that does not have redundant communication lines and the capability to dynamically reconfigure relationships in the case of failure of key components. For example, an attacker can cut off a control branch of the IDS by attacking an internal node or even interrupt the operation of the entire system by taking out the root command and control node. To solve this problem, we propose an IDS inspired by the human immune system. The architecture of the proposed IDS has no aggregation nodes or a root node that evaluates attack signatures. Instead, the function of attack signature evaluation is divided and placed within mobile agents. The mobile agents act similarly to white blood cells of the immune system and travel from host to host in the network to detect any intrusions. As in the immune system, intrusions are detected by distinguishing between """"self"""" and """"non-self"""", or normal and abnormal process behaviour respectively. The IDS can remain operational even when most of its components have been disabled because the agents that remain in the network can still carry out their task as they do not need to communicate with their home platform. Furthermore, because mobile agents are not static and their number can vary, the whole IDS is more difficult to disable than an IDS based only on static components."""	antivirus software;command (computing);control system;electronic signature;interrupt;intrusion detection system;mobile agent;reliability engineering;single point of failure;tree (data structure)	Marek Zielinski	2004			computer security;intrusion prevention system;computer science	Security	-61.713380119317684	64.79643005859974	12842
39b575b35f2be0dfe42763737a696ec4de218950	a network measurement architecture for adaptive applications	network measurement;network servers internet telecommunication computing prediction theory data communication software tools computerised monitoring;passive networks ip networks web and internet services adaptive systems information retrieval world wide web mirrors measurement delay network servers;network performance;site selection;telecommunication computing;data communication;network servers;low latency;server selection;internet;prediction theory;network connectivity;adaptive applications;software tools;computerised monitoring;mirrored web objects network measurement architecture adaptive applications network connectivity internet hosts data transport shared passive network performance discovery passive application specific measurements local centralized repository spand architecture spand implementation lookingglass www mirror site selection tool client response times server selection algorithm	The quality of network connectivity between a pair of Internet hosts can vary greatly. Some hosts may communicate over high bandwidth, low latency, uncongested paths, while others communicate over much lower quality paths. Adaptive applications can cope with these differences in connectivity by choosing alternate representations of objects or streams or by downloading the objects from alternate locations. In order to effectively adapt, applications must discover the condition of the network before communicating with distant hosts. Unfortunately, the ability to predict or report the quality of connectivity is missing in today’s suite of Internet services. To address this limitation, we have developed SPAND (Shared Passive Network Performance Discovery), a system that facilitates the development of adaptive network applications. In each domain, applications make passive application-specific measurements of the network and store them in a local centralized repository of network performance information. Other applications may retrieve this information from the repository and use the shared experiences of all hosts in a domain to predict future performance. In this way, applications can make informed decisions about adaptation choices as they communicate with distant hosts. In this paper, we describe and evaluate the SPAND architecture and implementation. We show how the architecture makes it easy to integrate new applications into our system and how the architecture has been used with specific types of data transport. Finally, we describe LookingGlass, a WWW mirror site selection tool that uses SPAND. LookingGlass meets the conflicting goals of collecting passive network performance measurements and maintaining good client response times. In addition, LookingGlass’s server selection algorithms based on application-level measurements perform much better than techniques that rely on geographic location or routing metrics. More than 90% of the time, our technique allows clients to download mirrored web objects within 40% of the fastest possible download time.	algorithm;centralized computing;disk mirroring;download;fastest;geographic coordinate system;host (network);hypertext transfer protocol;intel core (microarchitecture);network performance;routing;streams;self-replicating machine;server (computing);www	Mark Stemm;Srinivasan Seshan;Randy H. Katz	2000		10.1109/INFCOM.2000.832198	the internet;telecommunications;computer science;operating system;distributed computing;network performance;world wide web;computer network;low latency	Networks	-12.63781327194407	76.95175544250938	12848
ebf16cc03864dbcb1533a59616a7189dc47fffee	biobjective scheduling algorithms for execution time?reliability trade-off in heterogeneous computing systems	heterogeneous computing;scheduling algorithm	A heterogeneous computing (HC) system is composed of a suite of geographically distributed high-performance machines interconnected by a high-speed network, thereby providing high-speed execution of computationally intensive applications with diverse demands. In HC systems, however, there is a possibility of machine and network failures and this can have an adverse impact on applications running on the system. In order to decrease the impact of failures on an application, matching and scheduling algorithms must be devised which minimize not only the execution time but also the failure probability of the application. However, because of the conflicting requirements, it is not possible to minimize both at the same time. Thus, the goal of this paper is to develop matching and scheduling algorithms which account for both the execution time and the failure probability and can trade off execution time against the failure probability of the application. In order to attain these goals, a biobjective scheduling problem is first formulated and then two different algorithms, the biobjective dynamic level scheduling algorithm and the biobjective genetic algorithm, are developed. Unique to both algorithms is the expression used for computing the failure probability of an application with precedence constraints. The simulation results confirm that the proposed algorithms can be used for producing task assignments where the execution time is weighed against the failure probability.	analysis of algorithms;augmented assignment;ball grid array;benchmark (computing);converge;dls format;directed acyclic graph;genetic algorithm;heterogeneous computing;mathematical model;mathematical optimization;multi-objective optimization;network topology;pareto efficiency;requirement;run time (program lifecycle phase);scheduling (computing);simulation;the computer journal;tree network	Atakan Dogan;Füsun Özgüner	2005	Comput. J.	10.1093/comjnl/bxh086	fair-share scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;foreground-background;distributed computing;scheduling;symmetric multiprocessor system	HPC	-13.848166321576555	61.70463819438736	12849
67add931d8d728d02213a3f16b74a2a18a05fe7a	routing in the bidirectional shufflenet	optical network;shufflenet;wavelength routing;wdm optical backbone bidirectional shufflenet routing bidirectional shufflenet topology bidirectional links shortest path routing algorithm topology diameter average distance wormhole routing electronic networks back pressure flow control wavelength routing optical networks virtual channels deadlocks prevention network nodes lan interconnection;telecommunication links;telecommunication congestion control;deadlock avoidance;lan interconnection telecommunication network routing network topology telecommunication links telecommunication congestion control optical fibre networks wavelength division multiplexing;average distance;indexing terms;network topology optical receivers optical transmitters telecommunication network topology optical fiber networks wavelength routing system recovery optical interconnections spine optical design;lan interconnection;network topology;shortest path routing;optical fibre networks;telecommunication network routing;virtual channel;wormhole routing;flow control;wavelength division multiplexing	In this paper we study the bidirectional shufflenet topology, which is obtained from the well-known (unidirectional) shufflenet by considering bidirectional links. More specifically, we define a shortest path routing algorithm, and derive the diameter and the average distance of the topology. The bidirectional shufflenet is then compared, in terms of average distance, with other variations of the perfect shuffle. Bidirectional links are very common in real networks. Possible applications of bidirectional shufflenets are wormhole routing electronic networks with backpressure flow control, and wavelength routing optical networks. In the last part of the paper, the former class of networks is considered, when virtual channels are used to prevent deadlocks. We show that four virtual channels are sufficient to avoid deadlocks in the bidirectional shufflenet, regardless of the number of nodes in the topology.	algorithm;bidirectional search;deadlock;hyperlink;routing;shortest path problem;whole earth 'lectronic link;wormhole switching	Mario Gerla;Emilio Leonardi;Fabio Neri;Prasasth Palnati	2001	IEEE/ACM Trans. Netw.	10.1109/90.909027	index term;telecommunications;computer science;flow control;distributed computing;network topology;wavelength-division multiplexing;computer network	PL	-5.725411358269186	79.82768563500451	12862
7c4fad9d4d7cd2dbf66c59c19046b38aafd9e32c	applying formal methods to a protocol standard and its implementations	automatic protection switching;protocols;conformance;protocol standard;aps standard;physical layer;protocol studies;sonet automatic protection switching protocol;formal methods;optical fiber networks;conformance checks;formal method;concurrency workbench of north carolina;formal verification;conformance testing;protocol standards;protocol implementations;fault tolerance;manufacturing;performance analysis;lucent technologies aps implementation;verisoft tool;network elements;interoperability;open systems;protection switching;optical fiber communication;sonet;asynchronous transfer mode;north carolina	We explore the use of formal methods in the analysis of the SONET Automatic Protection Switching (APS) protocol. Unlike most protocol studies, we look at both conformance and interoperability aspect of APS. We use the Concurrency Workbench of North Carolina [9] to show proper interoperation of network elements running the protocol, and use the VeriSoft tool [12] to show conformance of Lucent Technologies APS implementation to the APS standard. We define a new notion of conformance, identify problems with APS, suggest general improvements to the structure of protocol standards, and suggest how protocol implementations can be written to allow conformance checks to be automated.	concurrency control;conformance testing;formal methods;interoperability;interoperation;synchronous optical networking;workbench	Glenn Bruns;Mark G. Staskauskas	1998		10.1109/PDSE.1998.668180	real-time computing;computer science;distributed computing;computer network	Security	-21.6903432859961	89.30244591449882	12872
c7c0f45f8183b484bfbb08814d0ddf6f8f66520b	estimating and understanding architectural risk		Designing a system in an era of rapidly evolving application behaviors and significant technology shifts involves taking on risk that a design will fail to meet its performance goals. While risk assessment and management are expected in both business and investment, these aspects are typically treated as independent to questions of performance and efficiency in architecture analysis. As hardware and software characteristics become uncertain (i.e., samples from a distribution), we demonstrate that the resulting performance distributions quickly grow beyond our ability to reason about with intuition alone. We further show that knowledge of the performance distribution can be used to significantly improve both the average case performance and minimize the risk of under-performance (which we term architectural risk). Our automated framework can be used to quantify the areas where trade-offs between expected performance and the “tail” of performance are most acute and provide new insights supporting architectural decision making (such as core selection) under uncertainty. Importantly it can do this even without a priori knowledge of an analytic model governing that uncertainty.CCS CONCEPTS• Computing methodologies → Uncertainty quantification; Modeling methodologies; • Computer systems organization→ Multicore architectures;	architectural decision;best, worst and average case;computer architecture;failure;glossary of computer graphics;high- and low-level;optimal design;profiling (computer programming);risk assessment;risk management;sas	Weilong Cui;Timothy Sherwood	2017		10.1145/3123939.3124541	real-time computing;uncertainty quantification;risk analysis (engineering);architecture;multi-core processor;computer science;software;management science;a priori and a posteriori;computing methodologies;random variable;risk assessment	Arch	-26.0952761957421	63.2511151789956	12884
846a49e9d4d3d61d74973d42bf3f534b366dd098	navigating the last mile with crowdsourced driving information	android os crowdsourced driving information digital maps transport network realtime traffic updates navigation services 3g 4g mobile networks internet navigation systems user preferences crowdnavi app;navigation 3g mobile communication 4g mobile communication android operating system driver information systems internet;trajectory vehicles google roads servers global positioning system	With digital maps of the transport network and realtime traffic updates, today's navigation services provide good quality routes in the major route level. Once entering the last mile near the destination, they unfortunately can be ineffective and, instead, local drivers often have a better understanding of the routes there. Given the deep penetration of 3G/4G mobile networks, drivers are now well connected anytime and anywhere; they are readily to access information from the Internet and share information to the community. These motivate our design of CrowdNavi, a complementary service to existing navigation systems, seeking to combat the last mile puzzle. CrowdNavi collects the crowdsourced driving information to identify the local driving patterns, and recommend the best local routes to reach the destinations. In this paper, we present the architectural design of CrowdNavi and the algorithms for different modules, including identifying the last segment from the drivers trajectories, scoring the landmark and locating best routes with user preferences. We have implemented the CrowdNavi app on Android OS, and have examined its performance under various circumstances. The experimental results demonstrate its superiority in navigating drivers in the last segment.	android;anytime algorithm;crowdsourcing;last mile;operating system;user (computing)	Xiaoyi Fan;Jiangchuan Liu;Zhi Wang;Yong Jiang	2016	2016 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2016.7562099	embedded system;internet privacy;world wide web;mobile robot navigation	DB	-18.122098605531274	76.85171739178729	12915
f5554d80100298785890fe8f66d7628a5675fb1a	security in ad-hoc sensor networks with pre-loaded time limited memory keys	public key cryptography;protocols;mica2dot platform specification ad hoc sensor networks pre loaded time limited memory keys information security ad hoc networks radio communication message encryption physical implementation sensor nodes tamper protected physical tamper protection time limited memory keys protocol tlmk protocol key distribution key storage smart sensors cpu power resources mica2 platform specification;ad hoc network;smart sensor;radiocommunication ad hoc networks protocols public key cryptography;mica2 simulation tlmk protocol ad hoc sensor networks security dsn key pre distribution time sensitivity;sensor network;wireless sensor network;key pre distribution;sensor network security;sensor nodes;ad hoc networks;protocols ad hoc networks encryption wireless sensor networks batteries authentication;radiocommunication;key distribution	Securing information in ad-hoc networks [1] is a non-trivial task due to the nature of their structure. Radio communication between sensors requires encryption of the messages and physical implementation of the sensor nodes in real environment requires from the node to be tamper-protected. It is very hard to comply with these two demands, because physical tamper-protection, in most cases, is unachievable. Encryption is usually either non-symmetric or symmetric. The latter is very sensitive to key revival. It is hard to distribute key securely and more — to keep at secret during operating time. This article describes Time Limited Memory Keys (TLMK) protocol of key distribution/storage for the ad hoc sensor network based on smart sensors with limited CPU power resources. Originally protocol is designed to fulfill MICA2/MICA2DOT platform [2] specification.	central processing unit;encryption;hoc (programming language);key distribution;sensor	Vadim Kimlaychuk	2011	2011 4th International Conference on Biomedical Engineering and Informatics (BMEI)	10.1109/BMEI.2011.6098723	wireless ad hoc network;wireless sensor network;computer science;internet privacy;key distribution;computer security;computer network	Mobile	-50.19190734070109	75.60078733118613	12921
04a63572445f8610bec775c3544cacf7b1cf0068	outfitting an inter-as topology to a network emulation testbed for realistic performance tests of ddos countermeasures	virtual machine;performance test;network emulation;software performance;large scale;software implementation	One of the significant requirements for testing a software implementation of an inter-AS DDoS countermeasure is to measure the performance of the implementation in a large scale topology with typical DDoS tools and traffic. Ideally, an emulated inter-AS topology with same scale of the real Internet will provide similar characteristics of the real Internet if the same number of physical servers or facilities are used. However, the number of available physical nodes in a network emulation testbed are limited to tens or hundreds of physical servers. Boosting the number of nodes by virtual machines is not suitable to measure actual software performance. We take a filtering approach in order to pick up a subgraph from the whole inter-AS topology of the real Internet to fit the facilities of a network emulation testbed. According to the consideration about required characteristics for realistic evaluation results, we propose four filtering techniques. In this paper, we try to evaluate and discuss the pros and cons of our filtering approaches and the appropriateness of the emulated inter-AS topologies created by our filtering methods.	boosting (machine learning);content-control software;denial-of-service attack;emulator;network emulation;norm (social);physical symbol system;requirement;software performance testing;testbed;virtual machine	Hiroaki Hazeyama;Mio Suzuki;Shinsuke Miwa;Daisuke Miyamoto;Youki Kadobayashi	2008			embedded system;real-time computing;simulation;software performance testing;computer science;virtual machine;operating system;computer security	Networks	-15.890226565062024	80.75296585806716	12938
2d28e3faf0c0aeac6058fdc9b9df63714ad84af8	workload engineering: optimising wan and dc resources through rl-based workload placement		With the rise in data centre virtualization, there are increasing choices as to where to place workloads, be it in web applications, Enterprise IT or in Network Function Virtualisation. Workload placement approaches available today primarily focus on optimising the use of data centre resources. Given the significant forecasts for network traffic growth to/from data centres, effective management of both data centre resources and of the wide area networks resources that provide access to those data centres will become increasingly important. In this paper, we present an architecture for workload placement, which uniquely employs a logically centralised controller that is both network and data centre aware, which aims to place workloads to optimise the use of both data centre and wide area network resources. We call this approach workload engineering. We present the results of a simulation study, where we use a reinforcement-learning based placement algorithm on the controller. Results of the study show this algorithm was able to place workloads to make more efficient use of network and data centre resources and placed ~5-8% more workloads than other heuristic placement algorithms considered, for the same installed capacity. 1. BACKGROUND With the rise in data centre (DC) virtualization, there are increasing choices as to where to place workloads, e.g. which may be represented by virtual machines (VMs) or containers. These choices may apply to web applications, to Enterprise IT and to Network Function Virtualisation (NFV), i.e. as defined by ETSI NFV [1]. Although the approach presented in this paper may apply to all cases, we focus on the NFV case. The Cisco Visual Networking Index predicts that global Internet traffic will grow 3-fold from 2015 to 2020 [2]. Further, most Internet traffic today is originated or terminated in a DC and the Cisco Global Cloud Index predicts that cloud workloads will grow 3.3-fold from 2014-2019 and that global cloud IP traffic will account for more than 80% of total DC traffic by 2019 [3]. Hence, effective management of DC resources and of the networks resources that provide access to those DCs will become increasingly important. Workload placement is a key resource management and scheduling function provided by DC virtualisation stacks (known as Virtualisation Infrastructure Managers, or VIMs in ETSI NFV terms) in use today [4], however, such solutions only consider the availability of resources within a DC {compute, memory, storage} when placing a workload. There are commercial solutions available today which augment such DC virtualisation stacks aiming to optimise workload placement by considering the availability of DC resources both within and between DCs [5], [6], [7], however, they do not consider availability of network resources. Mao et al [8] applied Reinforcement Learning (RL) to the problem of DC resource management, but similarly did not consider the availability of network resources. Conversely, other works [9, 10] have proposed approaches to workload placement within a DC which aimed to optimize the use of network resources, however, they either did not consider availability of DC resources [9] or of network resources between DCs [9, 10]. Lin et at [11] applied RL to the problem of network resource management, but similarly did not consider the availability of DC resources. In previous work [12], we proposed an approach to the placement of network traffic demands which aimed to optimize the use of IP network resources, i.e. which may provide wide area network (WAN) connectivity to and between DCs. This work did not consider availability of DC resources. In practice, as workloads impact both DC and network resources, effective workload placement needs to consider both; there is no point in optimizing one domain, if the other is constraining. This balance will also change over time as demands grow and as network and DC resources are reprovisioned asynchronously. Further, with the rise of cloud-based services, effective placement often needs to consider choices between DCs as well as within DCs. In this paper, we present an approach for workload placement which aims to optimize the use of both DC and WAN resources. 2. PROBLEM STATEMENT We consider the placement of a workload which is defined by requirements for both DC and network resources and their associated service level agreements (SLAs); a workload may be an aggregation of multiple DC resources and traffic demands: • DC: o Resource requirements: the number of vCPUs required, memory required, storage required o SLA requirements: e.g. availability o Diversity requirements: affinity/anti-affinity to other workloads o Capability requirements: e.g. Single-Root Input/Output Virtualization (SRIOV), Data Plane Development Kit (DPDK) • Network – per traffic demand: o Resource requirements: bandwidth o SLA requirements: latency, loss, availability o Diversity requirements: affinity/anti-affinity to other traffic demands We consider a scenario with multiple candidate DCs where the workload may be placed; these DCs are interconnected by a WAN. Each DC may contain multiple clusters of host compute/storage resources, each of which is under the control of a local orchestration/control function; in NFV terms, Network Function Virtualisation Infrastructure (NFVI) instances under control of a VIM (e.g. Openstack). The scope of the problem is shown in Figure 1 Figure 1. Workload Placement Scope	algorithm;centralisation;cloud computing;dpdk / dpdk.org;data center;forwarding plane;heuristic;internet protocol suite;local interconnect network;network function virtualization;network traffic control;processor affinity;reinforcement learning;requirement;scheduling (computing);service-level agreement;simulation;single-root input/output virtualization;vim;virtual machine;visual networking;web application	Ruoyang Xiu;John Evans	2017	CoRR		parallel computing;real-time computing;computer science;operating system	OS	-14.12866070856161	82.74225639408735	12944
97cbce13aa4a26d690e9480b01c2a9f498448320	is security an afterthought when designing apps?	mobile applications;mobile computing;security	Mobile applications only become really useful if combined with cloud-based services. We have observed that the increasingly short time to market may cause serious design flaws in the security architecture. In this talk I will highlight some flaws discovered in the past. For example, we looked at nine popular mobile messaging and VoIP applications and evaluated their security models with a focus on authentication mechanisms. We find that a majority of the examined applications use the user's phone number as a unique token to identify accounts; they contain vulnerabilities allowing attackers to hijack accounts, spoof sender-IDs or enumerate subscribers. Other examples pertain to (already fixed) problems in cloud-based storage services such as Dropbox.	authentication;cloud computing;computer security;dropbox;enumerated type;mobile app;telephone number	Edgar R. Weippl	2012		10.1145/2428736.2428740	engineering;internet privacy;security testing;world wide web;computer security	Security	-53.35206359793266	62.405430406792256	13003
b789308301555a7939d8b2a566c55d315a47b170	a secure computer network design	network design;secure computation	Abstract   This paper investigates fundamental issues in the design of computer networks capable of protecting information from illicit dissemination and modification. We examine networks with trusted and untrusted communications lines and develop a set of easily applied design rules for the connection of computers to form secure computer networks. Protocols that maintain security conditions are shown, covert channels and traffic analysis are examined, and a ‘good enough’ cryptosystem is shown to fulfill all of the network security and protocol requirements. Some attacks against these networks are analyzed for their effect, conclusions are presented, and future research is outlined.	network planning and design	Fred Cohen	1985	Computers & Security	10.1016/0167-4048(85)90028-8	network planning and design;computer science;network security;distributed computing;computer security;computer network	Theory	-55.41152652492737	70.70406090465107	13004
17fc7acf900ad011c7404088e3d056e1179bd1e8	resilience of sink filtering scheme in wireless sensor networks	distributed system;red sin hilo;filtering;reseau capteur;filtrage;poisson approximation;systeme reparti;heterogeneous sensor networks;message authentication code;reseau sans fil;securite;recoleccion dato;data gathering;wireless network;filtrado;wireless sensor network security;node compromise;election leader;resiliency;wireless sensor network;captador medida;measurement sensor;red sensores;sistema repartido;capteur mesure;community computing;safety;eleccion jefe;sensor array;authentification message;leader election;false data injection;cluster head;message authentication;collecte donnee;security;seguridad;wireless sensor networks	One of severe security threats in wireless sensor network is node compromise. A compromised node can easily inject false data reports on the events that do not occur. The existing approaches in which each forwarding sensor along a path probabilistically filters out injected false data may not be adequate because such protection may break down when more than a threshold number of nodes are compromised. To solve this problem, we present a sink filtering scheme in clusters of heterogeneous sensor networks. In addition to basic sensors, some powerful data gathering sensors termed as cluster heads (CHs) are added. Each aggregation report generated by a CH must carry multiple keyed message authentication codes (MACs); each MAC is generated by a basic sensor that senses the event. The sink node checks the validity of the carried MACs in an aggregation report and filters out the forged report. We analyze the resilience and overhead of the sink filtering scheme. Both analytical and simulation results show that the scheme is resilient to an increasing number of compromised nodes, with graceful performance degradation. Particularly, we adopt Poisson Approximation to investigate the performance tradeoff between resilience and overall cost, and give some suggestions on how to choose the parameters. The scheme is also scalable and efficient in communication, computation and storage.		Miao Ma	2006	Computer Communications	10.1016/j.comcom.2006.07.015	message authentication code;wireless sensor network;telecommunications;computer science;information security;operating system;key distribution in wireless sensor networks;computer security;psychological resilience;computer network	Mobile	-54.05180507320963	76.94123288291475	13006
16b4c2dc913fc361da4f03542f8f47dd0064deab	a generalized secret sharing scheme with cheater detection	secret sharing;secret sharing scheme	A new secret sharing scheme is presented in this paper to realize the generalized secret sharing policy. Different from most of previous works, it is computationally secure and each participant holds only one single shadow. Any honest participant in this scheme can detect and identify who is cheating even when all of the other participants corrupt together. An extended algorithm is also proposed to protect the secret form dishonest participant without the assumption of simultaneous release of the shadows. With (x,x)-homomorphism property, it can also be used to protect individual secrets while revealing the product of these secrets.	secret sharing	Hung-Yu Lin;Lein Harn	1991		10.1007/3-540-57332-1_12	computer science;shamir's secret sharing;mathematics;homomorphic secret sharing;secure multi-party computation;proactive secret sharing;secret sharing;verifiable secret sharing;algorithm;statistics	Crypto	-40.126487614894536	73.7590542291145	13045
a4f937ffb79c2ae7f9f897e6714b563cf9aeb8b1	on optimal light-trail assignment for multicast traffic with grooming capabilities support	multicast communication;light trail;traffic grooming;routing;unicast optical switches bandwidth routing optical fiber networks couplers network topology;optical fiber networks;optical switches;network topology;optical fibre networks;telecommunication traffic;numerical analysis;telecommunication network routing;integer programming;computational complexity;linear programming;bandwidth;traffic grooming light trail multicast;telecommunication network topology;couplers;heuristic algorithm optimal light trail network assignment grooming capability support ilp formulation static multicast traffic multicast routing problem unicast routing problem numerical analysis network topology computational complexity;telecommunication traffic computational complexity integer programming linear programming multicast communication numerical analysis optical fibre networks telecommunication network routing telecommunication network topology;multicast;unicast	In this paper, we propose a set of ILP formulation with traffic grooming consideration for static multicast traffic in light-trail networks under the objective to minimize number of established light-trails. Our major idea is to reduce the multicast routing problem to several instances of unicast routing problems owing to the hop length limitation of light-trails. In the numerical analysis, we use two network topologies and different scenarios to derive the required light-trails and the light-trail assignment of given multicast requests in light-trail networks. Compared with similar previous work, our formulation offers an option with lower computational complexity and can be used as a performance bound to corresponding heuristic algorithms.	algorithm;computational complexity theory;heuristic;level of measurement;multicast;network topology;numerical analysis;provisioning;routing;unicast	Ching-Fang Hsu;Tzu-Huan Tang;Yuan-Chih Chang	2013	2013 IEEE/ACIS 12th International Conference on Computer and Information Science (ICIS)	10.1109/ICIS.2013.6607903	routing;multicast;integer programming;traffic grooming;telecommunications;numerical analysis;protocol independent multicast;computer science;linear programming;pragmatic general multicast;distributed computing;distance vector multicast routing protocol;source-specific multicast;computational complexity theory;optical switch;network topology;bandwidth;xcast;computer network;unicast	HPC	-4.924785903151658	82.60052873906959	13052
fc01117ed45ea248fc6e223ef71cfa6f05234267	differentially private moving object database publication in location tracking service	trajectory privacy;privacy preserving;differential privacy	Location tracking applications which receives frequent updates of a moving object's position, collect numerous moving objects' location data. Public transit agencies can make use of tracking data to optimize traffic control strategies. While improper use of trajectory data could cause individuals' privacy leakage. However, existing privacy-preserving techniques are unable to provide sufficient privacy protection. In this paper, we propose a data-dependent differentially private sanitization algorithm to publish moving object database. Moreover, we make use of a set of real-world constraints to conduct constraint inference, which can boost the utility of the published data. At last, we experimentally evaluate the utility of the sanitized data in terms of range-count queries, results show high utility and efficiency of our proposal.	algorithm;constraint inference;data dependency;experiment;sanitization (classified information);spectral leakage	Zheng Huo;Teng Wang;Ping He	2016		10.1145/3007120.3007149	computer science;data mining;internet privacy;world wide web;computer security;differential privacy	DB	-40.2387311590366	63.347353321872994	13063
648f7a1a421883b2d77fa83e776c47a08459e38c	efficient low bit rate video compression technique for mobile applications	video streaming;motion compensation;video compression;motion compensated;accordian;spectral efficiency;sub sampling;mobile application	With the entry of 3G services, video based applications like live video streaming, gaming applications, video telephony are going to be in great demand. The data speed is limited in Mobile applications as the bandwidth available is a limited resource. The demand for video streaming is expected to grow in multi folds in future and speed is a critical issue in video streaming. Techniques that reduce the video bit rate are the best way to have a smooth video streaming for a given bandwidth. The mobile equipment screen displays are usually small in size, this size can hence be exploited to have a certain level of compromise with video resolution and by deploying good video compression techniques, the bit rate can be reduced to suit the mobile based applications. Improved video compression is an example of better spectral efficiency (getting the most out of limited bandwidth), which is what makes 3G cellular technology more advanced than its predecessors.	data compression;display resolution;mobile app;spectral efficiency;streaming media;videotelephony	P. Waingankar;G. S. Hayagreev	2011		10.1145/1980022.1980045	video compression picture types;simulation;uncompressed video;telecommunications;computer science;video tracking;multimedia;video processing;motion compensation;video post-processing	Mobile	-8.459238671617822	73.99330257549688	13073
8606cf099553ce9371bb1c1d0665b0996f581bcc	adaptive notification framework for converged environments		As communication environments converge, people have more ways in which to send and receive information—through various services, networks, and end-user devices. This paper proposes a notification framework architecture that allows notifications to be efficiently and effectively generated, distributed, and displayed in these new, diverse environments. This software is applicable to a wide range of applications, including office and enterprise operations, entertainment and mass media distribution, advertising, public service alerts, and vertical market applications. This framework also offers “intelligent” adaptation of notification processing; it handles notification requests according to user-level profiles and policies, simplifying notification requests for the sender and increasing the quality-of-experience for the receiver and, finally, increasing the impact of the notified information.	converge;user space	Robert M. Arlein;Stéphane Betgé-Brezetz;J. Robert Ensor	2008	Bell Labs Technical Journal	10.1002/bltj.20311	real-time computing;telecommunications;engineering;operating system;world wide web;computer security;computer network	OS	-25.470326433864262	76.74870866674193	13132
3044d1d4bc2760b8a89f7fb9653ce1f68cc3f47e	introducing tls/dtls secure access modules for iot frameworks: concepts and experiments		This paper introduces security modules for IoT frameworks. Many IoT legacy infrastructures use the TLS/DTLS protocols for communication security. Security modules are tamper resistant microcontrollers implementing open TLS/DTLS applications, with small memory footprint (less than 30KB) and modest RAM sizes (<1KB), and which perform strong mutual authentications based on symmetric or asymmetric cryptographic procedures. When a pair of security modules is used at both communication ends, this architecture is called SAM (Secure Access Module), by analogy with systems involving secure elements communications. We detail the software design of such modules for javacards, and present some performance figures. Three implementations are commented running on different platforms such as, Raspberry Pi, smartphones and Arduino boards.	arduino;authentication;communications security;cryptography;datagram transport layer security;experiment;memory footprint;microcontroller;random-access memory;raspberry pi 3 model b (latest version);sam;secure access module;smartphone;software design;tamper resistance	Pascal Urien	2017	2017 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2017.8024533	memory footprint;distributed computing;computer network;pi;datagram transport layer security;tamper resistance;communications security;architecture;computer science;analogy;secure access module	Security	-36.01102266073936	70.30741654764346	13173
0d747f175041060ba426064beb90d44379a2a5a8	a new distributed instrument for real time ethernet networks: experimental tests and characterization	experimental tests;performance evaluation;synchronization uncertainty distributed instrument real time ethernet networks logging probes timestamp assignment network events;real time;instruments ethernet networks testing protocols probes automatic control time measurement test equipment manufacturing automation costs;local area networks	This paper discusses the use of distributed instruments for performance evaluation of real-time Ethernet (RTE) networks. A new instrument, composed of several logging probes connected in different points of a RTE target network, is characterized and compared with commercially available test equipments. The most important problem in performance evaluation is the timestamp assignment to network events; special attention has been paid in measuring synchronization uncertainty among probes. In fact, experimental results show a synchronization accuracy less than 150 ns on timestamp assignments among probes of the same instrument. In the last part of the paper, a sample application on a real network has been described, illustrating the use of the proposed instrument.	distributed computing;fieldbus;open-source software;performance evaluation;real-time operating system;real-time transcription	Paolo Ferrari;Alessandra Flammini;Daniele Marioli;Andrea Taroni	2007	2007 IEEE Conference on Emerging Technologies and Factory Automation (EFTA 2007)	10.1109/EFTA.2007.4416814	local area network;embedded system;real-time computing;telecommunications;computer science;engineering;operating system;computer security;computer network	Robotics	-7.6632134322307275	70.74552300280443	13183
9a6fd5d52c3189b93d80b551434d492f0da83f3c	ensuring basic security and preventing replay attack in a query processing application domain in wsn	data integrity;query processing;packet loss;replay attack;authentication;sensor network;wireless sensor network;denial of service attack;performance metric;data freshness	Nodes in a wireless sensor network are susceptible to various attacks primarily due to their nature of deployment. Therefore, providing security to the network becomes a big challenge. We propose a scheme considering cluster architecture based on LEACH protocol to build a security mechanism in a queryprocessing paradigm within wireless sensor network. The scheme is capable of thwarting replay attack while ensuring essential properties of security such as authentication, data integrity and data freshness. Our scheme is lightweight as it employs symmetric key cryptography with very short-length key. We simulate our scheme to show its efficacy of providing basic security to the network as well as detecting replay attack in the sensor network. Further we compare our scheme with one of the existing schemes taking packet loss and packet rejection ratio as performance metrics.	application domain;authentication;cryptography;data integrity;database;dataflow;essence;malware;network packet;programming paradigm;rejection sampling;replay attack;routing;sensor;simulation;software deployment;symmetric-key algorithm	Amrita Ghosal;Subir Halder;Sur Sanjib;Dan Avishek;Sipra Das Bit	2010		10.1007/978-3-642-12179-1_28	otway–rees protocol;reflection attack;wireless sensor network;challenge–response authentication;computer science;key distribution in wireless sensor networks;internet privacy;network access control;computer security;replay attack;computer network	Security	-52.25606583099545	75.50434527496566	13196
a8d699c63901dabdf663bc4036f104158b5f06a3	computing of trust in ad-hoc networks	graphe transitif;modelizacion;distributed system;red sin hilo;confiance;systeme reparti;psychologie sociale;multimedia;generic model;reseau sans fil;securite informatique;wireless network;cerradura transitiva;metric;ad hoc network;red ad hoc;trust computing;small world;computer security;modelisation;trusted computing;confidence;sistema repartido;reseau ad hoc;fermeture transitive;confianza;seguridad informatica;grafo transitivo;edge graph;psicologia social;transitive closure;arete graphe;metrico;social psychology;modeling;transitive graph;metrique;arista grafico	Although, the notion of trust has been considered as a primitive for establishing relationships among nodes in ad-hoc networks, syntax and metrics of trust are not well defined. This paper studies computing of trust in ad-hoc networks and makes the following three contributions. Firstly, the notion of trust is formalized in terms of predict functions and strategy functions. Namely, the notion of trust in this paper is defined as a predict function that can be further evaluated by a strategy function for a pre-described action; Secondly, structures of trust are formalized as a map between a path in the underlying network graph and the corresponding edge of its transitive closure graph; Thirdly, a generic model for computing of trust in the small world is proposed.	hoc (programming language);transitive closure	Huafei Zhu;Feng Bao;Jianwei Liu	2006		10.1007/11909033_1	wireless ad hoc network;systems modeling;metric;computer science;artificial intelligence;theoretical computer science;wireless network;database;mathematics;distributed computing;confidence;trustworthy computing;transitive closure;computer security;algorithm	AI	-53.8648357277253	79.6268309988436	13209
f6f83befbcdef84426e424f4dba93703ee80555b	service architectures in h.323 and sip: a comparison	telephony systems;next generation ip networks;pstn h 323 sip next generation ip networks multimedia services telephony systems interworking quality of service service architectures telephony supplementary services;service architectures;pstn;sip;data mining;service architecture;telephony;telephony ip networks signalling protocols;next generation;ip networks;h 323;interworking;quality of service;internet telephony protocols ip networks laboratories europe next generation networking web and internet services scalability telecommunication standards concrete;telephony supplementary services;multimedia services;ip telephony;signalling protocols	One of the major challenges for next-generation IP networks is to provide new, attractive multimedia services. This includes traditional telephony (voice over IP) and the interworking with legacy telephony systems. In addition to the general problems regarding the support of realtime services in the IP network, e.g., quality of service, voice over IP focuses on the control of advanced features such as supplementary services well known from telephony and on the mechanisms for their fast and efficient development and deployment. The two most promising approaches in the area of multimedia over IP are the protocol suites H.323 (ITU-T) and SIP (IETF). Several comparisons of these two protocols have already been published, but comparisons of their service architectures have been rarely addressed. This tutorial describes and compares the service architectures of H.323 and SIP. The basic protocol architectures are explained, followed by an in depth evaluation of the service implementation mechanisms. The analyses focus mainly on the control of telephony supplementary services in H.323 and SIP and are backed up by detailed examples. Although the two protocol architectures are quite similar, it is shown that there are considerable differences regarding their supplementary service architectures. H.323 (together with H.450) has been especially focused on supplementary services, smooth interworking with the PSTN, and interoperability between different implementations. In this respect, it has clear advantages for IP telephony applications. SIP has been designed with a broader scope, providing more generic syntax and semantics regarding feature definition and session description. Since the SIP standards do not describe details of possible application and service features, this bears the danger of interoperability problems, e.g, for supplementary services. SIP offers advantages for non voice over IP services and applications. A coexistence of both protocols can be foreseen, stressing the importance of interworking between them.	backup;coexist (image);internet protocol suite;interoperability;protocol stack;quality of service;service-oriented architecture;software deployment	Josef Glasmann;Wolfgang Kellerer;Harald Müller	2003	IEEE Communications Surveys & Tutorials	10.1109/COMST.2003.5341337	quality of service;sip trunking;telecommunications;computer science;service-oriented architecture;voice over ip;session initiation protocol;telephony;h.323;ip multimedia subsystem;computer security;computer network	Networks	-14.319451402369491	92.71169303686433	13266
23311b1a51919361e217c2a55a2be3662c1748b0	schemes for slot reuse in crma	protocols;performance evaluation;metropolitan area networks;topology transmitters signal generators access control media access protocol computer science optical receivers hardware optical buffering;polynomial time algorithm;network topology;network topology multi access systems digital simulation metropolitan area networks local area networks protocols performance evaluation;simulation results slot reuse crma continuous message transmissions contiguous slots bus erasure nodes destination release;multi access systems;variable bandwidth switching system;network flow;combinatorial optimization;local area networks;digital simulation	Several schemes for slot reuse in CRMA are studied. A major challenge in CRMA is to incorporate slot reuse together with continuous message transmissions, i.e., to ensure that every message is transmitted in a stream of contiguous slots on the bus. Schemes based on the ideas of Erasure Nodes and Destination Release are developed and simulation results are presented.	scheduling (computing);simulation;throughput	Oran Sharon;Adrian Segall	1993	IEEE/ACM Trans. Netw.	10.1109/90.311625	local area network;communications protocol;real-time computing;flow network;telecommunications;combinatorial optimization;computer science;network topology;computer network	Embedded	-5.821513054489784	79.36969330749375	13284
151e8512a880cfb972edd173991f9d5a36ee062b	an analysis of safer	sousmodules z invariant;chaine markov;cadena markov;encryption;transformacion hadamard;block cipher;key words block cipher;transmission message;message transmission;cryptanalysis;cryptage;criptografia;scheduling;cryptography;xor circuit;security key;cryptographie;cle 64 bits;ordonamiento;algorithme safer;hadamard transformation;cle securite;transformation hadamard;circuit ou exclusif;invariant z submodules;ordonnancement;transmision mensaje;markov chain;safer;llave seguridad	We investigate some of the algebraic properties of the SAFER block cipher when the message space is considered as a Z -module. In particular, we consider the invariant Z -submodules of the PHT layer and show how these invariant Z -submodules give potential cryptographic weaknesses.	block cipher;cryptography;linear algebra;pseudo-hadamard transform	Sean Murphy	1998	Journal of Cryptology	10.1007/s001459900046	block cipher;cryptanalysis;markov chain;computer science;cryptography;theoretical computer science;mathematics;scheduling;computer security;encryption;algorithm;statistics	Crypto	-40.71032846985537	81.28149995638631	13349
7f9bbe985ccf6c16b6ef60ccb9ef04e4219b54cb	unauthorized origin crossing on mobile platforms: threats and mitigation	same origin policy;ios;android;mobile platform	With the progress in mobile computing, web services are increasingly delivered to their users through mobile apps, instead of web browsers. However, unlike the browser, which enforces origin-based security policies to mediate the interactions between the web content from different sources, today's mobile OSes do not have a comparable security mechanism to control the cross-origin communications between apps, as well as those between an app and the web. As a result, a mobile user's sensitive web resources could be exposed to the harms from a malicious origin. In this paper, we report the first systematic study on this mobile cross-origin risk. Our study inspects the main cross-origin channels on Android and iOS, including intent, scheme and web-accessing utility classes, and further analyzes the ways popular web services (e.g., Facebook, Dropbox, etc.) and their apps utilize those channels to serve other apps. The research shows that lack of origin-based protection opens the door to a wide spectrum of cross-origin attacks. These attacks are unique to mobile platforms, and their consequences are serious: for example, using carefully designed techniques for mobile cross-site scripting and request forgery, an unauthorized party can obtain a mobile user's Facebook/Dropbox authentication credentials and record her text input. We report our findings to related software vendors, who all acknowledged their importance. To address this threat, we designed an origin-based protection mechanism, called Morbs, for mobile OSes. Morbs labels every message with its origin information, lets developers easily specify security policies, and enforce the policies on the mobile channels based on origins. Our evaluation demonstrates the effectiveness of our new technique in defeating unauthorized origin crossing, its efficiency and the convenience for the developers to use such protection.	android;authentication;authorization;credential;cross-site cooking;cross-site scripting;dropbox;interaction;malware;mobile app;mobile computing;mobile device;protection mechanism;web content;web resource;web service;ios	Rui Wang;Luyi Xing;XiaoFeng Wang;Shuo Chen	2013		10.1145/2508859.2516727	mobile search;mobile web;computer science;mobile technology;mobile deep linking;internet privacy;mobile computing;world wide web;computer security;android	Security	-54.55696858199106	61.458948579615694	13371
1498e3c2accd801cf0876897a3079d938609565d	joint optimization of vm placement and request distribution for electricity cost cut in geo-distributed data centers	silicon;minimization;virtual machines cloud computing computer centres integer programming linear programming power aware computing pricing;large scale systems joint vm placement optimization request distribution electricity cost cut geo distributed data centers cloud services operational expenditure opex electricity price diversity multielectricity market data center resizing technique virtual machines user request distribution heterogeneous electricity prices mixed integer linear programming problem milp computation efficient heuristic algorithm;distributed databases;electricity;optimization;quality of service;electricity silicon quality of service optimization distributed databases delays minimization;delays	The rising demand on cloud services has made the electricity cost become the main operational expenditure (OPEX) to data center providers. By exploring the geographical distribution feature of data centers and the electricity price diversity in modern multi-electricity market, data center resizing technique emerges as a promising solution to lowering the electricity cost. Since services are usually provided by leasing virtual machines (VMs) over geo-distributed data centers, the corresponding user requests must be distributed only to these VMs. This motivates us to study the electricity cost minimization problem with the joint consideration of VM placement, user request distribution and data center resizing in geo-distributed data centers with heterogeneous electricity prices. To the best of our knowledge, we are the first to study this optimization problem, which is formulated as a mixed-integer linear programming (MILP) problem and then solved by a computation-efficient heuristic algorithm in large-scale systems. The high efficiency of our proposal is validated by extensive simulation based studies.	algorithm;cloud computing;computation;data center;experiment;heuristic (computer science);ibm notes;integer programming;linear programming;mathematical optimization;optimization problem;polynomial;simulation;two-phase commit protocol;virtual machine	Lin Gu;Deze Zeng;Song Guo;Baoliu Ye	2015	2015 International Conference on Computing, Networking and Communications (ICNC)	10.1109/ICCNC.2015.7069434	real-time computing;simulation;computer science;operations management	HPC	-20.900883258618023	63.38044985583764	13435
3c5c3e5f4d7f1019d4cbbb27327f852d59a26e45	an adaptive framework for multiprocessor real-time system	control systems;adaptive scheduling framework;multiprocessor;optimization technique;processor scheduling;real time;processor sharing;runtime;real time adaptivity;adaptive;scheduling algorithm;feedback;biomedical engineering;adaptive systems;multiprocessor real time system;feedback adaptive real time multiprocessor;optimization techniques;adaptive scheduling;computer science;microphone arrays;optimization techniques multiprocessor real time system adaptive scheduling framework real time adaptivity feedback;real time systems	In this paper, we develop an adaptive scheduling framework for changing the processor shares of tasks - a process called reweighting - on real-time multiprocessor platforms. Our particular focus is adaptive frameworks that are deployed in environments in which tasks may frequently require significant share changes. Prior work on enabling real-time adaptivity on multiprocessors has focused exclusively on scheduling algorithms that can enact needed adaptations. The algorithm proposed in this paper uses both feedback and optimization techniques to determine at runtime which adaptations are needed.	algorithm;experiment;feedback;mathematical optimization;multiprocessing;multiprocessor scheduling;real-time clock;real-time operating system;run time (program lifecycle phase);scheduling (computing);test case	Aaron Block;Björn B. Brandenburg;James H. Anderson;Stephen Quint	2008	2008 Euromicro Conference on Real-Time Systems	10.1109/ECRTS.2008.21	parallel computing;real-time computing;multiprocessing;computer science;control system;adaptive system;operating system;adaptive behavior;feedback;distributed computing;scheduling	Embedded	-8.19977562398898	61.65854624779639	13474
149405435a650d5e283271fd51a83144491606e0	analysis of optical networks with heterogeneous grooming architectures	blocking probability;optical network;probability;optical fiber networks wavelength division multiplexing telecommunication traffic analytical models reluctance generators wdm networks bandwidth computer networks optical wavelength conversion time division multiplexing;traffic grooming;wdm tdm switching;optical networks;optical fibre networks;telecommunication traffic;telecommunication network routing;performance model;user requirements;heterogeneous grooming architectures;time division multiplexing;telecommunication network routing optical fibre networks telecommunication traffic wavelength division multiplexing time division multiplexing probability;performance modeling;unit call capacity requirements optical networks heterogeneous grooming architectures wavelength division multiplexing wavelength capacity resource placement algorithms blocking probability time division multiplexing traffic grooming fixed path routing;analytical model;wavelength division multiplexing;wavelength division multiplex	Traffic grooming in optical networks employing wavelength division multiplexing (WDM) has gained prominence due to the prevailing disparity between the user requirement and wavelength capacity. Nodes in an optical network get upgraded to the latest grooming technology slowly with time. Hence, WDM grooming networks are expected to employ heterogeneous grooming architectures. In this paper, we develop an analytical model to evaluate the blocking performance of WDM grooming networks with heterogeneous grooming capabilities. We demonstrate the accuracy of the analytical model by comparing the analytical results with that of the simulation. We observe that analytical models with and without precise knowledge of the grooming architectures predict similar performance. The proposed analytical model can be employed by resource placement algorithms that identify a set of nodes and links that need to be upgraded when the resources are limited.	algorithm;binocular disparity;blocking (computing);simulation;user requirements document;wavelength-division multiplexing	Srinivasan Ramasubramanian;Arun K. Somani	2004	IEEE/ACM Transactions on Networking	10.1109/TNET.2004.836094	traffic grooming;telecommunications;computer science;user requirements document;probability;time-division multiplexing;wavelength-division multiplexing;computer network	Metrics	-5.98022984744104	84.70463284709156	13484
3215065de17f11380fd21328d90d52a8619946ac	controlling spam emails at the routers	belief networks;bayesian classifier;pattern classification unsolicited e mail telecommunication network routing internet telecommunication congestion control belief networks;telecommunication congestion control;unsolicited electronic mail electronic mail bandwidth bayesian methods communication system traffic control computer science internet network servers web server probes;short timespan delivery spam email control network router unsolicited bulk commercial email internet information bandwidth consumption front line defense end user level spam identification bayesian classifier;internet;telecommunication network routing;pattern classification;rate limiting;unsolicited e mail;control method	"""Like it or not, unsolicited bulk commercial Email (aka """"spam"""") has become a regular menu item on the Internet information diet. Every day, millions of people find their Email in-boxes clogged with vast quantities of spam. Moreover, the daily replenishment of all those in-boxes with new spam also consumes significant amount of network bandwidth. Dealing with spam is like fighting a battle against a large army; the most effective approach is to employ multiple tactics. However, almost all spam control methods that have been proposed and implemented follow the same basic theme of establishing a """"front line"""" of defense at the end-user level. Thus, in this paper we propose a method for blocking the supply lines. More specifically, we identify spam at the router level and control it via rate limiting. Spam identification is done in two phases. In the first phase, we identify the bulk stream of Email messages and in second phase we apply Bayesian classifier to identify whether it is a spam. If a bulk Email stream is classified as a spam then we rate limit it (e.g. no more than one copy per minute). Our proposed method exploits the short timespan delivery and bulkiness of spam Emails. We use publicly available spam corpus to evaluate our proposed scheme and in the other set of experiments, we work on one month sanitized log of our department Emails to provide the representative results."""	anti-spam techniques;antivirus software;blocking (computing);collaborative filtering;email;experiment;internet backbone;naive bayes classifier;network congestion;pattern matching;rate limiting;router (computing);spamming;vipul's razor	Banit Agrawal;Nitin Kumar;Mart Molle	2005	IEEE International Conference on Communications, 2005. ICC 2005. 2005	10.1109/ICC.2005.1494611	forum spam;the internet;naive bayes classifier;srizbi botnet;telecommunications;computer science;spamming;spambot;rate limiting;spam and open relay blocking system;email address harvesting;internet privacy;world wide web;computer security;sping;computer network	DB	-57.483039317606426	65.16164095151446	13489
32980448b09a3a61685281961949afd848933399	edge router multicasting with mpls traffic engineering	multicast delivery tree;routing protocols;branching point;multiprotocol label switching;near optimal performance;design engineering;steiner trees;branch point;ip multicast;traffic control;network performance;mpls;multiprotocol label switching telecommunication traffic quality of service traffic control design engineering unicast routing protocols multicast protocols steiner trees heuristic algorithms;trees mathematics;point to multipoint lsp;near optimal performance edge router multicasting internet mpls explicit routing traffic engineering network performance quality of service qos native ip multicasting point to multipoint lsp multipoint to multipoint lsp traffic aggregation layout design branching point multicast delivery tree unicast problems erm routing protocols steiner tree heuristic routing algorithm;qos;transport protocols;telecommunication traffic;internet;multicast protocols;layout design;explicit routing;heuristic algorithms;heuristic routing algorithm;multipoint to multipoint lsp;routing algorithm;traffic aggregation;unicast problems;traffic engineered;traffic engineering;quality of service;routing protocol;native ip multicasting;steiner tree;edge router multicasting;transport protocols multiprotocol label switching internet telecommunication traffic routing protocols quality of service trees mathematics multicast protocols;unicast;erm routing protocols	Explicit routing in MPLS is utilized in traffic engineering to maximize the operational network performance and to provide Quality of Service (QoS). However, difficulties arise while integrating native IP multicasting with MPLS traffic engineering, such as point-to-multipoint or multipoint-tomultipoint LSPs layout design and traffic aggregation. In this paper, we have proposed an edge router multicasting (ERM) scheme by limiting branching point of multicast delivery tree to only the edges of MPLS domains. As a result, multicast LSP setups, multicast flow assignments, and multicast traffic aggregation are reduced to unicast problems. We have studied two types of ERM routing protocols in the paper. The first approach is based on modifications to the existing multicast protocols, while the second approach applies Steiner tree-based heuristic routing algorithm in the edge router multicasting environment. The simulation results demonstrate that the ERM scheme based on Steiner tree heuristic can provide near-optimal performance. The results also demonstrate that ERM provides a traffic engineering friendly approach without sacrificing the benefits of native IP multicasting.	algorithm;heuristic routing;multicast;multipoint ground;multiprotocol label switching;network performance;point-to-multipoint communication;quality of service;router (computing);simulation;steiner tree problem;unicast	Baijian Yang;Prasant Mohapatra	2002		10.1109/ICON.2002.1033287	multiprotocol label switching;traffic engineering;multicast;quality of service;telecommunications;steiner tree problem;protocol independent multicast;computer science;distributed computing;routing protocol;xcast;computer network	Metrics	-5.41954133235297	83.6552524859543	13504
71621781df590618cbf0ae864d0c0bedf35b9285	a related-key attack against multiple encryption based on fixed points	related key attacks;complexity theory;barium;3des;cryptanalysis;barium ciphers complexity theory three dimensional displays;three dimensional displays;ciphers;triple encryptions;triple encryption;cryptanalysis triple encryption	In order to alleviate the burden of short keys, encrypting a multiple times has been proposed. In the multiple encryption mode, there may be encryptions under the same or different keys. There have been several attacks against this encryption mode. When triple encryption is based on two keys, for instance, Merkle and Hellman proposed a subtle meet-in-the-middle attack with a complexity similar to breaking a single encryption, requiring nearly all the codebook. In the case of triple encryption with three keys, Kelsey, Schneier, and Wagner proposed a related-key attack with complexity similar to breaking a single encryption. In this paper, we propose a new related-key attack against triple encryption which compares to breaking single encryption in the two aforementioned cases. Based on finding fixed points in a decrypt-encrypt sequence, we propose a related-key attack against a two-key triple encryption. Our attack has exactly the same performance as a meet-in-the-middle on double encryption. When considering two keys, it is comparable to the Merkle-Hellman attack, except that uses related keys. And, when considering three keys, it has a higher complexity than the Kelsey-SchneierWagner attack, but has the advantage that it can live with known plaintexts.	block cipher mode of operation;codebook;diffie–hellman key exchange;fixed point (mathematics);known-plaintext attack;meet-in-the-middle attack;merkle–damgård construction;merkle–hellman knapsack cryptosystem;multiple encryption;plaintext;related-key attack;triple des	Asli Bay;Atefeh Mashatan;Serge Vaudenay	2011		10.1007/978-3-642-35755-8_19	multiple encryption;block cipher;cryptanalysis;triple des;watermarking attack;disk encryption theory;40-bit encryption;plaintext-aware encryption;computer science;theoretical computer science;symmetric-key algorithm;barium;internet privacy;deterministic encryption;computer security;probabilistic encryption;56-bit encryption;attribute-based encryption	Crypto	-37.442029576981426	80.05898518156874	13509
6b37ebe37e7188462cf355ab8df07902b36da1e2	applied research on security of computer network technology	computer;network technology;application;security	With the popularity of the Internet, network security has been paid more and more attention. Application of network security has become important contents for lots of experts and scholars to study. This work began with the concept and features of computer network technology. Then it analyzed the threats of the computer network, including system vulnerabilities, viruses and Trojans, transport protocol, etc. Finally, it studied security measures including installing patch timely, installing anti-virus software and firewalls, developing new transport protocols, etc. It is hoped that it can provide a reference for the actual security work.	antivirus software;computer virus;firewall (computing);internet;network security;trojan horse (computing)	Jianpeng Zhang	2013		10.1145/2556871.2556921	software security assurance;computer security model;cloud computing security;application software;intelligent computer network;security through obscurity;security information and event management;security association;covert channel;asset;security bug;computer science;information security;logical security;network security;operating system;internet security;security service;internet privacy;network access control;network security policy;world wide web;computer security;host based security system	Security	-57.71643647757594	65.43123011439054	13519
3ce56df316d5c650232e036fe302444fbb027daf	cam01-3: connection preemption in multi-class networks	minimisation;polynomial time approximation algorithm;bandwidth polynomials quality of service streaming media telecommunication traffic resource management approximation algorithms web and internet services routing diffserv networks;internet connection preemption multiclass network np complete problem subset sum problem optimal algorithm exponential complexity polynomial time approximation algorithm bandwidth minimisation;subset sum problem;bandwidth minimisation;bandwidth allocation;connection preemption;internet;computational complexity;multiclass network;exponential complexity;optimal algorithm;minimisation bandwidth allocation computational complexity internet;np complete problem	We address the problem of connection preemption in a multi-class network environment. Our objective is: (i) to minimize the number of preempted connections, and (ii) to minimize the total preempted bandwidth, in that order. We show that this problem is NP-complete by reducing it to a well-known NP complete problem - the subset sum problem. Therefore, a known polynomial time algorithm, such as Minn.Conn [1], to solve this problem is suboptimal. We present an optimal algorithm with exponential complexity that can be used when the network load is light. We also present a fully polynomial time approximation algorithm that performs within a bounded factor from the optimal, and can be used in large networks having thousands of connections. We compare the performance of exact and approximate algorithms in a practical scenario by conducting simulations on a network representing twenty largest metros in the U.S. The simulations show that, on average, the approximate algorithm preempts bandwidth which is only a small fraction more as compared to that preempted by the exact algorithm, but is an order of magnitude more efficient in terms of execution time.	approximation algorithm;conn;complete (complexity);exact algorithm;karp's 21 np-complete problems;np-completeness;p (complexity);polynomial;preemption (computing);run time (program lifecycle phase);simulation;subset sum problem;time complexity	Fahad R. Dogar;Laeeq Aslam;Zartash Afzal Uzmi;Sarmad Abbasi;Young-Chon Kim	2006	IEEE Globecom 2006	10.1109/GLOCOM.2006.8	time complexity;minimisation;mathematical optimization;the internet;np-complete;computer science;theoretical computer science;mathematics;distributed computing;computational complexity theory;subset sum problem;bandwidth allocation	Theory	-4.83743863799676	80.06016127386314	13573
7368d093979f45c80c7e38a176aee9c547c0993b	managing trade-offs between information loss and latency in real-time distributed systems	multicast communication;real-time systems;telecommunication computing;data security;inter communication delays;latency;multicasting;partial order resequencing;real time distributed systems	Multicasting is used in many real-time distributed applications such as market data feeds, videoconferencing, interactive distance learning. The need for multicasting is either because the databases are replicated or simply because there are multiple destination nodes involved in the communication process. However consistency problems are inherent in distributed environments where the variable nature of inter-communication delays between sites may interfere with the correct order of the received data. Several consistency preserving algorithms rely on resequencing methods. In this paper, we use partial order resequencing in order to meet the temporal constraints of these real-time systems. This may cause loss of data and could affect the data integrity. By using simulation results and approximate analysis, we analyze the trade-offs between minimizing the latency and keeping the information loss acceptable.	approximation algorithm;data integrity;database;distributed computing;download;multicast;real-time clock;real-time computing;simulation	Hoda Maalouf	2009	2009 International Conference for Internet Technology and Secured Transactions, (ICITST)		real-time computing;computer science;theoretical computer science;distributed computing	DB	-22.21099738124485	70.72183536965666	13575
b878a08ca3d6a6368bcf45667f20c6cd11812f45	face recognition in biometric vending machines	face recognition	Many Biometric security systems are used to grant restricted access to certain resources. This paper presents a biometric system for automatic vending machines. It ensures that products submitted to legal restrictions are only sold to authorized purchasers. Making use of an identity card, the system checks if the purchaser verifies all the restrictions to authorize the product sale. No special cards or codes are needed, since the system only scans the ID card of the user and verifies that the purchaser is the ownership of the card taking a photograph. The simplicity of the system and the high recognition rates obtained make the biometric system an interesting element to be included in automatic vending machines in order to sell restricted products in certain areas.	authorization;biometric device;biometrics;code;digital camera;facial recognition system	José Javier Astrain;Jesús E. Villadangos;Alberto Córdoba;Manuel Prieto	2004			face detection;computer science;three-dimensional face recognition	Networks	-49.47887722092321	66.62591825254042	13576
d1747870a98e0a4b6afefd87aaf8e189592ac102	optical routing control using coherent pattern-matching circuit for photonic self-routing switch	ultrafast optics;monolithic integration;switching networks;tapped delay line;ring network;integrated optoelectronics;silica;packet switched;optical switches;code division multiple access;code division multiplexing;telecommunication network routing;optical control routing circuits optical packet switching ultrafast optics bit rate binary codes gold delay silicon;pattern matching;telecommunication network routing code division multiple access integrated optoelectronics optical switches switching networks;optical correlator;point of view;planar lightwave circuit;sio sub 2 si optical correlation monolithic ic ring networks address header formats photonic self routing switch coherent optical pattern matching circuit ultrafast optical signal sequence tapped delay lines input pattern set pattern 4 bit pattern matching circuit silica based planar lightwave circuit technology optical routing control banyan networks power penalty number of addresses binary code code division multiplexed gold codes 4 65 gbit s 10 gbit s si substrate	This paper describes optical routing control using a coherent optical pattern-matching circuit. This circuit can detect any specified pattern in an ultrafast optical signal sequence by using tapped delay-lines to optically correlate the input pattern with a set pattern. A whole four-bit pattern-matching circuit is monolithically integrated on a silicon substrate by the silicabased planar lightwave circuit technology. The fabricated circuit operates a t a bit-rate of 4.65 Gb/s. Pattern-matching circuits can apply t o optical routing control for photonic self-routing switches. Addressheader formats for ring and banyan networks are also discussed from an aspect of the power penalty versus the number of addresses. The header for ring networks is composed of a binary code or a Gold code. The header for banyan networks is composed of code-division-multiplexed Gold codes. Optically routing-controlled photonic packet switching using headers composed of binary codes is experimentally demonstrated at a bit-rate of 10 Gb/s.	4-bit;binary code;coherent;experiment;gigabyte;lightwave 3d;multilayer switch;multiplexing;network packet;network switch;packet switching;pattern matching;routing	Jun Nishikido;Masayuki Okuno;Akira Himeno	1992		10.1109/INFCOM.1992.263589	code division multiple access;telecommunications;computer science;photonic integrated circuit;optical switch;computer network	EDA	-6.452217165788973	86.94923844296055	13580
574cc1333065f4b7b5c11b7a3976515afa99e975	innovative technologies for video transmission over packet networks	video transmission;packet networks		network packet	Leonardo Chiariglione;Maurizio Decina;Francesco G. B. De Natale;Daniele D. Giusto	2001	European Transactions on Telecommunications	10.1002/ett.4460120302	packet analyzer;computer science;processing delay;jumbogram;packet switch	Mobile	-10.01132655175178	93.05291349560943	13628
2654cb27a51dd28ccc1e1a43253de671f890a2cf	a novel attack against android phones	operating system	In the first quarter of 2011, Android has become the top-selling operating system for smartphones. In this paper, we present a novel, highly critical attack that allows unprompted installation of arbitrary applications from the Android Market. Our attack is based on a single malicious application, which, in contrast to previously known attacks, does not require the user to grant it any permissions. 1 Responsible Disclosure We reported this vulnerability to Google on June 20, 2011. In order to give them time to fix the issue, we removed the main content of this paper and generalized title and abstract. This document merely serves as a timestamp of discovery. 2 Hash The SHA-512 hash of the full report as sent to Google is given below: 051426b1794e363544893b7123ba3d15c5d878a9ff736162b85479d063a 86940fe2d6280774fd98989cce8b1628d5d9428d0691ee4ffcc2c07da82 31ca79af5d	android tv;operating system;responsible disclosure;sha-2;smartphone	Michael Backes;Sebastian Gerling;Philipp von Styp-Rekowsky	2011	CoRR		pre-play attack;computer science;internet privacy;world wide web;computer security	Security	-54.731738026524376	62.429450768819066	13669
a22dc6a7262357287547a8918d468d7eb1aa0070	resource scheduling in data-centric systems		Effective resource scheduling is a fundamental issue for achieving high performance in various computer systems. The goal of resource scheduling is to arrange the best location of each resource and determine the most appropriate sequence of job execution, while satisfying certain constraints or optimizations. Although the topic of resource scheduling has been widely investigated for several decades, it is still a research hotspot as new paradigms continue to emerge, such as grid computing [1, 2], cloud computing [3, 4], big data analytics [5, 6], and so on. With the explosive growth of data volumes, more and more organizations are building large-scale data-centric systems (DCS). These systems are hosted by one or more data centers, where they serve as IT infrastructures for data processing, scientific computing, and a variety of other applications involving “big data”. Datacentric systems offer new solutions for existing applications and promote warehousescale data businesses such as cloud computing, cloud storage services, and so on. Unfortunately, there is no widely accepted standard definition for data-centric systems. However, in general, if a computing system involves large volumes of data which are hosted by data centers, it can be labeled as “data-centric systems”. Examples include large-scale web search engine, data management systems, data mining systems. Particularly, we focus on three kinds of data-centric systems in this chapter:	big data;categorization;cloud computing;cloud storage;computational science;data center;data mining;data-intensive computing;graph coloring;grid computing;ibm notes;jean-raymond abrial;job scheduler;mapreduce;scheduling (computing);standard-definition television;web search engine;zhi-li zhang	Zujie Ren;Xiaohong Zhang;Weisong Shi	2015		10.1007/978-1-4939-2092-1_46	fair-share scheduling;fixed-priority pre-emptive scheduling;earliest deadline first scheduling;flow shop scheduling;dynamic priority scheduling;resource allocation;rate-monotonic scheduling;genetic algorithm scheduling;two-level scheduling;deadline-monotonic scheduling;scheduling;round-robin scheduling	HPC	-19.60011894523943	60.9836732420724	13672
8467ef74a63801cca0336b1220b92f17aef5c9d8	an efficient audio-video synchronization methodology	data transmission;perceptual quality;timestamp based synchronization;propagation losses;information systems;information hiding;packet loss;audio video;embedded audio data;bit rate;data mining;multimedia information system;data communication;multimedia systems;data encapsulation;high bitrate information hiding techniques;synchronisation;video coding;audio coding;audio video synchronization;digital media;video coding audio coding data encapsulation feature extraction multimedia communication synchronisation;streaming media;synchronization;feature extraction;embedded audio data audio video synchronization multimedia information system timestamp based synchronization mpeg feature extraction high bitrate information hiding techniques;multimedia communication;robustness;mpeg;communication channels;streaming media synchronization propagation losses communication channels multimedia systems information systems bit rate data mining data communication robustness	In a multimedia information system, different types of digital media (such as video, audio, etc.) are stored, transmitted, and presented. During presentation time, the synchronization between audio and video data has to be preserved in order to offer the best perceptual quality. However, the timestamp-based synchronization methodology in MPEG/System layer suffers data packet loss during transmission, and the resulted absence of synchronization will be unacceptable for users. In order to address this issue, an information hiding based synchronization methodology has been proposed. In this methodology, audio data is embedded within the corresponding video frames by means of high bitrate information hiding techniques. At the receiver, the embedded audio data is extracted and played with the host video frames to achieve the synchronization. With this approach, significant advantages have been obtained: (1) the communication channel for audio data transmission is avoided; (2) the synchronization between audio and video data is robust to packet loss.	channel (communications);digital media;embedded system;information system;moving picture experts group;network packet;sound card;synchronization (computer science)	Ming Yang;Nikolaos G. Bourbakis;Zizhong Chen;Monica Trifas	2007	2007 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2007.4284763	synchronization;real-time computing;audio over ethernet;aes11;telecommunications;computer science;multimedia;data synchronization;audio signal flow;frame synchronization;computer network	Mobile	-7.77911683319192	102.93034180158656	13686
06e03606b0b7fcdbc87eab8c0b6cfe716b2360cf	vmesh: distributed segment storage for peer-to-peer interactive video streaming	random seeking;forward backward;peers local storage;random access functions;video streaming;web and internet services;distributed consensus;video streaming interactive systems peer to peer computing video on demand;interactive video;vmesh;buffer storage;distributed storage;distributed segment storage;indexing terms;random media;interactive vod system vmesh distributed segment storage peer to peer interactive video streaming random access functions video on demand peers local storage storage capacity cache and relay mechanism random seeking;group dynamic;network servers;interactive vod system;streaming media;aggregates;storage capacity;video on demand;peer to peer computing streaming media network servers delay video on demand bandwidth buffer storage aggregates random media web and internet services;peer to peer interactive video streaming;media streaming;bandwidth;peer to peer computing;peer to peer;user interaction;interactive systems;random access;cache and relay mechanism	"""Provisioning random access functions in peer-to-peer on-demand video streaming is challenging, due to not only the asynchronous user interactivity but also the unpredictability of group dynamics. In this paper, we propose VMesh, a distributed peer-to-peer video-on-demand (VoD) streaming scheme which efficiently supports random seeking functionality. In VMesh, videos are divided into segments and stored at peers' local storage in a distributed manner. An overlay mesh is built upon peers to support random forward/backward seek, pause and restart during playback. Our scheme takes advantage of the large aggregate storage capacity of peers to improve the segment supply so as to support efficient interactive commands in a scalable manner. Unlike previous work based on """"cache-and-relay"""" mechanism, in our scheme, user interactivity such as random seeking performed by a peer does not break the connections between it and its children, and hence our scheme achieves better playback continuity. Through simulation, we show that our system achieves low startup and seeking latency under random user interactivity and peer join/leave which is a crucial requirement in an interactive VoD system."""	aggregate data;algorithm;distributed hash table;goto;interactivity;internet;locality of reference;peer-to-peer;provisioning;random access;relay;scalability;scott continuity;server (computing);simulation;streaming media;thread-local storage	Wai-Pun Ken Yiu;Xing Jin;Shueng-Han Gary Chan	2007	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2007.071210	consensus;index term;distributed data store;computer science;internet privacy;world wide web;bandwidth;random access;group dynamics;computer network	Networks	-15.171197435977188	73.17070150943307	13697
8b9b672f7723ff8daae8ecdbba68d38e3ff11bd3	letting the puss in boots sweat: detecting fake access points using dependency of clock skews on temperature	802 11;evil twin attack;fake access point;wireless access point;device fingerprinting;security;clock skew	The only available IEEE 802.11 network identifiers (i.e., the network name and the MAC address) can be easily spoofed. Consequently, an attacker is able to fake a real hotspot and attract its traffic. By this means, the attacker can intercept, collect, or change users' traffic (often even if it is encrypted). In this paper, we describe an efficient method for detecting the replacement of access points (APs) by passive remote physical device fingerprinting. The main feature of our fingerprinting approach is the clock skew - an unavoidable phenomenon that causes clocks to run at minuscule yet remotely observable different speeds - which is extracted from information contained in beacon frames. We are the first to achieve a high discriminability of devices by completely eliminating the fingerprinters' influence and considering the clock skew's dependency on temperature. Finally, we develop a method for reliable detection of the presence of AP impostors that works without explicit temperature information. Compared to the best state-of-the-art approach, our method improves detection accuracy from about 30% to 90% without generating any traffic and requires less than one minute to collect a sufficient number of observations. Our approach yields a strong feature for passive remote physical device fingerprinting in wireless networks.	ap computer science;clock skew;device fingerprint;encryption;fingerprint (computing);identifier;java hotspot virtual machine;mac address;observable;peripheral;sensor;spoofing attack;visual intercept;wireless access point	Fabian Lanze;Andriy Panchenko;Benjamin Braatz;Thomas Engel	2014		10.1145/2590296.2590333	telecommunications;clock skew;computer science;information security;internet privacy;computer security	Security	-52.859577245402974	68.20025580642822	13710
db8498649a825415367a7fc2c6342de74804aec7	audiovisual quality study for videoconferencing on ip networks	packet loss;quality assessment;streaming media;synchronization;video recording;jitter	In this paper, an audiovisual quality assessment experiment was conducted on audiovisual clips collected using a PC-based videoconferencing application connected via a local IP network. The analyses of experimental results provided a better understanding of the influence of network impairments (packet loss, jitter, delay) on perceived audio and video qualities, as well as their interaction effect on the overall audiovisual quality in videoconferencing applications. We updated the human perception acceptability limits of audio-video synchronization for video conferencing. Further, we investigated the contribution of this synchronization to the audiovisual quality independently and accompanied with network impairments. Finally, we proposed an integration model to estimate the audiovisual quality in the studied context.	asynchrony (computer programming);dominating set;internet protocol suite;mega man network transmission;network packet;personal computer;video	Ines Saidi;Lu Zhang;Vincent Barriac;Olivier Déforges	2016	2016 IEEE 18th International Workshop on Multimedia Signal Processing (MMSP)	10.1109/MMSP.2016.7813379	synchronization;real-time computing;jitter;telecommunications;computer science;multimedia;packet loss	Visualization	-8.465798324438461	100.92168879592855	13736
72a5943258d583c4f123bfbbfbd2cf39e6c310d9	reasoning about distributed secrets		In 1977 Tore Dalenius described how partial disclosure about one secret can impact the confidentiality of other correlated secrets, and indeed this phenomenon is well-known in privacy of databases. The aim here is to study this issue in a context of programs with distributed secrets. Moreover, we do not assume that secrets never change, in fact we investigate what happens when they do: we explore how updates to some (but not all) secrets can affect confidentiality elsewhere in the system. We provide methods to compute robust upper bounds on the impact of such information leakages with respect to all distributed secrets. Finally we illustrate our results on a defence against side channels.	confidentiality;database	Nicolás E. Bordenabe;Annabelle McIver;Carroll Morgan;Tahiry M. Rabehaja	2017		10.1007/978-3-319-60225-7_11	computer security;theoretical computer science;partial disclosure;computer science;confidentiality;phenomenon	SE	-38.58664666753341	73.11907628986117	13770
796bc9fa02318327af95dfa243dede4ecfaf87f8	1984/1988 x.400 recommendations - user requirements	message handling systems;electronic mail systems;groupware cooperation and communication;group communication;user requirements	An evaluation of the 1984 and 1988 CCITT X.400 series of recommendations is given with particular reference to the use of a Message Handling System (MHS) for interpersonal communication. The human user's needs in electronic communication are studied. Based on these findings, the technical quality of the services provided are evaluated, as is the support of the human factors in communication. MHS is evaluated in terms of its suitability for the individual user and the applicability for communication in groups. Message handling services are presented and compared with user requirements. In particular, the new services of the X.400 recommendations of 1988 concerning interworking with Directory Services (DS), the security model, message store and distribution lists are examined to determine how they meet the needs of the human user, and how they could be used or extended to improve communication in groups.	requirement;user requirements document	Uta Pankoke-Babatz	1990	Computer Communications	10.1016/0140-3664(90)90087-W	communication in small groups;computer science;user requirements document;distributed computing;world wide web;computer security;computer network	Networks	-26.656647793857296	90.90000375983561	13772
9bb14cb2ddee28b70bf343ef50dddbe25b696049	secure automotive on-board protocols: a case of over-the-air firmware updates	automotive control;over the air;security protocols;software functionality;over the air firmware updates;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;security architectures;security architecture;security protocol	The software running on electronic devices is regularly updated, these days. A vehicle consists of many such devices, but is operated in a completely different manner than consumer devices. Update operations are safety critical in the automotive domain. Thus, they demand for a very well secured process. We propose an on-board security architecture which facilitates such update processes by combining hardware and software modules. In this paper, we present a protocol to show how this security architecture is employed in order to achieve secure firmware updates for automotive control units.	computer security;end-to-end encryption;engine control unit;firmware;key (cryptography);on-board data handling;patch (computing);trust anchor	Muhammad Sabir Idrees;Hendrik Schweppe;Yves Roudier;Marko Wolf;Dirk Scheuermann;Olaf Henniger	2011		10.1007/978-3-642-19786-4_20	software security assurance;embedded system;firmware;real-time computing;engineering;security service;computer security	Security	-51.03589632693962	69.17286344754679	13820
f8d285289d475eab424623da729e143ba274bed0	albl: an adaptive load balancing algorithm for distributed web systems	web clusters;distributed web systems;load balancing algorithms	This paper presents an adaptive load balancing algorithm (ALBL) for cluster-based web systems. The balancing policy is based on two criteria: HTTP process time and network delay. The former describes web server ability to process a forthcoming request, while the latter tries to estimate network conditions. Periodic criteria calculations are performed by agents at the web switch and the weight estimation process is transparent to web servers enhancing therefore distributed system’s scalability. We put to test our implementation against known blind selection balancing algorithms used at web-farms such as: Round Robin, stateful ones such as Least Connections and adaptive ones such as Least Load. We also put to test performance and scalability of previous algorithms. From our testbed scenario results we show that ALBL algorithm outperforms stateless and stateful algorithms and also presents significant performance gains towards adaptive algorithms. We also show that our algorithm scales well as the number of balancing servers and web cluster’s requests rate increases. We also pinpoint ALBL algorithm ability to predict network conditions and web servers load without the use of feedback information obtained by web servers but frequent service and network probes towards web servers issued by the web switch.	adaptive filter;algorithm;central processing unit;computational resource;distributed computing;human body weight;hypertext transfer protocol;load balancing (computing);network congestion;scalability;server (computing);server farm;state (computer science);stateless protocol;testbed;unbalanced circuit;web server	Sotirios Kontogiannis;Alexandros Karakos	2014	IJCNDS	10.1504/IJCNDS.2014.064041	round-robin dns;network load balancing services;real-time computing;computer science;load balancing;operating system;distributed computing;world wide web;computer security;server;computer network	Web+IR	-18.44927054719136	70.08480818457524	13821
7a9d707885a17bdccfb62dc093b520508243bd76	sla-based dynamic resource management in wireless environments	radio networks;quality assurance;wireless environment;top down;resource management quality of service wireless lan access control environmental management quality management companies quality assurance prototypes disaster management;device level configuration;wireless corporate network;service driven management;wireless lan quality of service radio networks;enterprise nomadism management architecture;network level configuration;service level agreement;wireless lan;quality of service;dynamic resource management;enterprise nomadism management architecture dynamic resource management wireless environment service driven management quality of service user access wireless corporate network service level agreement device level configuration automatic translation application level quality assurance network level configuration;user access;application level quality assurance;automatic translation	In this article, we focus on the service-driven management of quality of service and user access in wireless corporate networks. We propose a service-level agreement (SLA) oriented nomadism management architecture with a top-down vision starting by the specification of company objectives and going down to device-level configurations. We define an algorithm for the automatic translation of application-level quality assurance parameters into network-level configuration parameters. The description of the prototype implementation of our solution to the SLA-driven enterprise nomadism management is given and preliminary results on the self-adaptive capabilities of our mapping algorithm are given.	access control;algorithm;anisotropic filtering;differentiated services;entity framework;high- and low-level;location-based service;machine translation;prototype;quality of service;requirement;service-level agreement;top-down and bottom-up design	Badis Tebbani;Issam Aib;Guy Pujolle	2008	2008 IEEE/ACS International Conference on Computer Systems and Applications	10.1109/AICCSA.2008.4493554	quality assurance;quality of service;computer science;top-down and bottom-up design;database;computer security;computer network	DB	-18.670448154329485	83.08676937556193	13827
b1446e10aecc46f36cde860880f9bc8fe7eda82b	traffic characterization and internet usage in rural africa	network design;measurement;rural networks;performance;wireless network;network performance;presentation;traffic characterization;internet traffic;human factors;operating system;feedback loop;internet usage;rural community;rural area;interviews;urban area;south africa;developing world;user behavior;online social network;quality of service;peer to peer;social factor	While Internet connectivity has reached a significant part of the world's population, those living in rural areas of the developing world are still largely disconnected. Recent efforts have provided Internet connectivity to a growing number of remote locations, yet Internet traffic demands cause many of these networks to fail to deliver basic quality of service needed for simple applications. For an in-depth investigation of the problem, we gather and analyze network traces from a rural wireless network in Macha, Zambia. We supplement our analysis with on-site interviews from Macha, Zambia and Dwesa, South Africa, another rural community that hosts a local wireless network. The results reveal that Internet traffic in rural Africa differs significantly from the developed world. We observe dominance of web-based traffic, as opposed to peer-to-peer traffic common in urban areas. Application-wise, online social networks are the most popular, while the majority of bandwidth is consumed by large operating system updates. Our analysis also uncovers numerous network anomalies, such as significant malware traffic. Finally, we find a strong feedback loop between network performance and user behavior. Based on our findings, we conclude with a discussion of new directions in network design that take into account both technical and social factors.	feedback;internet access;malware;network performance;network planning and design;operating system;peer-to-peer;population;quality of service;social network;tracing (software);web application	David L. Johnson;Veljko Pejovic;Elizabeth M. Belding-Royer;Gertjan van Stam	2011		10.1145/1963192.1963363	network planning and design;simulation;internet traffic;quality of service;interview;developing country;performance;computer science;human factors and ergonomics;wireless network;feedback loop;network performance;world wide web;computer security;rural area;measurement	Metrics	-13.476341610413252	98.63577309547065	13832
d9c30e1cde2fa3dfa8604f191b3a5df06a52b684	typing access control and secure information flow in sessions	session types;secure information flow;communication centred computing;access control	We consider a calculus for multiparty sessions with delegation, enriched with security levels for session participants and data. We propose a type system that guarantees both session safety and a form of access control. Moreover, this type system ensures secure information flow, including controlled forms of declassification. In particular, it prevents information leaks due to the specific control constructs of the calculus, such as session opening, selection, branching and delegation. We illustrate the use of our type system with a number of examples, which reveal an interesting interplay between the constraints of security type systems and those used in session types to ensure properties like communication safety and session fidelity.		Sara Capecchi;Ilaria Castellani;Mariangiola Dezani-Ciancaglini	2014	Inf. Comput.	10.1016/j.ic.2014.07.005	computer science;access control;session id;database;distributed computing;computer security	Security	-35.0696247936867	70.60726471617266	13854
5c134551ba4d43c1459d3f5f2cfd5598c1444b6d	ubiquitous collision avoidance system for red light running		In this paper, a collision avoidance system is presented to detect red light running and warn nearby vehicles and pedestrians in real time in order to try to prevent possible accidents. No complex infrastructure-based solution such as those based on radars or cameras is here required. Instead, a ubiquitous solution based on smartphones carried by drivers and pedestrians is proposed so that it is the device inside the vehicle violating a traffic light, the one that self-reports the offence in order to generate alerts and warn nearby vehicles and pedestrians to prevent accidents. The proposal could also be used by road authorities to collect data on traffic lights that are most frequently violated in order to define an action plan to investigate causes and search solutions. It includes a classifier for learning and estimating driver behaviour based on collected data, which is used to predict whether he/she is about to run a red light or detect whether that has already happened. In the first case, the system broadcasts warnings directly to close vehicles and pedestrians through Wi-Fi, while in the second case, the proposal warns vehicles and pedestrians in the neighbourhood through a server. The proposal also involves the use of cryptographic schemes to protect authenticity and integrity of messages sent from traffic lights, smartphones and servers, and privacy and anonymity to promote the use of the system. A beta version with some parts of the proposal has been implemented and the obtained results are promising.	air traffic control radar beacon system;algorithm;collision detection;cryptographic protocol;cryptography;machine learning;open research;receiver operating characteristic;requirement;sensor;server (computing);smartphone;software release life cycle;virtual private server	Pino Caballero-Gil;Cándido Caballero-Gil;Jezabel Molina-Gil	2018		10.1145/3243046.3243054	computer network;anonymity;action plan;cryptography;collision avoidance system;computer science;neighbourhood (mathematics);classifier (linguistics);server	Mobile	-52.68653613678504	67.25536849654684	13879
1df8c3de80fa6421332e465a0d5d7c7956b1d93b	the security requirement for off-line e-cash system based on ic card	national security;key management;ic card system;payment system e cash system off line e cash system based on ic card e cash protocol;control systems;mathematics;e cash protocol security requirement offline e cash system ic card system eavesdropping transaction content cryptographic algorithm authentication module key management;information security;smart cards cryptography electronic money message authentication;authentication;cryptographic protocols;cryptographic protocols cryptography authentication information security national security privacy control systems load management mathematics forgery;forgery;e cash protocol;off line e cash system based on ic card;electronic money;security requirement;eavesdropping transaction content;cryptographic algorithm;smart cards;cryptography;security requirements;load management;e cash system;message authentication;similarity function;offline e cash system;privacy;payment system;authentication module	An offline E-cash system is presented that offers appreciably greater security and better privacy than currently considered E-cash system with similar functionality. Most off-line E-cash systems use the temper-resistant IC card which controls an E-cash issued by the card issuer. Offline E-cash system based on IC card has the threats of overspending, double spending, forgery E-cash, altering/eavesdropping transaction contents, etc. To prevent the above threats, there have been a lot of technical discussions of the security requirements for theoretical offline E-cash protocols based on IC card. However, there has been little attention paid to the security requirements for practical offline E-cash system based on IC card including entity authentication, key management, implementation of cryptographic algorithm, etc. Thus, this paper describes the security requirements for cryptographic algorithms, integrity for implementation of cryptographic algorithm, authentication module, key management, and E-cash protocols	algorithm;authentication;cryptography;double-spending;encryption;issuing bank;key management;online and offline;requirement;smart card	Haeryong Park;Kilsoo Chun;Seungho Ahn	2005	11th International Conference on Parallel and Distributed Systems (ICPADS'05)	10.1109/ICPADS.2005.279	cryptographic primitive;electronic money;computer science;cryptography;information security;national security;key management;authentication;internet privacy;privacy;openpgp card;world wide web;computer security	Security	-48.106414378554724	66.78002035305495	13893
936190f100faa0a345c53d4fc542292988cc756a	towards building practical secure multi-party databases	protocols;query processing;distributed databases;security;privacy	This work aims at building secure multi-party database systems, for emerging federation networks in healthcare, finance, and other marketplaces. The technical challenges come from the interface gap between existing distributed query processing (DQP) and multi-party computation software. We propose compositional MPC for modular DQP and MPC-aware query optimizations.	computation;database	Yuzhe Tang;Wenqing Zhuang	2016	2016 IEEE Cybersecurity Development (SecDev)	10.1109/SecDev.2016.029	query optimization;computer science;data mining;database;world wide web;query language	Security	-42.686635451901864	61.633209149841804	13908
a5e36ed54e758c3fb45ef9b6c6bb0c382b2a1268	end-to-end qos management for delay-sensitive scalable multimedia streams over diffserv	delay sensitive scalable multimedia streams;network resources;end to end qos;application level data streams;differentiated services;computer network management quality of service delays multimedia communication internet multimedia servers;multimedia applications;application software;web and internet services;multimedia streaming;data stream;computer communication;multimedia servers;differentiated service;multimedia application;multimedia systems;computer networks;network servers;internet;streaming media;delay quality of service streaming media web and internet services ip networks computer networks application software proposals multimedia systems network servers;computer network management;multimedia communication;media streaming;network level service;diffserv;ip networks;real time communication;scaling properties;quality of service;proposals;multimedia server;qos management system;layered media streams;network resources multimedia servers delay sensitive scalable multimedia streams diffserv internet computer communication multimedia applications real time communication network level service differentiated services quality of service application level data streams qos management system scaling properties layered media streams;delays	The migration of the Internet from classic computer communication to a platform for multimedia applications with real-time communication requires end-to-end improvements of the network-level service. The proposal known as Differentiated Services is a very promising approach for implementing quality of service in the Internet and is being discussed and developed. The challenge is to deliver end-to-end QoS on top of Differentiated Services considering multiple concurrent applicationlevel data streams. In this paper, we propose a QoS management system for multimedia servers that benefits from the scaling properties of layered media streams. This enables the system to map application QoS demands to available network resources and to adapt the quality of individual streams according to inter-stream QoS de-	algorithm;best-effort delivery;differentiated services;end-to-end encryption;end-to-end principle;image scaling;internet;network architecture;network congestion;network packet;profiling (computer programming);prototype;quality of service;real-time transcription;requirement;scalability;server (computing);service-level agreement;simulation	Markus Albrecht;Michael Köster;Peter Martini;Matthias Frank	2000		10.1109/LCN.2000.891062	real-time computing;mobile qos;computer science;world wide web;differentiated services;computer network	Networks	-7.3267554264543	96.05393500444107	13919
8c3896514950c3a810127cffc5e1722bb544eada	multicast service-oriented virtual network mapping over elastic optical networks	virtual network mapping;multicast service oriented virtual network mapping multicast tree construction link mapping spectrum requirements auto adjusted evolution gene evolution simulated annealing fittest multicast requests mapping order blocking probability normalized throughput mixed integer linear programming node mapping low computational complexity heuristic algorithm igsa algorithm integrated genetic and simulated annealing algorithm np hard problem spectrum consumption minimization big data applications physical resource utilization improvement physical infrastructure nfv network function virtualization multicast service oriented vn mapping eon elastic optical networks;virtualisation computational complexity genetic algorithms integer programming linear programming multicast communication optical fibre networks probability radio spectrum management resource allocation simulated annealing telecommunication network routing telecommunication network topology trees mathematics;integrated genetic and simulated annealing multicast virtual network mapping elastic optical networks eons mixed integer linear programming milp;elastic optical networks eons;bandwidth optical fiber networks simulated annealing resource management sociology statistics genetics;integrated genetic and simulated annealing;mixed integer linear programming milp;multicast	Network Function Virtualization (NFV) allows multiple Virtual Networks (VNs) to share the underlying physical infrastructure via VN mapping, thus improving the utilization of physical resources. In this paper, for the first time, we study the multicast service-oriented VN mapping that can support big data applications over Elastic Optical Networks (EONs). Since the problem of minimizing the spectrum consumption in multicast service-oriented VN mapping is NP-hard, we propose an efficient heuristic algorithm, called Integrated Genetic and Simulated Annealing (IGSA) algorithm to address the problem with low computational complexity. By encoding node mapping, multicast tree construction, link mapping and spectrum requirements in the same gene and auto-adjusted evolution, and utilizing simulated annealing to find the fittest multicast requests mapping order, IGSA can perform joint optimization for all the multicast requests in a global way. Through extensive simulations, we demonstrate that IGSA outperforms the other heuristic solutions in terms of spectrum consumption, blocking probability and normalized throughput, while achieving close to minimum spectrum consumption with a much lower time complexity than MILP.	algorithm;big data;blocking (computing);computational complexity theory;erlang (unit);frequency allocation;heuristic (computer science);mathematical optimization;multicast;network function virtualization;network mapping;requirement;routing;service-oriented device architecture;simulated annealing;simulation;throughput;time complexity	Xiujiao Gao;Zilong Ye;Weida Zhong;Chunming Qiao;Xiaojun Cao;Hanjia Zhao;Hong-Fang Yu;Vishal Anand	2015	2015 IEEE International Conference on Communications (ICC)	10.1109/ICC.2015.7249145	mathematical optimization;multicast;computer science;theoretical computer science;distributed computing;computer network	Visualization	-9.332454975448792	82.50457130133333	13954
1820c161d2a2b2930e588213c3cf454311ba4382	personalized sensitive attribute anonymity based on p - sensitive k anonymity	k anonymity;sensitive attribute protection;p sensitive;generalization;personal protection	With the development of science and technology, privacy protection has also been highly valued. Existing anonymity algorithms are only anonymous quasi-identifier to achieve privacy protection, but ignore the sensitive properties of the personalized protection. This paper proposed an anonymity algorithm based on p -sensitive k anonymity model, which can better protect sensitive attribute according to individual differences. The algorithm presented an innovative idea that user-defined sensitivity levels of sensitive attributes, at first users defined the sensitivity level according to their actual situation, and then used sensitive attribute level tree to generalize sensitive attribute, the high sensitivity of sensitive attribute was generalized to the higher level of the tree andvice versa. Compared with theresults of k anonymity and personalized (∂, k) anonymity, it is shows that the model based on p -sensitive k anonymity relative to other anonymous algorithms under shorter execution time and less information loss realizesthe personalized anonymity of sensitive attribute.	algorithm;identifier;personalization;privacy;quasi-identifier;run time (program lifecycle phase)	Jun-jie Jia;Guo-lei Yan;Li-cheng Xing	2016		10.1145/3028842.3028896	computer science;data mining;internet privacy;computer security	Security	-40.91003249750866	63.60798908882223	13989
3ba3347b1ebfd449ffff26b71e0afb9601aff341	real-time mixes: a bandwidth-efficient anonymity protocol	public key cryptography;subscriber lines;real time constraints;protocols;heart;data stream;real time;public key cryptography protocols isdn data privacy voice communication data communication;indexing terms;real time mixes;data communication;telephony;anonymous communication;isdn;protection;public key;protocols isdn privacy protection mobile communication bandwidth telephony narrowband heart performance analysis;long distance;data privacy;e mail like services;integrated services digital network;voice communication;data rate;mobile communication;continuous data stream;performance analysis;long distance network;data communication bandwidth efficient anonymity protocol real time mixes anonymous communication real time constraints telephony continuous data stream narrow band isdn integrated services digital network anonymous channels data rate subscriber lines long distance network performance analysis e mail like services voice communication;bandwidth;anonymous channels;real time communication;narrowband;privacy;integrated service digital network;narrow band isdn;bandwidth efficient anonymity protocol	We present techniques for efficient anonymous communication with real-time constraints as necessary for services like telephony, where a continuous data stream has to be transmitted. For concreteness, we present the detailed protocols for the narrow-band ISDN (Integrated Services Digital Network), although the heart of our techniques—anonymous channels—can also be applied to other networks. For ISDN, we achieve the same data rate as without anonymity, using the same subscriber lines and without any significant modifications to the long-distance network. A precise performance analysis is given. Our techniques are based on mixes, a method for anonymous communication for e-mail-like services introduced by D. Chaum.	data rate units;email;integrated services digital network;real-time clock;real-time transcription	Anja Jerichow;Jan Müller;Andreas Pfitzmann;Birgit Pfitzmann;Michael Waidner	1998	IEEE Journal on Selected Areas in Communications	10.1109/49.668973	information privacy;telecommunications;computer science;integrated services digital network;internet privacy;public-key cryptography;computer network	Networks	-47.08472201802651	71.7723873475083	13993
5cbdebb2bd1870185e30fa85a11c2a7dfdc0ecb3	sneo: proposal of a platform for network game using overlay network	protocols;online game;design engineering;routing;information retrieval;hybrid p2p model;proposals network servers information retrieval multimedia systems protocols network topology scalability routing indium tin oxide design engineering;network game architecture;p2p;client server systems;multimedia systems;network topology;portable game machine;indium tin oxide;network servers;client server;peer to peer computing client server systems computer games;overlay network;scalability;sneo;network game;peer to peer computing;consumer game machine;computer games;sneo online game consumer game machine portable game machine network game architecture client server model hybrid p2p model overlay network;proposals;client server model	Recently, many online games have been developed by improvement of network technology in consumer game machines and portable game machines. Typical network game architecture is based on client- server model and Hybrid-P2P model. Because of heavy resource needs in servers, it is not easy to develop network games in game providers. We propose a platform based on overlay network which does not need the server for the online game, and develop a common platform in online game. This platform s name is SNEO (non server network game environment by using overlay network) . Game provides can share the common platform in various games. Game providers become possible to produce games without considering about the load of networks and servers. In this paper, it proposes the outline of our platform, and the opponent matching protocol which becomes essence in online games.	algorithm;common platform;distributed computing;distributed hash table;middleware;multicast;overlay network;server (computing);simulation	Yoichi Nakamura;Hiroki Saito;Shin Ito;Yoshito Tobe	2007	27th International Conference on Distributed Computing Systems Workshops (ICDCSW'07)	10.1109/ICDCSW.2007.75	game design;computer science;distributed computing;game developer;game design document;world wide web;game programming;client–server model;computer network;game client	Metrics	-22.4175392417007	72.24846127329971	14003
4ffb6eb36b75427b06ea5d89ae91a8190f2f5fad	hive.js: browser-based distributed caching for adaptive video streaming	protocols;standards;web rtc;video streaming application program interfaces cache storage hypermedia markup languages peer to peer computing quality of experience transport protocols;bit rate;browsers;mpeg dash content delivery peer to peer web rtc;mpeg dash;webrtc;streaming media;content delivery;content delivery network technology browser based distributed caching adaptive video streaming hive js p2p technology standard cdn infrastructure video distribution peer to peer technology quality of user experience browser based plugin less distributed caching platform webrtc html5 api direct browser to browser communication transport adaptive http streaming protocol mpeg dash;peer to peer computing;peer to peer;peer to peer computing streaming media webrtc protocols browsers standards bit rate	Peer-to-peer (P2P) technology has long been considered a natural complement to standard CDN infrastructure for video distribution since it greatly reduces costs and improves quality of user experience. However, P2P solutions have traditionally required the installation of additional software or plugins to be deployed, which significantly hinders adoption. In this paper, we present Hive.js, a browser-based plugin-less distributed caching platform for video streaming. Hive.js is layered over WebRTC, a new set of HTML5 APIs for direct browser-to-browser communication, and it is designed to transport adaptive HTTP streaming protocols, specifically MPEG-DASH. Initial results obtained by evaluating Hive.js in a controlled test environment show that our approach significantly reduces the load on CDN infrastructure and does not sacrifice quality of user experience.	content delivery network;deployment environment;distributed cache;dynamic adaptive streaming over http;html5;moving picture experts group;peer-to-peer;plug-in (computing);streaming media;user experience;web application;webrtc	Roberto Roverso;Mikael Högqvist	2014	2014 IEEE International Symposium on Multimedia	10.1109/ISM.2014.45	communications protocol;computer science;operating system;database;internet privacy;world wide web;computer network	Arch	-9.492151139537784	97.73298070186007	14033
bbeddd5eefa3bc3f14b3fefd87a68294f629ee6f	enforcement of data-plane policies in next-generation networks	automated planning;policy enforcement;protocols;packet processing;internet architectures data plane policies next generation networks forward traffic data plane operations;next generation network;prototypes;data plane policy enforcement next generation internet network services packet processing automated planning;maintenance engineering;internet architecture;forward traffic;computer architecture;telecommunication traffic;data plane policies;planning internet next generation networking maintenance engineering protocols conferences prototypes;internet;data plane policy enforcement;telecommunication traffic computer architecture internet;planning;network services;next generation networks;theoretical foundation;next generation networking;data plane operations;conferences;internet architectures;next generation internet	Modern networks not only forward traffic, but also perform a variety of processing operations on packets (e.g., content inspection, transcoding, QoS scheduling). Such data plane operations cannot be easily coordinated in the current Internet architectures since there is no explicit policy support for packet processing services. As more diverse systems and protocols are deployed in the next-generation Internet, this problem becomes increasingly challenging. In our work, we propose a novel policy enforcement system for data-path functions in the next-generation Internet. Using a formalism to represent policies and automated planning tools, connection request can be adapted to meet the policy requirement of the domains they traverse. We present the theoretical foundations of this approach as well as a prototype implementation based on our network service architecture. Our results show that this approach is an effective solution to enforcing policies relating to the date plane of networks.	automated planning and scheduling;forwarding plane;internet;network packet;next-generation network;norm (social);prototype;quality of service;scheduling (computing);semantics (computer science);traverse	Shashank Shanbhag;Tilman Wolf	2010	2010 IEEE International Symposium on Policies for Distributed Systems and Networks	10.1109/POLICY.2010.23	computer science;distributed computing;computer security;computer network	Networks	-16.10814020723754	84.03722306229717	14046
8b8751fbcc804f19995b16e1123bac3e18d95af7	a new blind ecdsa scheme for bitcoin transaction anonymity		In this paper, we consider a scenario where a bitcoin liquidity provider sells bitcoins to clients. When a client pays for a bitcoin online, the provider is able to link the client’s payment information to the bitcoin sold to that client. To address the clients’ privacy concern, it is desirable for the provider to perform the bitcoin transaction with blind signatures. However, existing blind signature schemes are incompatible with the Elliptic Curve Digital Signature Algorithm (ECDSA) which is used by most of the existing bitcoin protocol, thus cannot be applied directly in Bitcoin. In this paper, we propose a new blind signature scheme that allows generating a blind signature compatible with the standard ECDSA. Afterwards, we make use of the new scheme to achieve bitcoin transaction anonymity. The new scheme is built on a variant of the Paillier cryptosystem and its homomorphic properties. As long as the modified Paillier cryptosystem is semantically secure, the new blind signature scheme has blindness and unforgeability.	algorithm;antivirus software;automatic target recognition;bitcoin;blind signature;communications of the acm;cryptosystem;digital signature;elliptic curve cryptography;homomorphic encryption;internet privacy;journal of cryptology;provable security;public-key cryptography;semantic security;smart card;smart contract;type signature;wire transfer;zero-knowledge proof	Xun Yi;Kwok-Yan Lam;Dieter Gollmann	2018	IACR Cryptology ePrint Archive			Security	-44.221855739791685	71.59784667674279	14051
070015e1acc47740c966eb6624bb7adec808f214	stable, distributed p2p protocols based on random peer sampling	lyapunov methods;incentive mechanism;sampling methods lyapunov methods markov processes peer to peer computing protocols;protocols;markov;lyapunov;stability;rare chunk;stability incentive mechanism lyapunov markov missing piece peer to peer rare chunk;missing piece;stability analysis;statistics;protocols lyapunov methods stability analysis markov processes peer to peer computing sociology statistics;markov processes;peer to peer computing;rare chunk selection protocol stable distributed p2p protocols random peer sampling peer to peer protocols fully random peer selection missing piece syndrome distributed random peer sampling protocols lyapunov function techniques multiple peer sampling rare chunk selection rule incentive mechanism;peer to peer;sociology	Peer-to-peer protocols that rely on fully random peer and chunk selection have recently been shown to suffer from instability. The culprit is referred to as the missing piece syndrome, whereby a single chunk is driven to near extinction, leading to an accumulation of peers having almost complete files, but waiting for the missing chunk. We investigate three distributed random peer sampling protocols that tackle this issue, and present proofs of their stability using Lyapunov function techniques. The first two protocols are based on the sampling of multiple peers and a rare chunk selection rule. The last protocol incorporates an incentive mechanism to prevent free riding. It is shown that this incentive mechanism interacts well with the rare chunk selection protocol and stability is maintained. Besides being stable for all arrival rates of peers, all three protocols are scalable in that the mean upload rate of each peer is bounded uniformly independent of the arrival rate.	chunking (computing);instability;lyapunov fractal;peer-to-peer file sharing;queueing theory;resource bounded measure;sampling (signal processing);scalability;selection rule;tree accumulation;upload	Barlas Oguz;Venkat Anantharam;Ilkka Norros	2012	2012 50th Annual Allerton Conference on Communication, Control, and Computing (Allerton)	10.1109/TNET.2014.2331352	communications protocol;markov chain;von neumann stability analysis;stability;lyapunov function;computer science;theoretical computer science;distributed computing;markov process;world wide web;statistics	Theory	-9.060756362291972	71.63950974603263	14065
dc5d3cbc22410b2bbaf3e74a9468f4ccd3f55cb9	a scalable and seamless connection migration scheme for moving target defense in legacy networks		In this paper, we propose a scalable and seamless connection migration scheme for moving target defense in legacy networks. The main idea is that a host is allowed to receive incoming packets with a destination address that is either its current IP address or its previous IP address for a period of time because the host does not physically move into another network. Experimental results show that our scheme outperforms the existing connection migration mechanism regardless of the number of active connections in the host. key words: cyber security, moving target defense, address mutation, connection migration, legacy network		Taekeun Park;Koohong Kang;Daesung Moon	2018	IEICE Transactions		artificial intelligence;computer vision;computer science;scalability;distributed computing	Arch	-58.18191238230412	69.36425394963904	14078
65373d6014131e5c3b2672db252813c7857689cd	statistical process control based chart for information systems security	reliability;computer intrusion detection;data processing;computer networks;process control	Intrusion detection systems have a highly significant role in securing computer networks and information systems. To assure the reliability and quality of computer networks and information systems, it is highly desirable to develop techniques that detect intrusions into information systems. We put forward the concept of statistical process control (SPC) in computer networks and information systems intrusions. In this article we propose exponentially weighted moving average (EWMA) type quality monitoring scheme. Our proposed scheme has only one parameter which differentiates it from the past versions. We construct the control limits for the proposed scheme and investigate their effectiveness. We provide an industrial example for the sake of clarity for practitioner. We give comparison of the proposed scheme with EWMA schemes and p chart; finally we provide some recommendations for the future work. Bernoulli distribution, Information system, Intrusion detection, Normal distribution, Statistical Process Control.	bernoulli polynomials;information security;information system;intrusion detection system	Mansoor S. Khan;Lirong Cui	2015		10.1117/12.2197092	computer science;artificial intelligence;data mining;computer security	Security	-59.77099716725244	69.4760710021744	14115
25aaf37cc075cfee48f1c3525840956ae16b82d1	a study of communication delays for web transactions	communication system;web pages;e commerce;digital library;web transactions;performance;web data;internet;communication delay;transaction processing;security;communication	A major bottleneck in using the web for accessing data and executing transactions for e-commerce is the performance. It can take 500–1400 ms to set up the connection and download a web page. Several hundred milliseconds are taken to transmit a multimedia web image. A simple web transaction may have a response time of 2–5 s. The consistency control mechanisms can double this time. A typical electronic trading transaction may take close to 2 min. I assert that the performance is unacceptable and the main cause is the communication system. The communication delays under a variety of scenarios and their causes and remedies are the focus of this study. Mechanisms have been developed for studying the performance of the web transaction processing on the Internet. Experimental studies have been conducted to analyze and understand the behavior of web based transactions and to measure the communication delays. The developed mechanisms have been used to perform a series of experiments around the world. Experiments were conducted to measure the communication delays for different steps which includes web page downloading, access to digital library data and transaction processing. This paper presents the experimental results for a variety of cases. It concludes by suggesting directions for decreasing the communication latency and improving the performance of web transactions.	active networking;cpu cache;control system;digital library;download;e-commerce;electronic trading;experiment;http persistent connection;hypertext transfer protocol;interaction;internet access;lossy compression;maxima and minima;overhead (computing);quality of service;remote computer;response time (technology);router (computing);scalability;server (computing);software agent;software system;transaction processing system;web cache;web page;web server;world wide web	Bharat K. Bhargava	2001	Cluster Computing	10.1023/A:1011816728298	web service;web application security;web development;parallel computing;web modeling;digital library;the internet;data web;web analytics;web design;transaction processing;performance;distributed transaction;computer science;operating system;web navigation;web page;database;distributed computing;online transaction processing;world wide web;web server;communications system;mashup;computer network	DB	-17.887921030709226	71.16129981489206	14125
b4afeae8dc9c2e4f48d6d138f3bc2c9868ff6d18	reconstruction methodology for rational secret sharing based on mechanism design		Rational secret sharing [1] is the intersection of game theory [2] and traditional secret sharing [3]. In rational secret sharing, the players are selfish and always behave in accordance with profit maximization. What this implies, primarily, is that rational players prefer obtaining the secret rather than not obtaining it and, secondarily, that players prefer as few other players as possible obtaining the secret. Motivated by selfishness, rational players either keep silent or send incorrect shares during the reconstruction phase, thereby the fairness and correctness of rational secret reconstruction become difficult to achieve. For the reasons mentioned above, existing investigations have focused on devising different reconstruction protocols, in order to restrict the selfishness of rational players and succeed in achieving fairness and correctness when reconstructing secrets. However, Game theory as well as existing investigations lacks a guideline reference model that is restrictive to the selfishness of rational players. Devising rational secret reconstruction protocols has always relied on the designers’ experience. Although many interesting and ingenious rational secret reconstruction protocols have been presented in the absence of a reference model, some researchers [4–6] do point out that such protocols are likely to be inadequate in two different ways: (1) the terminal strategy profile is unfair; and (2) the obtained secret is incorrect. To address the aforementioned problems, this article introduces mechanism design [7] from the field of microeconomics, and proposes a reference model for the purpose of devising rational secret reconstruction protocols. In the proposal, the rational secret reconstruction game is formalized; then, the expected goal of this game is discussed from the designer’s perspective and with consideration to the security, correctness and fairness of rational secret sharing. Finally, the rational secret reconstruction design model is defined on the basis of mechanism design. Through this brief analysis, we indicate that the proposed model is able to assist the designer in achieving fairness and correctness, with regard to rational secret reconstruction. Rational secret reconstruction game. In the extensive form game [2], each player considers his plan of action, at any point in time, when a decision needs to be made. Therefore, to cast the execution of rational secret reconstruction protocols, we formalize the rational secret reconstruction game based on the extensive form game.	correctness (computer science);entropy maximization;fairness measure;game theory;rational set;reconstruction filter;reference model;secret sharing;software design;universality probability	Xinghua Li;Jianfeng Ma;Mengfan Xu;Jingjing Guo	2015	Science China Information Sciences	10.1007/s11432-015-9066-9	theoretical computer science;mathematics;mechanism design;secure multi-party computation;secret sharing	Crypto	-37.83537207306187	73.19095803162293	14127
be1a3e25f03f930cbd13d185c148028218b2cbe6	short-circuiting the congestion signaling path for aqm algorithms using reverse flow matching	internet protocol;routeur;congestion trafic;controle congestion telecommunication;protocole transmission;protocolo internet;packet filtering;congestion trafico;data path;gestion trafic;protocole internet;telecommunication congestion control;active queue management;traffic management;camino datos;protocole tcp;transmission control protocol;signaling;protocolo transmision;protocole aqm;tcp congestion control;protocolo tcp;traffic congestion;route caching;active tjueue management;flash crowd;gestion trafico;router;chemin donnees;methode signalant congestion ack spoofing;layer 2;packet marking;ack spoofing;active queue management protocol;protocolo aqm;flash crowds;transmission protocol	Recently, we introduced a new congestion signaling method called ACK Spoofing, which offers significant benefits over existing methods, such as packet dropping and Explicit Congestion Notification (ECN). Since ACK Spoofing requires the router to create a “short circuit” signaling path, by matching marked data packets in a congested buffer with ACK packets belonging to the same flow that are traveling in the opposite direction, the focus of this paper is evaluating the feasibility of reverse flow matching. First, we study the behavior of individual flows from real bi-directional Internet traces to show that ACK Spoofing has the potential to significantly reduce the signaling latency for Internet core routers. We then show that reverse flow matching can be implemented at reasonable cost, using essentially the same hardware as the packet filtering logic commonly employed in Layer 2 transparent bridges. Finally, we show that this architecture can be scaled to accommodate worst-case traffic patterns on multi-gigabit links that would render ordinary route caching algorithms completely ineffective.	24-bit;48-bit;acknowledgement (data networks);active queue management;aggregate data;algorithm;best, worst and average case;classless inter-domain routing;denial-of-service attack;electronic signature;explicit congestion notification;firewall (computing);gigabit;ip traceback;item unique identification;limiter;lookup table;network congestion;network packet;network traffic control;nyquist rate;overselling;router (computing);sampling (signal processing);short circuit;tracing (software)	Mart Molle;Zhong Xu	2005	Computer Communications	10.1016/j.comcom.2004.07.039	internet protocol;data link layer;tcp congestion-avoidance algorithm;signalling;active traffic management;telecommunications;computer science;transmission control protocol;computer security;active queue management;computer network	Networks	-6.970948696889312	89.2474523890669	14143
4ba24c9e86c321c071fd9dc5ae0fc724be00743a	matching distributed systems to their environment using dissipative structures	distributed system;dissipative structures;stochastic process;search algorithm;stochastic processes computer networks;computer systems;dissipative structure;computer networks;stochastic processes;peer to peer computing bandwidth stochastic processes telecommunication traffic search problems sampling methods educational institutions distributed computing physics computing delay;message passing distributed system matching dissipative structures computer systems network latency stochastic process;message passing;distributed system matching;network latency;dissipative system	In contrast to a large body of theoretical work on computer systems, distributed systems are not idealised constructions, unconstrained by physical world limitations. They must be designed to account for limiting, real-world properties such as network latency, varying node capabilities, varying application behaviour and unexpected failures. These real-world properties that we describe under the general area of a system's environment have regularities or heterogeneities that can often be modelled as a stochastic process, often using well-known distributions. This paper proposes dissipative structures as a model to capture information about properties of these stochastic processes. In dissipative systems, agents (or nodes) sample information from their local environments and collectively build structures that capture knowledge of recent regularities or heterogeneities in the system's environment. Dissipative structures are a promising technique for transferring knowledge of the system's environment among agents without requiring excessive message passing. This approach offers the promise of building more efficient search algorithms based on reduced uncertainty of the system's environment	computer;dissipative system;distributed computing;interaction;message passing;peer-to-peer;run time (program lifecycle phase);search algorithm;stochastic process	Jim Dowling;Dominik Dahlem;Jan Sacha	2005	2005 International Conference on Collaborative Computing: Networking, Applications and Worksharing	10.1109/COLCOM.2005.1651268	stochastic process;simulation;dissipative system;computer science;theoretical computer science;distributed computing	SE	-11.631822169048961	71.8053622882415	14157
b647a84c03af88b6889feb827e5e9b1411d74c3a	id-nac: identity-based network access control for manets	key management;access control mobile ad hoc networks protection peer to peer computing routing monitoring identity based encryption admission control computer networks computer network management;secret sharing;network access control;identity based membership tokens;telecommunication congestion control;secure routing;indexes;mobile ad hoc networks;cryptography;secret sharing mobile ad hoc networks network access control identity based cryptography;mobile radio;identity based cryptography;telecommunication security;ad hoc networks;mobile ad hoc network;access control;peer to peer computing;mobile computing;telecommunication security ad hoc networks mobile radio radio access networks telecommunication congestion control;ad hoc nodes;security;identity based network access control;identity based membership tokens mobile ad hoc networks identity based network access control key management secure routing ad hoc nodes;radio access networks	Security in mobile ad hoc networks (MANETs) is an active research topic. Bulks of prior work focused on key management and secure routing without addressing an important pre-requisite: network access control, the problem of admission and revocation of ad hoc nodes. In this paper, we present ID-NAC, identity-based network access control for MANETs. In ID-NAC each node in the network maintains a profile table, which contains information about the behavior of the nodes in the MANET. It is used to assign a quantitative value for the trustworthiness of a node. Since, there is no observation about the behaviors of prospective members at first; they are admitted to the network tentatively. Then, their behaviors are monitored in the network and if they behave well, they can obtain an identity-based membership tokens based on their trustworthiness. In addition, using profile tables provide protection against wrongful revocation of membership tokens through malicious accusations. The feasibility of ID-NAC was verified by simulation.	access network;hoc (programming language);key management;network access control;prospective search;routing;security token;simulation;trust (emotion)	Narges Aghakazem Jourabbaf;Ali Movaghar-Rahimabadi	2008	2008 16th IEEE International Conference on Networks	10.1109/ICON.2008.4772595	wireless ad hoc network;mobile ad hoc network;computer science;information security;internet privacy;mobile computing;computer security;computer network	Mobile	-53.46439275011263	78.56554090774651	14194
dc4fe622f8bf40b8a1824c7339236b5f145cf6ee	deploying parallelised ciphertext-policy attributed-based encryption in clouds		In recent years, cloud storage has become an attractive solution due to its elasticity, availability and scalability. However, the security issue has started to prevent public clouds becoming more popular. Traditional encryption algorithms (both symmetric and asymmetric ones) fail to support achieving effective secure cloud storage due to severe issues such as complex key management and heavy redundancy. Ciphertext-policy attribute-based encryption (CP-ABE) scheme overcomes the aforementioned issues and provides fine-grained access control as well as deduplication features. CP-ABE has become a possible solution to cloud storage. However, its high complexity has prevented it from being widely adopted. This paper parallelises CP-ABE where issues to ensure secured cloud storage are considered and deployed in cloud storage environments. Major performance bottlenecks such as key management and encryption/decryption process are identified and accelerated, and a new AES encryption operation mode is adopted for f...	ciphertext;encryption	Wenjie Fan;Lifeng Li;Xiaowan Chen;Hai Jiang;Zhongwen Li;Kuan-Ching Li	2018	IJCSE	10.1504/IJCSE.2016.10011441	key management;real-time computing;redundancy (engineering);ciphertext;encryption;cloud storage;scalability;advanced encryption standard;computer science;data deduplication;distributed computing	Crypto	-42.990474335819314	67.4975986411124	14209
a4a501f0917260c13cc086b04d55e014ef7b60de	an inter-peer trustworthiness based on access control in peer-to-peer overlay networks	electronic mail;detection algorithms;access control peer to peer computing permission authorization change detection algorithms detection algorithms object detection electronic mail scalability floods;distributed peer to peer overlay networks;authorisation;computability;p2p;satisfiability;inter peer trustworthiness;permission;satisfiability inter peer trustworthiness access control distributed peer to peer overlay networks authorization;peer to peer computing authorisation computability;overlay network;authorization;access control;scalability;floods;peer to peer computing;peer to peer;peer to peer overlay networks;object detection;change detection algorithms	We discuss a fully distributed peer-to-peer (P2P) overlay network where each peer is autonomous and accesses to objects distributed in peers by taking advantage of acquaintances. An acquaintance peer of a peer p is a peer about whose service the peer p knows and with which the peer p can directly communicate. The satisfiability is defined to how satisfiable a requesting peer is for each access request by newly taking into account the authorization. The trustworthiness of each acquaintance is calculated by aggregating the satisfiability obtained through each interaction with the acquaintance. If acquaintance information is changed, the change is propagated to peers through acquaintances. Due to the limited size of memory, the peer throws away information of less trustworthy acquaintances to make space to store new acquaintance information. The trustworthiness of acquaintance of each peer is propagated in a peer-by-peer way while some acquaintance information is recorded in a peer. We discuss how to calculate the trustworthiness, satisfiability, and exchange the acquaintance information then with acquaintances. We evaluate how the trustworthiness of acquaintance is changing through interactions among peers and the hit ratio can be improved for a detection request	access control;authorization;autonomous robot;hit (internet);interaction;overlay network;peer-to-peer;trust (emotion)	Yoshio Nakajima;Kenichi Watanabe;Valbona Barolli;Tomoya Enokido;Makoto Takizawa	2007	First International Conference on Complex, Intelligent and Software Intensive Systems (CISIS'07)	10.1109/CISIS.2007.10	computer science;distributed computing;internet privacy;computer network	DB	-54.54132600720495	80.41164835330856	14211
ce5af00fbaf25ae6ab45327fc1805f9bb705d3d8	efficient subgroup exponentiation in quadratic and sixth degree extensions	elliptic curve;cyclotomic polynomial;group theory;corps fini;courbe elliptique;polynomials;finite field;curva eliptica;criptografia;cryptography;luc;campo finito;cryptographie;xtr	This paper describes several speedups for computation in the order p + 1 subgroup of Fp2 and the order p 2 − p + 1 subgroup of Fp6 . These results are in a way complementary to LUC and XTR, where computations in these groups are sped up using trace maps. As a side result, we present an efficient method for XTR with p ≡ 3 mod 4.	computation;lucas sequence;map;xtr	Martijn Stam;Arjen K. Lenstra	2002		10.1007/3-540-36400-5_24	combinatorics;discrete mathematics;cyclotomic polynomial;cryptography;xtr;mathematics;elliptic curve;group theory;finite field;algebra	NLP	-40.08280069015154	80.56162496171608	14216
afd21b79d1f70512923ee4e720b27337255813b6	authentication and certificate managements of unauthorized intrusion in ad-hoc networks, problems and solutions	public key cryptography;mobility management mobile radio;public key authentication ad hoc networks memory management mobile communication certification;memory management;certification;certificates management ad hoc network public key certificate authentication;authentication;ad hoc network;public key cryptography message authentication mobile ad hoc networks mobile computing mobility management mobile radio;public key;mobile ad hoc networks;authentication managements certificate managements unauthorized intrusion detection wireless technology mobile users mobility functions security managements connection decisions mobile ad hoc networks manet certification authority security certificates public keys message encryption malicious user traffic flow reduction user nodes;mobile communication;certificates management;ad hoc networks;public key certificate;message authentication;mobile computing	The development of today's wireless technology with its sophisticated devices and applications has attracted many users and becoming more important in their daily life. Ad hoc networks have emerged from this technology to provide new services to mobile users. In contrast with conventional wireless networks, ad hoc networks are not connected to any stationary infrastructure. Furthermore, the mobility functions, such as routing, connection's decisions and security managements, are performed by the nodes themselves independently. Therefore, the security problem for mobile ad hoc networks is becoming one of the major issues that need to be solved. The security of ad hoc networks is based on certification authority (CA) which issues and manages security certificates and public keys for message encryption. This paper introduces a new method of detecting unauthorized intrusion that is used by malicious user who issues a forged certificate to join a group of ad hoc network. This method also eliminates unnecessary certificates exchange among users' nodes to reduce traffic flow inside the network.	authentication;authorization;certificate authority;encryption;hoc (programming language);malware;mobile phone;public key certificate;routing;security hacker;sensor;simulation;stationary process	Norihito Yosaka;Iichiro Nishimura;Tomoyuki Nagase	2011	2011 14th International Conference on Network-Based Information Systems	10.1109/NBiS.2011.108	vehicular ad hoc network;wireless ad hoc network;adaptive quality of service multi-hop routing;mobile ad hoc network;computer science;operating system;ad hoc wireless distribution service;internet privacy;public-key cryptography;mobile computing;computer security;computer network	Mobile	-48.90163380667526	75.29473589722035	14258
b6de99b55813cd26dd297be09fd1db501b7ebe0d	information-centric networking in mobile and opportunistic networks	000 computer science knowledge systems;510 mathematics	Information Centric Networking (ICN) as an emerging paradigm for the Future Internet has initially been rather focusing on bandwidth savings in wired networks, but there might also be some significant potential to support communication in mobile wireless networks as well as opportunistic network scenarios, where end systems have spontaneous but time-limited contact to exchange data. This chapter addresses the reasoning why ICN has an important role in mobile and opportunistic networks by identifying several challenges in mobile and opportunistic Information-Centric Networks and discussing appropriate solutions for them. In particular, it discusses the issues of receiver and source mobility. Source mobility needs special attention. Solutions based on routing protocol extensions, indirection, and separation of name resolution and data transfer are discussed. Moreover, the chapter presents solutions for problems in opportunistic Information-Centric Networks. Among those are mechanisms for efficient content discovery in neighbour nodes, resume mechanisms to recover from intermittent connectivity disruptions, a novel agent delegation mechanisms to offload content discovery and delivery to mobile agent nodes, and the exploitation of overhearing to populate routing tables of mobile nodes. Some preliminary performance evaluation results of these developed mechanisms are	bandlimiting;content discovery platform;future internet;icn gps;indirection;microsoft outlook for mac;mobile agent;mobile phone;performance evaluation;population;programming paradigm;routing table;spontaneous order;testbed	Carlos Anastasiades;Torsten Braun;Vasilios A. Siris	2014		10.1007/978-3-319-10834-6_2	telecommunications;computer science;computer security;computer network	Mobile	-11.660540879441013	87.8983638819839	14260
0803f2f7dfdfd0fb2fa944e1e35cb2099e425ce9	securing every bit: authenticated broadcast in radio networks	radio networks;byzantine failures;wireless networks;fault tolerant;asymptotic optimality;wireless network;broadcast;byzantine faults;malicious interference;authenticated broadcast	This paper studies non-cryptographic authenticated broadcast in radio networks subject to malicious failures. We introduce two protocols that address this problem. The first, NeighborWatchRB, makes use of a novel strategy in which honest devices monitor their neighbors for malicious behavior. Second, we present a more robust variant, MultiPathRB, that tolerates the maximum possible density of malicious devices per region, using an elaborate voting strategy. We also introduce a new proof technique to show that both protocols ensure asymptotically optimal running time.  We demonstrate the fault tolerance of our protocols through extensive simulation. Simulations show the practical superiority of the NeighborWatchRB protocol (an advantage hidden in the constants of the asymptotic complexity). The NeighborWatchRB protocol even performs relatively well when compared to the simple, fast epidemic protocols commonly used in the radio setting, protocols that tolerate no malicious faults. We therefore believe that the overhead for ensuring authenticated broadcast is reasonable, especially in applications that use authenticated broadcast only when necessary, such as distributing an authenticated digest	asymptotically optimal algorithm;authentication;computational complexity theory;computer simulation;cryptographic hash function;cryptography;fault tolerance;overhead (computing);time complexity	Dan Alistarh;Seth Gilbert;Rachid Guerraoui;Zarko Milosevic;Calvin C. Newport	2010		10.1145/1810479.1810489	broadcast radiation;atomic broadcast;computer science;operating system;wireless network;distributed computing;computer security;computer network	Security	-51.15028828885725	77.62934210669596	14267
a067201d876d56e71349f74669d70255783d2202	enabling context-aware http with mobile edge hint		Due to dynamic wireless network conditions and heterogeneous mobile web content complexities, web-based content services in mobile network environments always suffer from long loading time. The new HTTP/2.0 protocol only adopts one single TCP connection, but recent research reveals that in real mobile environments, web downloading using single connection will experience long idle time and low bandwidth utilization, in particular with dynamic network conditions and web page characteristics. In this paper, by leveraging the Mobile Edge Computing (MEC) technique, we present the framework of Mobile Edge Hint (MEH), in order to enhance mobile web downloading performances. Specifically, the mobile edge collects and caches the meta-data of frequently visited web pages and also keeps monitoring the network conditions. Upon receiving requests on these popular webpages, the MEC server is able to hint back to the HTTP/2.0 clients on the optimized number of TCP connections that should be established for downloading the content. From the test results on real LTE testbed equipped with MEH, we observed up to 34.5% time reduction and in the median case the improvement is 20.5% compared to the plain over-the-top (OTT) HTTP/2.0 protocol.	compaq lte;download;edge computing;embedded system;http/2;hypertext transfer protocol;loader (computing);local algorithm;online and offline;over-the-top content;performance;serial digital video out;series and parallel circuits;server (computing);tcp congestion control;testbed;web content;web page	Peng Qian;Ning Wang;Gerry Foster;Rahim Tafazolli	2017	2017 14th IEEE Annual Consumer Communications & Networking Conference (CCNC)	10.1109/CCNC.2017.7983146	web service;real-time computing;mobile search;telecommunications;mobile database;computer science;mobile computing;world wide web	Mobile	-18.52237155397976	74.90040806582572	14269
faf712b5b42101368a4cfcde5ddaf09efe563986	algorithms for efficient data management of component-based applications in cloud environments	databases;cloud management;cloud management data management resource allocation application placement;application placement;resource allocation;data management;ibcn;technology and engineering;heuristic algorithms;bandwidth;scalability;algorithm design and analysis databases bandwidth quality of service scalability heuristic algorithms local area networks;quality of service;algorithm design and analysis;local area networks	Cloud environments face a growing demand for application hosting, and applications consisting of multiple data-sources and storage components. The need to ensure service level agreements for these types of applications creates important challenges for cloud infrastructure providers. The main contribution of this paper is an optimal cost-effective model and two algorithms to map component-based data oriented applications to cloud platforms. The first algorithm is based on an Integer Linear Programming formulation and minimizes an objective function, taking into account the capacities of the available nodes and links, as well as the customer requirements. This algorithm is able to obtain the optimal solution, but shows a limited scalability. For this reason a heuristic algorithm is designed to solve the scalability issue. The experimental results thoroughly compare the execution times and obtained node usage for both algorithms.	algorithm;cloud computing;component-based software engineering;computation;hercules graphics card;heuristic (computer science);ibm roadrunner;integer programming;linear programming formulation;loss function;optimization problem;real-time clock;requirement;scalability;service-level agreement;supercomputer	Maryam Barshan;Hendrik Moens;Steven Latré;Filip De Turck	2014	2014 IEEE Network Operations and Management Symposium (NOMS)	10.1109/NOMS.2014.6838257	local area network;algorithm design;real-time computing;scalability;quality of service;data management;resource allocation;computer science;theoretical computer science;database;distributed computing;bandwidth;computer network	Embedded	-20.331014030410866	64.41455828975208	14275
3151ed597dcb14c78ac4cf7f43146484bf4c640c	rbf-based vbr controller for real-time h.264/svc video coding	qp fluctuations;rbf based vbr controller;streaming;psnr;scalable video coding;constant bit rate;real time;h 264 avc;real time h 264 svc video coding;bit rate;radial basis function networks;rate control;video coding;streaming media;mobile live streaming application;video coding radial basis function networks;variable bit rate;bit rate encoding psnr static var compensators streaming media radial basis function networks video coding;streaming rate control variable bit rate scalable video coding h 264 svc h 264 avc;quantization parameter;static var compensators;incremental variation;incremental variation rbf based vbr controller real time h 264 svc video coding quantization parameter variable bit rate qp fluctuations rbf network mobile live streaming application reference cbr controller constant bit rate;encoding;rbf network;reference cbr controller;h 264 svc	In this paper we propose a novel VBR controller for real-time H.264/SVC video coding. Since consecutive pictures within the same scene often exhibit similar degrees of complexity, the proposed VBR controller allows for just an incremental variation of QP with respect to that of the previous picture, so preventing unnecessary QP fluctuations. For this purpose, an RBF network has been carefully designed to estimate the QP increment at each dependency (spatial or CGS) layer. A mobile live streaming application scenario was simulated to assess the performance of the proposed VBR controller, which was compared to a recently proposed CBR controller for H.264/SVC. The experimental results show a remarkably consistent quality, notably outperforming the reference CBR controller.	case-based reasoning;data compression;radial basis function network;real-time clock;streaming media;volume boot record	Sergio Sanz Rodríguez;Fernando Díaz-de-María	2010	28th Picture Coding Symposium	10.1109/PCS.2010.5702522	scalable video coding;real-time computing;peak signal-to-noise ratio;telecommunications;computer science;variable bitrate;constant bitrate;encoding;computer network	Embedded	-6.141601448556873	100.28602533106188	14303
094423b5c0f283ddcc46f06e35a555f6016392ce	return link optimization for internet service provision using dvb-s networks	distributed system;and forward;digital video broadcast;internet traffic;internet services;high speed	"""Satellite based Digital Video Broadcasting (DVB-S) allows the same low cost satellite dish to receive both television programs and Internet traffic. The satellite system is used to construct a high-speed simplex distribution system, while the return path, needed for the Internet service will be provided using a low speed terrestrial network. The bandwidth asymmetry between the return and forward paths results in a problem, which we have termed """"ACK congestion"""". A number of techniques that may alleviate ACK congestion over a DVB satellite link are analysed through simulation. The paper also presents a new ACK Compaction technique to eliminate ACK congestion, and an ACK spacing technique to preserve the self-clocking principle of TCP."""	acknowledgement (data networks);bounce address;clock rate;dvb-s;data compaction;digital video broadcasting;mathematical optimization;network congestion;return channel;satellite dish;self-clocking signal;simulation;terrestrial television	Nihal K. G. Samaraweera	1999	Computer Communication Review	10.1145/505724.505726	real-time computing;internet traffic;telecommunications;computer science;computer network	Networks	-6.986043809696645	89.2169872183829	14311
931d59c2516c026346a2d57f504edf33f3188604	lightweight cryptography: modern development paradigms	lightweight cryptography	The escalating number of the most various intelligent devices having Internet connection will be the defining direction of development of the Internet for the next years. Already now 98.8% of all manufactured microprocessors are used in the embedded applications and only 1.2% -- in traditional computers. Along with traditional Internet devices, such as personal computers, laptops, smartphones, the Internet access have the devices of household appliances, transport, various sensors (including connected with processing of biometric data, personal information of medical character, etc.), and also the tags of radio-frequency identification (RFID).  However there is a basic possibility of using of this technology for unauthorized obtaining of confidential information of personal character. So the former CIA director David Petraeus declared that data from the Internet-connected devices can be used for drawing up the most detailed file on any person.  Thus, development information and the Internet of technologies will demand effective implementation of the information security algorithms providing confidentiality and integrity of data. It is obvious that cryptographic methods of information security form a basis of such safety. Feature is that they have to be applied to the most various intelligent devices which because of their activity conditions as well as cost constrains peculiar to mass production, are characterized by rigid restrictions on the used memory resources, computing power, power supplies, etc. that in turn conducts to restrictions on the used technologies and technological decisions. So, for example, strict restrictions are imposed on energy consumption of passive intelligent devices such as radio-frequency tags or contactless smart cards. Other restriction imposed on the hardware is a limit on number of the logical elements used in an algorithm chip.  The report examines various approaches to the design of information security algorithms, effective for realization in the conditions of significantly limited resources such as radio-frequency tags, contactless smart cards, sensors, coprocessors for 8-bit processors etc.	8-bit;algorithm;authorization;biometrics;central processing unit;confidentiality;contactless smart card;coprocessor;cryptography;embedded system;information security;internet access;laptop;microprocessor;personal computer;personally identifiable information;power supply;radio frequency;radio-frequency identification;sensor;smartphone	Alexey Zhukov	2015		10.1145/2799979.2799981	embedded system;simulation;computer science;computer security	Security	-49.58760530160387	65.09313594132806	14350
7f4557da737e5a375d845be5460b9fd10d194141	16 mb/s token ring on unshielded twisted pair cabling	16 mbit s local area networks unshielded twisted pair cabling structured cabling systems token ring lan lobe connections;telecommunication cables;token networks;token networks local area networks telecommunication cables;token networks power cables cable shielding communication cables local area networks wiring costs telephony power system reliability electromagnetic interference;high performance;local area networks;local area network	Local area networks operating on structured cabling systems using unshielded twisted pair (UTP) cable are Jinding increased utilization. These systems provide low cost installation and easy administration. This paper addresses the technical issues concerning the implementation of a robust and practicul 16 Mbls token ring LAN using unshielded twisted pair cabling for lobe connections. Three technical approaches are presented and evaluated for both common unshielded twisted pair cable and new high performance unshielded twisted pair cable. It is shown that 16 Mbls token ring can operate with lobe lengths of 300 feet on both types of UTP cables provided the appropriate technical approach is implemented.	acoustic lobing;mebibyte;token ring;twisted pair	T. Hill;K. Kalbarczyk;Ronald V. Schmidt;R. W. Smith	1991		10.1109/LCN.1991.208048	local area network;token ring;category 5 cable;telecommunications;computer science;fiber media converter;twisted pair;computer network	Networks	-20.879151167892424	92.06853848797809	14373
3dda0b1fdbe224be90c569c457457f1188628158	security analysis of the extended access control protocol for machine readable travel documents	provable security;security analysis;security model;information security;machine readable travel document;german electronic id card;authenticated key exchange;authenticated key agreement;random oracle;access control;diffie hellman	We analyze the Extended Access Control (EAC) protocol for authenticated key agreement, recently proposed by the German Federal Office for Information Security (BSI) for the deployment in machine readable travel documents. We show that EAC is secure in the Bellare-Rogaway model under the gap Diffie-Hellman (GDH) problem, and assuming random oracles. Furthermore, we discuss that the protocol achieves some of the properties guaranteed by the extended CK security model of LaMacchia, Lauter and Mityagin (ProvSec 2008).	authentication;broadcast signal intrusion;computational diffie–hellman assumption;extended access control;human-readable medium;information security;mihir bellare;software deployment	Özgür Dagdelen;Marc Fischlin	2010		10.1007/978-3-642-18178-8_6	computer security model;security association;computer science;security service;internet privacy;world wide web;computer security	Crypto	-43.1963625130729	74.68860409527205	14377
0e160de4fef8f2b5603f0c5e4ad0f8dcdc3112d5	node-oriented internet protocol: a novel concept for enhancement of mobility and multi-homing in future internet	mobility management mobile radio;protocols;bandwidth aggregation node oriented internet protocol mobility enhancement multihoming future internet ip addressing scheme node identification node location address separation concept network interfaces load balancing nip three tuple addressing scheme interface id mapping system packet forwarding interface selection;network interfaces;protocols internet ip networks mobility management mobile radio network interfaces;internet;internet nickel ip networks routing protocols mobile nodes;ip networks	Mobility and multi-homing are closely related and mainly issues of the used IP addressing scheme. Novel addressing schemes that separate node identification and location are promising concepts to tackle the named issues. However, current approaches that make use of the address separation concept offer, among others, insufficient capabilities to select one or multiple network interfaces for a certain communication process, e.g. to enable load balancing. Therefore, we propose a novel approach called Node-oriented Internet Protocol (NIP). NIP adapts the address separation concept, introduces a novel three-tuple addressing scheme that adds an interface ID and enables network nodes to select sets of network interfaces to be used for communication sessions. Our work includes basic concepts for mapping system, schemes for packet forwarding, mechanisms for mobility and multi-homing support and strategies to ensure backwards compatibility. Building on that, the NIP concept enhances multi-homing and mobility capabilites with new functionalities in comparison to known approaches, especially referred to interface selection and bandwidth aggregation.	addressing scheme;backward compatibility;future internet;load balancing (computing);multihoming;multiple homing;network packet	Alexander Gladisch;Robil Daher;Djamshid Tavangarian	2012	37th Annual IEEE Conference on Local Computer Networks - Workshops	10.1109/LCNW.2012.6424045	internet protocol;reserved ip addresses;tier 1 network;communications protocol;the internet;next-generation network;internet layer;ip address management;computer science;network interface;ip forwarding;distributed computing;network address translation;ip tunnel;mobility model;internet connection sharing;computer security;mobile ip;internet traffic engineering;computer network;ipv6 address	Networks	-11.670897704272695	88.46146254583151	14378
10284838974afe6652fd153ad5c725fc4a3b2e95	efficient and identity-based signcryption with provably-secure	provable security	The idea of signcryption is to provide a method to encrypt and sign data together, so it is more efficient than using an encryption scheme combined with a signature scheme. We present an identitybased signcryption solution, which is one of the most efficient, provably-secure schemes proposed to date. Our scheme admits provable security in the random oracle model under the bilinear DiffieHellman assumption using the definitions proposed by Boyen and it is also forward secure.	ampersand;bilinear filtering;digital signature;encryption;provable security;random oracle;signcryption	Yiling Wen;Jianfeng Ma;Sang-Jae Moon	2010	JDCTA		computer science;provable security;signcryption;computer security	Security	-40.46186212417321	76.18995781031072	14403
9955ed35b018623705fd9482e5a6259802b66423	a grid resource management mechanism based on dynamic region	grid resource domain split assignment method;association rule model;processor scheduling;resource manager;resource management;data mining;servers;association rule;dynamic region;scheduling;resource management processor scheduling dynamic scheduling association rules grid computing rats fuzzy systems educational institutions computer science electronic mail;resource assignment;heuristics algorithm;grid resource management mechanism;optimization;task scheduling;grid computing;association rule model grid resource management mechanism dynamic region resource assignment task scheduling heuristics algorithm grid resource domain split assignment method;heuristic algorithm;scheduling grid computing;dynamic scheduling	To solve the bottleneck problem of tasks that the interdependence between tasks fails to consider during the course of resource assignment and task scheduling based on the heuristics algorithm, A Grid Resource’s Domain Split Assignment Method (GR-DSAM) is presented, which based on association rule model to group the sub-tasks. First, in order to enhance the sub-tasks’ relationship of the same sub-task-group and strengthen the independency of the sub-task-groups, this method groups all sub-tasks, which have been syncopated from users’ initialization tasks according to the interdependence of the sub-tasks. Secondly, the GR-DSAM takes the sub-task-group as one execution unit for reducing the unit communication, and improving the system’s efficiency. At the same time, the GR-DSAM divides the Grid resources into dynamic regions according to the sub-task-group’s resource demands. Simulation results show that the GR-DSAM is effective and efficient in solving the bottleneck problem of Grid resource assignment.	algorithm;association rule learning;display resolution;execution unit;heuristic (computer science);interdependence;scheduling (computing);simulation	Feng Yin;Haiyan Zhong	2009	2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2009.333	heuristic;real-time computing;association rule learning;dynamic priority scheduling;computer science;resource management;theoretical computer science;distributed computing;scheduling;grid computing;server	EDA	-16.917522531061866	63.157482561456014	14410
33791d591524767553018df4e1b3c4301f83ad64	osi clns and llc1 protocols on network systems hyperchannel		Status of this Memo The intent of this document is to provide a complete discussion of the protocols and techniques used to transmit OSI CLNS and LLC1 datagrams (and any associated higher level protocols) on Network Systems Corporation's HYPERchannel equipment. This document is intended for network planners and implementers who are already familiar with the OSI protocol suite and the techniques used to carry OSI traffic on standard networks such as 802.3. This memo provides information for the Internet community. It does not specify an Internet standard. Distribution of this memo is unlimited. In this document, we have three major technical objectives: 1. To standardize the encapsulation of LLC1 packets over HYPERchannel. The format will be used for OSI CLNS and for any other protocols using LLC1 over HYPERchannel. (Note that if one desires to use the LLC1/SNAP combination for TCP/IP, this is the format to use. This represents an alternative to the native mode for TCP/IP over HYPERchannel, allowing for sharing the medium at the LLC1 layer.) Halpern [Page 1]	datagram;encapsulation (networking);internet protocol suite;native (computing);osi model;protocol stack	Joel M. Halpern	1991	RFC	10.17487/RFC1223	computer science;database;computer security;computer network	Networks	-23.992773801974128	88.63878784305427	14424
9b3903d7ecb3424474a73b85e3cbda00c4287607	impacts of the sca core framework on high speed broadband waveform in sdr handheld system	radio logicial;evaluation performance;transmission longue distance;extensible markup language;performance evaluation;systeme embarque;telecommunication sans fil;software defined radio;telephone portable;implementation;xml language;evaluacion prestacion;wide band;transmision alta caudal;logicial personalizado;corba;round trip time;major element;embedded system;transmision larga distancia;enlace descendente;software radio;mobile phone;intergiciel;large bande;embedded systems;telefono movil;radio logicielle;downlink;high speed downlink packet access;portable equipment;object oriented;telecomunicacion sin hilo;software communication architecture;software package;sdr;analizador sintaxico;high rate transmission;oriente objet;middleware;sca;banda ancha;parser;waveform;progiciel;implementacion;canal descendant;common object request broker architecture;orientado objeto;analyseur syntaxique;long distance transmission;high speed;paquete programa;langage xml;lenguaje xml;appareil portatif;aparato portatil;transmission haut debit;wireless telecommunication	In this paper, we have shown a major element occupying the large portion of software communications architecture (SCA)-based software defined radio (SDR) handheld embedded system and an important feature for implementing a high speed broadband radio to an SCA waveform through a couple of experiments. First, this paper identifies the main items possessing the large portion of SCA-based SDR handheld embedded system by the experiment on the target platform which is similar to a commercial mobile handheld system. Both the world interoperabillity for microwave access (WiMAX) and high speed downlink packet access (HSDPA) waveform software packages are used as an SCA waveform application. This paper also presents the results of the relative binary size distribution of SCA software resources for looking for the major elements making an SCA-based SDR handheld embedded system heavier. As a result, when focusing on the relative weight portion of SCA core framework (CF), the SCA CF takes 16% up and others have 84% out of the whole binary size distribution of SCA software resources. The results of the experiment give us notice that the weight portion of SCA CF is minor and compatible with the overall software binary size needs of an SCA-based SDR handheld embedded system, on the other hand, the practical problem on the lightweight is in a common object request broker architecture (CORBA) and extensible markup language (XML) parser resources. Second, this paper describes an important feature for implementing a high speed broadband radio to an SCA waveform and presents the performance evaluation results of the SCA port communication on both power PC (PPC) 405 and x86 processor platforms. The PPC 405 platform, which is similar to a commercial mobile handset, takes the value of average round trip time (RTT) with a maximum of thirty six millisecond. The x86 platform, however, which is analogous to a server platform, maintains stable micro-second resolution. From our experiments, we observe that rapid SCA port communication, sufficiently less than the frame length of high-speed broadband radios, should be provided for serving those radio services in a commercial handheld system based on the SCA.		Sangchul Oh;Nam-Hoon Park;Ohjun Kwon;Yeongjin Kim	2009	IEICE Transactions	10.1587/transcom.E92.B.2095	embedded system;xml;telecommunications;computer science;operating system;common object request broker architecture;software-defined radio;computer network	DB	-6.50992197924801	73.87215013938149	14457
5463da9c6e07db277ae10afd11e83220b942acc1	separating encryption and key issuance in digital rights management systems	desciframiento;provable security;encryption;identity based encryption;droit auteur;decisional diffie hellman;copyright;editor;decryptage;cifrado;probabilistic approach;standard model;cryptage;digital content;criptografia;enfoque probabilista;cryptography;approche probabiliste;decryption;publisher;random oracle;cryptographie;editeur;digital right management;chosen ciphertext attack;derecho autor	Secure distribution of digital goods is now a significantly important issue for protecting publishers' copyrights. In this paper, we study a useful primitive for constructing a secure and efficient digital rights management system (DRM) where a server which encrypts digital content and one which issues the corresponding decryption key works independently, and existing schemes lack this property. We first argue the desired property necessary of an encryption scheme for constructing an efficient DRM, and formally define an encryption scheme as split encryption scheme containing such property. Also, we show that an efficient split encryption scheme can be constructed from any identity-based scheme. However, since currently there is no identity-based encryption scheme which is based on well-known computational assumption and/or provable security without the random oracle, by reasonably tuning the system parameter, we show another construction of split encryption which is secure against chosen ciphertext attacks in the standard model assuming that the decision Diffie-Hellman problem is hard to solve.	digital rights management;encryption;management system	Goichiro Hanaoka;Kazuto Ogawa;Itsuro Murota;Go Ohtake;Keigo Majima;Kimiyuki Oyamada;Seiichi Gohshi;Seiichi Namba;Hideki Imai	2003		10.1007/3-540-45067-X_31	random oracle;multiple encryption;standard model;h.235;disk encryption theory;40-bit encryption;plaintext-aware encryption;disk encryption;client-side encryption;computer science;cryptography;theoretical computer science;provable security;optimal asymmetric encryption padding;link encryption;filesystem-level encryption;on-the-fly encryption;internet privacy;disk encryption hardware;deterministic encryption;computer security;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption;bus encryption;keyfile	Crypto	-41.91964844433445	77.67749070270281	14465
6043f05b97e59822196aa65e51e54dcb895b4d35	client link-layer address option in dhcpv6		This document specifies the format and mechanism that is to be usednfor encoding the client link-layer address in DHCPv6 Relay-Forwardnmessages by defining a new DHCPv6 Client Link-Layer Address option.		Gaurav Halwasia;Shwetha Bhandari;Wojciech Dec	2013	RFC	10.17487/RFC6939	logical address;world wide web;business;dhcpv6;link layer	NLP	-25.332060134779347	88.23189017302433	14494
4e7a5ca9a81a8026f3b5d91a8ce6d9f38bc3fc37	a secure framework in mobile business transactions	mobile device;legal issues;mobile payment;wireless technology;ebook;public administration	Mobile and wireless technologies are growing without bounds. The extension of eGovernment services with mGovernment ones seems to be next to every day life more than we expect. People percentage having access to mobile devices and nomadic internet connection is rapidly increasing. These devices are used to receiving mails, managing businesses, taking information, playing games, etc. at the same level of confidentiality as watching tv or taking information from a newspaper. In order to surf this new wave of media, access public administrations and business will have to transform their work and services according to this demand creating a circle of convenience and efficiency.  In this paper we propose a framework in mobile business transactions, called CNS-Mobile. The aim is to achieve an as flexible as possible interoperable system, granting high security standards, and longevity. CNS-Mobile architecture overcomes problems as limited computational capabilities and limited power of handset and ensures users in the transactions and legal issues.	cns;confidentiality;e-government;internet access;interoperability;mobile device;speeded up robust features;television	Flavio Corradini;Chiara Ercoli;Andrea Lazzari;Alberto Polzonetti	2006		10.1145/1292331.1292370	mobile search;mobile web;telecommunications;computer science;operating system;mobile device;mobile business development;internet privacy;mobile computing;computer security;computer network;mobile payment	Mobile	-48.555445572582045	65.46337710017926	14502
198779030309dec90de903506ccb42e3974b1e24	secure multi-path in sensor networks	multi path;information security;random networks;sensor network;wireless sensor network;information gathering;random network coding;sensor networks;sensor nodes;security;security protocol	Wireless sensor network has been identified as being useful in a variety of domains including the battlefield and perimeter defense. These mission critical applications raise the concern for security in sensor network. Typical security problems identified include passive information gathering, subversion of a node, legitimate addition of a node to an existing sensor network, and so forth [1]. Under traditional routing concept, information security is usually ensured through high-level security protocols, but limited computational power and memory space in sensor nodes make traditional cryptographical techniques cumbersome to be implemented in sensor networks.	cryptography;dspace;high- and low-level;information security;mission critical;perimeter;routing;subversion	Feng Lu;Lijuan Geng;Liang-Tien Chia;Ying-Chang Liang	2007		10.1145/1322263.1322322	sensor web;embedded system;wireless sensor network;sensor node;computer science;information security;network security;security service;key distribution in wireless sensor networks;internet privacy;mobile wireless sensor network;network access control;computer security;computer network;visual sensor network	Mobile	-52.58353836332405	75.42577415101943	14504
5063d6fcca60668f6571e452dfff1d33b8ca0451	bdd-based cryptanalysis of keystream generators	diagrama binaria decision;diagramme binaire decision;keystream generator;automata estado finito;cryptanalyse;004 informatik;cryptanalysis;criptoanalisis;finite automaton;automate fini;binary decision diagram	Many of the keystream generators which are used in practice are LFSR-based in the sense that they produce the keystream according to a rule y = C(L(x)), where L(x) denotes an internal linear bitstream, produced by a small number of parallel linear feedback shift registers (LFSRs), and C denotes some nonlinear compression function. We present an n2 time bounded attack, the FBDD-attack, against LFSR-based generators, which computes the secret initial state x ∈ {0, 1} from cn consecutive keystream bits, where α denotes the rate of information, which C reveals about the internal bitstream, and c denotes some small constant. The algorithm uses Free Binary Decision Diagrams (FBDDs), a data structure for minimizing and manipulating Boolean functions. The FBDD-attack yields better bounds on the effective key length for several keystream generators of practical use, so a 0.656n bound for the self-shrinking generator, a 0.6403n bound for the A5/1 generator, used in the GSM standard, a 0.6n bound for the E0 encryption standard in the one level mode, and a 0.8823n bound for the two-level E0 generator used in the Bluetooth wireless LAN system.	algorithm;binary decision diagram;bitstream;bluetooth;carrier-to-noise ratio;cryptanalysis;data structure;encryption;key size;linear-feedback shift register;nonlinear system;one-way compression function;self-shrinking generator;shrinking generator	Matthias Krause	2001		10.1007/3-540-46035-7_15	cryptanalysis;discrete mathematics;computer science;theoretical computer science;mathematics;finite-state machine;binary decision diagram;algorithm	Crypto	-36.18971339175755	79.04895969542733	14528
4f403be76f6cec3badb2b375208ee6bb25793613	random projection data perturbation based privacy protection in wsns		Wireless sensor networks are responsible for sensing, gathering and processing the information of the objects in the network coverage area. Basic data fusion technology generally does not provide data privacy protection mechanism, and the privacy protection mechanism in health care, military reconnaissance, smart home and other areas of the application is usually indispensable. In this paper, we consider the privacy, confidentiality, and the accuracy of fusion results, and propose a data fusion algorithm for privacy preserving. This algorithm relies on the characteristics of data fusion, and uses the method of pre-distribution random number in the node to get the privacy protection requirements of the original data. Theoretical analysis shows that the malicious attacker attempts to steal the difficulty of node privacy in PPND algorithm. At the same time in the TOSSIM simulation results also show that, compared with TAG, SMART algorithm, PPND algorithm in the data traffic, the convergence accuracy of the good performance.	algorithm;confidentiality;home automation;information privacy;protection mechanism;random number generation;random projection;requirement;smart;simulation;tinyos	Zhao Ming;Wu Zheng-jiang;Hui Liu	2017	2017 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2017.8116426	wireless sensor network;data integration;protection mechanism;data mining;information privacy;algorithm design;sensor fusion;distributed computing;random projection;convergence (routing);computer science	Mobile	-53.66802162539207	75.5112269390261	14540
42f76507304335aaf51b2f1d9808d95b6db1b3be	bandits meet computer architecture: designing a smartly-allocated cache		In many embedded systems, such as imaging systems, the system has a single designated purpose, and same threads are executed repeatedly. Profiling thread behavior, allows the system to allocate each thread its resources in a way that improves overall system performance. We study an online resource allocation problem, where a resource manager simultaneously allocates resources (exploration), learns the impact on the different consumers (learning) and improves allocation towards optimal performance (exploitation). We build on the rich framework of multiarmed bandits and present online and offline algorithms. Through extensive experiments with both synthetic data and real-world cache allocation to threads we show the merits and properties of our algorithms.	computer architecture;embedded system;experiment;online algorithm;online and offline;profiling (computer programming);synthetic data	Yonatan Glassner;Koby Crammer	2016	CoRR		real-time computing;simulation;computer science;distributed computing	OS	-19.35541365703459	60.991464279471934	14580
22b33f57e3ffed02849874c6da46b770d9a40cae	freeze-tcp: a true end-to-end tcp enhancement mechanism for mobile environments	internet transport protocols mobile radio telecommunication traffic telecommunication control telecommunication signalling;tcpip base stations monitoring traffic control payloads cryptography sun security wireless networks wireless application protocol;telecommunication control;wireless network;mobile host;protocol design;security association;transport layer;transport protocols;mobile environment;telecommunication traffic;internet freeze tcp end to end tcp enhancement mechanism mobile environments transport layer tcp traffic flow control end to end semantics end to end signaling ip payload ipsec ipv6 security association encryption tcp ip code mobile clients pro active action signaling;internet;base station;mobile radio;telecommunication signalling;flow control;mobile ip	Optimizing TCP (Transport Layer) for mobility has been researched extensively. We present a brief summary of existing results which indicates that most schemes require intermediaries (such as base stations) to monitor the TCP traffic and actively participate in flow control in order to enhance performance. Although these methods simulate end-to-end semantics, they do not comprise true end-to-end signaling. As a result, these techniques are not applicable when the IP payload is encrypted. For instance IPSEC, which is expected to be standard under IPv6, encrypts the entire IP payload making it impossible for intermediaries to monitor TCP traffic unless those entities are part of the security association. In addition, these schemes require changes (in the TCP/IP code) at intermediate nodes making it difficult for the mobile clients to inter-operate with the existing infrastructure. In this paper we explore the “Freeze-TCP” mechanism which is a true end-to-end scheme and does not require the involvement of any intermediaries (such as base stations) for flow control. Furthermore, this scheme does not require any changes on the “sender side” or intermediate routers; changes in TCP code are restricted to the mobile client side, making it possible to fully inter-operate with the existing infrastructure. We then outline a method which integrates the best attributes of Freeze-TCP and some existing solutions. Performance results highlight the importance of pro-active action/signaling by the mobile-host. The data indicate that in most cases, simply reacting to disconnections tends to yield lower performance than pro-active mechanisms such as Freeze-TCP. Keywords— TCP, Mobile-IP, Wireless networks, Protocol design, implementation, analysis and performance.	client-side;encryption;end-to-end principle;entity;flow control (data);ipsec;internet protocol suite;mobile ip;optimizing compiler;router (computing);security association;simulation	Tom Goff;James Moronski;Dhananjay S. Phatak;Vipul Gupta	2000		10.1109/INFCOM.2000.832552	telecommunications;computer science;zeta-tcp;tcp tuning;computer security;transport layer;computer network	Security	-10.44951900697428	90.25314866998917	14634
c8d7d69edca2340e05c8ae348c3c28f79eada895	notification-based qos control protocol for multimedia group communication in high-speed networks	data transmission;protocols;groupware;high speed network;data transmission procedure;multimedia group communication;high speed networks;satisfiability;group communication;data communication;data transmission procedure notification based qos control protocol multimedia group communication high speed network;multicast protocols;communication system control multimedia communication intelligent networks high speed networks quality of service data communication multicast protocols bandwidth centralized control peer to peer computing;multimedia communication;protocols groupware quality of service multimedia communication data communication;bandwidth;centralized control;intelligent networks;peer to peer computing;quality of service;communication system control;notification based qos control protocol	In group communications, multiple processes first establish a group and then each process sends a message to multiple processes while receiving messages from multiple processes in the group. In addition, messages are required to be causally/totally delivered to each process. Due to the limited computation and communication resource, processes cannot send and receive as messages as the processes would like. We newly propose a notification-based data transmission procedure with two-phase slow start (TPSS) to efficiently exchange multimedia messages in a group so as to satisfy QoS requirement. In TPSS, the transmission rate of a process is increased by transmitting redundant data so that no data is lost even if some packets are lost.	computation;quality of service;tcp congestion control;transmitter;two-phase locking	Takuya Tojo;Tomoya Enokido;Makoto Takizawa	2004	24th International Conference on Distributed Computing Systems, 2004. Proceedings.	10.1109/ICDCS.2004.1281632	communications protocol;intelligent network;real-time computing;quality of service;telecommunications;communication in small groups;computer science;distributed computing;bandwidth;computer network;data transmission;satisfiability	HPC	-7.387834584004817	96.42426154983161	14683
74819c2e3f06f96e25dab5f9510191137df76c48	multiparty quantum key agreement with single particles	quantum information;quantum key agreement;journal;quantum cryptography	Two conditions must be satisfied in a secure quantum key agreement (QKA) protocol: (1) outside eavesdroppers cannot gain the generated key without introducing any error; (2) the generated key cannot be determined by any non-trivial subset of the participants. That is, a secure QKA protocol can not only prevent the outside attackers from stealing the key, but also resist the attack from inside participants, i.e. some dishonest participants determine the key alone by illegal means. How to resist participant attack is an aporia in the design of QKA protocols, especially the multi-party ones. In this paper we present the first secure multiparty QKA protocol against both outside and participant attacks. Further more, we have proved its security in detail.	key-agreement protocol	Bin Liu;Fei Gao;Wei Huang;Qiaoyan Wen	2013	Quantum Information Processing	10.1007/s11128-012-0492-6	quantum information;physics;quantum cryptography;quantum mechanics	Crypto	-40.513020054036716	73.93937720991875	14714
ae7eb4b802ebe14b2a100cf01ffa7b53dc316d7e	"""correction to """"towards a new theory of sequential switching networks"""" 1"""	switching network			Boris Beizer	1971	IEEE Trans. Computers	10.1109/T-C.1971.223379	computer science;label switching	Vision	-7.817748274997458	87.22296826066776	14745
119ec31908fcd9f9620ec7210cbd62387892802f	support vector machine detection of peer-to-peer traffic in high-performance routers with packet sampling: nonlinear kernel approach	support vector machines;p2p;packet sampling;detection;support vector machine;peer to peer;high performance	In this paper, we apply nonlinear support vector machines to identify peer-to-peer (p2p) traffic in high-performance routers with packet sampling. Due to their high port rates, those routers cannot extract the headers of all the packets that traverse them, but only a sample. The results in this paper suggest that nonlinear support vector machines are highly successful and outperform recent approaches like [1,2].	experiment;kernel (operating system);network packet;nonlinear programming;nonlinear system;peer-to-peer;router (computing);sampling (signal processing);support vector machine;traverse	Francisco Javier González-Castaño;Pedro S. Rodríguez-Hernández;Rafael P. Martínez-Álvarez;Andrés Gómez-Tato	2007		10.1007/978-3-540-72588-6_109	support vector machine;real-time computing;computer science;theoretical computer science;machine learning;distributed computing	ML	-12.547470060055923	79.61908604072534	14747
f6facc73fc167cb292345e8ac24f98b113c41a46	efficient task assignment on heterogeneous multicore systems considering communication overhead	ilp;multicore system;greedy algorithm;task assignment	This paper addresses task assignment problem on heterogeneous multicore systems with time constraint considering communication overhead. Processing cores in a heterogeneous system considered in this paper are grouped into clusters according to core types. Therefore, clusters have different computation capabilities. Communication links among various clusters have different communication capacities as well. The goal of heterogeneous task assignment problem is to minimize the total system cost for allocating a set of given tasks with data dependencies to a group of heterogeneous clusters while the time constraint is satisfied. The system cost considered in this paper is related to both execution load and communication load on various clusters and communication links. The general heterogeneous assignment problem is NP-complete. In this paper, we present the ILP formulation for solving the heterogeneous assignment problem. We also propose a heuristic, the Ratio Greedy Assign algorithm (RGA), to solve the problem efficiently for directed acyclic graphs (DAG). According to our experimental results, the Ratio Greedy Assign algorithm generates near-optimal results efficiently for all the benchmarks, while the ILP method cannot find a solution with acceptable computation time for large-sized benchmarks, such as 10-4lattice filter. Compared with a method that assigns all the tasks to a cluster of homogeneous cores, the RGA algorithm reduces the total system cost by 35.1% on average with four heterogeneous clusters. It reduces the cost by 24.6% on average with three heterogeneous cluster.	activity selection problem;assignment problem;computation;computer cluster;data dependency;directed acyclic graph;greedy algorithm;heterogeneous computing;heuristic;multi-core processor;np-completeness;overhead (computing);time complexity	Li Wang;Jing Liu;Jingtong Hu;Qingfeng Zhuge;Duo Liu;Edwin Hsing-Mean Sha	2012		10.1007/978-3-642-33078-0_13	greedy algorithm;parallel computing;real-time computing;computer science;generalized assignment problem;distributed computing	HPC	-13.777721747077358	61.55435732809258	14750
080ed816d94ce37cdb58f636d20373aebc0d1645	reconfiguration of logical topologies with minimum traffic disruptions in reliable wdm-based mesh networks	wdm network;mesh network;network reliability;computer simulation;wavelength division multiplex	A wavelength division multiplexing (WDM) network offers a flexible networking infrastructure by assigning the route and wavelength of lightpaths. We can construct an optimal logical topology, by properly setting up the lightpaths. Furthermore, setting up a backup lightpath for each lightpath improves network reliability. When traffic demand changes, a new optimal (or sub-optimal) topology should be obtained by again applying the formulation. Then, we can reconfigure the running topology to the logical topology obtained. However, during this reconfiguration, traffic loss may occur due to the deletion of older lightpaths. In this paper, we consider reconfiguring the logical topology in reliable WDM-based mesh networks, and we propose five procedures that can be used to reconfigure a running lightpath to a new one. Applying the procedures one by one produces a new logical topology. The procedures mainly focus on utilizing free wavelength resources and the resources of backup lightpaths, which are not used usually for transporting traffic. The results of computer simulations indicate that the traffic loss is remarkably reduced in the 14-node network we used as an example.	algorithm;backup;computer simulation;logical topology;mesh networking;procedural generation;tao;wavelength-division multiplexing	Shinya Ishida;Shin'ichi Arakawa;Masayuki Murata	2003	Photonic Network Communications	10.1023/A:1025679305036	computer simulation;telecommunications;computer science;mesh networking;distributed computing;reliability;computer network;logical topology	Metrics	-6.653846260977947	81.5148296536807	14799
8897250749729fbcaad60a520cd1f2c95b3bc33a	construction of credible ubiquitous p2p content exchange communities	distributed system;analisis contenido;communaute repartie;systeme reparti;calculateur embarque;web community;par a par;pervasive computing;p2p;gestion derecho autor numerico;processing time;digital rights management;informatica difusa;exchange interaction;content analysis;sistema repartido;content distribution;poste a poste;gestion droits numeriques;informatique diffuse;comportement utilisateur;boarded computer;temps traitement;rendezvous point;user behavior;p2p networks;analyse contenu;peer to peer;tiempo proceso;comunidad repartido;calculador embarque;digital right management;comportamiento usuario	This paper describes methods for suppressing illegal behavior in P2P networks to construct ubiquitous P2P content exchange communities. Although rigid digital rights management has been established elsewhere, it requires rather a large processing load and time, and it is mainly effective at preventing illegal behavior of end users. Here, we propose a more efficient method for processing content distribution. It aims to control content exchange so that illegal activities can be reduced to a sufficiently low level. By observing content exchange interactions in rendezvous points, it detects illegal activities and identifies which peer performed them. Simulation results show the effectiveness of the proposal.		Yuki Yokohata;Hiroshi Sunaga;Hiroyuki Nakamura	2005		10.1007/11596042_64	content analysis;telecommunications;computer science;exchange interaction;peer-to-peer;digital rights management;computer security;ubiquitous computing	HCI	-45.443825405604564	78.28270904610226	14806
d4da904a5bbd8bc61d5a47e5201253df7b91c8f8	cto roundtable: malware defense	malware defense;cto roundtable	The battle is bigger than most of us realize.	malware	Mache Creeger	2010	ACM Queue	10.1145/1716383.1731902	computer security	PL	-56.69866268580267	63.77790819070927	14812
f200da8563e16a74efc66d14df77420f950c7499	fractal-based models for internet traffic and their application to secure data transmission			fractal	Rashiq Rafiq Marie	2000			internet privacy;computer security;internet traffic engineering;computer network	Security	-17.692528378713934	88.66365888891741	14828
88f7e8a29087c71198604403f82345919edf2055	the beneffits of corba-based network management	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;ciencias basicas y experimentales;network management;tecnologias	73 One possible approach to handle these requirements is to design an open, standards-based, extensi-ble, and distributed network management system using CORBA. The CORBA interface to the system facilitates easy communication with other systems. Its extensible nature allows the system to grow in future. Finally, CORBA's distributed capabilities make it possible to manage large numbers of network devices in a scalable manner. ProSphere is a CORBA-based [1, 8] distributed network management system for General DataCom-m's (GDC) Asynchronous Transfer Mode (ATM) product line. This product line includes network edge and backbone ATM switches, which are deployed in many telecommunications carriers and private networks worldwide. The ProSphere architecture consists of a set of CORBA servers, which provide Network Management Services; and Java client applications that present information from the servers in graphical interfaces. The architecture is extensible, allowing new kinds of network devices to be supported with little or no change to existing software. The architecture is open, allowing end-user (customer) integration through CORBA Interface Definition Language (IDL) interfaces. The architecture is portable—Java clients can run from any type of host machine or Web browser. Finally, the ProSphere architecture is distributed in that the system components (clients, servers, and objects) can reside in separate processes and hosts. We describe the ProSphere architecture here and show how it benefits from the use of CORBA.	atm turbo;common object request broker architecture;game developers conference;graphical user interface;hypervisor;interface description language;internet backbone;java;network switch;private network;requirement;scalability;server (computing)	Paul Haggerty;Krishnan Seetharaman	1998	Commun. ACM	10.1145/286238.286250	network management;embedded system;computer science;operating system	Networks	-21.06171470950565	85.53633217799184	14857
20573c1e2b4c037279700ad97cc07985ffcb7d37	a component-based cross-layer framework for software defined wireless networks	media access protocol;physical layer;resource management;wireless communication;computer architecture;wireless sensor networks	Network architectures that exhibit cognitive behavior, such as self-adaptation and reconfiguration, are becoming extremely popular paradigms for the future heterogeneous wireless networks. Towards this direction, in this paper, we leverage on the component-based approach to achieve modular cross-layer design and propose a protocol stack with adaptive features that allows autonomous decision-making using local ambient information. The proposed framework allows segregating control from the data plane and combining different techniques, such as backpressure and Markov Random Fields (MRFs), for more efficient adaptation and flexibility against network variations. We demonstrate the effectiveness of the proposed approach and the component-based features of the architecture by presenting hybrid control plane mechanisms that combine the aforementioned techniques in a modular fashion. Finally, we provide directions for practically exploiting the proposed architecture.	autonomous robot;component-based software engineering;control plane;forwarding plane;markov chain;markov random field;protocol stack	Vasileios Karyotis;Eleni Stai;Symeon Papavassiliou	2016	2016 8th IFIP International Conference on New Technologies, Mobility and Security (NTMS)	10.1109/NTMS.2016.7792426	embedded system;real-time computing;wireless sensor network;telecommunications;computer science;resource management;distributed computing;key distribution in wireless sensor networks;wi-fi array;physical layer;wireless;computer network	Robotics	-20.437025566527385	79.8262201539145	14872
f959e211652bf4b8585fbb9c072b06983da1abc7	securing the industrial-tactile internet of things with deterministic silicon photonics switches	telecommunication traffic 5g mobile communication big data cloud computing computer network security field programmable gate arrays internet of things photonic switching systems;computer crime;internet of things;smart grids;deterministic silicon photonics switches optical bandwidth big data green cloud computing european union photonics transceivers cloud services speed of light network energy efficiency congestion free sd vn 5g wireless networks optical networks fpga technologies deterministic packet switches energy use dos attacks low jitter scheduling deterministic communications distinct secure deterministic virtual networks secure deterministic industrial tactile iot core network energy efficiency cyber security smart manufacturing smart cities smart transportation systems smart systems be iot best effort internet of things;internet of things delays smart grids computer crime field programmable gate arrays;field programmable gate arrays;delays;fpga security smart systems machine to machine m2m deterministic virtual private networks green industrial internet of things green tactile internet of things big data green cloud computing sdn control plane silicon photonics	Today's best-effort (BE) Internet of Things (IoT) faces challenges in providing the end-to-end-performance, security, and energy efficiency needed for the Smart Systems of the 21st century. These future smart systems will include smart cities, smart transportation systems, and smart manufacturing. This paper surveys the security weaknesses of the BE IoT. The BE-IoT cannot be partitioned into distinct interference-free virtual networks, which compromises performance, cyber-security, and energy efficiency. The design of a secure deterministic industrial-tactile IoT core network, which can embed millions of distinct secure deterministic virtual networks (SD-VNs) in layer 2, is then presented. Deterministic communications, combined with low-jitter scheduling, offers several benefits: 1) the removal of all congestion, interference, and DOS attacks; 2) a significant reduction in IoT router buffer sizes; 3) a significant reduction in IoT energy use; 4) a reduction of end-to-end IoT delays to the speed of light in fiber; and 5) deterministic packet-switches are relatively easy to synthesize using FPGA technologies. These benefits apply to optical and 5G wireless networks. Future smart systems can reserve their own congestion-free SD-VNs in layer 2 to manage their traffic, with significantly improved performance, security, and energy efficiency. A speed-of-light deterministic IoT core network can transform cloud services in the 21st century by exploiting a new technology: FPGAs combined with silicon photonics transceivers to achieve terabits/second of optical bandwidth. To illustrate the transformational potential, Big Data green cloud computing over a secure deterministic IoT spanning the European Union is explored.	best-effort delivery;big data;cloud computing;computer security;dos;end-to-end encryption;end-to-end principle;field-programmable gate array;file spanning;interference (communication);internet of things;network congestion;network packet;network switch;router (computing);scheduling (computing);smart city;smart system;terabit;transceiver	Ted H. Szymanski	2016	IEEE Access	10.1109/ACCESS.2016.2613512	telecommunications;computer science;operating system;distributed computing;smart grid;computer security;internet of things;field-programmable gate array;computer network	Arch	-12.908216952182539	84.14887447932453	14890
a04c5ac9fe75a920966a7195a8ac7386fb03eefe	anonymous fingerprinting based on committed oblivious transfer	protection information;commerce electronique;electronic commerce;zero knowledge proof;comercio electronico;intellectual property;oblivious transfer;droit auteur;copyright;cle publique;public key;proteccion informacion;fingerprinting;criptografia;cryptography;information protection;propiedad intelectual;llave publica;cryptographie;propriete intellectuelle;electronic trade;secure multiparty computation;derecho autor	Thwarting unlawful redistribution of information sold electronically is a major problem of information-based electronic commerce. Anonymous fingerprinting has appeared as a technique for copyright protection which is compatible with buyer anonymity in electronic transactions. However, the complexity of known algorithms for anonymous fingerprinting deters their practical implementation, since they rely either on secure multiparty computation or on general zero-knowledge proofs. A scheme for anonymous fingerprinting based on committed oblivious transfer is presented in this paper where all computations can be performed efficiently.	algorithm;bit array;e-commerce;electronic funds transfer;fingerprint (computing);leftover hash lemma;oblivious transfer;secure multi-party computation;smart card;zero-knowledge proof	Josep Domingo-Ferrer	1999		10.1007/3-540-49162-7_4	e-commerce;telecommunications;computer science;cryptography;oblivious transfer;database;distributed computing;internet privacy;computer security;intellectual property	Crypto	-44.20327605246056	71.702808849369	14903
d835674a7b2f05eecadf55fe1cff724a966d6c68	runtime service recovery for open information gateway	message publish and subscription;long distance radio;mesh networks logic gates servers base stations disaster management information exchange;service recovery;runtime service recovery information exchange disaster management system disaster response disaster relief open information gateway oigy communicaiton service recover long distance radio telecommunication computer networks dynamic power adjustment radio stations radio recovery dynamic mesh routers physical communication testbeds service reliability;service recovery long distance radio message publish and subscription;telecommunication network routing emergency management internetworking message passing middleware radio stations	How to effectively exchange information between parties in a disaster management system is one of the fundamental challenges to support timely and efficient disaster response and relief. Specifically, the timeliness, scalability, and availability are three desirable features for information exchange. We call the framework to support information exchange with the three features an Open Information Gateway (OIGY). In this paper, we present and experiment the mechanisms to recover communication service during and after disasters for Open Information Gateway. The designed mechanisms adopt long distance radio to support tele-communication and computer networks, dynamic power adjustment for radio stations to maximize the radio recovery with minimal interference, and dynamic MESH routers to connect devices located in different networks. We experimented the proposed mechanism on a physical communication testbeds to measure the delay for service recovery and reliability of the proposed mechanism.	information exchange;interference (communication);radio broadcasting;scalability;service discovery;television;testbed	Liang-Yu Chen;Hsin-Yi Chen;Chi-Sheng Shih;Ling-Jyh Chen;Kate Ching-Ju Lin;Wei-Ho Chung	2014	Proceeding of IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks 2014	10.1109/WoWMoM.2014.6918941	telecommunications;operating system;computer security;computer network	Mobile	-21.248190353783166	82.43168677729459	14905
b64de8beb8ac257a6ade5d6cb799522bc0e1dda0	improving routing table lookup in software routers	routing table lookup software hardware parallel processing random access memory switches;routing table lookup software router on chip fast memory processing and memory access overhead;hash table like method routing table lookup software router stable data structure;telecommunication network routing data structures table lookup telecommunication computing	For the speed-up in the routing table lookup in software routers, we introduce a new data structure called, sTable that achieves space efficiency while causing low processing overhead without hardware parallelism. Using a hash table-like approach, sTable stores only next hop information to handle most packets within the on-chip fast memory while causing some accesses to the off-chip slow memory to handle lookup errors. Routing table lookup experiments using Click show that, causing less processing overhead and a smaller number of lookup errors than Bloom filter, sTable reduces the average table lookup time by 44% (i.e., from 119 ns to 67 ns) compared to Bloom filter.	bloom filter;data structure;experiment;hash table;lookup table;overhead (computing);parallel computing;router (computing);routing table	HyunYong Lee;Akihiro Nakao	2015	IEEE Communications Letters	10.1109/LCOMM.2015.2418759	policy-based routing;routing table;route;routing;enhanced interior gateway routing protocol;static routing;parallel computing;topology table;border gateway protocol;zone routing protocol;computer science;dynamic source routing;theoretical computer science;destination-sequenced distance vector routing;forwarding plane;routing protocol;link-state routing protocol;metrics;computer network	OS	-5.7464778295524255	66.74377796609045	14909
a0ea59d6f99d813899d7f848a60597a22dad9d4d	tsqm: trust-based secure query method in anonymous communication system		Abstract The peer-to-peer network based on distributed hash table could locate the nodes effectively, but it cannot solve the node-failure problem. By introducing the concept of trust into anonymous communication system, this paper proposes a secure query method, in which, the nodes’ trust and the mutual distance between the nodes can be used to select high reliable nodes to construct anonymous communication path. The novel method could alleviate the node-failure problem, and further to improve the message forwarding efficiency.		Xiaohuan Liu;Fengyin Li;Jiguo Yu;Can Cui	2017		10.1016/j.procs.2018.03.014	data mining;communications system;computer science;distributed computing;distributed hash table	Security	-50.33737309110302	77.9545310148705	14916
ed45a135321e1769349b85ce5b3cdff518ba9e61	tnt10g: a high-accuracy 10 gbe traffic player and recorder for multi-terabyte traces	software;random access memory;raid field buses field programmable gate arrays linux logic design;clocks;accuracy;netfpga 10g 10 gb s ethernet fpga based network tester trace replayer and recorder multi terabyte pcap traces;ip networks;field programmable gate arrays;bit rate 10 gbit s tnt10g traffic player multiterabyte trace network tester fpga based tool ethernet network traffic netfpga 10g platform standard axi buses line rate operation custom developed linux driver raid0 array commodity ssd disk off the shelf component;field programmable gate arrays software hardware ip networks clocks random access memory accuracy;hardware	In this paper we present TNT10G (multi-Terabyte trace Network Tester), an FPGA-based tool for replaying and capturing massive Ethernet traces at 10 Gb/s. The tool is capable of reproducing and storing terabytes of network traffic at line rate, even if small packets are being used. Moreover, since the design works at low level (XGMII), accuracy is better than 10 ns, and it is also possible to observe and generate anomalous conditions, such as malformed frames, FCS errors, or illegal inter-frame gaps. All such features make TNT10G a truly useful tool for network testing and monitoring at 10 Gb/s. The design uses the NetFPGA-10G platform, although it could be easily ported to other boards since it uses standard AXI buses. The key element to achieve line-rate operation is a custom-developed Linux driver, which works in conjunction with a high-speed DMA backend core from Northwest Logic. Such blocks, together with a RAID0 array of commodity SSD disks, enable operation at 10 Gb/s. Finally, the use of a low-cost academic board together with off-the-shelf components allows for an open, extensible and cost-effective solution, a unique combination not found in commercial products.	automated x-ray inspection;direct memory access;field-programmable gate array;gigabyte;http 404;linux;media-independent interface;network packet;solid-state drive;standard raid levels;terabyte;tracing (software)	Jose Fernando Zazo;Marco Forconesi;Sergio López-Buedo;Gustavo Sutter;Javier Aracil	2014	2014 International Conference on ReConFigurable Computing and FPGAs (ReConFig14)	10.1109/ReConFig.2014.7032561	embedded system;real-time computing;computer hardware;computer science;operating system;accuracy and precision;field-programmable gate array;statistics	HPC	-6.918522739499717	65.25130492628247	14924
11e602247c7be93ef95ac238e516a461862fcda5	probabilistic analysis of scheduling precedence constrained parallel tasks on multicomputers with contiguous processor allocation	processor scheduling concurrent computing partitioning algorithms computer science performance analysis network topology approximation algorithms scheduling algorithm algorithm design and analysis large scale systems;parallel task;approximate algorithm;contiguous processor allocation;average case performance ratio;processor scheduling;resource allocation;binary system partitioning;largest task first;large scale;probabilistic analysis;parallel computations precedence constrained parallel tasks scheduling multicomputers processor allocation binary system partitioning;precedence constraint;parallel computer;scheduling problem;task graphs;task scheduling;resource allocation processor scheduling;performance ratio	ÐGiven a set of precedence constrained parallel tasks with their processor requirements and execution times, the problem of scheduling precedence constrained parallel tasks on multicomputers with contiguous processor allocation is to find a nonpreemptive schedule of the tasks on a multicomputer such that the schedule length is minimized. This scheduling problem is substantially more difficult than other scheduling problems due to precedence constraints among tasks, the inherent difficulty of task scheduling, and processor allocation in multicomputers. We present an approximation algorithm called LLB that schedules tasks level-by-level using the largest-task-first strategy supported by the binary system partitioning scheme to handle the three difficult issues in our scheduling problem. Though algorithm LLB does not have a bounded worst-case performance ratio, we show through probabilistic analysis that LLB has a quite reasonable average-case performance ratio for typical classes of parallel computations. In particular, algorithm LLB has an average-case performance ratio less than two for large scale parallel computations that have wide task graphs (i.e., that exhibit large parallelism). Index TermsÐAverage-case performance ratio, binary system partitioning, contiguous processor allocation, largest-task-first, parallel task, precedence constraint, probabilistic analysis, task scheduling.	approximation algorithm;average-case complexity;best, worst and average case;central processing unit;computation;distributed computing;elegant degradation;parallel computing;power of two;probabilistic analysis of algorithms;requirement;scheduling (computing)	Keqin Li;Yi Pan	2000	IEEE Trans. Computers	10.1109/12.888038	job shop scheduling;parallel computing;probabilistic analysis of algorithms;real-time computing;resource allocation;computer science;distributed computing	Metrics	-13.460356244571347	60.54427943449799	14933
a5d7f11f2363f9be13c4da17d237fe5bc5cf3de8	a new approach to www service quality evaluation	median opinion score www service quality evaluation telecommunication services quality evaluation issues european union european council quality of service quality of experience quality evaluation metric;quality of service internet quality of experience;web pages;quality of service world wide web web pages delays europe telecommunication standards internet;internet;telecommunication standards;world wide web;www quality model www service quality qos qoe service quality assessment;europe;quality of service;delays	The paper presents telecommunication services quality evaluation issues. It discusses the general European Union attitude and mentions the main documents of the European Council regarding the quality of service. The author presents two different, user's and operator's, points of view on the matter. Hence, two approaches to the service quality evaluation are discussed: an objective and subjective one. The author makes an effort to find a relationship between the quality of service and quality of experience for the WWW service. A proposal of new quality evaluation metric, based on the Median Opinion Score, is presented. Based on this approach, author proposed three zones, laid on the time scale, indicated by users' evaluation grades of web opening times which correspond with the service quality experienced by them.	document;quality of service;www	Janusz Henryk Klink	2014	2014 22nd International Conference on Software, Telecommunications and Computer Networks (SoftCOM)	10.1109/SOFTCOM.2014.7039062	service level requirement;service level objective;quality policy;engineering;service delivery framework;marketing;service design;multimedia;customer service assurance;world wide web	SE	-12.016226033018242	100.86674261240832	14935
14c273a2a81fa1a7f09bee34783ea8946bb0dad6	on the relation between differential privacy and quantitative information flow	utility function;satisfiability;conceptual framework;information flow;mutual information;logic in computer science;statistical query;information theory	Differential privacy is a notion that has emerged in the community of statistical databases, as a response to the problem of protecting the privacy of the database’s participants when performing statistical queries. The idea is that a randomized query satisfies differential privacy if the likelihood of obtaining a certain answer for a database x is not too different from the likelihood of obtaining the same answer on adjacent databases, i.e. databases which differ from x for only one individual. Information flow is an area of Security concerned with the problem of controlling the leakage of confidential information in programs and protocols. Nowadays, one of the most established approaches to quantify and to reason about leakage is based on the Rényi min entropy version of information theory. In this paper, we analyze critically the notion of differential privacy in light of the conceptual framework provided by the Rényi min information theory. We show that there is a close relation between differential privacy and leakage, due to the graph symmetries induced by the adjacency relation. Furthermore, we consider the utility of the randomized answer, which measures its expected degree of accuracy. We focus on certain kinds of utility functions called “binary”, which have a close correspondence with the Rényi min mutual information. Again, it turns out that there can be a tight correspondence between differential privacy and utility, depending on the symmetries induced by the adjacency relation and by the query. Depending on these symmetries we can also build an optimal-utility randomization mechanism while preserving the required level of differential privacy. Our main contribution is a study of the kind of structures that can be induced by the adjacency relation and the query, and how to use them to derive bounds on the leakage and achieve the optimal utility.	address space layout randomization;confidentiality;differential privacy;distance-regular graph;graph (discrete mathematics);information flow;information theory;maxima and minima;mutual information;randomized algorithm;rényi entropy;spectral leakage;statistical database	Mário S. Alvim;Miguel E. Andrés;Konstantinos Chatzikokolakis;Catuscia Palamidessi	2011		10.1007/978-3-642-22012-8_4	discrete mathematics;information flow;information theory;artificial intelligence;theoretical computer science;data mining;conceptual framework;mathematics;mutual information;algorithm;statistics;satisfiability	DB	-38.77393457928462	63.27636920111281	14937
2f233c7dea0abf2fb9169b3b05edae5f6e221c4b	receipt-free electronic voting scheme with a tamper-resistant randomizer	carte a puce;smart card;zero knowledge proof;java card;encryption;cryptanalyse;langage java;cifrado;satisfiability;tamper resistance;receipt freeness;cryptanalysis;criptoanalisis;cryptage;smart cards;voting;lenguaje java;voto;tamper resistant randomizer;vote;divertible zero knowledge proof;electronic voting;vote electronique;java language	We investigate the receipt-freeness issue of electronic voting protocols. Receipt-freeness means that a voter neither obtains nor is able to construct a receipt proving the content of his vote. [Hirt01] proposed a receipt-free voting scheme by introducing a third-party randomizer and by using divertible zero-knowledge proof of validity and designatedverifier re-encryption proof. This scheme satisfies receipt-freeness under the assumption that the randomizer does not collude with a buyer and two-way untappable channel exists between voters and the randomizer. But untappable channel is hard to implement in real world and will cause inconvenience to voters although it is provided. In this paper we extend [Hirt01] such that a tamper-resistant randomizer (TRR), a secure hardware device such as smart card or Java card, replaces the role of third-party randomizer and untappable channel. Moreover K-out-of-L receipt-free voting is provided in more efficient manner by introducing divertible proof of difference.	comment (computer programming);computation;digital signature;encryption;human-readable medium;interactivity;internet;java card;participatory monitoring;scrambler;smart card;tamper resistance;trusted third party;zero-knowledge proof	Byoungcheon Lee;Kwangjo Kim	2002		10.1007/3-540-36552-4_27	smart card;computer science;theoretical computer science;internet privacy;computer security;algorithm	Security	-43.134159332322994	76.14279662738386	14941
1183615dd9fae742ec401e72e1b6fd2ebbc15c32	communications in unknown networks: preserving the secret of topology	surete donnee;secrecy;protocols;reseau communication;entropia;base de connaissances;security of the topology;routing;network security;nudo;connaissance;network entropy;resolution math;routage;protocolo;conocimiento;dynamique reseau;securite donnee;communication in unknown networks;secret;data distribution;network topology;11t71;knowledge;local knowledge;protocole;criptografia;informatique theorique;cryptography;entropie;borne inferieure;distancia;resolucion matematica;communication protocol;cryptographie;base conocimiento;entropy;noeud;communication;red de comunicacion;topologie circuit;comunicacion;solving;node;communication network;security of data;lower bound;secreto;distance;dynamic networks;cota inferior;computer theory;knowledge base;informatica teorica;enrutamiento	In cryptography we investigate security aspects of data distributed in a network. This kind of security does not protect the secrecy of the network topology against being discovered if some kind of communication has taken place. But there are several scenarios where the network topology has to be a part of the secret. #R##N#In this paper we study the question of communication within a secret network where the processing nodes of the network have only partial knowledge (e.g. given as routing tables) of the topology. We introduce a model for measuring the loss of security of the topology when far distance communication takes place. A communication protocol preserves the secret of topology if no processing node can deduce additional information about the topology from the communication. We will investigate lower bounds on the knowledge that can be revealed from the communication string and show, for instance, that some knowledge about distances can always be revealed. Then, we consider routing tables. We show that several kinds of routing tables are not sufficient to guarantee the secrecy of topology. On the other hand, if a routing table allows us to specify the direction from which a message is coming, we can run a protocol solving the all-to-all communication problem such that no processing node can gain additional knowledge about the network.#R##N##R##N#Finally, we investigate the problem of whether routing tables can be generated from the local knowledge of the processing nodes without losing the secrecy of the network topology with respect to the resulting knowledge base. It will be shown that this is not possible for static networks and most kinds of dynamic networks.		Markus Hinkelmann;Andreas Jakoby	2007	Theor. Comput. Sci.	10.1016/j.tcs.2007.04.031	routing table;communications protocol;entropy;knowledge base;topology table;telecommunications;computer science;artificial intelligence;network security;routing protocol;geographic routing;network topology;algorithm;logical topology	ECom	-46.27832798005746	81.02613226520855	14947
611b4fa68420dc44e278f50681d0bba24c23b786	profiling contributors in the human-computer cloud		The concept of human-computer cloud is an adaptation of a traditional cloud computing paradigm to applications that require human expertise for performing some of the information processing operations. In these environments, it is important to maintain rich contributor profile that would allow to automatically route task requests to the contributors who will most likely complete them with high quality. On the other hand, the burden of filling and updating the profile shouldn't be entirely on the shoulders of contributors. This paper describes the profile structure of human-computer cloud environment and several mechanisms for automatically filling it and keeping up-to-date.	approximation algorithm;cloud computing;display resolution;human-centered computing;information processing;programming paradigm;rectifier;smart city;user profile	Alexander V. Smirnov;Nikolay Teslya;Andrew Ponomarev;Alexey Kashevnik	2018	2018 IEEE International Conference on Smart Computing (SMARTCOMP)	10.1109/SMARTCOMP.2018.00024	resource management;real-time computing;task analysis;cloud computing;profiling (computer programming);ontology (information science);information processing;shoulders;computer science	Robotics	-31.803487109390893	61.0491053866801	14987
2ab5052ea40baffdde58e639e6c95b25de743433	interaction & handover between ieee 802.16e and dvb-s/rcs using msctp protocol	radio networks;digital video broadcasting;satellite communication;protocols;video streaming;wimax digital video broadcasting ip networks mobile communication protocols quality of service satellite communication telecommunication standards video streaming;video streaming traffic satellite wireless radio network handover ieee 802 16e dvb s rcs msctp protocol wireless radio technology mobile wimax satellite broadcasting ip protocols qos;transform coding;network simulator;vertical handover;qos;satellite broadcasting;satellite wireless radio network handover;msctp protocol;telecommunication standards;satellites;mobile communication;next generation;ip networks;interaction model;digital video broadcasting satellite broadcasting wimax telecommunication traffic traffic control radio network next generation networking wireless application protocol context modeling streaming media;ip protocols;video streaming traffic;spatial networks;ieee 802 16e;quality of service;wimax;dvb s rcs;wireless radio technology;mobile terminal;mobile wimax	Until now, the interaction and the handover between the satellite and wireless radio networks of next generation has not yet taken into account because of the wide difference of operation between the two networks; and the difference of their protocol stacks structures. In this context, we propose an interaction model between a network based on wireless radio technology: the mobile WiMAX, and a spatial network based on satellite broadcasting and return of data: DVB-S/RCS. We suggest also to use the multi-homing protocol: MSCTP to provide the vertical handover for Mobile Terminals that are moving between the two networks. And we propose finally a new DVB-S/RCS protocol stack amended and based on MSCTP and IP protocols to be more interactive with the mobile WiMAX and the end users exchanging IP traffic. In this model we try to ensure good QoS for video streaming traffic; and we will show some experimental results of our vertical handover model using Network Simulator (ns2).	dvb-s;digital video broadcasting;multihoming;multiple homing;next-generation network;protocol stack;quality of service;revision control system;spatial network;streaming media	Tarek Bchini;Nabil Tabbane;Emmanuel Chaput;Sami Tabbane;André-Luc Beylot	2009	2009 IEEE Symposium on Computers and Communications	10.1109/ISCC.2009.5202261	embedded system;quality of service;telecommunications;computer science;computer network	Mobile	-15.31737790917661	91.83011533689762	15007
c06ce449f30ad82320b44748633f61f5372f4a71	a research on new public-key encryption schemes	security analysis;matematicas aplicadas;semantic security;probabilistic public key encryption scheme;mathematiques appliquees;integer factorization;efficiency;cryptage probabiliste;cle publique;public key encryption;logarithme discret;discrete logarithm;factorization;probabilistic encryption;eficacia;public key;factorizacion;lucas sequence;llave publica;factorisation;efficacite;applied mathematics	We investigate the properties of Lucas Sequence, and propose a new variant of (probabilistic) public-key encryption scheme based on Lucas sequence. Then we provide security analysis of the encryption schemes. The one-wayness of the proposed scheme is equivalent to Partial LUC-DL problem in ZN. For the proposed probabilistic encryption scheme, its semantic security is equivalent to Decisional LUC-DH problem in ZN. At last, we briefly analyze the efficiency of the proposed schemes. 2004 Elsevier Inc. All rights reserved.	lucas sequence;probabilistic encryption;public-key cryptography;semantic security	Zhengtao Jiang;Mingsen Xiang;Yumin Wang	2005	Applied Mathematics and Computation	10.1016/j.amc.2004.10.038	discrete mathematics;disk encryption theory;plaintext-aware encryption;theoretical computer science;mathematics;public-key cryptography;deterministic encryption;factorization;computer security;probabilistic encryption;algorithm;algebra	Crypto	-41.06897983755529	79.62212779456726	15009
faea4a1532d4688586110b0e138478c8b00abeb3	load balancing in distributed cloud data center configurations: performance and energy-efficiency		"""In this contribution two cloud server clusters are considered which process virtualized user service requests defined as Virtual Machines (VM) operated under the Hypervisor control. Load Balancing (LB) is applied to avoid temporary overloads and to enforce negotiated Service Level Agreements (SLA) defined by means and percentiles of processing delays. Two novel LB strategies are defined through which the two server clusters perfform job processing cooperatively through mutual job overflows by a """"Local Server System First"""" (LSSF) and through a """"Shortest Response Time First"""" (SRTF) strategy, respectively. The cooperation operation is performed by VM migration at the instant of VM scheduling by the Hypervisor. Both LB models are defined by queuing systems which are analyzed by the method of Markov-Chains. Energy efficiency has been analyzed by the authors through server consolidation, server sleep modes, and through Dynamic Voltage and Frequency Scaling (DVFS), c.f. [1-5]. In this contribution another method is studied which is based on a flexible VM migration to a common server cluster by which the total number of servers can be reduced making use of the effect of the economy of scale by server aggregation."""	computer cluster;data center;dynamic frequency scaling;dynamic voltage scaling;hypervisor;hysteresis;job scheduler;job stream;lattice boltzmann methods;load balancing (computing);markov chain;multiprocessing;queueing theory;responsiveness;scheduling (computing);semiconductor consolidation;server (computing);service-level agreement;virtual machine;virtual private server	Paul J. Kueh;Maggie Ezzat Mashaly	2017		10.1145/3077839.3084027	parallel computing;real-time computing;distributed computing	OS	-18.868716429045808	60.490844660838704	15013
eb84f538c313644c340094d92b7c35ab6d96846f	security analysis of a fuzzy identity-based encryption scheme	fuzzy identity based encryption;cryptanalysis;chosen plaintext secure;chosen ciphertext secure	Fuzzy identity-based encryption (FIBE) scheme is a kind of identity-based encryption (IBE) scheme, in which any user's identity is composed by a set of attributes and any ciphertext encrypted under identity ID can be decrypted by using a private key corresponding to identity ID′ if ID′ is close to ID as measured by some metric. Due to the error-tolerance property, FIBE scheme is very useful in real-world applications. However, most FIBE schemes are provable secure only in a weaker security model. In order to eliminate this problem, Ren et al. recently proposed a new FIBE scheme and proved that it is fully chosen-ciphertext secure in the standard model. Unfortunately, in this paper, we will show that their FIBE scheme is even not chosen-plaintext secure.	id-based encryption	Miaomiao Tian;Liusheng Huang;Wei Yang	2014	Journal of Circuits, Systems, and Computers	10.1142/S0218126614500339	cryptanalysis;computer science;theoretical computer science;mathematics;internet privacy;computer security;statistics	Crypto	-40.149269491711145	76.24523709349566	15031
5744e6b0730e4b80b3fbf28ec0a1b133fb9bec7e	omnicon:a mobile ip-based vertical handoff system for wireless lan and gprs links	wireless lans;cellular network;high-speed wireless internet access;multiple wireless access network;wireless internet connectivity;wireless lan;wireless lan availability;wireless lan connectivity;wireless technology;mobile node;gprs link;vertical handoff system	Wi-Fi based hotspots offer mobile users broadband wireless Internet connectivity in public work spaces and corporate/ university campuses. Despite aggressive deployment of these hotspots in recent years, high-speed wireless Internet access remains restricted to a small number of geographical areas because of limited physical coverage of wireless LANs. On the other hand, despite their lower throughput, cellular networks have a significantly wider coverage and are thus much more available. Recognizing that 2.5G or 3G cellular networks can effectively complement wireless LANs, we set out to develop a vertical handoff system that allows mobile users to seamlessly fall back to such cellular networks as GPRS or 3G whenever wireless LAN connectivity is not available. The resulting handoff mechanism allows a network connection on a mobile node to operate over multiple wireless access networks in a way that is completely transparent to end user applications. In this paper, we present the design, implementation, and evaluation of a fully operational vertical handoff system, called OmniCon, which enables mobile nodes to automatically switch between wireless LAN and GPRS, based on wireless LAN availability, by introducing a simple extension to existing Mobile IP implementation. We discuss the design issues in the proposed vertical handoff system for heterogeneous networks, including connection setup problems due to network address translation, and the disparity in link characteristics between wireless LANs and GPRS. A detailed performance evaluation study of the OmniCon prototype demonstrates its ability to migrate active network connections between these two wireless technologies with low handoff latency and close to zero packet loss.	access network;binocular disparity;internet access;mobile ip;network address translation;network packet;performance evaluation;prototype;software deployment;throughput;wireless access point	Srikant Sharma;Inho Baek;Yuvrajsinh Dodia;Tzi-cker Chiueh	2004	Workshops on Mobile and Wireless Networking/High Performance Scientific, Engineering Computing/Network Design and Architecture/Optical Networks Control and Management/Ad Hoc and Sensor Networks/Compil	10.1109/ICPPW.2004.1328035	embedded system;cellular network;active networking;gprs core network;throughput;the internet;wireless wan;ground-penetrating radar;heterogeneous network;wireless site survey;telecommunications;network switch;computer science;wireless network;wireless lan controller;key distribution in wireless sensor networks;municipal wireless network;wi-fi array;packet loss;fixed wireless;mobile computing;bandwidth;mobile ip;computer network	Mobile	-12.58160841797849	90.73178089459913	15032
4143066350d93b56d20412245c90d6e027a85511	reference model for smart home user behavior analysis software module	analytical models;sensors;prediction algorithms;home appliances;smart homes home appliances analytical models sensors medical services prediction algorithms usability;security of data home automation home computing;medical services;personal data security smart home user behavior analysis software module;usability;prediction techniques usability recommender system;smart homes	Smart Home spread is relatively low due to need of investments, usability issues and fears of the personal data security. To resolve these problems we suggest the reference model for the software responsible for analysis of Smart Home user behavior and simulation of the user's activities in automatic mode.	data security;home automation;personally identifiable information;reference model;simulation;usability	Dmitry Vavilov;Alexey Melezhik;Ivan Platonov	2014	2014 IEEE Fourth International Conference on Consumer Electronics Berlin (ICCE-Berlin)	10.1109/ICCE-Berlin.2014.7034262	embedded system;usability;engineering;world wide web;computer security;usability lab	Robotics	-47.26239687445909	60.83949541640761	15041
586dffbe31331d50beb03dd40ed1826f15cbf10b	design and evaluation of redundant ipc network adequate for an edge router	distributed system;high availability;routeur;arquitectura red;systeme reparti;machine unique;redundancia;availability;routing;disponibilidad;resource allocation;network processor;routage;architecture reseau;qualite service;machine transfert;single machine;maquina unica;sistema repartido;intermitencia;redundancy;intermittency;router;network architecture;asignacion recurso;transfer machine;maquina transferencia;intermittence;allocation ressource;disponibilite;service quality;redondance;calidad servicio;enrutamiento	In a high-capacity router, with both a single routing processor (RP) and multiple interface cards each equipped with multiple network processors (NPs), it is very important to easily scale its capacity and reliably for the transfer of controlling system messages between the RP and the NPs. For these reasons, the control plane used for control messages, such as inter-processor communication (IPC) messages, is separated from the data forwarding plane used for transferring user data. In this paper, we purpose and describe the implementation of control plane architecture, called Redundant IPC Network (RIPCN). We also evaluate the performance of the proposed RIPCN. From the evaluation results, when compared with a conventional IPC method, we show that the RIPCN not only provides an effective approach to the high availability of control plane, but also can improve its performance.	router (computing)	Youjin Kim;Jaedoo Huh;Haewon Jung;Kyoung-Rok Cho	2004		10.1007/978-3-540-27767-5_27	embedded system;availability;routing;real-time computing;network architecture;resource allocation;computer science;operating system;distributed computing;forwarding plane;redundancy;high availability;computer security;intermittent energy source;service quality;network processor	HPC	-5.537187597581819	73.33075529647093	15049
a8768b067d916cf1b84d5a96a75970123d44998f	network and service governance for the management of future networks	quality of service service governance network governance future networks management complex network environment dynamic joint network service management qos requirements operators business goals network policies ffth wlan policy driven wireless access load balancing self diagnosis monitoring packet loss delay fiber to the home access networks wireless local area networks;complex networks;resource allocation;telecommunication computing;qos governance policy based management policy translation self managed networks ftth wlan;monitoring;computer network management;optical fibre subscriber loops;business quality of service owl ontologies optical fiber subscriber loops semantics wireless lan;wireless lan;quality of service;wireless lan complex networks computer network management fault diagnosis monitoring optical fibre subscriber loops quality of service resource allocation telecommunication computing;fault diagnosis	The emergence of new technologies and services forces the network operator to manage uniformly and efficiently the complex network environment of Future Networks. The interworking of multiple underlying heterogeneous network domains with proprietary network management systems is currently a tedious task, and this fact will be exacerbated in the near future. To this end, we address the challenge of dynamic, efficient administration of Future Networks introducing the Network Governance paradigm; the latter automates the dynamic joint network and service management while fulfilling different QoS requirements for the users. The proposed governance framework supports the dynamic definition of operators' business goals, their translation to network policies and management actions and their enforcement onto the network. Moreover, an experimental case study on management of FFTH and WLAN testbeds has been implemented through two main mechanisms: policy-driven wireless access load balancing and self-diagnosis and monitoring, thereby proving the feasibility and applicability of the introduced concepts. The results show the performance gains including e.g. the QoS optimisation for packet loss and delay for a user class.	access network;complex network;emergence;fiber to the x;load balancing (computing);mathematical optimization;network governance;network packet;programming paradigm;quality of service;requirement;scalability;testbed;umbrella term;world wide web	Beatriz Fuentes;Eleni Patouni;Teemu Rautio;Evangelos A. Kosmatos;Roi Arapaglou;George Katsikas	2013	2013 Future Network & Mobile Summit		multi-frequency network;out-of-band management;service set;network intelligence;element management system;intelligent computer network;wireless wan;network architecture;heterogeneous network;network management station;radio resource management;wireless network;distributed computing;network management application;business;municipal wireless network;network access control;computer security;computer network	Metrics	-14.291241059081331	85.84334507725897	15066
909da31deba6cf4a837be9ea72d0af8cd2e8538e	reducing the implementation complexity of combined input and output queued switches by using extended maximal matching algorithm	bursty traffic extended maximal matching algorithm combined input and output queued switch scheduling nonuniform traffic bernoulli arrival;queueing theory;output queued;scheduling queueing theory telecommunication switching telecommunication traffic;telecommunication traffic;switches throughput traffic control scheduling algorithm fabrics delay computer science bipartite graph frequency;telecommunication switching;scheduling;bursty traffic	For a combined input and output queued (CIOQ) switch, maximal matching (MM) algorithm with a speedup of 2 has been known to deliver 100% throughput under any admissible traffic, where in each time slot, two independent schedulings and two cell transferrings are made respectively. This paper proposes a new kind of extended maximal matching (EMM) algorithm, which just utilizes a little information of VOQ length. We show that the implementation complexity of CIOQ switches is reduced by using the EMM(2) algorithm, where only one scheduling and two cell transferrings (data speedup of 2) are necessary in each time slot to achieve 100% throughput when input traffic is admissible. The EMM(2) algorithm can be easily realized by modifying the existing MM algorithms. In this paper, we provide a practical instance of EMM(2) algorithm, named EiSLIP(1,2), based on the well-known iSLIP algorithm. Simulations show that EiSLIP(1,2) algorithm with a data speedup of 2 achieves almost the same delay performance as output queued policy under uniform and non-uniform traffic with Bernoulli arrival, as well as the bursty traffic.	bernoulli polynomials;extended precision;input/output;mm algorithm;matching (graph theory);maximal set;network switch;scheduling (computing);simulation;speedup;throughput;whole earth 'lectronic link	Yang Xu;Wei Li;Beibei Wu;Wenjie Li;Bin Liu	2005	GLOBECOM '05. IEEE Global Telecommunications Conference, 2005.	10.1109/GLOCOM.2005.1577695	real-time computing;computer science;operating system;distributed computing;queueing theory;scheduling;computer network	HPC	-5.029746730264493	71.13108692587151	15075
1709d54e99bf8898d86b3f4a33bbbea89939e969	the virtual topology reconfiguration controller for wdm networks	discontinuous wavelengths virtual topology reconfiguration controller wdm networks traffic demands single hop lightpaths;communication system traffic control;wavelength assignment;wdm network;virtual topology reconfiguration controller;circuit topology;network topology;optical fibre networks;telecommunication traffic;network topology wdm networks communication system traffic control telecommunication traffic video recording circuit topology wavelength division multiplexing quality of service wavelength assignment computer science;single hop lightpaths;video recording;traffic demands;wdm networks;computer science;quality of service;telecommunication network topology;discontinuous wavelengths;telecommunication traffic optical fibre networks telecommunication network topology;wavelength division multiplexing	Reconfiguration of WDM networks allows network operators to reconfigure the topologies in response to changing traffic demands to improve the QoS. To reconfigure the current virtual topology, the time to reconfigure is decided, and then a target topology is created. Next, real transition between topologies is occurred. We propose a VTR controller for WDM networks. First, our controller decides when current virtual topology is reconfigured. Some traffic may travel with single hop lightpaths and others may not. What the amount of traffic which is serviced through multi-hop increases shows that current virtual topology is not adequate for traffic demands. We use this information to reconfigure. And, the controller creates a target topology. As discontinuous wavelengths increases in networks, it can increase the difficulty of establishing single hop lightpaths for future traffic. Hence, the controller establishes the lightpaths which would remain discontinuous as few as possible after assigning.	wavelength-division multiplexing	Seungyeon You;Sungchun Kim	2007	6th IEEE/ACIS International Conference on Computer and Information Science (ICIS 2007)	10.1109/ICIS.2007.180	telecommunications;engineering;distributed computing;computer network;logical topology	Visualization	-10.241723811065745	83.06902617330381	15109
20b167aed96d05ff77aca623b8e864163befd6e5	performance studies of mpls based integrated architecture for 3g-wlan scenarios with qos provisioning	mpls;umts;3g/wlan integration;traffic engineering and qos.;quality of service;wireless network;video conference;packet forwarding;wireless communication;heterogeneous network;network performance;voice over ip;satisfiability;packet loss;integrated services	Recently, the growing need of telecommunications such as VideoConference, Voice over IP etc. and for the diversity of transported flows, Internet network does not meet the requirements of future integrated services satisfying Quality-of-Services (QoS). This is become much more complex for heterogeneous networks especially for wireless networks. In this paper, we propose an MPLS based integrated architecture between 3G(UMTS)/WLAN networks. We present the performance analysis of this MPLS enabled 3GWLAN integrated framework for better QoS, throughput, less switching delay and less packet loss with the aim to fulfill the future demand of wireless communication. The mobility of the integrated framework is managed using hierarchical MIPv6 (HMIPv6). Integration point is considered at the MAP (Mobility Anchor Point) to restrict global update. Extensive simulation is done on mns-2.0 to evaluate the network performance in terms of packet forwarding, throughput and delay. For traffic engineering in the MPLS domain, CRLDP is used.	integrated services;mobile ip;multiprotocol label switching;network packet;network performance;provisioning;quality of service;requirement;semantic network;simulation;throughput	Iti Saha Misra;Chandi Pani	2007			real-time computing;wireless wan;telecommunications;computer science;end-to-end delay;packet forwarding;computer network	Networks	-12.529221868568142	90.57086547085457	15122
0d08a95027964ad0e9f9295de1ee22f7ead9069d	adaptive quality of service in voice over ip communications	internet voip qos qoe;protocols;transport protocols codecs forward error correction internet telephony quality of service;circuit noise;codecs;real time;working environment noise;voice quality;voice over ip;internet telephony;qos;transport protocols;forward error correction mechanism;telecommunication traffic;adaptive qos;forward error correction;internet;adaptive systems;qoe;quality of service internet telephony delay signal to noise ratio circuit noise telecommunication traffic working environment noise protocols costs adaptive systems;transport protocol;bandwidth;voice over ip communication;quality of service;signal to noise ratio;experimental measurement;adaptive qos quality of service voice over ip communication transport protocol codecs forward error correction mechanism;voip	The present work proposes an adaptive solution to provide quality of service in Voice over IP communications. This solution is based on three components that interact inorder to achieve higher quality in voice communication. The first two consist in changing the Codec and the transport protocol in real-time during a conversation; the third consists in using a Forward Error Correction mechanism to recover from loss packets. To demonstrate the voice quality obtained by this solution, a VoIP client application was developed, compatible with other VoIP clients, to implement the proposed quality of service algorithm and control the voice quality during a conversation. The results of the experimental measurements and simulations performed demonstrate that this solution is viable and significantly increases the voice quality of VoIP communication.	adaptive quality of service multi-hop routing;algorithm;client (computing);codec;forward error correction;network congestion;qr code;real-time clock;simulation;speech coding;streaming media;tree traversal	Nelson Costa;Mário Serafim Nunes	2009	2009 Fifth International Conference on Networking and Services	10.1109/ICNS.2009.33	real-time computing;quality of service;telecommunications;computer science;adaptive system;voice over ip;computer network	Mobile	-5.955689413962155	98.46100886408948	15124
2e72e467bc4445b697cc825666a341a8ed83b3ab	shield: scalable homomorphic implementation of encrypted data-classifiers	libraries;ring lwe;polynomials encryption electronic mail libraries graphics processing units;fhe;electronic mail;encryption;bayesian filter;implementation;gpu;polynomials;graphics processing units;gpu homomorphic encryption fhe ring lwe bayesian filter secure search decision trees implementation;secure search;decision trees;homomorphic encryption	"""Homomorphic encryption (HE) systems enable computations on encrypted data, without decrypting and without knowledge of the secret key. In this work, we describe an optimized Ring Learning With Errors (RLWE) based implementation of a variant of the HE system recently proposed by Gentry, Sahai and Waters (GSW). Although this system was widely believed to be less efficient than its contemporaries, we demonstrate quite the opposite behavior for a large class of applications. We first highlight and carefully exploit the algebraic features of the system to achieve significant speedup over the state-of-the-art HE implementation, namely the IBM homomorphic encryption library (HElib). We introduce several optimizations on top of our HE implementation, and use the resulting scheme to construct a homomorphic Bayesian spam filter, secure multiple keyword search, and a homomorphic evaluator for binary decision trees. Our results show a factor of <inline-formula><tex-math notation=""""LaTeX"""">$10\times$</tex-math><alternatives> <inline-graphic xlink:type=""""simple"""" xlink:href=""""khedr-ieq1-2500576.gif""""/></alternatives></inline-formula> improvement in performance (under the same security settings and CPU platforms) compared to IBM HElib for these applications. Our system is built to be easily portable to GPUs (unlike IBM HElib) which results in an additional speedup of up to a factor of <inline-formula> <tex-math notation=""""LaTeX"""">$103.5\times$</tex-math><alternatives><inline-graphic xlink:type=""""simple"""" xlink:href=""""khedr-ieq2-2500576.gif""""/> </alternatives></inline-formula> to offer an overall speedup of <inline-formula><tex-math notation=""""LaTeX""""> $1{,}035\times$</tex-math><alternatives><inline-graphic xlink:type=""""simple"""" xlink:href=""""khedr-ieq3-2500576.gif""""/></alternatives> </inline-formula>."""	amdahl's law;central processing unit;computation;cryptography;decision tree;email filtering;graphics processing unit;homomorphic encryption;interpreter (computing);key (cryptography);learning with errors;linear algebra;naive bayes spam filtering;search algorithm;spamming;speedup;web search engine;xlink	Alhassan Khedr;P. Glenn Gulak;Vinod Vaikuntanathan	2014	IEEE Transactions on Computers	10.1109/TC.2015.2500576	embedded system;parallel computing;homomorphic encryption;computer science;theoretical computer science;operating system;decision tree;distributed computing;homomorphic secret sharing;implementation;encryption;polynomial	Security	-36.47553046062613	76.5549643038558	15131
908e4442bbafffbb56bcf38a4711187b755816be	protocols for selection among replicated multicast servers.				Lenitra M. Clay;Mostafa H. Ammar;Ellen W. Zegura	2002			ip multicast;inter-domain;protocol independent multicast;pragmatic general multicast;distance vector multicast routing protocol;xcast	Metrics	-7.888796615996524	86.81835129659927	15170
ec10ce06bcbcf100be0e8c90e5ec68844bf3aacc	scale-free networks of collaborative processes to design distributed control systems	distributed system;system reliability;distributed control system;pervasive computing;scale free network;control system;scale free;community networks;mathematical model;power generation;power law	Pervasive computing is offering a level of personalized control over complex and distributed systems.We have designed a system using a communication network that displays a high degree of scale free behavior described by power law. Scale-free systems guarantee aggregation that is useful in building automation, sensors grid management and power generator grids. Synchronizability and stability are main problems of different processes.In order to keep a system stable and easy to manage is useful to have a scale-free structure. A mathematical model was used to define synchronizability criteria. At last, using aweighting scheme, the system was able to create scale-free networks with scale-free aggregates. The schema is activated when processes exchange run in the network. The design approach is valuable because it is one of the first attempts to use scale-free approach to design control systems.There are functional advantages of a scale free network topology. A scale-free network displays high degree of tolerance against random failures as only a few prominent hubs dominate their topology. However, vulnerability of hub is a risk to system reliability. © 2011 Published by Elsevier B.V.	distributed computing;distributed control system;mathematical model;network topology;personalization;sensor;telecommunications network;usb hub;ubiquitous computing	Francesco Rago;Pasquale Franzese	2011		10.1016/j.procs.2011.08.075	simulation;control system;artificial intelligence;operating system;scale-free network;data mining;distributed computing;statistics	Robotics	-8.619815267581622	73.19210928838433	15171
17c868a01ffdc54af5e306e74adbb498e3292b1f	cross-layer end-to-end label switching protocol for wimax-mpls heterogeneous networks	mpls;label switching;cross layer;wimax;network;protocol	The integration of WiMAX networks and multi-protocol label switching (MPLS) networks, called WiMPLS networks, is the trend for nomadic Internet access in the fourth generation (4G) wireless networks. The base station (BS) in such heterogeneous networks will play the role of bridge and router between the IEEE 802.16 subscriber stations (SSs) and MPLS networks. However, there is no such integrated solution so far and the switching efficiency of the BS should be considered as well. This paper, therefore, adopts a cross-layer fashion (from network layer to MAC layer) to design the end-to-end label switching protocol (ELSP) for filling this gap. ELSP provides the mechanism of end-to-end (SS-to-SS) and layer 2 switching transfer for switching performance enhancement by assigning the SS with the MPLS labels (M-labels). PLS etwork rotocol iMAX The M-label can be carried by the IEEE 802.16e extended subheader within the MAC protocol data unit (MPDU), which is fully compliant with the IEEE 802.16e standard. The security issue caused by M-label usage is also concerned and solved in this paper. This paper also reveals an extra advantage that the switching delay of the BS achieved by ELSP can be as low as hardware-accelerated IP lookup mechanism, e.g., ternary content addressable memory (TCAM). Simulation results show that ELSP efficiently improves elay the end-to-end transfer d	content-addressable memory;economic lot scheduling problem;end-to-end principle;hardware acceleration;internet access;lookup table;multiprotocol label switching;router (computing);simulation;telecommunications access method	Jenhui Chen;Woei-Hwa Tarn;Wu-Hsiao Hsu;Chih-Chieh Wang	2012	Journal of Systems and Software	10.1016/j.jss.2012.05.050	wimax;multiprotocol label switching;label distribution protocol;protocol;real-time computing;lan switching;telecommunications;computer science;label switching;computer network	Mobile	-12.12305244079691	90.44875859516509	15195
281789e224b09970cd25ee988a6f6f898c629bb8	no direction home: the true cost of routing around decoys		Decoy routing is a recently proposed approach for censorship circumvention. It relies on cooperating ISPs in the middle of the Internet to deploy the so called “decoy routers” that proxy network traffic from users in the censorship region. A recent study, published in an award-winning CCS 2012 paper [24], suggested that censors in highly connected countries like China can easily defeat decoy routing by selecting Internet routes that do not pass through the decoys. This attack is known as “routing around decoys” (RAD). In this paper, we perform an in-depth analysis of the true costs of the RAD attack, based on actual Internet data. Our analysis takes into account not just the Internet topology, but also business relationships between ISPs, monetary and performance costs of different routes, etc. We demonstrate that even for the most vulnerable decoy placement assumed in the RAD study, the attack is likely to impose tremendous costs on the censoring ISPs. They will be forced to switch to much more costly routes and suffer from degradation in the quality of service. We then demonstrate that a more strategic placement of decoys will further increase the censors’ costs and render the RAD attack ineffective. We also show that the attack is even less feasible for censors in countries that are not as connected as China since they have many fewer routes to choose from. The first lesson of our study is that defeating decoy routing by simply selecting alternative Internet routes is likely to be prohibitively expensive for the censors. The second, even more important lesson is that a fine-grained, data-driven approach is necessary for understanding the true costs of various route selection mechanisms. Analyses based solely on the graph topology of the Internet may lead to mistaken conclusions about the feasibility of decoy routing and other censorship circumvention techniques based on interdomain routing.	acm computing classification system;censoring (statistics);elegant degradation;inter-domain;internet censorship circumvention;internet topology;network traffic control;quality of service;rapid application development;routing;topological graph theory	Amir Houmansadr;Edmund L. Wong;Vitaly Shmatikov	2014			the internet;computer science;computer security;decoy;quality of service;censorship	Security	-57.156022638517314	69.40569952647661	15213
632322ee3e01a81378cebd66c057432e870248e2	large-scale group communication protocol for a two-layered group.	group communication;large scale		communications protocol	Kojiro Taguchi;Makoto Takizawa	2002			communication in small groups;computer science	Crypto	-30.64586193014911	69.62559726288636	15219
ba0dc4cd20799c29c428b64b3c3fd71f69153dd1	pattern password authentication based on touching location		Pattern passwords are one of the embedded authentication method of touchscreen devices, however it has some major drawbacks which briefly are identifiability and imitability. The password of the user is noticeable when entering the pattern due to shining circles. Therefore, what we put forward in this paper is a novel biometric implementation of a hidden system to pattern password authentication for increasing password security. As opposed to general research concept which extracts touch or keystroke durations, we focused on the touching coordinates calculated the distance of the line between the constant pattern node and the touched place as well as the angle. Using these inputs, we trained the neural network by Gauss-Newton and Levenberg-Marquardt algorithms and conducted the experiments with these trained classifiers.	authentication;password	Orcan Alpar;Ondrej Krejcar	2015		10.1007/978-3-319-24834-9_46	cognitive password;s/key;internet privacy;one-time password;world wide web;computer security;password strength	DB	-50.98029591120996	65.66623031046385	15234
23d415c087f815b18535d9d17764aa0f4d629d02	secure cloud computing with brokered trusted sensor networks	malware threat;wireless;risk analysis;smartphone based sensor networks;network security;smart phone;sensor network;mediation layer secure cloud computing brokered trusted sensor networks smartphone based sensor networks brokering network risk analysis malware threat malware defense covert channel analysis grids;covert channel;large scale;malware defense;brokering network;computational modeling;covert channel analysis;wireless sensor network brokered network security;hidden markov models;data privacy;secure cloud computing;network configuration;information processing;ieee 802 11 standards;mediation layer;security architecture;bandwidth;invasive software;invasive software data privacy grid computing;brokered trusted sensor networks;brokered network;grids;security;grid computing;meteorology;privacy;cloud computing	We propose a model for large-scale smartphone based sensor networks, with sensor information processed by clouds and grids, with a mediation layer for processing, filtering and other mashups done via a brokering network. Final aggregate results are assumed to be sent to users through traditional cloud interfaces such as browsers. We conjecture that such a network configuration will have significant sensing applications, and perform some preliminary work in both defining the system, and considering threats to the system as a whole from different perspectives. We then discuss our current, initial approaches to solving three portions of the overall security architecture: i) Risk Analysis relating to the possession and environment of the smart-phone sensors, ii) New malware threats and defenses installed on the sensor network proper, and iii) An analysis of covert channels being used to circumvent encryption in the user/cloud interface.	aggregate data;cloud computing;computer security;consumability;covert channel;encryption;high-level architecture;malware;mashup (web application hybrid);open research;privacy;real-time computing;sensor;smartphone	Apu Kapadia;Steven Myers;XiaoFeng Wang;Geoffrey C. Fox	2010	2010 International Symposium on Collaborative Technologies and Systems	10.1109/CTS.2010.5478459	wireless sensor network;risk analysis;cloud computing;information processing;covert channel;computer science;information security;network security;internet privacy;privacy;computational model;computer security;bandwidth;enterprise information security architecture;wireless;grid computing;computer network	Security	-45.326149119506475	64.673512100538	15240
2a9a6362370909f704d261b974c8f936e1fc55b4	energetic performance of service-oriented multi-radio networks: issues and perspectives	radio networks;wireless devices;service orientation;pervasive computing;wireless network;computer and information science;multi radio wireless networks;np hard problem;beyond 3rd generation network;network configuration;3rd generation;data och informationsvetenskap;service oriented architecture;energetic performance	Wireless devices now hold multiple radio interfaces, allowing to switch from one network to another according to required connectivity and related quality. Still, the selection of the best radio interface for a specific connection is under the responsibility of the end-user in most cases. Integrated multi-radio network management so as to improve the overall performance of the network(s) up to the software application layer, has led to a number of research efforts over the last few years. However, several challenges remain due to the inherent complexity of the problem. This paper specifically concentrates on the comprehensive analysis of energy-efficient multi-radio networking for pervasive computing. Building upon the service oriented architectural style, we consider pervasive networks of software services, which are deployed on the various networked nodes. The issue is then to optimize the energetic performance of the pervasive network through careful selection of the radio link over which service access should be realized for each such access. By considering the most common wireless interfaces in use today (Bluetooth, WiFi and GPRS), we introduce a formal model of service-oriented multi-radio networks. The proposed model enables characterizing the optimal network configuration in terms of energetic performance, which is shown to be a NP-hard problem and thus requires adequate approximation.	approximation;bluetooth;np-hardness;pervasive informatics;service-oriented device architecture;ubiquitous computing	Mauro Caporuscio;Damien Charlet;Valérie Issarny;Alfredo Navarra	2007		10.1145/1216993.1217002	multi-frequency network;service set;wi-fi;real-time computing;wireless wan;heterogeneous network;wireless site survey;computer science;radio resource management;operating system;wireless network;service-oriented architecture;np-hard;database;distributed computing;municipal wireless network;ubiquitous computing;computer network;umts terrestrial radio access network	Mobile	-13.581830263210179	87.36000963906928	15261
26da93c4cce91faa322de9f7dd11960575d00da5	a formula that generates hash collisions		We present an explicit formula that produces hash collisions for the Merkle-Damg̊ard construction. The formula works for arbitrary choice of message block and irrespective of the standardized constants used in hash functions, although some padding schemes may cause the formula to fail. This formula bears no obvious practical implications because at least one of any pair of colliding messages will have length double exponential in the security parameter. However, due to ambiguity in existing definitions of collision resistance, this formula arguably breaks the collision resistance of some hash functions.	adversary (cryptography);collision (computer science);collision attack;collision resistance;hash function;md5;one-way compression function;polynomial;sha-1;sha-2;security parameter;time complexity;eric	Andrew Brockmann	2018	CoRR		theoretical computer science;collision;collision resistance;discrete mathematics;hash function;security parameter;padding;ambiguity;computer science;double exponential function	Crypto	-37.314386578943626	77.75286776240033	15269
1ddd769e031572a8a1e2b030f0d0e39086753057	performance optimization of multicast content delivery in a mobile environment based on pmipv6	multicast communication;multicast communication ip networks mobile computing;handover delay;ip multicast;handover delay ip multicast multicast mobility multicast context transfer explicit tracking tuning the behavior of mld pmipv6 testbed ns 3;ns 3;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;tuning the behavior of mld;pmipv6 testbed;multicast context transfer;ip networks;multicast mobility;multicast content delivery group multicast mobility multicast signaling routers igmp mld nonroute optimization tunnel overhead handover latency mld proxy functions mag lma multicast routing functions proxy mobile ipv6 multicast listener mobility pmipv6;context handover wireless communication unified modeling language delays simulation;mobile computing;explicit tracking	Recently, a base solution has been adopted for supporting multicast listener mobility in Proxy Mobile IPv6 (PMIPv6). This solution brings multicast listener support into PMIPv6 by placing multicast routing functions at LMA while MAGs provide MLD proxy functions. Nevertheless, it does not address specific optimizations and performances issues such as handover latency, tunnel overhead, non-route optimization, etc. Specially, this paper focuses on handover performance in terms of service disruption time. The theoretical and simulation results show that through the utilization of multicast context transfer the service disruption time can be reduced significantly. By tuning the behavior of the IGMP/MLD for routers, we can also achieve a similar result, but make a dramatically increasing multicast-signaling. Thus, the impact of multicast-related signaling on the wireless link is studied to suggest the maximum number of listeners supported by one MAG. An enhanced multicast context transfer function is also proposed for group multicast mobility to reduce the number of signaling messages.	denial-of-service attack;digital distribution;mathematical optimization;multicast;overhead (computing);performance;performance evaluation;proxy mobile ipv6;routing;simulation;terms of service;testbed;transfer function	Tien-Thinh Nguyen;Christian Bonnet	2013	2013 IEEE Wireless Communications and Networking Conference (WCNC)	10.1109/WCNC.2013.6554743	real-time computing;multicast;ip multicast;inter-domain;reliable multicast;telecommunications;protocol independent multicast;computer science;operating system;pragmatic general multicast;internet group management protocol;distance vector multicast routing protocol;source-specific multicast;multimedia broadcast multicast service;mobile computing;xcast;computer network;multicast address	Mobile	-7.993210829649698	91.75364990875497	15283
9bc0e80b2bdad96c98cf923ff9141057ec873e28	a brief review of the state of the art in operational research in telecommunications	consultants;or;case studies;operations research;journal;operational research practice;application of operational research;operational research;practitioners;management;or society;management science;or insight	Nowadays operational research (OR) claims to be known as the science of better by the scientific community and by the industry. OR provides a set of techniques and tools for thinking, analysing and solving, which leads to taking decisions in a structured and focused way towards efficiency and optimality. Due to these aspects, the advance of telecommunications research has been strongly linked to operations research since its birth. With this paper we want to acknowledge the serious research carried out in telecommunications from operations research and to encourage an ongoing telecommunications research from an OR perspective and linked to real practice. A classification of the state of the art Currently, there is a wide range of research possibilities in telecommunications that can be classified according to the type of telecommunications network. For example, wirebased telecommunication systems (including interurban networks, or urban networks among others), wireless and mobile communications, satellite-based communication, etc. Other possible classification is according to the stage of operation state. For example, the planning stage that is sometimes called topological design, or the real time operation stage including traffic demand dynamic routing, communication admission control, and bandwidth allocation among other typical problems. Although topological design has been the most traditional problem in the OR community, other problems like dynamic routing or bandwidth allocation are gaining support in certain specialized research groups. Table 1 shows a list of references that can be used as a quick access guide to each addressed	communications satellite;network planning and design;operations research;routing;telecommunications network	Pablo Cortés;Jesús Muñuzuri	2008	OR Insight	10.1057/ori.2008.59	computer science;behavioral operations research;management science;management;operations research	Metrics	-20.51058698770404	94.16442776049766	15300
5fc9b11bfd1c57c733f4175e20676de410494589	compact zero-knowledge proofs of small hamming weight		We introduce a new technique that allows to give a zeroknowledge proof that a committed vector has Hamming weight bounded by a given constant. The proof has unconditional soundness and is very compact: It has size independent of the length of the committed string, and for large fields, it has size corresponding to a constant number of commitments. We show five applications of the technique that play on a common theme, namely that our proof allows us to get malicious security at small overhead compared to semi-honest security: 1) actively secure k-out-of-n OT from black-box use of 1-out-of-2 OT, 2) separable accountable ring signatures, 3) more efficient preprocessing for the TinyTable secure two-party computation protocol, 4) mixing with public verifiability, and 5) PIR with security against a malicious client.	antivirus software;black box;formal verification;hamming weight;overhead (computing);preprocessor;secure two-party computation;semiconductor industry;window function	Ivan Damgård;Ji Luo;Sabine Oechsner;Peter Scholl;Mark Simkin	2017		10.1007/978-3-319-76581-5_18	theoretical computer science;discrete mathematics;ring signature;computation;computer science;bounded function;preprocessor;soundness;separable space;hamming weight;zero-knowledge proof	Crypto	-38.66908395250691	76.5515994379211	15302
4489b1cf50afc4ca67de9898025c2b366c0cc998	efficient planning tool for wdm transport networks	efficient planning tool;wdm transport networks	Last generation optical components jointly with WDM techniques will allow the realisation of a switched optical layer based on wavelength routing of semi-permanent paths. This paper presents a computer-aided planning tool intended to cover the dimensioning, routing, and wavelength assignment in meshed networks with WDM optical cross-connects. An efficient graph­ colouring algorithm allows a fast wavelength assignment even for topologies with a large number of nodes. The performances of the planning tool are illustrated on a 8-nodes European optical network.	wavelength-division multiplexing	C. Bungarzeanu;L. Besuchet;Daniel Rodellar	2000			telecommunications;computer science;distributed computing	Robotics	-8.655019769952618	86.12790757106434	15315
bd9604354337eea2bfda69529ce6c0069d8ac490	sensor network integration by means of a virtual private network protocol	virtual networks;sensor networks;smart objects;network integration	Sensor networks are becoming an essential part of smart environments. However, most previous systems rely on ad-hoc mechanisms to access the sensor network from the enterprise information system. We propose the use of object oriented middlewares to provide a Virtual Private Network in which all involved elements (sensor nodes or computer applications) will able to communicate as if they all were in a single uniform network.		David Villa;Francisco Moya;Felix Jesús Villanueva;Óscar Aceña;Juan Carlos López	2012		10.1007/978-3-642-35377-2_12	sensor web;enterprise private network;intelligent computer network;overlay network;network architecture;wireless sensor network;network management station;computer science;network simulation;distributed computing;key distribution in wireless sensor networks;mobile wireless sensor network;computer security;computer network;visual sensor network	DB	-20.383243945431452	81.84617528179338	15330
ca32cd006de3a6f0b5de0f337911d1a1e8a92133	jamming-resistant communication: channel surfing without negotiation	random channel states;protocols;channel surfing;bismuth;state observer;jamming;negotiation process;wireless communication;spread spectrum communication;wireless communications;jamming resistant communication;indoor environment;telecommunication security;fading channel;off the shelf 802 11 devices;wireless fading channel;channel switching sequence;jamming wireless communication transceivers communication switching fading wireless networks costs communications society computer science communication system security;jamming attacks prevention;transceivers;radiocommunication;correlation;off the shelf 802 11 devices jamming resistant communication channel surfing jamming attacks prevention wireless communications channel switching sequence negotiation process wireless fading channel random channel states security;communication channels;fading channels;telecommunication security fading channels jamming radiocommunication;security;off the shelf	Channel surfing is an effective method to prevent jamming attacks in wireless communications. In traditional channel surfing schemes, two parties have to negotiate beforehand, in order to agree on the channel switching sequence. However, the negotiation process itself is vulnerable to jamming attacks. In this paper, we propose a novel channel surfing method without relying on such negotiation. Taking advantage of the reciprocity of the wireless fading channel, our method switches channels according to the random channel states observed by the two parties during their communication. Therefore, it does not introduce any extra communication overhead and can achieve strong security. To evaluate our method, we carry out extensive experiments using off-the-shelf 802.11 devices in a real indoor environment. Experimental results validate the efficiency and security of our method.	effective method;experiment;network switch;overhead (computing);radio jamming;shared secret;testbed	Shaxun Chen;Kai Zeng;Prasant Mohapatra	2010	2010 IEEE International Conference on Communications	10.1109/ICC.2010.5502311	telecommunications;computer science;information security;computer security;wireless;computer network	Robotics	-50.889289814261815	74.3526722345534	15345
e021b606d742246bacb53b955ae9756b8a098c17	countermeasures for covert channel-internal control protocols	micro protocols;overlay routing;smart covert channel tool covert channel internal control protocols hidden information microprotocol network covert channels reliable data transfer session management dynamic routing adaptive communication channel stealthy communication channel malware communication channel bot nets communication channel ping tunnel;icmp tunneling;active warden;network security;information hiding;telecommunication channels computer network security invasive software protocols;covert channels;steganography;passive warden;passive warden covert channels micro protocols steganography information hiding network security icmp tunneling overlay routing active warden;protocols payloads routing overlay networks communication channels reliability timing	Network covert channels have become a sophisticated means for transferring hidden information over the network, and thereby breaking the security policy of a system. Covert channel-internal control protocols, called micro protocols, have been introduced in the recent years to enhance capabilities of network covert channels. Micro protocols are usually placed within the hidden bits of a covert channel's payload and enable features such as reliable data transfer, session management, and dynamic routing for network covert channels. These features provide adaptive and stealthy communication channels for malware, especially bot nets. Although many techniques are available to counter network covert channels, these techniques are insufficient for countering micro protocols. In this paper, we present the first work to categorize and implement possible countermeasures for micro protocols that can ultimately break sophisticated covert channel communication. The key aspect of proposing these countermeasures is based on the interaction with the micro protocol. We implemented the countermeasures for two micro protocol-based tools: Ping Tunnel and Smart Covert Channel Tool. The results show that our techniques are able to counter micro protocols in an effective manner compared to current mechanisms, which do not target micro protocol-specific behavior.	botnet;categorization;communications protocol;countermeasure (computer);covert channel;http tunnel;icmp tunnel;malware;routing;session (computer science)	Jaspreet Kaur;Steffen Wendzel;Michael Meier	2015	2015 10th International Conference on Availability, Reliability and Security	10.1109/ARES.2015.88	covert channel;computer science;internet privacy;computer security;computer network	Security	-58.67737740887562	66.87375926004606	15358
3a4cd034bf6c27a13a44136d12c3f6de3051d62d	a key management scheme for secure communications of advanced metering infrastructure in smart grid	cryptographic algorithms key management scheme secure communications advanced metering infrastructure smart grid cyber security smart meters demand response projects;power system measurement;smart power grids;power system management;cryptography;unicast encryption smart grids authentication;transmission mode advanced metering infrastructure ami key management scheme kms smart grid;smart power grids cryptography power system management power system measurement smart meters;smart meters	Advanced metering infrastructure (AMI) is an important component of the smart grid. The cyber security should be considered prior to the AMI system applications. To ensure confidentiality and integrality, a key management scheme (KMS) for a large amount of smart meters (SMs) and devices is required, which is not a properly solved problem until now. Compared with other systems, there are three specific features of AMI that should be carefully considered, including hybrid transmission modes of messages, storage and computation constraints of SMs, and unfixed participators in demand response (DR) projects. In order to deal with security requirements and considering the distinctive features, a novel KMS is proposed. First, the key management framework of an AMI system is constructed based on the key graph. Furthermore, three different key management processes are designed to deal with the hybrid transmission modes, including key management for unicast, broadcast, and multicast modes. Relatively simple cryptographic algorithms are chosen for key generation and refreshing policies due to the storage and computation constraints of SMs. Specific key refreshing policies are designed since the participators in a certain DR project are not fixed. Finally, the security and performance of the KMS are analyzed. According to the results, the proposed scheme is a possible solution for AMI systems.	key management;smart meter	Nian Liu;Jinshan Chen;Lin Zhu;Jianhua Zhang;Yanling He	2013	IEEE Trans. Industrial Electronics	10.1109/TIE.2012.2216237	embedded system;engineering;cryptography;mathematics;distributed computing;smart grid;computer security;statistics	Embedded	-48.67071503034781	79.0616321418924	15389
7f905d8b0f1d5974460ec39faaa16dbf50592b89	binary hash tree based certificate access management for connected vehicles		We present a certificate access management system to support the USDOT's proposed rule on Vehicle-to-Vehicle (V2V) communications, Federal Motor Vehicle Safety Standard (FMVSS) No. 150. Our proposal, which we call Binary Hash Tree based Certificate Access Management (BCAM) eliminates the need for vehicles to have bidirectional connectivity with the Security Credential Management System (SCMS) for certificate update. BCAM significantly improves the ability of the SCMS to manage large-scale software and/or hardware compromise events. Vehicles are provisioned at the start of their lifetime with all the certificates they will need. However, certificates and corresponding private key reconstruction values are provided to the vehicle encrypted, and the keys to decrypt them are only made available to the vehicles shortly before the start of the validity periods of those certificates. Vehicles that are compromised can be effectively removed from the V2V system by preventing them from decrypting the certificates. We demonstrate that the system is feasible with a broadcast channel for decryption keys and other revocation information, even if that channel has a relatively low capacity.  Reproducibility VM download link: https://drive.google.com/open?id=0B4ozf__jZFRs7VmhqampHczhBTkU	credential;download;emoticon;encryption;entity;management system;merkle tree;provisioning;public-key cryptography;scalability;security management;symmetric multiprocessing;vehicle-to-vehicle	Virendra Kumar;Jonathan Petit;William Whyte	2017		10.1145/3098243.3098257	computer security;revocation list;public key certificate;certificate;computer network;certificate authority;computer science;x.509;public-key cryptography;hash tree;root certificate	Security	-45.35875530216526	68.1302411831855	15390
d8f15ebdaded7fdd3db5cae321ba00f9e6eecd3f	sla based dynamic provisioning of cloud resource in oltp systems		In the era of cloud computing, an increasing amount of services are moving online. Also increasing is the amount of cloud resource to power these services. Among these modern online transactions, many belong to the category of Online Transaction Processing (OLTP), which can be processed with predictable time and resource. However, with a large user base and fluctuated usage patterns, providing OLTP services efficiently remains a major challenge. In this paper we present an online algorithm that solves for a cost-minimizing provision scheme under fluctuated user requests, constrained by a tail-distribution-based Service Level Agreement (SLA), and incorporated with Neural Network prediction. Experiment shows that the algorithm delivers significant savings in provision, and outperforms a simple look-forward provision plan with the same SLA compliance.	online transaction processing;provisioning;service-level agreement	Xiaoqiu Qiu;Markus Hedwig;Dirk Neumann	2011		10.1007/978-3-642-29873-8_28	real-time computing;world wide web;computer network	HPC	-23.36912123683142	62.16740448105337	15411
29674d7bce9259a87d88f33409b737722da25141	dynamic session key based pairwise key management scheme for wireless sensor networks			key management;session key	B Premamayudu;K. Venkata Rao;P. Suresh Varma	2016	TIIS	10.3837/tiis.2016.12.024	key management;wireless sensor network;distributed computing;computer network;computer science;session key;pairwise comparison;key distribution in wireless sensor networks	Mobile	-49.41381534181991	77.26060187956693	15417
5efbdf5ceaa120d084cb8d3bf9d892623d5a6039	radar: adaptive rate allocation in distributed stream processing systems under bursty workloads	resource allocation distributed processing middleware quality of service;resource allocation;distributed processing;distributed stream processing systems;qos;rate allocation;bursty workloads;middleware;bursty workloads qos distributed stream processing systems rate allocation;quality of service;resource overhead adaptive rate allocation distributed stream processing system bursty workload road traffic control financial feeds processing network monitoring realtime sensor data analysis qos requirement quality of service end to end execution time rate demand qos constraint synergy middleware;optimization throughput radar applications resource management equations mathematical model	In the recent years we have witnessed a proliferation of distributed stream processing systems that need to operate under bursty workloads. Examples include road traffic control, processing of financial feeds, network monitoring and real-time sensor data analysis systems. Meeting the QoS requirements of the stream processing systems under burstiness is a challenging process. In this paper we present our approach for adaptive rate allocation within the distributed stream processing system to meet the end-to-end execution time and rate demands of the applications. Our algorithm determines the rates of the application components at runtime, with respect to the QoS constraints, to compensate for delays experienced by the components or to react to sudden bursts of load. Our technique is distributed and low-cost. Our detailed experimental results over our Synergy middleware illustrate that our approach is practical, depicts good performance and has low resource overhead.	algorithm;component-based software engineering;end-to-end principle;middleware;overhead (computing);quality of service;radar;real-time clock;real-time operating system;requirement;run time (program lifecycle phase);stream processing;synergy	Ioannis Boutsis;Vana Kalogeraki	2012	2012 IEEE 31st Symposium on Reliable Distributed Systems	10.1109/SRDS.2012.55	real-time computing;quality of service;computer science;operating system;distributed computing;computer network	Embedded	-26.668387288684983	62.16443246810403	15469
57a30725f6afd5047bcf277fd796ebcfe8724a0a	contribution to intelligent environment's security	home computing;security of data;home automation	Home automation is vulnerable in terms of security and confidentiality of data, something that must be addressed in a coherent manner. Although traditional security requirements remain the same, this new approach to computing represents additional challenges. In this paper, the goal is to develop an open services home gateway based security architecture for the home network including PKC. This contribution focuses on the security of home network components and the communications between them.	authorization;certificate authority;coherence (physics);computer security;confidentiality;cryptography;effective method;encryption;entity;home automation;intelligent environment;interaction;pkc (conference);requirement;usability;zero-knowledge proof	Othmane Mahmoudi;Abdelkader Belkhir	2013	2013 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2013.6637468	software security assurance;computer security model;cloud computing security;home automation;security through obscurity;security information and event management;security engineering;security convergence;covert channel;asset;computer science;engineering;information security;logical security;communications security;control theory;human-computer interaction in information security;security service;internet privacy;security testing;network access control;network security policy;world wide web;computer security	EDA	-48.31328807360303	61.29492372181199	15481
406add02e885dde494c8d181c90eab0e9b3d496c	public key cryptosystems based on chaotic-chebyshev polynomials	public key cryptography;chebyshev map;public key cryptosystems;chaos;chebyshev map chaos public key hash;digital signatures;public key encryption;cryptographic techniques;polynomials;hash;cryptanalysis;public key;chaotic chebyshev polynomials;pixel;public key cryptography chaos digital signatures polynomials;robustness;public key cryptography chaos polynomials public key chaotic communication chebyshev approximation security videos educational institutions communications technology;correlation;cryptanalysis public key cryptosystems chaotic chebyshev polynomials cryptographic techniques public key encryption;videos	Due to rapid developments in limits and possibilities of communications and information transmissions, there is a growing demand of cryptographic techniques, which has spurred a great deal of intensive research activities in the study of cryptography. This paper describes a public key encryption based on chebyshev polynomials [1].We discuss the algorithm for textual data and present the cryptanalysis which can be performed on this algorithm for the recovery of encrypted data [2]. We also describe a simple hashing algorithm for making this algorithm more secure, and which can also be used for digital signature [3]. The main scope of this paper is to propose an extension of this algorithm to images and videos and making it secure using multilevel scrambling and hash. Software implementations and experimental results are also discussed in detail.	algorithm;chebyshev polynomials;cryptanalysis;cryptosystem;digital signature;encryption;exclusive or;hash function;polynomial;public-key cryptography;text corpus	Gnanajeyaraman Rajaram;K. Ramar;Prasadh K. K. Pillai	2009	2009 International Conference on Intelligent Agent & Multi-Agent Systems	10.1109/ARTCom.2009.64	computer science;theoretical computer science;mathematics;internet privacy;public-key cryptography;computer security	Crypto	-41.24066869789146	80.77646587685467	15537
69a939d81538be5fda40e3e4a75e3487d51e3c91	rate control of elastic traffic with qos guarantees: a stability analysis &amp; experimental implementation	virtual networks;optimisation;programmable network environment;theoretical model;service provider;dynamic systems theory;elastic service;qos guarantee;telecommunication congestion control;time varying systems;tcp;traffic control;best effort;experimental implementation;source rate control;computer networks;stability;stability analysis quality of service ip networks web and internet services;transport protocols;rate control;telecommunication traffic;programmable network environment elastic traffic rate control qos guarantees stability analysis experimental implementation dynamical systems theory source rate control packet networks nonlinear optimization techniques tcp elastic service provider guaranteed minimum rate provider edge devices virtual network provider;virtual network operator;guaranteed minimum rate;qos guarantees;elastic traffic rate control;stability analysis;dynamical systems theory;virtual network provider;packet networks;provider edge devices;transport protocols computer networks optimisation quality of service stability telecommunication congestion control telecommunication traffic time varying systems;quality of service;elastic traffic;elastic service provider;nonlinear optimization;programmable networks;virtual network operator elastic service nonlinear optimization quality of service progranunable networks;nonlinear optimization techniques;progranunable networks	A dynamical systems theory of source rate control in packet networks, based on nonlinear optimization techniques, has been developed recently and applied to improving the performance of TCP and similar algorithms. However this research has been conducted within the best effort context. In this paper we consider a different context, that of a service provider offering an elastic service with a guaranteed minimum rate and applying rate control at the provider edge devices. We apply the basic theoretical model to the simple case of a single node with multiple sources and provide an analytical characterization of the stability requirements. An experimental implementation is described which attempts to capture the essential traffic control features of a future virtual network provider operating in a programmable network environment	algorithm;ampersand;best-effort delivery;dynamical systems theory;mathematical optimization;nonlinear programming;nonlinear system;provider edge;quality of service;requirement	Glynn Rogers;Jonathan Chan;Darwin Agahari	2006	2006 IEEE/IFIP Network Operations and Management Symposium NOMS 2006	10.1109/NOMS.2006.1687668	dynamical systems theory;real-time computing;nonlinear programming;computer science;distributed computing;computer network	Embedded	-5.592868070396276	95.43690533675922	15555
c692219eeb545b7b9012ce67279369fa8e21fca7	securecmerge: secure pdf merging over untrusted servers		Merging two or more PDF files is an operation that is commonly performed by users, most often using freely available online tools, such as pdfmerge, or cloud-based services, such as cloudconvert. These free online servers cannot always be trusted and can often pose great risk to the confidentiality of the PDF files. In this paper, we present a method, called SecureCMerge, to merge the PDF files using free online merge sites in a secure way. Our core idea is to encrypt the content (text and image blocks) in the PDF files using Shamir's Secret Sharing (SSS) scheme before uploading it to a PDF merge server. We also show that the SSS scheme is merge homomorphic and the proposed method, by virtue of using the SSS scheme, provides information theoretic security. Experimental results demonstrate that the proposed method accomplishes secure PDF merging at an acceptable overhead in computation time and size.	cloud computing;computation;confidentiality;encryption;information-theoretic security;linkage (software);overhead (computing);portable document format;server (computing);shamir's secret sharing;theory;thread (computing);time complexity;upload;web service	Neha Sharma;Priyanka Singh;Pradeep K. Atrey	2018	2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)	10.1109/MIPR.2018.00087	information-theoretic security;computation;encryption;cloud computing;sss*;secret sharing;distributed computing;server;computer science;upload	DB	-41.735895288929406	68.41975815324044	15556
a8fd73136cf7489fcb7c3ffde2a3f4051d837252	exploiting traffic localities for efficient flow state lookup	hachage;ecoulement trafic;distributed system;systeme reparti;overflow computer arithmetics;localite;packet classification;mesa;gestion red;network security;gestion trafic;securite informatique;locality;traffic flow;packet switching;traffic management;conmutacion por paquete;computer security;hashing;sistema repartido;hash table;seguridad informatica;gestion reseau;table;rebasamiento capacidad;gestion trafico;depassement capacite;network management;flujo trafico;commutation paquet	Flow state tables are an essential component for improving the performance of packet classification in network security and traffic management. Generally, a hash table is used to store the state of each flow due to its fast lookup speed. However, hash table collisions can severely reduce the effectiveness of packet classification using a flow state table. In this paper, we propose three schemes to reduce hash collisions by exploiting the locality in traffic. Our experiments show that all our proposed schemes perform better than the standard practice of hashing with overflow chains. More importantly, our move and insert to front scheme is insensitive to the hash table size.	collision (computer science);cryptographic hash function;experiment;hash chain;hash table;linked list;locality of reference;lookup table;markov chain;move-to-front transform;network packet;network security;real life;state transition table;tracing (software)	Tao Peng;Christopher Leckie;Kotagiri Ramamohanarao	2005		10.1007/11422778_91	feature hashing;network management;hopscotch hashing;hash table;double hashing;active traffic management;hash function;linear hashing;perfect hash function;dynamic perfect hashing;rainbow table;primary clustering;quadratic probing;telecommunications;computer science;consistent hashing;network security;operating system;table;traffic flow;distributed computing;cuckoo hashing;rolling hash;coalesced hashing;programming language;computer security;2-choice hashing;packet switching;cryptographic hash function;computer network;hash tree;hat-trie	Networks	-4.674103839002963	73.73700349644537	15577
634be77d972150f8a3be16db05afa166349540e3	poly-many hardcore bits for any one-way function and a framework for differing-inputs obfuscation		We show how to extract an arbitrary polynomial number of simultaneously hardcore bits from any oneway function. In the case the one-way function is injective or has polynomially-bounded pre-image size, we assume the existence of indistinguishability obfuscation (iO). In the general case, we assume the existence of differing-input obfuscation (diO), but of a form weaker than full auxiliary-input diO. Our construction for injective one-way functions extends to extract hardcore bits on multiple, correlated inputs, yielding new D-PKE schemes. Of independent interest is a definitional framework for differing-inputs obfuscation in which security is parameterized by circuit-sampler classes. 1 Department of Computer Science & Engineering, University of California San Diego, 9500 Gilman Drive, La Jolla, California 92093, USA. Email: mihir@eng.ucsd.edu. URL: http://cseweb.ucsd.edu/~mihir/. Supported in part by NSF grants CNS-1116800 and CNS-1228890. Department of Computer Science & Engineering, University of California San Diego, 9500 Gilman Drive, La Jolla, California 92093, USA. Email: istepano@eng.ucsd.edu. Supported in part by NSF grants CNS-1116800 and CNS-1228890. 3 Department of Computer Science, University of California Santa Barbara, Santa Barbara, California 93106, USA. Email: tessaro@cs.ucsb.edu. URL: http://www.cs.ucsb.edu/~tessaro/. Supported in part by NSF grant CNS-1423566.	ciphertext indistinguishability;computer science;definition;email;geforce 9 series;ibm notes;image resolution;jolla;obfuscation (software);one-way function;polynomial;sampling (signal processing)	Mihir Bellare;Stefano Tessaro	2013	IACR Cryptology ePrint Archive	10.1007/978-3-662-45608-8_6	discrete mathematics;theoretical computer science;mathematics;algorithm	Crypto	-35.09761874744133	76.81046176895198	15590
aa3e3eb956b2d590415f167da1def3c3e9452260	packet marking with distance based probabilities for ip traceback	topology;inet framework probabilistic packet marking distance based probability ip traceback ddos attack ip spoofing omnet;ddos attack;probability;computer network security;network security;distributed processing;ddos attacks;false negative;computer crime;ip spoofing;data mining;network topology;large scale;evaluation metric;distance based probability;ip traceback;inet framework;performance analysis;defense mechanism;ip networks;packet marking;probabilistic logic;false positive;probability computer network security distributed processing ip networks;computer crime government computer networks internet sampling methods computational modeling analytical models performance evaluation performance analysis robustness;simulation model;probabilistic packet marking;object oriented modeling;omnet;network security ip traceback probabilistic packet marking ddos attacks	IP traceback is one of the most important parts of the defense mechanism against DDoS attacks that widely use IP spoofing. Probabilistic Packet Marking (PPM) approach, in which routers probabilistically mark packets they transmit, seems to be a promising solution to perform an efficient IP traceback. In this work, we propose a new scheme that uses node sampling and routers mark packets with distance based probabilities. Also, a simulation model is constructed in order to evaluate and compare the performance of different PPM approaches objectively. Our simulation model is based on OMNET++ and INET Framework and can perform analysis by using evaluation metrics such as minimum number of packets required, robustness against spoofed packets, number of false positives and false negatives under large-scale DDoS attacks.	denial-of-service attack;ip address spoofing;ip traceback;item unique identification;network packet;performance;sampling (signal processing);simulation;traverse	Turker Akyuz;Ibrahim Sogukpinar	2009	2009 First International Conference on Networks & Communications	10.1109/NetCoM.2009.45	computer science;ip address spoofing;network security;internet privacy;computer security;denial-of-service attack;computer network	Metrics	-59.22205651064609	70.52614445476253	15615
8dcd3bf5eaf7a078e6be2f541b08231db2ba8251	zero-knowledge realization of software-defined gateway in fog computing				Te-Yuan Lin;Chiou-Shann Fuh	2018	TIIS	10.3837/tiis.2018.12.003		HPC	-17.7338666864337	86.62188405754367	15644
380645605e14aa824bdbd50bab86566def7221d1	going viral: flash crowds in an open cdn	content distribution network;peer to peer network;distributed networks;web service;social network;large scale;content distribution networks;open content;web caching;flash crowds	Handling flash crowds poses a difficult task for web services. Content distribution networks (CDNs), hierarchical web caches, and peer-to-peer networks have all been proposed as mechanisms for mitigating the effects of these sudden spikes in traffic to under-provisioned origin sites. Other than a few anecdotal examples of isolated events to a single server, however, no large-scale analysis of flash-crowd behavior has been published to date.  In this paper, we characterize and quantify the behavior of thousands of flash crowds on CoralCDN, an open content distribution network running at several hundred POPs. Our analysis considers over four years of CDN traffic, comprising more than 33 billion HTTP requests. We draw conclusions in several areas, including (i) the potential benefits of cooperative vs. independent caching by CDN nodes, (ii) the efficacy of elastic redirection and resource provisioning, and (iii) the ecosystem of portals, aggregators, and social networks that drive traffic to third-party websites.	cache (computing);content delivery network;digital distribution;ecosystem;news aggregator;open content;peer-to-peer;portals;provisioning;server (computing);slashdot effect;social network;web cache;web service	Patrick Wendell;Michael J. Freedman	2011		10.1145/2068816.2068867	web service;open content;computer science;multimedia;internet privacy;world wide web;computer security;computer network;social network	Metrics	-16.99239472317116	76.06427638190596	15666
e7f0154297a4ed7dab7dfa0e775253a8cebccf3c	developing a concept for handling it security with secured and trusted electronic connections	thesis or dissertation;german health card;it security;ocsp online certificate status protocol;web server attack;unicode bug;crl certificate revocation list			Volker Hockmann	2014			scvp;self-signed certificate;computer science;revocation list;certificate server;ocsp stapling;public key certificate;internet privacy;root certificate;online certificate status protocol;world wide web;computer security;certificate authority	Crypto	-48.1070696072959	63.156837500539076	15708
813e712e5a0f533c925be79b580e00e7ed23573e	on matsui's linear cryptanalysis	linear cryptanalysis;differential cryptanalysis	to linear cryptanalysis. We also described how to sum up characteristics (which also hold in diierential cryptanalysis). The iteration of this characteristic to seven rounds have probability 1=2 ? 2 ?11. A similar characteristic exist with a reverse order of the bytes in each word. From the tables in 9] we can see that about 4 2 112 = 2 24 known plaintexts are required to attack Feal-8, with success rate about 78% and that 2 25 known plaintexts are required for success rate about 97%. This characteristic can be used to attack Feal-N with up to 20 rounds, with a complexity (and known plaintexts) smaller than of exhaustive search. The attack on Feal-8 was applied successfully on a personal computer. It takes about 10 minutes to encrypt the 2 24 required known plaintexts and to nd the key. 7 Summary In this paper we studied Matsui's linear cryptanalysis. We showed that the formalism of diierential cryptanalysis can be adopted to linear cryptanalysis. In particular, we showed that characteristics can be deened, concatenated, and used in a very similar manner as in diierential cryptanalysis. Constraints on the size of S boxes were described. Matsui's characteristic used to attack DES in his paper is shown to be the best characteristic which has only up to one active S box at each round; on the other hand, we improved his results on Feal. We attack Feal-8 using 2 24 known plaintexts with linear cryptanalysis. Davies' attack on DESS5] was shown to be closely related 15 found two ve-round characteristic with probability 1=2 + 1=32. One of them is:	brute-force search;byte;concatenation;davies' attack;encryption;iteration;known-plaintext attack;linear cryptanalysis;personal computer;plaintext;s-box;semantics (computer science)	Eli Biham	1994		10.1007/BFb0053449	integral cryptanalysis;differential cryptanalysis;differential-linear attack;piling-up lemma;xsl attack;computer science;boomerang attack;higher-order differential cryptanalysis;mathematics;impossible differential cryptanalysis;statistics;linear cryptanalysis	Crypto	-37.6924388832704	80.78628969508554	15712
1649b6091fda3b0b5f8458c71c1de32095da1a1d	routing worm: a fast, selective attack worm based on ip address information	spine;geographic information;routing;web and internet services;computer worms;telecommunication congestion control;telecommunication security invasive software ip networks internet telecommunication network routing telecommunication traffic telecommunication congestion control;routing computer worms web and internet services computer science spine computer security bandwidth conferences;internet service provider;ipv4 address information;autonomic system;sasser worm;scanning worm;computer security;blaster worm;telecommunication traffic;attack worm;internet;telecommunication network routing;slammer worm;routing worm;ipv6;telecommunication security;ipv6 routing worm attack worm ipv4 address information code red worm slammer worm blaster worm sasser worm bgp routing table internet mutable address space network congestion scanning worm;bandwidth;code red worm;invasive software;ip networks;computer science;bgp routing table;internet mutable address space;network congestion;conferences	"""Most well-known worms, such as Code Red, Slammer, Blaster, and Sasser, infected vulnerable computers by scanning the entire IPv4 address space. In this paper, we present an advanced worm called """"routing worm"""", which implements two advanced attacking techniques. First, a routing worm uses BGP routing tables to only scan the Internet routable address space, which allows it propagate three times faster than a traditional worm. Second, and more importantly, the geographic information of BGP routing prefixes enables a routing worm to conduct pinpoint """"selective attacks"""" by imposing heavy damage to vulnerable computers in a specific country, company, Internet Service Provider, or Autonomous System, without collateral damage done to others. Because of the inherent publicity of BGP routing tables, attackers can easily deploy routing worms, which distinguishes the routing worm from other """"worst-case"""" worms. Compared to a traditional worm, a routing worm could possibly cause more severe congestion to the Internet backbone since all scans sent out by a routing worm are Internet routable (and can only be dropped at the destinations). In addition, it is harder to quickly detect a routing-worm infected computer since we cannot distinguish illegal scans from regular connections without waiting for traffic responses. In order to defend against routing worms and all scanning worms, an effective way is to upgrade the current Internet from IPv4 to IPv6, although such an upgrade will require a tremendous effort and is still a controversial issue."""	address space;autonomous robot;autonomous system (internet);best, worst and average case;border gateway protocol;code red (computer worm);computer;internet backbone;link-state routing protocol;network congestion;routing table;sql slammer	Cliff Changchun Zou;Donald F. Towsley;Weibo Gong;Songlin Cai	2005	Workshop on Principles of Advanced and Distributed Simulation (PADS'05)	10.1109/PADS.2005.24	routing;static routing;the internet;spine;computer science;ipv6;internet privacy;routing protocol;network congestion;default-free zone;computer security;bandwidth;computer network;computer worm	Networks	-57.75790420293958	69.39054285995029	15749
e26329f3c2b3a17bc1cc792a76a67b090ff4b796	context-aware handoff on smartphones	mobility management mobile radio;electronic mail;measurement;bayes methods;smart phones;wireless lan bayes methods energy consumption mobility management mobile radio smart phones ubiquitous computing;energy consumption;ubiquitous computing;wireless lan;context smart phones context modeling switches measurement data models electronic mail;switches;context modeling;bayes classifier context aware handoff energy efficiency network switching user experience degradation application context model heuristic network selection mechanism network performance energy consumption crowd sourced data smartphone users profile android platform cellular network wifi network;context;data models	Nowadays smartphone users often enjoy the availability of multi-networks by switching between the networks for better network performance, energy efficiency of smartphones, and more data offloading to less expensive networks. However, network switching inevitably brings about network disruptions leading to user experience degradation. In this paper, we propose an application context model that is used in conjunction with a heuristic network selection mechanism, which selects a network using three metrics (i.e., network performance, energy consumption, and cost). A Bayes classifier is used to provide a probability for the network selection given applications running during network disruptions. We construct the classifier via crowd-sourced data by considering smartphone users profile and the operating environments. We implement a prototype context-aware handoff on the Android platform and conducted an experiment in a real world scenario through one case study, switching between cellular and WiFi networks. The evaluation results suggest that context aware handoff achieves 25% energy cost, nearly one-third data offloading, and more than twice throughput with only one third of the network switchings.	access network;android;cluster analysis;context (computing);crowdsourcing;elegant degradation;heuristic;hierarchical clustering;naive bayes classifier;network performance;prototype;smartphone;throughput;user experience	Qiang Li;Qi Han;Limin Sun	2013	2013 IEEE 10th International Conference on Mobile Ad-Hoc and Sensor Systems	10.1109/MASS.2013.32	embedded system;data modeling;intelligent computer network;network architecture;network management station;network switch;computer science;operating system;network simulation;context model;computer security;ubiquitous computing;measurement;computer network	Mobile	-19.684052180205537	76.03089944651794	15778
4fe4ce0462ddd22ffc0f345167633923ff01dc77	evaluation of the adleman attack on multiply iterated knapsack cryptosystems		Early in 1982, A. Shamir [12] announced a polynomial time attack on the basic Merkle-Hellman knapsack cryptosystem. Since that time, attacks on various other knapsack cryptosystems have been proposed [1,2,4,6,7,11]. One of the most influential of the works in this area has been L. Adleman’s paper [1], which was the first to suggest the use of the Lenstra, Lenstra and Lovasz (L3) lattice basis reduction algorithm [9] in attacks on knapsack cryptosystems. The L3 algorithm is now the most important tool used in such attacks.		Ernest F. Brickell;Jeffrey C. Lagarias;Andrew M. Odlyzko	1983		10.1007/978-1-4684-4730-9_3	theoretical computer science;distributed computing;computer security	Crypto	-39.56693708211912	79.6375309397196	15779
afbd8f2d3d3207d2750ac995e476721e935358f5	normal and anomalous traffic flow pattern analysis for organizational networks		Traffic monitoring and analysis has become necessary to understand the nature of information flowing within an organization. This is particularly important due to the recent trend of increase in the percentage of anomalous traffic in the overall organizational traffic composition. In this work, we attempt to determine the typical characteristics seen in various organizational network traffic. We use simple flow analysis methods on different datasets which include normal and anomalous traffic. Results from such an analysis can play a vital role in problems ranging from feature selection for machine learning based models to help tune the rules of an intrusion detection system (IDS). Based on the analysis of number of flows, packet size, number of packets per flow, flow duration, and protocol composition present in each dataset, we present our findings in this work.	algorithm;computation;data-flow analysis;feature selection;internet protocol suite;intrusion detection system;machine learning;network packet;network traffic control;pattern recognition;protocol stack;san diego supercomputer center;traffic analysis	Safia Rahmat;Quamar Niyaz;Ahmad Y. Javaid;Weiqing Sun	2017	2017 IEEE 30th Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2017.7946652	control engineering;traffic generation model;real-time computing;data mining;computer science;traffic flow;feature selection;intrusion detection system;network packet;ranging	Metrics	-62.01432050760762	66.44609748515191	15794
e5be428d5faf677f6ade320f68e23b38cfbcc729	introducing tls-psk authentication for emv devices	smart card;protocols;banking;access control tls psk authentication emv devices online banking accounts phising threats two factor authentication tokens one time password chip authentication program tls psk protocol european mastercard and visa;tls psk authentication;smart cards authorisation banking;one time password;authorisation;web;smart card security emv tls web;phising threats;authentication;european mastercard and visa;tls psk protocol;classical mechanics;online banking accounts;phase shift keying;chip;authentication cryptography smart cards banking access control computer hacking microcontrollers cryptographic protocols security financial management;chip authentication program;servers;two factor authentication tokens;smart cards;cryptography;mutual authentication;web sites;tls;access control;emv devices;security;emv;credit cards	Access control to online banking accounts is a very critical topic for the always-on emerging society. In order to avoid phising threats resulting from classical mechanisms dealing with login and password tuples, the deployment of two-factor authentication tokens generating One Time Password (OTP) is recommended by many governmental organizations. A procedure based on EMV credit cards (the Chip Authentication Program) is proposed by several financial companies. However, due to passwords lifetime, OTP values may be collected by hackers via phishing attacks. In this paper we present a protocol that merges the CAP approach to the TLS-PSK protocol. As a consequence there is no need to collect OTP values, and phishing attacks don't work, because the mutual authentication between the card bearer and the WEB site is only performed via the SSL session.	access control;chip authentication program;high availability;java card;login;multi-factor authentication;mutual authentication;one-time password;online banking;phishing;pre-shared key;server (computing);software deployment;tls-psk;web server;world wide web	Pascal Urien	2010	2010 International Symposium on Collaborative Technologies and Systems	10.1109/CTS.2010.5478489	smart card;chip authentication program;computer science;information security;authentication protocol;multi-factor authentication;internet privacy;one-time password;world wide web;computer security	Security	-48.919109808509454	64.66844720048606	15795
141694651e3b90a8d553cc48ce6db567e8d41966	hypertext transfer protocol (http) client-initiated content-encoding		"""In HTTP, content codings allow for payload encodings such as for compression or integrity checks. In particular, the """"gzip"""" content coding is widely used for payload data sent in response messages. Content codings can be used in request messages as well; however, discoverability is not on par with response messages. This document extends the HTTP """"Accept-Encoding"""" header field for use in responses, to indicate the content codings that are supported in requests. Status of This Memo This is an Internet Standards Track document. This document is a product of the Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by the Internet Engineering Steering Group (IESG). Further information on Internet Standards is available in Section 2 of RFC 5741. Information about the current status of this document, any errata, and how to provide feedback on it may be obtained at http://www.rfc-editor.org/info/rfc7694. Copyright Notice Copyright © 2015 IETF Trust and the persons identified as the document authors. All rights reserved. This document is subject to BCP 78 and the IETF Trust's Legal Provisions Relating to IETF Documents (http://trustee.ietf.org/license-info) in effect on the date of publication of this document. Please review these documents carefully, as they describe your rights and restrictions with respect to this document. Code Components extracted from this document must include Simplified BSD License text as described in Section 4.e of the Trust Legal Provisions and are provided without warranty as described in the Simplified BSD License. 1 http://www.rfc-editor.org/info/rfc7694 2 http://trustee.ietf.org/license-info RFC 7694 HTTP CICE November 2015"""	bsd;bulk copy program;character encoding;discoverability;document;hypertext transfer protocol;netbsd gzip / freebsd gzip;payload (computing)	Julian F. Reschke	2015	RFC	10.17487/RFC7694	telecommunications;computer science;internet privacy;world wide web	Web+IR	-26.32714831846908	89.00075029790007	15800
096e4740ba467a4562454f84e9796faa20740a9c	a cryptographic solution to a game theoretic problem	bob;zero knowledge proof;game theory;building block;teoria juego;cryptographic protocol;strategie joueur;theorie jeu;nash equilibria;estrategia jugador;cheap talk;criptografia;cryptography;indexation;trusted third party;cryptographie;error probability;solution concept;strategic game;player strategy	Although Game Theory and Cryptography seem to have some simi lar scenarios in common, it is very rare to find instances where tools from one area are applied in the other. In this work we use cryptography to solve a game theoretic problem. The problem that we discus s ari es naturally in the game theory area of two-party strategic games. In these games there are two pl ayers. Each player decides on a “move” (according to some strategy), and then the players execute t he game, i.e. the two players make their moves simultaneously. Once these moves are played each play er receives a payoff, which depends on both moves. Each player only cares to maximize its payoff. In the game theory literature it was shown that higher payoff s can be achieved by the players if they use correlated strategies. This is enabled through the intr oduction of a trusted third party (a “mediator”), who assists the players in choosing their move. Though now th e property of the game being a two player game is lost. It is natural to ask whether a game can exist whic h would be a two player game yet maintain the high payoffs which the mediator aided strategy offered. We answer this question affirmatively. We extend the game by a dding an initial step in which the two players communicate and then they proceed to execute the gam as usual. For this extended game we can prove (informally speaking) the following: any corre lat d strategy for 2-player games can be achieved, provided that the players are computationally bo unded and can communicate before playing the game. We obtain an efficient solution to the above game-theoretic p roblem, by providing a cryptographic protocol to the followingCorrelated Element Selection problem. Both Alice and Bob know a list of pairs (a1; b1) : : : (an; bn) (possibly with repetitions), and they want to pick a randomindexi such that Alice learns onlyai and Bob learns onlybi. We believe that this problem has other applications, beyon d our application to game theory. Our solution is quite efficient: it has constant number of rounds, negligible error probability, and uses only very simple zero-knowledg proofs. The protocol that we describe in this work uses as a basic buil ding block “blindable encryption schemes” (such as ElGamal or Goldwasser-Micali). We note th at such schemes seem to be a very useful general primitive for constructing efficient protocols. As an example, we show a simple 1-out-of-n oblivious transfer protocol based on any such encryption sc heme.	alice and bob;call of duty: black ops;cryptographic protocol;cryptography;discus;encryption;game theory;generalized additive model;matchware mediator;oblivious transfer;trusted third party	Yevgeniy Dodis;Shai Halevi;Tal Rabin	2000		10.1007/3-540-44598-6_7	game theory;cheap talk;simulation;trusted third party;computer science;cryptography;artificial intelligence;cryptographic protocol;mathematics;computer security;solution concept;algorithm	Crypto	-38.28554095932349	73.92266639403981	15801
050a5ea48f68566399d351b0641d1c34aae382a1	visual correlation of host processes and network traffic	telecommunication security security of data data visualisation computer network management;leading indicator;system administration;usability study;telecommunication traffic data visualization computer security data security information security intrusion detection humans usability operating systems sockets;information visualization;computer security;data visualisation;network connectivity;network traffic;system administration visual correlation network traffic anomalous communication patterns computer system intrusion portall visualization network activity monitoring network eye framework computer security information visualization;computer network management;telecommunication security;security of data;communication pattern	Anomalous communication patterns are one of the leading indicators of computer system intrusions according to the system administrators we have interviewed. But a major problem is being able to correlate across the host/network boundary to see how network connections are related to running processes on a host. This paper introduces Portall, a visualization tool that gives system administrators a view of the communicating processes on the monitored machine correlated with the network activity in which the processes participate. Portall is a prototype of part of the Network Eye framework we have introduced in an earlier paper (Ball, et al., 2004). We discuss the Portall visualization, the supporting infrastructure it requires, and a formative usability study we conducted to obtain administrators' reactions to the tool.	computer;network traffic control;prototype;system administrator;usability testing	Glenn A. Fink;Paul Muessig;Chris North	2005	IEEE Workshop on Visualization for Computer Security, 2005. (VizSEC 05).	10.1109/VIZSEC.2005.18	computer security model;simulation;intelligent computer network;network architecture;information visualization;security information and event management;covert channel;computer science;logical security;network security;economic indicator;data mining;internet security;security service;network simulation;computer network programming;network access control;computer network operations;world wide web;computer security;data visualization;host based security system;computer network	Visualization	-62.13760309723255	62.542573798458164	15872
f63058480133f2940e164bdf7f23aea4a215c21a	a survey of data transfer and storage techniques in prevalent cryptocurrencies and suggested improvements		This thesis focuses on aspects related to the functioning of the gossip networks underlying three relatively popular cryptocurrencies: Ethereum, Nano and IOTA. rnWe look at topics such as automatic discovery of peers when a new node joins the network, bandwidth usage of a node, message passing protocols and storage schemas and optimizations for the shared ledger. We believe this is a topic that is often overlooked in works about blockchains and cryptocurrencies. Vulnerabilities and inefficiencies attain a higher significance than ones in a regular open source project because of the rather direct financial implications of these projects. Barring Bitcoin, a network that has been around for nearly 10 years, no other project has substantial documentation for its operational details other than scattered and sparse pages in the source code repositories. Almost all of the content described here has been extracted by studying the source code of the reference implementations of these projects. rnWe evaluate the use of Invertible Bloom Lookup Tables and the Graphene protocol to decrease block propagation times and bandwidth usage of certain messages. We perform realistic simulations that show significant improvements. We provide a complete implementation of Graphene in Geth, Ethereumu0027s main node software and test this implementation against the main Ethereum blockchain. rnWe also crawled the chosen cryptocurrency networks for publicly visible nodes and provide an Autonomous System-level breakdown of these nodes with the end goal of estimating the ease of performing attacks such as BGP hijacks and their impact. rnCode written for implementing Graphene in Geth, performing various simulations and for other miscellaneous tasks has been uploaded to Github at this https URL.	cryptocurrency;vii	Sunny Katkuri	2018	CoRR		message passing;documentation;implementation;source code;distributed computing;cryptocurrency;software;computer science;lookup table;upload	Crypto	-28.36943338269665	79.52980832639298	15873
6992d6afc5c93ca9b9fbce5cde498e71fba5d0c5	provably secure key assignment schemes from factoring	key assignment scheme;general poset;access control;provably secure;factoring	We provide constructions for key assignment schemes that are provably secure under the factoring assumption in the standard model. Our first construction is for simple “chain” hierarchies, and achieves security against key recovery attacks with a tight reduction from the problem of factoring integers of a special form. Our second construction applies for general hierarchies, achieves the stronger notion of key indistinguishability, and has security based on the hardness of factoring Blum integers. We compare our constructions to previous schemes, in terms of security and efficiency.	blum axioms;integer factorization;key escrow;provable security	Eduarda S. V. Freire;Kenneth G. Paterson	2011		10.1007/978-3-642-22497-3_19	factoring;discrete mathematics;computer science;access control;theoretical computer science;mathematics;distributed computing;computer security	Crypto	-39.02535113613745	76.71310751709363	15878
33a3f73fbb4ea54dec6e8832bb066e55414f45b8	how to generate and use universal samplers		The random oracle is an idealization that allows us to model a hash function as an oracle that will output a uniformly random string given any input. We introduce the notion of a universal sampler scheme that extends the notion of a random oracle, to a method of sampling securely from arbitrary distributions. We describe several applications that provide a natural motivation for this notion; these include generating the trusted parameters for many schemes from just a single trusted setup. We further demonstrate the versatility of universal samplers by showing how they give rise to simple constructions of identity-based encryption and multiparty key exchange. In particular, we construct adaptively secure non-interactive multiparty key exchange in the random oracle model based on indistinguishability obfuscation; obtaining the first known construction of adaptively secure NIKE without complexity leveraging. We give a solution that shows how to transform any random oracle into a universal sampler scheme, based on indistinguishability obfuscation. At the heart of our construction and proof is a new technique we call “delayed backdoor programming” that we believe will have other applications. ∗Supported by DFG grants GZ HO 4534/2-1 and GZ HO 4534/4-1. †Research supported in part from a DARPA/ONR PROCEED award, NSF grants 1228984, 1136174, 1118096, and 1065276, a Xerox Faculty Research Award, a Google Faculty Research Award, an equipment grant from Intel, and an Okawa Foundation Research Grant. This material is based upon work supported by the Defense Advanced Research Projects Agency through the U.S. Office of Naval Research under Contract N00014-11-1-0389. The views expressed are those of the author and do not reflect the official policy or position of the Department of Defense, the National Science Foundation, or the U.S. Government. ‡Supported by NSF CNS-0915361 and CNS-0952692, CNS-1228599 DARPA through the U.S. Office of Naval Research under Contract N00014-11-1-0382, Google Faculty Research award, the Alfred P. Sloan Fellowship, Microsoft Faculty Fellowship, and Packard Foundation Fellowship. §Supported by the DARPA PROCEED program. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of DARPA.	hash function;ibm notes;id-based encryption;interactivity;key exchange;netbsd gzip / freebsd gzip;random oracle;sampling (signal processing);universal quantification	Dennis Hofheinz;Tibor Jager;Dakshita Khurana;Amit Sahai;Brent Waters;Mark Zhandry	2016		10.1007/978-3-662-53890-6_24	theoretical computer science;discrete mathematics;idealization;oracle;encryption;random oracle;hash function;key exchange;backdoor;algorithm;computer science;obfuscation	Crypto	-35.40720371303701	76.67166880068383	15912
28e5747423d1117453ae53c2515046add0b9c242	cnoa: challenging number approach for uncovering tcp syn flooding using syn spoofing attack	ip spoofing;ddos attack	The challenging number is used for the detection of Spoofing attack. The IP Spoofing is considered to be one of the potentially brutal attack which acts as a tool for the DDoS attack which is considered to be a major threat among security problems in today’s internet. These kinds of attack are extremely severe. They bring down business of company drastically. DDoS attack can easily exhaust the computing and communication resources of its victim within a short period of time. There are attacks exploiting some vulnerability or implementation bug in the software implementation of a service to bring that down and some attacks will use all the available resources at the target machine. This deals on attacks that consume all the bandwidth available to the victim machine. While concentrating on the bandwidth attack the TCP SYN flood is the more prominent attack. TCP/IP protocol suite is the most widely used protocol suite for data communication. The TCP SYN flood works by exhausting the TCP connection queue of the host and thus denying legitimate connection request. There are various methods used to detect and prevent this attack, one of which is to block the packet based on SYN flag count from the same IP address. This kind of prevention methods becomes unsuitable when the attackers use the Spoofed IP address. The SYN spoofing becomes a major tool the TCP SYN flooding. For the prevention of this kind of attacks, the TCP specific probing is used in the proposed scheme where the client is requested challenging number while sending the ACK in the three way hand shake. This is very useful to find the Spoofed IP Packets/TCP SYN flood and preventing them.	acknowledgement (data networks);bandwidth (signal processing);computation;dfa minimization;denial-of-service attack;ip address spoofing;internet protocol suite;network packet;overhead (computing);packet switching;protocol stack;router (computing);syn flood;sensor;server (computing);software bug;spoofing attack;synergy;vulnerability (computing)	L. Kavisankar;C. Chellappan	2011	CoRR		land;pre-play attack;smurf attack;computer science;syn flood;ip address spoofing;internet privacy;spoofing attack;application layer ddos attack;tcp sequence prediction attack;computer security;denial-of-service attack;computer network	Security	-59.31031055993882	66.99752667579541	15929
1ac3d50831fa512b7eaf1ece29b60fba6c9f7a13	playback delay and buffering optimization in scalable video broadcasting	psnr performance;playback delay optimization;optimisation;scalable video;video streaming;psnr;decoding;video signal processing;buffering optimization;media scheduling playback delay optimization buffering optimization scalable video broadcasting video streaming common network resources server based scheduling strategy channel status polynomial time algorithm psnr performance quality of service qos common broadcast channel;scalable video broadcasting;buffer storage;lts4;qos;common broadcast channel;optimization problem;polynomial time algorithm;network servers;streaming media;broadcast channels;video servers delays scheduling optimisation buffer storage video streaming quality of service broadcast channels multimedia communication;scheduling;multimedia communication;common network resources;video servers;delay multimedia communication broadcasting streaming media quality of service scheduling decoding psnr network servers video signal processing;broadcasting;buffering;quality of service;channel status;media scheduling;playback delay;delays;server based scheduling strategy	The paper addresses the problem of optimizing the playback delay experienced by a population of heterogeneous clients in video streaming applications. We consider a typical broadcast scenario, where clients subscribe to different portions of a scalable video stream, depending on their capabilities. Clients share common network resources, whose limited rate directly drives the playback delays imposed on the different groups of receivers. We derive an optimization problem that targets a fair distribution of the playback delays among heterogeneous clients, as well as minimal buffer usage. A server-based scheduling strategy is then proposed that takes into account the properties of the targeted clients, the channel status, and the structure of the media encoding. A polynomial-time algorithm providing close to optimal results is introduced and it is shown to offer significantly reduced playback delays per client population, as compared to traditional scheduling strategies. At the same time, PSNR performance is not affected, which altogether leads to an overall improvement in the quality of service.	algorithm;mathematical optimization;optimization problem;peak signal-to-noise ratio;quality of service;scalability;scheduling (computing);server (computing);streaming media;time complexity	Jean-Paul Wagner;Pascal Frossard	2005	2005 1st International Conference on Multimedia Services Access Networks, 2005. MSAN '05.	10.1109/MSAN.2005.1489944	real-time computing;quality of service;computer science;operating system;distributed computing;computer network	HPC	-7.217627766791593	99.7169651602421	15931
40c63549f0683eea368974e03055f2459a359721	collecting and modeling the join/leave behavior of multicast group members in the mbone	virtual network;protocols;teleconferencing;usage models;protocol evaluation;realistic workloads;communications;real time systems teleconferencing protocols multimedia systems;data collection;group spatial characteristics;multicast protocols join leave behavior multicast group members mbone real time protocol global conferencing applications realistic workloads usage models protocol evaluation mlisten join leave times statistics member inter arrival times multicast tree routing information group spatial characteristics active sessions multicast backbone virtual network internet real time multimedia data;join leave times;active sessions;multimedia systems;computer networks;multicast tree;global conferencing applications;internet;join leave behavior;multicast protocols;multicast group members;statistics;meetings;real time multimedia data;real time protocol;mlisten;mbone;multicast protocols statistical analysis information analysis testing monitoring data analysis educational institutions routing spine ip networks;multicast tree routing information;member inter arrival times;real time systems;multicast backbone;mathematics computers information science management law miscellaneous	One purpose of the MBone is to study the performance of multicast and real-time protocols in global conferencing applications. Part of this evaluation is dependent on understanding how the MBone is used and developing realistic workloads and usage models to assist in protocol evaluation. We have developed a tool, called Mlisten, to accurately collect the join/leave times for multicast group members in MBone audio sessions. Using data collected with Mlisten and a set of analysis tools, we report statistics about several MBone audio sessions including member inter-arrival times and durations, multicast tree routing information,and group spatial characteristics. Data was also collected and analyzed for all active sessions to produce information about movement among multicast groups.	algorithm;mbone;multicast;real-time transcription;routing	Kevin C. Almeroth;Mostafa H. Ammar	1996		10.1109/HPDC.1996.546190	communications protocol;real-time computing;the internet;teleconference;mbone;computer science;operating system;distributed computing;xcast;computer network;data collection	HPC	-23.43771417768095	72.3856254116667	15949
8b46a76db8337f231029fe88f28ddf99f93f3a3f	secure session on mobile: an exploration on combining biometric, trustzone, and user behavior	secure session;event detection;fingerprint identification;invasive software;biometric;secure computation;security need;arm architecture;user identity;mobile computing platform;identity-tracking solution;password peeping;multisession data collection;trusted computing;system performance;user behavior;biometric-based continuous tracking;sensor fusion;onboard sensor;information-stealing malware;secure storage;internet;trustzone;fingerprint authentication log monitoring;payment processing;decommissioned device;internet connected mobile device;sensitive session driven application;data loss;implicit tracking;secure session-based payment system;mobile computing	With the rise of Internet connected mobile devices, applications have migrated from PCs to mobile computing platforms. An important aspect, payment processing, faces new security challenges from these developments. Inasmuch, these advancements demand efforts from researchers and industry to meet increasing security needs. Threats can ensue from data loss, theft from lost, stolen, or decommissioned devices, information-stealing malware, and password peeping. We propose a secure framework for sensitive session driven applications which combines biometric-based continuous and implicit tracking of user identities, and TrustZone. This framework is accomplished through monitoring fingerprint authentication logs as well as detecting events when the phone has left the user's hands, all while in TrustZone, a platform for secure computation and storage on mobile devices. This solution leverages multiple onboard sensors as well as the ARM architecture to accomplish these feats. We conducted two user-studies acquiring smartphone users' usage statistics to investigate security and usability needs of our identity-tracking solution. To monitor these subtle gestures in real-world uncontrolled environments, multi-session data collection has been conducted to iteratively improve system performance. The evaluation results have demonstrated the feasibility of this framework as a secure session-based payment system.	arm architecture;authentication;authorization;biometrics;fingerprint recognition;internet;malware;mobile computing;mobile device;multistage amplifier;normal mode;operating system;password;secure multi-party computation;self-replication;sensor;smartphone;threat (computer);touchscreen;uncontrolled format string;usability	Tao Feng;Nicholas DeSalvo;Lei Xu;Xi Zhao;Xi Wang;Weidong Shi	2014	6th International Conference on Mobile Computing, Applications and Services		computer science;internet privacy;world wide web;computer security	Mobile	-51.07800482307837	64.30866727393995	15951
d75ed68dc55ccf851ffc6502164d04fd06a7d600	a two-stage locality-sensitive hashing based approach for privacy-preserving mobile service recommendation in cross-platform edge environment		Abstract With the increasing popularity of service computing paradigm, tremendous resources or services are emerging rapidly on the Web, imposing heavy burdens on the service selection decisions of users. In this situation, recommendation (e.g., collaborative filtering) has been considered as one of the most effective ways to alleviate such burdens. However, in the mobile and edge environment, the service recommendation bases, i.e., historical service usage data are often generated from various mobile devices (e.g., Smartphone and PDA) and stored in different edge platforms. Therefore, effective collaboration between these distributed edge platforms plays an important role in the successful mobile service recommendation. Such a cross-platform collaboration process often faces the following two challenges. First, a platform is often reluctant to release its data to other platforms due to privacy concerns. Second, the collaboration efficiency is often low when the data in each platform update frequently. In view of these two challenges, we introduce MinHash, an instance of Locality-Sensitive Hashing (LSH), into service recommendation, and further put forward a novel privacy-preserving and scalable mobile service recommendation approach based on two-stage LSH, named SerRec t w o - L S H . Finally, extensive experiments are conducted on WS-DREAM , a real distributed service quality dataset, and the evaluation results demonstrate that both the service recommendation accuracy and the scalability have been significantly improved while privacy preservation is guaranteed.	locality of reference;locality-sensitive hashing	Lianyong Qi;Xuyun Zhang;Wan-Chun Dou;Chunhua Hu;Chi Yang;Jinjun Chen	2018	Future Generation Comp. Syst.	10.1016/j.future.2018.02.050	locality-sensitive hashing;mobile service;collaborative filtering;distributed computing;minhash;service quality;scalability;services computing;computer science;usage data	Web+IR	-31.534257578474172	61.92079253598248	15961
5abc66cb520b47afe5ba3be0597655a4f2b61293	transport protocol throughput fairness	dccp;fairness;cubic;protocol design;tcp;round trip time;indexing terms;transmission control protocol;computer architectures operating systems;end to end measurement;compound tcp;congestion control;protocol performance;bic;transport protocol;datagram congestion control protocol;high speed	Interest continues to grow in alternative transport protocols to the Transmission Control Protocol (TCP). These alternatives include protocols designed to give greater efficiency in high-speed, high-delay environments (so-called high-speed TCP variants), and protocols that provide congestion control without reliability. For the former category, along with the deployed base of ‘vanilla’ TCP – TCP NewReno – the TCP variants BIC and CUBIC are widely used within Linux: for the latter category, the Datagram Congestion Control Protocol (DCCP) is currently on the IETF Standards Track. It is clear that future traffic patterns will consist of a mix of flows from these protocols (and others). So, it is important for users and network operators to be aware of the impact that these protocols may have on users. We show the measurement of fairness in throughput performance of DCCP Congestion Control ID 2 (CCID2) relative to TCP NewReno, and variants Binary Increase Congestion control (BIC), CUBIC and Compound, all in “out-of-the box” configurations. We use a testbed and endto-end measurements to assess overall throughput, and also to assess fairness – how well these protocols might respond to each other when operating over the same end-to-end network path. We find that, in our testbed, DCCP CCID2 shows good fairness with NewReno, while BIC, CUBIC and Compound show unfairness above round-trip times of 25ms.	bandwidth-delay product;bayesian information criterion;cubic function;datagram;end-to-end principle;fairness measure;internet protocol suite;linux;network congestion;testbed;thinking outside the box;throughput;while	Saleem N. Bhatti;Martin Bateman	2009	JNW	10.4304/jnw.4.9.881-894	fairness measure;compound tcp;tcp congestion-avoidance algorithm;real-time computing;tcp global synchronization;tcp westwood plus;telecommunications;computer science;bic tcp;transmission control protocol;h-tcp;zeta-tcp;cubic tcp;scalable tcp;tcp tuning;tcp acceleration;tcp friendly rate control;slow-start;computer network	Networks	-5.127015336581585	93.19221022181809	15967
ceba62b5b1b96338fa37fb8b8b9958eb88e3a069	security-enhanced push button configuration for home smart control †	wi-fi;push button configuration;security;smart home;wireless protected setup	With the emergence of smart and converged home services, the need for the secure and easy interplay of various devices has been increased. Push Button Configuration (PBC) is one of the technologies proposed for easy set-up of a secure session between IT and consumer devices. Although the Wi-Fi Direct specification explicitly states that all devices must support the PBC method, its applicability is very limited. This is because the security vulnerability of PBC can be maliciously exploited so that attackers can make illegitimate sessions with consumer devices. To address this problem, this paper proposes a novel Security-enhanced PBC (SePBC) scheme with which we can uncover suspicious or malicious devices. The proposed mechanism has several unique features. First, we develop a secure handshake distance measurement protocol by preventing an adversary sitting outside the region from maliciously manipulating its distance to be fake. Second, it is compatible with the original Wi-Fi PBC without introducing a brand-new methodology. Finally, SePBC uses lightweight operations without CPU-intensive cryptography computation and employs inexpensive H/W. Moreover, it needs to incur little overhead when there is no attack. This paper also designs and implements the proposed SePBC in the real world. Our experimental results and analysis show that the proposed SePBC scheme effectively defeats attacks on PBC while minimizing the modification of the original PBC equipment.	ability to sit question;adversary (cryptography);algorithm;cpu (central processing unit of computer system);central processing unit;computation;cryptography;double-balloon enteroscopy;emergence;encryption software;exploit (computer security);hl7publishingsubsection <operations>;high-level programming language;home automation;home visit (procedure);malware;overhead (computing);periodic boundary conditions;premier boxing champions;primary biliary cirrhosis;privacy;protocols documentation;push-button;vulnerability (computing);sensor (device)	Junghee Han;Taejoon Park	2017		10.3390/s17061334		Security	-52.40833197081996	68.49468496408944	15979
463c056993ad8301b6295838ddd662cc39cb6d71	simpl systems: on a public key variant of physical unclonable functions		This paper theoretically discusses a novel security tool termed SIMPL system, which can be regarded as a public key version of physical unclonable functions (PUFs). Like the latter, a SIMPL system S is physically unique and non-reproducible, and implements an individual function FS . In opposition to a PUF, however, a SIMPL system S possesses a publicly known numerical description D(S), which allows its digital simulation and prediction. At the same time, it is required that any digital simulation of a SIMPL system S must work at a detectably lower speed than its real-time behavior. In other words, the holder of a SIMPL system S can evaluate a publicly known, publicly computable function FS faster than anyone else. This feature, so we argue in this paper, allows a number of improved practicality and security features. Once implemented successfully, SIMPL systems would have specific advantages over PUFs, certificates of authenticity, physically obfuscated keys, and also over standard mathematical cryptotechniques.	computable function;concrete security;cryptosystem;digital rights management;heuristic (computer science);message authentication;numerical analysis;public-key cryptography;real-time transcription;simpl;semantic role labeling;simulation;time complexity;vogl	Ulrich Rührmair	2009	IACR Cryptology ePrint Archive		public-key cryptography;theoretical computer science;computable function;key (lock);computer science	Security	-39.70045635036525	77.08206650690276	16002
0d30a2f882e8d062f7bc21369f0b982f1b9a0ff5	qos-driven and fair downlink scheduling for video streaming over lte networks with deadline and hard hand-off	video deadlines;mobility management mobile radio;fairness;video streaming;interrupters;lte;3gpp qos driven downlink scheduling scheme fair downlink scheduling video streaming lte networks deadline hand off hard hand off procedure long term evolution ubiquitous multimedia communication data transmission rate enhancement multimedia quality of service mobility scenarios service degradation qos requirements qos metrics video packet deadline hard ho service degradation multimedia traffic regular data traffic third generation partnership project;long term evolution;handoff;qos;telecommunication traffic;3g mobile communication;lte video streaming scheduling qos video deadlines fairness handoff;downlink;streaming media;scheduling;multimedia communication;video streaming 3g mobile communication long term evolution mobile computing mobility management mobile radio quality of service scheduling telecommunication traffic;streaming media quality of service downlink multimedia communication delay scheduling interrupters;quality of service;mobile computing	Long-term evolution (LTE) represents a promising technique for ubiquitous multimedia communication because of its significant enhancement to the data transmission rate. However, the hard hand-off (HO) procedure standardized in LTE is a menace to multimedia quality of service (QoS), due to the service interruption introduced by the procedure. Thus, one major challenge of such a system is to design an effective scheduler that can guarantee quality-of-service (QoS) to users under various mobility scenarios, including the hard HO procedure. Existing downlink scheduling approaches do not consider the characteristics of the video sources together with the service degradation evoked by hard HO, and therefore are unable to meet the QoS requirements of multimedia consumers. In this paper, we develop a QoS-driven downlink scheduling scheme for video streaming that considers both QoS metrics of video packet deadline and hard HO service degradation, in order to guarantee the QoS requirements of multimedia consumers. It will be demonstrated that the proposed scheduler is not only able to achieve satisfactory QoS for users during HO period, but also offers fairness for both multimedia traffic and regular data traffic. Simulation results confirm the efficiency of the proposed scheme.	compaq lte;elegant degradation;fairness measure;interrupt;menace;network packet;quality of service;requirement;scheduling (computing);simulation;streaming media;telecommunications link	Qian Liu;Zixuan Zou;Chang Wen Chen	2012	2012 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2012.154	real-time computing;mobile qos;quality of service;computer science;operating system;distributed computing;mobile computing;computer network	Embedded	-7.694020043066761	99.69320191612482	16003
fa2687a8b5c3cc4705fb5913ba95c1fd0da3d836	constructing peks schemes secure against keyword guessing attacks is possible	busqueda informacion;keyword;encryption;information retrieval;cle publique;public key encryption;palabra clave;cifrado;attaque informatique;mot cle;satisfiability;public key;cryptage;keyword search;recherche information;criptografia;cryptography;llave publica;computer attack;ataque informatica;cryptographie;keyword guessing attack;searchable encryption;consistency	Byun et al. suggested keyword guessing attacks and showed that some PEKS (public-key encryption with keyword search) schemes are not secure to keyword guessing attacks, when the number of possible keywords is bounded by some polynomial. Abdalla et al. showed that robust PEKS schemes should satisfy consistency which ensures the PEKS schemes fulfil their functions. In the paper, we show a negative result about the open problem to construct secure PEKS schemes against keyword guessing attacks. Our result shows that consistency implies insecurity to keyword guessing attacks in PEKS. This means that constructing secure and consistent PEKS schemes against keyword guessing attacks is impossible, when the number of possible keywords is bounded by some polynomial. 2008 Elsevier B.V. All rights reserved.	encryption;next-generation network;polynomial;public-key cryptography;search algorithm	Ik Rae Jeong;Jeong Ok Kwon;Dowon Hong;Dong Hoon Lee	2009	Computer Communications	10.1016/j.comcom.2008.11.018	computer science;internet privacy;public-key cryptography;world wide web;computer security	Crypto	-42.84296503340365	77.7229162747628	16049
afe639735bc22311097bceed97b2d3ac8ccfbf05	periodic polling for web cache consistency	proxy caching;algorithm;consistency maintenance;web caching	As the size of proxy cache increases, the lifetime of objects in the cache would increase. If the objects in the cache were to be stored for a long time without checking its validity, the number of stale documents would also increase. The idle network bandwidth can be used for proxy cache consistency maintenance. We propose the selection algorithm that can be used in periodic polling mechanism for the consistency maintenance of proxy cache server.	cache coherence;selection algorithm;server (computing);web cache	Beomseok Nam;Kern Koh	1999			real-time computing;cache;database;smart cache;data consistency;world wide web	Security	-17.55746599166454	70.04803942651583	16075
59190c574ab49c10069080239119e428fdb17c9f	practical modbus flooding attack and detection	change detection;intrusion detection;denial of service dos;modbus;089999 information and computing sciences not elsewhere classified	The Modicon Communication Bus (Modbus) protocol is one of the most commonly used protocols in industrial control systems. Modbus was not designed to provide security. This paper confirms that the Modbus protocol is vulnerable to flooding attacks. These attacks involve injection of commands that result in disrupting the normal operation of the control system. This paper describes a set of experiments that shows that an anomaly-based change detection algorithm and signature-based Snort threshold module are capable of detecting Modbus flooding attacks. In comparing these intrusion detection techniques, we find that the signature-based detection requires a carefully selected threshold value, and that the anomaly-based change detection algorithm may have a short delay before detecting the attacks depending on the parameters used. In addition, we also generate a network traffic dataset of flooding attacks on the Modbus control system protocol.	algorithm;anomaly detection;authentication;checksum;control system;digital signature;experiment;intrusion detection system;man-in-the-middle attack;modbus;network traffic control;sensor;snort	Sajal Bhatia;Nishchal Kush;Chris I. Djamaludin;Ayodeji J. Akande;Ernest Foo	2014			engineering;internet privacy;computer security;computer network	Security	-60.41185750522626	66.21958424925896	16092
3e5bc90c7c83f480d077ccd0beb2203296afe1f2	the complexity of restricted variants of the stable paths problem	theoretical model;aggregation function;border gateway protocol;weight distribution;stable paths problem;autonomic system;interdomain routing;technical report;distributed algorithm	Interdomain routing on the Internet is performed using route preference policies specified independently and arbitrarily by each autonomous system (AS) in the network. These policies are used in the border gateway protocol (BGP) by each AS when selecting next-hop choices for routes to each destination. Conflicts between policies used by different ASs can lead to routing instabilities that, potentially, cannot be resolved regardless of how long BGP runs. The stable paths problem (SPP) is an abstract graph theoretic model of the problem of selecting next-hop routes for a destination. A solution to this problem is a set of next-hop choices, one for each AS, that is compatible with the policies of each AS. In a stable solution each AS has selected its best next-hop if the next-hop choices of all neighbors are fixed. BGP can be viewed as a distributed algorithm for solving an SPP instance. In this report we consider a family of restricted variants of SPP, which we call f -SPP. We show that several natural variants of f -SPP are NP-complete. This includes a variant in which each AS is restricted to one of only two policies, and each of these two policies is based on a monotonic path weight aggregation function. Furthermore, we show that for networks with particular topologies and edge weight distributions, there exist efficient centralized algorithms for solving f -SPP.	autonomous robot;autonomous system (internet);border gateway protocol;centralized computing;distributed algorithm;existential quantification;inter-domain;karp's 21 np-complete problems;routing;self-propelled particles;theory	Kevin Donnelly;Assaf J. Kfoury;Andrei Lapets	2010	Fundam. Inform.	10.3233/FI-2010-319	distributed algorithm;simulation;border gateway protocol;computer science;technical report;weight distribution;distributed computing;computer network	ECom	-7.144930676744713	78.37536135672116	16151
4fc89f7fc8317c27b0ee46530c322bc97912c69c	towards interoperability: an architecture for pan-european eid-based authentication services	smart card;cas;authentication;eid;identity management;identification;member states;interoperability	In the last years several EU Member States have rolled out smartcard based electronic ID (eID) solutions to their citizens. Not all of these solutions are directly compatible to each other. However, with respect to the i2010 e-Government initiative and the upcoming EU Services Directive, cross-border identification and authentication is now on the agenda of all EU Member States. In this paper we present a smart-card based eID identification and authentication solution, which supports smart-cards from different Member States. The proposed solution can be easily integrated into existing authentication and identity management solutions and does not necessarily require any additional client software to be installed by citizens.	authentication;interoperability	Arne Tauber;Bernd Zwattendorfer;Thomas Zefferer;Yasmin Mazhari;Eleftherios Chamakiotis	2010		10.1007/978-3-642-15172-9_12	identification;smart card;interoperability;computer science;cas registry number;authentication;internet privacy;world wide web;computer security;identity management	Mobile	-46.65928305355029	64.47947142671939	16162
04007038826b67b158010094ad06b7bee7efe2c8	efficient ims authentication architecture based on initial access authentication in wibro-evolution (wibro-evo) system	wireless broadband internet;broadband networks;web and internet services;core network interface;authentication;authentication wireless lan bandwidth multimedia systems web and internet services mobile communication network servers 3g mobile communication network interfaces ip networks;mobile communication system;wlan;wibro evo system;packet switched;multimedia systems;network interfaces;network servers;3g mobile communication;internet;wireless lan 3g mobile communication broadband networks internet message authentication multimedia communication signalling protocols telecommunication security;multimedia communication;mobile communication;telecommunication security;wibro evolution;integrity sip registration messages;bandwidth;ip networks;radio interface;wireless lan;message authentication;ims authentication architecture;3g packet switched mobile communication systems;wireless broadband internet ims authentication architecture initial access authentication wibro evolution multimedia services wibro evo system radio interface core network interface integrity sip registration messages 3g packet switched mobile communication systems wlan;multimedia services;initial access authentication;core network;is research;signalling protocols	In order to overcome the drawbacks and combine the advantages of both 3G packet-switched mobile communication systems and WLAN, wireless broadband Internet (WiBro) system based on 2.3 GHz bandwidth and IEEE 802.16e has been developed in Korea. Recently, the new version of WiBro system, named WiBro-evolution (WiBro-EVO) system which provides various multimedia services, is researched. In this paper, we investigate the IMS authentication schemes and propose the efficient IMS authentication scheme based on the initial access authentication scheme in WiBro-EVO system. We also evaluate the performance of the proposed scheme to consider how it reduces the signaling message overhead in the WiBro-EVO network. The proposed scheme can reduce signaling overhead over the radio interface and core network interface. In addition, it can guarantee the integrity SIP registration messages.	authentication;compaq evo;ieee 1471;network interface;network packet;overhead (computing);packet switching	Sun-Hwa Lim;Sang-ho Lee	2007	2007 IEEE 65th Vehicular Technology Conference - VTC2007-Spring	10.1109/VETECS.2007.195	message authentication code;embedded system;the internet;core network;mobile telephony;telecommunications;computer science;network interface;authentication protocol;authentication;bandwidth;computer network;broadband networks	Mobile	-13.649023363682646	90.98593897852575	16178
caf968e4122e397ad80892f793c1da9eb9011b8f	sharvot: secret share-based voting on the blockchain		Recently, there has been a growing interest in using online technologies to design protocols for secure electronic voting. The main challenges include vote privacy and anonymity, ballot irrevocability and transparency throughout the vote counting process. The introduction of the blockchain as a basis for cryptocurrency protocols, provides for the exploitation of the immutability and transparency properties of these distributed ledgers.  In this paper, we discuss possible uses of the blockchain technology to implement a secure and fair voting system. In particular, we introduce a secret share-based voting system on the blockchain, the so-called SHARVOT protocol1. Our solution uses Shamir's Secret Sharing to enable on-chain, i.e. within the transactions script, votes submission and winning candidate determination. The protocol is also using a shuffling technique, Circle Shuffle, to de-link voters from their submissions.		Silvia Bartolucci;Pauline Bernat;Daniel Joseph	2018	2018 IEEE/ACM 1st International Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB)	10.1145/3194113.3194118	data mining;ballot;anonymity;public-key cryptography;shuffling;voting;distributed computing;cryptocurrency;secret sharing;electronic voting;computer science	Security	-43.65354688971581	70.40391808904833	16222
531d49a54d066739c24c49359b34dd5e567425dc	a non-key based security scheme supporting emergency treatment of wireless implants	logic gates authentication jamming receiving antennas wireless communication transmitting antennas;external authentication proxy wireless implants wireless communication module implantable medical devices nonkey based security scheme emergency treatment;wireless sensor networks biomedical telemetry computer network security prosthetics wireless channels	The security of wireless communication module for Implantable Medical Devices (IMDs) poses a unique challenge that doctors in any qualified hospital should have the access to the IMDs for an emergency treatment while the IMD should be protected from adversaries during a patient's daily life. In this paper, we present a non-key based security scheme for the emergency treatment of IMDs, named the BodyDouble. This scheme employs an external authentication proxy embedded in a gateway to authenticate the identity of a programmer. The gateway here employs a transmitting antenna to send data and jamming signals. When an adversary launches attacks, the gateway jams the request signal to the IMD and authenticates its identity. The gateway will also pretend to be the wireless module of the IMD by establishing a communication link with the adversary so that the adversary is spoofed to communicate with the gateway instead of the IMD. For the emergency situation, the IMD can be accessed without using any cryptographic keys by simply powering off or removing the gateway. Simulation results show that this security scheme can protect the IMD from the adversary's attacks successfully, and resist the potential repeated attacks to prevent the battery depletion of the IMD.	adversary (cryptography);authentication;depletion region;embedded system;emergence;key (cryptography);peripheral;programmer;proxy server;radio jamming;simulation;transmitter;usc interactive media & games division;wireless security	Guanglou Zheng;Gengfa Fang;Mehmet A. Orgun;Rajan Shankaran	2014	2014 IEEE International Conference on Communications (ICC)	10.1109/ICC.2014.6883392	wi-fi;wireless wan;wireless site survey;telecommunications;wireless network;wireless lan controller;key distribution in wireless sensor networks;base transceiver station;wi-fi array;fixed wireless;computer security;computer network	Mobile	-50.9978623260617	72.31577151418097	16223
6b5da3fe366427aebb3e5fa9fa27610466f60a6c	a differentially private approach for querying rdf data of social networks		As the amount of collected social network information in RDF format grows, the development of solutions for the privacy of individuals, their attributes and relationships with others becomes an important subject of study. However, data privacy solutions are not well suitable for this specific type of data, mainly because they usually do not consider relationships between individuals, which are crucial to semantic data and social networks. Differential privacy is one of the most suitable techniques for statistical queries and, although it has been extensively studied in many papers, there is still much research to be done in this context. This paper presents two main contributions for privacy preserving statistic queries containing sensitive information about relationships between individuals. The first one is a complete approach to applying &epsis;-differential privacy for RDF data and the second one presents an index-like data structure to efficiently compute parameters for the differential privacy mechanism: the query's actual value and data sensitivity for the given query. We conclude by evaluating our contributions over three real social network datasets presenting utility analysis for different values of &epsis;. We also show the performance benefit of our index-like data structure for sensitivity calculation.	avg;data structure;differential privacy;information privacy;information sensitivity;max;real-time transcription;rendering (computer graphics);social network;statistical model	Roney Reis de C. e Silva;Bruno de C. Leal;Felipe T. Brito;Vânia Maria Ponte Vidal;Javam C. Machado	2017		10.1145/3105831.3105838	semantic data model;database;computer science;differential privacy;rdf;data mining;privacy software;information sensitivity;information privacy;social network;data structure	DB	-39.67883848892098	62.91748753230619	16230
655cc818b3e6e09247ee12421afa1262492a37ac	evaluation of tcp performance by using high-speed communication satellite winds and large earth terminal	winds		communications satellite	Hiroyasu Obata;Kenji Ishida;Chisa Takano;Junichi Funasaka;Masaaki Bessho	2012	IEICE Transactions		wind	HPC	-17.38936514960912	94.4188001655289	16240
05843fdae13d8cac7ddf56c9c19c21ccf48336c2	leak-free group signatures with immediate revocation	groupware;group signature scheme;communication channels leak free group signatures immediate revocation cryptography credential systems security requirements systems architecture;security computer science public key management information systems information management public key cryptography application software communication channels ear protocols;separation of duty;group signature;groupware message authentication telecommunication security cryptography open systems telecommunication channels;cryptography;telecommunication security;message authentication;free group;telecommunication channels;system architecture;open systems;large classes	Group signatures are an interesting and appealing cryptographic construct with many promising potential applications. This work is motivated by attractive features of group signatures, particularly, their potential to serve as foundation for anonymous credential systems. We reexamine the entire notion of group signatures from a systems perspective and identify two new security requirements: leak-freedom and immediate-revocation, which are crucial for a large class of applications. We then present a new group signature scheme that achieves all identified properties. Our scheme is based on the so-called systems architecture approach. It is more efficient than the state-of-the-art and facilitates easy implementation. Moreover, it reflects the well-known separation-of-duty principle. Another benefit of our scheme is the obviated reliance on underlying anonymous communication channels, which are necessary in previous schemes.	antivirus software;cryptography;database;denial-of-service attack;digital credential;digital signature;group signature;linear programming relaxation;requirement;server (computing);stateless protocol;systems architecture;whole earth 'lectronic link	Xuhua Ding;Gene Tsudik;Shouhuai Xu	2004	24th International Conference on Distributed Computing Systems, 2004. Proceedings.	10.1109/ICDCS.2004.1281628	computer science;internet privacy;group signature;world wide web;computer security;computer network;systems architecture	Crypto	-42.21667277208312	75.12245076299232	16250
5f272074d6b63ad4eda8e3125475421d73d4a0db	dknns: scalable and accurate distributed k nearest neighbor search for latency-sensitive applications	distributed system;network measurement;network coordinate;latency sensitive network applications k nearest neighbor search network coordinate;latency sensitive network applications;k nearest neighbor search	To reduce the access latencies of end hosts, latency-sensitive applications need to choose suitably close service machines to answer the access requests from end hosts. Distributed K nearest neighbor search locates K service machines closest to end hosts, which can efficiently optimize the access latencies for end hosts. Existing work has weakness in terms of the accuracy and scalability. According to the scalable and accurate K nearest neighbor search problem, we propose a distributed K nearest neighbor search method called DKNNS in this paper. Service machines are organized into a locality-aware multilevel ring. DKNNS first locates a service machine that starts the search process based on a farthest neighbor search scheme, then discovers K nearest service machines based on a backtracking approach within the proximity region containing the target in the latency space. Theoretical analysis, simulation results and deployment experiments on the PlanetLab show that, DKNNS can determine K approximately optimal service machines, with modest completion time and query loads. Finally, DKNNS is also quite stable that can be used for reducing frequent searches by caching found nearest neighbors.	backtracking;experiment;locality of reference;nearest neighbor search;planetlab;scalability;search problem;simulation;software deployment	Yongquan Fu;Yijie Wang	2011	Science China Information Sciences	10.1007/s11432-011-4449-7	nearest-neighbor chain algorithm;r-tree;ball tree;nearest neighbor graph;best bin first;computer science;theoretical computer science;machine learning;distributed computing;cover tree;nearest neighbor search;fixed-radius near neighbors	Networks	-12.607259772766662	74.24273335755183	16260
0322571a07503a8298010ad5ebe6722ff761ea76	efficient hierarchical threshold symmetric group key management protocol for mobile ad hoc networks		With rapid growth of Ad Hoc Networks consisting of low power computing devices, security will be an important factor for their full implementation. Because of scarcity of resources in terms of computing capability and energy efficiency, designing of computationally efficient group key management protocols with dynamic topology is a major concern. Teo and Tan [11] proposed an energy-efficient generalized circular hierarchical group model, but this approach suffers from: (i) exponential increase of key messages due to dynamic topology and (ii) energy loss because the vicinity of nodes in a subgroup is high. This work is an extension of Teo u0026 Tan’s circular hierarchical model for fixed number of group members. The proposed modification overcomes these two weaknesses of Teo u0026 Tan’s protocol. The proposed modifications make this protocol secure against replay, masquerading, spoofing, chosen ciphertext and impersonation attacks because of proper authentication and digital signatures. The comparative numerical and simulation analysis of proposed approach has been made with Teo u0026 Tan, Wen-Lin-Hwang’s (WLH) and along with Tseng’s group key agreement approach. The analysis shows that proposed approach is well suited for low computational mobile devices with minimum delay. Through WLH protocol shows maximum throughput and minimum delay however it lacks in terms of security aspects.		Adarsh Kumar;Alok Aggarwal;Charu	2012		10.1007/978-3-642-32129-0_35	vehicular ad hoc network;wireless routing protocol;optimized link state routing protocol;mobile ad hoc network;ad hoc wireless distribution service;computer network	Mobile	-49.68675636922971	76.22493058438701	16278
dc49c60a846416a54e3d6732f4b04c7aa1be97bb	congestion handling in dynamic differentiated services networks	queueing;congestion handling;web and internet services;queueing theory;bandwidth allocation;service level agreements;network load;telecommunication congestion control;differentiated service;internet service provider;queueing theory telecommunication congestion control internet quality of service bandwidth allocation telecommunication traffic;provider policies;automatic set up;resource reservation;telecommunication traffic;network servers;internet;sla;queueing congestion handling dynamic differentiated services networks quality of service service level agreements sla internet service provider resource reservations traffic bandwidth brokers network load provider policies automatic set up scalable mechanism;dynamic differentiated services networks;traffic;diffserv networks;bandwidth broker;bandwidth;service level agreement;bandwidth brokers;intelligent networks;intelligent networks diffserv networks bandwidth web and internet services virtual private networks quality of service delay telecommunication traffic network servers web server;internet application;web server;quality of service;resource reservations;scalable mechanism;virtual private networks	Dflerentiuted Services is U very promising upprouch to uchieve quulity of service in the Internet. However, setting up stutic Service Level Agreements (SLA) between different Internet Service Provider domuins lucks flexibility und muy reduce quality of service us resource reservutions cunnot be udupted to the uctuul truffic. With the introduction of Bundwidth Brokers, U signrficunt step towurds U completely dynumic Differentiuted Services environment hus been made. Bundwidth Brokers negotiute und uutomutically set up SLAs uccording to network loud und provider policies. Nevertheless, this uutomutic set-up muy fuil i f there ure bottlenecks in the network cuused by physicul limitations or policy issues und muy lead to congestion. In this puper, we propose U sculuble mechunism to hundle these congestion situutions, thut uses 4 phuses euch solving U different level of congestion. Our mechunism does not need any desrinution information thus making it upplicuble for the mujority of Internet upplicutions.	differentiated services;internet;network congestion;quality of service;service-level agreement	Markus Albrecht;Michael Köster;Peter Martini	2001		10.1109/LCN.2001.990782	bandwidth throttling;internet transit;differentiated service;computer science;distributed computing;queueing theory;computer security;computer network	Networks	-6.476117544142888	95.16024846785407	16281
92f0e38ca94915a74f0dad0fe2fd4267d1e3cf65	case study: interactive visualization for internet security	graph drawing;routing data;network security;internet backbone;actual anomalous event;anomaly detection;case study;interactive visualization;data visualisation;internet;graphical user interfaces;routing protocols;border gateway protocol;interactive systems;information visualization;best route;internet security;internet connectivity;security of data;visualization;data security;routing protocol	Internet connectivity is defined by a set of routing protocols which let the routers that comprise the Internet backbone choose the best route for a packet to reach its destination. One way to improve the security and performance of Internet is to routinely examine the routing data. In this case study, we show how interactive visualization of Border Gateway Protocol (BGP) data helps characterize routing behavior, identify weaknesses in connectivity which could potentially cripple the Internet, as well as detect and explain actual anomalous events.	border gateway protocol;interactive visualization;internet backbone;internet security;network packet;router (computing);routing	Soon Tee Teoh;Kwan-Liu Ma;Shyhtsun Felix Wu;Xiaoliang Zhao	2002	IEEE Visualization, 2002. VIS 2002.		internet protocol;reserved ip addresses;internet backbone;tier 1 network;enhanced interior gateway routing protocol;anomaly detection;source routing;information visualization;hierarchical routing;internet traffic;autonomous system;interactive visualization;supernetwork;border gateway protocol;internet layer;computer science;network security;internet security;internet privacy;routing protocol;default-free zone;world wide web;data visualization;internet traffic engineering;computer network	Visualization	-59.517932325091294	65.74018774196897	16288
7aeb4702052b0c10b85b372c4cdf3d83399f5104	inter-domain popularity-aware video caching in future internet architectures	topology;servers;redundancy;degradation;indexes;artificial neural networks	Current TCP/IP based network is suffering from the usage of IP especially in the era of Internet of things (IoT). Recently Content Centric Network (CCN) is proposed as an alternative of the future network architecture. In CCN, data itself, which is authenticated and secured, is a name and can be directly requested at the network level instead of using IP and Domain Name System (DNS). Another difference between CCN and traditional networks is that the routers in CCN have the caching abilities. Then the end users can obtain the data from routers instead of from the remote server if the content has been stored in the router. Hence the overall network performance can be improved by reducing the required transmission hops and the advantage of the CCN caching has been shown in literature. In this paper, we design a new caching policy for the popularity-aware video caching in CCN to handle the `redundancy' problem in the existing schemes, where the same content may be stored multiple times along the road from server to users, thus leading to a significant performance degradation. Simulations are conducted and we could observe that the proposed scheme performs better comparing with the existing caching policies.	authentication;cache (computing);computer simulation;cyclomatic complexity;digital video;elegant degradation;future internet;inter-domain;internet of things;internet protocol suite;network architecture;network performance;p2p caching;router (computing);server (computing)	Zhi Liu;Mianxiong Dong;Bo Gu;Cheng Zhang;Yusheng Ji;Yoshiaki Tanaka	2015	2015 11th International Conference on Heterogeneous Networking for Quality, Reliability, Security and Robustness (QSHINE)		computer science;internet privacy;world wide web;computer network	Metrics	-14.679393678919565	75.09094470089867	16292
352eee1dacfe36762093ebb32ecfdbd212007924	meshman: a management framework for wireless mesh networks	radio networks;wireless mesh networks centralized control statistics quality management resource management bandwidth robustness routing prototypes linux;routing protocols;protocols;network layer failure;wireless channels;pediatrics;simple network management protocol;telecommunication network reliability;dynamic channel quality;routing;source routing;bandwidth resources;management framework;wireless mesh network;wireless communication;snmp;wireless channels protocols radio networks telecommunication network management telecommunication network reliability telecommunication network topology;meshman prototype;network layer failure management framework wireless mesh network bandwidth resources dynamic channel quality meshman prototype query interface user space daemon linux simple network management protocol snmp;bandwidth;mesh networks;linux;network dynamics;network management;telecommunication network topology;user space daemon;query interface;telecommunication network management	As wireless mesh networks become more popular, there exists a need to provide centralized management solutions, which facilitate network administrators to control, troubleshoot and collect statistics from their networks. Managing wireless mesh networks poses unique challenges due to limited bandwidth resources and dynamic channel quality. A robust management solution should function despite network layer failure. In this paper, we propose MeshMan, a network layer agnostic, low overhead solution to network management to cope with unreliable wireless channels, link and network level dynamics in wireless mesh networks. It combines the concepts of source routing with hierarchical addressing, and provides a native efficient query interface. A prototype of MeshMan has been implemented as a user space daemon on Linux and evaluated using a 12-node wireless mesh network testbed. Experimental studies demonstrate that MeshMan has comparable or better performance than the Simple Network Management Protocol (SNMP) in management overhead and response times when the network is stable while having much better performance in presence network dynamics.	anycast;centralized computing;daemon (computing);fault tolerance;linux;mesh networking;overhead (computing);prototype;response time (technology);scalability;simple network management protocol;source routing;testbed;user space;wireless mesh network	Vivek Aseeja;Rong Zheng	2009	2009 IFIP/IEEE International Symposium on Integrated Network Management	10.1109/INM.2009.5188814	multi-frequency network;wireless mesh network;switched mesh;service set;real-time computing;wireless wan;network architecture;wireless sensor network;heterogeneous network;wireless site survey;network management station;bridging;computer science;mesh networking;wireless network;shared mesh;distributed computing;order one network protocol;key distribution in wireless sensor networks;network management application;simple network management protocol;wi-fi array;hazy sighted link state routing protocol;computer network	Mobile	-12.36394831974974	77.43566798433618	16344
07941fbfe4be7d3eb54a6b1491019af8300c7f94	design, implementation and performance of a content-based switch	ssl connections content based switch l5 switch layer 2 3 4 information application level information traffic routing application level proxies switch hardware http sessions uniform resource locators session aware dispatching secure socket layer url;secure socket layer;http sessions;switches packet switching routing uniform resource locators buildings telecommunication traffic payloads data handling hardware dispatching;routing;telecommunication security telecommunication network routing packet switching telecommunication traffic transport protocols electronic switching systems;packet switching;switch hardware;functional equivalence;transport protocols;telecommunication traffic;application level information;telecommunication network routing;traffic routing;uniform resource locator;telecommunication security;session aware dispatching;electronic switching systems;content based switch;payloads;application level proxies;layer 2;data handling;switches;uniform resource locators;ssl connections;buildings;dispatching;l5 switch;hardware;url;layer 2 3 4 information	In this paper, we share our experience in designing and building a content based switch which we call L5. In addition to the layer 2-3-4 information available in the packet, a content based switch uses application level information to route traffic in the network. Making routing decisions based on information contained in the payload is not a new idea. In fact application level proxies which are functionally equivalent to a content-based switch, have been around for years. Our contribution is in combining the functionalities of an application level proxy with the data handling capabilities of a switch into a single system. In this paper, we describe the architecture of the L5 system along with the details of how application level information can be efficiently processed in switch hardware. We cover two specific application examples that we believe are ideal candidates for content-based switching: one is routing HTTP sessions based on Uniform Resource Locators (URL) and the other is session-aware dispatching of Secure Socket Layer (SSL) connections.	benchmark (computing);computer cluster;differentiated service;e-commerce;http cookie;hypertext transfer protocol;network packet;proxy server;router (computing);routing;server (computing);throughput;transport layer security;uniform resource identifier;user profile;web server	George Apostolopoulos;David Aubespin;Vinod G. J. Peris;Prashant Pradhan;Debanjan Saha	2000		10.1109/INFCOM.2000.832470	uniform resource locator;real-time computing;telecommunications;computer science;operating system;computer security;computer network	Networks	-23.80049079440074	86.20177428364354	16402
3ea8368c2680deec7369acb4740e70c03e60fd15	limits on the power of garbling techniques for public-key encryption		Understanding whether public-key encryption can be based on one-way functions is a fundamental open problem in cryptography. The seminal work of Impagliazzo and Rudich [STOC’89] shows that black-box constructions of public-key encryption from one-way functions are impossible. However, this impossibility result leaves open the possibility of using non-black-box techniques for achieving this goal. One of the most powerful classes of non-black-box techniques, which can be based on oneway functions alone, is Yao’s garbled circuit technique [FOCS’86]. As for the non-black-box power of this technique, the recent work of Döttling and Garg [CRYPTO’17] shows that the use of garbling allows us to circumvent known black-box barriers in the context of identity-based encryption. We prove that garbling of circuits that have one-way function (or even random oracle) gates in them are insufficient for obtaining public-key encryption. Additionally, we show that this model also captures (non-interactive) zero-knowledge proofs for relations with one-way function gates. This indicates that currently known one-way function based non-black-box techniques are perhaps insufficient for realizing public-key encryption. ∗University of California, Berkeley. Research supported in part from DARPA/ARL SAFEWARE Award W911NF15C0210, AFOSR Award FA9550-15-1-0274, AFOSR YIP Award, DARPA and SPAWAR under contract N66001-15-C-4065, and research grants by the Okawa Foundation, Visa Inc., and Center for Long-Term Cybersecurity (CLTC, UC Berkeley). The views expressed are those of the author and do not reflect the official policy or position of the funding agencies. †University of California Berkeley and University of Virginia. Supported by NSF award CCF-1350939 and AFOSR Award FA9550-15-1-0274. ‡University of Virginia. Supported by NSF CAREER award CCF-1350939, a subcontract on AFOSR Award FA9550-15-1-0274, and University of Virginia’s SEAS Research Innovation Award. §Kuwait University. Work done while at University of Virginia. Supported by Kuwait University and the Kuwait Foundation for the Advancement of Science.	black box;garbled circuit;ibm notes;id-based encryption;interactivity;one-way function;public key infrastructure;public-key cryptography;random oracle;steven rudich;synthetic environment for analysis and simulations;uc browser;virtual instrument software architecture;yao graph;zero-knowledge proof	Sanjam Garg;Mohammad Hajiabadi;Mohammad Mahmoody;Ameer Mohammed	2018	IACR Cryptology ePrint Archive	10.1007/978-3-319-96878-0_12	computer science;open problem;theoretical computer science;impossibility;public-key cryptography;cryptography;encryption	Crypto	-35.26398901467598	76.69734740436633	16429
d2d1a5264d93c2d0ede32572e78bab1c927bd49b	multi-functional secure data aggregation schemes for wsns	wireless sensor networks;secure data aggregation;distributed computing	Secure data aggregation schemes are widely adopted in wireless sensor networks, not only to minimize the energy and bandwidth consumption, but also to enhance the security. Statistics obtained from data aggregation schemes often fall into three categories, i.e., distributive, algebraic, and holistic. In practice, a wide range of reasonable aggregation queries are combinations of several different statistics. Providing multi-functional aggregation support is also a primary demand for data preprocessing in data mining. However, most existing secure aggregation schemes only focus on a single type of statistics. Some statistics, especially holistic ones (e.g., median), are often difficult to compute efficiently in a distributed mode even without considering the security issue. In this paper, we first propose a new Multi-functiOnal secure Data Aggregation scheme (MODA), which encodes raw data into well-defined vectors to provide value-preservation, order-preservation and context-preservation, and thus offering the building blocks for multi-functional aggregation. A homomorphic encryption scheme is adopted to enable in-ciphertext aggregation and end-to-end security. Then, two enhanced and complementary schemes are proposed based on MODA, namely, RandOm selected encryption based Data Aggregation (RODA) and COmpression based Data Aggregation (CODA). RODA can significantly reduce the communication cost at the expense of slightly lower but acceptable security on a leaf node, while CODA can dramatically reduce communication cost with the lower aggregation accuracy. The performance results obtained from theoretic analysis and experimental evaluation of three real datasets under different scenarios, demonstrate that our schemes can achieve the performance superior to the most closely related work.	data aggregation	Ping Zhang;Jianxing Wang;Kehua Guo;Fan Wu;Geyong Min	2018	Ad Hoc Networks	10.1016/j.adhoc.2017.11.004	computer network;raw data;wireless sensor network;distributed computing;encryption;tree (data structure);data aggregator;data pre-processing;distributive property;computer science	Mobile	-50.75843531755238	76.18785275735618	16477
dbe25cc0452bd082aadda419274db595a99c0da4	protecting web services against dos attacks: a case-based reasoning approach	multi agent system;case base reasoning;real time;mixture of experts;web service;cbr;dos attacks;dos attack	The real-time detection is a key factor to detect and block DoS attacks within Web services DoS attacks can be generated for different techniques that take advantage of points vulnerable within Web services This paper describes a novel proposal based on a real time agent to classify user requests and detect and block malicious SOAP messages The classification mechanism is based on a Case-Base Reasoning (CBR) model, where the different CBR phases are time bounded Within the reuse phase of the CBR cycle is incorporated a mixture of experts to choose the most suitable technique of classification depending on the feature of the attack and the available time to solve the classification A prototype of the architecture was developed and the results obtained are presented in this study.	case-based reasoning;denial-of-service attack;web service	Cristian Pinzón;Juan Francisco de Paz;Carolina Zato;Javier Pérez	2010		10.1007/978-3-642-13769-3_28	computer science;multi-agent system;internet privacy;world wide web;computer security;denial-of-service attack	AI	-59.72412488950132	67.88935863012213	16487
a1767b3b097295189da9771a94c6fdf9bd1b57d2	information-theoretically secure aggregate authentication code: model, bounds, and constructions		In authentication schemes where many users send authenticated messages to a receiver, it is desirable to aggregate them into a single short authenticated message in order to reduce communication complexity. In this paper, in order to realize such a mechanism in information-theoretic security setting, we first propose aggregate authentication codes. Specifically, we newly propose a model and a security definition for aggregate authentication codes. We also show tight lower bounds on sizes of entities’ secret-keys and (aggregated) tags. Furthermore, we present optimal (i.e., most efficient) constructions for aggregate authentication codes.	aggregate function;authentication	Asato Kubai;Junji Shikata;Yohei Watanabe	2013		10.1007/978-3-642-40588-4_2	data authentication algorithm;challenge–response authentication;authentication protocol;distributed computing;internet privacy;computer security	Crypto	-40.66315769224613	74.96384806271683	16492
198f5812958f9f67067a797b00692eb78d8c2ca7	automated design of cryptographic hash schemes by evolving highly-nonlinear functions	block ciphering;hachage;cryptage bloc;automated design;genetic program;security analysis;evolutionary computation;funcion no lineal;information security;competitividad;cryptographic hash function;search space;block cipher;securite informatique;non linear function;vulnerability;algoritmo genetico;cryptography and coding;linear functionals;computer security;qa 75 electronic computers computer science;vulnerabilite;hashing;vulnerabilidad;criptografia;cryptography;seguridad informatica;fonction non lineaire;competitiveness;cifrado en bloque;algorithme genetique;cryptographie;algorithme evolutionniste;genetic algorithm;algoritmo evolucionista;hash function;evolutionary algorithm;competitivite;non linear functions;fitness function;evolutionary computing	In the last years, a number of serious flaws and vulnerabilities have been found in classic cryptographic hash functions such as MD4 and MD5. More recently, similar attacks have been extended to the widely used SHA-1, to such an extent that nowadays is prudent to switch to schemes such as SHA-256 and Whirlpool. Nevertheless, many cryptographers believe that all the SHA-related schemes could be vulnerable to variants of the same attacks, for all these schemes have been largely influenced by the design of the MD4 hash function. In this paper, we present a general framework for the automated design of cryptographic block ciphers and hash functions by using Genetic Programming. After a characterization of the search space and the fitness function, we evolve highly nonlinear and extremely efficient functions that can be used as the core components of a cryptographic construction. As an example, a new block cipher named Wheedham is proposed. Following the Miyaguchi-Preneel construction, this block cipher is then used as the compression function of a new hash scheme producing digests of 512 bits. We present a security analysis of our proposal and a comparison in terms of performance with the most promising alternatives in the near future: SHA-512 and Whirlpool. The results show that automatically-obtained schemes such as those presented are competitive both in security and speed.	32-bit;block cipher;byte;cryptographic hash function;cryptographic primitive;cryptography;encryption;fitness function;genetic programming;list of cryptographers;md4;md5;macintosh programmer's workshop;nonlinear programming;nonlinear system;one-way compression function;point of view (computer hardware company);sha-1;sha-2;signedness;whirlpool (cryptography)	Juan E. Tapiador;Julio César Hernández Castro;Pedro Peris-Lopez;Arturo Ribagorda	2008	J. Inf. Sci. Eng.		merkle–damgård construction;cryptographic primitive;security of cryptographic hash functions;double hashing;hash function;perfect hash function;collision attack;merkle tree;preimage attack;sha-2;collision resistance;computer science;artificial intelligence;theoretical computer science;operating system;machine learning;hash chain;hash-based message authentication code;database;mathematics;computer security;algorithm;cryptographic hash function;mdc-2;swifft;evolutionary computation	Crypto	-41.154913946162154	82.9598099488786	16500
7359cd0b907321f407092ba2cb2654104f7553f8	towards provisioning hybrid virtual networks in federated cloud data centers		Abstract Network virtualization is an efficient way to enhance the resource utilization of physical network. It enables numerous heterogeneous virtual networks (VNs) coexist and share the resources of same physical network. Virtual network provisioning has been a key issue in network virtualization. Since the optimal virtual network provisioning is an NP-hard problem, existing studies devote to propose heuristic approaches for a tradeoff between computational complexity and the quality of VN provision. A traditional physical/substrate network usually sustains numerous infrastructure providers (InPs), and many applications in the substrate network can be characterized by hybrid virtual network which composed by both unicast and multicast virtual network. However, few research has conducted for the problem of hybrid virtual network provisioning (HVNP) among multiple domains. In our research, we model the HVNP problem through integer linear programming (ILP) for minimizing provisioning cost. Furthermore, we propose two effective algorithms to address the researched problem: ( i ) the decomposition-based algorithm, HVNP_D; and ( ii ) the spectral clustering based algorithm, HVNP_SC. Extensive simulation experiments have been carried out to assess the proposed algorithms. Simulation results demonstrate that our approaches have better performance than existing approach.	data center;provisioning	Gang Sun;Dan Liao;Dongcheng Zhao;Zhili Sun;Victor I. Chang	2018	Future Generation Comp. Syst.	10.1016/j.future.2017.09.065	multicast;network virtualization;virtual network;computer network;computational complexity theory;cloud computing;integer programming;computer science;provisioning;distributed computing;unicast	Arch	-9.64138855266771	82.89666635319836	16528
061ae6086098f8de92f68280e0a4fdaa4f16a844	a hybrid algorithm for content placement in distributed video on demand systems	video streaming cache storage telecommunication network topology video on demand;servers;hybrid placement technique hybrid algorithm distributed video on demand systems cache delivery video on demand systems static random network topologies fixed heavy tailed video demand server load decoupled systems placement policy single video analysis video content placement problem	We study the content placement problem for cache delivery video-on-demand systems under static random network topologies with fixed heavy-tailed video demand. The performance measure is the amount of server load; we wish to minimize the total download rate for all users from the server and maximize the rate from caches. Our approach reduces the analysis for multiple videos to consideration of decoupled systems with a single video each. For each placement policy, insights gained from the single video analysis carry back to the original multiple video content placement problem. Finally, we introduce a hybrid placement technique that achieves near optimal performance with low complexity.	digital video;download;hybrid algorithm;network topology;random graph;server (computing);simulation;user-generated content;video content analysis	James Yifei Yang;Bruce E. Hajek	2014	2014 IEEE International Symposium on Information Theory	10.1109/ISIT.2014.6874946	embedded system;real-time computing;computer science;server;computer network	Arch	-15.54111670358389	71.75711309783983	16533
9bd7b5ce057f4aa8cbb154e6844190c53f2e646f	a forensic readiness model for wireless networks	model design;digital forensics;wireless local area network;mobile device;wireless network;proof of concept;mobile communication	Over the past decade, wireless mobile communications technology based on IEEE 802.11 wireless local area networks (WLANs) has been adopted worldwide on a massive scale. However, as the number of wireless users has soared, so has the possibility of cyber crime, where criminals deliberately and actively break into WLANs with the intent to cause harm or access sensitive information. WLAN digital forensics is seen not only as a response to cyber crime in wireless environments, but also as a means to stem the increase of cyber crime in WLANs. The challenge in WLAN digital forensics is to intercept and preserve all the communications generated by the mobile devices and conduct a proper digital forensic investigation. This paper attempts to address this issue by proposing a wireless forensic readiness model designed to help monitor, log and preserve wireless network traffic for digital forensic investigations. A prototype implementation of the wireless forensic readiness model is presented as a proof of concept.	cybercrime;information sensitivity;mobile device;network traffic control;prototype;requirement;visual intercept	Sipho Ngobeni;Hein S. Venter;Ivan Burke	2010		10.1007/978-3-642-15506-2_8	service set;wi-fi;wireless wan;mobile web;heterogeneous network;wireless site survey;public land mobile network;computer science;wireless network;wireless lan controller;key distribution in wireless sensor networks;base transceiver station;internet privacy;municipal wireless network;mobile station;wi-fi array;fixed wireless;mobile computing;computer security;network forensics;computer network	Mobile	-53.183092437646614	71.03444180077757	16539
95b1f4fc59cb16e2fc3477a70269ccf1d68631dc	introduction and applicability statements for internet-standard management framework		Status of this Memo This memo provides information for the Internet community. It does not specify an Internet-standard of any kind. Distribution of this memo is unlimited. Abstract The purpose of this document is to provide an overview of the third version of the Internet-Standard Management Framework, termed the SNMP version 3 Framework (SNMPv3). This Framework is derived from and builds upon both the original Internet-Standard Management Framework (SNMPv1) and the second Internet-Standard Management Framework (SNMPv2). The architecture is designed to be modular to allow the evolution of the Framework over time. The document explains why using SNMPv3 instead of SNMPv1 or SNMPv2 is strongly recommended.	internet;simple network management protocol	Jeffrey D. Case;Russ Mundy;David Partain;Bob Stewart	2002	RFC	10.17487/RFC3410	engineering;knowledge management;data mining;management science;information framework	Web+IR	-26.056224640328697	88.53239237406748	16544
e62f1915df8cbf2e4a40f59ec299bda22794d9ac	improving messaging security in structured p2p overlay networks	media streaming applications;peer to peer computing routing streaming media algorithm design and analysis costs bandwidth intelligent networks intrusion detection computer crashes security;computer crashes;peer to peer network;p2p overlay networks;routing;routing algorithms;p2p;correct message delivery;intrusion detection;message forwarding;file sharing applications;structured overlay networks;telecommunication network routing;streaming media;structured overlay networks messaging security improvement p2p overlay networks peer to peer networking technologies peer nodes destination node message forwarding correct message delivery peer to peer overlays routing algorithms media streaming applications file sharing applications;telecommunication security;destination node;routing algorithm;media streaming;overlay network;bandwidth;file sharing;intelligent networks;message authentication;peer to peer networking technologies;peer to peer computing;peer nodes;peer to peer;security;telecommunication security message authentication peer to peer computing telecommunication network routing;peer to peer overlays;messaging security improvement;algorithm design and analysis	Peer-to-peer networking technologies are gaining increasing popularity for file sharing and media streaming applications. To support these set of applications, structured peer-to-peer (P2P) overlay networks may be employed to provide an overlay substrate. In structured P2P overlay networks, peer nodes, content objects and messages are often identified using a set of well defined identifications (Ids.) Objects are stored on peer nodes based on a set of predefined rules. Messages are routed towards the destination node, for example, the root node of the message Id, after an average of h routing hops. In the absence of faults, a high probability of successful message forwarding, i.e., a message is delivered correctly to the destination node, can be achieved even when a large fraction of the peer nodes crash. However, most current overlay networks are not secure. When one or more malicious nodes are presented in the overlay, they can prevent correct message delivery throughout the overlay. This paper studies attacks aimed at preventing correct message delivery in structured peer-to-peer overlays. Several different routing algorithms are analyzed to understand means to improve messaging security without significant additional cost.	algorithm;file sharing;message authentication code;messaging security;overlay network;routing;streaming media;tree (data structure)	Hong Heather Yu;John F. Buford;Madjid Merabti	2007	2007 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2007.4284673	routing;overlay network;computer science;information security;distributed computing;internet privacy;computer network	DB	-8.03021068921479	77.31927521316732	16614
4bb9441f0651aa08d5db8f5af0c45f600a0a63f1	using asynchronous collaborative attestation to build a trusted computing environment for mobile applications		Nowadays, mobile applications like mobile payments become more popular in public life, but users are eager to acquire a trusted execution system to protect its secrets. This paper presents the design, implementation, and evaluation of the Trusted Computing Environment for the Mobile Application, which protects the integrity and confidentiality of the software from the risk of untrusted mobile platform. The mechanism based on TrustZone and non-interactive verifiable computing provides the Asynchronous Collaborative Attestation Mechanism (ACAM) to runtime attest the active system. TrustZone is a strong hardware-feature based isolated execution technique, but it can not defend against the timing attacking. ACAM can effective prevent this kinds of risk by asynchronous remote attestation and reduces the overhead from real-time protection. The security analysis and evaluation shows that the approach has major potential in mobile trusted computing system and provides a higher secure level environment for mobile users.	arm architecture;antivirus software;confidentiality;interactivity;mobile app;mobile operating system;mobile payment;overhead (computing);trusted computing;trusted execution technology;verifiable computing	Lei Zhou;Fengwei Zhang;Guojun Wang	2017	2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)	10.1109/UIC-ATC.2017.8397459	distributed computing;computer science;mobile payment;asynchronous communication;trusted computing;verifiable computing;software;security analysis	Mobile	-44.575997767930104	73.3881732444247	16652
c1b5ec9cd44b86bdecc9288e0c782a0d1432e59a	a distributed dynamic mobility architecture with integral cross-layered and context-aware interface for reliable provision of high bitrate mhealth services		Mobile health (mHealth) has been receiving more and more attention recently as an emerging paradigm that brings together the evolution of advanced mobile and wireless communication technologies with the vision of “connected health” aiming to deliver the right care in the right place at the right time. However, there are several cardinal problems hampering the successful and widespread deployment of mHealth services from the mobile networking perspective. On one hand, issues of continuous wireless connectivity and mobility management must be solved in future heterogeneous mobile Internet architectures with ever growing traffic demands. On the other hand, Quality of Service (QoS) and Quality of Experience (QoE) must be guaranteed in a reliable, robust and diagnostically acceptable way. In this paper we propose a contextand content-aware, jointly optimized, distributed dynamic mobility management architecture to cope with the future traffic explosion and meet the medical QoS/QoE requirements in varying environments.	concerto;digital molecular matter (dmm);functional programming;mhealth;mathematical optimization;mobile ip;performance evaluation;programming paradigm;quality of service;real life;requirement;routing;software deployment;testbed	András Takács;László Bokor	2012		10.1007/978-3-642-37893-5_41	real-time computing;simulation;engineering;computer network	Mobile	-14.094027868145877	86.43786542828657	16677
de2f95a43a24ee545284f2d38046fec6f9ce8bcb	practical homomorphic encryption: a survey	lattices;encryption;graphics processing units cloud computing cryptography data privacy field programmable gate arrays;practical homomorphic encryption;gpu;fpga;public cloud service provider;homomorphic cryptography;data privacy;cryptography;graphics processing units;encryption field programmable gate arrays hardware graphics processing units cloud computing lattices;fpga practical homomorphic encryption cloud computing technology data security public cloud service provider homomorphic cryptography encrypted data computation data privacy graphics processing units gpu field programmable gate arrays;cloud computing technology;encrypted data computation;field programmable gate arrays;cloud computing;hardware;data security	Cloud computing technology has rapidly evolved over the last decade, offering an alternative way to store and work with large amounts of data. However data security remains an important issue particularly when using a public cloud service provider. The recent area of homomorphic cryptography allows computation on encrypted data, which would allow users to ensure data privacy on the cloud and increase the potential market for cloud computing. A significant amount of research on homomorphic cryptography appeared in the literature over the last few years; yet the performance of existing implementations of encryption schemes remains unsuitable for real time applications. One way this limitation is being addressed is through the use of graphics processing units (GPUs) and field programmable gate arrays (FPGAs) for implementations of homomorphic encryption schemes. This review presents the current state of the art in this promising new area of research and highlights the interesting remaining open problems.		Ciara Moore;Máire O'Neill;Elizabeth O'Sullivan;Yarkin Doröz;Berk Sunar	2014	2014 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2014.6865753	information privacy;computer science;theoretical computer science;homomorphic secret sharing;internet privacy;computer security;probabilistic encryption;field-programmable gate array	Arch	-38.58045042644462	68.57330945849179	16713
138ddcec51f6549d500ff9c48fda09c04ebaf25f	tastebuddy-based version selection strategy for bittorrent users against content pollution	version selection;computer network security;motion pictures;version selection bittorrent p2p content pollution;sorting;chunk based file sharing mode;tastebuddy based version selection strategy;pollution tin motion pictures peer to peer computing indexes sorting buildings;p2p;bittorrent users;content pollution;indexes;bittorrent;indexation;content pollution problem;chunk based file sharing mode tastebuddy based version selection strategy bittorrent users content pollution problem p2p networks;p2p networks;peer to peer computing;tin;buildings;peer to peer computing computer network security;pollution	Content pollution problem has attracted broad attention due to its impacts on P2P networks' efficiency and availability. Especially for Bit Torrent users, unmanageable versions of BT torrents and chunk-based file sharing mode make it more difficult to avoid pollution dissemination. In our paper, we propose a smart version selection strategy based on taste buddies to help users select high-quality versions and keep away from polluted ones. Performance evaluation based on real data shows that our approach effectively lowers the probability of selecting polluted versions compared with other strategies.	bittorrent;centralized computing;chunking (computing);database;file sharing;heap pollution;peer-to-peer;performance evaluation;reputation system;swarm	Lingyun Ruan;An'an Luo;Zhen Chen	2011	2011 Third International Conference on Communications and Mobile Computing	10.1109/CMC.2011.116	database index;bittorrent;pollution;telecommunications;tin;computer science;sorting;network security;operating system;peer-to-peer;internet privacy;world wide web;computer security;computer network	DB	-14.082952980507857	73.93264932778042	16728
4bffc40aa41aedc10a66811baeac065be0dd3371	attributetrust a framework for evaluating trust in aggregated attributes via a reputation system	databases;peer to peer computing databases servers public key educational institutions computational modeling access control;attributetrust;confidence relationship properties attributetrust aggregated attributes reputation system attribute based authorization system policy based privacy enhanced framework transitive trust transitive reputation attack resistance attribute provisioning voting mechanism formulation;transitive trust;voting mechanism formulation;service provider;data privacy authorisation;authorisation;policy based privacy enhanced framework;confidence relationship properties;transitive reputation;reputation system;servers;computational modeling;public key;data privacy;attack resistance;attribute based authorization system;attribute aggregation;authoring system;attribute provisioning;access control;peer to peer computing;trust negotiation transitive trust privacy reputation system attribute aggregation;trust negotiation;privacy;aggregated attributes	To enable a rich attribute-based authorization system, it is desirable that a large number of user attributes are available, possibly provided by multiple entities. The user may be required to aggregate his attributes and present them to a service provider to prove he has the right to access some service. In this paper, we present AttributeTrust - a policy-based privacy enhanced framework for aggregating user attributes and evaluating confidence in these attributes. We envision a future where attribute providers will be commonplace and service providers will face the problem of choosing one among multiple attribute providers that can provide the same user attribute. In AttributeTrust, we address this problem by means of a reputation system model based on transitive trust. Entities express confidence in other entities to supply trusted attributes, forming chains from a service provider to different attribute providers. A service provider uses this transitive reputation to decide whether to accept a particular attribute from a specific attribute provider.We discuss how the AttributeTrust model prevents common attacks on reputation systems. AttributeTrust differs from the current approaches by deriving its attack resistance from its specific context of attribute provisioning, its voting mechanism formulation, and unique properties of its confidence relationships.	aggregate data;authorization;entity;provisioning;reputation system	Apurva Mohan;Douglas M. Blough	2008	2008 Sixth Annual Conference on Privacy, Security and Trust	10.1109/PST.2008.28	service provider;information privacy;computer science;access control;data mining;authorization;internet privacy;public-key cryptography;privacy;computational model;computer security;server	DB	-44.099761350990924	61.137383389865086	16729
7e6933e7f522e18666280f26cff65c580853d5fe	an improved protocol for securely solving the shortest path problem and its application to combinatorial auctions		We propose a protocol to securely compute the solution to the (single source) Shortest Path Problem, based on Dijkstra’s algorithm and Secure Multiparty Computation. Our protocol improves state of the art by Aly et al. [FC 2013 & ICISC 2014] and offers perfect security against both semi-honest and malicious adversaries. Moreover, it can easily be adapted to form a subroutine in other combinatorial mechanisms and we show how it can help solve certain combinatorial auctions. Finally, we demonstrate the efficiency of our protocol by experiments and benchmarking.	cache-oblivious algorithm;dijkstra's algorithm;experiment;information-theoretic security;malware;secure multi-party computation;self-propelled particles;semiconductor industry;shortest path problem;subroutine	Abdelrahaman Aly;Sara Cleemput	2017	IACR Cryptology ePrint Archive		mathematical optimization;shortest path problem;combinatorial auction;computer science	Crypto	-42.774762837084054	80.03962640304023	16735
5bebce89792b3896926505704b951e674c3b02b6	analysis of the authenticated cipher morus (v1)	computer and information sciences;morus;authenticated encryption;caesar;cryptanalysis;symmetric key	We present several new observations on the CAESAR candidate MORUS (v1). First, we report a collision on its StateUpdate(S,M) function. Second, we describe a distinguisher in a nonce-reuse scenario with probability 1. Finally, we observe that the differences in some words#R##N#of the state after the initialization have probabilities significantly higher than the random case.We note that the presented results do not threaten the security of the scheme. This is the first external analysis of the authenticated cipher MORUS.	authentication;cipher	Aleksandra Mileva;Vesna Dimitrova;Vesselin Velichkov	2015		10.1007/978-3-319-29172-7_4	computer science;theoretical computer science;computer security;algorithm	Crypto	-43.4583721086106	79.97411481344514	16756
fb4c2c94f47d9b9855cbcbc476557fc7c48f18a4	push mail: a real case of ip convergence in ngn networks	ims protocols;protocols;postal services convergence next generation networking network servers electronic mail smart phones quality of service protocols personal digital assistants web and internet services;electronic mail;ims architecture;ngn networks ip multimedia subsystem network functional architecture multimedia service ims architecture ims protocols push mail technology mobile email application ip convergence;servers;ngn networks;multimedia communication;unified modeling language;mobile handsets;ip convergence;ip networks;network functional architecture;ip multimedia subsystem;mobile email application;multimedia service;push mail technology;multimedia services;multimedia communication electronic mail ip networks	The IP multimedia Subsystem (IMS) is a network functional architecture that is seen as a promising solution for facilitating multimedia service creation and deployment, as well as supporting interoperability and network convergence. The aim of this paper is to present the overall IMS architecture and protocols, as well as the related stakes. Section 2 deals with IMS architecture and IP services. Section 3 gives some developed applications and elucidates push technology and why it has been used in developing mobile email application. The final section presents an outline and the structure of developed Push email application.	email;ip multimedia subsystem;interoperability;network convergence;next-generation network;push technology;software deployment	Asma Ben Letaifa;Sami Tabbane	2009	2009 IEEE 70th Vehicular Technology Conference Fall	10.1109/VETECF.2009.5378955	unified modeling language;embedded system;communications protocol;computer science;operating system;world wide web;ip multimedia subsystem;server;computer network	Robotics	-15.708165926736358	92.01644515487918	16783
6434d830ba1f006eada1ff00bd2b6ad478dddcd5	a survey on privacy protection in blockchain system		Abstract Blockchain, as a decentralized and distributed public ledger technology in peer-to-peer network, has received considerable attention recently. It applies a linked block structure to verify and store data, and applies the trusted consensus mechanism to synchronize changes in data, which makes it possible to create a tamper-proof digital platform for storing and sharing data. It is believed that blockchain can be utilized in diverse Internet interactive systems (e.g., Internet of Things, supply chain systems, identity management, and so on). However, there are some privacy challenges that may hinder the applications of blockchain. The goal of this survey is to provide some insights into the privacy issues associated with blockchain. We analyze the privacy threats in blockchain and discuss existing cryptographic defense mechanisms, i.e., anonymity and transaction privacy preservation. Furthermore, we summarize some typical implementations of privacy preservation mechanisms in blockchain and explore future research challenges that still need to be addressed in order to preserve privacy when blockchain is used.		Qi Feng;Debiao He;Sherali Zeadally;Muhammad Khurram Khan;Neeraj Kumar	2019	J. Network and Computer Applications	10.1016/j.jnca.2018.10.020	the internet;implementation;computer security;anonymity;cryptography;supply chain;ledger;distributed computing;identity management;computer science;database transaction	Security	-45.711790515897334	64.59049915988828	16789
61d06365a832e6d24b3d83fbe1651337b64021a2	a novel protocol for multiparty quantum key management	quantum key management;quantum key backup;quantum cryptography;quantum security group communication	Key management plays a fundamental role in the field of cryptography. In this paper, we propose a novel multiparty quantum key management (QKM) protocol. Departing from single-function quantum cryptography protocols, our protocol has a salient feature in that it accomplishes a complete QKM process. In this process, we can simultaneously realize the functions of key generation, key distribution and key backup by executing the protocol once. Meanwhile, for the first time, we propose the idea of multi-function QKM. Firstly, the secret key is randomly generated by managers via the quantum measurements in $$d$$d-level Bell basis. Then, through entanglement swapping, the secret key is successfully distributed to users. Under circumstances of urgent requirement, all managers can cooperate to recover the users' secret key, but neither of them can recover it unilaterally. Furthermore, this protocol is further generalized into the multi-manager and multi-user QKM scenario. It has clear advantages in the burgeoning area of quantum security group communication. In this system, all group members share the same group key, and group key management is the foundation of secure group communication and hence an important subject of study.	key management	Gang Xu;Xiubo Chen;Zhao Dou;Yixian Yang;Zongpeng Li	2015	Quantum Information Processing	10.1007/s11128-015-1021-1	theoretical computer science;key-agreement protocol;derived unique key per transaction;key generation;pre-shared key;key distribution;physics;quantum cryptography;bb84;quantum mechanics	Theory	-40.9284847220814	73.74064363980315	16813
13bd906f20decc66efe35b8578fdd6d030457fb7	o-bin: oblivious binning for encrypted data over cloud	information retrieval cloud computing cryptography data privacy;oblivious binning process o bin data growth rate data search approximate similarities locality sensitive hashing search process high dimensional search space encrypted data public cloud probable similarity discovery lsh cryptographic primitives data privacy;similarity discovery;cloud;binning;security and privacy;binning similarity discovery security and privacy cloud;encryption cloud computing servers outsourcing data privacy	In recent years, the data growth rate has been observed growing at a staggering rate. Considering data search as a primitive operation and to optimize this process on large volume of data, various solution have been evolved over a period of time. Other than finding the precise similarity, these algorithms aim to find the approximate similarities and arrange them into bins. Locality sensitive hashing (LSH) is one such algorithm that discovers probable similarities prior calculating the exact similarity thus enhance the overall search process in high dimensional search space. Realizing same strategy for encrypted data and that too in public cloud introduces few challenges to be resolved before probable similarity discovery. To address these issues and to formalize a similar strategy like LSH, in this paper we have formalized a technique O-Bin that is designed to work over encrypted data in cloud. By exploiting existing cryptographic primitives, O-Bin preserves the data privacy during the similarity discovery for the binning process. Our experimental evaluation for O-Bin produces results similar to LSH for encrypted data.	approximation algorithm;cloud computing;cryptographic primitive;cryptography;encryption;information privacy;locality of reference;locality-sensitive hashing;outsourcing;product binning;lsh	Mahmood Ahmad;Zeeshan Pervez;Byeong Ho Kang;Sungyoung Lee	2015	2015 IEEE 29th International Conference on Advanced Information Networking and Applications	10.1109/AINA.2015.206	cloud computing;computer science;operating system;data mining;database;internet privacy	DB	-40.043168545181835	66.94019428091222	16870
4c2df43c81cb57f63c60ec8bbbeab75abac13b15	designing multihop wireless backhaul networks with delay guarantees	dsl;routing;interference;spread spectrum communication;spread spectrum communication wimax throughput delay interference costs ip networks routing dsl standardization;ip networks;wimax;standardization;throughput	As wireless access technologies improve in data rates, the problem focus is shifting towards providing adequate backhaul from the wireless access points to the Internet. Existing wired backhaul technologies such as copper wires running at DSL, T1, or T3 speeds can be expensive to install or lease, and are becoming a performance bottleneck as wireless access speeds increase. Longhaul, non-line-of-sight wireless technologies such as WiMAX (802.16) hold the promise of enabling a high speed wireless backhaul as a cost-effective alternative. However, the biggest challenge in building a wireless backhaul is achieving guaranteed performance (throughput and delay) that is typically provided by a wired backhaul. This paper explores the problem of efficiently designing a multihop wireless backhaul to connect multiple wireless access points to a wired gateway. In particular, we provide a generalized link activation framework for scheduling packets over this wireless backhaul, such that any existing wireline scheduling policy can be implemented locally at each node of the wireless backhaul. We also present techniques for determining good interference-free routes within our scheduling framework, given the link rates and cross-link interference information. When a multihop wireline scheduler with worst case delay bounds (such as WFQ or Coordinated EDF) is implemented over the wireless backhaul, we show that our scheduling and routing framework guarantees approximately twice the delay of the corresponding wireline topology. Finally, we present simulation results to demonstrate the low delays achieved using our framework.	backhaul (telecommunications)	Girija J. Narlikar;Gordon T. Wilfong;Lisa Zhang	2006		10.1109/INFOCOM.2006.319	wimax;routing;throughput;real-time computing;digital subscriber line;telecommunications;computer science;wireless network;interference;municipal wireless network;wi-fi array;fixed wireless;spread spectrum;standardization;computer network	Mobile	-9.589910350466827	87.68988937736796	16881
ab0cd49b1d0aac6147bc30f8deca774d76fa0735	protocol for mitigating the risk of hijacking social networking sites	cryptographic protocols;groupware;social networking (online);wireless lan;scrhc protocol;wi-fi;collaborative media;cyber attacks;hijacking;security authentication protocol;self-configuring repeatable hash chains;social networking sites;security protocols;session cookies;session hijacking;social networks	The proliferation of social and collaborative media has been accompanied by an increased level of cyber attacks on social networking and collaboration sites. One serious type of attack is session hijacking attacks which enable the attacker to impersonate the victim and take over his/her networking session(s). In this paper, we present a security authentication protocol for mitigating the risk of hijacking social networking and collaboration sites. The protocol is based on the recognition that users of social and collaborative media connect to their websites using a variety of platforms and connection speeds. To appeal to both mobile devices such as smart phones or tablets using Wi-Fi connections and high-end workstations such as PC's using high-speed connections, a novel Self-Configuring Repeatable Hash Chains (SCRHC) protocol was developed to prevent the hijacking of session cookies. The protocol supports three different levels of caching, giving the user the ability to forfeit storage space for increased performance and reduced workload. Performance evaluation tests are presented to show the effectiveness and flexibility of the SCRHC protocol.	algorithm;authentication protocol;cache (computing);http cookie;markov chain;mobile device;performance evaluation;session hijacking;smartphone;social media;tablet computer;workstation	Jeffrey Cashion;Mostafa A. Bassiouni	2011	7th International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom)		ip hijacking;session hijacking;computer science;link control protocol;cryptographic protocol;internet privacy;world wide web;computer security;computer network;social network	Mobile	-54.107661733745914	67.28200200913213	16894
9b101eb28da86847f6cfe266cdc114eeb0154f99	authenticated route optimization scheme for network mobility (nemo) support in heterogeneous networks	caro protocol;network mobility;ipsec;mobile hotspot	For the efficient communications between mobile or fixed hosts in mobile networks, the route optimization and its security are indispensable. So, the Internet Engineering Task Force introduced a NEMO basic support protocol in 2005. However, this protocol does not provide a strong security between hosts and especially in nested-mobile network it can incur a pinball routing problem. And the previous Proxy Binding Update (PUB) protocol has an advantage that can prove the ownership of address of a host using Multi-key Cryptographically Generated Address (MCGA) which can alleviate a neighbor bombing attack. However, a Mobile Network Node (MNN) belonging to the mobile network which can have low power or limited computing capability may be require burdened costs such as signification and verification of messages. Also, the PUB protocol does not provide the secure message communication architecture between the MNN and its Mobile Router (MR). In this paper we propose a CGA-based Authentication Route Optimization scheme (CARO) in mobile hotspots with heterogeneous networks. The proposed CARO protocol satisfies two problems using IPsec Encapsulating Security Payload (ESP) tunnel, a secret mobile group key, and the CGA. And we also do not require the considerable computing costs to the MNN or a Correspondent Node. In performance analysis, we prove more secure and efficient protocols than the previous protocols using the defense of various attacks and the result of computational cost, etc. Copyright © 2010 John Wiley & Sons, Ltd. In this paper we propose a CGA-based Authentication Route Optimization scheme (CARO) in mobile hotspots with heterogeneous networks. The proposed CARO protocol does not require the considerable computing costs to the MNN or a Correspondent Node (CN) and is more secure and efficient than the previous protocols. Copyright © 2010 John Wiley & Sons, Ltd.	authentication;mathematical optimization;proxy mobile ipv6	Jung-Doo Koo;Seong-Hoon Oh;Dong-Chun Lee	2010	Int. J. Communication Systems	10.1002/dac.1112	ipsec;heterogeneous network;telecommunications;computer science;operating system;computer security;computer network	HPC	-47.75666884409963	74.34340842203628	16896
b7862c7c5e841db4a0965e50fc3c9316281272ba	split message-based anonymity for jxta applications	anonymity;protocols;computer network security;public key;jxta core services split message based anonymity jxta applications open peer to peer protocols specification security improvements p2p networks path based approaches;telecommunication services computer network security peer to peer computing protocols;jxta;telecommunication services;peer to peer computing;protocols proposals peer to peer computing public key context;peer to peer;security;split message;proposals;context;java;split message peer to peer security anonymity jxta java	JXTA is an open peer-to-peer (P2P) protocols specification that, in its about 10 years of history, has slowly evolved to appeal to a broad set of applications. As part of this process, some long awaited security improvements have been included in the latest versions. However, under some contexts, even more advanced security requirements should be met, such as anonymity. Several approaches exist to deploy anonymity in P2P networks, but no perfect solution exists. Even though path-based approaches are quite popular, it is considered that, in dynamic groups, using a split message-based one is better. In this work, we propose ananonymity service for JXTA using such approach. The proposal takes advantage JXTA's core services, in a manner so that it can be easily integrated to existing end applications and services.	cryptography;jxta;message passing;peer-to-peer;pipeline (unix);requirement;timeout (computing)	Joan Arnedo-Moreno;Noemi Perez-Gilabert	2012	2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems	10.1109/CISIS.2012.14	computer science;internet privacy;world wide web;computer network	DB	-48.221637513615725	70.35069843185269	16931
49607818b4a10a802c1dbfe8953451abb69297aa	periodic broadcasting with vbr-encoded video	performance measure;image segmentation;television broadcasting variable rate codes video coding data compression visual communication video on demand packet switching image segmentation;data compression;packet loss;visual communication;packet switching;television broadcasting;variable rate codes;video coding;performance improvement;multimedia communication broadcasting delay video on demand image quality image segmentation image coding smoothing methods prefetching performance loss;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;image quality;video servers periodic broadcasting vbr encoded video near video on demand systems start up latency minimisation high image quality nonuniform segmentation near vod cbr encoded video open loop vbr encoding multiplexing schemes smoothing server buffering client prefetching performance measures packet loss delays link utilization cbr rate ratio vbr average rate;video on demand	We consider designing near video on demand (VoD) sy stems that minimize start-up latency while maintaining high image quality. Recently several re search teams have developed periodic broadcasting techniques for near VoD that use non-uniform segmen tation. These techniques give significant reduction s in start-up latency as compared with more conventio nal uniform segmentation. All of these schemes assume, however, that the videos are CBR-encoded. B ecause a CBR-encoded video has a larger average rate than an open-loop VBR encoding of the same vid o with the same image quality, there is potential to obtain further performance improvements by using VB R video. In this paper we develop a series of multiplexing schemes for the periodic broadcasting of VBR-encoded video. Our multiplexing schemes are based on smoothing, server buffering and client prefetching. There are two key but conflicting performance measures when using VBR video: latency a d packet loss. By introducing small additional delays in our multiplexing schemes, our traced-base d numerical work shows that the schemes can achieve nearly 100% link utilization with negligible packet loss. Our numerical examples show that even when the ratio of the CBR rate to the VBR average rate i s a modest 1.8, start-up latency can be reduced by a factor of four or more for common scenarios.	cpu cache;case-based reasoning;image quality;multiplexing;network packet;numerical analysis;server (computing);smoothing;video;volume boot record	Despina Saparilla;Keith W. Ross;Martin Reisslein	1999		10.1109/INFCOM.1999.751379	data compression;image quality;real-time computing;telecommunications;computer science;image segmentation;packet loss;packet switching;visual communication;computer network	Networks	-5.420179547091217	100.52407988556148	16933
65be384297ccce25d6737e61a9538a31c7b344d5	from wireless power transfer to wireless powered communications		This article consists only of a collection of slides from the author's conference presentation.	internet of things;phy (chip);protocol stack;smart tv;smart city;waveform;williams pinball controller	Ioannis Krikidis	2017	2017 24th International Conference on Telecommunications (ICT)	10.1109/ICT.2017.7998282	wireless network;computer network;fixed wireless;wi-fi array;wireless wan;computer science;wireless broadband;key distribution in wireless sensor networks;wi-fi;base transceiver station;telecommunications	Robotics	-16.14799178843896	88.74680835687123	16936
8adc3cd6c006c03f3be06ffe79f816a0226313ca	large-scale multi-party counting set intersection using a space efficient global synopsis	conference paper	Privacy-preserving set intersection (PPSI) of very large data sets is increasingly being required in many real application areas including health-care, national security, and law enforcement. Various techniques have been developed to address this problem, where the majority of them rely on computationally expensive cryptographic techniques. Moreover, conventional data structures cannot be used efficiently for providing count estimates of the elements of the intersection of very large data sets. We consider the problem of efficient PPSI by integrating sets from multiple (three or more) sources in order to create a global synopsis which is the result of the intersection of efficient data structures, known as Count-Min sketches. This global synopsis furthermore provides count estimates of the intersected elements. We propose two protocols for the creation of this global synopsis which are based on homomorphic computations, a secure distributed summation scheme, and a symmetric noise addition technique. Experiments conducted on large synthetic and real data sets show the efficiency and accuracy of our protocols, while at the same time privacy under the Honest-but-Curious model is preserved.	analysis of algorithms;computation;convex set;cryptography;data structure;emoticon;experiment;scalability;synthetic data;synthetic intelligence;video synopsis	Dimitrios Karapiperis;Dinusha Vatsalan;Vassilios S. Verykios;Peter Christen	2015		10.1007/978-3-319-18123-3_20	computer science;theoretical computer science;algorithm	ML	-39.65713081797582	64.57382129049617	16954
2ae6698077a2e6bc0e8cd33bf6aa4968a9477e3e	fair payments for outsourced computations	communications society;volunteer computing;financial data processing;protocols;outsourcing;networked set top boxes;security of data financial data processing outsourcing remuneration;personal communication networks;mobile device;remuneration;ieee communications society;usa councils;outsourced computations;secure payments;payment transactions;computer networks;indexes;cryptography;batteries;jobs remuneration;mobile handsets;job computation;us department of transportation;ad hoc networks;jobs remuneration fair payments outsourced computations volunteer computing networked set top boxes secure payments job computation payment transactions;book reviews;computer networks outsourcing us department of transportation cellular phones communications society usa councils mobile computing ad hoc networks personal communication networks batteries;mobile computing;fair payments;security of data;set top box;cellular phones	Initiated by volunteer computing efforts, the computation outsourcing problem can become a compelling application for networked set-top-boxes and mobile devices. In this paper we extend such environments with the ability to provide secure payments in exchange for outsourced CPU cycles. Previous contributions in wired networks have almost exclusively tackled only one side of the problem -- offering incentives for volunteer participation and preventing worker laziness. This makes sense in static environments where reputable outsourcers have little to gain from incorrectly rewarding honest participation. However, this assumption is no longer valid in ad hoc environments, where unique identities are difficult to provide and anyone can outsource computations. In this paper we propose a solution that simultaneously ensures correct remuneration for jobs completed on time and prevents worker laziness. Our solution relies on an offline bank to generate and redeem payments; the bank is oblivious to interactions between outsourcers and workers. In particular, the bank is not involved in job computation or verification. Our experiments show that the solution is efficient: the bank can perform hundreds of payment transactions per second and the overheads imposed on outsourcers and workers are negligible.	central processing unit;electronic funds transfer;experiment;formal verification;hoc (programming language);interaction;mesh networking;mobile device;online and offline;outsourcing;secret sharing;secure multi-party computation;transactions per second;volunteer computing	Bogdan Carbunar;Mahesh V. Tripunitara	2010	2010 7th Annual IEEE Communications Society Conference on Sensor, Mesh and Ad Hoc Communications and Networks (SECON)	10.1109/SECON.2010.5508202	embedded system;telecommunications;computer science;cryptography;operating system;mobile device;mobile computing;computer security;outsourcing;computer network	Mobile	-43.3025919077566	70.30077241964254	17001
4f0e93247edb68d8930c5b2408a4b5bdff16a08b	the importance of port security system in the implementation of transport modal-shift			transport layer security	Drazen Zgaljic;Paola Badurina-Tomic;Matej Plenca	2016		10.3233/978-1-61499-699-6-106	computer network;modal;port security;computer science	HPC	-23.111176082819554	87.56883183491307	17010
373060f4d64effc9f66f853ef1dd31df69275172	rfid ownership transfer with positive secrecy capacity channels	ownership transfer;epcglobal gen2;rfid;trusted third party	RFID ownership transfer protocols (OTPs) transfer tag ownership rights. Recently, there has been considerable interest in such protocols; however, guaranteeing privacy for symmetric-key settings without trusted third parties (TTPs) is a challenge still unresolved. In this paper, we address this issue and show that it can be solved by using channels with positive secrecy capacity. We implement these channels with noisy tags and provide practical values, thus proving that perfect secrecy is theoretically possible. We then define a communication model that captures spatiotemporal events and describe a first example of symmetric-key based OTP that: (i) is formally secure in the proposed communication model and (ii) achieves privacy with a noisy tag wiretap channel without TTPs.	information-theoretic security;otp gene;protocols documentation;radio frequency identification device;radio-frequency identification;symmetric-key algorithm;trusted third party;vendor information documentation	Jorge Munilla;Mike Burmester;Alberto Peinado;Guomin Yang;Willy Susilo	2016		10.3390/s17010053	radio-frequency identification;trusted third party;computer science;internet privacy;computer security	Security	-39.60906793373897	72.61308413004623	17037
f2bfed32c28b25076ceaa4a8897f050932ea9c88	the foundations of cryptography - volume 1, basic techniques			cryptography	Oded Goldreich	2001			cryptography;theoretical computer science;computer science	Crypto	-41.6533072592791	79.43104557805391	17088
3380aa549d6cc04ffaa79cff86f431df7b81075e	random block verification: improving the norwegian electoral mix-net		The VALG project is introducing e-voting to municipal and county elections to Norway. Part of the e-voting system is a mix-net along the lines of Puiggalí et al. a mix-net which can be efficiently verified by combining the benefits of optimistic mixing and randomized partial checking. This paper investigates their mix-net and proposes a verification method which improves both efficiency and privacy compared to Puiggalí et al.	mix network;optimistic replication;randomized algorithm	Denise Demirel;Hugo L. Jonker;Melanie Volkamer	2012			business;norwegian;voting;microeconomics	NLP	-42.19680850447368	73.1624655636747	17101
bdc8dd384a2096f52407f4f0dd16052795a316fa	a heuristic algorithm for multicast routing in sparse-splitting optical wdm networks	routing optical fiber networks heuristic algorithms optical wavelength conversion multicast communication biomedical optical imaging complexity theory;multicast routing algorithm heuristic algorithm sparse splitting optical wdm networks optical splitters network nodes;optical fibre networks;telecommunication network routing;wavelength division multiplexing optical fibre networks telecommunication network routing;wavelength division multiplexing	Multicast routing in optical WDM networks is investigated in the current paper in the presence of optical splitters only at a fraction of the network nodes. This work presents a novel multicast routing algorithm for sparse-splitting networks that is specifically designed for this category of networks. The proposed algorithm is compared with the most efficient multicast routing algorithms for sparse networks that are found in the literature through examples and simulations. Performance results show that the proposed approach achieves an important reduction on the average cost of the calculated multicasting trees, compared to the existing heuristics.	algorithm;heuristic (computer science);link-state routing protocol;multicast;provisioning;routing;simulation;sparse matrix;wavelength-division multiplexing	Costas K. Constantinou;Georgios Ellinas	2013	2013 17th International Conference on Optical Networking Design and Modeling (ONDM)		wireless routing protocol;routing;shared risk resource group;static routing;multicast;hierarchical routing;telecommunications;protocol independent multicast;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;distance-vector routing protocol;distributed computing;routing protocol;link-state routing protocol;distance vector multicast routing protocol;source-specific multicast;optical performance monitoring;xcast;wavelength-division multiplexing;computer network	EDA	-4.5786594486558	82.6461175353175	17110
913cfe3685edf2929bc481cd58f0d250f2baefbb	bertrand games between multi-class queues	delay costs pricing quality of service web and internet services stability queueing analysis communication system traffic control traffic control sufficient conditions;game theory;nash equilibrium;service provider;pricing;queueing theory;resource management;queueing theory game theory quality of service;differentiated service;data mining;qos bertrand games network providers multiclass queueing model post prices elastic traffic user traffic quality of service network services market nash equilibrium differentiated services;servers;queueing model;games;quality of service;network services	We develop a framework to study differentiated services when there are competing network providers. We adopt a multi-class queueing model, where providers post prices for various service classes. Traffic is elastic and users are Quality of Service (QoS)-sensitive, and choose a queue and a class with one of the providers. We model the relationship between capacity, QoS and prices offered by service providers in a competitive network services market. We establish sufficient conditions for existence of Nash equilibrium in the multi-class queueing game.	bertrand (programming language);differentiated services;nash equilibrium;quality of service;queue (abstract data type);queueing theory	Parijat Dube;Rahul Jain	2009	Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference	10.1109/CDC.2009.5400900	service provider;pricing;games;game theory;mobile qos;quality of service;differentiated service;computer science;resource management;queueing theory;nash equilibrium;server;computer network	Metrics	-6.891062461508172	95.14340504332363	17127
be50749be530c6fefccf1f14c0136d8191f44988	a security weakness in abdalla et al.'s generic construction of a group key exchange protocol	group key exchange;protocol compiler;key confirmation;key exchange;cryptography;implicit key authentication	In TCC u002707, Abdalla et al. presented a protocol compiler that transforms any authenticated 2-party key exchange protocol into an authenticated group key exchange (GKE) protocol. Abdalla et al.u0027s compiler is certainly elegant in its genericness, symmetry, simplicity and efficiency. However, this compiler is not as secure as claimed. Under a reasonable assumption, the GKE protocol constructed by the compiler (from a 2-party protocol) fails to achieve implicit key authentication. We here reveal this security problem with the compiler and show how to address it.	group key;key exchange	Junghyun Nam;Juryon Paik;Dongho Won	2011	Inf. Sci.	10.1016/j.ins.2010.09.011	oakley protocol;key exchange;computer science;cryptography;key-agreement protocol;distributed computing;internet privacy;computer security;statistics	AI	-41.34809964469236	75.9181636190307	17128
3cb4c7b852bf656a92255ffacb6614e3d953f98a	the impact of router outages on the as-level internet		We propose and evaluate a new metric for understanding the dependence of the AS-level Internet on individual routers. Whereas prior work uses large volumes of reachability probes to infer outages, we design an efficient active probing technique that directly and unambiguously reveals router restarts. We use our technique to survey 149,560 routers across the Internet for 2.5 years. 59,175 of the surveyed routers (40%) experience at least one reboot, and we quantify the resulting impact of each router outage on global IPv4 and IPv6 BGP reachability.  Our technique complements existing data and control plane outage analysis methods by providing a causal link from BGP reachability failures to the responsible router(s) and multi-homing configurations. While we found the Internet core to be largely robust, we identified specific routers that were single points of failure for the prefixes they advertised. In total, 2,385 routers -- 4.0% of the routers that restarted over the course of 2.5 years of probing -- were single points of failure for 3,396 IPv6 prefixes announced by 1,708 ASes. We inferred 59% of these routers were the customer-edge border router. 2,374 (70%) of the withdrawn prefixes were not covered by a less specific prefix, so 1,726 routers (2.9%) of those that restarted were single points of failure for at least one network. However, a covering route did not imply reachability during a router outage, as no previously-responsive address in a withdrawn more specific prefix responded during a one-week sample. We validate our reboot and single point of failure inference techniques with four networks, finding no false positive or false negative reboots, but find some false negatives in our single point of failure inferences.	adversary (cryptography);algorithm;border gateway protocol;causal filter;computer;control plane;customer edge;downtime;forwarding plane;fragment identifier;hash function;instability;interconnection;internet;linux;missile guidance;multihoming;network packet;network security;reachability;reboot (computing);reliability engineering;router (computing);routing;side-channel attack;single point of failure;software deployment;traceroute	Matthew J. Luckie;Robert Beverly	2017		10.1145/3098822.3098858	distributed computing;single point of failure;computer science;computer network;ipv6;router;real-time computing;ipv4;reboot;one-armed router;default-free zone;core router	Networks	-12.703355325597228	78.89147544230758	17134
58c60e51e159780c2217079d11cf4d3d1a0463b3	evaluation of a massively parallel architecture for network security applications	multiprocessor interconnection networks;computer engineering;experimental analysis;experimental analysis massively parallelized processing architecture mppa ambric malware detection covert timing channel entropy function;encryption;mppa;entropy function;network security;ambric;computer science evaluation of a massively parallel architecture for network security applications university of california;covert timing channel;cyber security threats;symmetric encryption engine;davis dipak ghosal mason;fpga;ambric parallel processing device;parallel architectures;program processors cryptography field programmable gate arrays invasive software multiprocessor interconnection networks parallel architectures;malware;cryptography;guarding enterprise networks;parallel architectures inspection computer security field programmable gate arrays computer architecture parallel processing computer networks concurrent computing data security timing;programmable processor interconnection;invasive software;ip networks;massively parallelized processing architecture;entropy;symmetric encryption engine network security guarding enterprise networks cyber security threats fpga cpu mppa massively parallelized processing architecture ambric parallel processing device programmable processor interconnection malware detection covert timing channel;blake christopher;parallel architecture;field programmable gate arrays;cpu;malware detection;program processors;massively parallelized processing architecture mppa;hardware;massively parallel processing	Network security applications such as to detect malware, security breaches, and covert channels require packet inspection and processing. Performing these functions at very high network line rates and low power is critical to safe guarding enterprise networks from various cyber-security threats. Solutions based on FPGA and single or multi-core CPUs has several limitations with regards to power and the ability to match the ever increasing line rates. This paper describes a MPPA (Massively Parallelized Processing Architecture) framework based on the Ambric parallel processing device that can speed up computation of network packet processing and analysis tasks. This is accomplished with a programmable processor interconnection that enables parallelizing the application and replication of data through channels. In this paper, we consider three network security applications - detecting malware, detecting covert timing channels, and a symmetric encryption engine. Experimental analyses of parallel implementations of the detection algorithms show that MPAA can easily achieve throughput greater than 1Gbps with low power usage.	ambric;central processing unit;computation;computer security;covert channel;encryption;field-programmable gate array;gigabit;interconnection;malware;massively parallel processor array;multi-core processor;network packet;network security;parallel computing;parallel programming model;sensor;symmetric-key algorithm;throughput;timing channel	Blake C. Mason;Dipak Ghosal;Cherita L. Corbett	2010	2010 18th Euromicro Conference on Parallel, Distributed and Network-based Processing	10.1109/PDP.2010.20	parallel computing;computer science;theoretical computer science;network security;operating system;distributed computing;field-programmable gate array;computer network	Arch	-7.750907432055249	66.54136121298647	17137
cad50ef9b4bdfec2a254652d937f7296b71dd88d	performance analysis of video storage based on clustered nas architecture	video databases;architecture systeme;video a peticion;video a la demande;base donnee video;system performance;user support;network atteched storage;video on demand;analyse performance;performance analysis;performance model;arquitectura sistema;system architecture;analisis eficacia	Previous studies on video storage servers focused on improving the disk throughput and reducing the server buffer size. In this paper, we propose a novel clustered NAS architecture to store the video files so as to improve the users supported and reduce the reponse time that clients have to wait. One performance model is presented to give the relationship among the factors that will affect the system performance. Through the model we can get the method to determine the size of data block that video file stripe to and allocate the requests arrived.		Yong Hu;Changsheng Xie	2001		10.1007/3-540-45453-5_131	embedded system;real-time computing;simulation;computer science;operating system;computer performance;systems architecture	HPC	-14.865325988699427	70.75511328616781	17151
ed87e58e10086d78877ebb07051cc7b487cfb881	new efficient non-malleable commitment schemes	seals;zero knowledge proof;complexity theory;e commerce;information technology;cryptographic protocols;communication complexity;cryptographynon malleablecommitment;cryptographic protocol;civil engineering;computational complexity;cryptography;computer science;cryptography computational complexity seals information technology civil engineering cryptographic protocols complexity theory computer science;commitment scheme	Non-malleable commitment is recently one of research focuses in international cryptographic community. It has many important applications in e-commerce, and plays important role in constructing other cryptographic protocols. Most existing non-malleable commitment schemes are constructed by requiring that a committer proves, by zero-knowledge proof, that he knows his committed secret. The attached zero-knowledge proof process makes existing non-malleable commitments have higher computational and communication complexity. More efficient schemes are appealing. This paper constructs three new efficient non-malleable commitment schemes which do not require that a committer proves he knows his committed secret by zero-knowledge proof, but rather require a committer proves, by other arguments, that he does know the secret at the same time he makes commitment. These non-malleable commitment schemes, without zero-knowledge proof, are much more efficient.	commitment ordering;committer;communication complexity;cryptographic protocol;cryptography;e-commerce;zero-knowledge proof	Jiawei Dou;Shundong Li	2007	Sixth International Conference on Advanced Language Processing and Web Information Technology (ALPIT 2007)	10.1109/ALPIT.2007.109	cryptographic primitive;commitment scheme;computer science;theoretical computer science;distributed computing;computer security	Theory	-40.82845803813493	76.25861002268527	17154
68cb39188dc7ae16b60e371017dbfde89a45927e	gpmip: a proxy mobile ipv6 based global mobility management architecture and protocol	wireless links;fluid flow mobility model;residence time;cost function;fluid flow;location update;mobility management;global mobility management;hierarchical mobile ipv6;mobile node;mobility model;proxy mobile ipv6	This paper specifies a Proxy Mobile IPv6 based global mobility management architecture and protocol procedure, named GPMIP. In GPMIP, the mobility management is performed by network entity other than mobile node itself. The benefit is the elimination of the wireless link data delivery tunnel overhead between the mobile node and the access router. To compare with well known Hierarchical Mobile IPv6 mobility management protocol, the location update, packet delivery, and total cost functions generated by a mobile node during its average domain residence time in each protocol are formulated based on fluid flow mobility model. Then, the impacts of various system parameters on the cost functions are analyzed, respectively. The analysis results indicate that the proposed Proxy Mobile IPv6 based global mobility management protocol can guarantee lower total costs.	mobile ip;network packet;overhead (computing);proxy mobile ipv6;router (computing)	Huachun Zhou;Hongke Zhang;Yajuan Qin;Hwang-Cheng Wang;Han-Chieh Chao	2008		10.1145/1506270.1506351	telecommunications;computer science;mobility model;computer security;residence time;mobile ip;computer network;fluid dynamics	Mobile	-10.614014987635112	89.32799373413498	17195
3da667f940d754a89adbe756e478b3a4adda67ec	qos-sensitive transport of real-time mpeg video using adaptive forward error correction	performance evaluation;multimedia on the internet;mpeg video;real time;quality of service transport protocols forward error correction communication system traffic control redundancy timing stability analysis impedance real time systems workstations;code standards;network and resource management;transport protocols;video coding;telecommunication traffic;forward error correction;congestion control;telecommunication standards;multimedia communication;quality of service control scheduling;quality of service;multimedia communication video coding code standards telecommunication standards real time systems quality of service forward error correction transport protocols telecommunication traffic performance evaluation;adaptive redundancy control real time mpeg video adaptive forward error correction adaptive end to end protocol quality of service dynamic networks user specified qos timing constraints retransmission based congestion control packet level fec protocol afec redundancy transport protocol application layer protocol mafec unix workstations performance packet drops delays traffic burstiness;dynamic networks;real time systems;time constraint	"""This paper presents an adaptive end-to-end protocol for quality of service (QoS)-sensitive transport of real-time MPEG video using packet-level forward error correction in dynamic networks. The objective is to facilitate a user-speciied QoS end-to-end|i.e., without special network support|for real-time MPEG video traac whose timing constraints rule out the use of retransmission-based congestion control and QoS pro-visioning schemes. In previous work, we proposed an adaptive packet-level FEC protocol called AFEC and analyzed its properties with respect to optimality and stability. The control problem is nontrivial due to the fact that increased redundancy, beyond a certain point, can \back-re"""" resulting in self-induced congestion which impedes the timely recovery of information (e.g., MPEG video frames) at the receiver. In this paper, we extend the previous work by implementing and customizing AFEC to the transport of real-time MPEG video, realizing the system as a transport and application layer protocol called MAFEC running end-to-end on UNIX workstations, and measuring its performance over controlled network environments. We show that MAFEC is able to eeectively hide potentially adverse network eeects such as packet drops and delays stemming from traac burstiness and nonsta-tionary structural changes using adaptive redundancy control, exporting a constant-QoS service commensurate with user-speciied, desired QoS."""	analog front-end;end-to-end principle;error detection and correction;forward error correction;moving picture experts group;network congestion;network packet;real-time clock;real-time transcription;retransmission (data networks);stemming;unix;workstation	Kihong Park;Wei Wang	1999		10.1109/MMCS.1999.778482	real-time computing;quality of service;telecommunications;computer science;operating system;forward error correction;network congestion;transport layer;computer network	Embedded	-5.558534032636971	99.05369428257883	17196
57170167e1b079faacd8200f8d44a2254848ac83	sketches characterization and compression for nomadic computing	compression algorithm;groupware;mobile handsets performance evaluation image coding mobile communication collaboration pixel compression algorithms;image coding;sketch characterization;mobile device;performance evaluation;peer applications;data compression;nomadic computing;peer to peer collaborative systems nomadic computing mobile computing;compression algorithms;real time;collaboration;mobile computer;wireless ad hoc network;sketch characterization nomadic computing mobile computing wireless ad hoc networks collaborative media freehand writing data overflow peer applications sketch compression algorithm mobile devices data traffic image compression human perception;collaborative system;data traffic;sketch compression algorithm;image compression;mobile ad hoc networks;pixel;peer to peer collaborative systems;mobile communication;mobile handsets;collaborative media;compression ratio;freehand writing;peer to peer computing data compression groupware image coding mobile ad hoc networks mobile computing;peer to peer computing;mobile computing;peer to peer;human perception;mobile devices;data overflow;wireless ad hoc networks	Nomadic computing often refers to people using computer support working anywhere, anytime and not necessarily attached to a specific location or time of the day. Mobile computing and wireless ad-hoc networks are important elements in this kind of scenarios. Nowadays it is common to see architects, engineers, geologists and/or designers working on the field and sharing ideas on a collaborative media using sketches and freehand writing. On this scenario, data overflow among the peer applications often happens, since the sketches have to be distributed among all participants in real time. This paper presents a work on characterization and compression algorithms for sketches, with and without loss of information, to be used on mobile devices, in order to reduce the data traffic. We focused our study on three parameters of the algorithms: time required characterizing and compressing the sketch, size of the resulting information and human perceived of lost information. Our results present algorithms with a compression ratio lower than 1% the size of the original image without information loosing under human perception.	adobe freehand;anytime algorithm;computer;data compression;hoc (programming language);mobile computing;mobile device;technical support;ubiquitous computing	Nelson Baloian;Ramon Cruzat;Richard Ibarra;Javier Bustos-Jiménez	2011	Proceedings of the 2011 15th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2011.5960113	data compression;computer science;operating system;database;distributed computing;multimedia;mobile computing;world wide web	HCI	-20.52307253486934	76.07747270385428	17200
5e162bc57e5752dfac565406235103417dbe7feb	scheduling internet of things applications in cloud computing		Internet of Things (IoT) is one of the greatest technology revolutions in the history. Due to IoT potential, daily objects will be consciously worked in harmony with optimized performances. However, today, technology is not ready to fully bring its power to our daily life because of huge data analysis requirements in instant time. On the other hand, the powerful data management of cloud computing gives IoT an opportunity to make the revolution in our life. However, the traditional cloud computing server schedulers are not ready to provide services to IoT because IoT consists of a number of heterogeneous devices and applications which are far away from standardization. Therefore, to meet the expectations of users, the traditional cloud computing server schedulers should be improved to efficiently schedule and allocate IoT requests. There are several proposed scheduling algorithms for cloud computing in the literature. However, these scheduling algorithms are limited because of considering neither heterogeneous servers nor dynamic scheduling approach for different priority requests. Our objective is to propose Husnu S. Narman husnu@ou.edu 1 Holcombe Department of Electrical and Computer Engineering, Clemson University, Clemson, SC, 29634, USA 2 Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology, Zahir Raihan Rd, Dhaka, 1000, Bangladesh 3 School of Computer Science, University of Oklahoma, Norman, OK, 73019, USA dynamic dedicated server scheduling for heterogeneous and homogeneous systems to efficiently provide desired services by considering priorities of requests. Results show that the proposed scheduling algorithm improves throughput up to 40 % in heterogeneous and homogeneous cloud computing systems for IoT requests. Our proposed scheduling algorithm and related analysis will help cloud service providers build efficient server schedulers which are adaptable to homogeneous and heterogeneous environments byconsidering systemperformancemetrics, such as drop rate, throughput, and utilization in IoT.	algorithm;cloud computing;computer engineering;computer science;consciousness;dedicated hosting service;internet of things;performance;requirement;scheduling (computing);server (computing);throughput	Husnu S. Narman;Md. Shohrab Hossain;Mohammed Atiquzzaman;Haiying Shen	2017	Annales des Télécommunications	10.1007/s12243-016-0527-6	real-time computing;computer science;distributed computing;round-robin scheduling;computer network	HPC	-24.251344835731015	68.12301413095919	17215
3a69932c79841ef0fc3f995afdeffdee99cc392b	reflective channel hierarchies	publish subscribe;work in progress;middleware;operant conditioning	Hierarchical channel structures are used to create granular sub-channels from a parent channel. Utilized in routing situations that are more or less static, they require that the channel namespace schema be both well defined and universally understood. The publish/subscribe messaging model currently requires a message publisher to place messages into a specific channel within the hierarchy. A relocation of responsibility for channel selection logic from the publishing client to the middleware service would open up static channel hierarchies to the application of reflective techniques. This shift in responsibilities enables the service more control over the definition, creation and maintenance of the channel hierarchy. The service is now able to apply reflective and adaptive techniques to dynamically adapt, grow and improve the hierarchy to better meet the needs of its changing environment and operating conditions. This paper describes work-in-progress on the definition of reflective channel hierarchies.	middleware;publish–subscribe pattern;relocation (computing);routing	Edward Curry;Desmond Chambers;Gerard Lyons	2003			hierarchy;psychology;middleware;communication channel;operant conditioning;knowledge management	Mobile	-20.82265026225211	81.65211774678885	17221
2262313513d4252c5ed06a4713ab306d8f4e5f3e	fast handover latency analysis in proxy mobile ipv6	analytical models;working group;data packet;mobility management mobile radio;fast handover latency;transport protocols ip networks mobile computing mobility management mobile radio;pmipv6 protocol operation fast handover latency proxy mobile ipv6 mobile node tunneling overhead pmipv6 handover process service interruption period data packet;ieee communications society;over the air;pmipv6 protocol operation;computer hacking;manganese;transport protocols;service interruption period;tunneling overhead;mobile communication;pmipv6 handover process;cities and towns;ip networks;mobile node;vehicles;mobile computing;manganese analytical models computer hacking mobile communication cities and towns ieee communications society vehicles;proxy mobile ipv6	In Proxy Mobile IPv6 (PMIPv6), any involvement by the Mobile Node (MN) is not required so that any tunneling overhead could be removed from over-the-air. However, during the PMIPv6 handover process, there still exists a service interruption period during which the MN is unable to send or receive data packets because of PMIPv6 protocol operations. To reduce the handover latency, Fast Handover for PMIPv6 (PFMIPv6) is being standardized in the IETF MIPSHOP working group. In PFMIPv6, however, handover initiation can be false, resulting in the PFMIPv6 handover process done so far becoming unnecessary. Therefore, in this paper, we provide a thorough analysis of the handover latency in PFMIPv6, considering the false handover initiation case. The analysis is very meaningful to obtain important insights on how PFMIPv6 improves the handover latency. Further, our analytical study is verified by simulation results.	interrupt;network packet;numerical analysis;overhead (computing);proxy mobile ipv6;randomness;simulation;tunneling protocol	Mun-Suk Kim;Sukyoung Lee;David Cypher;Nada Golmie	2010	2010 IEEE Global Telecommunications Conference GLOBECOM 2010	10.1109/GLOCOM.2010.5684107	real-time computing;working group;telecommunications;computer science;manganese;operating system;mobile computing;soft handover;computer network	Mobile	-10.423347220193007	89.94871638410702	17225
f5ac9a3e9356f7186ec6401209f55d1002391188	internet technologies and infrastructure for asia-wide distance education	virtual networks;multicast communication;distance education;virtual private networks bandwidth allocation computer aided instruction distance learning internet multicast communication quality of service telecommunication network routing transport protocols;bandwidth allocation;computer aided instruction;distance learning;transport protocols;internet technology;internet;telecommunication network routing;overlay network;quality of service;udlr technology internet technologies asia wide distance education wide coverage high quality network 13 mbps unidirectional broadcast satellite ipv6 multicast overlay network ipv6 tunnel technology virtual network bandwidth optimization bandwidth scalability qos policy routing soi asia environment;internet educational technology distance learning asia satellite broadcasting bandwidth ip networks joining processes scalability routing;virtual private networks	SOI Asia project aims at Asia-wide distance education development with its design emphasizing on new model of network technologies that provides wide-coverage high-quality network to support high-quality distance education instead of relying on the available Internet connectivity with inadequate quality. A 13-Mbps unidirectional broadcast satellite covers Asia region enabling lecture sharing among student sites. IPv6 multicast overlay network is established by UDLR and IPv6 tunnel technologies to create a virtual network connecting lecturer-site and student-sites on top of network heterogeneity. Bandwidth optimization and scalability are achieved by IPv6 multicast. QoS using policy routing and ALTQ utilizes and manages bandwidth to ensure high quality lectures. Experiment results show that SOI Asia environment delivers better quality streams with stable rate, high correlation, low data loss and jitter compared to the available Internet connectivity. These design aspects, technology model and experimental results can be the considerations of future region-wide distance education development	communications satellite;display resolution;internet;mathematical optimization;multicast;network model;overlay network;requirement;routing;scalability;silicon on insulator	Patcharee Basu;Achmad Husni Thamrin;Shoko Mikawa;Keiko Okawa;Jun Murai	2007	2007 International Symposium on Applications and the Internet	10.1109/SAINT.2007.15	distance education;overlay network;telecommunications;computer science;distributed computing;world wide web;computer network	Networks	-8.03183648098824	89.34872064310116	17246
ea9c57b21672d1378fff33e9da097d885f350379	restricting edf migration on uniform heterogeneous multiprocessors	systeme temps reel;sistema temporizado;multiprocessor;migration;processor scheduling;earliest deadline first;timed system;periodicite;periodicity;reglamento edf;periodicidad;periodic tasks;uniform heterogeneous multiprocessors;ordonnancement edf;systeme temporise;edf;real time system;sistema tiempo real;ordonnancement processeur;multiprocesador;hard real time systems;multiprocesseur	Restricted migration of periodic and sporadic tasks on uniform heterogeneous multiprocessors is considered. Migration between different processors of a multiprocessor causes overhead that may be prohibitively high for real-time systems, where accurate timing is essential. Nonetheless, periodic tasks, which generate jobs at regular intervals, may be able to migrate without causing overhead if the migration can be controlled. In particular, if consecutive jobs of the same task do not share any data then they may be allowed to execute on different processors without incurring migration overhead — i.e.,restricted migration may be permitted. On uniform multiprocessors, each processor has an associated speed. A job executing on a processor of speed s for t units of time will performs× t units of work. A utilization-based test for restricted migration on uniform multiprocessors is presented where each processor schedules jobs using the earliest deadline first (EDF) scheduling algorithm. RÉSUMÉ.Nous considérons des migrations restreintes pour des tâches périodiques et sporadiques pour des plates-formes hétérogènes. Les migrations entre processeurs différents causent une surcharge qui peut potentiellement être importante pour des systèmes temps réel, où la prédictabilité est essentielle. Néanmoins, les tâches périodiques, qui génèrent des travaux à intervalles réguliers, peuvent migrer sans causer une surcharge, si les migrations sont contrôlées. En particulier, si des travaux consécutifs de la même tâche ne partagent pas de données, ils peuvent s’exécuter sur des processeurs différents sans induire une surcharge lors de la migration, c’est-à-dire, qu’une migration restreinte peut être autorisée. Sur des plates-formes uniformes, chaque processeur possède une vitesse. Un travail s’exécutant sur un processeur de vitesses pendantt unités de temps progressera de s × t unités de travail. Un test orienté utilisation, pour les migrations restreintes et les plates-formes uniformes est présenté où chaque processeur ordonnance les travaux avec la stratégie earliest deadline first (EDF).	algorithm;central processing unit;earliest deadline first scheduling;heisenbug;job stream;linear algebra;meme;multiprocessing;overhead (computing);real-time clock;real-time computing;sans institute;scheduling (computing)	Shelby Funk;Sanjoy K. Baruah	2005	Technique et Science Informatiques	10.3166/tsi.24.917-938	earliest deadline first scheduling;multiprocessing;real-time operating system;computer science;human migration;operating system;algorithm	Embedded	-10.832286953371698	62.82139065288903	17269
2dd0f01bf84493ad3b4e3ba738fbdecd0cb334bc	mitigating information asymmetries to achieve efficient peer-to-peer queries	selfish network;peer-to-peer network infrastructure;data item;realistic peer-to-peer network;query performance;query strategy;selfish peer-to-peer network;mitigating information asymmetries;achieve efficient peer-to-peer queries;peer-to-peer query;particular data item;asymmetric information;distributed algorithms;information asymmetry;private information;computational complexity	Querying for a particular data item is perhaps the most important feature to be supported by peer-to-peer network infrastructures, and receives the most research attention in recent literature. Most existing work follows the line of designing decentralized algorithms to maximize the performance of peer-to-peer queries. These algorithms often have specific rules that peer nodes should adhere to (e.g., placement of data items on particular nodes), and thus assume that peers are strictly cooperative. However, in realistic peer-to-peer networks, selfish and greedy peer nodes are the norm, and query strategies degenerate to random or flooding based searches. In this paper, we explore the design space with respect to query efficiency in selfish peer-to-peer networks where nodes have asymmetric information, and apply the signaling mechanism from microeconomics to facilitate the sharing of private information and thus improve search efficiency. We extensively simulate the signaling mechanism in the context of other alternative solutions in selfish networks, and show encouraging results with respect to improving query performance.	data item;greedy algorithm;peer-to-peer;personally identifiable information;query optimization;simulation	Jiang Guo;Baochun Li	2004	International Conference on Parallel Processing, 2004. ICPP 2004.	10.1109/ICPP.2004.1327908	information asymmetry;distributed algorithm;query expansion;computer science;theoretical computer science;distributed computing;world wide web;algorithm;computer network	DB	-9.935876725158096	74.53204051120507	17303
d07f75d3f37093582cdcb96039fafd047b8c2c69	bigcache: a cache-based bigdata management in mobile networks	replication;big data sharing;caching;mobile networks;internet bandwidth;internet traffic;big data storage;big data retrieval;cloud computing	This work proposes BigCache, a cache-based BigData management in mobile networks. Today's handy world produces torrent of data, which should be processed in time, so that data are transformed in useful information. Moreover, the mobile world adds the exponential growth of information in the form of BigData such as image, audio or video. This BigData is frequently and repeatedly downloaded across the world on various devices, where a mobile device became a first choice. Hence, we focus on how effectively a BigData can be delivered to the end user using cache-based approach in mobile networks. The main contributions of our work are threefold. First, we present an architecture of BigCache along with the cache decision system and cache replacement process for rapid access to BigData at large extent in mobile networks. Second, we propose three different caching schemes, designated as request-based caching scheme, priority-based caching scheme and scale-based caching scheme in BigCache. Third, our performance s...	big data	Kshama Raichura;Nilesh Padhariya	2017	IJMC	10.1504/IJMC.2017.10001204	replication;internet traffic;cloud computing;computer science;operating system;database;smart cache;internet privacy;world wide web;computer security;computer network	Mobile	-17.024789063372072	73.39294856030062	17314
e1388d6fc6647b1bc7fb69cc457090b10d6b0ba5	verification of integrity and secrecy properties of a biometric authentication protocol	biometric authentication;satisfiability;integrity checking	In this paper, we clarify and verify an established biometri c authentication protocol. The selected protocol is intended to have t hr e properties: effectiveness (integrity checks are carried out on all hardware b efore enabling transmission of biometric data), correctness (the user is satisfi ed that integrity checks have been executed correctly before transmission of biomet ric data occurs), and secrecy (unauthorized users cannot obtain biometric data b y intercepting messages between the system’s hardware components). We analys e the clarified protocol using applied pi calculus and the ProVerif tool, and de monstrate that it satisfies the intended properties of the protocol. Moreover, th is paper shows that the verification result between the naive interpretation and th e clarified interpretation is different.	authentication protocol;authorization;biometrics;communications protocol;correctness (computer science);cryptographic nonce;cryptography;email;encryption;entity–relationship model;online banking;proverif;replay attack;trusted computing;π-calculus	Anongporn Salaiwarakul;Mark Ryan	2008		10.1007/978-3-540-79104-1_1	computer science;database;internet privacy;computer security;biometrics;satisfiability	Security	-36.677205250990355	72.31474429977304	17318
8e25721184588f383ab6202470f57af0ec3ea33d	proxy re-signature scheme that translates one type of signature scheme to another type of signature scheme	bob;generic algorithm;bilinear map;signature scheme;proxy signature	  In 1998, Blaze, Bleumer, and Strauss (BBS) proposed proxy re-signatures, in which a semi-trusted proxy acts as a translator  between Alice and Bob to translate a signature from Alice into a signature from Bob on the same message. The proxy, however,  does not learn any signing key and cannot sign arbitrary messages on behalf of either Alice or Bob. In the 12  th   ACM Conference on Computer and Communications Security (CCS 2005), Ateniese and Hohenberger formalised the definition of  security for a proxy re-signature and presented two secure proxy re-signature schemes based on bilinear maps. They left open  the problem of determining whether or not a proxy re-signature scheme can be built that translates one type of signature scheme  to another i.e. a scheme that translates Alice’s Schnorr signatures into Bob’s RSA based ones.      In this paper we address this open problem. We construct proxy signature scheme that translates Alice’s Schnorr/ElGamal signature  to Bob’s RSA signature. We construct this by generating suitable proxy re-sign keys by establishing communication among delegatee,  proxy signer and the delegator. At no point of conversion the security of Schnorr, ElGamal and RSA signature schemes are compromised.  The Signatures generated by regular signature generation algorithm and the proposed re-signature algorithm are indistinguishable.      		N. R. Sunitha;B. B. Amberker	2010		10.1007/978-3-642-14478-3_28	ring signature;merkle signature scheme;blind signature;schnorr signature;elgamal signature scheme	Crypto	-39.54106690692964	75.43650374814148	17320
407b560bc8d72d1a5540049aa65ac41ecb95cfbb	leo satellite routing algorithm in software defined space terrestrial integrated network		In modern society, low earth orbit (LEO) satellite network is hosting more and more data services, and better performance is required. Software Defined Network(SDN) is an emerging technology, which separates control plane and forward plane. Controller is responsible for centralized control while network devices for forwarding. In this paper, SDN technology is applied to the LEO satellite network constituting software defined space terrestrial integrated network. Utilizing the advantage of SDN centralize control and the characteristic of LEO satellite network topology, this paper proposes the shortest path algorithm from source satellite to destination satellite. Before the routing starts, the controller computes the shortest path and sends flow table to network devices. The network devices forward packets based on the logical address. Through the comparison of simulation, end-to-end delay, loss packet rate and throughput of the shortest path algorithm are better than other routing algorithms.	centralisation;centralized computing;control plane;controller (control theory);dijkstra's algorithm;dynamic resolution adaptation;end-to-end principle;network packet;network topology;routing;shortest path problem;simulation;software-defined networking;terrestrial television;throughput	Andong Guo;Chenglin Zhao;Fangmin Xu;Chao Qiu	2017	2017 17th International Symposium on Communications and Information Technologies (ISCIT)	10.1109/ISCIT.2017.8261222	computer network;networking hardware;control theory;throughput;software-defined networking;computer science;algorithm;network topology;network packet;dijkstra's algorithm;shortest path problem	Networks	-12.074591538541734	83.64260237919879	17352
2f47d365036c1d78e0af9f4dc875f12f6dab3656	the nrl protocol analyzer: an overview	verification;outil logiciel;interfase usuario;software tool;protocole transmission;user interface;specifications;implementation;prolog;prototypes;analizador;interrogation base donnee;interrogacion base datos;cryptographic protocol;specification language;requirements;ejecucion;protocolo transmision;lenguaje descripcion;design and implementation;herramienta controlada por logicial;criptografia;cryptography;communications networks;cryptographie;interface utilisateur;lenguaje especificacion;communications protocols;analyzer;langage specification;analyseur;lenguaje formal;database query;formal language;langage description;computer program verification;programming languages;description language;transmission protocol;langage formel	The NRL Protocol Analyzer is a prototype special-purpose veri cation tool, written in Prolog, that has been developed for the analysis of cryptographic protocols that are used to authenticate principals and services and distribute keys in a network. In this paper we give an overview of how the Analyzer works and describe its achievements so far. We also show how our use of the Prolog language bene ted us in the design and implementation of the Analyzer.	authentication;cryptographic protocol;cryptography;programming tool;prolog;prototype	Catherine A. Meadows	1996	J. Log. Program.	10.1016/0743-1066(95)00095-X	formal language;alloy analyzer;verification;specification language;computer science;cryptography;theoretical computer science;cryptographic protocol;database;programming language;user interface;implementation;prolog	Security	-35.07627629600971	62.30802889508825	17382
55075429c1ff59d296fae2366a4f03961f528ae5	adapting privacy-preserving computation to the service provider model	benchmarking;distributed algorithms;protocols;complexity theory;service provider;secure multi party computation;secure computation;cryptographic protocols;communication complexity;distributed algorithms communication complexity cryptographic protocols data privacy;wires;privacy preservation;sliding mode control network servers distributed computing circuits computer architecture service oriented architecture algorithm design and analysis distributed algorithms cryptographic protocols complexity theory;business model;rational security;servers;performance improvement;cryptographic protocols privacy preserving computation service provider model secure multiparty computation business model auctions benchmarking distributed algorithmic mechanism design;computational modeling;logic gates;data privacy;service provider model;privacy preserving computation;distributed algorithmic mechanism design;system architecture;security;distributed algorithm;rational security secure multi party computation distributed algorithmic mechanism design;secure multiparty computation;auctions	There are many applications for Secure Multi-Party Computation (SMC), but practical adoption is still an issue. One reason is that the business model of the application does not match the system architecture of regular secure computation. An important business model is that of a single service provider dealing with many customers. Applications with this business model are e.g. auctions or benchmarking. This paper provides SMC in a system architecture for service providers.Furthermore we achieve an interesting performance improvement. Our SMC protocol has a significantly improved complexity if all parties behave semi-honest, but can still deal with a minority of malicious parties at the usual complexity.The solution also relates to distributed algorithmic mechanism design which proposes to build distributed algorithms that implement mechanisms that compute the result given rational players.	best, worst and average case;client (computing);communication complexity;complexity;distributed algorithm;distributed algorithmic mechanism design;imperative programming;provider model;secure multi-party computation;semiconductor industry;server (computing);systems architecture;worst-case complexity	Florian Kerschbaum	2009	2009 International Conference on Computational Science and Engineering	10.1109/CSE.2009.261	distributed algorithm;computer science;theoretical computer science;database;distributed computing;secure multi-party computation;computer security;computer network	Theory	-39.30244896843356	71.42808691943152	17429
3f0baec50505fcada2637e3d155aac2e89babd25	enhancing ieee 802.11p/wave to provide infotainment applications in vanets	vanet;802 11p;wave;infotainment;mac	IEEE 802.11p/WAVE (Wireless Access for Vehicular Environment) is the emerging standard to enable wireless access in the vehicular environment. Most of the research contributions in this area has focused on safety-related applications, while comfort and information/entertainment applications (such as on board Internet access, point-of-interest notification, e-map download) have been considered only recently. Notwithstanding, the user interest in this kind of applications is expected to become a big market driver in a near future. In this paper, an extension to IEEE 802.11p is proposed that is compliant with the multi-channel operation of the WAVE architecture and targets at the support of non-safety applications, while preserving the delivery of safety services. The proposed W-HCF (WAVE-based Hybrid Coordination Function) protocol leverages controlled access capabilities on top of the basic contention-based access of the IEEE 802.11p; it exploits vehicles' position information and coordination among WAVE providers in order to improve performances of delay-constrained and loss-sensitive non-safety applications.		Marica Amadeo;Claudia Campolo;Antonella Molinaro	2012	Ad Hoc Networks	10.1016/j.adhoc.2010.09.013	vehicular ad hoc network;embedded system;telecommunications;inter-access point protocol;computer science;wave;ieee 802.11h-2003;computer security;computer network;ieee 802.11e-2005	Visualization	-15.886857925469593	89.9880252926138	17450
0914e2b9f99fd6078bdfea41dc9eec09a76dbc2c	interactive transparent networking: protocol meta modeling based on efsm	estensibilidad;modelizacion;distributed system;red sin hilo;optimisation;systeme reparti;sistema activo;formal specification;calculateur embarque;protocolo red;network protocol;protocole transmission;optimizacion;reseau sans fil;cross layer optimization;gestion red;systeme modulaire;cellular radio;wireless network;tcp;aplicacion espacial;sistema modular;information access;protocole tcp;systeme actif;transmission control protocol;interface reseau;active system;specification formelle;modelisation;active network;especificacion formal;notices;protocolo transmision;network interfaces;interactive transparent networking;sistema repartido;metamodel;protocolo tcp;metamodele;interactive tcp;metamodelo;red celular;cell network;reseau cellulaire;protocol meta engineering;modular system;event notification;boarded computer;gestion reseau;notification;acces information;acceso informacion;optimization;extensibilite;network management;scalability;protocole reseau;information system;radiotelephonie cellulaire;network services;networked systems;active networks;modeling;efsm;calculador embarque;application spatiale;systeme information;meta model;space application;sistema informacion;transmission protocol	the extensibility and evolution of network services and protocols had become a major research issue in recent years. The 'programmable' and 'active' network paradigms have been trying to solve the problems emanating from the immutable organization of network software layers by allowing arbitrary custom codes to be embedded inside network layers. In this work, we propose a new approach for building extensible network systems to support cross-layer optimization. The fundamental idea is to perform a simple, light-weight meta-engineering on the classical OSI protocols' organization to make it interactive and transparent. The protocols become (interactive) since they can provide event notification to service subscribers, and they become (transparent) since they also allow controlled access to their state information. Actual protocol extensions (or modifications) can then be performed at the application space by what we call Transientware Modules. This organization provides the infrastructure needed for easy and practical extensions of the current network services and it becomes much easier to address other difficult issues like security and flexibility. We call this mechanism Interactive Transparent Networking (InTraN) and we call the extended kernel InTraN-enabled. We have realized a FreeBSD implementation of the extensible InTraN-enabled kernel. In this paper, we present a formal EFSM-based model for the proposed meta-engineering and illustrate the principles through a real example of TCP extension. Then, we demonstrate how it can be used to realize equivalents of other protocol modifications by showing the InTraN model of 'Snoop' [4].	code;embedded system;event (computing);extended finite-state machine;extensibility;freebsd;immutable object;kernel (operating system);mathematical optimization;osi model;transparent network substrate;snoop	Javed I. Khan;Raid Zaghal	2006	Computer Communications	10.1016/j.comcom.2006.05.009	metamodeling;embedded system;active networking;simulation;telecommunications;computer science;transmission control protocol;computer network	Networks	-25.734808977757005	81.34459413563923	17465
642d445adfdfe8a11ea3180185ce9559f0d9a90b	qos-aware application placement over distributed cloud	indium phosphide;measurement;resource management;iii v semiconductor materials;bandwidth;quality of service;cloud computing	We are facing an increasing interest about virtualization technologies that enable new paradigms and technical approaches like Cloud Computing, Software Defined Networks. Infrastructure Providers (InPs), managing distributed physical resources, need to perform the mapping of the requested virtual resources on the physical ones. For this purpose, they need to optimize the allocation process in order to: (1) optimally use the various types of available resources shared among customers, and (2) be compliant with Service Level Agreement (SLA) to meet the QoS attributes. This mapping phase, called Virtual Network Embedding, is known to be an NP-hard problem. The aim of the PhD thesis project described in this paper is to propose algorithmic solutions that allow the InP to optimize the mapping of virtual computational nodes and network links in order to improve objective metrics (e.g., revenue) while satisfying multiple QoS attributes agreed in the SLA. To achieve this goal, the thesis will address these main topics: (1) efficient online heuristics for network-aware embedding of multiple network requests, (2) multi-constrained embedding according multiple QoS metrics (e.g., maximum expected delay). Early results show that our algorithms performs better than existent ones, encouraging us to continue with the future work.	algorithm;cloud computing;heuristic (computer science);performance;quality of service;service-level agreement	Francesco Bianchi;Francesco Lo Presti	2016	2016 39th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)	10.1109/MIPRO.2016.7522239	real-time computing;simulation;quality of service;cloud computing;computer science;resource management;operating system;distributed computing;bandwidth;measurement;statistics;computer network	HPC	-20.95173706136782	64.82049664821689	17492
27952cb5161005e582eaa7c2d90212c5335d61cb	write-optimized consistency verification in cloud storage with minimal trust			cloud storage	Yuzhe Richard Tang;Ju Chen	2016	IACR Cryptology ePrint Archive		cloud storage;database;computer science	Crypto	-41.59426853114761	69.21617869832768	17529
204f6bedf27794fbb8a4d9b1382ee08eb5c7f3da	distributed anonymization: achieving privacy for both data subjects and data providers	data sharing;data provider;data repository;query result;private databases;partitioned databases;achieving privacy;independent data provider;data confidentiality;data providers;data subject;data subjects;multiple databases	There is an increasing need for sharing data repositories containing personal information across multiple distributed and private databases. However, such data sharing is subject to constraints imposed by privacy of individuals or data subjects as well as data confidentiality of institutions or data providers. Concretely, given a query spanning multiple databases, query results should not contain individually identifiable information. In addition, institutions should not reveal their databases to each other apart from the query results. In this paper, we develop a set of decentralized protocols that enable data sharing for horizontally partitioned databases given these constraints. Our approach includes a new notion, l-site-diversity, for data anonymization to ensure anonymity of data providers in addition to that of data subjects and a distributed anonymization protocol that allows independent data providers to build a virtual anonymized database while maintaining privacy for both data subjects and data providers.	algorithm;analysis of algorithms;confidentiality;cryptography;cryptology eprint archive;data anonymization;data mining;database;distributed computing;earthbound;file spanning;john d. wiley;microdata (html);mondrian olap server;personally identifiable information;privacy;secure multi-party computation;yang	Pawel Jurczyk;Li Xiong	2009			computer science;data mining;database;internet privacy;view	DB	-41.097030909434665	65.55729064261145	17550
5fe805f96380ea8a46b6ad67f94f2a5db6734735	formal models of bank cards for free	smart card application formal model learning technique system behaviour inference finite state machine banking smart card emv protocol suite reverse engineering security evaluation;banking;formal specification;cryptography standards credit cards protocols testing learning automata;inference mechanisms;finite state machines;formal verification;smart cards;learning artificial intelligence;article in monograph or in proceedings;security of data;reverse engineering;smart cards banking finite state machines formal specification formal verification inference mechanisms learning artificial intelligence reverse engineering security of data	Learning techniques allow the automatic inference of the behaviour of a system as a finite state machine. We demonstrate that learning techniques can be used to extract such formal models from software on banking smartcards which - as most bank cards do - implement variants of the EMV protocol suite. Such automated reverse-engineering, which only observes the smartcard as a black box, takes little effort and is fast. The finite state machine models obtained provide a useful insight into decisions (or indeed mistakes) made in the design and implementation, and would be useful as part of security evaluations - not just for bank cards but for smartcard applications in general - as they can show unexpected additional functionality that is easily missed in conformance tests.	black box;conformance testing;finite-state machine;protocol stack;reverse engineering;smart card	Fides Aarts;Joeri de Ruiter;Erik Poll	2013	2013 IEEE Sixth International Conference on Software Testing, Verification and Validation Workshops	10.1109/ICSTW.2013.60	embedded system;smart card;formal verification;computer science;engineering;operating system;software engineering;data mining;formal specification;finite-state machine;programming language;computer security;reverse engineering	SE	-50.92378324491231	68.99908767802748	17556
13363064eb1ec1c518b73887dc9b47fdb9439d35	dynamic replication of web contents	amjad mahmood 对象复制 数据资料 计算机 服务系统 dynamic replication of web contents;object replication web distributed web server system data placement internet;cost function;search space;constraint optimization problem;optimization problem;web distributed web server system data placement internet object replication;storage capacity;denial of service;polynomial time;greedy algorithm;world wide web;reading and writing	The phenomenal growth of the World Wide Web has brought huge increase in the traffic to the popular web sites. Long delays and denial of service experienced by the end-users, especially during the peak hours, continues to be the common problem while accessing popular sites. Replicating some of the objects at multiple sites in a distributed web-server environment is one of the possible solutions to improve the response time/latency. The decision of what and where to replicate requires solving a constraint optimization problem, which is NP-complete in general. In this paper, we consider the problem of placing copies of objects in a distributed web server system to minimize the cost of serving read and write requests when the web servers have limited storage capacity. We formulate the problem as a 0–1 optimization problem and present a polynomial time greedy algorithm with backtracking to dynamically replicate objects at the appropriate sites to minimize a cost function. To reduce the solution search space, we present necessary conditions for a site to have a replica of an object in order to minimize the cost function. We present simulation results for a variety of problems to illustrate the accuracy and efficiency of the proposed algorithms and compare them with those of some well-known algorithms. The simulation results demonstrate the superiority of the proposed algorithms.	backtracking;constrained optimization;denial-of-service attack;greedy algorithm;loss function;mathematical optimization;np-completeness;optimization problem;polynomial;response time (technology);self-replicating machine;self-replication;server (computing);simulation;time complexity;web server;world wide web	Amjad Mahmood	2007	Science in China Series F: Information Sciences	10.1007/s11432-007-0018-5	time complexity;optimization problem;greedy algorithm;real-time computing;computer science;distributed computing;world wide web;computer security;denial-of-service attack;web server;algorithm	AI	-18.556458395718938	66.48771895422489	17573
5c9e73ece05d0fa2113d3ca278f3db807f5922f4	heuristic-based optimal resource provisioning in application-centric cloud		Cloud Service Providers (CSPs) adapt different pricing models for their offered services. Some of the models are suitable for short term requirement while others may be suitable for the Cloud Service User’s (CSU) long term requirement. In this paper, we look at the problem of finding the amount of resources to be reserved to satisfy the CSU’s long term demands with the aim of minimizing the total cost. Finding the optimal resource requirement to satisfy the the CSU’s demand for resources needs sufficient research effort. Various algorithms were discussed in the last couple of years for finding the optimal resource requirement but most of them are based on IPP which is NP in nature. In this paper, we derive some heuristic-based polynomial time algorithms to find some near optimal solution to the problem. We show that the cost for CSU using our approach is comparable to the solution obtained using optimal Integer Programming Problem(IPP).	algorithm;gnu linear programming kit;heuristic;integer programming;mathematical optimization;np (complexity);optimization problem;overhead (computing);provisioning;time complexity	Sunirmal Khatua;Preetam K. Sur;Rajib Kumar Das;Nandini Mukherjee	2014	CoRR		mathematical optimization;simulation;computer science	Metrics	-20.644920349884735	64.15683524225837	17594
90324963f523860ffee4b354fee35d3a213d7ae9	power efficient server consolidation for cloud data center	server consolidation;integer linear programming;optimisation;cloud;virtual machine allocation	Cloud computing has become an essential part of the global digital economy due to its extensibility, flexibility and reduced costs of operations. Nowadays, data centers (DCs) contain thousands of different machines running a huge number of diverse applications over an extended period. Resourcemanagement in Cloud is an open issue since an efficient resource allocation can reduce the infrastructure running cost. In this paper, we propose a snapshot-based solution for server consolidation problem from Cloud infrastructure provider (CIP) perspective. Our proposed mathematical formulation aims at reducing power cost by employing efficient server consolidation, and also considering the issues such as (i) mapping incoming and failing virtual machines (VMs), (ii) reducing a total number of VM migrations and (iii) consolidating running server workloads. We also compare the performance of our proposed model to the well-known Best Fit heuristics and its extension to include server consolidation via VM migration denoted as Best Fit with Consolidation (BFC). Our proposed mathematical formulation allows us to measure the solution quality in absolute terms, and it can also be applicable in practice. In our simulations, we show that relevant improvements (from 6% to 15%) over the widely adopted Best Fit algorithm achieved in a reasonable computing time. © 2016 Elsevier B.V. All rights reserved.	algorithm;base one foundation component library (bfc);cloud computing;data center;extensibility;failure;heuristic (computer science);semiconductor consolidation;server (computing);simulation;snapshot (computer storage);virtual machine;whole earth 'lectronic link	Somnath Mazumdar;Marco Pranzo	2017	Future Generation Comp. Syst.	10.1016/j.future.2016.12.022	parallel computing;real-time computing;simulation;integer programming;cloud computing;computer science;operating system;database;distributed computing;computer security	Arch	-20.224728383125882	62.558439931985816	17615
d590d9a510203912a0d8ed7c0410f7714bc0c373	highly reliable wavelength-reuse wavelength-division multiplexing semipassive optical access network architecture with double cover area and high network capacity	wavelength reuse;system capacity;cover area;highly reliable wdm semipassive optical access network;ring topology	We propose a wavelength-reuse wavelength-division multiplexing semipassive optical access network architecture with ring topology. Two access rings are controlled by one central office. The system capacity, as well as the network cover area, can be doubled with this proposal. When fiber failure occurs, the corresponding switches in remote nodes change to protection state to restore the network communication. Copyright © 2014 John Wiley & Sons, Ltd.	access network;channel capacity;downstream (software development);john d. wiley;network architecture;network switch;protection mechanism;ring network;wavelength-division multiplexing	Yan Gong;Chaoqin Gan;Chenwei Wu	2015	Int. J. Communication Systems	10.1002/dac.2740	ring network;telecommunications;computer science;computer network	Arch	-8.323670175610593	84.99414405405199	17629
f9ab8727344e6461f207020d35c48bd4ed0696d3	an science gateway with cost adaptive resource management schemes		In order to process heavy data and computation applications such as scientific application in cloud computing environment, it is important to do an efficient resource schedule that decrease the resource usage cost while guaranteeing users’ Service Level Agreement. To resolve this issue, we propose and implement Science Gateway, which execute the scientific application efficiently on heterogeneous cloud service providers instead of users. Especially, we propose a cost-adaptive resource management schemes (i.e. VM pool management scheme that decreases the resource management cost significantly based on the long-term payment plans of cloud resource providers and VM placement management scheme that guarantee the performance of communication between VMs). Finally, we demonstrate that our proposed system improves the performance of existing cloud systems through some experimental and simulation results.		Woojoong Kim;Seung-Hwan Kim;Chan-Hyun Youn	2015		10.1007/978-3-319-38904-2_14	computer science;management science;world wide web	HPC	-22.0912335459394	64.66201871687797	17666
6aa00bc21d4aef97dec79c8cace8f563eb9f7583	adaptive video-aware fec-based mechanism with unequal error protection scheme	qoe;unequal error protection uep;forward error correction fec;adaptive video mechanism;video aware fec;cross layer	Real-time video services over wireless networks are becoming a part of everyday life and have been used to spread information ranging from education to entertainment content. However, the challenge of dealing with the fluctuating bandwidth, scarce resources and the time-varying error rate of theses networks, unveils the need for an error-resilient video transport. In this context, Forward Error Correction (FEC) approaches are required to provide the distribution of video applications for wireless users with Quality of Experience (QoE) assurance. This work proposes an adaptive cross-layer Video-Aware FEC mechanism with Unequal Error Protection (UEP) scheme to enhance video transmission in wireless networks, while increasing the user satisfaction and improving the usage of wireless resources. The benefit and impact of the proposed mechanism are demonstrated by using simulation and assessed through objective and subjective QoE metrics.	forward error correction;real-time transcription;simulation;software metric	Roger Immich;Eduardo Cerqueira;Marília Curado	2013		10.1145/2480362.2480550	real-time computing;telecommunications;computer science;computer network	Mobile	-8.270599155016807	100.73087134290701	17695
7c456bd766de90ae877edb97de49cf1ec58d6a23	a rewriting-based forwards semantics for maude-npa	protocol verification;standard rewriting based model checking;reasoning modulo an equational theory;model checking;logical narrowing based reachability analysis;term rewriting;cryptographic protocol analysis	The Maude-NRL Protocol Analyzer (Maude-NPA) is a tool for reasoning about the security of cryptographic protocols in which the cryptosystems satisfy different equational properties. It tries to find secrecy or authentication attacks by searching backwards from an insecure attack state pattern that may contain logical variables, in such a way that logical variables become properly instantiated in order to find an initial state. The execution mechanism for this logical reachability is narrowing modulo an equational theory. Although Maude-NPA also possesses a forwards semantics naturally derivable from the backwards semantics, it is not suitable for state space exploration or protocol simulation.  In this paper we define an executable forwards semantics for Maude-NPA, instead of its usual backwards one, and restrict it to the case of concrete states, that is, to terms without logical variables. This case corresponds to standard rewriting modulo an equational theory. We prove soundness and completeness of the backwards narrowing-based semantics with respect to the rewriting-based forwards semantics. We show its effectiveness as an analysis method that complements the backwards analysis with new prototyping, simulation, and explicit-state model checking features by providing some experimental results.	authentication;cryptographic protocol;cryptography;cryptosystem;executable;maude system;model checking;modulo operation;printer working group;reachability;rewriting;simulation;state pattern;state space	Santiago Escobar;Catherine A. Meadows;José Meseguer;Sonia Santiago	2014		10.1145/2600176.2600186	discrete mathematics;theoretical computer science;mathematics;algorithm	Logic	-36.024529634312245	72.5092009510626	17714
ee2ac5f37c81ae2d78abc803028384912dd5a49a	scheduling for atomic broadcast operation in heterogeneous networks with one port model	grid scheduling;modelizacion;distributed system;algoritmo paralelo;maximum degree;systeme reparti;atomic operation;maximum weighted subtree first;parallel algorithm;redundancia;heterogeneous computing;metodo arborescente;heuristic method;heterogeneous environment;distributed computing;metodo heuristico;nearest neighbor first;difusion atomica;supercomputer;communication model;simulator;algorithme parallele;grid;supercomputador;modelisation;vecino mas cercano;scheduling algorithm;sistema repartido;simulador;redundancy;heterogeneidad;rejilla;scheduling;diffusion donnee;nearest neighbor;difusion dato;diffusion atomique;simulateur;atomic broadcast;grille;calculo repartido;plus proche voisin;tree structured method;nearest neighbour;operacion atomica;methode arborescente;methode heuristique;data broadcast;message forwarding table;modeling;calcul reparti;ordonnancement;network computing;heuristic algorithm;operation atomique;reglamento;redondance;superordinateur;heterogeneity;heterogeneite;one port communication model;heterogeneous network	With the emergence of the network technologies, heterogeneous computing has become a wide accept paradigm for distributed and network computing. In this paper, we present different algorithms aiming to efficiently perform atomic one-to-all broadcast in a heterogeneous network with a one port model. The proposed algorithms are divided into graph-based and tree-based ones. In graph-based algorithms, we present Nearest Neighbor First and Maximum Degree Neighbor First schemes. A prescheduling strategy with constructing a message forwarding table for avoiding redundant transmissions is applied as runtime support. In the tree- based approaches, there are five heuristic algorithms: Nearest Neighbor First, Maximum Degree Neighbor First, Maximum Height Subtree First, Maximum Subtree First, and Maximum Weighted Subtree First, proposed based on different network characteristics. To evaluate the performance of the proposed techniques, we have developed a simulator that contains a parametric graph generator for generating network graphs with various characteristics. We have implemented all of the proposed scheduling algorithms on the simulator. The performance results show that the Maximum Weighted Subtree First performs best in high degree heterogeneous environments. On the contrary, with homogeneous-like environments, the graph-based Nearest Neighbor First will be the best choice. In summary, contribution of this study relies on informing significant suggestions for adapting proper broadcasting mechanism in different heterogeneous platforms.	algorithm;apollonian network;atomic broadcast;emergence;file spanning;heterogeneous computing;heuristic;job shop scheduling;list of distributed computing projects;makespan;microsoft solutions framework;minimum spanning tree;mobile computing;national supercomputer centre in sweden;negation normal form;network topology;programming paradigm;routing;scheduling (computing);tree (data structure)	Ching-Hsien Hsu;Bing-Ru Tsai	2008	The Journal of Supercomputing	10.1007/s11227-008-0261-6	nearest neighbor graph;supercomputer;parallel computing;computer science;theoretical computer science;operating system;machine learning;distributed computing;scheduling	HPC	-4.605873094534038	74.99713585355614	17724
ee6302295e7b3bd1da251a7314c0f191c2382785	stateful process migration for edge computing applications		Low-latency is an advantage of edge computing. To utilize this advantage, a server-side application communicating with user equipment (UE) should be migrated from a server executing the application to a server near the UE's destination. However, the downtime caused by this migration can be a problem for applications that require ultra-low latency. To reduce the downtime, we propose a novel method for migrating only processes that contain UE-specific states, and not the entire application. The method introduces conversion of inter-process communication channels to enable communication continuity of the migrated processes. Finally, we show that the downtime for our method is shorter than that for VM migration and container migration.	downtime;edge computing;inter-process communication;overhead (computing);pid;process migration;prototype;scott continuity;server (computing);server-side;state (computer science);stateful firewall;system migration	Motoshi Horii;Yuji Kojima;Kenichi Fukuda	2018	2018 IEEE Wireless Communications and Networking Conference (WCNC)	10.1109/WCNC.2018.8377072	handover;process migration;user equipment;real-time computing;computer network;stateful firewall;latency (engineering);downtime;edge computing;computer science;server	HPC	-18.06547140367941	79.59163286073498	17733
7bc047711193bd7cb0e81045d3897d3ab4b09084	practical and exposure-resilient hierarchical id-based authenticated key exchange without random oracles	generators;public key resistance computational modeling generators scalability;resistance;computational modeling;public key;scalability;exposure resilience authenticated key exchange hierarchical id based authenticated key exchange	ID-based authenticated key exchange (ID-AKE) is a cryptographic tool to establish a common session key between parties with authentication based on their IDs. If IDs contain some hierarchical structure such as an email address, hierarchical ID-AKE (HID-AKE) is especially suitable because of scalability. However, most of existing HID-AKE schemes do not satisfy advanced security properties such as forward secrecy, and the only known strongly secure HID-AKE scheme is inefficient. In this paper, we propose a new HID-AKE scheme which achieves both strong security and efficiency. We prove that our scheme is eCK-secure (which ensures maximal-exposure-resilience including forward secrecy) without random oracles, while existing schemes is proved in the random oracle model. Moreover, the number of messages and pairing operations are independent of the hierarchy depth; that is, really scalable and practical for a large-system.	authenticated key exchange;authentication;cryptography;diffie–hellman key exchange;email;forward secrecy;maximal set;random oracle;scalability;session key	Kazuki Yoneyama	2013	2013 International Conference on Security and Cryptography (SECRYPT)		scalability;computer science;distributed computing;internet privacy;public-key cryptography;resistance;computational model;key distribution;computer security	Security	-41.096205985616756	75.39566374558673	17748
d41d0124e98bf8d0b777ed93b649258c5c0e1f6c	enhancement of forensic computing investigations through memory forensic techniques	computers;network centric applications;software;ram forensics;volatile memory forensics computer forensics digital evidence digital investigation electronic evidence ram forensics;computer forensics;memory forensic techniques;data stored off system;data mining;data stored off system forensic computing investigations memory forensic techniques digital evidence electronic devices network connections network centric applications;media;electronic devices;digital investigation;forensics physics computing application software australia electronic mail image storage cryptography random access memory availability security;network connectivity;cryptography;volatile memory forensics;network connections;forensic computing investigations;digital evidence;security of data;forensics;electronic evidence;operating systems	The use of memory forensic techniques has the potential to enhance computer forensic investigations. The analysis of digital evidence is facing several key challenges; an increase in electronic devices, network connections and bandwidth, the use of anti-forensic technologies and the development of network centric applications and technologies has lead to less potential evidence stored on static media and increased amounts of data stored off-system. Memory forensic techniques have the potential to overcome these issues in forensic analysis. While much of the current research in memory forensics has been focussed on low-level data, there is a need for research to extract high-level data from physical memory as a means of providing forensic investigators with greater insight into a target system. This paper outlines the need for further research into memory forensic techniques. In particular it stresses the need for methods and techniques for understanding context on a system and also as a means of augmenting other data sources to provide a more complete and efficient searching of investigations.	computer data storage;high- and low-level;memory forensics	Matthew Simon;Jill Slay	2009	2009 International Conference on Availability, Reliability and Security	10.1109/ARES.2009.119	computer science;internet privacy;world wide web;computer security	EDA	-51.81894589141724	61.117340989763434	17759
df87a69dccd49b76dfeb8ac40806f079ff396390	detecting malicious data injections in wireless sensor networks: a survey	measurement;journal article;algorithms;correlation;security;wireless sensor networks	Wireless Sensor Networks are widely advocated to monitor environmental parameters, structural integrity of the built environment and use of urban spaces, services and utilities. However, embedded sensors are vulnerable to compromise by external actors through malware but also through their wireless and physical interfaces. Compromised sensors can be made to report false measurements with the aim to produce inappropriate and potentially dangerous responses. Such malicious data injections can be particularly difficult to detect if multiple sensors have been compromised as they could emulate plausible sensor behaviour such as failures or detection of events where none occur. This survey reviews the related work on malicious data injection in wireless sensor networks, derives general principles and a classification of approaches within this domain, compares related studies and identifies areas that require further investigation.	embedded system;malware;sensor;structural integrity and failure	Vittorio P. Illiano;Emil C. Lupu	2015	ACM Comput. Surv.	10.1145/2818184	wireless sensor network;telecommunications;computer science;information security;key distribution in wireless sensor networks;internet privacy;computer security;correlation;measurement	Mobile	-53.134893081045405	74.62071198975949	17762
ff9421d1f68c916cdcf42024d713b7e4b5c0213b	a fast-startup tcp mechanism for voip services in long-distance networks	time varying;degradation;codecs;tcpip throughput codecs transport protocols transportation streaming media multimedia systems bandwidth degradation quality of service;tcpip;multimedia systems;service operation;transport protocols;feasibility study;long distance;streaming media;congestion control;transportation;bandwidth;network dynamics;quality of service;sliding window;throughput	In this paper, a fast-startup TCP (fsTCP) mechanism for VoIP services in long-distance networks is proposed. Most VoIP applications usually operate on the top of UDP/IP protocol. However, there are some weaknesses in long-distance connections. For example, UDP offers no congestion control and no adjustment in voice packet rate. Traditional TCP protocol employees sliding windows to solve the problems, but the slow-startup feature of TCP causes a low initial throughput of VoIP connections at startup. The low throughput caused by TCP slow-start operation is not able to meet the bit-rate requirement of VoIP Codec. The quality of voice will degrade seriously during startup period of TCP. To improve the deficiency, the fast-startup TCP is proposed. A feasibility study of TCP-like congestion control applied on VoIP services. The proposed scheme improves throughputs of VoIP connections by adjusting TCP congestion window parameters before transmitting VoIP data. Three popular VoIP codecs, including G.711, G.726 and G. 729, are simulated in the proposed TCP to demonstrate the fast start-up throughput characteristics. Via the sliding window of congestion control, the VoIP services operating on TCP protocol will be able to adjust the bit-rates of codec in response to the time-varying network dynamics.	angular defect;codec;g.711;g.726;microsoft windows;network congestion;network packet;tcp congestion control;throughput;time-varying network;transmitter	Mong-Fong Horng;Hung-Wei Hsu;Wan-Ling Du;Yi-Hsiang Hung;Ming-Harng Lee	2006	2006 International Conference on Intelligent Information Hiding and Multimedia	10.1109/IIH-MSP.2006.11	tcp westwood;sliding window protocol;compound tcp;tcp congestion-avoidance algorithm;feasibility study;transport;throughput;codec;tcp delayed acknowledgment;real-time computing;tcp global synchronization;degradation;quality of service;tcp westwood plus;telecommunications;computer science;bic tcp;tcp hole punching;network dynamics;transmission control protocol;h-tcp;internet protocol suite;tcp vegas;zeta-tcp;cubic tcp;scalable tcp;hstcp;tcp tuning;network congestion;tcp acceleration;tcp friendly rate control;slow-start;transport layer;bandwidth;computer network	Networks	-5.79272155340051	98.15244936513595	17785
7afe5a021bf60d964e2d06d73bfaf1403628aff7	reducing server trust in private proxy auctions	commerce electronique;confiance;psychologie sociale;confidencialidad;mise a jour;comercio electronico;securite;serveur informatique;integrite;cache memory;integridad;confidentiality;attaque;antememoria;actualizacion;ataque;vida privada;confidentialite;antememoire;confidence;integrity;private life;confianza;safety;subasta;psicologia social;bidding;servidor informatico;vie privee;social psychology;enchere;seguridad;electronic trade;updating;attacking;computer server	We investigate proxy auctions, an auction model which is proving very successful for on-line businesses (e.g., [9]), where a trusted server manages bids from clients by continuously updating the current price of the item and the currently winning bid as well as keeping private the winning client's maximum bid. We propose techniques for reducing the trust in the server by defining and achieving a security property, called server integrity. Informally, this property protects clients from a novel and large class of attacks from a corrupted server by allowing them to verify the correctness of updates to the current price and the currently winning bid. Our new auction scheme achieves server integrity and satisfies two important properties that are not enjoyed by previous work in the literature: it has minimal interaction, and only requires a single trusted server. While the privacy property of our scheme holds under a standard intractability assumption, the server integrity property holds unconditionally.		Giovanni Di Crescenzo;Javier Herranz;Germán Sáez	2004		10.1007/978-3-540-30079-3_9	reverse proxy;confidentiality;cpu cache;bidding;computer science;artificial intelligence;operating system;database;distributed computing;confidence;world wide web;computer security;algorithm;server	ECom	-44.723492564984966	77.80073318669584	17794
6e20fdc20343197e8a0beb73d255efbc5461cf0c	demo abstract: a cross-device testing and reporting system for large-scale real-time wireless networks		We designed a crossdevice testing and reporting system, called cross-device testing and reporting system (CD-TRS), to facilitate the functional validation of protocol and application design in large-scale RTWNs. CD-TRS leverages the nice property of RTWNs that all devices in the network are fully synchronized. By specifying and retrieving events and device status from multiple devices in the runtime simultaneously, CD-TRS can further assemble them into a network-wide report on the detailed system behavior by aligning the records according to their associated network timestamps (or absolute slot number (ASN) in most RTWNs). By comparing this runtime network behavior report with the required protocol and application specifications, abnormal device/network behavior can be observed and their root cause(s) can be effectively located. This thus can significantly reduce the complexity of RTWN testing and reporting. In the following, we first describe the overall architecture of CD-TRS, and then demonstrate how CD-TRS helps with the functional validation of D2-PaS, a distributed and dynamic packet scheduling framework we recently developed for handling disturbances in real-time wireless networks.	network packet;real-time clock;real-time transcription;scheduling (computing)	Tao Gong;Huayi Ji;Song Han;Tianyu Zhang;Chuancai Gu;Xiaobo Sharon Hu;Mark Nixon	2017	2017 IEEE Real-Time and Embedded Technology and Applications Symposium (RTAS)	10.1109/RTAS.2017.21	debugging;wireless network;architecture;timestamp;real-time computing;scheduling (computing);embedded system;root cause;autonomous system (internet);computer science;network packet;distributed computing	Embedded	-28.228379262530286	66.00080921882227	17802
e8a3fe32b3c60ffbf9bbc17cfa0bb53e3b8aad1d	fixed-priority scheduling of mixed soft and hare real-time tasks on multiprocessors		1This paper answers several open questions of practical concerns to schedule soft real-time (SRT) tasks, to guarantee their bounded tardiness, under fixed-priority scheduling in homogeneous multiprocessor systems. We consider both cases with only SRT tasks and with mixed sets of SRT and hard real-time (HRT) tasks. For the case in which the system has only SRT tasks, we show that any fixed priority assignment policy yields a capacity augmentation factor of 2−1/M where M is the number of processors. We prove the optimality of the utilization-monotonic (UM) priority assignment (i.e., assigning higher priorities to high-utilization tasks) under our sufficient test for guaranteeing bounded tardiness. We show that UM priority assignment can yield a utilization bound of M+1/2M, which is shown asymptotically the best possible bound. For the case in which the system has mixed SRT and HRT tasks, we present two new fixed-priority assignment algorithms and their associated schedulability tests. One is a clustering-based greedy priority assignment policy and another is based on Audsley's optimal priority assignment (OPA) approach. We show that the utilization bounds, augmentation factors, and speedup factors are still maintained by the hard real-time cases. Therefore, introducing soft real-time tasks does not create additional problems (at least in those metrics) for scheduling if the priority assignments are properly done. As demonstrated by extensive experiments, these two policies yield reasonably good performance overall and much better performance than the deadline-monotonic priority assignment.	central processing unit;cluster analysis;division algorithm;entity–relationship model;experiment;fixed-priority pre-emptive scheduling;greedy algorithm;multiprocessing;non-monotonic logic;opa;real-time clock;real-time computing;real-time locating system;scheduling (computing);speedup;surround sound	Jian-Jia Chen;Wen-Hung Huang;Zheng Dong;Cong Liu	2017	2017 IEEE 23rd International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA)	10.1109/RTCSA.2017.8046312	distributed computing;real-time computing;dynamic priority scheduling;multiprocessing;computer science;speedup;deadline-monotonic scheduling;scheduling (computing);priority ceiling protocol;bounded function;schedule	Embedded	-10.425979888012346	60.46204313563682	17814
5484e428ab0553737903a6c15d5be887fe626c50	lifting and reduction of antimatroids		A system is disclosed for authenticating an object on the basis of certain physical phenomena or character, specifically, measurable, but not practicably duplicable random variations in the object. In one form, the object (authenticator (T)) is a paper tag having a reference space (14), the varying translucency pattern of which is a measurable but practicably unduplicable characteristic of the paper. The reference space (14) is sensed to provide reference signals indicative of the varying translucency. A reference numeral (10) is then provided from some registered form, as on the tag or in a list. If the numeral (10) is readily accessible, it likely will be cryptographically encoded. Note the value of putting encoded information on the tag to avoid the need for large reference files. For verification, freshly sensed reference signals, as from the tag (T) (actually characteristic of the tag) are compared with signals that previously were sensed as characteristic of the tag (T). Structures are disclosed as specific forms of the authenticator (T), along with apparatus for authenticator production, detection and manipulation. Different forms of tags (210) are disclosed, the measurable characteristic of which involves light transmissivity and reflectivity. Apparatus (111) for spectrographic confirmation of tag material is also disclosed. In an illustrative form of a tag (T) as an identification means, tags and processing apparatus utilize magnetic medium (218) and printed images (214). The magnetic medium is also disclosed to be recorded as for developing information on shelf life and sales channels.	antimatroid;lifting scheme	M. Nakamura	1999	Electronic Notes in Discrete Mathematics	10.1016/S1571-0653(05)80042-3	discrete mathematics;numeral system;reflectivity;mathematics;authentication;artificial intelligence;communication channel;measure (mathematics);pattern recognition	Theory	-37.571180553028036	70.89073099889487	17834
8c021661059724344fe4210a964be4f52887691e	location privacy issues in wireless sensor networks	wsn;wireless sensor network;sensor nodes;traffic analysis;trafficanalysis;location privacy	We discuss location privacy issues in wireless sensor networks. We consider sensor nodes with more responsible roles and the need to protect locations of such nodes. Available countermeasures against various types of traffic analysis attacks are examined and their problems are identified. We do not propose new traffic analysis resistance technique. Instead, we draw attention to blanks in current situation and identify several open questions, which should be answered in order to ensure location privacy of nodes.	call of duty: black ops;countermeasure (computer);hoc (programming language);privacy;routing;sensor node;traffic analysis;virtual channel	Jirí Kur;Andriy Stetsko	2008		10.1007/978-3-642-03315-5_12	engineering;key distribution in wireless sensor networks;internet privacy;mobile wireless sensor network;computer security;computer network	Security	-52.68542530620076	75.48466081999659	17836
f29dc6f71759b318df6cb296f9b1d563812efa0e	standardization of an european digital mobile radiocommunication system		In their every day activities, public safety organisations need various kinds of communications services. TETRA offers both the usual cellular services as well as professional radio services such as group communication, field workforce management services (dispatching) and efficient data services. TETRA is a unique combination of group voice communications, mobile telephony and mobile data services specifically designed for authority use.		Woldemar F. Fuhrmann;Klaus Spindler	1986			computer engineering;computer network;standardization;telecommunications;computer science	Mobile	-18.200611185050846	92.54828700255868	17859
1d6f45d6f28c35b6dd25fcc3902386c82fe35e09	addressing interest diversity in p2p based collaborative spam filtering	internet spam;groupware;information filtering;search algorithm;query formulation;collaborative information filtering;p2p;percolation search algorithm;email networks;scale free;spam filtering;collaborative filtering;network traffic;collaborative spam filtering;unsolicited e mail groupware information filtering peer to peer computing query formulation;message feedback retrieval;interest groups;spam feedback retrieval;collaboration unsolicited electronic mail information filtering information filters feedback military computing collaborative work peer to peer computing telecommunication traffic traffic control;unsolicited e mail;peer to peer computing;false positive;peer to peer;message feedback retrieval p2p collaborative spam filtering collaborative information filtering internet spam percolation search algorithm email networks spam feedback retrieval	Collaborative information filtering tends to be a promising technology in the fight again Internet spam, and the peer-to-peer framework is believed to be more suitable to implement this collaboration compared to centralized ones. However, the assumption of uniform information interests across peers in collaborative filtering limits the improvement in filtering accuracy and increases network traffic unnecessarily. To address this problem, we propose to construct multiple interest groups for a peer, each corresponding to one message category; and to use a percolation search algorithm to retrieve message feedbacks in scale-free email networks. Experiments show the proposed model can get remarkable improvement in false positive reduction and good performance in spam feedback retrieval	anti-spam techniques;centralized computing;collaborative filtering;email filtering;information filtering system;network traffic control;next-generation network;peer-to-peer;percolation;search algorithm;spamming;test set;the fight: lights out	Weidong Fang;Shoubin Dong	2006	2006 Fifth International Conference on Grid and Cooperative Computing Workshops	10.1109/GCCW.2006.16	type i and type ii errors;computer science;bag-of-words model;collaborative filtering;information filtering system;scale-free network;peer-to-peer;database;internet privacy;world wide web;information retrieval;search algorithm	HPC	-12.747167252989897	73.62836115172233	17864
a05fa0444b3badfaa93eb40ae1f73a2f3a993a2c	information fusion in computer security	computer security;information fusion	Nowadays vast amount of information is stored within computers and exchanged through computer networks. The type of information is extremely variable, computers being used for personal communications, business relations, electronic commerce, government services, etc. As a consequence huge volume of data at different level of privacy could be accessed everywhere at any time. Moreover, the network paradigm allows also the remote acquisition of data from remote devices, and their remote control. This is an extraordinary opportunity for our society, as well as a source of potential risks, as data and remote devices can be also accessed and misused by criminals. By relying heavily on computers for many aspects of everyday life, work, and entertainment, computer networks are clearly among the most critical infrastructures of our society. On the other hand, the security of computers and of network communications is far from being a solved problem. Computer networks are complex, the complexity being originated by multiple factors such as the number of connected nodes, the number of connections per node, and the heterogeneous nature of the nodes [1]. The complexity of a system causes its vulnerability to attacks, as it is difficult to spot all the weakest-links, and to effectively monitor and protect the multiple points-of-failure. Thus, to attack a particular node in the network, the attacker may exploit the vulnerabilities of the nodes connected to that node. In addition, each node itself is typically a complex system, where the relations among parts are not usually known. For example, a personal computer may have installed a variety of software, and even for a computer expert it could be difficult to clearly trace the interrelationships between each software piece, the operating system, and the outside network. As a consequence of such a complexity, the detection of attacks, and the understanding of what really happened when an attack is detected, relies heavily on the collection of multiple evidences from different sources, and their correlation. A number of research issues are involved in computer security, the major issues being the identification of the most effective input sources, and the extraction of suitable features. Attackers typically craft their fraudulent behaviors so that their features are very similar to legitimate behaviors. As a consequence, new attacks are hardly detected, as the feature used to analyze the data may be inadequate to spot attack traces. Other issues in attack detection are related to the algorithms used to analyze the data. All these components must be carefully designed not only to improve the detection capability, but also to avoid the flooding by huge volumes of false alarms. It is easy to see that even if a set of suited features has been devised, still it could be difficult to identify attack patterns, as the related alarms can be hardly distinguished from false alarms generated by legitimate behaviors. As the volume of	algorithm;attack patterns;complex system;complexity;computer security;e-commerce;operating system;personal computer;privacy;programming paradigm;remote control;tracing (software);vulnerability (computing)	Giorgio Giacinto;Fabio Roli;Carlo Sansone	2009	Information Fusion	10.1016/j.inffus.2009.03.002	computer science	Security	-56.92159608747719	65.37334354632999	17917
1e9e7e7fa537f50cd3c5845ad621c80367fa46a6	licensing options for virtual network functions in telecommunications cloud environment		In the paper we present the main licensing options for telecommunications Network Elements. We have special focus on Core Network Elements deployed in cloud environment, such as Mobile Switching Center Server (MSS) and Telecommunication Application Server (TAS). The flexibility and the efficiency of the remote licensing option is shown with some recent practical examples.	application server;telecommunications network;thermal-assisted switching	Attila Hilt;Gabor Jaro	2018	2018 11th International Symposium on Communication Systems, Networks & Digital Signal Processing (CSNDSP)	10.1109/CSNDSP.2018.8471802	telecommunications network;task analysis;virtual network;application server;software;core network;cloud computing;telecommunications;computer science;server	Arch	-19.248347861687087	88.78421378081978	17924
d47378158e766bc30806fba7562f69a3eb533823	secure elgamal-type cryptosystems without message encoding		ElGamal cryptosystem is one of the oldest public-key cryptosystems. It is known to be semantically secure for arbitrary messages in the random oracle model under the decisional Diffie-Hellman assumption. Semantic security also holds in the standard model when messages are encoded as elements in the group for which the decisional Diffie-Hellman assumption is defined. This paper introduces a setting and companion cryptosystem where semantic security can be proved in the standard model without message encoding. Extensions achieving security against chosen-ciphertext attacks are also provided.	chosen-ciphertext attack;ciphertext indistinguishability;cryptosystem;decisional diffie–hellman assumption;diffie–hellman key exchange;encryption;public-key cryptography;random oracle;semantic security	Marc Joye	2016		10.1007/978-3-662-49301-4_29	hybrid cryptosystem	Crypto	-39.002222697994725	76.62125964712824	17934
851fdb9a2c299407a33e7808d44385e305b6a57d	mobile p2p multicast based on social network reducing psychological forwarding cost	social network services;multicast communication;audio streaming;video streaming;mobile device;social networking services;streaming video;p2p;psychology;wireless access network;processing power mobile p2p multicast social network psychological forwarding cost wireless access network mobile device audio streaming video streaming memory capacity;cooperative behavior;video streaming mobile handsets multicast communication peer to peer computing social networking online;social network;multi agent simulation;large scale;memory capacity;streaming media;psychological forwarding cost;batteries;social networking online;mobile communication;mobile handsets;p2p networks;peer to peer computing;processing power;mobile computing;peer to peer;peer to peer computing batteries mobile communication social network services psychology mobile computing streaming media;service quality;mobile p2p multicast;mobile network;mobile user	The enhancements of the transmission speed in wireless access networks and mobile-device capacity enable us to use data/audio streaming/video streaming multicast service in large scale networks via their personal mobile devices. Peer-to-peer (P2P) architecture ensures scalability and robustness more easily and more economically than server-client architecture; as the number of nodes in a P2P network increases, the amount of workload per node decreases and lessens the impact of node failure. However, mobile users feel much larger psychological cost due to strict limitations on bandwidth, processing power, memory capacity, and battery life, and they want to minimize their contributions to these services. Therefore, the issue of how we can reduce this psychological cost remains. In this paper, we consider how effective a social networking service is as a platform for mobile P2P multicast. We model users' cooperative behaviors in mobile P2P multicast streaming, and propose a social-network based P2P streaming architecture for mobile networks. We also measured the psychological forwarding cost of real users in mobile P2P multicast streaming through an emulation experiment, and verify that our social-network based mobile P2P multicast streaming improves service quality by reducing the psychological forwarding cost using multi-agent simulation.	access network;agent-based model;client–server model;emulator;h.264/mpeg-4 avc;information systems;mobile device;multicast;network model;network topology;peer-to-peer;scalability;simulation;social network;streaming media	Hiroyuki Kubo;Ryoichi Shinkuma;Tatsuro S Takahashi	2010	2010 IEEE Global Telecommunications Conference GLOBECOM 2010	10.1109/GLOCOM.2010.5683911	cellular network;multicast;ip multicast;mobile telephony;reliable multicast;protocol independent multicast;computer science;operating system;pragmatic general multicast;instructions per second;peer-to-peer;mobile device;distributed computing;internet privacy;source-specific multicast;mobile computing;service quality;xcast;computer network;social network	Mobile	-17.984142041196293	74.6579387555136	17936
511847eb495dec436c4767000fb5cb79355f5cae	efficient hardware architecture for fast ip address lookup	protocols;memory accesses hardware architecture fast ip address lookup multigigabit ip router longest matching prefix forwarding table binary trie searching hierarchical indexing structure hardware pipeline sram data structure table updates;communications;conference_paper;hardware table lookup data structures routing computer architecture information technology indexing pipelines random access memory explosions;index structure;tree data structures;computer applications;hardware architecture;memory access;internet;telecommunication network routing;indexing;internet tree data structures tree searching telecommunication network routing string matching table lookup indexing protocols;tree searching;string matching;table lookup;data structure	 A multigigabit IP router may receive several millions packets per second from each input link. For each packet, the router needs to find the longest matching prefix in the forwarding table in order to determine the packet’s next-hop. In this paper, we present an efficient hardware solution for the IP address lookup problem. We model the address lookup problem as a searching problem on a binarytrie. The binary-trie is partitioned into four levels of fixed size 255-node subtrees. We employ a hierarchical indexing structure to facilitate direct access to subtrees in a given level. It is estimated that a forwarding table with 40K prefixes will consume 2.5Mbytes of memory. The searching is implemented using a hardware pipeline with a minimum cycle of 12.5ns if the memory modules are implemented using SRAM. A distinguishing feature of our design is that forwarding table entries are not replicated in the data structure. Hence, table updates can be done in constant time with only a few memory accesses.	dimm;data structure;lookup table;network packet;random access;replication (computing);router (computing);static random-access memory;throughput;time complexity;tree (data structure);trie	Derek Chi-Wai Pao;Angus K. M. Wu;Cutson Liu;Kwan Lawrence Yeung;King Sun Chan	2002		10.1109/INFCOM.2002.1019300	routing table;communications protocol;search engine indexing;virtual routing and forwarding;parallel computing;the internet;data structure;computer science;theoretical computer science;operating system;ip forwarding;hardware architecture;database;forwarding plane;tree;computer applications;computer network;string searching algorithm	Metrics	-5.881716491996339	66.93202348585663	17937
a7248ffa536f17aac55ba3dc231a9fb90b58138d	cylindrical coordinates security visualization for multiple domain command and control botnet detection	human cognition;proceedings;conference proceedings;detection;dns traffic;domain;graph isomorphism;visualization;security visualization;cylindrical;omics international;abstracts;coordinates;control;and;visual signature;botnet detection;multiple;security;for;botnet;command	The botnets are one of the most dangerous species of network-based attack. They cause severe network disruptions throughmassive coordinated attacks nowadays and the results of this disruption frequently cost enterprises large sums in financial losses. In this paper, we make an in-depth investigation on the issue of botnet detection and present a new security visualization tool for visualizing botnet behaviors on DNS traffic. The core mechanism is developed with the objective of enabling users to recognize security threats promptly and mitigate the damages by only visualizing DNS traffic in cylindrical coordinates. We compare our visualization method with existing ones and the experimental results show that ours has greater perceptual efficiency. The ideas and results of this study will contribute toward designing an advanced visualization technique that offers better security. Also, the approach proposed in this study can be utilized to derive new and valuable insights in security aspects from the complex correlations of Big Data. © 2014 Elsevier Ltd. All rights reserved.	big data;botnet;denial-of-service attack	Ilju Seo;Heejo Lee;Seung Chul Han	2014	Computers & Security	10.1016/j.cose.2014.07.007	cognition;visualization;geographic coordinate system;domain;computer science;information security;graph isomorphism;internet privacy;cylinder;botnet;world wide web;computer security;scientific control;multiple	Security	-61.45563892548146	62.64961058976374	17938
5d36f645e7fcc7f1ab1f4017ba9cb835ffa2e68d	game-theoretic static load balancing for distributed systems	tiempo respuesta;modelizacion;distributed system;optimal solution;reponse temporelle;optimum pareto;equilibrio nash;solution optimale;reseau communication;probleme statique;systeme reparti;fairness;game theory;nash equilibrium;static problems;equilibrio de carga;juego cooperativo;sistema informatico;equilibrio juego;equilibrage charge;distributed computing;static load;telecommunication network;teoria juego;response time;computer system;theorie jeu;multi user;carga repartida;cooperative game;strategie nash;nash bargaining solution;equite;temps reponse;modelisation;equidad;equilibre nash;equity;sistema repartido;time response;community networks;jeu cooperatif;red telecomunicacion;solucion optima;algorithme reparti;juego no cooperativo;reseau telecommunication;load balancing;estrategia nash;calculo repartido;charge repartie;algoritmo repartido;nash strategy;systeme informatique;load balance;equilibre jeu;non cooperative game;game equilibrium;expected response time;distributed systems;carga estatica;pareto optimal solution;respuesta temporal;pareto optimum;distributed algorithm;modeling;red de comunicacion;optimo pareto;communication network;calcul reparti;charge statique;jeu non cooperatif;distributed load	In this paper, we present a game theoretic approach to solve the static load balancing problem for singleclass and multi-class (multi-user) jobs in a distributed system where the computers are connected by a communication network. The objective of our approach is to provide fairness to all the jobs (in a singleclass system) and the users of the jobs (in a multi-user system). To provide fairness to all the jobs in the system,weuse a cooperative game tomodel the load balancing problem.Our solution is based on theNash Bargaining Solution (NBS)which provides a Pareto optimal solution for the distributed systemand is also a fair solution. An algorithm for computing the NBS is derived for the proposed cooperative load balancing game. To provide fairness to all the users in the system, the load balancing problem is formulated as a non-cooperative game among the users who try to minimize the expected response time of their own jobs. We use the concept of Nash equilibrium as the solution of our non-cooperative game and derive a distributed algorithm for computing it. Our schemes are compared with other existing schemes using simulations with various system loads and configurations. We show that our schemes perform near the system optimal schemes and are superior to the other schemes in terms of fairness. © 2010 Elsevier Inc. All rights reserved.	computer;distributed algorithm;distributed computing;entity;fairness measure;game theory;geographical operations system;job stream;load (computing);load balancing (computing);multi-user;nash equilibrium;pareto efficiency;response time (technology);simulation;structural load;telecommunications network	Satish Penmatsa;Anthony T. Chronopoulos	2011	J. Parallel Distrib. Comput.	10.1016/j.jpdc.2010.11.016	game theory;distributed algorithm;simulation;computer science;load balancing;distributed computing;mathematical economics;telecommunications network	Metrics	-13.143136986761048	64.19591209384488	17939
f285ba728e5565817020713bbb0e9448c2c563f6	soa and wireless mobile networks in the tactical domain: results from experiments	semiconductor optical amplifiers;tactical soa profile land mobile radio mobile nodes soa web services wireless mesh networks;web services electronic messaging military communication military computing mobile radio radio equipment;force;wireless communication;mobile communication;service oriented architecture force semiconductor optical amplifiers mobile communication interoperability wireless communication;interoperability;service oriented architecture;nato friendly force information wireless broadband mobile network node tactical domain service oriented architecture paradigm soa web services radio hardware equipment messaging service	The NATO research task group IST-118 titled “SOA recommendations for disadvantaged grids in the tactical domain” is addressing the challenge of implementing the Service Oriented Architecture (SOA) paradigm at the tactical level by providing guidance and best practices in the form of a Tactical SOA Profile. The group will conduct identification and feasibility assessments of possible improvements of the Tactical SOA Profile, over a series of live and emulated experiments. In this paper, we describe our first experiments in applying SOA Web services to mobile nodes that are connected using Wireless Broadband Mobile Networks (WBMN) in the tactical domain. The experiments involved components provided by various nations, including radio hardware equipment, the Publish/Subscribe messaging service and NATO Friendly Force Information (NFFI) (as our functional service). We measured the system performance at service and physical (radio) levels in the presence of network disruption. We conclude by presenting the results of the experiments and a view of future work.	best practice;denial-of-service attack;emulator;experiment;programming paradigm;publish–subscribe pattern;service-oriented architecture;web service	Marco Manso;Jose Maria Alcaraz Calero;Christoph Barz;Trude Hafsoe Bloebaum;Kevin Chan;Norman Jansen;Frank Trethan Johnsen;Garik Markarian;Peter-Paul Meiler;Ian Owens;Joanna Sliwa;Qi Wang	2015	MILCOM 2015 - 2015 IEEE Military Communications Conference	10.1109/MILCOM.2015.7357508	telecommunications;engineering;tactical communications system;computer security;computer network	Mobile	-18.975555182506504	87.38586702534481	17946
738effac47055263da1602075aecdd736da4c570	protocol engineering principles for cryptographic protocols design	image recognition;gait period biometrics gait expression gait recognition feature extraction;image recognition humans feature extraction data mining spatial databases biometrics image databases computer science video sequences image segmentation;biometrics;gait recognition;nearest neighbor classifier human recognition gait moment image swing distances gait period low quality silhouette images gait probability image noise reduces gait probability distribution moment deviation image gait energy image motion features;gait expression;feature extraction;probability distribution;gait analysis;image recognition feature extraction gait analysis image denoising;image denoising;gait period;nearest neighbor classifier	Design of cryptographic protocols especially authentication protocols remains error-prone, even for experts in this area. Protocol engineering is a new notion introduced in this paper for cryptographic protocol design, which is derived from software engineering idea. We present and illustrate protocol engineering principles in three groups: cryptographic protocol security requirements analysis principles, detailed protocol design principles and provable security principles. Furthermore, we illustrate that some of the well-known Abadi and Needham's principles are ambiguous. This paper is useful in that it regards cryptographic protocol design as system engineering, hence it can efficiently indicate implicit assumptions behind cryptographic protocol design, and present operational principles on uncovering these subtleties. Although our principles are informal, but they are practical, and we believe that they will benefit other researchers.	authentication protocol;cognitive dimensions of notations;communications protocol;cryptographic protocol;cryptography;needham–schroeder protocol;provable security;requirement;requirements analysis;software engineering;systems engineering;whole earth 'lectronic link	Ling Dong;Kefei Chen;Mi Wen;Yanfei Zheng	2007	Eighth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing (SNPD 2007)	10.1109/SNPD.2007.441	probability distribution;computer vision;speech recognition;gait analysis;feature extraction;computer science;machine learning;pattern recognition;biometrics;statistics	SE	-36.99285214650444	69.65644013375457	17959
87009dbcc0d50df51d3fefed18a3705affb10be0	chaos machine: different approach to the application and significance of numbers		In this paper we describe a theoretical model of chaos machine, which combines the benefits of hash function and pseudo-random function, forming flexible one-way push-pull interface. It presents the idea to create a universal tool (design pattern) with modular design and customizable parameters, that can be applied where randomness and sensitiveness is needed (random oracle), and where appropriate construction determines case of application and selection of parameters provides preferred properties and security level. Machine can be used to implement many cryptographic primitives, including cryptographic hashes, message authentication codes and pseudo-random number generators. Additionally, document includes sample implementation of chaos machine named Naive Czyzewski Generator, abbreviated NCG, that passes all the Dieharder, NIST and TestU01 test sets. Algorithm was designed and evaluated to be a cryptographically strong, inasmuch as indistinguishable from a uniform random function. The generator was developed to work as cryptographically secure pseudo-random number generator, collision resistance hash function or a cryptographic module. One can target a given period length by choosing the appropriate space parameter, i.e., for a given parameter m, algorithm is claimed to have period between 2 to 2.	algorithm;collision resistance;cryptographic hash function;cryptographic primitive;cryptographically secure pseudorandom number generator;fips 140-2;message authentication code;modular design;network of cancer genes;one-way function;pseudorandom function family;pseudorandomness;random number generation;random oracle;randomness;reference implementation;software design pattern;strong cryptography;testu01;theory	Maciej A. Czyzewski	2016	IACR Cryptology ePrint Archive			Crypto	-36.54962859766518	81.22855028983383	17967
e4ad3be1258395687b69efec2799cf0017b46d1d	minimizing energy for wireless web access with bounded slowdown	optimal solution;ieee 802 11;protocols;power saving;web pages;wireless;web;http;wireless network;web accessibility;tcp;mobile computer;power saving mode;round trip time;energy consumption;bounded slowdown;power management;tcp performance;web browsing;dynamic adaptation;trace driven simulation;energy saving	"""On many battery-powered mobile computing devices, the wireless network is a significant contributor to the total energy consumption. In this paper, we investigate the interaction between energy-saving protocols and TCP performance for Web-like transfers. We show that the popular IEEE 802.11 power-saving mode (PSM), a """"static"""" protocol, can harm performance by increasing fast round trip times (RTTs) to 100 ms; and that under typical Web browsing workloads, current implementations will unnecessarily spend energy waking up during long idle periods.To overcome these problems, we present the Bounded-Slowdown (BSD) protocol, a PSM that dynamically adapts to network activity. BSD is an optimal solution to the problem of minimizing energy consumption while guaranteeing that a connection's RTT does not increase by more than a factor p over its base RTT, where p is a protocol parameter that exposes the trade-off between minimizing energy and reducing latency. We present several trace-driven simulation results that show that, compared to a static PSM, the Bounded-Slowdown protocol reduces average Web page retrieval times by 5-64%, while simultaneously reducing energy consumption by 1-14% (and by 13× compared to no power management)."""		Ronny Krashinsky;Hari Balakrishnan	2005	Wireless Networks	10.1007/s11276-004-4751-z	hypertext transfer protocol;communications protocol;ieee 802.11;real-time computing;telecommunications;computer science;operating system;wireless network;transmission control protocol;web accessibility;web page;distributed computing;mobile computing;round-trip delay time;wireless;computer network	Mobile	-14.290421480907549	69.03406938647935	17995
78d2e2e9353d251d3094112189a94377adaddf7d	measuring local topological anonymity in social networks	social network services;anonymity;phase measurement;re identification;social sciences;resistance;re identification social networks anonymity;visualization;current measurement;phase measurement social network services electrical resistance measurement correlation visualization current measurement resistance;social networks;identification;electrical resistance measurement;correlation;network theory graphs;social sciences identification network theory graphs;reidentification statistics local topological anonymity measurement social network based services service providers node identity recovery sanitization process sanitized graph structure structural reidentification attacks global reidentifiability global node anonymity local reidentification structurally hidden node structural similarity measures visual inspection local node reidentifiability lta values	Service providers of social network based services release their sanitized graph structure for third parties (e.g., business partners) from time to time. However, as these releases contain valuable information additionally to what is publicly available in the network, these may be targeted by re-identification attacks, i.e., where an attacker tries to recover the identities of the nodes that were removed during the sanitization process. One powerful type of these, called structural re-identification attacks consider only structural properties, and work according to a specific strategy: first they re-identify some nodes by their globally unique properties, and then in an optional second phase, nodes related to these are re-identified by their locally unique properties. Global re-identifiability or global node anonymity is a well studied concept, however, node anonymity for local re-identification has not yet been analyzed. Therefore in this paper, after discussing the related literature on anonymity and re-identification, we introduce the novel term of Local Topological Anonymity (LTA), which describes the resistant power of a node against local re-identification attacks, or, in other words, indicates how well the node is structurally hidden in her neighborhood. Regarding these attacks in the literature, we propose three measure variants of LTA based on structural similarity measures, and evaluate them by visual inspection and simulation in multiple networks. We show that one of the proposed measures provides good prediction on local node re-identifiability as there is correlation between the LTA values and the re-identification statistics provided by the state-of-the-art algorithm.	algorithm;heuristic (computer science);sanitization (classified information);simulation;social network;software propagation;structural similarity;visual inspection	Gábor György Gulyás;Sándor Imre	2012	2012 IEEE 12th International Conference on Data Mining Workshops	10.1109/ICDMW.2012.87	identification;visualization;anonymity;computer science;data mining;internet privacy;resistance;computer security;correlation;social network	DB	-58.4803163614701	63.227719182796356	18032
33853565b4dcad38b9b79091a48d3f40409f06d7	secure multiparty computations on bitcoin	cryptographic protocols;electronic money;bitcoin;mpc;decentralized digital currency;emulation-based definition;online gambling sites;secure multiparty computation protocols;secure multiparty lotteries;timed commitments;bitocoin;lottery;multiparty computations	Is it possible to design an online protocol for playing a lottery, in a completely decentralized way, that is, without relying on a trusted third party? Or can one construct a fully decentralized protocol for selling secret information, so that neither the seller nor the buyer can cheat in it? Until recently, it seemed that every online protocol that has financial consequences for the participants needs to rely on some sort of a trusted server that ensures that the money is transferred between them. In this work, we propose to use Bitcoin (a digital currency, introduced in 2008) to design such fully decentralized protocols that are secure even if no trusted third party is available. As an instantiation of this idea, we construct protocols for secure multiparty lotteries using the Bitcoin currency, without relying on a trusted authority. Our protocols guarantee fairness for the honest parties no matter how the loser behaves. For example, if one party interrupts the protocol, then her money is transferred to the honest participants. Our protocols are practical (to demonstrate it, we performed their transactions in the actual Bitcoin system) and in principle could be used in real life as a replacement for the online gambling sites.	bitcoin;digital currency;fairness measure;interrupt;money;real life;server (computing);trusted third party;universal instantiation	Marcin Andrychowicz;Stefan Dziembowski;Daniel Malinowski;Lukasz Mazurek	2013	2014 IEEE Symposium on Security and Privacy	10.1145/2896386	trusted third party;internet privacy;world wide web;computer security	Security	-42.75139707017313	71.62729066242224	18042
78b8ab0081c28c94c56bf01f93f4753de4dcd7d0	using soft real-time scheduling schemes to support continuous media			real-time transcription;scheduling (computing)	Changpeng Fan	1995			real-time computing;scheduling (computing);computer science	Embedded	-11.495418513666037	62.59433614827601	18068
f4029c60178926590514b50b7cca5c9e3ae695c4	game-theoretic scalable peer-to-peer media streaming	incentive mechanisms peer to peer streaming unstructured networks game theory repeated games nash equilibrium strategies;incentive mechanism;protocols;degradation;streaming media peer to peer computing bandwidth protocols game theory web server scalability incentive schemes degradation network servers;game theory;incentive mechanisms;nash equilibrium;conference_paper;incentive mechanism peer to peer media streaming game theory performance degradation peer streaming performance;peer to peer computing game theory media streaming;repeated game;network servers;peer to peer streaming;streaming media;peer to peer media streaming;repeated games;nash equilibrium strategies;unstructured networks;media streaming;bandwidth;scalability;web server;incentive schemes;peer streaming performance;peer to peer computing;strategic game;performance degradation;peer to peer	Peer-to-peer media streaming framework has been widely considered as a promising platform for delivering high quality multimedia content on the global scale. A fundamental requirement is that each peer needs to contribute outgoing bandwidth to deliver media packets to its neighbors. Although most existing protocols mandate such contribution, misbehaving peers may still deliberately limit their outgoing bandwidth to conserve their own resources. This would inevitably lead to performance degradation of other well-behaving peers. It is crucial to have an effective incentive mechanism such that peers are encouraged to contribute. In this paper, we formulate two strategic games to model the interactions between server and its immediate peers and between neighboring peers, respectively. We have devised the equilibrium strategies which relate a peer's streaming performance to its contribution. Simulation results show that the proposed game-theoretical incentive mechanism protects well-behaving peers from being exploited by misbehaving counterparts.	display resolution;elegant degradation;game theory;interaction;peer-to-peer;requirement;scalability;server (computing);simulation;streaming media	Mark Kai Ho Yeung;Yu-Kwong Kwok	2008	2008 IEEE International Symposium on Parallel and Distributed Processing	10.1109/IPDPS.2008.4536231	game theory;computer science;repeated game;distributed computing;internet privacy;computer network	Arch	-25.310251391488507	73.5416117397954	18090
9191e378c0cf1ae53bb838e92dce72a84afba0d7	session details: session 5b: secure computation 2			secure multi-party computation	Kenneth G. Paterson	2018		10.1145/3285878		Crypto	-42.84397813283593	76.68587348272725	18103
ae64d00dcdc3937e0548537227995a97cb248a24	performance-aware security of unicast communication in hybrid satellite networks	satellite communication;file servers;unicast communication;satellite network;protocols;internet key exchange protocol;end to end communication security;internet key exchange;http;tcp;unicast security protocols;layered internet security protocol;hybrid satellite networks;dual mode secure socket layer protocol;satellite channel;end to end communication security performance aware security unicast communication hybrid satellite networks unicast security protocols layered internet security protocol tcp http performance enhancing proxy servers satellite channel network layer security internet key exchange protocol dynamic key establishment web browsing dual mode secure socket layer protocol;transport protocols;performance aware security;adverse effect;computer network performance evaluation;internet;cryptography;satellites;decision support systems;telecommunication security;unicast artificial satellites protocols web server internet html network servers delay tcpip cryptography;simulation study;performance enhancing proxy servers;web server;web browsing;end to end delay;transport protocols computer network performance evaluation file servers internet satellite communication telecommunication security;proxy server;network layer security;key establishment;dynamic key establishment;security protocol	In this work, we address the performance problems that arise when unicast security protocols IPSEC and SSL are applied for securing the end-to-end communication in hybrid satellite networks. Satellite networks use TCP and HTTP performance-enhancing proxy servers to overcome the adverse effect of the large delay-bandwidth product of the satellite channel. However, the proxy servers cannot function when IPSEC and SSL are used for secure unicast communication in hybrid satellite networks. We therefore propose the use of the Layered IPSEC (LES) protocol as an alternative to IPSEC for networklayer security. We describe a modification to the Internet Key Exchange protocol if dynamic key establishment is needed for Layered IPSEC. For application-level security of web browsing with acceptable end-to-end delay, we propose the Dual-mode SSL protocol (DSSL) to be used instead of SSL. We describe how LES and DSSL protocols achieve the desired end-to-end communication security while allowing the TCP and HTTP proxy servers to function correctly. Through simulation studies, we quantify the improvement in performance that is achieved using our proposed protocols, compared to traditional IPSEC and SSL.	algorithm;communications security;end-to-end encryption;end-to-end principle;hypertext transfer protocol;ipsec;internet key exchange;large eddy simulation;mathematical optimization;performance-enhancing proxy;proxy server;unicast	Ayan Roy Chowdhury;John S. Baras	2009	2009 IEEE International Conference on Communications	10.1109/ICC.2009.5199335	internet key exchange;decision support system;adverse effect;computer science;cryptography;security parameter index;internet privacy;computer security;web server;computer network	Security	-8.443472244352142	91.33310357379086	18110
9763fa25516b19ecec14d8d71144d9421fa43218	a novel quantum scheme for secure two-party distance computation	secure multiparty computation;computational geometry;quantum private query;secure two-party distance	Secure multiparty computational geometry is an essential field of secure multiparty computation, which computes a computation geometric problem without revealing any private information of each party. Secure two-party distance computation is a primitive of secure multiparty computational geometry, which computes the distance between two points without revealing each point’s location information (i.e., coordinate). Secure two-party distance computation has potential applications with high secure requirements in military, business, engineering and so on. In this paper, we present a quantum solution to secure two-party distance computation by subtly using quantum private query. Compared to the classical related protocols, our quantum protocol can ensure higher security and better privacy protection because of the physical principle of quantum mechanics.	computation	Zhen-wan Peng;Runhua Shi;Hong Zhong;Jie Cui;Shun Zhang	2017	Quantum Information Processing	10.1007/s11128-017-1766-9	theoretical computer science;quantum mechanics;computation;physics;computational geometry;quantum algorithm;quantum network;commitment scheme;quantum;secure two-party computation;secure multi-party computation	Theory	-40.68029953998017	74.69226645231129	18143
3faad7a776d42e9447b75ab481626e4786ef6d4e	toward ubiquitous communication platform for emergency medical care	mobile ipv6;mobile network	Interaction between emergency medical technicians (EMTs) and doctors is essential in emergency medical care. Doctors require diverse information related to a patient to provide efficient aid. In 2005, we started the Ikoma119 project and have developed a ubiquitous communication platform for emergency medical care called Mobile ER. Our platform, which is based on wireless internet technology, has such desirable properties as low-cost, location-independent service, and ease of service introduction. We provide an overview of our platform and describe the services that we have developed. We also discuss the remaining issues to realize our platform’s actual operation. key words: emergency medical care, mobile network, Mobile IPv6, network mobility	internet protocol suite;location-based service;mobile ip;proxy mobile ipv6;ubiquitous computing	Kenichi Ishibashi;Naoto Morishima;Masayuki Kanbara;Hideki Sunahara;Masami Imanishi	2009	IEICE Transactions		internet protocol;cellular network;the internet;simulation;internationalization and localization;telecommunications;computer science;computer security;mobile ip;computer network	HCI	-16.72770394527446	89.38052439604547	18165
330c149538052ca7f75a66f0cae9c41b4b8df5d0	a dynamic resource defragmentation scheme for virtualized sdn-enabled substrate networks		"""Virtual network embedding (VNE) was subject to extensive research which lead to the emergence of a large number of efficient online VNE algorithms. When virtual networks (VNs) arrive and depart over time, the substrate network can easily drift into an inefficient configuration, where resources are increasingly fragmented causing a VN request rejection although cumulatively, there are enough available resources. The ability to reallocate running VNs clearly leads to a better resource utilization. In this paper, we propose """"Garbage Collector""""(GC), a novel network control program for dynamic and online resource management in virtualized SDN-enabled substrates. GC efficiently addresses the fragmentation problem by performing selective migration. Simulations show that GC clearly improves acceptance ratio of VNE algorithms. They also reveal that, it outperforms some existing works from the literature by increasing the VN acceptance ratio by more than 10%."""	acceptance testing;computer simulation;emergence;fragmentation (computing);garbage collection (computer science);network control program;network topology;rejection sampling;selection algorithm;software-defined networking	Armel Francklin Simo Tegueu;Slim Abdellatif;Thierry Villemur;Pascal Berthou	2017	2017 IEEE 6th International Conference on Cloud Networking (CloudNet)	10.1109/CloudNet.2017.8071530	defragmentation;resource management;virtual network;garbage collection;network control program;fragmentation (computing);computer science;distributed computing	HPC	-19.903427319138345	62.85981549659835	18177
956ab989370d60f7eca008bc3fea7102dcf8f436	reservation based wavelength assignment for sparse groomed optical wdm mesh networks	blocking probability;wavelength routing;wavelength assignment;synchronous digital hierarchy;photonic switching systems;wdm network;probability;optical switch;traffic grooming;wavelength assignment wavelength routed network optical wavelength division multiplexed network wdm mesh network channel capacity electronic traffic groomed network sonet sdh groomers synchronous optical network synchronous digital hierarchy core optical cross connect nodes oxc optical switching blocking probability wavelength reservation discrete event simulation technique network performance arpanet nsfnet topology;telecommunication traffic;performance improvement;optical cross connect;telecommunication network routing;channel capacity;channel capacity wavelength division multiplexing telecommunication network routing telecommunication network topology telecommunication traffic sonet synchronous digital hierarchy photonic switching systems probability discrete event simulation;mesh network;telecommunication network topology;wavelength assignment optical fiber networks wavelength division multiplexing wdm networks mesh networks telecommunication traffic network topology wavelength routing channel capacity sonet;sonet;core network;wavelength division multiplexing;discrete event simulation;wavelength division multiplex	In this paper, we consider performance improvements for a sparse groomed wavelength routed optical wavelength division multiplexed (WDM) network. In such networks, the wavelength capacity per channel can be as high as 40 Gbps whereas the individual session requests can be much lower. Traffic grooming, that multiplexes several sessions on a wavelength, is a widely studied technique to reduce the effects of this capacity mismatch. In this paper, we consider an electronic traffic groomed network that consists of SONET/SDH groomers at the core optical cross connect (OXC) nodes. Since these groomers are expensive, reducing the number of groomers needed is an important design goal. A sparse groomed network is defined as one where only a subset of the core network nodes possess grooming capability in addition to optical switching; other nodes only possess optical switching and optical add/drop capabilities. In order to improve the overall blocking probability, we present a mechanism for reserving wavelengths between the grooming nodes in a network. The performance of the mechanism is studied using discrete event simulation techniques for various topologies and system parameters. The results show that when we reserve enough wavelengths for groomed traffic, the performance of the network is improved by up to 100% and up to 76% for ARPANET and NSFNET topologies respectively.	blocking (computing);data rate units;digital cross connect system;erlang (unit);mesh networking;national science foundation network;optical cross-connect;optical switch;routing;simulation;sparse matrix;synchronous optical networking;wavelength-division multiplexing	Sundar Subramani;Krishna M. Sivalingam	2005	2nd International Conference on Broadband Networks, 2005.	10.1109/ICBN.2005.1589613	core network;traffic grooming;telecommunications;computer science;discrete event simulation;mesh networking;synchronous optical networking;probability;optical switch;channel capacity;wavelength-division multiplexing;optical cross-connect;computer network	HPC	-5.893943741085333	84.64077631207397	18179
217981c9635213fb9a415c379c336f36b151931e	real-time control systems secured communication		Abstract As demands on privacy, personal data and in general secure and responsible dealing with confidential personal information are growing, the need for their protection grows as well. When confidential data are being transported, there is a high risk of their stole and misuse or complete loss. Thatu0027s why a question of secure communication is one of the most actual topics of a present day. Itu0027s not just information technologies problem, but since embedded and automation devices are more and more sophisticated, able to use for example internet technologies, this question also concerns the area of automation and control systems. Especially in complex distributed control and measurement systems that supports remote control, internet visualization, wireless transfers or remote data acquisition, it is the primary goal to ensure the most secure and reliable communication. This work deals with securing the communication of embedded systems connected over public networks and internet. To fulfill that, PKI technologies are used. Benefits of secured communication are employed in Guardian system, patient monitoring platform developed at Technical University of Ostrava.	control system;real-time transcription	Petr Czekaj;Ondrej Krejcar	2009		10.3182/20090210-3-CZ-4002.00006	engineering;internet privacy;world wide web;computer security	Robotics	-45.821731893044884	62.662525375982526	18180
4fde15a77dd74bb4d1cb287074f1fd1a3fbbc2e0	stean: a storage and transformation engine for advanced networking context	firewalls computing;routing protocols;context switches routing protocols firewalls computing engines;engines;software defined networking internet;switches;context;state transformation stean storage and transformation engine for advanced networking context legacy internet systems software defined networking sdn network function virtualization nfv	Legacy Internet systems and protocols are mostly static and keep state information in silo-style storage, thus making state migration, transformation and re-use difficult. Software Defined Networking (SDN) approaches in unison with Network Functions Virtualization (NFV) allow for more flexibility, yet they are currently restricted to a limited set of state migration options. Impeding the sharing of networking and system state severely limits the ability to optimally manage resources and dynamically adapt to a desirable overall configuration. We propose a generalized way to collect, store, transform, and share context between NFs in both the legacy Internet and NFV/SDN-driven systems. To this end, we design and implement a Storage and Transformation Engine for Advanced Networking Context (STEAN), which constitutes a shared context storage, making network state information available to other systems and protocols. Its pivotal feature is the ability to allow for state transformation as well as for persisting state to enable future reuse. By means of experimentation, we show that STEAN covers a diverse set of challenging use cases in legacy systems as well as in NFV/SDN-enabled systems.	communications protocol;internet;legacy system;network function virtualization;overhead (computing);routing;silo;software deployment;software-defined networking;unison	Marc Werner;Johannes Schwandke;Matthias Hollick;Oliver Hohlfeld;Torsten Zimmermann;Klaus Wehrle	2016	2016 IFIP Networking Conference (IFIP Networking) and Workshops	10.1109/IFIPNetworking.2016.7497203	active networking;real-time computing;computer science;distributed computing;computer network	Networks	-15.133831223782096	83.03417701640564	18187
7ca75e79462dca6b89de9cb301899a6550d8c3cd	determining a parallel session attack on a key distribution protocol using a model checker	parallel session attack;model checking;attacks on security protocols;formal analysis;security protocol;formal analysis of security protocols;key distribution	The use of security protocols to protect sensitive information is critical. However, flaws in the design of security protocols can make them ineffective. This paper discusses various attacks against security protocols that exploit weaknesses in their design and a key-distribution protocol is analysed using a model checker. The analysis reveals weaknesses in the protocol, which can be exploited in a parallel session attack that allows an attacker to impersonate a legitimate principal. Correction to the protocol are proposed and a formal analysis of the fix is presented. The results of this analysis provide confidence in the correctness and effectiveness of the proposed corrected protocol.	correctness (computer science);cryptographic protocol;information sensitivity;key distribution;model checking	Vladimir Pasca;Anca Jurcut;Reiner Dojen;Tom Coffey	2008		10.1145/1497185.1497218	computer security model;model checking;otway–rees protocol;reflection attack;universal composability;computer science;security service;internet privacy;security testing;key distribution;computer security;computer network	Security	-43.85960225612477	74.06066134782535	18195
19372e74da57e948ba0d813f3853eb2ed3a68f6a	a behavior-based method for detecting dns amplification attacks	dns;ddos;k means;detection;amplification	DNS (Domain Name System) amplification attack has become a popular form of the attacks of the Distributed Denial of Service (DDoS) in recent years. In DNS amplification attacks, the attackers utilize spoofed source IP addresses and open recursive DNS servers to perform the bandwidth consumption attacks. A lot of responses are generated and they are sent to the targets after the attackers send only a little of DNS requests. Various methods have been proposed for detecting the DNS amplification attacks. However, almost of them have to determine parameters in advance, which is not easy for many cases. In this study, we utilized the detection pattern and combination of three features to distinguish normal and attack. It can solve the problem that limitation of detection in the case of high-frequency and low-amplification attack.	denial-of-service attack;recursion;sensor	Longzhu Cai;Yaokai Feng;Junpei Kawamoto;Kouichi Sakurai	2016	2016 10th International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS)	10.1109/IMIS.2016.88	computer science;internet privacy;computer security;denial-of-service attack;domain name system;computer network;k-means clustering	Security	-59.99020011951329	66.4458465184472	18199
7ed14fbda99a340601ee762c2d96ee7515433e8e	large-scale geolocation for netflow	anomaly;telecommunication traffic internet ip networks;geology prototypes databases ip networks data analysis educational institutions google;nfdump;netflow;detection;telecommunication traffic;iso 3166;internet;geoip;nfsen;ip networks;bit rate 10 gbit s ip address geolocation large scale geolocation netflow business advertisements security analysis internet connection exporter based geolocation collector based geolocation;security;geolocation	The importance of IP address geolocation has increased significantly in recent years, due to its applications in business advertisements and security analysis, among others. Current approaches perform geolocation mostly on-demand and in a small-scale fashion. As soon as geolocation needs to be performed in real-time and in high-speed and large-scale networks, these approaches are not scalable anymore. To solve this problem, we propose two approaches to large-scale geolocation. Firstly, we present an exporter-based approach, which adds geolocation data to How records in a way that is transparent to any How collector. Secondly, we present a How collector-based approach, which adds native geolocation to NetFlow data from any How exporter. After presenting prototypes for both approaches, we demonstrate the applicability of large-scale geolocation by means of use cases. Our prototypes have shown to be scalable enough for deployment on the 10 Gbps Internet connection of the Masaryk University.	aggregate data;anomaly detection;data rate units;geolocation;malware;next-generation network;preprocessor;prototype;real-time clock;real-time computing;real-time transcription;scalability;software deployment;video post-processing	Pavel Celeda;Petr Velan;Martin Rabek;Rick Hofstede;Aiko Pras	2013	2013 IFIP/IEEE International Symposium on Integrated Network Management (IM 2013)		computer science;information security;geolocation;internet privacy;computer security;computer network	OS	-58.98064342568638	64.60778816422228	18213
39be6ff44eb19599b175363f12cca5ee857b1987	characterizing spdy over high latency satellite channels		The increasing complexity of Web contents and the growing diffusion of mobile terminals, which use wireless and satellite links to get access to the Internet, impose the adoption of more specialized protocols. In particular, we focus on SPDY, a novel protocol introduced by Google to optimize the retrieval of complex webpages, to manage large Round Trip Times and high packet losses channels. In this perspective, the paper characterizes SPDY over high latency satellite links, especially with the goal of understanding whether it could be an efficient solution to cope with performance degradations typically affecting Web 2.0 services. To this aim, we implemented an experimental set-up, composed of an ad-hoc proxy, a wireless link emulator, and an instrumented Web browser. The results clearly indicate that SPDY can enhance the performances in terms of loading times, and reduce the traffic fragmentation. Moreover, owing to its connection multiplexing architecture, SPDY can also mitigate the transport layer complexity, which is critical when in presence of Performance Enhancing Proxies usually deployed to isolate satellite trunks.	esa;emulator;fragmentation (computing);hoc (programming language);hypertext transfer protocol;internet;interrupt latency;multiplexing;network packet;performance;performance-enhancing proxy;spdy;scheduling (computing);testbed;web 2.0	Luca Caviglione;Alberto Gotta	2014	ICST Trans. Mobile Communications Applications	10.4108/mca.2.5.e3	spdy;computer network;satellite;latency (engineering);computer science;communication channel	Networks	-7.804810806004491	91.71721298409291	18223
3b9e15b32ca096e7ab1de673c94e113ec0fe268f	high effect secure data transmission mechanisms in wireless sensor networks using id-based key management scheme		This study presents an ID-based key management scheme that exploits an implied public key to address secure data transmissions for reducing required memory capacities and CPU computations in Wireless Sensor Networks (WSNs). In the proposed scheme, each sensor node only has to store a secret key for encrypting and aggregating data during transmissions. Furthermore, the system supports direct and aggregate data transmission modes that provide rapid and secure transmission methods without complex decryption and large bandwidth consumption for sensor nodes. This approach is efficient enough to be implemented on large-scale WSNs.	aggregate data;central processing unit;computation;encryption;key (cryptography);key management;public-key cryptography;secure transmission;sensor node	Hua-Yi Lin	2009	JCIT		wireless wan;wireless sensor network;wireless site survey;computer science;wireless network;key management;distributed computing;key distribution in wireless sensor networks;wi-fi array;fixed wireless;mobile wireless sensor network;computer security;computer network;data transmission	Security	-50.216633244299686	76.11190218695822	18233
78c6b34b827e26a8d2fd5df7c2abc1392630b2b8	ensuring privacy in location-based services: an approach based on opacity enforcement	opacity;discrete event systems;location privacy	With the proliferation of mobile devices, Location-Based Services (LBS) that provide networked services based on users’ locations have become increasingly popular. Such services, providing personalized and timely information, have raised privacy concerns such as unwanted revelation of users’ current locations to potential stalkers. Many prior studies have proposed to address LBS privacy by sending “cloaking queries” that contain coarser location information. However, this method has been shown to be insufficient and no formal methodology exists for enforcing LBS privacy in mobile environments. In this work, we show that this problem can be formally addressed using the notion of opacity in discrete event systems. We use nondeterministic finite-state automata to capture the mobility patterns of users and label the transitions by the location information in the queries. Using opacity verification techniques, we show that the technique of sending cloaking queries to the server can still reveal the exact location of the user. To enforce location privacy, we apply the opacity enforcement technique by event insertion proposed in our prior work. Specifically, we synthesize suitable insertion functions that insert fake queries into the cloaking query sequences. The generated fake queries are always consistent with the mobility model of the user and provably ensure privacy of the user’s current location. Finally, to minimize the overhead from fake queries, we design an optimal insertion function that introduces minimum average number of fake queries.	automata theory;finite-state machine;location-based service;mobile device;overhead (computing);personalization;privacy;server (computing);springer (tank)	Yi-Chin Wu;Karthik Abinav Sankararaman;Stéphane Lafortune	2014		10.3182/20140514-3-FR-4046.00008	computer science;internet privacy;world wide web;computer security	Security	-40.59622963352028	60.61631720836586	18260
915b9224088a6a747f647847062fcce886d58103	an adaptive rate-based method for maintaining consistency in networked multiplayer computer games	consistency regulation adaptive rate based method networked multiplayer computer games client server network conditions;computer games client server systems;client server systems;bandwidth games servers computational modeling computers simulation;client server networks;multiplayer computer games;computer games;client server networks consistency multiplayer computer games;consistency	This paper presents a dynamic, rate-based method that regulates consistency, in response to changes in the underlying network, for client-server-based Multiplayer Computer Games. It operates on the premise that, as the network conditions between client and server changes, so too does the inconsistency from the client's viewpoint. Hence, adapting the rate of updates between the server and the client can help maintain an acceptable level of consistency.	client–server model;pc game;server (computing)	Séamus McLoone;Tomás Ward;Damian Wynne;Aaron McCoy	2012	2012 IEEE/ACM 16th International Symposium on Distributed Simulation and Real Time Applications	10.1109/DS-RT.2012.30	client;real-time computing;computer science;client-side;distributed computing;server-side;fat client;world wide web;game client;remote evaluation	Arch	-10.803301581370473	103.48496756819694	18269
548ddf7e29065e3ded9029006ac81d166e56b796	scramble! your social network data	authorised user;data item;access control list;access control;checks integrity;social network data;cryptographic technique;encrypted content;current sns site;sns provider;sns-independent firefox extension	Social network sites (SNS) allow users to share information with friends, family, and other contacts. However, current SNS sites such as Facebook or Twitter assume that users trust SNS providers with the access control of their data. In this paper we propose Scramble, the implementation of a SNS-independent Firefox extension that allows users to enforce access control over their data. Scramble lets users define access control lists (ACL) of authorised users for each piece of data, based on their preferences. The definition of ACL is facilitated through the possibility of dynamically defining contact groups. In turn, the confidentiality and integrity of one data item is enforced using cryptographic techniques. When accessing a SNS that contains data encrypted using Scramble, the plugin transparently decrypts and checks integrity of the encrypted content.	access control list;authorization;bcrypt;blog;cloud computing;confidentiality;data item;encryption;firefox;jan bergstra;microtransaction;public-key cryptography;scrambler;social network;web 2.0;wiki	Filipe Beato;Markulf Kohlweiss;Karel Wouters	2011		10.1007/978-3-642-22263-4_12	computer science;internet privacy;world wide web;computer security	Security	-47.32848243055881	64.65893898060486	18279
73ea4acb9dffc155992092b52293227043304538	evaluation of video streaming performance over peer-to-peer network	video streaming ip networks peer to peer computing telecommunication congestion control;network simulator 2 ns2 video streaming peer to peer network real time transport protocols mpeg 4;network congestion video streaming performance peer to peer network video service smart tv access internet connectivity packets loss ip based network video quality;streaming media peer to peer computing delays bandwidth psnr servers video recording	The streaming of video service, either live or video on-demand streaming is in receipt of remarkable attraction from the users and industry. The ISPs nowadays provide the smart TV access over the Internet connectivity, where the users can access the real-time contents adjoining to the trendy contents like web browsing, email and downloading. The multimedia applications, specifically video streaming contains delay, bandwidth and packets loss requirements. The congestion over the network is a critical factor that creates packets loss, consequently the quality of streaming video is degraded. In this paper, evaluation of the video streaming performance has been performed by applying different simulation scenarios over IP-based network. The core objective is to analyse the network behaviour and video quality. The network behaviour includes packets loss, end-to-end delay and throughput. The received video quality is compared and analysed using application level values, which include Peak Signal to Noise Ratio (PSNR) method and Mean Opinion Score (MOS) scale. In this paper, each experiment performed in simulation, shows different network behaviour and quality of received video depending on the network congestion and sent with dummy background traffic.	bandwidth (signal processing);best-effort delivery;differentiated services;download;dummy variable (statistics);email;end-to-end principle;experiment;integrated services;internet;network congestion;network packet;peak signal-to-noise ratio;peer-to-peer;quality of service;real-time clock;real-time web;requirement;simulation;smart tv;streaming media;throughput;uncompressed video;video	Shafquat Ali Memon;Syed Raheel Hassan;Nisar Ahmed Memon	2014	2014 International Conference on Collaboration Technologies and Systems (CTS)	10.1109/CTS.2014.6867597	multimedia;internet privacy;computer network	Metrics	-7.088253888894383	99.11548014509476	18295
2b8a0628dbb96c588d2e315b9da3492ee05c8580	routing dependable connections with specified failure restoration guarantees in wdm networks	backup lightpath;wavelength routing;wdm network;fault tolerant;telecommunication network reliability;primary lightpaths;primary backup multiplexing;simulation;telecommunication congestion control;failure restoration guarantees;dependable connections;blocking performance;optical fibre networks;simulation experiment;telecommunication traffic;computational modeling;telecommunication network routing;fault tolerant requirements;link failure;fault tolerance;performance gain;intelligent networks wdm networks fault tolerance wavelength routing wavelength division multiplexing performance gain optical buffering telecommunication traffic fault diagnosis computational modeling;wdm networks;intelligent networks;primary backup;telecommunication traffic telecommunication network routing fault tolerance telecommunication network reliability wavelength division multiplexing optical fibre networks telecommunication congestion control;load conditions dependable connections failure restoration guarantees wdm networks wavelength routing wavelength division multiplexing fault tolerant requirements backup lightpath primary backup multiplexing primary lightpaths simulation blocking performance;optical buffering;fault diagnosis;wavelength division multiplexing;wavelength division multiplex;load conditions	This paper considers the problem of dynamically establish ing dependable connections (D-connections) with specified failure restoration guarantees in wavelength-routed wavelength-divisio n multiplexed (WDM) networks. We call a connection with fault tolerant requirements as a D-connection. We recommend using a pro-active approach to fault tolerance wherein a D-connection is identified with the esta blishment of a primary and a backup lightpath at the time of honoring the connection request. However, the backup lightpath may not be available toa connection throughout its existence. Upon occurrence of a fault, a fail ed connection is likely to find its backup path available with a certain specified guarantee. We develop algorithms to select routes and wavelengths to es tablish Dconnections with specified failure restoration guarantees . The algorithms are based on a technique calledprimary-backup multiplexing . We present an efficient and computationally simple method to estimate t he average number of connections per link for which the backup paths arenot readily available upon occurrence of a link failure. This measure is used for selecting suitable primary and backup lightpaths for a connection. We conduct extensive simulation experiments to evaluate the e ff ctiveness of the proposed algorithms on different networks. The resultsshow that the blocking performance gain is attractive enough to allow some reduction in guarantee. In particular, under the light load conditions, more than 90% performance gain is achieved at the expense of less than 10% g uarantee reduction.	algorithm;backup;blocking (computing);circuit restoration;experiment;fault tolerance;requirement;routing;simulation;wavelength-division multiplexing	Gurusamy Mohan;Arun K. Somani	2000		10.1109/INFCOM.2000.832576	fault tolerance;real-time computing;telecommunications;computer science;computer network	Networks	-7.2645947049165915	82.29828592382091	18298
65f0d47998c23e5af91511bb0a71150af6b17e43	uniform price auction for allocation of dynamic cloud bandwidth	resource allocation cloud computing game theory numerical analysis pricing;game theory auction pricing cloud bandwidth;numerical simulation uniform price auction dynamic cloud bandwidth allocation cloud service ubiquitous adoption cloud user applications two tier pricing model reservation phase dynamic phase supply uncertainty game theoretical approach price stability;bandwidth resource management pricing interrupters numerical models channel allocation stability analysis	With the ubiquitous adoption of Cloud services by both companies and consumers alike, lack of an efficient system to explicitly price and allocate limited bandwidth has severely impacted the performance of Cloud user-applications. In this context, we consider a two-tier pricing model - consisting of Reservation Phase and Dynamic Phase - that caters to the needs of different kinds of applications. While the Reservation Phase can be used by Cloud users to obtain guarantees on minimum bandwidth well ahead in time, Dynamic Phase can be used to demand and obtain (possibly) additional bandwidth dynamically. Bandwidth being a limited resource, we develop a unique multi-stage uniform price auction with supply uncertainty to dynamically allocate bandwidth to users in the Dynamic Phase. We study the proposed model using a game theoretical approach. Our results prove that proposed auction mechanism is a promising approach for bandwidth allocation. We show that the model promotes the dual advantage of market efficiency and maximum revenue for the Cloud provider. We also demonstrate the price stability using numerical simulations. We argue that for rational, payoff-maximizing tenants of Cloud, the price is stable over the long run which makes the mechanism suitable for practical use.	bandwidth (signal processing);cloud computing;multitier architecture;numerical analysis;platform as a service;simulation;supercomputer education research centre;value (ethics);vii;work breakdown structure	Wee Kim Tan;Dinil Mon Divakaran;Gurusamy Mohan	2014	2014 IEEE International Conference on Communications (ICC)	10.1109/ICC.2014.6883772	simulation;dynamic bandwidth allocation	DB	-23.077976794554733	65.27343726569316	18308
578d560f6e2bf5367611ece12603f0647b2e3473	a versatile suite of strong authenticated key agreement protocols for body area networks	public key cryptography;wireless networks;ieee standards;body sensor networks;authentication;cryptographic protocols;wireless body area network wireless communication network initial security setup single device authenticated multiple key agreement protocol elliptic curve hidden public key transfer pre shared password numerical display fractional variation common unauthenticated base protocol ieee standard wireless ban;protocols public key elliptic curves dh hemts authentication wireless communication;elliptic curve cryptography;telecommunication security;telecommunication security body area networks cryptographic protocols ieee standards public key cryptography security of data;key agreement;wireless networks authentication elliptic curve cryptography key agreement body sensor networks;body area networks;security of data	Authenticated key agreement protocols are increasingly being applied to wireless communications for initial security setup. They were, however, traditionally developed one by one without regard to the structural and computational differences between one protocol and another. This paper addresses a rising need for implementing, in a single device, multiple key agreement protocols authenticated with different means and hence suitable to a variety of device configurations. It presents three elliptic curve based key agreement protocols with authentication via hidden public key transfer, pre-shared password, and numerical display, and with only fractional variations from a common unauthenticated base protocol. It also analyzes their security. These protocols have been adopted into a new IEEE standard on wireless body area networks (BAN); they are applicable to other wireless networks as well.	authentication;communications protocol;computation;dictionary attack;elliptic curve cryptography;key-agreement protocol;man-in-the-middle attack;numerical analysis;online and offline;password;public-key cryptography	Jin-Meng Ho	2012	2012 8th International Wireless Communications and Mobile Computing Conference (IWCMC)	10.1109/IWCMC.2012.6314287	ieee 802.11s;key;yak;security association;computer science;authentication protocol;wireless network;authentication;cryptographic protocol;elliptic curve cryptography;key distribution in wireless sensor networks;internet privacy;public-key cryptography;key distribution;computer security;computer network	Crypto	-47.4945760889441	75.19081708995041	18315
8761befb120989cc3f67aede9abd5e6e25402c36	interactions between http adaptive streaming and tcp	video streaming;http;tcp;adaptive streaming	HTTP adaptive streaming (HAS) is quickly becoming a popular mechanism for delivering on-demand video content over the Internet. The chunked transmission and application-layer adaptation create a very different traffic pattern than traditional progressive video downloads where the entire video is downloaded with a single request.  In this paper, we investigate experimentally the interplay between HAS and the network transport control protocol (TCP). We investigate the impact of network delay on achievable throughput and discover that HAS streams cannot fully utilize the available bandwidth due to the start and stop nature of HAS traffic patterns and its interaction with TCP. We investigate TCP pacing as a potential solution to this issue, particularly for packet losses that occur as a result of bursting packets into the network at the start of a transmission. We find that pacing can significantly increase a TCP flow's congestion window but it does not necessarily translate into higher throughput. Instead, we find that packet losses at the end of chunk transmission have a greater impact on throughput.	digital video;experiment;hypertext transfer protocol;interaction;internet;network congestion;network packet;progressive scan;streaming media;tcp congestion control;tcp pacing;throughput	Jairo O. Esteban;Steven A. Benno;Andre Beck;Yang Guo;Volker Hilt;Ivica Rimac	2012		10.1145/2229087.2229094	compound tcp;tcp congestion-avoidance algorithm;hypertext transfer protocol;tcp delayed acknowledgment;real-time computing;tcp global synchronization;tcp westwood plus;tcp pacing;telecommunications;computer science;tcp hole punching;transmission control protocol;h-tcp;zeta-tcp;hstcp;tcp tuning;tcp acceleration;tcp friendly rate control;slow-start;computer network	Networks	-7.0296149208426675	97.54494798661037	18359
23779b2e69f48370b21b046bb9a6c84987c33637	evaluating network intrusion detection systems for high-speed networks		Network Intrusion Detection Systems (NIDSs) play a crucial role in detecting malicious activities within the networks. Basically, an NIDS monitors network flows and compares it with the pre-defined suspicious patterns. To be effective, different intrusion detection algorithms and packet capturing methods have been implemented. With rapidly increasing network speeds, NIDSs face a challenging problem of monitoring large and diverse traffic volumes; in particular, the high packet drop rate has a significant impact on detection accuracy. In this work, we investigate three popular open-source NIDSs: Snort, Suricata, and Bro along with their comparative performance benchmarks. We investigate key factors (including system resource usage, packet processing speed and packet drop rate) that limit applicability of NIDSs to large-scale networks. Moreover, we also analyse and compare the performance of NIDSs when configurations and traffic volumes are changed.	algorithm;benchmark (computing);bro;intrusion detection system;network packet;open-source software;packet analyzer;pattern matching;response time (technology);sensor;snort;software-defined networking;suricata;thread (computing)	Qinwen Hu;Muhammad Rizwan Asghar;Nevil Brownlee	2017	2017 27th International Telecommunication Networks and Applications Conference (ITNAC)	10.1109/ATNAC.2017.8215374	flow network;resource (disambiguation);the internet;packet processing;intrusion detection system;network packet;computer network;computer science	Security	-61.83883448399005	66.79534294834264	18379
56ab9209c3c97f9576b9c217f50114411f216477	range multicast routers for large-scale deployment of multimedia application	multimedia application;overlay multicast;vcr like interactivity;interactive multimedia;large scale;video on demand;multimedia communication	In this paper, we present the Range Multicast protocol and the implemented prototype. We propose to demonstrate the system at the 2004 ACM Multimedia Conference.	multicast;prototype;software deployment	Ning Jiang;Yao Hua Ho;Kien A. Hua	2004		10.1145/1027527.1027558	multicast;ip multicast;inter-domain;reliable multicast;protocol independent multicast;computer science;pragmatic general multicast;internet group management protocol;multimedia;interactive media;distance vector multicast routing protocol;source-specific multicast;multimedia broadcast multicast service;world wide web;xcast;computer network	HPC	-15.640089091096518	94.46917043550214	18393
09e6716ba89bc25f9f0519ca2d8bb6c6f4072d50	improved online/offline signature schemes	metodo adaptativo;on line;en linea;methode indirecte;methode adaptative;fonction hachage;offline;signature scheme;general methods;digital signature;criptografia;cryptography;metodo indirecto;adaptive method;signature numerique;cryptographie;en ligne;conmutador;hash function;indirect method;modular multiplication;commutateur;selector switch;hors ligne	The notion of on-line/off-line signature schemes was introduced in 1990 by Even, Goldreich and Micali. They presented a general method for converting any signature scheme into an on-line/off-line signature scheme, but their method is not very practical as it increases the length of each signature by a quadratic factor. In this paper we use the recently introduced notion of a trapdoor hash function to develop a new paradigm called hash-sign-switch, which can convert any signature scheme into a highly efficient on-line/off-line signature scheme: In its recommended implementation, the on-line complexity is equivalent to about 0.1 modular multiplications, and the size of each signature increases only by a factor of two. In addition, the new paradigm enhances the security of the original signature scheme since it is only used to sign random strings chosen off-line by the signer. This makes the converted scheme secure against adaptive chosen message attacks even if the original scheme is secure only against generic chosen message attacks or against random message attacks.	digital signature;hash function;online and offline;programming paradigm	Adi Shamir;Yael Tauman Kalai	2001		10.1007/3-540-44647-8_21	ring signature;digital signature;hash function;merkle signature scheme;eddsa;computer science;cryptography;theoretical computer science;mathematics;distributed computing;group signature;blind signature;schnorr signature;elgamal signature scheme;computer security;algorithm	Crypto	-41.00731513902267	78.78755418098419	18408
c2c020155899c95dbf7787ba0843b3c59417ca8d	an evaluation of service discovery protocols in the internet of things		The IoT environment surfaces challenging requirements for service discovery, such as: services heterogeneity, mobility, scalability, security, QoS support and context management. Different protocols have been proposed to facilitate service discovery, but it is difficult to assess how well these protocols meet the IoT requirements. This paper presents an evaluation of commonly used service discovery protocols for the IoT, CoAP-SD, DNS-SD, mDNS-SD, and DDS-SD, performed against both qualitative and quantitative metrics, on a physical experimental setup. The results show the limitations and strengths of the protocols, and future research directions are discussed.	constrained application protocol;internet of things;quality of service;requirement;scalability;secure digital;service discovery	Christian Cabrera;Andrei Palade;Siobhán Clarke	2017		10.1145/3019612.3019698	quality of service;scalability;computer network;service discovery;context management;service-oriented architecture;internet of things;computer science	Mobile	-16.531154691458212	86.57801062439405	18412
86e6b352499c3da7fa03df46f0bbdff5879492d5	transformations of two cryptographic problems in terms of matrices	discrete logarithm;diffie hellman	The Discrete Logarithm and the Diffie-Hellman are two hard computational problems, closely related to cryptography and its applications. The computational equivalence of these problems has been proved only for some special cases. In this study, using LU-decomposition to Vandermonde matrices, we are able to transform the two problems in terms of matrices, thus giving a new perspective to their equivalence. A first study on matrix transformations for the Double and Multiple Discrete Logarithms is also presented.	computational problem;cryptography;diffie–hellman problem;discrete logarithm;lu decomposition;qr decomposition;regular expression;transformation matrix;turing completeness;vandermonde matrix	Elena C. Laskari;Gerasimos C. Meletiou;Dimitris K. Tasoulis;Michael N. Vrahatis	2005	ACM SIGSAM Bulletin	10.1145/1140378.1140384	arithmetic;discrete logarithm;discrete mathematics;diffie–hellman key exchange;baby-step giant-step;mathematics;algebra	Crypto	-39.54721214908673	80.34382598665619	18422
588386e579a93abd4da3017d15b6561eae0af853	algorithms and metrics for processing multiple heterogeneous continuous queries	workload;tiempo respuesta;time average;operator scheduling;metodo caso peor;politica optima;reponse temporelle;metodo adaptativo;virtual memory;streaming;continuous queries;computacion informatica;shared memory;surveillance;memoria compartida;data stream;continuous query;performance;interrogation base donnee;en continu;interrogacion base datos;en continuo;metric;response time;promedio temporal;methode adaptative;optimal policy;qualite service;equite;temps reponse;equidad;transmission en continu;vigilancia;equity;monitoring;time response;ciencias basicas y experimentales;scheduling;adaptive method;charge travail;memoire virtuelle;methode cas pire;algorithms;design;metrico;monitorage;transmision fluyente;quality of service;carga trabajo;grupo a;monitoreo;respuesta temporal;politique optimale;worst case method;data stream management system;database query;memoria virtual;service quality;ordonnancement;metrique;continuous process;reglamento;memoire partagee;moyenne temporelle;calidad servicio	The emergence of monitoring applications has precipitated the need for Data Stream Management Systems (DSMSs), which constantly monitor incoming data feeds (through registered continuous queries), in order to detect events of interest. In this article, we examine the problem of how to schedule multiple Continuous Queries (CQs) in a DSMS to optimize different Quality of Service (QoS) metrics. We show that, unlike traditional online systems, scheduling policies in DSMSs that optimize for average response time will be different from policies that optimize for average slowdown, which is a more appropriate metric to use in the presence of a heterogeneous workload. Towards this, we propose policies to optimize for the average-case performance for both metrics. Additionally, we propose a hybrid scheduling policy that strikes a fine balance between performance and fairness, by looking at both the average- and worst-case performance, for both metrics. We also show how our policies can be adaptive enough to handle the inherent dynamic nature of monitoring applications. Furthermore, we discuss how our policies can be efficiently implemented and extended to exploit sharing in optimized multi-query plans and multi-stream CQs. Finally, we experimentally show using real data that our policies consistently outperform currently used ones.	algorithm;best, worst and average case;emergence;experiment;fairness measure;management system;quality of service;response time (technology);scheduling (computing)	Mohamed A. Sharaf;Panos K. Chrysanthis;Alexandros Labrinidis;Kirk Pruhs	2008	ACM Trans. Database Syst.	10.1145/1331904.1331909	shared memory;design;real-time computing;simulation;quality of service;metric;performance;computer science;virtual memory;artificial intelligence;scheduling;response time;service quality;equity	DB	-12.09630074527897	65.09158452536388	18485
db17927bb56c041a22d9d7df05a193ac84aaae32	a novel query caching scheme for dynamic infiniband subnets	virtualization;performance evaluation;time factors hardware virtualization peer to peer computing scalability benchmark testing performance evaluation;time factors;reliable datagram socket protocol query caching scheme dynamic infiniband subnets subnet manager dynamic virtualized cloud environment virtual machine vm subnet administration sa opensm;scalability;peer to peer computing;benchmark testing;subnet administration infiniband cache subnet manager scalability virtualization live migration;virtual machines cache storage cloud computing query processing;hardware	In large InfiniBand subnets the Subnet Manager (SM) is a potential bottleneck. When an InfiniBand subnet grows in size, the number of paths between hosts increases polynomials and the SM may not be able to serve the network in a timely manner when many concurrent path resolution requests are received. This scalability challenge is further amplified in a dynamic virtualized cloud environment. When a Virtual Machine (VM) with InfiniBand interconnect live migrates, the VM addresses change. These address changes result in additional load to the SM as communicating peers send Subnet Administration (SA) path record queries to the SM to resolve new path characteristics. In this paper we benchmark OpenSM to empirically demonstrate the SM scalability problems. Then we show that our novel SA Path Record Query caching scheme significantly reduces the load towards the SM. In particular, we show by using the Reliable Datagram Socket protocol that only a single initial SA path query is needed per communicating peer, independent of any subsequent (re)connection attempts.	benchmark (computing);cache (computing);datagram socket;infiniband;polynomial;scalability;subnetwork;virtual machine	Evangelos Tasoulas;Ernst Gunnar Gran;Bjørn Dag Johnsen;Tor Skeie	2015	2015 15th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing	10.1109/CCGrid.2015.10	benchmark;parallel computing;scalability;virtualization;computer science;operating system;database;distributed computing;computer network	HPC	-14.08425618254648	77.14864335668423	18490
f9fefd0e688354ea66439f7682d7302282fb4145	on the study of eeg-based cryptographic key generation		Biometric-based cryptographic key generation is regarded as a data mining approach that uses knowledge discovery techniques to extract biometric information to generate cryptographic keys for protecting secured data by encryption. This application has been widely used in security systems to limit the weakness of passwords. Although conventional biometrics such as fingerprint, face, voice, and handwriting contain biometric information that is unique and repeatable for each individual, they are difficult to change to be used in different purposes. In this paper, we propose a system to exploit human electroencephalography (EEG) data as a new biometric for cryptographic key generation. This system provides high potential because EEG is impossible to be faked or compromised. Our method is evaluated using the EEG Alcoholism and GrazIIIa datasets, and is shown to reliably produce secure cryptographic keys with a 99% success rate. c 2017 he uthors. Published by Elsevier B. . .	biometrics;cryptography;cryptosystem;data mining;electroencephalography;encryption;error detection and correction;fingerprint;key (cryptography);key generation;password	Dang Nguyen;Dat Tran;Dharmendra Sharma;Wanli Ma	2017		10.1016/j.procs.2017.08.126	data mining;password;cryptographic primitive;encryption;knowledge extraction;key (cryptography);computer science;cryptographic protocol;biometrics;exploit	Security	-37.38994429970512	69.4309404030969	18502
2979092189ad5c66d2e80e6b130b381c28f7d0d3	an improved secure authentication protocol for wimax with formal verification		Privacy and Key management protocols (PKM) is used in WiMAX for providing authentication and key management. Basic PKM protocol provides one way authentication between SS and BS results many flaws. However, PKM protocol version 2 (PKMv2) solves the major security problems but new flaws have emerged. This paper analyzes the PKM protocol and its later versions using AVISPA which is a push button tool for the automated validation of security protocol. A secure authentication protocol has also been proposed and analyzed, results show that proposed protocol does not have any security flaws.	authentication protocol;formal verification	Anjani Kumar Rai;Shivendu Mishra;Pramod Narayan Tripathi	2011		10.1007/978-3-642-22714-1_42	data authentication algorithm;authentication protocol;ssliop;challenge-handshake authentication protocol;computer network	Crypto	-46.48558613925299	73.9721326731277	18521
beb651756bba0f2d190d19b2066eff1019b7f9ea	a description language for communication services of future network architectures	protocols;encryption;web services computer architecture internet;resource description framework;web service;runtime;computer architecture;internet;error correction;web services;payloads;network architecture;protocols delay runtime web services error correction payloads encryption;network services;web service description languages communication services future network architectures resource description framework networking service description internet;communication service	For selecting and composing communication services to create a networking stack in a flexible future network architecture, service descriptions are required. In this paper, we propose a language for describing communication services. The language has been implemented by using the Resource Description Framework (RDF) and evaluated by describing a set of dependencies and a complete service. Irrespective of the selection and composition methods at design time, deployment time and runtime, the language can be used any place where a networking service description is required.	network architecture;protocol stack;resource description framework;software deployment	M. Rahamatullah Khondoker;Eric M. S. P. Veith;Paul Mueller	2011	2011 International Conference on the Network of the Future	10.1109/NOF.2011.6126685	computer science;database;distributed computing;rdf query language;world wide web	HPC	-18.23850435269657	84.4327708571017	18525
231f495acea8c1cd0c6680ec5d9371fbf099ca3d	wireless ata: a new data transport protocol for wireless storage	transport protocol	This paper introduces a new data transport architecture and protocol for storage that is implemented on wireless devices and that can be accessed through a short-range wireless access technology such as Bluetooth or 802.11. We call the protocol WATA (Wireless ATA), as its architecture is similar to current ATA and ATA-based technologies. In this paper, we give basic technical details of the protocol and discuss its main advantages and disadvantages over the current protocols, and talk about our decisions to implement a prototype system to see an actual implementation of the architecture.	assistive technology;bluetooth;encryption;operating system;prototype;serial ata;wireless access point	Serdar Ozler;Ibrahim Korpeoglu	2005			wireless transport layer security;wi-fi;wireless wan;wireless lan controller;capwap;wi-fi array;computer network	Mobile	-17.138569196350588	88.98722879151761	18539
70437bf3674dbb45441f724b82ae82eef9a2a75e	architecture for extensible mobile instant messaging and presence service over ims	signalling protocols 3g mobile communication electronic messaging mobile computing open systems;protocols;instant messaging;electronic mail;efficient algorithm;presence service;mobile applicaitons ims mobile instant messaging and presence service mobile middleware;network servers message service mobile communication computer architecture mobile computing protocols communication system control routing multimedia databases telecommunication standards;call session control function;extensible mobile instant messaging;media;servers;3g mobile communication;call session control function extensible mobile instant messaging ims presence service sip proxy servers oma imps specification interoperability 3g mobile communication;oma imps specification;multimedia communication;mobile communication;xml;electronic messaging;mobile applicaitons;middleware;mobile instant messaging and presence service;interoperability;sip proxy servers;system architecture;mobile computing;open systems;ims;proxy server;mobile middleware;signalling protocols	In this paper, we have designed and implemented the system architecture for extensible mobile instant messaging and presence service over the IMS. More specifically, we have implemented the SIP proxy servers for IMS P-CSCF and S-CSCF for the realization of extensible mobile instant messaging and presence service. The salient feature of the proposed system architecture is that the architecture is based on IETF SIMPLE standard, and the extensibility of the presence service is achieved by implementing theOMA IMPS specification. An efficient algorithm is presented for achieving the extensible presence service over IMS. The implementation results show that the proposed system architecture can effectively provide not only interoperability but also extensibility for representing userspsila status information in the 3 G mobile communication environment.	algorithm;extensibility;ip multimedia subsystem;information management system (ims);instant messaging;interoperability;oma;performance evaluation;presence information;proxy server;server (computing);systems architecture	Jae-Wook Nah;Yeong-Hun Cho;Suwook Kim;Jong-Tae Park	2008	2008 3rd International Conference on Communication Systems Software and Middleware and Workshops (COMSWARE '08)	10.1109/COMSWA.2008.4554446	communications protocol;interoperability;xml;media;mobile telephony;computer science;operating system;middleware;internet privacy;open system;mobile computing;world wide web;ip multimedia subsystem;server;computer network	Mobile	-16.152778620860367	91.84221164142788	18546
764237dc5617bff42ec1a907cd4965437c44e93d	applicability of or-proof techniques to hierarchical identity-based identification		We discuss the applicability of the well known OR-proof technique to hierarchical identity-based identification (HIBI) protocols for enhancing their security. We first describe formal security definitions for HIBI protocol not only in the adaptive hierarchical-identity setting but also in both “static” and “weak selective” hierarchical-identity settings. Next, we investigate whether the security enhancement transformations for identity-based identifications presented at ACNS 2012, which is based on the OR-proof technique, can be applied to HIBI protocols. We formally prove that several of these transformations are applicable to HIBI with slight modification. Curiously, the rest do not seem applicable, which stems from hierarchy and delegation. We also present a variant transformation and show that it can enhance the security of HIBI protocols in all three hierarchical-identity settings.		Atsushi Fujioka;Taiichi Saito;Keita Xagawa	2012		10.1007/978-3-642-35404-5_14	security enhancement;theoretical computer science;hierarchy;computer science;delegation	Crypto	-39.956851064525246	75.72849195483732	18563
93e04c72b723e3235c3c8f05e9cfc73fc6c70a83	paas: power aware algorithm for scheduling in high performance computing	power aware scheduling;energy optimization power aware scheduling power aware algorithms high performance computing dynamic voltage and frequency scaling;high performance computing;processor scheduling;power aware algorithms;paas multiagent framework energy consumption analysis energy consumption monitoring hardware based power measurement device watts up net meter dvfs knobs dynamic voltage and frequency scaling knobs hpc systems load balancing hpc systems energy reduction energy consumption optimization high performance computing power aware algorithm for scheduling;energy consumption scheduling knowledge based systems processor scheduling power demand optimization time frequency analysis;energy optimization;energy consumption;scheduling;optimization;wattmeters energy conservation energy consumption multi agent systems optimisation parallel processing power aware computing power measurement resource allocation scheduling;power demand;time frequency analysis;knowledge based systems;dynamic voltage and frequency scaling	Energy consumption has become the major concern in High Performance Computing (HPC) systems as far as operational cost, reliability of systems and environmental impacts are concerned. The optimization of energy consumption in HPC systems is challenging task. The frequency/voltage used for execution of a job has a key impact in overall energy consumption. In this paper, we have implemented Power Aware Algorithm for Scheduling (PAAS), which focuses on energy reduction and load balancing aspects of HPC systems. The PAAS guides the scheduler to take intelligent decisions based on the information available in knowledge base. The Scheduler provides an optimal energy aware schedule for each node to minimize the make span across nodes and to reduce energy consumption. The knowledge base gives the optimal frequency and voltage where energy consumption is minimal for a particular job. The Dynamic Voltage and Frequency Scaling (DVFS) knobs are tuned across the nodes based on predicted optimal frequency and voltage. We used hardware based power measurement device Watts up? .NET meter for individual computing nodes as well as Multi-Agent framework for monitoring and analyzing energy consumption. We evaluated the algorithm on the experimental test-bed with the set of scientific applications. Our technique showed an average measured energy savings of 12.64% and a maximum of 13.5%.	.net framework;algorithm;decision tree;dynamic voltage scaling;frequency scaling;job shop scheduling;knowledge base;load balancing (computing);makespan;mathematical optimization;platform as a service;requirement;scheduling (computing);supercomputer;testbed;watts humphrey	H. V. Raghu;Sumit Kumar Saurav;Bindhumadhava S. Bapu	2013	2013 IEEE/ACM 6th International Conference on Utility and Cloud Computing	10.1109/UCC.2013.71	embedded system;parallel computing;real-time computing;time–frequency analysis;computer science;operating system;knowledge-based systems;scheduling	HPC	-18.322450948001848	61.2214244508595	18565
23eab8551b95795afcc26767fcdc780198278e0e	improving the discovery of ixp peering links through passive bgp measurements	topology;telecommunication traffic computer network security internet internetworking peer to peer computing protocols telecommunication links telecommunication network routing telecommunication network topology;protocols;telecommunication links;computer network security;measurement;border gateway protocol passive bgp measurement ixp peering link discovery internet autonomous system topology end to end routing network economics network security internet exchange points flattening as hierarchy publicly available bgp data traffic engineering bgp communities ixp route servers multilateral peering agreements p2p links bgp based as topology collections caida s ark dimes projects policy data multilateral peering links;routing;telecommunication traffic internet internetworking peer to peer computing protocols telecommunication links telecommunication network routing telecommunication network topology;inter domain;missing links bgp internet autonomous systems bgp measurement inter domain routing ixp topology;telecommunication traffic;internet;telecommunication network routing;bgp;border gateway protocol ixp peering link discovery passive bgp measurements internet autonomous system topology end to end routing network economics security as interconnections internet exchange points flattening as hierarchy missing peering links observable peering links bgp vantage points traceroute monitors traffic engineering bgp communities ixp route server multilateral peering agreements bgp based as topology collections caida ark dimes projects p2p links;servers communities topology routing internet monitoring network topology;internetworking;missing links;peer to peer computing;telecommunication network topology;ixp;autonomous systems	The Internet Autonomous System (AS) topology has important implications on end-to-end routing, network economics and security. Despite the significance of the AS topology research, it has not been possible to collect a complete map of the AS interconnections due to the difficulties involved in discovering peering links. The problem of topology incompleteness is amplified by the increasing popularity of Internet eXchange Points (IXPs) and the “flattening” AS hierarchy. A recent study discovered that the number of missing peering links at a single IXP is larger than the total number of the observable peering links. As a result a large body of research focuses on measurement techniques that can alleviate the incompleteness problem. Most of these proposals require the deployment of additional BGP vantage points and traceroute monitors. In this paper we propose a new measurement methodology for improving the discovery of missing peering links through the publicly available BGP data. Our approach utilizes the traffic engineering BGP Communities used by IXPs' Route Servers to implement multi-lateral peering agreements. We are able to discover 36K additional p2p links from 11 large IXPs. The discovered links are not only invisible in previous BGP-based AS topology collections, but also 97% of those links are invisible to traceroute data from CAIDA's Ark and DIMES projects for June 2012. The advantages of the proposed technique are threefold. First, it provides a new source of previously invisible p2p links. Second, it does not require changes in the existing measurement infrastructure. Finally, it offers a new source of policy data regarding multilateral peering links at IXPs.	autonomous system (internet);border gateway protocol;correctness (computer science);dimes;end-to-end principle;inter-rater reliability;lateral thinking;looking glass server;observable;peer-to-peer;peering;routing;san diego supercomputer center;software deployment;traceroute	Vasileios Giotsas;Shi Zhou	2013	2013 Proceedings IEEE INFOCOM	10.1109/INFCOM.2013.6567146	communications protocol;routing;the internet;inter-domain;route views;autonomous system;border gateway protocol;computer science;network security;distributed computing;computer security;internet exchange point;measurement;computer network	Networks	-11.3701333153337	78.62662868783259	18575
611c28f72f9a928edcfe0c9b8c4ca77eb5d83eec	location based handshake and private proximity test with location tags	bloom filter location based service proximity test spatial temporal location tag location cheating location privacy fuzzy extractor;protocols entropy servers privacy ieee 802 11 standard security mobile communication	A location proximity test service allows mobile users to determine whether they are in close proximity to each other, and has found numerous applications in mobile social networks. Unfortunately, existing solutions usually reveal much of users’ private location information during a proximity test. They are also vulnerable to location cheating where an attacker reports false locations to gain an advantage. Moreover, the initial trust establishment among unfamiliar users in large scale mobile social networks has been a challenging task. In this paper, we propose a novel scheme that enables a user to perform (1) a location based handshake that establishes secure communications among strangers, who do not have a pre-shared secret, and (2) a privacy-preserving proximity test without revealing the user’s actual location to the server or other users not within the proximity. The proposed scheme is based on a novel concept, i.e., spatial-temporal location tags, and we put forward a location tag construction method using environmental signals that provides an unforgeable location proof. We use Bloom filters to efficiently represent users’ location tags and vicinity regions. We exploit fuzzy extractor, a lightweight cryptographic primitive, to extract shared secrets between matching location tags. We conduct extensive analysis, simulation, and real experiments to demonstrate the feasibility, security, and efficiency of our scheme.	bloom filter;cryptographic primitive;cryptography;experiment;fuzzy extractor;location-based service;mobile social network;randomness extractor;secure communication;server (computing);shared secret;simulation	Yao Zheng;Ming Li;Wenjing Lou;Yiwei Thomas Hou	2017	IEEE Transactions on Dependable and Secure Computing	10.1109/TDSC.2015.2472529	bloom filter;cheating;cryptographic primitive;computer science;distributed computing;location-based service;fuzzy extractor;exploit;mobile telephony;server	Mobile	-39.85906461593259	60.9728709926681	18619
9b4dbe2f28a26c9d43e4e793f5e1790e0d1a9ef7	length-doubling ciphers and tweakable ciphers	universal hash function;enciphering scheme;tweakable ciphers;deterministic encryption;ciphers;symmetric encryption	We motivate and describe a mode of operation HEM (resp., THEM) that turns a n-bit blockcipher into a variable-input-length cipher (resp., tweakable cipher) that acts on strings of [n..2n − 1] bits. Both HEM and THEM are simple and intuitive and use only two blockcipher calls, while prior work at least takes three. We prove them secure in the sense of strong PRP and tweakable strong PRP, assuming the underlying blockcipher is a strong PRP.	block cipher mode of operation;pdf/a;parallel redundancy protocol;period-doubling bifurcation;string (computer science)	Haibin Zhang	2012		10.1007/978-3-642-31284-7_7	computer science;theoretical computer science;block size;universal hashing;symmetric-key algorithm;mathematics;distributed computing;deterministic encryption;computer security	Crypto	-37.534967096869586	77.88865080770223	18684
3a03c45e8d0cf6636d82eed18b4f93b60a028a2d	shift arithmetic on a token ring network	ring network	"""The Data Link layer can be further subdivided into:! 1.! Logical Link Control (LLC): error and flow control! 2.! Media Access Control (MAC): framing and media access! different link protocols may provide different services, e.g., Ethernet doesn't provide reliable delivery (error recovery)! MAC topics:! • ! framing and MAC address assignment! • ! LAN forwarding! • ! IP to MAC address resolution! • ! IP to MAC: Address Resolution Protocol (ARP)! • ! MAC to IP: Reverse ARP (RARP), BOOTstrap Protocol (BOOTP), Dynamic Host Configuration Protocol (DHCP)! • ! media access control! application transport network LLC MAC physical Multiple Access Problem! Broadcast channel of rate R bps, shared medium! • ! if two users send at the same time, collision results in no packet being received (interference)! • ! if no users send, channel goes idle! • ! thus, want to have only one user send at a time! Media Access Control: ! • ! determines who gets to send next! • ! what to do if more than one hosts """" send at the same time and there's collision!"""	access control;arithmetic shift;error detection and correction;framing (world wide web);interference (communication);lan messenger;mac address;network packet;nyquist rate;reliable messaging;ring network;synchronous data link control;token ring	Miron Livny;Udi Manber	1985			distributed computing;parallel computing;token ring;computer science;token passing;token bus network;ring network	Networks	-23.08027155876764	89.01024370013555	18712
35f25ae7c7d549b758fcc077defda52dba5637dc	modeling a 10 gbit/s/port shared memory atm switch	shared memory;paper technology;high speed optical techniques;traffic control;traffic model;bicmos integrated circuits;optical switches;chip;telecommunication switching;performance analysis;technical report;asynchronous transfer mode traffic control optical switches bicmos integrated circuits telecommunication switching laboratories high speed optical techniques performance analysis local area networks paper technology;high speed;local area networks;asynchronous transfer mode;telekommunikation;telecommunications	The speed of optical transmission links is growing at rate which is difficult for the micro-electronic technol ogy of ATM switches to follow. In order to cover the transmission rate gap between optical transmission lin and ATM switches, ATM switches operating at mult Gbit/s rate have to be developed. A 10 Gbit/s/port sha memory ATM switch is under development at Linköpin Institute of Technology (LiTH) and Lund Institute of Technology (LTH) in Sweden. It has 8 inputs and 8 ou puts. The switch will be implemented on a single chip 0.8 μm BiCMOS. In this paper, we report on a perform ance analysis of the switch under a specific traffic mod This traffic model emulates the LAN type of traffic. Pe formance analysis is crucial for evaluating and dime sioning the very high speed ATM switch.	atm turbo;bernoulli polynomials;bicmos;emulator;gigabit;local interconnect network;network switch;shared memory;simulation;value (ethics)	Tawfik Lazraq;Jakob Brundin;Per Andersson;Åke Arvidsson	1997		10.1145/268437.268741	local area network;chip;shared memory;crossover switch;electronic engineering;telecommunications;computer science;engineering;atm adaptation layer;technical report;asynchronous transfer mode;crossbar switch;optical switch;computer network	Networks	-20.942769455141892	91.43062150769632	18717
0eb465d7e11d9732b2512861e2b1c4d7ae5402ad	towards edge slicing: vnf placement algorithms for a dynamic & realistic edge cloud environment		To support the much desired ultra-short latency of 5G mobile systems, many micro-data centers will be deployed in the vicinity of mobile users, defining a distributed edge cloud. Over this edge cloud, it is important to create optimal network slices to support different 5G verticals. Optimality is defined in terms of cost efficiency and QoS support. Therefore, it is important to understand the behavior of mobile users in terms of mobile service consumption. In this paper, we present, on one hand, a tool for developing a spatio-temporal model of mobile service usage over a particular geographical area. This tool will help to define the behavior of mobile users in terms of mobility patterns and mobile service consumption. On the other hand, based on this tool, we present a benchmark of some interesting Virtualized Network Functions (VNF) placement algorithms, among them our enhanced version of the predictive placement strategy. The comparison is based on data overload, overload of Virtual Machines (VMs) and QoS.	algorithm;benchmark (computing);cost efficiency;data center;geographic coordinate system;instant messaging;network function virtualization;quality of service;social network;streaming media;virtual machine;z/vm	Abdelquoddouss Laghrissi;Tarik Taleb;Miloud Bagaa;Hannu Flinck	2017	GLOBECOM 2017 - 2017 IEEE Global Communications Conference	10.1109/GLOCOM.2017.8254653	real-time computing;latency (engineering);mobile service;cloud computing;slicing;quality of service;virtual machine;cost efficiency;computer science;algorithm	Visualization	-20.110016225102687	75.24032940146087	18751
8db3dacc69a3e97fab2722d1eac18feb62e1fd7b	correlation in distributed intrusion detection system using mobile agent	intrusion detection system architecture;correlator agent;mobile agent	This paper presents an architecture of a distributed intrusion detection system (DIDS) using Mobile Agent (MA).MA can invoke different agent( viz. Correlator agent, Filter Agent ).MA runs on top of Mobile Agent Platform. To manage uniformity on heterogeneous network, MAP works as virtual Machine. Correlator agent (CA) works as a means for the communication among the hosts and server in the network. MA invokes CA for sending rules that co-ordinate and responsible for determining whether some suspicious activities in different network nodes can be combined to be a distributed intrusion. Our implementation result justifies the architecture of the DIDS.	intrusion detection system;mobile agent	Zakiya Malek;Asha Koshti;Chintan Bhatt;Hemant Agrwal;Bhushan Trivedi	2011		10.1007/978-3-642-29280-4_65	embedded system;host-based intrusion detection system;real-time computing;engineering;mobile agent;computer security	ML	-60.937361397803656	69.03258391844709	18815
0f2f9f199ed7124438bdc53d96d8a63b8c06a36b	providing trust in wireless sensor networks using a bio-inspired technique	bio inspired algorithms;wireless sensor network;ant colony system;trust reputation management;wireless sensor networks;trust and reputation	Wireless Sensor Networks (WSNs) are becoming more and more spread and both industry and academia are focusing their research efforts in order to improve their applications. One of the first issues to solve in order to achieve that expected improvement is to assure a minimum level of security in such a restrictive environment. Even more, ensuring confidence between every pair of interacting nodes is a critical issue in this kind of networks. Under these conditions we present in this paper a bio-inspired trust and reputation model, called BTRM-WSN, based on ant colony systems aiming at providing trust and reputation in WSNs. Experiments and results demonstrate the accuracy, robustness and lightness of the proposed model in a wide set of situations.	ant colony;british informatics olympiad;interaction;sensor	Félix Gómez Mármol;Gregorio Martínez Pérez	2011	Telecommunication Systems	10.1007/s11235-010-9281-7	wireless sensor network;computer science;key distribution in wireless sensor networks;internet privacy;computer security;computational trust;computer network	Mobile	-52.32602551374769	75.16082372854872	18835
8ffe4c89318c2db9a4f00761f2b35212a5991d0d	a non-parametric data envelopment analysis approach for cloud services evaluation		Due to advantages of cloud computing, services are increasingly deployed in cloud. It is a challenge to choose a proper service. Besides QoS requirements, customers expect more efficient services which provide better performance but with minimum cost. In this paper, we propose a non-parametric method to evaluate relative efficiency of cloud services based on Data Envelopment Analysis. It can classify cloud services into different efficiency levels and tell how to improve less efficient services. We illustrate the method with a case study.	data envelopment analysis	Chunxiang Xu;Yupeng Ma;Xiaobo Wang	2014		10.1007/978-3-319-22885-3_22	efficiency;business;data mining;cloud computing;quality of service;nonparametric statistics;data envelopment analysis	SE	-24.760394379043866	64.2241624815467	18842
ec1f5abe7093b6656383c6c3698ef0852f3e574c	bounds for lpt schedules on uniform processors	nonpreemptive scheduling;nonpreemptive schedules;uniform processors;list scheduling;lpt schedules;list schedules;independent tasks	We study the performance of LPT (largest processing time) schedules with respect to optimal schedules in a nonpreemptive multiprocessor environment. The processors are assumed to have different speeds and the tasks being scheduled are independent.	central processing unit;multiprocessing;parallel port	Teofilo F. Gonzalez;Oscar H. Ibarra;Sartaj Sahni	1977	SIAM J. Comput.	10.1137/0206013	parallel computing;real-time computing;computer science;distributed computing	Theory	-11.708110861418763	61.06489279765258	18848
cd8c3a82aa961b1b93bd195951b4cc33dbd6f457	a new methodology to adapt sip protocol for voice traffic transported over ip network	oscillations;turn and stun protocol session initiation protocol network address translation voice over ip multimedia sessions;session initiation protocol;voice over ip;network address translation;transport protocols telecommunication traffic ip networks network address translation internet telephony communication standards intelligent systems intelligent networks laboratories electronic mail;network address translator;turn and stun protocol;ip networks;multimedia sessions	The convergence of company communications on IP network continues to oscillate between the protocol owners and the standards SIP, MGCP and H.323. We propose in this paper a new approach allowing a transparent traversal of NATs (Network Address Translation) to SIP protocol (Session Initiation Protocol). This ensures thus optimisation in the case of multimedia sessions. Indeed, the fact that SIP belongs to the application layer constitutes a weakness vis-àvis the traversal of NATs. It is due, on the one hand, to the way in which the server responds to requests of clients. On the other hand, it is caused by the dynamic allocation of the UDP ports. The approach proposed, called ''Adequate Solution for each Situation'' (ASS), allows to adapt in a dynamic way one of the following three solutions: connection-oriented media, STUN and TURN, following the situation which occurs during the call initialisation.	connection-oriented communication;internet protocol suite;mathematical optimization;memory management;network address translation;server (computing)	Abdelhamid Mellouk;Mustapha Guezouri	2006	Advanced Int'l Conference on Telecommunications and Int'l Conference on Internet and Web Applications and Services (AICT-ICIW'06)	10.1109/AICT-ICIW.2006.20	internet protocol;reverse address resolution protocol;real-time computing;user datagram protocol;next-generation network;sip trunking;stateless protocol;telecommunications;internet protocol control protocol;ip address management;computer science;operating system;tunneling protocol;voice over ip;network address translation;session initiation protocol;link-local address;internet protocol suite;port control protocol;ip tunnel;oscillation;world wide web;ip multimedia subsystem;ipv4 address exhaustion;nat traversal;computer network;arp spoofing	HPC	-23.08501723188413	89.7539694980788	18868
e93c54ca4b1afd00ba2b7743c86757c1c6e770c0	available and safe message freshness detection algorithm	railways;railway control systems;availability;simulation;safety;detection algorithm;critical systems;message delay;distributed systems;message freshness detection;real time systems	The detection of messages delayed more than a given threshold – called ‘message freshness detection’ – is an important requirement in many distributed critical real-time systems. In this paper, a solution for addressing this requirement is described and deeply analysed. Our solution, the ‘available and safe freshness detection algorithm (ASFDA)’, was proposed for a distributed infrastructure for railway control, but it fits also to different systems with similar characteristics. ASFDA allows the detection of ‘old’ messages: violations of real-time requirements. ASFDA is based on round trip time estimation technique, a well known method used in distributed systems with real-time requirements. In the paper, we demonstrate that ASFDA can detect all the messages older than allowed; we also demonstrate, through an availability analysis performed by simulation, that the availability penalty reached by the proposed freshness detection algorithm is practically negligible if compared with its theoretical limits.	asf+sdf meta-environment;advanced synchronization facility;algorithm;clock synchronization;distributed computing;enrico clementi;fits;ixl (interactive agency);network packet;point-to-point protocol;protocol stack;real-time clock;real-time computing;replay attack;representation oligonucleotide microarray analysis;requirement;role-based collaboration;simulation;verification and validation	Andrea Bondavalli;Lorenzo Falai;Stefano Porcarelli;Salvatore Sabina;Fabrizio Zanini	2010	IJCCBS	10.1504/IJCCBS.2010.036604	reliability engineering;embedded system;availability;real-time computing;computer science;operating system;distributed computing;computer security	Embedded	-6.768276369073326	70.26059249964472	18871
2ba493bac90b9af77adc737d515de92367043d0b	voice quality measurement system for telephone service	sla service level agreement;voice quality;pstn;measurement system;perceptual evaluation of speech quality;mos;voice over internet protocol;service level agreement;mobile internet;r factor;pesq;voip	Recently, plenty of voice quality measuring devices of VoIP(Voice over Internet Protocol) service is developed to support high quality VoIP service for communication. However, the existing voice quality measuring devices select the unique measurement method, which uses PESQ(Perceptual Evaluation of Speech Quality) or R-factor only. However, the each voice quality measurement method differs from its usage and assumed range, which leads to the slightly different results at the same testing area for voice services. At the actual VoIP service business and related regulatory organizations, they request to use the above two types of algorithm at the same time for measuring voice quality. However, the development expenses are very high to use the above two types of algorithm at the same time for measuring voice quality due to additional resources and subsidiary devices. VoIP business and regulatory agencies also request the hardware specification of the voice quality measurement device is similar to that of VoIP service user terminal, considering VoIP service supply at the wireless mobile internet such as WiBro(Wireless Broadband). In this paper, we present the voice quality measurement method by using of the above two algorithms at the one physical measurement device at the same time for more accurate and reliable VoIP voice quality measurement. In addition, we introduce the development method of the voice quality measurement device with relatively low cost.	algorithm;computer terminal;display resolution;pesq;system of measurement	Il-Gu Jung;Eun-Jin Ko;Hyun-Chul Kang;Gilhaeng Lee	2008		10.1145/1456223.1456233	voice activity detection;mean opinion score;real-time computing;telecommunications;computer science;voice over ip;computer network	Metrics	-11.845680773770427	100.96558133387549	18877
66e9896cce543a86e9dcdc41c5e5d7b3dae14558	optimal utilization bounds for the fixed-priority scheduling of periodic task systems on identical multiprocessors	fixed priority scheduling real time system periodic task system identical multiprocessor scheduling;processor scheduling;periodic task systems;data exchange;processor scheduling real time systems;fixed priority;runtime;resumes;65;utilization bounds real time systems periodic task systems identical multiprocessors fixed priority scheduling;scheduling algorithm;periodic tasks;identical multiprocessor scheduling;periodic task system;real time system;fixed priority scheduling;utilization bounds;parallel processing;real time systems processor scheduling;real time systems;system identication;identical multiprocessors	In fixed-priority scheduling, the priority of a job,.once assigned, may not change. A new fixed-priority algorthm for scheduling systems of periodic tasks upon identical multiprocessors is proposed. This algorithm has an achievable utilization of (m+1)/2 upon m unit-capacity processors. It is proven that this algorithm is optimal from the perspective of achievable utilization in the sense that no fixed-priority algorithm for scheduling periodic task systems upon identical multiprocessors may have an achievable utilization greater than (m+1)/2.	algorithm;central processing unit;fixed-priority pre-emptive scheduling;scheduling (computing)	Sanjoy K. Baruah	2004	IEEE Transactions on Computers	10.1109/TC.2004.16	data exchange;fair-share scheduling;parallel processing;parallel computing;real-time computing;dynamic priority scheduling;computer science;rate-monotonic scheduling;operating system;distributed computing;scheduling	Embedded	-10.847943543048183	60.866872589084956	18880
021417af52bc6227afcbdbc11f05000e02dfea60	optimizing selection of competing services with probabilistic hierarchical refinement	reliability;automobiles;run time evaluation;data distribution;time factors;probabilistic model checking;web services;probabilistic logic;quality of service;concrete	Recently, many large enterprises (e.g., Netflix, Amazon) have decomposed their monolithic application into services, and composed them to fulfill their business functionalities. Many hosting services on the cloud, with different Quality of Service (QoS) (e.g., availability, cost), can be used to host the services. This is an example of competing services. QoS is crucial for the satisfaction of users. It is important to choose a set of services that maximize the overall QoS, and satisfy all QoS requirements for the service composition. This problem, known as optimal service selection, is NP-hard. Therefore, an effective method for reducing the search space and guiding the search process is highly desirable. To this end, we introduce a novel technique, called Probabilistic Hierarchical Refinement (ProHR). ProHR effectively reduces the search space by removing competing services that cannot be part of the selection. ProHR provides two methods, probabilistic ranking and hierarchical refinement, that enable smart exploration of the reduced search space. Unlike existing approaches that perform poorly when QoS requirements become stricter, ProHR maintains high performance and accuracy, independent of the strictness of the QoS requirements. ProHR has been evaluated on a publicly available dataset, and has shown significant improvement over existing approaches.	effective method;monolithic application;np-hardness;optimizing compiler;quality of service;refinement (computing);requirement;search-based software engineering;selection algorithm;service composability principle	Tian Huat Tan;Manman Chen;Jun Sun;Yang Liu;Étienne André;Yinxing Xue;Jin Song Dong	2016	2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)	10.1145/2884781.2884861	web service;reliability engineering;mobile qos;quality of service;concrete;computer science;operating system;data mining;reliability;database;probabilistic logic	SE	-20.27367881483894	65.1901732955403	18910
40f3d0ec1254d63e7225db89d8f27adf190cd4a0	a differentially private index for range query processing in clouds		Performing non-aggregate range queries on cloud stored data, while achieving both privacy and efficiency is a challenging problem. This paper proposes constructing a differentially private index to an outsourced encrypted dataset. Efficiency is enabled by using a cleartext index structure to perform range queries. Security relies on both differential privacy (of the index) and semantic security (of the encrypted dataset). Our solution, PINED-RQ develops algorithms for building and updating the differentially private index. Compared to state-of-the-art secure index based range query processing approaches, PINED-RQ executes queries in the order of at least one magnitude faster. The security of PINED-RQ is proved and its efficiency is assessed by an extensive experimental validation.		Cetin Sahin;Tristan Allard;Reza Akbarinia;Amr El Abbadi;Esther Pacitti	2018	2018 IEEE 34th International Conference on Data Engineering (ICDE)	10.1109/ICDE.2018.00082	data mining;differential privacy;magnitude (mathematics);range query (data structures);encryption;cloud computing;computer science;semantic security;plaintext	DB	-40.35697918683078	67.05481586309993	18932
18496653f9441487985ab137441990cebdbe54be	an alert fusion framework for situation awareness of coordinated multistage attacks	cyber world;graph theory;real time fusion;alert data;goal orientation;intrusion detection fusion power generation computer science data analysis subcontracting fuses conferences protection;coordinated multistage attacks;ex post facto analysis;real time system intrusion alert fusion situation awareness coordinated multistage attacks cyber world cyber attacks attack countermeasures attack detection ex post facto analysis alert data scenario credibilities real time fusion scenario credibility values multistage goal oriented attacks;fusion;fuses;real time;multistage attacks;intrusion detection;attack detection;protection;data analysis;cyber attacks;scenario credibilities;situation awareness alert correlation fusion intrusion detection multistage attacks;sensor fusion security of data real time systems graph theory;situation awareness;attack countermeasures;fusion power generation;real time system;scenario credibility values;computer science;multistage goal oriented attacks;sensor fusion;subcontracting;security of data;intrusion alert fusion;conferences;alert correlation;real time systems	Recent incidents in the cyber world strongly suggest that coordinated multistage cyber attacks are quite feasible and that effective countermeasures need to be developed. Attack detection by correlation and fusion of intrusion alerts has been an active area of current research. However, most of these research efforts focus on ex post facto analysis of alert data to uncover related attacks. In this paper, we present an approach for dynamically calculating 'scenario credibilities' based on the state of a live intrusion alert stream. We also develop a framework for attack scenario representation that facilitates real-time fusion of intrusion alerts and calculation of the scenario credibility values. Our approach provides a usable mechanism for detecting, predicting and reasoning about multistage goal-oriented attacks in real time. The details of the fusion framework and a description of multistage attack detection using this framework are presented in this paper.	multistage amplifier;real-time locating system;sensor	Sunu Mathew;Chintan Shah;Shambhu J. Upadhyaya	2005	Third IEEE International Workshop on Information Assurance (IWIA'05)	10.1109/IWIA.2005.3	simulation;engineering;data mining;computer security	Vision	-61.65892977303668	61.38744105474099	18946
70886e009b1d64868791afa8ba08cbe23a0d9f6d	on the feasibility of a user-operated mobile content distribution network		The vast majority of mobile data transfers today follow the traditional client-server model. Although in the fixed network P2P approaches have been exploited and shown to be very efficient, in the mobile domain there has been limited attempt to leverage on P2P (D2D) for large-scale content distribution (i.e., not DTN-like, point-to-point message transfers). In this paper, we explore the potential of a user-operated, smartphone-centric content distribution model for smartphone applications. In particular, we assume source nodes that are updated directly from the content provider (e.g., BBC, CNN), whenever updates are available; destination nodes are then directly updated by source nodes in a D2D manner. We leverage on sophisticated information-aware and application-centric connectivity techniques to distribute content between mobile devices in densely-populated urban environments. Our target is to investigate the feasibility of an opportunistic content distribution network in an attempt to achieve widespread distribution of heavy content (e.g., video files) to the majority of the destination nodes. We propose ubiCDN as a ubiquitous, user-operated and distributed CDN for mobile applications.	client–server model;content delivery network;corner case;data mule;delay-tolerant networking;digital distribution;digital video;mobile app;mobile device;point-to-point protocol;population;relay;server (computing);smartphone;ubiquitous computing;video file format	Ioannis Psaras;Vasilis Sourlas;Denis Shtefan;Sergi Rene;Mayutan Arumaithurai;Dirk Kutscher;George Pavlou	2017	2017 IEEE 18th International Symposium on A World of Wireless, Mobile and Multimedia Networks (WoWMoM)	10.1109/WoWMoM.2017.7974295	computer network;mobile database;mobile search;radio access network;distributed computing;mobile technology;mobile computing;computer science;small cell;mobile station;mobile web	Mobile	-18.588630797020073	76.04741074020066	18949
0c4cb211a3a16867cb166bcacff444091c4696f2	preventing distributed denial-of-service attacks on the ims emergency services support through adaptive firewall pinholing	ddos attack;next generation network;emergency service;internet architecture;distributed denial of service;ip multimedia subsystem	Emergency services are vital services that Next Generation Networks (NGNs) have to provide. As the IP Multimedia Subsystem (IMS) is in the heart of NGNs, 3GPP has carried the burden of specifying a standardized IMS-based emergency services framework. Unfortunately, like any other IP-based standards, the IMS-based emergency service framework is prone to Distributed Denial of Service (DDoS) attacks. We propose in this work, a simple but efficient solution that can prevent certain types of such attacks by creating firewall pinholes that regular clients will surely be able to pass in contrast to the attackers clients. Our solution was implemented, tested in an appropriate testbed, and its efficiency was proven.	denial-of-service attack;firewall (computing);firewall pinhole;ip multimedia subsystem;next-generation network;testbed	Andreea Ancuta Onofrei;Yacine Rebahi;Thomas Magedanz	2010	CoRR	10.5121/ijngn.2010.2101	computer science;internet privacy;ip multimedia subsystem;computer security;denial-of-service attack;computer network	Security	-54.93184022333529	69.31239257231981	18954
07f26a59c496636b87429fa755744f727901fe03	an analytical model to design and manage a green sdn/nfv cpe node	analytical models;software;virtualization;servers hardware virtualization computer architecture analytical models markov processes software;network functions virtualization analytical model green sdn nfv cpe node internet agile network flexible network capex cost reduction opex cost reduction data center management node orchestration node management telecommunications context nfv customers service providers green policy customer premises equipment nodes system performance optimization;computer architecture;servers;virtualisation computer centres computer network management green computing internet software defined networking;markov processes;network function allocation nfv sdn;hardware	In the last few years, SDN and NFV have been introduced with the potential to change the ossified Internet paradigm, with the final goal of creating a more agile and flexible network, at the same time reducing both CAPEX and OPEX costs. For this reason, a lot of research efforts have been devoted to optimize the implementation of these technologies, also inheriting experience from data center management. However, orchestration and management of SDN/NFV nodes present new challenges with respect to data center management, mainly due to the telecommunications context where NFV resides. With this in mind, the target of this paper is to define a management model for NFV customers and service providers, a green policy of the customer premises equipment (CPE) nodes, and an analytical model to support their design. The model is then applied to a case study to demonstrate how it can be used to optimize system performance and choose the most important parameters characterizing the design of a CPE node.	agile software development;constant phase element;data center;kerrison predictor;network function virtualization;oracle rac;programming paradigm;prototype;server (computing);software-defined networking	Giuseppe Faraci;Giovanni Schembra	2015	IEEE Transactions on Network and Service Management	10.1109/TNSM.2015.2454293	real-time computing;virtualization;computer science;operating system;markov process;computer security;server;computer network	Networks	-15.16779794132983	85.29874074661711	18984
19c94d86135a29b749dd616fb5665d92985fe737	novel leases for iaas cloud	virtual machining;resource management;virtualisation cloud computing resource allocation;scheduling algorithms;scheduling;node cloud computing infrastructure as a service haizea lease manager lease;informatics;amazon ec2 iaas cloud infrastructure as a service virtualized resources resource allocation fifo queue first in first out queue virtual machines haizea manager open source lease manager period reservation token reservation advertisement soft and hard deadline;resource management cost benefit analysis scheduling informatics virtual machining cloud computing scheduling algorithms;cost benefit analysis;cloud computing	Infrastructure as a Service (IaaS) cloud offers the virtualized resources to the customer in the form of leases. IaaS cloud provider allocates the resources to the leases using various modes such as advance reservation, best effort and immediate. Advance reservation lease requires the resources at a specific time. Best effort lease is placed in a FIFO (first in first out) queue and allocated to resources only when sufficient resources are available. Immediate lease is assigned on its arrival if the resources are available, otherwise it is rejected. Haizea is an open source lease manager that provides these leases by creating virtual machines. However, it is not possible to satisfy the requirements of the leases as no cloud provider has the unlimited resource capacity at a time. In this paper, we propose four new modes of leases, namely period reservation (PR), token reservation (TR), advertisement (AD) and soft and hard deadline (SHD) for the lease managers such as Haizea and Amazon EC2. These modes are more efficient and flexible in contrast to the existing leases. The theoretical analysis clearly shows that the proposed leases outperform the existing leases in terms of cost and acceptance of leases.	amazon elastic compute cloud (ec2);best-effort delivery;cloud computing;fifo (computing and electronics);online advertising;open-source software;requirement;virtual machine	Sanjaya Kumar Panda;Prasanta K. Jana	2015	2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2015.7275747	real-time computing;computer science;resource management;operating system;scheduling;computer network	HPC	-23.680030590431286	63.62296847548624	18987
e0430e56b0713bed55e7ae967b3954365fb075de	containing sybil attacks on trust management schemes for peer-to-peer networks	transaction verification distributed system p2p network sybil attack malware proliferation key mean clustering;computer simulation sybil attacks trust management schemes peer to peer networks malware proliferation malicious peers bogus identities artificial reputation manipulation trust levels legitimate peers honest peers k means clustering scheme transaction verification collaboration identification public information performance analysis p2p network;peer to peer computing malware information systems clustering algorithms databases estimation;trusted computing computer network performance evaluation computer network security invasive software pattern clustering peer to peer computing	In this paper, we introduce a framework to detect possible sybil attacks against a trust management scheme of peer-to-peer (P2P) networks used for limiting the proliferation of malware. Sybil attacks may underscore the effectivity of such schemes as malicious peers may use bogus identities to artificially manipulate the reputation, and therefore, the levels of trust of several legitimate and honest peers. The framework includes a k-means clustering scheme, a method to verify the transactions reported by peers, and identification of possible collaborations between peers. We prove that as the amount of public information on peers increases, the effectivity of sybil attacks may decrease. We study the performance of each of these mechanisms, in terms of the number of infected peers in a P2P network, using computer simulation. We show the effect of each mechanism and their combinations. We show that the combination of these schemes is effective and efficient.	cluster analysis;computer simulation;download;interaction;k-means clustering;malware;peer-to-peer;sybil attack;transaction verification;trust management (information system);trust management (managerial science);with high probability	Lin Cai;Roberto Rojas-Cessa	2014	2014 IEEE International Conference on Communications (ICC)	10.1109/ICC.2014.6883424	computer science;internet privacy;world wide web;computer security;computer network	Mobile	-59.509871559444285	72.5705856524554	19018
66dc251d3a184664685845ffa9b825b08ff33500	cryptanalysis of a chaotic block cipher with external key and its improved version	block cipher;known plaintext attack;divide and conquer	Recently, Pareek et al. proposed a symmetric key block cipher using multiple onedimensional chaotic maps. This paper reports some new findings on the security problems of this kind of chaotic cipher: 1) a number of weak keys exists; 2) some important intermediate data of the cipher are not sufficiently random; 3) the whole secret key can be broken by a known-plaintext attack with only 120 consecutive known plain-bytes in one known plaintext. In addition, it is pointed out that an improved version of the chaotic cipher proposed by Wei et al. still suffers from all the same security defects.	block cipher;byte;computational complexity theory;cryptanalysis;key (cryptography);known-plaintext attack;list of chaotic maps;malware;map;plaintext;pseudorandomness;symmetric-key algorithm;weak key	Chengqing Li;Shujun Li;Gonzalo Álvarez;Guanrong Chen;Kwok-Tung Lo	2006	CoRR	10.1016/j.chaos.2006.08.025	weak key;rail fence cipher;block cipher;transposition cipher;differential cryptanalysis;substitution cipher;divide and conquer algorithms;residual block termination;two-square cipher;running key cipher;ciphertext stealing;block cipher mode of operation;key clustering;theoretical computer science;known-plaintext attack;stream cipher attack;mathematics;stream cipher;affine cipher;caesar cipher;slide attack;cbc-mac;polyalphabetic cipher;3-way	Crypto	-37.58348916395567	80.65732559586507	19076
69640ccc9e323f0114d671f56b998fe0fcab7d68	on necessary conditions for secure distributed computation		"""What assumptions are required to achieve an unconditionally secure distributed circuit evaluation in a fully connected network? This question was addressed with respect to the allowed number of malicious players [BGW, CCD, RB], given that every channel is unconditionally secure. In this paper we investigate whether the security of all channels is also a necessary condition. [BGW, CCD] showed how secure computation can be achieved, provided that a constant fraction of the total number of players is honest. An insecure channel can be modeled as faults on both ends of the channel. Thus, as long as the number of such \faulty"""" players is smaller then the fraction established in [BGW, CCD], the channels can be made insecure. However, an insecure channel seems to be a much weaker fault than a corruption of both players. Thus, can a bigger fraction of insecure channels be tolerated? In this paper we show that this is not the case. That is, we show that in some cases the perfect security of multi-party protocols in a fully connected network requires all the channels to be physically secure. In particular, we show a simple protocol (for three parties) for which if privacy of even one channel is compromised, the protocol can not be computed securely. Thus, we establish that the security of all channels is not only su cient (by the work of [BGW, CCD]), but also necessary . The lower bound holds even if players follow the protocol. That is, we establish our impossibility result even if all the players are honest but curious | if they follow the protocol exactly, but try to extract additional information \on the side"""". Thus, our result gives a pure security perspective of the impossibility. An additional feature of our result is its extreme simplicity, which is usually hard to come by for the lower bound proofs. AMS(MOS) Subject Classi cation: 68M10, 68P25, 68Q05. MIT Lab. for Computer Science Cambridge, MA 02139. E-mail to: \raf@theory.lcs.mit.edu"""". Part of this work was done while the author was at the IBM Research, T.J. Watson Research Center, Yorktown Heights, NY 10598. IBM Research, T.J. Watson Research Center, Yorktown Heights, NY 10598. E-mail to: \moti@ibm.com""""."""	charge-coupled device;computer science;distributed computing;ibm research;information-theoretic security;network topology;privacy;secure multi-party computation;thomas j. watson research center	Rafail Ostrovsky;Moti Yung	1989			computation;secure two-party computation;computer science;distributed computing	Crypto	-43.669501798078024	83.42984216516294	19110
89d1850dd85f9f897d0c050fc79dbcae4ca3d29a	fast and space-efficient secure frequent pattern mining by fhe	protocols;frequent pattern mining;encryption;fully homomorphic encryption;servers;cache pruning;ciphertext caching;big data;data privacy	In the big data era, security and privacy concerns are growing. One of the big challenges is secure Frequent Pattern Mining (FPM) over Fully Homomorphic Encryption (FHE). There exist some research efforts aimed at speeding-up, however, we have a big room so as to decrease time and space complexity. Apriori over FHE, in particular, generates a large number of ciphertexts during the support calculation, which results in both large time and space complexity. To solve it, we proposed a speedup technique, around 430 times faster and 18.9 times smaller memory usage than the state-of-the-art method, by adopting both packing and caching mechanism. In this paper, we further propose to decrease the memory space used for caching. Our goal is to discard redundant cached ciphertexts without increasing the execution time. Our experimental results show that our method decreases the memory usage by 6.09% at most in comparison with our previous method without increasing the execution time.	apriori algorithm;big data;cache (computing);dspace;data mining;homomorphic encryption;redundancy (engineering);run time (program lifecycle phase);set packing;speedup	Hiroki Imabayashi;Yu Ishimaki;Akira Umayabara;Hayato Yamana	2016	2016 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2016.7841083	computer science;theoretical computer science;database;internet privacy	EDA	-36.89111978975757	66.58066560691539	19123
4d0faa6c19139564b27ba83b5ca868c0a1b61e19	on the problem of capacity allocation and flow assignment in self-healing atm networks	tolerancia falta;internet protocol;ecoulement trafic;distributed system;transportation networks;eje troncal;virtual network;multiplexage longueur onde;optimisation;capacity allocation;mode transfert asynchrone;systeme reparti;generalized multi protocol label switching;protocolo internet;optimizacion;resource allocation;atm network design;resource manager;design flow;resource management;protocole internet;traffic flow;packet switching;chemin virtuel;transport layer;conmutacion por paquete;spare capacity allocation;atm networks;path based approach;qualite service;reseau federateur;gestion recursos;sistema repartido;camino virtual;red atm;flow assignment;link failure;fault tolerance;gestion ressources;optimization;grade of service;asignacion recurso;backbone;quality of service;allocation ressource;reseau atm;flujo trafico;commutation paquet;link based approach;virtual path;tolerance faute;atm network;self healing;service quality;multiplaje longitud onda;asynchronous transfer mode;red virtual;reseau virtuel;calidad servicio;wavelength division multiplexing;modo transferencia asincrono	In the current overlay transport networks, IP/ATM/SONET/DWDM, each layer manages its own control plane, each control plane acting independently of what happens in the other. In the course of recent years, the generalized multi-protocol label switching (GMPLS) has emerged as the new unified control plane for all the above transport layers. As such, the already installed ATM core resource management features must be reused as a particular implementation of GMPLS, either directly or with some adaptations. Among such transferable research work are studies related to the problem of capacity allocation and flow assignment in self-healing ATM networks. This problem has been investigated by many authors, using two main design approaches: the path-based and the link-based approaches. In the path-based design approach, the focus in almost all proposed solutions has been to determine the optimal spare capacity and backup virtual paths (BVPs) allocation for all traffic flows. To our knowledge, no study has been done to quantify the impact of the selection of BVPs on the optimized spare capacity allocation (SCA). In this paper, we address this issue by comparing four SCA design schemes quantitatively in terms of spare capacity requirements (SCRs). The comparison is based on spare optimization, a single link failure or node failure scenario, and 100% restoration. We also introduce a link-based design approach of the above problem and show that the solution obtained is adequate in terms of grade of service and quality of service requirements. 2007 Elsevier B.V. All rights reserved.	atm turbo;backup;circuit restoration;control plane;generalized multi-protocol label switching;mathematical optimization;multiprotocol label switching;network topology;non-functional requirement;synchronous optical networking;wavelength-division multiplexing	Isaac Woungang;Sudip Misra;Mohammad S. Obaidat	2007	Computer Communications	10.1016/j.comcom.2007.05.043	internet protocol;grade of service;fault tolerance;quality of service;telecommunications;resource allocation;computer science;design flow;resource management;traffic flow;asynchronous transfer mode;distributed computing;service quality;transport layer;packet switching;wavelength-division multiplexing;computer network	Embedded	-4.921060559787464	77.75813841143912	19127
1551bb65a27043a0e978fb37eb58fd641738ac52	an investigation into long range detection of passive uhf rfid tags	national security;bepress selected works;rfid tag;long range detection;chip;rfid;uhf tags;radio frequency identification;long range;credit cards;rfid uhf tags long range detection	Radio frequency identification tags (RFID) have been in use for a number of years, in a variety of applications. They are a small computer chip like device that can range in size from a thumbnail to a credit card size device. They consist of a small silicon chip, and an antenna used to receive and transmit data. When a tag receives a signal from a valid reader it sends a response, typically a tag ID and any other requested/available data back to the reader device. The newer range of RFID chips that are coming into use now use higher frequencies (UHF) and are able to be detected, or transmitted to, from longer distances (1 – 10 m) with a conventional handheld reader. This increased distance alone presents many opportunities for users and misusers alike. These include but are not limited to passive scanning/sniffing of information in transit, deception, disruption of signal, and injection of malicious or false data into the broadcast envelope. There is no evidence currently in the literature of long-range scans or attacks on UHF RFID tag or supporting infrastructure. Given that these tags are now being used in military applications, an improved understanding of their vulnerabilities from long range scanning techniques will contribute to national security. An understanding of the long range scanning potential of these devices also will allow further study into the possible misuse of RFID technology in society by governments, business and individuals.	caller id;denial-of-service attack;handheld game console;integrated circuit;packet analyzer;radio frequency;radio-frequency identification;thumbnail;ultra high frequency	Craig Valli;Andrew Woodward;Ken Wild;Reino Karvinen	2005			telecommunications;world wide web	Security	-54.82708820011461	67.82186455665382	19136
bb1fbc0308b019a3951b913fd838e50749b2e041	enhancement of dynamic id based user authentication for multi-server environment	dynamic programming;authentication;user anonymity multi server authentication;user anonymity property dynamic id based user authentication multiserver environment access resources remote server provided efficiency strong security;authentication servers smart cards computers law;security of data dynamic programming;multi server;security of data;user anonymity	User authentication is an important technology to guarantee that only the legal users can access resources from the remote server. for user authentication, in 2011, Lee et al. proposed a dynamic user authentication scheme for multi-server environments. They claimed that this scheme provided efficiency, strong security, and user anonymity property. However, we find that Lee et al.'s scheme is still vulnerable to masquerade attack and cannot provide user anonymity. This paper will propose an improvement to remedy the weakness of Lee et al.'s scheme.	authentication;polynomial-time approximation scheme;server (computing);spoofing attack	Hui-Feng Huang;Pin-Han Lin	2012	2012 Sixth International Conference on Genetic and Evolutionary Computing	10.1109/ICGEC.2012.86	data authentication algorithm;ntlmssp;computer science;authentication protocol;internet authentication service;dynamic programming;generic bootstrapping architecture;lightweight extensible authentication protocol;multi-factor authentication;authentication;internet privacy;world wide web;computer security	Mobile	-45.11325282443546	73.70547081934114	19141
930b80d9a784e8de8e23a4a0e2de2ee927ad38e3	achieving maximum throughput and minimum delay in heterogeneous peer-to-peer streaming networks	digital video broadcasting;graph theory;video signal processing;streaming delay maximum throughput minimum delay heterogeneous peer to peer streaming networks regular peers upload bandwidth selfish peers real time video high speed internet mobile devices expensive upload bandwidth selfish peer random hamiltonian cycles p2p streaming algorithm optimal streaming rate;high speed techniques;internet;video signal processing delays digital video broadcasting graph theory high speed techniques internet media streaming mobile radio peer to peer computing real time systems;mobile radio;media streaming;peer to peer computing;random graph theory peer to peer networks streaming media delay analysis;delays;real time systems	In this paper, we consider a Peer-to-Peer (P2P) streaming network with two types of peers: regular peers that can contribute one unit of upload bandwidth and selfish peers that cannot contribute any upload bandwidth. This model captures a practical scenario where real-time video is needed to broadcast not only to computers connected through high-speed Internet but also to mobile devices with limited and expensive upload bandwidth. The objective is to maximize the streaming rate guaranteed to each regular or selfish peer and minimize the delay for this content to be distributed to all peers. Using random Hamiltonian cycles, we propose a P2P streaming algorithm that can achieve (1 - 1/K)2 of the optimal streaming rate and O(logN) streaming delay for any fixed constant K > 2, where N denotes the number of peers in the network.	computer;hamiltonian (quantum mechanics);maximum throughput scheduling;mobile device;peer-to-peer;real-time clock;streaming algorithm;upload	Joohwan Kim;R. Srikant	2012	2012 Conference Record of the Forty Sixth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)	10.1109/ACSSC.2012.6489208	real time streaming protocol;real-time computing;computer science;distributed computing;computer network	Metrics	-8.839838152972188	103.62564359180934	19147
1df31259411309e687db88cb49e0b8b838f3f9c0	end-to-end energy models for edge cloud-based iot platforms: application to data stream analysis in iot		Internet of Things (IoT) is bringing an increasing number of connected devices that have a direct impact on the growth of data and energy-hungry services. These services are relying on Cloud infrastructures for storage and computing capabilities, transforming their architecture into more a distributed one based on edge facilities provided by Internet Service Providers (ISP). Yet, between the IoT device, communication network and Cloud infrastructure, it is unclear which part is the largest in terms of energy consumption. In this paper, we provide end-to-end energy models for Edge Cloud-based IoT platforms. These models are applied to a concrete scenario: data stream analysis produced by cameras embedded on vehicles. The validation combines measurements on real test-beds running the targeted application and simulations on well-known simulators for studying the scaling-up with an increasing number of IoT devices. Our results show that, for our scenario, the edge Cloud part embedding the computing resources consumes 3 times more than the IoT part comprising the IoT devices and the wireless access point.	computation;decus;data center;elegant degradation;embedded system;end-to-end principle;glossary of computer graphics;image scaling;internet of things;overhead (computing);real-time clock;response time (technology);simulation;streaming media;telecommunications network;wearable computer;wireless access point	Yunbo Li;Anne-Cécile Orgerie;Ivan Rodero;Betsegaw Lemma Amersho;Manish Parashar;Jean-Marc Menaud	2018	Future Generation Comp. Syst.	10.1016/j.future.2017.12.048	service provider;architecture;telecommunications network;wireless access point;the internet;distributed computing;computer science;cloud computing;efficient energy use;end-to-end principle	Embedded	-18.688296431648247	78.7527424689652	19150
6cfa4ea5bffbca5ea6284ec7f8c64303bb7d2545	a p2p auto-recover method for the factory data of cable modem over the hfc network	cable television;peer to peer computing cable television calibration data handling hybrid fibre coax networks maintenance engineering modems network coding;p2p docsis network coding;p2p;maintenance engineering;docsis;network coding;proceedings paper;hybrid fibre coax networks;modems;data handling;peer to peer computing;calibration;cable modem auto recovery p2p auto recovery method factory data hfc network data over cable service interface specification product docsis product calibration table digital certificates malfunction product handling maintenance branch device replacement network coding peer to peer network carol;modems peer to peer computing ip networks hybrid fiber coaxial cables communication cables calibration cable tv	With the popularization of the Data-Over-Cable Service Interface Specifications (DOCSIS) product, many devices have been installed in client sides. the issue of how to maintain the quality while providing quick repair becomes more and more important. in some practical circumstances, the cable modem may lose the factory data which include the calibration table and the digital certificates. These data are unique and vital for the regular operations of cable modem. the traditional way of handling the malfunction product is to ship back the product to the maintenance branch and replaces a working device for the customer. in this paper we will present a solution which is based on network coding over peer to peer (P2P) network to fix the problem automatically online, named Cable modem Auto-Recovery (CAROL).	alice and bob;cable modem;hybrid fibre-coaxial;linear network coding;lookup table;peer-to-peer;public key certificate	Yu-Liang Chen;Guo-Heng Luo;Yi-Ming Chang;Shyan-Ming Yuan	2012	2012 Sixth International Conference on Genetic and Evolutionary Computing	10.1109/ICGEC.2012.26	maintenance engineering;embedded system;linear network coding;calibration;cable internet access;telecommunications;docsis set-top gateway;cable modem;computer science;operating system;machine learning;digital cable;group method of data handling;peer-to-peer;cable modem termination system;zenith cable modem;television;uncapping;computer network	DB	-19.97079890132274	93.70836204792381	19167
85eb36fe7828f69a75226d837a78d41ebd646a81	p2p vs. ip multicast: comparing approaches to iptv streaming based on tv channel popularity	popularity;comparative analysis;t technology general;service provider;ip multicast;p2p;video quality;q science general;qa75 electronic computers computer science;content distribution;tv channel;peer to peer;iptv;unicast;tk electrical engineering electronics nuclear engineering;ta engineering general civil engineering general	Already a popular application in the Internet, IPTV is becoming, among the service providers, a preferred alternative to conventional broadcasting technologies. Since many of the existing deployments have been done within the safe harbor of telco-owned networks, IP multicast has been the desired streaming solution. However, previous studies showed that the popularity of the TV channels follows the Pareto principle, with the bulk of TV channels being watched only by a small fraction of viewers. Recognizing the potential scalability issues, we believe that multicast streaming approach may not be desirable for unpopular TV channels, especially when there are many such channels in the provider’s service package. For this reason, the peer-to-peer content distribution paradigm is seen as an alternative, in particular for non-popular content. In order to analyze its viability, in this paper we perform a comparative analysis between IP multicast and a peer-to-peer overlay using unicast connections as streaming approaches, in the context of channels with different degrees of popularity. The analysis targets the bandwidth utilization, video quality and scalability issues, and our findings show that while multicast is always more efficient, peer-to-peer has a comparable performance for unpopular channels with a low number of viewers.	digital distribution;iptv;international safe harbor privacy principles;multicast;pareto efficiency;peer-to-peer;programming paradigm;qualitative comparative analysis;scalability;streaming media;unicast	Alex Bikfalvi;Jaime García-Reinoso;Iván Vidal;Francisco Valera;Arturo Azcorra	2011	Computer Networks	10.1016/j.comnet.2010.12.020	service provider;qualitative comparative analysis;multicast;ip multicast;reliable multicast;telecommunications;protocol independent multicast;computer science;video quality;peer-to-peer;internet privacy;source-specific multicast;world wide web;computer security;xcast;computer network;unicast	Metrics	-15.030848809690369	76.18630646203012	19184
f0afe6fbace7008178dd8a463a973e2ba116442f	preparing floss for future network paradigms: a survey on linux network management		Operating system tools must fulfil the requirements generated by the advances in networking paradigms. To understand the current state of the Free, Libre and Open Source Software (FLOSS) ecosystem, we present a survey on the main tools used to manage and interact with the network, and how they are organized in Linux-based operating systems. Based on the survey results, we present a reference Linux network stack that can serve as the basis for future heterogeneous network environments, contributing towards a standardized approach in Linux. Using this stack, and focusing on dynamic and spontaneous network interactions, we present an evolution path for network related technologies, contributing to Linux as a network research operating system and to FLOSS as a whole.	autonomous robot;baseline (configuration management);ecosystem;interaction;linux;network architecture;open-source software;operating system;programming paradigm;protocol stack;reference architecture;requirement;spontaneous order;traction teampage	Alfredo Matos;John Thomson;Paulo Trezentos	2011			systems engineering;engineering;operating system;software engineering	OS	-17.743648294791754	84.42799827723196	19189
d67407565657fb7e737539ee32cd3bb2107f50d3	threshold-multisignature schemes where suspected forgery implies traceability of adversarial shareholders	group signature;signature scheme;threshold signature	Abs t rac t . In this paper, we are going to combine the idea of the (t, n) threshold signature scheme with the multisignature scheme and propose a new type of signature scheme, called the (t, n) threshold-multisignature scheme. In the (t, n) threshold-multisignature scheme, at least t shareholders of a specific group have to cooperate to generate a valid group signature and suspected forgery implies traceabihty of adversarial shareholders. The validity of that signature for the specific group can be verified without knowing the membership of the signers to that group.	digital signature;group signature;multisignature;traceability	Chuan-Ming Li;Tzonelih Hwang;Narn-Yih Lee	1994		10.1007/BFb0053435	computer science;internet privacy;group signature;blind signature;world wide web;computer security;algorithm	Crypto	-42.06838582859168	74.47698132908022	19206
6796b517d20cbfab9129cd7a504ce021d36670b4	optimatch: enabling an optimal match between green power and various workloads for renewable-energy powered storage systems		To reduce energy consumption and carbon emission, many data centers have deployed (or anticipate to build) their own renewable-energy power plants. However, the renewable energy (such as wind, tide, and solar energy) has the serious issues of intermittency and variability that prevent the green energy from being utilized effectively in practice. To cope with the issues, new power-supply management policies and workload scheduling algorithms have been designed. However, most existing work focuses on power optimization on computation only. In this paper, we introduce a novel scheme called OptiMatch to optimize the match between the power supply and the user-workload demand for massive storage systems that are mostly powered by renewable energy sources. OptiMatch has a hierarchical architecture, which consists of a number of heterogeneous storage devices. OptiMatch systematically utilizes the performance disparities between heterogeneous storage devices (i.e., performance per watt, IOPS/watt) to split the process for every write request into two stages: an on-line stage and a deferred off-line stage. The deferred off-line requests are used to match the green energy supplies. To maximize green energy utilization and minimize power budget without sacrificing quality of service, the fundamental methodology is to make the aggregate power supplies be proportional to the I/O workload demand at any time. To this end, our OptiMatch employs novel co-design optimizations. (1) We propose a dual-drive power control approach that makes the number of active nodes proportional to the workload demand when the green power supply is insufficient, meanwhile be proportional to the green power supply when green power is sufficient. (2) During periods of insufficient green supplies, we exploit virtualization consolidation schemes which enable a fine-grained power control to minimize the grid budgets. (3) During the periods of sufficient green supplies, we design an intelligent workload scheduling scheme which enables a near-optimal off-line requests assignment to maximize the green utilization. The experimental results demonstrate that the new OptiMatch framework can achieve high green utilization (up to 94.9%) with a minor performance degradation (less than 9.8%)	aggregate data;algorithm;computation;data center;elegant degradation;heart rate variability;input/output;mathematical optimization;online and offline;optimal matching;performance per watt;power optimization (eda);power supply;quality of service;scheduling (computing);semiconductor consolidation	Xiaoyang Qu;Jiguang Wan;Fengguang Song;Xiaozhao Zhuang;Fei Wu;Changsheng Xie	2017	2017 46th International Conference on Parallel Processing (ICPP)	10.1109/ICPP.2017.30	parallel computing;workload;distributed computing;power control;renewable energy;real-time computing;computer science;energy consumption;power budget;architecture;power optimization;watt	HPC	-20.850157956579302	61.773076176687795	19215
e9b2d994886360091df75de22648859a71b80e19	a comparison of asynchronous transfer mode (atm) and high speed ethernet: the network design implications to a business organization	network design;ethernet;network performance;lan;asynchronus transfer mode;wan;networking;high speed;asynchronous transfer mode	Technological advances such as high speed Ethernet and ATM have provided a means for business organizations to employ high performance networking. However, few studies have been conducted to verify the architecture's typical performance in a business environment. This study analyzed the network performance of high speed Ethernet and ATM when they were configured as LAN backbones. The results revealed that ATM exhibited performance superior to high speed Ethernet, but when adjustments were made for differences in line speed, the throughput was similar. In addition to analyzing empirical data about each technologies' performance, the advantages and limitations of using ATM in a business network are discussed.		Dennis C. Guster;Changsoo Sohn;Paul Safonov;David Robinson	2003	International Journal of Information Technology and Decision Making	10.1142/S0219622003000860	local area network;embedded system;network planning and design;real-time computing;synchronous ethernet;ethernet flow control;computer science;ata over ethernet;atm adaptation layer;jumbo frame;asynchronous transfer mode;ethernet global data protocol;connection-oriented ethernet;metro ethernet;carrier ethernet;ethernet over sdh;reliability;network performance;ethernet;ethernet over pdh;computer network	Arch	-6.582142482869726	91.933816483578	19223
cde98f056b2bcf521d3acd34c02d9be688b79094	a game-theoretic approach to rule sharing mechanism in networked intrusion detection systems: robustness, incentives and security	optimisation;game theory;incentive compatibility;computer network security;nash equilibrium;collaborative intrusion detection network game theory rule sharing mechanism networked intrusion detection system incentives security ids intrusion data exchange data privacy knowledge based intrusion detection network automatic knowledge propagation mechanism decentralized two level optimization nash equilibrium;intrusion detection;optimization problem;data privacy;optimisation computer network security data privacy game theory knowledge based systems;robustness;optimization;peer to peer computing;network intrusion detection system;peer to peer computing optimization intrusion detection nash equilibrium knowledge engineering robustness;knowledge based systems;knowledge base;knowledge engineering	Collaboration among IDSs allows users to benefit from the collective knowledge and information from their collaborators and achieve more accurate intrusion detection. However, most existing collaborative intrusion detection networks rely on the exchange of intrusion data which raises the privacy concern of participants. To overcome this problem, we propose a knowledge-based intrusion detection network, which provides a platform for IDS users to effectively share their customized detection knowledge in an IDS community. An automatic knowledge propagation mechanism is proposed based on a decentralized two-level optimization problem formulation, leading to a Nash equilibrium solution which is shown to be scalable, incentive compatible, fair, efficient and robust.	game theory;internet privacy;intrusion detection system;mathematical optimization;nash equilibrium;optimization problem;scalability;software propagation	Quanyan Zhu;Carol J. Fung;Raouf Boutaba;Tamer Basar	2011	IEEE Conference on Decision and Control and European Control Conference	10.1109/CDC.2011.6161171	intrusion detection system;optimization problem;game theory;knowledge base;incentive compatibility;computer science;knowledge engineering;data mining;distributed computing;computer security;intrusion prevention system;nash equilibrium;robustness	Mobile	-29.155528997586686	72.69350946987166	19347
bbfe6332092f1e68a9beb4e39bd30a42bc104c2a	personal network (pn) applications	personal network;use case	The applications of PN will be realised under many scenarios where users can have access to their personal network all the time. This network will enable the user to share critical information, play games, control their home remotely, etc. All this will be achieved with seamless interworking and handover between networks and user devices. This paper presents an array of use case scenarios that validates the ubiquitous usage of PN.	personal network	Ramjee Prasad;Knud Erik Skouby	2005	Wireless Personal Communications	10.1007/s11277-005-0569-y	use case;telecommunications;computer science;computer security;computer network	Mobile	-16.370419666542418	86.94954643646088	19368
4fb33821695efba77eb20181e4fd26c61604a0dc	security of symmetric encryption schemes with one-way ind-cna key setup		We analyse the consequences of specific properties of the key-setup phase in symmetric encryption schemes for their security. We find that key-setup routines satisfying IND-CNA and one-wayness allow to construct schemes which are provably secure against key-recovery attacks. We propose a specific cryptosystem based on a stream cipher with a one-way IND-CNA key-setup, for which we present a proof, based on a set of scheme-specific assumptions, that it remains secure even if a successful key-recovery attack against the underlying cipher is found.	cryptographic nonce;cryptosystem;encryption;key (cryptography);key-recovery attack;netware;one-way function;provable security;related-key attack;stream cipher;symmetric-key algorithm	Bartosz Zoltak	2004	IACR Cryptology ePrint Archive		40-bit encryption;cryptographic key types;56-bit encryption;theoretical computer science;cryptosystem;computer network;disk encryption hardware;stream cipher;deterministic encryption;probabilistic encryption;computer science	Crypto	-39.506335721667355	79.04305273927962	19371
33f0ea777df3bfc6913ab83bbf92e8efdeb6cc43	an adaptive expert system approach for intrusion detection	networks;adaptive expert systems;intrusion detection;fuzzy sets;fuzzy logic;intruder detection;computer security;intelligent detection;expert system	Intrusion detection is a type of computer network security system that attempts to identify inappropriate use of the system. As more corporate computer systems become linked to the internet and as more stakeholder transactions take place between systems, the identification and prevention of computer network misuse becomes increasingly critical. Expert system technology is often used to construct intruder detection systems. However, Intrusion Detection System (IDS) researchers have tended to build systems that are hard to manage, lack intuitive user interfaces and are cumbersome to use in real-live situations. In this paper, we present an adaptive expert system for intrusion detection that utilises fuzzy sets. This system has the ability to adapt to the type and/or degree of threat and is relatively simple to implement when used with computer system networks. Examples of rule sets are presented. The adaptive ability of the system is demonstrated by experimenting with the system using Clips 6.10.	artificial intelligence;clips;computer;experiment;expert system;feedback;fuzzy set;internet;intruder detection;intrusion detection system;network security policy;rule 184;surround sound;system manager (hp lx);threat (computer);usability;user interface	Stephen F. Owens;Reuven R. Levary	2006	IJSN	10.1504/IJSN.2006.011780	fuzzy logic;anomaly-based intrusion detection system;intrusion detection system;legal expert system;computer science;artificial intelligence;data mining;fuzzy set;computer security;expert system;intrusion prevention system	Security	-61.99406863821345	62.59029667488112	19376
0052822ffe468ae36c2fd878e327534ae6508de1	mssa: a m-level sufferage-based scheduling algorithm in grid environment	directed acyclic graph;sufferage;m level;scheduling algorithm;makespan;grid environment;article	Scheduling is an emergent area in Grid Environment. It is essential to utilize the processors efficiently and minimize the schedule length. In Grid Environment, tasks are dependent on each other. We use Directed Acyclic Graph (DAG) to solve task scheduling problems. In this paper, we have proposed a new scheduling algorithm called M-Level Sufferage-based Scheduling Algorithm (MSSA) for minimizing the schedule length. It has twophase process: m-level and sufferage value. M-level is used to calculate the earliest time. Sufferage is used to assign priority and select an optimal machine. MSSA always gives optimal or sub-optimal solution. Our result shows better results than other scheduling algorithms such as MET, MCT, Min-Min and Max-Min with respect to scheduling length and resource utilization.	algorithm;central processing unit;directed acyclic graph;emergence;job shop scheduling;makespan;mobile data terminal;scheduling (computing);systemverilog	Sanjaya Kumar Panda;Pabitra Mohan Khilar	2013		10.1007/978-3-642-36071-8_32	fair-share scheduling;job shop scheduling;parallel computing;real-time computing;dynamic priority scheduling;computer science;operating system;distributed computing;scheduling;directed acyclic graph	HPC	-14.972826901353613	61.69179447150687	19385
3f095f71ed2df1f0a7eafb83240d8b5d9c704039	comprehensive statistical admission control for streaming media servers	statistical approach;disk performance;resource utilization;continuous media;real time;statistical model;numerical analysis;streaming media;random variable;variable bit rate;media streaming;rate limiting;statistical modeling;bandwidth sharing;reading and writing;admission control	Streaming media servers and digital continuous media recorders require the scheduling of I/O requests to disk drives in real time. There are two accepted paradigms to achieve this: deterministic or statistical. The deterministic approach must assume larger bounds on such disk parameters as the seek time, the rotational latency and the transfer rate, to guarantee the timely service of I/O requests. The statistical approach generally allows higher utilization of resources, in exchange for a residual probability of missed I/O request deadlines. We propose a novel statistical admission control algorithm called TRAC based on a comprehensive three random variable (3RV) model to support both reading and writing of multiple variable bit rate media streams on current generation disk drives. Its major distinctions from previous work include (1) a very realistic disk model which considers multi-zoning of disks, seek and rotational latency profiles, and unequal reading and writing data rate limits, (2) a dynamic bandwidth sharing mechanism between reading and writing, and (3) support for random placement of data blocks. We evaluate the TRAC algorithm through an extensive numerical analysis and real device measurements. The results show that it achieves a much more realistic resource utilization (up to 38\% higher) as compared with the best, previously proposed algorithm based on a single random variable (1RV) model. Most impressive, in all the experiments the difference between the results generated by TRAC and the actual disk device measurements match closely.	algorithm;computational complexity theory;data rate units;experiment;gigabit;hard disk drive performance characteristics;input/output;logical disk manager;numerical analysis;prototype;scheduling (computing);stream (computing);streaming media;trac	Roger Zimmermann;Kun Fu	2003		10.1145/957013.957025	statistical model;real-time computing;simulation;computer science;operating system;distributed computing;world wide web;statistics	HPC	-16.82450151239363	67.35496618654078	19395
8fa2736baa6aa3a522336801fb441c41cc9c43a6	a method for embedding secret key information in rsa public key and its application	public key cryptography;cerification;certification;certificate authority;encryption;secret key information embedding;ibe;rsa;ibe rsa cerification pki;impersonation prevention secret key information embedding rsa public key encryption certificate verification certificate authority;public key encryption;receivers;certificate verification;redundancy;encryption proposals receivers redundancy public key cryptography;public key cryptography certification;pki;impersonation prevention;proposals	In public key encryption, we need to be able to verify the certificate from a certificate authority to prevent impersonation. In this paper, we propose an encryption system in which we can verify a public key without the certificate. We can realize our encryption system without a impersonation nor a key escrow problem.	certificate authority;embedded system;encryption;key (cryptography);key distribution center;key escrow;public key infrastructure;public-key cryptography	Motoki Kitahara;Takashi Nishide;Kouichi Sakurai	2012	2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing	10.1109/IMIS.2012.123	key;certificate policy;implicit certificate;key exchange;self-signed certificate;computer science;certificate server;public key certificate;on-the-fly encryption;internet privacy;public-key cryptography;root certificate;key distribution;computer security;certificate authority;encryption;probabilistic encryption;56-bit encryption;attribute-based encryption;computer network;keyfile	EDA	-44.01041775374914	75.4516708816695	19427
8a4212bfc5445ced39439ab0edfd975b646e3cc8	definitions of managed objects for internet fibre channel protocol (ifcp)		The iFCP protocol (RFC 4172) provides Fibre Channel fabricnfunctionality on an IP network in which TCP/IP switching and routingnelements replace Fibre Channel components. The iFCP protocol is usednbetween iFCP Gateways. This document provides a mechanism to monitornand control iFCP Gateway instances, and their associated sessions,nusing SNMP. [STANDARDS-TRACK]	internet fibre channel protocol	Kevin Gibbons;Charles Monia;Joshua Tseng;Franco Travostino	2006	RFC	10.17487/RFC4369	simple network management protocol;the internet;computer network;internet protocol suite;fibre channel;default gateway;computer science	Theory	-23.621264597572612	88.0483268197993	19428
b44d9c50f4e2b1a3f4a8d2ad721dc5591a1015e3	characteristics of random walk search on embedded tree structure for unstructured p2ps	graph theory;file list;proposals routing barium peer to peer computing indexes bandwidth network topology;routing;barium;embedded tree structure;unstructured;unstructured p2p network;p2p;tree data structures;tree data structures graph theory peer to peer computing random processes;network topology;indexes;random walk;file request message;shortest path tree p2p random walk unstructured file search;tree structure;random processes;shortest path tree;file request message random walk search embedded tree structure file search unstructured p2p network hop limited shortest path tree file list;random walk search;bandwidth;file search;p2p networks;peer to peer computing;proposals;hop limited shortest path tree	We propose a random-walk-based file search for unstructured P2P networks. In the proposal, each node keeps two pieces of information, one is on the hop-limited shortest path tree rooted at itself and the other is on the indexes of files owned by neighbor nodes, referred to as the file list. A random-walk search is conducted along the concatenation of hop limited shortest path trees. To find a file, a node first checks its file list. If the requested file is found in the list, the node sends the file request message to the file owner, otherwise, it sends a file-search message to a randomly-selected leaf node on the hop-limited shortest path trees. Numerical examples show that our proposal is much more efficient than the normal random-walk search, while it waists much less network bandwidth than the flooding (network-broadcast) based search.	concatenation;embedded system;randomness;shortest path problem;tree (data structure);tree structure	Phouvieng Hieungmany;Shigeo Shioda	2010	2010 IEEE 16th International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2010.90	database index;routing;torrent file;computer science;graph theory;stub file;theoretical computer science;journaling file system;peer-to-peer;distributed computing;open;barium;tree structure;tree;file system fragmentation;random walk;network topology;bandwidth;statistics;shortest-path tree;computer network	HPC	-8.318085142118461	76.69678911564918	19456
a590c4296e8f96afa608089cf87290f03125fef4	multilayer optimization of inverse-multiplexed 100 gb/s ethernet services over optical transport networks	wdm;optical transport networks;optical channel;wavelength assignment;reference network topology;nonhomogeneous media ethernet networks optical fiber networks wavelength division multiplexing containers routing degradation stimulated emission telecommunication traffic transport protocols;ethernet service;vcat;optical transport network;bit rate 100 gbit s;network evolution;routing;color;data stream;wavelength assignment problem;optical fiber networks;indexing terms;wavelength division multiplexing channel capacity linear programming multipath channels optical fibre lan telecommunication network routing telecommunication network topology telecommunication traffic transport protocols wavelength assignment;network topology;transport protocols;multilayer optimization framework;telecommunication traffic;multipath strategy;telecommunication network routing;channel capacity;packet traffic growth;cost efficiency;linear programming;linear program;degraded service routing;optimization;network architecture;multipath channels;inverse multiplexing technique;telecommunication network topology;optical fibre lan;ethernet networks;multipath routing;virtual concatenation protocol;sonet;multilayer optimization;containers;wavelength division multiplexing;bit rate 100 gbit s packet traffic growth optical transport network ethernet service inverse multiplexing technique virtual concatenation protocol vcat optical channel wdm wavelength division multiplexing multilayer optimization framework linear programming reference network topology wavelength assignment problem degraded service routing multipath strategy;100 gb s ethernet	Stimulated by the remarkable packet traffic growth, the transport of 100 Gb/s Ethernet (100-GbE) services is to become a reality in a near future. To provide a smooth and costefficient network evolution, inverse-multiplexing techniques can be employed to carry the high-capacity data streams. In this context, the Virtual Concatenation (VCAT) protocol, available in Optical Transport Network (OTN) systems, represents the most adequate solution to decompose the 100-GbE signal into logical containers of 10 Gb/s and 40 Gb/s. With VCAT, each container can be independently routed throughout the network under several distribution paradigms, such as the classical single-path and multipath schemes, and the alternative degraded-service approach. In the network architecture considered, each routing path is required to be transmitted over an optical channel at the underlying WDM layer. Hence, in this work, we provide an optimization framework for solving the resource provisioning problem for 100-GbE at both OTN and WDM layers. Linear Programming based heuristics are proposed for routing the containers and dimension the capacity required at the OTN level. In particular, solutions for single-path, multipath, and degradedservice routing are described and evaluated in a reference network topology. The optimization procedures are also extended to resolve the wavelength assignment problem at the physical WDM layer. With this optimized multilayer architecture, the capacity gains resulting from the adoption of multipath strategies over single-path are properly evaluated and demonstrated. In addition, it is shown that the implications of using diverserouting over the WDM layer have a minor impact in the capacity savings.	assignment problem;concatenation;fibre channel;gigabyte;heuristic (computer science);linear programming;mathematical optimization;multipath routing;network architecture;network packet;network topology;numerical analysis;provisioning;requirement;selection algorithm;software deployment;wavelength-division multiplexing	João Santos;João Manuel Ferreira Pedro;Paulo P. Monteiro;João Pires	2009	2009 Next Generation Internet Networks	10.1109/NGI.2009.5175767	telecommunications;computer science;linear programming;wavelength-division multiplexing;computer network	Networks	-6.250345490072259	83.93928377811157	19457
a5e350175f3c289380b4872df78801e60dfd8122	scalability in ip-oriented networks (guest editorial)	computer architecture;internet;multicast protocols;diffserv networks;ip networks;scalability intelligent networks quality of service internet ip networks diffserv networks computer architecture multicast protocols communication system control hardware;intelligent networks;scalability;quality of service;communication system control;hardware	Presents the guest editorial for this issue of the publication.	scalability	Nirwan Ansari;Amitabh Mishra;Heinrich J. Stüttgen	2003	IEEE Communications Magazine	10.1109/MCOM.2003.1204744	intelligent network;real-time computing;multicast;scalability;the internet;quality of service;telecommunications;computer science;distributed computing;xcast;computer network	Vision	-14.210863459300509	91.95289412869556	19466
81f30c5013ea1b42492b509db096dd3535b3f7ea	taxonomy of malware detection techniques: a systematic literature review	databases;computers;detectors;unsolicited electronic mail;internet;malware	Malware is an international software disease. Research shows that the effect of malware is becoming chronic. To protect against malware detectors are fundamental to the industry. The effectiveness of such detectors depends on the technology used. Therefore, it is paramount that the advantages and disadvantages of each type of technology are scrutinized analytically. This study's aim is to scrutinize existing publications on this subject and to follow the trend that has taken place in the advancement and development with reference to the amount of information and sources of such literature. Many of the malware programs are huge and complicated and it is not easy to comprehend the details. Dissemination of malware information among users of the Internet and also training them to correctly use anti-malware products are crucial to protecting users from the malware onslaught. This paper will provide an exhaustive bibliography of methods to assist in combating malware.	evolutionary taxonomy;first-class function;malware;onslaught;requirement;sensor;software requirements;systematic review	Hanif-Mohaddes Deylami;Ravie Chandren Muniyandi;Iman Tabatabaei Ardekani;Abdolhossein Sarrafzadeh	2016	2016 14th Annual Conference on Privacy, Security and Trust (PST)	10.1109/PST.2016.7906998	cyber-collection;detector;the internet;computer science;cryptovirology;malware;internet privacy;world wide web;computer security	Security	-58.06640123505485	62.05799286595601	19472
3fc4ad97e419c5569fa66609c2c1bab0f4331b1b	audit expert system of communication security assessment		Abstract The main goal of the research consists in the elaboration of a system concerning the investigation of security communication, which regards a set of security factors, such as: the degree of encryption, the freshness of nonces, intruder activation, the lifetime of keys, secrets, etc. This paper is devoted to the presentation of systematization formalisms describing the functioning of a security model. In our variant, we investigate the changes of all chosen factors (security attributes) during the realization of protocol operations. The security attributes should be systematically corrected in this process. It changes the general security level of communication. The audit system strategy leads us to one of the most noticeable security in fluence characteristics that refer to time parameters. We can introduce the notation concerning the lifetime of elements (key, message, nonces, secret, etc.). When the value of time activity of an element exceeds its lifetime, then the communication security is definitely threatened. By using special rules presented in the works of Burrows, and Needham 2 , among other authors, and by creating additional logic formulas, we can estimate intermediate security probability parameters. Finally, we propose a certain kind of probability time automata in order to investigate and predicate different types of communication threats. These automata are built on the basis of a colored Petri net. In addition, this investigation consists in checking communication security (or a kind of threats) and making a threat prediction about possible cases that are connected with losing information. We also included in the model a procedure of security modification with respect to time (the activity of some parameters depends on time). We define the finite set of states by using the LU - technique (interval attribute activity) of a date notation. The proposed system resolves security problem in more comprehensive (multifaceted) way. Ingredient security factors can be grouped in different combinations. This approach increased the range of investigated threaten structures to even unknown hacker algorithm inventions.	communications security;expert system	Henryk Piech;Grzegorz Grodzki	2017		10.1016/j.procs.2017.08.188	computer security model;artificial intelligence;information security audit;machine learning;data mining;covert channel;security association;security convergence;computer science;security testing;security information and event management;security service	Crypto	-37.090953828636216	72.27413635837071	19493
70203818fb4deced687d9d2f15a02452dbd37169	energy proportionality of an enterprise network	energy efficient;data collection;enterprise networks;traffic flow;data center;energy consumption;network power	Energy efficiency is becoming increasingly important in the operation of networking infrastructure, especially in enterprise and data center networks. While strategies for lowering the energy consumption of network devices have been proposed, what is lacking is a comprehensive measurement study conducted across a large network (such as an enterprise), that monitors power usage as a function of traffic flowing through the network. We present a large power profile study that we conducted in an enterprise network, comprising of 90 live switches from various vendors. We first describe Urja, the system that we built, that collects required configurations from a wide variety of deployed switches and uses them to accurately predict the power consumed by individual devices and the network as a whole. Urja is vendor neutral, and relies on standard SNMP MIBs to gather the required configuration and traffic information. Further, based on available knobs in current devices, the analysis engine in Urja lists various configuration and rewiring changes that can be made to the devices in order to make the network more energy proportional. Urja has been deployed in an enterprise sub-network for about 4 months; through comprehensive analysis of the data collected over this period, we present various changes (in increasing order of cost and complexity) that network administrators can perform; in this segment of an enterprise network, we can save over 30% of the network energy through simple configuration and rewiring changes, and without any performance impact.	data center;network switch;simple network management protocol;subnetwork	Priya Mahadevan;Sujata Banerjee;Puneet Sharma	2010		10.1145/1851290.1851302	data center;enterprise private network;real-time computing;operating system;traffic flow;network simulation;efficient energy use;computer security;computer network;data collection	Networks	-18.381558850442286	78.53685774470101	19524
6e2e85502956078541f7f6ef4115c163ccf34d02	buffer management for heterogeneous resolution display in home vod services	video object;video streaming;domestic appliances;personal digital assistant;heterogeneous resolution display;qos adaptation;digital tv;home vod services;buffer management;buffer storage;home appliances;indexing terms;qos;video on demand;buffer management home vod services heterogeneous resolution display home appliances inter arrival time video objects streaming rate qos;video streaming buffer storage domestic appliances quality of service video on demand;video objects streaming rate;quality of service;inter arrival time;displays streaming media personal digital assistants home appliances digital tv multimedia systems cellular phones computer science intelligent networks home automation	This paper presents an efficient buffer management scheme to support heterogeneous resolution display in home VOD services. The proposed scheme provides different quality services for various home appliances such as digital TV, home theater, and personal digital assistants (PDAs). Specifically, the proposed scheme exploits the reference popularity of video objects as well as the inter-arrival time between two consecutive requests on the same object. The scheme also considers the different streaming rate of video objects to provide QoS adaptive VOD service for heterogeneous appliances. Experiments with real world VOD traces show that the proposed scheme improves the performance of home VOD systems significantly	cache (computing);clock rate;elegant degradation;home theater in a box;personal digital assistant;time of arrival;tracing (software);versant object database	Taeseok Kim;Hyokyung Bahn;Kern Koh	2006	IEEE Transactions on Consumer Electronics	10.1109/TCE.2006.1706515	quality of service;computer science;multimedia;internet privacy;computer network	Mobile	-7.550497219534754	99.52538945314915	19543
27de3913ab62f5b0256b0bb39d30bb8df6091d8a	on strict estimation method of provable security against differential and linear cryptanalysis	provable security;commerce electronique;partage secret;comercio electronico;secret sharing;securite;estimation method;cle publique;upper bound;linear cryptanalysis;public key;criptografia;cryptography;safety;llave publica;cryptographie;codigo algebraico;seguridad;algebraic code;electronic trade;code algebrique	We give stricter upper bounds to the probabilities of differential and linear hull of DES-like ciphers than the previous results. The previous results in [6, 7] said that every r-round differential (or linear hull) with r ≥ 4 is bounded by 2p 2  (or 2q 2 ) where p (or q) is the maximum probability of a non-trivial differential (or linear hull) of the function which is used in each round. Using our new estimation method of provable security it is shown that these bounds change depending on the number of rounds. This change gives a decrease function of the number of rounds with the limit value. Moreover, our estimation gives 2p 2  -p 3  (or 2q 2  -q 3 ) for 4 and 5 rounds so our method is stricter than the previous one. The bounds converge to about p 2 (or q 2 ) for an increasing number of rounds.	linear cryptanalysis;provable security	Yasuyoshi Kaneko;Shiho Moriai;Kazuo Ohta	1997		10.1007/BFb0028481	computer science;cryptography;theoretical computer science;provable security;mathematics;distributed computing;secret sharing;computer security;algorithm;statistics;linear cryptanalysis	Crypto	-36.741145293790886	75.85066084326628	19551
f86b8fcfe0c804e08ad7857aae37aebb0e8884c7	ripplelog: a path search algorithm for a distributed query processing	routing protocols;query processing;path search algorithm;routing;distributed processing;search algorithm;logging;data mining;distributed query processing ripple routing incremental path search logging data query transmission;data query transmission;distributed query processing;message passing procedure;message passing;logging mechanism;search problems;floods;search problems distributed processing query processing;logging mechanism ripplelog path search algorithm distributed query processing decomposed sub queries message passing procedure;decomposed sub queries;incremental path search;query processing message passing routing protocols algorithm design and analysis computer science data engineering cost function distributed computing search methods design optimization;ripple;ripplelog;message logging	Distributed query processing (DQP) requires data or decomposed sub-queries be routed to different destination nodes for execution, thus a path search algorithm is needed to find best paths for data/query transmissions. When a node doesn't know how to route a data/query to a specified destination node, the path search algorithm on the node has to initiate a message passing procedure around its neighbors to find the best path to the destination. To accomplish the path search with low message passing traffic for distributed query processing, the paper propose a distinctive path search algorithm, RippleLog, which is composed of the following two mechanisms: 1)the incremental message passing mechanism, which limits the number of nodes involved for the path search so as to reduce the message passing traffic; 2)the logging mechanism, which maintains a message-log on each node for the best path evaluation and further reduce the message passing traffic.	database;login;message passing;overhead (computing);query optimization;requirement;routing;search algorithm	Junhu Zhang;Jinlong Wang;Dongqing Yang	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.350	fast path;computer science;theoretical computer science;path expression;database;distributed computing;fringe search	DB	-6.451648013408317	68.7880145578237	19577
074d7a62ad96f3bf8780819c06c81a11dd0cd50a	case study for a gpon deployment in the enterprise environment	ip and rf video;surveillance;single mode fibre;wlan;qos;gpon based pols;security;voip;cloud computing	Enterprise networks are facing disruptive change caused by the use of Internet versus enterprise based applications, increasing video content, integration of voice services onto the LAN, and the transition from wired to wireless LANs. This paper explores this opportunity to adopt Passive Optical LANs (POLs), based on Gigabit Passive Optical Network technology (GPON), rather than continuing with use of traditional twoor three-tier switched Ethernet solution.	cloud computing;computer cooling;data center;digital video;emergence;fiber to the x;floor and ceiling functions;gigabit;multitier architecture;outsourcing;passive optical network;requirement;software deployment;stationary process;total cost of ownership	Stanislav Milanovic	2014	JNW	10.4304/jnw.9.01.42-47	single-mode optical fiber;real-time computing;quality of service;cloud computing;telecommunications;computer science;information security;operating system;voice over ip;computer network	OS	-12.761803252935431	86.88167174305013	19602
e6a33cb93fa8395e0c0e574305ecc70eddb12602	reliability-aware service chaining in carrier-grade softwarized networks		Network Function Virtualization (NFV) has revolutionized service provisioning in cloud datacenter networks. It enables the complete decoupling of Network Functions (NFs) from the physical hardware middle boxes that network operators deploy for implementing service-specific and strictly ordered NF chains. Precisely, NFV allows for dispatching NFs as instances of plain software called virtual network functions (VNFs) running on virtual machines hosted by one or more industry standard physical machines. Nevertheless, NF softwarization introduces processing vulnerability (e.g., failures caused by hardware or software, and so on). Since any failure of VNFs could break down an entire service chain, thus interrupting the service, the functionality of an NFV-enabled network will require a higher reliability compared with traditional networks. This paper encloses an in-depth investigation of a reliability-aware joint VNF chain placement and flow routing optimization. In order to guarantee the required reliability, an incremental approach is proposed to determine the number of required VNF backups. Through illustration, it is shown herein that the formulated single path routing model can be easily extended to support resource sharing between adjacent backup VNF instances. This paper advocates the absolute existence of a share-resource-based VNF assignment strategy that is capable of trading off all of the reliability, bandwidth, and computing resources consumption of a given service chain. A heuristic is proposed to work around the complexity of the presently formulated integer linear programming (ILP). Thorough numerical analysis and simulations are conducted in order to verify and assert the validity, correctness, and effectiveness of this proposed heuristic reflecting its ability to achieve very close results to those obtained through the resolution of the complex ILP within a negligible amount of time. Above and beyond, the proposed resource-sharing-based VNF placement scheme outperforms existing resource-sharing agnostic schemes by 15.6% and 14.7% in terms of bandwidth and CPU utilization respectively.	backup;bidirectional search;cplex;central processing unit;correctness (computer science);coupling (computer programming);data center;greedy algorithm;heuristic;heuristic (computer science);integer programming;interrupt;linear programming;mathematical optimization;network function virtualization;new foundations;numerical analysis;place and route;provisioning;reed–solomon error correction;resolution (logic);routing;shortest path problem;simulation;solver;technical standard;virtual machine	Long Qu;Maurice Jose Khabbaz;Chadi M. Assi	2018	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2018.2815338	real-time computing;flow routing;virtual network;cloud computing;carrier grade;virtual machine;shared resource;integer programming;computer science;provisioning	Networks	-12.402121900233105	81.99592579639521	19616
1caed1467401c1fdfb4acb4b71686f8f4b4545e1	practical proofs of knowledge without relying on theoretical proofs of membership on languages	interaction protocol;proof of knowledge	Formulations and properties of proving possession of knowledge in interactive protocols arc investigated. A four-move protocol for quadratic residuosity is proposed and a new notion of practical soundness is introduced based on its application to a cryptographic identification scheme. The role of cryptographic assumptions in arguments (i.e., computationally convincing proofs) of knowledge is also explored.	cryptography;identification scheme;proof of knowledge;quadratic residue	Kouichi Sakurai	1997	Theor. Comput. Sci.	10.1016/S0304-3975(96)00277-0	discrete mathematics;computer science;theoretical computer science;mathematics;proof of knowledge;algorithm	Crypto	-39.898905395697376	75.88949604082057	19651
5e0cbf745376bdcbe2e33779b336343d0763caf5	erratum to: a new lightweight rfid grouping authentication protocol for multiple tags in mobile environment			authentication protocol;radio-frequency identification	Jian Shen;Haowen Tan;Yan Zhang;Xingming Sun;Yang Xiang	2017	Multimedia Tools and Applications	10.1007/s11042-017-4602-4	computer science;lightweight extensible authentication protocol;computer network;authentication protocol	Mobile	-45.587224325257445	75.6802515892028	19655
0df32e5cc7ac80baabe8b4847deb7603de617ae3	completeness of the authentication tests	protocol analysis;cryptographic protocol;satisfiability;critical value	Protocol participants manipulate values, transforming the cryptographic contexts in which they occur. The rules of the protocol determine which transformations are permitted. We formalize these transformations, obtaining new versions of the two authentication tests from earlier strand space papers. We prove that the new versions are complete, in this sense: any collection of behaviors that satisfies those two authentication tests, when combined with some feasible adversary behavior, yields a possible execution. We illustrate the strengthened authentication tests with brief analyses of three protocols.	adversary (cryptography);authentication;cryptography;strand (programming language)	Shaddin F. Doghmi;Joshua D. Guttman;F. Javier Thayer	2007		10.1007/978-3-540-74835-9_8	otway–rees protocol;critical value;computer science;theoretical computer science;cryptographic protocol;computer security;protocol analysis;algorithm;satisfiability	Crypto	-36.88454798238884	72.86257764403261	19682
4fd93043facc8c8c7db5736e6e895bf3025d7aab	layer two tunnelling protocol (l2tp): atm access network extensions		This document augments the procedures described in RFC 2661 to further support ATM SVC (Switched Virtual Circuits) or PVC (Permanent Virtual Circuits) based access networks. L2TP (Layer 2 Tunneling Protocol) specifies a protocol for tunnelling PPP packets over packet based networks and over IP networks in particular. L2TP supports remote access by ISDN and PSTN networks. The extensions defined within this document allow for asymmetric bi-directional call establishment and service selection in the ATM access network.	atm turbo;access network;layer 2 tunneling protocol	Yves T'Joens;Paolo Crivellari;Bernard Sales	2002	RFC	10.17487/RFC3301	telecommunications;computer science;atm adaptation layer;asynchronous transfer mode;tunneling protocol;distributed computing;x.25;ip tunnel;layer 2 tunneling protocol;computer network	Networks	-23.59651233783861	88.52456606378303	19688
7aa4a43f562e0d65bcefdd347bd1c4426c916c36	introduction to network experiments using the geni cyberinfrastructure	performance evaluation;measurement;traffic generation;distributed computing;network experiments;resource availability;modeling	In this tutorial, we will introduce the SIGMETRICS/Performance community to the vast testbeds, tools and resources openly available through the GENI (Global Environment for Network Innovations) project. We will present details about the distributed computing resources available on GENI for researchers interested in simulation as well as measurement-based performance evaluation experiments. We will demonstrate simple experiments on GENI, and leave them with information on how to run experiments for research and education using GENI resources.	cyberinfrastructure;distributed computing;experiment;performance evaluation;simulation	Jay Aikat;Kevin Jeffay	2012		10.1145/2254756.2254830	simulation;systems modeling;computer science;data science;management science;measurement	HPC	-20.642244269715658	86.45891844890046	19705
0c4fd4d05c25a2841d976f2d117dbe3cc3892c30	histogram matrix: log file visualization for anomaly detection	histogram matrix;log files;statistical analysis data visualisation matrix algebra security of data;anomaly detection;interactive search;matrix algebra;automatic generation;data visualisation;log file analysis;histograms humans intrusion detection information technology data visualization event detection availability information security information analysis data security;statistical analysis;visualization technique;log file visualization;statistical technique;statistical techniques;intrusion detection system histogram matrix log file visualization anomaly detection statistical technique interactive search;security of data;intrusion detection system	In today's IT environments, there is an ever increasing demand for log file analysis solutions. Log files often contain important information about possible incidents, but inspecting the often large amounts of textual data is too time-consuming and tedious a task to perform manually. To address this issue, we propose a novel log file visualization technique called Histogram Matrix (HMAT). HMAT visualizes the content of a log file in order to enable a security administrator to efficiently spot anomalies. The system uses a combination of graphical and statistical techniques and allows even non-experts to interactively search for anomalous log messages. Contrary to other approaches, our proposal does not only work on certain special kinds of log files, but instead works on almost every textual log file. Additionally, the system allows to automatically generate security events if an anomaly is detected, similar to anomaly-based intrusion detection systems. This paper introduces HMAT, demonstrates its functionality using log files from a variety of services in real environments, and identifies strengths and limitations of the technique.	anomaly detection;anomaly-based intrusion detection system;data logger;interactivity;text corpus;transaction log	Adrian Frei;Marc Rennhard	2008	2008 Third International Conference on Availability, Reliability and Security	10.1109/ARES.2008.148	computer science;journaling file system;web log analysis software;data mining;database;world wide web	OS	-61.21099861315103	61.70058175291714	19716
0c052ad76e9130eb638e7e1cd6caa0a78caa4b03	ppm-hda: privacy-preserving and multifunctional health data aggregation with fault tolerance	spatial aggregation;servers privacy cascading style sheets cryptography mobile communication additives;telecommunication security biomedical communication body area networks cloud computing data communication fault tolerance statistical analysis;cascading style sheets;privacy preserving;additives;cloud assisted wbans multifunctional aggregation differential privacy spatial aggregation temporal aggregation fault tolerance privacy preserving;temporal aggregation;servers;cloud assisted wbans;cryptography;fault tolerance;mobile communication;multifunctional aggregation;differential privacy;min max aggregation ppm hda privacy preserving multifunctional health data aggregation fault tolerance wireless body area networks cloud assisted wban health care system remote health monitoring continuous patient care health care services mobile users cloud server differential attacks security analysis data aggregation schemes performance evaluations communication overhead;privacy	Wireless body area networks (WBANs), as a promising health-care system, can provide tremendous benefits for timely and continuous patient care and remote health monitoring. Owing to the restriction of communication, computation and power in WBANs, cloud-assisted WBANs, which offer more reliable, intelligent, and timely health-care services for mobile users and patients, are receiving increasing attention. However, how to aggregate the health data multifunctionally and efficiently is still an open issue to the cloud server (CS). In this paper, we propose a privacy-preserving and multifunctional health data aggregation (PPM-HDA) mechanism with fault tolerance for cloud-assisted WBANs. With PPM-HDA, the CS can compute multiple statistical functions of users' health data in a privacy-preserving way to offer various services. In particular, we first propose a multifunctional health data additive aggregation scheme (MHDA+) to support additive aggregate functions, such as average and variance. Then, we put forward MHDA⊕ as an extension of MHDA+ to support nonadditive aggregations, such as min/max, median, percentile, and histogram. The PPM-HDA can resist differential attacks, which most existing data aggregation schemes suffer from. The security analysis shows that the PPM-HDA can protect users' privacy against many threats. Performance evaluations illustrate that the computational overhead of MHDA+ is significantly reduced with the assistance of CSs. Our MHDA⊕ scheme is more efficient than previously reported min/max aggregation schemes in terms of communication overhead when the applications require large plaintext space and highly accurate data.	adversary model;aggregate data;aggregate function;cascading style sheets;computation;data aggregation;differential cryptanalysis;fault tolerance;information privacy;intel high definition audio;maxima and minima;multi-function printer;multistage interconnection networks;overhead (computing);performance evaluation;plaintext;server (computing);utility functions on indivisible goods;virtual private server	Song Han;Shuai Zhao;Qinghua Li;Chun-Hua Ju;Wanlei Zhou	2016	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2015.2472369	fault tolerance;computer science;cryptography;internet privacy;cascading style sheets;privacy;computer security;differential privacy;computer network	Mobile	-43.15943092100005	65.31484492936988	19731
00ac44f9e312a1d64751c4af41e5fa3edb194c2c	efficient recovery from false state in distributed routing algorithms	distributed system;fault tolerant;routing;recovery;checkpointing;network routing;fault tolerance;routing algorithm;security;network congestion	Malicious and misconfigured nodes can inject incorrect state into a distributed system, which can then be propagated system-wide as a result of normal network operation. Such false state can degrade the performance of a distributed system or render it unusable. For example, in the case of network routing algorithms, false state corresponding to a node incorrectly declaring a cost of 0 to all destinations (maliciously or due to misconfiguration) can quickly spread through the network. This causes other nodes to (incorrectly) route via the misconfigured node, resulting in suboptimal routing and network congestion. We propose three algorithms for efficient recovery in such scenarios and prove the correctness of each of these algorithms. Through simulation, we evaluate our algorithms – in terms of message and time overhead – when applied to removing false state in distance vector routing. Our analysis shows that over topologies where link costs remain fixed and for the same topologies where link costs change, a recovery algorithm based on system-wide checkpoints and a rollback mechanism yields superior performance when using the poison reverse optimization.	algorithm;correctness (computer science);distance-vector routing protocol;distributed computing;mathematical optimization;network congestion;network topology;overhead (computing);rollback (data management);simulation;transaction processing system;usability	Daniel Gyllstrom;Sudarshan Vasudevan;James F. Kurose;Gerome Miklau	2010		10.1007/978-3-642-12963-6_16	routing table;routing domain;routing;enhanced interior gateway routing protocol;fault tolerance;static routing;real-time computing;hierarchical routing;zone routing protocol;equal-cost multi-path routing;computer science;dynamic source routing;information security;multipath routing;destination-sequenced distance vector routing;distributed computing;routing protocol;link-state routing protocol;path vector protocol;hazy sighted link state routing protocol;geographic routing;routing information protocol;computer network	Networks	-9.390355523833955	72.70345437577026	19748
7d7ccac7c1bd0c000b1fa9d879a769f37eaa113f	num-based fair rate-delay balancing for layered video multicasting over adaptive satellite networks	ip layers;app layers;satellite communication;satellite network;multicast communication;traffic variations;layered video multicasting;layered video;scalable video coding;adaptive physical layer;perforation;si sap;svc;physical layer;queueing theory;adaptive physical layers;resource manager;resource management;num based fair rate delay balancing;protocol design;video quality;acm;adaptive satellite networks;cross layer diffserv architecture;traffic variations num based fair rate delay balancing layered video multicasting adaptive satellite networks mac ip layers app layers rate delay balancing network utility maximization num scalable video coding svc cross layer diffserv architecture adaptive physical layer ip queues video layers distribution adaptive physical layers water filling load;qos;wireless communication;video coding;network utility maximization num;low latency;streaming media;water filling;network utility maximization;satellites;video layers distribution;mac;scheduler;ip queues;access protocols;diffserv networks;water filling load;video communication access protocols diffserv networks multicast communication queueing theory satellite communication video coding;ip networks;load balance;dvb s2;num;cross layer;quality of service;dvb s2 network utility maximization num water filling cross layer acm scalable video coding scheduler delay si sap qos;video communication;dynamic adaptation;delay streaming media quality of service ip networks satellites resource management wireless communication;rate delay balancing	Trading delay and rate in upcoming satellite networks are of paramount interest. In this paper, we present a solution to optimally distribute resources across MAC, IP and APP layers to deal with the problem of efficiently and reliably delivering low latency and high rate inelastic services over such networks. In order to do so, we formulate the problem of rate/delay balancing according to a Network Utility Maximization (NUM) paradigm assuming Scalable Video Coding (SVC) feeding a cross-layer DiffServ architecture, and an adaptive physical layer. We solve not only the bit loading balancing across the IP queues but also the video layers distribution to be sent among the adaptive physical layers, all constrained by delay requirements. The solution, which provides a fair rate-delay trade-off, happens to be on a water filling load across the queuing architecture, and it is suitable for multicasting scenarios. Finally, we propose a full protocol design, implementation, and performance evaluation based on truly available standardized tools, hence, it is ready-to-use. Our solution significantly outperforms non cross-layer approaches in terms of delay and video quality, and it dynamically adapts to channel and traffic variations.	communications protocol;computer user satisfaction;differentiated services;encoder;expectation–maximization algorithm;interactivity;load balancing (computing);multicast;network utility;peak signal-to-noise ratio;performance evaluation;programming paradigm;requirement;scalable video coding;scheduling (computing);video decoder	David Pradas;Maria Angeles Vázquez-Castro	2011	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2011.110507	real-time computing;quality of service;telecommunications;computer science;resource management;computer network	Networks	-6.640459845851256	99.60173718283062	19753
ff39564844b3d2bf025bef136fec1ebfcd007729	anycasting in connection-oriented computer networks: models, algorithms and results	connection oriented networks;optymalizacja;siec polączeniowa;mpls;computer network;odpornośc;anycasting;optimization;survivability	Our discussion in this article centers around various issues related to the use of anycasting in connection-oriented computer networks. Anycast is defined as a one-to-one-of-many transmission to deliver a packet to one of many hosts. Anycasting can be applied if the same content is replicated over many locations in the network. Examples of network techniques that apply anycasting are Content Delivery Networks (CDNs), Domain Name Service (DNS), Peer-to-Peer (P2P) systems. The role of anycasting is growing concurrently with the popularity of electronic music, movies, and other content required by Internet users. In this work we focus on the optimization of anycast flows in connection-oriented networks. We formulate a model of anycast connections and next propose a heuristic algorithm based on the Lagrangean relaxation aimed to optimize jointly routes for anycast and unicast connections. Results of numerical experiments are presented and evaluated. Finally, we analyze briefly problems related to anycasting in dynamic routing and multi-layer networks.	algorithm;anycast;connection-oriented communication;experiment;heuristic (computer science);layer (electronics);linear programming relaxation;mathematical optimization;network packet;numerical analysis;one-to-one (data model);peer-to-peer;routing;unicast	Krzysztof Walkowiak	2010	Applied Mathematics and Computer Science	10.2478/v10006-010-0015-5	multiprotocol label switching;telecommunications;computer science;distributed computing;computer network	Metrics	-6.0153174134421805	83.46747860768073	19761
e01cfc0c0761ee8d76e7ccaf8c0b3aa09f28fe05	software defined mobile network for flexible deployments of various iot applications	opencellular;5g;internet of things iot;software defined network sdn;general purpose processor gpp	Facebook has recently announced its OpenCellular platform for promoting open-source wireless access technology developments and broader applications. In this demonstration, we would like to show a software defined mobile network that realizes both eNB and EPC key functions according to the 3GPP LTE standard on a general purpose processor (GPP) based computational platform. It is very adaptive and flexible for supporting a variety of internet of things (IoT) applications in vertical industries.	assistive technology;compaq lte;computation;electronic product code;graph partition;internet of things;open-source software	Yang Yang;Haidong Xu;Jing Xu;Jiang Wang	2016	2016 IEEE 13th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)	10.1109/MASS.2016.059	embedded system;computer science;operating system;5g;computer security;internet of things;computer network	Mobile	-16.296680099927826	86.57716361233439	19802
f42a0f3abe190f756e116605c087716d28b50b5f	caractérisation de flux et qualité de service pour systèmes de combat futurs	internet protocol;distributed system;arquitectura red;communication donnee;aplicacion militar;gestion qualite;systeme reparti;application militaire;gestion calidad;protocolo internet;criterio resultado;recoleccion dato;systeme reparti application militaire;data gathering;demanda repeticion automatica;protocole internet;performance requirement;critere performance;flux donnee;flujo datos;architecture reseau;data communication;qualite service;sistema repartido;capteur mesure;internet;military application;demande repetition automatique;network architecture;qualite de service;data flow;automatic repeat request;collecte donnee;service quality;quality management;calidad servicio	Futur combat systems will rely on the use of remote sensors to detect, identify and track targets. Embedded or deployed along coasts, these sensors generate data streams requiring various garanteed services from the networks. Sensor datas must be collected, processed and transported in a format making easy quick and accurate decisions. We focus on providing multiple quali~ of service (differentiated services) on a so called tactical internet.	differentiated services;embedded system;internet;sensor	Laurent Enel;Ludovic Martinet	2005	Annales des Télécommunications	10.1007/BF03219956	internet protocol;data flow diagram;quality management;the internet;network architecture;telecommunications;computer science;automatic repeat request;service quality;computer network;data collection	Security	-27.139383404588997	82.23349555341801	19844
75aa0422c57003b9c6bf3dd528a0e6f489e68e97	ip-recovery in the dvb-h link layer for tv on mobile	digital video broadcasting;internet protocol;mobile handsets digital video broadcasting forward error correction iptv;protocols;ip networks digital video broadcasting forward error correction robustness protocols decoding transform coding;mobile device;decoding;transmission error;reed solomon dvb h forward error correction internet protocol link layer mpeg multi protocol encapsulation osi;audiovisual decoding quality dvb h link layer tv on mobile ip recovery internet protocol mobile devices transmission over error prone channels ip datagrams forward error correction fec two bit signaling locator information error probability;osi;transform coding;digital video broadcast;multi protocol encapsulation;forward error correction;mobile communication;reed solomon;mobile handsets;mobile communication ip networks digital video broadcasting forward error correction error statistics;error statistics;robustness;ip networks;error probability;mpeg;link layer;experimental research;audiovisual decoding quality ip recovery dvb h link layer dvb h internet protocol mobile device mobile arena ip datagram error prone channel forward error correction transmission error probability;dvb h;digital video broadcasting tv decoding forward error correction information filtering information filters internet protocols robustness tcpip;iptv	Recently, DVB-H Internet Protocol based TV on Mobile devices made its entrance in the mobile arena. Due to transmission over an error-prone channel, IP datagrams (packet at network layer) may be corrupted. To improve reception robustness, the DVB-H link layer is equipped with Forward Error Correction (FEC), allowing correction of erroneous IP datagrams, using two-bit signaling information. During reception, locator information is derived prior to FEC, indicating the storage position of correctly received IP datagrams. This is essential due to the variable-length sizes of the IP-based data. For the situation that FEC fails to correct all erroneously received data, the locator information enables retrieval of all correctly received IP datagrams and indicates the location of potentially corrected IP datagrams. Using the derived locator information, experimental research has shown that after FEC, a considerable number of correct IP datagrams can still be recovered from an incorrect MPE-FEC frame. This results in up to 50% data recovery for medium-sized datagrams. This successful recovery depends on the received IP datagram length and the transmission error probability and results in an improved audiovisual decoding quality.		Onno Eerenberg;Arie Koppelaar;Armand M. Stuivenwold;Peter H. N. de With	2011	IEEE Transactions on Consumer Electronics	10.1109/TCE.2011.5955165	internet protocol;communications protocol;link layer;real-time computing;transform coding;mobile telephony;telecommunications;computer science;probability of error;mobile device;forward error correction;digital video broadcasting;reed–solomon error correction;osi model;statistics;robustness;computer network	Mobile	-6.059352526781064	103.30633001672332	19848
ff61bebc3aea9ae6c73febfbcc161ecc33205633	the effect of isp traffic shaping on user-perceived performance in broadband shared access networks	quality of experience qoe access internet service provider isp traffic shaping;broadband networks;access;internet service provider isp;user perceived performance;transport protocols;hypermedia;subscriber isp traffic shaping user perceived performances broadband access networks internet service providers ftp http application session level traffic model user perceived performances tbf token bucket filter;internet;transport protocols broadband networks hypermedia internet subscriber loops telecommunication services token networks;subscriber loops;quality of experience qoe;telecommunication services;token networks;user behavior;traffic shaping;streaming media internet power cables broadband communication protocols quality of service contracts	Recent studies on the practice of shaping subscribers’ traffic by Internet service providers (ISPs) give a new insight into the actual performance of broadband access networks at a packet level. Unlike metro and backbone networks, however, access networks directly interface with end-users, so it is important to base the study and design of access networks on the behaviors of and the actual performance perceived by end-users. In this paper we study the effect of ISP traffic shaping using traffic models based on user behaviors and application/session-layer metrics providing quantifiable measures of user-perceived performance for HTTP, FTP, and streaming video traffic. To compare the user-perceived performance of shaped traffic flows with those of unshaped ones in an integrated way, we use a multivariate non-inferiority testing procedure. We first investigate the effect of the token generation rate and the token bucket size of a token bucket filter (TBF) on user-perceived performance at a subscriber level with a single subscriber. Then we investigate their effect at an access level where shaped traffic flows from multiple subscribers interact with one another in a common shared access network. The simulation results show that for a given token generation rate, a larger token bucket — i.e., up to 100 MB and 1 GB for access line rates of 100 Mbit/s and 1 Gbit/s, respectively — provides better user-perceived performance at both subscriber and access levels. It is also shown that the loose burst control resulting from the large token bucket — again up to 100 MB for access line rate of 100 Mbit/s — does not negatively affect user-perceived performance with multiple subscribers even in the presence of non-conformant subscribers; with a much larger token bucket (e.g., size of 10 GB), however, the negative ∗Tel.: +44 (0)1792 602024. Email address: k.s.kim@swansea.ac.uk (Kyeong Soo Kim) Preprint submitted to Computer Networks June 4, 2014 ar X iv :1 30 8. 38 49 v2 [ cs .N I] 3 J un 2 01 4 effect of non-conformant subscribers on the user-perceived performance of conformant subscribers becomes clearly visible because the impact of token bucket size and that of token generation rate are virtually indistinguishable in this case.	access network;data rate units;email;gigabit;hypertext transfer protocol;internet access;internet backbone;megabit;megabyte;metro (design language);network packet;perceived performance;simulation;streaming media;token bucket;traffic shaping	Kyeong Soo Kim	2014	Computer Networks	10.1016/j.comnet.2014.06.001	leaky bucket;traffic policing;the internet;telecommunications;token bucket;computer science;telecommunications service;operating system;generic cell rate algorithm;traffic shaping;computer security;transport layer;computer network;broadband networks	Metrics	-5.339112522638411	97.66031976524138	19881
e94e9011e4f18ffe407697a2e61f540bd55b5b08	revocable abe with bounded ciphertext in cloud computing		Revocable Attribute-Based Encryption (R-ABE) has received much concern recently due to its characteristic of capability on encrypting the Data, according to some attributes, whereas users can decrypt the ciphertexts if they own the credential of those attributes with ability to revoke the expired users. We propose a new practical Revocable Attribute Based Encryption which has a short ciphertext O(1) and private keys O(1) with efficient running time. In this scheme the users can effectively be revoked and added with backward and forward secrecy in the indirect mode, which can controlled by Key Authority Party without reseting the system parameter’s or updating and redistributing the attributes private keys which has expense. Assuming the cloud provider is semi-honest and has been delegated by KA in order to apply dynamic processing on the data and controlling users. This scheme is secured against Chosen Plaintext Adversary (CPA), assuming the (Decision) Bilinear Diffie-Hellman Exponent assumption (n-BDHE) is being held.	adversary (cryptography);attribute-based encryption;bilinear transform;ciphertext;cloud computing;computation;credential;diffie–hellman problem;forward secrecy;plaintext;semiconductor industry;stateless protocol;time complexity	Mohamed Ali Hamza;Jianfei Sun;Xuyun Nie;Zhiquan Qin;Hu Xiong	2017	I. J. Network Security		computer network;ciphertext;cloud computing;semantic security;computer science;distributed computing;bounded function	Security	-41.26963894021901	69.13229238170403	19912
3ddcf372fac5e433157a5576bc0d3966389e3aae	combining trust and risk to reduce the cost of attacks	distributed system;controle acces;gestion informacion;confiance;systeme reparti;psychologie sociale;context information;securite informatique;computer security;confidence;sistema repartido;confianza;seguridad informatica;information management;psicologia social;social psychology;access control;information system;gestion information;systeme information;sistema informacion;trust and reputation	There have been a number of proposals for trust and reputation-based systems. Some have been implemented, some have been analysed only by simulation. In this paper we first present a general architecture for a trust-based system, placing special emphasis on the management of context information. We investigate the effectiveness of our architecture by simulating distributed attacks on a network that uses trust/reputation as a basis for access control decisions.	access control;computation;interaction;intrusion detection system;privacy;simulation;sybil attack;threat (computer);traffic analysis	Daniel Cvrcek;Ken Moody	2005		10.1007/11429760_26	computer science;access control;confidence;information management;operations research;computer security;computational trust;information system	Security	-36.48740870815339	61.22227282521497	19923
19a03a02230e9cd9e3be1f4bf773f47f4fb46c61	building a network-aware and load-balanced structured peer-to-peer system for range query	p2p system;proximity aware network;range query;fault tolerant;fault tolerance network aware peer to peer system load balanced structured peer to peer system range query donuts peer to peer system load balancing proximity aware network;query processing;turning;routing;resource allocation;peer to peer system;upper bound;resource allocation peer to peer computing query processing;buildings peer to peer computing routing delay turning upper bound ip networks information management costs load management;information management;fault tolerance;load balanced structured peer to peer system;load management;load balancing;communication cost;donuts peer to peer system;ip networks;network aware peer to peer system;load balance;peer to peer computing;buildings	We present a structured P2P system called Donuts, which exploits proximity, achieves load balance, and supports range query. The motivation is that range query incurs many overlay contiguous traverses, so making overlay neighbors physically nearby can significantly reduce communication costs. However, building a proximity-aware network may compromise load balance, as efficient load balance requires flexibility of node placement so that a lightly loaded node can leave its position to join beside a heavily loaded node to share its load. To resolve the conflict, we introduce a new concept - grouping. The idea is to cluster physically nearby nodes into several overlay sections to increase the flexibility of proximity join, routing, and load balancing while maintaining key ranges in neighboring nodes adjacent. Moreover, grouping can improve search efficiency by taking advantage of cache. It can also increase fault tolerance, especially to local catastrophes. In the following we introduce Donuts by starting from a simple model and gradually moving into a refined and sophisticated one.	cpu cache;catastrophe theory;fault tolerance;load balancing (computing);peer-to-peer;range query (database);routing;xslt/muenchian grouping	Yuh-Jzer Joung;Yi-Fang Chou	2007	2007 IEEE 23rd International Conference on Data Engineering	10.1109/ICDE.2007.369015	fault tolerance;real-time computing;computer science;load balancing;distributed computing;information management;computer network	DB	-11.408090143578999	73.18250304953172	19937
27d8f7d4977d094221d2a71ab2d8234df8569414	biometric access control for athletic events	smart card;confidence level;information security;access control	The confidence level of citizens, as far as the ability of the organizers to provide security is concerned, is a factor directly impacting their attendance in athletic events. This paper, proposes a system called BioAthletics that implements strong access control, enhancing the safety feeling of event spectators. BioAthletics integrates intelligent biometric access control systems and smart cards for authenticating participants. A pilot version of BioAthletics was deployed and tested in terms of acceptability, information security and performance.	access control;authentication;biometrics;control system;information security;smart card	Christos K. Dimitriadis;Despina Polemi	2006		10.1007/978-0-387-39229-5_3	computer access control;engineering;access control;internet privacy;world wide web;computer security	Security	-49.97052705741854	66.2385372140842	19995
58eace1a2470f3a3d02e4179e9685efb881add32	design of a secure and decentralized location service for agent platforms	location service;agent platform;public key;overlay network;article in monograph or in proceedings	Agent platforms designed for Internet-scale, open networks need scalable and secure location services for agents and services. The location service based on the Fonkey public key distribution infrastructure presented in this paper has been designed and implemented for this purpose. It is scalable in the total number of published identifier–contact address pairs, the number of updates/changes, and the number of agent platforms publishing and requesting contact addresses. This system also supports a signing mechanism to authenticate the publisher of an identifier–contact address pair. Experimental results show that the current implementation based on the Bunshin/Free Pastry overlay network exhibits good scaling behavior.	authentication;identifier;image scaling;key distribution;location-based service;overlay network;public-key cryptography;scalability	Benno J. Overeinder;Michel A. Oey;Reinier J. Timmer;Reinout van Schouwen;Erik Rozendaal;Frances M. T. Brazier	2007		10.1007/978-3-642-11368-0_8	engineering;world wide web;computer security;computer network	Security	-46.9205990326717	71.25360232612111	19998
0790f220e5c5be7eea49ba138284937efa794294	cryptanalysis of a digital signature scheme on id-based key-sharing infrastructures	public key cryptography;discrete logarithm problems;electronic document identification systems;encryption;digital signature schemes;computation theory;cryptanalyse;probabilistic approach;cryptosystem;cryptanalysis;sharing;signature scheme;key pre distribution;particion;cryptage;digital signature;criptografia;enfoque probabilista;cryptography;approche probabiliste;defaillance;non repudiation;discrete logarithm problem;signature numerique;cryptographie;key predistribution;cryptosysteme;id based;failures;partage;digital signature scheme;fallo;key sharing	At ISW’99, Nishioka, Hanaoka and Imai proposed a digital signature scheme on ID-based key-sharing infrastructures. That signature scheme is claimed to be secure if the discrete logarithm problem is hard to solve. Two schemes (the ID-type and the random-type schemes) based on the linear scheme for the Key Predistribution Systems (KPS) and the discrete logarithm problem (DLP) were given. In this paper we show that those two schemes fail to meet the nonrepudiation requirement: with negligible amount of computation, a signature could be forged. For the ID-type signature scheme, any verifier could forge a signature to raise repudiation between that verifier and the signer. The random type signature scheme has the same weakness. Furthermore, for the random-type signature scheme, once a signer issued a signature, anyone (not only the user in the scheme) could forge that signer’s signature for a n arbitrary message.	computation;cryptanalysis;digital light processing;digital signature;discrete logarithm;forge;non-repudiation;type signature	Hongjun Wu;Feng Bao;Robert H. Deng	2001		10.1007/3-540-44586-2_13	ring signature;cryptanalysis;digital signature;merkle signature scheme;eddsa;theory of computation;computer science;cryptography;cryptosystem;mathematics;distributed computing;internet privacy;group signature;blind signature;schnorr signature;elgamal signature scheme;computer security;encryption	Crypto	-42.28270437540837	77.23678487566431	20001
24979d72f3e4d08bbba00dc453e0cfd2d06614e2	survey on the technological aspects of digital rights management	modelizacion;distributed system;controle acces;grain size;multidisciplinaire;reseau pair;systeme reparti;intellectual property;droit auteur;reutilizacion;piratage;securite informatique;copyright;p2p;reuse;piracy;computer security;modelisation;igual a igual p2p;sistema repartido;digital content;grosor grano;seguridad informatica;propiedad intelectual;multidisciplinary;access control;multidisciplinar;peer to peer;pirateria;modeling;propriete intellectuelle;digital right management;reutilisation;derecho autor;grosseur grain	Digitalization of content is both a blessing and a curse. While it allows for efficient transmission and consumption, the ease of copying and sharing digital content has resulted in rampant piracy. Digital Rights Management (DRM) has emerged as a multidisciplinary measure to protect the copyright of content owners and to facilitate the consumption of digital content. In this paper, we survey the technological aspects of DRM. We present a discussion of DRM definitions, aspects, requirements and user issues. We formulate a general DRM model and specify its various DRM component. We then examine the available techniques (such as watermarking and fingerprinting) behind each DRM component. We next look at DRM standardization and known attacks. We also evaluated emerging trends such as the use of P2P in DRM and DRM for personal access control, some noteworthy issues such as content reuse and granularity, as well as citing some future directions such as frequent content key upgrades.	access control;digital recording;digital rights management;fingerprint (computing);peer-to-peer;requirement;watermark (data file)	William Ku;Chi-Hung Chi	2004		10.1007/978-3-540-30144-8_33	systems modeling;telecommunications;computer science;artificial intelligence;access control;operating system;peer-to-peer;reuse;database;multidisciplinary approach;computer security;intellectual property;grain size	Security	-46.97524060117958	68.31667985889148	20014
8070fe1af8a5c2c8e7152c00a64d0940d9536c02	machine-learning approaches for p2p botnet detection using signal-processing techniques	fourier transform;classification;machine learning;entropy;peer to peer;botnet	The distributed and decentralized nature of P2P botnets makes their detection a challenging task. Further, the botmasters continuously try to improve their botnets in order to evade existing detection mechanisms. Thus, although a lot of research has been seen in this field, their detection continues to be an important area of research.  This work proposes a novel approach for the detection of P2P botnets by converting the 'time-domain' network communications of P2P botnets to 'frequency-domain'. We adopt a signal-processing based approach by treating the traffic of each pair of nodes seen in network traffic as a 'signal'. Apart from the regular 'network behavior' based features, we extract features based on Discrete Fourier Transforms and Shannon's Entropy theory to build supervised machine learning models for the detection of P2P botnets. Herein we present encouraging results obtained from the preliminary experiments.	botnet;discrete fourier transform;distributed computing;experiment;machine learning;network traffic control;peer-to-peer;shannon (unit);signal processing;supervised learning	Pratik Narang;Vansh Khurana;Chittaranjan Hota	2014		10.1145/2611286.2611318	fourier transform;entropy;biological classification;computer science;distributed computing;internet privacy;botnet;world wide web;computer security	ML	-61.894546865397515	66.28569129309038	20066
619389d26b65fd8cf61ea87c743d00bfa2262d04	a large engineering network architecture	protocols;network protocol;personal computer;network topology wiring aerospace engineering workstations optical fiber cables file servers power engineering computing microcomputers hardware programming;computer networks;protocols computer networks;network architecture;network protocols large engineering network architecture engineering environment personal computers workstations minicomputers windowing terminals	Providing networking to engineers to& is demunding because of the types of tools that are required to be competitive. As the engineering environment becomes more complicated with large numbers of personal computers, workstations, minicomputers, and w idwing terminals using different network protocols and applications.practica1 network topologies become dtficult to build. This paper discusses an approach that attempts to optimize the network in this type of environment.	communications protocol;minicomputer;network architecture;network topology;personal computer;workstation	Brian Smith;Billy Durham;Bob Hatfield	1992		10.1109/LCN.1992.228110	embedded system;communications protocol;intelligent computer network;network architecture;heterogeneous network;open network architecture;network management station;computer science;operating system;network simulation;distributed computing;service discovery;computer network programming;network access control;computer network operations;host;computer network	HPC	-19.94525533039042	86.20115263518602	20077
462dc4f8ef6bd6a31c3bf5ed1f8103c9c95cfe6b	a novel batch-based lkh tree balanced algorithm for group key management		Logical key hierarchy (LKH) is the most suitable key management scheme for a large dynamic group [1, 2]. Ref. [3] proposed LKH key management scheme, but it did not discuss how to keep tree balanced when membership changes. Ref. [4] proposed LTM (LKH Tree Manager) algorithm, but it has high relocating cost. Ref. [5] proposed a tree balanced algorithm, but had not given out detailed steps. Ref. [6] proposed batch balanced algorithm (BBA), but it causes high cost for reconstructing the tree. In this paper, we propose three merging algorithms and a novel tree balanced algorithm.	algorithm;group key;key management	Jie Xu;Linke Li;Sibian Lu;Huayun Yin	2015	Science China Information Sciences	10.1007/s11432-015-1045-1	distributed computing	DB	-49.033669857291926	78.11545974616536	20079
880c992298fe1d75126a4ec812dd4a78c59c20c1	heuristic algorithms for joint optimization of unicast and anycast traffic in elastic optical network-based large-scale computing systems		In recent years elastic optical networks have been perceived as a prospective choice for future optical networks due to better adjustment and utilization of optical resources than is the case with traditional wavelength division multiplexing networks. In the paper we investigate the elastic architecture as the communication network for distributed data centers. We address the problems of optimization of routing and spectrum assignment for large-scale computing systems based on an elastic optical architecture; particularly, we concentrate on anycast user to data center traffic optimization. We assume that computational resources of data centers are limited. For this offline problems we formulate the integer linear programming model and propose a few heuristics, including a meta-heuristic algorithm based on a tabu search method. We report computational results, presenting the quality of approximate solutions and efficiency of the proposed heuristics, and we also analyze and compare some data center allocation scenarios.		Marcin Markowski	2017	Applied Mathematics and Computer Science	10.1515/amcs-2017-0043	mathematical optimization;guided local search;mathematics;metaheuristic;tabu search;anycast;heuristic;unicast;distributed computing	HPC	-6.376712880854206	83.00964796449858	20085
fa3886c68b39a6462bfe2e619249713f303b82e4	on monitoring and fault management of next generation networks	doctoralthesis	This thesis investigates monitoring and fault management of next generation networks, in particular in environments where the network nodes within an Autonomous System (AS) are centrally controlled and managed. Existing works on network monitoring and fault management are developed in an isolated and extremely complex manner, where the management protocols, such as SNMP, IPFIX and PSAMP, are separately designed and deployed without an overall consideration. To address this issue, we propose a systematic framework for network monitoring and fault management, which takes account of monitoring protocol, traffic matrix composition and derivation, system rebooting, dynamic fault management and related security issues. We propose a new network monitoring framework, which exploits the extensibility of the Internet Protocol (IP), especially for IP Version 6 (IPv6), the fundamental building block for next generation networks. This is implemented by defining a new IPv6 hop-by-hop extension header. Messages with such header would be able to carry metrics related to node and links along the path when they traverse the network. This approach is augmented with a path-based intrinsic monitoring protocol, which can effectively associate SNMP-based MIB information to a network path within the AS domain. To deal with fault management, we propose a novel transient loop avoidance algorithm, which exploits traffic matrix information for updating forwarding tables in an optimal order achieving minimal link overflow. For fault recovery, we present an efficient network rebooting algorithm, which utilizes a priori knowledge of network traffic demand to minimize the rebooting time of all nodes in the entire AS, while ensuring that only a designated portion of traffic volume is affected. The proposed network monitoring, fault management and recovery schemes are evaluated through extensive analysis and experiments. Results show that our monitoring approach only generates less than 5% of the traffic generated by traceroute, at only around 12% of the time taken by traceroute, to retrieve information for a 16-node network; our fault management method can achieve zero transient loop with minimal link overflow; and our fault recovery scheme can significantly reduce rebooting time, which is 86.78% lower than the traditional approach by rebooting network node one by one. These approaches, although not yet implemented in an	algorithm;autonomous system (internet);experiment;extensibility;hop-by-hop transport;mebibyte;network traffic control;next-generation network;simple network management protocol;traverse;traceroute	Lei Shi	2010			fcaps;real-time computing;network management station;engineering;fault management;distributed computing;network management application;computer security	Networks	-13.554545887498287	82.2985401675318	20087
8ce65e8858b17453434622c23c75b91d7610e103	challenging the security of content-based image retrieval systems	security flaws;psnr;content based image retrieval systems;data privacy;filtering mechanism;multimedia content piracy;image retrieval content based retrieval data privacy;robustness;robustness psnr security;content based image retrieval;security;content based retrieval;security flaws content based image retrieval systems filtering mechanism multimedia content piracy;image retrieval	Content-Based Image Retrieval (CBIR) has been recently used as a filtering mechanism against the piracy of multimedia contents. Many publications in the last few years have proposed very robust schemes where pirated contents are detected despite severe modifications. As none of these systems have addressed the piracy problem from a security perspective, it is time to check whether they are secure: Can pirates mount violent attacks against CBIR systems by carefully studying the technology they use? This paper is an initial analysis of the security flaws of the typical technology blocks used in state-of-the-art CBIR systems. It is so far too early to draw any definitive conclusion about their inherent security, but it motivates and encourages further studies on this topic.	content-based image retrieval;experiment;exploit (computer security);robustness (computer science);stepping level	Thanh-Toan Do;Ewa Kijak;Teddy Furon;Laurent Amsaleg	2010	2010 IEEE International Workshop on Multimedia Signal Processing	10.1109/MMSP.2010.5661993	peak signal-to-noise ratio;image retrieval;computer science;internet privacy;world wide web;information retrieval;robustness	Security	-46.58657982708597	67.76250811595354	20132
aaa7c49828fbd6444bc31314d6b55adc12446cf1	role-based profile analysis for scalable and accurate insider-anomaly detection	information security face detection monitoring costs intrusion detection computer crime access control permission information analysis laboratories;role based profile analysis;anomaly detection;telecommunication security monitoring security of data;accurate approach security technology individual based monitoring mechanism scalable anomaly detection role based profile analysis;scalable anomaly detection;intelligence community;security technology;monitoring;telecommunication security;accurate approach;enterprise system;individual based monitoring mechanism;synthetic data;security of data;data security	Sensitive organizations such as the intelligence community (IC) have faced increasing challenges of insider threats because insiders are not always friends, but can be significant threats to the corporate assets. Statistically, it is accepted that the cost of insider threats exceeds that of outsider threats. Many security technologies have been invented to prevent threats from outsiders, but they have limited use in countering insiders' abnormal behaviors. Furthermore, individual-based monitoring mechanisms are not scalable for a large enterprise system. Therefore, in this paper, we introduce a scalable and accurate approach with the role-based profile analysis for countering insider threats, focusing on the relationship between insiders and their systems to detect anomalies. Also, we describe our simulation with synthetic data sets of baseline and threat scenarios	anomaly detection;baseline (configuration management);complexity;enterprise system;experiment;insider threat;interdependence;operating system;scalability;simulation;synthetic data	Joon Sung Park;Joseph Giordano	2006	2006 IEEE International Performance Computing and Communications Conference	10.1109/.2006.1629440	anomaly detection;enterprise system;computer science;data mining;data security;internet privacy;computer security;computer network;synthetic data	SE	-60.539072964404696	63.78218162410694	20147
880f1c1f695b9eb6c68d52ba565be8b394e756e6	a new exponentiation algorithm resistant to combined side channel attack.		Since two different types of side channel attacks based on passive information leakage and active fault injection are independently considered as implementation threats on cryptographic modules, most countermeasures have been separately developed according to each attack type. But then, Amiel et al. proposed a combined side channel attack in which an attacker combines these two methods to recover the secret key in an RSA implementation. In this paper, we show that the BNP (Boscher, Naciri, and Prouff) algorithm for RSA, which is an SPA/FA-resistant exponentiation method, is also vulnerable to the combined attack. In addition, we propose a new exponentiation algorithm resistant to power analysis and fault attack as well as the combined attack. The proposed secure exponentiation algorithm can be employed to strengthen the security of CRT-RSA.	algorithm;attack model;cathode ray tube;correctness (computer science);cryptography;differential fault analysis;exponentiation by squaring;fault injection;information leakage;key (cryptography);overhead (computing);rsa (cryptosystem);side-channel attack;spectral leakage	Hyungdong Kim;YongJe Choi;Dooho Choi;JaeCheol Ha	2013	J. Internet Serv. Inf. Secur.		power analysis;side channel attack;cryptography;information leakage;algorithm;exponentiation;countermeasure;computer science	Security	-41.88844550160754	80.27874000635695	20150
04f5d1c2cc99c3ae88865840e98a95a4e753106b	autonomous decentralized community wireless sensor network system architecture to achieve high-speed connectivity under dynamical situation	sensor systems;management system;wireless sensor networks production systems monitoring sensor systems wireless communication communications technology food technology production facilities network topology collaboration;food technology;collaboration;food manufacturing;production lines;product line;autonomous community collaboration technology;satisfiability;wireless sensor network;network topology;wireless communication;autonomous initialization technology autonomous decentralized community wireless sensor network system production plant monitoring systems food factory monitoring systems production lines autonomous community collaboration technology;monitoring system;autonomous decentralized community wireless sensor network system;monitoring;wireless sensor networks food manufacturing;food factory monitoring systems;production facilities;production plant monitoring systems;production systems;communications technology;autonomous initialization technology;system architecture;high speed;wireless sensor networks	In recent years, with development in wireless communication technologies and sensor devices, wireless sensor networks have gained worldwide attention. In production plant monitoring systems, especially food factory monitoring systems, it is needed to relocate sensors in accordance with reorganization of production lines. A conventional centralized management systems isn't able to cope with huge number of sensors and rapidly changing topology. Autonomous Decentralized Community Wireless Sensor Network System (ADCWSN) is presented to solve these problems. In ADCWSN, all nodes are autonomous, and each node copes with problems by mutual corporation according to the situation. (This set of nodes which mutual corporate forms community.) In this paper, Autonomous Initialization Technology and Autonomous Community Collaboration Technology are proposed to satisfy expandability and the effectiveness of proposed technologies is shown through simulation.	autonomous robot;centralized computing;sensor;simulation	Satoshi Niki;Shoichi Murakami;Khalid Mahmood;X J David Lu;Kinji Mori	2009	2009 International Symposium on Autonomous Decentralized Systems	10.1109/ISADS.2009.5207372	embedded system;simulation;wireless sensor network;computer science;food technology;key distribution in wireless sensor networks;management	Embedded	-24.62386090659646	80.6063542229374	20154
aa910851a2977d27b6ba70cae94327b2a79a7627	simt - a privacy preserving web metrics tool	legislation;customer relationship management;privacy preservation;web service;multichannel retailer simt web metrics tool consumer metrics customer relationship management crm software packages internet privacy restrictions consumer analysis privacy legislation privacy specifications web sites data re identification problems p3p policy declarative specification privacy constraints inference problems legal restrictions;internet;customer relationship management internet data privacy;data privacy;software package;web services data privacy customer relationship management software packages web and internet services legislation prototypes law legal factors system testing;web metrics	Consumer metrics for analyzing the success of customer relationship management (CRM) are gaining increasing importance. CRM software packages have become commonplace. However, two major shortcomings exist. First, most software solutions are not offered as a Web service on the Internet. Second, privacy restrictions need to be integrated into an overall framework of success indicators for consumer analysis. Whereas the first aspect can be addressed with standardized developer software for Web services, the second must consider privacy legislation, privacy specifications on Web sites (P3P), and data re-identification problems. To address these problems, we have developed a web service - called SIMT - that automatically adapts CRM indicators to an online retailer's P3P policy. It is based on a declarative specification of privacy constraints, and syntactically extends P3P. This paper presents the prototype and describes how inference problems and legal restrictions have been addressed. The system has been tested on data from a large multi-channel retailer.	customer relationship management;internet;omnichannel;online shopping;p3p;privacy;prototype;single instruction, multiple threads;web service	Maximilian Teltzrow;Sören Preibusch;Bettina Berendt	2004	Proceedings. IEEE International Conference on e-Commerce Technology, 2004. CEC 2004.	10.1109/ICECT.2004.1319742	web service;privacy software;customer relationship management;privacy policy;the internet;information privacy;privacy by design;computer science;database;internet privacy;world wide web	DB	-43.06786070625775	60.67002734673911	20158
095f9e02eb366bcfdd25ad67009fda8b2a40450d	a toolkit for modeling and simulation of real-time virtual machine allocation in a cloud data center	data models servers computational modeling scheduling algorithms cloud computing resource management;resource management;lightweight simulation system cloud computing data centers dynamic and real time resource scheduling;servers;computational modeling;scheduling algorithms;lightweight simulation system;scheduling objective realtime virtual machine allocation cloud data center resource scheduling infrastructure as a service iaas large scale cloud application workload model cloud provisioning algorithm cloudsched virtual machines cloud computing;virtual machines cloud computing computer centres resource allocation scheduling;dynamic resource scheduling;cloud computing;data models;data centers	Resource scheduling in infrastructure as a service (IaaS) is one of the keys for large-scale Cloud applications. Extensive research on all issues in real environment is extremely difficult because it requires developers to consider network infrastructure and the environment, which may be beyond the control. In addition, the network conditions cannot be predicted or controlled. Therefore, performance evaluation of workload models and Cloud provisioning algorithms in a repeatable manner under different configurations and requirements is difficult. There is still lack of tools that enable developers to compare different resource scheduling algorithms in IaaS regarding both computing servers and user workloads. To fill this gap in tools for evaluation and modeling of Cloud environments and applications, we propose CloudSched. CloudSched can help developers identify and explore appropriate solutions considering different resource scheduling algorithms. Unlike traditional scheduling algorithms considering only one factor such as CPU, which can cause hotspots or bottlenecks in many cases, CloudSched treats multidimensional resource such as CPU, memory and network bandwidth integrated for both physical machines and virtual machines (VMs) for different scheduling objectives (algorithms). In this paper, two existing simulation systems at application level for Cloud computing are studied, a novel lightweight simulation system is proposed for real-time VM scheduling in Cloud data centers, and results by applying the proposed simulation system are analyzed and discussed.	algorithm;central processing unit;cloud computing;data center;performance evaluation;provisioning;real-time clock;real-time transcription;requirement;scheduling (computing);simulation;virtual machine	Wenhong Tian;Yong Zhao;Minxian Xu;Yuanliang Zhong;Xiashuang Sun	2015	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2013.2266338	fair-share scheduling;data modeling;data center;real-time computing;cloud computing;dynamic priority scheduling;computer science;resource management;operating system;two-level scheduling;distributed computing;round-robin scheduling;computational model;scheduling;server	HPC	-22.666034153696902	61.78995115303233	20160
1adb990681b20a9304e643a3c79222c96be5017f	evaluating next-cell predictors with extensive wi-fi mobility data	phase measurement;mobility management mobile radio;compression based predictors;mobile radiocommunication;telecommunication sans fil;implementation;localization;wireless network;wlan;telecommunication network;next cell predictors;client server systems;localizacion;domain independent predictors;wireless lan client server systems computer network management markov processes mobile computing mobility management mobile radio;radiocommunication service mobile;wi fi mobility prediction location prediction mobility management location aware applications wireless network cellular network wlan;medida fase;predictor;mobility prediction;empirical evidence;predicteur;accuracy;low order markov predictors next cell predictors extensive wi fi mobility data client mobility wi fi wireless network domain independent predictors compression based predictors markov based predictors ppm predictors spm predictors;client mobility;spm predictors;precision;localisation;mesure phase;red celular;red telecomunicacion;telecomunicacion sin hilo;cell network;reseau cellulaire;computer network management;wi fi wireless network;mobility management;prediction accuracy;reseau telecommunication;cellular network;gestion de movilidad;mobility pattern;low order markov predictors;location awareness;wireless lan;location prediction;markov processes;ppm predictors;gestion mobilite;wireless networks wireless lan mobile radio mobility management land mobile radio cellular systems mobile computing pervasive computing printing computer society application software;implementacion;radiocomunicacion servicio movil;mobile computing;location aware applications;wi fi;empirical evaluation;reseau local sans fil;markov based predictors;extensive wi fi mobility data;wireless telecommunication	Location is an important feature for many applications, and wireless networks may serve their clients better by anticipating client mobility. As a result, many location predictors have been proposed in the literature, though few have been evaluated with empirical evidence. This paper reports on the results of the first extensive empirical evaluation of location predictors using a two-year trace of the mobility patterns of more than 6,000 users on Dartmouth's campus-wide Wi-Fi wireless network. The surprising results provide critical evidence for anyone designing or using mobility predictors. We implemented and compared the prediction accuracy of several location predictors drawn from four major families of domain-independent predictors, namely, Markov-based, compression-based, PPM, and SPM predictors. We found that low-order Markov predictors performed as well or better than the more complex and more space-consuming compression-based predictors	location-based service;markov chain;markov model;super paper mario	Libo Song;David Kotz;Ravi Jain;Xiaoning He	2004	IEEE Transactions on Mobile Computing	10.1109/TMC.2006.185	telecommunications;computer science;operating system;accuracy and precision;mobile computing;computer security;computer network	Mobile	-13.986744841535906	98.2833979435644	20215
833ee91da12611499e8282df32ed5f3ae564652d	blowtorch: a framework for firewall test automation	automated testing;tool support;test automation;network security;capture replay;process control;test generation;covering array;production grammar;network firewall	Firewalls play a crucial role in network security. Experience has shown that the development of firewall rule sets is complex and error prone. Rule set errors can be costly, by allowing damaging traffic in or by blocking legitimate traffic and causing essential applications to fail. Consequently, firewall testing is extremely important. Unfortunately, it is also hard and there is little tool support available.Blowtorch is a C++ framework for firewall test generation. The central construct is the packet iterator: an event-driven generator of timestamped packet streams. Blowtorch supports the development of packet iterators with a library for packet header creation and parsing, a transmit scheduler for multiplexing of multiple packet streams, and a receive monitor for demultiplexing of arriving packet streams. The framework provides iterators which generate packet streams using covering arrays, production grammars, and replay of captured TCP traffic. Blowtorch has been used to develop tests for industrial firewalls that are placed between an IT network and a process control network.	algorithm;blocking (computing);c++;cognitive dimensions of notations;event-driven programming;expect;firewall (computing);handshaking;iterator;multiplexing;network packet;network security;parsing;scheduling (computing);test automation	Daniel Hoffman;Kevin Yoo	2005		10.1145/1101908.1101925	application firewall;real-time computing;packet analyzer;computer science;processing delay;network security;process control;distributed computing;stateful firewall;computer security;context-based access control	Networks	-18.180287434308102	83.6798330634974	20228
fb951c47cd9c137e5068583e7d72253678b1edd9	an open-system 4g/b3g network architecture	mobility management mobile radio;distributed networks;resource manager;multicast protocol fourth generation networks beyond third generation networks heterogeneous networks open system message interfaces cross layer coordination dynamic network conditions mobility resource management schemes reconfigurable multiantenna end terminal;3g mobile communication 4g mobile communication telecommunication services mobility management mobile radio multicast protocols;resource management multicast protocols ip networks australia quality of service control systems communication system signaling mobile radio mobility management wireless lan transport protocols;3g mobile communication;multicast protocols;mobility management;open system;telecommunication services;bandwidth broker;4g mobile communication;network architecture;cross layer;quality of service;wireless systems;dynamic networks;heterogeneous network	The development of fourth generation or beyond third generation (4G/B3G) networks is driven by the need to offer the subscribers with the convenience of using the same end terminal to obtain seamless services across heterogeneous networks. In this paper, we propose a consolidated 4G/B3G architecture that is open, hierarchical, layered and modular with cross-layer coordination and distributed network functionalities. Well-defined message interfaces enable the layers/levels within the architecture to support the cross-layer coordination under dynamic network conditions. Novel augmentations in mobility and resource management schemes are proposed that result in consolidating the corresponding salient areas of 4G/B3G architectures discussed in the literature. Seamless services in the network can be accessed through our reconfigurable multi-antenna end terminal. A common mechanism for control/signaling across heterogeneous networks is adopted to facilitate wireless system discovery and paging. A multicast protocol is proposed to ensure the reliable transfer of control/signaling messages over this incorporated signaling system.	access network;anytime algorithm;end-to-end principle;mobile phone;multicast;network architecture;next-generation network;paging;real-time transcription;reconfigurable computing;seamless3d;signaling protocol;signalling system no. 7	Vinod Mirchandani;M. Rubaiyat Kibria;Abbas Jamalipour	2005	IEEE International Conference on Communications, 2005. ICC 2005. 2005	10.1109/ICC.2005.1494567	network architecture;heterogeneous network;quality of service;telecommunications;computer science;telecommunications service;resource management;distributed computing;open system;computer network	Robotics	-14.534773516475578	90.90504368658763	20238
1eca209f373ed3f45456e85cab207197d5ed94ab	formulation of a heuristic rule for misuse and anomaly detection for u2r attacks in solaris operating system environment	misuse;anamoly;: intrusion detection;rule-based system;heuristic;user-to-root attack;rule based system;operating system;anomaly detection;intrusion detection;buffer overflow	This paper proposes a heuristic rule for detection of user-to-root (U2R) attacks against Solaris TM operating system. Relevant features for developing heuristic rules were manually mined using Solaris TM Basic Security Module audit data. The proposed rule was tested on both DARPA 1998 and 1999 intrusion detection datasets. Results show that all user-to-root attacks exploiting the suid program were detected with 100% probability and with zero false alarms. The rule can detect both successful and unsuccessful U2R attempts against the Solaris TM operating system. The proposed rule is general enough to detect any U2R attack that leverages the buffer overflow technique. Empirical results indicate that the rule also detected novel user-to-root attacks in DARPA 1998 intrusion detection dataset. Hence the rule has the potential and can be used for anomaly detection.	anomaly detection;buffer overflow;heuristic;intrusion detection system;mined;openbsm;operating system;setuid	Maheshkumar Sabhnani;Gürsel Serpen	2003			computer security;host-based intrusion detection system;anomaly detection;computer science;rule-based system;operating system;real-time computing;intrusion detection system;buffer overflow;heuristic;anomaly-based intrusion detection system	Security	-62.21812589248017	63.251881269859346	20242
5098f087ef96745aafa7e0c54616c977224bfeb9	socialdtn: a dtn implementation for digital and social inclusion	social proximity;digital social inclusion;amazon riverside communities;delay disruption tolerant networking	Despite of the importance of access to computers and to the Internet for the development of people and their inclusion in society, there are people that still suffer with digital divide and social exclusion. Delay/Disruption-Tolerant Networking (DTN) can provide the technical support for the digital/social inclusion of these people as it allows opportunistic and asynchronous communication, which does not depend upon networking infrastructure. We introduce SocialDTN, an implementation of the DTN architecture for Android devices that operates over Bluetooth and aims to take advantages of users' social daily routines to improve data forwarding. As we want to exploit the social proximity and interactions existing among users, SocialDTN considers a social-aware opportunistic routing proposal,dLife, instead of the well-known (but social-oblivious) PROPHET. Some preliminary field experimentations are explained based on the direct delivery of content.	android;bluetooth;computer;delay-tolerant networking;interaction;operand forwarding;routing;technical support;whole earth 'lectronic link	Waldir Moreira;Ronedo Ferreira;Douglas Cirqueira;Paulo Mendes;Eduardo Cerqueira	2013		10.1145/2502880.2502892	telecommunications;internet privacy;computer security;computer network	HCI	-27.810781536290314	77.98500554551742	20247
48ef4f44d5098ef1d67bdcca2004987b4f10351e	attribute-based keyword search with proxy re-encryption in the cloud			encryption;proxy re-encryption	Yan Li Chen;Yuanyuan Hu;Minhui Zhu;Geng Yang	2018	IEICE Transactions		mathematics;theoretical computer science;cloud computing;proxy re-encryption	DB	-41.14725760550765	68.66900385572858	20249
cb5d41409996f2fbbafdb71c07a43fd90f13912b	profit-aware scheduling in task-level for datacenter networks		Applications perform massive and diverse tasks in data centers. Tasks completion condition seriously affects application performance. However, most existing flow-level or task-level scheduling methods treat flows in isolation, meanwhile, few works discuss the efficiency of task-level scheduling from the perspective of the task profit.#R##N##R##N#In this paper, we introduce a profit-aware task-level scheduling scheme named PAT, whose target is to maximize the profit of completing tasks within their reasonable time. To this end, a maximizing profit optimization model is proposed on task-level, and an efficient approximate scheduling algorithm is presented. Furthermore, a situation of absent deadline information is discussed and an ePAT method is presented to solve this situation. Based on the proposed algorithm, we design and implement PAT and ePAT. Some comprehensive experiments are conducted to evaluate the performance of our methods. The experimental results show that our methods bring higher profit than other scheduling methods.	data center;scheduling (computing)	Xiaoyi Tao;Heng Qi;Wenxin Li;Keqiu Li;Yang Liu	2017	Computers & Electrical Engineering	10.1016/j.compeleceng.2016.07.013	lottery scheduling;real-time computing;dynamic priority scheduling;computer science;genetic algorithm scheduling;deadline-monotonic scheduling;fair-share scheduling;two-level scheduling;rate-monotonic scheduling;distributed computing;fixed-priority pre-emptive scheduling	OS	-18.44941092919946	62.56303702939209	20293
5ba7e4eda1c37452b9fd992ab4a7b9e95762a06d	a data grid security system based on shared context	distributed data;distributed system;systeme reparti;single sign on;authentication;securite informatique;serveur informatique;cache memory;securite donnee;system security;data grid system;authentification;antememoria;computer security;antememoire;sistema repartido;autenticacion;seguridad informatica;secure system;servidor informatico;securite donnee basee contexte;security policy;ressource donnee repartie;security of data;data grid;computer server	Data grid system supports uniform and secure access of heterogeneous distributed data resources across a range of administrative domains, each with its own local security policy. The security challenge has been a focus in a data grid environment. This paper mainly presents GridDaEn's security mechanisms. In addition to the basic authentication and authorization functionality, it provides an integrated security strategy featured by shared context-based secure channel building to leverage security processing efficiency so as to improve interaction performance occurring among multiple domains in GridDaEn. Meanwhile, by means of proxy credential single-sign-on across multiple domains can be achieved. Experiments show that this approach can guarantee system security and reliability with great performance enhancement.	authorization;basic access authentication;computer security;credential;experiment;proxy server;requirement;secure channel	Nong Xiao;Xiaonian Wu;Wei Fu;Xiangli Qu	2004		10.1007/978-3-540-30141-7_8	computer security model;cloud computing security;security convergence;computer science;operating system;data grid;authentication;database;security service;world wide web;computer security	Security	-35.64508711673202	61.40966478727428	20319
cb0965b206970e0b0df742cba4e8071d0cdc8de8	a new private data aggregation scheme for wireless sensor networks	data transmission;private data aggregation scheme;performance evaluation;wireless sensor networks intelligent sensors servers data privacy cryptography;data security wireless sensor network data aggregation complex number data privacy;data collection;wireless sensor networks security of data;wireless sensor network;servers;data privacy;cryptography;data aggregation;data security private data aggregation scheme wireless sensor networks query server data privacy;sensor nodes;communication cost;complex number;query server;security of data;wireless sensor networks;intelligent sensors;data security	Many wireless sensor network (WSN) applications require privacy of the sampled data during transmission from the source nodes to a data collecting device, say a query server. Providing an efficient data aggregation scheme with preserving data privacy is a challenging problem in WSNs. Although the secure data aggregation in WSNs has been well studied in the recent years, there exists a little work, for instance PDA (Privacy-preserving Data Aggregation), which focuses on protecting sensor data not only from adversaries but also from the participating trusted sensor nodes. However, PDA suffers from two problems. The first one is high communication cost due to unnecessary traffics in the network during data transmissions. The second one is high computation cost due to the use of expensive technique to customize sensor data. To resolve the problems, we, in this paper, propose a new private data aggregation scheme for WSNs. The proposed scheme applies the additive property of complex numbers in order to combine sensor data and preserve data privacy during transmissions to the query server. We show from our analytical performance evaluations that our scheme is more efficient than the PDA scheme in terms of both communication and computation costs.	access control;adversary (cryptography);computation;confidentiality;data aggregation;information privacy;information sensitivity;key management;personal digital assistant;regular expression;sensor;sensor node;server (computing);simulation;tinyos;transmitter;utility functions on indivisible goods	Rabindra Bista;Hee-Dae Kim;Jae-Woo Chang	2010	2010 10th IEEE International Conference on Computer and Information Technology	10.1109/CIT.2010.79	wireless sensor network;information privacy;computer science;key distribution in wireless sensor networks;internet privacy;computer security;statistics;computer network	Mobile	-50.58188961571068	76.18438580032802	20339
356d411aa32084d26d18d93ecce4f8f26b70d5de	an analysis framework for information loss and privacy leakage on android applications	androids;testing;humanoid robots;data privacy;security;privacy;credit cards	Managing privacy leakage is of great importance in the Android platform. The variety of new user-privacy fraud reveals a new challenge in predicting potential privacy disclosure threats and protecting the privacy inside our pocket. In this paper, we present an analysis framework, called AppLeak, for information loss evaluation, privacy leakage detection, and privacy risk assessment on Android applications. With newly formalized privacy measures, AppLeak can effectively and efficiently support mobile user in identifying privacy risks of specific mobile applications.	android;internet privacy;mobile app;risk assessment;spectral leakage	Kuo-Hui Yeh;Nai-Wei Lo;Chuan-Yen Fan	2014	2014 IEEE 3rd Global Conference on Consumer Electronics (GCCE)	10.1109/GCCE.2014.7031192	privacy software;information privacy;privacy by design;engineering;internet privacy;world wide web;computer security	Security	-45.63327967824783	61.593866954889535	20340
3194efa10a8c80e6b129291e4db24df457fb60e4	understanding network saturation behavior on large-scale blue gene/p systems	blue gene p;topology;global communication;telecommunication congestion control;fat tree;network topology;large scale;petascale;torus;three dimensional displays;telecommunication network topology computer network management cray computers large scale systems parallel machines telecommunication congestion control;p system;computer network management;similar topology network saturation behavior large scale blue gene p systems massive scale systems ibm blue gene cray xt fat tree switched topologies network sharing network congestion 3d torus;bandwidth;parallel machines;large scale systems network topology hardware costs fabrics bandwidth kernel monitoring counting circuits communication switching;telecommunication network topology;switches;magnetic cores;saturation;network congestion;cray computers;large scale systems;fat tree petascale saturation blue gene p torus	As researchers continue to architect massive-scale systems, it is becoming clear that these systems will utilize a significant amount of shared hardware between processing units. Systems such as the IBM Blue Gene (BG) and Cray XT have started utilizing flat (i.e., scalable) networks, which differ from switched fabrics in that they use a 3D torus or similar topology. This allows the network to grow only linearly with system scale, instead of the super linear growth needed for full fat-tree switched topologies, but at the cost of increased network sharing between processing nodes. While in many cases a full fat-tree is an over estimate of the needed bisectional bandwidth, it is not clear whether the other extreme of a flat topology is sufficient to move data around the network efficiently. In this paper, we study the network behavior of the IBM BG/P using several application communication kernels, and we monitor network congestion behavior based on detailed hardware counters. Our studies scale from small systems to 8 racks (32,768 cores) of BG/P and provide insights into the network communication characteristics of the system. As researchers continue to architect massive scale systems, it is becoming clear that these systems will utilize a significant amount of shared hardware between processing units. Systems such as the IBM Blue Gene (BG) and Cray XT have started utilizing flat (i.e., scalable) networks, which differ from switched fabrics in that they use a 3D torus or similar topology. This allows the network to grow only linearly with system scale, instead of the super linear growth needed for full fat-tree switched topologies, but at the cost of increased network sharing between processing nodes. While in many cases a full fat-tree is an over estimate of the needed bisectional bandwidth, it is not clear whether the other extreme of a flat topology is sufficient to move data around the network efficiently. In this paper, we study the network behavior of the IBM BG/P using several application communication kernels, and we monitor network congestion behavior based on detailed hardware counters. Our studies scale from small systems to 8 racks (32,768 cores) of BG/P and provide insights into the network communication characteristics of the system.	blue gene;cartesian closed category;experiment;fat tree;file allocation table;ibm personal computer xt;job control (unix);linear function;network congestion;p system;scalability;time formatting and storage bugs;vii	Pavan Balaji;Harish Gapanati Naik;Narayan Desai	2009	2009 15th International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2009.117	parallel computing;petascale computing;real-time computing;fat tree;network switch;computer science;torus;operating system;database;distributed computing;network congestion;network topology;bandwidth;saturation;computer network;p system	HPC	-12.91143241165932	80.55383434048053	20356
cbcb98a62e2fbd5e04d01c1e3c78172942cfe540	on a serverless networked virtual ball game for multi-player	peer to peer computing protocols avatars delay network servers throughput virtual environment computer architecture internet educational institutions;protocols;virtual ball game;real time;peer to peer architecture;virtual reality;p2p;allocated topographical zone;serverless network;games;multiplayer game;distributed virtual environment;network architecture;peer to peer computing;computer games;protocols serverless network virtual ball game distributed virtual environment peer to peer architecture allocated topographical zone network latency multiplayer game;peer to peer;network latency;virtual reality computer games peer to peer computing protocols	This paper studies the way to improve consistency of states in a ball-game typed distributed virtual environment (DVE) with lag, in peer-to-peer (P2P) architecture. That is, we are studying how to reduce in real-time the difference of states between the participating terminals in a virtual ball game caused by transmission lag or update interval. We are also studying how to control shared objects in real-time in a server-less network architecture. Specifically, a priority field called Allocated Topographical Zone (AtoZ) is used in P2P for DVE. In a critical case, defined as inconsistent phenomena between the peers, caused by the network latency, a stricter ownership determination algorithm, called dead zone is introduced. Concession parameter is used to reduce the possibility of such a case. By using these protocols in combination, a robust and effective scheme is achieved for a virtual ball game and these protocols ware extended for multi-player game. As an example of the application, a realtime networked doubles air-hockey is implemented for evaluation of the influence of these protocols on interactivity and on consistency	dead reckoning;digital video effect;distributed algorithm;experiment;interactivity;multi-user;network architecture;object type (object-oriented programming);peer-to-peer;prototype;real-time clock;real-time locating system;real-time transcription;server (computing);software prototyping;topography;virtual reality;warez	Yoshihiro Kawano;Tatsuhiro Yonekura	2005	2005 International Conference on Cyberworlds (CW'05)	10.1109/CW.2005.68	games;communications protocol;latency;simulation;network architecture;computer science;operating system;peer-to-peer;distributed computing;virtual reality;multimedia	Embedded	-10.730658414423264	103.41804664939048	20362
8cc5ef1fc1b0a3526f01904974b1686e0e41d3fc	pseudo trust: zero-knowledge based authentication in anonymous peer-to-peer protocols	p2p system;analytical models;protocols;one way hash function;zero knowledge proof;centralized trusted party;information security;man in middle attack resistance;authentication;cryptographic protocols;knowledge management;trust management;p2p;trust model;trace driven simulations;man in middle attack resistance pseudo trust zero knowledge based authentication anonymous peer to peer protocols p2p systems one way hash function identity based trust management schemes trace driven simulations centralized trusted party cryptography processing overheads;virtual prototyping;anonymous peer to peer protocols;telecommunication security;performance analysis;identity management systems;scalability;message authentication;peer to peer computing;zero knowledge;peer to peer;telecommunication security cryptographic protocols message authentication peer to peer computing;trace driven simulation;cryptography processing overheads;authentication peer to peer computing protocols knowledge management identity management systems performance analysis information security analytical models virtual prototyping scalability;p2p systems;pseudo trust;identity based trust management schemes;zero knowledge based authentication	Most of the current trust models in peer-to-peer (P2P) systems are identity based, which means that in order for one peer to trust another, it needs to know the other peer's identity. Hence, there exists an inherent tradeoff between trust and anonymity. To the best of our knowledge, there is currently no P2P protocol that provides complete mutual anonymity as well as authentication and trust management. We propose a zero-knowledge authentication scheme called pseudo trust (PT), where each peer, instead of using its real identity, generates an unforgeable and verifiable pseudonym using a one-way hash function. A novel authentication scheme based on zero-knowledge proof is designed so peers can be authenticated without leaking any sensitive information. With the help of PT, most existing identity-based trust management schemes become applicable in mutual anonymous P2P systems. We analyze the levels of security and anonymity in PT, and evaluate its performance using trace-driven simulations and a prototype implementation. The strengths of pseudo trust include the lack of need for a centralized trusted party or CA, high scalability and security, low traffic and cryptography processing overheads, and man-in-middle attack resistance. We aim for the pseudo trust design to be included in the P2P trust and anonymity context.	authentication;authentication protocol;centralized computing;computational complexity theory;cryptographic hash function;cryptography;experiment;formal verification;information sensitivity;one-way function;peer-to-peer;prototype;scalability;simulation;software deployment;trust management (information system);trusted third party;zero-knowledge proof	Li Lu;Jinsong Han;Lei Hu;Jinpeng Huai;Yunhao Liu;Lionel M. Ni	2007	2007 IEEE International Parallel and Distributed Processing Symposium	10.1109/IPDPS.2007.370284	trust anchor;computer science;information security;internet privacy;world wide web;computer security;computational trust;zero-knowledge proof;computer network	Security	-43.00927392051336	74.61897022929672	20376
3655ba1618562f8fd69b75bcce581de94750584e	a secure framework for user privacy in heterogeneous location networks	sensibilidad contexto;distributed system;systeme reparti;context aware;confidencialidad;informatique mobile;location based service;protocole transmission;securite;information source;source information;localization;multiplicite;cryptographic protocol;localizacion;confidentiality;service utilisateur;vida privada;confidentialite;protocolo transmision;sistema repartido;localisation;private life;criptografia;cryptography;safety;multiplicidad;cryptographie;vie privee;servicio usuario;sensibilite contexte;user service;mobile computing;seguridad;multiplicity;fuente informacion;transmission protocol	A heterogeneous location network is one that derives location information from multiple sources and provides various location based services to users irrespective of the device used. User privacy is an important issue that needs to be addressed for the growth of heterogeneous location networks. We propose a secure framework for assuring user privacy in heterogeneous location networks. We also present lightweight cryptographic protocols along with an analysis of the computation requirements and security capabilities of the proposed framework.	computation;cryptographic protocol;cryptography;location-based service;privacy;privacy policy;profiling (computer programming);requirement;xml	Harikrishna Vasanta;Yiu Shing Terry Tin;Colin Boyd;Mark Looi;Juan Manuel González Nieto	2004		10.1007/978-3-540-30178-3_25	confidentiality;telecommunications;computer science;cryptography;operating system;cryptographic protocol;multiplicity;mobile computing;world wide web;computer security	Security	-46.10253226939591	78.70873107098069	20400
0fe9c5ceaf1971c5c8ae88f500d6701af9b47eb7	synchronization model for multimedia communication and presentation in distributed systems	distributed system;resource utilization;time dependent media;time dependent;multimedia presentations;clocks;distributed processing;multimedia systems;multimedia computing;synchronisation;network servers;feedback;synchronization multimedia communication distributed systems time dependent media media streams petri nets multimedia presentations;streaming media;synchronization;multimedia data;multimedia communication;multimedia databases;multimedia computing multimedia communication synchronisation petri nets distributed processing;media streaming;multimedia communication multimedia systems streaming media synchronization multimedia databases feedback network servers clocks jitter computer science;computer science;petri nets;jitter;multimedia presentation;distributed systems;petri net;media streams	The integration of time dependent media in applications requires the synchronization of media streams. The problem of synchronization is more important if we consider multimedia data presented in the distributed systems. The specification of synchronization is supported by the synchronization editor, the creation and the transport of synchronization objects are managed by the synchronization coordinator, and the execution of multimedia presentations is performed by the synchronizer. We use a Petri nets model for the specification of synchronization, andpropose a method using by the Normalized Relative Time Stamps (NRTS) to synchronize multimedia objects. We also use two policies, aggressive and conservative, for execution of synchronization presentations. We believe that a best synchronization scheme must be adaptive to various applications, i.e., the performance of synchronization among various media streams is dependent on the applications. On the view of resources utilization, we try to propose a scheme that can tune the accuracy of detecting the asynchrony. Thus, we can get the balance on the tradeofS between the performance of presentation and utilization of resources.	asynchronous i/o;distributed computing;petri net;sensor;synchronization (computer science);synchronization model;synchronizer (algorithm)	Lung-Hsiung Wang;Jan-Min Chen	1996		10.1109/ICPADS.1996.517553	clock synchronization;synchronization;real-time computing;telecommunications;computer science;distributed computing;multimedia;data synchronization;file synchronization;synchronization;petri net	DB	-22.2635134052218	70.67837698976656	20419
e47aa17d5be28d5165278ed87f1449886eb79357	location privacy for a quality of access to mobile internet monitoring system	antennas encryption mobile communication privacy computational modeling libraries;decryption location privacy mobile internet monitoring system adkintun mobile smart phones homomorphic encryption;telecommunication security authorisation cryptography data privacy internet mobile radio smart phones	In order to measure the quality of access to mobile Internet, NIC Chile Research Labs developed Adkintun Mobile, a passive monitor installed in volunteer users smart-phones [2]. Periodically, the client application records data related to network state, which is sent to the collector server. Researchers of the laboratory have access to such stored data. Since from connexion to antennas location can be deduced, location data of individuals is exposed to researchers, which is a concern for location privacy. We propose a model where researchers can access, query and compute aggregations on stored data, learning nothing more about users location than the result of the aggregation. Our model uses homomorphic encryption to preserve location privacy. Location data is sent encrypted from mobile devices to the server. The server can homomorphically evaluate predefined functions such as counting the number of users in a given location (Fig. 1).Query and result decryption are performed from a separate layer, which protects the secret key from being used for direct decryption of the records.	client (computing);homomorphic encryption;key (cryptography);mobile device;network interface controller;privacy;server (computing);smartphone	Giselle Font;Javier Bustos-Jiménez;Sebastian Blasco;Alejandro Hevia	2014	2014 IEEE Conference on Communications and Network Security	10.1109/CNS.2014.6997533	mobile broadband;privacy software;mobile search;mobile web;imt advanced;computer science;internet privacy;mobile station;mobile computing;mobile communications over ip;computer security;computer network	Security	-45.30829185457493	64.84456798632935	20426
511eefd6d3ad7e6c29b85d503c96b53e556d19f9	reduce to the max: a simple approach for massive-scale privacy-preserving collaborative network measurements (short paper)	secret sharing;network monitoring;distributed computing;privacy preservation;collaborative networks;traffic monitoring;secure multiparty computation;homomorphic encryption	  Privacy-preserving techniques for distributed computation have been proposed recently as a promising framework in collaborative  inter-domain network monitoring. Several different approaches exist to solve such class of problems, e.g., Homomorphic Encryption  (HE) and Secure Multiparty Computation (SMC) based on Shamir’s Secret Sharing algorithm (SSS). Such techniques are complete  from a computation-theoretic perspective: given a set of private inputs, it is possible to perform arbitrary computation tasks  without revealing any of the intermediate results. In this paper we advocate the use of “elementary” (as opposite to “complete“)  Secure Multiparty Computation (E-SMC) procedures for traffic monitoring. E-SMC supports only simple computations with private input and public output, i.e., they can not handle secret input nor secret (intermediate) output. The proposed simplification brings a dramatic reduction  in complexity and enables massive-scale implementation with acceptable delay and overhead. Notwithstanding their simplicity,  we claim that a simple additive E-SMC scheme is sufficient to perform many computation tasks of practical relevance to collaborative  network monitoring, such as anonymous publishing and set operations.    		Fabio Ricciato;Martin Burkhart	2011		10.1007/978-3-642-20305-3_9	homomorphic encryption;computer science;distributed computing;secure multi-party computation;internet privacy;secret sharing;computer security;network monitoring;computer network	Networks	-39.274633687440115	73.8977922730202	20444
0e49065b1ba25a4922115e2ffdbdc70771c3ea1e	management intelligence for optimal resource allocations in network server systems	end to end qos;topology;protocols;control theory;optimal resource allocation;heuristics based bandwidth adjustment;resource management intelligent networks network servers control systems bandwidth control theory content management monitoring channel allocation feedback loop;service provider;network server;resource allocation;bandwidth allocation;network server system;resource management;management intelligence;client server systems;qos adaptive data transfer;online monitor and control approach;packet loss rate;receivers;heuristics based bandwidth adjustment management intelligence optimal resource allocation network server system qos adaptive data transfer online monitor and control approach bandwidth allocation packet loss rate;network servers;monitoring;feedback loop;bandwidth;telecommunication network management bandwidth allocation client server systems network servers quality of service resource allocation;quality of service;on line monitoring;data transfer;telecommunication network management	In this paper, we provide a control-theoretic treatment of the resource allocations that adaptively occur in a QoS-aware network server system. Here, the target system being controlled is a logical service point that processes the transactions requested by clients using a resource infrastructure, with a goal of maximizing the revenues. Accurate management of resource allocations with a revenue-oriented goal is quite complex, due to the interactions among various transactions that dynamically share the resources in the system (such as server nodes, disks, content caches, and network bandwidth). So, we adopt an on-line monitor-and-control approach, aided by heuristics, that iteratively adjusts the resource allocation based on the observed transaction drop rate. We undertake a case study of end-to-end QoS-adaptive data transfer to illustrate the methodology. In terms of control theory, the bandwidth allocation and the packet loss rate constitute the system input and output respectively, with the heuristics-based bandwidth adjustment strategies incorporated in a controller along the feedback loop. The use of control theory allows offering predictable convergence properties of the QoS seen by applications, while maximizing the service provider revenues.	bundle adjustment;control theory;end-to-end encryption;feedback;heuristic (computer science);input/output;interaction;network packet;online and offline;quality of service;server (computing)	Kaliappa Nadar Ravindran;Mohammad Rabby;Shereef Elmetwaly	2010	2010 IEEE Network Operations and Management Symposium - NOMS 2010	10.1109/NOMS.2010.5488497	service provider;communications protocol;real-time computing;quality of service;resource allocation;computer science;resource management;feedback loop;distributed computing;bandwidth;server;computer network;bandwidth allocation	Embedded	-6.732421081070054	95.46016016550261	20450
68439981874dabc3f0974003ea6be92814aea117	identity-based threshold signature secure in the standard model.	standard model;threshold signature	Recently, design of Identity-based (ID-based) threshold signature schemes which are efficient and provably secure in the standard model has drawn great concerns. In this paper, an ID-based threshold signature scheme based on Paterson and Schuldt’s signature scheme is presented. The proposed construction is proved secure in the standard model and its security rests on the hardness of the computational Diffie-Hellman problem. To the best of authors’ knowledge, this is the first ID-based threshold signature scheme in the literature to achieve this security level.	diffie–hellman problem;digital signature;interactivity;provable security;random oracle	Hu Xiong;Zhiguang Qin;Fagen Li	2010	I. J. Network Security		standard model;computer science	Crypto	-40.647730909250306	76.76704995401315	20453
f8f11bbc935dfb8415526cae8984ff4a3424923e	characterizing the correlation between video types and user quality of experience in the large-scale internet video service	key performance indicator;video service;user engagement;quality of experience;video signal processing internet quality of experience;video type;user engagement video service quality of experience video type key performance indicator;streaming media bandwidth correlation internet quality of service time frequency analysis bit rate;key performance indicators large scale internet video service user quality of experience qoe entertainment cartoon sport news music teleplay specialty	The video service is one of the most important Internet services, and user quality of experience (QoE) represents the degree of recognition of the video service. Therefore, research on QoE is significant in improving the quality of the video service. Considering the influence of different factors on QoE, this paper studies the effect of video content types on QoE. In this article, we divide videos into seven types: entertainment, cartoon, sport, news, music, teleplay, specialty. Besides, we utilize user engagement to measure QoE. The study shows that the correlation which is mainly reflected in following aspects between video types and QoE is substantial. Firstly, video types can impact QoE directly. For example, the proportion of high engagement of cartoon is higher than other videos by 30%. Secondly, video types affect the distribution of the key performance indicators (KPIs). Lastly, video types influence the correlation between user engagement and KPI.	digital video;regular expression;universality probability;web service	Xiaoru Wang;Anming Wei;Yingyun Yang;Jinhui Ning	2015	2015 12th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2015.7382273	subjective video quality;computer science;video quality;performance indicator;multimedia;internet privacy;world wide web;pevq	Metrics	-10.706437468937276	99.34300134776919	20512
c9c0413e5f1890af516151a1aef908c70ee60a18	160 gbps simulation of a quantum dot semiconductor optical amplifier based optical buffer	optical packet switching;programmable delays;physical layer;quantum dot;semiconductor optical amplifier;optical buffers;quantum dot semiconductor optical amplifier;wavelength converters;high speed;optical packet switched	We demonstrate the applicability of quantum-dot semiconductor-opticalamplifier based wavelength converters to the implementation of an ultra-high speed optical packet switching buffer. The buffer architecture consists of cascaded programmable delay stages that fully utilize the available wavelengths and thus minimize the number of wavelength converters that are required to implement the buffer. Physical layer simulations demonstrate error-free operation of the buffer with 3 cascaded Time-Slot-Interchager (TSI) stages at 160 Gbps in the 1.55um window.	data rate units;network packet;optical amplifier;optical buffer;packet switching;quantum dot;semiconductor;simulation;time-slot interchange	Maria Spyropoulou;Konstantinos Yiannopoulos;Stelios Sygletos;Kyriakos Vlachos;Ioannis Tomkos	2007		10.1007/978-3-540-72731-6_13	optical burst switching;telecommunications;computer science;quantum dot;optical performance monitoring;optical amplifier;physical layer;computer network	EDA	-6.282766730322195	87.33036184450006	20524
b56c89776e4eb73680f1f4b5db97bbb891173a25	evaluating multi user distributed action games architectures on a corba platform	architectures;corba.;distributed games;data consistency;distributed application	The development of distributed applications is rapidly growing and some applications, like those which manipulate graphics, images and sounds, need special care. In this paper, we extend the two architectures performance comparison we’ve made at [13] with another one based on CORBA event channel to design a multi user action game that heavily uses sounds and images, identifying the main drawbacks of this kind of implementation. We have run the three different game implementation in a dedicated network to measure the packets traffic, bandwidth use, events lost and data consistency on the redrawing process of each player’s screen. As results, we see that to different kinds of games the use of appropriate architectures may lead to a great processing economy, network traffic reduction and gains on the user presentation quality.	common object request broker architecture;distributed computing;graphics;multi-user;network traffic control	Hendrik T. Macedo;Alessandro C. M. de Araújo;Dave Cavalcanti;Rogério de C. Andrade;Charles A. G. Madeira;Carlos André Guimarães Ferraz	2000			computer science;distributed computing;data consistency;real-time computing;multi-user;network packet;common object request broker architecture;graphics;bandwidth (signal processing);communication channel	HPC	-17.630952353273777	97.8674538491763	20571
a96885d7ae773220f021ae456553b98121304c6e	mobile encryption gateway (meg) for email encryption		Email cryptography applications often suffer from major problems that prevent their widespread implementation. MEG, or the Mobile Encryption Gateway aims to fix the issues associated with email encryption by ensuring that encryption is easy to perform while still maintaining data security. MEG performs automatic decryption and encryption of all emails using PGP. Users do not need to understand the internal workings of the encryption process to use the application. MEG is meant to be email-client-agnostic, enabling users to employ virtually any email service to send messages. Encryption actions are performed on the user’s mobile device, which means their keys and data remain personal. MEG can also tackle network effect problems by inviting non-users to join. Most importantly, MEG uses end-to-end encryption, which ensures that all aspects of the encrypted information remains private. As a result, we are hopeful that MEG will finally solve the problem of practical email encryption.	email encryption;magnetoencephalography;mobile device	Gregory B. Rehm;Michael Thompson;Brad Busenius;Jennifer Fowler	2017	CoRR		computer security;encryption;data security;cryptography;computer network;client-side encryption;computer science;default gateway;email encryption;mobile device;link encryption	Security	-44.94271528371869	68.05412981625936	20587
5cb936d8ab3f29058f84746c17cb0beb228e4898	efficient and side-channel resistant authenticated encryption of fpga bitstreams	encryption field programmable gate arrays authentication clocks resistance;side channel analysis fpga bitstream authenticated encryption;cryptography;field programmable gate arrays cryptography;field programmable gate arrays;real world security side channel resistant authenticated encryption fpga bitstream protection bitstream confidentiality unauthorized copying reverse engineering dynamic reconfiguration diac aes based authenticated encryption scheme ale xilinx virtex bitstream encryption aes based ae algorithms threshold masking techniques real world efficiency	State-of-the-art solutions for FPGA bitstream protection rely on encryption and authentication of the bitstream to both ensure its confidentiality, thwarting unauthorized copying and reverse engineering, and prevent its unauthorized modification, maintaining a root of trust in the field. Adequate protection of the FPGA bitstream is of paramount importance to sustain the central functionality of dynamic reconfiguration in a hostile environment. In this work, we propose a new solution for authenticated encryption (AE) tailored for FPGA bitstream protection. It is based on the recent proposal presented at DIAC'12: the AES-based authenticated encryption scheme ALE. Our comparison to existing AES-based schemes reveals that ALE is at least twice more resource-efficient than the best AE modes of operation instantiated with AES. In the view of the recent successful side-channel attacks on Xilinx Virtex bitstream encryption, we investigate the possibility for side-channel resistant implementations of all these AES-based AE algorithms using state-of-the-art threshold masking techniques. Also in this side-channel resistant setting, the protected ALE design is about twice more resource-efficient than the best AE modes of operation with the same countermeasure. We conclude that the deployment of dedicated AE schemes such as ALE significantly facilitates the real-world efficiency and security of FPGA bitstream protection in practice: Not only our solution enables authenticated encryption for bitstream on low-cost FPGAs but it also aims to mitigate physical attacks which have been lately shown to undermine the security of the bitstream protection mechanisms in the field.	aes instruction set;algorithm;authenticated encryption;authentication;authorization;bitstream;block cipher mode of operation;computation;confidentiality;data rate units;field-programmable gate array;google cloud messaging;hash-based message authentication code;protection mechanism;reverse engineering;sha-2;secret sharing;side-channel attack;software deployment;trust anchor;virtex (fpga)	Andrey Bogdanov;Amir Moradi;Tolga Yalçin	2012	2012 International Conference on Reconfigurable Computing and FPGAs	10.1109/ReConFig.2012.6416743	embedded system;real-time computing;40-bit encryption;computer science;cryptography;on-the-fly encryption;computer security;encryption	Security	-35.44940120988319	75.40451501598224	20597
72b7fea9e527f18182ba44281b44de790e32d155	reining in long tails in warehouse-scale computers with quick voltage boosting using adrenaline	energy efficiency;tail queries;datacenters;latency critical workloads;fine grained dynamic voltage frequency scaling	Reducing the long tail of the query latency distribution in modern warehouse scale computers is critical for improving performance and quality of service (QoS) of workloads such as Web Search and Memcached. Traditional turbo boost increases a processor’s voltage and frequency during a coarse-grained sliding window, boosting all queries that are processed during that window. However, the inability of such a technique to pinpoint tail queries for boosting limits its tail reduction benefit. In this work, we propose Adrenaline, an approach to leverage finer-granularity (tens of nanoseconds) voltage boosting to effectively rein in the tail latency with query-level precision. Two key insights underlie this work. First, emerging finer granularity voltage/frequency boosting is an enabling mechanism for intelligent allocation of the power budget to precisely boost only the queries that contribute to the tail latency; second, per-query characteristics can be used to design indicators for proactively pinpointing these queries, triggering boosting accordingly. Based on these insights, Adrenaline effectively pinpoints and boosts queries that are likely to increase the tail distribution and can reap more benefit from the voltage/frequency boost. By evaluating under various workload configurations, we demonstrate the effectiveness of our methodology. We achieve up to a 2.50 × tail latency improvement for Memcached and up to a 3.03 × for Web Search over coarse-grained dynamic voltage and frequency scaling (DVFS) given a fixed boosting power budget. When optimizing for energy reduction, Adrenaline achieves up to a 1.81 × improvement for Memcached and up to a 1.99 × for Web Search over coarse-grained DVFS. By using the carefully chosen boost thresholds, Adrenaline further improves the tail latency reduction to 4.82 × over coarse-grained DVFS.	acm transactions on computer systems;boosting (machine learning);dynamic voltage scaling;frequency scaling;image scaling;intel turbo boost;long tail;memcached;quality of service;tail call;tails	Chang-Hong Hsu;Yunqi Zhang;Michael Laurenzano;David Meisner;Thomas F. Wenisch;Ronald G. Dreslinski;Jason Mars;Lingjia Tang	2017	ACM Trans. Comput. Syst.	10.1145/3054742	boosting (machine learning);sliding window protocol;workload;real-time computing;latency (engineering);quality of service;computer science;power budget;granularity;frequency scaling	Arch	-20.498116449019818	60.87806721184221	20611
d62a7544c8ebedd1500da30a2557cf59bf4582e7	ontario healthcare privacy act: compliant ad hoc healthcare applications	buffer overrun;exploit;buffer overflow;framework;metasploit			Stephanie Chow	2006		10.1145/1501434.1501522	buffer overflow;computer science;internet privacy;computer security;computer network	Crypto	-47.533414351191325	61.73149703790209	20640
b262bb2cf500fdfebd22ba07baed5d803c499cb4	mutual authentication in self-organized vanets	authentication;wireless communication;vehicular ad hoc network;self organization;security	The practical deployment of vehicular networks is still a pending issue. In this paper we describe a new self-organized method of authentication for VANETs, which allows their widespread, fast and secure implementation. Our proposal does not involve any central certification authority because the nodes themselves certify the validity of public keys of the other nodes. On the one hand we propose an algorithm that each node must use to choose the public key certificates for its local store. On the other hand, we also describe a new node authentication method based on a cryptographic protocol including a zero-knowledge proof that each node must use to convince another node on the possession of certain secret without revealing anything about it, which allows non-encrypted communication during authentication. Thanks to the combination of the aforementioned tools, the cooperation among vehicles can be used for developing several practical applications of VANETs, such as detection and warning about abnormal traffic conditions. One of the most interesting aspects of our proposal is that it only requires existing devices such as smartphones, because the designed schemes are fully distributed and self-organized. In this work we include an analysis of both an NS-2 simulation and a real device implementation of the proposed algorithms, which enables us to extract promising conclusions and several possible improvements and open questions for further research.	mutual authentication;self-organization	Cándido Caballero-Gil;Pino Caballero-Gil;Jezabel Molina-Gil	2014	Computer Standards & Interfaces	10.1016/j.csi.2013.12.005	vehicular ad hoc network;self-organization;computer science;information security;authentication protocol;authentication;internet privacy;computer security;wireless;computer network	HCI	-48.23095385103322	74.90103022301611	20653
1250ffffdebf7d7494bb3f79e04bb706285cbcfe	practical verifiably encrypted signature based on waters signatures	ves scheme;certified key model;digital signatures cryptography;standard computational diffie hellman assumption;water signatures;rogue key attack water signatures standard computational diffie hellman assumption random oracles verifiably encrypted signature scheme ves scheme certified key model signature forger;signature forger;random oracles;rogue key attack;verifiably encrypted signature scheme	Waters proposed the first efficient signature scheme that is known to be existentially unforgeable based on the standard computational Diffie-Hellman assumption without random oracles. Lu et al. then proposed the first verifiably encrypted signature (VES) scheme based on Waters signatures. However, the security proofs of Lu et al. and some other VES schemes are built on the certified-key model, in which the key pair of the adjudicator is chosen by the simulator rather than the signature forger. It demands that the adjudicator must be honest enough never to forge signatures. In the real world, it is hard for users to choose such trusted third party. In this study, the authors first show that Lu et al.’s VES is not secure in the chosen-key model by presenting a rogue key attack. Then they present the first VES scheme based on Waters signatures secure in the chosen-key model, where two inside adversaries, malicious adjudicator and malicious verifier, have more powers than ever.	antivirus software;computational diffie–hellman assumption;decisional diffie–hellman assumption;digital signature forgery;encryption;forge;known-key distinguishing attack;lu decomposition;malware;public-key cryptography;rogue;simulation;trusted third party;virtual execution system	Zuhua Shao;Yipeng Gao	2015	IET Information Security	10.1049/iet-ifs.2013.0385	ring signature;mathematics;internet privacy;world wide web;computer security	Crypto	-40.68664426136527	75.27348904477311	20663
ca25d20d4fec8e8179202c97e8f878a43bf7f254	collision resistance of hash functions in a weak ideal cipher model	collision resistance;hash function;provable security	This article discusses the provable security of blockcipher-based hash functions. It introduces a new model called a weak ideal cipher model. In this model, an adversary is allowed to make key-disclosure queries to the oracle as well as encryption and decryption queries. A key-disclosure query is a pair of a plaintext and a ciphertext, and the reply is a corresponding key. Thus, in this model, a block cipher is random but completely insecure as a block cipher. It is shown that collision resistant hash functions can be constructed even in this weak model. key words: hash function, provable security, collision resistance	adversary (cryptography);block cipher;ciphertext;collision resistance;cryptographic hash function;cryptography;encryption;key disclosure law;plaintext;provable security	Shoichi Hirose;Hidenori Kuwakado	2012	IEICE Transactions		weak key;transposition cipher;security of cryptographic hash functions;double hashing;differential cryptanalysis;hash function;perfect hash function;collision attack;primary clustering;ciphertext stealing;block cipher mode of operation;sha-2;collision resistance;computer science;theoretical computer science;provable security;hash chain;mathematics;stream cipher;internet privacy;computer security;cbc-mac;ciphertext;cryptographic hash function;mdc-2;swifft	Crypto	-41.04462688088072	77.3593682760357	20675
69e133903800dbe3d3b5c2c47a26887abfbc031c	learning with rounding, revisited: new reduction, properties and applications		The learning with rounding (LWR) problem, introduced by Banerjee, Peikert and Rosen [BPR12] at EUROCRYPT ’12, is a variant of learning with errors (LWE), where one replaces random errors with deterministic rounding. The LWR problem was shown to be as hard as LWE for a setting of parameters where the modulus and modulus-to-error ratio are super-polynomial. In this work we resolve the main open problem of [BPR12] and give a new reduction that works for a larger range of parameters, allowing for a polynomial modulus and modulus-to-error ratio. In particular, a smaller modulus gives us greater efficiency, and a smaller modulus-to-error ratio gives us greater security, which now follows from the worst-case hardness of GapSVP with polynomial (rather than super-polynomial) approximation factors. As a tool in the reduction, we show that there is a “lossy mode” for the LWR problem, in which LWR samples only reveal partial information about the secret. This property gives us several interesting new applications, including a proof that LWR remains secure with weakly random secrets of sufficient minentropy, and very simple new constructions of deterministic encryption, lossy trapdoor functions and reusable extractors. Our approach is inspired by a technique of Goldwasser et al. [GKPV10] from ICS ’10, which implicitly showed the existence of a “lossy mode” for LWE. By refining this technique, we also improve on the parameters of that work to only requiring a polynomial (instead of super-polynomial) modulus and modulus-to-error ratio.	approximation;best, worst and average case;bit error rate;deterministic encryption;eurocrypt;lattice problem;learning with errors;lossy compression;modulus of continuity;modulus robot;polynomial;rounding;trapdoor function	Joël Alwen;Stephan Krenn;Krzysztof Pietrzak;Daniel Wichs	2013		10.1007/978-3-642-40041-4_4		Crypto	-37.49272871456484	76.67335249382175	20679
dc1c5af3276da22f96977f60532524fb29564fc6	performance analysis of multi-stage interconnection networks with deterministic service times	interconnection network;performance analysis;multi stage networks;parallel processing	"""Received (received date) Revised (revised date) Communicated by (Name of Editor) ABSTRACT In this paper we present a performance model for a constant service time, globally synchronized multistage interconnection network that is an improvement on earlier work in this eld. The events at the network input are assumed to have a geometric distribution in time. As the events are combined within the network, it can happen that two events arrive simultaneously at one of the network server elements, called a double arrival rate stream (DAR) server. Analytical methods are described to derive the response time and inter-departure time distribution of the double arrival rate constant service time server, which has a queuing property (DAR/D/1). Due to the queuing eeect of the servers in the rst stage of the network, their outputs show a \distorted"""" geometric distribution, which is known to introduce analytical diiculties in the performance evaluation of the subsequent stages. A method is presented to derive the response time of servers in the second stage, when the network has a uniform workload distribution. It is shown that the knowledge of the response times of the rst and second stage of the network is suucient to predict the total response time of a large network with an accuracy better than 3%, even under a heavy workload."""	interconnection;multistage amplifier;performance evaluation;profiling (computer programming);queueing theory;response time (technology);server (computing);time server	Gerard L. Reijns;Arjan J. C. van Gemund;Hasyim Gautama	2001	Parallel Processing Letters	10.1142/S0129626401000464	parallel processing;parallel computing;real-time computing;computer science;operating system;network simulation;distributed computing;queuing delay	Metrics	-11.894564085588133	67.01229358466038	20687
1835d490e0b46ff37b4071f001797f1ad74ca2ca	an epistemic approach to coercion-resistance for electronic voting protocols	protocols;turing machines;coercion resistance;civitas system electronic voting protocols coercion resistance security requirements epistemic approach symbolic protocol adversary model;symbolic protocol;radiation detectors;cryptographic protocols;resistance;epistemic approach;polynomials;proof of concept;adversary model;electronic voting security cryptographic protocols cryptography privacy concrete polynomials turing machines;cryptography;security requirements;civitas system;electronic voting security protocol analysis;mathematical model;electronic voting protocols;security of data government data processing protocols;security protocol analysis;security;electronic voting;government data processing;security of data;privacy;concrete	Coercion resistance is an important and one of themost intricate security requirements of electronicvoting protocols. Several definitions of coercionresistance have been proposed in the literature,including definitions based on symbolic models.However, existing definitions in such models arerather restricted in their scope and quite complex.In this paper, we therefore propose a new definitionof coercion resistance in a symbolic setting, basedon an epistemic approach. Our definition isrelatively simple and intuitive. It allows for afine-grained formulation of coercion resistance andcan be stated independently of a specific, symbolicprotocol and adversary model. As a proof of concept,we apply our definition to three votingprotocols. In particular, we carry out the firstrigorous analysis of the recently proposed Civitassystem. We precisely identify those conditions underwhich this system guarantees coercion resistance orfails to be coercion resistant. We also analyzeprotocols proposed by Lee et al. and Okamoto.	adversary model;requirement;tamper resistance	Ralf Küsters;Tomasz Truderung	2009	2009 30th IEEE Symposium on Security and Privacy	10.1109/SP.2009.13	concrete;computer science;cryptography;information security;theoretical computer science;mathematical model;internet privacy;resistance;privacy;proof of concept;computer security;adversary model	Security	-36.35984650069784	72.43899585214255	20711
b2a1ed3ff5f467677cc7cadf14ab1e0ce2022418	a multiple copy approach for delivering messages under deadline constraints	multiprocessor interconnection networks;distributed system;communication system traffic control;control systems;message delivery;multiple copy;multiprocessing programs;application software;point to point;message traffic multiple copy deadline constraints expected recovery cost distributed real time system point to point interconnection topology disjoint routes message delivery;distributed processing;disjoint routes;network topology;fault tolerant computing;time factors;distributed real time system;costs power system reliability real time systems application software time factors network topology communication system traffic control computer network reliability multiprocessor interconnection networks control systems;deadline constraints;message traffic;power system reliability;expected recovery cost;multiprocessor interconnection networks distributed processing fault tolerant computing multiprocessing programs;point to point interconnection topology;computer network reliability;real time systems	A scheme to minimize the expected recovery cost incurred by a distributed real-time system as a result of messages failing to meet their deadline is proposed. The scheme is intended for distributed systems with point-to-point interconnection topology. The goal of minimizing the expected cost is achieved by sending multiple copies of a message through disjoint routes, thus increasing the probability of successful message delivery within the deadline. The number of copies of each message to be sent is determined by optimizing the tradeoff between the increase in the message traffic due to additional copies and the decrease in the probability of a message missing its deadline. The objective used to determine the optimal number of copies is formalized, and a numerical example is presented, showing that reductions of more than 70% can be achieved at low to moderate loads. At high loads the reductions are in the range of 10-40%. >		P. Ramathan;Kang G. Shin	1991		10.1109/FTCS.1991.146677	parallel computing;real-time computing;computer science;distributed computing	Logic	-9.925465850680299	65.97539607071538	20741
1fe54b92bd454fbaa2b10cbf029a579608ad8bc5	a framework of authentication and authorization for e-health services	medical records;information privacy;authentication;health system;personal data;data privacy;security and privacy;authorization;e health;health services;privacy	This article introduces a framework for authentication and authorization in e-health services. It aims to build the architecture for authentication and authorization within an e-health service system. The architecture will help to build a secure and privacy protection e-health service system. The underlying framework will not only inform researchers of a better design for e-health service, but also assist e-health systems developers in the understanding of intricate constructions within authentication and authorization. This includes protecting the privacy of medical records of patients in terms of information privacy.	authentication;authorization;information privacy	Song Han;Geoff Skinner;Vidyasagar Potdar;Elizabeth Chang	2006		10.1145/1180367.1180387	privacy software;privacy policy;information privacy;privacy by design;computer science;authentication;authorization;internet privacy;privacy;world wide web;computer security;medical record	Security	-44.70407799086943	62.27415640241963	20760
485f4642b0e82b43b903db2c59d62b8380d1f027	guided multiple hashing: achieving near perfect balance for fast routing lookup	routing protocols;network processor guided multiple hashing approach packet forwarding function ip network layer protocols routing table lookup trie based lookup multihashing developments d random 2 left d left localized optimization global key to bucket assignment off chip memory;transport protocols ip networks routing protocols table lookup;transport protocols;arrays routing memory management indexes delays load management throughput;ip networks;table lookup	The routing and packet forwarding function is at the core of the IP network-layer protocols. The throughput of a router is constrained by the speed at which the routing table lookup can be performed. Hash-based lookup has been a research focus in this area due to its O(1) average lookup time, as compared to other approachs such as trie-based lookup which tends to make more memory accesses. With a series of prior multi-hashing developments, including d-random, 2-left, and d-left, we discover that a new guided multi-hashing approach holds the promise of further pushing the envelope of this line of research to make significant performance improvement beyond what today's best technology can achieve. Our guided multi-hashing approach achieves near perfect load balance among hash buckets, while limiting the number of buckets to be probed for each key (address) lookup, where each bucket holds one or a few routing entries. Unlike the localized optimization by the prior approaches, we utilize the full information of multi-hash mapping from keys to hash buckets for global key-to-bucket assignment. We have dual objectives of lowering the bucket size while increasing empty buckets, which helps to reduce the number of buckets brought from off-chip memory to the network processor for each lookup. We introduce mechanisms to make sure that most lookups only require one bucket to be fetched. Our simulation results show that with the same number of hash functions, the guided multiple-hashing schemes are more balanced than d-left and others, while the average number of buckets to be accessed for each lookup is reduced by 20-50%.	computer memory;encode;empty string;galois/counter mode;hash function;hash table;load balancing (computing);lookup table;mathematical optimization;network packet;network processor;router (computing);routing table;simulation;throughput;trie;wrapper function	Xi Tao;Yan Qiao;Jih-Kwon Peir;Shigang Chen;Zhuo Huang;Shih-Lien Lu	2013	2013 21st IEEE International Conference on Network Protocols (ICNP)	10.1109/ICNP.2013.6733607	routing table;computer science;theoretical computer science;key-based routing;distributed computing;routing protocol;transport layer;computer network	Arch	-5.648755331425832	66.81779042651857	20784
4a30fb02f57773b8f2e3d9bbceed161f4594e4ca	automated synthesis of reactive controllers for software-defined networks	networked control systems;telecommunication control;abstraction based synthesis approach automated synthesis reactive controllers internet software defined network management tool support network control logic management reactive synthesis problem synthesis tools network changes network wide specification network abstractions control logic synthesis simulation relations;telecommunication network management control system synthesis internet networked control systems telecommunication control;internet;control system synthesis;abstracts switches games access control routing gold;telecommunication network management	With the tremendous growth of the Internet and the emerging software-defined networks, there is an increasing need for rigorous and scalable network management methods and tool support. This paper proposes a synthesis approach for managing software-defined networks. We formulate the construction of network control logic as a reactive synthesis problem which is solvable with existing synthesis tools. The key idea is to synthesize a strategy that manages control logic in response to network changes while satisfying some network-wide specification. Finally, we investigate network abstractions for scalability. For large networks, instead of synthesizing control logic directly, we use its abstraction-a smaller network that simulates its behavior-for synthesis, and then implement the synthesized control on the original network while preserving the correctness. By using the so-called simulation relations, we also prove the soundness of this abstraction-based synthesis approach.	correctness (computer science);decision problem;logic synthesis;scalability;simulation	Anduo Wang;Salar Moarref;Boon Thau Loo;Ufuk Topcu;Andre Scedrov	2013	2013 21st IEEE International Conference on Network Protocols (ICNP)	10.1109/ICNP.2013.6733666	element management system;real-time computing;the internet;intelligent computer network;overlay network;network architecture;network management station;computer science;networked control system;network simulation;distributed computing;network management application;computer network	Embedded	-15.687695769599697	84.27994514297862	20786
b3a8cb3ca8f24c9319fc9b3017cb70c1b7ddf01b	guaranteeing response times for aperiodic tasks in global multiprocessor scheduling	multiprocessor scheduling;matematisk analys;aperiodic;multiprocessor;multiprocessor systems;utility function;mathematical analysis;optimal threshold;scheduling;synthetic utilization;datavetenskap datalogi;dhalls effect;computer science	We provide a constant time schedulability test for an on-line multiprocessor server handling aperiodic tasks. Dhall's effect is avoided by dividing the tasks in two priority classes based on task utilization: heavy and light. We prove that if the load on the multiprocessor server stays below U threshold = 3 − √7 ≈ 35.425%, the server can accept an incoming aperiodic task and guarantee that the deadlines of all accepted tasks will be met. The same number 35.425% is also a threshold for a task to be characterized as heavy. The bound U threshold = 3 − √7≈ 35.425% is easy-to-use, but not sharp if we know the number of processors in the multiprocessor system. Assuming the server to be equipped with m processors, we calculate a formula for the sharp bound U threshold (m), which converges to U threshold from above as m → ∞. The results are based on a utilization function u(x) = 2(1 − x)/(2 + √2+2x). By using this function, the performance of the multiprocessor server can in some cases be improved beyond U threshold(m) by paying the extra overhead of monitoring the individual utilization of the current tasks.	algorithm;aperiodic graph;categorization;central processing unit;expanded memory;integrated circuit layout design protection;lu decomposition;multiprocessing;multiprocessor scheduling;online and offline;overhead (computing);real-time clock;scheduling (computing);server (computing);synthetic intelligence;time complexity;time server	Lars Lundberg;Håkan Lennerstad	2006	Real-Time Systems	10.1007/s11241-006-9005-y	parallel computing;real-time computing;multiprocessing;computer science;operating system;distributed computing;scheduling;multiprocessor scheduling;symmetric multiprocessor system	Embedded	-10.215847199631996	60.85092328846683	20808
da8b2ce9ecb14f7283a1c6b8f4699da0a5eeb84d	resource use pattern analysis for predicting resource availability in opportunistic grids	use pattern analysis;scheduling;opportunistic grids;grid computing	This work presents a method for predicting resource availability in opportunistic grids by means of Use Pattern Analysis (UPA), a technique based on non-supervised learning methods. This prediction method is based on the assumption of the existence of several classes of computational resource use patterns, which can be used to predict resource availability. Trace-driven simulations validate this basic assumptions, which also provide the parameter settings for the accurate learning of resource use patterns. Experiments made with an implementation of the UPA method show the feasibility of its use in the scheduling of grid tasks with very little overhead. The experiments also demonstrate the method’s superiority over other predictive and non-predictive methods. An adaptative prediction method is suggested to deal with lack of training data at initialisation. Further adaptative behaviour is motivated by experiments which show that, in some special environments, reliable resource use patterns may not always be detected.	computation;computational resource;experiment;overhead (computing);pattern recognition;preemption (computing);scheduling (computing);simulation;supervised learning;windows task scheduler	Marcelo Finger;Germano Capistrano Bezerra;Danilo R. Conde	2010	Concurrency and Computation: Practice and Experience	10.1002/cpe.1478	parallel computing;simulation;computer science;operating system;data mining;database;distributed computing;supervised learning;operations research;scheduling;grid computing	Web+IR	-16.60717383668838	61.751346155109864	20836
4995ace78c3cec2f650acd877af43b59e89e2d26	sport wearable biometric data encrypted emulation and storage in cloud	databases;generators;encryption;nosql database stress testing sport wearable biometric data encrypted emulation data generator nosql dbms data encryption nserc;servers;encryption generators databases three dimensional displays benchmark testing servers;three dimensional displays;sql cloud computing cryptography sport;benchmark testing	We investigated different encryption algorithms for sport wearable devices by utilizing a newly developed data generator for the testing purposes. Additionally we investigated different data encryption algorithms for a NoSQL DBMS. Testing results for data generator, data encryption and NoSQL database stress testing are presented and discussed as well. The research project was conducted in support of NSERC grant “GAUGE: Exact Positioning Systems For Sport and Healthcare Industries”.	algorithm;biometrics;emulator;encryption;global positioning system;nosql;stress testing;wearable computer;wearable technology	Nick McDonald;Daniel Atkinson;Youry Khmelevsky;Scott McMillan	2016	2016 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2016.7726819	benchmark;client-side encryption;computer science;operating system;database;internet privacy;world wide web;encryption;server	DB	-37.78374745862331	68.15895124223967	20851
23b20c3b5609fbdf02ab0359b811241b093e7416	router-based brokering for surrogate discovery in edge computing		In-network processing pushes computational capabilities closer to the edge of the network, enabling new kinds of location-aware, real-time applications, while preserving bandwidth in the core network. This is done by offloading computations to more powerful or energy-efficient surrogates that are opportunistically available at the network edge. In mobile and heterogeneous usage contexts, the question arises how a client can discover the most appropriate surrogate in the network for offloading a task. In this paper, we propose a brokering mechanism that matches a client with the best available surrogate, based on specified requirements and capabilities. The broker is implemented on standard home routers, and thus, leverages the ubiquity of such devices in urban environments. To motivate the feasibility of this approach, we conduct a coverage analysis based on collected access point locations in a major city. Furthermore, the brokering functionality introduces only a minimal resource overhead on the routers and can significantly reduce the latency compared to distant, cloud-based solutions.	cloud computing;computation;cyclic redundancy check;distributed hash table;edge computing;end-to-end principle;interconnection;location awareness;network processor;overhead (computing);real-time clock;relay;requirement;router (computing);surrogates;tracing (software);wireless access point	Julien Gedeon;Christian Meurisch;Disha Bhat;Michael Stein;Lin Wang;Max Mühlhäuser	2017	2017 IEEE 37th International Conference on Distributed Computing Systems Workshops (ICDCSW)	10.1109/ICDCSW.2017.61	latency (engineering);edge device;cloud computing;router;core network;computer network;server;distributed computing;edge computing;computer science	HPC	-18.24649051826352	79.92755464515236	20852
6d18e254c381b51dfdc44fec4e8c47c6ecb592eb	the lower bound of attacks on anonymity systems - a unicity distance approach	004 informatik;330 wirtschaft;ddc 330;ddc 004	During the last years a couple of attacks on generic anonymity protocols emerged, like e.g. the hitting-set attack. These attacks make use of informations gained by passively monitoring anonymizing networks to disclose the communication profile of the users.	unicity distance	Dogan Kesdogan;Lexi Pimenidis	2006		10.1007/978-0-387-36584-8_12	engineering;internet privacy;world wide web;computer security	Security	-48.69594464333861	63.104506052428256	20879
8e109b2afe1f25c02241d1233f1a27559e2a99e7	impact of osi on the architecture of the design of application processes			osi model	Gesualdo Le Moli	1989			architecture;computer architecture;computer science	EDA	-20.903911770692023	88.5044276743879	20923
272261688007d016b82b921c12abab2770bb84a1	provisioning qos in inter-domain traffic engineering	end to end qos;multi protocol label switching;path computation element;source routing;multi protocol label switched;autonomic system;setup time;diffserv;traffic engineered;traffic engineering;quality of service;eq link;label switched path	This work describes an architectural framework that allows inter-domain Traffic Engineering Label Switched Paths (TE-LSPs) with guaranteed quality of service (QoS) to be setup. Such TE-LSPs, called EQ-links, are setup by coordinating path computation elements (PCEs) of neighboring autonomous systems (ASs) along a pre-determined inter-AS path, computed through cooperative interaction between pairs of neighboring ASs. After defining the architectural requirements for the framework, we describe and analyze the Inter-AS Path Computation Protocol (IA-PCP), which computes an interdomain path at the AS level, i.e., selecting a sequence of ASs to the destination, based on a loose source routing approach. The results of the IA-PCP computations are then fed to the PCEs for complete path computation. The proposed architecture has been actually implemented within the testbed of the EuQoS project, which is aimed at enabling end-to-end QoS in the Internet. We report results related to the setup time of EQ-links, measured in the pan-European testbed of the EuQoS project, showing that path computation and setup takes an affordable time overhead.	autonomous system (internet);computation;differentiated services;end-to-end encryption;enterprise architecture framework;flip-flop (electronics);inter-domain;loose source routing;modular programming;multiprotocol label switching;network topology;overhead (computing);prototype;provisioning;quality of service;relational operator;requirement;test engineer;testbed;the times	Olivier Dugeon;Enzo Mingozzi;Giovanni Stea;Luca Bisti	2008	Annales des Télécommunications	10.1007/s12243-008-0059-9	multiprotocol label switching;traffic engineering;source routing;real-time computing;quality of service;telecommunications;computer science;distributed computing;differentiated services;computer network	Networks	-16.444069888286844	83.05433871188588	20947
0016c85ee94a96a67e3897c790bcd6e8d206bfab	natural selection in peer-to-peer streaming: from the cathedral to the bazaar	peer to peer network;market model;overlay multicast;natural selection;peer to peer streaming;streaming media;resource sharing;media streaming;peer to peer;peer to peer networks	Success of peer-to-peer applications in many cases is attributed to user altruism, where a user contributes some of its own resources to facilitate performance of other users. This observation has been corroborated with some experimental evidence. In this paper we make a first attempt to demonstrate that there are many scenarios where peer-to-peer resource sharing is a natural behavior that selfish users can use to improve their own performance. In particular we examine such natural incentives that exist in a streaming media application which lead such greedy users to cooperate and share resources with each other in forming an efficient overlay multicast tree. We define a freestyle Bazaar environment in which streaming media receivers interact with each other and cooperatively construct an overlay tree for improving their perception of media streams from a single server. Through simulations we demonstrate the efficacy of our proposed environment.	advanced chess;greedy algorithm;multicast;overlay network;peer-to-peer;server (computing);simulation;streaming media;the cathedral and the bazaar	Vivek Shrivastava;Suman Banerjee	2005		10.1145/1065983.1066006	shared resource;natural selection;computer science;internet privacy;dead peer detection;world wide web;computer network	Networks	-24.00842990900779	73.80778727571986	20953
9358d202c467cfc6693cc9f22ef8b7372a0d633e	fix the leak! an information leakage aware secured cyber-physical manufacturing system		Cyber-physical additive manufacturing systems consists of tight integration of cyber and physical domains. This results in new cross-domain vulnerabilities that poses unique security challenges. One of the challenges is preventing confidentiality breach due to physical-to-cyber domain attacks, where attackers can analyze various analog emissions from the side-channels to steal the cyber-domain information. This information theft is based on the idea that an attacker can accurately estimate the relation between the analog emissions (acoustics, power, electromagnetic emissions, etc.,) and the cyber-domain data (such as G-code). To obstruct this estimation process, it is crucial to quantize the relation between the analog emissions and the cyber-data, and use it as a metric to generate computer aided manufacturing tools, such as slicing and tool-path generation algorithms, that are aware of these information leakage through the side-channels. In this paper, we present a novel methodology that uses mutual information as a metric to quantize the information leakage from the side-channels, and demonstrates how various design variables (such as object orientation, nozzle velocity, etc.,) can be used in an optimization algorithm to minimize the information leakage. Our methodology integrates this leakage aware algorithms to the state-of-the-art slicing and tool-path generation algorithms and achieves 24.76% average drop in the information leakage through acoustic side-channel. To the best of our knowledge, this is the first work that demonstrates the idea of generating information leakage aware computer aided manufacturing tools for protecting the confidentiality of the manufacturing system.	3d modeling;3d printing;acoustic cryptanalysis;algorithm;benchmark (computing);confidentiality;g-code;information leakage;mathematical optimization;mutual information;quantization (signal processing);security breach notification laws;side-channel attack;spectral leakage;utility functions on indivisible goods;velocity (software development)	Sujit Rokka Chhetri;Sina Faezi;Mohammad Abdullah Al Faruque	2017	Design, Automation & Test in Europe Conference & Exhibition (DATE), 2017		embedded system;algorithm design;mathematical optimization;electronic engineering;real-time computing;simulation;telecommunications;computer science;engineering;electrical engineering;information security;operating system;solid modeling;computer security;force;algorithm	EDA	-49.40227385492436	62.56090166068078	20956
0b5f78932a123ade32225aaa715249fb5b8c36c8	privacy-preserving spectral analysis of large graphs in public clouds	bepress selected works;privacy preserving computation;differential privacy;approximate eigen decomposition;spectral analysis;sparse graph spectral analysis;cloud computing;cloud computing privacy preserving computations spectral analysis approximate eigen decomposition;privacy preserving computations	Large graph datasets have become invaluable assets for studying problems in business applications and scientific research. These datasets, collected and owned by data owners, may also contain privacy-sensitive information. When using public clouds for elastic processing, data owners have to protect both data ownership and privacy from curious cloud providers. We propose a cloud-centric framework that allows data owners to efficiently collect graph data from the distributed data contributors, and privately store and analyze graph data in the cloud. Data owners can conduct expensive operations in untrusted public clouds with privacy and scalability preserved. The major contributions of this work include two privacy-preserving approximate eigen decomposition algorithms (the secure Lanczos and Nystrom methods) for spectral analysis of large graph matrices, and a personalized privacy-preserving data submission method based on differential privacy that allows for the trade-off between data sparsity and privacy. For a N-node graph, the proposed approach allows a data owner to finish the core operations with only O(N) client-side costs in computation, storage, and communication. The expensive O(N2) operations are performed in the cloud with the proposed privacy-preserving algorithms. We prove that our approach can satisfactorily preserve data privacy against the untrusted cloud providers. We have conducted an extensive experimental study to investigate these algorithms in terms of the intrinsic relationships among costs, privacy, scalability, and result quality.	approximation algorithm;client-side;cloud computing;computation;differential privacy;eigen (c++ library);experiment;information privacy;information sensitivity;personalization;scalability;sparse matrix	Sagar Sharma;James Powers;Keke Chen	2016		10.1145/2897845.2897857	cloud computing;computer science;theoretical computer science;data mining;database;computer security;differential privacy	DB	-39.964900051866806	65.77128990605014	20963
1559d5c8b48625c7551d46a85dcd13b05c08318d	cross-layer design of source rate control and qos-aware congestion control for wireless video streaming	automatic control;qos aware congestion control;wireless channels;video streaming;transmission error;streaming video;telecommunication congestion control;cross layer design streaming media communication system control automatic control system performance delay internet transport protocols bandwidth equations;transport layer;system performance;source rate control;wireless channel;transport protocols;rate control;internet;transport protocol cross layer design source rate control qos aware congestion control video streaming wireless channel;wireless channels quality of service telecommunication congestion control transport protocols video streaming;streaming media;congestion control;cross layer design;transport protocol;bandwidth;wireless video streaming;quality of service;communication system control;mac layer	Cross-layer design has been used in streaming video over the wireless channels to optimize the overall system performance. In this paper we extend our previous work (i.e. joint design of source rate control and congestion control for video streaming over the Internet) in P.Zhu et al., (2005) and propose a cross-layer design approach for wireless video streaming. By jointly designing the source rate control at the application layer and congestion control at the transport layer, and taking advantage of MAC layer information, our approach can avoid the throughput degradation caused by transmission error of the wireless channel, and better support the QoS requirements of the application. Simulation results show that the proposed mechanism can significantly improve the playback quality of the application, while maintaining good performance of the transport protocol	elegant degradation;network congestion;quality of service;requirement;simulation;streaming media;throughput	Peng Zhu;Wenjun Zeng;Chunwen Li	2006	2006 IEEE International Conference on Multimedia and Expo	10.1109/ICME.2006.262735	real-time computing;telecommunications;computer science;automatic control;transport layer;computer network	Embedded	-5.722310066694863	101.55465144548644	20998
dfd6a7eef3e8a67d90b0a26e7bc8312ea4ff317c	a cloud computing framework for on-demand forecasting services		This paper presents the Forecast-as-a-Service (FaaS) framework, a cloud-based framework that provides on-demand customer-defined forecasting services. Based on the principles of service-oriented architecture (SOA), the FaaS enables the use of different types of data from different sources to generate different kinds of forecasts at different levels of detail for different prices. The FaaS framework has been developed to provide on-demand forecasts of solar or wind power. Forecasts can be long-term forecasts useful for prospecting or planning by potential investors, or short-term forecasts suitable for operational decision making by operators of existing facilities. FaaS provides a more flexible and affordable alternative to the subscription model provided by current forecast service vendors. By improving the flexibility and economics of renewable energy forecasting services with SOA and cloud computing, FaaS achieves the goal of Services Computing.	cloud computing	Kwa-Sur Tam;Rakesh Sehgal	2014		10.1007/978-3-319-11167-4_35	cloud computing;cloud testing;data mining;utility computing;services computing;world wide web;computer network	HPC	-28.71445413131003	61.416168147347285	21007
c388b5c5d56113e374cd51a3b2263380614ec975	enhancing password security through interactive fear appeals: a web-based field experiment	passwords;information security;field experiment;web sites message authentication;interactive password strength meter password security enhancement interactive fear appeal treatment web based field experiment authentication mechanism information security weak passwords strong passwords static fear appeals account registration process website;web sites;interactivity;message authentication;dictionaries information security educational institutions appraisal computers abstracts;fear appeals;field experiment passwords information security fear appeals interactivity	Passwords remain the dominant authentication mechanism for information security. Unfortunately, research has shown that most passwords are highly insecure. Given the risks of using weak passwords, there is a need to effectively motivate users to select strong passwords. In this study we examine the influence of interactivity, as well as static and interactive fear appeals, on motivating users to increase the strength of their passwords. We developed a field experiment involving the account registration process of a website in use in which we observed the strength of passwords chosen by users. Data were collected from 354 users in 65 countries. We found that while the interactive password strength meter and static fear appeal treatments were not effective, the interactive fear appeal treatment resulted in significantly stronger passwords. Our findings suggest that interactive fear appeals are a promising means of encouraging a range of secure behaviors in end users.	authentication;information security;interactivity;password strength	Anthony Vance;David Eargle;Kirk Ouimet;Detmar W. Straub	2013	2013 46th Hawaii International Conference on System Sciences	10.1109/HICSS.2013.196	message authentication code;cognitive password;password policy;fear appeal;field experiment;computer science;information security;password psychology;internet privacy;interactivity;world wide web;password;computer security	HCI	-52.45856450113141	64.02772093938513	21015
c702ce7ff4ba0e0bf5434ce247a019346d524f55	on demand self-organized public key management for mobile ad hoc networks	wireless links;public key cryptography;key management;web of trust;wireless network;simulation;self adjusting systems;trust authority;data mining;public key mobile ad hoc networks authentication wireless networks computer network management public key cryptography delay broadcasting costs engineering management;self adjusting systems ad hoc networks mobile radio public key cryptography;public key;mobile ad hoc networks;public key management;self organized wireless network;mobile radio;ad hoc networks;mobile ad hoc network;self organization;mobile node;self organized wireless network on demand public key management mobile ad hoc networks;mobile computing;on demand;electrical engineering electronics nuclear engineering	A mobile ad hoc network MANET is a self-organized wireless network where mobile nodes can communicate with each other without reliance on a centralized authority. Security solutions for traditional networks are not suitable for MANETs due to the infrastructureless nature and the absence of centralized administration. Key management through accessing trusted authorities or centralized servers are infeasible for MANETs due to the absence of any infrastructure, frequent mobility, and wireless link instability. In this paper we propose an on demand, self-organized, public key management for MANETs based on the existence of a web of trust between mobile nodes forming the network. The proposed scheme allows each user to create its public key and the corresponding private key, to issue certificates to neighboring nodes, and to perform public key authentication without relying on any centralized authority. Simulation results show that the proposed scheme is efficient and highly robust in stationary networks and networks with low to high mobility.	centralized computing;certificate authority;hoc (programming language);instability;key authentication;key management;network performance;public key certificate;public-key cryptography;root certificate;routing;self-organization;simulation;stationary process;web of trust	Hisham Dahshan;James Irvine	2009	VTC Spring 2009 - IEEE 69th Vehicular Technology Conference	10.1109/VETECS.2009.5073720	vehicular ad hoc network;mobile ad hoc network;computer science;internet privacy;public-key cryptography;mobile computing;computer security;computer network	Mobile	-48.942670132562704	76.47707510951653	21033
1fce05083ac5a92690190ae769a7ebd00988ec2a	image denoising in the encrypted domain	image encryption;image denoising;homomorphic processing;lattice cryptography	The increasing advance of Cloud-based solutions brings about serious privacy problems when outsourcing images for their processing in untrusted environments. One of the fundamental privacy-aware image manipulations that can be outsourced is denoising, an ubiquitous signal processing primitive with a broad set of applications. Traditional Signal Processing in the Encrypted Domain solutions cannot efficiently address this problem, as they require interactive protocols in order to cope with polynomial operations and comparisons at the same time. We propose methods based on 2-RLWE (Ring Learning with Errors) to efficiently perform the whole image denoising operation on encrypted images in a fully non-interactive way; we show how to combine homomorphic polynomial operations and thresholding without involving decryption or interaction, therefore enabling fully unattended encrypted image processing. We evaluate our solutions for real image sizes and strict security parameters, showing their practicality and feasibility.	cryptography;encryption;image processing;interactivity;learning with errors;noise reduction;outsourcing;polynomial;secret sharing;signal processing;thresholding (image processing)	Alberto Pedrouzo-Ulloa;Juan Ramón Troncoso-Pastoriza;Fernando Pérez-González	2016	2016 IEEE International Workshop on Information Forensics and Security (WIFS)	10.1109/WIFS.2016.7823916	computer science;theoretical computer science;digital image processing;internet privacy;computer security	Vision	-39.42943027699872	70.53489480271003	21072
3d606bdc2633944a839a04b81d85aae05288095d	dynamic energy allocation for coordinated optimization in enterprise workloads	file servers;optimisation;mathematical model throughput sensors time factors equations genetic algorithms telemetry;energy efficient;power aware computing business data processing file servers optimisation;power allocation;component level power distribution dynamic energy allocation coordinated optimization enterprise workloads power control server computer systems power optimization enterprise server;power distribution;power aware computing;energy performance;business data processing;power optimization;power modeling;power control	Power optimization and power control are challenging issues for server computer systems. To obtain power optimization in an enterprise server, one needs to observe temporal behavior of workloads, and how they contribute to relative variations in power drawn by different server components. This depth of analysis helps to validate and quantify various energy/performance trends important for power modeling. In this paper we discuss an adaptive infrastructure to synthesize models that dynamically estimate the throughput and latency characteristics based on component level power distribution in a server. In this infrastructure, we capture telemetry data from a distributed set of physical and logical sensors in the system and use it to train models for various phases of the workload. Once trained, system power, throughput and latency models participate in an optimization heuristics that re-distribute the power to maximize the overall performance/watt of an enterprise server. We demonstrate modeling accuracy and improvement in energy efficiency due to coordinated power allocation among server components.	expectation–maximization algorithm;genetic algorithm;heuristic (computer science);mathematical optimization;multi-objective optimization;optimization problem;penalty method;performance per watt;power optimization (eda);quality of service;requirement;response time (technology);sensor;server (computing);service-level agreement;support vector machine;throughput;transaction processing over xml	Rahul Khanna;Kshitij A. Doshi;Christian Le;John Ping;Martin Dimitrov;Mariette Awad;Melissa Stockman	2011	2011 International Conference on Energy Aware Computing	10.1109/ICEAC.2011.6136681	embedded system;real-time computing;computer science;operating system;power optimization;server farm	OS	-20.96647934657959	62.414774400680265	21092
127c769e7d3f0a34bb38f8ebb2c165dd8fa7f6fd	a modified si epidemic model for combating virus spread in wireless sensor networks		We study the dynamics of virus spread in wireless sensor networks (WSNs). We first analyze the susceptible-infective (SI) epidemic model for WSNs. In the SI model, once a sensor node is attacked by a virus, the infective node then, using normal communications, spreads the virus to its neighboring nodes, which further spread the virus to their neighbors, the process continues until the whole network fails. To combat this drawback, we propose a modified SI model by leveraging the sleep mode of WSNs to perform system maintenance. The modified SI model can improve the network anti-virus capability and flexibly adapt to different types of virus, without causing any additional hardware effort and signaling overhead. We derive the explicit analytical solutions for the modified SI model, which can capture both the spatial and temporal dynamics of the virus spread process. Extensive numerical results are presented to validate our analysis. The proposed model and analysis method are expected to be used for analysis and design of information (including virus) propagation mechanisms in distributed wireless or computer networks.		Shensheng Tang	2011	IJWIN	10.1007/s10776-011-0147-z	simulation;telecommunications;key distribution in wireless sensor networks;computer security;computer network	Embedded	-56.24996922466582	74.87887441906	21094
92de47dba5b430b8e19822c1161aa196912e5fc4	a novel comprehensive steganalysis of transmission control protocol/internet protocol covert channels based on protocol behaviors and support vector machine	network security;information hiding;protocol behaviors;covert channels;comprehensive detection;svm	Abstract#R##N##R##N#Covert channels are malicious conversations disguised in legitimate network communications, allowing information leak to the unauthorized or unknown receiver. Various network steganographic schemes that modify the header fields of transmission control protocol/Internet protocol (TCP/IP) have been proposed in recent years. People before conducted detection research based on the surface content of the header field and did not take into account the differences between the behavior characters of covert channels and the inherent behavior regularities of the header fields. Up to date, there is little comprehensive research on the steganalysis against the storage covert channels. In this paper, we focus on the detection of storage covert channels and introduce a novel comprehensive detection method based on the protocol behaviors. The protocol behavior characters are utilized to evaluate the regularities or correlations of header fields between adjacent packets according to the conventional use. First, the behavior features of the header fields in TCP/IP are extracted; a support vector machine is then applied to the behavior feature sets for discovering the existence of covert channels. Some recognized covert channel tools are detected in our detection experiment. Experimental results and discussion show that our detection method is of effectiveness. Copyright © 2014 John Wiley & Sons, Ltd.	covert channel;steganalysis;support vector machine	Yao Shen;Liusheng Huang;Xiaorong Lu;Wei Yang	2015	Security and Communication Networks	10.1002/sec.1081	support vector machine;covert channel;computer science;network security;internet privacy;information hiding;computer security;computer network	Security	-59.19021339379405	67.6968260032106	21108
7a619517ad04c1b14934e33bd0ff400cecc523b1	sliding-window forward error correction using reed-solomon code and unequal error protection for real-time streaming video		SummaryrnForward error correction (FEC) techniques are widely used to recover packet losses over unreliable networks in real-time video streaming applications. Traditional frame-level FEC encodes 1 video frame in each FEC coding window. By contrast, in the expanding-window FEC scheme, high-priority frames are included in the FEC processing of the following frames, so as to construct a larger coding window. In general, expanding-window FEC improves the recovery performance of FEC, because the high-priority frame can be protected by multiple windows and the use of a larger coding window increases the efficiency. However, the larger window size also increases the complexity of the coding and the memory space requirements. Consequently, expanding-window FEC is limited in terms of practical applications. Sliding-window FEC adopts a fixed window size in order to approximate the performance of the expanding-window FEC method, but with a reduced complexity. Previous studies on sliding-window FEC have generally adopted an equal error protection (EEP) mechanism to simplify the analysis. This paper considers the more practical case of an unequal error protection (UEP) strategy. An analytical model is derived for estimating the playable frame rate (PFR) of the proposed sliding-window FEC scheme with a Reed-Solomon erasure code for real-time non-scalable streaming applications. The analytical model is used to determine the optimal FEC configuration which maximizes the PFR value under given transmission rate constraints. The simulation results show that the proposed sliding-window scheme achieves almost the same performance as the expanding-window scheme, but with a significantly lower computational complexity.	error detection and correction;forward error correction;real-time clock;reed–solomon error correction;streaming media	Yung-Tsung Weng;Chi-Huang Shih;Yeh-Kai Chou	2018	Int. J. Communication Systems	10.1002/dac.3405	sliding window protocol;real-time computing;erasure code;frame rate;computational complexity theory;computer science;reed–solomon error correction;forward error correction;network packet	Embedded	-6.606067753193957	101.52850351975255	21126
2947c5fa5edffa3b0a4670fc66d911e3adc849fd	system architecture and characteristic analysis for the intelligent home using digital cable tv gateway	logic gates cable tv business security smart homes artificial intelligence;access control characteristic analysis system architecture intelligent home digital cable tv gateway household demand environment home gateway home networking digital cable tv set top box feature oriented modification;home networks cable television;gateway digital cable tv set top box intelligent home	Changes in household demand environment bring impact on the home networking and home gateway. To realize a bright future of the home gateway based on digital cable TV set-top box, which has many features and advantages, in this paper, it mainly discusses that feature-oriented modification for access control, and provides the preliminary framework of solution to achieve intelligent home, under the conditions of safe and manageable.	access control;home automation;set-top box;tv gateway;television set	Yue Ma	2014	2014 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting	10.1109/BMSB.2014.6873581	embedded system;cable internet access;telecommunications;engineering;digital cable;cable modem termination system;interactive television;computer network	Arch	-17.296739341348783	92.81843458129697	21170
45dcff03e6a24d66201b20429c68d998f659dea2	integrity, consistency, and verification of remote computation	forking consistency;authenticated data types;verifiable computation;distributed consistency enforcement	1. SUMMARY With the advent of cloud computing, many clients have outsourced computation and data storage to remote servers. This has led to prominent concerns about the privacy of the data and computation placed outside the control of the clients. On the other hand, the integrity of the responses from the remote servers has been addressed in-depth only recently. Violations of correctness are potentially more dangerous, however, in the sense that the safety of a service is in danger and that the clients rely on the responses. Incidental computation errors as well as deliberate and sophisticated manipulations on the server side are nearly impossible to discover with today’s technology. Over the last few years, there has been rising interest in technology to verify the results of a remote computation and to check the consistency of responses from a cloud service. These advances rely on recently introduced cryptographic techniques, including authenticated data types (ADT), probabilistically checkable proofs (PCPs), fully-homomorphic encryption (FHE), quadratic programs (QP), and more. With multiple clients accessing the remote service, a further dimension is added to the problem in the sense that clients isolated from each other need to guarantee that their verification operations relate to the same “version” of the server’s computation state. This tutorial will survey the recent work in this area and provide a broad introduction to some of the key concepts underlying verifiable computation, towards single and multiple verifiers. The aim is to give a systematic survey of techniques in the realm of verifiable computation, remote data integrity, authenticated queries, and consistency verification. The approaches rely on methods from cryptography and from distributed computing. The presentation will introduce the necessary background techniques from these fields, describe key results, and illustrate how they ensure integrity in selected cases. The tutorial consists of three parts:	authentication;cloud computing;computation;computer data storage;correctness (computer science);cryptography;data integrity;distributed computing;formal verification;homomorphic encryption;privacy;probabilistically checkable proof;server (computing);server-side	Christian Cachin	2014		10.1145/2660267.2660575	theoretical computer science;consistency model;release consistency;database;distributed computing;sequential consistency	Security	-41.125442179524526	66.0543287586072	21214
36b4a9ac1e2cc6ad161782007a4868a3ca1a0f44	topology2vec: topology representation learning for data center networking		The use of machine learning (ML) algorithms to conduct prediction or analysis tasks in a data center networking (DCN) environment is gaining increasing attention today. Recent research in traffic prediction, abnormal traffic monitoring, and routing selection has led to significant progress by making full use of historical data and improved ML models. However, such approaches face challenges when dealing with graphical data. These approaches have limited capabilities to explore the information that is hiding in the network’s topological structure. To solve these challenges, we study the problem of representation learning in DCN topologies. To serve as a bridge, we proposed a novel method, “Topology2Vec,” to learn the network topology and represent the nodes using low-dimensional vectors, which is useful in many topology-related tasks. Both network structure and performance are considered in our method to ensure that the representation can adapt to different requirements. To evaluate the effectiveness, we demonstrate this method in a controller placement problem as a typical use case using topological data from real-world data centers. The experiments show that the use of “Topology2Vec” as a premise has produced better results in terms of network latency.	algorithm;data center;dynamic circuit network;experiment;graphical user interface;machine learning;network topology;requirement;routing	Zhenzhen Xie;Liang Hu;Kuo Zhao;Feng Chun Wang;Junjie Pang	2018	IEEE Access	10.1109/ACCESS.2018.2846541	telecommunications network;task analysis;premise;control theory;network topology;distributed computing;latency (engineering);data center;computer science;feature learning;topology	Networks	-14.158317600349648	79.52291006761116	21220
3fed110a8770caeb444ebcc681098e26bfcb6b1a	software-defined networking: standardization for cloud computing's second wave	etsi;ietf;standards;onf;itu;software defined networking;service chaining;internet engineering task force;sdn;international telecommunication union;european telecommunications standards institute;editorial material;network function virtualization;cloud computing;open networking foundation	As cloud computing's second wave begins to transform the networking industry, a snapshot of developments in software-defined networking standardization suggests how its components--devices, controllers, applications, service chains, network function virtualization, and interfaces--are maturing.	apache wave;cloud computing;software-defined networking	Ying-Dar Lin;Dan Pitt;David Hausheer;Erica Johnson;Yi-Bing Lin	2014	IEEE Computer	10.1109/MC.2014.329	computer science;operating system;software engineering;delay-tolerant networking;software-defined networking;world wide web;computer network	Visualization	-16.782926819902094	87.20041277042617	21240
b0a0f236ebe534b8aacd11689d033ee1ed913519	activity spoofing and its defense in android smartphones		Smartphones have become ubiquitous in today’s digital world as a mobile platform allowing anytime access to email, social platforms, banking, and shopping. Many providers supply native applications as a method to access their services, allowing users to login directly through a downloadable app. In this paper, we first expose a security vulnerability in the Android framework that allows for third party apps to spoof native app activities, or screens. This can lead to a wide variety of security risks including the capture and silent exfiltration of login credentials and private data. We then compare current defense mechanisms, and introduce the concept of Trusted Activity Chains as a lightweight protection against common spoofing attacks. We develop a proof of concept implementation and evaluate its effectiveness and performance overhead.	arp spoofing;activity recognition;android;anytime algorithm;credential;email;information privacy;lock (computer science);login;machine code;mobile app;mobile operating system;open-source software;overhead (computing);smartphone;spoofing attack;usability testing;vulnerability (computing)	Brett Cooley;Haining Wang;Angelos Stavrou	2014		10.1007/978-3-319-07536-5_29	internet privacy;world wide web;computer security	Mobile	-54.831859343934696	60.51185796872612	21242
2394ecc7a9becadf0cc4c922409b89b051186a3d	single-path routing of time-varying traffic	probability;routing telecommunication traffic reliability engineering educational institutions performance analysis engineering management history cost function computer science linear programming;iterated rounding algorithm;randomised algorithms;iterative methods;np hard problem;telecommunication traffic;internet;optimal multipath routing;telecommunication network routing;computational complexity;randomized rounding algorithm;worst case performance bound;linear programming;ip network;ip networks;telecommunication network topology;telecommunication traffic computational complexity internet ip networks iterative methods linear programming probability randomised algorithms telecommunication network routing telecommunication network topology;ip network heuristic optimal single path intra domain routing time varying traffic profile optimal multipath routing linear programming randomized rounding algorithm iterated rounding algorithm np hard problem worst case performance bound probability isp topology;time varying traffic profile;isp topology;heuristic optimal single path intra domain routing	We consider the problem of finding a single-path intra-domain routing for time-varying traffic. We characterize the traffic variations by a finite set of traffic profiles with given non-zero probabilities. Our goal is to optimize the average performance over all of these traffic profiles. We solve the optimal multi-path version of this problem using linear programming and develop heuristic single-path solutions using randomized rounding and iterated rounding. We show through simulations that the single-path routings produced by proposed algorithms are good oblivious routing, i.e., the routing performs well in the worst case as well. We analyze our single-path heuristic (finding the optimal single-path routing is NP -Hard), and prove that the randomized rounding algorithm has a worst case performance bound of O(log(KN)/ log(log(KN))) compared to the optimal multi-path routing with a high probability, where K is the number of traffic profiles, and N number of nodes in the network. Further, our simulations show the iterated rounding heuristics perform close to the optimal multi-path routing on a wide range of topologies, including synthetic graphs, and measured ISP topologies, in both the average and the worst-case. We also show that the naive shortest-path routing on these same topologies and traffic profiles would lead to much higher congestion. Overall, these results are extremely positive since they show that in a widerange of practical situations, it is not necessary to deploy multipath routing; instead, an appropriately computed single-path routing is sufficient to provide both good average and worst-case performance.	best, worst and average case;heuristic (computer science);iteration;linear programming;multipath routing;network congestion;norm (social);randomized algorithm;randomized rounding;shortest path problem;simulation;synthetic intelligence	Abhishek Kashyap;Bobby Bhattacharjee;Richard J. La;Mark A. Shayman;Vahid Tabatabaee	2006		10.1109/GLOCOM.2006.29	mathematical optimization;static routing;the internet;equal-cost multi-path routing;computer science;linear programming;theoretical computer science;multipath routing;destination-sequenced distance vector routing;probability;np-hard;distributed computing;iterative method;computational complexity theory;computer network	Metrics	-4.77618152128273	82.54449842068962	21250
4d3f1586432a381038c106bc428f24b32f5e0508	security overhead and its impact in vanets	protocols;standards;protocol layers security overhead vehicular ad hoc networks vanet car2x communication systems traffic safety critical driver assistance systems safeguard communication authorization authority certificate message exchange;security containers cams vehicular ad hoc networks protocols standards computer aided manufacturing;cams;vehicular ad hoc networks;computer aided manufacturing;vanet cross layer optimization security;security;vehicular ad hoc networks intelligent transportation systems protocols telecommunication security;containers	Vehicular ad hoc networks (VANETs), often called Car2X communication systems, are about to enter the mass market in upcoming years. They are intended to increase traffic safety by enabling new safety critical driver assistance systems. This also means that strong security mechanisms are required to safeguard communication within VANETs. However, standardized security mechanisms lead to significant overhead in terms of data rate requirement and delay. Prior work has focused on reducing the overhead by advanced strategies for pseudonym and authorization authority certificate exchange. However, we find that this is not enough to enable reliable message exchange in VANETs. Various other sources of overhead caused by security mechanisms in VANETs are identified in the provided analysis. Thereby, we find cross layer and cross message dependencies. In combination with the non-fragmentation property of VANET messages, such dependencies are discovered to lead to massive dropping of packets due to maximum size violations at low protocol layers. Thus, we develop a method for cross layer on demand content assembling for VANET messages, which can avoid the size limit violations without preventing individual layers from disseminating their variable length data sets.	architecture design and assessment system;authorization;certificate authority;denial-of-service attack;fork (software development);fragmentation (computing);hoc (programming language);overhead (computing);uncompressed video	Sebastian Bittl;Karsten Roscher;Arturo A. Gonzalez	2015	2015 8th IFIP Wireless and Mobile Networking Conference (WMNC)	10.1109/WMNC.2015.17	vehicular ad hoc network;engineering;internet privacy;computer security;computer network	Mobile	-48.93609014430741	73.47203582764472	21264
4fd643182643a1cfe6aec3ce11dd5292814a4e6f	informing security indicator design in web browsers	user evaluation;extended validation ev certificate indicators;information security;browser interface;qualitative study;usable security	In this paper, we aim at providing conceptual and empirical insights to the design of security indicators in web browsers. In examining why security indicators in web browsers fail to warn users about web frauds, we propose affordance-based principles for our new design of web authentication indicators. Following these principles, we present a new design for Extended Validation (EV) certificate interface in the Firefox browser. We then conduct an exploratory qualitative study to evaluate three different versions of EV indicators. Our findings offer some preliminary implications for the designs of more effective web authentication indicators.	authentication;extended validation certificate;firefox	Pan Shi;Heng Xu;Xiaolong Zhang	2011		10.1145/1940761.1940839	web application security;web modeling;content security policy;web design;engineering;web navigation;internet privacy;world wide web;computer security	HCI	-55.74232140151324	60.95193056348462	21296
3da82c5bd8235de29b9523e8cab61a845dd09eb9	understanding the spreading patterns of mobile phone viruses	virus informatique;mobile radiocommunication;telecommunication sans fil;call graph;market share;telephone portable;securite informatique;bluetooth technology;transmission message;technologie bluetooth;communication service mobile;radiocommunication service mobile;message transmission;mobile phone;computer security;wireless communication;social network;virus informatico;radio link;telefono movil;phase transition;telecomunicacion sin hilo;seguridad informatica;multimedia communication;faisceau hertzien;mobile communication;computer virus;mobility management;transition phase;phase transitions;gestion de movilidad;transicion fase;haz hertziano;caracteristique propagation;gestion mobilite;radiocomunicacion servicio movil;communication multimedia;multimedia messaging service;caracteristica propagacion;communication pattern;transmision mensaje;propagation characteristic;wireless telecommunication	We modeled the mobility of mobile phone users in order to study the fundamental spreading patterns that characterize a mobile virus outbreak. We find that although Bluetooth viruses can reach all susceptible handsets with time, they spread slowly because of human mobility, offering ample opportunities to deploy antiviral software. In contrast, viruses using multimedia messaging services could infect all users in hours, but currently a phase transition on the underlying call graph limits them to only a small fraction of the susceptible users. These results explain the lack of a major mobile virus breakout so far and predict that once a mobile operating system's market share reaches the phase transition point, viruses will pose a serious threat to mobile communications.	antiviral agents;bluetooth;breakout box;call graph;graphon;mobile malware;mobile operating system;mobile phone;multimedia;phase transition;virus	Pu Wang;Marta C. González;R. A. Hidalgo CesarA.Hidalgo;Albert-László Barabási	2009	Science	10.1126/science.1167053	phase transition	Mobile	-13.955490067089269	98.3125020925881	21299
5ac13bf68d9f944c14079230cba03a3da6523a42	an integrated network management solution for multi-technology domain networks	internet protocol;multiplexage longueur onde;gestion reseau telecommunication;architecture systeme;protocolo internet;flexibilidad;protocole internet;computer network management;multimedia communication;arquitectura sistema;flexibilite;network management;system architecture;communication multimedia;gestion reseau ordinateur;multiplaje longitud onda;flexibility;telecommunication network management;wavelength division multiplexing	In today's network, several transport technologies have to be managed to work in close conjunction. Until recently, service providers needed separate, single-vendor solutions or interfaces to manage these different technology areas. This letter proposes an integrated transport network management solution of domain-specific and inter-domain network management systems. Both are based on the same generic, component-based management system that features vendor-independent interfaces and dramatically reduces development efforts.	common object request broker architecture;component-based software engineering;inter-domain;software suite;systems architecture	Geert Jan Hoekstra;Willem A. Romijn;Harold C. H. Balemans;Abdelkader Hajjaoui;Gijs van Ooijen	2002	Bell Labs Technical Journal	10.1002/bltj.17	internet protocol;network management;element management system;simulation;network management station;telecommunications;computer science;engineering;network management application;structure of management information;wavelength-division multiplexing;computer network;systems architecture	HPC	-14.627453471161303	95.2060206799095	21315
6f69e61219a3d42264241e65bef5b6be4e3ad60e	exposing mobile malware from the inside (or what is your mobile app really doing?)		It is without a doubt that malware especially designed for modern mobile platforms is rapidly becoming a serious threat. The problem is further multiplexed by the growing convergence of wired, wireless and cellular networks, since virus writers can now develop sophisticated malicious software that is able to migrate across network domains. This is done in an effort to exploit vulnerabilities and services specific to each network. So far, research in dealing with this risk has concentrated on the Android platform and mainly considered static solutions rather than dynamic ones. Compelled by this fact, in this paper, we contribute a fully-fledged tool able to dynamically analyze any iOS software in terms of method invocation (i.e., which API methods the application invokes and under what order), and produce exploitable results that can be used to manually or automatically trace software’s behavior to decide if it contains malicious code or not. By employing real life malware we assessed our tool both manually, as well as, via heuristic techniques and the results we obtained seem highly accurate in detecting malicious code. D. Damopoulos · G. Kambourakis · S. Gritzalis Department of Information and Communication Systems Engineering, University of the Aegean, GREECE E-mail: ddamop@aegean.gr G. Kambourakis E-mail: gkamb@aegean.gr S. Gritzalis E-mail: sgritz@aegean.gr S. O. Park School of Computer Science & Engineering, Chung-Ang University, SOUTH KOREA E-mail: sopark3@gmail.com	android;application programming interface;event (computing);heuristic;machine learning;mobile app;mobile device;mobile malware;multiplexing;password;peer-to-peer;real life;sensor;software propagation;subroutine;systems engineering;threat (computer);undocumented feature;vulnerability (computing);ios	Dimitrios Damopoulos;Georgios Kambourakis;Stefanos Gritzalis;Sang Oh Park	2014	Peer-to-Peer Networking and Applications	10.1007/s12083-012-0179-x	computer science;operating system;cryptovirology;database;internet privacy;world wide web;computer security;computer network	Security	-56.88489386040584	60.79991736150744	21318
0f382517bb4bd1c937c55e78b88f84f57e29cf33	security-driven scheduling algorithms based on eigentrust in grid	scheduling algorithm processor scheduling grid computing security distributed computing helium power system protection fault tolerance algorithm design and analysis educational institutions;helium;processor scheduling;trust management;distributed computing;trust model;scheduling algorithm;fault tolerance;power system protection;task scheduling;security;grid computing;high performance;algorithm design and analysis;eigenvectors	Grid computing provides a virtual framework for controlled sharing of resources across institutional boundaries. Recently, trust has been recognized as an important factor for scheduling in Grid. Trust is a complex subject relating to such as reliability, honesty, and competence of the trusted entity. Trust value computing becomes more difficult in Grid as the nodes are independent and distributed, and with a securityaware task execution model, task scheduling is crucial to achieving high performance. In this paper, we present a trust model wherein each node is assigned a trust value that reflects the transaction experiences. Eigenvector is used to calculate the trust value and distribute eigentrust algorithm is modified according to the characteristic of the Grid. Furthermore, trust managers are set to guide scheduling, and securitydriven algorithms are proposed to ensure the security of the executions. Simulations are performed to evaluate the performance of the algorithms.	algorithm;computer simulation;eigentrust;grid computing;scheduling (computing)	Keqin Li;Yan He;Xiaoling Liu;Ying Wang	2005	Sixth International Conference on Parallel and Distributed Computing Applications and Technologies (PDCAT'05)	10.1109/PDCAT.2005.212	fair-share scheduling;fixed-priority pre-emptive scheduling;algorithm design;fault tolerance;parallel computing;real-time computing;dynamic priority scheduling;eigenvalues and eigenvectors;computer science;rate-monotonic scheduling;information security;theoretical computer science;two-level scheduling;database;distributed computing;lottery scheduling;helium;power-system protection;round-robin scheduling;scheduling;grid computing	HPC	-16.573786705020442	61.14948614615369	21320
28653d8fa2d29cfdedf750560781c001739e45d7	a proposal to realize the provision of secure android applications -- adms: an application development and management system	databases;androids;smart phones;event notification code secure android applications adms application development market manager android os security manager security related event;smart phones security databases mobile communication androids humanoid robots proposals;security manager android smartphone malicious android application;android smartphone;security manager;humanoid robots;mobile communication;smart phones operating systems computers security of data;security;proposals;security of data;operating systems computers;malicious android application	"""To realize the provision of secure Android applications, this paper proposes an application development and management system, or ADMS for short, that is operated and maintained by application developers and the market manager. ADMS requires (i) Android OS to be equipped with a """"security manager"""", (ii) all application developers to embed a code for event notification into applications to tell every event to the security manager whenever an application launches a security-related event, and (iii) market manager to remove all such applications that don't include the event notification code."""	android;event (computing);information security;malware;management system;operating system;security management	Harunobu Agematsu;Junya Kani;Kohei Nasaka;Hideaki Kawabata;Takamasa Isohara;Keisuke Takemori;Masakatsu Nishigaki	2012	2012 Sixth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing	10.1109/IMIS.2012.143	embedded system;security management;mobile telephony;computer science;humanoid robot;information security;operating system;internet privacy;computer security;computer network	SE	-50.55552724435807	63.04136481981962	21333
93cd186e3af4aacd62fc540b5ccb9dbfd3f5939b	an improved secure data communication using blind source separation and chaos	encryption;secure data communication;chaos;blind source separation;specific mixing;random sequences;data communication blind source separation chaotic communication source separation cryptography data security paper technology independent component analysis computer science data engineering;security performance;data communication;cryptography;security performance secure data communication blind source separation chaos generation pseudorandom sequence encryption specific mixing;pseudorandom sequence;chaos generation;correlation;random sequences blind source separation chaos generators cryptography data communication;chaos generators;blind source separation bss	This paper proposes an improved secure data communication [1] by using the concept of underdetermined BSS problem and chaos. The purpose of the chaos is to generate the pseudorandom sequence, which in turn is used for encryption and specific mixing. The proposed method has high security performance. The experimental results illustrate that performance of this is highly secured.	blind signal separation;chaos theory;cryptography;encryption;lossless compression;pseudorandom number generator;source separation	Anil Kumar;Sucheta Sushan Ghose;M. K. Ghose	2009	2009 11th IEEE International Symposium on Multimedia	10.1109/ISM.2009.77	computer science;cryptography;theoretical computer science;machine learning;distributed computing;computer security;correlation;encryption	Arch	-41.778965497560364	83.32716176098259	21350
b9c9a37059ba3c1e59c5625560711549e5c26283	analysis on the generalization of proxy signature	discrete log problem;integer factorization;elliptic curve discrete log problem;bilinear pairings;proxy signature;diffie hellman problem	Proxy signature is a specific digital signature, which allows an original signer to delegate her signing capability to proxy signer and then, the later can perform message signing on behalf of the former. Authentication is a desired property in cryptographic protocols. The proxy signature provides this property. In this article, we cover the research progress made on proxy signature and investigate its relationships with other existing signature schemes having continuous progress until now. We also provide real-world scenarios, to understand better the situations, where these schemes are applicable for security purposes. We analyze the security properties of existing schemes and make a comparison among them on the basis of different number theoretic problems. Some open problems are also discussed, to the best of our knowledge. In addition, we provide some future directions, which can be used as a hint to work further in the area of proxy signature. We hope that this article will provide a ready reference to work in the related area. Copyright © 2012 John Wiley & Sons, Ltd.	authentication;blind signature;cryptographic protocol;cryptography;designated verifier signature;diffie–hellman problem;digital light processing;digital signature;elliptic curve cryptography;graph coloring;handbook;integer factorization;john d. wiley;ring signature;theory	Namita Tiwari;Sahadeo Padhye	2013	Security and Communication Networks	10.1002/sec.581	ring signature;discrete logarithm;computer science;integer factorization;theoretical computer science;blind signature;schnorr signature;computer security;algorithm	Security	-36.74852128567977	74.32379400949273	21378
5ba6c75601462bff9adf881f2a3aaaf826a04099	translation of structure of management information version 2 (smiv2) mib modules to yang modules		YANG is a data modeling language used to model configuration and state data manipulated by the Network Configuration Protocol (NETCONF), NETCONF remote procedure calls, and NETCONF notifications. The Structure of Management Information (SMIv2) defines fundamental data types, an object model, and the rules for writing and revising MIB modules for use with the Simple Network Management Protocol (SNMP). This document defines a translation of SMIv2 MIB modules into YANG modules, enabling read-only (config false) access to data objects defined in SMIv2 MIB modules via NETCONF. Information about the current status of this document, any errata, and how to provide feedback on it may be obtained at in effect on the date of publication of this document. Please review these documents carefully, as they describe your rights and restrictions with respect to this document. Code Components extracted from this document must include Simplified BSD License text as described in Section 4.e of the Trust Legal Provisions and are provided without warranty as described in the Simplified BSD License. This document may contain material from IETF Documents or IETF Contributions published or made publicly available before November 10, 2008. The person(s) controlling the copyright in some of this material may not have granted the IETF Trust the right to allow modifications of such material outside the IETF Standards Process. Without obtaining an adequate license from the person(s) controlling the copyright in such materials, this document may not be modified outside the IETF Standards Process, and derivative works of it may not be created outside the IETF Standards Process, except to format it for publication as an RFC or to translate it into languages other than English.	bsd;data modeling;document;management information system;mebibyte;modeling language;read-only memory;remote procedure call;simple network management protocol;structure of management information;yang	Jürgen Schönwälder	2012	RFC	10.17487/RFC6643	computer science;theoretical computer science;database;world wide web	Web+IR	-26.75924980817572	88.81555779854884	21380
5927f0420939ed385f0c107840dc2b322494461f	image-based anomaly detection technique: algorithm, implementation and effectiveness	image sampling;experimentation with real networks testbed;network measurement;eye;human eye;stochastic process;image processing;data compression;anomaly detection;real time;video compression;motion estimation;network measurement approach;neyman pearson;video coding data compression data visualisation eye image sampling image sequences motion estimation object detection telecommunication traffic;video coding;data visualisation;large scale;telecommunication traffic;passive monitoring;statistical analysis;network traffic analysis;stochastic processes;motion prediction technique large scale network attack network traffic analysis netviewer network measurement approach anomaly detection data visualization passive monitoring multidimensional packet header data series of sample frame sequence human eye image processing video compression;network traffic;telecommunication traffic video compression large scale systems data visualization monitoring humans image processing layout multidimensional systems testing;data visualization;netviewer;network measurements;experimentation with real networks testbeds;large scale network attack;frame sequence;series of sample;motion prediction technique;stochastic processes experimentation with real networks testbeds image processing network anomaly detection network measurements statistical analysis;multidimensional packet header data;change analysis;network anomaly detection;object detection;image sequences	"""The frequent and large-scale network attacks have led to an increased need for developing techniques for analyzing network traffic. This paper presents NetViewer, a network measurement approach that can simultaneously detect, identify, and visualize attacks and anomalous traffic in real-time by passively monitoring packet headers. We propose to represent samples of network packet header data as frames or images. With such a formulation, a series of samples can be seen as a sequence of frames or video, revealing certain kinds of attacks to the human eye. This enables techniques from image processing and video compression to be applied to the packet header data to reveal interesting properties of traffic. We show that """"scene change analysis"""" can reveal sudden changes in traffic behavior or anomalies. We also show that """"motion prediction"""" techniques can be employed to understand the patterns of some of the attacks. We show that it may be feasible to represent multiple pieces of data as different colors of an image enabling a uniform treatment of multidimensional packet header data. We compare the effectiveness of NetViewer with classical detection theory-based Neyman-Pearson test"""	algorithm;anomaly detection;color;data compression;detection theory;framing (world wide web);image processing;network packet;network traffic control;real-time clock;sampling (signal processing);tracing (software);video;video content analysis;video processing	Seong Soo Kim;A. L. Narasimha Reddy	2006	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2006.877215	data compression;stochastic process;computer vision;simulation;telecommunications;computer science;data visualization;statistics;computer network	Networks	-61.218834322191235	65.94146501420302	21388
e92e5406df818d9298c3ebccf09ba38806556f88	on track of sigfox confidentiality with end-to-end encryption		The last years brought many novel challenges for the Internet of Things (IoT). Low capital and operational expenditures, massive deployments of devices, reliability and security are among the most crucial ones. The recently introduced Low-power wide area (LPWA) technologies provide one possible way of addressing these challenges. In the current paper, we focus on one of the most mature LPWA technology, namely Sigfox. We provide a brief security assessment of this technology and highlight the main security imperfections. Notably, we also consider the recent changes introduced in the last revision of the Sigfox specification released in the fourth quarter of 2017. Importantly, this paper discusses the highlighted issues and compares three selected cryptographic encryption solutions (AES, ChaCha and OTP) in respect to the main IoT triad of performance, security and cost. We investigate the encryption solutions and characterize their energy consumption in a real-life implementation. The results herein presented are useful for understanding the cost of enabling security aspects and enable selecting the most efficient encryption protocol.	confidentiality;cryptographic protocol;cryptography;end-to-end encryption;internet of things;low-power broadcasting;real life;wiki	Radek Fujdiak;Petr Blazek;Konstantin Mikhaylov;Lukas Malina;Petr Mlynek;Jiri Misurec;Vojtech Blazek	2018		10.1145/3230833.3232805	computer security;lpwan;confidentiality;cryptographic protocol;cryptography;encryption;symmetric-key algorithm;one-time pad;computer science;end-to-end encryption	Security	-50.29086431459854	71.3125823390588	21425
4919c9b8f0c3c9d4de39c297f8b8477081287988	abstract accountability language: translation, compliance and application	verification;grammar;online services;health care use case abstract accountability language services based economy on line services data privacy data disclosures issues translational semantics tspass theorem prover;tspass prover;context grammar authorization hospitals online services data privacy syntactics;hospitals;semantics;health care data privacy;first order temporal logic;data privacy;syntactics;verification accountability first order temporal logic semantics tspass prover;authorization;accountability;context	With the rise of the services-based economy and the democratization of on-line services, more and more users (individual and/or business) use on-line applications in their daily lives. Usually personal data transits between different actors involved in a service's delivery chain (e.g. application/storage service providers) and thus might raise some privacy issues. Accountability, which is the property of an entity of being responsible for its acts, can help mitigate data privacy and data disclosures issues in such applications. In this paper, we propose a translational semantics for our accountability language and we present some expected properties. We introduce a natural criterion to achieve the accountability compliance of two clauses and few heuristics to speed up the resolution time. We demonstrate the feasibility of our verification process with a realistic health care use case and the TSPASS theorem prover.	automated theorem proving;computer science;diagram;expect;first-order predicate;gadget (computer science);heuristic (computer science);information privacy;interaction;mind;online and offline;personally identifiable information;semantics (computer science);software system;temporal logic;user (computing)	Walid Benghabrit;Hervé Grall;Jean-Claude Royer;Mohamed Sellami	2015	2015 Asia-Pacific Software Engineering Conference (APSEC)	10.1109/APSEC.2015.14	verification;computer science;knowledge management;data mining;grammar;database;semantics;authorization	SE	-43.58435131730325	61.68213619357291	21483
5b2a282cadb3f9ad2095c2edb1d342b173249643	feature engineering for detection of denial of service attacks in session initiation protocol		The Session Initiation Protocol SIP is a text-based protocol, which defines the messaging between the SIP entities to establish, maintain, and terminate a multimedia session. Because of the text- and transaction-based nature of the SIP protocol, it encounters various types of malformed message and resource depletion attacks. In this paper, we study the security concerns of the SIP-based systems, and propose a feature set for it. Engineered features are derived from the SIP header fields in real time detecting the deviation of the input traffic from normal state. These features are built at three levels: packet, transaction, and dialog. The designed features can accurately detect the SIP known attacks. Moreover, because we successfully model the state machine of SIP during its normal behavior, we can also identify the unknown attacks. To study the effectiveness of the engineered feature set, we employ them in a sample one-class support vector machine classifier. We evaluate the engineered features on three different datasets with various types of attack scenarios including resource depletion and authentication and brute force attacks. The impact of these attack scenarios on the designed features are shown in different test cases to demonstrate the effectiveness of our proposed feature set. Copyright © 2014 John Wiley & Sons, Ltd.	denial-of-service attack;feature engineering	Hassan Asgharian;Ahmad Akbari;Bijan Raahemi	2015	Security and Communication Networks	10.1002/sec.1106	computer science;internet privacy;world wide web;computer security	Security	-58.959724533665245	64.83551648155208	21491
bd04fb6bf534e965d834dbca1d6d183da72e3ae8	use of multiple networks in the xerox network system	protocols;information retrieval;computer networks;computer architecture;internet;workstations;ip networks;intelligent networks;networked systems;ethernet networks;intelligent networks ip networks internet ethernet networks protocols information retrieval workstations computer networks computer architecture costs	Managing information is an integral part of today's office, and Xerox's Network System is a distributed office information system that provides tools for doing this. With these tools, office personnel can create, store, retrieve, display, modify, reproduce, and share information in ways that encourage creativity and increase productivity. Workstations like Star help to simplify creation, modifiying, and displaying information. I Electronic filing, printing, database, and mail systems simplify storing, retrieving, reproducing, and sharing information. With the continuing improvements in the price/performance ratio of computing and communications, the structure of computerized office information systems is changing. We no longer need large centralized systems to realize economies of scale. Instead, we can push intelligence back into the workstation, and decentralize resources by function into dedicated servers to create a system that is a collection of loosely coupled elements tied together by a communication network. The Network System is just such a system, in which expensive resources are shared and information is exchanged among users. Within an organization, we typically find natural localities of activity and interaction. Interaction between localities generally decreases as they are farther apart. While the nature and characteristics of the interaction between close and distant stations are different, both are essential to the functioning of an organization. The Ethernet local computer network24 provides digital transmission of data, and satisfies most of the requirements for local office communications. The Ethernet, however, was designed in the context of an overall network architecture and is viewed as one component of an internetwork communication system that serves many diverse devices connected to many different kinds of networks.5-8 An internetwork architecture allows the communication system to be reconfigured to satisfy the immediate and future requirements of the user. For example, the Network System may have only one Ethernet initially and then be expanded (without software modification) to contain two or more Ethernets, which are interconnected directly or via other communication media, whose choice depends on the volume, frequency, and dispersion ofcommunications. Public and private packet-switching facilities can be used to carry higher dispersions of low-volume office communication, and as facilities for lower cost, higher rate, modemless digital transmission become available, they can be used to carry higher volumes of data. Of concern in this article are the major features of the Network System's internetwork communication system, in particular, its ability to use different kinds of networks (Figure 1). Protocol layers above the internetwork communication system permit different kinds of office services to be added as the need arises, thereby allowing an organization to minimize the initial purchase cost and to control any system expansion. The article also describes how the Network System can be connected to systems (network-based or stand-alone) from other vendors that obey different protocols by using protocol conversion gateways at different levels.	centralized computing;database;dedicated hosting service;floor and ceiling functions;information system;internetworking;loose coupling;network architecture;network packet;packet switching;printing;requirement;telecommunications network;workstation	Yogen K. Dalal	1982	Computer	10.1109/MC.1982.1653861	embedded system;communications protocol;intelligent network;the internet;workstation;ethernet flow control;computer science;ata over ethernet;operating system;distributed computing;computer network	Networks	-20.837798389287723	92.73432032744446	21539
1178f56238e6475a1196db5b169af8f910044fb9	dnis: a middleware for dynamic multiple network interfaces scheduling	available bandwidth;resource utilization;mobile device;scheduling algorithm;operating system;intelligent network;middleware;parameter estimation;network interface;newsletter	Wireless Intelligent Networks Center, Nile University, Smart Village, Egypt Many of today's mobile devices are equipped with multiple network interfaces that can be used to connect to the Internet, including Ethernet, WiFi, 3G, and Bluetooth. However, current operating systems, such as Windows and Linux, typically choose only one of the available network interfaces and assign all the traffic to it, even if more than one is connected to the Internet. This results in an obvious under utilization of the available bandwidth. Different bandwidth aggregation techniques suggested altering different layers of the TCP/IP stack which requires applying modifications on the client's stack and/or the cloud, which cannot be widely deployed easily. In this work, we present DNIS, a networking middleware that achieves bandwidth aggregation using per-TCP connection scheduling on different interfaces in a way that is transparent to both the user and the applications. DNIS is composed of two main components: (1) a parameter estimator that estimates the applications' characteristics and requirements as well as interfaces' properties; (2) a scheduler that uses the estimated parameters to assign different TCP connections to network interfaces. We present an implementation for DNIS for the Windows OS and show its performance for different scheduling algorithms. Our initial results show significant enhancement of the overall device's throughput, up to 54%, increasing resource utilization and enhancing the user's experience.	algorithm;bluetooth;dialed number identification service;internet protocol suite;linux;microsoft windows;middleware;mobile device;network interface controller;operating system;requirement;scheduling (computing);throughput	Ahmed Saeed;Karim Habak;Mahmoud Fouad;Moustafa Youssef	2010	Mobile Computing and Communications Review	10.1145/1854219.1854226	embedded system;intelligent network;in situ resource utilization;real-time computing;telecommunications;computer science;network interface;operating system;middleware;mobile device;estimation theory;scheduling;computer network	Mobile	-17.511471592236845	81.13398523526118	21551
1b40c5b1499fe087bfc1a9614dd2e41fdd1ab2be	wide-area lustre file system using lnet routers		Scientific and big data computations are increasingly being distributed across wide-area networks, and they often require access to remote files. The file systems that are directly mounted over wide-area networks transparently support such computations, and also obviate the need for special purpose file transfer tools. In typical distributed file systems, the access is limited to local sites, and in particular, the reach of Lustre file system implemented over InfiniBand (IB) is limited to at most tens of miles due to 2.5ms latency bound. We describe LNet router methods that connect IB Lustre file system to remote Ethernet clients over wide-area networks. We collect extensive Lustre throughput measurements over 10Gbps connections with 0–366ms round-trip times. They demonstrate that Gbps throughput can be sustained over connections spanning the globe. We present Lustre throughput profiles over local and wide-area connections, which show the effects of various buffers and credits; in particular, they highlight the throughput limits for large transfers over wide-area connections. Furthermore, the measurements show the positive effects of pipelining in achieving higher throughput for successively file transfers compared to rates indicated by IOzone benchmark rates.	benchmark (computing);big data;computation;data rate units;emulator;file spanning;file transfer;iozone;infiniband;lustre (programming language);pipeline (computing);router (computing);throughput	Nageswara S. V. Rao;Neena Imam;Jesse Hanley;Sarp Oral	2018	2018 Annual IEEE International Systems Conference (SysCon)	10.1109/SYSCON.2018.8369541	latency (engineering);throughput;lustre (file system);big data;computer network;infiniband;pipeline (computing);file transfer;ethernet;computer science	HPC	-14.56583866580449	80.48068988886216	21581
8662c5986698ee5cdb514084d91b216b7d1bf31c	greening iot with fog: a survey		The current growth in Internet services, mobile devices, and machine-to-machine (M2M) technologies is providing the building blocks for the Internet of Things (IoT) as it is being applied across all industry sectors. With ongoing proliferation of IoT applications, a new platform called Fog/edge computing, in addition to Cloud computing, is being developed to address requirements such as bandwidth, latency and location awareness. As with previous many telecommunication systems, energy consumption concerns in IoT have been deferred to the point that it may become a bottleneck in the future. This work conducts a survey of existing literature addressing IoT energy consumption growth. We firstly highlight the factors and technologies in the system design, application layer and network virtualizations which lead to higher or lower energy consumption of an IoT service. Furthermore, we report strategies that can help to alleviate power consumption of IoT applications and services using Fog computing. Our objective is to provide a survey for network designers and policy makers who wish to gain an insight into deploying energy-efficient IoT applications.	bottleneck (engineering);cloud computing;computation;edge computing;fog computing;internet of things;location awareness;machine to machine;microgrid;mobile device;network planning and design;osi model;real-time clock;requirement;sensor;systems design;web service	Fatemeh Jalali;Safieh Khodadustan;Chrispin Gray;Kerry Hinton;Frank Suits	2017	2017 IEEE International Conference on Edge Computing (EDGE)	10.1109/IEEE.EDGE.2017.13	the internet;application layer;energy consumption;cloud computing;systems design;mobile device;location awareness;computer network;computer security;edge computing;engineering	EDA	-25.72540010067157	67.43583148519842	21591
36ae8314fb50e164fce92abf993af4ab90c2a49d	a governance architecture for self-adaption & control in iot applications		The “Internet of Things” has become a reality with projections of 28 billion connected devices by 2021. Much R&D is currently focused on creating methods to efficiently handle an influx of data. Flow based programming, where data is moved through a network of processes, is a model well suited to IoT. This paper proposes a dynamic, distributed data processing architecture, utilizing a flow based programming inspired approach. We illustrate a distributed configuration management protocol, which coordinates processing between edge devices and a central controller. Our proposed architecture is evaluated in a vehicle use case that predicts driver alertness. We present a scenario for reducing data on vehicular networks when the connectivity options are limited, while maintaining computational accuracy.	computation;configuration management;data mining;dataflow;distributed computing;internet of things;server (computing);transmitter;scikit-learn	Roger Young;Sheila Fallon;Paul Jacob	2018	2018 5th International Conference on Control, Decision and Information Technologies (CoDIT)	10.1109/CoDIT.2018.8394824	vehicular ad hoc network;flow-based programming;edge device;control theory;architecture;configuration management;data modeling;distributed computing;computer science;data processing	Robotics	-18.94121254382648	80.35483658808049	21603
6193e53996791fc3b07154fc4b4e25885ec44f3b	carbon-aware online control of geo-distributed cloud services	google;geo distributed datacenters;minimization;carbon dioxide;online control carbon reduction load balancing capacity right sizing geo distributed datacenters three way tradeoff;lyapunov optimization techniques carbon aware online control geodistributed cloud services datacenter carbon emission cloud service providers power consumption carbon footprint cloud running electricity cost minimization carbon emission minimization service level agreement sla requirement emission reduction budget;geographic information systems cloud computing computer centres distributed processing environmental economics;servers;carbon dioxide servers google facebook correlation carbon tax minimization;three way tradeoff;facebook;online control;load balancing;capacity right sizing;correlation;carbon tax;carbon reduction	Recently, datacenter carbon emission has become an emerging concern for the cloud service providers. Previous works are limited on cutting down the power consumption of datacenters to defuse such a concern. In this paper, we show how the spatial and temporal variabilities of the electricity carbon footprint can be fully exploited to further green the cloud running on top of geographically distributed datacenters. Specifically, we first verify that electricity cost minimization conflicts with carbon emission minimization, based on an empirical study of several representative geo-distributed cloud services. We then jointly consider the electricity cost, service level agreement (SLA) requirement, and emission reduction budget. To navigate such a three-way tradeoff, we take advantage of Lyapunov optimization techniques to design and analyze a carbon-aware control framework, which makes online decisions on geographical load balancing, capacity right-sizing, and server speed scaling. Results from rigorous mathematical analysis and real-world trace-driven evaluation demonstrate the effectiveness of our framework in reducing both electricity cost and carbon emission.	cloud computing;data center;image scaling;load balancing (computing);lyapunov fractal;lyapunov optimization;mathematical optimization;server (computing);service-level agreement	Zhi Zhou;Fangming Liu;Ruolan Zou;Jiangchuan Liu;Hong A Xu;Hai Jin	2016	IEEE Transactions on Parallel and Distributed Systems	10.1109/TPDS.2015.2504978	carbon neutrality;real-time computing;simulation;computer science;load balancing;operating system;carbon dioxide;distributed computing;computer security;correlation;server;computer network	Metrics	-21.22950302215056	62.900880196776576	21616
55b4388a1b92934a3721e820a8edc9b2aa087fbd	a one-time password authentication scheme for secure remote access in intelligent home networks	remote access;controle acces;remote control;reseau communication;access network;acceso remoto;equipement menager;domestic appliances;one time password;ingenierie connaissances;control inteligente;reseau acces;acces a distance;authentication;securite informatique;cle publique;automatizacion domestica;intelligence artificielle;telecommande;vulnerability;intelligent control;remote operation;authentification;service utilisateur;computer security;red acceso;home network;vulnerabilite;vulnerabilidad;autenticacion;public key;mot de passe;criptografia;cryptography;teleaccion;seguridad informatica;password;llave publica;reseau intelligent;cost effectiveness;artificial intelligence;cryptographie;commande intelligente;access control;intelligent networks;control remoto;inteligencia artificial;servicio usuario;equipo domestico;domotique;user service;user authentication;red de comunicacion;communication network;contrasena;controle intelligent;teleoperation;home automation;key distribution;knowledge engineering	One of the important services that intelligent home networks provide is to remotely control home appliances in home network. However, the remote control service causes intelligent home networks to have various security threats. Thus, for the service, intelligent home networks should provide strong security services, especially user authentication. In this paper, we provide a public key based one-time password authentication scheme for secure remote access in intelligent home networks. To provide 2-factor strong authentication conveniently and cost effectively, we adopt and enhance YEH-SHEN-HWANG’s authentication scheme. Since our scheme uses a server-side public key to addresses the vulnerabilities of YEH-SHEN-HWANG’s scheme, it can securely perform user authentication, server authentication and session key distribution without any pre-shared secret, while defending against server compromise.	authentication;home automation;one-time password	Ilsun You	2006		10.1007/11893004_100	password policy;chip authentication program;s/key;telecommunications;challenge–response authentication;engineering;authentication protocol;internet authentication service;lightweight extensible authentication protocol;multi-factor authentication;world wide web;computer security;challenge-handshake authentication protocol	Crypto	-47.75514949112914	69.35694724132341	21638
49070ec287f92640773d6cd72165287f93d5da70	reliable location-based services from radio navigation systems	facility regulation and control;models theoretical;radio waves;signal processing computer assisted;ships;security measures;cellular phone;location based security;geographic information systems;location tag;reproducibility of results;humans;loran c	Loran is a radio-based navigation system originally designed for naval applications. We show that Loran-C's high-power and high repeatable accuracy are fantastic for security applications. First, we show how to derive a precise location tag--with a sensitivity of about 20 meters--that is difficult to project to an exact location. A device can use our location tag to block or allow certain actions, without knowing its precise location. To ensure that our tag is reproducible we make use of fuzzy extractors, a mechanism originally designed for biometric authentication. We build a fuzzy extractor specifically designed for radio-type errors and give experimental evidence to show its effectiveness. Second, we show that our location tag is difficult to predict from a distance. For example, an observer cannot predict the location tag inside a guarded data center from a few hundreds of meters away. As an application, consider a location-aware disk drive that will only work inside the data center. An attacker who steals the device and is capable of spoofing Loran-C signals, still cannot make the device work since he does not know what location tag to spoof. We provide experimental data supporting our unpredictability claim.	authentication;biometrics;data center;disk storage;extractor device component;extractors;fuzzy extractor;global positioning system;location awareness;location-based service;loran-c;navigation;randomness extractor;theft	Di Qiu;Dan Boneh;Sherman C. Lo;Per K. Enge	2010		10.3390/s101211369	embedded system;telecommunications;engineering;electrical engineering;radio wave;geographic information system;optics;world wide web;computer security;loran-c;physics	HCI	-51.23518615624614	66.72730518732533	21639
755dac836d266de38f17db1e14070e57fdea1c4a	millimeter wave wireless communications (rappaport, t., et al; 2014) [book review]	book reviews telecommunication network management millimeter wave wireless communication;millimeter wave wireless communication;book reviews;telecommunication network management	This book presents broad information in the area of millimeter wave wireless communications, specifically dealing with communications, circuits, antennas, propagation, and networking and standards. With the proliferation of cellular wireless devices, such as smartphones and the rapid adoption of Internet of Things (IoT) technology, the demand for higher wireless bandwidth will only increase. This demand will be further exacerbated by the fact that smartphones are quickly becoming the devices of choice for people to watch multimedia content. The 4G technologies are fast going to reach their limits to satisfy this demand. This has resulted in the search for technologies to help increase the available bandwidth. Millimeter wave (mmWave) technology, wherein communication happens in the spectrum range of 3–30 GHz, appears to be one of the promising technologies.	bandwidth (signal processing);internet of things;smartphone;software propagation	Satyajayant Misra	2015	IEEE Wireless Communications	10.1109/MWC.2015.7306370	telecommunications	Mobile	-18.137367677877634	95.8054229021228	21665
98bcf3dce48ae1a2b72c918db0bc884d5af6c874	advanced mobility support in next-generation all-ip wireless networks: a cross-layer approach - part i	wireless terminals;mobility management mobile radio;next generation all ip wireless networks;cost function;wireless network;multimedia application;cross layer approach;internet;advanced mobility support;wireless terminals advanced mobility support next generation all ip wireless networks cross layer approach mobility management internet layer specific mobility management architectures;layer specific mobility management architectures;mobility management;next generation networking wireless networks mobile radio mobility management cross layer design intelligent networks cities and towns ip networks access protocols land mobile radio mobile communication;next generation;cross layer design;ip networks;cross layer;mobile computing;mobility management mobile radio internet ip networks mobile computing	In next generation wireless networks mobility management is a severe problem that needs careful attention, in order to achieve inter-working of Internet with wireless networks, and to meet the requirement of seamless handoff for real-time and multimedia applications. Advanced mobility support is required to effectively deal with the challenges that mobility poses. Single layer-specific mobility management architectures can hardly provide advanced mobility support required in future all-IP wireless networks. Advanced mobility support calls for a coordination of layers through a well defined cross layer platform to achieve better performance. We propose a mobility scenario driven mobility management architecture that exploits cross layer design in wireless terminals to provide seamless terminal mobility in future all-IP wireless network. Each mobility scenario uses a specific cost function that incorporates parameters necessary to support handoff decision in that particular environment	internet;loss function;mathematical optimization;network packet;next-generation network;real-time transcription;seamless3d	George Kalaba Kalebaila;H. Anthony Chan	2006	2006 IEEE 17th International Symposium on Personal, Indoor and Mobile Radio Communications	10.1109/PIMRC.2006.254234	the internet;telecommunications;computer science;operating system;wireless network;mobility model;mobile computing;computer security;computer network	Mobile	-12.742459120908793	90.51729271737632	21673
a10db16e62c9ebab1702df667582c247363f9567	rate-distortion-optimized multi-view streaming in wireless environment using network coding	signal image and speech processing;quantum information technology spintronics	Multi-view video streaming is an emerging video paradigm that enables new interactive services, such as 3D video, free viewpoint television, and immersive teleconferencing. Because of the high bandwidth cost they come with, multi-view streaming applications can greatly benefit from the use of network coding, in particular in transmission scenarios such as wireless network, where the channels have limited capacity and are affected by losses. In this paper, we address the topic of cooperative streaming of multi-view video content, wherein users who recently acquired the content can contribute parts of it to their neighbors by providing linear combinations of the video packets. We propose a novel method for selection and network encoding of the transmitted frames based on the users’ preferences for the different views and the rate-distortion properties of the stream. Using network coding enables the users to retrieve the content in a faster and more reliable manner and without the need for coordination among the senders. Our experimental results prove that our preference-based approach provides a high-quality decoding even when the uplink capacity of each node is only a small fraction of the rate of the stream.	distortion;linear network coding	Claudio Greco;Irina Delia Nemoianu;Marco Cagnazzo;Béatrice Pesquet-Popescu	2016	EURASIP J. Adv. Sig. Proc.	10.1186/s13634-016-0308-4	telecommunications;computer science;multimedia	Networks	-6.49801949076172	102.91455367985128	21703
a1bbeb1f746907b282015c650a95069f74ba6caf	remarks on the attack of fouque et al. against the lic scheme	smart card;public key cryptosystem;signature scheme	In 2007, `-Invertible Cycles (`IC) was proposed by Ding et al. This is one of the most efficient trapdoors for encryption/signature schemes, and of the mixed field type for multivariate quadratic publickey cryptosystems. Such schemes fit on the implementation over low cost smart cards or PDAs. In 2008, Fouque et al. proposed an efficient attack against the `IC signature scheme by using Gröbner basis algorithms. However, they only explicitly dealt with the odd case, i.e. ` is odd, but the even case; they only implemented their proposed attack in the odd case. In this paper, we propose an another practical attack against the `IC encryption/signature scheme. Our proposed attack does not employ Gröbner basis algorithms, and can be applied to the both even and odd cases. We show the efficiency of the attack by using some experimental results. Furthermore, the attack can be also applied to the `ICscheme. To the best of our knowledge, we for the first time show some experimental results of a practical attack against the `ICscheme for the even case.	algorithm;computable function;cryptosystem;digital signature;direction finding;encryption;experiment;gröbner basis;integrated circuit;linear equation;personal digital assistant;smart card;time complexity	Naoki Ogura;Shigenori Uchiyama	2008	IACR Cryptology ePrint Archive	10.1007/978-3-540-89598-5_3	smart card;computer science;theoretical computer science;computer security	Security	-39.501364165133936	80.05843336752496	21706
9c6d6f1c78ba88c5c6c2344854493a8a032f664c	customized cloud service quality: approaching pareto-efficient outcomes in concurrent multiple-issue negotiations	protocols;service level agreements;contracts;monitoring;quality of service;proposals;negotiation;cloud computing	To date, cloud service consumers usually cannot obtain customized quality guarantees according to their specific business constraints. However, on-demand service provisioning, a large number of services with multiple quality parameters, and a plethora of consumers prevent manual negotiations that are typically conducted in face-to-face meetings. Therefore, the design and realization of appropriate mechanisms for an automated negotiation of service level agreements plays a major role for cloud service markets to emerge. Moreover, from a business point of view, the negotiating parties also have specific demands on the performance of such mechanisms and want to obtain the best result that is achievable while not revealing their private information. In this paper, we propose a negotiation mechanism for the envisioned scenario, that allows to approach efficient results despite private information, and evaluate its performance.	best, worst and average case;cloud computing;microsoft outlook for mac;pareto efficiency;personally identifiable information;point of view (computer hardware company);provisioning;service-level agreement;two-phase commit protocol;two-phase locking	Melanie Holloway;Dieter Schuller;Ralf Steinmetz	2015	2015 IEEE/ACM 8th International Conference on Utility and Cloud Computing (UCC)	10.1109/UCC.2015.43	service level requirement;service level objective;communications protocol;quality of service;cloud computing;differentiated service;computer science;service delivery framework;operating system;service design;negotiation	HPC	-24.66197892858295	65.34658813822567	21711
294cf7120e98ed45983d40c1e35e01dbc42d63c6	comment on “remote physical device fingerprinting”	transport protocols computer network security linux;transport control protocols remote physical device fingerprinting tcp timestamps computer identification linux hosts;privacy network security clocks linux;network level security and protection;privacy;privacy network level security and protection	In this paper we revisited a method to identify computers by their clocks skew computed from TCP timestamps. We introduced our own tool to compute clock skew of computers in a network. We validated that the original method is suitable for the computer identification but we also discovered that Linux hosts running NTP had become immune to the identification.	clock skew;computer;device fingerprint;linux	Libor Polcak;Jakub Jirasek;Petr Matousek	2014	IEEE Transactions on Dependable and Secure Computing	10.1109/TDSC.2013.26	computer science;operating system;internet privacy;privacy;computer security;computer network	Visualization	-55.15312621354673	67.40673963035408	21718
55f67ad68a7d334e83f0af059e8515258c039ba3	security and accounting enhancements for roaming in ims	hip;roaming;ip multimedia subsystem;security;multimedia services;ims;cryptographic identity	As the multimedia services are gaining popularity, the operators are seeking new architectures, such as IP Multimedia Subsystem (IMS), that would allow provision of these services with sufficient level of quality and security. In the future, however, it is not anymore so clear who is an operator, because the ubiquitous communication visions enables every player to interact in multitude of ways with other entities and provide services of their own. In this paper we investigate a setting, where a roaming subscriber wishes to receive service from an operator, who has no previous relationship with the home operator. We propose methods based on cryptographic identities which enable the each party to get assurance about the authenticity of each participant and the accountability of the executed actions. While suggesting completely new mechanisms for existing systems, the proposal also addresses the needs to leverage the available infrastructures in a convenient way.	access network;attachments;cryptography;electronic billing;entity;ip multimedia subsystem;software deployment	Seppo Heikkinen	2008		10.1007/978-3-540-68807-5_11	telecommunications;computer science;information security;operating system;internet privacy;ip multimedia subsystem;computer security;computer network	Security	-47.487539933659264	65.33896437136598	21731
8f8cf4a3f24c22ba1f9e6a810ceb8b183c328e06	founding cryptography on oblivious transfer	zero knowledge proof;oblivious transfer;communication channels	Suppose your netmail is being erratically censored by Captain Yossarian. Whenever you send a message, he censors each bit of the message with probability 1/2, replacing each censored bit by some reserved character. Well versed in such concepts as redundancy, this is no real problem to you. The question is, can it actually be turned around and used to your advantage? We answer this question strongly in the affirmative. We show that this protocol, more commonly known as oblivious transfer, can be used to simulate a more sophisticated protocol, known as oblivious circuit evaluation([Y]). We also show that with such a communication channel, one can have completely noninteractive zero-knowledge proofs of statements in NP. These results do not use any complexity-theoretic assumptions. We can show that they have applications to a variety of models in which oblivious transfer can be done.	channel (communications);cryptography;interactivity;np (complexity);oblivious transfer;redundancy (engineering);secure multi-party computation;simulation;theory;zero-knowledge proof	Joe Kilian	1988		10.1145/62212.62215	computer science;theoretical computer science;oblivious transfer;mathematics;distributed computing;algorithm;zero-knowledge proof;channel	Crypto	-37.672210393105196	74.51010022153505	21770
0b84bcbdeb05d84950ebc36ba9df53fb1cb0aa8e	fast cryptographic primitives and circular-secure encryption based on hard learning problems	pseudo random generator;security properties;key dependent message security;encryption;linear functionals;security proof;public key;lattice based cryptography;linear time;learning problems	The well-studied task of learning a linear function with errors is a seemingly hard problem and the basis for several cryptographic schemes. Here we demonstrate additional applications that enjoy strong security properties and a high level of efficiency. Namely, we construct: 1. Public-key and symmetric-key cryptosystems that provide security for key-dependent messages and enjoy circular security. Our schemes are highly efficient: in both cases the ciphertext is only a constant factor larger than the plaintext, and the cost of encryption and decryption is only n · polylog(n) bit operations per message symbol in the public-key case, and polylog(n) bit operations in the symmetric-case. 2. Two efficient pseudorandom objects: a “weak randomized pseudorandom function” — a relaxation of standard PRF — that can be computed obliviously via a simple protocol, and a length-doubling pseudorandom generator that can be computed by a circuit of n · polylog(n) size. The complexity of our pseudorandom generator almost matches the complexity of the fastest known construction (Applebaum et al., RANDOM 2006), which runs in linear time at the expense of relying on a nonstandard intractability assumption. Our constructions and security proofs are simple and natural, and involve new techniques that may be of independent interest. In addition, by combining our constructions with prior ones, we get fast implementations of several other primitives and protocols.	ciphertext;cryptosystem;encryption;fastest;high-level programming language;linear function;linear programming relaxation;period-doubling bifurcation;plaintext;primitive recursive function;pseudorandom function family;pseudorandom generator;pseudorandomness;public-key cryptography;randomized algorithm;time complexity;whole earth 'lectronic link	Benny Applebaum;David Cash;Chris Peikert;Amit Sahai	2009		10.1007/978-3-642-03356-8_35	lattice-based cryptography;time complexity;discrete mathematics;computer science;theoretical computer science;pseudorandom function family;mathematics;distributed computing;pseudorandom generator;random seed;public-key cryptography;computer security;encryption;pseudorandom generator theorem;algorithm	Crypto	-37.91247612423093	76.81264806501505	21773
3e91e34cf9c64cd8bd924b069bff83b7509fcfb6	on anonymity of group signatures	anonymity;encryption;securite;gerente;cryptanalyse;personnel encadrant;cifrado;intelligence artificielle;anonymat;cryptanalysis;criptoanalisis;group signature;cryptage;manager;criptografia;cryptography;safety;artificial intelligence;cryptographie;inteligencia artificial;seguridad;chosen ciphertext attack;anonimato	A secure group signature is required to be anonymous, that is, given two group signatures generated by two different members on the same message or two group signatures generated by the same member on two different messages, they are indistinguishable except for the group manager. In this paper we prove the equivalence of a group signature’s anonymity and its indistinguishability against chosen ciphertext attacks if we view a group signature as an encryption of member identity. Particularly, we prove ACJT’s group signature is IND-CCA2 secure, so ACJT’s scheme is anonymous in the strong sense. The result is an answer to an open question in literature.	antivirus software;chosen-ciphertext attack;ciphertext indistinguishability;encryption;group signature;turing completeness	Sujing Zhou;Dongdai Lin	2005		10.1007/11596981_19	ring signature;cryptanalysis;anonymity;computer science;cryptography;mathematics;internet privacy;group signature;world wide web;computer security;encryption	Crypto	-42.81777148493885	77.71504335935471	21798
05bf054047b6baecc0ecd88153e37239f29a768b	more bars, more bang for the buck: channel-dependent pricing for video delivery to mobile users	video on demand pricing resource allocation storage management telecommunication links;wireless service provider channel dependent pricing mobile users high quality video content delivery channel resource allocation content characteristics playback schedules end user devices physical resource allocation video quality video frame transmission prioritization tiered link quality dependent data pricing scheme usage based pricing wireless networks selfish users video content prefetching short intervals link quality video consumers oblivious scheduler wireless cell;streaming media pricing games wireless communication indexes conferences resource management	A great deal of research energy has been focused on the challenge of delivering high-quality video content to mobile users. In many over-the-top video services, however, the scheduler responsible for channel resource allocation is not aware of content characteristics or playback schedules at end user devices. Therefore, it cannot allocate physical resources in a way that maximizes video quality. For example, it cannot prioritize the transmission of a video frame that is to be displayed within seconds over one whose playback deadline is minutes away. Furthermore, for content that is to be viewed immediately, previous pricing structures that incentivize delaying network use to off-peak hours or WiFi offloading do not apply. To address this issue, we introduce a tiered link quality-dependent data pricing scheme for use together with usage-based pricing in wireless networks. Our pricing model encourages selfish users to prefetch video content during short intervals of good link quality, and use minimal resources when they have a poor link quality. This offers an economic incentive to video consumers to use physical resources more efficiently even with an oblivious scheduler, and leads to better overall video quality for all users in a wireless cell, as well as increased revenue for the wireless service provider.	bang file;digital video;download;over-the-top content;scheduling (computing);simulation;spectral efficiency	Fraida Fund;S. Amir Hosseini;Shivendra S. Panwar	2014	2014 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2014.6849293	multimedia;internet privacy;computer network	Mobile	-17.518057853749216	73.66754900261809	21802
5dd73f5a9a851918279d079b1ecd604275cbdd26	content distribution stochastic fluid models for multi-regions p2p networks	content management;modelizacion;dynamique processus;distributed system;reseau pair;systeme reparti;red www;distribution network;reseau distribution;ecoulement;technology;distributed processing;fluid flow;reseau web;flujo;gestion contenido;probabilistic approach;dinamica proceso;modelo fluido;fluid model;red distribucion;modelisation;igual a igual p2p;sistema repartido;science technology;internet;content distribution;enfoque probabilista;approche probabiliste;descarga;gestion contenu;world wide web;downloading;modele fluide;computer science;dynamic content;p2p networks;information system;process dynamics;peer to peer;modeling;computer science theory methods;systeme information;telechargement;analytical model;flow fluid;sistema informacion;stochastic fluid model	Region P2P networks (called RP2P), based on Chord protocol, are constructed by regions, but not the whole Internet as previous work. Nodes' joining and leaving, lookups and content forward algorithms are presented. To analyze the performance of the RP2P networks and study the dynamic content distribution process between RP2P networks, the stochastic fluid models as an important fluid-flow analytical model are adopted. The final results we got are as follows: the total number of RP2P networks has a more impact on the get probability of downloading content than the total number of nodes; and the content get probability will tend to be a stable value with the increase of nodes' number. These results demonstrate that the method of constructing RP2P networks is better than those of building the universal P2P network.		Zhiqun Deng;Dejun Mu;Guanzhong Dai;Wanlin Zhu	2004		10.1007/978-3-540-30483-8_10	degree distribution;evolving networks;telecommunications;content management;computer science;artificial intelligence;hierarchical network model;information system;technology;fluid dynamics	ECom	-8.947196557311775	74.11605280480971	21807
e9b0efe2060158756ef637e66de2c9d248b531f4	application of topology abstraction techniques in multi-domain optical networks	dense wavelength division multiplexing;optical network;topology;multiprotocol label switching;gmpls;telecommunication network reliability;converters;availability;routing;distributed interdomain lightpath provisioning;topology abstraction techniques;signaling schemes;optical fiber networks;packet cell switching networks;topology abstraction;optoelectronic dwdm networks;optical networks;wavelength division multiplexing multiprotocol label switching optical fibre networks telecommunication network reliability telecommunication network routing telecommunication network topology;wavelength dimension;network topology;optical fibre networks;all optical multidomain dwdm networks;interdomain blocking;telecommunication network routing;multi domain;inter domain routing;performance analysis;multi domain dwdm provisioning;multidomain optical networks;telecommunication network topology;interdomain lightpath rwa;domain level state aggregation;dense wavelength division multiplexing topology abstraction techniques multidomain optical networks distributed interdomain lightpath provisioning packet cell switching networks wavelength dimension hierarchical gmpls based framework all optical multidomain dwdm networks optoelectronic dwdm networks routing scalability interdomain blocking interdomain lightpath rwa signaling schemes domain level state aggregation;topology abstraction optical networks gmpls inter domain routing multi domain dwdm provisioning;routing scalability;wavelength division multiplexing availability routing topology network topology optical fiber networks converters;hierarchical gmpls based framework;wavelength division multiplexing	As DWDM networks proliferate there is a growing need to address the issue of distributed interdomain lightpath provisioning. Although inter-domain provisioning has been well-studied for packet/cellswitching networks, the wavelength dimension presents many additional challenges. This paper develops a novel hierarchical GMPLS-based framework for provisioning all-optical and opto-electronic multi-domain DWDM networks. In particular, several topology abstraction schemes are proposed for aggregating domain-level state to improve routing scalability and lower inter-domain blocking. Inter-domain lightpath RWA and signaling schemes are also tabled. Performance analysis results are presented along with directions for future work.	blocking (computing);generalized multi-protocol label switching;inter-domain;network packet;provisioning;routing;scalability;wavelength-division multiplexing	Q. X. Liu;Nasir Ghani;Mehmet A. Kok	2006	Proceedings of 15th International Conference on Computer Communications and Networks	10.1109/ICCCN.2006.5741894	telecommunications;computer science;distributed computing;wavelength-division multiplexing;computer network	HPC	-7.55352821624647	84.37857717541279	21809
2dda8a84ea6291474b62ae3a817a55dec2560fbf	firewall monitoring		Securing resources against unauthorized access and/or use is a major concern of every organization that uses computer networks. To protect internal networks from external attacks, firewalls are utilized since they restrict network access while letting legitimate users have unencumbered access. Firewalls are also used to log security auditing information about connections and operations. We describe a monitor database gateway (MDBG) designed and implemented to replace older forms of firewall logging by a database system. SQL commands can be used to retrieve logged information instead of ad hoc scripts. The database application allows secure access from other components of a firewall through the Kerberos authentication as well as other authentication methods. If the underlying database changes, only a small portion of the MDBG must be modified; the code for the other components of the firewall remains un-	access network;authentication;authorization;client (computing);computer data storage;database server;firewall (computing);hoc (programming language);kerberos;real-time transcription;sql;server (computing)	Ernst L. Leiss;Jianyu You	1998	CLEI Electron. J.			Security	-52.86764020152109	60.69959901747596	21838
10005c68cd81341b543a761e7cb7f4730127f10a	whowas: a platform for measuring web deployments on iaas clouds	active measurement;web service;azure;ec2;cloud computing	Public infrastructure-as-a-service (IaaS) clouds such as Amazon EC2 and Microsoft Azure host an increasing number of web services. The dynamic, pay-as-you-go nature of modern IaaS systems enable web services to scale up or down with demand, and only pay for the resources they need. We are unaware, however, of any studies reporting on measurements of the patterns of usage over time in IaaS clouds as seen in practice. We fill this gap, offering a measurement platform that we call WhoWas. Using active, but lightweight, probing, it enables associating web content to public IP addresses on a day-by-day basis. We exercise WhoWas to provide the first measurement study of churn rates in EC2 and Azure, the efficacy of IP blacklists for malicious activity in clouds, the rate of adoption of new web software by public cloud customers, and more.	amazon elastic compute cloud (ec2);cloud computing;microsoft azure;tag cloud;web content;web service	Liang Wang;Antonio Nappa;Juan Caballero;Thomas Ristenpart;Aditya Akella	2014		10.1145/2663716.2663742	web service;cloud computing;computer science;engineering;operating system;internet privacy;world wide web;computer security	Metrics	-54.02916081763958	61.94584030470927	21848
f066f66e83e238030d69cb0a5da87c235c8148f8	forgery attacks on chang et al.'s signature scheme with message recovery		It is found that Chang et al.’s signature scheme with message recovery is not as secure as they claimed, in fact. In this letter, two forgery attacks is proposed to show that the signature can be forged on any uncontrolled messages. To overcome these attacks, the one-way hash functions and the message redundancy schemes may be still used.	cryptographic hash function;digital signature;one-way function;uncontrolled format string	Xiaotong Fu;Chunxiang Xu;Guozhen Xiao	2004	IACR Cryptology ePrint Archive		ring signature;redundancy (engineering);merkle signature scheme;elgamal signature scheme;cryptographic hash function;blind signature;hash function;distributed computing;computer security;message authentication code;computer science	Crypto	-43.826698580570984	75.73511881989383	21857
34ed209b6a1995e6a3fedfe270e1393ba0441269	censorspoofer: asymmetric communication using ip spoofing for censorship-resistant web browsing	voice over ip;ip spoofing;asymmetric communication;censorship resistance	A key challenge in censorship-resistant web browsing is being able to direct legitimate users to redirection proxies while preventing censors, posing as insiders, from discovering their addresses and blocking them. We propose a new framework for censorship-resistant web browsing called CensorSpoofer that addresses this challenge by exploiting the asymmetric nature of web browsing traffic and making use of IP spoofing. CensorSpoofer de-couples the upstream and downstream channels, using a low-bandwidth indirect channel for delivering outbound requests (URLs) and a high-bandwidth direct channel for downloading web content. The upstream channel hides the request contents using steganographic encoding within Email or instant messages, whereas the downstream channel uses IP address spoofing so that the real address of the proxies is not revealed either to legitimate users or censors. We built a proof-of-concept prototype that uses encrypted VoIP for this downstream channel and demonstrated the feasibility of using the CensorSpoofer framework in a realistic environment.	blocking (computing);download;downstream (software development);email;encryption;ip address spoofing;instant messaging;physical address;prototype;steganography;web content	Qiyan Wang;Xun Gong;Giang T. K. Nguyen;Amir Houmansadr;Nikita Borisov	2012		10.1145/2382196.2382212	computer science;ip address spoofing;voice over ip;internet privacy;spoofing attack;world wide web;computer security	Security	-55.53027370963284	64.68536904591976	21873
b3c54a54048687606f7606bdfa5ca743125e28fa	system model for multi-level cloud based tactile internet system		With the realization of 5G system which will become a fact by 2020, there is a great demand to achieve the Tactile Internet system. Tactile Internet system should handle a 1 ms communication latency, which is the main problem of the system realization. One of the proposed system structures to achieve such latency is to build the system based on the multilevel cloud architecture and the 5G network structure. In this work, we build a system model for a multi-level cloud based Tactile Internet system. The model is used to find the system latency and evaluate the system performance. The proposed system is simulated and the results show that the system will achieve a lower latency than other known architectures. The proposed model also reduces the overall network congestion. It can be used to optimize the number of clouds in the system to achieve the best system performance.		Abdelhamied A. Ateya;Anastasia Vybornova;Konstantin E. Samouylov;Andrey Koucheryavy	2017		10.1007/978-3-319-61382-6_7	architecture;computer science;the internet;latency (engineering);real-time computing;network congestion;mobile edge computing;cloud computing;system model	Robotics	-23.69965067314998	68.19667107000116	21938
e15317c95eb1ec2129e9900a717f289f66bb0917	static and dynamic job scheduling with communication aware policy in cluster computing	static scheduling algorithm;dynamic scheduling algorithm;early scheduling strategy;dynamic job scheduling;cluster computing;scheduling strategy;high performance;performance evaluation;better performance;communication intensive job;communication aware policy;parallel job	Parallel jobs submitted to processors should be efficiently scheduled to achieve high performance. Early scheduling strategies for parallel jobs make use of either space-sharing approach or time-sharing approach. The scheduling strategy proposed in this work, makes use of both the policies for parallel jobs while scheduling under clusters. Static and dynamic scheduling algorithms were developed for communication intensive jobs. The algorithms are used to handle different types of jobs such as serial, parallel and mixed jobs. For performance evaluation, the workload from Grid5000 platform is considered. The main objective is to achieve performance and power improvement. The dynamic scheduling algorithm with communication aware policy gives better performance when compared to static scheduling algorithm that is tested under the given workload.	computer cluster;job scheduler;scheduling (computing)	A. Neela Madheswari;R. S. D. Wahida Banu	2013	Computers & Electrical Engineering	10.1016/j.compeleceng.2013.01.008	fair-share scheduling;fixed-priority pre-emptive scheduling;parallel computing;real-time computing;earliest deadline first scheduling;gang scheduling;flow shop scheduling;dynamic priority scheduling;computer science;rate-monotonic scheduling;two-level scheduling;deadline-monotonic scheduling;distributed computing;scheduling;lottery scheduling;round-robin scheduling;multiprocessor scheduling	HPC	-14.48826451632386	60.581581308006385	21965
f27e0758ef3511bb5ec174bd0fe7bd8c55e9d28c	development of the universal safety information registration system for vulnerable people using a mobile phone	disaster information system;personal communication networks;multilingual audio assistance universal safety information registration system mobile phone;safety information;personal computer;chaos;disaster vulnerable people;aging;earthquakes;mobile phone;personal digital assistants;handicapped aids;universal safety information registration system;safety mobile handsets earthquakes personal digital assistants personal communication networks chaos informatics microcomputers aging privacy;safety;multilingual audio assistance;mobile handsets;informatics;information system;safety handicapped aids public administration;disaster vulnerable people disaster information system safety information;microcomputers;privacy;public administration	When an earthquake occurs, in order to get safety information, the safety information registration system (SIRS) is most frequently used. Today, almost all SIRS can be accessed from personal computer but they can access from PDA, such as mobile phones. However, access of the current SIRS is more difficult, especially for visual disabled and aged people, also for the non- Japanese natives. In this study, we developed the universal SIRS with easy access for disaster vulnerable such as physically handicapped and people with language barrier. Our newly developed system enables registration of safety information by with simple operation by pushing buttons with guidance of bigger characters and multilingual audio assistance, so forth.	accessibility;mobile phone;personal computer;personal digital assistant	Hiroaki Yuze;Zhengyi Zhang;Yuki Yoshida;Takashi Kawada;Chaoqun Wang	2008	22nd International Conference on Advanced Information Networking and Applications - Workshops (aina workshops 2008)	10.1109/WAINA.2008.136	simulation;telecommunications;computer science;operating system;microcomputer;internet privacy;informatics;privacy;computer security;information system	Mobile	-49.09412784904083	65.35517629999758	21982
b722fa7a5c993240f9adf7752fa99b6dc816a49d	proofs of proofs of work with sublinear complexity		In the setting of blockchain based transaction ledgers we study the problem of “simplified payment verification” (SPV) which refers to the setting of a transaction verifier that wishes to examine the last k blocks of the blockchain (e.g., for the purpose of verification of a certain transaction) using as only advice the genesis block (or some “checkpoint” block that is known to it). The straightforward solution to this task requires the delivery of the blockchain, the verification of the proof of work it contains, and subsequently the examination of the last k blocks. It follows that the communication required to complete this task is linear in the length of the chain. At first thought the above seems the best one can hope: a sublinear in the length of the chain solution to the problem will be susceptible to an attacker that, using precomputation, can fool the verifier. Contrary to this intuition, we show that with a suitable modification to the current Bitcoin blockchain protocol (that incurs a single hash expansion in each block and gives rise to the notion of an interconnected blockchain) we can produce proofs of proof of work with sublinear complexity in the length of the chain hence enabling SPV to be performed much more efficiently.	bitcoin;genesis;precomputation;proof-of-work system;transaction processing system	Aggelos Kiayias;Nikolaos Lamprou;Aikaterini-Panagiota Stouka	2016		10.1007/978-3-662-53357-4_5	proofs involving the addition of natural numbers;probabilistically checkable proof	Crypto	-38.129653603851864	74.57617594700696	22002
b59c8603091fb0111854bfd1f76666528fee0058	differential-linear type attacks on reduced rounds of shacal-2	block ciphering;hachage;cryptage bloc;confidencialidad;block cipher;securite informatique;confidentiality;attaque;computer security;ataque;vida privada;confidentialite;hashing;private life;criptografia;cryptography;seguridad informatica;cifrado en bloque;cryptographie;vie privee;hash function;attacking	SHACAL-2 is a 256-bit block cipher with various key sizes based on the hash function SHA-2. Recently, it was recommended as one of the NESSIE selections. This paper presents differential-linear type attacks on SHACAL-2 with 512-bit keys up to 32 out of its 64 rounds. Our 32-round attack on the 512-bit keys variants is the best published attack on this cipher.	substructural type system	YongSup Shin;Jongsung Kim;Guil Kim;Seokhie Hong;Sangjin Lee	2004		10.1007/978-3-540-27800-9_10	block cipher;triple des;hash function;running key cipher;related-key attack;telecommunications;computer science;fluhrer, mantin and shamir attack;meet-in-the-middle attack;stream cipher attack;slide attack;computer security;algorithm;mdc-2	Crypto	-42.13367753585614	78.36520366933837	22033
312c032aa627ffc7a4d57a6b50896fb0a8766193	toward a mathematical foundation for information		We describe a general purpose, probabilistic system model that can be used to model a large class of probabilistic (as well as deterministic) computer systems. We develop the necessary probability theory to rigorously state and reason about properties of probabilistic systems. Then we give two definitions of information flow security that make use of this formalism. Intuitively, information flow security is the aspect of computer security concerned with how information is permitted to flow through a computer system. The first definition is based on Goguen and Meseguer's Noninterference; the second is based on McLean's FM. We prove that the second definition is strictly stronger than the first. We give a verification condition for information flow security and prove that it implies both of our definitions. Finally, we show some relationships between our definitions and other definitions in the literature, including definitions from classical information theory.		James W. Gray	1992	Journal of Computer Security	10.3233/JCS-1992-13-405	computer security model;computer science;theoretical computer science;computer security;algorithm	Crypto	-35.9502687747713	71.8764469056707	22109
9e9f1b792120a8d4c6a0d8bcedcede9b499d5c09	the balancing-flow reverse path join protocol based on multicast.				Hui Lü;Yanxiang He;Weidong Wen;Xuhui Li	2005			multicast;ip multicast;inter-domain;reliable multicast;resource reservation protocol;protocol independent multicast;pragmatic general multicast;internet group management protocol;distributed computing;distance vector multicast routing protocol;source-specific multicast;xcast;open shortest path first;multicast address	DB	-7.825728488434104	86.75989960747874	22119
4a0d4b5378e88fbd26ce0dba3cd43602167e129f	efficient and random oracle-free conditionally anonymous ring signature	standard model;ring signature;niwi proof system;conditional anonymity	Compared to conventional ring signature schemes, conditionally anonymous ring signatures allow to revoke the anonymity of actual signer without the group manager's help if necessary. When the actual signer intends to confirm his role, it can be proved by a confirmation algorithm. In addition, any user, who is in a ring but not signer, can claim this through a disavowal algorithm. There were several proposals which were proved secure in random oracles. In other words, the security of such schemes depends on the randomness of hash functions. Recently, Zeng et al. proposed a generic construction of conditionally anonymous ring signature scheme without random oracles. Their scheme relies on NIZKs and pseudorandom functions, which render it to be inefficient. This paper proposes a practical ring signature scheme with traceability without random oracles in the common reference string model.	random oracle;ring signature	Shengke Zeng;Zhiguang Qin;Qing Lu;Qinyi Li	2012		10.1007/978-3-642-33272-2_3	ring signature;standard model;mathematics;internet privacy;world wide web;computer security;algorithm	Crypto	-40.17628497996275	75.9506960772331	22161
f3655778a6a222ab42f9137666e86ea1a14ccb40	on a novel filtering mechanism for capacity estimation: extended version	distributed system;filtering;filtrage;systeme reparti;filtrado;network capacity;sistema repartido;internet;retard;retraso	Packet-pair has been used as one of the primary means to measure network capacity. Yet, most prior proposal tools are sensitive to network status and perform poorly in heavy-loaded network. We present a novel filtering mechanism to address the negative effects of cross traffic. After split the origin set of probe pairs into two packet sets composed of the first and second packet of all pairs respectively, we select the packets with minimum one-way delay in each set and use them to reconstruct a new pair free from interference of cross traffic, from which the final capacity estimates are derived. We show the mechanism in detail and validate it in simulations as well as Internet experiments. Preliminary results show that the proposed mechanism is feasible and robust for the heavy-loaded network, which can produce accurate estimates with relatively fewer overheads compared to similar tools. Finally, we analyze the difference in the first and second packet of probe pair in depth, which argues a novel direction of the analysis of packet-pair.		Jianping Yin;Shaohe Lv;Zhiping Cai;Chi Liu	2005		10.1007/11599593_20	filter;the internet;simulation;telecommunications;computer science;data mining;distributed computing;computer security;algorithm;statistics	Theory	-4.7988582036486545	89.49093297191457	22165
72b922b4f1cab28204c56a15ac46f90a042e43fa	fault tolerance logical network properties of irregular graphs	performance evaluation;models for overlay networks;fault tolerance;performance measurement;graph algorithms;large scale systems	Assume a desktop grid middleware or a deployed cloud infrastructure that are both based on a large number of volunteers for computanation-intensive applications or business applications. In this case, the Internet is the communication layer; hence, the communication graph is not regular. Scalability and fault tolerance issues are implicitly present on any platform. For instance, the overlay network that must be built to control the application as part of the run-time support system needs to be scalable and fault tolerant. In this paper, we focus on the fault tolerance properties of large, irregular graphs that may be used as models for the Internet. In a previous work, we presented algorithms and a framework for computing fault tolerance properties of different variants of randomly-generated binomial graphs (BMG). In the present paper we compute various metrics, and among them the node and link connectivities and the fault diameter. We also compare our implementation of the diameter computation with the work of Magnien et al.	algorithm;cloud computing;computation;desktop computer;fault tolerance;internet;middleware;overlay network;randomness;scalability	Christophe Cérin;Camille Coti;Michel Koskas	2012		10.1007/978-3-642-33078-0_27	performance measurement;fault tolerance;parallel computing;real-time computing;computer science;theoretical computer science;operating system;distributed computing;computer network	HPC	-8.139508616606516	70.61171902722182	22185
392739da698b0b1f1794a95e8e0ba56654ef908a	aggregated signatures for chaining: a secure provenance scheme	silicon;digital signatures;public key;distributed databases	With the explosion of information in daily life, determining the trustworthiness of data has become inevitable. As data from different sources can be used in critical applications such as health-care and military for decision making, data provenance plays an important role to gauge the trustworthiness of data. Although, lots of research has been conducted out on provenance generation, provenance management/storage and provenance dissemination in various fields of computing such as: databases, scientific workflows, file systems, distributed cloud computing, and wireless sensor networks. However, security of data provenance has gained limited attention from research community. Since provenance generates a Directed Acyclic Graph (DAG) and chain structure, traditional security solutions are not directly applicable. In this paper, a novel aggregated signature based chaining scheme is presented. The proposed scheme ensures confidentiality, integrity, non-repudiation and availability in a distributed environment to achieve secure provenance. Differentfrom existing work, we assume a stronger attacker model inwhich more than two consecutive colluding users can launchattacks on provenance chain. Security analysis shows that ourscheme can detect such attacks. We have evaluated our proposed scheme empirically and analytically to validate its effectiveness. Our results show that our scheme outperforms existing schemes in term of computation and security.	antivirus software;cloud computing;computation;computer security;confidentiality;correctness (computer science);database;directed acyclic graph;electronic signature;formal verification;lineage (evolution);non-repudiation;overhead (computing);tamper resistance;trust (emotion)	Idrees Ahmed;Abid Khan;Muhammad Saleem Khan;Mansoor Ahmed	2016	2016 IEEE Trustcom/BigDataSE/ISPA	10.1109/TrustCom.2016.0307	computer science;internet privacy;world wide web;computer security	Security	-42.293554427886974	65.92633525371005	22189
2769ac2a06eafa4c28961c1d12c112571c6f791e	an anonymous authentication scheme for trusted computing platform	computer security	The Trusted Computing Platform is the industrial initiative to implement computer security. However, privacy protection is a critical problem that must be solved in Trusted Computing Platform. In this paper, we propose a simple and efficient method to implement anonymous authentication in such setting. The new scheme is proved to be secure under the strong RSA assumption and decisional Diffie-Hellman assumption.	antivirus software;authentication;computer security;cryptography;decisional diffie–hellman assumption;diffie–hellman key exchange;discrete logarithm;lecture notes in computer science;polynomial;privacy;provable security;pseudorandomness;secret sharing;springer (tank);strong rsa assumption;traceability;trusted computing;trusted platform module;zero-knowledge proof	He Ge	2005	IACR Cryptology ePrint Archive		direct anonymous attestation;trusted network connect;trusted computing;strong rsa assumption;computer security;authentication;computer science;trusted platform module	Security	-42.62564259891948	75.40748297438755	22226
637eb6697c5ffdb9b15c43ac90a00a6bfd76b95e	design of virtual infrastructure manager with novel vnf placement features for edge clouds in 5g		This paper focuses on multi-tenant 5G networks with virtualization and mobile edge computing capabilities, in the scope of cloud-enabled small cell deployments. In this context, the work here presented deals with the service management and orchestration challenges that arise when handling service mapping on the multi-tenant distributed cloud-enabled radio access network architecture. For that aim, once analysed cloud edge services management and 5G network instantiation in the OpenStack platform, we modify the provided virtual infrastructure manager so as to incorporate virtual network function placement features of the SESAME environment. As main contributions, we adapt the OpenStack application instances to 5G Network Service instantiation, and we include an energy-aware and latency-constrained placement solution.		Ruben Solozabal;Bego Blanco;Jose Oscar Fajardo;Ianire Taboada;Fidel Liberal;Elisa Jimeno;Javier Garcia Lloreda	2017		10.1007/978-3-319-65172-9_56	virtualization;architecture;network service;orchestration (computing);mobile edge computing;radio access network;computer network;virtual network;real-time computing;cloud computing;engineering	DB	-14.631834530944454	84.936760205607	22247
5f520ebad4131066af10f350c665b276dd421d52	a highly efficient transport protocol for large capacity data files non-ordered block transfer on xcast	multicast scheme;file servers;multicast communication;motion pictures;explicit multicast;web and internet services;nbt;data file nonordered block transfer;transport protocols;network servers;computer communications software transport protocols multicast communication;video on demand;video recording;computer communications software;xcast;transport protocol;bandwidth;plural download request;ip network;ip networks;web server;transport protocols unicast bandwidth motion pictures file servers network servers web server web and internet services video on demand video recording;large capacity stored file transfer;unicast;explicit multicast transport protocol data file nonordered block transfer xcast nbt large capacity stored file transfer ip network plural download request multicast scheme	This paper describes on a protocol named NBT (NBT: non-ordered block transfer) which efficiently transfers large-capacity stored files, and is applicable in a pure IP network. Ordinary file transfer is performed on unicast basis. However, the unicast wastes bandwidth by sending the same large-capacity file to each request, when plural download-requests are simultaneously made. NBT has been proposed to alleviate this problem. Since the original NBT adopts ATM as a multicast scheme, the network domain in which the NBT can be used is restricted. As the solution, adoption of explicit multicast (XCAST) is proposed as a multicast scheme, resulting in a flexible NBT. The proposed system is especially effective when the server frequently transfers large capacity files.	atm turbo;bandwidth (signal processing);download;file transfer;internet protocol suite;multicast;netbios over tcp/ip;retransmission (data networks);server (computing);unicast;xcast	Tomoo Sumida;Katsuyoshi Ito	2005	11th International Conference on Parallel and Distributed Systems (ICPADS'05)	10.1109/ICPADS.2005.28	real-time computing;computer science;operating system;database;distributed computing;transport layer;xcast;computer network	HPC	-7.458523996177219	90.32422107089899	22251
552d68e4194200c4da99207b7cb16985fb96a0ea	distributed denial of service attacks in wireless sensor networks detection and countermeasures		Wireless sensor networks (WSNs) have been widely applied in many areas for real-time event detection. They are designed using both mobile and static sensor nodes (SNs) for different applications such as smart parking, environmental monitoring, health care systems, automotive industries, sports, open space surveillance, and so on. WSNs communicate through wireless mediums and are accessible to anyone, which make SNs susceptible to different types of attacks. Distributed denial of service (DDoS) is one such attack. It wastes the limited energy of SNs and causes loss of data packets within a network. A DDoS attack launches a coordinated attack by flooding the target nodes with bogus requests, thus exhausting their resources, and forcing them to deny service to legitimate member nodes. In this study, the authors propose a message analyser scheme for WSNs. The method is capable of detecting compromised SNs vulnerable to a DDoS attack. In addition, it is able to detect all compromised messages transmitted by the attackers to the base station through the sender nodes. The proposed method is compared with other related protocols. The results show that their method can effectively detect and defend against DDoS attacks in WSNs.		Ademola P. Abidoye;Ibidun C. Obagbuwa	2017	IET Wireless Sensor Systems	10.1049/iet-wss.2017.0029	wireless sensor network;united states space surveillance network;wireless;automotive industry;network packet;computer network;communication source;computer science;denial-of-service attack;base station	Embedded	-53.87828664651119	74.02084314362803	22316
fe682f2b125e21968d13ff2fbdbfa1ec6d08e3ac	lossless handoff in microcellular networks for wireless internet access	virtual connection tree architecture;microcellular networks;wireless internet access;protocols;intelligent networks ip networks base stations protocols land mobile radio cellular systems delay bandwidth wireless communication web and internet services;handoff rates;base stations;ip based cellular networks;cell size;wireless atm;web and internet services;delays microcellular radio transport protocols internet asynchronous transfer mode packet radio networks protocols;cell sequence;performance;tree architecture;protocol design;packet radio networks;small cell sizes;lossless handoff;wireless communication;transport protocols;internet;transient delay profile;cell loss prevention;wireless internet;cellular network;performance lossless handoff microcellular networks wireless internet access small cell sizes handoff rates broadband wireless environment virtual connection tree architecture wireless atm network virtual connection tree protocol cell loss prevention cell sequence ip based cellular networks transient delay profile;bandwidth;ip networks;virtual connection tree;microcellular radio;intelligent networks;land mobile radio cellular systems;wireless atm network;asynchronous transfer mode;delays;broadband wireless environment;protocol	Small cell sizes can lead to high rates of handoff in a broadband wireless environment. The Virtual Connection Tree architecture has been proposed as an effective method to deal with this in a wireless ATM network. In this paper we review the Virtual Connection Tree approach and we present and analyze a simple protocol designed to prevent cell loss and ensure cell sequence during handoff. Then we show how the connection tree concept can be modified to permit simple, efficient and loss-free handoffs in IP-based cellular networks. Finally, we determine the transient delay profile during a handoff and characterize overall performance of the approach.	atm turbo;effective method;internet access;lossless compression;virtual circuit	Anthony S. Acampora;Joseph Soma-Reddy	2000		10.1109/PIMRC.2000.881546	communications protocol;cellular network;intelligent network;protocol;real-time computing;the internet;performance;telecommunications;computer science;base station;asynchronous transfer mode;transport layer;bandwidth;wireless;computer network	Networks	-11.440780754012941	90.92968376477991	22318
62dac531c97934339094602b636e9d0f9e75100b	a decentralized and extensible system of java concurrent objects to monitor and control tcp/ip networks	distributed management java concurrent objects l tcp ip networks monitoring tcp ip networks control decentralised architecture extensible system scripts network elements network management managed nodes cooperative agents first predicate order logic snmp distributed control distributed processing distributed intelligence;simple network management protocol;network monitoring;telecommunication control;java monitoring control systems tcpip ip networks protocols containers data acquisition actuators network servers;cooperative agents;telecommunication computing;software agents;transport protocols;computerized monitoring;management by delegation;decentralized control;ip networks;network management;monitoring and control;java transport protocols telecommunication computing telecommunication control telecommunication network management computerized monitoring decentralized control software agents;telecommunication network management;java	This paper presents a decentralised architecture that is comprised of a set of scripts, agents and concurrent objects that interact among them to perform thee tasks of monitoring and control of the devices resources and processes that are interconnected by means of a TCP/IP network. The scripts perform network management tasks and can be deployed and executed in the managed nodes on demand by using a set of cooperative agents. Concurrent objects abstract the network elements. They act autonomously to monitor the state of the network elements and can perform corrective actions on them if a malfunctioning is detected. Executing the scripts through the agents does this. Besides, it is possible to interact remotely with a concurrent object by using rules in first predicate order logic. A rule allows expressing actions that the object has to perform if it has reached a given state. The system has been developed almost entirely in Java and it is a good example of how the centralised framework proposed by SNMP can coexist with a decentralised architecture in which the distribution of control, processing and intelligence of the management tasks is obtained.	internet protocol suite;java	Luis E. García;Mercedes Garijo	2000		10.1109/ICC.2000.853087	network management;real-time computing;decentralised system;computer science;software agent;operating system;distributed computing;simple network management protocol;java;network monitoring;transport layer;computer network	PL	-19.73501238405142	83.46906618204159	22328
32059f31eb4face6387723cd3de2d32d8dfdc88a	rationality and traffic attraction: incentives for honest path announcements in bgp	incentives;autonomic system;routing policies;theoretical analysis;bgp	We study situations in which autonomous systems (ASes) may have incentives to send BGP announcements differing from the AS-level paths that packets traverse in the data plane. Prior work on this issue assumed that ASes seek only to obtain the best possible outgoing path for their traffic. In reality, other factors can influence a rational AS's behavior. Here we consider a more natural model, in which an AS is also interested in attracting incoming traffic (e.g., because other ASes pay it to carry their traffic). We ask what combinations of BGP enhancements and restrictions on routing policies can ensure that ASes have no incentive to lie about their data-plane paths. We find that protocols like S-BGP alone are insufficient, but that S-BGP does suffice if coupled with additional (quite unrealistic) restrictions on routing policies. Our game-theoretic analysis illustrates the high cost of ensuring that the ASes honestly announce data-plane paths in their BGP path announcements.	autonomous system (internet);border gateway protocol;control plane;forwarding plane;game theory;malware;rationality;routing;traverse	Sharon Goldberg;Shai Halevi;Aaron D. Jaggard;Vijay Ramachandran;Rebecca N. Wright	2008		10.1145/1402958.1402989	simulation;border gateway protocol;incentive;computer science;computer security;computer network	Networks	-57.776343504027096	72.6803896446818	22338
5305cf6a72d3f32040efa607ad9a87763ab91a3b	investigation into tcp congestion control performance for a wireless isp	wireless access;broadband network;wireless network;tcp congestion control;wireless internet;wireless technology	Wireless technology and devices are becoming ever more pervasive and embedded in our lives. In particular, wireless access to the internet is defining the way that we learn, work and socialize. The primary motivation for undertaking this investigation was the author’s involvement in a community broadband project. The contributions of the paper have real impacts for industry and the results of this investigation have been used to provide recommendations to a community wireless internet provider and highlight the wider impact on the UK broadband network. Five major contributions have been achieved: (1) Results from both wired and wireless scenarios are critically evaluated and then concluded; (2) Accurate simulations of 802.11b network in NS2 are validated with live network tests; (3) Evidence is given through both simulation and real network tests to show that current TCP standards are inefficient on wireless networks; (4) A new TCP congestion control algorithm is proposed as well as an outline for a fresh approach; (5) Industry reactions are then given to recommendations for network changes as a result of this investigation.	algorithm;embedded system;network congestion;pervasive informatics;simulation;socialization;tcp congestion control	J. Lillis;Lin Guan;Xin Gang Wang;Alan Grigg;Waltenegus Dargie	2009		10.1007/978-3-642-01209-9_26	motorola canopy;wireless ad hoc network;wi-fi;wireless wan;heterogeneous network;wireless site survey;internet access;telecommunications;engineering;wireless network;wireless distribution system;wireless lan controller;key distribution in wireless sensor networks;base transceiver station;municipal wireless network;wi-fi array;fixed wireless;computer security;slow-start;computer network	Networks	-15.225976918056736	89.35032908765852	22381
67b863a4e37485d6fb02168e0596d9340ce9fc73	per-user profile replication in mobile environments: algorithms, analysis, and simulation results	performance measure;user mobility;maximum flow;personal communication service;algorithm analysis;costs and benefits;mobile environment;user profile;critical system;mobility pattern;mobile computing;communication service;mobile user	We consider per-user profile replication as a mechanism for faster location lookup of mobile users in a personal communications service system. We present a minimum-cost maximum-flow based algorithm to compute the set of sites at which a user profile should be replicated given known calling and user mobility patterns. We show the costs and benefits of our replication algorithm against previous location lookup approaches through analysis. We also simulate our algorithm against other location lookup algorithms on a realistic model of a geographical area to evaluate critical system performance measures. A notable aspect of our simulations is that we use well-validated models of user calling and mobility patterns.	algorithm;critical system;database storage structures;geographic coordinate system;hidden line removal;lookup table;network topology;population;requirement;self-replication;simulation;user profile	Narayanan Shivakumar;Jan Jannink;Jennifer Widom	1997	MONET	10.1023/A:1013668230171	maximum flow problem;simulation;human–computer interaction;computer science;cost–benefit analysis;operating system;mobility model;mobile computing;world wide web;computer network	Mobile	-16.903115161634958	77.27191056117671	22390
b5d35deb3bae7d71a34933c25d94f5fc3cf4d95f	mobility in jcsp: new mobile channel and mobile process models	process model	The original package developed for network mobility in JCSP, although useful, revealed some limitations in the underlying models permitting code mobility and channel migration. In this paper, we discuss these limitations, as well as describe the new models developed to overcome them. The models are based on two different approaches to mobility in other fields, mobile agents and Mobile IP, providing strong underlying constructs to build upon, permitting process and channel mobility in networked JCSP systems in a manner that is transparent to the user.	code mobility;jcsp;mobile ip;mobile agent;proxy mobile ipv6	Kevin Chalmers;Jon M. Kerridge;Imed Romdhani	2007			mobile ip;distributed computing;code mobility;jcsp;process modeling;mobility model;computer science;communication channel	Mobile	-18.68362729642462	89.05020067109275	22393
b33c3ba6a72d1089460c581878dccb270c6331a3	a framework for unified network security management: identifying and tracking security threats on converged networks	management system;network security;real time;large scale;network model	A comprehensive network security management system must coordinate detection and scanning tools for converged networks; derive fully-integrated attack and network models; perform vulnerability and multi-stage attack analysis; support large-scale attack visualization; and possibly orchestrate strategic responses to unwarranted actions that cross network boundaries. We present an architecture that embodies these principles. The unified network security management system described in this paper gleans data from a suite of detection tools for various networking domains. Aggregate real-time network data supplies a comprehensive modeling framework used for further analysis, correlation, and visualization. The resulting system not only provides network administrators with a heads-up cockpit display of their entire network, it also supports guided response and predictive capabilities for multi-stage attacks in converged networks.	aggregate function;coherence (physics);data feed;multistage amplifier;network convergence;network security;real-time clock;real-time computing;real-time transcription;security management;semantic network;technological convergence	Jerald Dawkins;K. Clark;Gavin Wylie Manes;Mauricio Papa	2005	Journal of Network and Systems Management	10.1007/s10922-005-6292-x	organizational network analysis;element management system;intelligent computer network;network architecture;network management station;security information and event management;computer science;network segmentation;network security;network model;unified threat management;data mining;management system;security service;network simulation;network management application;management;network access control;computer security;computer network	Security	-60.539975166813484	70.07107456690129	22406
6c69a18b7a33eca887adaa7133a33bc9ed19eb00	security extensions for improving data security of event repositories in epcglobal networks	history based access control security extensions data security epcglobal networks location based event data rfid aided supply chains distributed event repositories sensitive business secrets in memory technology;security extensions;supply chains permission servers licenses access control simple object access protocol;in memory security extensions rfid aided supply chains history based access control;telecommunication security radiofrequency identification;in memory;telecommunication security;supply chain;access control;history based access control;rfid aided supply chains;radiofrequency identification;data security	Location-based event data is captured in RFID-aided supply chains for tacking individual goods. They are stored in distributed event repositories by involved supply chain parties. Performing anti-counterfeiting checks involves exchange of event data without exposure of sensitive business secrets. Current EPC global standards leave the definition of security strategies open for concrete implementation. We consider data security as the major aspect that needs to be clarified before wide adaption of EPC global standards will be considered by industries. The given work contributes by defining security extensions for EPC global networks and sharing implementation details of our research prototype. We show that incorporating in-memory technology enables history-based access control while keeping response times fast.	access control;data security;electronic product code;event-driven process chain;global network;in-memory database;microsoft outlook for mac;prototype;radio-frequency identification	Matthieu-P. Schapranow;Alexander Zeier;Hasso Plattner	2011	2011 IFIP 9th International Conference on Embedded and Ubiquitous Computing	10.1109/EUC.2011.63	computer security model;cloud computing security;embedded system;security through obscurity;security information and event management;computer science;information security;access control;logical security;operating system;security service;distributed computing;data security;supply chain;internet privacy;network access control;network security policy;world wide web;computer security;computer network	DB	-47.34789771739185	63.3195041805535	22410
bfb8b75b54303a722422671d14f3d314e5be2aa2	privacy-preserving location-based service scheme for mobile sensing data †	location based service;privacy preservation;mobile sensing;mobile cloud	With the wide use of mobile sensing application, more and more location-embedded data are collected and stored in mobile clouds, such as iCloud, Samsung cloud, etc. Using these data, the cloud service provider (CSP) can provide location-based service (LBS) for users. However, the mobile cloud is untrustworthy. The privacy concerns force the sensitive locations to be stored on the mobile cloud in an encrypted form. However, this brings a great challenge to utilize these data to provide efficient LBS. To solve this problem, we propose a privacy-preserving LBS scheme for mobile sensing data, based on the RSA (for Rivest, Shamir and Adleman) algorithm and ciphertext policy attribute-based encryption (CP-ABE) scheme. The mobile cloud can perform location distance computing and comparison efficiently for authorized users, without location privacy leakage. In the end, theoretical security analysis and experimental evaluation demonstrate that our scheme is secure against the chosen plaintext attack (CPA) and efficient enough for practical applications in terms of user side computation overhead.	algorithm;attribute-based encryption;authorization documentation;cerebral palsy;ciphertext;computation (action);embedded system;embedding;extravasation;location-based service;mobile cloud computing;overhead (computing);plaintext;privacy;spectral leakage;transient ischemic attack;icloud	Qing-Qing Xie;Liangmin Wang	2016		10.3390/s16121993	mobile search;mobile database;computer science;location-based service;internet privacy;mobile computing;world wide web;computer security	Security	-42.999315192240054	65.38078970752954	22418
4a6f4ebb14da18698fb9e3908ec57a5f96a9dfea	revealing, characterizing, and detecting crowdsourcing spammers: a case study in community q&a	web sites internet outsourcing security of data unsolicited e mail;会议论文;crowdsourcing unsolicited electronic mail ecosystems conferences computers knowledge discovery;quality control community q a crowdsourcing spammer detection crowdsourcing spammer characterization crowdsourcing services internet chinese based crowdsourcing website zhubajie com crowd workers spamming behaviors baidu zhidao community based question answering site china spam campaigns spammer accounts crowdsourcing spam attacks sybil accounts	Crowdsourcing services have emerged and become popular on the Internet in recent years. However, evidence shows that crowdsourcing can be maliciously manipulated. In this paper, we focus on the “dark side” of the crowdsourcing services. More specifically, we investigate the spam campaigns that are originated and orchestrated on a large Chinese-based crowdsourcing website, namely ZhuBaJie.com, and track the crowd workers to their spamming behaviors on Baidu Zhidao, the largest community-based question answering (QA) site in China. By linking the spam campaigns, workers, spammer accounts, and spamming behaviors together, we are able to reveal the entire ecosystem that underlies the crowdsourcing spam attacks. We present a comprehensive and insightful analysis of the ecosystem from multiple perspectives, including the scale and scope of the spam attacks, Sybil accounts and colluding strategy employed by the spammers, workers' efforts and monetary rewards, and quality control performed by the spam campaigners, etc. We also analyze the behavioral discrepancies between the spammer accounts and the legitimate users in community QA, and present methodologies for detecting the spammers based on our understandings on the crowdsourcing spam ecosystem.	crowdsourcing;dark side;ecosystem;internet;question answering;sensor;software quality assurance;spamming;sybil attack;user profile	Aifang Xu;Xiaonan Feng;Ye Tian	2015	2015 IEEE Conference on Computer Communications (INFOCOM)	10.1109/INFOCOM.2015.7218643	spamming;internet privacy;world wide web	Security	-57.44651409041708	62.9751753755144	22420
4d86964398d13f0c25d0f913eac02f6997ada0bb	elasticity detection: a building block for delay-sensitive congestion control		This paper develops a technique to detect whether the cross traffic competing with a flow is elastic or not, and shows how to use the elasticity detector to improve congestion control. If the cross traffic is elastic, i.e., made up of buffer-filling flows like Cubic or Reno, then one should use a scheme that competes well with such traffic. Such a scheme will not be able to control delays because the cross traffic will not cooperate. If, however, cross traffic is inelastic, then one can use a suitable delay-sensitive congestion control algorithm, which can control delays, but which would have obtained dismal throughput when run concurrently with a buffer-filling algorithm.  We use the elasticity detector to demonstrate a congestion control framework that always achieves high utilization, but which can also achieve low delays when cross traffic permits it. The technique uses an asymmetric sinusoidal pulse patternand estimates elasticity by computing the frequency response(FFT) of the cross traffic estimate; we have measured its accuracy to be over 90%. We have developed Nimbus, a protocol that explicitly switches between TCP-competitive and delay-sensitive modes using the elasticity detector. Our results on emulated and real-world paths show that Nimbus achieves throughput comparable to or better than Cubic always, but with delays that are much lower when cross traffic is inelastic. Unlike BBR, Nimbus is fair to Cubic, and has significantly lower delay in all cases; for example, on real-world paths, Nimbus has 11% lower throughput but at 40-50 ms lower packet delay.	algorithm;behavior-based robotics;buffer overflow;cubic function;elasticity (cloud computing);elasticity (data store);emulator;experiment;frequency response;internet;network congestion;network packet;network switch;pdf/a;queuing delay;sensor;throughput	Prateesh Goyal;Akshay Narayan;Frank Cangialosi;Deepti Raghavan;Srinivas Narayana;Mohammad Alizadeh;Hari Balakrishnan	2018		10.1145/3232755.3232772	fast fourier transform;throughput;computer network;network congestion;computer science;elasticity (economics);frequency response;detector;network packet;pulse (signal processing)	Networks	-5.266513775041152	92.44907941547496	22422
fe9472848fea3e1a34115618374d6ba7ca48ede1	the deployment of a darknet on an organization-wide network: an empirical analysis	organisation s network;protocols;empirical analysis;sensors;organization network;telecommunication congestion control;backscatter;external source ip address;organisation s network darknet scan coverage;transmission control protocol organization wide network darknet sensors backscatter malicious traffic external source ip address tcp scan organization network attack traffic;tcp scan;darknet;transmission control protocol;transport protocols telecommunication congestion control;transport protocols;ieee computer society;monitoring;scan;production;darknet sensors;ip networks;coverage;attack traffic;organization wide network;organizations;malicious traffic;telecommunication traffic monitoring mechanical sensors backscatter mechanical engineering educational institutions tcpip intrusion detection production reliability engineering	Darknet sensors have the interesting property of collecting only suspicious traffic, including misconfiguration, backscatter and malicious traffic. The type of traffic collected highly depends on two parameters: the size and the location of the darknet sensor. The goals of this paper are to study empirically the relationship between these two parameters and to try to increase the volume of attackers detected by a given darknet sensor. Our empirical results reveal that on average, on a daily basis, 485 distinct external source IP addresses perform a TCP scan on one of the two /16 networks of our organizationpsilas network. Moreover, a given darknet sensor of 77 IP addresses deployed in the same /16 network collects on average attack traffic from 26% of these attackers.	classless inter-domain routing;darknet;denial-of-service attack;network address;network governance;randomness;software deployment;the daily dot	Robin Berthier;Michel Cukier	2008	2008 11th IEEE High Assurance Systems Engineering Symposium	10.1109/HASE.2008.54	communications protocol;telecommunications;computer science;organization;engineering;sensor;transmission control protocol;computer security;backscatter;transport layer;computer network	Security	-57.89471132587567	68.4010387488103	22443
5650ff1b8b3b7cddde65c896b83a514e959015a7	decor: a distributed coordinated resource monitoring system	piece selection policy;distributed coordination;optimisation;resource allocation;p2p vod streaming;redundancy elimination;scaling up;information gathering;monitoring system;redundancy;peer selection policy;redundancy elimination decor distributed coordinated resource monitoring system central controller network information task allocation arrangements global optimization information gathering partial network failure path based application distributed smartre click software router;resource allocation computer network reliability optimisation redundancy;replica management policy;global optimization;optimization monitoring redundancy decoding resource management delay memory management;task allocation;computer network reliability	Network resources are often limited, so how to use them efficiently is an issue that arises in many important scenarios. Many recent proposals rely on a central controller to carefully orchestrate resources across multiple network locations. The central controller gathers network information and relative levels of usage of different resources and calculates optimized task allocation arrangements to maximize some global benefit. Examples of architectures that use this framework include coordinated sampling (CSAMP [1]) and redundancy elimination (SmartRE [2]). However, a centralized solution creates practical problems as it is susceptible to overload, and the controller is a single point of failure.  In this paper, we present a distributed solution called DECOR that achieves global optimization based on local information that closes to centralized approaches in terms of performance. In DECOR, the responsibility of resource monitoring and information gathering is spread among multiple nodes; thus, no single point is overloaded. Allocation of tasks is also done in a similar distributed fashion. DECOR can easily scale up to large networks, and the partial network failures do not affect DECOR's functioning in other parts of the network.  DECOR can be applied to most of path-based applications. We describe in detail how to apply it to distributed SmartRE and implement it in the Click software router.	bottleneck (engineering);bottleneck (software);centralized computing;critical point (network science);function overloading;global optimization;mathematical optimization;reliability engineering;router (computing);sampling (signal processing);scalability;single point of failure	Shan-Hsiang Shen;Aditya Akella	2012	2012 IEEE 20th International Workshop on Quality of Service	10.1109/IWQoS.2012.6245994	real-time computing;simulation;resource allocation;computer science;operating system;distributed computing;redundancy;global optimization;computer network	HPC	-21.15970953691788	68.7835975353014	22460
c9fe5c286e907fef774fefd983f1964efb0ff958	towards inferring mechanical lock combinations using wrist-wearables as a side-channel		Wrist-wearables such as smartwatches and fitness bands are equipped with a variety of high-precision sensors that support novel contextual and activity-based applications. The presence of a diverse set of on-board sensors, however, also expose an additional attack surface which, if not adequately protected, could be potentially exploited to leak private user information. In this paper, we investigate the feasibility of a new attack that takes advantage of a wrist-wearableu0027s motion sensors to infer input on mechanical devices typically used to secure physical access, for example, combination locks. We outline an inference framework that attempts to infer a locku0027s unlock combination from the wrist motion captured by a smartwatchu0027s gyroscope sensor, and uses a probabilistic model to produce a ranked list of likely unlock combinations. We conduct a thorough empirical evaluation of the proposed framework by employing unlocking-related motion data collected from human subject participants in a variety of controlled and realistic settings. Evaluation results from these experiments demonstrate that motion data from wrist-wearables can be effectively employed as a side-channel to significantly reduce the unlock combination search-space of commonly found combination locks, thus compromising the physical security provided by these locks.	attack surface;experiment;gyroscope;lock (computer science);on-board data handling;physical access;physical security;sim lock;sensor;side-channel attack;smartwatch;statistical model;wearable computer	Anindya Maiti;Ryan Heard;Mohd Sabra;Murtuza Jadliwala	2018		10.1145/3212480.3212498	physical access;lock (computer science);real-time computing;theoretical computer science;user information;side channel attack;smartwatch;wearable computer;physical security;computer science;attack surface	Security	-52.37338922981274	67.6530449041258	22516
587aa48e24e6726b83c4a9aff2c8460eda4bfca0	privacy-preserving group discovery with linear complexity	security model;communication complexity;privacy preservation;linear complexity;authenticated key exchange;general solution;indexation	Affiliation-Hiding Authenticated Key Exchange (AH-AKE) protocols enable two distrusting users, being in possession of membership credentials for some group, to establish a secure session key without leaking any information about this group to non-members. In practice, users might be members of several groups, and such protocols must be able to generate session keys between users who have one or more groups in common. Finding efficient solutions for this group discovery problem has been considered an open research problem, inherent to the practical deployment of these protocols. We show how to solve the privacy-preserving group discovery problem with linear computational and communication complexity, namely O(n) complexity where n is the number of groups per user. Our generic solution is based on a new primitive — Index-Hiding Message Encoding (IHME), for which we provide definitions and an unconditionally secure construction. Additionally, we update the syntax and the security model of AH-AKE protocols to allow multiple input groups per participant and session. Furthermore, we design a concrete multi-group AH-AKE protocol by applying IHME to a state-of-the-art single-group scheme.	authenticated key exchange;authentication;communication complexity;computation;computer security;credential;open research;session key;software deployment	Mark Manulis;Benny Pinkas;Bertram Poettering	2010		10.1007/978-3-642-13708-2_25	computer security model;computer science;communication complexity;distributed computing;world wide web;computer security	Security	-41.52687398020175	74.9561897874041	22531
330a8f8a4ccea991d02a7baf63677f7b01cf19c1	certificate revocation list distribution in vehicular communication systems	vehicular communication systems;elektroteknik och elektronik;vanet;electrical engineering electronic engineering information engineering;revocation;security architecture;security;certificate revocation list;vehicular communication	The need to evict compromised, faulty, or illegitimate nodes is well understood in prominent projects designing security architectures for Vehicular Communication (VC) systems. The basic approach envisioned to achieve this is via distribution of Certificate Revocation Lists (CRLs). Nonetheless, the problem of how to distribute CRLs effectively and efficiently has not been investigated. In this paper, we addresses exactly this problem. We propose a flexible, simple, and scalable design that leverages on road-side VC infrastructure. Our scheme can distribute large CRLs across wide VC regions within minutes, by utilizing a bandwidth of only a few Kbps at each road-side infrastructure unit.	data rate units;scalability	Panagiotis Papadimitratos;Ghita Mezzour;Jean-Pierre Hubaux	2008		10.1145/1410043.1410062	vehicular ad hoc network;computer science;information security;x.509;revocation list;vehicular communication systems;internet privacy;online certificate status protocol;computer security;enterprise information security architecture;computer network	Security	-50.862042960121954	74.75034139364408	22538
479878d5dfa9f70016a9bce26dcbf67567777435	research and construction of the full-service ip high-speed intelligent bearer network for the digital oil field		The construction of the basic bearer network is the “road network project” of digital oil field information field, which is the “highway” to connect the information application platforms, data centers and terminal users. Start with digital oil field, this thesis analyzes the construction of the basic networks, as well as the syncretic technology development status, the prospective development tendency and the popularization and application prospects. This thesis also confirms the method of development, clarifies the approach of evolution, and shows different periods of evolution and phased technical points.		Xian Zhang;Yumin Feng;Xiaohui Song	2017		10.1007/978-3-319-61566-0_46	computer network;computer science;oil field	HCI	-20.573730267179773	94.75795343191639	22544
08c6ae065c7f6d104c1fd008ce469eb9f5eb034f	statistical traffic multiplexing with service guarantees over optical core networks	optical network;optical packet switching;time scale;optical switch;optical transport network;optical burst switched;qos guarantee;time division multiplex;optical fiber networks;optical switches;statistical multiplexing;optical communications;multiplexing;canon;canon optical networks optical communications statistical multiplexing obs;optical networks;resource reservation;optical fiber networks optical switches multiplexing quality of service optical packet switching optical fibers;large scale;optical fibers;cost efficiency;next generation;optical communication;quality of service;obs;optical packet switched;core network	Statistical multiplexing at the optical layer has been considered a critical requirement in order to build the next generation of ultra-high capacity optical transport networks in a cost-efficient manner. However, even today, the state of the art of commercially available optical core networks is based on mature wavelength switching and routing technologies, which lack a transport and control plane architecture that can support statistical traffic multiplexing with guaranteed Quality of Service (QoS) across a wide range of QoS parameters even if they can support fast reconfiguration at msec time scales. For several years, most research efforts have focused on the concepts of Optical Burst Switching (OBS) and Optical Packet Switching (OPS), which are based on the hybrid use of electronic nodes and optical switches to exploit Time Division Multiplexing (TDM) in order to achieve statistical multiplexing and dynamic resource reservation over optical networks. While burst switching has been experimentally proven as a technically feasible technique, its performance suffers especially under strict requirements for QoS guarantees. In this paper we evaluate the performance gains that can be achieved exploiting statistical multiplexing over a large scale core optical network and we demonstrate the efficiency of the CANON architecture (Clustered Architecture for Nodes in an Optical Network) as a viable alternative to OBS, which can achieve both targets for statistical multiplexing gains and QoS guarantees at the same time.	blocking (computing);control plane;cost efficiency;experiment;interconnection;lossless compression;multiplexing;next-generation network;optical burst switching;optical switch;original chip set;packet switching;provisioning;quality of service;requirement;resource bounded measure;routing	Andreas Drakos;Theofanis Orphanoudakis;Christina Tanya Politi;Alexandros A. Stavdas	2010	2010 International Conference on Data Communication Networking (DCNET)		optical transport network;statistical time division multiplexing;real-time computing;optical burst switching;multiwavelength optical networking;telecommunications;computer science;optical switch;optical performance monitoring;optical communication;computer network	Networks	-10.058971822424407	85.02465632927816	22573
404eabae4d9d1f6ae206c50d2f87ee0933a3bf72	efficient and secure certificateless signature scheme in the standard model	key escrow;certificateless signature;trust level;standard model	SummaryrnrnCertificateless cryptography not only enjoys many advantages of identity-based cryptography (IBC) but also eliminates the fatal drawback, which is called the key escrow in IBC. Most of the early certificateless signature schemes are secure based on the random oracle model, and nowadays, more and more researchers put emphasis on the scheme based on the standard model. In 2010, Xia et al. demonstrated that the previous schemes in the standard model cannot resist the public-key-replace attack. In 2012, for the purpose of overcoming the common drawback, Yu et al. presented a new certificateless signature scheme. However, under the public-key-replace attack and malicious-but-passive key generation center attack, this scheme is proven to be vulnerable. Moreover, there are too many bilinear pairings used in this scheme, which lead to its low computation efficiency. Aiming at the weakness of the scheme byYu et al., we propose a new certificateless signature scheme, which provides stronger security and higher computational efficiency than the existing schemes. In addition, according to the concept of Giraultu0027s trust level, the new scheme can reach trust level 3. Copyright © 2015 John Wiley u0026 Sons, Ltd.	digital signature	Liaojun Pang;Yufei Hu;Yi Liu;Kedong Xu;Huixian Li	2017	Int. J. Communication Systems	10.1002/dac.3041	standard model;key escrow;computer science;internet privacy;world wide web;computer security	Web+IR	-45.21067719189788	74.19940450779117	22587
8dc234cf313b09e4de1bd9862b79d3af72153087	a practical quadratic residues based scheme for authentication and privacy in mobile rfid systems	authentication;rfid systems;security protocols;privacy	In this paper we propose a novel approach to authentication and privacy in mobile RFID systems based on quadratic residues and in conformance to EPC Class-1 Gen-2 specifications. Recently, Chen et al. (2008) [10] and Yeh et al. (2011) [11] have both proposed authentication schemes for RFID systems based on quadratic residues. However, these schemes are not suitable for implementation on low-cost passive RFID tags as they require the implementation of hash functions on the tags. Consequently, both of these current methods do not conform to the EPC Class-1 Gen-2 standard for passive RFID tags which from a security perspective requires tags to only implement cyclic redundancy checks (CRC) and pseudo-random number generators (PRNG) leaving about 2.5k–5k gates available for any other security operations. Further, due to secure channel assumptions both schemes are not suited for mobile/wireless reader applications. We present the collaborative authentication scheme suitable for mobile/wireless reader RFID systems where the security of the server–reader channel cannot be guaranteed. Our schemes achieves authentication of the tag, reader and back-end server in the RFID system and protects the privacy of the communication without the need for tags to implement expensive hash functions. Our scheme is the first quadratic residues based scheme to achieve compliance to EPC Class-1 Gen-2 specifications. Through detailed security analysis we show that the collaborative authentication scheme achieves the required security properties of tag anonymity, reader anonymity, reader privacy, tag untraceability and forward secrecy. In addition, it is resistant to replay, impersonation and desynchronisation attacks. We also show through strand space analysis that the proposed approach achieves the required properties of agreement, originality and secrecy between the tag and the server. 2012 Elsevier B.V. All rights reserved.	authentication;conformance testing;cyclic redundancy check;electronic product code;entity–relationship model;forward secrecy;hash function;mobile rfid;privacy;pseudorandomness;quadratic residue;radio-frequency identification;random number generation;replay attack;secure channel;server (computing);strand (programming language)	Robin Doss;Saravanan Sundaresan;Wanlei Zhou	2013	Ad Hoc Networks	10.1016/j.adhoc.2012.06.015	computer science;authentication;cryptographic protocol;internet privacy;privacy;world wide web;computer security;computer network	Security	-45.87873467410921	74.02903101010723	22598
a5704a30688ea99f5eada7a84769dda31e6c6cd2	exploiting the congestion control behavior of the transmission control protocol	opt ack tcp congestion control security;transport protocols internet telecommunication congestion control;telecommunication congestion control;tcp;network congestion congestion control behavior transmission control protocol web server;transmission control protocol;transport protocols;opt ack;internet;tcp congestion control;congestion control;security;network congestion;protocols informatics web server internet bandwidth network servers data security jacobian matrices robust control logic	This paper presents a realistic method for exploiting an already known insecurity of the Congestion Control behavior of the Transmission Control Protocol that was originally pointed out in 1999 and that affects all known TCP implementations. This insecurity exploits the fundamental assumption of TCP that the communicating remote end is trustworthy and is behaving correctly. We developed a methodology and an algorithm which we used to attack a web server and deceive it in transmitting with a constant rate of 900 Mbits per second. During the attack the server was incapable of reacting to the network congestion it caused.	algorithm;autonomous system (internet);denial-of-service attack;digital subscriber line;internet;malware;mike lesser;network congestion;operating system;python;server (computing);transmitter;user space;web server	Stefanos Harhalakis;Nikolaos Samaras;Vasileios Vitsas	2009	2009 Fourth Balkan Conference in Informatics	10.1109/BCI.2009.11	quic;compound tcp;tcp congestion-avoidance algorithm;network traffic control;tcp global synchronization;tcp westwood plus;computer science;information security;transmission control protocol;flow control;explicit congestion notification;distributed computing;h-tcp;scalable tcp;hstcp;tcp tuning;packet loss;network congestion;tcp acceleration;computer security;tcp friendly rate control;slow-start;transport layer;computer network	Networks	-58.450342509696945	68.39752769212946	22620
30dbe644427360a0695bd19e3710768395b1bdc2	adapting caching to audience retention rate: which video chunk to store?		Rarely do users watch online contents entirely. We study how to take this into account to improve the performance of cache systems for video-on-demand and video-sharing platforms in terms of traffic reduction on the core network. We exploit the notion of “Audience retention rate”, introduced by mainstream online content platforms and measuring the popularity of different parts of the same video content. We first characterize the performance limits of a cache able to store parts of videos, when the popularity and the audience retention rate of each video are available to the cache manager. We then relax the assumption of known popularity and we propose a LRU (Least Recently Used) cache replacement policy that operates on the first chunks of each video. We characterize its performance by extending the well-known Che’s approximation to this case. We prove that, by refining the chunk granularity, the chunk-LRU policy increases its performance. It is shown numerically that even for a small number of chunks (N = 20), the gains of chunk-LRU are still significant in comparison to standard LRU policy that caches entire files, and they are almost optimal.	approximation;cpu cache;cache (computing);digital video;numerical analysis;web content;whole earth 'lectronic link	Lorenzo Maggi;Lazaros Gkatzikis;Georgios S. Paschos;Jeremie Leguay	2015	CoRR		real-time computing;computer science;operating system;multimedia;world wide web	Metrics	-16.005727232952555	71.93867067196791	22645
50d88821d1e6aa1875cf722e07a5045906640e0a	one-message unilateral entity authentication schemes		A one-message unilateral entity authentication scheme allows one party, called the prover, to authenticate himself, i.e., to prove his identity, to another party, called the verifier, by sending a single authentication message.  In this paper we consider schemes where the prover and the verifier do not share any secret information, such as a password, in advance. We propose the first theoretical characterization for one-message unilateral entity authentication schemes, by formalizing the security requirements for such schemes with respect to different kinds of adversaries. Afterwards, we propose three provably-secure constructions for one-message unilateral entity authentication schemes.	access control;acknowledgement (data networks);adversary (cryptography);authentication;computational hardness assumption;password;provable security;requirement	Alfredo De Santis;Manuela Flores;Barbara Masucci	2017		10.1145/3098954.3098982	computer security;challenge-handshake authentication protocol;password;authentication protocol;computer science;challenge–response authentication;provable security;authentication;one-time password;data authentication algorithm;distributed computing	Security	-41.67184240370386	75.32162680681206	22701
06702e0004b95d2ddd092cae82190e271eaf0cf6	the aurora gigabit testbed	distributed system;protocols;systeme reparti;shared memory;multimedia;selected works;memoria compartida;reseau ordinateur;telecommunication network;packet switching;conmutacion por paquete;computer networks;transmision asincronica;computer network;sistema repartido;mode transmission;grande vitesse;red telecomunicacion;gigabit network;multimedia communication;reseau telecommunication;red ordenador;transmission mode;asynchronous transmission;bepress;transmission asynchrone;gran velocidad;atm;modo transmision;distributed shared memory;high speed;commutation paquet;memoire partagee;is research	AURORA is one of five U.S. networking testbeds charged with exploring applications of, and technologies necessary for, networks operating at gigabit per second or higher bandwidths. The emphasis of the AURORA testbed, distinct from the other four testbeds, BLANCA, CASA, NECTAR, and VISTANET, is research into the supporting technologies for gigabit networking. Like the other testbeds, AURORA itself is an experiment in collaboration, where government initiative (in the form of the Corporation for National Research Initiatives, which is funded by DARPA and the National Science Foundation) has spurred interaction among pre-existing centers of excellence in industry, academia, and government. AURORA has been charged with research into networking technologies that will underpin future high-speed networks. This paper provides an overview of the goals and methodologies employed in AURORA, and points to some preliminary results from our first year of research, ranging from analytic results to experimental prototype hardware. This paper enunciates our targets, which include new software architectures, network abstractions, and hardware technologies, as well as applications for our work. Comments University of Pennsylvania Department of Computer and Information Science Technical Report No. MSCIS-93-28. Author(s) David D. Clark, Bruce S. Davie, David J. Farber, Inder S. Gopal, Bharath K. Kadaba, W. David Sincoskie, Jonathan M. Smith, and David L. Tennenhouse This technical report is available at ScholarlyCommons: http://repository.upenn.edu/cis_reports/317 The AURORA Gigabit Testbed MS-CIS-93-28 DISTRIBUTED SYSTEMS LAB 26 David D. Clark Bruce S. Davie David J. Farber Inder S. Gopal Bharath K. Kadaba W. David Sincoskie Jonathan M. Smith David L. Tenilenhouse University of Pennsylvania School of Engineering and Applied Science Computer and Information Science Department Philadelphia, PA 19104-6389	aurora;bandwidth (signal processing);computational auditory scene analysis;corporation for national research initiatives;data rate units;electrical connection;experiment;gigabit;information and computer science;information science;internet;interoperability;network architecture;network switch;prototype;software architecture;software deployment;testbed;workstation	David D. Clark;Bruce S. Davie;David J. Farber;Inder S. Gopal;Bharath K. Kadaba;W. David Sincoskie;Jonathan M. Smith;David L. Tennenhouse	1993	Computer Networks and ISDN Systems	10.1016/0169-7552(93)90056-A	distributed shared memory;shared memory;embedded system;communications protocol;simulation;telecommunications;computer science;asynchronous communication;atmosphere;world wide web;packet switching;telecommunications network;computer network	HPC	-21.033621648026486	91.30409757327652	22730
73596e74282b508c1041d3cf3b32523819a65bbe	secure two-party point-circle inclusion problem	secure multi party computation;computational geometry;privacy preservation;private comparison;homomorphic encryption scheme;modular multiplication	Privacy-preserving computational geometry is a special secure multi-party computation and has many applications. Previous protocols for determining whether a point is inside a circle are not secure enough. We present a two-round protocol for computing the distance between two private points and develop a more efficient protocol for the point-circle inclusion problem based on the distance protocol. In comparison with previous solutions, our protocol not only is more secure but also reduces the number of communication rounds and the number of modular multiplications significantly.	privacy-preserving computational geometry;secure multi-party computation	Yonglong Luo;Liusheng Huang;Hong Zhong	2007	Journal of Computer Science and Technology	10.1007/s11390-007-9011-0	modular arithmetic;universal composability;commitment scheme;computational geometry;computer science;secure two-party computation;theoretical computer science;distributed computing;secure multi-party computation;computer security	Theory	-40.42726258766795	74.86696822057993	22736
d4b2b7ad6a2a2692eb06d9d2e3eefaac507b9d04	fish: a novel peer-to-peer overlay network based on hyper-debruijn	p2p system;fault tolerant;asymptotic optimality;p2p;load balance;peer to peer;peer to peer overlay networks	  Autonomy, efficiency, robustness and load balancing are four desirable features for Peer-to-Peer (P2P) systems. These four  features however, are often in conflict with each other. We present a novel P2P architecture, called FISH, based on the Hyper-deBruijn  topology. FISH provides flexibility in terms of connections per node and the level of fault-tolerance, and possesses a low  diameter. We further address the challenge of dynamic operations of peers by introducing a novel set of algorithms. We also  design two variants of Hyper-deBruijn topology for achieving an asymptotical optimal diameter. Comprehensive experiments show  that FISH has a good trade-off among the four expected features.    	overlay network;peer-to-peer	Ye Yuan;Guoren Wang;Yongjiao Sun	2010		10.1007/978-3-642-14246-8_8	fault tolerance;real-time computing;computer science;load balancing;peer-to-peer;database;distributed computing;computer security;computer network	OS	-12.243744217460682	72.67721312268485	22756
7ae543cab669a508c9caef85ed31ad265ac1a143	the active process interaction with its environment	distributed application;active circuit;arquitectura red;network management and control;circuito activo;programmation;architecture reseau;routeur informatique;programacion;circuit actif;congestion avoidance;router;network architecture;load balance;programming;processus actif	Adding programmability to the interior of the network provides an infrastructure for distributed applications. Speci®cally, network management (NM) and control applications require access to and control of network device state. For example, a routing load balancing application may require access to the routing table, and a congestion avoidance application may require interface congestion information. There are fundamental problems associated with this interaction that are apparent in current technologies. In this paper, the basic tradeos associated with the interaction between an active process and its environment and presenting ABLE++ as an example architecture is studied. Most notably, two design tradeos, eciency vs. abstraction and application ¯exibility vs. security are explored. The advantages of the architecture by implementing a congestion avoidance algorithm are demonstrated. Ó 2001 Published by Elsevier Science B.V.	abstraction layer;algorithm;archi;cpu cache;computation;distributed computing;information retrieval;limbo;load balancing (computing);network congestion;networking hardware;programmer;routing table	Jessica A. Kornblum;Danny Raz;Yuval Shavitt	2000		10.1007/3-540-40057-5_9	embedded system;programming;real-time computing;simulation;network architecture;computer science;load balancing;slow-start	Arch	-5.639513834382407	75.50800858032748	22781
4decd3c39df9f2190eefb3469c3f7f79031aa1ed	a splitting infrastructure for load balancing and security in an mpls network	multiprotocol label switching;load management multiprotocol label switching telecommunication traffic clouds routing aggregates data security cryptography testing protection;load security;routing;resource allocation;label edge routers;telecommunication security multiprotocol label switching resource allocation telecommunication network routing;multi protocol label switched;testing;traffic flow;protection;telecommunication traffic;multi path routing;telecommunication network routing;aggregates;cryptography;clouds;telecommunication security;open source implementation;load management;load balancing;load balance;functional requirement;label switched paths;open source implementation traffic splitting load balancing load security multipath routing multiprotocol label switching label switched paths label edge routers;mechanism design;multipath routing;traffic splitting;open source;data security;label switched path	Several multi-path routing algorithms have been recently proposed to achieve load balancing and increase security. However, the functionalities required to split traffic flows over multiple paths have not been standardized yet. Multi-protocol label switching (MPLS) offers a suitable environment to implement multi-path routing algorithms, as multiple parallel label switched paths (LSPs) may be established to carry each a portion of a traffic flow. This paper focuses on a traffic splitting mechanism designed for MPLS networks. We propose a set of new operations to be performed by the edge routers and illustrate them with reference to a popular open source implementation of the MPLS stack. We implemented the new operations and give a demonstration of their functionality using an experimental testbed.	algorithm;egress filtering;linux;load balancing (computing);multipath routing;multiprotocol label switching;network packet;network security;open-source software;prototype;shim (computing);testbed;transistor–transistor logic	Stefano Avallone;Vittorio Manetti;Marina Mariano;Simon Pietro Romano	2007	2007 3rd International Conference on Testbeds and Research Infrastructure for the Development of Networks and Communities	10.1109/TRIDENTCOM.2007.4444681	multiprotocol label switching;label information base;computer science;load balancing;distributed computing;computer security;computer network	Mobile	-15.805897649723594	83.25421730293317	22789
211acc5e15c9ec73fd85e2a2cf100dbc35a3681a	a privacy-aware decentralized and personalized reputation system		Reputation systems enable consumers to evaluate the trustworthiness of business entities (retailers, sellers) over the marketplace. In electronic marketplaces, the reputation of an business entity (retailer, seller) is computed by aggregating the “trust-scores” assigned to her by the parties who have had transactions with her. Most reputation systems designed for online marketplaces use all the available trust-scores to compute the reputation of business entity. However, in some scenarios, the consumer may wish to compute the reputation of a business entity by considering the trust-scores from a set of trustworthy participants, however, she does not want to disclose the identities of the users she trusts. There are two privacy protection challenges in the design of this kind of personalized reputation system: 1) protecting the set of trusted users of participants, and 2) protecting the trust-scores assigned by the participants in the trusted set. In this paper, we present a novel framework for computing the personalized global reputation of a business entity by considering the trust-scores from a set of trusted participants without disclosing identities of participants in the trusted set and their trust-scores. To this extent, the participants share cryptograms of their trust-scores for the business entity to the decentralized public bulletin board or tally center. These encrypted trust-scores are then used by the requester to compute the personalized reputation score of the business entity without leaking private information of participants in the system. We have analyzed the security and privacy properties of the scheme for the malicious adversarial model. The protocol has a linear message complexity, which proves that the system can be deployed in a real setup where such personalized recommendations may be required in practice. Furthermore, the system ensures correctness, privacy and security of trust-scores of participants in the trusted set under the malicious adversarial model.	adversary (cryptography);adversary model;centralized computing;computationally bounded adversary;correctness (computer science);cryptogram;encryption;entity;interaction;interactivity;online marketplace;personalization;personally identifiable information;privacy;proof of knowledge;reputation system;secure multi-party computation;trust (emotion);trusted operating system;ws-trust;zero-knowledge proof	Samiran Bag;Muhammad Ajmal Azad;Feng Hao	2018	Computers & Security	10.1016/j.cose.2018.05.005	adversarial system;reputation system;computer security;bulletin board;internet privacy;trustworthiness;encryption;computer science;correctness;private information retrieval;reputation	Security	-38.72579997998757	65.86228316907885	22903
1dfcd363b9365847b396edb7e1af5b008dc67b3f	a rule-based expert server system for multimedia transmission	rule based expert system technology;session management;multimedia systems network servers expert systems network topology streaming media engines runtime real time systems decision making inference algorithms;expert systems;xml format;rule based;multimedia transmission server system;runtime;multimedia systems;network topology;network servers;engines;streaming media;xml decision making expert systems multimedia communication;multimedia communication;xml;inference algorithms;xml format rule based expert server system multimedia transmission server system rule based expert system technology decisionmaking procedure;decisionmaking procedure;rule based expert server system;real time systems;knowledge base;expert system	In this paper, a novel multimedia transmission server system is designed using rule-based expert system technology. Working parameters and session management methods are separated from the decisionmaking procedure and stored in a knowledge base (XML format). The server fires different transmission strategies inside the knowledge base by runtime inference. Thus it can easily adjust transmission parameters under various environments and incorporate newly developed methods without significantly changing the main body of the server code. Results indicate that the expert system can efficiently deliver smooth streams and save server resources. The overhead brought along with the flexibility is tested to be acceptable.	algorithm;ansari x prize;central processing unit;experiment;expert system;forsyth–edwards notation;ieee transactions on multimedia;ieee/acm transactions on networking;knowledge base;letter-quality printer;logic programming;media server;network congestion;optical burst switching;overhead (computing);performance;propagation constant;random early detection;scalability;server (computing);session (computer science);streaming media;throughput;xml	Xiaofei Zhou;Kenneth Ong	2007	21st International Conference on Advanced Information Networking and Applications (AINA '07)	10.1109/AINA.2007.20	xml;computer science;artificial intelligence;operating system;data mining;database;world wide web;expert system;network topology;server farm	DB	-6.71771907381423	96.5044305814127	22932
e72618ea385f9331af07641df7520490c0bf42dc	multicast routing in 40 gb/s heterogeneous optical networks	optical network;wavelength routing;multicast communication;shortest path algorithm;bandwidth allocation;trees mathematics;optical networks;multicast tree;optical fibre networks;telecommunication traffic;telecommunication network routing;optical wavelength conversion;intelligent networks optical fiber networks wavelength division multiplexing optical fiber devices wavelength routing optical wavelength conversion bandwidth repeaters telecommunication traffic optical receivers;wavelength conversion;wavelength conversion multicast routing multirate traffic mrmt heterogeneous optical network bandwidth utilization wdm equipment tdm equipment multicast tree shortest path algorithm;multicast routing;multicast;bandwidth allocation multicast communication telecommunication network routing telecommunication traffic optical fibre networks trees mathematics optical wavelength conversion	This paper addresses multicast routing in 40 Gb/s traffic in heterogeneous optical networks. The multicast routing of multi-rate traffic (MRMT) problem is informally defined as the process of finding the best routing which maximizes the total bandwidth utilization in the network, for a given set of sessions, and a given WDM and TDM equipment budget. In our model, a multicast connection is realized by constructing a multicast tree. The whole process is divided into two steps. Numerical results demonstrate our approach utilizes network resources more efficiently, as compared to the approach based on shortest path algorithm.	dijkstra's algorithm;experiment;ibm notes;iterative method;mathematical optimization;multicast;numerical method;optical carrier transmission rates;requirement;routing;shortest path problem;wavelength-division multiplexing	Kefei Wang;Maher Ali;Jitender S. Deogun	2005	IEEE International Conference on Communications, 2005. ICC 2005. 2005	10.1109/ICC.2005.1494617	policy-based routing;routing;static routing;multicast;dijkstra's algorithm;ip multicast;inter-domain;reliable multicast;telecommunications;protocol independent multicast;computer science;dynamic source routing;destination-sequenced distance vector routing;pragmatic general multicast;distributed computing;link-state routing protocol;distance vector multicast routing protocol;source-specific multicast;xcast;computer network;multicast address;bandwidth allocation	Robotics	-5.289504203134795	82.86831072818103	22939
c65a2f94976f1bb134ad11b6e7cee02a37b3efb7	the kdm-cca security of the kurosawa-desmedt scheme			kde display manager	Jinyong Chang;Rui Xue;Anling Zhang	2015	IEICE Transactions		chosen-ciphertext attack;computer science;distributed computing;internet privacy;computer security	Crypto	-44.423731286017215	76.11537624552462	22966
c97de5525b01dc81f0e2d7e5b2d1e096e2e58ffa	adaptive cca broadcast encryption with constant-size secret keys and ciphertexts		We consider designing broadcast encryption schemes with constant-size secret keys and ciphertexts, achieving chosen-ciphertext security. We first argue that known CPA-to-CCA transforms currently do not yield such schemes. We then propose a scheme, modifying a previous selective CPA secure proposal by Boneh, Gentry, and Waters. Our proposed scheme has constant-size secret keys and ciphertexts and we prove that it is selective chosen-ciphertext secure based on standard assumptions. Our scheme has ciphertexts that are shorter than those of the previous CCA secure proposals. Then we propose a second scheme that provides the functionality of both broadcast encryption and revocation schemes simultaneously using the same set of parameters. Finally we show that it is possible to prove our first scheme adaptive chosen-ciphertext secure under reasonable extensions of the bilinear Diffie-Hellman exponent and the knowledge of exponent assumptions. We prove both of these extended assumptions in the generic group model. Hence, our scheme becomes the first to achieve constant-size secret keys and ciphertexts (both asymptotically optimal) and adaptive chosen-ciphertext security at the same time.	broadcast encryption	Duong Hieu Phan;David Pointcheval;Siamak Fayyaz Shahandashti;Mario Strefler	2012		10.1007/978-3-642-31448-3_23	theoretical computer science;mathematics;internet privacy;computer security	Crypto	-40.12319290356426	75.94036865843454	23039
1c49123d5adcd347203b6472c68ed300d6283296	research on coverage and link of multi-layer satellite network based on stk	global coverage;simulation system;会议论文;multi layer satellite network;permanent link	This paper proposed a multi-layer satellite network to archive the global communication, facilitate the complexity of link handover and create the permanent link. The STK (Satellite Tools Kit) is used to design the satellite network according to the simulation objects including the scenario, satellite, facility and constellation, and further more the coverage analysis and link analysis capabilities are respectively designed to study the network performance. A satellite library is also constructed to allow users to call existing satellites and the data transmission capability is designed for client to receive simulation data from server during the simulation. As the simulation results shown in this paper, the design of HSBN (Hierarchical Space-Based Network) can satisfy requirements of global coverage and permanent link. The proposed satellite network can realize the global communication and reduce link handover complexity over the entire operating cycle.	archive;code coverage;layer (electronics);link analysis;network performance;requirement;stk;server (computing);simulation;toshiba satellite	Junqing Qi;Zhuoming Li;Gongliang Liu	2015	2015 10th International Conference on Communications and Networking in China (ChinaCom)	10.1109/CHINACOM.2015.7497975	telecommunications;network simulation;computer network	Mobile	-11.242987824057494	84.96914254896387	23043
12a9466f10f0c64d4957e3cb4296a4cc2c740761	on the design and quantification of privacy preserving data mining algorithms	information loss;robust estimator;privacy preservation;maximum likelihood estimate;expectation maximization;data mining algorithm;em algorithm;privacy preserving data mining	The increasing ability to track and collect large amounts of data with the use of current hardware technology has lead to an interest in the development of data mining algorithms which preserve user privacy. A recently proposed technique addresses the issue of privacy preservation by perturbing the data and reconstructing distributions at an aggregate level in order to perform the mining. This method is able to retain privacy while accessing the information implicit in the original attributes. The distribution reconstruction process naturally leads to some loss of information which is acceptable in many practical situations. This paper discusses an Expectation Maximization (EM) algorithm for distribution reconstruction which is more effective than the currently available method in terms of the level of information loss. Specifically, we prove that the EM algorithm converges to the maximum likelihood estimate of the original distribution based on the perturbed data. We show that when a large amount of data is available, the EM algorithm provides robust estimates of the original distribution. We propose metrics for quantification and measurement of privacy-preserving data mining algorithms. Thus, this paper provides the foundations for measurement of the effectiveness of privacy preserving data mining algorithms. Our privacy metrics illustrate some interesting results on the relative effectiveness of different perturbing distributions.	aggregate data;data mining;expectation–maximization algorithm;internet privacy	Dakshi Agrawal;Charu C. Aggarwal	2001		10.1145/375551.375602	expectation–maximization algorithm;computer science;data science;data mining;database;statistics	ML	-39.13541509233532	63.14140576313322	23071
692f7846d186a35a4bcb04108399ea3efe433528	scalable network emulation - the net approach	node virtualization;migration;placement;virtual time;scalable network emulation	Network emulation is an efficient method for evaluating distributed applications and communication protocols by combining the benefits of real world experiments and network simulation. The process of network emulation involves the execution of connected virtual nodes running the software under test in a controlled environment. Our Network Emulation Testbed (NET) achieves high scalability by combining efficient node virtualization and adaptive virtual time. In this paper, we provide an overview of our system. First, we introduce our efficient emulation architecture. Second, we present our approaches (NETplace and NETbalance) to minimize the runtime of the network experiments. The idea of NETplace is to minimize the load of the testbed by calculating an initial placement of virtual nodes onto the testbed nodes. During the runtime of the experiment NETbalance adapts this placement to changed resource requirements of the software under test. Finally, we introduce NETcaptain, a graphical user interface to setup, control and visualize network experiments.	distributed computing;emulator;experiment;graphical user interface;hardware virtualization;network emulation;network security;requirement;scalability;simulation;testbed;x86 virtualization	Andreas Grau;Klaus Herrmann;Kurt Rothermel	2012	JCM	10.4304/jcm.7.1.3-16	embedded system;real-time computing;computer science;human migration;operating system;distributed computing;computer network;hardware emulation;placement	Networks	-16.52130907845812	80.90719099841732	23098
5087fa690aa37d248649e46a005b356c51b0e5fe	boosting ethernet performance by segment-based routing	routing protocols;off the shelf equipment;fault tolerant;fault tolerant capability;static reconfiguration;topology agnostic routing algorithms;bandwidth allocation;tree based turn prohibition segment based routing cluster networks routing algorithm 802 3 ethernet technology off the shelf equipment ethernet clusters fault tolerant capability virtual channels static reconfiguration spanning tree protocol topology agnostic routing algorithms;workstation clusters bandwidth allocation local area networks routing protocols;segment based routing;virtual channel;802 3 ethernet technology;routing algorithm;cost effectiveness;virtual channels;boosting ethernet networks routing clustering algorithms topology bandwidth strontium turning scalability fault tolerance;ethernet clusters;workstation clusters;tree based turn prohibition;spanning tree protocol;high performance;off the shelf;cluster networks;local area networks	Ethernet is turning out to be a cost-effective solution for building cluster networks offering compatibility, simplicity, high bandwidth, scalability and a good performance-to-cost ratio. Nevertheless, Ethernet still makes inefficient use of network resources (links) and suffers from long failure recovery time due to the lack of a suitable routing algorithm. In this paper we embed an efficient routing algorithm into 802.3 Ethernet technology, making it possible to use off-the-shelf equipment to build high-performance and cost-effective Ethernet clusters, with an efficient use of link bandwidth and with fault tolerant capabilities. The algorithm, referred to as segment-based routing (SR), is a deterministic routing algorithm that achieves high performance without the need for virtual channels (not available in Ethernet). Moreover, SR is topology agnostic, meaning it can be applied to any topology, and tolerates any combination of faults derived from the original topology when combined with static reconfiguration. Through simulations we verify an overall improvement in throughput by a factor of 1.2 to 10.0 when compared to the conventional Ethernet routing algorithm, the spanning tree protocol (STP), and other topology agnostic routing algorithms such as Up*/Down* and tree-based turn-prohibition, the last one being recently proposed for Ethernet	algorithm;boosting (machine learning);deterministic routing;fault tolerance;file spanning;locality of reference;scalability;semiconductor industry;simulation;spanning tree protocol;throughput	Andres Mejia;Jose Flich;José Duato;Sven-Arne Reinemo;Tor Skeie	2007	15th EUROMICRO International Conference on Parallel, Distributed and Network-Based Processing (PDP'07)	10.1109/PDP.2007.28	local area network;routing;fault tolerance;static routing;parallel computing;real-time computing;cost-effectiveness analysis;synchronous ethernet;rdma over converged ethernet;ethernet flow control;computer science;dynamic source routing;multipath routing;destination-sequenced distance vector routing;distributed computing;ethernet over sdh;routing protocol;link-state routing protocol;spanning tree protocol;computer network;bandwidth allocation	HPC	-9.387800928670446	80.18811152577503	23131
0fa7d6b6becc4d59197abf1b4f90e661c48ef771	intrusion detection technique for black hole attack in mobile ad hoc networks	packet queueing delay time;aodv;mobile networks;manets;simulation;rrep;intrusion detection;destination sequence number;malicious nodes;mobile ad hoc networks;black hole attacks;packet processing delay time;hop count;route reply;rreq	A black hole attack is particularly harmful against routing in mobile ad hoc networks where a malicious node tries to capture the path toward itself by falsely claiming a fresh and shortest route to the destination, and then drops all the receiving data packets instead of forwarding them to the destination node. This paper presents an intrusion detection technique for detecting and isolating the black hole attack from AODV-based MANETs by employing the detection mechanism at the source node. The detection mechanism uses the destination sequence number, hop count, and average of packet processing delay and queueing delay time of routing packets in order to detect the black hole attack. The main strength of the proposed detection mechanism is to preserve the network resources by eliminating additional control traffic overhead. The simulation results demonstrate the effectiveness of the proposed mechanism in the presence of black hole attacks.	black hole;hoc (programming language);intrusion detection system	Sunil Kumar;Kamlesh Dutta	2015	IJIPSI	10.1504/IJIPSI.2015.075435	packet drop attack;optimized link state routing protocol;geography;telecommunications;computer security;computer network	Mobile	-54.84984132836624	76.07444142342972	23140
7b0c4e834bcad93e61bdb8c5241fe86c77f5bab2	interworking between the session initiation protocol (sip) and the extensible messaging and presence protocol (xmpp): presence		This document defines a bidirectional protocol mapping for the#N#exchange of single instant messages between the Session Initiation#N#Protocol (SIP) and the Extensible Messaging and Presence Protocol#N#(XMPP).		Peter Saint-Andre;Avshalom Houri;Joe Hildebrand	2014	RFC	10.17487/RFC7248	bosh;session description protocol;session announcement protocol;user datagram protocol;srv record;stateless protocol;internet protocol control protocol;operating system;session initiation protocol;world wide web;computer network	Theory	-25.068603714999345	87.90805437227799	23164
a521a6cc4c1f597665cc682d65efdd52299705af	an efficient algorithm for virtual-wavelength-path routing minimizing average number of hops	minimisation;resource utilization;optical network;average hop length virtual wavelength path routing wavelength assignment wavelength division multiplexing wdm optical networks network cost minimization resource utilization maximization traffic demand network topology minimum hop path assignment;wavelength assignment;resource allocation;efficient algorithm;wdm optical network;supercomputer education research centre;indexing terms;network routing;network topology;telecommunication traffic telecommunication network routing network topology minimisation wavelength division multiplexing optical fibre networks resource allocation;optical fibre networks;telecommunication traffic;telecommunication network routing;routing and wavelength assignment;wavelength assignment costs resource management telecommunication traffic network topology heuristic algorithms wavelength routing wavelength division multiplexing optical fiber networks optical wavelength conversion;wavelength conversion;heuristic algorithm;wavelength division multiplexing;wavelength division multiplex	In this paper, we present a novel heuristic for routing and wavelength assignment in Virtual-Wavelength-Path (VWP) routed WDM optical networks. We are the first to take up the approach of both minimizing the network cost as well as maximizing the resource utilization. Our algorithm not only minimizes the number of wavelengths required for supporting the given traffic demand on any given topology, but also aims to minimize the mean hop length of all the lightpaths which in turn maximizes the resource utilization. The algorithm initially assigns the minimum hop path to each route and then performs efficient rerouting to reduce the number of wavelengths required while also trying to minimize the average hop length. To further reduce the network cost, we also propose a wavelength assignment procedure for VWP routed networks which minimizes the number of wavelength converters required. Our algorithm has been tested on various topologies for different types of traffic demands and has been found to give solutions much better than previous standards for this problem.	algorithm;heuristic (computer science);network topology;routing and wavelength assignment;wavelength-division multiplexing	Harsha V. Madhyastha;N. Balakrishnan	2003	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2003.818228	heuristic;minimisation;routing;in situ resource utilization;index term;telecommunications;resource allocation;computer science;distributed computing;network topology;wavelength-division multiplexing;computer network	Metrics	-4.991400116846306	82.54035784843204	23168
68433bad68422104e0113f1c5be57e585240d52f	secure multi-party protocols for item-based collaborative filtering		Recommender systems have become extremely common in recent years, and are utilized in a variety of domains such as movies, music, news, products, restaurants, etc. While a typical recommender system bases its recommendations solely on users' preference data collected by the system itself, the quality of recommendations can significantly be improved if several recommender systems (or vendors) share their data. However, such data sharing poses significant privacy and security challenges, both to the vendors and the users. In this paper we propose secure protocols for distributed item-based Collaborative Filtering. Our protocols allow to compute both the predicted ratings of items and their predicted rankings, without compromising privacy nor predictions' accuracy. Unlike previous solutions in which the secure protocols are executed solely by the vendors, our protocols assume the existence of a mediator that performs intermediate computations on encrypted data supplied by the vendors. Such a mediated setting is advantageous over the non-mediated one since it enables each vendor to communicate solely with the mediator. This yields reduced communication costs and it allows each vendor to issue recommendations to its clients without being dependent on the availability and willingness of the other vendors to collaborate.	algorithm;collaborative filtering;communications protocol;computation;cryptography;emoticon;encryption;interaction;library (computing);matchware mediator;mediator pattern;privacy;recommender system;standard library	Erez Shmueli;Tamir Tassa	2017		10.1145/3109859.3109881	data mining;collaborative filtering;recommender system;encryption;computation;computer science;vendor;data sharing	Web+IR	-38.68450007377084	65.92927310550444	23170
f8a1e347b155cb9ebba65e73a8f044f4355e7310	new results on impossible differential cryptanalysis of reduced-round camellia-128	block cipher;differential cryptanalysis;internal standard	Camellia, a 128–bit block cipher which has been accepted by ISO/IEC as an international standard, is increasingly being used in many cryptographic applications. In this paper, using the redundancy in the key schedule and accelerating the filtration of wrong pairs, we present a new impossible differential attack to reduced–round Camellia. By this attack 12–round Camellia–128 without FL/FL−1 functions and whitening is breakable with a total complexity of about 2 encryptions and 2 chosen plaintexts. In terms of the numbers of the attacked rounds, our attack is better than any previously known attack on Camellia–128.	block cipher;cryptography;fast software encryption;hash table;image-line fl studio;impossible differential cryptanalysis;integral cryptanalysis;key schedule;lecture notes in computer science;plaintext;springer (tank);time complexity;whitening transformation	Hamid Mala;Mohsen Shakiba;Mohammad Dakhilalian;Ghadamali Bagherikaram	2009		10.1007/978-3-642-05445-7_18	block cipher;contact analysis;differential cryptanalysis;kasiski examination;two-square cipher;mod n cryptanalysis;piling-up lemma;xsl attack;boomerang attack;higher-order differential cryptanalysis;impossible differential cryptanalysis;linear cryptanalysis;confusion and diffusion	Crypto	-38.26821975490142	80.41627288199423	23209
befd764d614a6a062f9028878f85ff6ce7bd4c0f	efficient authentication scheme for data aggregation in smart grid with fault tolerance and fault diagnosis	high availability;handwriting recognition;performance evaluation;fault tolerant;availability;signature verification;authentication;satisfiability;power system faults;smart grids;fault tolerant system;smart power grids;fault tolerant systems;digital signature;data aggregation;fault tolerance;communication overhead authentication scheme data aggregation smart grid fault tolerance fault diagnosis per packet signature per signature verification signature aggregation schemes batch verification schemes signature amortization schemes;smart grids authentication fault diagnosis fault tolerance fault tolerant systems availability;smart grids authentication batch verification digital signature fault tolerance fault diagnosis;smart power grids fault diagnosis fault tolerance handwriting recognition power system faults;fault diagnosis;batch verification	Authentication schemes relying on per-packet signature and per-signature verification introduce heavy cost for computation and communication. Due to its constraint resources, smart grid's authentication requirement cannot be satisfied by this scheme. Most importantly, it is a must to underscore smart grid's demand for high availability. In this paper, we present an efficient and robust approach to authenticate data aggregation in smart grid via deploying signature aggregation, batch verification and signature amortization schemes to less communication overhead, reduce numbers of signing and verification operations, and provide fault tolerance. Corresponding fault diagnosis algorithms are contributed to pinpoint forged or error signatures. Both experimental result and performance evaluation demonstrate our computational and communication gains.	algorithm;antivirus software;authentication;computation;data aggregation;fault tolerance;high availability;network packet;overhead (computing);performance evaluation;smart card	Depeng Li;Zeyar Aung;John R. Williams;Abel Sanchez	2012	2012 IEEE PES Innovative Smart Grid Technologies (ISGT)	10.1109/ISGT.2012.6175680	real-time computing;engineering;distributed computing;computer security	Mobile	-47.51781638693343	75.95496249606755	23222
1b2f249e413c87f09632af28586ce420897779c4	dvb: from broadcasting to ip delivery	internet protocol;mpeg2 ts;digital video broadcast;ipdc;h 264;dvb;iptv	This paper gives a brief overview of the Digital Video Broadcasting (DVB) project. Starting in 1993, this project produced standards for digital broadcasting in all media (satellite, cable, terrestrial) using return channels of various kinds. In the current phase, DVB has also embraced Internet Protocol (IP) based delivery on telco and cable.	digital video broadcasting;terrestrial television	Helmut Bürklin;Ralf Schäfer;Dietrich Westerkamp	2007	Computer Communication Review	10.1145/1198255.1198266	internet protocol;embedded system;telecommunications;computer science;digital video broadcasting;computer network	Networks	-17.761182418714203	93.75782213662713	23226
