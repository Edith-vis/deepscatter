id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
3566247ccad3aee2ebf45fdc29baa8a725d20ee9	a pomdp approach to the dynamic defense of large-scale cyber networks		We investigate the problem of optimally mitigating the progression of an adversary through a network in real-time, decreasing the probability of it reaching its goal(s), while minimizing the negative impact to availability. Our model is based on a type of attack graph, termed a condition dependency graph, which models the dependencies between security conditions (attacker capabilities) and exploits. By embedding a state space on the graph, we are able to quantify the progression of the attacker over time. The defender is able to interfere with the attacker’s progression by blocking some exploits from being carried out. The nature of the attacker’s progression through the network is dictated by its private strategy, which depends on the defender’s action. The defender’s uncertainty of the attacker’s true strategy is modeled by considering a finite collection of attacker types. Using noisy security alerts (exhibiting both missed detections and false alarms), the defender maintains a belief representing the joint distribution over the attacker’s current capabilities and true strategy. The resulting problem of determining how to optimally interfere with the attacker’s progression is cast as a partially observable Markov decision process. To deal with the large state space, we develop a scalable online defense algorithm for tracking beliefs and prescribing defense actions over time. Using the context provided by the state, we are able to efficiently process security alerts even in the presence of a high rate of false alarms. The behavior of the computed defense policy is demonstrated on an illustrative example.	adversary (cryptography);algorithm;blocking (computing);color gradient;computation;control theory;exploit (computer security);general instrument ay-3-8910;interaction;intrusion detection system;linear separability;mason;markov chain;network security;partially observable markov decision process;partially observable system;real-time clock;real-time web;scalability;sensor;state space;stochastic control	Erik Miehling;Mohammad Rasouli;Demosthenis Teneketzis	2018	IEEE Transactions on Information Forensics and Security	10.1109/TIFS.2018.2819967	computer vision;computer science;machine learning;partially observable markov decision process;artificial intelligence	Web+IR	-64.58695817680757	61.26640658745842	5675
65f39b83700156d1f8da7c603ae0594ffb0e3ea6	off-line analysis of internet traffic for accurate identification of p2p applications using neural networks	erbium;dynamic port numbers;resource provisioning;capacity planning;neural networks;encrypted payloads;offline analysis;multilayer perceptrons;port hopping;p2p;multi layer perceptron traffic classification flow features radial basis function network;flow features;multilayer perceptron;data mining;data model;multilayer perceptron offline analysis internet traffic p2p applications identification neural networks application specific traffic engineering capacity planning resource provisioning service differentiation obfuscation techniques dynamic port numbers port hopping encrypted payloads radial basis function network;radial basis function networks;telecommunication traffic;servers;mlp neural network;internet traffic;internet java erbium data mining data models servers educational institutions;internet;radial basis function network;model building;obfuscation techniques;traffic classification;telecommunication traffic internet multilayer perceptrons peer to peer computing radial basis function networks;service differentiation;p2p applications identification;multi layer perceptron;traffic engineered;application specific traffic engineering;peer to peer computing;rbf network;data models;neural network;java	P2P applications supposedly constitute a substantial proportion of today's Internet traffic. The ability to accurately identify different P2P applications in internet traffic is important to a broad range of network operations including application-specific traffic engineering, capacity planning, resource provisioning, service differentiation, etc. However, current P2P applications use several obfuscation techniques, including dynamic port numbers, port hopping, and encrypted payloads. As P2P applications continue to evolve, robust and effective methods are needed for identification of P2P applications. In this paper, we compare two neural network approaches (Radial Basis Function Network and Multi-Layer Perceptron) that precisely identify the P2P traffic. We find out that RBFN outperforms MLP neural network, but owing to the large time taken for model building, RBF network is found suitable for off-line identification of P2P applications in the internet traffic.	artificial neural network;encryption;frequency-hopping spread spectrum;memory-level parallelism;multilayer perceptron;online and offline;peer-to-peer;provisioning;radial (radio);radial basis function network	Sunil Agrawal;B. S. Sohi	2012	2012 1st International Conference on Recent Advances in Information Technology (RAIT)	10.1109/RAIT.2012.6194633	traffic generation model;network traffic control;computer science;data mining;distributed computing;internet traffic engineering;computer network	Metrics	-63.80045497550189	66.7163426150793	7061
d33c77df11357b248270eaa4f59b3bec878fc95e	the algorithm model for cumulative vulnerability risk assessment	cumulative risk;vulnerability;risk assessment;rough sets;reverse iteration algorithm	The network information security vulnerability assessment consists of two kinds of risks. The stable risks of vulnerability itself and the cumulative multi-risks that are generated from a successful attack and which can impact on the whole network. To count cumulative multi-risk, a new method has been developed, which uses vulnerabilities in attack graph and reverse iteration tracing algorithm based on rough sets. Two kinds of cumulative multi-risks will be identified, named ‘the worst state’ and ‘the critical state’. The experimental evidences prove the veracity and validity of the new algorithm model.	algorithm;approximation;information security;information system;iteration;network topology;risk assessment;rough set;veracity;vulnerability (computing)	Yong Yan Chen;Hong Chun Shu	2014	IJIPT	10.1504/IJIPT.2014.066362	risk assessment;rough set;vulnerability;computer science;data mining;computer security	Security	-63.09282497250396	63.363439317260664	7172
be7cf0760385645f7402825efbb4b9ca0e93f32f	traffic classification using a statistical approach	statistical approach;analisis estadistico;gestion trafic;probabilistic approach;traffic management;high precision;classification;bayes estimator;internet;statistical analysis;enfoque probabilista;approche probabiliste;precision elevee;analyse statistique;traffic classification;precision elevada;gestion trafico;clasificacion	Accurate traffic classification is the keystone of numerous network activities. Our work capitalises on hand-classified network data, used as input to a supervised Bayes estimator. We illustrate the high level of accuracy achieved with a supervised Naı̈ve Bayes estimator; with the simplest estimator we are able to achieve better than 83% accuracy on both a per-byte and a per-packet basis.	byte;high-level programming language;keystone effect;naive bayes classifier;network packet;traffic classification	Denis Zuev;Andrew W. Moore	2005		10.1007/978-3-540-31966-5_25	minimax estimator;econometrics;active traffic management;the internet;traffic classification;bayes estimator;biological classification;computer science;data mining;statistics	Metrics	-63.49493235461715	69.29924217127086	8919
f61a5cc0af2ca18f3aeaa6b21948a1257bca6fca	hybrid modeling for large-scale worm propagation simulations	internet incidents;haute performance;securite informatique;simulation;modelo hibrido;distributed computing;service web;intelligence artificielle;web service;modele hybride;hybrid model;computer security;large scale;internet;seguridad informatica;network model;alto rendimiento;terrorisme;calculo repartido;artificial intelligence;inteligencia artificial;internet worms;terrorismo;high performance;calcul reparti;servicio web;terrorism;network modeling	Internet becomes more and more popular, and most companies and institutes use web services for e-business and many other purposes. As results, Internet and web services become core infrastructure for a company or an institute. With the explosion of Internet, the occurrence of cyber terrorism has grown very rapidly. It is difficult to find and close all security flaws in a computer system that is connected to a network. Internet worms take advantages of these security flaws, and attack a large number of hosts with self-propagating techniques. To study and analyze internet worms, one of the most feasible ways is to use simulations. It is quite challenging to simulate very large-scale worm attacks. In this paper, we propose a hybrid model for large-scale worm propagation simulations.		Eul-Gyu Im;Jung-Taek Seo;Dong-Soo Kim;Yong Ho Song;Yongsu Park	2006		10.1007/11760146_59	simulation;computer science;artificial intelligence;network model;law;world wide web;computer security	Vision	-63.23916882307152	70.8278283974758	9164
4ba4efd9a0c47ce0f6624c19944a7f57f0f9490a	select: self-learning classifier for internet traffic	protocols;training;unsupervised machine learning traffic classification clustering self seeding;accuracy;servers;clustering algorithms protocols ports computers accuracy servers algorithm design and analysis training;clustering algorithms;ports computers;algorithm design and analysis	Network visibility is a critical part of traffic engineering, network management, and security. The most popular current solutions - Deep Packet Inspection (DPI) and statistical classification, deeply rely on the availability of a training set. Besides the cumbersome need to regularly update the signatures, their visibility is limited to classes the classifier has been trained for. Unsupervised algorithms have been envisioned as a viable alternative to automatically identify classes of traffic. However, the accuracy achieved so far does not allow to use them for traffic classification in practical scenario. To address the above issues, we propose SeLeCT, a Self-Learning Classifier for Internet Traffic. It uses unsupervised algorithms along with an adaptive seeding approach to automatically let classes of traffic emerge, being identified and labeled. Unlike traditional classifiers, it requires neither a-priori knowledge of signatures nor a training set to extract the signatures. Instead, SeLeCT automatically groups flows into pure (or homogeneous) clusters using simple statistical features. SeLeCT simplifies label assignment (which is still based on some manual intervention) so that proper class labels can be easily discovered. Furthermore, SeLeCT uses an iterative seeding approach to boost its ability to cope with new protocols and applications. We evaluate the performance of SeLeCT using traffic traces collected in different years from various ISPs located in 3 different continents. Our experiments show that SeLeCT achieves excellent precision and recall, with overall accuracy close to 98%. Unlike state-of-art classifiers, the biggest advantage of SeLeCT is its ability to discover new protocols and applications in an almost automated fashion.	algorithm;best, worst and average case;bootstrapping (compilers);cluster analysis;deep packet inspection;electronic signature;experiment;filter (signal processing);iteration;precision and recall;push technology;random seed;semiconductor industry;statistical classification;test set;tracing (software);traffic classification;trojan horse (computing);type signature;ios	Luigi Grimaudo;Marco Mellia;Elena Baralis;Ram Keralapura	2014	IEEE Transactions on Network and Service Management	10.1109/TNSM.2014.011714.130505	communications protocol;algorithm design;computer science;operating system;machine learning;data mining;accuracy and precision;cluster analysis;world wide web;computer security;server;computer network	Security	-63.28558885461046	66.34393885236453	11696
1a0312e6f9e748e6542df21890d0c6eada12d297	preset: a toolset for the evaluation of network resilience strategies	internet worm behaviour;resilience specific functionality;protocols;dynamic network reconfiguration;computer network security;resilience mechanisms;resilience grippers protocols monitoring entropy internet adaptation models;preset;ponder2 policy based management framework;computer network resilience problem;internet;resilience;monitoring;grippers;resilience strategies;invasive software;event driven policies;omnet simulation environment;entropy;invasive software computer network reliability computer network security internet;adaptation models;computer network resilience problem preset resilience strategies dynamic network reconfiguration resilience specific functionality event driven policies ponder2 policy based management framework omnet simulation environment resilience mechanisms internet worm behaviour;computer network reliability	Computer networks support many of the services that our society relies on. Therefore, ensuring their resilience to faults and challenges, such as attacks, is critical. To do this can require the execution of resilience strategies that perform dynamic reconfiguration of networks, including resilience-specific functionality. It is important that resilience strategies are evaluated prior to their execution, for example, to ensure they will not exacerbate an on-going problem. To facilitate this activity, we have developed a toolset that supports the evaluation of resilience strategies that are specified as event-driven policies. The toolset couples the Ponder2 policy-based management framework and the OMNeT++ simulation environment. In this paper, we discuss the network resilience problem and motivate simulation as a suitable way to evaluate resilience strategies. We describe the toolset we have developed, including its architecture and the implementation of a number of resilience mechanisms, and its application to evaluating strategies that detect and mitigate Internet worm behaviour.	event-driven programming;simulation	Alberto E. Schaeffer Filho;Andreas Mauthe;David Hutchison;Paul Smith;Yue Yu;Michael Fry	2013	2013 IFIP/IEEE International Symposium on Integrated Network Management (IM 2013)		communications protocol;entropy;the internet;simulation;computer science;network security;law;computer security;psychological resilience;computer network	Arch	-63.17482240963324	60.70438546496612	12373
36026cd7c7937821ff749d7f83098937e981fb49	modeling modern network attacks and countermeasures using attack graphs	netspa attack graph system;reachability analysis authorisation computer network security graph theory;software;graph theory;client side attack;proxy firewall;reverse reachability computation modeling modern network attack enterprise networks risk measurement netspa attack graph system zero day exploit client side attack intrusion prevention system proxy firewall personal firewall host based vulnerability scan point to point reachability algorithm;computer network security;boolean functions;authorisation;point to point;modeling modern network attack;scap;data mining;servers;computational modeling;enterprise networks risk measurement;network defense;intrusion prevention system;personal firewall;data structures;computational modeling computer networks analytical models computer security application software laboratories protection computer worms risk management military computing;attack tree network reachability network defense scap attack graph;present day;tree network;network reachability;point to point reachability algorithm;fires;zero day exploit;attack graph;reverse reachability computation;reachability analysis;host based vulnerability scan;attack tree	"""By accurately measuring risk for enterprise networks, attack graphs allow network defenders to understand the most critical threats and select the most effective countermeasures. This paper describes substantial enhancements to the NetSPA attack graph system required to model additional present-day threats (zero-day exploits and client-side attacks) and countermeasures (intrusion prevention systems, proxy firewalls, personal firewalls, and host-based vulnerability scans). Point-to-point reachability algorithms and structures were extensively redesigned to support """"reverse"""" reachability computations and personal firewalls. Host-based vulnerability scans are imported and analyzed. Analysis of an operational network with 84 hosts demonstrates that client-side attacks pose a serious threat. Experiments on larger simulated networks demonstrated that NetSPA's previous excellent scaling is maintained. Less than two minutes are required to completely analyze a four-enclave simulated network with more than 40,000 hosts protected by personal firewalls."""	algorithm;application firewall;client-side;computation;fibre channel point-to-point;firewall (computing);image scaling;intrusion detection system;personal firewall;reachability	Kyle Ingols;Matthew Chu;Richard Lippmann;Seth E. Webster;Stephen W. Boyer	2009	2009 Annual Computer Security Applications Conference	10.1109/ACSAC.2009.21	point-to-point;computer science;graph theory;operating system;distributed computing;authorization;boolean function;zero-day attack;computational model;computer security;intrusion prevention system;server;computer network	Security	-63.16735169140016	60.614976123910616	15061
edb707cda872d19bed57d934bb92a9d0fb684d37	an evaluation of connection characteristics for separating network attacks	extraction information;analisis estadistico;protocole transmission;analisis datos;information extraction;securite informatique;attack families;attack family separation;attaque informatique;data mining;protocole tcp;transmission control protocol;computer security;data analysis;protocolo transmision;honeypot;statistical analysis;forensic science;network attacks;monitoring;protocolo tcp;fouille donnee;police scientifique;seguridad informatica;analyse statistique;computer attack;ataque informatica;analyse donnee;successful attacks;ciencia forense;unsuccessful attacks;monitorage;monitoreo;attack characteristics;security;busca dato;extraccion informacion;transmission protocol	The goal of this paper is to evaluate the efficiency of connection characteristics to separate different attack families that target a single TCP port. Identifying the most relevant characteristics might allow statistically separating attack families without systematically using forensics. This study is based on a dataset collected over 117 days using a test-bed of two high interaction honeypots. The results indicated that to separate unsuccessful from successful attacks in malicious traffic: • the number of bytes is a relevant characteristic • time-based characteristics are poor characteristics • using combinations of characteristics does not improve the efficiency of separating attacks.	algorithm;baseline (configuration management);byte;cluster analysis;computer forensics;data mining;honeypot (computing);interaction;k-means clustering;network packet;server message block;testbed	Robin Berthier;Michel Cukier	2009	IJSN	10.1504/IJSN.2009.023430	telecommunications;computer science;information security;transmission control protocol;honeypot;data analysis;forensic science;world wide web;computer security;information extraction	Metrics	-62.895509577565186	69.42317015267722	15298
fa451179f483cd4fdfb2ce0d717cb184ae77db74	multi-agent based approach of botnet detection in computer systems		A new approach for the botnet detection based on multi-agent system is proposed. For increasing of the efficiency of botnet detection multi-agent systems were involve that allowed to make antivirus diagnosis via agents’ communication within corporate network. The structure and main principles of antiviral agents’ functioning within multi-agent system are developed. The principles of communication between the agent’s units before and after attack on the computer system were developed. A new technique for sensor diagnosis in monitor mode which uses fuzzy logic was developed. A new technique for sensor diagnosis in scanner mode with generation of detectors using the modified negative selection algorithm was developed.	botnet;hardware description language	Oleg Savenko;Sergiy Lysenko;Andriy Kryschuk	2012		10.1007/978-3-642-31217-5_19	real-time computing;fuzzy logic;botnet;scanner;multi-agent system;computer science;monitor mode	Security	-65.00312522255908	63.29008859848656	18424
2148b6d1e055f4a7f1dd8e050bf0d50ea0db39f4	an integrated scheme for intrusion detection in wlan	utilisation information;distributed system;intruder detector;uso informacion;wireless local area network;systeme reparti;man in the middle attack;information use;maquina estado finito;securite informatique;intrusion detection;attaque informatique;computer security;sistema repartido;oui;seguridad informatica;denial of service;intrusion detection systems;analyse sequence;computer attack;ataque informatica;sequence analysis;wireless lan;information system;detecteur intrus;machine etat fini;detector intruso;reseau local sans fil;finite state machine;systeme information;systeme detection intrusion;denegacion de servicio;deni service;sistema informacion;dos attack	Wireless Local Area Network (WLAN) is susceptible to security provisioning in spite of the solutions such as the Wired Equivalent Protocol (WEP) or IEEE 802.1x. This paper proposes an integrated scheme for intrusion detection in WLAN systems. The proposed scheme operates with one or more Gathering Agents (GAs) and a Master Server (MS). Each GA is used to get security information by collecting the frame packets in WLAN, whereas the MS is purposed to detect and prevent the various attacks by analyzing the packets in the WLAN systems. A detection engine contained in the MS employs ‘OUI list matching’ for detection of MAC spoofing attacks, ‘sequence number analysis’ for man-in-the-middle attacks, and ‘Finite State Machine (FSM) analysis’ for Denial-of-Service (DoS) attacks. By experiments, it is shown that the proposed scheme could effectively detect and prevent the various attacks that could possibly be done in the WLAN systems.	denial-of-service attack;experiment;finite-state machine;ieee 802.1x;intrusion detection system;man-in-the-middle attack;organic user interface;organizationally unique identifier;provisioning;server (computing);software release life cycle;spoofing attack;wired equivalent privacy	Dong Phil Kim;Seok Joo Koh;Sang Wook Kim	2006		10.1007/11919568_72	intrusion detection system;embedded system;telecommunications;computer science;finite-state machine;computer security;denial-of-service attack	Security	-63.60501436706108	70.05092691594767	18975
0c9d42f67b7ed2f35efd504524352636e3f0270e	frequency- and ordering-based similarity measure for host-based intrusion detection	protection information;measurement;deteccion;relacion orden;detector;intruso;securite informatique;frequence;detecteur;system monitoring;ordering;computer crime;intrusion detection;detection;similitude;algorithme;computer security;algorithm;vecino mas cercano;relation ordre;frecuencia;proteccion informacion;medida;information protection;seguridad informatica;similarity;detection rate;plus proche voisin;nearest neighbour;k nearest neighbor;intrus;mesure;similitud;false positive;frequency;intruder;similarity measure;intrusion detection system;algoritmo;data security	This paper discusses a new similarity measure for the anomaly‐based intrusion detection scheme using sequences of system calls. With the increasing frequency of new attacks, it is getting difficult to update the signatures database for misuse‐based intrusion detection system (IDS). While anomaly‐based IDS has a very important role to play, the high rate of false positives remains a cause for concern. Defines a similarity measure that considers the number of similar system calls, frequencies of system calls and ordering‐of‐system calls made by the processes to calculate the similarity between the processes. Proposes the use of Kendall Tau distance to calculate the similarity in terms of ordering of system calls in the process. The k nearest neighbor (kNN) classifier is used to categorize a process as either normal or abnormal. The experimental results, performed on 1998 DARPA data, are very promising and show that the proposed scheme results in a high detection rate and low rate of false positives.	intrusion detection system;similarity measure	Sanjay Rawat;Ved Prakash Gulati;Arun K. Pujari	2004	Inf. Manag. Comput. Security	10.1108/09685220410563397	anomaly-based intrusion detection system;intrusion detection system;computer science;artificial intelligence;data mining;computer security	Security	-63.38176674233717	69.93211636261427	19195
a6838565e52ef42a36c1fa0df918d1bce17d7196	a worm propagation model based on people's email acquaintance profiles	modelizacion;systema diferencial;instant messaging;electronic mail;stochastic process;securite informatique;token protocol;funcion aleatoria;differential system;differential equation;correo electronico;economic model;user reaction;approche deterministe;protocole jeton;deterministic approach;computer security;modelo economico;modelisation;reaction utilisateur;modele economique;internet;random process;network connectivity;random function;seguridad informatica;comportement utilisateur;enfoque determinista;processus stochastique;user behavior;proceso estocastico;modeling;systeme differentiel;protocolo testigo;comportamiento usuario;courriel;fonction aleatoire;reaccion usuario	One frequently employed way of propagation exploited by worms is through the victim's contact book. The contact book, which reflects the acquaintance profiles of people, is used as a “hit-list”, to which the worm can send itself in order to spread fast. In this paper we propose a discrete worm propagation model that relies upon a combined email and Instant Messaging (IM) communication behaviour of users. We also model user reaction against infected email as well as the rate at which antivirus software is installed. User acquaintance is perceived as a “network” connecting users based on their contact book links. We then propose a worm propagation formulation based on a token propagation algorithm, further analyzed with a use of a system of continuous differential equations, as dictated by Wormald's theorem on approximating “well-behaving” random processes with deterministic functions.		Thodoros Komninos;Yannis C. Stamatiou;G. Vavitsas	2006		10.1007/11944874_31	stochastic process;simulation;telecommunications;economic model;random function;mathematics;computer security;differential equation;statistics	Vision	-63.34551255334718	71.31108014943068	20678
94c0215644068de7d094f1fa8ebb8b45b6e898cc	mining association rules for intrusion detection	itemsets;wireless networks;wired networks;mining association rules;wireless network;intrusion detection;association rules;data mining;association rule mining;wired network;association rule;wired networks mining association rules intrusion detection data mining reviews wireless networks;intrusion detection data mining association rule wired network wireless network;ad hoc networks;reviews;data mining association rules intrusion detection wireless networks wireless lan computer science weapons power system protection information security communication system security;security of data data mining reviews;security of data;intrusion detection system	Intrusion detection system has been a powerful weapon to protect networks from attacks and has gained more and more attention. Data mining has been proven as an important method to detect intrusions. It has been the recent research focus and trend to apply data mining techniques in intrusion detection system for discovering new types of attacks, but it is still in its infancy. This paper reviews the new development of association rules mining technologies for intrusion detection in wired as well as wireless networks. The challenges and advanced developments of technologies to use association rule mining for intrusion detection are discussed.	association rule learning;data mining;effective method;intrusion detection system;sensor	Guoping Zhang;Huiguo Chen;Xueshu Jiang	2009	2009 Fourth International Conference on Frontier of Computer Science and Technology	10.1109/FCST.2009.22	anomaly-based intrusion detection system;intrusion detection system;association rule learning;computer science;wireless network;data mining;computer security;intrusion prevention system;computer network	ML	-63.82329630418209	65.01851017017665	21789
2602cd2ff975e8539afed2976226df6c95fbee73	quantitative intrusion intensity assessment using important feature selection and proximity metrics	computers;software metrics;proximity metrics;paramter optimizations;anomaly detection;computer crime;intrusion detection;random forests;software metrics security of data;radio frequency;kdd 1999 dataset;inaccurate detection rates;feature extraction;random forest;quantitative intrusion intensity assessment;classification algorithms;detection rate;kdd 1999 dataset quantitative intrusion intensity assessment feature selection proximity metrics intrusion detection system inaccurate detection rates proximity metrics computation quantitative intensity value random forest;quantitative intensity value;intrusion detection telecommunication computing radio frequency information security aerospace engineering support vector machines support vector machine classification hidden markov models usa councils educational institutions;feature selection;optimization;proximity metrics intrusion detection system random forests feature selection paramter optimizations;proximity metrics computation;security of data;parameter optimization;intrusion detection system	The problem of previous approaches in anomaly detection in Intrusion Detection System (IDS) is to provide only binary detection result; intrusion or normal. This is a main cause of high false rates and inaccurate detection rates in IDS. In this paper, we propose a new approach named Quantitative Intrusion Intensity Assessment (QIIA). QIIA exploits feature selection and proximity metrics computation so that it provides intrusion (or normal) quantitative intensity value. It is capable of representing how an instance of audit data is proximal to intrusion or normal in the form of a numerical value. Prior to applying QIIA to audit data, we perform feature selection and parameters optimization of detection model in order not only to decrease the overheads to process audit data but also to enhance detection rates. QIIA then is performed using Random Forest (RF) and it generates proximity metrics which represent the intrusion intensity in a numerical way. The numerical values are used to determine whether unknown audit data is intrusion or normal. We carry out several experiments on KDD 1999 dataset and show the evaluation results.	algorithm;anomaly detection;computation;data mining;experiment;feature selection;intrusion detection system;mathematical optimization;numerical analysis;radio frequency;random forest	Sang Min Lee;Dong Seong Kim;YoungHyun Yoon;Jong Sou Park	2009	2009 15th IEEE Pacific Rim International Symposium on Dependable Computing	10.1109/PRDC.2009.29	anomaly-based intrusion detection system;intrusion detection system;random forest;anomaly detection;computer science;machine learning;pattern recognition;data mining;feature selection;computer security	Security	-63.979876647405895	64.1889716901363	23569
415b85020b6d34ee93952fc224a72ffc7a26086e	hmm-web: a framework for the detection of attacks against web applications	communications society;web services hidden markov models security of data;application software;hmm web;web and internet services;hidden markov model;training;multiple classifiers system;false alarm rate;intrusion detection;indexing terms;data mining;web applications;html;computer architecture;web application vulnerabilities;intrusion detection hidden markov models hmm web internet services web application vulnerabilities;corona;hidden markov models;feature extraction;information management;web services;detection rate;internet services;book reviews;web server;hidden markov models intrusion detection application software computer architecture service oriented architecture web and internet services communications society corona information management html;service oriented architecture;multiple classifier system;security of data;noise	Nowadays, the web-based architecture is the most frequently used for a wide range of internet services, as it allows to easily access and manage information and software on remote machines. The input of web applications is made up of queries, i.e. sequences of pairs attribute←value. A wide range of attacks exploits web application vulnerabilities, typically derived from input validation flaws. In this work we propose a new formulation of query analysis through Hidden Markov Models (HMM) and show that HMM are effective in detecting a wide range of either known or unknown attacks on web applications. In addition, despite previous works, we explicitly address the problem related to the presence of noise (i.e., attacks) in the training set. Finally, we show that performance can be increased when a sequence of symbols is modelled by an ensemble of HMM. Experimental results on real world data, show the effectiveness of the proposed system in terms of very high detection rates and low false alarm rates. Index Terms —Multiple Classifiers System, Intrusion Detection, Web Applications, Hidden Markov Models	data validation;hidden markov model;internet protocol suite;intrusion detection system;markov chain;sensor;string (computer science);test set;web application	Igino Corona;Davide Ariu;Giorgio Giacinto	2009	2009 IEEE International Conference on Communications	10.1109/ICC.2009.5199054	intrusion detection system;web service;application software;web application;index term;html;corona;feature extraction;computer science;noise;service-oriented architecture;data mining;constant false alarm rate;database;world wide web;web server;hidden markov model;computer network	DB	-64.59961997010909	65.93894094741465	26151
80a3fe2d908713e9d11c830bfb7001cde1e19ef6	from the design of a generic metamorphic engine to a black-box classification of antivirus detection techniques	virus informatique;modelizacion;multiagent system;behavioral analysis;heuristic method;securite informatique;metodo heuristico;boite noire;indice aptitud;intelligence artificielle;classification;metamorphisme;metamorphism;computer security;modelisation;indice aptitude;virus informatico;masquage;black box;capability index;enmascaramiento;seguridad informatica;analyse comportementale;computer virus;intrusion detection systems;masking;artificial intelligence;analisis conductual;caja negra;methode heuristique;inteligencia artificial;sistema multiagente;modeling;metamorfismo;clasificacion;systeme detection intrusion;systeme multiagent	In this paper, we propose an original black-box approach concerning antivirus products evaluation. Contrary to classical tests focusing on detection rates concerning a specific malware sample, we use a generic metamorphic engine to observe the detection products behaviors. We believe that this point of view presents a double interest: First, it offers an original way of evaluating current antivirus products focusing on the observed detection technique. More precisely, the use of metamorphic malware guarantees the difficulty of static signature based detection techniques to focus only on heuristic and behavioral detection approaches. Second, by pointing out current detection capabilities, we practically evaluate the danger that complex metamorphic malware could represent. To achieve this goal, we start with the description of a generic metamorphic engine acting in two steps: obfuscation and modeling. Then, we apply this engine to a real mass-mailing worm and propose the resulting metamorphic malware samples to current antivirus products. The observed results lead to a classification of detection techniques in two main categories: the first one, relying on static detection techniques, presents low detection rates obtained by heuristic analysis. The second one, composed of behavioral detection programs, mainly focuses on elementary suspicious actions. In all cases, no product was able to detect a global malware behavior. Consequently, we consider that metamorphic malware detection still represents a real challenge for antivirus products. Through this study, we hope to help defenders understand and defend against the threat represented by this class of malware.	alert correlation;antivirus software;black box;blocking (computing);computer security;dataflow;email;experiment;heuristic (computer science);heuristic analysis;intrusion detection system;malware;obfuscation (software);observable;self-replication;sensor;software propagation;threat (computer)	Jean-Marie Borello;Eric Filiol;Ludovic Mé	2009	Journal in Computer Virology	10.1007/s11416-009-0136-2	intrusion detection system;black box;simulation;systems modeling;biological classification;process capability index;computer science;artificial intelligence;operating system;masking;metamorphism;computer security;computer virus	Security	-63.141248911369956	70.10169138901217	28983
7c29530775786489d8dc51b7637863c0c4a3acaf	network heartbeat packets recognition based on dtw and hc-fcm algorithm	fuzzy c means algorithm;dynamic time warping algorithm;protocols;pattern clustering;hc fcm algorithm;fuzzy theory;computer network security;information extraction;prototypes;collaboration;business logic;heartbeat packets hc fcm dtw;fuzzy set theory;hc fcm;dtw algorithm;protocol set;network connectivity;heuristic algorithms;heartbeat packets;network heartbeat packet recognition;clustering algorithms;network connection;dtw;periodic sequence recognition technique;dynamic time warping algorithm network heartbeat packet recognition hc fcm algorithm dtw algorithm business logic network connection pre defined signature protocol set periodic sequence recognition technique fuzzy theory information extraction fuzzy c means algorithm;heart beat algorithm design and analysis clustering algorithms heuristic algorithms collaboration timing prototypes;time warp simulation;similarity function;algorithm design and analysis;time warp simulation computer network reliability computer network security fuzzy set theory pattern clustering protocols;heart beat;computer network reliability;pre defined signature;timing	Heartbeat packets are usually used to complete the auxiliary work of applications. These packets are mostly insensitive to the business logic, and they are generally used to detect the existence of network connections, or check for patches and updates. The existing products with similar functions can only recognize heartbeat packets with pre-defined signatures. In order to provide a more general approach, we develop an algorithm which can recognize heartbeat packets based on timing characteristics, packet size, payload content, and a set of protocol related properties.	algorithm;antivirus software;business logic;fuzzy cognitive map;network packet	Tao He;Hao Zhong	2010	2010 Sixth International Conference on Natural Computation	10.1109/ICNC.2010.5584359	real-time computing;computer science;theoretical computer science;machine learning;heartbeat;out-of-order delivery	DB	-63.20376627602562	65.44595243918319	29917
3db98a9261eb6c0f5ab2d27644b0fa3266472eab	kiss: stochastic packet inspection classifier for udp traffic	protocols;internet classification engine;reordering;supervised learning;support vector machines;flow asymmetry kiss stochastic packet inspection classifier udp traffic internet classification engine peer to peer streaming chi square test support vector machines packet sampling reordering;kiss;training;stochastic packet inspection classifier;packet radio networks;p2p;testing;packet sampling;inspection;traffic classification supervised learning algorithms;telecommunication traffic;client server;supervised learning algorithms;internet;statistical analysis;stochastic processes;telecommunication traffic internet packet radio networks peer to peer computing statistical analysis stochastic processes support vector machines;peer to peer streaming;traffic classification;true positive;udp traffic;chi square test;decision process;payloads;ip networks;flow asymmetry;stochastic processes inspection protocols internet testing search engines peer to peer computing payloads feeds support vector machines;internet application;support vector machine;peer to peer computing;peer to peer	"""This paper proposes KISS, a novel Internet classification engine. Motivated by the expected raise of UDP traffic, which stems from the momentum of Peer-to-Peer (P2P) streaming applications, we propose a novel classification framework that leverages on statistical characterization of payload. Statistical signatures are derived by the means of a Chi-Square (χ2)-like test, which extracts the protocol """"format,"""" but ignores the protocol """"semantic"""" and """"synchronization"""" rules. The signatures feed a decision process based either on the geometric distance among samples, or on Support Vector Machines. KISS is very accurate, and its signatures are intrinsically robust to packet sampling, reordering, and flow asymmetry, so that it can be used on almost any network. KISS is tested in different scenarios, considering traditional client-server protocols, VoIP, and both traditional and new P2P Internet applications. Results are astonishing. The average True Positive percentage is 99.6%, with the worst case equal to 98.1,% while results are almost perfect when dealing with new P2P streaming applications."""	antivirus software;best, worst and average case;chi;client–server model;electronic signature;euclidean distance;network packet;peer-to-peer;sampling (signal processing);server (computing);support vector machine;type signature	Alessandro Finamore;Marco Mellia;Michela Meo;Dario Rossi	2010	IEEE/ACM Transactions on Networking	10.1109/TNET.2010.2044046	support vector machine;telecommunications;computer science;theoretical computer science;operating system;data mining;distributed computing;supervised learning;computer network	Metrics	-63.95669098810421	66.64113221799072	33709
1fbd15e14915b13c62c1bf7765ffc1342a6bc33b	investigating the agility bias in dns graph mining		The concept of agile domain name system (DNS) refers to dynamic and rapidly changing mappings between domain names and their Internet protocol (IP) addresses. This empirical paper evaluates the bias from this kind of agility for DNS-based graph theoretical data mining applications. By building on two conventional metrics for observing malicious DNS agility, the agility bias is observed by comparing bipartite DNS graphs to different subgraphs from which vertices and edges are removed according to two criteria. According to an empirical experiment with two longitudinal DNS datasets, irrespective of the criterion, the agility bias is observed to be severe particularly regarding the effect of outlying domains hosted and delivered via content delivery networks and cloud computing services. With these observations, the paper contributes to the research domains of cyber security and DNS mining. In a larger context of applied graph mining, the paper further elaborates the practical concerns related to the learning of large and dynamic bipartite graphs.	agile software development;cloud computing;computer security;content delivery network;data mining;digital distribution;structure mining	Jukka Ruohonen;Ville Leppänen	2017	2017 IEEE International Conference on Computer and Information Technology (CIT)	10.1109/CIT.2017.55	computer science;distributed computing;computer network;data mining;cloud computing;ipv6;dynamic network analysis;fast flux;botnet;bipartite graph;round-robin dns;domain name system	Visualization	-65.23117223725565	64.07411652971365	34022
de9692aafc9e1b61af41019366b46eff7c8a329a	a survey of payload-based traffic classification approaches	machine learning algorithms;protocols;accuracy;internet;vectors;internet protocols ports computers algorithm design and analysis accuracy vectors machine learning algorithms;open source software internet traffic identification performance evaluation;ports computers;algorithm design and analysis	Internet traffic classification has been the subject of intensive study since the birth of the Internet itself. Indeed, the evolution of approaches for traffic classification can be associated with the evolution of the Internet itself and with the adoption of new services and the emergence of novel applications and communication paradigms. Throughout the years many approaches have been proposed for addressing technical issues imposed by such novel services. Deep-Packet Inspection (DPI) has been a very important research topic within the traffic classification field and its concept consists of the analysis of the contents of the captured packets in order to accurately and timely discriminate the traffic generated by different Internet protocols. DPI was devised as a means to address several issues associated with port-based and statistical-based classification approaches in order to achieve an accurate and timely traffic classification. Many research works proposed different DPI schemes while many open-source modules have also become available for deployment. Surveys become then valuable tools for performing an overall analysis, study and comparison between the several proposed methods. In this paper we present a survey in which a complete and thorough analysis of the most important open-source DPI modules is performed. Such analysis comprises an evaluation of the classification accuracy, through a common set of traffic traces with ground truth, and of the computational requirements. In this manner, this survey presents a technical assessment of DPI modules and the analysis of the obtained evaluation results enable the proposal of general guidelines for the design and implementation of more adequate DPI modules.	central processing unit;common platform;computation;deep packet inspection;emergence;executable;ground truth;internet protocol suite;misd;network packet;open-source software;parallel computing;performance application programming interface;requirement;simd;software deployment;tracing (software);traffic classification;whole earth 'lectronic link	Michael Finsterbusch;Chris Richter;Eduardo Rocha;Jean-Alexander Muller;Klaus Hanssgen	2014	IEEE Communications Surveys & Tutorials	10.1109/SURV.2013.100613.00161	communications protocol;algorithm design;the internet;simulation;telecommunications;computer science;operating system;data mining;accuracy and precision;world wide web;computer security;statistics;computer network	Metrics	-63.26740836119833	66.56903442511637	34471
8859d3caf59901edc555e335cc49ca5f666e2535	deep packet pre-filtering and finite state encoding for adaptive intrusion detection system	teledetection;intruder detector;filtering;evaluation performance;filtrage;haute performance;performance evaluation;televigilancia;securite;surveillance;detection adaptative;reconfigurable architectures;evaluacion prestacion;reseau ordinateur;filtrado;simulation;simulacion;intrusion detection;high precision;systeme adaptatif;computer network;security system;feasibility;codificacion;remote supervision;vigilancia;adaptive systems;network traffic;telesurveillance;remote sensing;precision elevee;safety;teledeteccion;coding;secure system;adaptive system;precision elevada;alto rendimiento;red informatica;sistema adaptativo;computer science;detecteur intrus;seguridad;detector intruso;high performance;architecture reconfigurable;practicabilidad;faisabilite;intrusion detection system;codage;adaptive detection;deteccion adaptativa	1389-1286/$ see front matter Published by Elsevi doi:10.1016/j.comnet.2010.12.007 ⇑ Corresponding author. E-mail addresses: nweng@siu.edu (N. Weng) Vespa), benfano.soewito@bakrie.ac.id (B. Soewito). An intrusion detection system (IDS) is a promising technique for detecting and thwarting attacks on computer systems and networks. In the context of ever-changing threats, new attacks are constantly created, and new rules for identifying them are dramatically increasing. To adapt to these new rules, IDSs must be easily reconfigurable, they must keep up with line rates of network traffic, and they must have high detection accuracy. In this paper, we propose a high-performance memory-based IDS that can be easily reconfigured for new rules. Our IDS achieves high performance and memory efficiency by utilizing deep packet pre-filtering and novel finite state encoding. We present simulation and experimental results that show the novelty and feasibility of our system. Published by Elsevier B.V.	attack (computing);intrusion detection system;network packet;sensor;simulation;threat (computer)	Ning Weng;Lucas Vespa;Benfano Soewito	2011	Computer Networks	10.1016/j.comnet.2010.12.007	intrusion detection system;embedded system;telecommunications;computer science;adaptive system;operating system;computer security	Security	-63.47739442885558	69.83139488793407	36143
d2c1964880de730bd32d2cbe29a3f9bf9d3cdec4	traffic flooding attack detection with snmp mib using svm	minimisation;distributed system;hierarchical system;minimization;hierarchical structure;statistical data;haute performance;systeme reparti;ddos attack;mise a jour;distinguishing attack;analisis estadistico;analisis datos;reseau interconnecte;data gathering;surveillance;gestion red;high speed networks;securite informatique;systeme hierarchise;mib;transmision alta caudal;chainage donnee;distributed computing;minimizacion;intrusion detection;intelligence artificielle;packet switching;probabilistic approach;conmutacion por paquete;high precision;actualizacion;computer security;classification a vaste marge;sistema jerarquizado;dos ddos;data analysis;vigilancia;sistema repartido;snmp;internet;statistical analysis;machine learning;monitoring;enfoque probabilista;approche probabiliste;seguridad informatica;precision elevee;denial of service;analyse statistique;data link;gestion reseau;intrusion detection systems;donnee statistique;precision elevada;alto rendimiento;high rate transmission;calculo repartido;artificial intelligence;analyse donnee;feature selection;network management;inteligencia artificial;monitorage;support vector machine;maquina ejemplo soporte;internet worms;vector support machine;dato estadistico;network services;monitoreo;red interconectada;interconnected power system;high performance;high efficiency;calcul reparti;commutation paquet;systeme detection intrusion;intrusion detection system;updating;denegacion de servicio;deni service;transmission haut debit;ligazon datos	Recently, as network flooding attacks such as DoS/DDoS and Internet Worm have posed devastating threats to network services, rapid detection and proper response mechanisms are the major concern for secure and reliable network services. However, most of the current Intrusion Detection Systems(IDSs) focus on detail analysis of packet data, which results in late detection and a high system burden to cope with high-speed network environment. In this paper we propose a lightweight and fast detection mechanism for traffic flooding attacks. Firstly, we use SNMP MIB statistical data gathered from SNMP agents, instead of raw packet data from network links. Secondly, we use a machine learning approach based on a Support Vector Machine(SVM) for attack classification. Using MIB and SVM, we achieved fast detection with high accuracy, the minimization of the system burden, and extendibility for system deployment. The proposed mechanism is constructed in a hierarchical structure, which first distinguishes attack traffic from normal traffic and then determines the type of attacks in detail. Using MIB data sets collected from real experiments involving a DDoS attack, we validate the possibility of our approaches. It is shown that network attacks are detected with high efficiency, and classified with low false alarms.	denial-of-service attack;experiment;feature selection;filesystem-level encryption;level structure;machine learning;mebibyte;network packet;network traffic control;prototype;real-time clock;simple network management protocol;software deployment;support vector machine;system deployment;time complexity	Jaehak Yu;Hansung Lee;Myung-Sup Kim;Daihee Park	2008	Computer Communications	10.1016/j.comcom.2008.09.018	intrusion detection system;telecommunications;computer science;artificial intelligence;feature selection;computer security	Security	-63.61042493472276	69.70066327169052	38120
9d66183314c24394530c30673e72e7f614c05c68	detecting unknown worms using randomness check	teletrafic;random distribution;valor elevado;matrice aleatoire;tecnologia electronica telecomunicaciones;internet worm;distribution aleatoire;endommagement;valeur elevee;randomness;random matrix;vulnerability;deterioracion;vulnerabilite;teletrafico;vulnerabilidad;internet;monitoring;teletraffic;high value;monitorage;tecnologias;damaging;grupo a;monitoreo;matriz aleatoria;distribucion aleatoria;early detection;traffic matrix;rank	From the introduction of CodeRed and Slammer worms, it has been learned that the early detection of worm epidemics is important in order to reduce the damage resulting from outbreaks. A prominent characteristic of Internet worms is the random selection of subsequent targets. In this paper, we propose a new worm detection mechanism by checking the random distribution of destination addresses in network traffic. The proposed mechanism constructs a matrix from network traffic and checks the rank of the matrix in order to detect the spreading of Internet worms. From the fact that a random binary matrix holds a high rank value, ADUR (Anomaly Detection Using Randomness check) is proposed for detecting unknown worms based on the rank of the matrix. From experiments on various environments, it is demonstrated that the ADUR mechanism effectively detects the spread of new worms in the early stages, even when there is only a single host infected in a monitoring network. Also, we show that ADUR is highly sensitive so that the worm epidemic can be detectable quickly, e.g., three times earlier than the infection of 90% vulnerable hosts. key words: Internet worm, early detection, randomness, traffic matrix, rank	anomaly detection;cyclic redundancy check;experiment;network traffic control;randomness;sql slammer;sensor;the matrix	Hyundo Park;Heejo Lee;Hyogon Kim	2007	IEICE Transactions	10.1093/ietcom/e90-b.4.894	probability distribution;the internet;rank;telecommunications;vulnerability;random matrix;computer security;randomness;statistics	Metrics	-62.96689905634883	69.70408745114955	38853
99cfdb4e4dff8fb5c60b2ff840571aafb203bf67	optimal defense strategies for ddos defender using bayesian game model	bayesian game;ddos defense;nonlinear programming	In a typical DDoS attack and defense scenario, both the attacker and the defender will take actions to maximize their utilities. However, each player does not know his opponent's investment and cannot adopt the optimal strategies. We formalize a Bayesian game model to handle these uncertainties and specify two problems usually faced by the defender when choosing defense measures. A nonlinear programming method is proposed to handle policies' permutation in order to maximize the defender's utility. Followed the Nash equilibrium, security administrators can take optimal strategies. Finally, the practicality and effectiveness of the model and method are illustrated by an example. © 2013 Springer-Verlag.	denial-of-service attack;windows defender	Yuling Liu;Dengguo Feng;Yifeng Lian;Kai Chen;Yingjun Zhang	2013		10.1007/978-3-642-38033-4_4	internet privacy;computer security	AI	-64.62130242477703	61.61293056659709	39645
10f4bee5ff4da5aaf5c6f526b89f72ba44a967c3	combining hidden markov models for improved anomaly detection	communications society;detectors;kernel;complexity theory;security of data hidden markov models operating system kernels;receiver operating characteristics;receiver operator characteristic;hidden markov model;paper technology;anomaly detection;information technology;training;maximum realizable roc technique;hmm;intrusion detection;event detection;hidden markov models intrusion detection training data event detection operating systems kernel computerized monitoring communications society paper technology information technology;hids;training data;computerized monitoring;multi classifier systems;gold;hidden markov models;operating system;markov processes;host based intrusion detection system;operating system kernels;maximum realizable roc technique host based intrusion detection system hids anomaly detection hidden markov model hmm system call operating system kernel receiver operating characteristics;operating system kernel;system call;security of data;intrusion detection system;critical parameter;host based intrusion detection systems;operating systems	In host-based intrusion detection systems (HIDS), anomaly detection involves monitoring for significant deviations from normal system behavior. Hidden Markov Models (HMMs) have been shown to provide a high level performance for detecting anomalies in sequences of system calls to the operating system kernel. Although the number of hidden states is a critical parameter for HMM performance, it is often chosen heuristically or empirically, by selecting the single value that provides the best performance on training data. However, this single best HMM does not typically provide a high level of performance over the entire detection space. This paper presents a multiple-HMMs approach, where each HMM is trained using a different number of hidden states, and where HMM responses are combined in the Receiver Operating Characteristics (ROC) space according to the Maximum Realizable ROC (MRROC) technique. The performance of this approach is compared favorably to that of a single best HMM and to a traditional sequence matching technique called STIDE, using different synthetic HIDS data sets. Results indicate that this approach provides a higher level of performance over a wide range of training set sizes with various alphabet sizes and irregularity indices, and different anomaly sizes, without a significant computational and storage overhead.	anomaly detection;computation;convex hull;heuristic;hidden markov model;high-level programming language;host-based intrusion detection system;kernel (operating system);markov chain;operating system;operational system;overhead (computing);sensor;software bug;synthetic intelligence;system call;test set	Wael Khreich;Eric Granger;Robert Sabourin;Ali Miri	2009	2009 IEEE International Conference on Communications	10.1109/ICC.2009.5198832	intrusion detection system;host-based intrusion detection system;speech recognition;computer science;machine learning;pattern recognition;receiver operating characteristic;hidden markov model	Metrics	-63.527713815889285	63.5725328764876	43389
4688ff24a2e08f4a8a3ce87ddcf39a213fcad159	an alert fusion model inspired by artificial immune system	danger theory;alert fusion;artificial immune system;computer network security;danger theory intrusion detection system alert fusion alert correlation artificial immune system;false alarms alert fusion model artificial immune system network security intrusion detection systems human defence system danger theory ids models;intrusion detection;computational modeling;aggregates;immune system;ip networks;computer network security alarm systems artificial immune systems;correlation;alarm systems;artificial immune systems;intrusion detection system;correlation ip networks computational modeling immune system aggregates intrusion detection;alert correlation	In the recent years one of the most focused topics in the field of network security and more specifically intrusion detection systems was to find a solution to reduce the overwhelming alerts generated by IDSs in the network. Inspired by human defence system and danger theory we propose a complementary subsystem for IDS which can be integrated into any existing IDS models to aggregate the alerts in order to reduce them, and subsequently reduce false alarms among the alerts. After evaluation using different datasets and attack scenarios, our model managed to aggregate the alerts by the average rate of 97.5 percent.	aggregate data;alert correlation;artificial immune system;experiment;intrusion detection system;network security	Mohammad Mahboubian;Nur Izura Udzir;Subramaniam Shamala;Nor Asilah Wati Abdul Hamid	2012	Proceedings Title: 2012 International Conference on Cyber Security, Cyber Warfare and Digital Forensic (CyberSec)	10.1109/CyberSec.2012.6246083	engineering;artificial intelligence;data mining;computer security	Security	-63.612087142465484	65.01951113665234	44443
a291abdcb8e6fe4f60101e9292b15c18402c287e	identifying security vulnerabilities through input flow tracing and analysis	virus informatique;software;programa;software tool;logiciel;vulnerability assessment;medida caudal flujo;securite informatique;software systems;methode;vulnerability;input;analyse entree sortie;reliability management;computer security;computer viruses;vulnerabilite;virus informatico;vulnerabilidad;seguridad informatica;identification;entree ordinateur;computer virus;input output analysis;identificacion;software tools;source code;analisis entrada salida;security products;entrada ordenador;flow measurement;metodo;method;mesure debit ecoulement	A software system can be considered as a collection of data and procedures that are separated from the environment and interact with it through channels of communication. If we assume that the system does not contain any Trojan horse code, then the only way it can be attacked is during the processing of input through interactions with the environment. While most methodologies attempt to identify security vulnerabilities in the local context, proposes the use of complete input tracing that examines the source code and identifies all possible inputs from malicious sources, traces the input flow from the source until termination of use and compares the flow segments for known security vulnerability constructs. Discusses input flow tracing and its benefits such as the provision of metrics for security assurance, complete vulnerability assessment and the ability to examine combinations of vulnerabilities.	vulnerability (computing)	Simeon Xenitellis	2003	Inf. Manag. Comput. Security	10.1108/09685220310489562	vulnerability management;simulation;security through obscurity;telecommunications;computer science;secure coding;computer security;computer virus	Security	-62.87522309002207	69.82515678583654	45612
17f2912c069e1debbe9746912683a62fbf873e36	a game-based intrusion detection mechanism to confront internal attackers	security and protection;non cooperative game theory;game theory;computer communication networks;utility function;intrusion detection;bounded rationality;nash equilibria;internal attacker;repeated game;quantal response equilibrium;operating system;detection algorithm;detection mechanism;intrusion detection system	Insiders might threaten organizations’ systems any time. By interacting with a system, an insider plays games with the security mechanisms employed to protect it. We apply game theory to model these interactions in an extensive form game that is being played repeatedly with an Intrusion Detection System (IDS). The outcomes of the game are quantified by first specifying players’ preferences, and then, by using the von NeumanneMorgenstern utility function, to assign numbers that reflect these preferences. Examining players’ best responses, the solution of the game follows by locating all the Nash Equilibria (NE). We extend the NE notion to the logit Quantal Response Equilibrium (QRE), to capture players’ bounded rationality and model insider’s behavior. The QRE results are more realistic, and show that the solution of the game might be significantly different than the corresponding NE solution. Thus, we determine how an insider will interact in the future, and how an IDS will react to protect the system. To easily exploit QRE results in ID, we propose the use of a detection mechanism. To present a possible implementation scheme of the detection mechanism, we give the application model and a detailed game-based detection algorithm.	algorithm;game theory;insider threat;interaction;intrusion detection system;nash equilibrium;quantum;quick response engine;rationality;utility	Ioanna Kantzavelou;Sokratis K. Katsikas	2010	Computers & Security	10.1016/j.cose.2010.06.002	non-cooperative game;implementation theory;intrusion detection system;game theory;minimax;simulation;best response;extensive-form game;simultaneous game;computer science;artificial intelligence;non-credible threat;repeated game;strategy;screening game;chicken;normal-form game;algorithmic game theory;sequential game;computer security;equilibrium selection;solution concept	AI	-64.40135090864025	61.541544601883864	47896
20698580d9b45ef9a8368a0961a9459e19b6be3d	covariance-matrix modeling and detecting various flooding attacks	second order;anomaly detection;statistical analysis covariance matrices security of data;statistical anomaly detection;flooding attacks;statistical analysis;floods covariance matrix information systems linear matrix inequalities internet bandwidth intrusion detection monitoring computer crime computer networks;covariance matrices;second order feature;distributed denial of service;statistical anomaly detection covariance matrix modeling flooding attacks detection chebyshev inequality theory threshold matrix denial of service flooding attacks;stable set;information system;threshold matrix;security of data;threshold matrix covariance matrix flooding attacks second order feature statistical anomaly detection;covariance matrix	This paper presents a covariance-matrix modeling and detection approach to detecting various flooding attacks. Based on the investigation of correlativity changes of monitored network features during flooding attacks, this paper employs statistical covariance matrices to build a norm profile of normal activities in information systems and directly utilizes the changes of covariance matrices to detect various flooding attacks. The classification boundary is constrained by a threshold matrix, where each element evaluates the degree to which an observed covariance matrix is different from the norm profile in terms of the changes of correlation between the monitored network features represented by this element. Based on Chebyshev inequality theory, we give a practical (heuristic) approach to determining the threshold matrix. Furthermore, the result matrix obtained in the detection serves as the second-order features to characterize the detected flooding attack. The performance of the approach is examined by detecting Neptune and Smurf attacks-two common distributed Denial-of-Service flooding attacks. The evaluation results show that the detection approach can accurately differentiate the flooding attacks from the normal traffic. Moreover, we demonstrate that the system extracts a stable set of the second-order features for these two flooding attacks	denial-of-service attack;heuristic;information system;neptune;sensor;smurf attack;social inequality	Daniel S. Yeung;Shuyuan Jin;Xizhao Wang	2007	IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans	10.1109/TSMCA.2006.889480	covariance matrix;anomaly detection;computer science;theoretical computer science;data mining;mathematics;computer security;second-order logic;denial-of-service attack;information system;statistics	Web+IR	-62.86373115725379	64.15866817667836	48296
e466c872931d1a2790d2c45bc88e30f6da87ce57	classifying service flows in the encrypted skype traffic	protocols;telecommunication traffic cryptography internet telephony protocols statistical analysis;precision recall term skype service flow classification method skype traffic encryption skype traffic detection voice call skypeout video conferencing statistical protocol identification analysis spid analysis representative dataset method;cryptography peer to peer computing protocols computational modeling fingerprint recognition analysis of variance;internet telephony;telecommunication traffic;statistical analysis;cryptography	In this paper, we consider the problem of detecting Skype traffic and classifying Skype service flows such as voice calls, skypeOut, video conferencing, chat, file upload and download. We propose a classification method for Skype encrypted traffic based on the Statistical Protocol IDentification (SPID) that analyzes statistical values of some traffic attributes. We have evaluated our method on a representative dataset to show excellent performance in terms of Precision and Recall.	download;encryption;precision and recall;sensor;upload	Maciej Korczynski;Andrzej Duda	2012	2012 IEEE International Conference on Communications (ICC)	10.1109/ICC.2012.6364024	computer science;cryptography;internet privacy;world wide web;statistics;computer network	Visualization	-63.32373830158523	67.07475537802634	50405
0e013466d9b89e1fd087e1debf57e7e5ca8f7c9a	empirical and theoretical evaluation of active probing attacks and their countermeasures	workload;active probing;anonymity;distributed system;teledetection;base donnee repartie;confidencialidad;red local;distributed database;steganographie;methode empirique;analisis estadistico;contre mesure electronique;securite;systeme critique;logiciel a securite critique;metodo empirico;empirical method;base repartida dato;probabilistic approach;round trip time;anonymous communication;sistema reactivo;confidentiality;anonymat;confidentialite;local network;steganography;esteganografia;critical system;internet;statistical analysis;contra medida electronica;theoretical analysis;enfoque probabilista;approche probabiliste;remote sensing;safety critical software;safety;analyse statistique;teledeteccion;charge travail;reactive system;pattern recognition;systeme reactif;reconnaissance forme;electronic countermeasure;reconocimiento patron;carga trabajo;reseau local;seguridad;anonimato	A variety of remote sensing attacks allow adversaries to break flow confidentiality and gather mission-critical information in distributed systems. Such attacks are easily supplemented by active probing attacks, where additional workload (e.g., ping packets) is injected into the victim system. This paper presents statistical pattern recognition as a fundamental technology to evaluate the effectiveness of active probing attacks. Our theoretical analysis and empirical results show that even if sophisticated approaches of link padding are used, sample entropy of probing packets’ round trip time is an effective and robust feature statistic to discover the user payload traffic rate, which is important for maintaining anonymous communication. Extensive experiments on local network, campus network, and the Internet were carried out to validate the system security predicted by the theoretical analysis. We give some guidelines to reduce the effectiveness of such active probing attacks.	adversary (cryptography);capability maturity model;confidentiality;correctness (computer science);distributed computing;experiment;mathematical model;mission critical;padding (cryptography);pattern recognition;ping (networking utility);randomness;sample entropy	Xinwen Fu;Bryan Graham;Dong Xuan;Riccardo Bettati;Wei Zhao	2004		10.1007/978-3-540-30114-1_19	local area network;robust random early detection;the internet;confidentiality;anonymity;telecommunications;reactive system;computer science;electronic countermeasure;steganography;empirical research;round-trip delay time;distributed database;computer security;statistics	Security	-63.03188828358377	69.60155346756748	52154
f818e31ec6d2fc598594f2de5f5211bce05547a2	a combined data mining approach for ddos attack detection	extraction information;modelizacion;distributed system;red sin hilo;systeme reparti;ddos attack;informatique mobile;analisis datos;reseau sans fil;information extraction;securite;heuristic method;wireless network;metodo heuristico;endommagement;data mining;classification;deterioracion;selection automatique;modelisation;data analysis;sistema repartido;fouille donnee;seleccion automatica;safety;analyse donnee;feature selection;methode heuristique;reseau neuronal;damaging;mobile computing;seguridad;modeling;busca dato;clasificacion;extraccion informacion;red neuronal;automatic selection;neural network	Recently, as the serious damage caused by DDoS attacks increases, the rapid detection and the proper response mechanisms are urgent. However, existing security mechanisms do not provide effective defense against these attacks, or the defense capability of some mechanisms is only limited to specific DDoS attacks. It is necessary to analyze the fundamental features of DDoS attacks because these attacks can easily vary the used port/protocol, or operation method. In this paper, we propose a combined data mining approach for modeling the traffic pattern of normal and diverse attacks. This approach uses the automatic feature selection mechanism for selecting the important attributes. And the classifier is built with the theoretically selected attribute through the neural network. And then, our experimental results show that our approach can provide the best performance on the real network, in comparison with that by heuristic feature selection and any other single data	artificial neural network;data mining;denial-of-service attack;feature selection;heuristic	Mihui Kim;Hyunjung Na;Kijoon Chae;Hyochan Bang;Jung-Chan Na	2004		10.1007/978-3-540-25978-7_95	robust random early detection;systems modeling;biological classification;computer science;artificial intelligence;operating system;wireless network;machine learning;data mining;data analysis;application layer ddos attack;mobile computing;feature selection;computer security;information extraction;denial-of-service attack;artificial neural network	AI	-63.71799697857124	69.9659924613291	53441
013fd0420dbc0516f39cd7515bcfa7241eb7a581	honeystat: local worm detection using honeypots	internet protocol;memoria tampon;intruder detector;statistical data;base donnee;red local;overflow computer arithmetics;protocolo internet;surveillance;data collection;securite informatique;protocole internet;database;base dato;large data sets;intrusion detection;alert management;process management;network analysis;computer security;local network;vigilancia;false positive rate;monitoring;buffer overflow;seguridad informatica;intrusion detection systems;donnee statistique;gestion alerta;rebasamiento capacidad;gestion alerte;depassement capacite;monitorage;dato estadistico;false positive;detecteur intrus;monitoreo;memoire tampon;reseau local;analyse circuit;detector intruso;early detection;systeme detection intrusion;analisis circuito;alert correlation;buffer memory	Worm detection systems have traditionally used global strategies and focused on scan rates. The noise associated with this approach requires statistical techniques and large data sets (e.g., 2 monitored machines) to yield timely alerts and avoid false positives. Worm detection techniques for smaller local networks have not been fully explored. We consider how local networks can provide early detection and compliment global monitoring strategies. We describe HoneyStat, which uses modified honeypots to generate a highly accurate alert stream with low false positive rates. Unlike traditional highly-interactive honeypots, HoneyStat nodes are script-driven, automated, and cover a large IP space. The HoneyStat nodes generate three classes of alerts: memory alerts (based on buffer overflow detection and process management), disk write alerts (such as writes to registry keys and critical files) and network alerts. Data collection is automated, and once an alert is issued, a time segment of previous traffic to the node is analyzed. A logit analysis determines what previous network activity explains the current honeypot alert. The result can indicate whether an automated or worm attack is present. We demonstrate HoneyStat’s improvements over previous worm detection techniques. First, using trace files from worm attacks on small networks, we demonstrate how it detects zero day worms. Second, we show how it detects multi vector worms that use combinations of ports to attack. Third, the alerts from HoneyStat provide more information than traditional IDS alerts, such as binary signatures, attack vectors, and attack rates. We also use extensive (year long) trace files to show how the logit analysis produces very low false positive rates.	antivirus software;buffer overflow;client honeypot;honeypot (computing);intrusion detection system;logistic regression;logit analysis in marketing;multihoming;statistical model;tracing (software);zero-day (computing)	David Dagon;Xinzhou Qin;Guofei Gu;Wenke Lee;Julian B. Grizzard;John G. Levine;Henry L. Owen	2004		10.1007/978-3-540-30143-1_3	intrusion detection system;telecommunications;computer science;operating system;world wide web;computer security	Security	-62.851232591306406	69.40604353829191	56786
62b15088cf2d1a2703820fb2b7d38a7f188d6f61	co-fql: anomaly detection using cooperative fuzzy q-learning in network	multi agent system;t technology;reinforcement learning;intrusion detection;fuzzy system;cooperative ids	Wireless networks are increasingly overwhelmed by Distributed Denial of Service DDoS attacks by generating flooding packets that exhaust critical computing and communication resources of a victim's mobile device within a very short period of time. This must be protected. Effective detection of DDoS attacks requires an adaptive learning classifier, with less computational complexity, and an accurate decision making to stunt such attacks. We propose a distributed intrusion detection system called Cooperative IDS to protect wireless nodes within the network and target nodes from DDoS attacks by using a Cooperative Fuzzy Q-learning Co-FQL optimization algorithmic technique to identify the attack patterns and take appropriate countermeasures. The Co-FQL algorithm was trained and tested to establish its performance by generating attacks from the NSL-KDD and “CAIDA DDoS Attack 2007” datasets during the simulation experiments. Experimental results show that the proposed Co-FQL IDS has a 90.58% higher accuracy of detection rate than Fuzzy Logic Controller or Q-learning algorithm or Fuzzy Q-learning alone.	anomaly detection;facebook query language;q-learning	Shahaboddin Shamshirband;Babak Daghighi;Nor Badrul Anuar;Miss Laiha Mat Kiah;Ahmed Patel;Ajith Abraham	2015	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-141419	intrusion detection system;computer science;artificial intelligence;distributed computing;application layer ddos attack;reinforcement learning;computer security;fuzzy control system;computer network	Robotics	-63.356146494001436	64.44663201144576	59509
7d255c95ac88257cf0f4d04aa42fb5e4314204ab	implementation and evaluation of a protocol for detecting network-wide threshold crossing alerts	management system;distributed protocol;threshold detection;false negative;detection threshold;distributed aggregation threshold detection decentralized management;decentralized management;false positive;protocols aggregates computer network management monitoring technology management hysteresis tree graphs counting circuits testing time measurement;telekommunikation;distributed aggregation;telecommunications	Threshold crossing alerts (TCAs) indicate to a management system that a management variable, associated with the state, performance or health of the network, has crossed a certain threshold. In this paper, we report on implementing and evaluating TCA-GAP, a distributed protocol for detecting network-wide TCAs, which reports threshold crossings on aggregates, such as SUM, AVERAGE, or MAX of device counters. We present a concept for assessing the quality of detecting network-wide TCAs, which we apply to evaluate TCA-GAP on a lab testbed. First, we evaluate the correctness of the protocol by determining the correctly detected threshold crossings, the false positives and the false negatives. Second, for the correctly detected threshold crossings, we measure the delays between the time a crossing was reported by the protocol and the time of its actual occurrence. Finally, we demonstrate that the fundamental tradeoff between the quality of TCA detection and the management overhead can be controlled in TCA-GAP by modifying the maximum message rate on the management overlay.	advanced telecommunications computing architecture;correctness (computer science);max;overhead (computing);sensor;testbed	Fetahi Zebenigus Wuhib;Rolf Stadler;Alexander Clemm	2006	2006 4th IEEE/IFIP Workshop on End-to-End Monitoring Techniques and Services	10.1109/E2EMON.2006.1651278	real-time computing;computer science;distributed computing;computer security	Security	-63.66180955689898	63.08069763377837	59871
2c1c28640b4ce4f56288371b37d8b9599f911bfa	adaptive and scalable android malware detection through online learning	kernel androids humanoid robots;batch learning scalable android malware detection adaptive android malware detection machine learning based android malware detection malware characteristics rnalware popuwtion drift online machine learning droidol security sensitive behavior inter procedural control flow sub graph features online passive aggressive classifier;malware detection online learning graph kernels;learning artificial intelligence android operating system graph theory invasive software	It is well-known that malware constantly evolves so as to evade detection and this causes the entire malware population to be non-stationary. Contrary to this fact, prior works on machine learning based Android malware detection have assumed that the distribution of the observed malware characteristics (i.e., features) do not change over time. In this work, we address the problem of malware population drift and propose a novel online machine learning based framework, named DroidOL to handle it and effectively detect malware. In order to perform accurate detection, security-sensitive behavior are captured from apps in form of inter-procedural control-flow sub-graph features using a state-of-the-art graph kernel. In order to perform scalable detection and to adapt to the drift and evolution in malware population, an online passive-aggressive classifier is used. In a large-scale comparative analysis with more than 87,000 apps, DroidOL achieves 84.29% accuracy outperforming two state-of-the-art malware techniques by more than 20% in their typical batch learning setting and more than 3% when they are continuously re-trained. Our experimental findings strongly indicate that online learning based approaches are highly suitable for real-world malware detection.	android;control flow;graph kernel;malware;online machine learning;qualitative comparative analysis;scalability;sensor;stationary process	Annamalai Narayanan;Yang Liu;Lihui Chen;Jinliang Liu	2016	2016 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2016.7727508	computer science;machine learning;internet privacy;world wide web;computer security	ML	-64.84856627747764	64.77072090156032	61081
0cefdcb042e68bc7466b23df4100186710a449f6	agent-based real time intrusion detection system against malformed packet attacks	internet protocol;systeme temps reel;distributed system;multiagent system;systeme reparti;protocolo internet;agent based;real time;extraction forme;securite informatique;protocole internet;false negative;intelligence artificielle;packet switching;fragmentacion;conmutacion por paquete;information gathering;computer security;sistema repartido;internet;extraccion forma;seguridad informatica;intrusion detection systems;artificial intelligence;real time system;sistema tiempo real;inteligencia artificial;information system;false positive;delinquency;sistema multiagente;delinquance;pattern extraction;fragmentation;commutation paquet;systeme information;systeme detection intrusion;intrusion detection system;systeme multiagent;sistema informacion;delincuencia	The current paper proposes a network-based Intrusion Detection System (IDS) that can efficiently detect attacks based on malformed packets that continues to increase, along with more intelligent and skillful hacking techniques. Our system firstly extracts the important features from network packets and analyzes simple attacks and detects IP fragmentation attacks. Thereafter, it collects information from the SA and the FA and other strange information related to the malformed packet. Finally, it judges whether or not an intrusion has occurred on the basis of information gathered from target systems by CAs. The simulation result shows 0% false-positive and 0% false-negative, 100% detection ratio, thereby confirming the accuracy of the proposed IDS in detecting fragmentation attacks.	intrusion detection system	Jun-Cheol Jeon;Eun-Yeung Choi;Kee-Young Yoo	2006		10.1007/11802372_98	anomaly-based intrusion detection system;intrusion detection system;real-time operating system;telecommunications;computer science;artificial intelligence;computer security	Security	-63.35787077101611	69.96928410438856	62478
46ac42f0d13314f380190dc16883ec692468d818	flexible network monitoring with flame	evaluation performance;network measurement;performance evaluation;network monitoring;securite;bepress selected works;flexibilidad;implementation;evaluacion prestacion;reseau actif;worm detection;open architecture;active network;active networks network monitoring network measurement worm detection;monitoring;portable equipment;safety;networking;red activa;conexion en red;flexibilite;reseautique;monitorage;implementacion;monitoreo;active networks;seguridad;appareil portatif;flexibility;aparato portatil	Increases in scale, complexity, dependency and security for networks have motivated increased automation of activities such as network monitoring. We have employed technology derived from active networking research to develop a series of network monitoring systems, but unlike most previous work, made application needs the priority over infrastructure properties. This choice has produced the following results: (1) the techniques for general infrastructure are both applicable and portable to specific applications such as network monitoring; (2) tradeoffs can benefit our applications while preserving considerable flexibility; and (3) careful engineering allows applications with open architectures to perform competitively with custom-built static implementations. These results are demonstrated via measurements of the lightweight active measurement environment (LAME), its successor, flexible LAME (FLAME), and their application to monitoring for performance and security.	active networking;complexity;extensibility;network traffic control;open architecture;performance tuning	Kostas G. Anagnostakis;Michael B. Greenwald;Sotiris Ioannidis;Dekai Li;Jonathan M. Smith	2006	Computer Networks	10.1016/j.comnet.2006.04.018	embedded system;active networking;telecommunications;computer science;operating system;computer security;computer network	Metrics	-63.38720096338156	69.19122145573098	67180
9d0610caff636d6eac92873f55e3966888533d62	a selectivity based approach to continuous pattern detection in streaming graphs	graphs;cybersecurity	"""Cyber security is one of the most significant technical challenges in current times. Detecting adversarial activities, prevention of theft of intellectual properties and customer data is a high priority for corporations and government agencies around the world. Cyber defenders need to analyze massive-scale, high-resolution network flows to identify, categorize, and mitigate attacks involving networks spanning institutional and national boundaries. Many of the cyber attacks can be described as subgraph patterns, with prominent examples being insider infiltrations (path queries), denial of service (parallel paths) and malicious spreads (tree queries). This motivates us to explore subgraph matching on streaming graphs in a continuous setting. The novelty of our work lies in using the subgraph distributional statistics collected from the streaming graph to determine the query processing strategy. We introduce a “Lazy Search"""" algorithm where the search strategy is decided on a vertexto-vertex basis depending on the likelihood of a match in the vertex neighborhood. We also propose a metric named “Relative Selectivity"""" that is used to select between different query processing strategies. Our experiments performed on real online news, network traffic stream and a synthetic social network benchmark demonstrate 10-100x speedups over selectivity agnostic approaches."""	adversary (cryptography);benchmark (computing);categorization;database;denial-of-service attack;dhrystone;experiment;file spanning;image resolution;lazy evaluation;network packet;search algorithm;selectivity (electronic);social network;subgraph isomorphism problem;windows insider	Sutanay Choudhury;Lawrence B. Holder;George Chin;Khushbu Agarwal;John Feo	2015		10.5441/002/edbt.2015.15	computer science;theoretical computer science;data mining;database;graph;computer security	ML	-66.2058480850149	62.283244727797495	69521
83ac3e486a5a0cf929e9efbd84bcbe5c3fc05707	game theory with learning for cyber security monitoring	game theory;monitoring games malware decision making adaptation models computational modeling;computer security;computational modeling;thesis;monitoring;malware;games;adaptation models;stochastic game game theory cyber security monitoring security games q learning;stochastic games learning artificial intelligence security of data	Recent attacks show that threats to cyber infrastructure are not only increasing in volume, but are getting more sophisticated. The attacks may comprise multiple actions that are hard to differentiate from benign activity, and therefore common detection techniques have to deal with high false positive rates. Because of the imperfect performance of automated detection techniques, responses to such attacks are highly dependent on human-driven decision-making processes. While game theory has been applied to many problems that require rational decisionmaking, we find limitation on applying such method on security games when the defender has limited information about the opponent's strategies and payoffs. In this work, we propose Q-Learning to react automatically to the adversarial behavior of a suspicious user to secure the system. This work compares variations of Q-Learning with a traditional stochastic game. Simulation results show the possibility of Naive Q-Learning, despite restricted information on opponents.	algorithm;best, worst and average case;computer security;embedded system;experiment;game theory;image scanner;markov chain;minimax;naive bayes classifier;q-learning;rationality;real-time clock;reinforcement learning;simulation;vulnerability (computing)	Key-whan Chung;Charles A. Kamhoua;Kevin A. Kwiat;Zbigniew T. Kalbarczyk;Ravishankar K. Iyer	2016	2016 IEEE 17th International Symposium on High Assurance Systems Engineering (HASE)	10.1109/HASE.2016.48	games;game theory;simulation;computer science;artificial intelligence;screening game;malware;simulations and games in economics education;computational model;computer security	Security	-64.48092599180248	61.56850876364334	70780
e018aefa135330672a1e6b4f87d7be172eb29dfb	a context adaptive intrusion detection system for manet	anomaly;sensibilidad contexto;informatica movil;modelizacion;network lifetime;intruder detector;context awareness;context aware;informatique mobile;manet;recompense;network security;detection adaptative;control inteligente;securite informatique;vivacidad;adaptive control;reseau ad hoc mobile;intrusion detection;attaque informatique;anomalie;systeme adaptatif;intelligent control;sistema de deteccion de intrusiones;vivacite;anomalia;computer security;modelisation;red movil ad hoc;recompensa;reward;lifetime;control adaptativo;seguridad informatica;adaptive system;commande adaptative;energy security;intrusion detection systems;presupuesto;computer attack;liveness;sistema adaptativo;ataque informatica;mobile ad hoc network;energy budget;commande intelligente;budget;mobile node;sensibilite contexte;detecteur intrus;mobile computing;modeling;detector intruso;systeme detection intrusion;intrusion detection system;adaptive detection;deteccion adaptativa	0140-3664/$ see front matter 2010 Elsevier B.V. A doi:10.1016/j.comcom.2010.06.015 * Corresponding author. Tel.: +886 5 379 0411x335 E-mail addresses: bcheng@ccu.edu.tw (B.-C. Chen (R.-Y. Tseng). Due to the ad hoc and mobile nature of a MANET, it is much more vulnerable to attacks than a wired network. As a result, there has been a significant research focusing on designing an Intrusion Detection System (IDS) for MANETs to detect anomalous behavior and misuse. However, each mobile node in a MANET typically has limited energy and thus it is not efficient to perform IDS functions within a node to detect every incoming packet. There is a need for an IDS to implement an intelligent control mechanism in order to monitor and recognize security breach attempts efficiently over a period of the expected network lifetime. By leveraging the Network Node Intrusion Detection (NNID) strategy, we developed a context adaptive IDS controller that advises an IDS to carry out intrusion detection while being prepared for a possible ‘‘cut through” if it is likely that the residual energy is not sufficient. By being embedded with the context adaptive IDS controller, the proposed Context Adaptive Intrusion Detection System (CAIDS) is able to adapt to the current node context (such as residual energy, security threats and traffic loading) for accommodating and inspecting new arriving packets. The performance is evaluated using a reward function that discovers an effective way to perform intrusion detection and delivers security benefits while meeting the energy budget. The numerical results show that CAIDS offers a good trade-off between lifetime performance and security. This study demonstrates empirically that the CAIDS model intelligently monitors and recognizes security breach attempts while adhering to the resource budget plan over the period of expected network lifetime. 2010 Elsevier B.V. All rights reserved.	embedded system;entity–relationship model;hoc (programming language);intelligent control;intrusion detection system;network packet;numerical analysis;reinforcement learning	Bo-Chao Cheng;Ryh-Yuh Tseng	2011	Computer Communications	10.1016/j.comcom.2010.06.015	anomaly-based intrusion detection system;intrusion detection system;embedded system;host-based intrusion detection system;adaptive control;telecommunications;computer science;adaptive system;network security;operating system;mobile computing;computer security;intrusion prevention system;computer network;intelligent control	Security	-63.7876434998577	70.19082323744432	71368
c1fc4e5b3cc32c02f4f13814eeaa86df3b4c5696	f-tad: traffic anomaly detection for sub-networks using fisher linear discriminant	traffic behavior;traffic anomaly detection;wide backbone network traffic identification;learning algorithm;normal distribution;traffic analysis and measurment;fisher linear discriminant anomaly detection adaptive defense system traffic analysis and measurment;network security;telecommunication traffic monitoring communication system security information security communications technology gaussian distribution adaptive systems internet computer crime robustness;anomaly detection;real time;training;network administration;data mining;real time detection;fisher linear discriminant method;internet traffic anomaly detection network security network administration traffic monitoring traffic analysis fisher linear discriminant method self learning algorithm real time detection wise mon traffic behavior wide backbone network traffic identification statistical estimation monitoring;telecommunication traffic;statistical distributions;internet;monitoring;principal component analysis;telecommunication security;traffic analysis;fisher linear discriminant;bandwidth;ip networks;adaptive defense system;self learning algorithm;traffic monitoring;learning artificial intelligence;statistical estimation monitoring;telecommunication traffic internet learning artificial intelligence statistical distributions telecommunication security;wise mon	Traffic anomaly detection is one of the most important technologies that should be considered in network security and administration. In this paper, we propose a traffic anomaly detection mechanism that includes traffic monitoring and traffic analysis. We develop an analytical system called WISE-Mon that inspects the traffic behavior by monitoring and analyzing the traffic. We establish a criterion for detecting abnormal traffic by analyzing training set of traffic and applying Fisher linear discriminant method. By using the properties of distributions such as chi-square distribution and normal distribution to the training set, we derive a hyperplane which enables to detect abnormal traffic. Since the trend of traffic can be changed as time passes, the hyperplane has to be updated periodically to reflect the changes. Accordingly, we consider the self-learning algorithm which reflects the trend of traffic and so enables to increase accuracy of detection. The proposed mechanism is reliable for traffic anomaly detection and compatible to real-time detection. For the numerical results, we use a traffic set collected from campus network. It shows that the proposed mechanism is reliable and accurate for detecting the abnormal traffic. Furthermore, it is observed that the proposed mechanism can categorize a set of abnormal traffic into various malicious traffic subsets.	algorithm;anomaly detection;categorization;cybercrime countermeasures;linear discriminant analysis;network security;numerical analysis;numerical method;real-time clock;real-time computing;sensor;subdivision surface;test set;traffic analysis	Hyunhee Park;Meejoung Kim;Chul-Hee Kang	2009	2009 Third International Conference on Network and System Security	10.1109/NSS.2009.60	normal distribution;traffic generation model;probability distribution;anomaly detection;the internet;telecommunications;computer science;network security;data mining;computer security;bandwidth;statistics;principal component analysis	Metrics	-63.108020874963785	66.47912176624077	71731
f9d984b3e55105bacf315446c1083ca7a38f3cf9	distributed intrusion detection system based on artis	modelizacion;distributed system;intruder detector;adaptability;adaptabilite;networks;systeme reparti;artificial immune system;immune regulation;sistema inmunitario;securite informatique;educational software program;computer intrusion detection;intrusion detection;intelligence artificielle;didacticiel;adaptabilidad;network intrusion detection;computer security;modelisation;data storage;sistema repartido;pattern matching;seguridad informatica;immune system;intrusion detection systems;artificial intelligence;programa didactico;inteligencia artificial;concordance forme;detecteur intrus;modeling;detector intruso;systeme detection intrusion;systeme immunitaire;intrusion detection system	Traditional IDS (Intrusion Detection System) performs detection by matching the sample pattern with the intrusion pattern that has been defined, as a result the IDS loses the diversity and the self-adaptation and can not detect the variation intrusion and the unknown intrusion. This paper gives a distributed intrusion detection approach based on the Artificial Immune System. It defines the Self, Nonself and immune cell and builds an intrusion detection model composed of memory cell, mature cell and immature cell and also gives the environment definition, matching rule, training detection system, immune regulation and memory, monitor generation and so on. The result of the experiment show that this intrusion detection system model has the characters of distributed, error tolerance, dynamic learning, adaptation and this approach is efficient to the network intrusion detection.	artificial immune system;bandwidth (signal processing);error-tolerant design;intrusion detection system;memory cell (binary);network security;self-organization;sensor	Pei-Li Qiao;Jie Su;Chengwei Sun	2005		10.1117/12.601862	anomaly-based intrusion detection system;embedded system;host-based intrusion detection system;engineering;artificial intelligence;computer security;intrusion prevention system	ML	-63.94444158162782	70.0505709054009	73244
d53399398cdb8e38134fb5289373667e1d1ad582	an intrusion detection game in access control system for the m2m local cloud platform	game theory;game theory authorisation cloud computing;authorisation;cloud;intrusion detection;m2m;access control;intrusion detection game machine to machine system nash equilibrium multistage bayesian game defender rational attacker ids intrusion detection system distributed m2m gateways distributed m2m local cloud platform access control system;cloud game theory access control intrusion detection m2m;games logic gates monitoring bayes methods history intrusion detection;cloud computing	A distributed M2M local cloud platform which consists of distributed M2M gateways, needs to be equipped with an Intrusion Detection System (IDS) to monitor its resources against security attacks, especially from the insider, e.g. another gateway within the local cloud. In this paper, the interaction between rational attacker and defender in the context of an M2M local cloud platform as a multi-stage Bayesian game is studied. In this game formulation, a defender is able to update its belief upon the maliciousness of the attacker. The feasible Nash equilibrium of the game is reviewed and an analytical framework for the rational attacker and defender is provided for a given set of resources with different security values under some constraints on the attack and monitor resources. In the numerical analysis, it can be shown that by having multiple resources to be attacked and/or monitored simultaneously provides a kind of diversity which helps to improve the belief update of the defender.	access control;cloud computing;control system;converge;intrusion detection system;m2m (eclipse);microsoft outlook for mac;nash equilibrium;numerical analysis	Bayu Anggorojati;Neeli R. Prasad;Ramjee Prasad	2013	2013 19th Asia-Pacific Conference on Communications (APCC)	10.1109/APCC.2013.6765968	host-based intrusion detection system;computer science;distributed computing;internet privacy;computer security;intrusion prevention system	AI	-64.54763596434077	61.70188651583587	73447
3126ba3bed82bcfe3d19edfc9f3a7576264a2113	service usage classification with encrypted internet traffic in mobile messaging apps	mobile messaging app in app analytics service usage classification encrypted internet traffic;mobile messaging app;service usage classification;delay effects;telecommunication traffic behavioural sciences computing cryptography hidden markov models intelligent networks internet mobile computing pattern classification pattern clustering;hidden markov models;internet;cryptography;feature extraction;mobile communication internet cryptography feature extraction mobile computing hidden markov models delay effects;mobile communication;mixed identify service usages service usage classification mobile messaging application encrypted internet traffic intelligent network management packet inspection in application usages cumma user behavioral patterns network traffic characteristics packet length time delay service usage predictor clustering hidden markov model based method clustering hmm based method;mobile computing;encrypted internet traffic;in app analytics	The rapid adoption of mobile messaging Apps has enabled us to collect massive amount of encrypted Internet traffic of mobile messaging. The classification of this traffic into different types of in-App service usages can help for intelligent network management, such as managing network bandwidth budget and providing quality of services. Traditional approaches for classification of Internet traffic rely on packet inspection, such as parsing HTTP headers. However, messaging Apps are increasingly using secure protocols, such as HTTPS and SSL, to transmit data. This imposes significant challenges on the performances of service usage classification by packet inspection. To this end, in this paper, we investigate how to exploit encrypted Internet traffic for classifying in-App usages. Specifically, we develop a system, named CUMMA, for classifying service usages of mobile messaging Apps by jointly modeling user behavioral patterns, network traffic characteristics, and temporal dependencies. Along this line, we first segment Internet traffic from traffic-flows into sessions with a number of dialogs in a hierarchical way. Also, we extract the discriminative features of traffic data from two perspectives: (i) packet length and (ii) time delay. Next, we learn a service usage predictor to classify these segmented dialogs into single-type usages or outliers. In addition, we design a clustering Hidden Markov Model (HMM) based method to detect mixed dialogs from outliers and decompose mixed dialogs into sub-dialogs of single-type usage. Indeed, CUMMA enables mobile analysts to identify service usages and analyze end-user in-App behaviors even for encrypted Internet traffic. Finally, the extensive experiments on real-world messaging data demonstrate the effectiveness and efficiency of the proposed method for service usage classification.	behavioral pattern;broadcast delay;cluster analysis;encryption;experiment;https;hidden markov model;hypertext transfer protocol;intelligent network;internet;kerrison predictor;list of http header fields;markov chain;network packet;network traffic control;parsing;performance;transport layer security	Yanjie Fu;Hui Xiong;Xinjiang Lu;Jin Yang;Can Chen	2016	IEEE Transactions on Mobile Computing	10.1109/TMC.2016.2516020	feature extraction;computer science;cryptography;operating system;internet privacy;mobile computing;world wide web;internet traffic engineering;computer network	Metrics	-63.85001613226027	66.43483476201011	79504
94575e90c9194b83b0ad9164e1c8effae4df2405	an immunity-based model for dynamic distributed intrusion detection	distributed system;intruder detector;adaptability;adaptabilite;networks;systeme reparti;model combination;procesamiento informacion;televigilancia;securite;surveillance;distributed networks;0130c;computer intrusion detection;data processing;traitement donnee;intrusion detection;data fusion;data mining;adaptabilidad;remote supervision;sistema repartido;fouille donnee;telesurveillance;fusion donnee;safety;information processing;8920;detecteur intrus;traitement information;fusion datos;detector intruso;intrusion detection system	The traditional intrusion detection systems mostly adopt the analysis engine of the concentrating type, so the misinformation rate is higher and lack of self-adaptability, which is already difficult to meet increasing extensive security demand of the distributed network environment. An immunity-based model combining immune theory, data mining and data fusion technique for dynamic distributed intrusion detection is proposed in this paper. This system presents the method of establishing and evolving the set of early gene, and defines the sets of Self, Nonself and Immunity cells. Moreover, a detailed description is given to the architecture and work mechanism of the model, and the characters of the model are analyzed.	intrusion detection system	Pei-Li Qiao;Tong Wang;Jie Su	2008		10.1117/12.772250	anomaly-based intrusion detection system;intrusion detection system;data processing;information processing;artificial intelligence;data mining;computer security	ML	-63.98101466462816	70.04747089428554	82263
4560305dc50a0437a3cae43c5a5b628db72abb8e	identifying the provenance of correlated anomalies	lineage;distributed system;anomalies;intrusion detection;detection;grid;monitoring;provenance;distributed;correlation;quality of service	Identifying when anomalous activity is correlated in a distributed system is useful for a range of applications from intrusion detection to tracking quality of service. The more specific the logs, the more precise the analysis they allow. However, collecting detailed logs from across a distributed system can deluge the network fabric. We present an architecture that allows fine-grained auditing on individual hosts, space-efficient representation of anomalous activity that can be centrally correlated, and tracing anomalies back to individual files and processes in the system. A key contribution is the design of an anomaly-provenance bridge that allows opaque digests of anomalies to be mapped back to their associated provenance.	anomaly detection;distributed computing;intrusion detection system;quality of service;tracing (software)	Dawood Tariq;Basim Baig;Ashish Gehani;Salman Mahmood;Rashid Tahir;Azeem Aqil;Fareed Zaffar	2011		10.1145/1982185.1982236	intrusion detection system;real-time computing;quality of service;computer science;data mining;grid;world wide web;computer security;correlation	Networks	-64.03892914808712	67.57626492665995	83264
0c252a2ed9606f32f8e92b02901e1a95231b6826	economic denial of sustainability attacks mitigation in the cloud		Cyber security is one of the most attention seeking issues with the increasing advancement of technology specifically when the network availability is threaten by attacks such as Denial of Service attacks (DoS), Distributed DoS attacks (DDoS), and Economic Denial of Sustainability (EDoS). The loss of the availability and accessibility of cloud services have greater impacts than those in the traditional enterprises networks. This paper introduces a new technique to mitigate the impacts of attacks which is called Enhanced DDoS-Mitigation System (Enhanced DDoSMS) that helps in overcoming the determined security gap. The proposed technique is evaluated experimentally and the result shows that the proposed method adds lower delays as a result of the enhanced security. The paper also suggests some future directions to improve the proposed framework.		Wael Alosaimi;Michal Zak;Khalid Al-Begain;Roobaea Alroobaea;Mehedi Masud	2017	IJCNIS		computer network;computer science;attention seeking;denial;cloud computing;sustainability;denial-of-service attack	Security	-63.08273279559404	61.77655131055239	84362
ed06bcf2fdc29673dc0a7d78d9c78ac4f6bc81cc	a theoretical model for the average impact of attacks on billing infrastructures	modelizacion;distributed system;billing;theoretical model;systeme reparti;securite informatique;time window;vulnerability;service utilisateur;computer security;modelisation;vulnerabilite;vulnerabilidad;sistema repartido;tariffication;tarification;seguridad informatica;retard;mathematical model;fenetre temporelle;servicio usuario;facturation;ventana temporal;user service;retraso;modeling;tarificacion;facturacion	The 0-delay is a mathematical model to evaluate the average impact of attacks on a billing infrastructure, that is an infrastructure that supports the billing of a set of users for some service. The model describes the search for vulnerabilities as a competition between a set of attackers and one of defenders, that are interested, respectively, in attacking and patching the infrastructure. As implied by its name, the model assumes that both the attack and the patching occur as soon as the vulnerability is discovered. The model assumes that the impact increases with the size of the vulnerability window, the time in between the discovery of the vulnerability by an attacker and by a defender and it relates this size to the numbers of attackers and of defenders. After describing the model, we describe some applications and generalizations.		Fabrizio Baiardi;Claudio Telmon	2005		10.1007/11560326_23	simulation;systems modeling;telecommunications;vulnerability;computer science;mathematical model;computer security	Crypto	-63.278478515962064	70.98481142923842	85012
22c19716fc625175790a53f0c418e8590a4a1bf0	access control requirements for preventing insider threats	sensibilidad contexto;estensibilidad;controle acces;grain size;context aware;contre mesure electronique;securite informatique;intelligence artificielle;intelligence community;computer security;large scale;contra medida electronica;grosor grano;seguridad informatica;artificial intelligence;access control;extensibilite;scalability;inteligencia artificial;sensibilite contexte;electronic countermeasure;grosseur grain	Today the Intelligence Community (IC) has faced increasing challenges of insider threats. It is generally accepted that the cost of insider threats exceeds that of outsider threats. Although the currently available access control approaches have a great potential for preventing insider threats, there are still critical obstacles to be solved, especially in large-scale computing environments. In this paper we discuss those requirements with respect to scalability, granularity, and context-awareness. For each requirement we discussed related problems, techniques, and basic approaches to the corresponding countermeasures. Detailed solutions and implementations are not described in this paper.	access control;requirement	Joon Sung Park;Joseph Giordano	2006		10.1007/11760146_52	scalability;simulation;telecommunications;computer science;access control;electronic countermeasure;computer security;grain size	Security	-63.95558270464595	70.12987746420806	86536
403258f70f6b258934bf59ce9efc47b7b1c9cbe6	sdbf: smart dns brute-forcer	markov chain model;generators;information sources;measurement;markov processes dictionaries feature extraction probes servers generators measurement;network performance;probes;large scale;servers;internet;program testing;reverse dns sdbf smart dns brute forcer domain name structure security assessment network penetration testing dns service reconnaissance tasks botnets brute force attacks natural language modeling markov chain models dns scanner domain name system brute force scanning;feature extraction;natural language;dictionaries;markov process;security assessment;markov processes;security of data internet markov processes natural language processing program testing;security of data;natural language processing;language model	The structure of the domain name is highly relevant for providing insights into the management, organization and operation of a given enterprise. Security assessment and network penetration testing are using information sourced from the DNS service in order to map the network, perform reconnaissance tasks, identify services and target individual hosts. Tracking the domain names used by popular Botnets is another major application that needs to undercover their underlying DNS structure. Current approaches for this purpose are limited to simplistic brute force scanning or reverse DNS, but these are unreliable. Brute force attacks depend of a huge list of known words and thus, will not work against unknown names, while reverse DNS is not always setup or properly configured. In this paper, we address the issue of fast and efficient generation of DNS names and describe practical experiences against real world large scale DNS names. Our approach is based on techniques derived from natural language modeling and leverage Markov Chain Models in order to build the first DNS scanner (SDBF) that is leveraging both, training and advanced language modeling approaches.	botnet;brute force;brute-force search;language model;markov chain;natural language;penetration test	Cynthia Wagner;Jérôme François;Radu State;Thomas Engel;Gérard Wagener;Alexandre Dulaunoy	2012	2012 IEEE Network Operations and Management Symposium	10.1109/NOMS.2012.6212021	telecommunications;computer science;operating system;data mining;markov process;world wide web;computer security;statistics;computer network;language model	Security	-64.75105845331119	65.91501130884265	92870
90839a746090773ad0ed8e79640d0b31f6a08c87	hifind: a high-speed flow-level intrusion detection approach with dos resiliency	estensibilidad;teletrafic;faux positif;metodo caso peor;teledetection;on line systems;intruder detector;routeur;congestion trafic;streaming;televigilancia;network monitoring;congestion trafico;surveillance;high speed networks;information transmission;data stream;gestion trafic;securite informatique;intrusion detection;attaque informatique;traffic management;falso positivo;computer security;remote supervision;teletrafico;transmission en continu;vigilancia;resilience;monitoring;traffic congestion;theoretical analysis;telesurveillance;systeme en ligne;seguridad informatica;remote sensing;teledeteccion;teletraffic;methode cas pire;computer attack;gestion trafico;router;ataque informatica;information gateway;network level security and protection;extensibilite;scalability;resiliencia;monitorage;transmision fluyente;transmision informacion;attack resilience;transmission information;false positive;detecteur intrus;statistical detection;monitoreo;pasarela informacion;passerelle d information;worst case method;detector intruso;high speed;intrusion detection system;data streaming	Global-scale attacks like worms and botnets are increasing in frequency, severity and sophistication, making it critical to detect outbursts at routers/gateways instead of end hosts. In this paper, leveraging data streaming techniques such as the reversible sketch, we design HiFIND, a High-speed Flow-level Intrusion Detection system. In contrast to existing intrusion detection systems, HiFIND: (i) is scalable to flow-level detection on high-speed networks; (ii) is DoS resilient; (iii) can distinguish SYN flooding and various port scans (mostly for worm propagation) for effective mitigation; (iv) enables aggregate detection over multiple routers/gateways; and (v) separates anomalies to limit false positives in detection. Both theoretical analysis and evaluation with several router traces show that HiFIND achieves these properties. To the best of our knowledge, HiFIND is the first online DoS resilient flow-level intrusion detection system for high-speed networks (e.g. OC192), even for the worst-case traffic of 40-byte-packet streams with each packet forming a flow. 2009 Elsevier B.V. All rights reserved.	aggregate data;best, worst and average case;botnet;emoticon;intrusion detection system;network packet;optical carrier transmission rates;router (computing);syn flood;scalability;software propagation;tracing (software)	Zhichun Li;Yan Gao;Yan Chen	2010	Computer Networks	10.1016/j.comnet.2009.10.016	anomaly-based intrusion detection system;intrusion detection system;telecommunications;computer science;computer security;psychological resilience;computer network	Security	-62.97205691221729	69.39573663899642	93584
942dad5016c870be6db82eb05b2b75ded9fb439a	physics-based features for anomaly detection in power grids with micro-pmus		The expansion of monitoring systems for power grids from the traditional transmission lines to include the distribution grid - closer to the end-user - is largely due to the advance in electrical monitoring devices and their increasing affordability. This paradigm-shift benefits from new algorithms that can be implemented at the grid edge (as opposed to the transmission grid) to detect anomalies faster, more efficiently, and in real-time. Micro-PMUs are phasor measurement units that can be placed on the distribution lines to provide real-time data about the state of the grid and can detect fast transients. In this paper, we use data from micro-PMUs to engineer physics-based features for a novel anomaly detection algorithm that detects anomalies based on the transient properties of the power grid. This allows for a more capable, agile, and reliable anomaly scoring system that can learn normal behavior patterns and detect anomalous behavior efficiently. We show that by combining the classical data-based approaches with physics-based features in the anomaly detection algorithm, the machine learning algorithm proposed is capable of detecting different classes of anomalies (such as edge devices on-off attacks, single line-to-ground (SLG) faults, etc.). Simulation results on IEEE 34-node test feeder show that we can achieve better detection performance than traditional techniques for a broader class of anomalies.	agile software development;algorithm;anomaly detection;bbc micro;computer simulation;machine learning;phasor;programming paradigm;real-time clock;real-time data;sensor;steady state;switch;transmission line	Mahmoud El Chamie;Kin Gwn Lore;Devu Manikantan Shila;Amit Surana	2018	2018 IEEE International Conference on Communications (ICC)	10.1109/ICC.2018.8423024	edge device;real-time computing;anomaly detection;grid;electric power transmission;feature extraction;computer science;phasor	Robotics	-63.98075218177141	62.97563211765637	95931
6dccbb5208544e838ddaacfc7861de1ca0875c68	adaptive detection of local scanners	metodo adaptativo;change detection;scan detection;analisis estadistico;detection adaptative;securite informatique;scanneur;methode adaptative;probabilistic approach;escaner;scanner;busca local;mine detection;computer security;codificacion;epidemia;statistical analysis;criptografia;enfoque probabilista;cryptography;approche probabiliste;seguridad informatica;robustesse;epidemie;adaptive method;analyse statistique;coding;cryptographie;robustness;internet worms;security;local search;recherche locale;epidemic;codage;adaptive detection;deteccion adaptativa;robustez	Network attacks often employ scanning to locate vulnerable hosts and services. Fast and accurate detection of local scanners is k ey to containing an epidemic in its early stage. Existing scan detection scheme s us statically determined detection criteria, and as a result do not respond well to traffic perturbations. We present two adaptive scan detection schemes, Success Based (SB) and Failure Based (FB), which change detection criteria based on traffic stati tics. We evaluate the proposed schemes analytically and empiricall y using network traces. Against fast scanners, the adaptive schemes render detecti on precision similar to the traditional static schemes. For slow scanners, the ad aptive schemes are much more effective, both in terms of detection precision an d speed. SB and FB have non-linear properties not present in other schemes. Th ese properties permit a lowerSustained Scanning Threshold and a robustness against perturbations in the background traffic.	algorithm;image scanner;nonlinear system;sandy bridge;sensor;tracing (software)	Ahren Studer;Chenxi Wang	2006		10.1007/11767480_1	telecommunications;computer science;cryptography;local search;information security;coding;computer security;change detection;statistics;robustness	Security	-63.10787881477492	69.79342704796863	98749
81ff14ac62d89c5213d96e4a46704e38f024512a	efficient quarantining of scanning worms: optimal detection and coordination	detectors;information security;bayesian methods;sequential analysis;intrusion detection;bayesian decision theory;design method;monitoring;aggregates;decision theory;taxonomy;detectors bayesian methods sequential analysis intrusion detection monitoring aggregates design methodology decision theory information security taxonomy;design methodology	Current generation worms have caused considerable damage, despite their use of unsophisticated scanning strategies for detecting vulnerable hosts. A number of adaptive techniques have been proposed for quarantining hosts whose behaviour is deemed suspicious. Such techniques have been proven to be effective against fast scanning worms. However, worms could evade detection by being less aggressive. In this paper we consider the interplay between worm strategies and detection techniques, which can be described in game-theoretic terms. We use epidemiological modelling to characterise the outcome of the game (the pay-off function), as a function of the strategies of the worm and the detector. We design detection rules that are optimal against scanning worms with known characteristics. We then identify specific detection rules that are close to optimal, in some mathematically precise sense, against any scanning worm. Finally, we design methods for coordinating information among a set of end-hosts, using Bayesian decision theory. We evaluate the proposed rules using simulations driven by traces from a corporate environment of 600 hosts, and assess the benefits of coordination.	decision theory;game theory;sensor;simulation;tracing (software)	Ayalvadi J. Ganesh;Dinan Gunawardena;Peter B. Key;Laurent Massoulié;Jacob Scott	2006	Proceedings IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications	10.1109/INFOCOM.2006.97	design methods;computer science;information security;machine learning;data mining;computer security;taxonomy;statistics	Embedded	-63.727988616636495	61.53886024480429	103280
b55824ff1ed68d7fd38f91124751c81138c00e04	complementing static and dynamic analysis approaches for better network defense	program diagnostics;protocols;computer network security;logic gates malware performance analysis system analysis and design portable document format protocols abstracts;system analysis and design;gateway level malicious code prevention static analysis dynamic analysis network defense malicious file execution prevention host system packet reassembly network performance reduction minimal agent based system dependability;malware network defense heuristics;software agents;software agents computer network performance evaluation computer network security invasive software program diagnostics;computer network performance evaluation;logic gates;malware;network defense;abstracts;portable document format;performance analysis;invasive software;heuristics;static and dynamic analysis	This paper presents a novel approach to prevent execution of malicious files on host system present in the network. For preventing a malicious file at gateway level, it is required to do reassembly of packets which in turn reduces the network performance by huge margins. This work combines static and dynamic analysis approaches and implements a minimal agent based system to prevent malicious files and in turn increase the dependability using existing systems.	agent-based model;dependability;network performance;segmentation and reassembly	Himanshu Pareek;N. Sarat Chandra Babu	2013	2013 43rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)	10.1109/DSN.2013.6575334	reliability engineering;communications protocol;logic gate;computer science;software agent;network security;operating system;heuristics;distributed computing;malware;world wide web;computer security;structured systems analysis and design method;computer network	SE	-63.097835943786684	60.73574484599834	103965
67561de83fa1e1fd8e8e1fa5f2dcffef7a2e10b2	application of bp neural network in wireless network security evaluation	radio networks;security evaluation;wireless networks;electronic mail;neural networks;neural nets;availability;impact factor;wireless network;controllability;risk management;bayesian methods;neural networks wireless networks artificial neural networks risk management data security electronic mail mathematical model bayesian methods communication system security matlab;risk assessment bp neural network wireless network security evaluation;wireless communication;artificial neural networks;telecommunication security neural nets radio networks;bp neural network;telecommunication security;mathematical model;risk assessment;security assessment;neural network model;matlab toolbox bp neural network wireless network security assessment indices training error;wireless network security evaluation;wireless sensor networks;matlab;neural network;communication system security;data security	As most assessment indices are subjective and uncertainly in wireless network security evaluation, this paper proposes a model that BP neural network is used in wireless network security assessment system. After building a neural network model, we could obtain the values of each evaluation index and the whole risk situation of the wireless network by inputting impact factors into neural network. At the same time, we also could know the training error of neural network under the help of MATLAB toolbox.	artificial neural network;matlab;network model;network security	Jianxin Fu;Lianfen Huang;Yan Yao	2010	2010 IEEE International Conference on Wireless Communications, Networking and Information Security	10.1109/WCINS.2010.5541848	network management station;computer science;wireless network;machine learning;data mining;time delay neural network;network simulation;network management application;computer security;artificial neural network;computer network	Mobile	-64.03718132323039	66.6541159154168	109490
07c865b3b1ab39b8c1cb4361f15ab07f8ab6f495	cyber security: influence of patching vulnerabilities on the decision-making of hackers and analysts		Patching of vulnerabilities on computer systems by analysts enables us to protect these systems from cyber-attacks. However, even after patching, the computer systems may still be vulnerable to cyber-attacks as the patching process may not be foolproof. Currently, little is known about how hacker’s attack actions would be influenced by the varying effectiveness of the patching process. The primary objective of this study was to investigate the influence of the patching process on the attack-and-defend decisions of hackers and analysts. In this study, we used a 2-player zero-sum stochastic Markov security game in a lab-based experiment involving participants performing as hackers and analysts. In the experiment, participants were randomly assigned to two between-subjects patching conditions: effective (N = 50) and less-effective (N = 50). In effective patching, the probability of the network to be in a non-vulnerable state was 90% after patching by the analyst; whereas, in less-effective patching, the probability of the network to be in the non-vulnerable state was 50% after patching by the analyst. Results revealed that the proportion of attack and defend actions were similar between effective and less-effective conditions. Furthermore, although the proportion of defend actions were similar between vulnerable and non-vulnerable states, the proportion of attack actions were smaller in the non-vulnerable state compared to the vulnerable state. A majority of time, both players deviated significantly from their Nash equilibria in different conditions and states. We highlight the implications of our results for patching and attack actions in computer networks.		Zahid Maqbool;V. S. Chandrasekhar Pammi;Varun Dutt	2018	2018 International Conference On Cyber Situational Awareness, Data Analytics And Assessment (Cyber SA)	10.1109/CyberSA.2018.8551421		SE	-64.39307726425528	61.131657496006	113833
611b5dcf2e725144b7cd6d23cb4893b0d3109950	a real-time network intrusion detection system based on incremental mining approach	computers;real time systems intrusion detection association rules data mining information analysis computer science internet electronic mail artificial intelligence ip networks;itemsets;electronic mail;incremental mining approach;network security;real time;anomaly based nids;static mining real time network intrusion detection system incremental mining approach fuzzy association rule;intrusion detection;association rules;incremental mining;data mining;fuzzy set theory;static mining;security of data data mining fuzzy set theory real time systems;internet;association rule;web sites;real time network intrusion detection system;online mining;artificial intelligence;ip networks;incremental mining network security real time nids anomaly based nids association rules fuzzy association rules online mining;computer science;information analysis;fuzzy association rule;network intrusion detection system;security of data;algorithm design and analysis;real time nids;real time systems;fuzzy association rules	The fuzzy association rule has been proven to be effective to present userspsila network behavior offline from a huge amount of collected packets. However, not only effectiveness, efficiency is important as well for Network Intrusion Detection Systems (NIDSs). None of those proposed NIDSs subject to fuzzy association rule can meet the real-time requirement because they all applied static mining approach. In the paper, we propose a real-time NIDS by incremental mining for fuzzy association rules. By consistently comparing the two rule sets, one mined from online packets and the other mined from training attack free packets, our system can make a decision per time unit, 2 seconds in the paper. Experiments have been done to demonstrate its excellent effectiveness and efficiency of the system.	association rule learning;experiment;intrusion detection system;mined;online and offline;real-time clock;real-time computing;real-time locating system	Ming-Yang Su;Kai-Chi Chang;Hua-Fu Wei;Chun-Yuen Lin	2008	2008 IEEE International Conference on Intelligence and Security Informatics	10.1109/ISI.2008.4565050	association rule learning;computer science;network security;machine learning;data mining;computer security	SE	-63.3290593449949	65.83501958133672	114558
b03bd206ab7df2247c531f65df0815dbcd917087	a digital content management model for making profits in digital content sites	content management;protection information;informacion electronica;deteccion;securite informatique;information access;detection;computer security;information electronique;modelo;proteccion informacion;digital content;information protection;seguridad informatica;comportement utilisateur;acces information;gestion contenu;electronic information;acceso informacion;modele;profitability;user behavior;models;comportamiento usuario	In this paper, we present a digital content management model to detect users who attempt to make an illegal copy of fee-charging contents. We define a set of rules to identify abnormal access behavior patterns. Our model can be applied to protect contents in fee-charging content sites.		Hyeonjeong Mun;Sooho Ok;Yongtae Woo	2002		10.1007/3-540-36227-4_61	telecommunications;content management;computer science;world wide web;computer security;information protection policy;profitability index	HCI	-63.316096964268695	71.04107433023908	115355
c00aae2c6a0e48d3fe9ea2456efade520c2f1157	a coordinated cyber attack detection system (ccads) for multiple substations	cyber security of substations coordinated cyber attacks intrusion detection system ids cyber physical testbed;cyber physical security testbed coordinated cyber attack detection system multiple substations ccads power grid cyber security power system facilities ids alarms attack geographic location substation criticality firewall log attack pattern time failure propagation graph tfpg fuzzy cognitive map fcm;intrusion detection system ids;cyber physical testbed;coordinated cyber attacks;substations firewalls computing circuit breakers correlation;substation protection cyber physical systems firewalls fuzzy reasoning power engineering computing power grids security of data;cyber security of substations	In recent years, the concern over cyber security of power grids has increased significantly due to the fast growing connectivity among power system facilities. Several cyber security measures, e.g., intrusion detection systems (IDSs) and anomaly detection systems (ADSs), have been proposed to (1) mitigate unauthorized access, (2) detect anomalies, and (3) block abnormal behaviors in the communication system of substations. However, due to the lack of capability to handle coordinated cyber attacks by existing cyber security solutions, there is a need for effective methods that can detect coordinated cyber attacks. This paper proposes a new method to detect coordinated cyber attacks on power systems by identifying the relations among detected events. Examples of the relations include (1) IDS alarms, (2) geographic location of the attack, (3) criticality of substations, (4) firewall logs, and (5) attack patterns. Time Failure Propagation Graph (TFPG) and Fuzzy Cognitive Map (FCM) are used for the detection algorithms. A cyber-physical security testbed has been used to simulate the coordinated cyber attacks and validate the methods of the proposed coordinated cyber attack detection system (CCADS).	algorithm;anomaly detection;attack patterns;authorization;computer security;criticality matrix;edge detection;firewall (computing);fuzzy cognitive map;geographic coordinate system;ibm power systems;intrusion detection system;online and offline;physical security;real-time clock;real-time computing;real-time transcription;response time (technology);sensor;simulation;software propagation;testbed;traction substation	Chih-Che Sun;Junho Hong;Chen-Ching Liu	2016	2016 Power Systems Computation Conference (PSCC)	10.1109/PSCC.2016.7540902	embedded system;engineering;computer security;computer network	Security	-63.41000730153616	62.3974327055729	116508
badcd342f1396992030a617ff32529bf677bce90	anomalous payload detection system using analysis of frequent sequential pattern	detectors;pattern clustering;telecommunication traffic data mining data reduction feature extraction pattern classification pattern clustering support vector machines telecommunication security;compact representative dataset;ensemble method;support vector machines;mimicry attack detection;anomalous traffic payload detection system;anomaly detection;training;performance of systems;frequent sequential patterns;data mining;telecommunication traffic;feature reduction;mimicry attack detection anomalous traffic payload detection system frequent sequential pattern mining n gram technique data flow pattern clustering feature reduction compact representative dataset intelligent system one class svm classifier ensemble method;feature extraction;clustering method;principal component analysis;telecommunication security;intelligent system;pattern classification;payloads;svm;frequent sequential pattern mining;one class svm classifier;data reduction;sequential pattern;data flow;n gram technique;svm anomaly detection frequent sequential patterns;payloads pattern analysis detectors feature extraction traffic control telecommunication traffic information security information analysis clustering methods support vector machines	We present a new framework of anomalous payload detection system. First of all, frequent sequential patterns (FSPs) are mined from raw traffic payloads. Setting different supports, we have several level of description of normal payload. We extract each FSP feature using n-gram technique. Thus we can have a deeper insight of data flow. By using advanced clustering method to fulfill the feature reduction, we obtain a compact representative dataset which can be directly used to intelligent system. One-class SVM classifier is used to construct each detector and ensemble method is used to further improve the performance of system. Experimental results show that our anomalous payload detection system can effectively detect the mimicry attack and other stealthy exploits.	artificial intelligence;cluster analysis;dataflow;mined;n-gram	Jun Ma;Guanzhong Dai;Jing Zhou	2009	2009 Fifth International Conference on Information Assurance and Security	10.1109/IAS.2009.34	engineering;machine learning;pattern recognition;data mining	EDA	-63.415673784656356	65.10517587940252	116851
495f6ed94e2403551768166953a638c7d4753ab5	challenging entropy-based anomaly detection and diagnosis in cellular networks	distributed consensus;dependable systems;fault tolerance	In this paper we challenge the applicability of entropy-based approaches for detecting and diagnosis network traffic anomalies, and claim that full statistics (i.e., empirical probability distributions) should be applied to improve the change-detection capabilities. We support our claim by detecting and diagnosing large-scale traffic anomalies in a real cellular network, caused by specific OTT (Over The Top) services and smartphone devices. Our results clearly suggest that anomaly detection and diagnosis based on entropy analysis is prone to errors and misses typical characteristics of traffic anomalies, particularly in the studied scenario.	anomaly detection;network traffic control;sensor;smartphone	Pierdomenico Fiadino;Alessandro D'Alconzo;Mirko Schiavone;Pedro Casas	2015		10.1145/2785956.2790011	fault tolerance;consensus;computer science;data mining;computer security	Metrics	-63.135992787033906	65.72078207930524	118291
0b0cfafeb395047c4fb3c2d483a2afe247f0c232	modeling viral economies for digital media	modele comportement;estensibilidad;performance measure;economie;scale free networks;modelizacion;police;distributed system;behavior model;economia;sistema operativo;commerce electronique;loi puissance;tratamiento transaccion;systeme reparti;incentive based economies;comercio electronico;multimedia;intellectual property;droit auteur;ley poder;economic sciences;financial performance;pricing;par a par;modelo comportamiento;comercializacion;copyright;economic model;interpretacion abstracta;probabilistic approach;scale free network;fijacion precios;modelo economico;commercialisation;modelisation;ciencias economicas;structure reseau;scale free;modele economique;client server;sistema repartido;tariffication;dynamic pricing;poste a poste;ecosysteme;operating system;digital media;ecosistema;marketing;tarification;enfoque probabilista;approche probabiliste;multimedia distribution;propiedad intelectual;comportement utilisateur;policia;systeme exploitation;sciences economiques;economy;extensibilite;scalability;user behavior;power law;network structure;interpretation abstraite;transaction processing;abstract interpretation;peer to peer;modeling;propriete intellectuelle;fixation prix;comportamiento usuario;electronic trade;traitement transaction;ecosystem;viral marketing;tarificacion;derecho autor	"""Financial efficiency is the premier performance measure for most systems. Existing economic ecosystems for distribution of multimedia leave a lot to be desired: client-server platforms do not scale well resulting in substantial operational costs, whereas peer-to-peer platforms cannot police copyright control and are thus notorious for not being able to capitalize on its vast delivery potential. In this paper, we introduce an economic model that aims at predicting financial performance of both client-server and viral distribution systems for multimedia. The model consists of several probabilistic components: a global scale-free viral network of users and a localized user-behavior model that abstracts marketing, pricing, and executed transactions. The model uses simulation to predict relative economic behavior. In order to showcase our model, we compared the popular """"on-line store"""" distribution system to the recently proposed off-line incentive-based viral ecosystem for multimedia. We also constructed an efficient dynamic pricing scheme and evaluated its performance in considered multimedia distribution scenarios."""	behavior model;client–server model;digital media;ecosystem;online and offline;peer-to-peer;server (computing);simulation	Shan He;Renan G. Cattelan;Darko Kirovski	2008		10.1145/1352592.1352609	simulation;computer science;scale-free network;operations research	OS	-63.349787717388224	71.1558663588899	118696
4133844b976307a4166e46385a5c3c3d910f9db8	application of anomaly detection algorithms for detecting syn flooding attacks	detection probability;adaptive thresholding;criterio resultado;algoritmo adaptativo;network security;anomaly detection;securite informatique;false alarm rate;performance requirement;critere performance;computer security;adaptive algorithm;algorithme adaptatif;detection anomalie;seguridad informatica;denial of service;detection algorithm;point changement;cumulant;taux fausse alarme;change point detection;porcentaje falsa alarma;punto cambio;change point;denegacion de servicio;deni service;dos attack	We investigate statistical anomaly detection algorithms for detecting SYN flooding, which is the most common type of denial of service (DoS) attack. The two algorithms considered are an adaptive threshold algorithm and a particular application of the cumulative sum (CUSUM) algorithm for change point detection. The performance is investigated in terms of the detection probability, the false alarm ratio, and the detection delay. Particular emphasis is on investigating the tradeoffs among these metrics and how they are affected by the parameters of the algorithm and the characteristics of the attacks. Such an investigation can provide guidelines to effectively tune the parameters of the detection algorithm to achieve specific performance requirements in terms of the above metrics.	algorithm;anomaly detection;denial-of-service attack;quality of service;requirement;syn flood;sensor	Vasilios A. Siris;Fotini Papagalou	2004	IEEE Global Telecommunications Conference, 2004. GLOBECOM '04.	10.1016/j.comcom.2005.09.008	anomaly detection;telecommunications;computer science;network security;computer security;denial-of-service attack;algorithm	Vision	-63.13866820583602	69.55532719514133	120829
3bb8afb6f6e3f51000f2dbfc0d52addd309512aa	a comparison of classification techniques for detection of voip traffic	firewalls computing;protocols;legacy techniques classification techniques voice over ip communications voip communications voice communications internet session initiation protocol sip voip services skype google talk yahoo voice usage policy enforcement quality assurance data networks voip protocol traffic network traffic communication flows anomaly detection;protocols ports computers classification algorithms telecommunication traffic algorithm design and analysis tunneling firewalls computing;detection techniques;voice communication data communication internet telephony signalling protocols telecommunication services telecommunication traffic;telecommunication traffic;detection techniques voip traffic classification;traffic classification;classification algorithms;ports computers;algorithm design and analysis;voip;tunneling	A new breed of applications for Voice over IP (VoIP) communications has emerged in recent years, providing a viable service for voice communications on the Internet. Mostly provided as over-the-top services, both standards-based Session Initiation Protocol (SIP) VoIP services and proprietary alternatives such as Skype, Google Talk and Yahoo! Voice have earned considerable popularity, mostly because of their low cost and ease of use. However, for various reasons, such as usage policy enforcement, quality assurance, security or specific business interests, there is a need to detect and monitor the presence of VoIP traffic on data networks. The main objective of this paper is to present a survey of techniques for detection and classification of VoIP protocol traffic, with an emphasis on two major categories (profiling of network traffic patterns and modeling of communication flows for anomaly detection) also discussing the several algorithms and techniques within these two groups. Legacy techniques are also briefly described, albeit for the sake of completeness.	algorithm;anomaly detection;baseline (configuration management);categorization;channel (communications);entity;evasion (network security);internet;machine learning;network traffic control;over-the-top content;quality of service;sensor;tunneling protocol;usability	Hugo Fonseca;Tiago Cruz;Paulo Simões;Edmundo Monteiro;Jose Silva;Pedro Gomes;Nuno Centeio	2014	2014 Eighth International Conference on Next Generation Mobile Apps, Services and Technologies	10.1109/NGMAST.2014.32	statistical classification;communications protocol;algorithm design;traffic classification;telecommunications;computer science;voice over ip;quantum tunnelling;world wide web;mobile communications over ip;computer security;computer network	Metrics	-63.510411645228636	66.66564090357531	121858
48cefd8a3edd4714133f8e86a466ec8d9f73e4ca	high-speed intrusion detection in support of critical infrastructure protection	scada;ecoulement trafic;intruder detector;grain size;critical information infrastructure protection ciip;reseau communication;sistema critica;surveillance;network security;information infrastructure;real time;systeme critique;securite informatique;customization;personnalisation;security management;telecommunication network;intrusion detection;traffic flow;controle information;critical infrastructure protection cip;sistema reactivo;computer security;vigilancia;critical system;sante;monitoring;control informacion;community networks;grosor grano;grande vitesse;network traffic;red telecomunicacion;seguridad informatica;temps reel;comportement utilisateur;reseau telecommunication;intrusion detection systems;personalizacion;reactive system;systeme reactif;tiempo real;gran velocidad;user behavior;monitorage;health;information system;salud;detecteur intrus;information control;networked systems;monitoreo;critical infrastructure;detector intruso;red de comunicacion;flujo trafico;high speed;communication network;systeme information;systeme detection intrusion;comportamiento usuario;intrusion detection system;telecommunication networks;critical infrastructure protection;distributed architecture;sistema informacion;flow monitoring;grosseur grain	Telecommunication network plays a fundamental role in the management of critical infrastructures since it is largely used to transmit control information among the different elements composing the architecture of a critical system. The health of a networked system strictly depends on the security mechanisms that are implemented in order to assure the correct operation of the communication network. For this reason, the adoption of an effective network security strategy is seen as an important and necessary task of a global methodology for critical infrastructure protection. In this paper we present 2 contributions. First, we present a distributed architecture that aims to secure the communication network upon which the critical infrastructure relies. This architecture is composed of an intrusion detection system (IDS) which is built on top of a customizable flow monitor. Second, we propose an innovative method to extrapolate real-time information about user behavior from network traffic. This method consists in monitoring traffic flows at different levels of granularity in order to discover ongoing attacks.	critical infrastructure protection;intrusion detection system	Salvatore D'Antonio;Francesco Oliviero;Roberto Setola	2006		10.1007/11962977_18	intrusion detection system;embedded system;telecommunications;computer science;network security;computer security	Security	-64.034399353551	69.06115762983823	125296
b6868b07748e228ece78067c1c85d19194bee6dc	estimating the relative trustworthiness of information sources in security solution evaluation	distributed system;cortafuego;confiance;sistema experto;systeme reparti;psychologie sociale;information sources;analisis estadistico;protocole transmission;information source;surveillance;source information;real time;securite informatique;attaque informatique;computer security;pare feu reseau;protocolo transmision;confidence;fichier log;vigilancia;sistema repartido;fichero actividad;statistical analysis;monitoring;confianza;seguridad informatica;temps reel;analyse statistique;action observation;psicologia social;computer attack;tiempo real;ataque informatica;social psychology;monitorage;systeme expert;monitoreo;log file;fuente informacion;security protocol;firewall;expert system;transmission protocol	When evaluating alternative security solutions, such as security mechanism, security protocols etc., “hard” data or information is rarely available, and one have to relay on the opinions of domain experts. Log-files from IDS, Firewalls and honeypots might also be used. However, such source are most often only used in an “penetrate and patch” strategy, meaning that system administrators, security experts or similar surveillance the network and initiate appropriate reactions to the actions observed. Such sources refers to real-time information, but might also be used in a more preventive manner by combining it with the opinions provided by the domain experts. To appropriately combine the information from such various sources the notion of trust is used. Trust represents the degree to which a particular information source can be trusted to provide accurate and correct information, and is measured as information source relative trustworthiness. In this paper we show how to assign this relative trustworthiness using two trust variables; (1) knowledge level and (2)level of expertise.	aspect-oriented software development;bayesian network;computation;computer security;correctness (computer science);daniel goossens;firewall (computing);honeyd;honeynet project;honeypot (computing);informatics;information source;knowledge level;linux intrusion detection system;norm (social);prototype;real-time computing;real-time data;relay;risk management;system administrator;trust (emotion);trust metric;trustworthy computing;ver (command);web page;world wide web	Siv Hilde Houmb;Indrakshi Ray;Indrajit Ray	2006		10.1007/11755593_11	firewall;telecommunications;computer science;artificial intelligence;confidence;computer security;expert system	Security	-63.133601376045114	69.87681504144724	125364
65ab68f75c173ff65c2eb016eb0085900cc855d7	anti-virus security and robustness of heterogeneous immune static network	immune network;anti-virus security;unknown virus;unknown non-self;security;self database;immune model;anti-virus;non-self representation;immune computation model;non-self detection;normal model;static network system;known non-self;heterogeneous immune static network;non-self database;network security;neural network;computer model;immune system	Unknown viruses are dangerous for networks, but traditional approaches for recognizing the features of viruses are not good at detecting the unknown viruses. To overcome the bottleneck, a normal model and an immune computation model were proposed with self/non-self representation to detect recognize and eliminate worms in a heterogeneous e-learning network. Inspired from the natural immune system, the immune computation included the steps of detecting self/non-self, recognizing known non-self, learning unknown non-self and eliminating non-self. The self/non-self detection was based on querying in the self database and the self database was built on the normal model of the static network system. After the detection, the recognition of known non-self was based on querying in the non-self database and the recognition of unknown non-self was based on learning unknown non-self. The learning algorithm was designed on the neural network or the learning mechanism from examples. The last step was elimination of all the non-self and failover of the damaged Web system. The immunization of the static network system was programmed with Java to test effectiveness of the approach, after the static network system was infected by some worms. The results of the immunization simulations show that, the immune program can detect all the worms, recognize all known worms and most unknown worms, and eliminate the worms. Moreover, the damaged files of the static network system can all be repaired through the normal model and immunization. Therefore, the normal model and the immune computation model of the static network system are effective in some anti-virus applications.	algorithm;antivirus software;artificial neural network;failover;interpretation (logic);java;model of computation;sensor;simulation	Tao Gong	2008			real-time computing;distributed computing;computer network	AI	-65.09031505042604	63.25001230676781	131052
8974ab13f5818346364750e438df7d6f17fdac46	security in networks: a game-theoretic approach	computers;intrusion;game theory;nash equilibrium;network security;internet network security game theory nash equilibrium virus attacks;receivers;viruses;gametheory;computer viruses;computational modeling;internet;games;grippers;gametheory security intrusion viruses deception;intrusion detection costs computer security computer worms bayesian methods information security internet computer viruses computer networks nash equilibrium;security;internet computer viruses game theory;virus attacks;deception	This paper explores network security as a game between attacker and defender. In this game, the attacker and defender both anticipate each other¿s best strategy. Thus, instead of focusing on the best response to an attack, the paper analyzes the Nash equilibrium for the joint strategies. The paper studies two types of problem. The first type concerns networks where the data can be modified by an intruder. Given the probability that such an intruder exists, the network user decides whether to trust the data he observes. When present, the intruder chooses how to corrupt the data. The second type models virus attacks. The virus designer decides how aggressive the virus should be and the defender chooses a mechanism to detect the virus. If the virus is too aggressive, it is easy to detect. Accordingly, there is an optimum level of aggressiveness.	computer;game theory;intrusion detection system;nash equilibrium;network security	Assane Gueye;Jean C. Walrand	2008	2008 47th IEEE Conference on Decision and Control	10.1109/CDC.2008.4739431	games;game theory;the internet;simulation;intrusion;computer science;engineering;internet privacy;computational model;computer security;nash equilibrium;computer virus	AI	-64.1867207515691	61.59541411966536	132147
1d381d8e88f921dfbdf1f9242bb005d359d69048	minetrac: mining flows for unsupervised analysis & semi-supervised classification	hierarchical clustering;cluster algorithm;evidence accumulation;telecommunication traffic internet learning artificial intelligence;clustering algorithms partitioning algorithms accuracy training algorithm design and analysis computational modeling vegetation;computer model;training;supervised classification;traffic flow;hierarchical clustering unsupervised traffic analysis semi supervised traffic classification sub space clustering evidence accumulation;semi supervised learning;supervised machine learning;vegetation;automatic classification minetrac mining flows unsupervised analysis semi supervised classification well known limitations port based analysis techniques payload based analysis techniques internet traffic analysis unsupervised machine learning techniques semi supervised machine learning techniques ip flows sharing sub space clustering evidence accumulation hierarchical clustering algorithms inter flows structure;accuracy;telecommunication traffic;computational modeling;internet traffic;internet;machine learning;traffic classification;traffic analysis;clustering algorithms;ground truth;semi supervised traffic classification;learning artificial intelligence;network services;automatic classification;sub space clustering;data structure;algorithm design and analysis;training algorithm;flow analysis;partitioning algorithms;unsupervised traffic analysis	Driven by the well-known limitations of port-based and payload-based analysis techniques, the use of Machine Learning for Internet traffic analysis and classification has become a fertile research area during the past half-decade. In this paper we introduce MINETRAC, a combination of unsupervised and semi-supervised machine learning techniques capable of identifying and classifying different classes of IP flows sharing similar characteristics. The unsupervised analysis is accomplished by means of robust clustering techniques, using Sub-Space Clustering, Evidence Accumulation, and Hierarchical Clustering algorithms to explore inter-flows structure. MINETRAC permits to identify natural groupings of traffic flows, combining the evidence of data structure provided by different partitions of the same set of traffic flows. Automatic classification is performed by means of semi-supervised learning, using only a small fraction of ground-truth flows to map the identified clusters into their associated most-probable originating network service or application. We evaluate the performance of MINETRAC using real traffic traces, additionally comparing its performance against previously proposed clustering-based flow analysis methods and supervised/semi-supervised classification approaches.	algorithm;cluster analysis;data structure;data-flow analysis;ground truth;hierarchical clustering;machine learning;semi-supervised learning;semiconductor industry;supervised learning;tracing (software);traffic analysis;tree accumulation;whole earth 'lectronic link	Pedro Casas;Johan Mazel;Philippe Owezarski	2011	2011 23rd International Teletraffic Congress (ITC)		unsupervised learning;algorithm design;the internet;traffic classification;internet traffic;data structure;ground truth;computer science;machine learning;data-flow analysis;traffic flow;pattern recognition;data mining;hierarchical clustering;accuracy and precision;cluster analysis;computational model;vegetation;conceptual clustering	Metrics	-63.75621348147597	66.5741678393915	132695
d136ee2aefc50f25d6ff220da4d5ce4996997fe5	validation of network simulation model with emulation using example malware	firewalls computing;emulation;virtual machines computer network security finite state machines invasive software microprocessor chips;virtual machine network simulation model cyber army modeling and simulation malware propagation cyams finite state representation behavioral simulation finite state machine model cpu core;automata;computational modeling;malware;computational modeling malware emulation firewalls computing data models ip networks automata;ip networks;data models	Under the Cyber Army Modeling and Simulation (CyAMS) program, a model validation was conducted using data from an emulated network for malware propagation to compare against the CyAMS finite state representation of network nodes and processes using behavioral simulation. During the validation process, the finite state machine model was effective in identifying important caveats in the emulation tests. Once the experimental parameters were correctly defined, the CyAMS model and the emulated networks showed similar outcomes. The simulation in this case utilized at most 3 CPU cores, whereas the emulation approach required roughly 2,000 real computers and 14,800 virtual machines. The results highlight the possibility that simulation methods can be as effective as emulation test beds in selected cases. Further, simulation results can be an effective tool to verify the goals of emulation based experiments in some cases. Results demonstrated that several orders of magnitude of less computing resources are required for a simulation compared to emulation for this particular test case.	central processing unit;computer;emulator;experiment;finite-state machine;malware;numeric character reference;simulation;software propagation;test case;testbed;theory;virtual machine	Scott E. Brown;Brian Henz;Harold Brown;Michael Edwards;Michael Russell;Jonathan Mercurio	2015	MILCOM 2015 - 2015 IEEE Military Communications Conference	10.1109/MILCOM.2015.7357619	real-time computing;simulation;computer science;theoretical computer science;semulation;hardware emulation	EDA	-65.7695667484153	65.25270149314622	137666
ea1b85c4ddd440319a2af47cfa4549d6c8238b8a	incorporating data mining tools into a new hybrid-ids to detect known and unknown attacks	tolerancia falta;extraction information;analisis estadistico;fault tolerant;analisis datos;information extraction;network security;pervasive computing;securite informatique;intelligence artificielle;vulnerability;attaque informatique;data mining;informatica difusa;computer security;data analysis;vulnerabilite;vulnerabilidad;honeypot;statistical analysis;monitoring;fouille donnee;informatique diffuse;seguridad informatica;fault tolerance;denial of service;analyse statistique;computer attack;ataque informatica;artificial intelligence;analyse donnee;inteligencia artificial;monitorage;monitoreo;busca dato;extraccion informacion;tolerance faute;denegacion de servicio;deni service;dos attack	Modern network attacks range from fully automated to multilayer attacks. Vulnerabilities in a system are exploited by an intelligent attacker to facilitate to do anything from denial of service (DoS) attacks to the system takeover. This paper addresses the development of an architecture that includes the use of fault tolerance and honeypot technology to provide layered protection to avoid a single point of failure.	data mining;denial-of-service attack;fault tolerance;hash function;hash table;honeypot (computing);intelligent agent;knowledge base;malware;reliability engineering;single point of failure;supervised learning;system administrator	Lokesh D. Pathak;Ben Soh	2006		10.1007/11833529_84	fault tolerance;telecommunications;computer science;network security;world wide web;computer security;ubiquitous computing;information extraction;denial-of-service attack	Security	-63.639648110735365	69.91329549111965	138480
0b4cc0d1c59381eae66120508afdba9edf05d667	a pointillist approach for comparing honeypots	distributed system;intruder detector;long period;systeme reparti;analisis estadistico;communication systems;packet loss;localization;securite informatique;research center;error sistematico;mesure niveau;localizacion;vulnerability;attaque informatique;classification;perdida transmision;ecole d ingenieur;perte transmission;computer security;vulnerabilite;vulnerabilidad;sistema repartido;localisation;internet;statistical analysis;monitoring;bias;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;seguridad informatica;telecommunication;analyse statistique;level measurement;intrusion detection systems;eurecom;transmission loss;computer attack;ataque informatica;monitorage;detecteur intrus;delinquency;graduate school;monitoreo;detector intruso;delinquance;clasificacion;systeme detection intrusion;erreur systematique;centre de recherche;medicion nivel;delincuencia	The concept of electronic decoys (honeypots), which are network resources that are deployed to be probed, attacked, and eventually compromised, is used in the area of IT security to learn more about attack patterns and attackers’ behavior in real-world networks. Our research focuses on gathering detailed statistics on the threats over a long period of time in order to get a better understanding of their characteristics. In this perspective, we are deploying honeypots of different interaction levels in various locations. At a first glance, these honeypots can be considered as permanent sensors that gather statistical information on a long-term perspective. Generally speaking, honeypots are often classified by their level of interaction. For instance, it is admitted that a high interaction approach is suited for recording hacker shell commands, while a low interaction approach provides limited information on the attackers’ activities. So far, there exists no serious comparison to express the level of information on which both approaches differ. Thanks to the environment that we are deploying, we are able to provide a rigorous comparison between the two approaches, both qualitatively and quantitatively. The proposed analysis leads to an interesting study of malicious activities hidden by the noise of less interesting ones. Furthermore, it shows the complementarities of the two approaches: a high interaction honeypot allows controlling the relevance of low interaction honeypot configurations. Thus, both interaction levels are required to build an efficient network of distributed honeypots.	attack patterns;honeypot (computing);image noise;network packet;relevance;sensor;software deployment;threat (computer)	Fabien Pouget;Thorsten Holz	2005		10.1007/11506881_4	intrusion detection system;juvenile delinquency;the internet;internationalization and localization;telecommunications;biological classification;vulnerability;computer science;bias;packet loss;computer security;communications system	Web+IR	-63.08333071496912	69.73475252564039	139117
a48d1f53c55e6e5dd415c6f9f610ffa3a13699c5	effective metric for detecting distributed denial-of-service attacks based on information divergence	distributed system;faux positif;systeme reparti;entropia;deteccion optimal;loi probabilite;securite telecommunication;attacks detection;ley probabilidad;probability distributions;kullback leibler divergence;metric;legitimate flows;probabilistic approach;flujo informacion;falso positivo;information divergence;flux information;relative entropy;renyi theory;information flow;sistema repartido;teoria renyi;enfoque probabilista;approche probabiliste;optimal information distance distributed denial of service attacks information divergence relative entropy probability distributions renyi divergence kullback leibler divergence legitimate flows attack flows optimal detection sensitivity;probability distribution;entropie;denial of service;distributed denial of service;telecommunication security;distributed denial of service attacks;metrico;entropy;theorie renyi;detection optimale;optimal detection;theorie information;optimal detection sensitivity;false positive;distributed denial of service attacks ddos;security of data;attack flows;metrique;information theory;optimal information distance;denegacion de servicio;deni service;renyi divergence;teoria informacion	In information theory, the relative entropy (or information divergence or information distance) quantifies the difference between information flows with various probability distributions. In this study, the authors first resolve the asymmetric property of Re´nyi divergence and Kullback-Leibler divergence and convert the divergence measures into proper metrics. Then the authors propose an effective metric to detect distributed denial-of-service attacks effectively using the Re´nyi divergence to measure the difference between legitimate flows and attack flows in a network. With the proposed metric, the authors can obtain the optimal detection sensitivity and the optimal information distance between attack flows and legitimate flows by adjusting the order's value of the Re´nyi divergence. The experimental results show that the proposed metric can clearly enlarge the adjudication distance, therefore it not only can detect attacks early but also can reduce the false positive rate sharply compared with the use of the traditional Kullback-Leibler divergence and distance approaches.	denial-of-service attack;sensor	Ke Li;Wanlei Zhou;Shui Yu	2009	IET Communications	10.1049/iet-com.2008.0586	probability distribution;entropy;information theory;theoretical computer science;mathematics;kullback–leibler divergence;divergence;computer security;denial-of-service attack;statistics	Mobile	-63.12585361362745	69.81645363230628	139367
f310eda342ecb1e61409fd4dcd406acd3560193c	using network fault predictions to enable ip traffic management	network health;change detection;spatial correlator;network performance;traffic management;spatial correlation;protocol implementation;majority voting;fault model;production network	IP traffic management is important for the continued growth of the Internet. Several traffic management algorithms exist today. However, to enable these algorithms it is necessary to provide reliable alarms relating to network performance bottlenecks and failures. In this work we propose an algorithm to obtain reliable predictive alarms for network fault conditions. The algorithm is based on modeling network fault behavior. The algorithm has been successfully tested on two production networks. Predictive alarms were obtained for four different types of failures: file server failures, network access problems, protocol implementation errors, and runaway processes. The potential of using this model to do fault classification is also discussed. In addition, it is shown that the proposed algorithm performs better than the majority-vote scheme.	access network;algorithm;bottleneck (software);characteristic function (convex analysis);discriminant;file server;fingerprint;internet;mebibyte;network performance;process (computing);server (computing);testbed	Marina Thottan	2001	Journal of Network and Systems Management	10.1023/A:1011381512107	traffic generation model;majority rule;active traffic management;spatial correlation;network traffic control;real-time computing;network management station;computer science;fault model;network simulation;network performance;computer security;change detection;computer network	Metrics	-63.08231033473999	67.65844271388153	140853
8881ded676c05a77c41e2ea9437f55287d703065	the internet traffic classification an online svm approach	support vector machines;bayes methods;naive bayes;security monitoring;entry data sets internet traffic classification online svm approach quality of service security monitoring network management internet traffic identification naive bayes kernel estimation auckland vi;support vector machines support vector machine classification telecommunication traffic kernel testing ip networks web and internet services quality of service data security monitoring;telecommunication traffic bayes methods computer network management internet pattern classification quality of service support vector machines telecommunication security;naive bayes kernel estimation;telecommunication traffic;internet traffic;internet;online svm approach;auckland vi;computer network management;telecommunication security;pattern classification;network management;quality of service;internet traffic classification;internet traffic identification;kernel estimate;entry data sets	Accurate and quick classification of Internet traffic is of fundamental importance to numerous network activities, such as quality of service, security monitoring and network management. So accurate, quick, effective classification is necessary. In this paper, we apply online SVM technique for Internet traffic identification and compare the result with that of previously applied naive Bayes kernel estimation in AUCKLAND Vi and Entry data sets. Our results show that online SVM technique is more robust and accurate than naive Bayes algorithm. The test error can be limited to 5.81% in Entry data sets. For AUCKLAND Vi data sets, the test error can be limited to 14.05% and greatly outperforms naive Bayes kernel estimation.	computational problem;internet;naive bayes classifier;network packet;online algorithm;quality of service;real-time computing;relay;sparse matrix;support vector machine;traffic classification	Yuhai Liu;Hongbo Liu;Hong-Yu Zhang;Xin Luan	2008	2008 International Conference on Information Networking	10.1109/ICOIN.2008.4472820	network management;support vector machine;the internet;naive bayes classifier;internet traffic;quality of service;computer science;machine learning;data mining;computer security;computer network	Metrics	-63.35385594611668	66.47654607243403	141843
0ea0389898ad7d184fdeee6a110b52b6a41f1661	prospect theoretic study of cloud storage defense against advanced persistent threats	electronic mail;game theory;pricing;simulation;games;cloud computing	Cloud storage is vulnerable to Advanced Persistent Threats (APTs), which are stealthy, continuous, well funded and targeted. In this paper, prospect theory is applied to study the interactions between a subjective cloud storage defender and a subjective APT attacker. Two subjective APT games are formulated, in which the defender chooses its interval to scan the storage device and the attacker decides its duration between launching two attacks under uncertain APT attack durations and action of the opponent, respectively. The Nash equilibria of the static subjective APT games are derived. We also study the dynamic APT game and propose a Q-learning based APT defense strategy for cloud storage. Simulation results show that the APT defense benefits from the subjective view of the attacker and the proposed defense strategy can improve detection performance with a higher utility.	attack rate;benchmark (computing);cloud storage;interaction;nash equilibrium;q-learning;simulation;theory	Dongjin Xu;Yanda Li;Liang Xiao;Narayan B. Mandayam;H. Vincent Poor	2016	2016 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2016.7842178	pricing;games;game theory;simulation;cloud computing;computer science;internet privacy;computer security	EDA	-64.57069618430694	61.4040331542207	145389
eeac1de36811ba4217303c2e88577b7d1a666a92	the multi-fractal nature of worm and normal traffic at individual source level	modelizacion;fractals;red www;securite informatique;reseau web;intelligence artificielle;computer security;modelisation;internet;seguridad informatica;fractal;fractale;artificial intelligence;world wide web;inteligencia artificial;modeling	Worms have been becoming a serious threat in web age because worms can cause huge loss due to the fast-spread property. To detect worms effectively, it is important to investigate the characteristics of worm traffic at individual source level. We model worm traffic with the multi-fractal process, and compare the multi-fractal property of worm and normal traffics at individual source level. The results show that the worm traffic possesses less multi-fractal property.	fractal	Yufeng Chen;Yabo Dong;Dongming Lu;Yunhe Pan	2005		10.1007/11427995_50	simulation;fractal;telecommunications;computer science;artificial intelligence;computer security	Metrics	-63.27339250103891	70.654358630156	146440
19071a8dab567758045e996ef8f9211ddff237b3	big data analysis-based security situational awareness for smart grid	association analysis smart grid security situation assessment big data game theory;security smart grids games big data communication networks game theory	Advanced communications and data processing technologies bring great benefits to the smart grid. However, cyber-security threats also extend from the information system to the smart grid. The existing security works for smart grid focus on traditional protection and detection methods. However, a lot of threats occur in a very short time and overlooked by exiting security components. These threats usually have huge impacts on smart gird and disturb its normal operation. Moreover, it is too late to take action to defend against the threats once they are detected, and damages could be difficult to repair. To address this issue, this paper proposes a security situational awareness mechanism based on the analysis of big data in the smart grid. Fuzzy cluster based analytical method, game theory and reinforcement learning are integrated seamlessly to perform the security situational analysis for the smart grid. The simulation and experimental results show the advantages of our scheme in terms of high efficiency and low error rate for security situational awareness.	big data;computer security;game theory;information system;network security;reinforcement learning;simulation;threat (computer)	Kaoru Ota;Mianxiong Dong;Jianhua Li;Hongkai Wang	2018	IEEE Transactions on Big Data	10.1109/TBDATA.2016.2616146	telecommunications network;situation analysis;game theory;big data;computer science;reinforcement learning;information system;smart grid;situation awareness;computer security	AI	-63.62238452804879	63.854390068146586	151489
07bfb8ae148d5deb681df27f5f0a7de1eb91fb4a	on the design and use of internet sinks for network abuse monitoring	estensibilidad;internet protocol;intruder detector;methode empirique;protocolo internet;surveillance;metodo empirico;securite informatique;empirical method;protocole internet;telescopio;intrusion detection;elemento arquitectural;element architectural;network intrusion detection;computer security;vigilancia;internet;monitoring;telescope;seguridad informatica;intrusion detection systems;design feature;laboratory experiment;extensibilite;scalability;monitorage;detecteur intrus;monitoreo;detector intruso;systeme detection intrusion	Monitoring unusedor dark IP addresses offers opportunities to significantly improve and expand knowledge of abuse activity wi thout many of the problems associated with typical network intrusion detect ion and firewall systems. In this paper, we address the problem of designing and d eploying a system for monitoring large unused address spaces such as class A te lescopes with 16M IP addresses. We describe the architecture and implementat ion of the Internet Sink (iSink) system which measures packet traffic on unused I P addresses in an efficient, extensible and scalable fashion. In contrast to t raditional intrusion detection systems or firewalls, iSink includes an ctivecomponent that generates response packets to incoming traffic. This gives the iSink an important advantage in discriminating between different types of attacks ( through examination of the response payloads). The key feature of iSink’s design that distinguishes it from other unused address space monitors is that its active r esponse component is statelessand thus highly scalable. We report performance results of o ur iSink implementation in both controlled laboratory experiments and from a case study of a live deployment. Our results demonstrate the efficiency and scalability of our implementation as well as the important perspective on a buse activity that is afforded by its use.	address space;classful network;commodity computing;computer monitor;computer security;dce/rpc;data mining;experiment;fingerprint (computing);firewall (computing);internet background noise;intrusion detection system;jensen's inequality;monit;network packet;network security;network traffic control;router (computing);sampling (signal processing);scalability;semantic network;software deployment;vern paxson;web server;whole earth 'lectronic link	Vinod Yegneswaran;Paul Barford;David Plonka	2004		10.1007/978-3-540-30143-1_8	intrusion detection system;embedded system;telecommunications;computer science;operating system;database;distributed computing;computer security	Security	-62.9918386946506	69.23142535567501	152857
00853b4f3122bff8e8166534c1a09669654539de	selection of intrusion detection system threshold bounds for effective sensor fusion	teletrafic;faux positif;intruder detector;theoretical model;multisensor;sistema experto;sensors;polinomio chebychev;rule based;computer intrusion detection;supercomputer education research centre;fusion capteur;data fusion;chebyshev polynomial;falso positivo;polynome tchebychev;refinement method;sensor performance;teletrafico;design technique;evaluation metric;a priori knowledge;false positive rate;fusion donnee;detection rate;teletraffic;present day;systeme expert;sensor fusion;methode raffinement;false positive;detecteur intrus;fusion datos;detector intruso;metodo afinamiento;empirical evaluation;capteur multiple;intrusion detection system;expert system	The motivation behind the fusion of Intrusion Detection Systems was the realization that with the increasing traffic and increasing complexity of attacks, none of the present day stand-alone Intrusion Detection Systems can meet the high demand for a very high detection rate and an extremely low false positive rate. Multi-sensor fusion can be used to meet these requirements by a refinement of the combined response of different Intrusion Detection Systems. In this paper, we show the design technique of sensor fusion to best utilize the useful response from multiple sensors by an appropriate adjustment of the fusion threshold. The threshold is generally chosen according to the past experiences or by an expert system. In this paper, we show that the choice of the threshold bounds according to the Chebyshev inequality principle performs better. This approach also helps to solve the problem of scalability and has the advantage of failsafe capability. This paper theoretically models the fusion of Intrusion Detection Systems for the purpose of proving the improvement in performance, supplemented with the empirical evaluation. The combination of complementary sensors is shown to detect more attacks than the individual components. Since the individual sensors chosen detect sufficiently different attacks, their result can be merged for improved performance. The combination is done in different ways like (i) taking all the alarms from each system and avoiding duplications, (ii) taking alarms from each system by fixing threshold bounds, and (iii) rule-based fusion with a priori knowledge of the individual sensor performance. A number of evaluation metrics are used, and the results indicate that there is an overall enhancement in the performance of the combined detector using sensor fusion incorporating the threshold bounds and significantly better performance using simple rule-based fusion.	intrusion detection system	Ciza Thomas;N. Balakrishnan	2007		10.1117/12.719295	simulation;telecommunications;artificial intelligence;sensor fusion;computer security;expert system	Mobile	-64.00250567921806	69.62847469292255	153689
fc3bff3e90fab0f8e2ffb16211e00e9285bef4b8	two stochastic models for security evaluation based on attack graph	graph theory;middle level attack graph;security evaluation;network design;enterprise networks;markov decision process stochastic model security evaluation multiple prerequisite attack graph large scale enterprise network middle level attack graph;markov decision process stochastic model attack graph security evaluation;security of data decision theory graph theory markov processes;large scale enterprise network;large scale;computational modeling;monitoring;stochastic processes;decision theory;multiple prerequisite attack graph;security metric;stochastic processes information security large scale systems computer networks computer security interference humans power generation forward contracts game theory;book reviews;markov processes;stochastic model;markov decision process;security;attack graph;security of data;shortest path problem	Multiple-prerequisite graph (MP graph) is a type of attack graph that has been developed to help defending large scale enterprise network. As a middle-level attack graph, it has its unique advantages. However, quantitative security evaluations based on MP graph has not been proposed yet. In this paper, we present two stochastic models for quantitative security evaluation using MP graphs. These models are constructed based on the use of Markov Decision Process to model the attackerpsilas behaviors. The network administrators can use these two models respectively to evaluate security metrics at network designing stage and network defending stage.	algorithm;criticality matrix;markov chain;markov decision process;mathematical optimization;network security;scalability;shortest path problem;stochastic process	Yinqian Zhang;Xun Fan;Zhi Xue;Hao Xu	2008	2008 The 9th International Conference for Young Computer Scientists	10.1109/ICYCS.2008.406	markov decision process;network planning and design;decision theory;computer science;information security;connectivity;stochastic modelling;graph theory;theoretical computer science;machine learning;data mining;moral graph;markov process;shortest path problem;computational model;computer security;statistics	Security	-63.3841232501851	60.54532378075571	154783
1caf95c76f5ce8891e2ea89551e73b4fbd69dac3	online traffic classification based on co-training method	classification algorithms feature extraction training accuracy supervised learning jitter monitoring;telecommunication traffic learning artificial intelligence pattern classification telecommunication computing telecommunication network management telecommunication security;telecommunication computing;telecommunication traffic;traffic classification;telecommunication security;pattern classification;co training traffic classification subnet;co training;learning artificial intelligence;subnet;netipt online traffic classification cotraining method service measurements network management security monitoring machine learning techniques labeled training samples semisupervised learning method unlabeled samples packet size network jitter robust interpacket time feature;telecommunication network management	"""Online traffic classification has been widely used in quality of service measurements, network management and security monitoring. Currently, more and more research works tend to apply machine learning techniques to online traffic classification, and most of them are based on supervised learning and unsupervised learning techniques. Although supervised learning method has exhibited good classification performance, it needs lots of labeled training samples which are difficult to collect. The co-training method is a semi-supervised learning method, which can use little labeled samples and plenty of unlabeled samples to enhance the performance of supervised learning method. In this paper, we investigate the co-training algorithm for online traffic classification. The co-training algorithm needs two separate features which are sufficient to train a good classifier. We choose packet size and inter-packet time of the first packets of a traffic flow as two features. However, the inter-packet time is dependent to network conditions and will be impacted by network jitter. This paper constructs a robust inter-packet time feature named """"Netipt"""" which is resilient to network jitter, and we integrate Netipt feature to co-training algorithm. We test our co-training algorithm based on two real-world traffic datasets. The results show that the co-training algorithm can enhance the accuracy of traffic classification drastically even when there are very few training samples."""	algorithm;co-training;machine learning;network packet;quality of service;semi-supervised learning;semiconductor industry;subnetwork;supervised learning;teaching method;traffic classification;unsupervised learning	Jinghua Yan;Xiao-chun Yun;Zhi-Gang Wu;Hao Luo;Shuzhuang Zhang;Shuyuan Jin;Zhibin Zhang	2012	2012 13th International Conference on Parallel and Distributed Computing, Applications and Technologies	10.1109/PDCAT.2012.105	semi-supervised learning;unsupervised learning;traffic classification;subnet;computer science;machine learning;linear classifier;pattern recognition;data mining;computer security;one-class classification;computer network	Metrics	-63.402194130997664	66.43183144653717	156965
1916c046e89efbbc7d6dbb8b70b6b0f37120ec0a	balancing safety against performance: tradeoffs in internet security	electronic commerce internet telecommunication security security of data monitoring;electronic commerce;internet access;e commerce;real time;costs and benefits;control system;it security;internet;monitoring;continuous optimization;safety internet monitoring information security power system security real time systems face detection costs bandwidth licenses;telecommunication security;cooperative intelligent real time control architecture for dynamic information assurance internet security internet accessible computing systems script kiddies sophisticated criminal enterprises intrusion monitoring computing power storage space licensing fees e commerce server throughput costs modeling security monitoring response actions stochastic expectations clrcadla automatic security control system real time tradeoffs system resources system performance e commerce transactions security activity threat profiles security maintaining activity risk reduction cooperative intelligent architecture;internet security;security of data	All Internet-accessible computing systems are currently faced with incessant threats ranging from simple scriptkiddies to highly sophisticated criminal enterprises. In r esponse to these threats, sites must perform extensive intru sion monitoring. This intrusion monitoring can have signif icant costs in terms of bandwidth, computing power, storage space, and licensing fees. Furthermore, when exploits are detected, the victims must take actions that can consume further resources and compromise their objectives (e.g., b y reducing e-commerce server throughput). In this paper, we explore techniques for modeling the costs and benefits of various security monitoring and response actions. Given these models and stochastic expectations about the types of attacks that a site is likely to face, our CIRCADIA automatic security control system is able to make real-time tradeoffs between the level of safety and security that is en forced, and the level of system resources/performance that are applied to the main computational objectives (e.g., ecommerce transactions). We show how CIRCADIA is able to dynamically adjust its security activities to account fo r changing threat profiles and objectives. The result: a continually-optimized balance of security-maintaining a ctivity that reduces risk while still allowing the system to meet its goals.	computation;computer accessibility;control system;e-commerce;internet security;real-time transcription;server (computing);sion's minimax theorem;throughput	Vu A. Ha;David J. Musliner	2003		10.1109/HICSS.2003.1174465	e-commerce;real-time computing;the internet;internet access;computer science;cost–benefit analysis;marketing;operating system;database;internet privacy;world wide web;computer security	Security	-64.51959988490783	61.6588368583726	157499
f203f065cfccad985c90239f7ffe631a8e19941c	design and implementation of security system based on immune system	concurrent logic programming;agent based;network security;design and implementation;immune system;secure system	We design a network security system using an analogy of natural world immunology. We adopt an immune mechanism that distinguishes self or non-self and cooperation among immune cells of the system. This system implements each immune cell as an agent based on our multiagent language, which is an extension of concurrent logic programming languages. These agents can detect and reject intrusion by cooperating with each other.	agent-based model;concurrent logic programming;network security;programming language	Hiroyuki Nishiyama;Fumio Mizoguchi	2002		10.1007/3-540-36532-X_15	real-time computing;computer science;distributed computing;computer security	AI	-65.18651960579786	63.286553961403996	165365
f996a3455020b9d75a5fc36e1fa855ef4efa8bd1	nonlinear dynamics of traffic jams	network monitoring network security situation awareness heterogeneous multisensor data fusion security analysis snort netflow network traffic multilayer feedforward neural network multiclass problem feature reduction fusion engine;security analysis;feed forward neural network;fusion engine;network monitoring;network security;real time;netflow;multilayer feedforward neural network;computer networks;multi sensor data fusion;snort;telecommunication traffic;feature reduction;network traffic;data security neural networks telecommunication traffic traffic control sensor fusion sensor phenomena and characterization feedforward systems multi layer neural network feedforward neural networks engines;telecommunication security;situation awareness;heterogeneous multisensor data fusion;feedforward neural nets;sensor fusion;multiclass problem;network security situation awareness;security of data;telecommunication traffic computer networks feedforward neural nets security of data sensor fusion telecommunication security;neural network	We review current progress and challenges in modeling of nonlinear phenomena in traffic flow. We are particularly interested in the nonlinear dynamics of traffic jams: the transition to instabilities of traffic flow, the formation of traffic jams and the evolution of the traffic jams. A discrete dynamic system approach is proposed. The self- organized oscillatory behavior and chaotic behavior in traffic are identified and formulated. The results can help to explain the appearance of a phantom traffic jam observed in real traffic. It is also proved that coarser resolution results in richer dynamics of the traffic flow including traffic jams. This is exactly what the numerical simulations showed. It is clear that the spatial and temporal resolution affects traffic variable and assumptions in a considerable way. Continuum models run into the limits of describing discrete phenomena in a continuous way. Therefore a combination of continuum and discrete descriptions will be necessary to further improve and declare specific traffic phenomena.	apache continuum;chaos theory;dynamical system;imaging phantom;jam;nonlinear dynamics;numerical analysis;simulation;triune continuum paradigm	Tong Li	2007	Second International Multi-Symposiums on Computer and Computational Sciences (IMSCCS 2007)	10.1109/IMSCCS.2007.60	engineering;data mining;network simulation;computer security;computer network	Networks	-63.717005996679625	65.12261502087746	166193
d739066c5b9c15832456183d97e9c7a34ea5290c	an automatic and generic early-bird system for internet backbone based on traffic anomaly detection	anomaly;distributed system;correlacion;eje troncal;systeme reparti;ddos attack;analisis estadistico;protocole transmission;securite;anomaly detection;real time;real time traffic;probabilistic approach;anomalie;protocole tcp;transmission control protocol;reseau federateur;anomalia;protocolo transmision;sistema repartido;internet;statistical analysis;protocolo tcp;enfoque probabilista;approche probabiliste;temps reel;safety;analyse statistique;tiempo real;correlation;backbone;internet security;seguridad;alert correlation;dos attack;transmission protocol	Worm and Dos, DDos attacks take place more and more frequently nowadays. It makes the internet security facing serious threat. In this paper, we introduced the algorithm and design of ESTABD, an internet backbone Early-bird System of Traffic Anomaly Detection Based. By observing the raw variables such as packets count of protocol, TCP flags and payload length distribution etc., ESTABD analyzes real-time traffic to discover the abrupt traffic anomalous and generate warnings. A traffic anomaly detection algorithm based on Statistic Prediction theory is put forward and the algorithm has been tested on real network data. Further more, Alerts correlation algorithm and system policy are addressed in this paper to detect the known worms& Dos attacks and potentially unknown threats.	anomaly detection;internet backbone	RongJie Gu;Puliu Yan;Tao Zou;Chengcheng Guo	2005		10.1007/978-3-540-31956-6_87	anomaly detection;telecommunications;computer science;internet security;computer security;denial-of-service attack	Security	-62.894114548058035	69.50987802585381	167501
dc0960c5ff4c0c6fb988182dd22d1be62c41de9e	intrusion detection effectiveness improvement by a multiagent system		Recent studies about Intrusion Detection Systems (IDS) performance reveal that the value of an IDS and its optimal operation point depend not only on the Hit and False alarm rates but also on costs (such as those associated with making incorrect decisions about detection) and the hostility of the operating environment. An adaptive multiagent IDS is proposed in this paper and it is evaluated according to a promising metric that take into account all these parameters. This paper shows results of a prototype that clearly point out how multiagent technology can improve IDS effectiveness.	adaptive behavior;agent-based model;interpreter (computing);intrusion detection system;multi-agent system;operating environment;prototype;robustness (computer science);synthetic data	Agustín Orfila;Javier Ignacio Carbó Rubiera;Arturo Ribagorda	2005	IJCSA		data mining;false alarm;operating environment;intrusion detection system;constant false alarm rate;computer science;intrusion prevention system	AI	-63.839282231885626	63.95280649008417	169635
32075ab45e58a494e29da2c4ed4c0e039ae6452b	smart architecture for high-speed intrusion detection and prevention systems	distributed system;systeme reparti;systeme protection;securite informatique;prevention systems;intrusion detection;packet switching;conmutacion por paquete;feasibility;computer security;sistema repartido;grande vitesse;criptografia;pattern matching;cryptography;seguridad informatica;intrusion detection systems;pattern classification;protection system;cryptographie;gran velocidad;concordance forme;sistema proteccion;architecture;high speed;commutation paquet;practicabilidad;systeme detection intrusion;faisabilite;classification forme	The overall performance of an intrusion protection system depends not only on the packet header classification and pattern matching, but also on the post-operative determination of correlative patterns of matched rules. An increasing number of patterns associated with a rule heighten the importance of correlative pattern matching. This work proposes a TCAM-based smart architecture that supports both deep pattern-matching and correlative pattern-matching. The proposed architecture overcomes the difficulties in implementing TCAM when the patterns are very deep and the rules for packet payload involve many patterns whose positions lie within a range. A real case payload is simulated using a Snort 2.3 rule set and simulation results demonstrate the feasibility of the proposed architecture in supporting a high-speed and robust intrusion detection and prevention system.		Chih-Chiang Wu;Sung-Hua Wen;Nen-Fu Huang	2006		10.1007/11935070_22	intrusion detection system;embedded system;feasibility study;telecommunications;computer science;computer security	Arch	-63.567058517732725	69.80900470102405	175705
5a6475e3b9508472d7d88d1d55d2ed88e0a9e933	llsim: network simulation for correlation and response testing	network simulation;sensor systems;pc workstation;automatic testing;traffic control;java based event driven simulator;datasets;telecommunication computing;intrusion detection;intrusion detection sensors;response systems;network simulator;computer networks;arbitrary networks;configurable network simulator;virtual machines;llsim;network firewall policies;research evaluation;response testing;workstations;darpa cyber panel program llsim network simulation correlation testing response testing configurable network simulator data sets general purpose correlation systems response systems java based event driven simulator user configurable core models event generators pc workstation arbitrary networks communication links intrusion detection sensors simple response actions network firewall policies datasets;simple response actions;force measurement;system testing;communication links;general purpose correlation systems;user configurable core models;system testing intrusion detection automatic testing force measurement laboratories java discrete event simulation workstations sensor systems traffic control;event generators;data sets;darpa cyber panel program;security of data;correlation testing;digital simulation;telecommunication computing digital simulation computer networks virtual machines java security of data;java;discrete event simulation	LLSIM is an easily configurable network simulator that can produce a wide variety of data sets without expensive testbeds. These data sets are useful for researchers who are developing general-purpose correlation and response systems. LLSim is a Java-based event-driven simulator consisting of user-configurable core models of networks and hosts with network and host events. Several event generators and models of several intrusion detection sensors were developed On a typical PC workstation, LLSim can emulate arbitrary networks with hundreds of nodes and communication links, and can accurately simulate hundreds of intrusion detection sensors operating in these environments. It can also help researchers evaluate the effectiveness of simple response actions such as altering network firewall policies in response to an attack LLSim has been used to produce datasets used in the DARPA Cyber Panel program.	simulation	Joshua W. Haines;Stephen A. Goulet;Robert S. Durst;Terrance G. Champion	2003		10.1109/DISCEX.2003.1194965	embedded system;real-time computing;computer science;distributed computing	ECom	-65.70354796171446	65.2623061574846	176722
c73d4cc2c7b0c2b08f8708b0a69ad64c996aae1f	intrusion detection system for securing geographical information system web servers	distributed system;intruder detector;modelo markov oculto;systeme reparti;systeme information geographique;red www;geographic information system;modelo markov;modele markov cache;hidden markov model;securite informatique;reseau web;intrusion detection;computer security;markov model;sistema repartido;internet;seguridad informatica;intrusion detection systems;pattern recognition;world wide web;reconnaissance forme;modele markov;reconocimiento patron;detecteur intrus;detector intruso;systeme detection intrusion;sistema informacion geografica;intrusion detection system	Web servers which provide Geographical Information System (GIS) services are very vulnerable against attacks exploiting web-based programming errors. A traditional Intrusion Detection System (IDS), however, has limitations to detect web-based attacks because they usually use signature-based IDS. Therefore, we propose IDS based on Hidden Markov Model (HMM) for securing GIS web servers. We adopt HMM which has been achieved good performance in pattern recognition and intrusion detection. We demonstrate effectiveness and efficiency of our proposed system by carrying out several experiments.		Jong Sou Park;Hong Tae Jin;Dong Seong Kim	2004		10.1007/11427865_9	anomaly-based intrusion detection system;intrusion detection system;telecommunications;computer science;geographic information system;world wide web;computer security;hidden markov model	DB	-63.62597658522953	69.9565876820376	177116
79d15c84f4955df0c9b53a8b3404dd43b69c7533	data mining framework for random access failure detection in lte networks	eigenvalues and eigenfunctions;telecommunication network reliability data mining long term evolution telecommunication computing;software;histograms;degradation;detection algorithms;eigenvalues and eigenfunctions training data mining histograms detection algorithms degradation software;training;network reliability data mining framework random access channel failure detection lte networks sleeping cell problem cell degradation cell outage rach failure detection software firmware problem base station bs user equipment ue n gram feature selection algorithm computational efficiency heuristic performance metric sleeping cell detection framework dynamic lte system simulator long term evolution minimization of drive testing functionality mdt functionality 1 gram algorithm;data mining	Sleeping cell problem is a particular type of cell degradation. There are various software and hardware reasons that might cause such kind of cell outage. In this study a cell becomes sleeping because of Random Access Channel (RACH) failure. This kind of network problem can appear due to misconfiguration, excessive load or software/firmware problem at the Base Station (BS). In practice such failure might cause network performance degradation, which is hardly traceable by an operator. In this paper we present a data mining based framework for the detection of problematic cells. In its core is the analysis of event sequences reported by a User Equipment (UE) to a serving BS. The choice of N in N-gram feature selection algorithm is considered, because of its significant impact on computational efficiency. Moreover, qualitative and heuristic performance metrics have been developed to assess the performance of the proposed detection algorithm. Sleeping cell detection framework is verified by means of dynamic LTE (Long-Term Evolution) system simulator, using Minimization of Drive Testing (MDT) functionality. It is shown that sleeping cell can be determined with very high reliability even using 1-gram algorithm.	access network;anomaly detection;compaq lte;computation;data mining;dimensionality reduction;downtime;elegant degradation;feature selection;firmware;heuristic;k-nearest neighbors algorithm;n-gram;network performance;random access;selection algorithm;simulation;traceability	Sergey Chernov;Fedor Chernogorov;Dmitry Petrov;Tapani Ristaniemi	2014	2014 IEEE 25th Annual International Symposium on Personal, Indoor, and Mobile Radio Communication (PIMRC)	10.1109/PIMRC.2014.7136373	real-time computing;degradation;telecommunications;theoretical computer science;operating system;data mining;histogram;computer network	Arch	-64.41152897022988	64.25896253573634	177204
69c627243edd6f4b33677261ef919fcfe4f222c4	a dynamic online traffic classification methodology based on data stream mining	protocols;concept drift;data stream;real time;dynamic real time network traffic;data mining;data stream based traffic classification;accuracy;data mining telecommunication traffic traffic control communication system traffic control streaming media laboratories machine learning statistics computer science data engineering;telecommunication traffic;internet;machine learning;telecommunication traffic computer network management data mining internet learning artificial intelligence pattern classification;network traffic;dynamic online traffic classification methodology;heuristic algorithms;data stream mining;computer network management;traffic classification;classification algorithms;data stream based traffic classification dynamic online traffic classification methodology data stream mining network management machine learning dynamic real time network traffic;pattern classification;time use;network management;user behavior;learning artificial intelligence;classification accuracy;algorithm design and analysis;data models	Recently, traffic classification (TC) becomes more and more important for network management and measurement tasks. The new-coming machine learning based classification methods can achieve high classification accuracy and fast identification ability; however, all these related TC methods up to now always have the assumption of the stability of classification model constituted from network traffic. It is not true since seldom real-world traffic is static. In this paper, we make a first step towards classifying dynamic online traffic in a data stream perspective to handle the dynamic real-time network traffic. In this paper, we validate the dynamic feature of real-world traffic for the first time, using concept drift from two different levels: overall traffic level and application level. The conclusion convinces us that the user behavior reflected in traffic can vary dramatically due to different conditions and different periods. We then propose a novel integrated dynamic online traffic classification framework; called DSTC (Data Stream based Traffic Classification). This DSTC differs from previous work since it aims to deal with dynamic traffic with online identification ability. It is a more realistic framework in which training phase can go simultaneously with classification phase and more accurate training model can be constructed with the feedback from classification result. Experiment results have shown that DSTC can have a high stable classification accuracy of above 95% for network traffic with different periods and user conditions, while accuracy for the traditional classification methodology can vary from 81% to 97% when dealing with different traffic.	concept drift;data stream mining;machine learning;network packet;network traffic control;real-time clock;real-time computing;traffic classification	Xu Tian;Qiong Sun;Xiaohong Huang;Yan Ma	2009	2009 WRI World Congress on Computer Science and Information Engineering	10.1109/CSIE.2009.904	traffic generation model;network management;data modeling;communications protocol;algorithm design;the internet;traffic classification;computer science;concept drift;machine learning;data mining;database;accuracy and precision;data stream mining;world wide web	ML	-63.55767016414599	66.36632659602598	178343
2d5f4e953b7dbbef60c8ad786c05ea01294d321c	using neural networks to classify internet users	access network;neural networks;neural nets;internet traffic characterization;neural networks ip networks telecommunication traffic artificial neural networks electronic mail traffic control performance analysis internet mathematics reliability engineering;neural networks internet traffic characterization traffic measurements cluster analysis;telecommunication traffic;cluster analysis;internet traffic;internet;statistical analysis;portuguese isp neural network training internet user classification traffic engineering network management artificial neural network models hourly traffic profile performance evaluation cluster analysis access network;computer network management;statistical analysis internet telecommunication traffic neural nets learning artificial intelligence computer network management;network management;traffic engineered;traffic measurements;learning artificial intelligence;artificial neural network;neural network;traffic measurement	Traffic engineering and network management can greatly benefit from a reliable classification of Internet users. This paper evaluates the potential of different artificial neural network models for classifying Internet users based on their hourly traffic profile. The training of the neural networks and the evaluation of their performance rely on a previous classification of the Internet users obtained through cluster analysis. The results obtained for two data sets measured at the access network of a Portuguese ISP indicate that neural networks constitute a valuable tool for classifying Internet users.	access network;backpropagation;cluster analysis;internet;learning vector quantization;neural networks;programming paradigm;randomness;software propagation;supervised learning	António Nogueira;Maria Rosário de Oliveira;Paulo Salvador;Rui Valadas;Antonio Luiz Schalata Pacheco	2005	Advanced Industrial Conference on Telecommunications/Service Assurance with Partial and Intermittent Resources Conference/E-Learning on Telecommunications Workshop (AICT/SAPIR/ELETE'05)	10.1109/AICT.2005.93	network management;the internet;internet traffic;computer science;machine learning;data mining;cluster analysis;computer security;artificial neural network;computer network;access network	ML	-63.59313283754731	66.60997355809803	180098
6fa32890a3cdea82ca817106c0dcd5e5139d1554	an internet traffic classification methodology based on statistical discriminators	statistical discriminators traffic classification traffic identification;p2p traffic class;pattern clustering;traffic identification;telecommunication traffic computer network management internet pattern classification pattern clustering peer to peer computing quality of service security of data statistical analysis telecommunication congestion control;telecommunication congestion control;traffic control;p2p;telecommunication traffic;cluster analysis;internet traffic;internet;statistical analysis;statistical discrimination;computer network management;traffic classification;training phases;pattern classification;network management;internet application;statistical discriminators;peer to peer computing;quality of service;internet traffic classification;security;security of data;internet telecommunication traffic traffic control computer science computer network management statistical analysis payloads communication system traffic control ip networks application software;p2p traffic class internet traffic classification statistical discriminators cluster analysis quality of service traffic control security network management training phases	This work presents an Internet traffic classification methodology based on statistical discriminators and cluster analysis. An accuracy identification of Internet applications is an important research area, because it is directly related to solve many network problems such as: quality of service (QoS), traffic control, security, network management and operation. The main difference to previous approaches lies in the discriminators use; rather than using only one set of discriminators for all classes we use a set of different statistical discriminators for each traffic class. Using real traces into the training and classification phases, we validated the methodology for P2P traffic class.	cluster analysis;internet;peer-to-peer;quality of service;real-time computing;statistical machine translation;tracing (software);traffic classification	Raimir Holanda Filho;Marcus Fabio Fontenelle do Carmo;José Everardo Bessa Maia;G. P. Siqueira	2008	NOMS 2008 - 2008 IEEE Network Operations and Management Symposium	10.1109/NOMS.2008.4575244	network management;the internet;simulation;traffic classification;internet traffic;quality of service;computer science;information security;peer-to-peer;cluster analysis;computer security;computer network	Metrics	-63.59243349699655	66.59441494295703	180690
ccbc27a48857c3d9e2f8c2dc4477006f33a305fd	application identification system for sdn qos based on machine learning and dns responses		In recent years, the demand for application-specific qualify of service (QoS) management has grown. To effectively do application-specific QoS, a system albe to do flow classification at the application level is required. This paper presents an application identification system that can be integrated with a QoS management system in a software defined network (SDN). This paper describes the method to obtain ground truth (label) of the flow from four mainstream operating systems (OS), and the method to classify flow based on supervised machine learning and DNS responses. In our experiment, average F-measure of all applications reached 93.48%. The testing data set contained 294 applications, given that each platform version or execution file of an application was one application. The testing data set included Skype, Facebook, and other popular applications. Results showed that this system can identify application traffic on different platforms with high accuracy.	algorithm;ground truth;machine learning;operating system;quality of service;real-time clock;real-time computing;software-defined networking;supervised learning;test set	Nen-Fu Huang;Che-Chuan Li;Chi-Hsuan Li;Chia-Chi Chen;Ching-Hsuan Chen;I-Hsien Hsu	2017	2017 19th Asia-Pacific Network Operations and Management Symposium (APNOMS)	10.1109/APNOMS.2017.8094160	computer network;software-defined networking;quality of service;management system;computer science;test data;ground truth;artificial intelligence;machine learning	Embedded	-63.31024045380415	66.56338063517266	184544
a7c017b8d8ee2356c4aa8c509e471e5e5364e3e2	markov game modeling of moving target defense for strategic detection of threats in cloud networks.		The processing and storage of critical data in large-scale cloud networks necessitate the need for scalable security solutions. It has been shown that deploying all possible security measures incurs a cost on performance by using up valuable computing and networking resources which are the primary selling points for cloud service providers. Thus, there has been a recent interest in developing Moving Target Defense (MTD) mechanisms that helps one optimize the joint objective of maximizing security while ensuring that the impact on performance is minimized. Often, these techniques model the problem of multi-stage attacks by stealthy adversaries as a single-step attack detection game using graph connectivity measures as a heuristic to measure performance, thereby (1) losing out on valuable information that is inherently present in graph-theoretic models designed for large cloud networks, and (2) coming up with certain strategies that have asymmetric impacts on performance. In this work, we leverage knowledge in attack graphs of a cloud network in formulating a zero-sum Markov Game and use the Common Vulnerability Scoring System (CVSS) to come up with meaningful utility values for this game. Then, we show that the optimal strategy of placing detecting mechanisms against an adversary is equivalent to computing the mixed Min-max Equilibrium of the Markov Game. We compare the gains obtained by using our method to other techniques presently used in cloud network security, thereby showing its effectiveness. Finally, we highlight how the method was used for a small real-world cloud system.		Ankur Chowdhary;Sailik Sengupta;Dijiang Huang;Subbarao Kambhampati	2018	CoRR		computer science;artificial intelligence;connectivity;cvss;machine learning;cloud computing;adversary;scalability;network security;heuristic;distributed computing;markov chain	Metrics	-64.53588812909793	61.50250148044466	186407
0ce8ba4330c15912707c85b7018d395995b89fa2	security architecture based on multilayer distributed intrusion detection system	computers;detection sensors;sensor systems;sensors;real time;distributed processing;nonhomogeneous media intrusion detection event detection communication system security data security real time systems statistical analysis distributed processing computer architecture teamwork;statistical methods;statistical method;intrusion detection;event detection;hybrid model;computer architecture;software architecture;detection sensors security architecture multilayer distributed intrusion detection system event detection statistical methods;statistical analysis;multilayer distributed intrusion detection system;security architecture;network flow;security;security of data;object oriented modeling;intrusion detection system;statistical analysis distributed processing security of data software architecture	The architecture of designed intrusion detection system is based on two layer hybrid model for event detection. System function is based on analysis parts of network flow in a real communication and offers processing of this data in a real time. The core of the first layer are detection sensors, which offer base processing based on statistical methods with direct interconnection to countermeasure module. Performance and accuracy of designed system is secured with central distributed processing, in which is used detection based on particular event description, which foregoing intrusion. The architecture presented in this article is a result of teamwork of Department of computer and informatics and Institute of computer technologies of Technical University of Kosice. Its partial results are processed in author's master thesis and research within the APPV-0073-07 project.	communications security;dataflow;decision tree;distributed computing;flow network;inbound marketing;informatics;information security;interconnection;intrusion detection system;real-time clock;real-time computing;sensor;type signature	Martin Chovanec;Liberios Vokorokos;Ján Perhác	2009	2009 5th International Symposium on Applied Computational Intelligence and Informatics	10.1109/SACI.2009.5136261	intrusion detection system;host-based intrusion detection system;real-time computing;computer science;information security;distributed computing;computer security	Arch	-63.649864768082494	63.45350994226616	187412
10b9d0fefd1b8a697b41ed49108062ada93074fa	a botnet detection game	games computers security equations random variables mathematical model computational modeling;network infectivity botnet detection game security threat internet bot master compromised network stealth aggression strategic botnet utilization legitimate user vigilance botnet infection unique pure symmetric nash equilibrium homogeneous agents;invasive software computer network security game theory internet	Botnets continue to constitute a major security threat to users of the internet. We examine a novel security game between a bot master and the legitimate users of the compromised network. The more a bot master utilizes his botnet, the more likely it is he will be detected by the legitimate users of the network. Thus he must balance stealth and aggression in his strategic utilization of the botnet. The legitimate users of the network must decide how vigilant they will be in trying to detect the presence of the botnet infection. We establish the existence of a unique, pure, symmetric Nash equilibrium in a game with homogeneous agents. Network effects are numerically explored in relation to the infectivity of the network.	bot herder;botnet;nash equilibrium;numerical analysis;stealth	Braden Soper;John Musacchio	2014	2014 52nd Annual Allerton Conference on Communication, Control, and Computing (Allerton)	10.1109/ALLERTON.2014.7028469	simulation;bot herder;engineering;internet privacy;botnet;computer security	Security	-64.24057027487497	61.64919381066657	187692
d0ef199ecdf0c2da3abcfa362f29906eb096d1e2	augury: a time series based application for the analysis and forecasting of system and network performance metrics	forecasting;market research;measurement;data mining;servers;monitoring;time series analysis	This paper presents AUGURY, an application for the analysis of monitoring data from computers, servers or cloud infrastructures. The analysis is based on the extraction of patterns and trends from historical data, using elements of time-series analysis. The purpose of AUGURY is to aid a server administrator by forecasting the behaviour and resource usage of specific applications and in presenting a status report in a concise manner. AUGURY provides tools for identifying network traffic congestion and peak usage times, and for making memory usage projections. The application data processing specialises in two tasks: the parametrisation of the memory usage of individual applications and the extraction of the seasonal component from network traffic data. AUGURY uses a different underlying assumption for each of these two tasks. With respect to the memory usage, a limited number of single-valued parameters are assumed to be sufficient to parameterize any application being hosted on the server. Regarding the network traffic data, long-term patterns, such as hourly or daily exist and are being induced by work-time schedules and automatised administrative jobs. In this paper, the implementation of each of the two tasks is presented, tested using locally-generated data, and applied to data from weather forecasting applications hosted on a web server. This data is used to demonstrate the insight that AUGURY can add to the monitoring of server and cloud infrastructures.	computer;embedded system;job stream;maschinen krieger zbv 3000;network congestion;network performance;network traffic control;pattern recognition;paul werbos;seasonality;server (computing);server administrator;stochastic process;time series;web server	Nicolas Gutierrez;Manuela Wiesinger-Widi	2016	2016 18th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)	10.1109/SYNASC.2016.062	market research;parallel computing;real-time computing;forecasting;computer science;operating system;time series;data mining;database;distributed computing;server;measurement;statistics	Metrics	-64.03128056393861	67.58669214675456	188144
2b583cfd01f25283619d3822b48037881df2647f	a case study: using architectural features to improve sophisticated denial-of-service attack detections	computer crime intrusion detection application software operating systems hardware traffic control boosting tcpip telecommunication traffic radio access networks;sophisticated denial of service attack detections;training;intrusion detection;trees mathematics;data mining;hardware architecture;denial of service attack;statistical analysis;operating system;monitoring;feature extraction;denial of service;statistical gradient boosting trees model;detection rate;network based intrusion detection systems;ip networks;correlation;architecture level features;networked systems;architecture level features sophisticated denial of service attack detections network based intrusion detection systems operating system hardware architecture statistical gradient boosting trees model;security of data;trees mathematics security of data statistical analysis;intrusion detection system;dos attack	Application features such as port numbers are used by Network-based Intrusion Detection Systems (NIDSs) to detect attacks coming from networks. System calls and the operating system related information are used by Host-based Intrusion Detection Systems (HIDSs) to detect intrusions towards a host. However, the relationship between hardware architecture events and Denial-of-Service (DoS) attacks has not been well revealed. When increasingly sophisticated intrusions emerge, some attacks are able to bypass both the application and the operating system level feature monitors. Therefore, a more effective solution is required to enhance existing HIDSs. In this paper, we identify the following hardware architecture features: Instruction Count, Cache Miss, Bus Traffic and integrate them into a novel HIDS framework based on a modern statistical Gradient Boosting Trees model. Through the integration of application, operating system and architecture level features, our proposed HIDS demonstrates a significant improvement of the detection rate in terms of sophisticated DoS intrusions.	cpu cache;denial-of-service attack;experiment;gradient boosting;host-based intrusion detection system;operating system;sensor	Ran Tao;Li Yang;Lu Peng;Bin Li;Alma Cemerlic	2009	2009 IEEE Symposium on Computational Intelligence in Cyber Security	10.1109/CICYBS.2009.4925084	anomaly-based intrusion detection system;real-time computing;computer science;computer security;computer network	Security	-62.88246607713879	63.79342795477225	192006
020f95329df4f637f8e9f09d5776f6d14c6a1189	an efficient svm-based method for multi-class network traffic classification	sample size;telecommunication traffic computer network management pattern classification support vector machines;electronic mail;support vector machines;training;support vector machines training games equations mathematical model electronic mail accuracy;accuracy;telecommunication traffic;network traffic;games;computer network management;traffic classification;fuzzy tournament svm based method multiclass network traffic classification network service network management support vector machine low training sample size requirement delay requirement;pattern classification;mathematical model;support vector machine;network services	Multi-class network traffic classification is a fundamental function for network services and management. Support vector machine (SVM) based network traffic classification has recently attracted increasing interest, for its high accuracy and low training sample size requirement. However, to better fit applications with delay requirements, it is desirable to reduce the high computation cost of existing SVM-based traffic classifiers. In this paper, we propose a novel scheme for SVM-based traffic classification (called fuzzy tournament). Experiment results based on real network traffic traces show that our proposed scheme can reduce computation cost by as much as 7.65 times; in the mean time, misclassification ratio is consistently reduced by up to 2.35 times as well.	computation;network packet;network traffic control;requirement;support vector machine;tracing (software);traffic classification	Ning Jing;Ming Yang;Shaoyin Cheng;Qunfeng Dong;Hui Xiong	2011	30th IEEE International Performance Computing and Communications Conference	10.1109/PCCC.2011.6108074	support vector machine;computer science;machine learning;pattern recognition;data mining;statistics	HPC	-63.53377010475202	66.5095249103156	192243
5ff429e717bd606c73e901c18a4a2c35c2ec2f19	tri-tier immune system in anti-virus and software fault diagnosis of mobile immune robot based on normal model	human immune system;tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;artificial immune system;mobile robot;space time;anti virus;immune robot;immune system;tecnologias;grupo a;normal model;fault diagnosis;adaptive immunity	In this paper, anti-virus problem and software fault diagnosis of mobile robot, an immune robot, is discussed with proposal of a novel tri-tier immune system (TTIS). TTIS is a novel artificial immune system, which is comprised of three computing tiers and based on the normal model. The three tiers include inherent immune tier, adaptive immune tier and parallel immune tier. The tri-tier immune model is built on some theories of human immune system and has many good features, such as adaptability, immunity, memory, learning, and robustness. At the same time, for such immune robot, a novel normal model for the robot software is also proposed. The normal model is built on the space–time properties of each component in the robot software and can uniquely identify the normal state of the robot software. Such tri-tier immune system based on the normal model is suitable for anti-virus and fault diagnosis, which enable the immune robot to detect all viruses and faults in the robot software, recognize many viruses and faults, eliminate the viruses and faults, and repair the damaged robot software to its normal state. Meanwhile, simulation results show that the tri-tier immune system has the properties of immunity, security and robustness.	antivirus software;artificial immune system;biomimetics;failover;interpretation (logic);mobile robot;multitier architecture;robot software;robustness (computer science);simulation;testbed;theory;triangular function	Tao Gong;Zixing Cai	2008	Journal of Intelligent and Robotic Systems	10.1007/s10846-007-9186-1	embedded system;simulation;immune system;computer science;engineering;artificial intelligence;artificial immune system	Robotics	-65.20711217734242	63.2778049351575	192749
c0cbe21981ea0fd87cc94e2c46439f560c2a68fa	design contest overview: combined architecture for network stream categorization and intrusion detection (canscid)	canscid;field programmable gate arrays intrusion detection ip networks ethernet networks computer architecture doped fiber amplifiers inspection;intrusion detection;fpga;inspection;stream categorization memocode design contest deep packet inspector canscid regular expression matching fpga ethernet mac intrusion detection;computer architecture;security of data field programmable gate arrays local area networks pattern matching;pattern matching;regular expression matching;memocode design contest;deep packet inspector;ip networks;ethernet mac;field programmable gate arrays;ethernet networks;security of data;doped fiber amplifiers;local area networks;stream categorization	This year we received 8 submissions for our Deep Packet Inspection problem. 6 submissions used FPGAs, and 2 used GP-GPUs. The organizers find it significant that no team submitted a software-only solution that did not use some kind of hardware accelerator— an indication that software alone could not meet the required line rate. This year the contest ended in a tie. Congratulations to the joint winners, Team Sasao Lab and Team Limenators, each having implemented 140 patterns while maintaining line rate. Additionally, Team Sasao Lab was the only team to use an NFA approach rather than DFAs for matching the regular expressions. Full results are given in Table II. The performance of the two winners was verified by the organizers using undisclosed test inputs. The performance of the other teams is self-reported.	categorization;deep packet inspection;deterministic finite automaton;field-programmable gate array;graphics processing unit;intrusion detection system;nondeterministic finite automaton;regular expression	Michael Pellauer;Abhinav Agarwal;Asif Khan;Man Cheuk Ng;Muralidaran Vijayaraghavan;Forrest Brewer;Joel S. Emer	2010	Eighth ACM/IEEE International Conference on Formal Methods and Models for Codesign (MEMOCODE 2010)	10.1109/MEMCOD.2010.5558620	embedded system;real-time computing;computer science;distributed computing;programming language;field-programmable gate array	Robotics	-66.83639471959677	63.617613364771515	193160
61a8a5020001fad94027ca4638085451f73956ae	mining concept drifting network traffic in cloud computing environments	concept drift;time dependent;theoretical model;computer network security;support vector machine and concept drift;support vector machines;fixed time;roc thresholding cloud computing environments anomaly based network intrusion detection systems anomaly based network ids normal activity patterns network attack detection normal traffic pattern profile availability statistical fingerprint user activity system updates concept drift mining false positive rates system performance reduction ids reliability improvement roc curves fixed time invariant classification thresholds concept drifting network traffic supervised machine learning control theoretic model concept drift detection online support vector machine based classifier incremental anomaly based detection kullback leibler divergence based relative entropy measurement scheme feedback control engine;anomaly based intrusion detection systems;data mining;system performance;supervised machine learning;relative entropy;computer network performance evaluation;telecommunication traffic;feedback;false positive rate;network traffic;number of factors;pattern classification;roc curve;support vector machine and concept drift anomaly based intrusion detection systems;traffic control adaptation models intrusion detection accuracy support vector machines hidden markov models telecommunication traffic;support vector machine;network intrusion detection system;feedback control;telecommunication traffic cloud computing computer network performance evaluation computer network security data mining feedback pattern classification support vector machines;intrusion detection system;cloud computing	Anomaly-based network Intrusion Detection Systems (IDS)model patterns of normal activity and detect novel network attacks. However, these systems depend on the availability of the systems normal traffic pattern profile. But the statistical fingerprint of the normal traffic pattern can change and shift over a period of time due to changes in operational or user activity at the networked site or even system updates. The changes in normal traffic patterns over time lead to concept drift. Some changes can be temporal, cyclical and can be short-lived or they can last for longer periods of time. Depending on a number of factors the speed at which the change in traffic patterns occurs can also be variable, ranging from near instantaneous to the change occurring over the span of numerous months. These changes in traffic patterns are a cause of concern for IDSs as they can lead to a significant increase in false positive rates, thereby reducing the overall system performance. In order to improve the reliability of the IDS, there is a need for an automated mechanism to detect valid traffic changes and avoid inappropriate ad hoc responses. ROC curves have historically been used to evaluate the accuracy of IDSs. ROC curves generated using fixed, time-invariant classification thresholds do not characterize the best accuracy that an IDS can achieve in presence of concept-drifting network traffic. In this paper, we present integrated supervised machine learning and control theoretic model (especially for clouds) for detecting concept drift in network traffic patterns. The model comprises of an online support vector machine based classifier (incremental anomaly based detection), a Kullback-Leiblerdivergence based relative entropy measurement scheme (quantifying concept drift) and feedback control engine (adapting ROC thresholding). In our proposed system, any intrusion activity will cause significant variations, thereby causing a large error, while a minor aberration in the variations(concept drift) will not be immediately reported as alert.	anomaly detection;cloud computing;concept drift;feedback;fingerprint;hoc (programming language);intrusion detection system;kullback–leibler divergence;machine learning;network traffic control;receiver operating characteristic;sensor;supervised learning;support vector machine;theory;thresholding (image processing);time-invariant system	Sai Kiran Mukkavilli;Sachin Shetty	2012	2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (ccgrid 2012)	10.1109/CCGrid.2012.142	support vector machine;computer science;network security;machine learning;pattern recognition;data mining;feedback;computer performance	Metrics	-63.280868254171956	67.39963052642177	194217
3cccc219f6aca116048c79d43be49b0eca1848a3	a taxonomy on intrusion alert aggregation techniques	pattern clustering computer crime;a general works;taxonomy ids alert aggregation clustering;clustering;alert aggregation;taxonomy;ids;alert clustering intrusion alert aggregation techniques security threats organizations intrusion detection systems ids intrusion activities duplicated alerts information security operator alert reducing alert fusing;clustering algorithms algorithm design and analysis genetic algorithms classification algorithms taxonomy partitioning algorithms security	As security threats advance in a drastic way, most of the organizations apply various intrusion detection systems (IDSs) to optimize detection and to provide comprehensive view of intrusion activities. But IDS produces huge number of duplicated alerts information that overwhelm security operator. Alert aggregation addresses this issue by reducing, fusing and clustering the alerts. Techniques from a different scope of disciplines have been proposed by researchers for different aspects of aggregation. In this paper we present a comprehensive review on proposed alert aggregation techniques. Our main contribution is to classify the literature based on the techniques applied to aggregate the alerts.	aggregate data;algorithm;cluster analysis;intrusion detection system;online aggregation;taxonomy (general)	Taqwa Ahmed;Maheyzah Md Siraj;Anazida Zainal;Mazura Mat Din	2014	2014 International Symposium on Biometrics and Security Technologies (ISBAST)	10.1109/ISBAST.2014.7013129	computer science;data mining;world wide web;computer security;intrusion prevention system	Security	-63.79067230105763	64.94290420163128	198917
