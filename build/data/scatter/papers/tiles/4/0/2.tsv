id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
4925ddb64ba1498b7a286b4999eb7f6358b69c14	enhancing technological capability through supplier development: a study of the uk aerospace industry	pulp manufacturing;outsourcing;industrial case study;technological innovation;core competencies;defense industry;supplier relationships;technological capability enhancement;manufacturing industries;aerospace industry;indexing terms;management aerospace industry;technology management;appropriate technology;aerospace industry management;competitive subassemblies;research and development;innovation;advanced product technology;industrial relations;communication channels strengthening;manufacturing industry;supplier development;indirect effect;communication channels;management;technology strategy;advanced process technology;supplier development schemes;competitive subsystems;communication channels strengthening technological capability enhancement supplier development innovation competitive subsystems competitive subassemblies advanced product technology advanced process technology supplier development schemes aerospace industry defense industry technology strategy supplier relationships	The current trend in manufacturing industry is for large companies to focus on core competencies and to outsource more design and manufacture. Combined with the rationalization of the supplier base, this has meant that companies are increasingly dependent on key suppliers to continue providing competitive subsystems and sub-assemblies which incorporate advanced product and process technology. Suppliers in turn are reliant on their customers for information for innovation. This paper discusses the potential to enhance the technological capability of the supply network through supplier development schemes. Case studies of supplier development in the UK aerospace and defense sectors are presented in order to establish whether supplier development is enhancing technological capability in small companies in the UK supply base. The formal processes of supplier development are found to have little direct impact on supplier technological capability, but instead have an important indirect effect-primarily through strengthening relevant communication channels. There remains an opportunity for large companies to utilize supplier development to promote better technology management practices.	outsourcing	Fiona M. Reed;Kathryn Walsh	2002	IEEE Trans. Engineering Management	10.1109/TEM.2002.803379	economics;systems engineering;engineering;marketing;technology management;operations management;industrial relations;manufacturing;management;manufacturing engineering	SE	-80.9585747583053	5.6712416764957725	5662
a681d69cf9b160eeef32e5aba2d3e03287726f01	monitoring collaboration in software processes using social networks		Collaboration monitoring in software process is important to check if the collaboration is indeed happening as planned, but there are few approaches that define how to measure and monitor collaboration. By assessing collaboration during an ongoing process execution, project managers can take corrective actions that might improve the process execution and, consequently, reflect on quality gains of the final product. This research work proposes to evaluate the level of coordination achieved by a running software process through social network analysis metrics.		Gabriella Castro Barbosa Costa;Francisco W. Santana;Andréa Magalhães Magdaleno;Cláudia Maria Lima Werner	2014		10.1007/978-3-319-10166-8_8	systems engineering;knowledge management;social software engineering;software deployment	HCI	-68.62616891643509	21.678284886738272	5668
6dea92cd46af60be0845529329645aeeb68a5ec3	quantifizierung des leistungsparameters kooperationsqualität im rahmen eines ansatzes der wertschöpfungsprozessbezogenenleistungsanalyse in produktionsnetzwerken				Hendrik Jähn;Thomas P Burghardt;Marco Fischer	2007			computer science;knowledge management	Crypto	-96.6367568423893	23.34137156105508	5679
3baa7fb9d83233f9e6f71af9036f0c4d37ee2712	gravity - making of disintegration by monarchy ft. diva von teese	director roy raz;diva von teese;monarchy ft.;soft-core dystopia;sexual innuendo;london electro-pop duo;dita von teese	Gravity brings the CG and VFX to this off-kilter, soft-core dystopia created by director Roy Raz for Dita Von Teese and the London electro-pop duo Monarchy. Possibly the first use of a mosquito (3D or otherwise) as sexual innuendo.	darwin information typing architecture;dystopia;visual effects	Gravity	2013		10.1145/2503541.2503593		Theory	-91.5365946992095	20.882523039696743	5689
1454e73c11f1cba1a67d70045ee6c6f962ad0f24	strategic tactical and operational production-distribution models: a review	reverse logistics;information technology;product distribution;supply chain design;scm;distributed manufacturing;production distribution planning;supply chain management;production distribution models	The concept of supply chain management is gaining so much importance that the firms can compete in today’s global economy. This paper provides a detailed literature survey of previous research on supply chain management literature at strategic, tactical, operational levels and reverse logistics, but we limited our research only to the models developed for production and distribution problem. We scrutinise the previous reviews in order to distinguish our research from the others. In the light of these previous reviews, we have developed our classification scheme. The models reviewed in this research have been classified in terms of the solution methodology used. These are: optimisation-based models, metaheuristic-based models, Information Technology (IT)-driven models and hybrid models. The objective is to develop a framework for the existing literature to reveal major trends in the literature and to explore research opportunities in this area.	cellular automaton;logistics;mathematical optimization;metaheuristic	Bilge Bilgen;Irem Ozkarahan	2004	IJTM	10.1504/IJTM.2004.005059	supply chain management;economics;product distribution;marketing;operations management;management science	AI	-76.56435670398129	7.990004800767002	5691
4b526bc9db95b1f89f7d8e61521db9d5b1419e2b	teamwork - eine methode zum entwurf verteilter, wissensbasierter theorembeweiser			eine and zwei	Jörg Denzinger	1993			software engineering;computer science;teamwork	Vision	-103.37257822293888	24.977998496212297	5786
319c586c1e313968b116e7b3b06afd0de44c3c0a	datastores supporting services lifecycle in the framework of cloud governance		While adopting the Cloud, the small and medium sized enterprises (SMEs) could increase their benefit by embracing some Platform-as-a-Service (PaaS) solutions, doubled by a Cloud Governance or Cloud brokerage approach. However, in order to fully exploit the advantages brought by Cloud environments, and enter in real competition with ”big players” from different markets, SMEs must group themselves under the umbrella of a common marketplace, via some Cloud Governance solutions, and expose together complex, tailored and integrated solutions. The implementation of an effective Cloud Governance solution requires a strong support for storing and manipulating data which is relevant for various aspects of applications, both at business and technical level, support which is closely linked to cloud service lifecycle. This paper focuses on analyzing the main requirements related to data storage in an effective Cloud Governance system, details the functionality of the most important datastores and presents various use cases involving the entire storage architecture.	authentication;cloud computing;cloud management;computer data storage;electronic billing;emergence;internet;platform as a service;prototype;requirement	Adrian Copie;Teodor-Florin Fortis;Victor Ion Munteanu;Viorel Negru	2012	Scalable Computing: Practice and Experience		environmental resource management;operations management;business;commerce	OS	-72.31110602399359	12.417867893380262	5848
108893cf873a6f2765b27df7015fbe9718bfaef3	anwendung impliziter adaptiver regelalgorithmen zur auswertung redundanter prozessmesssignale				Klaus Knupfer	1983				NLP	-99.52004069874094	24.215453213128388	5895
625e2e82f01f0c53a2dcee9105b52bea279b7031	latent semantic analysis for business protocol discovery using log files	business protocol discovery;log files;lsa;message correlation;web services;latent semantic analysis	Recently, business protocol discovery has great importance in the field of web services. This field of research which aims at discovering the dynamic behaviour of the web service is mainly based on the execution history and reverse engineering techniques. On the other hand, latent semantic analysis (LSA) is a mathematical approach that aims at extracting relationships between large sets of data with regard to the context of data occurrence. In this paper, a new LSA-based approach for business protocol discovery is presented. A new microscopic/macroscopic pattern is defined and used for allowing incremental composition of protocols. The proposed approach uses synthetically generated log files, with the presence of noise and incomplete information. The results obtained from applying the proposed approach have proved its efficiency for business protocol discovery.	algorithm;cycle (graph theory);data logger;latent semantic analysis;loop (graph theory);reverse engineering;server (computing);succession;web service	Abdelkader Moudjari;Salim Chikhi;Hamamache Kheddouci	2014	Int. J. Web Eng. Technol.	10.1504/IJWET.2014.067550	web service;latent semantic analysis;computer science;data mining;database;law;world wide web	DB	-63.76128107668998	46.45365266847562	5901
8a444b88a492c6accfcfbffaab3b9497bd4a3e70	social analysis in the requirements engineering process: from ethnography to method	employment;viewpoint oriented approach;air traffic control;collaborative work;ethnography;design engineering;software prototyping;workplace observation;industry standard notation;uml;prototypes;air traffic control system;social aspects of automation;electrical equipment industry;requirements engineering;qa75 electronic computers computer science;prototyping;collaborative software air traffic control design engineering prototypes collaborative work software prototyping employment knowledge engineering electrical equipment industry unified modeling language;coherence method;complex system;systems analysis;air traffic control systems analysis social aspects of automation software prototyping;requirement engineering;unified modeling language;social analysis;collaborative software;knowledge engineering;air traffic control system social analysis requirements engineering ethnography workplace observation prototyping coherence method viewpoint oriented approach industry standard notation uml	Over a number of years, we have been involved in investigations into using workplace observation to inform requirements for complex systems. This paper discusses how our work has evolved from ethnography with prototyping, through presentation of ethnographic fieldwork, to developing a method for social analysis that has been derived from our experience of applying ethnographic techniques. We discuss the strengths and weaknesses of each of these approaches with a particular focus on our most recent work in developing the Coherence method. This method is based on a fusion of viewpoint-oriented and ethnographic approaches to requirements engineering and uses an industry-standard notation (UML) to represent knowledge of work. We use a common example of an air traffic control system to illustrate each approach.	complex systems;control system;field research;requirement;requirements engineering;software prototyping;unified modeling language	Stephen Viller;Ian Sommerville	1999		10.1109/ISRE.1999.777980	unified modeling language;simulation;computer science;systems engineering;engineering;software engineering;air traffic control;prototype;requirements engineering;management	SE	-65.21559146216856	16.7264337585525	5926
a100b2e0ac185332e993ce18eba7212de37324cc	it-enabled incentive schemes in telephone banking	marketing data processing;information technology;bank data processing;telephony;incentive schemes telephony banking marketing and sales monitoring insurance costs customer satisfaction profitability contracts;distribution channel;marketing data processing bank data processing telephony information technology;profitability;incentive scheme;information technology incentive schemes telephone banking it competitiveness marketing distribution channels franchising telephone consultants customer relationships profits	"""In this paper we show that an IT-enabled suitable design of incentives improves the competitiveness of new marketing and distribution channels like telephone banking. Using and extending a framework developed by Nault and Dexter [8] for franchising, we show that an ITenabled """"ownership of customers"""" increases the effort of telephone consultants to establish ongoing customer relationships, leading to higher income for the consultants and higher profits for the banking firm. Moreover, it can be shown that the bank can optimize incentive parameters in such a way to achieve a first-best solution."""	dexter (malware)	Klaus Sandbiller;Andreas Will;Hans Ulrich Buhl;Barrie R. Nault	1997		10.1109/HICSS.1997.661603	telephone banking;computer science;marketing;telephony;management;law;information technology;commerce;profitability index	Mobile	-83.45534158766927	6.480028140511176	5943
d7edacb5df781efb1f583eab479dcc6a4e75fb0c	equation-based object-oriented modeling languages and tools - report on the workshop eoolt 2010 at m	datavetenskap datalogi;computer science	EOOLT 2010 was the third edition of the EOOLT workshop series. The workshop is intended to bring together researchers and practitioners from different equation-based object-oriented (EOO) modeling language communities. This year’s workshop also expands the scope to include the whole design space of languages for cyber-physical systems, where physical dynamics are mixed with networks and software. The workshop gathered 31 participants to present and discuss thirteen different papers grouped into the four areas of realtime oriented modeling languages and tools, modeling language design, simulation and model compilation, and modeling and simulation tools.	compiler;cyber-physical system;modeling language;simulation	Peter Fritzson;Edward A. Lee;François E. Cellier;David Broman	2010		10.1007/978-3-642-21210-9_13	computer science;data science;software engineering;operations research	PL	-62.858455641927016	20.075815547541467	5959
6d43d03fa5c8385ed438fc8fc9206ebe85bd53f6	eine modifikation des deriche-verfahrens zur kantendetektion		Canny stellte 1983 Gutekriterien fur Kantendetektoren vor, durch deren Optimierung er einen optimalen eindimensionalen FIR-Filter fur Stufenkanten gewann. Vier Jahre spater prasentierte Deriche ein Verfahren zur Kantendetektion, das unmittelbar auf Cannys Ansatz aufbaut, jedoch IIR-Filter verwendet, die sich sehr effizient rekursiv implementieren lassen. Allerdings werden bei Verwendung der Deriche-Filter die Kantenamplituden in Abhangigkeit von den Kantenrichtungen systematisch verzerrt. Im folgenden wird gezeigt, das es sich dabei um einen systematischen Amplitudenfehler handelt, der sich durch eine einfache Modifikation des Verfahrens beseitigen last. Aufgrund seiner offensichtlichen „Verwandschaft“ mit den Deriche-Filtern wird auch der Shen-Filter in die Untersuchungen mitaufgenommen.	eine and zwei	Stefan Lanser;Wolfgang Eckstein	1991		10.1007/978-3-662-08896-8_18	philosophy;performance art	Crypto	-106.12598214891007	31.562203176269175	5981
fdb5e0989a22f521969eb5b12e234f7922db6010	experiencing process flexibility patterns with alaska simulator		Alaska Simulator is an interactive software tool developed at the University of Innsbruck which allows people to explore different approaches to process flexibility by using a familiar metaphor, i.e., travel planning and execution. In addition, Alaska Simulator is used for studying research questions in the context of business process management and other related fields. For this, Alaska Simulator provides integrated support of different approaches to process flexibility in terms of decision deferral patterns, which all allow interleaving process modeling with execution and provide mechanisms for effectively dealing with uncertainty. The biggest challenge for users of such flexible systems is to find the right balance between pre-planning activities and keeping options open. To address this challenge Alaska Simulator allows safe exploration and systematic investigation of how much pre-modeling is needed under different circumstances.	business process;forward error correction;process modeling;programming tool	Barbara Weber;Stefan Zugal;Jakob Pinggera;Werner Wild	2009			systems engineering;deferral;simulation;software;business process management;interleaving;process modeling;computer science	HCI	-67.34307220384949	17.757205695013067	5985
d9e8e3cdb8dc1c5214bf77d33ae96a54a6656a5d	neural net analysis of the propensity for change in large software systems	software metrics;change count history;complexity metrics;fuzzy reasoning;neural nets;maximum cyclomatic complexity metrics;software systems;backpropagation;mozilla change data;fuzzy set theory;software project management;fuzzy modeling;neural net analysis;lines of code;neural net;neural networks software systems history biological neural networks project management open source software testing intelligent networks application software software libraries;knowledge acquisition;rule generation;large software system;software metrics backpropagation fuzzy reasoning fuzzy set theory knowledge acquisition neural nets;backpropagation neural net analysis large software system code metrics change count history fuzzy modeling rule generation mozilla change data maximum cyclomatic complexity metrics;fuzzy model;neural network;code metrics	A novel approach for analyzing the relationship between code metrics and change count histories is presented. Specifically, neural networks are employed to determine a mapping between metrics and change count. While these neural networks can be trained to a high degree of accuracy, their internal workings remain opaque to the user. As such, a fuzzy modeling approach is additionally employed to generate the rules governing the neural computation. These rules are linguistic in nature and are thus more easily interpreted by software project managers. Application of this method to Mozilla change data reveals the importance of fan-out, total lines of code and maximum cyclomatic complexity metrics in predicting amount of change per file.	algorithm;artificial neural network;black box;computation;cyclomatic complexity;fan-out;fuzzy concept;fuzzy rule;nonlinear system;software metric;software project management;software system;source lines of code	Steven B. Morphet;James W. Fawcett;S. Kanat Bolazar;Murat K. Gungor	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/FUZZY.2006.1681882	software project management;computer science;artificial intelligence;backpropagation;theoretical computer science;machine learning;data mining;fuzzy set;source lines of code;artificial neural network;software metric;software system	SE	-67.48273229866292	35.052491658534215	6001
811dc24f21dfee6ec2fc71a87d01e568cf3b34f2	metamodellierung im geschäftsprozessmanagement: konzept, erfahrung und potentiale				Harald Kühn;Stefan Junginger;Dimitris Karagiannis;C. Petersen	1999				Crypto	-97.7609880379152	24.909507868880468	6022
30b346a5594bfdf7812c0869213808f1c8e481f9	entwicklung eines cae-werkzeuges zum entwurf von flugsteuerungs- und hydrauliksystemen			x/open	Dieter Scholz	1997				Crypto	-101.41692725622795	26.335747786077302	6032
6748c516b2435498a7f496c3e261dbc0a903aa37	die sap ag im spiegel der berichterstattung der computerwoche			die (integrated circuit)	Georges-André Althaus;Gerhard Knolmayer	1998	Wirtschaftsinformatik		software engineering;knowledge management;computer science	Robotics	-93.55074325916839	26.774013126882096	6081
a414902249ffc349ea5966604715d15674bbd046	effective communication of software development knowledge through community portals	knowledge management;software engineering;knowledge;community portal;software development;knowledge sharing;grounded theory;communication channels;documentation	Knowledge management plays an important role in many software organizations. Knowledge can be captured and distributed using a variety of media, including traditional help files and manuals, videos, technical articles, wikis, and blogs. In recent years, web-based community portals have emerged as an important mechanism for combining various communication channels. However, there is little advice on how they can be effectively deployed in a software project.  In this paper, we present a first study of a community portal used by a closed source software project. Using grounded theory, we develop a model that characterizes documentation artifacts along several dimensions, such as content type, intended audience, feedback options, and review mechanisms. Our findings lead to actionable advice for industry by articulating the benefits and possible shortcomings of the various communication channels in a knowledge-sharing portal. We conclude by suggesting future research on the increasing adoption of community portals in software engineering projects.	blog;documentation;knowledge management;portals;software development;software engineering;software project management;web application;wiki	Christoph Treude;Margaret-Anne D. Storey	2011		10.1145/2025113.2025129	software engineering process group;software mining;software project management;documentation;computer science;engineering;knowledge management;social software engineering;software development;software engineering;multimedia;knowledge;software walkthrough;grounded theory;world wide web;domain knowledge;software peer review	SE	-73.53663556985785	19.638346606534434	6099
0f52270a8dbcffb9d8b2ca52116766192be5a376	open the way to future networks - a viewpoint framework from itu-t		Advancements concerning research and development of Future Networks (FNs) technologies have been introduced in recent years, such as network virtualization and software defined/driven network (SDN), information centric networking (ICN), cloud networking, autonomic management, and open connectivity. In this context ITU-T has developed initial Recommendations that lay out the essential directions for subsequent detailed work including further standardization of Future Networks. This paper presents the background and the context of FNs’ standardization, the results and future plans originated from the initial standardization work performed by ITU-T.	autonomic networking;cloud computing;icn gps;recommender system;software-defined networking;viewpoint	Daisuke Matsubara;Takashi Egawa;Nozomu Nishinaga;Myung-Ki Shin;Ved P. Kafle;Alex Galis	2013		10.1007/978-3-642-38082-2_3	simulation;engineering;software engineering;management science	Mobile	-69.85967356835828	41.38041556058985	6110
8871dab41d1d2e88ed8efe2dc43a541a85047e4e	evaluating the relation between coding standard violations and faultswithin and across software versions	software;fault location coding standard violations software versions software faults misra c 2004 standard;pilot study;history;standards;density measurement;maintenance;software fault tolerance;code standards;data mining;inspection;software standards software tools industrial relations standards development inspection laboratories fault location software quality maintenance code standards;empirical evidence;standards development;industrial relations;software standards;software tools;software versions;software faults;encoding;misra c 2004 standard;coding standard violations;software quality;fault location	In spite of the widespread use of coding standards and tools enforcing their rules, there is little empirical evidence supporting the intuition that they prevent the introduction of faults in software. In previous work, we performed a pilot study to assess the relation between rule violations and actual faults, using the MISRA C 2004 standard on an industrial case. In this paper, we investigate three different aspects of the relation between violations and faults on a larger case study, and compare the results across the two projects. We find that 10 rules in the standard are significant predictors of fault location.	fault injection;misra c;relation (database);sensitivity and specificity;software project management;software versioning	Cathal Boogerd;Leon Moonen	2009	2009 6th IEEE International Working Conference on Mining Software Repositories	10.1109/MSR.2009.5069479	reliability engineering;real-time computing;empirical evidence;inspection;computer science;software versioning;operating system;software engineering;data mining;industrial relations;software quality;software fault tolerance;encoding	SE	-63.3435745925591	35.05446760818207	6160
e6f09b1ae556840500f2357dfc09d68b9c939a68	systems dynamics modelling of a manufacturing supply chain system	make to order;system dynamics modelling;town and country planning;operant conditioning;system dynamics;integrable system;dynamic behaviour;system performance;business and management studies;customer satisfaction;modelling framework;make to order systems;initial condition;systems dynamics;supply chain;supply chain network;simulation modelling;supply chain management;manufacturing supply chain	Supply chains are multifaceted structures focusing on the integration of all the factors involved in the overall process of production and distribution of end products to the customers. Growing interest in supply chain systems has highlighted the need to adopt appropriate approaches that can ensure the efficient management of their complexity, enormity and broadness of scope. With the main aim of supply chain management being to optimise the performance of supply chains, attention is mainly drawn to the development of modelling frameworks that can be utilised to analyse and comprehend the dynamic behaviour of supply chains. While there have been only a few supply chain modelling attempts reported in the literature, this paper proposes a modelling framework that is used to simulate the operation of a supply chain network of moderate complexity. The proposed model comprises four echelons and is build around a central medium-sized manufacturing company operating as a typical Make-to-Order (MTO) system. The developed model was built using a systems dynamics (SD) approach. The operations performed within a supply chain are a function of a great number of key variables which often seem to have strong interrelationships. The ability of understanding the network as a whole, analysing the interactions between the various components of the integrated system and eventually supplying feedback without de-composing it make systems dynamics an ideal methodology for modelling supply chain networks. The objective of the paper is to model the operation of the supply chain network under study and obtain a true reflection of its behaviour. The modelling framework is also used to study the performance of the system under the initial conditions considered and compare it with that obtained by running the system under eight different scenarios concerning commonly addressed real-life operational conditions. The modelling effort has focused on measuring the supply chain system performance in terms of key metrics such as inventory, WIP levels, backlogged orders and customer satisfaction at all four echelons. The study concludes with the analysis of the obtained results and the conclusions drawn from contrasting the system’s performance under each investigated scenario to that of the benchmark model.	system dynamics	Mustafa Özbayrak;Theopisti Papadopoulou;Melek Akgun	2007	Simulation Modelling Practice and Theory	10.1016/j.simpat.2007.09.007	supply chain management;simulation;service management;systems engineering;engineering;system dynamics	Robotics	-76.7911037469677	8.36597929209347	6195
7a33e6280507d2d578d095ad3108a04eb6f4cc5f	experimental study using functional size measurement in building estimation models for software project size	software;software project estimation;training;empirical software engineering;software project estimation functional size measurement experiment empirical software engineering;size measurement;computer science education;estimation;size measurement project management software engineering application software uncertainty software development management conference management engineering management computer science phase estimation;mathematical model;regression analysis;software development management computer science education;experiment;software development management;functional size measurement;web application development projects functional size measurement estimation models software project size software product size predictability research problem concordia university	This paper reports on an experiment that investigates the predictability of software project size from software product size. The predictability research problem is analyzed at the stage of early requirements by accounting the size of functional requirements as well as the size of non-functional requirements. The experiment was carried out with 55 graduate students in Computer Science from Concordia University in Canada. In the experiment, a functional size measure and a project size measure were used in building estimation models for sets of web application development projects. The results show that project size is predictable from product size. Further replications of the experiment are, however, planed to obtain more results to confirm or disconfirm our claim.	causality;computer science;computers, freedom and privacy conference;design of experiments;experiment;functional requirement;non-functional requirement;power supply unit (computer);self-replicating machine;software project management;web application development	Nelly Condori-Fernández;Maya Daneva;Luigi Buglione;Olga Ormandjieva	2010	2010 Eighth ACIS International Conference on Software Engineering Research, Management and Applications	10.1109/SERA.2010.42	experiment;estimation;simulation;computer science;systems engineering;software engineering;mathematical model;regression analysis;statistics	SE	-66.13553410748953	30.152083411708226	6228
ace9e569d43571066d6885c549b6d45e558f5377	software ecosystem modeling: the value chains	software industry;software ecosystem modeling;software ecosystem;software supply network	The software ecosystem is providing a new way of interpreting the software industry. Primarily, software ecosystem modeling, one of the most studied areas in the software ecosystem domain, is an emerging field. However, modeling software ecosystems present several challenges: (a) How can value chains be identified in an ecosystem? (b) What are the typical roles that an actor plays in an ecosystem? (c) How can a boundary in an ecosystem be described?  To capture the ecosystem of the Dutch software industry, we performed forty-two case studies. This work enhanced the software supply network diagram to define the proposed diagrams of an ecosystem within this industry. We determined eight value chain models that can be used to identify typical roles that an actor plays in an ecosystem.  We observed that most, if not all software producing organizations are hybrid companies in that they fill multiple roles in the value chains. The resulting models enable ones to identify actors and their roles quickly in an ecosystem. Moreover, they facilitate further understanding of the elemental business models and value chains. As such, this work provides an elementary step towards a software ecosystem modeling language.	diagram;ecosystem model;elemental;emoticon;graph drawing;modeling language;software ecosystem;software industry	Eko Handoyo;Slinger Jansen;Sjaak Brinkkemper	2013		10.1145/2536146.2536167	knowledge management	SE	-76.02789745006481	5.765946213169338	6231
ee0d1106af5c67268a7836a6706ee46cff3bf2cf	service value networks for competency-driven educational services: a case study		Service networks represent a flexible way for delivering services to customers. In earlier work, we have applied the e-value methodology to conceptually model such networks. This paper, however, presents an approach for composing Service Value Networks (SVNs) based on customer and supplier perspectives. A broker is in charge of composing a SVN that reflects not only customer desires but also supplier offerings. Moreover, the application of using real-world services is shown by means of a case study. Finally, we provide some reflections as well as future lines of research.	amiga reflections;combinatorial optimization;fits;interaction;linkage (software);mathematical optimization;product bundling;vagueness;value network	Iván S. Razo-Zapata;Pieter De Leenheer;Jaap Gordijn;Hans Akkermans	2011		10.1007/978-3-642-22056-2_9	service bureau;mobile qos;service delivery framework;services computing;service system	ML	-70.3150586764286	11.6922808109307	6235
a34ee0e81cf25a52150731bc614ef119cbd0f308	relating architectural decay and sustainability of software systems	software metrics;quality attributes;measurement;longevity;software systems;maintenance engineering;sustainability;computer architecture;software architecture;measurement computer architecture taxonomy software systems maintenance engineering computer bugs;source code software software architecture software maintenance software metrics software quality;software evolution software system architectural decay software system sustainability system quality system health code sustainability level architectural smells software metrics software maintenance;taxonomy;quality attributes sustainability software metrics longevity evolution software architecture;computer bugs;evolution	Ensuring the longevity of a software system is an important concern for developers and maintainers. However, when a system's architecture decays during evolution and its quality degrades as a result, the system's long-term sustainability is highly affected. In this light, providing mediums to estimate and track the sustainability of a software system is necessary to help engineers stay aware of system health. Most existing techniques and tools estimate the level of sustainability in code, paying significantly less attention to the analysis and understanding of architectural decay. This position paper provides a taxonomy of architectural smells, metrics, and their impacted quality properties. We relate these smells to maintenance and evolution areas as a first step toward our ultimate goal of estimating the sustainability of systems. We finally report some initial results drawn from a set of subject systems as promising future work using our taxonomy.	code smell;software rot;software system;taxonomy (general)	Duc Minh Le;Carlos Carrillo;Rafael Capilla;Nenad Medvidovic	2016	2016 13th Working IEEE/IFIP Conference on Software Architecture (WICSA)	10.1109/WICSA.2016.15	maintenance engineering;reliability engineering;software architecture;systems engineering;engineering;software engineering;evolution;sustainability;taxonomy;measurement	SE	-64.27882388779365	33.825058506122694	6250
e5e1fbfc385f263855bee2a417e151d73347e014	editorial: special issue on service-based electronic commerce systems	selected works;bepress	The increasing popularity of service-based applications accounts for the growth of e-commerce, as e-commerce systems are maintained by service providers themselves. Further, service-based e-commerce systems provide a flexible, low-cost business model to enable customers to focus more on their core business. The business can easily meet the fluctuating demands of business transactions through this model. Emerging electronic commerce systems are expected to be available anytime, anywhere, and using different official or personal computing devices. Service-based ecommerce systems will have businesses as customers using an on-demand model. Differing from traditional electronic commerce, the timely reporting and resolution of customer issues resulting in enhanced customer service and ubiquitous usage are the advantages of service-based e-commerce systems. This special issue aims to expose the readership to the latest research results on service-based electronic commerce systems, including the key technologies, such as enhancing the scalability, reliability, operational portability, security, integration and performance of the services. The special issue is composed of 3 refereed papers covering such topics as smartphone-based	e-commerce	Shiguo Lian;Xi Chen;Katina Michael	2013	Electronic Commerce Research	10.1007/s10660-013-9109-0	computer science;multimedia;operations research	DB	-77.82784275420194	15.537149103100443	6254
8eb4584c33817ec109e0dd9e7710e37f560db637	it is more blessed to give than to receive - open software tools enable open innovation		Open Innovation (OI) has attracted scholarly interest from a wide range of disciplines since introduced by Chesbrough [1], i.e. ”a paradigm that assumes that firms can and should use external ideas as well as internal ideas, and internal and external paths to market, as they look to advance their technology”. However, OI remains unexplored for software engineering (SE), although widespread in practice through Open Source Software (OSS). We studied the relation between SE and OI and in particular how OSS tools impact on software-intensive organization’s innovation capability. We surveyed the literature on SE and OI [3] and found that studies conclude that start-ups have higher tendency to opt for OI compared to established companies. The literature also suggests that firms assimilating external knowledge into their internal R&D activities, have higher likelihood of gaining financial advantages. In a case study, we observed how OSS tools Jenkins and Gerrit enabled open innovation [2]. We mined software commits to identify major contributors, found them be affiliated to Sony Mobile, contacted five of them for interviews about their and their employer’s principles and practices with respect to OI and tools, which they gave a consistent view of. Our findings indicate that the company’s transition to OI was part of a major paradigm shift towards OSS, while the adoption of open tools was driven bottom up by engineers with support from management. By adopting OI, Sony Mobile achieved freed-up developers’ time, better quality assurance, inner source initiatives, flexible development environment, faster releases and upgrades. Particularly, the introduction of a test framework was proposed by Sony Mobile but implemented by other contributors [2]. However, the benefits are gained through investing significant attention and resources to the OSS community in terms of technical contributions and leadership. BODY Sharing software tools enables open innovation, brings faster upgrades and frees up resources, but demands investments in the open community		Per Runeson;Hussan Munir;Krzysztof Wnuk	2016	TinyToCS		knowledge management;quality assurance;open innovation;operations management;software;top-down and bottom-up design;development environment;engineering	SE	-73.48347142428702	19.144503714648653	6277
89446252b7de91a9016dbe0a312e6c9dc5f9c7d6	security risk management in complex organization	risk management companies iso standards information security;security of data iso standards organisational aspects risk management;common risk register complex organization it security risk management international corporation corporative rules legal rules regulation rules operational decisions croatian telecom deutsche telecom group iso 27001 requirements information security	Security Risk Management is foundation and starting point for implementation of security measures in any organization and challenge by itself. But in complex organizations there are additional challenges, how to align IT Security Risk Management with overall Security Risk Management and later with the Company's overall Risk Management. When organization is part of some international corporation, corporative rules also need to be followed in addition to legal and regulation rules. In telecom industry in regular operations also is very important that security assessment could be performed in short timeslot as support for operational decisions. Croatian Telecom as a part of Deutsche Telecom Group is facing all of this issues in addition to ISO 27001 requirements against which the Company is certified. To solve the challenge, the Company developed three methodologies for Information Security Risk Management. All of these methodologies are merged in common Risk Register as well as aligned with the Company's Risk Management. In this paper each Information Security Risk Management methodology will be described including its application area, as well as how recognized security risks are shown in common Risk Register and how they relate to the Company's Risk Management.	align (company);iso/iec 27001:2013;information security;requirement;risk management	Ivan Sedinic;Tamara Perusic	2015	2015 38th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)	10.1109/MIPRO.2015.7160481	standard of good practice;certified information security manager;itil security management;security management;information security management system;security information and event management;it risk management;security convergence;risk management;threat;information security;information security standards;it risk;security service;risk management information systems;management;computer security;information security management;factor analysis of information risk	DB	-73.16493864704113	13.101321065370378	6279
04d1119f7b41938df58e9e087b9885a223060f79	seven lessons to teach design	software engineering;point of view	"""Design is probably the most important topic to teach in a software engineering course, but it is also the most difficult. Beside trying to formalize the design activity, it seems equally important, from a pedagogical point of view, to understand why design is hard and what its prerequisites are. This paper presents an analysis of actual design errors found in students' projects. These errors fall into seven categories. Each category is analyzed in order to identify the root difficulty and to suggest some pedagogic solutions. 1 I n t r o d u c t i o n A common debate among the software engineering community is where to draw the dividing line between """"programmers"""" and """"software engineers."""" To go beyond such ready made, and false, answers as """"a software engineer is the team leader"""", """"is one who uses XXX design formalism"""", or worse """"is one who has followed a software engineering curriculum"""", we need to investigate deeper criteria. A traditional criterion is to focus on the engineering part of the activity. An engineer is then a person who knows how to apply scientific results to produce artifacts and how to manage projects. Following this criterion, we have built a software engineering curriculum focusing on state of the art techniques and project management [Jacquot 90]. However, we constantly note at the end of each year that some of our students well deserve their qualification as """"engineer"""" while others remain """"highlevel programmers"""". Although this judgement must be tempered by the fact that employers greatly appreciate our students, we still feel some kind of dissatisfaction. An analysis of our judgement has shown that it is mostly motivated by the design eapabiliti~ of the students. In fact, a software engineer is a professional who knows how to design software. Then, the problem facing us is: """"can we teach design?"""" Once again quick answers such as """"oblige students to use Abstract Data Type techniques,"""" or """"teach them graphical design formalisms and tools"""" have proven insufficient. Examinations show that our students have a reasonably good theoretical knowledge of"""	abstract data type;artifact (software development);graphical user interface;point of view (computer hardware company);programmer;semantics (computer science);software engineer;software engineering	Jean-Pierre Jacquot;J. Guyard	1991		10.1007/BFb0024292	computer science;systems engineering;software engineering;computer engineering	SE	-65.15596387629547	18.877040732421477	6297
a3396ec930a907e9de04cc6213d7530e3421df18	boundary spanning capabilities in offshored information systems development projects: a conceptual framework	boundary spanning	As more firms seek to reap benefits from offshore outsourcing, many firms are facing failures in these ventures. IS capabilities literature has identified critical capabilities for firms that seek to offshore outsource. In this study we extend this theory and focus on boundary spanning capability as a critical IS capability for firms seeking to offshore outsource. We distinguish internal and external boundary spanning and conceptualize these in the offshored information systems development (ISD) context & present a conceptual research framework.	file spanning;information system;outsourcing;software development process	Poornima Krishnan;C. Ranganathan	2008			submarine pipeline;management science;knowledge management;computer science;conceptual framework;information system;boundary spanning;outsourcing;offshore outsourcing	AI	-79.90506889325036	4.292606791036597	6339
4efde40b309ffa912c7e26013cd6c8eece7606fe	aufgabenorientiertes modell zur nutzung der automatisierten datenverarbeitung im hochschulbereich (teil 2)			v-model	Paul Schmitz;Dietrich Krekel	1982	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1.1982.5.3.142		NLP	-103.3978118517726	26.001280930924	6344
fe6cc021f95726a403222cb61f16675f6568b569	the role of collaborative support to promote participation and commitment in software development teams	group learning;pedestrian safety;software process improvement;poison control;injury prevention;collaboration;safety literature;traffic safety;injury control;home safety;injury research;safety abstracts;human factors;occupational safety;software development;safety;safety research;accident prevention;violence prevention;bicycle safety;poisoning prevention;falls;ergonomics;suicide prevention;awareness mechanisms;workflow systems	Abstract#R##N##R##N#This work discusses the use of collaborative technology as an element for extending software process culture within development teams. This discussion starts with the idea that collaboration support comprises an important element for software process improvement (SPI) and an agent for process learning. We argue that improving awareness information about work processes and about the collaboration intrinsic to it may help software development teams to better accept the idea of defining, standardizing and continuously improving their work. Our approach relies on the use of workflow systems for software process support. We have built an environment—PIEnvironment—by extending a commercial workflow system with awareness information mechanisms and participation channels. Through case studies, we have evaluated its use for the enactment of software process activities. Copyright © 2007 John Wiley & Sons, Ltd.	software development	Renata Mendes de Araujo;Marcos R. S. Borges	2007	Software Process: Improvement and Practice	10.1002/spip.314	personal software process;team software process;software engineering process group;systems engineering;engineering;knowledge management;suicide prevention;human factors and ergonomics;injury prevention;software development;software engineering;software walkthrough;empirical process;management;computer security;software development process;collaboration	SE	-70.59694446782377	19.158045957907408	6350
3befd8e48abae5dd6ba6ff053823c1db82e7e6a0	file-level vs. module-level regression test selection for .net		Regression testing is used to check the correctness of evolving software. With the adoption of Agile development methodology, the number of tests and software revisions has dramatically increased, and hence has the cost of regression testing. Researchers proposed regression test selection (RTS) techniques that optimize regression testing by skipping tests that are not impacted by recent program changes. Ekstazi is one such state-of-the art technique; Ekstazi is implemented for the Java programming language and has been adopted by several companies and open-source projects.   We report on our experience implementing and evaluating Ekstazi#, an Ekstazi-like tool for .NET. We describe the key challenges of bringing the Ekstazi idea to the .NET platform. We evaluate Ekstazi# on 11 open-source projects, as well as an internal Microsoft project substantially larger than each of the open-source projects. Finally, we compare Ekstazi# to an incremental build system (also developed at Microsoft), which, out of the box, provides module-level dependency tracking and skipping tasks (including test execution) whenever dependencies of a task do not change between the current and the last successful build. Ekstazi# on average reduced regression testing time by 43.70% for the open-source projects and by 65.26% for the Microsoft project (the latter is in addition to the savings provided by incremental builds).	.net framework;agile software development;build automation;correctness (computer science);java;open-source software;out of the box (feature);programming language;regression testing;run time (program lifecycle phase);thinking outside the box	Marko Vasic;Zuhair Parvez;Aleksandar Milicevic;Milos Gligoric	2017		10.1145/3106237.3117763	programming language;regression testing;real-time computing;computer science;software engineering;java programming language;agile software development;correctness;incremental build model;software	SE	-65.50124700629333	34.33995100397762	6397
bbc8dd793fcc53872c70f2de298fa2eeaf3bf0f6	kein problem mehr mit vergessenen passwörtern	330 wirtschaft;ddc 330	Über die Hälfte der Studenten vergessen jährlich ihre Passwörter und verursachen deshalb enorme Verwaltungsprobleme. Die Universität Regensburg hat einen neuen Weg beschritten, um dem Herr zu werden. Sie setzt auf die sensorlose Biometrie Tippverhalten.	sie (file format);unified model	Dieter Bartmann;Martin Wimmer	2007	Datenschutz und Datensicherheit - DuD	10.1007/s11623-007-0071-7	computer science	Theory	-103.86158277000847	34.13410738182547	6433
456e3118a4f3a8a2218a548d4c9413f1b9d67c4f	modélisation du bilan de masse en surface de la calotte glaciaire antarctique. (modeling of the antarctic ice sheet surface mass balance)			linear algebra	Luc Gential	2007				Graphics	-104.40618558686862	17.162519452591454	6436
98730015996638f70d0a54132958e388bd55ca45	9. integration of life-cycle constraints in design activity	design activity;life-cycle constraints	The constraints concerning the whole life-cycle of a product must be integrated as soon as possible during the product design process, in order to decrease the final cost and to reduce the time to market. For this purpose, we propose a multi-actors and multi-views Cooperative Design Modeler, named CoDeMo, that allows the integration of different partners during the design activity. Our design methodology proposes the emerging of a product model from the specific constraints, results of the activity of the technologists, the manufacturers or the recycling actors. CoDeMo facilitates the dialogue between the diverse professions with the specification of the links existing among the views and by proposing a coordination system.		S. Tichkiewitch;D. Brissaud	2000			simulation;systems engineering;engineering;operations management;product design specification;design review;product design;product engineering	EDA	-63.63179174141749	13.987394964439474	6445
b67f9379eb9c7c978154afb33370aa6841801fb3	xenia: a security system for grid computing based on trust chains (xenia: um sistema de segurança para grades computacionais baseado em cadeias de confiança)			grid computing;unified model	José de Ribamar Braga Pinheiro Junior	2008				HPC	-94.62126465006976	30.048851283733057	6452
06ba3429ad3de5b2f92ce2de9a7150c95642ff0d	selecting the right visualization of indicators and measures - dashboard selection model	publikationer;konferensbidrag;artiklar;rapporter	Background: Contemporary software development organizations utilize multiple channels to disseminate information about their indicators, measures, trends and predictions. Selecting these channels is usually done based on the availability of the visualization technology and a set of requirements elicited from stakeholders at the company. Eliciting these kind of requirements can be labor-intensive and time-consuming. Goal: The objective of this research is to develop a method for selecting which dashboard should be used. As the set of dissemination patterns of measures in modern organizations is limited, this method should be able to identify the needs of visualizations at the company and match them to the dissemination patterns and their supporting technology. Method: The research method applied is action research conducted at Volvo Car Group. The action research is conducted as part of a project redesigning a large project status reporting tool and has been designed to quantify the requirements elicited from the stakeholders of the system. Results: The results is the dashboard selection model which consists of seven dimensions – type of reporting, data acquisition method, type of stakeholders, method of delivery, frequency of updates, aim of the information, and length of data processing (flow). Conclusions: The conclusions show that using this model leads to a rapid identification of the best visualization method for measurement data, which has a cost-saving impact on measurement programs and effect-maximizing impact on the companies.	dashboard;dashboard (business);data acquisition;information visualization;interactivity;requirement;scientific visualization;software development	Miroslaw Staron;Kent Niesel;Wilhelm Meding	2015		10.1007/978-3-319-24285-9_9	simulation;systems engineering;engineering;data mining	SE	-66.17688648559302	12.618665112072748	6563
39aba5c0f2f80ff3cd69ab8244752c4404626304	what makes software architecture-based testing distinguishable	software architecture program testing;specification based testing software architecture based testing;specification based testing;software architecture;program testing;software architecture based testing;software testing system testing life testing automatic testing software architecture software systems assembly systems computer architecture books formal languages	Has software architecture-based testing any characteristic which makes it unique with respect to other testing techniques? This recurrent question will be analyzed in this short paper, providing some initial solution, while leaving ample space for discussion.	recurrent neural network;software architecture	Henry Muccini	2007	2007 Working IEEE/IFIP Conference on Software Architecture (WICSA'07)	10.1109/WICSA.2007.49	non-regression testing;test strategy;keyword-driven testing;reference architecture;software architecture;black-box testing;computer architecture;verification and validation;regression testing;software performance testing;white-box testing;manual testing;system integration testing;integration testing;computer science;engineering;acceptance testing;software reliability testing;software engineering;software construction;software testing;system testing;computer engineering	SE	-63.82730695704782	27.952412006519392	6575
03dbb01858b95eb81629e2804a4710987a781486	explicitly representing expected cost: an alternative to roc representation	roc analysis;cost sensitive learning	"""#"""" $!%& ' ( ) * + -, ./ 0 1 0 2 430 14 5 1' 6 7 +89 :14 + 6 ; 7 0 ( 5< '3>= ?1) @(A7 0 '3 14 5<1' 6 ! ' ( ) * + CBD * > ) * /BD + (@ 8 0 E +50 + + ( ) +F+ G +8 """" $!%H ' ( ) * + -,9I J0 2 G 6 K J0 5 6 ) + 5LA7MN ! * . O '3 B# ( / # B#B# 5 ' @P 0 + F+ +821' 6 ) : + 5Q14 R8? S(J 14 #./ C T ?14J0= /14 6 ; U V 0 I 6 / 5DS(J > ) * ' @D .QBGJ 1) #I 4 O W + T O14 6 ; 'AX 0 W + ' G5 B# 6 7 ' ! R + ( 4Y* D50J 6@ I ' Z. ' X 0 2 6.9 E 0 ( ) + 'A#[ > P"""" $!%Q +1' W ' > 0FD K14 6 ; ' I 1' +B# 2 0 'F B# ( + 0 0 F# 0 W8?J0 \ F O +8V1' 6 ) 7 + 5<14 8? S(J = 1) 'A9 950J 6@# 0 >50J 1' ] S(J0 * ( 9 + V # U 6.9 1' ',9 * .U FCB# 6 W 1 ?S(J0 OJ 5^ _"""" $!%` + * @ 6 2 I ! 5 @: >5 J 1' 5D E !14 6 +1' A Categories and Subject Descriptors M)A a>A bdc e:f g h i]j h?k l:m'nog p lql?h?r p0nsj p(tvu ws 0 F*xzy|{ } ~)Z G  +)}   }>+ )} +0~   {+} General Terms """" $!%d[ * @0 6 ',o%9 6  6 !w+ F"""	component-based software engineering;intermediate representation;like button;microsoft dynamics ax	Chris Drummond;Robert C. Holte	2000		10.1145/347090.347126	computer science;machine learning;pattern recognition;receiver operating characteristic;statistics	ML	-88.91384424565028	28.03298072479843	6703
27e46493d36fd38fee272c835aa0a4eb604e1f18	neue klinische anwendungen der dreidimensionalen rekonstruktion in der echographischen diagnostik	raytracing;image processing;virtual reality;health;image processing software;feature measurement	Die Verwendung der Ultraschalltechnik als bildgebendes Verfahren gehört in den unterschiedlichsten Bereichen der Medizin zur klinischen Routine. In den letzten Jahren sind sowohl bei der Weiterentwicklung der Echoscanner selbst als auch auf der Softwareseite im Bereich der computer-gestützten Auswertung von Ultraschalldaten enorme Fortschritte erzielt worden. Die Ergebnisse der Tätigkeiten im Sonderforschungsbereich 414 “Rechner- und sensorgestützte Chirurgie” sind bedeutsame Beispiele der Fortschritte in der klinischen Anwendung in unterschiedlichen medizinischen Fachrichtungen. Wir zeigen ein Beispiel aus der 3D-Echographie (Diagnose von Knochentumoren und ihren Auswirkungen auf das umgebende Weichgewebe) und zwei Beispiele aus der Echokardiographie (Vermessung von Herzklappenringen und Diagnose von Herzklappeninsuffizienzen durch Volumetrie und Visualisierung). Die echokardiographischen Anwendungen unterscheiden sich dabei hinsichtlich der verwendeten Ultraschallinformation. Während für die Vermessung von Herzklappenringen die morphologische Information aus den Backscatterdaten gewonnen wird, wird bei der Bestimmung von Flußvolumen auf die Dopplerdaten zurückgegriffen. The application of ultrasound has become a standard imaging technique in clinical routine. During the last years enormous technical advances could be achieved concerning the ultrasound scanners as well as the software for computer-aided analysis of image data. In this paper we show some results of the research project “computer and sensor supported surgery” (SFB 414) as examples for the progress of clinical use of ultrasound in different medical fields. One example shows three-dimensional echography (diagnosis of bone tumors and their affect on the surrounding tissue). Two examples belong to the field of echocardiography (assessment of heart valve anuli and diagnosis of mitral regurgitation by volumetric measurements and visualization). The echocardiographic applications mainly differ by the kind of ultrasound data. The assessment of atrioventricular anuli is based on morphological data obtained from backscatter data whereas the measurement of flow volumes is based on Doppler data.	blue (queue management algorithm);computer simulation;eine and zwei;medical ultrasound	Gerald-P. Glombitza;Raffaele De Simone;Ulrich Mende;Matthias Merdes;Robert Krempien;Detlef Zerfowski;Christian-Friedrich Vahl;Hans-Peter Meinzer;Siegfried Hagl	1999	Informatik Forschung und Entwicklung	10.1007/s004500050120	image processing;computer science;health;virtual reality		-107.16449932316996	29.393509973089305	6714
0c1657187e91c31de6d83f763c94ac24142ec9bb	on privacy and utility while improving software quality		Software development produces large amounts of data both from the process, as well as the usage of the software product. Software engineering data science turns this data into actionable insights for improving software quality. However, the processing of this data can raise privacy concerns for organizations, which are obligated by law, regulations and polices, to protect personal and business sensitive data. Early data privacy studies in sub-disciplines of software engineering found that applying privacy algorithms often degraded the usefulness of data. Hence, there is a recognized need for finding a balance between privacy and utility. A survey of data privacy solutions for software engineering data was conducted. Overall, researchers found that a combination of data minimization and obfuscation of data, produced results with high levels of privacy while allowing data to remain useful.	privacy;software quality	Fayola Peters	2017	ECEASST	10.14279/tuj.eceasst.75.1053	theoretical computer science;data mining;software quality;software;minification;software development;information privacy;obfuscation;computer science	Arch	-69.02110386735359	31.317870472216175	6741
7c93a812c4bbf7a7a697333cc9c0910f66b769de	kreuzkatalytische netzwerke als wirtschaftsprinzip		Im Zeitalter explodierender Informationsverfügbarkeit wird ein Zusammenhang zwischen Informationsnutzung und Innovation erkennbar. Neben den konventionellen Organisationsformen der Wirtschaft existieren Netze, die diese Informationsflut hervorragend nutzen können. Kreuzkatalytische Netzwerke (KKN) sind solche Organisationsformen mit ausgezeichneter Innovationskraft. Anhand von Bespielen werden Muster dargestellt und deren Funktionsweise erläutert. Die Entwicklung einer Theorie KKN ist eine der nächsten Arbeiten, die anzugehen ist. Derzeitige Anwendung der KKN-Modelle dient zur Beratung von Wirtschaft und Gesellschaft um eine sozialverträgliche und ökonomisch tragfähige Gesellschaft zu entwickeln. 1 Informationsexplosion Das exponentielle Wachstum von Information eröffnet wirtschaftliche und gesellschaftliche Möglichkeiten neuer effizienter Informationsstrukturen. Wahrgenommen werden Organisationen oder Individuen nur noch, wenn sie als Information verfügbar sind, ansonsten sind sie unsichtbar. Werden diese neuen Möglichkeiten und Netzstrukturen nicht genutzt, wird beispielsweise ein wirtschaftlicher Abstieg unausweichlich oder es kommt zum „Aussterben“ aufgrund vollständiger Rückständigkeit. Ein Kreuzkatalytisches Organisationsprinzip kann erfolgversprechende Lösungskonzepte konstruieren. Die Kombination von Wirtschaft, Wissenschaft und Umweltaspekten über Kreuzkatalytische Netzwerke (KKN) ermöglicht weitreichende Synergien. Die Methode der KKN eröffnet ein Verständnis erfolgversprechender Prinzipien und erlaubt Synergiebildung zu unterstützen. Komplexe Fragestellungen, z.B. zur Nachhaltigkeit und Synergiebildung, lassen sich durch einfache gekoppelte Systemmodelle nicht erklären. Die vielfältigen Verhaltensoptionen können nicht mehr eindeutig aufgeschlüsselt werden.	eine and zwei;gesellschaft für informatik;institut für dokumentologie und editorik;sie (file format);unified model	K.-M. Reiß	2004					-104.10341546270693	33.614514426495006	6748
dc8309d22c6a3af664160200c3e6a3b803484718	minimizing roundtrip response time in distributed databases with vertical fragmentation	computacion informatica;distributed database design;ciencias basicas y experimentales;matematicas;grupo a;vertical fragmentation	Rodolfo A. Pazos R.1, Graciela Vázquez A.2José A. Martı́nez F.3Joaquı́n Pérez O.4 Juan J. Gonzalez B.5 1 Instituto Tecnológico de Cd. Madero, Mexico r pazos r@yahoo.com.mx 2 ESIME, Instituto Politécnico Nacional, Mexico gravazquez@hotmail.com 3 Instituto Tecnológico de Cd. Madero, Mexico jose.mtz@gmail.com 4 Centro Nacional de Investigación y Desarrollo Tecnológico, Mexico jperez@cenidet.edu.mx 5 Instituto Tecnológico de Cd. Madero, Mexico jjgonzalezbarbosa@hotmail.com	distributed database;fragmentation (computing);response time (technology)	Rodolfo A. Pazos Rangel;A. Vázquez GracielaVázquez;José Antonio Martínez Flores;Joaquín Pérez Ortega;Gilberto Martínez-Luna	2014	J. Computational Applied Mathematics	10.1016/j.cam.2013.09.057	distributed database	Theory	-95.50942528314054	15.516220232570285	6879
8dc610690bd1365ccf36897c40fc2dea4134fe57	automatische merkmalsauswahl für neuronale netze mit anwendung in der pixelbezogenen klassifikation von bildern				Ute Matecki	1999				Vision	-102.13726490012432	25.7997585924785	6908
de5b1188a2b910f56660e7ee911527feb4f03ea6	constrained graph drawing	doctoral_thesis	II Teile dieser Arbeit basieren auf Veröffentlichungen, die aus der Zusammenar-beit mit anderen Wissenschaftlerinnen und Wissenschaftlern entstanden sind. Zu allen diesen Inhalten wurden wesentliche Beiträge geleistet. Baumträger haben und ein Algorithmus, um einen solchen effizient zu berechnen, falls er existiert.	graph drawing;unified model	Barbara Pampel	2012			computer science;theoretical computer science;engineering drawing	DB	-106.50970045992261	30.71193577012323	6928
3aacebb25bf077671e590acde42fa15882d4d057	avaliação por imagem tridimensional das características morfológicas e do crescimento do terço médio da face de pacientes com craniossinostose sindrômica submetidos ao avanço frontofacial em monobloco associado à distração osteogênica	anormalidades craniofaciais;tomografia computadorizada por raios x;osteotomia de le fort;craniossinostoses;crescimento;imagem tridimensional		power-on reset	Cristiano Tonello	2016				Vision	-104.8611459418975	20.06940682199963	6956
8ab0d9726d33b01e186db9ee5477e17fa7e6eec0	repräsentation und nutzung von verhaltenswissen in der bildfolgenauswertung				Michael Arens	2004				NLP	-99.60719115190572	26.231691156024002	6957
49b112f6eac4acb104334b4c8401238d1ecc0fc7	editorial zum schwerpunktthema: case - der weg ist das ziel				Rainer Thome	1991	Wirtschaftsinformatik		knowledge management;software engineering;computer science	Crypto	-93.68056259747878	26.240403228447498	7018
18d3d525809da3dbdcc42adf12bdbc1da0c5578e	some new observations about software science indicators for estimating software quality	software quality	Abstract   The paper discusses the problem of estimating implementation time and gives some observations and comparisons between existing methods. Further, it proposes a new simple method for estimating implementation time which takes an account of the level of nesting within programs. The results of experiments show a high degree of agreement between theoretical and observed values for tested programs.	software quality	D. Davcev	1984	Inf. Process. Manage.	10.1016/0306-4573(84)90056-6	simulation;computer science;data mining;management science;software quality	SE	-66.45308236724165	31.245904789255857	7035
5cd2dc7cb36c0de65f8b27a66c447ebef81644c5	smart metering und eu-datenschutzrecht		Am 4. April 2011 hat die Artikel-29-Datenschutz-Gruppe eine Stellungnahme zu Datenschutz und Smart Metering angenommen. Ziel der Stellungnahme ist es, den anwendbaren EU-Datenschutzrechtsrahmen für die Smart Metering-Technologie im Energiesektor darzustellen.	eine and zwei;smart meter	Jörg Hladjk	2011	Datenschutz und Datensicherheit - DuD	10.1007/s11623-011-0136-5	computer security;internet privacy;metering mode;computer science	Vision	-102.78240624096627	37.072519678811446	7040
037996ef796c2915563bb46bf19829d04ca30636	economic impact of iot cyber risk - analysing past and present to predict the future developments in iot risk analysis and iot cyber insurance		This paper is focused on mapping the current evolution of Internet of Things (IoT) and its associated cyber risks for the Industry 4.0 (I4.0) sector. We report the results of a qualitative empirical study that correlates academic literature with 14 I4.0 frameworks and initiatives. We apply the grounded theory approach to synthesise the findings from our literature review, to compare the cyber security frameworks and cyber security quantitative impact assessment models, with the world leading I4.0 technological trends. From the findings, we build a new impact assessment model of IoT cyber risk in Industry 4.0. We therefore advance the efforts of integrating standards and governance into Industry 4.0 and offer a better understanding of economics impact assessment models for I4.0.	computer security;industry 4.0;internet of things	Petar Radanliev	2018	CoRR	10.1049/cp.2018.0003	empirical research;knowledge management;impact assessment;grounded theory;computer science;cyber-insurance;risk analysis (business);economic impact analysis;corporate governance;internet of things	Security	-78.47480698407375	7.757152930380739	7087
2532fdf74e05d421e19480c599604e9aa8979bf3	caractérisation des images stationnaires par des modèles non gaussiens bidimensionnels à moyenne ajustée	metodo cuadrado menor;autocorrelacion;modelizacion;methode moindre carre;image processing;least squares method;simulation;modele lineaire;procesamiento imagen;senal estacionaria;simulacion;least square method;modelo lineal;signal stationnaire;traitement image;statistical model;modelisation;modelo 2 dimensiones;linear model;modele statistique;modele 2 dimensions;moving average processes;processus moyenne mobile;modelo estadistico;cumulant;modeling;two dimensional model;cumulante;autocorrelation;stationary signal	Dans cet article on developpe quatre methodes lineaires des moindres carres consacrees a ľidentification des signaux non gaussiens bidimensionnels (2-D) a moyenne ajustee (ma), eventuellement a phase non minimale (pnm), ainsi qu’une relation liant ľautocorrelation et les cumulants. Ľune des methodes est fondee uniquement sur les cumulants tandis que les autres exploitent a la fois les autocorrelations et les cumulants ďordre m (m > 2). Ces methodes sont non surparametrisees et non restreintes aux cas ou les deux coefficients extremes b(qp q2) et b(0,0) du modele ma, ďordre (q1, q2), sont non nuls. La relation presentee et trois methodes parmi les quatre proposees derivent de la transformation de ľequation non lineaire de Brillinger et Rosenblatt en relations lineaires grâce a la solution explicite de Tugnait (formule modifiee de la version 2-D de ľalgorithme ‘C(q, k)’ de Giannakis). Une generalisation a ľordre m de la version 2-D de la methode classique de Giannakis-Mendel est aussi presentee. Et par des simulations sur deux tailles du meme signal ma 2-D synthetique, en ľabsence et en presence de bruit, on evalue les performances des methodes developpees et de la solution explicite de Tugnait en les comparant, puis on teste la relation proposee sous un environnement bruite, et on termine par une application a la caracterisation ďune image reelle homogene texturee par un modele ma 2-D que nous identifierons dans le cas bruite et non bruite.	triple des	M'hamed Bakrim;Driss Aboutajdine	2001	Annales des Télécommunications	10.1007/BF03008830	image processing;mathematics;least squares;statistics	Crypto	-105.9807328796602	16.53629498740207	7096
636f966d1c2f0fb03d36616d8af7ac3e021fb1fa	pädagogische ergonomie oder: beim sitzen kommt es nicht nur auf die haltung an				Torsten Otto	2004	LOG IN		engineering;multimedia;performance art	Logic	-102.81174425480445	26.841336271269768	7113
6a98285396dc1eb1356df06d5978ef59c2f76fa5	the antecedents of transaction costs in digital ecosystems: a configurational view on the interplay of app architecture and platform governance	business studies;fsqca;cloud;conference paper;other research area;information management;platform governance;transaction cost theory;complementor	The locus of value creation and innovation in the software industry is shifting more and more to platform ecosystems on which numerous developers create extensions with additional functionalities based on the platforms core architecture. While such complementors may strongly profit from platforms, there are considerable costs. Recent studies therefore examined the costs of fitting apps to the specifications of certain platforms; however, these works largely neglect costs arising from the transactional relationship between platform and complementor. In order to shed light on this, our work examines how design choices of platform governance and app architecture impact the emergence of four types of cost-inducing hazards within the transactional context of the ecosystem. By using a configurational approach based on fuzzy-set qualitative comparative analysis (FsQCA), we display complex interactional effects of the causal conditions on complementors’ perception of hazardous environments and thus provide valuable insights for both practice and theory on platform ecosystems.		Dominik Dellermann;Fabian Reck	2017			transaction cost;simulation;cloud computing;computer science;environmental resource management;artificial intelligence;marketing;operations management;operating system;software engineering;database;information management;management;world wide web;business studies	Web+IR	-77.77866185963988	6.018926289318671	7119
f29c142879e32823db9d4af4266e60ff0e4f3dbf	a taxonomy of evaluation approaches in software engineering	classification;software engineering;taxonomy;evaluation	As in any academic discipline, the evaluation of proposed methodologies and techniques is of vital importance for assessing the validity of novel ideas or findings in Software Engineering. Over the years, a large number of evaluation approaches have been employed, some of them drawn from other domains and other particularly developed for the needs of software engineering related research. In this paper we present the results of a survey of evaluation techniques that have been utilized in research papers that appeared in three leading software engineering journal and propose a taxonomy of evaluation approaches which might be helpful towards the organization of knowledge regarding the different strategies for the validation of research outcomes. The applicability of the proposed taxonomy has been evaluated by classifying the articles retrieved from ICSE'2012.	categorization;cellular automaton;software engineering;taxonomy (general)	Alexander Chatzigeorgiou;Theodoros Chaikalis;Georgia Paschalidou;Nikos Vesyropoulos;Christos K. Georgiadis;Emmanouil Stiakakis	2015		10.1145/2801081.2801084	software engineering process group;biological classification;computer science;evaluation;data mining;management science;taxonomy	SE	-71.11587669051225	22.582502205634515	7122
0a2c887799a7d6bcc273771aa87b63f1090eca26	open source-style collaborative development practices in commercial projects using github		Researchers are currently drawn to study projects hosted on GitHub due to its popularity, ease of obtaining data, and its distinctive built-in social features. GitHub has been found to create a transparent development environment, which together with a pull request-based workflow, provides a lightweight mechanism for committing, reviewing and managing code changes. These features impact how GitHub is used and the benefits it provides to teams' development and collaboration. While most of the evidence we have is from GitHub's use in open source software (oss) projects, GitHub is also used in an increasing number of commercial projects. It is unknown how GitHub supports these projects given that GitHub's workflow model does not intuitively fit the commercial development way of working. In this paper, we report findings from an online survey and interviews with GitHub users on how GitHub is used for collaboration in commercial projects. We found that many commercial projects adopted practices that are more typical of oss projects including reduced communication, more independent work, and self-organization. We discuss how GitHub's transparency and popular workflow can promote open collaboration, allowing organizations to increase code reuse and promote knowledge sharing across their teams.	code reuse;distributed version control;open collaboration;open-source software;self-organization	Eirini Kalliamvakou;Daniela E. Damian;Kelly Blincoe;Leif Singer;Daniel M. Germán	2015	2015 IEEE/ACM 37th IEEE International Conference on Software Engineering		workflow;interview;computer science;systems engineering;organization;engineering;knowledge management;software design;software engineering;collective intelligence;management;writing;world wide web;crowdsourcing;collaborative software;encoding;collaboration	SE	-74.05307285870396	21.622484823969234	7134
f0a4c6cdfb43af3d6a983be71b3e5cf246b09efc	is internal capital market of china listed companies efficient? - empirical evidences from listed companies which have multiple divisions in h-stock	cash flow-sensitivity based on roa;evaluation method;internal capital market efficiency	In theory, when external capital market is not efficiency, groups can allocate resource efficiently through internal capital market. In this paper, we studied of listed companies which have multiple divisions in Hstock, used Cash Flow-Sensitivity Based on ROA to validate internal capital market efficiency of large samples. Results display that, on the whole, internal capital market of listed companies is efficiency, and the greater part of listed companies can continually allocate resource efficiently through internal capital market, part of listed companies have excellent capacity to “pick winner”. This paper is the first literature which employs listed companies as large samples to evaluate internal capital market efficiency directly, which would make research results more reliable and more representative. It would provide evidences for developing groups in our country and lay the foundation of further research in theory and method.	coefficient;corporate governance;enterprise information system;information systems;resource-oriented architecture	Fengjuan Wang;Zhihua Xie	2011			finance;financial system;business	ML	-84.78703524361939	6.479458570202004	7137
bef6e26c6404ac11b2a3aa62b1c6407a597f44d9	determinants of usage variations of business intelligence & analytics in organizations - an empirical analysis		While Business Intelligence & Analytics (BIA) applications are increasingly being adopted into business, significant variation exists in using them to empower business activities and there is limited empirical research examining the drivers of extensive usage of BIA in organizations. Building on TechnologicalOrganizational-Environmental framework, we present and empirically test a conceptual model of factors associated with the extent of BIA usage. We find that sophistication of data-related infrastructure in firms drives usage while data management challenges hamper the usage extent. Further, we find that large organizations have a higher propensity to use BIA in business functions while managerial challenges related to integration and talent management prevent extensive usage. Finally, we find that industry competitive intensity influences usage extent. Drawing on a large sample, this study highlights the antecedents of BIA usage and can help researchers and practitioners to understand what factors can enable firms to use BIA	business continuity planning	Suresh Malladi;Mayuram S. Krishnan	2013				HCI	-80.22516871341628	4.847425573029275	7151
8432d368ecc7d68e40ee58475cb3257225f7f9bf	an alias method for sampling from the normal distribution	normal distribution;echantillonnage;simulation;simulacion;curva gauss;random number;sampling;loi normale;nombre aleatoire;muestreo;random numbers;numero aleatorio;gaussian distribution	The most efficint algorithms for sampling from the standard normal distribution require long lists of constants. The size of these tables grows with the employed precision. By adapting A.J. Walker's “alias method” to the normal distribution a sampling procedure is developed which needs only three fixed tables of 128 bytes each. The new method is as fast as its competitors and easier to implement. Die effizientesten Algorithmen für Stichproben von der Standardnormalverteilung benötigen lange Listen von Konstanten. Die Größe dieser Tafeln wächst mit der verwendeten Präzision. Durch eine Anpassung der “Aliasmethode” von A.J. Walker an die Normalverteilung wird eine Stichprobenprozedur entwicklet, die nur drei feste Tafeln von je 128 Bytes braucht. Die neue Methode ist ebenso schnell wie ihre Konkurrenten und leichter zu implementieren.	algorithm;alias method;amiga walker;byte;eine and zwei;internet explorer;sampling (signal processing)	Joachim H. Ahrens;Ulrich Dieter	1989	Computing	10.1007/BF02239745	normal distribution;combinatorics;calculus;inverse transform sampling;mathematics;statistics	DB	-97.22792576910415	37.112670181534284	7157
8e38c407dd194904bf6de7406f30b31d53c9d476	algorithmes d'approximation pour l'optimisation en ligne d'ordonnancements et de structures de communications. (approximation algorithms for on-line optimization of scheduling and communication structures)			approximation algorithm;mathematical optimization;online and offline;scheduling (computing)	Nicolas Thibault	2006				Theory	-102.08028986183196	14.79161547010342	7159
3f93182da349ce8370d0fc22251de2817600e1fc	conception cognitive de plan de site correlee a la connaissance prealable des lecteurs pour la recherche d'informations sur le web	navigation;visualization;navigation visualization	L'efficacité du Web est un catalyseur important de la croissance du média électronique. Le but de nos efforts est d'examiner l'influence de la conception et de la structure de plan de site, en regard de la connaissance préalable des lecteurs quant au sujet traité. Cette influence est évaluée sur la base de l'exactitude de sa compréhension, la vitesse et la qualité de navigation ainsi que la fixation en mémoire pour rappel. Nous avons supposé que la représentation cognitive du contenu de plan de site peut aider des étudiants de faible niveau de connaissance préalable à organiser leur représentation. Les pages Web sont réparties en deux types différant par la structure des pages d'accueil (cognitive ou non-cognitive). Les sujets sont également répartis en deux catégories (étudiants à haut niveau de connaissance ou à faible niveau de connaissance préalable). Trente deux sujets volontaires ont réalisé en 4 groupes une série de plusieurs tâches (questionnaire d'évaluation des connaissances préalables, première navigation libre, premier rappel des titres de page d'accueil, deuxième navigation pour la recherche d'informations par questionnaire, deuxième rappel des titres de page d'accueil, évaluation du site par le sujet à l'aide d'un questionnaire). La structure de page d'accueil et la connaissance préalable des sujets étaient contrôlées.	les trophées du libre;linear algebra	Kashif Hussain;Sylvie Leleu-Merviel;Shazia Yasin Mughal	2006	2006 Canadian Conference on Electrical and Computer Engineering	10.1109/CCECE.2006.277400	navigation;visualization;computer science	Comp.	-107.31363397427882	14.794630182819517	7165
30d96812623f35580ba4e7b36d34dddf41d616ec	entry barrier's difference between ict and non-ict industries	ict market;information technology;bass diffusion model;innovation;entry barrier	Purpose – Given the increasingly saturated information and communication technology (ICT) market and the intensification of competition among ICT firms, there is a need for a better understanding of entry barriers in the ICT market. The purpose of this paper is to examine the overall characteristics of these entry barriers and identify firms' strategies for achieving market dominance.Design/methodology/approach – The authors examined the overall characteristics of these entry barriers and identified firms' strategies for achieving market dominance by tracking the actual patterns of firms' ICT market entry based on the Bass diffusion model.Findings – The results indicate that the saturation of the ICT market reduced entry barriers, which strengthened the imitation effect. In addition, entry barriers were lower for ICT firms than for non‐ICT ones. Furthermore, entry barriers were higher for the manufacturing sector than for the service sector, indicating that the innovation effect was stronger for the manuf...		Changgyu Yang;Sang-Gun Lee;Jaebeom Lee	2013	Industrial Management and Data Systems	10.1108/02635571311312712	barriers to entry;innovation;economics;marketing;law;information technology;commerce	DB	-83.01865272661796	5.651682344234664	7170
1e56f94ec99175b8c412d89d6bc4e9e53de888bc	a hybrid approach to assessing data quality		Various techniques have been proposed to enable organizations to initiate procedures to assess and ultimately to improve the quality of their data. The utility of these assessment techniques (ATs) has been demonstrated in different organizational contexts. However, while some of the ATs are geared towards specific application areas and are often not suitable in different applications, others are more general and therefore do not always meet specific requirements. To address this problem we propose the Hybrid Approach to assessing data quality, which can generate usable ATs for specific requirements using the activities of existing ATs. A literature review and bottom-up analysis of the existing data quality (DQ) ATs was used to identify the different activities proposed by each AT. Based on example requirements from an asset management organization, the activities were combined using the Hybrid Approach in order to generate an AT which can be followed to assess an existing DQ problem. The Hybrid Approach demonstrates that it is possible to develop new ways of assessing DQ which leverage the best practices proposed by existing ATs by combining the activities dynamically.	best practice;bottom-up proteomics;data quality;requirement	Philip Woodall;Ajith Kumar Parlikad	2010			data mining;computer science;data quality	SE	-67.11260018310082	14.1851512117634	7184
ca0ec45dfa5080008cee879cf781dc8f4c463883	quantified ux: towards a common organizational understanding of user experience	interdisciplinary teams;user experience;evaluation	User Experience (UX) is increasingly being recognized as an important factor for the commercial success of digital products. In fact, it has become a buzzword, which is interpreted differently by different parties. This lack of common understanding inevitably leads to misunderstandings and inefficiency in industrial practice. We therefore propose a quantifiable way of describing User Experience (QUX). Based on the analysis of 84 UX evaluation methods, a sample of UX characteristics from literature, and 24 interviews with experts from academia and practice, we propose a formalism and a corresponding tool to measure, visualize, and communicate a product's UX within organizations. We showcase the benefits of our approach by integrating it into the product development processes of companies from three different industries.	a/ux;new product development;pc-ux;semantics (computer science);usability;user experience	Florian Lachner;Philipp Naegelein;Robert Kowalski;Martin Spann;Andreas Butz	2016		10.1145/2971485.2971501	user experience design;human–computer interaction;computer science;knowledge management;evaluation;management	HCI	-74.38131644915246	13.23389439809942	7230
188a7ae0b0985500733d3e0bf8fd1fa8556fbda2	g&d entwickelt kams für die zweite generation der deutschen gesundheitskarte		der Online-Werbung oder der Marktforschung erfasst und ausgewertet und zu individuellen Nutzungs-, Kaufoder Bewegungsprofilen verdichtet. Je mehr das Internet im Alltag genutzt wird, desto mehr Datenspuren liefern Hinweise auf Interessen, Vorlieben und Verhaltensweisen der Nutzerinnen und Nutzer. Den digitalen Augen und Ohren im Internet nicht alles preiszugeben, ist das legitime Recht aller Nutzer“, so Wagner. „Die Globalität des Internet macht es häufig jedoch schwer, dies einzufordern. Wer nicht will, dass seine Daten Neugier und Sammelwut preisgegeben sind, sollte digitale Vorsorge treffen“ so der Datenschutzbeauftragte. Zwar bringe es die digitale Lebenswelt mit sich, dass man nicht immer und vollständig anonym bleiben könne; darin gleiche sie letztlich dem analogen Alltag. Hier wie dort wechsele man zwischen notwendiger Preisgabe persönlicher Daten und berechtigtem Verschweigen. Welche Möglichkeiten bestehen, Datenspuren im Internet zu vermeiden, wie Inhalte bei E-Mail und Online-Speichern durch Verschlüsselung geschützt werden können oder wie die penetrante Dateninkontinenz von Smartphones unterbunden werden kann, erläutert der Landesbeauftragte für den Datenschutz auf seinem Internet-Angebot zum Selbstdatenschutz: http://www.datenschutz. rlp.de/de/selbstds.php	die (integrated circuit);internet explorer;sie (file format);smartphone;triple des;word error rate	Wagner;Informationen Zu Publikati-Onen	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0281-0		OS	-104.70763420764051	36.95155959622542	7251
bd1b2f6ff011b3bd587991d1d50d209811f1be74	effizienz und effektivität im gesundheitswesen: d. beitr. d. allg. systemtheorie für d. methode ihrer ermittlung u. beurteilung				Michael Klausing	1981				NLP	-103.17613527248183	22.671054918010377	7282
52a9d184a0b3b03ce4e6903009434dc70b00a23a	20èmes journées bases de données avancées, bda '04, montpellier, france, 19 - 22 octobre 2004, actes (informal proceedings)			bibliothèque de l'école des chartes;broadcast driver architecture		2004				HPC	-99.0538526460695	17.431689154135412	7299
f9b125a264cfd7ccdf285d18562b26a2ac9f800e	cost model for digital preservation: cost of digital migration		The Danish Ministry of Culture has funded a project to set up a model for costing preservation of digital materials held by national cultural heritage institutions. The overall objective of the project was to increase cost effectiveness of digital preservation activities and to provide a basis for comparing and estimating future cost requirements for digital preservation. In this study we describe an activity-based costing methodology for digital preservation based on the Open Archice Information System (OAIS) Reference Model. Within this framework, which we denote the Cost Model for Digital Preservation (CMDP), the focus is on costing the functional entity Preservation Planning from the OAIS and digital migration activities. In order to estimate these costs we have identified cost-critical activities by analysing the functions in the OAIS model and the flows between them. The analysis has been supplemented with findings from the literature, and our own knowledge and experience. The identified cost-critical activities have subsequently been deconstructed into measurable components, cost dependencies have been examined, and the resulting equations expressed in a spreadsheet. Currently the model can calculate the cost of different migration scenarios for a series of preservation formats for text, images, sound, video, geodata, and spreadsheets. In order to verify the model it has been tested on cost data from two different migration projects at the Danish National Archives (DNA). The study found that the OAIS model provides a sound overall framework for the cost breakdown, but that some functions need additional detailing in order to cost activities accurately. Running the two sets of empirical data showed among other things that the model underestimates the cost of manpower-intensive migration projects, while it reinstates an often underestimated cost, which is the cost of developing migration software. The model has proven useful for estimating the costs of preservation planning and digital migrations. However, more work is needed to refine the existing equations and include the other functional entities of the OAIS model. Also the user-friendliness of the spreadsheet tool must be improved in future versions of the model. The CMDP is presently closing its second phase, where it has been extended to include the OAIS Functional Entity Ingest. This has also enabled us to adjust the theoretical model further, especially regarding the accuracy and precision of the model and in relation to the underlying parameters used in the equations, such as migration frequency and format complexity. Understanding the nature of digital preservation cost is prerequisite for increasing the overall efficiency, and achieving first quality for preservation of cultural heritage materials.		Ulla Bøgvad Kejser;Anders Bo Nielsen;Alex Thirifays	2011	IJDC	10.2218/ijdc.v6i1.186	simulation;computer science;data mining;database;world wide web	EDA	-69.03764954740933	14.515226690986365	7309
2089a194b734f7519d3648ae69e681d1878fc470	prioritizing software anomalies with software metrics and architecture blueprints	software metrics;god class;mobile communication;media;computer architecture;surgery;software architecture	According to recent studies, architecture degradation is to a large extent a consequence of the introduction of code anomalies as the system evolves. Many approaches have been proposed for detecting code anomalies, but none of them has been efficient on prioritizing code anomalies that represent real problems in the architecture design. In this sense, our work aims to investigate whether the prioritization of instances of three types of classical code anomalies, Divergent Change, God Class and Shotgun Surgery, can be improved when supported by architecture blueprints. These blueprints are informal models often available in software projects, and they are used to capture key architecture decisions. Moreover, we are also investigating what information may be useful in the design blueprints to help developers on prioritizing the most critical software anomalies. In many cases, developers indicated that it would be interesting the insertion of additional information on the blueprints in order to detect architecturally-relevant anomalies.	blueprint;elegant degradation;god object;sensor;shotgun surgery;software bug;software metric	Everton T. Guimarães;Alessandro F. Garcia;Eduardo Figueiredo;Yuanfang Cai	2013	2013 5th International Workshop on Modeling in Software Engineering (MiSE)		reliability engineering;reference architecture;software visualization;software architecture;architecture tradeoff analysis method;verification and validation;architectural pattern;computer science;systems engineering;package development process;software design;software framework;software development;software design description;software engineering;software construction;software architecture description;software walkthrough;resource-oriented architecture;software deployment;software quality;software system;software peer review	SE	-63.7461602291715	34.21310195369697	7379
936b9da33aa3303dae537730fdd7e2d81662fe24	objektive und subjektive biodiversität städtischer parks				Angela Hof;Alexander Keul	2017	AGIT Journal	10.14627/537633040		Vision	-95.5893529713673	22.15868262331666	7392
72eb3fc98a9bfcc9b0b6ff63b2c2d3c20c1d690e	benefits and applications of cross-pollination - guest editors' introduction	reliability engineering;project management;design engineering;application software;construction industry;computer industry;software engineering;technology transfer;acoustical engineering;software engineering application software reliability engineering acoustical engineering computer industry technology transfer design engineering construction industry project management solids;solids	0 7 4 0 7 4 5 9 / 0 0 / $ 1 0 . 0 0 © 2 0 0 0 I E E E The speed of this evolution is both a challenge and a risk. It’s wonderful to see so many new and never imagined applications, but three decades after the discipline’s emergence, our society heavily depends on software technology. The public and the discipline’s practitioners dramatically underestimated a software product’s lifetime. For example, no one budgeted for Y2K corrections, and the complete cost—probably exceeding tens of billions of dollars—is yet to be calculated. We rely on software without knowing it’s impacts. Occasionally, we stumble across a blue screen when we do not expect it and recognize loopholes that weaken our security. If we drive a car or fly in a plane. We accept that there are certain risks that have been calculated before, allowing us to consciously decide. Software is embedded and hidden from daily life, and in most cases, nobody completely assessed its impacts.	consciousness;embedded system;emergence;emoticon;year 2000 problem	Tomoo Matsubara;Christof Ebert	2000	IEEE Software	10.1109/MS.2000.819964	project management;computing;application software;mechanical engineering technology;mechatronics;acoustical engineering;computer science;systems engineering;engineering;methods engineering;social software engineering;civil engineering;civil engineering software;railway engineering;software engineering;solid;computer-aided engineering;requirements engineering;production engineering;computer engineering;mechanical engineering	ML	-69.19228991811113	26.932656501167333	7395
e0ff08eaaaa0dc3033d0d1b00e21640838294cf4	editorial: the software engineering association	software engineering		software engineering	Keith H. Bennett	1999	IEE Proceedings - Software		personal software process;computer science;social software engineering;software development;civil engineering software;software engineering;software construction;software requirements;computer engineering;software peer review	SE	-63.54651114807328	25.205276303457754	7398
0589fcb4d3815af2d60c98ddc4c3963128786ae0	ein beitrag zur automatisierung von prüfprozeduren mit einem rechnergesteuerten system und problemorientierter formulierung der prüfaufgabe in cma			cma-es	Udo Schlossarek	1993				Robotics	-100.40461283708831	24.447311222479446	7487
13243167691d7a7cab8a24d00f65e32dc764513b	empirical software engineering research - the good, the bad, the ugly	computers;empirical study;software systems;empirical software engineering;testing;software engineering testing software systems communities computers production;software engineering;validating experiments;adoption of research software engineering empirical studies validating experiments;engineering and technology;teknik och teknologier;adoption of research;community computing;datavetenskap;production;empirical studies;computer science;communities;knowledge state software engineering research community ideas validation	"""The Software Engineering Research community has slowly recognized that empirical studies are an important way of validating ideas and increasingly our community has stopped accepting the sufficiency of arguing that a smart person has come up with the idea and therefore it must be good. This has led to a flood of Software Engineering papers that contain at least some form of empirical study. However, not all empirical studies are created equal, and many may not even provide any useful information or value. We survey the gradual shift from essentially no empirical studies, to a small number of ones of questionable value, and look at what we need to do to insure that our empirical studies really contribute to the state of knowledge in the field. Thus we have the good, the bad, and the ugly. What are we as a community doing correctly? What are we doing less well than we should be because we either don't have the necessary artifacts or because the time and resources required to do """"the good"""" is perceived to be too great? And where are we missing the boat entirely in terms of not addressing critical questions and often not even recognizing that these questions are central even if we don't know the answers. We look to see whether we can find some commonality in the projects that have really made the transition from research to widespread practice to see whether we can identify some common themes."""	artifact (software development);experimental software engineering;shift jis	Elaine J. Weyuker	2011	2011 International Symposium on Empirical Software Engineering and Measurement	10.1109/ESEM.2011.66	computer science;systems engineering;engineering;knowledge management;software engineering;management science;empirical research;management	SE	-70.12255774551775	25.362356825976672	7554
17da4743ccbf1449b0070b620d7492d0e15f4d89	ein objektorientiertes konzept zur modellierung und simulation komplexer systeme			simulation	Carsten Thomas	1996				EDA	-103.35278830824552	23.449443975639984	7555
7014d0734c349f63be18bf9b34f3e5cba939dc30	webservices für die verrechnung in wertschöpfungsnetzwerken auf basis vollständiger finanzpläne		Kurzfassung Das Angebot von integrierten Bündeln aus Sachund Dienstleistungen im Rahmen so genannter Hybrider Wertschöpfungsnetzwerke stellt neue Anforderungen an die Informationssysteme der beteiligten Partner. Daten und Prozesse sind zu integrieren, um die Lösungen effektiv anbieten zu können. Die Verrechnung ist eine Teilaufgabe der Netzwerkkoordination. Gegenstand ist die Planung, Durchführung und Kontrolle von Zahlungsströmen zwischen den Partnern und gegenüber dem Endkunden. Der Beitrag untersucht, welche Webservices im Rahmen einer Serviceorientierten Architektur bereitgestellt werden sollten, um die Verrechnung für Hybride Wertschöpfung zu unterstützen. Dazu wird analysiert, welche Daten durch die Informationssysteme der Netzwerkpartner verfügbar gemacht werden müssen. Entwicklungsmöglichkeiten für zusätzliche betriebswirtschaftliche Funktionalität zur Unterstützung des Verrechnungsprozesses werden aufgezeigt.	eine and zwei;gesellschaft für informatik;unified model;web service	Jörg Becker;Ralf Knackstedt;Martin Matzner	2009			database;data mining;web service;computer science		-102.6104301497654	34.416990371700905	7559
59406ef268a74dd5a0a5fba59d80e8ca5ad63356	halbgott computer - die fantastische realität der 70er jahre				James B. Martin;Adrian R. Norman	1972				Vision	-95.702378415573	21.713883614870447	7588
8c9c6f72c9a5741c4ed38a6c26b84bfe853f6fd8	der eugh stärkt den zusammenhalt in der europäischen union		Das unbedingte Bekenntnis zu Europa, zur europäischen Idee der gemeinsamen Werte und Ziele als Absage an Krieg und Menschenrechtsverletzungen waren die Beweggründe für die Gründung der Europäischen Union. Heute überwiegt die Unsicherheit über die Zukunft Europas. Umso mehr Bedeutung kommt dem Gerichtshof der Europäischen Union als Anker und Bewahrer europäischer Grundrechte zu, um Europa wieder als Wertegemeinschaft und als Raum der Freiheit, der Sicherheit und des Rechts wahrnehmbar zu machen.	borderlands 2;europa;unified model	Sabine Leutheusser-Schnarrenberger	2016	Datenschutz und Datensicherheit - DuD	10.1007/s11623-016-0612-z	computer science;internet privacy;performance art	OS	-103.50459664641754	35.93229286300463	7604
f8beebdadaa2caac448bf0a799c7d3a5d5818329	how do developers react to api deprecation?: the case of a smalltalk ecosystem	mining software repositories;ecosystems;empirical studies	When the Application Programming Interface (API) of a framework or library changes, its clients must be adapted. This change propagation---known as a ripple effect---is a problem that has garnered interest: several approaches have been proposed in the literature to react to these changes.  Although studies of ripple effects exist at the single system level, no study has been performed on the actual extent and impact of these API changes in practice, on an entire software ecosystem associated with a community of developers. This paper reports on an empirical study of API deprecations that led to ripple effects across an entire ecosystem. Our case study subject is the development community gravitating around the Squeak and Pharo software ecosystems: seven years of evolution, more than 3,000 contributors, and more than 2,600 distinct systems. We analyzed 577 methods and 186 classes that were deprecated, and answer research questions regarding the frequency, magnitude, duration, adaptation, and consistency of the ripple effects triggered by API changes.	application programming interface;deprecation;pharo;ripple effect;smalltalk;software ecosystem;software propagation;squeak	Romain Robbes;Mircea Lungu;David Röthlisberger	2012		10.1145/2393596.2393662	ecosystem;simulation;systems engineering;engineering;software engineering;empirical research;world wide web	SE	-65.46325696533279	33.97568589420055	7608
5a1ed3d7bcd9b67361ec20a40cd241efc7ee9211	key performance indicators for the evaluation of rfid-enabled b-to-b e-commerce applications: the case of a five-layer supply chain	key performance indicator;relationship management;rfid technology;e commerce;research design;data collection;performance;supply chain performance;performance improvement;era2012;supply chain	This paper attempts to track key performance indicators in order to assess the impacts of RFID technology in a five layer supply chain in the utility sector. Findings point to some performance improvements especially when RFID enables more integrated and more collaborative B-to-B e-commerce solutions. The research design involves multiple units and levels of analysis, and relies on diverse data collection methods and generates a vast amount of data. The concept of a living laboratory proved to be an insightful approach for exploring issues related to inter-company connectedness and relationship management.	e-commerce	Ygal Bendavid;Élisabeth Lefebvre;Louis A. Lefebvre;Samuel Fosso Wamba	2009	Inf. Syst. E-Business Management	10.1007/s10257-008-0092-2	e-commerce;customer relationship management;supply chain management;economics;performance;service management;computer science;systems engineering;engineering;marketing;operations management;performance indicator;supply chain;data collection	DB	-78.92010191405733	6.315157597929863	7619
13f39c056bc086ad05cb3ab8ece7d7c155b37324	challenges for emerging art forms under the visual artists rights act		INTRODUCTION ................................................................................ 431 I. THE MORAL RIGHTS DEBATE .................................................... 432 A. The Origins of Moral Rights .................................................. 432 B. The Berne Convention ........................................................... 434 C. The Limited Scope of Moral Rights in the U.S. ..................... 436 II. EMERGING MEDIUMS: PROBLEMS OF FUNCTION AND TASTE ....................................................................................... 438 A. Photography .......................................................................... 438 B. Public Art ............................................................................... 439 III. SITE-RESPONSIVE ART: CURRENT ISSUES IN VARA APPLICATION ......................................................................... 441 A. An Overview of Site-Responsive Art ..................................... 441 B. The Andy Monument ............................................................. 443 C. “Recognized Stature” and Limits on Emerging Mediums .... 444 D. A Proposed Solution for VARA Application to Emerging Mediums .............................................................................. 445 CONCLUSION ..................................................................................... 448	bibliothèque des ecoles françaises d'athènes et de rome;failure;hgnc;human height	Martina Hinojosa	2013	JTHTL		humanities;art;visual artists rights act	AI	-92.92039125107807	22.07927209875659	7630
a97506e8a6b7e63ecec85aa03784f93346cb629c	lwa 2009		Die Workshop-Woche „Lernen, Wissen und Adaptivität“ (LWA) wird in diesem Jahr vom 21.-23. September 2009 an der Technischen Universität Darmstadt stattfinden. Wie schon in den Jahren zuvor werden im Rahmen der LWA von verschiedenen Fachgruppen der Gesellschaft für Informatik eine Reihe interessanter Workshops organisiert, die einen Einblick in aktuelle Trends, Technologien und Anwendungen geben. Die LWA versteht sich als Forum, bei dem etablierte und neu auf einem Gebiet arbeitende Wissenschaftler miteinander diskutieren, was den besonderen Reiz dieser Veranstaltung ausmacht. Aus diesem Grund möchten wir, neben Vertretern aus Hochschule, Forschungsinstituten und Wirtschaft, insbesondere junge Forscher und Studierende einladen, ihre Beiträge bei den entsprechenden Workshops einzureichen. Die Teilnahmegebühren werden sehr günstig im unteren zweistelligen Bereich liegen. Die folgenden Workshops werden von den einzelnen Fachgruppen veranstaltet.	die (integrated circuit);eine and zwei;gesellschaft für informatik;internet explorer	Frederik Janssen;Melanie Hartmann	2009	KI			AI	-103.58953532940653	34.84035011830357	7634
3306dabd7666408a99119cd058ccbe51d7205315	theoretisch-methodische grundlagen zur rechnergestützten optimalen planung von produktion und ressourceneinsatz in industriebetrieben, dargestellt am beispiel von polygrafischen und verpackungsmittelherstellenden betrieben				Winfried Brecht	1984				NLP	-101.68050368044123	26.34540018968282	7700
cdc5777905429ff2abe2388a34f04217710ad092	information policies of developing countries: the case of brazil	information policy;troca de informacoes;developing country;brasil	Presenta el caso del Brasil como ejemplo ilustrativo de los problemas que encaran quienes deciden la politica de informacion en un pais en desarrollo. Se refiere al nacionalismo como respuesta frente a la invasion de elementos culturales extranjeros y que en el sector informacion se traduce en la creacion de barreras en el flujo de informacion. Trata sobre el desarrollo y las restricciones de la industria de la computacion en el Brasil y compara su politica con otros paises industrializados		Victor Rosenberg	1982	JASIS	10.1002/asi.4630330403	developing country	NLP	-106.6065190875464	17.580966254483165	7743
4e5d000ae30acf642814daf581e33be9ad075d00	détection de mots clés et d'expressions régulières en vue de la reconnaissance d'entités nommées dans des documents manuscrits. (keyword detection and regular expression spotting for named entity recognition in handwritten documents)			bibliothèque des ecoles françaises d'athènes et de rome;linear algebra;named entity;named-entity recognition;regular expression;vue	Gautier Bideault	2015				ML	-106.97246727828043	12.993422228519721	7754
c40a8f92c0f68f27c14740bb047f1fb62b51085f	motivation-oriented architecture modelling for e-healthcare prosumption		The enterprise architecture (EA) is a coherent and consistent set of principles and rules that guide system design. In EA modelling methods, an enterprise is identified with institution, business or administrative unit, a firm or an industrialized region. Enterprise architecture is also considered as strategic information assets, which determine the business mission, the technology necessary to perform the mission, the transitional processes for implementing new technologies in response to the changing mission needs. In this paper, the human i.e., stakeholders' roles are emphasized as well as the motivation orientation in the enterprise architecture development is discussed. The following questions are formulated: who is the stakeholder of the EA, who is accountable and responsible for EA development, and what goals, constraints, and values are realized in the stakeholder activities' processes for the organization mission and vision by example of e-healthcare prosumption system.	archimate;coherence (physics);enterprise architecture framework;knowledge management;systems architecture;systems design;the open group	Malgorzata Pankowska	2015			enterprise architecture framework;enterprise systems engineering;systems engineering;engineering;knowledge management;architecture domain;operations management;enterprise architecture management;solution architecture;enterprise architecture;enterprise integration;view model;business architecture;enterprise life cycle	SE	-70.13832461021137	9.83217083270976	7812
a99818345e1f0bcdca866a7419f86d850de542c0	construction and application of a national data-sharing service network of material environmental corrosion	atmospheric corrosion;corrosion test site;data-sharing;environmental corrosion;materials data;seawater corrosion;soil corrosion	This article discusses the key features of a newly developed national data-sharing online network for material environmental corrosion. Written in Java language and based on Oracle database technology, the central database in the network is supported with two unique series of corrosion failure data, both of which were accumulated during a long period of time. The first category of data, provided by national environment corrosion test sites, is corrosion failure data for different materials in typical environments (atmosphere, seawater and soil). The other category is corrosion data in production environments, provided by a variety of firms. This network system enables standardized management of environmental corrosion data, an effective data sharing process, and research and development support for new products and after-sale services. Moreover this network system provides a firm base and data-service platform for the evaluation of project bids, safety, and service life. This article also discusses issues including data quality management and evaluation in the material corrosion data sharing process, access authority of different users, compensation for providers of shared historical data, and finally, the related policy and law legal processes, which are required to protect the intellectual property rights of the database.		Xiaogang Li;Jin Gao;Chaofang Dong;Cuiwei Du;Degui Luo;Lin Lu	2007	Data Science Journal		corrosion;data mining;computer science;data quality;oracle;intellectual property;service life;data sharing;java	ML	-66.7565442010465	5.021748056616885	7815
84894a7c5d3ed7711cdc7a683b3f7b82ec4bba4c	multicriteria decision support methodologies for auditing decisions: the case of qualified audit reports in the uk	modelizacion;multicriteria analysis;legislation;entreprise;decision support;petite moyenne entreprise;auditing;decision aid;systeme aide decision;empresa;accounting;ayuda decision;sistema ayuda decision;comptabilite;classification;registre;discriminant analysis;analyse discriminante;modelisation;analisis discriminante;decision support system;legislacion;multicriteria decision aid;accounting standards;small medium sized firm;firm;aide decision;contabilidad;audicion;analisis multicriterio;analyse multicritere;classification accuracy;modeling;pequenas y medianas empresas;audit;clasificacion;registro;register	All UK companies are required by company law to prepare financial statements that must comply with law and accounting standards. With the exception of very small companies, financial accounts must then be audited by UK registered auditors who must express an opinion on whether these statements are free from material misstatements, and have been prepared in accordance with legislation and relevant accounting standards (unqualified opinion) or not (qualified opinion). The objective of the present study is to explore the potentials of developing multicriteria decision aid models for reproducing, as accurately as possible, the auditors' opinion on the financial statements of the firms. A sample of 625 company audited years with qualified statements and 625 ones with unqualified financial statements over the period 1998-2003 from 823 manufacturing private and public companies is being used in contrast to most of the previous works in the UK that have mainly focused on very small or very large public companies. Furthermore, the models are being developed and testing using the walk-forward approach as opposed to previous studies that employ simple holdout tests or resampling techniques. Discriminant analysis and logit analysis are also used for comparison purposes. The out-of-time and out-of-sample testing results indicate that the two multicriteria decision aid techniques achieve almost equal classification accuracies and are both more efficient than discriminant and logit analysis.	decision support system	Fotios Pasiouras;Chrysovalantis Gaganis;Constantin Zopounidis	2007	European Journal of Operational Research	10.1016/j.ejor.2006.04.039	accounting management;decision support system;economics;computer science;marketing;operations management;management;audit;operations research	DB	-83.46366846834925	8.94113977477038	7817
9edaa15cf0995691159ab7d9b403ce996f442ccb	utilisation du chaos pour améliorer l'estimation du temps d'arrivée dans le cas multi-utilisateur : application à un système de télémétrie de type uwb. (using chaos to enhance multiuser time-of-arrival estimation: application to uwb ranging systems)			multi-user;ultra-wideband	Hang Ma	2014				HCI	-102.40499100107367	16.65780078697834	7822
362750c4741883f0954ff53ae5876ade020169e4	análise gráfica de estruturas porosas sobre a ótica da estereologia				Egnilson Miranda de Moura	2011			stereology;geography;mineralogy	Crypto	-105.15749627551202	17.9952444560102	7939
4623ac518d7bfe874daf79da7b61ba0f29833ff5	"""entwicklung und anwendung der rechnerunterstützung durch """"personal-computer"""" in der bioptisch-zytologischen diagnostik am beispiel der schilddrüsenzytologie"""			institut für dokumentologie und editorik;personal computer	Hans Joachim Scholman	1985				OS	-101.6342214641897	26.857885337683083	7943
a1514b3eb80d88ba27250db84dc7a7b8e7b12058	reading beside the lines: indentation as a proxy for complexity metric	software metrics;software;size lines of code;complexity metrics;computer languages;maintainability whitespace change metric complexity indentation;complexity theory;standard deviation;indentation;complexity;software engineering;lab on a chip software maintenance code standards java encapsulation inspection history software standards software tools merging;lines of code;whitespace;code fragments indentation complexity metrics size lines of code;code fragments;software metrics software engineering;correlation;change metric;rank correlation;maintainability;data models;java;reactive power	Maintainers face the daunting task of wading through a collection of both new and old revisions, trying to ferret out revisions which warrant personal inspection. One can rank revisions by size/lines of code (LOC), but often, due to the distribution of the size of changes, revisions will be of similar size. If we can't rank revisions by LOC perhaps we can rank by Halstead's and McCabe's complexity metrics? However, these metrics are problematic when applied to code fragments (revisions) written in multiple languages: special parsers are required which may not support the language or dialect used; analysis tools may not understand code fragments. We propose using the statistical moments of indentation as a lightweight, language independent, revision/diff friendly metric which actually proxies classical complexity metrics. We have extensively evaluated our approach against the entire CVS histories of the 278 of the most popular and most active SourceForge projects. We found that our results are linearly correlated and rank-correlated with traditional measures of complexity, suggesting that measuring indentation is a cheap and accurate proxy for code complexity of revisions. Thus ranking revisions by the standard deviation and summation of indentation will be very similar to ranking revisions by complexity.	algorithmic efficiency;altered level of consciousness;assertion (software development);c++;characters per line;concurrent versions system;cyclomatic complexity;delta encoding;dylan;forge;java;language-independent specification;linear model;lisp;open-source software;php;parsing;patch (computing);perl;programming complexity;proxy server;python;qr code;ruby;sampling (signal processing);scheme;simulation;smalltalk;source lines of code;sourceforge	Abram Hindle;Michael W. Godfrey;Richard C. Holt	2008	2008 16th IEEE International Conference on Program Comprehension	10.1109/ICPC.2008.13	reliability engineering;data modeling;complexity;computer science;theoretical computer science;operating system;software engineering;ac power;programming language;standard deviation;java;source lines of code;correlation;rank correlation;algorithm;maintainability;software metric	SE	-64.57576548960074	36.60167221214496	7975
b3d18e1e60344a3b8405d005fd39ba787e830ad2	probleme der elektronischen rechtsdokumentation - dargestellt am beispiel der steuerrechtsdatenbank der datev e g	probleme der elektronischen rechtsdokumentation;beispiel der steuerrechtsdatenbank der	Die Probleme elektronischer Dokumentationssysteme sind heutzutage kaum noch datenverarbeitungsspezifisch. Die Anforderungen an inhaltserschliessende Dokumentationssysteme sind weitgehend bekannt; sie lassen sich etwa folgendermasen skizzieren:		Joachim Conradi	1974		10.1007/3-540-07141-5_249		NLP	-103.93782627739209	32.19972134291474	8045
d6b13409852d5403d5437dfd3ee884e25fbebad4	improving it quality: the basics to boost service and cut costs	benchmarking;cycle time;functional integration;information technology;performance;quality improvement;communications technology;communication technology;organization design;service quality;new products;quality programmes	While IT has been widely used to facilitate right‐sizing, the role of IT in the quality movement has been proven but underutilized. Companies focusing on quality to increase revenues have seen dramatic results, improving products and services severalfold, with half the number of employees. IT has helped those organizations design goods that are easier to manufacture, improve new product cycle time through cross‐functional integration of systems, and use electronic networks to speed up communications internally and with suppliers and customers. Yet most IT departments have been reactive rather than proactive, involved only peripherally in their organization′s total quality programmes. Quality improvement is vital to companies trying to thrive in an increasingly competitive environment, and IT must be a partner in an organization′s efforts to institutionalize quality. A business can begin this effort with several basic steps. Briefly explaining the evolution of the quality movement will help put those steps...		Richard L. Nolan	1995	Inf. Manag. Comput. Security	10.1108/09685229510104936	quality assurance;information and communications technology;quality policy;marketing;operations management;management science;management;information technology;software quality control;computer security	Crypto	-75.76294993785599	4.512069552084656	8050
0f8ebcd2a61533a33947d40c0dc2c145fe948dff	editorial: kommunikations-endgeräte bieten zugang zu nachrichten- und informationssystemen				Hans Helmrich	1989	it - Informationstechnik	10.1524/itit.1989.31.3.179		NLP	-95.94711593867174	24.05462072638942	8059
5fc0bd53f94a5e77c9a9bfca25c7f613717e0a0a	subclassing xp: breaking its rules the right way	software prototyping team working project management programming systems re engineering;degradation;project management;software prototyping;finishing;database machines;testing;extreme programming;pair programming;experience report;team working;stability;stability testing application specific processors spatial databases web server database machines hardware degradation finishing computer bugs;team refactoring;spatial databases;wotif com;application specific processors;web server;xp subclassing;computer bugs;programming;team refactoring extreme programming xp subclassing wotif com pair programming;hardware;systems re engineering	"""Extreme programming encourages adoption of all of its practices. In practice many projects drop practices. What remains can be an incomplete methodology, which is dangerous. This problem can be overcome by replacing each removed dropped practice with a compensating practice tailored to the circumstances of the project - effectively subclassing XP. This experience report recounts the experiences of subclassing of XP at Wotif.com, where pair programming was replaced with """"pairing"""" and refactoring was replaced with """"team refactoring""""."""	code refactoring;extreme programming;pair programming	Greg Luck	2004	Agile Development Conference	10.1109/ADEVC.2004.19	systems engineering;engineering;software engineering;database	SE	-68.77551834669542	26.565449938873662	8061
6c3ba442de6a5c705f475eab594694df877c2941	adopting a digital business operating system		The role of software in society and in industry in particular continues to grow exponentially. Most companies either have or are in the process of adoption continuous deployment of their software at products in the field and collect data concerning the performance of their systems. The continuous, fast feedback loops that companies now have available allow for a fundamentally different way of organizing. In fact, based on our work with dozens of companies, we have come to the conclusion that companies are moving towards a new, digital operating system. In this paper, we first present the key elements of the digital operating system and then discuss some of the challenges companies experience during the transformation.	business operating system;continuous delivery;feedback;organizing (structure);software deployment	Jan Bosch	2018	2018 Federated Conference on Computer Science and Information Systems (FedCSIS)	10.15439/2018F001	software deployment;software;operating system;computer science	DB	-76.339957066012	17.410241292171392	8065
facfc76e6939c512ffbc509edd65b7700cc53ff5	multi-project management in software engineering using simulation modelling	multi project network;system dynamics modelling;system dynamics modeling;system dynamics;resource allocation;project manager;software engineering;simulation model;multi project management;simulation modelling;critical chain project management	Multi-project management is crucial in Software Engineering as it draws the resources from common pools, affects the completion date of other projects, determines the priority of use of resources among various projects, involves the judgment of multi-tasking of a common resource, and eventually, determines the success or failure of the projects. Hence, this paper argues that a formal simulation model using System Dynamics principles should be built to study the dynamics of software multi-project management. However, System Dynamics modelling by itself lacks the capability to construct the multi-project network, and thus confines the use of simulation in a single project environment. Thus, this paper is proposing an integration of the System Dynamics model with a multi-project network constructing method, called Critical Chain Project Management (CCPM). CCPM, not only constructs the network, but also recognizes the interdependencies of the multiple projects. However, the combination of these two principles does not simulate unexpected situations, change of policies and strategies that may be encountered during the project development. Hence, a Scenario model is proposed to be integrated with the System Dynamics and CCPM. With such integration, the project manager can identify the restraining factors in various possible scenarios in the multi-project environment, and provide feasible solutions to the senior management.	causality;computer multitasking;feedback;interaction;interconnection;interdependence;knowledge base;project network;resource contention;risk management;simulation;software engineering;software industry;system dynamics	Bengee Lee;James Miller	2004	Software Quality Journal	10.1023/B:SQJO.0000013359.71560.47	project management;extreme project management;simulation;economics;software project management;systems engineering;engineering;operations management;software engineering;management science;system dynamics;project management triangle;management;project planning;project portfolio management	SE	-68.09841571216818	17.1639997986353	8110
e9521fa53f8f3a7b9458d43ede362d1cb33b3fd9	stevens lecture on software development methods at csmr 2009	software;application software;software maintenance;software systems;computer industry;data mining;software engineering;systems engineering and theory;books;stevens award;awards activities;engineering management;software development;programming software maintenance computer industry application software software tools software systems books software engineering systems engineering and theory engineering management;stevens award stevens lecture;system development;software tools;stevens lecture;communities;programming	"""The international Stevens Award was created to recognize outstanding contributions to the literature or practice of methods for software and systems development. Harry Sneed is honored """"for his leadership and many contributions to the practice and principled growth of software maintenance techniques and their industrialization."""""""	software development process;software maintenance;stevens award	Harry M. Sneed	2009	2009 13th European Conference on Software Maintenance and Reengineering	10.1109/CSMR.2009.69	programming;application software;computer science;engineering;software development;industrial engineering;software engineering;software maintenance;software system	SE	-65.1087207568357	26.40547991134052	8120
9ba56f1043862c9b80fae3a9998c21da059657c1	data evolution and migration strategies for nosql databases (datenevolutions- und migrationsstrategien in nosql-datenbanken)		This article presents various data migration strategies for NoSQL databases, especially for document stores, and evaluates them in term of their efficiency. Some strategies do not execute the migration operation immediately but migrate the data on-demand (lazy and hybrid migration). The different migration strategies are classified with the use of four dimensions and will be compared to each other. The overall aim of the project is the development of an advisor which proposes an optimal migration strategy based on metrics. Various optimization goals are to be taken into account. The project Darwin is presented, which is implementing the techniques described in this article. 30 GI-Workshop on Foundations of Databases (Grundlagen von Datenbanken), 22.05.2018 25.05.2018, Wuppertal, Germany. Copyright is held by the author/owner(s). Datenevolutionsund Migrationsstrategien in NoSQL-Datenbanken Mark Lukas Möller Institut für Informatik Universität Rostock mark.moeller2@uni-rostock.de	darwin;database;lazy evaluation;mathematical optimization;nosql	Mark Lukas Möller	2018			nosql;database;computer science	DB	-96.38864258242582	32.04211299802353	8154
f60711d88223f67869805389bd63f8723bdc3d0d	integrating sdlc and itsm to 'servitize' systems development	system analysis and design;analysis and design;itsm;itil it service management service science system development analysis and design integration;system development;information system;it service management;operation and maintenance	IT Service Management (ITSM) is generating much interest in industry as the quality and reliability of IT services are increasingly recognized as a critical factor for business success. Academic researchers have been slower to respond to industry demand for IT service management research and coursework. This paper argues that academia has an important role to play in integrating ITSM concepts and skills into traditional information systems coursework, specifically system development. The core systems analysis and design course is used to illustrate how IT service management concepts and models can be introduced into existing coursework to support the focus on IT services required by industry today, eventually reducing the growing percentage of IT budgets currently attributed to the operation and maintenance stages of ‘nonservitized’ systems development projects.	americas conference on information systems;best practice;business requirements;capability maturity model;gene regulatory network;ibm service management framework;information system;operating system service management;sequence alignment;software development process;structured systems analysis and design method;synchronous data link control;synergy	Carol E. Pollard;Dhiraj Gupta;John W. Satzinger	2009			reliability engineering;information technology infrastructure library;systems engineering;knowledge management;service design;incident management	SE	-71.3611515286022	17.606964305021076	8188
7b5110e1fabbe7ac5c2db69cec2fa705e396e8b8	kompatibilitätsanalyse bei evolution framework-basierter anwendungen		Die Entwicklung betrieblicher Informationssysteme basiert auf dem Einsatz von Frameworks. Diese bieten ein hohes Maß an Wiederverwendung und sind flexibel anpassbar. Mit der Evolution der eingesetzten Frameworks unabhängig von der Anwendung entsteht die Notwendigkeit, Frameworks durch neuere Versionen zu ersetzen, um Fehler zu beheben oder neue Funktionen benutzen zu können. Etwaige Inkompatibilitäten neuer Versionen erfordern Anpassungen an der Anwendung. In der Praxis entsteht das Problem, dass die erforderlichen Anpassungen schwierig zu bestimmen sind. In dieser Arbeit zeigen wir einen Ansatz zur automatischen Kompatibilitätsanalyse bei der Evolution framework-basierter Anwendungen.	altran praxis;evolution;intentionally blank page;unified model	Fabian Christ;Jan-Christopher Bals	2011			mathematical physics;philosophy	DB	-102.07098979915631	32.6336275785841	8200
5cf47a76e651a3108ac8520ca49ef8b513e98148	strategic channel alignment: an analysis of the configuration of physical and virtual marketing channels	e commerce;strategic alignment;marketing strategy;marketing channel	Extensive integration of online and offline channels is often described as the most preferable strategy for multi channel retailing. However, empirical findings challenge this assumption by showing that retailers choose a variety of disparate multi channel strategies. Given this variety, we conjecture that there is no single best approach to multi channel retailing, but that, depending on the general marketing strategy, different multi channel strategies can be suitable for retailers. We develop a model of strategic channel alignment and identify four different paths of channel alignment, which we use to reconstruct and interpret multi channel strategies as an alignment of general marketing strategy and online strategy. An application of the model to four prominent and successful cases from the grocery retailing industry shows that although the companies pursue fundamentally different multi channel strategies, they can all be considered as examples of successful alignment and mature multi channel strategies.	online and offline;web strategy	Claas Müller-Lankenau;Kai Wehmeyer;Stefan Klein	2006	Inf. Syst. E-Business Management	10.1007/s10257-005-0031-4	e-commerce;economics;computer science;marketing;operations management;marketing strategy;advertising;strategic alignment	ML	-79.50283725401195	6.75424776939704	8243
f50a90b8c9eb107452a15dfd36beae7ae4754a3e	supporting the evolution of research in software ecosystems: reviewing the empirical literature		The field of software ecosystems is gradually transiting towards an established means of software development and distribution, counting numerous areas of applicability. However, research in software ecosystems, although the activity of over 10 years, is still characterized as premature with significant lack of software ecosystem specific theories that are solid, mature, generic, and detailed enough to be measurable and transferable. In this study, we intent to come closer to an evolution of the field by supporting the “localization” of research, i.e. the focus on specific types of software ecosystems. To do so, we investigate the literature of empirical, non open source ecosystem studies and intent to identify the various aspects and perspectives studied.	ecosystem	Konstantinos Manikas	2016		10.1007/978-3-319-40515-5_5	computer science;systems engineering;knowledge management;management science	SE	-75.11976997097838	20.6130321784354	8315
9e16c9cc0b7bba9850c1ddaf1c354f160c72f63b	einsatz paralleler rechner in prozeßsteuerung und sensorik				Wolfgang G. A. Trier	1999				NLP	-97.48330207582384	24.875026324125816	8371
8ebe6b64583e6a09710ad03cfe86e0730c89127a	ein verfahren zur prognose der verkehrsverteilung in einem geplanten straßennetz		Zusammenfassung: Die Verkehrsdichten in den Zweigen eines Straflennetzes ergeben sich aus der Realisierung des gesamten Verkehrsbedarfs, der dutch eine Matrix D beschrieben werden kann. Zur Prognose des Verkehrs in einem geplanten StraBennetz gibt es verschiedene M6gfichkeiten, urn dutch eine Operation mit D die erwarteten Verkehrsdichten zu ermitteln. Bei dem hier beschriebenen Verfahren wird in diese Operation eine Zufallsvariable eingef0ahrt. Mit ihr soUen die Sch/itzfehler, Fahrgewohnheiten und undefinierten Pr~iferenzen in die Rechnung eingehen, die bei der Auswahi der Wege im Netz durch die Verkehrsteitnehmer eine Rolle spieten. Damit wird eine bessere Ann~iherung der Rechenergebnisse an das praktische Geschehen bei einem vertretbaren Aufwand an Rechenzeit erreicht. Das Verfahren wird ausffihrlich beschrieben und an Hand eines durchgerechneten Fails aus der Praxis mit anderen Methoden verglichen. Zum SchluB werden Verfeinerungen des Verfahrens diskutiert, mit denen sich die Rechenergebnisse bei erh6htem Aufwand verbessem Iassen.	altran praxis;die (integrated circuit);eine and zwei;triple des	Hasso von Falkenhausen	1963	Unternehmensforschung	10.1007/BF01920959	discrete mathematics;mathematics;performance art	OS	-104.24634339171737	30.091926250577817	8385
f16a65b74576e62399b266614d3f5c92ed4b9ebb	home networking - vernetzung mit internetzugang, integration digitaler medien, funknetze	home network			Torsten Horn	2002				Crypto	-97.57401639869552	26.724160775600616	8400
7a5c4603482364bd09b9ba4cfa68ab899b20d2b0	an inquiry into the relationship between cluster supply chain and industry cluster	supplier cluster;supplier cluster industry cluster cluster supply chain;industries supply chains organizations manufacturing supply chain management economics roads;industries;cluster supply chain;supply chains;roads;industry cluster;manufacturing;supply chain;organizations;economics;supplier cluster cluster supply chain industry cluster;supply chain management	With the development of industry cluster, cluster supply chain as the link to every enterprise in industry cluster is come into being accordingly. The development and improvement of industry cluster promotes cluster supply chain perfect gradually, and the development of cluster supply chain also promotes industry cluster grow up. How to understand and deal with the complicated relationship between enterprises in cluster guarantees enterprise most benefit, and is also the premise for the whole industry cluster develop and grow up.	computer cluster		2010		10.1109/ICEE.2010.804	supply chain management;economics;service management;marketing;operations management;supply chain	ML	-72.63337014548614	6.074364764437231	8497
948a40f89ebb894fa972f8953179b1526d68972f	underpinning the ebusiness framework - defining ebusiness concepts and classifying ebusiness indicators	spectrum;business process;e commerce;organizational structure	This paper presents a framework for the classification of indicators used to measure ecommerce and e-business. This framework is presented in the so-called E-Business Effect Matrix. It consolidates developments around the widely used OECD framework of readiness, intensity and impact on the company level. The E-Business Effect Matrix visualizes the whole spectrum of e-business effects. It relates e-business techniques with business processes, organizational structures, and business performance for three different dimensions and thereby structures the research fields of ‘ICT & Statistics’ and ‘E-business Effects’. Furthermore, this paper combines material on e-business definitions from statistical and scientific sources into a framework for defining e-business. This framework distinguishes e-commerce from e-business and can be used in discussions on standardization of the definitions national statistical institutes (NSIs) use to inquire e-business.	business process;conceptual schema;e-commerce;electronic business	Xander de Graaf;Robin Muurling	2003			e-commerce;business process;underpinning;electronic business;standardization;organizational structure;information and communications technology;knowledge management;business	Web+IR	-78.39632136920524	7.498679069397162	8505
277ad73b6139d7cd0766405df8b013036d38fd18	the automated student advisor: a large project for expert systems courses	software systems;expert system	The paper examines a large project for an Expert Systems course, the Automated Student Advisor, which assists students in selecting courses for the next semester. The system was designed and implemented in the last third of a semester course by students and the instructor working as a software group. The result was a software system that is now in use at the university.	expert system;software system	Robert M. Harlan	1994		10.1145/191029.191046	computer science;software engineering;software system	SE	-65.85146863833306	26.36162749229709	8512
e96217c8ca3b1f66f6d31ff55d211628ff1890c6	machine virtuelle universelle pour codage vidéo reconfigurable. (a universal virtual machine for reconfigurable video coding)			data compression;virtual machine	Jérôme Gorin	2011				Vision	-101.83721594878142	13.666522046185644	8566
d81e0948cb99c6e04e372aaf5d8b7a789998039d	towards proactive management of technical debt by software metrics		Large software development organizations put enormous amount of effort not only for responding to continuous requests of customers but also for reengineering and refactoring activities to keep their product maintainable. Often rapid and immature feature deliveries over long period of time gradually decrease the product quality, and therefore the refactoring activities become costly and effort-intensive. This situation is described by the concept of “technical debt”, which represents the accumulated rework that organization has to do in order to prevent the slowdown of the development. In this paper we report results of a case study at Ericsson on using software metrics for moving towards proactive management of technical debt. Our observations show that there are four distinguishable maturity phases of quality management over the eight years of development time of two large products: Start-n-stop, Reactive, Systematic, and Proactive quality management. Three sophisticated metrics are applied to help the organizations to move towards Proactive management of technical debt. These metrics are used on a systematic basis to provide information on the areas of the product that have tendency of accumulating technical debt. Software engineers use this information for making decisions on whether or not the pinpointed areas should be refactored.	capability maturity model;code refactoring;heat map;interactivity;rework (electronics);software bug;software development;software engineer;software metric;technical debt	Anna Börjesson Sandberg;Miroslaw Staron;Vard Antinyan	2015			quality management;software metric;software;business process reengineering;business;code refactoring;slowdown;systems engineering;software development;technical debt	SE	-68.84578689109468	23.93668603717484	8597
82808e9bdd4160f02d8b0a917e75c5e133f17ac8	wissensbasierte unterstützung der planung technischer systeme: konzeption eines planungswerkzeuges und exemplarische anwendung im bereich der montagesystemplanung				Peter Ganghoff	1993				DB	-103.29382681145235	23.80222917171483	8602
2436940c80c8e0b82883ef7ff4fdb4f385de34a6	rechtsprechung zum telekommunikationsrecht					2010	Computer und Recht	10.9785/ovs-cr-2010-363		Theory	-96.28873788667894	23.147716095813145	8618
007eb117f809ec97f6c9e1568d2d37cb01e359ab	toward big data value engineering for innovation	technological innovation;energy industry;architecture landscape;stakeholders;software engineering;value discovery;value engineering;computer architecture;innovation;big data;energy industry big data value discovery value engineering architecture landscape ecosystem innovation;value engineering big data;ebay in the grid business model big data value engineering value discovery method bdd method big data design method bounded rationality expandable rationality eco arch approach it service company energy industry;ecosystem;problem solving;big data technological innovation problem solving computer architecture software engineering stakeholders	"""This article articulates the requirements for an effective big data value engineering method. It then presents a value discovery method, called Eco-ARCH (Eco-ARCHitecture), tightly integrated with the BDD (Big Data Design) method for addressing these requirements, filling a methodological void. Eco-ARCH promotes a fundamental shift in design thinking for big data system design -- from """"bounded rationality"""" for problem solving to """"expandable rationality"""" for design for innovation. The Eco-ARCH approach is most suitable for big data value engineering when system boundaries are fluid, requirements are ill-defined, many stakeholders are unknown and design goals are not provided, where no architecture pre-exists, where system behavior is non-deterministic and continuously evolving, and where co-creation with consumers and prosumers is essential to achieving innovation goals. The method was augmented and empirically validated in collaboration with an IT service company in the energy industry to generate a new business model that we call """"eBay in the Grid""""."""	big data;data system;problem solving;rationality;requirement;systems design	Hong-Mei Chen;Rick Kazman;Juan Garbajosa;Eloy González	2016	2016 IEEE/ACM 2nd International Workshop on Big Data Software Engineering (BIGDSE)	10.1145/2896825.2896837	systems engineering;engineering;knowledge management;management science	SE	-72.91752615662296	8.502155971323267	8680
a4ba93fcf2dfb327c863f03b52cb7d0911d48218	evaluating an innovative technology in the presence of uncertainty.		Seamlessly merging real and virtual reality, Augmented Reality (AR) is a promising technology that offers novel ways to use IS outside the office. For a company it is hard to determine whether to put R&D efforts into such an innovative technology. Developing methods to model, describe, assess and analyze such new technologies is a main challenge of the IS discipline. The purpose of this work is to support a decision concerning the adoption of an innovative technology. Yet, it is not known how the use of this technology would change business processes and also several uncertainties must be addresses. A threestep approach, dealing with these problems is proposed. To generate knowledge about how to use this technology scenarios are identified and analyzed within a framework. Furthermore, a decision model to estimate the impact of different investment decisions is established.	augmented reality;business process;virtual reality	Oliver Knut;Tobias Blum;Helmut Krcmar	2006			business process;computer science;decision model;management science;merge (version control);emerging technologies;augmented reality;investment decisions;virtual reality	HCI	-74.26658687588802	12.655588120099324	8705
471d263b3c8e79c62344f8358c7c3efa3c50ac1f	intuitionistic model constructions and normalization proofs	publikationer;konferensbidrag;artiklar;rapporter	Introduction Présentation Étant données red une règle de réduction, conv sa clôture reexive, transitive et symétrique. Pour prouver que red est fortement normalisante, deux possibilités : prouver des propriétés de red (Church-Rosser.. .) ; fournir une fonction de normalisation : un algorithme qui choisit un représentant irréductible pour chaque classe d'équivalence de conv.	brouwer fixed-point theorem;church–rosser theorem;forte 4gl;gödel;intuitionistic logic;ion implantation;linear algebra;thierry coquand;vii	Thierry Coquand;Peter Dybjer	1997	Mathematical Structures in Computer Science	10.1017/S0960129596002150	discrete mathematics;mathematics;algorithm	Logic	-95.29179138194422	34.431940138289754	8712
91494780789e0acf7c8a97c80986d0dc43dfe7c3	information infrastructures for utilities management in the brewing industry		There is an increasing focus on sustainability in manufacturing industries. Operations management and plant/process control have a significant impact on production efficiency and hence environmental footprint. Information systems are an increasingly important tool for monitoring, managing and optimising production efficiency and resource consumption.		Michael J. Lees;Robert A. Ellen;Marc Steffens;Paul Brodie;Iven M. Y. Mareels;Rob J. Evans	2012		10.1007/978-3-642-33618-8_13	operations management;business;commerce	EDA	-71.36530538132523	4.803726831465546	8748
cf9ac70989203075337d536ed34d20892e4e6c5e	an approach to the machine front end services for the cim open system architecture (cim-osa)			computer-integrated manufacturing;javascript osa;systems architecture	Wu-Nan Hou	1993				ML	-91.48513258796612	28.947219937372168	8750
c9e6681475e69bcfb72d1126e74eb9d60def05dc	eine sprache zur systemprogrammierung und ein compilerkonzept für diese sprache			eine and zwei	Günter Merbeth	1975	Elektronische Informationsverarbeitung und Kybernetik		algebra;combinatorics;mathematics	Vision	-95.86453274363963	34.558175352869476	8776
6fe73f8b72335da18c276d8bfe5b6ad820eb68d5	taming the complexity of artifact reproducibility		Reproducing research results, as it is required for peer review, can be a time-consuming and difficult task. In this work, we propose three approaches to improve the way of how research results can be substantiated and discuss their applicability. Our proposals are based on a brief study on evaluation methods (for SDN research) and insights from a comprehensive discussion on reproducibility.	software-defined networking;usability	Matthias Flittner;Robert Bauer;Amr Rizk;Stefan Geißler;Thomas Zinner;Martina Zitterbart	2017		10.1145/3097766.3097770	management science;computer science;reproducibility;data mining	HCI	-63.303095872106255	19.15435434180291	8802
5f128586923bb72b62b5d7b44f7d73a0633a72f8	räumliche mobilität und ki	computer science;computer and information science	"""Bewegungen von Personen und Gütern im geografischen Raum werden als räumliche Mobilität bezeichnet. Zum Mobilitätsbegriff gehört die Möglichkeit und Bereitschaft zur Bewegung. Im Verkehr zeigt sich die realisierte Mobilität. Die Verwendung des Begriffs Mobilität betont die individuellen Motive und Hintergründe der Bewegung im Raum. Die Modellierung der Mobilität benötigt also Wissen über Motive, Ziele und Hintergründe menschlichen Planens und Handelns sowie Prozesswissen über den Ablauf einer Planung bzw. Handlung. Verkehrsmodellierung, hingegen, muss sich nicht zwingend mit den Motiven des Handelns beschäftigen, wohl aber mit deren Auswirkungen. Erst wenn Prognosen erstellt werden sollen, müssen wir uns mehr über die Motivationen der Verkehrsteilnehmer Gedanken machen. Gerade an diesem Punkt wird die Verkehrsmodellierung für die KI interessant: Verteilte Agenten produzieren ein gemeinsames Phänomen, das als Verkehr bezeichnet wird. Aus individuellem, persönlich motiviertem Verhalten entsteht kollektives Verhalten (s. Beitrag von Winter in diesem Heft), das eigenen Regeln unterworfen ist. Die Verkehrswissenschaften beschreiben klassischerweise kollektives Verkehrsverhalten mit statistischen Mitteln oder als physikalische Flussmodelle (s. Interview Nagel). Ziel einer Modellierung mit Methoden der KI ist die Beschreibung bzw. Produktion des Verkehrs als emergentes Phänomen dazu eignen sich insbesondere MultiAgenten Simulationen. Die Modellierung der einzelnen Verkehrsteilnehmer als Basis für eine Verkehrssimulation ermöglicht zusätzlich eine Unterstützung der Informationsverarbeitung des """"Homo mobilis"""". Forschungen im Bereich Navigation und Wegfindung (z.B. [Gol99]) bieten gute Ansatzpunkte für Modelle raum-zeitlicher Informationsverarbeitung und deren verwendete Datenstrukturen. Im neueren Forschungsgebiet Location-Based Services [SV04] wird die Unterstützung einzelner Verkehrsteilnehmer mit Hilfe von Kommunikationsgeräten (z.B. Handys, PDA’s) untersucht. Die Modellierung kognitiver räumlicher Fähigkeiten und Aktivitäten war Thema des Schwerpunkthefts 01/2008. In diesem Überblick verzichten wir daher auf eine detaillierte Diskussion der räumlichen Wissensverarbeitung, Wissensrepräsentation, sowie des qualitativen Schließens."""	aldert van der ziel;binary prefix;die (integrated circuit);eine and zwei;heterogeneous earliest finish time;institut für dokumentologie und editorik;parity (physics);personal digital assistant;triple des	Sabine Timpf;Franziska Klügl-Frohnmeyer	2008	KI		humanities;computer science;performance art	OS	-105.11849178559571	34.14052416397483	8805
faa212bb4c2205a3988fa4ff3563b30825ca98e3	qualität und effektivität von gütesiegeln. eine übersicht über nationale und internationale angebote		Nach einem kurzen Überblick der einzelnen Kategorien von Modellen werden diese unter Berücksichtigung der nationalen und internationalen Entwicklungen ausführlich dargestellt, bevor im Anschluss auf eine Darstellung zur Bewertung nach Qualität und Effektivität erfolgt. Der Beitrag schließt an die Erörterungen des Autors über Gütesiegel als vertrauensbildende Maßnahme im E-Commerce im letzten Heft an.	e-commerce;eine and zwei;heterogeneous earliest finish time	Jörg Hladjk	2002	Datenschutz und Datensicherheit		internet privacy;computer science	Theory	-103.1567076885353	36.1899127055803	8851
ffc4d00b4acd304947afaf1026fd9a415ee684ca	optimal design in geodetic gnss-based networks		........................................................................................................................... i Sammanfattning ............................................................................................................. ii Acknowledgements ...................................................................................................... iii List of Papers ................................................................................................................ vii List of Figures.............................................................................................................. viii List of Tables ................................................................................................................. ix Acronyms ........................................................................................................................ x	geodetic datum;optimal design;satellite navigation;vii	Mohammad Amin Alizadeh Khameneh	2017				Theory	-95.80808463336527	23.745411950795077	8859
04f2ed1a827461458033c6d0272a87aa30ac5195	operational use evaluation of it investments: an investigation into potential benefits	economie;economia;evaluacion proyecto;evaluation performance;performance evaluation;inversion;evaluacion prestacion;information technology;technologie information;investment;it investment;investissement;evaluation projet;economy;it investment appraisal;it evaluation;project evaluation;tecnologia informacion;operational use evaluation;prior operational use evaluation	The process of evaluation of IT projects often seems to cease just as quantifiable results start to become available—in Operational Use (OU). This paper investigates OU IT evaluation and contrasts it with the evaluation undertaken during the specification, construction, and testing of IT projects; which we choose to call Prior Operational Use (POU) to distinguish it from OU. Analysis of 123 usable responses from the FTSE 500 companies, show that many companies appear not to undertake OU evaluation. However, where OU evaluation was conducted, it appears to be of clear value to the organisations. Benefits claimed include the ability to assess deviations from their original plans, and to provide a basis for validating the original methods used (in their POU evaluations).		Hussein Al-Yaseen;Tillal Eldabi;David Y. Lees;Ray J. Paul	2006	European Journal of Operational Research	10.1016/j.ejor.2005.07.001	inversion;economics;investment;operations management;management;operations research;information technology	HPC	-83.3997021023513	9.07757022229153	8874
c2bc2e165fe6af3de5de600af57cb0b301ce0c0f	beyond server consolidation	virtualization technology;beyond server consolidation;efficient use	Virtualization technology was developed in the late 1960s to make more efficient use of hardware. Hardware was expensive, and there was not that much available.	business continuity;fault tolerance;hardware virtualization;reliability engineering;rewriting;scott continuity;semiconductor consolidation;server (computing);software as a service;software quality assurance;utility computing;x86 virtualization	Werner Vogels	2008	ACM Queue	10.1145/1348583.1348590	embedded system;full virtualization;real-time computing;operating system	Arch	-72.59508545437026	33.42550407918695	8957
868e76f2ed0dddc29012beceb381356f6a7432ac	uml 2.0—neue möglichkeiten und alte probleme	unified modeling language	Die inzwischen in einer stabilisierten Entwurfsfassung vorliegende Revision der weit verwendeten Unified Modeling Language (UML) zur Version 2.0 verspricht einige Neuerungen,welche die Möglichkeiten der objektorientierten Entwicklung erweitern sollen. Die Revision der Sprache setzt sich neben der Erweiterung der Ausdrucksmächtigkeit auch die Präzisionssteigerung der angebotenen graphischen Primitive zum Ziel. Der vorliegende Beitrag stellt überblicksartig die wesentlichen Neuerungen der UML 2.0 vor und beleuchtet kritisch fortdauernde Unzulänglichkeiten des Sprachansatzes.	unified modeling language;vhf omnidirectional range	Mario Jeckle;Chris Rupp;Barbara Zengler;Stefan Queins;Jürgen Hahn	2004	Informatik-Spektrum	10.1007/s00287-004-0416-7	unified modeling language;computer science;systems engineering;software engineering	OS	-101.37587980043044	32.24169284623205	8959
8f53b9fa225a6e01ffd680fc9c484d299b7e6551	análisis de dos métodos de estimación para sistemas lineales estacionarios e invariantes en el tiempo con perturbaciones correlacionales con el estado observable del tipo: una entrada una salida		THIS STUDY PRESENTS A COMPARATIVE THEORETICAL ANALYSIS AND PRACTICE IMPLEMENTATION, BETWEEN TWO ESTIMATORS: LEAST SSQUARE METHOD AND INTRUMENTAL VARIABLE METHOD, FOR SYSTEMS WITH INTERNAL AND EXTERNAL PERTURBATIONS, CORRELATED WITH OBSERVABLE STATE. IN THEORICAL SENSE, THE STOCHASTIC PROCESS WAS CONSIDERED, AND THE BASIC DIFFERENCE BETWEEN BOTH ESTIMATORS WERE EXPOSED: TWO THEOREMS GIVES THE PRINCIPAL PROPERTIES OF BOTH ESTIMATORS. IN PRACTICE SENSE, THE SIMULATION RESULT ILLUSTRATED THE PROPERTIES OF BOTH ESTIMATORS FOR INVARIANT AND STATIONARY MODEL AND NOISES CORRELATED WITH OBSERVABLE STATE.	naruto shippuden: clash of ninja revolution 3;observable;unique name assumption	José de Jesús Medel Juárez	2002	Computación y Sistemas		art;performance art;cartography	Vision	-108.38231903684289	17.49834777731506	8969
3eb01c9237392205b677d5e4df33b3f04918e242	integration verschiedener informationsquellen bei der navigation in virtuellen umgebungen				Sibylle D. Steck	2000				NLP	-98.93310712316557	26.638127435874985	8981
b07a9310ceeec29ded60fb9e1c51d28c8db4bb74	intelligent vehicle r&d: a review and contrast of programs worldwide and emerging trends	esquiva colision;industrie automobile;programme recherche;systeme intelligent;articulo sintesis;vehiculo caminero;vehicule routier;article synthese;sistema inteligente;automatisation;recherche developpement;securite routiere;automatizacion;traffic safety;user assistance;research and development;assistance utilisateur;investigacion desarrollo;industria automovil;intelligent vehicles;seguridad trafico;asistencia usuario;intelligent system;aide circulation;programa investigacion;collision avoidance;securite trafic;aide utilisateur;esquive collision;review;road vehicle;research program;automobile industry;automation	Intelligent Vehicle (IV) systems are becoming increasingly common on automobiles, heavy trucks, transit buses, and even in the military. Intelligent vehicle systems are defined as systems which sense the driving environment and provide information and/or control to assist the driver in optimal vehicle operation. The focus is on the “tactical level” function of driving (steering/braking/throttle), as distinct from the “strategic level” of route selection, etc. A similar term used widely in Europe is Advanced Driver Assistance Systems. This paper provides an overview of intelligent vehicle R&D activities worldwide, focusing primarily on Europe, Japan, and the USA. Key applications are described, and government-sponsored programs, industrial development, market factors, and user issues are covered. An analysis is provided as to key differences between major programs, and a set of research priorities for the development of enabling technologies is offered.		Richard Bishop	2005	Annales des Télécommunications	10.1007/BF03219820	simulation;computer science;engineering;electrical engineering;automation;transport engineering	DB	-68.32703605355682	5.828282755423146	9017
318617c8153686cfe909212a7bc7597657d80a6a	konzepte zur integration von 3d graphik in der seitenbeschreibungssprache postscript			postscript	Veronika Samara	1994				Vision	-100.18413154908868	26.213034906993485	9076
4aff8bab538deeeba88eb434c9a1995dbe169e9e	how service innovation contributes to co-create value in service networks		The purpose of this paper is to investigate how service innovations (in a living lab context) contribute to co-create value in a service network. Exploratory research is developed using a qualitative approach and case study on mobility services in Bologna. Our findings reveal that the involved entities are able to recombine their existing resources and design a new value proposition based on the ICT solution. Theoretical and empirical research suggests that collaboration and participation in decision making are critical to service system reconfiguration. The study shows the importance of including insights from Service Science Management and Engineering and Design (SSMED) in the management of network theory. Moreover, the research paves the way for new perspectives on analysis of local governance issues based on value co-creation processes in the ICT service solution context. Using this perspective, service innovations in the overall management of public services view a city as a Smart Local Service System (SLSS), whose competitiveness depends on its ability to access and share common resources to create mutual value.	service innovation	Maria Vincenza Ciasullo;Francesco Polese;Orlando Troisi;Luca Carrubbo	2016		10.1007/978-3-319-32689-4_13	service;service product management;knowledge management;service delivery framework;marketing;service design;service guarantee;business;service system	ECom	-76.22894887961884	6.167377057527557	9149
d638c48e08d114e2861b5ac413d9afc30b707ad8	vergleich der benutzerschnittstellen unter vm/cms (rel. 4) und unter nos/ve (rel. 1.2.3.) auf der basis eines kenngrößenkatalogs		Presentation du0027un catalogue de caracteristiques classificatoires adapte a la description comparative du0027interfaces utilisateur. Deux interfaces utilisateur sont examinees: VM/CMS (Rel. 4) du0027IBM et NOS/VE (Rel. 1.2.3) de CDC	nos/ve;rel;z/vm	Klaus Fromme;Dietrich Krekel	1989	Angewandte Informatik		operating system;cartography;engineering	Vision	-102.67582336838342	25.7383002645619	9256
45f74e2469fcc6b01bb05fc58bdabda08afd5e44	modèle de préférences contextuelles pour les analyses olap		Les systèmes OLAP (On-Line Analytical Processing) permettent l’analyse de grands volumes de données issues des systèmes transactionnels de l’entreprise. Ils reposent le plus souvent sur des bases de données multidimensionnelles (BDM) qui organisent les données en sujets d’analyse appelés faits, et axes d’analyse appelés dimensions. L’analyse en ligne OLAP consiste à explorer intuitivement les BDM par l’application d’un ensemble d’opérateurs multidimensionnels (Abelló et al., 2003), (Ravat et al., 2008). Les systèmes OLAP actuels ont peu de connaissances sur l’utilisateur. Ils ne tiennent pas compte des caractéristiques spécifiques de chaque utilisateur pour la restitution des données, à savoir ses objectifs et ses centres d’intérêts. Ceci oblige l’analyste à naviguer au sein des données par un enchainement d’opérations et une succession de résultats intermédiaires pour obtenir les données pertinentes à sa prise de décision (adaptées à ses besoins spécifiques d’analyse). L’analyse OLAP peut s’avérer alors une tâche fastidieuse qui dégrade les performances du processus d’analyse décisionnelle. Cette dégradation est aggravée par un coût d’exécution important des requêtes dans un environnement OLAP avec un grand nombre de dimensions (Choong et al., 2003). Notre objectif est de personnaliser l’exploration des BDM en restituant les données en fonction des préférences utilisateur et de son contexte d’analyse. Ceci permettrait de réduire la charge de navigation de l’utilisateur.	background debug mode interface;bibliothèque de l'école des chartes;estdomains;linear algebra;olap cube;online analytical processing;performance;succession;word lists by frequency	Houssem Jerbi;Franck Ravat;Olivier Teste;Gilles Zurfluh	2009			dissolution;phosphorus;ammonium;catalytic oxidation;catalysis;ion;molybdenum;inorganic chemistry;chemistry;alkali metal	Crypto	-105.40310157131508	14.256188882026297	9337
d37fdc56c0e76a54627b1577d549ea56ec75761e	indikatoren zur bewertung der nachhaltigkeit von unternehmensarchitekturen		Zusammenfassung: Nachhaltigkeit ist ein aus der Umweltökonomie stammendes Konzept, welches angewandt auf Unternehmen einen verantwortungsvollen Umgang mit der physischen (Ökologie) und sozialen Umwelt (Ökonomie, Soziologie) fordert. Dieser Beitrag diskutiert, inwiefern sich Nachhaltigkeit, losgelöst von Fragen der Ökologie, auf Unternehmensarchitekturen übertragen lässt und welche Indikatoren sich für ein Bewertungssystem nachhaltiger Architekturen eignen.	citeseerx	Stephan Aier;Turgut Dogan	2005			computer science;information management	OS	-101.89453761290733	34.440860213935444	9343
44b8c112cc0211fc2780a114c0f69f9e8192869b	rsa basierte sicherheitsdienste für die kommunikationstechnik		Bei der heute fortschreitenden Verbreitung der elektronischen Kommunikation treten zunehmend sicherheitsrelevante Aspekte wie Rechtsverbindlichkeit, Integritat und Vertraulichkeit elektronisch ubertragener Nachrichten zu Tage.		Peter Volkmer	1991		10.1007/978-3-642-76758-6_20		NLP	-103.809412868471	35.35870705468084	9378
8e5c66123da5dc01d58fc114616188be2ef322de	bridging the gap between software development and information security	information security;software engineering security of data;software engineering;softdev;software security;programming information security software testing risk analysis computer bugs costs system testing humans software design best practices;building security in;human resource;software development;softdev building security in bsi infosec;software security software development information security technical security risk;bsi;security of data;infosec	business units and thus not even practiced in a cohesive, coherent manner. In the worst cases, busy business unit executives trade roving bands of developers like Pokémon cards in a fifth-grade classroom (in an attempt to get ahead). Suffice it to say, none of this is good. The disconnect between security and development has ultimately produced software development efforts that lack any sort of contemporary understanding of technical security risks. Today's complex and highly connected computing environments trigger myriad security concerns, so by blowing off the idea of security entirely, software builders virtually guarantee that their creations will have way too many security weaknesses that could—and should—have been avoided. This article presents some recommendations for solving this problem. Our approach is born out of experience in two diverse fields: software security and information security. Central among our recommendations is the notion of using the knowledge inherent in information security organizations to enhance secure software development efforts. Don't stand so close to me Best practices in software security include a manageable number of simple activities that should be applied throughout any software development process (see Figure 1). These lightweight activities should start at the earliest stages of software development and then continue throughout the development process and into deployment and operations. Although an increasing number of software shops and individual developers are adopting the software security touchpoints we describe here as their own, they often lack the requisite security domain knowledge required to do so. This critical knowledge arises from years of observing system intrusions, dealing with malicious hackers, suffering the consequences of software vulnera-bilities, and so on. Put in this position , even the best-intended development efforts can fail to take into account real-world attacks previously observed on similar application architectures. Although recent books 1,2 are starting to turn this knowledge gap around, the science of attack is a novel one. Information security staff—in particular, incident handlers and vulnerability/patch specialists— have spent years responding to attacks against real systems and thinking about the vulnerabilities that spawned them. In many cases, they've studied software vulnerabili-ties and their resulting attack profiles in minute detail. However, few information security professionals are software developers (at least, on a full-time basis), and their solution sets tend to be limited to reactive techniques such as installing software patches, shoring up firewalls, updating intrusion detection signature databases, and the like. It's very rare to find information security …	application security;book;box counting;bridging (networking);coherence (physics);database;firewall (computing);information security;intrusion detection system;malware;patch (computing);software deployment;software developer;software development process;vulnerability (computing)	Kenneth R. van Wyk;Gary McGraw	2005	IEEE Security & Privacy	10.1109/MSP.2005.118	software security assurance;information security audit;computer security model;standard of good practice;certified information security manager;cloud computing security;critical security studies;security through obscurity;security information and event management;security engineering;security convergence;asset;security bug;computer science;information security;software development;logical security;security service;security testing;computer security;information security management	Security	-68.80024840786045	25.441470803225496	9399
2e7f0eedb75f2bc4c98f5fb19eaa2be0998dc44b	service systems framework focusing on value creation: case study	processus innovation;gestion entreprise;gestion des connaissances;service system;information technology;knowledge management;innovation process;firm management;service process;proceso innovacion;proceso servicio;service innovation;d management;research management;research and development;innovation management;processus service;r d management;method creation;investigacion desarrollo;service systems;administracion empresa;value creation;it services;technology creation;gestion conocimiento;manufacturing firms;r amp;recherche et developpement	The impact of R&D on service businesses is increasing rapidly due to the movement to service economies. The shift to focus on the service businesses in manufacturing industries, is affecting their internal business processes, including research organisations. In this paper, we studied an exploratory research experiment in a manufacturing enterprise toward service research, focusing on an advanced service research initiative. We are seeking to understand how best for research organisations to contribute to service businesses. A conceptual framework of service systems was developed. We conducted a survey. We conducted a survey and found that method creation is critical for the success of service projects, beyond technology creation found that method creation is critical for the success of service project, beyond technology creation. In addition, the primary outputs of service research projects vary based on the positioning of the service project in the framework. It is necessary to recognise the findings for the research management.	business process	Yuriko Sawatani;Kiyoshi Niwa	2009	Int. J. Web Eng. Technol.	10.1504/IJWET.2009.031012	innovation;service;service product management;innovation management;knowledge management;service delivery framework;service design;service guarantee;service desk;management;information technology;service innovation;service system	SE	-79.67353857494054	5.10866900383157	9400
24897e14ed8e39649f90b4ba5570eabd1dd4963f	vom körper zum server: mobile und drahtlose datenerfassung und -übertragung in gesundheitspflege-, notfall- und aal-szenarien		In vielen Szenarien in den Bereichen Gesundheitspflege, Notfallversorgung und AAL werden Daten durch Sensoren am menschlichen Korper erhoben. Diese Daten werden je nach Anwendungsfall entweder zur spateren Auswertung lokal gespeichert oder aber direkt uber eine Funkverbindung zu einer Datensenke gesendet.rnIn dieser Arbeit wird ein System vorgestellt, das in der Lage ist, Szenarien mit unterschiedlichen Anforderungen zu ermoglichen, wobei die gesamte Ubertragungsstrecke vom Korper uber hausliche Gateways bis hin zu Servern bzw. Backendsystemen abgedeckt wird.rnDa kein geeignetes Hardwaresystem verfugbar war, wurde mit INGA ein Sensorknoten geschaffen, der den Anforderungen an die Sensorausstattung, die Verarbeitungskapazitat und die Funkubertragung gerecht wird.rnZur Absicherung der Funkubertragung werden die Daten mit einem auf One-Time-Pads basierenden Kryptosystem verschlusselt.rnDie Ubertragung zum hauslichen Gateway geschieht uber ein unterbrechungstolerantes Kommunikationsprotokoll (DTN), welches auch eine implizite Synchronisation derjenigen Daten ermoglicht, die auserhalb der Kommunikationsreichweite des Gateways, also auserhalb der Wohnung, aufgenommen wurden.rnUm im auserhauslichen Bereich auch Notfallmeldungen absetzen zu konnen, wird auserdem ein mobiler Notfallkanal uber ein Smartphone realisiert.rnDie aufgezeichneten Daten werden in den betrachteten Szenarien auf dem Gateway in der Wohnung der betreffenden Person gespeichert und dort ausgewertet.rnUm auserdem auch die Integritat dieser verteilen Gateways auch bei einer groseren Anzahl von Installationen sicherstellen zu konnen, wird ein System zur Fernuberwachung der verteilten Gateways uber selbstinitiierte VPN-Verbindungen zu einer zentralen Uberwachungsinstanz geschaffen.rnMit den vorgestellten Losungen werden somit vielfaltige Anwendungsfalle mit teils gegensatzlichen Anforderungen unterstutzt, die noch dazu parallel auf ein und denselben Sensorsystemen und mit den gleichen Protokollen betrieben werden konnen.	atm adaptation layer	Felix Büsching	2013			art;performance art	Mobile	-106.59126005231087	32.52625258384611	9408
5c6c5e63b263d486450c31d433da23c8d691f1a4	anwendung computergestützter simulationswerkzeuge zur unterstützung der strategisch-taktischen werksentwicklung eines batterieherstellers hinsichtlich der energieeffizienz		Der nachfolgende Beitrag versucht einen Weg aufzuzeigen, inwiefern das Verfahren der Modellbildung und Simulation eine Unternehmensentwicklung auf strategischer und taktischer Entscheidungsebene unterstützen kann, um effizienter Materialund Energieressourcen einzusetzen. Bislang wurden Software-Werkzeuge zur Modellbildung, wenn überhaupt, auf operativer Basis genutzt und flossen nicht in die konkrete strategische Ausrichtung bspw. der Produktion ein. Im Forschungsprojekt KapSimEnergie wurde daher der Versuch unternommen, eine derartige Unterstützung bereitzustellen. Das Projekt KapSimEnergie lief vom 15.08.2011 bis zum 14.04.2013.	eine and zwei;simulation;unified model	Alexander Bock;Volker Wohlgemuth	2013					-104.51512694196472	31.293625355785846	9424
495fc892e30cfd15e738363ed7fadf1594d67b28	an investigation of agility issues in scrum teams using agility indicators	agile software development;agile methods;agility indicator;context sharing;uncertainty;scrum agility indicator;scrum;research method;stability;conference paper;conference item;multiple case study;autonomous team;software development;enterprise agility	Agile software development methods have emerged and become increasingly popular in recent years, yet the issues encountered by software development teams that strive to achieve agility using agile methods are yet to be explored systematically. Built upon a previous study that has established a set of indicators of agility, this study investigates what issues are manifested in software development teams using agile methods. It is focused on Scrum teams particularly. In other words, the goal of the paper is to evaluate Scrum teams using agility indicators and therefore to further validate previously presented agility indicators within the additional cases. A multiple case study research method is employed. The findings of the study reveals that the teams using Scrum do not necessarily achieve agility in terms of team autonomy, sharing, stability and embraced uncertainty. The possible reasons include previous organizational plan-driven culture, resistance towards the Scrum roles and changing resources.	agile software development;autonomous robot;lero (software engineering);scrum (software development);software engineering	Minna Pikkarainen;Xiaofeng Wang	2009		10.1007/978-1-4419-7355-9_38	systems engineering;engineering;knowledge management;scrum;agile software development;process management;empirical process	HCI	-70.63045786533033	20.79849188979885	9431
a43bacf9a6fb63b97b6b729e9cdf3bbaeab859cc	ethics understanding of software professional in risk reducing reusability coding using inclusion set theory	set theory;software engineering;lines of code;software development	The technical skill or ability of an individual is different to person in software developments of projects . So, it is necessary to identify the talent and attitude of an individual contribution can be uniformly distributed to the different phases of software development cycle. The line of code analysis metrics to understanding the various skills of the programmers in code development. By using the inclusion set theory of n (AUB) refer to strength and risk free code developed from union of software professionals and system must comprise of achievement of the system goal, effective memory utilization and intime delivery of the product. KeywordsSoftware Development, Software Coding, People Managements, Inclusion Set Theory, Risk Analysis and Management.	experience;intime rtos / intime for windows;performance;programmer;risk factor (computing);set theory;software development process;source lines of code;static program analysis	G. Singaravel;V. Palanisamy;A. Krishnan	2009	CoRR		kpi-driven code analysis;reusability;personal software process;verification and validation;team software process;software engineering process group;software sizing;computer science;systems engineering;engineering;knowledge management;package development process;social software engineering;software framework;software development;software design description;software engineering;software construction;software walkthrough;programming language;management;source lines of code;software deployment;software development process;software quality;static program analysis;software system;set theory;software peer review	SE	-64.26172329301333	26.162237424877073	9453
ae9c76895ad2600c1fc3f6a982d7ed36f0e12d48	elche fangen - von der kunst in it-projekten beobachtungen und interviews durchzuführen		"""IT-Projekte leben von der engen Zusammenarbeit zwischen Entwicklern, Nutzern und anderen Stakeholdern. Beobachtungen und Interviews sind starke Instrumente, um Bedürfnisse, Wissen, Ideen, Befürchtungen und Erwartungen kennenzulernen. Sie dienen vor allem der Exploration, dem Entdecken, Verstehen und Erklären. Sie finden außerdem Einsatz in der formativen und summativen Evaluation. Im """"Walk and Talk"""" können Akteure in IT-Projekten Beobachtungen und Interviews in Unternehmens-, Prozess-, Projektund Anforderungsanalysen anwenden und die Ergebnisse für die Arbeit in ihren IT-Projekten verwenden. Ein Walk and Talk ist eine Kombination aus Beobachtung, Begehung und Gesprächen, die als leitfaden-gestützte Interviews geführt werden. Er erstreckt sich über einige Stunden bis zu zwei Tagen. Außerdem können noch Fokusgruppen-Interviews oder Workshops hinzukommen. """"Agil """"ist dieser Ansatz, weil er sich mit ein wenig Übung strukturiert, flexibel, ergebnisoffen und mit Fokus auf die Beforschten einsetzen lässt. Die Beforschten sind in der Regel die Nutzer und andere Kunden. Dabei können die Durchführenden das Konzept des """"Elchs auf dem Tisch"""" nutzen. Vier Elche stehen für Tabus in der Arbeitswelt, wie Macht, Karriere, Beziehungen und Fehler. Diese Tabus können sowohl negative als auch positive Energie in einem Unternehmen entwickeln. 1 Soziale Aspekte und Standardisierung in IT-Projekten: Die Rolle der Sozioinformatik """"Brauchen wir mehr Detaillierung der Verfahren oder ist es nicht besser, gut ausgebildete Fachleute mit einem gut gefüllten 'Vorgehens-' und 'ProjektmanagementWerkzeugkasten' auszustatten?"""" Diese Frage des Programmkomitees zum Workshop 2014 der GI-Gruppe Vorgehensmodelle möchte ich mit einem eindeutigen """"das kommt darauf an"""" beantworten. In IT-Projekten brauchen die Akteure vielfältige methodische, fachliche und soziale Kompetenzen. Schritte des Projektmanagement, der Software-Entwicklung oder Maintenance lassen sich sicher gut in detaillierten Vorgehensmodellen beschreiben. Wie sieht es jedoch mit dem Kennenlernen von Bedürfnissen, Wissen, Ideen, Befürchtungen und Erwartungen von Nutzern, Auftraggebern und anderen Stakeholdern in ITProjekten aus? Das ist ein wichtiges Thema in der Sozioinformatik."""	die (integrated circuit);eine and zwei;i/o controller hub;intentionally blank page;internet explorer;sie (file format);triple des;unified model;vhf omnidirectional range	Christa Weßel	2014			history;performance art	OS	-105.15768326483499	34.6667604133663	9462
968d8fc83711c331ecca14595dcbd49c4d308c6f	it-fabrik beflügelt die prozessorganisation		Die Diskussionen zur angemessenen Ausgestaltung der IT-Organisation werden seit fast 30 Jahren mit großer Leidenschaft geführt. Der rasche technologische Fortschritt und immer neue Anwendungsfelder heizen die Gespräche zwischen Nutzern, Herstellern und Management an, lassen aber leider immer nur kleine Etappenergebnisse zu. Viele Normierungsgremien, wie die International Organization for Standardization oder das britische Office of Government Commerce, haben technische und fachliche Standards erarbeitet und verabschiedet. Dennoch ergibt sich eine Lücke zwischen den de-jure und den de-facto Standards. Verbreitet und zum Einsatz kommen heute die Best Practices von den IT-Abteilungen. Eine Strukturierung dieser Erfahrungen und die Formulierung der wichtigsten Prozesse erfolgt durch Referenzmodelle. Gepaart mit dem richtigen Umsetzungswissen sowie dem Zugang zu aktuellen Technologien bieten die Modelle den wirtschaftlichsten Ansatz, IT-Leistungen der betrieblichen Organisation zur Verfügung zu stellen.	best practice;eine and zwei;fabrik (software);internet explorer	Sven Karl Mertens	2006	Praxis der Informationsverarbeitung und Kommunikation	10.1515/PIKO.2006.109	computer science;distributed computing	DB	-103.25484486040044	34.15878566209527	9474
46ab074f4285b737c338a28c12510da09384387a	the network from above and below	application identification;home network;home networks;access control;network management;ethnographic fieldwork	Recently, the HCI community has taken a strong interest in problems associated with networking. Many of those problems have also been the focus of much recent networking research, e.g., traffic identification, network management, access control. In this paper we consider these two quite different viewpoints of the problems specifically associated with home networking. Focusing on traffic identification as a core capability required by much recent HCI work, we explore the mismatch between the approaches the two communities have taken, and suggest some resulting challenges and directions for future work.	access control;human–computer interaction	Patrick Brundell;Andy Crabtree;Richard Mortier;Tom Rodden;Paul Tennent;Peter Tolmie	2011		10.1145/2018602.2018604	network management;simulation;computer science;access control;management science;computer security;computer network	Networks	-69.92132051751443	41.39044758968706	9479
a9361f7fff94b8766fb6c14a189a974a25c8e7df	automatisierung und fehlerdiagnose bei der extrakorporalen membranoxygenierung (automation and fault supervision for extracorporeal membrane oxygenation systems)		Die Extrakorporale Membranoxygenierung ist eine der letzten Therapieoptionen fur schwere Falle eines akuten Lungenversagens. Hierzu wird Blut in einem externen Kreislauf ahnlich einer Herz-Lungen-Maschine durch einen Oxygenator gepumpt. In diesem findet ein zusatzlicher Gasaustausch statt. Im Gegensatz zum Einsatz im Operationssaal wird die langer andauernde Therapie auf der Intensivstation in der Regel nicht kontinuierlich durch einen Kardiotechniker uberwacht. Die in diesem Beitrag vorgestellten Konzepte fur Automatisierung und Fehlerdiagnose sind ein wichtiger Schritt hin zu einem sicheren und zuverlassigen teil-autonomen Betrieb eines Systems, das sich den individuellen Bedurfnissen des Patienten kontinuierlich anpasst.	automation	Marian Walter;André Stollenwerk;Tobias Wartzek;Jutta Arens;Rüdiger Kopp;Steffen Leonhardt	2010	Automatisierungstechnik	10.1524/auto.2010.0838	engineering;control engineering;oxygenator;extracorporeal membrane oxygenation;mechanical engineering;cardiology;internal medicine	EDA	-105.01935599098383	30.33690324975797	9481
1c05644a39a441eccfce333215abf642b62aebd3	so einfach wie strom aus der steckdose: ein störfestes betriebssystem für sensible geschäftsprozesse			internet explorer	Jörg Wittenberger	2003				NLP	-102.05926416002163	28.786117151615144	9491
5775242a47edf3d3ac1d0b53ab35929a969afefa	das märchen von der funktion term_al_bad - overflow.				Stefan Eichholz	1986	Informatik Spektrum		world wide web;computer science	Crypto	-97.8571294317729	25.4604675652168	9510
72278ec9fc5239e8414f961fe0ae9d3e1684c329	teaching software modeling in a simulated project environment	case tools;software modeling;uml;best practice;software engineering;software engineering environment;design and implementation;case tool;project communication;modeling tool	Teaching software engineering in the academia always faces the problem of inability to show problems of real life development projects. The courses seem to be unable to properly show the need of using software modeling as important means of coping with complexity and handling communication within the project. The paper presents format of a course that tries to overcome this. It focuses on application of modeling tools in a realistic software engineering environment. The objective is to teach best practices of software design and implementation with the use of UML. The students can practice design and communication techniques based around CASE tools in teams of 12 to 14 people. The paper summarizes 5 years of experience in teaching modeling with CASE tools. Authors present a concept of how to simulate the roles of architects, designers and programmers as close to reality as possible. The paper also discusses the problems of organizing laboratory work for a large group of students. Authors present the tasks and their arrangement during the course.		Robert Szmurlo;Michal Smialek	2006		10.1007/978-3-540-69489-2_37	personal software process;verification and validation;simulation;software engineering process group;software sizing;software project management;uml tool;computer science;systems engineering;engineering;package development process;software design;social software engineering;component-based software engineering;software development;software design description;software engineering;applications of uml;software construction;software walkthrough;software deployment;computer-aided software engineering;software development process;software requirements;best practice;software peer review	SE	-66.05296837356165	25.88108631018285	9552
86805c009f1009aca2b74b8288d68e6bd96bd18a	gibt es eine datengrundlage für die systemmedizin?: eine literaturstudie am beispiel der pneumonie			eine and zwei	Robin Niklas Reschke	2017				NLP	-101.15762628022972	27.357207934349454	9569
e024949428fcf16f32402e9a8abfada40fdabbab	cross-business information technology integration and acquirer value creation in corporate mergers and acquisitions	long run abnormal operating performance;information technology;cross business it integration;corporate mergers and acquisitions;merger and acquisition;value creation;short run abnormal stock returns	This study develops and tests the idea that the cross-business information technology integration (CBITI) capability of an acquirer creates significant value for shareholders of the acquirer in mergers and acquisitions (M&A). In M&A, integrating the IT systems and IT management processes of acquirer and target could generate benefits such as (a) the consolidation of IT resources and the reduction of overall IT costs of the combined firm, (b) the development of an IT-based coordination mechanism and the realization of cross-firm business synergies, (c) the minimization of potential disruptions to business operations, and (d) greater ability to comply with relevant laws and regulations and the reduction of regulatory compliance costs. We test these ideas in a sample of 141 acquisitions conducted by 86 Fortune 1000 firms. In the short run, acquirers that have high levels of CBITI capabilities receive positive and significant cumulative abnormal returns to their M&A announcements. Announcement period returns indicate that the capital markets value CBITI similarly in same-industry and different-industry acquisitions. In the long run, acquirers with high levels of CBITI capabilities obtain significantly higher abnormal operating performance. They create significantly greater value in complementary acquisitions from different industries than in related acquisitions from the same industry. The findings have important implications for M&A research and practice.	acquiring bank	Hüseyin Tanriverdi;Vahap Bülent Uysal	2011	Information Systems Research	10.1287/isre.1090.0250	industrial organization;marketing;management;law;information technology;commerce	Logic	-82.6847029267685	6.617672779587806	9598
7c6f764588bbdde950638329b17e2b1b0623c63f	an ontology-based competency model for workflow activity assignment policies	assignment problem;competency based training;training;research paper;competences;work flow;gap analysis;business process management;domain specificity;business process;design methodology	Purpose – Assigning business process activities to agents (human or automated) for their performance or supervision is a critical issue in business process management. Role-based approaches are commonly used to specify work assignment policies, with roles defined as collections of capabilities and privileges required to perform job functions. The purpose of this paper is to address the activity assignment problem through a competency-based approach. In this context, an ontology-based competency model is developed to assist in identifying the competencies that exist in an organization and the competencies required, by workflow activities and in performing a competency gap analysis as a prerequisite for domain-specific user development through competency-based training. Design/methodology/approach – An approach for developing a business process activity assignment policy based on an ontology-based competency model is presented. This model is also used to define domain-specific training courses that enable users meet the competency requirements of process activities. In broad terms, the approach consists of the following steps: identification of the competencies required in order to perform the various activities involved in each business process and definition of roles based on these competencies; identification of the competencies acquired in the organization and assignment of users to roles; performance of competency gap analysis to identify the missing user competencies for role playing and identification of user development needs; and development of competency-based training scenarios intended to fill the user competency gaps. Findings – An experimental implementation of the ontology-based competency model proposed in the banking domain provided a fine-grained role structure that was based on the competencies required by business process activities, and a user-to-role assignment that closely matched the competencies required for role playing, and brought forward missing user competencies that pointed to required user training needs. Originality/value – The proposed ontology-based competency model fulfils the need for a sustained work assignment approach based on user roles. To this end, roles and users are defined as collections of required and acquired competencies, respectively. A novel approach based on ontology-based competency ontologies was also developed to fill required but missing user competencies.		Aristomenis M. Macris;E. Papadimitriou;George Vassilacopoulos	2008	J. Knowledge Management	10.1108/13673270810913630	workflow;simulation;economics;design methods;computer science;knowledge management;business process management;competence;assignment problem;business process;management	DB	-67.94425609708125	13.250619893002675	9608
f2635f4b672ef5a947d7a00ecf2a05f681f44431	entwicklung eines toleranzmodells zur behandlung von maß-, form- und lagetoleranzen				Dierk G. Feldmann;Sylvia Jörgensen-Rechter	1992			computational science;systems engineering;mathematics	NLP	-98.91022760805379	21.343398073825615	9613
fa892ed3ae257f6aad649b8a279c3c84a1793f57	study on audit evidence gathering cost under online auditing environment	audit cost management;software;auditing;costing;computer assisted audit field;information system online auditing audit evidence gathering audit cost;online auditing environment;materials;data mining;online auditing;audit cost management audit evidence gathering cost online auditing environment continuous auditing computer assisted audit field china;data analysis;costing auditing;audit evidence gathering;continuous auditing;information system;audit cost;china;data acquisition;cost management;algorithm design and analysis;hardware;audit evidence gathering cost;costs environmental management information science educational institutions environmental economics computer applications management information systems home appliances government public finance	Continuous auditing is an active research domain in computer-assisted audit field, and online auditing studied in China is also one mode of continuous auditing, The audit evidence gathering mode changed under online auditing environment, which will influence the audit evidence gathering cost. In this paper, audit evidence gathering method under online audit environment is introduced. Then, the components of audit evidence gathering cost under online auditing environment are analyzed. In addition, how online auditing environment influence the audit evidence gathering cost is analyzed. Finally, the strategies to reduce the audit evidence gathering cost under online auditing environment is proposed. The research in this paper can give theory guidance on audit cost management under online auditing environment.		Wei Chen;Sifeng Liu;Hong-yuan Zheng	2008	2008 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2008.4811734	information security audit;information technology audit;operational auditing;computer science;internal audit;audit trail;data acquisition;data analysis;joint audit;audit;audit plan;china;information system	DB	-79.99588231120254	13.035305335529443	9629
e04b9c5635a9dc09c511db93ac986300075a08e9	smart marketplaces: a step beyond web services	real time;web service;strategic alliance;system integration;business value;service integration	This paper identifies a new form of Internet intermediaries called smart marketplaces. Beyond other online marketplaces and strategic alliances, a smart marketplace provides an infrastructure and various core service components to facilitate the real-time integration of Web services. The structure of smart marketplaces and potential players are discussed. We analyze the business value of service integration offered by a smart marketplace, and further investigate the competition within and between smart marketplaces.	smart tv;web service	Xianjun Geng;Yun Huang;Andrew B. Whinston	2003	Inf. Syst. E-Business Management	10.1007/BF02683508	web service;computer science;marketing;business value;management;law;commerce;system integration	DB	-74.49440764574904	5.532554381720844	9654
650b8585ac398d2c46ada58bceac8b6e71d75649	the application profiles and development characteristics of library open source software projects	software sponsorship;software development;library systems;software licensing;open source software	Purpose – Little is known as to the breadth and diversity of Open Source Software (OSS) applications for libraries and the development characteristics that influence the sustainability and success of projects creating them. The purpose of this paper is to address this gap by analyzing a large sample of library OSS projects. Design/methodology/approach – A total of 594 library OSS projects (469 from SourceForge and 125 from Foss4lib) are classified by type and further differentiated and assessed across a number of criteria including, but not limited to, sponsorship status, license type, and development status. Findings – While various types of library OSS applications were found to be under development and in use, the results show that there has been a steady decrease in the number of projects initiated since 2009. Although sponsorship was significantly positively associated with several indicators of OSS project success, the proportion of sponsored projects was relatively small compared to the proportions reported in some other contexts. In total, 71 percent of the projects have a restrictive license scheme, suggesting that the OSS ideology is valued among library OSS projects. The results also indicate that library OSS projects exhibit several characteristics that differ from the traditional developer-oriented OSS projects in terms of their technical environment. Originality/value – This study, as the first of its kind, offers a broader, more quantitative picture of the state of library OSS applications as well as the development characteristics of projects developing them. Several implications for research and practice, and directions for future research are provided.	library (computing);open sound system;open-source software;sourceforge	Namjoo Choi	2014	Library Hi Tech	10.1108/LHT-09-2013-0127	team software process;software development;world wide web;library classification	SE	-69.45937856459578	30.462723115973176	9662
1350d38f4d6a0c5d2f1a2e25015d61505d269e44	"""erratum to """"numerical measures of segregation"""" [math. soc. sci. 42 (2001) 13-29]"""				R. Hutchens	2004	Mathematical Social Sciences	10.1016/S0165-4896(03)00086-6	mathematical economics;welfare economics;mathematics	Theory	-95.79621737746278	18.501663240966952	9666
90a5a50c39084d7c99fa14c6199dccfb7666817f	widersprüchliche ziele bei daten- und verbraucherschutz?		Der Datenschutz ist ein immer wieder neu diskutiertes Thema. Sein grundlegendes Ziel ist, dass der Bürger selbst über seine personenbezogenen Daten bestimmen kann. Für Unternehmen, die zur Unterstützung des Kundenkontakts Informationssysteme einsetzen, besteht daher bereits die Herausforderung, von ihren Kunden die Einwilligung zur automatisierten Verarbeitung deren personenbezogener Daten einzuholen. Der Artikel stellt dar, wie neue Vorschriften im Bereich des Verbraucherschutzes bei Finanzdienstleistungen (Vermittlerrichtlinie und MiFID (engl. Markets in Financial Instruments Directive)) nun sogar vorschreiben, dass bestimmte personenbezogene Daten des Kunden zu dokumentieren sind. Es wird erläutert, weshalb hierdurch Kunde und Finanzberater in ein Dilemma geraten und welche Herausforderungen sich für Finanzdienstleister bzgl. des Umgangs mit Kundendaten aufgrund dieser Vorgaben ergeben. Zudem werden resultierende Fragestellungen für die Informatik diskutiert.	directive (programming);es evm;internet explorer;prisoner's dilemma	Marcus Kaiser	2007	Informatik-Spektrum	10.1007/s00287-007-0225-x	world wide web;library science;computer science	Crypto	-102.88298829803594	35.53869545290373	9682
ebb0fa6e2cd47f632e26c9be49b332a028788b09	prozesssicherung komplexer verfahrenstechnischer systeme: dargestellt am beispiel eines druckluftsystems				Jürgen Ihlow	1984				NLP	-103.39629955684694	23.832893621644285	9720
811ccc3e82511e8bfc3cecffc678354d32da384a	optimal filters for the generation of multiresolution sequences	criterio optimalidad;filtering;filtrage;filtre reponse impulsion finie;optimal filtering;optimal filter;filtrado;finite impulse response filter;filtro respuesta impulsion acabada;filtro optimal;optimality criterion;critere optimalite;filtre optimal	Classes of filters are defined, for the optimal construction of multiresolution signal and image sequences. Minimization of the variances of the error images between successive levels is the optimality criterion. Both IIR and FIR filter characterization is obtained. Causal and noncausal, oneand two-dimensional filters are examined. Zusammenfassung Zur optimalen Konstruktion von Multiresolutionssignalund Bildfolgen werden bestimmte Klassen von Filtern eingef~hrt. Die Minimierung der Varianz der Fehlerbilder aufeinanderfolgenden Aufl6sungsstufen dient dabei als Optimalit/itskriterium. Es werden sowohl eine rekursive als auch eine nichtrekursive Beschreibung gewonnen. Kausale und nichtkausale, einund zweidimensionale Filter werden untersucht. R~um~ Nous d~finissons des classes de filtres pour la construction optimale de s~quences de signaux multi-r~solution et d'images. La minimisation des variances des images d'erreur entre niveaux successifs est le crit+re d'optimisation. La caract6risation de filtres RIF et RII est conjointement obtenue. Les filtres causaux et non causaux, monoet bidimensionnels sont examin6s.	bibliothèque de l'école des chartes;causal filter;eine and zwei;finite impulse response;infinite impulse response;linear algebra;optimality criterion;rule interchange format	Michael G. Strintzis	1994	Signal Processing	10.1016/0165-1684(94)90123-6	filter;electrical engineering;finite impulse response;control theory;mathematics;algorithm	ML	-98.161056001909	35.30887285315107	9742
b36bdb7607d62fee6d429af56301dbaa53112ba5	trade-offs in software design and delivery	design trade offs;creativity;innovation	"""There are many design and delivery trade-offs that engineers face in creating or evolving software systems. Challenges in accelerating delivery, offering more features, providing better more reliable systems, or managing costs - whose optimization are just some of the hurdles that contribute to system success (or failure). This panel will discuss the heuristics of trade-offs, the inherent risks - and plans to build on the success of the 2012 SPLASH workshop """"What Drives Design""""."""	heuristic (computer science);mathematical optimization;software design;software system	Steven Fraser;Richard P. Gabriel;Gail E. Harris;Ricardo Lopez;Dennis Mancl;William F. Opdyke	2012		10.1145/2384716.2384741	innovation;simulation;creativity	SE	-65.16611833261507	20.689211988479226	9749
493bbd3b14792e0d81eee47b7b8bdddf57b2afe7	rezension „einführung in die wirtschaftsinformatik band 1 und band 2“		Beide Bände erweitern den Bestand an Einführungs-/Lehrbüchern im Kerngebiet der Wirtschaftsinformatik. Dabei brechen beide Bücher, wie es die Autoren auch darlegen, bewusst mit den traditionellen Konzepten und Vorgehensweisen in der Vermittlung von Wirtschaftsinformatik-Kenntnissen. Vielmehr werden die Themen aus der Sichtweise der Digital Natives betrachtet und erläutert. Band 1 ist ausgelegt auf die Vermittlung der Grundlagen, auf das Verständnis des digitalen Zeitalters und der digitalen Transformation sowie auf die damit verbundenen Auswirkungen. In den ersten beiden Kapiteln wird eine Einführung in das Themenfeld der Wirtschaftsinformatik und deren Veränderungen gegeben, auch und vor allem im Zeitalter der Digitalisierung, sowie in das digitale Zeitalter an	3-methyl-2-oxobutanoate dehydrogenase (ferredoxin) activity;diethylstilbestrol;digital native;eine and zwei;eddie (text editor);internet explorer;ku band;vhf omnidirectional range	Christian Leyh	2018	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-018-0391-0		OS	-104.93698112053254	33.75544548370931	9753
b52e5538e7f344057e63b91b4d636f59f3158c71	optimal and stable supply chain services system: integrating management services with robust optimisation modelling	service system;robust optimisation;small and medium sized enterprises;risk management;1503 business and management;uncertainty management;0805 distributed computing;supply chain services;centre for strategic economic studies cses;scm;smes;optimisation modelling;management services;services systems;rscss;supply chain management;corporate governance	Developments in supply chain management (SCM) have dramatically increased within the past few years to cover a wide range of cross-disciplinary topics. With the significant developments in both technologies and business environments, a service system is proposed to work optimally under complex, globalised supply chain environments. Following the studies on SCM theories, this research develops a robust enterprise supply chain services framework taking into account of risk management in firm governance. Consequently, a robust supply chain services system (RSCSS) was built by combining optimisation modelling with the six-core management service modules of knowledge, data, task, information, communication and risk. In this system, the robust optimisation method was used to manage uncertainties. Importantly, by integrating the six-core management services modules with robust optimisation, this RSCSS can assist in supporting optimal and stable operations in a wide range of enterprises, especially for small and medium enterprises running global businesses dynamically and economically.	mathematical model;mathematical optimization;randomness;risk management;robust optimization;simulation;theory;victoria (3d figure);web service	Catherine Xiaocui Lou;Wei Dai	2015	IJHPCN	10.1504/IJHPCN.2015.066525	superconducting magnetic energy storage;corporate governance;supply chain management;service management;knowledge management;service system	ML	-76.98485894300435	7.5027897558733105	9796
b1128e7479eb726ca4aeaab09f389a6b992ba5f5	cios müssen sich auf sicherheit und innovation konzentrieren				Rudolf Kergaßner	2013	Wirtschaftsinformatik & Management	10.1365/s35764-013-0363-7		EDA	-95.98554774934131	26.671089434339763	9807
18e988e2981a8f697b0d666edc54bbf238695915	keep calm and wait for the spike! insights on the evolution of amazon services		Web services are black box dependency magnets. Hence, studying how they evolve is both important and challenging. In this paper, we focus on one of the most successful stories of the serviceoriented paradigm in industry, i.e., the Amazon services. We perform a principled empirical study, that detects evolution patterns and regularities, based on Lehman’s laws of software evolution. Our findings indicate that service evolution comes with spikes of change, followed by calm periods where the service is internally enhanced. Although spikes come with unpredictable volume, developers can count in the near certainty of the calm periods following them to allow their absorption. As deletions rarely occur, both the complexity and the exported functionality of a service increase over time (in fact, predictably). Based on the above findings, we provide recommendations that can be used by the developers of Web service applications for service selection and application maintenance.	black box;calm technology;input/output;lehman's laws of software evolution;programming paradigm;service-oriented architecture;service-oriented software engineering;the spike (1997);web service;world wide web	Apostolos V. Zarras;Panos Vassiliadis;Ioannis Dinos	2016		10.1007/978-3-319-39696-5_27	black box (phreaking);data science;systems engineering;computer science;amazon rainforest;empirical research;software evolution;web service;certainty;lehman's laws of software evolution	SE	-68.83390003253353	24.099055365304878	9830
73581bc47132dfebf39b678620df6b747d7864b7	newsgames: nuevas tendencias en el periodismo ibérico		El fenómeno de la gamificación en España ha cobrado un papel principal en los nuevos modelos de negocios. Durante los últimos años las estrategias de ludificación han comenzado a aplicarse con éxito en múltiples sectores, incluidos los del periodismo y la comunicación. En el siguiente artículo exponemos las cuestiones sobre las que se sustentan estos nuevos modelos periodísticos y señalamos los retos a los que se enfrentan. Además exploramos los últimos news games producidos en la península ibérica.	han unification;linear algebra;naruto shippuden: clash of ninja revolution 3	Francisco Julián Martínez Cano	2016				EDA	-107.11362136989788	16.604359182537884	9836
f2d516b02b4cb7877bc4e6a8093714025742454e	better standards to enhance european competitiveness	legislation;technological innovation;standards;competitiveness promotion european competitiveness european standardisation system market access consumer protection boost innovation;industries;production management;europe standards proposals technological innovation context legislation industries;europe;proposals;context	By outlining clear requirements for goods and services, standards help protect consumers, create new and larger markets, improve market access, boost innovation, and promote competitiveness. The European Commission has put forward proposals to modernise the European standardisation system to meet the challenges of our ever faster changing world, thus contributing to the objectives of smart, sustainable and inclusive growth.	competitive analysis (online algorithm);requirement	Liliana Brykman	2011	2011 7th International Conference on Standardization and Innovation in Information Technology (SIIT)	10.1109/SIIT.2011.6083602	economics;marketing;production manager;management;economic growth;commerce	Robotics	-81.36464450988674	6.894320948957834	9837
7c31a4019ab19db0123c90ba72250bc99d80ace5	design science research: paradigm or approach?	research paradigms;literature review;design science research	Due to the significant increase of theoretical evaluation of software prototypes, design science research (DSR) as a new research direction has emerged in recent years with the aim to ensure for both, rigor and relevance in prototyping research projects. On the one hand, a theoretical background ensures a usable and professional software prototype and on the other hand, new and innovative software prototypes provide rich data for theory testing and evaluating. DSR has proven to produce practically relevant research results but unfortunately it is still not a fully accepted research approach since it has somehow failed to develop theoretical contributions. Nevertheless, we believe that design science research is an important key factor for a new and innovative research paradigm. This paper provides an overview of DSR and tries to combine both, rigor and relevance, in a unified perception.	ansi escape code;programming paradigm;prototype;relevance;software prototyping	Sven Weber	2010			systems engineering;engineering;management science	SE	-63.89671962212319	19.323454889277873	9874
80b5ad8f0dcd097f6da4266dcca7dc1c128f73a2	génération de rdf à partir de sources de données aux formats hétérogènes		Résumé. Contrairement à ce que promeut le Web des données, les données exposées par la plupart des organisations sont dans des formats non-RDF tels que CSV, JSON, ou XML. De plus sur le Web des objets, les objets contraints préféreront des formats binaires tels que EXI ou CBOR aux formats RDF textuels. Dans ce contexte, RDF peut toutefois servir de lingua franca pour l’interopérabilité sémantique, l’intégration de données aux formats hétérogènes, le raisonnement, et le requêtage. Dans ce but, plusieurs outils et formalismes permettent de transformer des documents non-RDF vers RDF, les plus flexibles étant basés sur des langages de transformation ou de correspondance (GRDDL, XSPARQL, R2RML, RML, CSVW, etc.). Cet article définit un nouveau langage, SPARQLGenerate, qui permet de générer du RDF à partir: (i) d’une base de données RDF, et (ii) d’un nombre quelconque de documents aux formats arbitraires. L’originalité de SPARQL-Generate est qu’il étend SPARQL 1.1, et peut donc (i) être appris facilement par les ingénieurs de la connaissance familiers de SPARQL, (ii) être implémenté au dessus de n’importe quel moteur SPARQL existant, (iii) tirer parti des mécanismes d’extension de SPARQL pour prendre en compte de futurs formats.	bibliothèque des ecoles françaises d'athènes et de rome;cbor;efficient xml interchange;extensibility;grddl;json;linear algebra;quel;resource description framework;sparql;semantic interoperability;transformer;web of things;world wide web;nouveau	Maxime Lefrançois;Antoine Zimmermann;Noorani Bakerally	2017			database;rdf;computer science	Security	-107.56421016282836	14.869717661074068	9896
d55ea4ac46dd322eb79c8500b13a17b37620b717	why not one big database? principles for data ownership	94;decentralization;outsourcing;case history;distributed database;theoretical framework;standards;translation value;converters;incentives;information technology;costs and benefits;economic modelling;ownership;database management;economic models;information sharing;distributed database design;distributed databases;incomplete contracts;database design;hd28 m414 no 3695;hd28 m414 no 3695 94;centralization	Results of this research concern incentive principles which drive information sharing and affect database value. Many real world centralization and standardization efforts have failed, typically because departments lacked incentives or needed greater local autonomy. While intangible factors such as “ownership” have been described as the key to providing incentives, these soft issues have largely eluded formal characterization. Using an incomplete contracts approach from economics, we model the costs and benefits of restructuring organizational control, including critical intangible factors, by explicitly considering the role of data “ownership.” There are two principal contributions from the approach taken here. First, it defines mathematically precise terms for analyzing the incentive costs and benefits of changing control. Second, this theoretical framework leads to the development of a concrete model and seven normative principles for improved database management. These principles may be instrumental to designers in a variety of applications such as the decision to decentralize or to outsource information technology and they can be useful in determining the value of standards and translators. Applications of the proposed theory are also illustrated through case histories.	autonomy;database;outsourcing	Marshall W. van Alstyne;Erik Brynjolfsson;Stuart E. Madnick	1995	Decision Support Systems	10.1016/0167-9236(94)00042-4	economics;incentive;computer science;knowledge management;cost–benefit analysis;marketing;economic model;operations management;centralized government;data mining;database;management science;management;world wide web;decentralization;distributed database;database design;outsourcing	DB	-76.40788435565555	11.27611774229205	9913
850c9f6364521a1f8d9bb88d1f08505f9b836e85	unser aller profession gib uns heute? oder die frage nach einer mäeutischen informatik		In der bisherigen Professionalisierungsdebatte der Informatik fällt ein deutlicher Bezug zu einem klassisch-kriteriellen bzw. funktionalistischen Professionsbegriff auf, der sich seit den 30er Jahren (nicht nur) in der Professionssoziologie als sehr wirkmächtig darstellt. Ein solcher Professionsbegriff verstellt aber den Blick auf die Problemlagen, die von Interesse sind, wenn wir professionelles informatisches Handeln (im Sinne angewandter Informatik) begreifen wollen. Dieser Beitrag will den Blick öffnen – hin zu anderen Professionsbegriffen und anderen Professionalisierungsdiskursen, die den Denkund Handlungsmustern der angewandten Informatik näher liegen.	gibibyte	Peter Bittner	2003	EMISA Forum		systems engineering;library science;computer science	OS	-102.62726655613358	33.43522509771131	9949
0676d96b57a6338ef6fa65cd8e9315d6de4221a9	a conformance test suite for ttcn-3 tools	compiler testing;conformance testing;semantics tests;syntax tests;ttcn-3	With more than 10 years of maturing through industrial use and standardization, the Testing and Test Control Notation (TTCN-3) has become a widely used technology that many businesses depend upon for ensuring their product quality. With the rising number of supporters and tools, the demand for a means to assess the standards compliance of TTCN-3 tools has increased. In this article, we describe the motivation, approach, methodology, and results of the still ongoing project to develop a standardized conformance test suite for TTCN-3 tools. We discuss the challenges involved in creating such a test suite, the way to deal with imposed resource limitations of the project, and where we think the effort is heading.	conformance testing;course (navigation);standards-compliant;ttcn-3;test suite	Benjamin Zeiss;András Kovács;Nikolay V. Pakulin;Bogdan Stanca-Kaposta	2013	International Journal on Software Tools for Technology Transfer	10.1007/s10009-013-0285-y	software engineering	SE	-64.98594492297934	27.170006605252254	9963
0e88dc988e596e716eae89f79370bdc58796a004	two view line-based matching, motion estimation and reconstruction for central imaging systems. (mise en correspondance de lignes à partir de deux vues, estimation du mouvement et reconstruction pour les systèmes centraux)			iso 8601;motion estimation	Saleh Mosaddegh	2011				Vision	-104.63208685644277	11.21513619962503	9968
d5251ebc29bf3d9d72571ac8defaa5b2b59f96ef	positive affects inducer on software quality	positive affect;software quality	This paper presents an early empirical study on an agile methodology (Extreme Programming) using Positive Affect metric. The question of interest is whether an agile methodology has any distinct outcome on the positive affectivity of the software developers. And whether these affects will contribute to the quality of software produced. Quantitative methods were utilized, including participative observation and simple statistical tests such as Spearman Correlation and Mann-Whitney test. The results showed that Extreme Programming has positive affectivity which leads to the increase in software quality. This study suggests that when people experience joy and mild contentment, they are more likely to be more creative over wider range of problems, become more resilient over time and are more likely to develop long-term plans and goals.	agile software development;experience;extreme programming;proactive parallel suite;software developer;software engineering;software quality	Sharifah Lailee Syed-Abdullah;Omar Mazni;Mohd Nasir Abdul Hamid;Che Latifah bt Ismail;Jusoff Hj. Kamaruzaman	2009	Computer and Information Science		simulation;computer science;software quality;affect	SE	-72.1160866290001	22.170618534544705	10024
cd3089f500b978c262336e6560321c162dddab7a	introduction of the software configuration management team and defect tracking system for global distributed development	distributed development;software metrics;distributed system;configuracion;description systeme;systeme developpement;system description;systeme reparti;tracking system;metrique logiciel;gestion sistema;software management;gestion configuration;software configuration management;sistema repartido;development systems;descripcion sistema;configuration;system management;configuration management;gestion systeme;gestion logiciel	This article explains an experience of introducing a Software Configuration Management Team and Defect Tracking System for a global distributed development. A Software Configuration Management Team was set up at one site and included the responsibility of representing the other site for defect fixing prioritization. The Defect Tracking System could include descriptions in both English and Japanese and could replicate the contents between the two sites. The Software Configuration Management Team monitored metrics and identified the fundamental communication problems between the two sites, and improved the system to solve the problems. As a result of this, the ratio of the number of newly introduced defects by modification for defect removal was reduced to one-third of the ratio at the starting point of testing.		Shinji Fukui	2002		10.1007/3-540-47984-8_25	systems management;simulation;tracking system;software configuration management;computer science;artificial intelligence;configuration management;configuration;software metric	SE	-67.1379464970955	32.73293054470905	10044
6ac5101ea814fcc83e10e3daebdf94f7d469123f	a study of user involvement in packaged software selection		This paper is concerned with the decision-making processes surrounding the adoption of packaged software in organizations. We begin by looking at its increasing utilization and consider some of the strengths and limitations of employing a standardized approach, particularly in relation to its consideration of end-user requirements. We note the highly problematic nature of installing a global standardized product in the local environment. Using a field study concerning the adoption of a customer relationship management package in a small organization, we go on to illustrate the limited amount of end-user involvement in the selection and procurement of the product. We argue that the art of salesmanship by the third party vendor and project team, which focuses on the interests of senior management, ultimately secures the selection and procurement of the	customer relationship management;field research;procurement;requirement;user requirements document	Debra Howcroft;Ben Light	2002			marketing;operations management;database;management	SE	-76.56872534331463	10.149930921318477	10050
fb215dde68f8da07d2ef9cfd4f2849e699173d0c	c++-entwicklung mit linux - eine einführung in die sprache und die wichtigsten werkzeuge, von gcc und emacs bis sniff+			eine and zwei;linux;emacs	Thomas Wieland	2001				OS	-101.8304556276229	30.225448949277176	10059
68dd5e23dcf7ba9d3f12805ffa022b8b4aec5ab4	a model for availability growth with application to new generation offshore wind farms	offshore wind farm;management industrial management;condition monitoring;systemic risk;availability growth	A model for availability growth is developed to capture the effect of systemic risk prior to construction of a complex system. The model has been motivated by new generation offshore wind farms where investment decisions need to be taken before test and operational data are available. We develop a generic model to capture the systemic risks arising from innovation in evolutionary system designs. By modelling the impact of major and minor interventions to mitigate weaknesses and to improve the failure and restoration processes of subassemblies, we are able to measure the growth in availability performance of the system. We describe the choices made in modelling our particular industrial setting using an example for a typical UK Round III offshore wind farm. We obtain point estimates of the expected availability having populated the simulated model using appropriate judgemental and empirical data. We show the relative impact of modelling systemic risk on system availability performance in comparison with estimates obtained ∗Corresponding Author Email addresses: athena.zitrou@strath.ac.uk (Athena Zitrou), tim.bedford@strath.ac.uk (Tim Bedford), lesley.walls@strath.ac.uk (Lesley Walls) Preprint submitted to Reliability Engineering & System Safety November 17, 2015 from typical system availability modelling assumptions used in offshore wind applications. While modelling growth in availability is necessary for meaningful decision support in developing complex systems such as offshore wind farms, we also discuss the relative value of explicitly articulating epistemic uncertainties.		Athena Zitrou;Tim Bedford;Lesley Walls	2016	Rel. Eng. & Sys. Safety	10.1016/j.ress.2015.12.004	reliability engineering;engineering;systemic risk	ML	-64.76360373705707	20.4526879644373	10078
1e8f055ca0702e7cf749ca7545d91a3d27ab3ec5	a dynamic analysis on implementing performance excellence model: importance, achievement and correlations	importance level;improvement;performance;performance excellence model;correlation;achievement level	Performance excellence model (PEM) has become an important management pattern for many years in the world. In 2004, China issued two national standards of PEM. But at present, most researches on PEM are based on the static data on some certain time, in this way there lacks systematic research on its dynamic changes features, including the improvement of PEM implementation, the impacts of process improvement towards results improvement, etc. Hence this article conducts a research on the improvements of items’ achievement levels of PEM implementation, the relationship between the improvements and items’ importance levels, and the impacts of process improvements towards financial results. Through the researches on the Government Quality Award (GQA) recipients in Shandong province and Anhui province, it is found that those recipients have gained improvements with different levels in terms of item’s achievement after PEM implementation and the achievement level is in positive correlation with its importance. Besides, under the control of achievement level before PEM import, the improvement rate of achievement is also in positive correlation with its importance. Moreover, the improvement of process helps to improve the financial results and each 1% increase in the process’s improvement rate of achievement level per year on average will lead to a 0.605% increase in the annual improvement rate of financial results. Organization’s opinion on importance level is different with the PEM criteria. And the point value gap among process categories should be narrowed down. 2016 Elsevier Ltd. All rights reserved.	capability maturity model;factor analysis;industrial robot;philip l. roe	Decheng Wen;Jie Lv;Xiao Chen;Ting Dai	2016	Computers & Industrial Engineering	10.1016/j.cie.2016.09.024	performance;engineering;operations management;mathematics;management;operations research;correlation	HPC	-84.7984041466455	7.686142118057213	10120
b3ce415635c7b57f309b63a1068617ef2123d972	division of labour and the design of systems for computer support for cooperative work	general study;information management system;condicion trabajo;information systems security;science gestion;mis systems;information systems research;type;journal of it;tipo;collaborative work;analisis sistema;jit;teaching cases;information security;concepcion sistema;case studies;information science;division of labour;cooperation;information security systems;information technology;business information technology;security information systems;it journals;technologie information;information systems management;methode;it teaching cases;cooperacion;operational research society;work division;estudio general;travail en collaboration;business model;estudio impacto;journal of information technology teaching cases;etude impact;estudio caso;computer information systems;jit journal;computer support for cooperative work cscw;team work;geographic information systems;system design;information technology journal;information management;information systems journals;information systems technology;computer aid;managing information systems;etude cas;accounting information systems;travail equipe;system analysis;information and management;management information systems;trabajo equipo;define information systems;asistencia ordenador;strategic information systems;analyse systeme;sociologie travail;business information management;soft system methodology;information system;health information systems;computer information technology;journal of information technology;working condition;etude generale;business information systems;tecnologia informacion;business systems analyst;condition travail;metodo;impact study;division travail;method;assistance ordinateur;conception systeme;work sociology;social power;journal information technology;it journal;management science;cooperative work;journal of information systems;poder;information technology journals;pouvoir social;organizational requirements definition for information technology ordit	The design of systems which provide computer support for cooperative work (CSCW) has been dominated by models of collaborative teams in academic or design environments. Such settings are characterized by a relatively egalitarian power distribution and a division of labour established locally by the collaborating parties. This paper describes other types of collaborative work in which the roles of participants are characterized by pre-established divisions of labour and unequal power distribution. A case study is presented of a collaborative group allocating and scheduling service calls in an electricity company. Using the Organizational Requirements Definition for Information Technology (ORDIT) methods for responsibility analysis a number of alternative organizational structures are described which may serve this task. The alternatives are based upon different job design structures which distribute responsibilities to work roles by different rationales. An analysis is offered of the different CSCW systems that would be necessary to support these alternatives. The paper concludes by examining the implications of pre-established but variable organizational structures for the design of generic CSCW systems.	technical support	Ken Eason	1996	JIT	10.1080/026839696345414	computer science;engineering;knowledge management;electrical engineering;computer-supported cooperative work;management information systems;sociology;management;operations research;information technology;information system	HCI	-66.92574765937769	5.846652983621222	10135
d5cccfe9e6136cf6d92b88d5d2591f7afe14e943	modélisation de l'impact des croyances et de la communication sur la formation et la dynamique des attitudes : une approche multi-agent		Cet article presente un modele de simulation multi-agent permettant d’etudier la formation et la dynamique des attitudes basees sur la perception des individus ainsi que sur la diffusion de l’information par le biais de la communication. Nous presentons l’attitude comme etant un ensemble d’associations entre l’objet social et ses evaluations d’intensite variable, comme le propose Fazio [11]. Nous illustrons le role de la communication sur la dynamique des attitudes au travers de plusieurs experimentations.	bibliothèque de l'école des chartes;bibliothèque des ecoles françaises d'athènes et de rome;linear algebra;multi-agent system	Kei-Léo Brousmiche;Jean-Daniel Kant;Nicolas Sabouret;Stéphane Fournier;François Prenot-Guinard	2014			psychoanalysis;sociology	Crypto	-105.62862754464076	15.297158456808273	10137
9fd147e532bf1a4d97fee4fca8bc6f02de75320d	central patents index chemical code: a user's viewpoint	compose chimique;search strategy;etude comparative;recherche documentaire;indexation;comparative study;strategie recherche;document retrieval;chemical compound	Evaluation comparative de l'efficacite de la recherche sur les brevets decrivant les composes chimiques, selon qu'elle est effectuee a partir du Code de fragmentation chimique ou a partir d'autres strategies de recherche		Edlyn S. Simmons	1984	Journal of Chemical Information and Computer Sciences	10.1021/ci00041a004	document retrieval;computer science;comparative research	Theory	-107.85683276011946	14.208294063004063	10166
ec8662964a2da89f2d2686cc7f7b7eb469676314	beitrag zur mathematischen modellbildung und digitalen simulation des wärme- und stofftransportes unter besonderer berücksichtigung der thermischen nutzung unterirdischer wässer durch wärmepumpen			simulation;zur farbenlehre	Norbert Victor	1983				Theory	-101.38660144454062	25.840055449075138	10201
e258cbfd0382a18842202e1d62a697ad3a78295b	how interfirm collaboration benefits it innovation	reseau social;inversion;information technology;innovation process;technologie information;investment;information technology innovation;social network;modelo;firm cooperation;innovation;etude longitudinale;estudio longitudinal;social networks;analyse correlation;investissement;modele;cooperation entreprise;interfirm collaboration;innovacion;tecnologia informacion;longitudinal data;follow up study;models;information technology investment;cooperacion empresa;red social;analisis correlacion;correlation analysis	Many studies have observed that close interfirm collaborations have positive effects on a firm’s innovation. Yet, they have not shown how the collaboration contributes to this process. Higher innovation rates could be a result of revolutionary improvements, evolutionary improvements, or both. We investigated changes in the innovation process. Longitudinal data from 23 top IT firms across 9 years were collected and analyzed. Results suggested that close interfirm collaborations were associated with evolutionary but not revolutionary improvement. Results also suggested that the longer the IT firms had engaged in close interfirm collaboration, the larger the effect on IT innovations. # 2006 Elsevier B.V. All rights reserved.		Buraj Patrakosol;David L. Olson	2007	Information & Management	10.1016/j.im.2006.10.003	innovation;social science;economics;operations management;sociology;management;operations research;information technology;social network	AI	-86.25826683749689	4.5248827888422065	10212
6b0b1581ef8655ed0c3efa7f8f88afa8b0c3dc4a	towards evidence based splitting of organizations	graph theory;water management;building block	The reported research program aims at finding and testing principles for adequately splitting organizations. Using actors from Enterprise Ontology as organization building blocks on one hand and criteria from organization science on the other hand, an expert-meeting was presented the organizationsplitting choices for a part of the Dutch Agency of Public Works and Water Management. The experts could construct their own free-format (gut-feeling) organization choice and they could choose from predefined alternatives, based on the High Internal Cohesion / Low External Coupling criterion and calculated using the min-cut algorithm from graph-theory. The gut-feeling alternative appeared to be close to the (non-trivial) calculated organization alternative, with separation of functions as main reason for difference. Also, business service dependencies appeared to determine organization-splitting far more dominantly than information dependencies.	algorithm;graph theory;maxima and minima;minimum cut	Martin Op't Land	2007		10.1007/978-0-387-73947-2_25	combinatorics;knowledge management;operations management;mathematics	Web+IR	-76.51510272153338	13.672128293283055	10231
3768e39dd4d60538de454f270949501417293ac0	alfabetización tecnológica: el reto del gobierno electrónico en méxico	capacitacion;gobierno digital;ciudadanos;elecciones;divulgacion;voto;estrategia de estado;tecnologias de la informacion y comunicacion;gobierno electronico;tecnologica;alfabetizacion;mexico	The aim of this study is to review strategies, policies and the institutional agenda from the Mexican e-government; also explains the combined effect of environment (internal and external forces) in the National System named “e-México”, this info can be used as a guidelines to manage risks of digital government by leaders. Digital government can be viewed as a complicated game “crossword puzzle”, composed of individual rules and players, when all players join up properly, the entertainment is granted, GOBIERNO ELECTRÓNICO * Este artículo forma parte del Proceeding of the 10th Annual International Conference on Digital Government Research. http://dl.acm.org/citation.cfm?id=1556176.1556204&coll=&dl=GUIDE&type=series&idx=SERIES10714&part=series& WantType=Proceedings&title=AICPS ** Líder de proyecto en materia de seguridad informática bancaria antifraude desde 2012. En México ha desarrollado proyectos en varios estados de la República Mexicana y a nivel Internacional en Estados Unidos de América. Ingeniero en Sistemas Computacionales con Especialidad en Desarrollo de Aplicaciones Software por el Instituto Politecnico Nacional. Consultor de proyectos de sistemas convergentes Web/VoIP y Desarrollador de aplicaciones J2EE. *** Maestría en Administración. Facultad de Contaduría Pública. Benemérita Universidad Autónoma de Puebla. México, Consultora en proyectos de Gobierno Electrónico para la Secretaría de Asuntos Políticos de la Organización de los Estados Americanos desde 2009. Doctoranda en Estudios Jurídicos por la Universidad Rey Juan Carlos. Máster en Estudios Sociales de la Ciencia y la Tecnología por la Universidad de Salamanca (España). Máster en Informática y Derecho por la Universidad Complutense de Madrid, Licenciada y Maestra en Derecho por la Escuela Libre de Derecho de Puebla.	crossword;e-governance;e-government;fire emblem: path of radiance;iso 8601;linear algebra;méxico indígena;naruto shippuden: clash of ninja revolution 3;power-on reset	Enrique Gabriel Munive Aportela;Erika Yamel Munive Cortés	2009			geography;management;cartography	EDA	-106.97845480780963	20.53850176701055	10299
72ad5972822ebc35834b8824ab9c9d221a7c65a5	entwicklung nichtlinearer tomographischer rekonstruktionsverfahren für die materialprüfung und prozessüberwachung				Uladzimir Samadurau	2005				Robotics	-99.32469602508402	24.722905080649927	10301
64c04b05eccee20f864c46b768a59430822567ad	big data for supply chain management in the service and manufacturing sectors: challenges, opportunities, and future perspectives	journal article;service applications;big data;supply chain management scm;manufacturing sector	Data from service and manufacturing sectors is increasing sharply and lifts up a growing enthusiasm for the notion of Big Data. This paper investigates representative Big Data applications from typical services like finance & economics, healthcare, Supply Chain Management (SCM), and manufacturing sector. Current technologies from key aspects of storage technology, data processing technology, data visualization technique, Big Data analytics, as well as models and algorithms are reviewed. This paper then provides a discussion from analyzing current movements on the Big Data for SCM in service and manufacturing world-wide including North America, Europe, and Asia Pacific region. Current challenges, opportunities, and future perspectives such as data collection methods, data transmission, data storage, processing technologies for Big Data, Big Data-enabled decision-making models, as well as Big Data interpretation and application are highlighted. Observations and insights from this paper could be referred by academia and practitioners when implementing Big Data analytics in the service and manufacturing sectors. 2016 Elsevier Ltd. All rights reserved.	algorithm;big data;computer data storage;data visualization	Ray Y. Zhong;Stephen T. Newman;George Q. Huang;Shulin Lan	2016	Computers & Industrial Engineering	10.1016/j.cie.2016.07.013	big data;computer science;engineering;marketing;operations management;management;operations research	DB	-71.64378750566472	5.67002079800311	10319
56004eb8b75db568ca58323490975dee633d0bbc	fuse by: syntax und semantik zur informationsfusion in sql		Daten und Informationen heterogener Quellen können gleiche Objekte repräsentieren und dennoch sich widersprechen oder sich ergänzen. Werden solche Daten integriert, entstehen Datenkonflikte. Wir beschreiben eine einfache Ergänzung von SQL, die Daten über gleiche Objekte fusioniert. Der FUSE BY Operator vereint sich ergänzende Daten zu einem Tupel und löst gegebenenfalls Datenkonflikte. Neben der Syntax des Ausdrucks beschreiben wir seine einfache und intuitive Semantik. Schließlich werden Erweiterungen diskutiert, die es erlauben den Ausdruck um Expertenwissen zu ergänzen. 1 Informationsfusion Integrationssysteme stellen Nutzern eine einheitliche Sicht auf mehrere Informationsquellen zur Verfügung. Die Abfrage der einzelnen Informationsquellen und das Zusammenführen der Informationen aus den Quellen übernimmt dabei das Integrationssystem. Dabei müssen auftretende Konflikte auf Schemaund Datenebene gelöst werden. Unter Informationsfusion in Integrationssystemen (auch: Data Merging) wird im Folgenden der Prozess des Zusammenführens der Daten aus den einzelnen Quellen unter Auflösung von auftretenden Konflikten verstanden. Dabei wird Objektidentität vorrausgesetzt, z.B. durch eine global eindeutige und konsistente ID. Abbildung 1 zeigt als Beispiel zwei Tabellen, die jeweils die Daten einer Informationsquelle repräsentieren. Die Tabellen überlappen sich sowohl vertikal in den Spalten, als auch horizontal in den Personen. Desweiteren ergänzen sich die Tabellen: Spalte PKW ist nur in Tabelle Q1 enthalten, Spalte TELEFON ausschließlich in Tabelle Q2. Wie leicht zu erkennen ist, ergeben sich auf Datenebene möglicherweise Konflikte. So sind z.B. die Personen Melanie, Jens und Christoph in beiden Tabellen beschrieben. Es sind zwei verschiedene Konfliktarten zu unterscheiden: a) ” Unsicherheiten“, also fehlende Information durch NULL Werte in den Tabellen, z.B. das Alter von Jens in Tabelle Q1 und b) ” Widersprüche“, z.B. das Alter von Christoph . Möchte man die Daten aus beiden Tabellen in eine einzige Tabelle überführen, bzw. anfragen, stellt sich die Frage, wie man mit den auftretenden Konflikten umgeht. Dieses Problem wurde erstmals in [Da83] erwähnt. Seither gibt es verschiedene Lösungsansätze, vor allem zur Konfliktvermeidung (Beseitigung von Unsicherheit). Gleichwohl gibt es kein In-	eine and zwei;emoticon;internet explorer;list of concept- and mind-mapping software;sql;unified model;vhf omnidirectional range	Jens Bleiholder;Felix Naumann	2004			syntax;sql;fuse (electrical);natural language processing;computer science;artificial intelligence		-106.61151745875019	35.59762341392701	10320
0ea2943de0282502f5e33547b0e380e42acd63f2	systemanalytische aspekte bei der entwicklung von expertensystemen				Johannes Ecke-Schüth	1991				NLP	-100.36044512817828	25.248597356752033	10332
fd8da97f5e77a210c6e3a7e66216ed34e42a6283	fault prediction and dynamic error analysis in computer systems	software metrics;abstract data types;programming abstraction;real time monitoring;system performance;error analysis;system development;fault diagnosis;data types	Real time monitoring and analysis of computer system performance data can be advantageous in many ways to an industry that spends many billions of dollars each year on computer systems development and service.  Traditional approaches to computer system fault diagnosis and repair have a distinctly ex post facto character. From legions of computer service representatives, only a particularly efficacious few seem able to divine accurate clues about failing components by using collections of computer system performance data. Additionally, tracing intermittent problems using this post mortem approach is time and resource intensive and is economically unattractive, especially as installed bases grow and expert technicians become more scarce.	computer;error analysis (mathematics);failure;software development process	Roy A. Maxion	1981		10.1145/800175.809885	embedded system;real-time computing;simulation;computer science	Graphics	-63.71557144496172	40.28079868024461	10341
5ab38b174397dfb7bb838679db217b2e1385c0a1	the educational value chain as a modelling tool in re-engineering efforts	business environment;value chain	Educational models are used within an institution to describe different educational components and the existing relationships. The important components within an educational domain are in a sense similar to business environments including institutional structures, processes and resources. In the educational domain, the developer may use educational models to gain a better understanding of the key mechanisms of the specific problem domain or to act as a basis for improving current structures and operations of the different processes within the problem domain. In this paper, we introduce the educational value chain as a graphical tool that developers may use in re-engineering efforts to identify possible bottlenecks that are likely to occur, as well as providing a route to follow when determining the value that can be added by technology.	graphical user interface;problem domain	Alta van der Merwe;Johannes C. Cronjé	2004		10.1145/1071509.1071534	simulation;business domain;systems engineering;engineering;operations management	HCI	-64.15448448918056	15.393291213117365	10350
bd2a9d55c581107207e365759ea50ad9aed97020	gutachter der at-beiträge in 2008 und 2009				Bernd Reißenweber	2010	Automatisierungstechnik	10.1524/auto.2010.0816	engineering;control engineering;mechanical engineering	Logic	-105.21081392864983	25.00635239967636	10447
81fa6798a51d3fae89a2887e430bbc6abff9a7a8	sécurisation d'un système de transactions sur terminaux mobiles. (securing a mobile-based transaction system)				Chrystel Gaber	2013			computer network;database transaction;business	DB	-94.02162551582396	29.809905692763277	10502
556fd8b4f93e40c3491d2d7ccbf657db002f64ef	maintenance management initiatives towards achieving sustainable development		As sustainable development is a concept more and more popular, the need to provide its practical application has emerged. The way to help companies improve their economical, environmental and social performance is by minimizing waste. It means less waste generated and increase waste reusage or recycling; using resources such as materials, water and energy at the highest possible efficiency; avoiding or at least improving management of metalworking fluids, lubricating oils and hydraulics oils. Other goals are improved environmental, health and safety performance, adopting lean manufacturing and other sustainable engineering techniques, as well as improved working conditions. The achieve reduction of waste at production site best practice in manufacturing and maintenance processes are needed. The aim of this chapter is to present how well performed maintenance management can help to achieve sustainable development of a company.	best practice;integrated computer-aided manufacturing	Malgorzata Jasiulewicz-Kaczmarek;Przemyslaw Drozyner	2011		10.1007/978-3-642-19536-5_55	environmental planning;systems engineering;environmental resource management	HCI	-62.86272404657427	8.782638800178358	10519
296deb8570308170b072d6c0eb1a307538454d52	alles 4.0! oder manchmal doch 3.5?		Einleitung Industrie 4.0 ist sowohl in der Wirtschaft als auch in der Wissenschaft ein vieldiskutiertes Thema. Bezeichnet wird damit die vierte industrielle Revolution, in der Informationstechnologie eine wesentliche Rolle spielen wird, was durch die softwaretypische Versionsnummer unterstrichen wird – nicht ,,Industrie 4“, sondern ,,Industrie 4.0“. Darüber hinaus gibt es Berührungspunkte zu weiteren aktuellen Themen, z. B. zum Internet der Dinge, zum taktilen Internet, zu Big Data und auch zu autonomen Systemen. Wissenschaftler verstehen, dass die vierte industrielle Revolution Antworten auf bislang unbeantwortete Fragen erfordert. Wirtschaftsvertreter erwarten bessere Geschäfte durch individualisierte Produkte oder Vorteile durch Qualitätsgewinne und eine flexiblere Produktion. Es scheint so, als müsse man sich unbedingt mit dem Thema befassen und dazu eine Position entwickeln. Der Anhang ,,4.0“ steht für einen Aufbruch im positiven Sinne und wird inzwischen gern auch in Bereichen verwendet, die mit der vierten industriellen Revolution nicht in Beziehung stehen. Vielfach wird er auch einfach für ,,Digitalisierung von irgendetwas“ verwendet. So enthält Der Wirtschaftsführer für junge Juristen 2016/2017 [1] gleich vier Artikel, in denen ,,4.0“ vorkommt: ,,Jurist 4.0: IT verstehen, umsetzen und nutzen“, ,,Justiz 4.0 – auch die Justiz wird noch digitaler“, ,,Lawyer 4.0 – Legal Tech, lernfähige Algorithmen und analoges Recht“ und ,,Legal Function 4.0 – und was dies für junge Anwälte bedeutet“. Während im Industriebereich die vorhergehenden drei Revolutionen eindeutig benannt werden können, kann das in der Juristerei durchaus bezweifelt werden. Man kann sich schon fragen, wer oder was denn ,,Jurist 2.0“ war. Allerdings ist auch in der Produktion keine eindeutige, allgemein akzeptierte Definition von Industrie 4.0 vorhanden. Im Folgenden wird eine Definition vorgeschlagen und es werden Schritte auf dem Weg von der dritten zur vierten industriellen Revolution diskutiert. Darüber hinaus wird hinterfragt, ob es in jedem Falle sinnvoll ist, alle Aspekte von Industrie 4.0 zu realisieren oder ob nicht in bestimmten Situationen ein teilweiser Verzicht auf bestimmte Fähigkeiten einer umfassenden Industrie-4.0-Lösung akzeptabel ist. Darüber hinaus darf bezweifelt werden, dass ein Übergang vom aktuellen Status Quo zur Industrie 4.0 in allen Facetten in einem Schritt möglich sein wird.	bielefeld conspiracy;big data;eine and zwei;entity–relationship model;industry 4.0;word error rate	Peter Liggesmeyer	2017	Informatik-Spektrum	10.1007/s00287-017-1034-5	world wide web;software engineering;computer science	OS	-104.32352838916006	35.19815836135532	10595
10081cfd5946b5898464423693464736cd601f42	human resource flow and software firm performance: the role of direct vs. indirect competitors	economics of is;it policy and management;strategic group competition;management of it resources	Recent years have witnessed increasingly stiff competition for talents among software firms. The economic impact of obtaining workers from or losing workers to competing firms, however, has rarely been quantified. Built on the literature of human resource flow and firm competition, this study examines the impact of human resource flows from and to different types of competitors on company performance. In particular, we divide competitors into direct and indirect competitors according to their market and resource similarity. Using a large dataset on labour mobility derived from LinkedIn.com, we quantify the impact of employees who came from or joined direct and indirect competitors respectively. We find that employees from competitors bring great benefits to the recipient firms. Specifically, a 1 percent increase of the number of employees from direct (indirect) competitors that join the focal company in the previous year increases the company’s economic value added by 0.054 (0.074) percent in the current year. Our results also contribute to the existing literature on human resources and company strategy and provide practical implications to recruiters and policy makers in the software industry.	focal (programming language);software industry	Yuxin Huang;Chunmian Ge	2015			industrial organization;strategic human resource planning;environmental resource management;resource management;microeconomics;resource	HCI	-84.44782123069939	6.731141193618839	10611
72abc4f40f1e6483a02c19ace243153c8353c2c8	leistungssteigerung von prozeßrechnersystemen durch den einsatz von hochsprachprogrammierten multiprozessoren	leistungssteigerung von proze;rechnersystemen durch den;einsatz von hochsprachprogrammierten multiprozessoren	Trotz standig steigender Leistung moderner Mikrorechnersysteme bleibt eine zusatzliche Leistungserhohung durch Parallelarchitekturen eine attraktive Perspektive. Seit langem gibt es hier einige verschiedenartige Ansatze /2/, /11/. Fur den potentiellen industriellen Anwender akzeptabel jedoch sind vermutlich nur solche Konzepte, bei denen keine neuen Programmierkenntnisse erforderlich sind und alte erprobte Programme unverandert, aber schneller, lauffahig sind. Diese Forderung erhielt darum von vornherein die hochste Prioritat und bestimmte faktisch das Systemkonzept. Dis unten vorgestellte Hardwarearchitektur ist also das Ergebnis der Systemanforderungen und nicht etwa, wie leider oft, ein Startpunkt der Uberlegungen.		K.-H. Niemann;Wilfried Gerth	1988		10.1007/978-3-642-73445-8_65		Theory	-104.5935229053626	32.963787848221486	10622
f2b70c4b1ac7c3283564149ec0599480e4ac387a	kooperationsvereinbarung zur internetsicherheit zwischen enisa und europäischen normungsgremien cen und cenlec		der Online-Werbung oder der Marktforschung erfasst und ausgewertet und zu individuellen Nutzungs-, Kaufoder Bewegungsprofilen verdichtet. Je mehr das Internet im Alltag genutzt wird, desto mehr Datenspuren liefern Hinweise auf Interessen, Vorlieben und Verhaltensweisen der Nutzerinnen und Nutzer. Den digitalen Augen und Ohren im Internet nicht alles preiszugeben, ist das legitime Recht aller Nutzer“, so Wagner. „Die Globalität des Internet macht es häufig jedoch schwer, dies einzufordern. Wer nicht will, dass seine Daten Neugier und Sammelwut preisgegeben sind, sollte digitale Vorsorge treffen“ so der Datenschutzbeauftragte. Zwar bringe es die digitale Lebenswelt mit sich, dass man nicht immer und vollständig anonym bleiben könne; darin gleiche sie letztlich dem analogen Alltag. Hier wie dort wechsele man zwischen notwendiger Preisgabe persönlicher Daten und berechtigtem Verschweigen. Welche Möglichkeiten bestehen, Datenspuren im Internet zu vermeiden, wie Inhalte bei E-Mail und Online-Speichern durch Verschlüsselung geschützt werden können oder wie die penetrante Dateninkontinenz von Smartphones unterbunden werden kann, erläutert der Landesbeauftragte für den Datenschutz auf seinem Internet-Angebot zum Selbstdatenschutz: http://www.datenschutz. rlp.de/de/selbstds.php	die (integrated circuit);internet explorer;sie (file format);smartphone;triple des;word error rate	Wagner;Informationen Zu Publikati-Onen	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0280-1		OS	-104.62493831318424	36.90733231851518	10627
09a558ccc7d830ae3a75a1934736979104a5d496	towards compliance of cross-organizational processes and their changes - research challenges and state of research		Businesses require the ability to rapidly implement new processes and to quickly adapt existing ones to environmental changes including the optimization of their interactions with partners and customers. However, changes of either intraor cross-organizational processes must not be done in an uncontrolled manner. In particular, processes are increasingly subject to compliance rules that usually stem from security constraints, corporate guidelines, standards, and laws. These compliance rules have to be considered when modeling business processes and changing existing ones. While change and compliance have been extensively discussed for intra-organizational business processes, albeit only in an isolated manner, their combination in the context of cross-organizational processes remains an open issue. In this paper, we discuss requirements and challenges to be tackled in order to ensure that changes of cross-organizational business processes preserve compliance with imposed regulations, standards and laws.		David Knuplesch;Manfred Reichert;Juergen Mangler;Stefanie Rinderle-Ma;Walid Fdhila	2012		10.1007/978-3-642-36285-9_65	public relations;engineering;operations management;management	SE	-73.74902718340391	11.033517401635278	10633
2efbe7d29bd060642297e24b7079a499c5bb20fe	the meaning of success for software smes: an holistic scorecard based approach	software process improvement;software engineering;conference item;business success;software smes;management	Software processes support the work of software development and software process improvement (SPI) is concerned with improving the operation of the software process. One of the primary reasons for conducting SPI is to increase the success of a software development company (1), (2). While evidence of the benefits of SPI exists, project/senior managers report that their motivation for conducting SPI would be strengthened by the provision of further evidence of the positive impact of SPI on business success (3). This pa- per proposes a new approach that utilises the Holistic Scorecard (HSC) (4) to systematically examine business success in software development companies. Furthermore, we relate the experience of applying this new approach to software small to medium sized enterprises (SMEs). This novel approach to examining success in software development companies provides a suitable mechanism for SPI researchers and practitioners seeking to establish evidence of the business benefits of SPI.	holism	Paul Clarke;Rory O'Connor	2011		10.1007/978-3-642-22206-1_7	personal software process;team software process;software engineering process group;software project management;systems engineering;knowledge management;operations management;software development;business;empirical process;software quality	SE	-69.66621670159014	20.72010779519824	10636
a924a8aaeddf2cf4d2a44d815c2de2fa4bf00df9	coordination and governance in geographically distributed enterprise architecting: an empirical research design	empirical research design;greater detail;architecting coordination framework;governance perspective;effective implementation;proposed research framework;research model;enterprise architecting;previous research;enterprise architecture;effective geographically;empirical research;research framework	"""Previous research examining the effective implementation and management of enterprise architecture (EA) has typically used a governance perspective. However, this perspective does not consider the challenges associated with the """"architecting"""" effort-.e., the processes involved in generating and managing the EA. This requires the coordinated action of many stakeholders and architects, especially when they are geographically dispersed because distance and time barriers need to be bridged to coordinate their efforts. In this paper we adapt a previously suggested architecting coordination framework to develop a research model that integrates the coordination and governance perspectives in order to examine the development and implementation of effective geographically dispersed EAs. We use data obtained from two practitioner workshops on EA and follow up interviews with two participants to do some preliminary analysis. We then propose an empirical research design to study our proposed research framework in greater detail."""	bridging (networking);enterprise architecture	J. Alberto Espinosa;Wai Fong Boh	2009	2009 42nd Hawaii International Conference on System Sciences	10.1109/HICSS.2009.646	enterprise architecture framework;information governance;knowledge management;software engineering;enterprise architecture management;conceptual framework;database;management science;enterprise data management;enterprise architecture;empirical research;management;enterprise information security architecture;enterprise information system;enterprise life cycle	SE	-78.034420394907	6.514127427197852	10692
da18c8518c2c651ef3a623bc5896fb9838647e35	lessons learned from independent verification and validation of models and simulations (work in progress)	verification;software testing;sensitivity analysis;validation;subject matter expert review	"""This paper describes lessons learned while conducting Independent Verification and Validation (IV&V) efforts for a number of models and simulations (M&S) within the U. S. Department of Defense (DOD), and it describes the issues and solutions identified during those efforts. These examples and the lessons learned from them are based on verification and validation (V&V) of existing """"legacy"""" M&S tools used within the DOD."""	simulation;verification and validation	James N. Elele;David H. Hall;Allie R. Farid;David J. Turner;Mark E. Davis;David R. Keyser	2014			verification and validation of computer simulation models;simulation;computer science;systems engineering;management science	Logic	-64.46331114381088	25.391075475861857	10706
b2fee90723d1fc208789d24dc23c035bc744a9d5	un caso de big data punta a punta: análisis de datos de transporte y su uso en el negocio		En este art́ıculo se presentan los resultados de un proyecto de análisis de datos de una empresa de transporte, que involucró la recolección, preparación, visualización, transformación y análisis de 3 años de datos de viajes de colectivos, incluyendo boletos y posicionamiento geográfico. Este caso cubre el proyecto de punta a punta, incluyendo la incorporación de los resultados en el proceso de negocio. Nosotros sostenemos que una caracteŕıstica clave de los proyectos de big data debe encontrarse en el proceso que se lleva a cabo y que inicia con la captura de grandes cantidades de datos, pasando por el procesamiento (que en muchos casos requiere una infraestructura especial o particular, con más de una computadora, en modo distribuido) hasta el análisis y el aprovechamiento de la información en el negocio. En nuestro punto de vista, este último paso (la inserción de la información en la toma de decisiones del negocio) es tan importante como el uso de bases NoSQL o Hadoop o procesar varios terabytes.	apache hadoop;bibliothèque de l'école des chartes;big data;linear algebra;modo (software);naruto shippuden: clash of ninja revolution 3;nosql;os-tan;power-on reset;terabyte;unique name assumption	Camilo Melani;Juan V. Echagüe;Joaquín Torré Zaffaroni;Daniel Yankelevich	2016	CoRR		business process;knowledge management;library science;global positioning system;analysis project;ticket;big data;visualization;computer science;data preparation	Security	-106.70995387782312	18.773436391171863	10720
c732f36580415ce54e6afc093d07a25a73b47c05	filtres de kalman réduits et efficaces pour l'assimilation de données en océanographie. (efficient reduced kalman filters for data assimilation in oceanography)			data assimilation;kalman filter	Ibrahim Hoteit	2001				Logic	-104.39061503814017	16.810737316889522	10725
66747f2e2f54475a383639a8d12b2420e7f97ba0	identifying business process activity mappings by optimizing behavioral similarity		This paper describes an approach designed to create a mapping between corresponding activities from two business processes that is geared towards handling noisy similarity values for the labels describing these activities. This is achieved by formulating an optimization problem – maximize the behavioral similarity of the processes as a whole – whose target value depends on the mapping. Thereby, the mapping is created not only with respect to label similarities but also with respect to the overall control flow structure, which avoids some mistakes resulting from erroneous label similarities. A preliminary evaluation demonstrates the improvement.	business process;control flow;external validity;greedy algorithm;linear programming formulation;mathematical optimization;optimization problem;optimizing compiler;simulation;software studies	Jörg Becker;Dominic Breuker;Patrick Delfmann;Hanns-Alexander Dietrich;Matthias Steinhorst	2012			computer science;operations management;data mining;management science	AI	-72.18104259484691	26.855925274233872	10813
27d92a41dd3625c9358bd8c31a15e8cd9699790b	template parsing with user feedback	learning style;spreadsheet programs;program debugging spreadsheet programs user centred design grammars error correction error detection;user feedback;development tool;grammars;error correction;mathematics education;feedback error correction switches programming profession mathematics educational programs educational institutions mathematical model inspection testing;user centred design;program debugging;error detection;code testing template parsing user feedback spreadsheets end user programming system nontrivial errors code inspection code auditing;end user programming	Spreadsheets are among the most widely used end-user programming systems. According to some estimates, up to 90% of spreadsheets have non-trivial errors in them [7]. In many cases, spreadsheet errors have resulted in huge financial losses for companies. Spreadsheets are also in use in Science and Mathematics education in schools primarily because they offer a flexible modeling environment. With widespread adoption of spreadsheets by end users there is a greater need for better auditing tools to help users develop safer spreadsheets. Traditional approaches like code inspection, auditing, and testing might not be really conducive for users disadvantaged by their background, education, learning style or physical abilities. In this context, it is important to develop tools that work with minimal user intervention. Errors in spreadsheets might arise for a variety of reasons ranging from the user’s lack of understanding of the specifications or requirements of the spreadsheet to errors arising from entering the formulas or values incorrectly (for example, typos, poor understanding of operator precedence etc.). In Section 2 we discuss the main approaches we have explored so far. In Section 3 we discuss the importance of being able to infer the underlying models of spreadsheets and the steps involved in a first attempt at extracting specifications (templates) from spreadsheets.	algol 68;end-user development;order of operations;parsing;requirement;spreadsheet	Robin Abraham	2005		10.1109/VLHCC.2005.60	simulation;computer science;theoretical computer science;programming language	SE	-69.8481269895694	36.12111489678799	10853
4c1bad15daf2d533de000bfe3bf9142e1c4302b6	ein diskreter ansatz zur modellierung von tumorwachstum und strahlentherapie		Kurzfassung. Der Einflusses einer Radiotherapie auf die Progression von primären Hirntumoren wird modelliert. Ein hybrider Ansatz wird für zelluläres Tumorwachstum und die Veränderung lokaler Nährstoffkonzentrationen genutzt. Die Nährstoffverteilung wird durch zwei partielle Differentialgleichungen beschrieben und hat direkten Einfluss auf die durch das Modell abgebildeten zellulären Prozesse und umgekehrt. Diese beinhalten Mitose, Chemotaxis und Nekrose, werden mittels eines zellulären Automaten beschrieben und in Abhängigkeit von der Nährstoffkonzentration und der jeweiligen Populationsanzahl durch wahrscheinlichkeitsbedingte Modelle gesteuert. Der Effekt einer Therapie mittels Bestrahlung wird mit Hilfe des linear-quadratischen Modells beschrieben. Dieses ermöglicht die Quantifizierung des Bestrahlungseffekts verschiedener Fraktionierungsschemata. Zusätzlich erlaubt die Integration des Zellzyklus in das Wachstumsmodell eine Abbildung der Variabilität der Radiosensitivität einzelner Zellen. Eine qualitative Beurteilung erster Ergebnisse zeigt eine plausible Beschreibung des Tumorwachstums und des Effekts einer Bestrahlung.	color gradient;eine and zwei;v-model	Y. Schröder;Stefan Becker;Alina Toma;Andreas Mang;Tina A. Schütz;Thorsten M. Buzug	2011		10.1007/978-3-642-19335-4_78	mathematical physics;philosophy	Crypto	-106.09313869101666	28.662663743854957	10904
3dfe0b31b1ecc1e909aebc9a5fd6646b4221318c	economic and technological complexity: a model study of indicators of knowledge-based innovation systems		The Economic Complexity Index (ECI; Hidalgo and Hausmann, 2009) measures the complexity of national economies in terms of product groups. Analogously to ECI, the Patent Complexity Index (PatCI) can be developed on the basis of a matrix of nations versus patent classes. Using linear algebra, the three dimensions—countries, product groups, and patent classes—can be combined into a measure of “Triple Helix” complexity (THCI) including the trilateral interaction terms between knowledge production, wealth generation, and (national) control. THCI can be expected to capture the extent of systems integration between the global dynamics of markets (ECI) and technologies (PatCI) in each national system of innovation. We measure ECI, PatCI, and THCI during the period 2000–2014 for the 34 OECD member states, the BRICS countries, and a group of emerging and affiliated economies (Argentina, Hong Kong, Indonesia, Malaysia, Romania, and Singapore). The three complexity indicators are correlated between themselves; but the correlations with GDP per capita are virtually absent. Of the world's major economies, Japan scores highest on all three indicators, while China has been increasingly successful in combining economic and technological complexity. We could not reproduce the correlation between ECI and average income that has been central to the argument about the fruitfulness of the economic complexity approach.	economic complexity index;knowledge-based systems;linear algebra;system integration	Inga A. Ivanova;Øivind Strand;Duncan Kushnir;Loet Leydesdorff	2016	CoRR		economics;macroeconomics;microeconomics;economy;economic growth;economic system	AI	-84.73234544314035	6.979001896093131	10905
08807e4e5192c2ad104465f772d7c0de40d9fadc	system and architecture evaluation framework using cross-domain dynamic complexity measures	complexity theory;measurement;complexity theory measurement complex systems autonomous automobiles context observers;observers;behavioral based dynamic complexity measures architecture evaluation framework cross domain dynamic complexity measures system complexity content architecting systems complexity analysis system architecture selection fragility real world complex systems multistep framework autonomous car architecture google system complexity evaluation;computational complexity;complex systems;autonomous automobiles;context;measurement techniques system level design complexity theory systems engineering and theory	This work proposes a framework for effective quantification and comparison of system complexity content when architecting systems. Properly interpreted results from complexity analysis help make better informed system architecture selection between competing designs since the increased complexity of a system can lead to increased fragility and more exposure to failures and risks. Therefore the quantification of complexity is important when designing and planning the operation of a complex system. Our prior work on dynamic complexity measures provides the foundation for the framework discussed herein. The scope of this paper is to apply dynamic complexity measures to current, real-world complex systems. This work introduces a multi-step framework to evaluate complex systems and enhance a systems engineer's ability to compare competing systems/architectures. The framework has also proved useful for generating technical risks. A case study is included which utilizes the framework to evaluate an autonomous car architecture being developed by Google. The results demonstrate how the framework can help guide stakeholder decisions. The findings advance system complexity evaluation state-of-the-art by providing a framework using behavioral-based dynamic complexity measures.	analysis of algorithms;autonomous car;complex system;complex systems;systems architecture;systems engineering	Jonathan Fischi;Roshanak Nilchiani;Jon Wade	2016	2016 Annual IEEE Systems Conference (SysCon)	10.1109/SYSCON.2016.7490519	complexity;simulation;computer science;systems engineering;operations management;socio-ecological system;worst-case complexity;complexity management	Robotics	-77.53502984281039	17.93357926257743	10910
fbf44903db66062ba63469067a8f7a70b4ea9e1d	web 2.0 for practitioners	developpement logiciel;google;software tools internet public domain software;data engineering joining processes application software internet security;red www;web and internet services;collaboration;reseau web;publishing;software engineering world wide web;software engineering;software engineers;professional development;public domain software;prospectiva;open technologies;internet;prospective;desarrollo logicial;software development;web 2 0;open technologies web 2 0 software engineers internet;world wide web;software tools;blogs	Web 2.0 has been a buzzword ever since software engineers started connecting different applications and data on the Internet. What are the most promising technologies for applying Web 2.0 in your IT? What tools go beyond gimmicks to help professional developers? Authors Nicolas Serrano and Jose Manuel Torres introduce the major open technologies and show how to integrate them in a professional application. Needless to say, we can't dive into all the interesting details, such as security or performance engineering. We'll have to leave those for later columns.	column (database);computer security;internet;nicolas jacobsen;performance engineering;software engineer;web 2.0	Nicolás Serrano;José Manuel Torres	2010	IEEE Software	10.1109/MS.2010.84	professional development;the internet;computer science;engineering;software development;software engineering;database;publishing;management;web 2.0;public domain software;world wide web;collaboration	SE	-72.53251656623044	28.287982668893125	10926
d7bb785319e4a519039177b14b4e42bd27f2652c	environnements socio-techniques - jfsma 15 - vingt-troisièmes journées francophones sur les systèmes multi-agents, rennes, france, june 30th-july 1st, 2015					2015				Logic	-104.68001981648514	15.451215364530752	11040
bba69dcef29ab531d773e0be6a5235f1faf0b318	proposal for using ahp method to evaluate the quality of services provided by outsourced companies		Abstract   This work aims to describe the development stages of a decision support system for evaluating the quality of services provided by outsourced companies that serve organisations in the Brazilian retail sector. It used applied research, implemented through a case study conducted with the outsourced service providers of one of the 158 subsidiaries of a retail company. Using the Analytic Hierarchy Process (AHP), it was possible to develop an evaluation model capable of measuring the performance of the quality indicators and evaluating the performance of the outsourced services provided to the company under study.		André Andrade Longaray;João de Deus Rodrigues Gois;Paulo Roberto da Silva Munhoz	2015		10.1016/j.procs.2015.07.083	knowledge management	SE	-70.92940232564303	9.376741120286855	11065
11d97664ce6a30ee6c8da1f5d62a49313294053a	assembly time modeling through connective complexity metrics	design for assembly;complexity	This paper presents the development of a model for predicting the assembly time of a system based on complexity metrics of the system architecture. A convention for modeling architecture is presented, followed by ten analyzed systems. These systems are subjected to complexity metrics developed for other applications. A model is developed based on a recognizable trend and a regression of that trend. The regression is then further refined based on its similarities to additional metrics other than that used in regression. The final model uses average path length, part count, and path length density to predict assembly time to within ±16% of that predicted by the Boothroyd and Dew Hurst design for assembly analysis method.	allen boothroyd;assembly language;average path length;complexity;hurst exponent;logical connective;systems architecture	James L. Mathieson;Bradley A. Wallace;Joshua D. Summers	2010	2010 International Conference on Manufacturing Automation	10.1080/0951192X.2012.684706	mathematical optimization;complexity;simulation;computer science;operations management;machine learning;engineering drawing;design for assembly;mechanical engineering	Robotics	-70.30546785207399	32.68060753029065	11112
0048eecf87f924d58a2614f3f612cfd0602db52d	methoden der syntaktischen analyse bei formalen sprachen		Das Interesse an Algorithmen zur syntaktischen Analyse bei formalen Sprachen stammt von der Konstruktion von Ubersetzern fur Programmiersprachen und dem Bemuhen, diese Konstruktion wenigstens teilweise zu automatisieren. Inzwischen gibt es eine Fulle von sich mehr oder weniger unterscheidenden Analysemethoden, wahrend nur wenige davon in syntaxgesteuerten (d.h. anhand der formalen Beschreibung der Syntax analysierenden) Compilern oder in (teilweise) automatisch erzeugten Compilern Verwendung gefunden haben. Dieses liegt zum grosten Teil daran, daβ man bei dem Auffinden von Methoden zur effizienten syntaktischen Analyse weitgehend die Erfassung einer moglichst grosen Teilklasse der Klasse kontextfreier Sprachen erstrebte. Bei dem tatsachlichen Bau von Compilern zieht man es jedoch im allgemeinen vor, die syntaktische Beschreibung der Programmiersprache gegebenenfalls soweit zu andern, das es dafur ein zwar nur auf eine eng eingeschrankte Klasse anwendbares, aber einfaches Analyseverfahren gibt. Ferner ist die Theorie der Analysealgorithmen sehr stark auf den Fall kontextfreier Sprachen beschrankt, wahrend man neuerdings zur syntaktischen Beschreibung von hoheren Programmiersprachen wie etwa bei ALGOL 68’ auch komplexere Systeme benutzt.		Jürgen Eickel	1972		10.1007/978-3-642-80732-9_4	performance art;philosophy	NLP	-105.51105432717682	32.357706714174206	11253
bfc3ff21f8418e415548529083cd68e9f3dfa488	a case study on implementing false data injection attacks against nonlinear state estimation	flash memory;firmware;state estimation;smart grid;cyber security;false data injection;reverse engineering	Smart grid aims to improve control and monitoring routines to ensure reliable and efficient supply of electricity. The rapid advancements in information and communication technologies of Supervisory Control And Data Acquisition (SCADA) networks, however, have resulted in complex cyber physical systems. This added complexity has broadened the attack surface of power-related applications, amplifying their susceptibility to cyber threats. A particular class of system integrity attacks against the smart grid is False Data Injection (FDI). In a successful FDI attack, an adversary compromises the readings of grid sensors in such a way that errors introduced into estimates of state variables remain undetected. This paper presents an end-to-end case study of how to instantiate real FDI attacks to the Alternating Current (AC) --nonlinear-- State Estimation (SE) process. The attack is realized through firmware modifications of the microprocessor-based remote terminal systems, falsifying the data transmitted to the SE routine, and proceeds regardless of perfect or imperfect knowledge of the current system state. The case study concludes with an investigation of an attack on the IEEE 14 bus system using load data from the New York Independent System Operator (NYISO).	adversary (cryptography);attack surface;data acquisition;end-to-end principle;fault detection and isolation;firmware;microprocessor;nonlinear system;sensor;sysop;system integrity;the new york times;threat (computer);transcranial alternating current stimulation	Charalambos Konstantinou;Michail Maniatakos	2016		10.1145/2994487.2994491	embedded system;real-time computing;engineering;computer security	Security	-64.11068621499992	57.25301042826846	11273
205125d04f36604c735d89689f866149191da88d	sustainable target cube - a synthesis of sustainability and information system-		The businesses have a critical role in moving the society toward sustainability. The fast changing and dynamic global business environment requires firms to be more flexible to quickly adapt and respond to market changes. Among the forces that drive changes, requirements for corporate responsibility and sustainability are getting more urgent. During such difficult time as this economic downturn, companies are faced with hard choices to survive. Research has acknowledged that addressing sustainability issues is critical to the long-term existence and thriving of companies [4]. The concept of sustainability make it necessary that besides the economic categories and the operational environment protection, it should be considered the social effects of company in management actions. Sustainability business oriented can be realized through developing a corporate target cube in enterprise. Such cube will help organizations to shape their targets in accepting social, environmental and economic responsibilities. The current research tries to review the research background done till now and depict a perspective of an integrated target cube for both scholars and managers. Furthermore, this paper has a holistic look toward the concept of sustainable information system.	cube;holism;information system;requirement	Tabassom Hashemi Farzad;Horst Junker	2014			cube;information system;systems engineering;sustainability;engineering	HCI	-75.20784673216762	7.61574114646031	11324
c3db7af29715bc67156bfc2934c0556cab67c0bf	relation of code clones and change couplings	developpement logiciel;correlacion;analisis estadistico;visualizacion;maintenance;validacion;clone;software systems;metric;satisfiability;clona;visualization;statistical analysis;software evolution;visualisation;visualization technique;desarrollo logicial;logiciel libre;software development;analyse statistique;mantenimiento;software libre;code clone;metrico;validation;source code;file sharing;correlation;metrique;open source software;open source	Code clones have long been recognized as bad smells in software systems and are considered to cause maintenance problems during evolution. It is broadly assumed that the more clones two files share, the more often they have to be changed together. This relation between clones and change couplings has been postulated but neither demonstrated nor quantified yet. However, given such a relation it would simplify the identification of restructuring candidates and reduce change couplings. In this paper, we examine this relation and discuss if a correlation between code clones and change couplings can be verified. For that, we propose a framework to examine code clones and relate them to change couplings taken from release history analysis. We validated our framework with the open source project Mozilla and the results of the validation show that although the relation is statistically unverifiable it derives a reasonable amount of cases where the relation exists. Therefore, to discover clone candidates for restructuring we additionally propose a set of metrics and a visualization technique. This allows one to spot where a correlation between cloning and change coupling exists and, as a result, which files should be restructured to ease further evolution.	bug tracking system;code refactoring;code smell;duplicate code;open-source software;programming language;qr code;relevance;software bug;software engineer;software engineering;software system;statistically close	Reto Geiger;Beat Fluri;Harald C. Gall;Martin Pinzger	2006		10.1007/11693017_31	visualization;computer science;software engineering;database;engineering drawing;algorithm	SE	-64.53689489963513	36.19792048984604	11339
967b991c793cb662c47d41b4aa12c5217f2fc4de	counting bugs is harder than you think	buffer overflow software assurance metrics and tool evaluation samate project us national institute of standards and technology unites states web application security scanner malware research protocol electronic voting system samate reference dataset software metrics source code scanner numeric overflow;software metrics;software;nist;measurement;software measurement nist malware java communities;software engineering;software debugging software engineering software tools software metrics;software metrics program debugging safety critical software;malware;safety critical software;software tools;software debugging;program debugging;communities;java	Software Assurance Metrics and Tool Evaluation (SAMATE) is a broad, inclusive project at the U.S. National Institute of Standards and Technology (NIST) with the goal of improving software assurance by developing materials, specifications, and methods to test tools and techniques and measure their effectiveness. We review some SAMATE sub-projects: web application security scanners, malware research protocol, electronic voting systems, the SAMATE Reference Dataset, a public repository of thousands of example programs with known weaknesses, and the Static Analysis Tool Exposition (SATE). Along the way we list over two dozen possible research questions, which are also collaboration opportunities. Software metrics are incomplete without metrics of what is variously called bugs, flaws, or faults. We detail numerous critical research problems related to such metrics. For instance, is a warning from a source code scanner a real bug, a false positive, or something else? If a numeric overflow leads to buffer overflow, which leads to command injection, what is the error? How many bugs are there if two sources call two sinks: 1, 2, or 4? Where is a missing feature? We conclude with a list of concepts which may be a useful basis of bug metrics.	buffer overflow;code injection;malware research;microsoft software assurance;open research;software bug;software metric;vulnerability (computing);web application security	Paul E. Black	2011	2011 IEEE 11th International Working Conference on Source Code Analysis and Manipulation	10.1109/SCAM.2011.24	nist;computer science;operating system;software engineering;database;malware;programming language;java;software metric;measurement	SE	-63.53393009307562	37.631124900915424	11352
7d92d14c9b77e58c558433f6a8b48102a8d86041	the impact of it governance on performance of ifrs conversion under erp systems	reliability;information systems;standards;risk management;companies;planning	In response to the international trend, in recent years companies have officially adopted the International Financial Reporting Standards (IFRSs) and need to perform upgrade or adjustment to their Enterprise Resource Planning (ERP) systems for the IFRS conversion. Information technology (IT) governance in an ERP system environment will become a key that cannot be ignored by the management. To investigate the impact of implementing IT governance in an ERP environment on the effectiveness of ERP implementation and IFRS conversion The findings are as follows: Effective IT governance in a company can improve the project performance of ERP implementation; The improvement of the information quality and system quality of an ERP system can demonstrate the effectiveness of the IFRS conversion through the ERP system; The project performance of ERP implementation can improve the information quality and system quality of the ERP system as well as the effectiveness of the IFRS implementation.	erp;enterprise resource planning;environment variable;information quality	Wen-Hsien Tsai;Po-Yuan Chu;Jui-Chu Chang;Hsiu-Li Lee;Yi-Chin Huang	2015	2015 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)	10.1109/IEEM.2015.7385723	planning;accounting;economics;risk management;environmental resource management;reliability;management;information system;commerce	DB	-81.87079113105128	7.278658843815236	11356
e471dba02c1a99e2a55041951aac1138702f6285	four personality traits make a software engineer	software engineering		software engineer	Wolfgang Zuser;Thomas Grechenig	2004			software;engineering;systems engineering;big five personality traits	Logic	-64.15635001605074	24.829323740550596	11380
58d08ab65fb4ee79758bfc59f552c62130064a9d	evolving process simulators by using validated learning	customer development;software process simulation;software process;validated learning;software engineering;lean startup;computational modeling;computer model;empirical evidence;learning artificial intelligence;action learning;process simulation	"""Software process simulation has been evolved towards a mature technology for analyzing the behavior of software processes: Methods for systematically developing simulators exist, tools for modeling and execution are available, models for nearly all kinds of processes have been created, and empirical evidence on the accuracy of many models has been gathered. However, software process simulation is still waiting for a breakthrough success. Although simulation is a technology that has been successfully established in many domains, software process simulation is not widely used in software engineering practice. Should we pivot or persevere? This article argues that it is necessary to use a rigorous approach for discovering """"customers"""" of process simulators and finding out what they consider to be value. One mechanism to do this is to apply so-called """"validated learning"""", i.e., to apply an actionable learning approach to identify what is relevant and what is irrelevant by systematically testing value hypotheses. Doing this promises that simulation efforts can be concentrated on value-creation and that wrong avenues can be avoided. Besides this, the article sketched prerequisites and lessons learned that need to be considered when applying simulators in practice as well as upcoming opportunities for making software process simulation a success."""	relevance;simulation;software development process;software engineering	Jürgen Münch	2012	2012 International Conference on Software and System Process (ICSSP)		simulation;software engineering process group;computer science;systems engineering;knowledge management;goal-driven software development process	SE	-67.75963660155736	18.493367351422346	11396
22dfe39e0a278707bedde63269249457f490e63b	lessons learned from modeling the dynamics of software development	developpement logiciel;computer program;ciclo desarrollo;project management;brooks law;software project teams;life cycle;computer software development;system dynamics;software management;software systems;hd28 m414 no 2069 88;organizacion proyecto;ingenieria logiciel;software engineering;software project management;computer programming management;lessons learned;desarrollo logicial;software development;90 percent syndrome;cycle developpement;genie logiciel;gestion projet;feedback system;computer simulation;gestion logiciel	Software systems development has been plagued by cost overruns, late deliveries, poor reliability, and user dissatisfaction. This article presents a paradigm for the study of software project management that is grounded in the feedback systems principles of system dynamics.	list of code lyoko episodes;programming paradigm;software development process;software project management;software system;system dynamics	Tarek K. Abdel-Hamid;Stuart E. Madnick	1989	Commun. ACM	10.1145/76380.76383	computer simulation;project management;biological life cycle;personal software process;simulation;software project management;computer science;social software engineering;software development;software engineering;feedback;system dynamics;systems development life cycle;software walkthrough;software deployment;software development process;software system;software peer review	SE	-64.20834537963482	25.459087924831437	11411
4db54e801d0516231e0978d2455ef7000a06efad	metrics for measuring data quality - foundations for an economic data quality management	data quality management;data quality	The article develops metrics for an economic oriented management of data quality. Two data quality dimensions are focussed: consistency and timeliness. For deriving adequate metrics several requirements are stated (e. g. normalisation, cardinality, adaptivity, interpretability). Then the authors discuss existing approaches for measuring data quality and illustrate their weaknesses. Based upon these considerations, new metrics are developed for the data quality dimensions consistency and timeliness. These metrics are applied in practice and the results are illustrated in the case of a major German mobile services provider.	data quality;fractal dimension;requirement	Bernd Heinrich;Marcus Kaiser;Mathias Klier	2007			reliability engineering;quality policy;data quality;data management;computer science	DB	-80.82271471842287	15.543354131199143	11437
64d3e01915867249fdbfda20d551d4e0c002a611	vorhersagemodell für die verfügbarkeit von it-services aus anwendungssystemlandschaften	verfugbarkeit;it service;anwendungssystemlandschaft	Serviceorientierung und Cloud Computing haben dazu geführt, dass sich inzwischen immer mehr Unternehmen darauf spezialisieren, ITDienstleistungen für Organisationen anzubieten. Erhöhter Wettbewerb in dieser Branche führt zu Kostenund Qualitätsdruck, was eine bessere Beherrschung des damit einhergehenden Leistungserstellungsprozesses durch quantifizierbare Vorhersagen für Anpassungen an den Anwendungssystemlandschaften der Service-Anbieter wünschenswert macht. In diesem Beitrag wird ein neuer Ansatz entwickelt, um die Verfügbarkeit von IT-Services aus Anwendungssystemlandschaften vorherzusagen. Entgegen bisher bekannter Lösungen geht dieser Ansatz nicht davon aus, dass die einzelnen Systemkomponenten unabhängig voneinander ausfallen. Es wird gezeigt, dass der Lösungsansatz ohne diese Abhängigkeiten die Ergebnisse analytischer Methoden erreicht. Somit können Entscheidungsprozesse unterstützt werden.	cloud computing;eine and zwei;unified model	Sascha Bosse;Matthias Splieth;Klaus Turowski	2013			data mining;computer science;performance art	AI	-102.04969008070611	35.38062627545821	11453
77523fcab5ebf1a46ce56ba4fd6cd168823388c6	actes de la première conférence internationale rivf'03 rencontres en informatique vietnam-france, rivf'03, hanoi, vietnam, 10-13 février, 2003			linear algebra		2003				AI	-105.48309592135213	16.885386301890268	11461
76fc7a8c211213a5ab72ca094b29df123af3e375	on the r-order of coupled sequences iii	spectral radius;parallel processing;eigenvectors	For convergent sequences {x n,1 },...{x n,s } coupled by a system (2) of inequalities the optimal individualR-orders τ1,...,τ s are determined as the spectral radii of certain matrices composed of exponents appearing in (2). Für konvergente Folgen {x n,1 },...,{x n,s }, welche über ein System (2) von Ungleichungen miteinander verkoppelt sind, werden die besten individuellenR-Ordnungen τ1,...,τ s bestimmt. Dazu wird gezeigt, daß diese gleich den Spektralradien von bestimmten Matrizen sind, welche aus Exponenten in (2) gebildet werden.		Wolfgang Burmeister;Jochen W. Schmidt	1983	Computing	10.1007/BF02280786	parallel processing;mathematical optimization;combinatorics;mathematical analysis;eigenvalues and eigenvectors;mathematics;spectral radius;algebra	Theory	-96.26770480862896	34.88513990880333	11472
1acfa42f45b8d3c68e30e8bd6a63cf97179cb589	ein hochgeschwindigkeits-vernetzungselement für eine flexible parallelrechnerarchitektur			eine and zwei	Karel van Loon	1993				Robotics	-98.59754085645042	25.159922428201284	11532
47b52b4f5e1ef70df77294b16ea1b827331b5d9f	steps towards effective it governance: strategic is planning, evaluation and benefits management	information system;business case;information systems;information systems management;management;empirical study	This paper reports on the results of an empirical study into the integration of strategic information systems planning and business-IT alignment, IT evaluation, and the proactive management of business benefits in large organisations, and to consider the linkages achieved between these processes. An argument is developed which suggests that at the heart of good IT governance practice is an integrated cycle of building a business case, alignment and prioritisation, evaluation, system acquisition, and post implementation proactive benefits realisation.	automated planning and scheduling;business requirements;organizational behavior;requirement;strategic information system	Judith McKay;Peter Marshall;Lisa Smith	2003				AI	-77.84107209174003	10.28792554826267	11568
6a58b717ef1c6bb5556d26a3e7c2e978d864ebc7	a framework for managing cloned product variants	software development management;software maintenance;cloned product variant management;related software product collection management;single-copy representations;software product development;software product line engineering approaches;software product maintenance;software re-engineering	"""We focus on the problem of managing a collection of related software products realized via cloning. We contribute a framework that explicates operators required for developing and maintaining such products, and demonstrate their usage on two concrete scenarios observed in industrial settings: sharing of features between cloned variants and re-engineering the variants into """"single-copy"""" representations advocated by software product line engineering approaches. We discuss possible implementations of the operators, including synergies with existing work developed in seemingly unrelated contexts, with the goal of helping understand and structure existing work and identify opportunities for future research."""	software product line;synergy	Julia Rubin;Marsha Chechik	2013	2013 35th International Conference on Software Engineering (ICSE)		reliability engineering;long-term support;verification and validation;systems engineering;engineering;package development process;backporting;social software engineering;software framework;software development;software design description;software engineering;software construction;software walkthrough;software analytics;resource-oriented architecture;software maintenance;software deployment;software system	SE	-66.43535801464006	22.092621176580494	11578
359f276715f16c7ac904f7bae7317227663dfd6a	modeling the vulnerability discovery process	security vulnerability;software testing;patch development;vulnerability discovery process modeling;security model;resource allocation;software defects;risk evaluation;resource management;software systems;software fault tolerance;servers;program testing;operating system;software development;operating systems software systems software testing resource management investments software reliability computer science computer security life testing system testing;security of data;life span;software fault tolerance program testing resource allocation security of data;patch development vulnerability discovery process modeling security vulnerability servers operating systems software defects resource allocation;operating systems;data security	Security vulnerabilities in servers and operating systems are software defects that represent great risks. Both software developers and users are struggling to contain the risk posed by these vulnerabilities. The vulnerabilities are discovered by both developers and external testers throughout the life-span of a software system. A few models for the vulnerability discovery process have just been published recently. Such models will allow effective resource allocation for patch development and are also needed for evaluating the risk of vulnerability exploitation. Here we examine these models for the vulnerability discovery process. The models are examined both analytically and using actual data on vulnerabilities discovered in three widely-used systems. The applicability of the proposed models and significance of the parameters involved are discussed. The limitations of the proposed models are examined and major research challenges are identified	libressl;operating system;software bug;software developer;software system	Omar H. Alhazmi;Yashwant K. Malaiya	2005	16th IEEE International Symposium on Software Reliability Engineering (ISSRE'05)	10.1109/ISSRE.2005.30	vulnerability management;computer security model;reliability engineering;life expectancy;vulnerability;responsible disclosure;resource allocation;computer science;systems engineering;engineering;resource management;software development;operating system;software engineering;vulnerability assessment;software testing;data security;secure coding;computer security;software fault tolerance;server;software system	Security	-64.08845129540528	29.663701295250206	11662
e61ee44cfe60823e5ce5c7df4fb73d6791a31060	hitchhikers need free vehicles!: shared repositories for statistical analysis in sbst		As a means for improving the maturity of the data analysis methods used in the search-based software testing field, this paper presents the need for shared repositories of well-documented statistical analysis code and replication data. In addition to explaining the benefits associated with using these repositories, the paper gives suggestions (e.g., the testing of analysis code) for improving the study of data arising from experiments with randomized algorithms.		Gregory M. Kapfhammer;Phil McMinn;Chris J. Wright	2016		10.1109/SBST.2016.019	development testing;computer science;data science;data mining;software testing;world wide web	Logic	-68.15622120237583	31.034956324691365	11680
4ab6996d9d71aaf6c02cd8777fd82b286fbb2664	towards a unifying process framework for services knowledge management	service system;unified process;knowledge management;shared knowledge;single domain;service life	Activities concerned with the design, planning and execution of services are becoming increasingly complex. This is due to the involvement of many different stakeholders, the complexity of the service systems themselves, and the dynamic nature of their organizational and ICT environments. Service knowledge management helps share and reuse relevant knowledge among the different stakeholders, and therefore emerges as a critical factor to perform service activities with required efficiency and quality. Recent advances in knowledge management provide promising opportunities to support individual service activities within a single domain. Yet, sharing knowledge throughout the service life-cycle and across service domains is still very challenging. The source of service knowledge, its usage, update frequency, encoding and associated stakeholders may vary depending upon the service activity and the service domain. Based on a critical analysis of currently proposed frameworks, we argue that a process framework approach is beneficial for service knowledge management. To support our claim, we offer an abstract template and a typical service life-cycle that can be adopted to integrate heterogeneous service knowledge from diverse sources.	complexity;knowledge management;service-oriented architecture	Vikrambhai S. Sorathia;Marten van Sinderen;Luís Ferreira Pires	2010		10.1007/978-3-642-14319-9_27	organizational learning;service product management;differentiated service;systems engineering;knowledge management;service delivery framework;body of knowledge;service design;management science;business;service desk;personal knowledge management;data as a service;knowledge value chain;domain knowledge	Web+IR	-73.81278748348659	10.021429011357947	11709
5268ef32cea7bcd16b12979a50b5246b76736f77	self-enforcing networks als tools zur auswahl eines geeigneten (ggf. hybriden) vorgehensmodells in it-projekten		Die Auswahl eines geeigneten Vorgehensmodells (VM) für bestimmte Projekte oder als institutionelle Vorgabe erfordert nicht nur die Kenntnis der zahleichen VM sondern auch die Zuordnung zu den Anforderungen des jeweiligen Projekts. Unser Artikel beschreibt die Möglichkeiten, die für diese Probleme ein von uns entwickeltes selbstorganisiert lernendes neuronales Netz bietet. Dies Netz, das Self Enforcing Network SEN, wird in seiner Grundlogik beschrieben; seine praktischen Verwendungsmöglichkeiten werden in verschiedenen Szenarien demonstriert. Die wesentlichen praktischen Vorteile von SEN sind Flexibilität sowie leichte Bedienbarkeit und Interpretation der Ergebnisse.	die (integrated circuit)	Christina Klüver;Jürgen Klüver	2015				HPC	-105.83274552933355	32.43016839909899	11811
824458ab1663960a58e7555771c1a786484cb8c6	the risks of large organizations in developing complex systems	software agents;multi agent systems;emergent properties;complex system;community structure;web services;theoretical foundations;system development;the semantic web;networked systems;organizational structure	"""The risks to the large organization of being able to complete the development of large software intensive systems on time and in budget include not just the defining and maintaining of proper requirements and work processes, but also in the defining and maintaining of the proper organizational work structures. Bureaucratic structures prevalent in large organizations can be inefficient and irrational especially in regards to unplanned surprises, exigencies, contingencies, and the emergent properties that are the normal part of the development and integration of first-of and one-of-a-kind large systems. All large software intensive systems, at their true core, are experiments, and experimentation and bureaucracy have proved to be, over time, destructively antithetical in basic values. Conway's law, first stated in 1968, has by the lights of 2005 provided only a superficial explanation of the antipathy of bureaucracy towards the unknown and risk. The belief that """"[o]rganizations which design systems...are constrained to produce designs which are copies of the communication structures of these organizations"""", can be easily refuted by noting that hierarchical organizations have been quite successful in designing and implementing networked systems subsequent to the invention of Ethernet and TCP/IP. The example provided by Conway was not sufficient by itself to draw the conclusion was made, a common fallacy of cause and effect, but he was certainly on an interesting path of investigation. Large system development failures cannot be prevented soley through improved planning, requirements, processes and software. Improvement must also come from the recognition of the limits of organization, planning and process; the recognition of the basic antipathy between bureaucracy and risk; the recognition of the need for organizational structures that scale yet remain responsive; the recognition of the need for better attitudes towards faults and failures, and the recognition that in order to reduce the risks that are inherent when the technical becomes political, that one must reduce the risks of speaking truth to power. The short article that follows is intended to raise more questions than provide answers, and the references are intended to provide a starting point for further research."""	automated planning and scheduling;bureaucracy;comefrom;causality;complex systems;conway's game of life;conway's law;emergence;experiment;internet protocol suite;process (computing);requirement;the superficial	Robert Schaefer	2005	ACM SIGSOFT Software Engineering Notes	10.1145/1095430.1095444	organizational structure;web service;complex systems;computer science;systems engineering;engineering;software agent;software engineering;multi-agent system;management science;management;community structure;emergence	SE	-63.99704235727381	6.99762207450609	11863
93389c35b2ed4831cb16708860c99b3544e9ed63	étude multirisque en milieu urbain et sig. le cas de l'agglomération de mulhouse	etude multi risque;spatial analysis;mulhouse		milieu intérieur	Elise Beck;Chrisitane Weber;Michel Granet	2006	Revue Internationale de Géomatique	10.3166/rig.16.395-414	regional science;economies of agglomeration;sociology	Logic	-105.50191797405004	16.248184433904665	11880
ed333a4b35f9000e396f3bedd5b7a99a17d0bc06	a general framework for estimating multidimensional contingency fit	contingency theory;multidimensional fit;organizational performance	This paper develops a framework for estimating multidimensional fit. In the context of contingency thinking and the resource-based view of the firm, there is a clear need for quantitative approaches that integrate fit-as-deviation, fit-as-moderation, and fit-as-system perspectives, implying that the impact on organizational performance of series of bivariate (mis)fits and bundles of multiple (mis)fits are estimated in an integrated fashion. Our approach offers opportunities to do precisely this. Moreover, we suggest summary statistics that can be applied to test for the (non)significance of fit linkages at both the disaggregated level of individual bivariate interactions, as well as the aggregated level of groups of multivariate interactions. We systematically compare our approach with extant alternatives using simulations, including the fit-as-mediation alternative. We find that our approach outperforms these established alternatives by including fit-as-moderation and fit-as-deviation as special cases, by being better able to capture the nature of the underlying fit structure in the data and by being relatively robust to mismeasurements, small sample sizes, and collinearity. We conclude by discussing our method's advantages and disadvantages.		Simon C. Parker;Arjen van Witteloostuijn	2010	Organization Science	10.1287/orsc.1090.0464	econometrics;organizational performance;economics;contingency theory;data mining;management	Theory	-79.7870989564364	5.945784969894748	11908
ecebbd2e9c6300e77265de1bc3368132bab54af7	standard methodology in digital library project management	project management;digital library;digital libraries;project manager;project management institute;design methodology	Purpose – The objective of this paper is to provide a description of the model for standardized project management developed by the Project Management Institute (PMI), as applied to digital library projects.Design/methodology/approach – Using the PMI model for project management, the paper develops a context for managing digital library projects according to the PMI's standard methodology.Findings – The paper finds that by using a standard methodology increases the likelihood of delivering projects on time and on budget.Originality/value – This paper will be of interest to digital library project managers as it fills a gap in the literature by providing an accessible overview of the major components of standard project management methodology as defined by the PMI.	digital library	H. Frank Cervone	2007	OCLC Systems & Services	10.1108/10650750710720748	project management;digital library;program management;work breakdown structure;earned value management;design methods;software project management;opm3;computer science;project management triangle;project charter;world wide web;schedule;project planning;project method;project portfolio management	EDA	-70.37846447840221	13.68177949410083	11912
716e9aaefdf8d1ce8a6b66985329e2639916deee	fighting physics: a tough battle	informatique dans les nuages;routing;routage;internet;computacion en nube;cloud computing;enrutamiento	The laws of physics and the Internetu0027s routing infrastructure affect performance in a big way.		Jonathan M. Smith	2009	ACM Queue	10.1145/1530818.1530063	routing;the internet;simulation;cloud computing;computer science;operating system;operations research;computer security	Theory	-98.02184564783138	13.032897136549003	11958
42870528580b945215c6eaf9e628e2c8322d4a4b	a historical perspective on runtime assertion checking in software development	software testing;runtime assertion checking;ucl;component based software engineering;formal methods;discovery;theses;conference proceedings;software engineering;architecture description languages;model driven development;digital web resources;ucl discovery;open access;software development;architecture centric software engineering;ucl library;book chapters;open access repository;architecture transformation refinement languages;architecture analysis languages;software architectures;ucl research	This report presents initial results in the area of software testing and analysis produced as part of the Software Engineering Impact Project. The report describes the historical development of runtime assertion checking, including a description of the origins of and significant features associated with assertion checking mechanisms, and initial findings about current industrial use. A future report will provide a more comprehensive assessment of development practice, for which we invite readers of this report to contribute information.	assertion (software development);software development;software engineering;software testing	Lori A. Clarke;David S. Rosenblum	2006	ACM SIGSOFT Software Engineering Notes	10.1145/1127878.1127900	formal methods;computer science;engineering;component-based software engineering;software development;software engineering;software testing;programming language	SE	-62.898465731034946	29.384593647712077	12014
6c444a106be9d9a7e702eb04fa5cb66e36ea98a7	tagungsbericht: 36. treffen der gi - fachgruppe test, analyse und verifikation von software (tav-36), 26. und 27. juni 2014, softwareforen leipzig		"""In zwei weiteren Vorträgen vom Fraunhofer-FokusInstitut wurde ebenfalls das Thema Sicherheit thematisiert. Michael Berger stellte in seinem Vortrag """"Test Prioritization in Security Risk Testing"""" einen Ansatz vor, Sicherheitstests und SicherheitsRisikoanalyse miteinander zu verbinden. Der Ansatz ist modellbasiert und basiert auf einer speziellen Sprache zur Modellierung von (Sicherheits-)Risiken. Ebenfalls der Integration von Risikoanalyse und Sicherheitstest widmet sich Johannes Viehmann in seinem Vortrag """"Risikoanalyse mit automatischen Sicherheitstests RACOMAT Methode und Tool"""". RACOMAT benutzt spezielle Security Test Pattern, die durch einen Prozess, eine Pattern-Bibliothek sowie ein Werkzeug unterstützt werden."""	die (integrated circuit);eine and zwei;vhf omnidirectional range	Stephan Jacobs	2014	Softwaretechnik-Trends		software engineering;computer science;software	SE	-101.58015914632713	31.85090642104915	12020
4fa7900e84a2ea64e5c485695324d13e20d29e03	simulation von elektrofahrzeugen	battery;electric drive;simulation;electric vehicle	Die wesentlichen Aufgaben und Herausforderungen der Simulation von Elektrofahrzeugen werden in dieser Arbeit erörtert. Die Anforderungen an die Simulationsumgebung, die eingesetzten Modelle und die Parametrierung werden diskutiert. Konkret wird für die vorgestellten Modelle die objektorientierte Modellierungsprache Modelica verwendet. Die eingesetzten Komponenten und Bibliotheken werden vorgestellt und kommen am Beispiel eines Kleinfahrzeugs zum Einsatz.	institut für dokumentologie und editorik;simulation	Christoph Kral;Dragan Simic	2011	Elektrotechnik und Informationstechnik	10.1007/s00502-011-0801-2	control engineering;software engineering;engineering;modelica	AI	-105.28216886553653	25.424452972292478	12045
f527c58d7a96b6bec94f3eaa937901e874874e23	enterprise spice based education capability maturity model	zinātniskās publikācijas;rīgas tehniskā universitāte;izdevums rtu zinātniskie raksti;rtu	In the context of knowledge society, education became one of the most critical systems. The quality of all other systems strongly depends on the quality of education system as never before. The purpose of this paper is to address the problem of quality of education system. An approach to solve this problem is based on the main assumption that education is a process oriented activity. According to this approach, product quality can be achieved by the means of process quality – process capability. Introduced here, SPICE conformant education process capability maturity model is based on process capability maturity modeling elaborated by world-wide software engineering community during the last 25 years, namely ISO/IEC 15504 that defines the capability dimension and the requirements for process definition and domain independent integrated model for enterprise-wide assessment and improvement Enterprise SPICE. A participative approach is proposed for education process assessment and improvement.	capability maturity model;iso/iec 15504;knowledge society;requirement;spice;software engineering	Antanas Mitasiunas;Leonids Novickis	2011		10.1007/978-3-642-29231-6_9	reliability engineering;leancmmi;process capability index;systems engineering;engineering;operations management;capability immaturity model	SE	-69.97279499709076	15.0203522521778	12080
85e4c46718723b8c725053218446d9fbfc5305c4	hashkollisionen und qualifizierte zertifikate		Für qualifizierte Zertifikate im Sinne des deutschen Signaturgesetzes (SigG) wird üblicherweise das X.509-Format verwendet. In diesem Aufsatz werden die Konsequenzen der z.Z. bekannten SHA-1-Kollisionsangriffe für solche Zertifikate betrachtet und diskutiert, inwieweit die Sicherheit qualifizierter X.509-Zertifikate durch unvorhersagbare Seriennummern erhöht werden kann und wie praktikabel diese Maßnahme ist.	internet explorer	Max Gebhardt;Georg Illies;Werner Schindler	2007			computer vision;magnet;artificial intelligence;latent image;computer science	Crypto	-105.85463643530555	33.30338469919601	12087
1fe764c5ac62cbc30554f0bd3dba6dd6ac0a058c	modellbildung und simulation in der schulischen ausbildung			simulation	Henry Herper	2001				Logic	-97.17878145978636	23.309158154123875	12099
f82c03f2f26bbb3e6bcb1b09bf3738b46b0a8d59	wbcms  uma arquitetura web orientada a serviços para melhorar a colaboração em biodiversidade: o caso da comunidade de modelagem de distribuição de espécies				Karla Donato Fook	2009				Crypto	-106.06834043812952	18.57562110568535	12110
6bc786e4b5732b6707950bddf36056e0f249f775	software engineering for resilient systems		In 2016, Google Cloud had 74 minutes of total downtime, Microsoft Azure had 270 minutes, and 108 minutes of downtime for Amazon Web Services (see cloudharmony.com). Reliability is one of the most important properties of a successful cloud platform. Several approaches can be explored to increase reliability ranging from automated replication, to live migration, and to formal system analysis. Another interesting approach is to use software fault injection to test a platform during prototyping, implementation and operation. Fault injection was popularized by Netflix and their Chaos Monkey fault-injection tool to test cloud applications. The main idea behind this technique is to inject failures in a controlled manner to guarantee the ability of a system to survive failures during operations. This talk will explain how fault injection can also be applied to detect vulnerabilities of OpenStack cloud platform and how to effectively and efficiently detect the damages caused by the faults injected.	amazon web services;cd-rom;cloud computing;downtime;fault injection;formal system;google cloud messaging;microsoft azure;software engineering;system analysis;web service	Josef Kittler;Moni Naor	2017		10.1007/978-3-319-65948-0	system of systems engineering;systems engineering;social software engineering;software development;software construction;requirements engineering;systems development life cycle;resource-oriented architecture;computer engineering	SE	-63.658516390411215	26.442301905637116	12111
5fedb5e2dbd703a88526345a55756f60a1c830ff	formale entwicklung einer steuerung für eine fertigungszelle mit sysyfos		Using the synthesis approach of Manna and Waldinger, a formally specified and verified control circuitery for a production cell was developped. Building an appropriate formal language level, we could achieve a requirements specification to the informal description. We demonstrated that the paradigm of deductive synthesis can be applied to the development of complete verified systems, including hardware and mechanics. We defined two domain–specific logical operators that schematise frequent patterns in specification and proof and hence allow a more concise and expressive presentation. In [Bur95], an english short version of this paper, without appendices, can be found. Abstract. Mit Hilfe der deduktiven Programmsynthese nach Manna und Waldinger wird eine formal spezifizierte und verifizierte Steuerung für eine Fertigungszelle entwickelt. Durch die Erstellung einer geeigneten formalen Sprachebene unter starker Ausnutzung impliziter Spezifikationstechnik wird erreicht, daß die formale Anforderungsspezifikation einer satzweisen “Übersetzung” der informellen Beschreibung entspricht. Es wird demonstriert, wie das Paradigma der deduktiven Synthese zur Entwicklung ganzer verifizierter Systeme, einschließlich Hardware und Mechanik, angewendet werden kann. Es werden zwei anwendungsspezifische logische Operatoren definiert, die eine Schematisierung der in Spezifikation und Beweis häufig vorkommenden Aussagenmuster darstellen und mit deren Hilfe sich beide kürzer und klarer darstellen lassen. In [Bur95] findet sich eine englische Kurzfassung dieses Papiers (ohne Anhänge). Mit Hilfe der deduktiven Programmsynthese nach Manna und Waldinger wird eine formal spezifizierte und verifizierte Steuerung für eine Fertigungszelle entwickelt. Durch die Erstellung einer geeigneten formalen Sprachebene unter starker Ausnutzung impliziter Spezifikationstechnik wird erreicht, daß die formale Anforderungsspezifikation einer satzweisen “Übersetzung” der informellen Beschreibung entspricht. Es wird demonstriert, wie das Paradigma der deduktiven Synthese zur Entwicklung ganzer verifizierter Systeme, einschließlich Hardware und Mechanik, angewendet werden kann. Es werden zwei anwendungsspezifische logische Operatoren definiert, die eine Schematisierung der in Spezifikation und Beweis häufig vorkommenden Aussagenmuster darstellen und mit deren Hilfe sich beide kürzer und klarer darstellen lassen. In [Bur95] findet sich eine englische Kurzfassung dieses Papiers (ohne Anhänge).	deductive database;eine and zwei;eddie (text editor);formal language;internet explorer;logical connective;programming paradigm;software requirements specification	Jochen Burghardt	2014	CoRR			OS	-100.50114764508446	30.8968033414591	12190
cadfc7bf7c449ed0a57851217f62d4782b0b65ad	towards a process analysis approach to adopt robotic process automation		Robotic Process Automation (RPA) is an emerging approach that automates repetitive human tasks using robots. For business processes, RPA refers to configuring software-based robots to do the work previously done by actors in the organizations. RPA offers many benefits including improved business efficiency, increased productivity, data security, reduced cycle time, and improved accuracy while allowing organizations to relieve their employees from repetitive and tedious tasks. However, implementing RPA represents a challenge and organizations must learn to manage RPA adoption to achieve maximum results. This paper aims to help organizations to effectively adopt RPA for automating their business processes. More precisely, it proposes a new method to guide organizations in analyzing their business processes in order to identify the most suitable for RPA. We present the principles underlying our method and the results obtained in the context of key processes from the banking domain.		Abderrahmane Leshob;Audrey Bourgouin;Laurent Renard	2018	2018 IEEE 15th International Conference on e-Business Engineering (ICEBE)	10.1109/ICEBE.2018.00018	task analysis;business process;business efficiency;automation;process management;knowledge management;process automation system;data security;computer science;software	Robotics	-67.55607948341688	13.677849813785214	12277
67e0f3ed6f8442806fd2ad080a2f4a6ab8031b8a	a measure of staying power: is the persistence of emergent concepts more significantly influenced by technical domain or scale?	staying power;technology space;technical emergence	This study advances a four-part indicator for technical emergence. While doing so it focuses on a particular class of emergent concepts—those which display the ability to repeatedly maintain an emergent status over multiple time periods. The authors refer to this quality as staying power and argue that those concepts which maintain this ability are deserving of greater attention. The case study we consider consists of 15 subdatatsets within the dye-sensitized solar cell framework. In this study the authors consider the impact technical domain and scale have on the behavior of persistently emergent concepts and test which of these has a greater influence.	emergence;persistence (computer science);solar cell	Stephen Carley;Nils C. Newman;Alan L. Porter;Jon Garner	2017	Scientometrics	10.1007/s11192-017-2342-x	simulation;artificial intelligence;operations management	HCI	-75.86928934508059	11.918141185776639	12281
d7e4765d743f2dc7d72de20579eb4f1855ffbaf8	on customer satisfaction of battery electric vehicles based on kano model: a case study in shanghai		Due to the greenhouse effect and limited energy resources, more and more countries and firms have put more attention to clean energy so as to reduce pollution emissions. The development of battery electric vehicle (BEV) becomes crucial to meet the government and society’s demands. As one new product with immature technology, there are many factors affecting the wide utilization of BEV. It is necessary to study customer satisfaction of BEV so as to distinguish customer needs, help find the way to improve customer satisfaction, and identify critical factors. Considering the non-linear relationship between product performance and customer satisfaction, the Kano model is used to analyze customer needs for the BEV so as to promote the adoption of BEV in Shanghai. Four approaches to Kano model are used to categorize the BEV attributes as must-be quality, one-dimensional quality, attractive quality and indifferent quality. According to the strategic rule (Mu003eOu003eAu003eI), the priorities of efforts towards promoting the adoption of BEV is identified, i.e., the government and vehicle firms have to fulfill all the must-be requirements. They should make great improvement of one-dimensional qualities to make the BEV competitive to the traditional motor vehicles. Finally, the customers will be very satisfied if the attractive requirements are fulfilled.		Yanping Yang;Hongbin Yan;Tieju Ma	2015		10.1007/978-3-319-25135-6_33	engineering management;marketing;operations management;business	SE	-72.35324917663533	6.818429630500531	12307
2d5f576bd0ccc6e14ae00ded000ce81d60e54219	ask the engineers: exploring repertory grids and personal constructs for software data analysis		"""Maturity in software projects is often equated with data-driven predictability. However, data collection is expensive and measuring all variables that may correlate with project outcome is neither practical nor feasible. In contrast, a project engineer can identify a handful of factors that he or she believes influence the success of a project. The challenge is to quantify engineers' insights in a way that is useful for data analysis. In this exploratory study, we investigate the repertory grid technique for this purpose.  The repertory grid technique is an interview-based procedure for eliciting """"constructs"""" (e.g., adhering to coding standards) that individuals believe influence a worldly phenomenon (e.g., what makes a high-quality software project) by comparing example elements from their past (e.g., projects they have worked on). We investigate the relationship between objective metrics of project performance and repertory grid constructs elicited from eight software engineers. Our results show correlations between the engineers' subjective constructs and the objective project outcome measures. This suggests that repertory grids may be of benefit in developing models of project outcomes, particularly when project data is limited."""	capability maturity model;repertory grid;software engineer;software project management	Lucas Layman;Carolyn B. Seaman;Davide Falessi;Madeline Diep	2015	2015 IEEE/ACM 8th International Workshop on Cooperative and Human Aspects of Software Engineering		personal software process;productivity;interview;software project management;computer science;systems engineering;knowledge management;data mining;project management triangle	SE	-71.13654032699964	22.517699112549195	12322
6247cad0bafeea0500abfbe6ba0cf89ab4bff048	analyse-synthese-codierung basierend auf dem modell bewegter dreidimensionaler, gegliederter objekte			v-model	Geovanni Martinez	1998				NLP	-103.50204687360973	26.06568604150094	12454
e560fa7eebd47a8736c79fd5d51cac1b426b37b9	a pmo installation for ti project management in a r&d institution	software;project management office;iso 9001 2000 standard;project management;standards organizations;iso standards;project manager;information technology;training;non compliance evaluation;pmo installation;production process;research and development;project management office pmo installation ti project management r d institution standardization global economic crisis information technology iso 9001 2000 standard;hardware software project management organizations standards organizations training;global economic crisis;organizations;economics;economic crisis;research and development economics iso standards project management;r d institute;r d institution;standardization;information technology project management office project management non compliance evaluation r d institute;ti project management;hardware	The search for standardization to productive processes improvements gets sharp during periods that are marked by global economic crisis. To look for alternatives aiming at staying present and competitive, considering new market requirements was the reaction of a research and development institute that works with Information Technology. This scenario triggered the motivation to perform the effort described in this article. This institution was chosen for a case study that aims at observing if there was an increase of compliance rates to the project management process that is adherent to the ISO 9001:2000 standard, with the focus on the hardware department. The compliance increase was imagined to be the result of the installation consequence of a Project Management Office (PMO). The performed actions for the PMO structuring were observed and documented, as well as the correlation of process compliance data from a two year period of developed projects, proving the impact of the PMO performance in projects outcomes.	requirement	Aleteia Xavier Bettin;Carlos Miguel Tobar Toledo;Denise P. Prado;Íris Bento da Silva	2010	2010 Seventh International Conference on the Quality of Information and Communications Technology	10.1109/QUATIC.2010.67	project management;systems engineering;organization;engineering;environmental resource management;software engineering;scheduling;management;information technology;standardization	SE	-75.09202236782538	10.684616969813618	12461
86e4c8ddd39ec4fe71045f64becd4b44d480baa4	diagnostic multi-sources adaptatif. application à la détection d'intrusion dans des serveurs web		Résumé. Le but d’un système adaptatif de diagnostic est de surveiller et diagnostiquer un système tout en s’adaptant à son évolution. Ceci passe par l’adaptation des diagnostiqueurs qui précisent ou enrichissent leur propre modèle pour suivre au mieux le système au fil du temps. Pour détecter les besoins d’adaptation, nous proposons un cadre de diagnostic multi-sources s’inspirant de la fusion d’information. Des connaissances fournies par le concepteur sur des relations attendues entre les diagnostiqueurs mono-source forment un méta-modèle du diagnostic. La compatibilité des résultats du diagnostic avec le méta-modèle est vérifiée en ligne. Lorsqu’une de ces relations n’est pas vérifiée, les diagnostiqueurs concernés sont modifiés. Nous appliquons cette approche à la conception d’un système adaptatif de détection d’intrusion à partir d’un flux de connexions à un serveur Web. Les évaluations du système mettent en évidence sa capacité à améliorer la détection des intrusions connues et à découvrir de nouveaux types d’attaque.	bibliothèque de l'école des chartes;hypertext transfer protocol;intrusion detection system;linear algebra;metamodeling;multi-source;server (computing);web server	Thomas Guyet;Wei Wang;Rene Quiniou;Marie-Odile Cordier	2009				Crypto	-106.02250555030031	15.40744495514299	12492
524fd2fd41064d490f685657615383b5704d223f	eine methode zum entwurf betrieblicher informationssyteme		In dem Beitrag wird eine Analyseund Entwurfsmethode sowie eine darauf aufbauende Entwicklungsumgebung präsentiert. Sie zielt darauf, eine softwaretechnisch fortschrittliche konzeptuelle Modellierung betrieblicher Informationssysteme mit der Modellierung organisatorischer und strategischer Handlungsoptionen zu verbinden. Auf diese Weise bietet sie die Chance, die Synergien zu nutzen, die eine integrierte Betrachtung der Anforderungen eines strategisch orientierten Business Reengineering und der Ausschöpfung der damit verbundenen Automatisierungsspielräume verspricht. Dazu werden Konzepte eingeführt, die die genannten Aspekte auf verschiedenen Abstraktionsund Formalisierungsstufen in anschaulicher Weise abzubilden gestatten. Auf diese Weise wird nicht nur der gesamte Lebenszyklus von Informationssystemen abgedeckt, sondern auch ein Medium für einen gehaltvollen Diskurs zwischen betriebswirtschaftlich und softwaretechnisch geprägten Sichtweisen geboten. Es werden zudem Konzepte bereitgestellt, um existierende Daten und Anwendungen zu integrieren. Die Entwicklungsumgebung unterstützt u.a. schnelles Prototyping und die Simulation alternativer Geschäftsprozeßentwürfe.	code refactoring;eine and zwei;intentionally blank page;sie (file format);simulation;unified model	Hubert Österle	1980		10.1007/978-3-642-67838-7_13			-102.84967845984465	32.364955314209276	12505
1491045c4cd505e5cf62a34aef8d97cb00a5dc62	präsentieren - eine kompetenz fürs leben			eine and zwei	Rüdeger Baumann;Bernhard Koerber	2009	LOG IN			Theory	-97.33559426714253	23.503759358634003	12549
3bfc59f7b45bc10a5f6c6f309e2040e6d8478f22	an implementation of correspondence analysis in r and its application in the analysis of web usage			correspondence analysis	Oleg Nenadic	2007				AI	-92.39215477932906	22.360180475060762	12562
201589b3361071e6d338636cf40e2c70e54cfc9e	risk identification at the interface between business case and requirements	business analyst;commercial success;due diligence;business case;risk identication;commercial risk;risk identification;datavetenskap datalogi;success factors;commercialization;risk mitigation	[Motivation:] The requirements engineering (RE) research community is aware of the importance of performing feasibility studies before starting requirements elicitation. Unfortunately, projects still frequently fail to achieve commercial success, responsibility is often unknown, and requirements engineers may be deemed responsible for mistakes made by others. [Problem:] There is neither empirical evidence available from a post-mortem risk analysis for projects that performed adequate RE but commercially failed nor guidance for requirements engineers on validating a business case analysis to mitigate this risk. [Principal idea:] By performing a post-mortem analysis of software development projects that failed to achieve commercial success, we investigate the root causes for the failures and, in most cases, trace the causes back to business case issues. We identify risk areas and provide practical due diligence guidance to the practitioner. [Contribution:] This exploratory case study performs an in-depth review of a detailed post-mortem analysis of three software development projects performed over a 2.5 year period. Each of the analyzed projects failed to make the expected transition to commercialization despite using appropriate RE techniques and achieving satisfactory deliverables. The analysis identifies risk factors that the RE practitioner should consider and we provide a checklist for RE practitioners to use when checking for these risks in an antecedent business case as part of their due diligence. A low-cost commercial viability assessment technique, employing Fermi approximation, is provided to equip the RE practitioner with a risk mitigation tool in the absence of business analyst resources.	approximation;business analysis;business process;new product development;programmer;recommender system;requirement;requirement prioritization;requirements elicitation;requirements engineering;risk factor (computing);software development	David Callele;Birgit Penzenstadler;Krzysztof Wnuk	2013		10.1007/978-3-642-37422-7_18	reliability engineering;risk analysis;economics;risk management;business requirements;systems engineering;operations management;business case;management	SE	-69.77487371517695	22.74583721270621	12568
ba12f17ce584a4f48d61318e6d4599c4409e274f	a business process intelligence system for enterprise process performance management	gestion integrada;modelo dinamico;process performance evaluation;modelizacion;dynamique processus;tesoreria;gestion integree;occupation time;movimiento caja;flow analysis and prediction;evaluation performance;gestion entreprise;dynamic enterprise process modeling depm;technology watch;profit flow business process intelligence system enterprise process performance management business process management systems cost effective process execution dynamic process performance evaluation activity based management manufacturing enterprise activity flow information flow resource flow cost flow cashflow;control de calidad;tresorerie;modele entreprise;performance evaluation;process measurement;temps service;process performance evaluation dynamic enterprise process modeling depm flow analysis and prediction process measurement;performance management;evaluacion prestacion;processus metier;dynamical processes;manufacturing process;dynamic model;resource management;manufacturing enterprise;firm management;automatisation;integrated management;tiempo servicio;vigilancia tecnologica;service time;flujo informacion;automatizacion;dinamica proceso;modelo empresa;resource flow;fluid flow measurement;activity based management;journal;intelligence economique;qualite service;production process;enterprise process performance management;dynamical system;business process management systems;intelligent systems costs automation area measurement fluid flow measurement information analysis manufacturing processes virtual manufacturing quality management resource management;flux information;modelisation;systeme dynamique;profit;business model;control proceso;manufacturing processes;information flow;temps occupation;monitoring;beneficio;procedimiento fabricacion;activity flow;business data processing;evaluation criteria;modele dynamique;business process intelligence;veille technologique;intelligent systems;tiempo ocupacion;process control;processus fabrication;treasury assets	Business process management systems traditionally focused on supporting the modeling and automation of business processes, with the objective of enabling fast and cost-effective process execution. As more and more processes become automated, customers become increasingly interested in managing process execution. This paper presents a set of concepts and a methodology toward business process intelligence (BPI) using dynamic process performance evaluation, including measurement models based on activity-based management (ABM) and a dynamic enterprise process performance evaluation methodology. The proposed measurement models support the analysis of six process flows within a manufacturing enterprise including activity flow, information flow, resource flow, cost flow, cash flow, and profit flow, which are crucial for enterprise managers to control the process execution quality and detect problems and areas for improvements. The proposed process performance evaluation methodology uses time, quality, service, cost, speed, efficiency, and importance as seven evaluation criteria. A prototype system supporting dynamic enterprise process modeling, analysis of six process flows, and process performance prediction has been implemented to validate the proposed methodology.	agent-based model;business process interoperability;child process;code refactoring;data-flow analysis;dynamic enterprise;level structure;multi-agent system;multi-level cell;performance evaluation;performance prediction;process modeling;process ontology;prototype;queueing theory;simulation	WenAn Tan;Weiming Shen;Lida Xu;Bosheng Zhou	2008	IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)	10.1109/TSMCC.2008.2001571	manufacturing execution system;quality management;performance management;simulation;enterprise software;competitive intelligence;artifact-centric business process model;business process management;function model;resource management;integrated enterprise modeling;process control;process modeling;cash flow;business process model and notation;process management;enterprise architecture;business process;event-driven process chain;process mining;enterprise integration;business process discovery;business process modeling;enterprise information system;enterprise life cycle	OS	-68.73581358098436	7.90870477554179	12573
3b6acc26dccf70a4ccb74c47c8bbf7e61640a6ca	emergence of service-added model in b2c for small-sized companies	e commerce;degree of freedom;small sized companies;online shopping;customer relations;intermediary model;b2c management;b2c;service added model	Independent site administration is not as easy for small-sized companies as it is for large ones in the field of B2C e-commerce from the perspective of limited resources. The most prevalent and effective method of compensating for such limited resources is through participation in organizations such as intermediary sites like online shopping malls. On the other hand, the recent movement in Japan which has caught our attention is the emergence of a scheme where customers who access specific sites are privileged to receive exclusive services. This sort of scheme will be referred to here as the service-added model. Though the idea for the service-added model is very simple, it without a doubt enables small-sized companies to increase the access volume to their sites as well as the chance for interaction between the site and customers. At the same time there is a negative aspect of this movement: that this subsequent increase in access volume may cause small-sized companies to neglect the movement of establishing relationships with customers. Yet it is believed that the service-added model could be a promising choice for the sites of small-sized companies as a future B2C model because it allows them to retain the high degree of freedom regarding decision-making and the use of customer data compared with the intermediary model. The idea is supported by our research on sites adopting the service-added model.	customer relationship management;e-commerce;effective method;emergence;online shopping;semiconductor consolidation	Taro Kamioka;Kazuhiko Yahata	2006		10.1145/1151454.1151529	public relations;marketing;operations management;business	HCI	-81.10290253645992	6.956695299484036	12578
32c9285ea3565d79de7dae58f94c292ba2512a0c	betriebssysteme und echtzeit, echtzeit 2015, fachtagung des gemeinsamen fachausschusses echtzeitsysteme von gesellschaft für informatik e.v. (gi), vdi/vde-gesellschaft für mess- und automatisierungstechnik (gma) und informationstechnischer gesellschaft im vde (itg) sowie der fachgruppe betriebssyste			desktop virtualization;gesellschaft für informatik;intel gma;virtual distributed ethernet		2015		10.1007/978-3-662-48611-5		Logic	-99.19099527573628	29.47563785677073	12600
0a88f16ac3f4ffe71498e7c9a55cf935dde60bc6	informatik-didaktik außerhalb der informatik		Wie lassen sich in der Erwachsenenbildung einzelne, für Neue Medien relevante informatische Bildungskerne auch „außerhalb der Informatik“, z.B. für Studierende eines traditionell eher technikfernen Fachs wie Pädagogik aufbereiten? Wir zeigen exemplarisch, wie ein aktueller Begriff der Medienkompetenz zur didaktischen Rechtfertigung der Inhalts-Entscheidung „Informatik an Hand von XML für SozialwissenschaftlerInnen“ herangezogen werden kann. 1 Informatik: ein weites Feld Zur Frage „Was ist Informatik“ zeichnet sich die Diskussion durch vergleichsweise große Heterogenität aus. Dies wundert nicht, da das Fach immer noch jung ist, sich stets neuen Anforderungen gegenüber sieht und deshalb Kontroversen, was „die“ Informatik als Praxis und als Wissenschaft auszeichnet, stets neu geführt werden müssen. Anders der fachdidaktische Diskurs in der Informatik. Eine Zeit lang waren konsensual Algorithmen und Datenstrukturen als der zentrale Bezugspunkt anerkannt. Später führte das Bedürfnis, außer Problemlösungen auch semiformale Spezifikationen und Modelle methodisch gegen eine Instanz prüfen zu können, auch zur Einbeziehung lebensweltlicher Bezüge der Informatik in die fachdidaktischen Curricula. Die Informatik hatte spätestens damit ihre Unschuld als reine Formaloder Strukturwissenschaft längst verloren. Konsequenterweise wird im GI-Papier „Informatische Bildung und Medienerziehung“ ein Spektrum an Themen und Methoden angedeutet, das, recht betrachtet, in viele traditionelle Gebiete der Geistesund Sozialwissenschaften weit hineinreicht. Trotz dieses weit geöffneten Felds konzentrieren sich auch neuere Darstellungen der Informatik wie z. B. das „Handbuch Informatik“ [RP02], die Neuauflage des „Informatik-Dudens“ [ECS01] und auch Hubwiesers Informatik-Didaktik [Hu00] auf Aspekte wie Algorithmen und Datenstrukturen, Programmierparadigmen oder Modellierung. Es entsteht so eine merkwürdige Diskrepanz zwischen ihren bildungstheoretischen Prolegomena und den konkretisierenden Praxisteilen. Dies legt für uns den Schluss nahe, dass das methodisch-wissenschaftlich beherrschte Terrain der Informatik doch deutlich enger	altran praxis;didaktik;die (integrated circuit);eine and zwei;entscheidungsproblem;fach;gesellschaft für informatik;internet explorer;xml	Johannes Busse	2002			philosophy;performance art	OS	-104.94528947960809	33.56811772551838	12684
aa754dd02a8e44497356231b4182f19ba823149e	on engineering standards based carrier grade platforms	upgrade;product life cycle;middleware;robustness;exponential growth;communication technology;off the shelf	The remarkable pace of advancement in communications technologies and the exponential growth of the market have pressured network equipment providers into producing more features in products in a much faster rate at lower costs. The strategy of buying constituent components instead of building one's own has shown promises in achieving these goals. In this paper, we articulate the needs for following standards, and discuss the impact and the required changes for engineering a standards based carrier grade platform. The focus is on the introduction of an availability management middleware, in the form of an off-the-shelf component, and its impact on the product life cycle. By applying and adapting a selection of research results from the dependability community, we show that the telecommunications industry can benefit and achieve its target of reducing development costs.	carrier grade;dependability;middleware;time complexity	Francis Tam	2007		10.1145/1316550.1316554	simulation;systems engineering;engineering;operations management	AI	-65.09168342449304	10.777310371328086	12740
7c469d80e35cab097eaada994f0010f50c2eb4ae	sur l'approximation du contrôle optimal des systémes gouvernés par des equations différentielles avec retard par la méthode de différences finies	mes gouvern;sur l;rences finies		bibliothèque de l'école des chartes;linear algebra	Irena Lasiecka;Andrzej Hatko	1975		10.1007/3-540-07623-9_308	calculus;mathematics	Crypto	-103.61885302039164	16.312752587043718	12752
30073cbb78b66f2fa7cbbcdc8779f3608ad94f5b	in memoriam: alberto del lungo (1965-2003)	alberto del lungo			Elisa Pergola;Simone Rinaldi	2005	Theor. Comput. Sci.	10.1016/j.tcs.2005.08.021		ECom	-105.01883904441017	18.41153239855343	12768
4ba30f9a1cb867a1e42810d2016d1589fbab366d	analysis on the development of e-platforms in the aec sector	production networks;electronic commerce;e business;e commerce;business relationships;best practice;construction industry;ifc;step;information integration;gap analysis;e platforms;aec sector;interoperability;electronic business	Recent studies have illustrated that despite the fact that the AEC sector has yet to adopt international standards like STEP and IFC in order to have interoperability and information integration across its value chain and within the construction life cycle, it has embraced e-commerce and e-business. Indeed, case studies demonstrate that the use of electronic collaborative and commerce platforms by the different players in the AEC sector can be as sophisticated as the best practices found in automotive, aeronautics, or retailing sectors. However, the same studies do also recognise that though the best practices are at the same level, they are much less frequently deployed. This paper presents a methodology based on business factors to assess the readiness and likeliness of the development of e-business and e-commerce between disparate players in AEC projects.	best practice;e-commerce;echo suppression and cancellation;electronic business;embedded system;iso 10303;industry foundation classes;interoperability;requirement;software deployment;strategic management	António Grilo;Ricardo Jardim-Gonçalves	2005	International Journal of Internet and Enterprise Management	10.1504/IJIEM.2005.007640	e-commerce;interoperability;economics;computer science;knowledge management;marketing;operations management;information integration;electronic business;management;best practice	DB	-72.66282819595773	8.148037477877471	12776
3b181d018fa05a6f93c477858baa0e7c1cd0c902	patterns of innovation: a web-based matlab programming contest	collaborative development;open source software development;evolutionary coding;programming contest;matlab;open source	In this paper, we describe an innovative web-based MATLAB programming contest and point out some interesting connections between the contest and open source software development.	matlab;open-source software;software development;web application	Ned Gulley	2001		10.1145/634067.634266	computer science;theoretical computer science;world wide web	ML	-63.831671079940115	22.69933500349353	12807
96fbb5a8e7f5951856a32cd0de37bc3326a7bb1e	possibilities and benefits of intermediate care units in healthcare systems from a logistics perspective		Intermediate care units have been established as a response to the emerging challenges of healthcare systems to maintain high quality and continuous care. While the term is well known in both literature and practice, it lacks a unified definition. There is no common consensus of how intermediate care units can be successfully implemented and properly utilized in healthcare systems. Large variations of services in intermediate care units can be found. This literature review has structured the existing research on intermediate care units, identifying the possibilities and benefits of intermediate care units in healthcare systems from a logistics perspective. The main findings discussed in this study concern the following topics: the effect of intermediate care units on healthcare system performance and patient outcomes, and potential users of and services provided by intermediate care units. This study presents the state-of-the-art research on intermediate care units and suggests topics for further research.	logistics	Aili Biriita Bertnum;Giuseppe Ismael Fragapane;Marco Semini;Jan Ola Strandhagen	2018		10.1007/978-3-319-99704-9_33	process management;health care;business	ML	-80.70421440508677	10.24258549698144	12853
75f123466107e15a7542a37937462fcc8cf4f38b	utilisation du backtrack intelligent dans un branch-and-bound. application au problème d'open-shop	branch and bound	La plupart des recherches arborescentes utilisées en recherche opérationnelle pour résoudre les problèmes d’atelier sont des procédures de séparation-évaluation en profondeur d’abord qui utilisent un backtrack chronologique qui présente quelques inconvénients comme le thrashing. Ces recherches arborescentes énumèrent non pas sur des variables, comme il est courant dans la communauté Programmation par contraintes, mais sur des contraintes et dans le cadre d’une minimisation. Nous proposons dans cet article une technique de backtrack intelligent adapté à ces recherches arborescentes. Les résultats obtenu sur des problèmes d’Open-Shop montrent que notre technique est efficace puisqu’elle a permis de résoudre un Open-Shop ouvert à 10 jobs et 10 machines.	backtrack;branch and bound;council for educational technology;courant–friedrichs–lewy condition;job stream;linear algebra;the print shop;thrashing (computer science)	Narendra Jussien;Christelle Guéret	1998			mathematical economics;philosophy	ML	-108.3547469404666	16.10082896806358	12875
346b964e9da5a16a7ade7584e520bd7d4755bd21	catch-up strategy of latecomer firms in asia: a case study of innovation ambidexterity in pc industry		ABSTRACTOver the last decade, more and more East Asian firms have moved beyond imitation and are delivering innovative products and services to the market. This study examines (a) how a latecomer firm in East Asia transformed its business model in pursuit of manufacturing its own brand and (b) how it managed its exploration and exploitation of the market and technology in response to growth and competition. Given the lack of research on firms transitioning from contract manufacturing (CM) to own-brand manufacturing (OBM), this study offers fresh insights into how Acer, a leading Taiwanese original equipment manufacturer (OEM), has pursued new ways of creating value using an innovation ambidexterity strategy to maximise its customer value and boost performance.Acer is chosen for this case study because of its significance and impact in the global PC industry. Data were collected through interviews and secondary data analysis. Our findings show that innovation ambidexterity is a deliberate transition proces...		T T Kuo;Sirirat Sae Lim;Lamin K. Sonko	2018	Techn. Analysis & Strat. Manag.	10.1080/09537325.2018.1475642	original equipment manufacturer;marketing;economics;imitation;contract manufacturing;business model;ambidexterity;east asia	NLP	-82.65571768287393	6.2472200009518675	12896
de63e93e2697f37e572179c2821ecf67976032df	möglichkeiten und grenzen des einsatzes von corba in db-basierten client/server-anwendungssystemen	client server		common object request broker architecture	Jürgen Sellentin;Bernhard Mitschang	1997			operating system;client–server model;common object request broker architecture;computer science	Crypto	-99.69350627494347	29.435287373792207	12930
a559a08e3db26ea485eadd27ee00c43493da324e	krisensimulation mit abstrakten handlungstypen: ein neuer, methodischer ansatz				Dieter Will	2000				Crypto	-99.15548711192538	26.83250734880564	12941
3bc5448afd5b4a87d5b653d969d5bc249a5ee3a6	flexible integration in supply chains auf basis von web services	supply chain;web service		web service	Jörg-Michael Friedrich;Jochen Speyerer	2003			supply chain management;operations management;web service;supply chain;business	Robotics	-93.97366045857211	27.960951222792193	13053
ff1ab7734fb0ed049aa6474f175cb6102ae9ad67	actes du xxixème congrès inforsid, lille, france, 24-25 mai 2011			les trophées du libre		2011				Vision	-104.68987214862348	16.57349712249751	13066
580c5bf262c44fc816cc19edacdd64b86cbe15d6	mobile location based gaming als wegbereiter für location based services (lbs)		Zusammenfassung: Location Based Services sind seit Anfang der 1990er im Gespräch. Den großen Durchbruch haben LBS bisher aber noch nicht erzielt. Ein Lösungsansatz hierzu heißt „Mobile Location Based Gaming“ (MLBG). Hierbei wird der Spieltrieb des Menschen zur Schaffung von Akzeptanz von LBS ausgenutzt. In diesem Beitrag wird MLBG eingeführt und ein realisiertes mobiles ortsabhängiges Abenteuerspiel („Mobile Hunters“) vorgestellt, das die derzeit vorhandene Mobilfunk-Infrastruktur nutzt, um ein virtuelles Spielfeld zu erzeugen, das wiederum auf die reale Welt abgebildet wird. Diese Form des Spielens, bei der die virtuelle Welt eines Spiels auf die reale Welt abgebildet wird, erscheint zunächst als etwas befremdlich, erweist sich jedoch, wie in diesem Beitrag gezeigt, als ein hilfreicher Schritt in Richtung kontextbasierter Mehrwertdienste.	internet explorer;location-based game;location-based service;unified model	Jörg Lonthoff;Thomas Leiber	2005			internet privacy;computer security;location-based service;computer science	HCI	-103.91585217848447	37.385217553006825	13087
91fae44fbfe2c1814957df0ea61512ebb013e024	an unconstrained dual program for computing convexc 1-spline approximants	structure optimization;aproximacion;duality;approximation;dualite;aproximacion esplin;convex function;spline approximation;approximation spline;unconstrained optimization;dualidad;optimizacion sin restriccion;optimisation sans contrainte;fonction convexe;funcion convexa	In the present paper the problem of approximating given data sets by convex cubicC 1-splines is considered. To this programming problem a dual program is constructed which is unconstrained. Therefore an efficient computational treatment is possible. Es wird die Aufgabe betrachtet, eine vorgegebene Datenmenge durch konvexe kubischeC 1-Splines zu approximieren. Zu diesem Problem wird eine zugehörige duale Optimierungsaufgabe konstruiert, welche den Vorteil hat, daß keine Nebenbedingungen auftreten, und welche sich daher effektiver als das Ausgangsproblem numerisch behandeln läßt.	computation;eine and zwei	Jochen W. Schmidt	1987	Computing	10.1007/BF02310102	convex function;convex analysis;mathematical optimization;duality;approximation;calculus;mathematics;geometry	ML	-97.01932263987898	35.770288943703044	13101
cdd9c53a7856d33387dfc7f43c7172cd48194c50	"""integrating resources for translational research : a unified approach for learning health systems. (intégration de ressources en recherche translationnelle : une approche unificatrice en support des systèmes de santé """"apprenants"""")"""		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Integrating resources for translational research : a unified approach for learning health systems Jean-Francois Ethier	align (company);archive;automatic identification and data capture;baseline (configuration management);comefrom;capability maturity model;charge-coupled device;conditional random field;consortium;core data;data acquisition;data element;data model;domain analysis;emoticon;error detection and correction;fast healthcare interoperability resources;games computers play;hal;health level 7;high-level programming language;information model;jean;linear algebra;map;multi-agent system;nc (complexity);ontology (information science);oracle data mining;overhead (computing);parallels desktop for mac;population;primary source;programming paradigm;randomized algorithm;requirement;scott continuity;semantic interoperability;star catalogue;statistical relational learning;table (information);tabulation hashing;thesaurus;virtual screening;vocabulary;cagrid	Jean-François Ethier	2016				ML	-108.00169593082688	12.051002489523755	13103
79d1e83e6af2ccb6aa96896547d7de0b27cf2e70	towards an interactive index structuring system for content-based image retrieval in large image databases. (vers un système interactif de structuration des index pour une recherche par le contenu dans des grandes bases d'images)		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Towards an interactive index structuring system for content-based image retrieval in large image databases Hien Phuong Lai	bibliothèque de l'école des chartes;content-based image retrieval;database	Hien Phuong Lai	2013				Vision	-107.70657173400173	11.918422236911052	13107
652600f2e05b3acebd6a17531f49cc3b25d725cb	dispatch tooling for global service delivery	databases;service management;political realities dispatch tooling global service delivery tool development service management support service quality redundant work reduction constraint handling technical requirements;global service delivery;web services information management information services;information services;agile development;technical requirements;servers;dispatch tooling;tool development;information management;business;web services;process control;constraint handling;productivity;service management support;servers business process control productivity databases usability;redundant work reduction;agile development service management tool development;usability;service quality;political realities;service delivery	Tool development to support service management is a problem in optimizing service quality and reducing redundant work subject to competing constraints, both technical requirements and political realities. However, many of the constraints only become clear over time, and often only after a series of iterations as tooling exposes new or previously discounted constraints. We present a case study: the evolution of tooling for global dispatch of work orders supporting incident tickets. We discuss different approaches, how they highlighted different constraints, and even how they competed with each other, and conclude with a discussion of approaches to balancing constraints, many of which are not initially apparent and some of which shift over time.	agile software development;authorization;business process;change management (engineering);constraint (mathematics);dynamic dispatch;itil;iteration;operating system service management;requirement;usability	David Loewenstern;Melissa J. Buco;Yixin Diao;Heiko Ludwig;Christopher Ward	2010	2010 International Conference on Network and Service Management	10.1109/CNSM.2010.5691244	web service;productivity;usability;service management;computer science;service delivery framework;operating system;process control;agile software development;information management;management;service quality;information system;server	SE	-71.44078221529793	14.977776644692621	13118
df60bbfff4b150c417084f8c3e6cb502615d2b9e	the service-dominant ecosystem: mapping a service dominant strategy to a product-service ecosystem		Nowadays product-oriented companies are facing the need to focus on the service rather than the product alone. By following a Service-Dominant Strategy, we need to focus on the ecosystem embodying the collaboration to provide such a service. This collaborative perspective on value creation and value sharing is the foundation for designing new business models within the ecosystem. We take the lessons learned in the car-leasing domain on the development of a Service-Dominant Strategy to design a tool supporting the transition from product focus to Product-Service ecosystems.	ecosystem	Egon Lüftenegger;Marco Comuzzi;Paul W. P. J. Grefen	2013		10.1007/978-3-642-40543-3_3	ecosystem services;ecosystem management;environmental resource management;total human ecosystem	Networks	-75.26023424129859	6.097484760663876	13172
93acddcc8a92d5c86846fba0c1e6e35f784b0dbd	integrando processos de negócio à elicitação de requisitos.				Soeli T. Fiorini;Julio Cesar Sampaio do Prado Leite	1997	RITA		software engineering;simulation;computer science	Logic	-104.90618884803612	19.57823024808451	13207
34bfa7e8f3438ecbd418e9ab327662464b64e826	adoption of mobile services in business - case study of mobile crm	electronic commerce;service provider;customer relationship management;computer aided software engineering mobile handsets web and internet services business customer relationship management personal digital assistants research and development management technology management engineering management collaboration;mobile service;business case;mobile customer relationship management;success factor;mobile computing customer relationship management electronic commerce;mobile crm;mobile services adoption;mobile customer relationship management mobile services adoption mobile crm mobile technology mcommerce;mcommerce;mobile computing;mobile technology;value added	The development of mobile technologies offers new opportunities for service providers to create more sophisticated and value added mobile services. These new mobile services can provide a way to deliver various kinds of information to the customers or to work as an interaction channel between service provider and customer. This paper shortly summarized mobile technologies that can be used for creating mobile services for mCommerce. The paper also discuss about success factors for mobile services. Furthermore the paper introduces a case study of a mobile customer relationship management (CRM), that attempts devaluate proposed success factors	customer relationship management;mobile commerce	Petteri Alahuhta;Heli Helaakoski;Alexander Smirnov	2005	IEEE International Conference on e-Business Engineering (ICEBE'05)	10.1109/ICEBE.2005.22	e-commerce;service provider;mobile search;mobile qos;mobile commerce;computer science;knowledge management;value added;marketing;operating system;mobile technology;location-based service;business case;mobile business development;mobile computing;mobile payment	Mobile	-73.56255496208304	6.115198097939487	13223
224de234193935ee55b61e7cf63669b41767f7d8	der tfs-repräsentationsformalismus und seine anwendung in der maschinellen sprachverarbeitung			team foundation server	Martin C. Emele	1997				NLP	-95.80143089711646	24.996965746709282	13289
3b166d34b543b6e95a1891a759fe064be6df71b7	change bursts as defect predictors	software metrics;quality assurance;software;measurement history predictive models complexity theory software quality assurance programming;windows vista;empirical study;complexity metrics;complexity theory;history;measurement;software quality assurance;software quality configuration management software metrics;version control defect predictor software development windows vista change burst defect prone component predictive power software quality;change history;change burst;defects;predictive power;product metrics;defect predictor;developers;process metrics;defect prone component;software development;software mining;empirical studies process metrics product metrics software quality assurance version control change history defects developers software mining;predictive models;change process;empirical studies;version control;programming;configuration management;organizational structure;software quality	In software development, every change induces a risk. What happens if code changes again and again in some period of time? In an empirical study on Windows Vista, we found that the features of such change bursts have the highest predictive power for defect-prone components. With precision and recall values well above 90%, change bursts significantly improve upon earlier predictors such as complexity metrics, code churn, or organizational structure. As they only rely on version history and a controlled change process, change bursts are straight-forward to detect and deploy.	microsoft windows;precision and recall;software bug;software development	Nachiappan Nagappan;Andreas Zeller;Thomas Zimmermann;Kim Herzig;Brendan Murphy	2010	2010 IEEE 21st International Symposium on Software Reliability Engineering	10.1109/ISSRE.2010.25	reliability engineering;quality assurance;computer science;systems engineering;database;empirical research;management	SE	-64.13647250517202	34.34918755949782	13326
f7b58878ef44e6d578da1971f4b3961ae3a8b0ce	werkzeugunterstützte eliminierung von data-races in eclipse		Ein Data-Race bezeichnet eine Situation, in der ein Thread auf ein Datum zugreift und gleichzeitig ein anderen Thread darauf schreibt.[5] In C++ ist seit dem C++11-Standard festgelegt, dass das Verhalten im Falle eines Data-Races undefiniert ist (siehe [2] §1.10/21). Weil undefinierte Zustände von kritischen Systemen in einer technikdurchdrungenen Gesellschaft wie der unseren zu beliebig großen Sachund Personenschäden führen können, ist die Vermeidung solcher Zustände ein wichtiges Forschungsgebiet. Ein Data-Race wird als gefährlich bezeichnet, wenn durch das undefinierte Verhalten mindestens eine kritische Invariante des Gesamtsystems verletzt werden kann. Informell kann man sagen, dass Data-Races gefährlich sind, wenn das Gesamtverhalten des Systems unerwartet beeinflusst werden kann. Gefährlich ist z. B., wenn eine globale Zustandsvariable einen Wert annehmen kann, der kein definiertes Verhalten verursacht. Nicht gefährlich hingegen ist z. B. die Ausgabe von Fortschrittsinformationen auf der Kommandozeile. Weil die Identifikation von Data-Races im Allgemeinen unentscheidbar ist, verwenden wir eine überapproximierte Data-Race-Menge. Um dies zum Ausdruck zu bringen, sprechen wir im Folgenden von einem potentiellen Data-Race, wenn nicht entschieden werden kann, ob es sich um ein reales Data-Race handelt. Es hat sich gezeigt, dass die manuelle Bewertung einzelner potentieller Data-Races viel Zeit beansprucht und daher für Systeme mit vielen potentiellen Data-Races nicht mit vertretbarem Aufwand durchführbar ist. Hier bieten sich prinzipiell zwei Lösungswege. Zum einen kann man versuchen, durch präzisere Analysen die Anzahl der vermeintlichen DataRaces zu verringern. Zum anderen kann man versuchen, den manuellen Bewertungsprozess durch bessere Werkzeugunterstützung zu beschleunigen. Dazu kann man versuchen, mit Heuristiken potentielle Data-Races vorab zu klassifizieren[1]. Außerdem kann man relevante Informationen so aufbereiten, dass sie schneller verarbeitet werden können. Letzteren Ansatz verfolgen wir im Weiteren.	c++;eine and zwei;eclipse;geodetic datum;internet explorer;race condition;sie (file format);unified model	Timm Felden;Torsten Görg	2013	Softwaretechnik-Trends		software engineering;computer science;eclipse	OS	-102.74887475534008	32.29447969225409	13412
32ea3f65ef2d092f91d6f63f610b48f22ac15900	wegeplanung autonomer mobiler roboter mittels dynamischer systeme				Michael Dose	1995				Vision	-103.12323952832693	23.368219489466334	13425
9408457d42e3be0957e7c88074457d3ae7dfcf4f	implementing environmental practices within the greek dairy supply chain: drivers and barriers for smes		Purpose – Food supply chain (FSC) in Greece is dominated by small and medium-sized enterprises (SMEs), who face several challenges in adopting green practices. The purpose of this paper is to identify the key drivers and barriers influencing the environmental performance of SMEs within the Greek dairy supply chain (SC). Design/methodology/approach – Descriptive research methodology attempts to prioritize the drivers and barriers for improving the environmental sustainability performance. Analytical hierarchy process and sensitivity analysis are used to understand the complex nature of the influencing factors. Findings – The analysis identifies five barriers and six drivers for the implementation of green practices within the dairy SC. While external drivers significantly influence the market structure and logistics network, government, competitors and customers are the driving factors for improving environmental performance. Research limitations/implications – The study contributes to filling the literature gap on key factors influencing the implementation of green practices within the FSC. The identified influential factors will contribute toward building a framework for improving sustainability performance within the Greek dairy SC. Practical implications – The study is expected to benefit the Greek and European SMEs by driving their environmental practices within the perishable SC network. Originality/value – The paper provides directions for researchers, practitioners and policy makers in understanding the challenges for implementing green practices in the dairy SC. The holistic approach followed in this paper is a building block for a conceptual framework on implementing environmental sustainability within the FSC. Apart from contributing to the current literature by extending the research horizon to SMEs’ green adoption capability, this study also provides better understanding of the pivotal role of internal and external key factors in influencing sustainability performance.	analytical hierarchy;barrier (computer science);futures studies;holism;in-memory database;logistics;nl (complexity);nl-complete;sustainable water and innovative irrigation management	Abhijeet Ghadge;Merilena Kaklamanou;Sonal Choudhary;Michael Bourlakis	2017	Industrial Management and Data Systems	10.1108/IMDS-07-2016-0270	market structure;competitor analysis;marketing;analytic hierarchy process;descriptive research;engineering;conceptual framework;supply chain;environmental resource management;sustainability;government	HCI	-81.94009438422309	4.608162955942464	13465
7a931bfab252cd14c3a3232925b3bac45239e440	identifying different forms of innovation in retail banking		To be competitive and capture new customers, banks must develop continuous innovations that can reduce costs, enhance existing service quality, expand current service offerings, and increase market share. This article proposes a typology of different types of innovation in the retail banking sector on the basis of a case study of the leading French credit institution, Crédit Agricole. This bank does not innovate just incrementally, and radical innovations resulted from the launch of a new distribution channel, though several innovations are unrelated to new technology. This study adds to literature on innovation services by enhancing understanding of the different types of innovation. The empirical investigation further shows that the banking sector can develop process innovations, which give the bank a longer term competitive advantage. To innovate radically, the bank should anticipate the impact of its new offerings on different areas of the system.	biological anthropology	Véronique Favre-Bonte;Elodie Gardet;Catherine Thevenard-Puthod	2013	IJSSMET	10.4018/ijssmet.2013100103	marketing;retail banking	HCI	-81.80552477534592	6.654449871880994	13480
0b0adfcc47674727c5711873394032163d2f488d	risk-aware service level agreement design for enterprise information systems	operations strategy;new technology;reliability;model combination;slo;information systems;service provider;green it sla slo performance model workload forecast;risk analysis;emergency service;resource manager;resource management;economics information systems adaptation models reliability quality of service resource management;decision maker;sla;enterprise information system;risk analysis cloud computing decision making enterprise resource planning information systems;enterprise resource planning;performance model;workload forecast;service level agreement;economics;information system;quality of service;green it;adaptation models;system management;service quality;economic price risk aware service level agreement design enterprise information systems corporate computing cloud computing it operation decision makers sla it decision makers operation cost service quality;cloud computing	Effective information systems have become key to sustainable business practices. However rising costs of operation and a growing system complexity are driving the search for a more efficient delivery of corporate computing. New technologies in the emerging service world such as cloud computing provide powerful alternatives to traditional IT operation concepts. Nonetheless, executive decision makers still have reservations about migrating to this new technology. In addition to security concerns, a key issue is the still prevailing lack of strict SLAs in these service offerings. In fact, service providers hesitate to offer strictly binding SLAs because assessing economic risk exposure is a major challenge. In this paper, we present a novel model for sustainable SLA design for enterprise information systems. Our model combines various state-of-the-art concepts from the field of system management and balances the failure risk with the cost of operation. More concretely, our model helps IT decision makers to understand the relationship between the operation cost and the service quality. Consequently, the minimum economic price of a service and the corresponding operation strategy, given the customer requirements and the infrastructure characteristics, can be determined based on our approach.	cloud computing;enterprise information system;information systems;quality of service;requirement;service-level agreement;systems management	Markus Hedwig;Simon Malkowski;Dirk Neumann	2012	2012 45th Hawaii International Conference on System Sciences	10.1109/HICSS.2012.509	service level requirement;service level objective;computer science;knowledge management;marketing;resource management;operations management;operating system;service design;database;management science;management;information system	DB	-77.28921576283979	13.92992769734972	13498
8ebc3cfa93cb0c45f9d105bd3e7da0b5ce34e8be	sistema multiagente integrador de bibliotecas digitales		Resumen. Debido a la existencia de múltiples Bibliotecas Digitales en Internet, cuando un usuario pretende obtener una buena parte de la información disponible sobre un tema, éste tiene que invertir mucho tiempo para buscar las fuentes dentro de ellas y después integrar los resultados que considera relevantes. En este art́ıculo se presenta la aplicación de un sistema multiagente que realiza búsquedas de documentos en diferentes bibliotecas digitales dada una determinada consulta y criterio, para que posteriormente integre los resultados y los presente al usuario. El sistema integra las ventajas de los sistemas Multiagente, Arquitecturas Orientadas a Servicios y algunos de los principios de la Integración de Información. En el art́ıculo, se presenta el detalle de la arquitectura propuesta (roles de agentes y protocolos de interacción) y de las fases de Integración de Información, lo que conforma el núcleo del sistema.	linear algebra;lo que tú quieras oír;unique name assumption	Christian Sánchez-Sánchez;Héctor Jiménez-Salazar;Carlos Rodríguez-Lucatero;Esaú Villatoro-Tello;Gabriela Ramírez-de-la-Rosa	2015	Research in Computing Science		philosophy;performance art	Crypto	-106.56222220919851	17.26828567526637	13500
b5d37406fe09eb01a203890f79fa7de4e1db4267	anwendung der gestaltpsychologie zur verbesserung der visuellen kommunikation in der datenverarbeitung			gestalt psychology	Otto Buchegger	1979	Elektronische Rechenanlagen			NLP	-102.20306563624345	25.82833193008886	13547
23833850490359a333fe66dd3fac23d12b928008	generalisierbarkeit einzelner physiologischer messungen über meßzeitpunkte und situationen				A. Hinz;C. Kegler;G. Schreinicke;B. Hüber	1994				NLP	-96.81357239199616	23.50664859689901	13565
ca4be32245058e26a221e67aa619347e02120966	verteilte online und onboard evolution und adaption von kontrollmechanismen für rekonfigurierbare modulare roboter				Florian Schlachter	2014				Vision	-99.03834889513347	26.399164359470838	13588
96c22fbbda276da4451fbb7637b6f72742d84f6c	polynômes prenant des valeurs premières	probabilistic model			François Dress;Michel Olivier	1999	Experimental Mathematics	10.1080/10586458.1999.10504622	calculus;mathematical analysis;mathematics	Crypto	-103.5582475895856	13.369358406158726	13631
488bc3c5888590c02b43939f84d0be718b41a64a	graphische präsentationen von ausführbaren sa/rt - modellen	graphische pr;sentationen von ausf;hrbaren sa	In diesem Papier wird eine graphische Endbenutzerprasentation von ausfuhrbaren SA/ RT-Modellen vorgestellt, die im Rahmen des Prototyping den Kommunikationsprozes zwischen dem Systemanalytiker, der die Anforderungsdefinition erstellt und dem Endbenutzer, der die zu erfullenden Anforderungen liefert, wesentlich verbessert. Ziel dieser Kommunikationsverbesserung ist eine Vereinfachung der Validierung eines zu erstellenden Systems. Dazu wird zunachst die Technik der Graphischen Prasentation, die eine benutzerfreundliche Sicht auf ein System darstellt, erlautert. Nach der Vorstellung von verschiedenen Verknupfungsmoglichkeiten von SA/RT-Modellen und Graphischen Prasentationen wird das implementierte System beschrieben, das die beste Verknupfungsalternative realisiert.		Martin Meuser	1993			systems engineering;software engineering;computer science	EDA	-101.7241802056471	32.000673102276195	13661
13abc7f0b72d67b34ee8b7861dee3435bb670906	zur struktur des augenfolge- und fixationssystems des menschen unter regelungstechnischen gesichtspunkten mit berücksichtigung des reafferenzprinzips		In a recording device one end of a flexible, wear-resistant capillary tube is located in an ink reservoir while its other end forms a recording tip and is fastened to a movable carriage. The capillary tube draws ink out of the reservoir and conveys it to the recording tip.	bibliothèque de l'école des chartes	Peter Lässig	1967	Elektronische Informationsverarbeitung und Kybernetik		geometry;capillary action;combinatorics;mathematics	Crypto	-105.28138052395089	22.047252211603467	13711
fdee6395dbd0868961c0348124c5f4446b597aac	anpassbare computerspiele für senioren		Vom Spielverhalten älterer Erwachsener, warum Computerspiele dabei helfen können, fit und gesund zu bleiben und von einem beachtlichen Markt. Überblick Obwohl sich Kartenund Brettspiele unter Senioren großer Beliebtheit erfreuen, wurden erste Ansätze, Computerspiele für ältere Menschen zu entwickeln, weitestgehend belächelt. Ältere Erwachsene werden mit Gesellschaftsspielen in Verbindung gebracht, und Studien über das selbsteingeschätzte Spielverhalten älterer Menschen bestätigen diese Ansicht zunächst. Senioren nennen als ihre Spielevorlieben meist etablierte Brettund Kartenspiele und heben dabei den einfachen Zugang und bekannte Spielprinzipien als wichtige Merkmale hervor [13]. Allerdings spielen viele Senioren bereits jetzt regelmäßig Computerspiele. Casual Games, also Spiele mit überschaubarer Spielmechanik, leichtem Einstieg, schnellen Erfolgserlebnissen und ohne komplexe Geschichte, stellen dabei die beliebteste Klasse dar. Weiterhin zeigen Forschungsergebnisse [16], dass ältere Menschen ein besonderes Interesse an solchen Computerspielen haben, denen Sie das Potenzial zuschreiben, zu der Verbesserung ihres körperlichen und geistigen Wohlbefindens beizutragen. Dazu zählen ,,Gehirnjogging“ Spiele, wie z. B. Sudoku, aber auch zunehmend bewegungsbasierte Umsetzungen bekannter Spiele, wie z. B. Bowling (siehe u. a. wii-senioren.de). Je nach Art können solche spielerischen Aktivitäten tatsächlich sowohl kognitiv [3, 12] als auch körperlich [9] positive Auswirkungen haben. Neben der spielgestalterischen Perspektive stellen sich in diesem Kontext auch aus der informatisch-technischen Perspektive spannende Fragen: ,,Sind die bestehenden Interaktionsmethoden für die Zielgruppe geeignet?“, ,,Wie kann eine Zugänglichkeit und Benutzbarkeit sichergestellt werden?“, ,,Gibt es besondere Anforderungen an die Nutzungssicherheit?“ und ,,Können aus den Interaktionsdaten nützliche Informationen, z. B. im breiteren Kontext präventiver Maßnahmen oder einer therapeutischen Behandlung, gewonnen werden?“. Zudem muss die Datensicherheit eine zentrale Rolle spielen. Da die Zielgruppe der Senioren einen stetig wachsenden Anteil der Bevölkerung ausmacht, erfährt sie derzeit nicht nur aus wissenschaftlicher, sondern auch aus wirtschaftlicher Perspektive vermehrt Aufmerksamkeit. Die gesamte Spieleindustrie ist ein Markt von häufig unterschätztem Umfang, mit einem überschlagenen Umsatz von 1,82 Mrd. Euro durch 69,5 Mio. verkaufte Computerund Videospiele, alleine für die deutsche Games-Industrie, wobei 20 % der regelmäßigen Spieler über 50 Jahre alt sind [5]. Es gibt also eine große Zielgruppe	eine and zwei;gesellschaft für informatik;internet explorer;sie (file format);sudoku	Jan D. Smeddinck;Kathrin Maria Gerling;Rainer Malaka	2014	Informatik-Spektrum	10.1007/s00287-014-0835-z	software engineering;computer science	DB	-104.70720757140089	34.189329924955075	13716
016c796d1a8110b1ee46595b13b3b1444772be51	findings and recommendations from a pan-european research project: comparative analysis of e-catalog standards	electronic commerce;comparative analysis;standards;xml;electronic product catalogs;electronic commerce standards;electronic data interchange;b2b e commerce	This paper describes the methodology of a European research project on e-catalog standards and presents its major findings by formulating recommendations for future standardization work. The comparative analysis of 14 standards was conducted within the CEN/ISSS Workshop eCAT that aims at setting the basis for harmonized e-catalog standards. As part of this workshop, we present a framework and a complementing set of criteria for assessing the quality of ebusiness standards. Eventually, we apply this methodology to our object of interest. The findings can be regarded as an assessment of the state of the art in e-catalog standardization. By identifying problems and obstacles that hinder a broader acceptance and diffusion of standards, we argue on more suitable, harmonized standards.	cen/xfs;electronic business;qualitative comparative analysis;recommender system	Volker Schmitz;Jörg Leukel	2005	Int. J. IT Standards and Standardization Res.	10.4018/jitsr.2005070105	e-commerce;qualitative comparative analysis;xml;computer science;marketing;electronic data interchange;world wide web;commerce	HCI	-70.687356275522	12.479009780725214	13724
f453ec034c8ca769056253c547b1dfb6582d2b33	managing technical debt in enterprise software packages	measurement;software quality cost benefit analysis evolutionary computation software development management software maintenance software packages;software maintenance;software management;maintenance engineering;enterprise software;technical debt;customer satisfaction;software evolution;business;software packages business software quality measurement maintenance engineering context;cots;technology adoption;software platforms;longitudinal data;context;software quality;software packages;enterprise software product adoption technical debt management evolutionary model software technical debt theory commercial enterprise software package optimization problem software quality customer satisfaction early adopter scenario late adopter scenario software package lifecycle stage	We develop an evolutionary model and theory of software technical debt accumulation to facilitate a rigorous and balanced analysis of its benefits and costs in the context of a large commercial enterprise software package. Our theory focuses on the optimization problem involved in managing technical debt, and illustrates the different tradeoff patterns between software quality and customer satisfaction under early and late adopter scenarios at different lifecycle stages of the software package. We empirically verify our theory utilizing a ten year longitudinal data set drawn from 69 customer installations of the software package. We then utilize the empirical results to develop actionable policies for managing technical debt in enterprise software product adoption.	cross-sectional data;customer relationship management;enterprise software;manifest (transportation);mathematical optimization;models of dna evolution;optimization problem;software quality;technical debt;theory;tree accumulation	Narayan Ramasubbu;Chris F. Kemerer	2014	IEEE Transactions on Software Engineering	10.1109/TSE.2014.2327027	maintenance engineering;reliability engineering;verification and validation;software quality management;enterprise software;computer science;systems engineering;package development process;software evolution;social software engineering;software development;software engineering;technical debt;software technical review;software walkthrough;customer satisfaction;software maintenance;software deployment;software quality control;software quality;measurement;software peer review	SE	-66.5113364904272	28.617835175476667	13735
07dc20e1547f56f701db405155e31335bc29c01d	maturity model for advancing smart grid interoperability	interoperability capability maturity model smart grids communities organizations standards organizations;smart grid interoperability;energy management systems;energy management smart grid interoperability interconnection maintenance interconnection integration project predictability component costs labor costs agreement quality gridwise architecture council gwac united states department of energy capability maturity models software industry concepts interoperability maturity model;smart power grids capability maturity model energy management systems open systems power system interconnection;power system interconnection;maturity model;smart power grids;ieee;capability maturity model;open systems;system integration architecture energy management information technology intelligent systems interoperability maturity model software engineering	Interoperability is about the properties of devices and systems to connect and work properly. Advancing interoperability eases integration and maintenance of the resulting interconnection. This leads to faster integration, lower labor and component costs, predictability of projects and the resulting performance, and evolutionary paths for upgrade. When specifications are shared and standardized, competition and novel solutions can bring new value streams to the community of stakeholders involved. Advancing interoperability involves reaching agreement for how things join at their interfaces. The quality of the agreements and the alignment of parties involved in the agreement present challenges that are best met with process improvement techniques. The GridWise® Architecture Council (GWAC) sponsored by the United States Department of Energy is supporting an effort to use concepts from capability maturity models used in the software industry to advance interoperability of smart grid technology. An interoperability maturity model has been drafted and experience is being gained through trials on various types of projects and community efforts. This paper describes the value and objectives of maturity models, the nature of the interoperability maturity model and how it compares with other maturity models, and experiences gained with its use.	capability maturity model;interconnection;interoperability;software industry	M. Knight;Steven E. Widergren;J. Mater;A. Montgomery	2013	2013 IEEE PES Innovative Smart Grid Technologies Conference (ISGT)	10.1109/ISGT.2013.6497915	interoperability;systems engineering;engineering;operations management;software engineering;service integration maturity model	SE	-66.81528542158127	11.77585914648637	13791
e527b26302c102dd33970ca012c5030b17124c07	current practices in software processes for system planning and requirements analysis	requirement analysis;software process	Software process modelling has been acquiring increasing attentions not only in the software research community but also in the industry. In this paper, we report our attempt to understand real software processes. The lower stream processes such as detailed design, programming and testing are relatively well known and often taken as a target of formal process description. On the other hand, the upper-stream processes including system planning, requirements definition and general design phases are human intensive activities and require more understanding. Thus, we have focused on these upper stream phases. Taking an approach of in-depth interviews and document investigation, we describe the current status of the software process practices in the Japanese industry in the phases of system planning and requirements analysis/definitions. The nature of the study is comparative, comparing the practices of more than a dozen companies and through that comparing some of the characterists of Japanese way to those of other countries.	process modeling;requirement;requirements analysis;requirements engineering;semantics (computer science);software development process;software engineer;xojo	T. Tamai	1993	Information & Software Technology	10.1016/0950-5849(93)90004-M	requirements analysis;personal software process;software requirements specification;verification and validation;team software process;software engineering process group;extreme programming practices;computer science;systems engineering;engineering;knowledge management;software design;software development;software design description;requirement;software engineering;software construction;management science;software walkthrough;empirical process;management;software deployment;goal-driven software development process;software development process;software requirements;software metric	SE	-68.49593584704814	21.996729981256614	13794
0af4a3ea77f033cf4fa157f43751215acbe7c886	towards a knowledge management framework for crossing knowledge boundaries in agricultural value chain		AbstractThe purpose of the paper is to propose a framework for the development of a decision support system in order to evaluate the knowledge boundaries in agricultural value chain. Knowledge boundaries exist due to differences in the way we work, share our knowledge, expertise, different organisational culture, etc. In this paper, we identify the most common knowledge boundaries that are reported in the literature, and propose a general framework for a preparation of a decision support system to evaluate the existing knowledge boundaries. In particular, we are interested in identifying the knowledge boundaries in agricultural value chain, evaluating them and providing possible solutions of crossing them. It is a two-step method: firstly, a semi-automatic ontology is generated using the freely available tool OntoGen, which we use to define the most commonly reported concepts in crossing knowledge boundaries, and then, based on the obtained ontology, we propose a decision support system for evaluation of ...	knowledge management	Biljana Mileva-Boshkoska;Shaofeng Liu;Huilan Chen	2018	Journal of Decision Systems	10.1080/12460125.2018.1468173	knowledge management;organizational culture;management science;ontology;decision support system;computer science;common knowledge;agricultural value chain	AI	-67.98582212284747	13.149128219512065	13813
68b9a2afae9f570301dc52f84c271e956cddb226	pigsparql: übersetzung von sparql nach pig latin.		Dieser Beitrag untersucht die effiziente Auswertung von SPARQLAnfragen auf großen RDF-Datensätzen. Zum Einsatz kommt hierfür das Apache Hadoop Framework, eine bekannte Open-Source Implementierung von Go gle's MapReduce, das massiv parallelisierte Berechnungen auf einem verteilten Syst m ermöglicht. Zur Auswertung von SPARQLAnfragen mit Hadoop wird in diesem Beitrag PigSPARQL, eine Übersetzung von SPARQL nach Pig Latin, vorg estellt. Pig Latin ist eine von Yahoo! Research entworfene Sprache zur ve rteilten Analyse von großen Datensätzen. Pig, die Implementierung von Pig Latin für Ha doop, übersetzt ein Pig Latin-Programm in eine Folge von MapReduce-Jobs, d ie anschließend auf einem Hadoop-Cluster ausgeführt werden. Die Evaluatio n von PigSPARQL anhand eines SPARQL spezifischen Benchmarks zeigt, dass d er gewählte Ansatz eine effiziente Auswertung von SPARQL-Anfragen mit Ha doop ermöglicht.	apache hadoop;eine and zwei;mapreduce;sparql	Alexander Schätzle;Martin Przyjaciel-Zablocki;Thomas Hornung;Georg Lausen	2011			computer science;algorithm;cartography	Theory	-106.35346477953794	36.101923646239634	13864
f2ead358e10b00053e29fda80cbd48f057d285d8	aktives sehen in aktiven fahrzeugen?		Wir schreiben das Jahr 2020. Ein nett anzusehender Roboter serviert Ihnen im Restaurant gerade Ihr Essen. Längst verfügen diese dienstbaren Helfer nicht nur über die Sensorik einer Fledermaus, sondern auch über zwei Augen, die sich ständig betriebsam bewegen und, leicht schielend, die heruntergefallene Gabel fixieren, damit der kleine R2D2 sie ohne Probleme aufheben kann. Faszinierend, auch wenn Sie sich vielleicht etwas wehmütig an die freundliche Bedienung von früher erinnern. Nach dem Essen setzen Sie sich in Ihr nagelneues intelligentes Fahrzeug. Es ist mit einem aktiven Kamerasystem ausgestattet, das Sie nicht nur vor Gefahren warnt und die Fahrzeuggeschwindigkeit der aktuellen Geschwindigkeitsbegrenzung anpaßt, sondern Ihnen auch das Fahren im Stau wie auf der Autobahn abnimmt, wann immer Sie das wollen. Sicher, der Kasten unter der Dekke stört etwas, aber schließlich muß das schwenkbare Kamerasystem ja irgendwohin. Sicher, Sie waren schon zum wiederholten Male beim Kundendienst, weil sich die Sakkadensteuerung einfach nicht mit der Schlaglochpiste im Nachbardorf verträgt, aber ohne das geht es nun mal nicht. Oder vielleicht doch? Wenden wir uns noch einmal dem kleinen Ober zu. Der Serviceroboter ist sicher eine visionäre Applikation, die besonders nach Aktivem Sehen verlangt. Ein Stereokamerasystem mit der Möglichkeit der Vergenzkontrolle ist für Greifaufgaben geradezu prädestiniert. Natürlich muß der Roboter seinen Blick auf interessante Objekte wenden können. Die Frage, ob er dazu seine Kameras blitzschnell positionieren können muß, kann bei der Breite möglicher Anwendungen noch nicht eindeutig beantwortet werden. Der Praktiker schreckt jedoch vor der bei heute realisierten Systemen aufwendigen, teuren Aktuatorik zurück und wird nach Lösungen suchen, die dieses liebste Spielzeug mancher Wissenschaftler nicht benötigen. Aktives Sehen bedeutet in der Robotik aber nicht nur bewegte Kameras, sondern vor allem aktive (Seh)sensorik. Die meisten Navigationsaufgaben in geschlossenen Räumen werden erfolgreich mit Karte und Infrarot-Scannern erledigt. Im Entwicklungsstadium befinden sich bildgebende IR-Systeme verschiedener Auflösungen, die zu jedem Bildpunkt Grauwert und Entfernung liefern. Solche Sensoren erlauben einen direkten Zugang zu Informationen, die heute nur aufwendig und für die Praxis oft nicht robust genug gewonnen werden können. Aus Sicht autonomer Fahrzeuge lebt der Serviceroboter in einer heilen Welt. Er bewegt sich vergleichsweise im Zeitlupentempo in weitgehend kontrollierbarer Umgebung und kann im Notfall sogar (meistens) kurz anhalten, rechts und links schauen, nachdenken und dann weiterrollen. Im Gegensatz dazu ist ein Auto bereits in der Stadt mit hoher Geschwindigkeit unterwegs. Dabei ist es nicht unabhängig, sondern Teil des fließenden Verkehrs. Dies bedingt schnelle Reaktionen auf eine komplexe, sich rasch verändernde und oft wenig kooperative Umwelt. Eine zuverlässige Fahrzeugregelung verlangt nach Zykluszeiten von 4080 ms. Bereits Warnsysteme, erst recht aber automatische Systeme erfordern höchste Zuverlässigkeit bei der Lösung ihrer Aufgaben. Die Sehsysteme müssen ihre Aktives Sehen in aktiven Fahrzeugen?	altran praxis;eine and zwei;intentionally blank page;internet explorer;parity (physics);rasch model;sie (file format);système universitaire de documentation;vhf omnidirectional range;zentralblatt math	Uwe Franke	1999	KI			OS	-105.66130884345891	34.34740385335216	13866
8e0a341e44e9591a2fef7d5612137b30070597b2	zwischenbericht des ak requirements-engineering-frameworks und produktlinien		Es gibt heute eine Vielzahl von Frameworks, die aus verschiedenen Perspektiven die Grundzüge des Requirements-Engineering und -Management beschreiben (z.B. Prozess-, Informationsund Reifegradmodelle). In unterschiedlichem Maße berücksichtigen sie Belange der Software-Produktlinienentwicklung. Der Arbeitskreis „Requirements-Engineering-Frameworks und Produktlinien“ stellt die Frameworks einander gegenüber und bewertet sie hinsichtlich ihrer Eignung für die industrielle Produktlinien-Entwicklung. Dieser erste Zwischenbericht erläutert Ziele und Vorgehen des Arbeitskreises [3].	eine and zwei;requirement;requirements engineering;sie (file format)	Andreas Birk;Samuel Fricker;Eva Geisberger;Gerald Heller;Dirk Janzen;Thomas von der Maßen;Birgit Penzenstadler;Klaus Schmid	2008	Softwaretechnik-Trends		computer science;software engineering;systems engineering;requirements engineering	Crypto	-101.24833726116732	32.47040597368159	13883
9025873c57ac0eb140fd640ece42638a5a2dec8c	einführung des wissensmanagementsystems knowledge café in einer wirtschaftsprüfungsgesellschaft				Norbert Gronau;Marten Schönherr	2001				NLP	-97.82692255677753	25.82759657916246	13937
3fde79fafc9edbe0ad4282104e44c468a2bf1af4	active learning for real time detection of polyps in videocolonoscopy	videocolonoscopy;active learning;real time analysis;colorectal cancer;computer aided detection	HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Active Learning For Real Time Detection Of Polyps In Videocolonoscopy Quentin Angermann, Aymeric Histace, Olivier Romain	archive;comefrom;hal;linear algebra	Quentin Angermann;Aymeric Histace;Olivier Romain	2016		10.1016/j.procs.2016.07.017	simulation;computer science;colorectal cancer;artificial intelligence;multimedia;active learning	ML	-107.81866234159746	11.11242734010648	13998
218c2a56f4fa1b686fdd9ee38c71c92dd5250609	veränderungen der kommunikation in der steuerberatung durch den einsatz internetbasierter technologien				Ingmar Schörck	2003				NLP	-100.92570821907613	26.77011289692476	14001
37dfbb65ab4212111af5dff8b7b765112d07480e	a future for professional communicators in software engineering	software engineering	When disaster strikes, helping people survive in the short term is vital but not sufficient. Those touched by a disaster need jobs to pick up their lives again, but jobs do not survive if business hasn’t anticipated the possibility of such disruption. The companies that survive catastrophic events with minimal negative effect are the ones that have disaster plans to preserve critical data offsite, that have plans to resume operation at a new location, and that have implemented knowledge management practices, which allow them to adjust nimbly to the shortor long-term loss of personnel.....Read more.	denial-of-service attack;job stream;knowledge management;software engineering	John K. Horberg	1994		10.1145/192506.192547	personal software process;computing;software engineering process group;computer science;social software engineering;software development;civil engineering software;software engineering;software construction;software engineering professionalism;software walkthrough;software requirements;computer engineering;software peer review	HCI	-69.19583423922113	25.51596451544485	14010
146059ea323a7d90776d5f07a6277de6fb295bb8	ein ansatz zur lösung großer netzwerkprobleme mit fixed charge kanten				Xihe Lin	1997				Theory	-98.98856458415574	26.62843338827243	14026
60abb48cb293ed1d389c26c002d063977db63c17	mythen, menschen, manager - projektmanagement und usability	qualitatssicherung;nutzerorientierung;projektmanagement;usability engineering;gebrauchsfreundlichkeit;other;kundenorientierung		usability	Rainer Heers;Stefan Voigt	2004			usability engineering;human–computer interaction;usability;computer science	HCI	-96.46192969407433	28.993893364400613	14030
92b4d2dd85aff1b4af39f3dafd043b475a1273c1	transformation de programmes prolog en vue de la compilation			compiler;linear algebra;prolog;vue	G. Landais	1986			algorithm;computer science;prolog	PL	-103.44635193361964	13.83149441834594	14053
97c5f4d37d2b9e4749d27b68709dcc8867db0c28	effizientes informations- und dokumentations-management - ein objektorientierter ansatz	und dokumentations-management;ein objektorientierter ansatz;effizientes informations	Beim Verkauf komplexer technischer Produkte wird die Dokumentation ein immer wichtigerer Wettbewerbsfaktor, da eine gut strukturierte, verstandliche und korrekte Beschreibung eines Produkts einen echten Wettbewerbsvorteil schafft. Das Erstellen von Dokumentationen ist jedoch eine sehr komplexe und zeitaufwendige Aufgabe. In diesem Artikel wird ein objektorientierter Modellierungsansatz und ein Dokumentmanagementsystem vorgestellt, das auf Basis eines objektorientierten Datenbanksystems implementiert wurde und eine effiziente Verwaltung, Erstellung und Suche von Dokumenten ermoglicht. Dabei ist die Grundlage des verwendeten Losungsansatzes eine ganzheitliche Modellierung, in der die Dokumente zusammen mit dem, was sie beschreiben, objektorientiert reprasentiert werden.		Gabriele Höfling;Johann Kempe	1993			performance art;philosophy	NLP	-104.88774795050823	32.43420991091979	14061
bb749091cf5caaac82e3204583faf2b74beb6b16	make space for the customer: the shift towards customer centricity		Companies need to understand what their products and services do for their customers. But how can we encourage the organizations that we work for to concentrate more on the needs of their customers and end users? How can we inspire each other to deliver more innovative products?		Kostanija Petrovic;Melanie Siegmann	2011		10.1007/978-3-642-21675-6_56	customer to customer;voice of the customer;marketing;advertising;business;customer retention;commerce;customer advocacy	AI	-74.39318363458428	4.586488795638058	14067
661f96944757d5020d0530d33c487778b4767f52	modèles d'arbre pour xolap		Résumé. Avec l’avènement de XML comme standard de représentation de données décisionnelles, les entrepôts de données XML trouvent leur place dans le développement de solutions décisionnelles. Dans ce contexte, il devient nécessaire de permettre des analyses OLAP sur des cubes de données XML. Afin de contribuer à ces recherches, de définir un cadre formel et de permettre l’optimisation indispensable des requêtes décisionnelles exprimées en XQuery, nous travaillons à définir une algèbre XML-OLAP (ou XOLAP). En premier lieu, nous avons exprimé avec l’algèbre XML TAX (Tree Algebra for XML) les opérateurs OLAP usuels. Il s’agit maintenant de prendre en compte les structures complexes permises par XML. Comme premier pas, nous proposons dans cet article un opérateur rollup basé sur un modèle d’arbre qui prend en compte des données XML multidimensionnelles organisées en hiérarchies complexes. Mots clés : XML, Entrepôts de données, XOLAP, Modèles d’arbre, Hiérarchies complexes, Algèbre, opérateur rollup	bibliothèque de l'école des chartes;data cube;decision support system;olap cube;online analytical processing;reactions to the november 2015 paris attacks;relational model;xml namespace;xquery	Marouane Hachicha;Jérôme Darmont	2010			xml;database;online analytical processing;xquery;computer science	DB	-107.70953246647272	14.984386015295906	14117
f8fc41ce37112aa6c118635a48225aa39681f314	software management and the impact of improved programming technology	computer performance evaluation;software event monitor;operating systems	This paper presents the impact of “Improved Programming Technology” as viewed by a major financial institution. Limitations and/or advantages are discussed in terms of an overview as well as the institution's practical experience. Recommendations as to the most productive elements for initial implementation are also included.	recommender system;software project management	George P. DiNardo	1975		10.1145/800181.810347	simulation;computer science;systems engineering;software development;software engineering	HCI	-66.19022379493562	25.410777936952616	14133
cb691c6bcb4aa04980fd879dfb6a37d089f82e38	fraktale dimension der kontur endoskopisch ermittelter farbbilder von geschwüren des magens				Dietrich Paulus;Heinrich Niemann;Christian Lenz;L. Demling;C. Ell	1993			mathematics	Crypto	-97.62045260799849	22.447043804127446	14144
49a586d38b61c72929405e86dc10819b77fe672c	establishing experience factories at daimler-benz an experience report	organizational learning;experience report;large scale;lessons learned;continuous improvement;guarantee management experience factories daimler benz systematic learning continuous improvement software development software improvement program application projects organizational learning mercedes cars airbus airplanes reconnaissance systems space systems control systems;production facilities concrete large scale systems embedded software software engineering continuous improvement programming uncertainty delay application software;software development;management of change software development management;management of change;experience factory;process improvement;software development management	The experience factory concept enables systematic learning and continuous improvement in software development. As with most learning initiatives, it is hard to establish. In our experience, there is a great deal of uncertainty and skepticism about the mission and contents of an experience factory. The starting phase is especially endangered through pitfalls or unexpected delays. As expectations vary and there is pressure to demonstrate success within only a few months, tension arises which may jeopardize the entire enterprise. In the course of a large-scale software improvement program, we have established three experience factories in different environments of the Daimler-Benz AG within two years. At each site, several application projects are involved. In this paper we describe how we approached the task, what actions we took, and the lessons we learned.	software development	Frank Houdek;Kurt Schneider;Eva Wieser	1998		10.1109/ICSE.1998.671602	personal software process;long-term support;verification and validation;organizational learning;simulation;software engineering process group;software project management;computer science;systems engineering;engineering;social software engineering;software development;operating system;software engineering;software construction;software as a service;software walkthrough;management;software deployment;software development process;software peer review	SE	-68.69405895175173	24.8656729016531	14155
1a5d6d053cc640d4503085d28eeb134ae4ec1149	aspekte der schattierung dreidimensionaler objekte zur realitätsnahen visualisierung in der computer graphics			computer graphics	Klaus Dieter Bösing	1989				Visualization	-100.58825646096938	22.663088316496488	14158
454987bca3ee8bad77d415e77e178fdb28f6080d	bridging the gap between the use of sap erp and bpm		Many companies use the standardised enterprise resource planning (ERP) software SAP and combine this with a business process management (BPM) approach. This use of SAP standard software specifies a variety of business processes that then influence the overall application of BPM. This article presents a final report of nine principles based on the experience of professional users in different companies. These principles can be applied in industrial companies as a process improvement technique to take full advantage of the use of SAP and the application of BPM.	beam propagation method;bridging (networking);business process;erp;enterprise resource planning;world wide web	Markus Grube	2018			process management;business;bridging (networking)	SE	-68.82963180421957	15.715115960178272	14182
bf819d4e36c0267afcf4c42b0b26cf14284fd34f	utilizando dados georeferenciados para o tratamento do problema indoor-outdoor detection				Raissa P. P. M. Souza;Fabrício A. Silva;Thais R. M. Braga Silva	2018				Vision	-105.77825821954247	18.150532797775497	14189
ab17a48c47849b02811286ddfa4ee9d04c948333	the evolving relationship between open standards and technology	open standard	The relationship between open standards and technology is undergoing a change, particularly in the way standards are developed and deployed today and in their impact on business. In addition to integrating mature standards into its systems, our industry will have to invest more time and effort nurturing and promoting fledgling standards. Standards represent a challenge and an opportunity. The challenge is to deliver the best performing, best integrated products that fully support a standard. On the other hand, each generation of standards represents a baseline to build on. Already, the more stable standards are influencing systems design to the point that, in some instances, the path to highest performance will be through a standard.		Wayne E. Rosing;Matt M. Perez	1990	IEEE Computer	10.1109/MC.1990.10089	open standard;computer science;operating system	Visualization	-69.58858929414393	12.659223194279338	14217
4e58823a65402d8bd73c50490c05079a9d2d2c11	loss evaluation analysis of illegal attack in scskp		It has always been a challenging problem to evaluate the security of cloud services. In this paper, we analyze this problem exploiting the loss expectation by illegal attack in a quantitative way. With one of the key cloud services, storage cloud services based on key–value pairs (SCSKP for short), we quantify the protection ability with the Markov model analysis on the possibilities of various illegal attack. The loss expectation caused by the illegal attack will be calculated based on the analysis and then be used to quantify the resistance ability of SCSKP against such attacks, which serves as ametric to evaluate the security of the cloud service. We provide three series of experiments are exploited to test the expectation of losses. The results show that our method is valid and able to reflect the security situation of the cloud service.	cloud computing;experiment;markov chain;markov model;sion's minimax theorem	Peng Zhang;Lei Liu;Rui Zhang;Guangli Li	2017	Soft Comput.	10.1007/s00500-015-1806-2	pre-play attack;data mining;internet privacy;computer security	Security	-64.29227998853595	59.5227541282934	14223
9b2bca23a74a3da414a3f40a1f4f049a1a658334	application - modélisation fractale des rentabilités boursières des marchés émergents				Hugues Aubry;Lotfi Belkacem	2001	Technique et Science Informatiques		distributed computing;computer science;database	Crypto	-103.20428277327116	15.560757852131466	14252
45fd4f25d6041d0e675dc92c78104c5a236258d7	hilbert transform relations for complex signals	transformation fonctionnelle;filtro respuesta impulsion inacabada;phase minimum;senal compleja;minimum phase;hilbert transformation;transformacion discreta;complex signal;transformation hilbert;coefficient;transformacion hilbert;transformacion funcional;signal complexe;infinite impulse response filter;filtro electrico;hilbert transform;functional transformation;discrete transformation;filtre reponse impulsion infinie;filtre electrique;transformation discrete;electric filter;coeficiente;fase minima	The log-magnitude and phase, or real and imaginary parts of the Fourier transform of a minimum phase causal signal are related through Hilbert transform. These relations are extended for complex data. The method to stabilize an IIR Complex Coefficient filter, through the process of converting a mixed phase system into a minimum phase system, is discussed. Zusammenfassung. Betrag und Phase oder Realund Imagin~irteil der Fouriertransformierten eines minimalphasigen kausalen Signals sind durch die Hilberttransformation miteinander verbunden. Diese Beziehungen werden auf den Fall komplexer Daten verallgemeinert. Die Methode, ein komplexes IIR-Filter zu stabilisieren, indem ein 'gemischtphasiges' in ein minimalphasiges System iiberfiihrt wird, wird diskutiert. R6sum6. L'amplitude et la phase, ou les parties r6elle et imaginaire de la transform6e de Fourier d 'un signal causal h phase minimale sont reli6s par la transform6e de Hilbert. Ces relations sont 6tendues aux donn6es complexes. La m6thode permettant de stabiliser un filtre IIR ~ coefficients complexes par le biais de la conversion d'un syst~me h phase mixte en un syst~me ~t phase minimate est discut6e.	causal filter;coefficient;hilbert transform;imaginary time;infinite impulse response;linear algebra;minimum phase	G. R. Reddy;M. N. Shanmukha Swamy	1991	Signal Processing	10.1016/0165-1684(91)90052-K	mathematical analysis;hilbert transform;minimum phase;coefficient;calculus;mathematics;geometry;infinite impulse response	Security	-97.86125203551248	34.38065129097917	14254
08bc9f785aaeafbab44a4aba6e776dadb6364a16	f-secure: deutsche besorgt wegen zugriffe von unbefugten auf in der cloud inhalte		Das Thema Datenschutz steht aktuell auf der Tagesordnung – aber auch vor dem Fall PRISM waren die Verbraucher besorgt über die Sicherheit und Vertraulichkeit ihrer Daten in der Cloud. Eine weltweit in 15 Ländern durchgeführte und am 27.06.2013 veröffentlichte Umfrage von F-Secure zeigt, dass schon vor den Nachrichten über PRISM sechs von zehn Verbrauchern über die Sicherheit der Speicherung ihrer Inhalte in Social-Networkingund Cloud-Storage-Diensten besorgt waren. 59 Prozent der Verbraucher – in Deutschland 52 Prozent – äußerten sich besorgt darüber, dass jemand anderes auf ihre bei diesen Anbietern gespeicherten Inhalte zugreifen könnte. Dabei sind vor allem jüngere Menschen im Alter von 20 bis 30 Jahren sowie Anwender, die mit verschiedenen Geräten ins Internet gehen und daher in der Regel auch am meisten Cloud-Lösungen beanspruchen, besonders sensibilisiert. Im Rahmen seiner „Digital Lifestyle Survey 2013“ hat F-Secure im April 2013 6.000 Menschen in 15 Ländern befragt.	cloud storage;eine and zwei;internet explorer;prism (surveillance program);vhf omnidirectional range	Das Thema	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0255-2		OS	-103.46447042301521	36.21553818010081	14268
b9fe27e74751fef1853154340962c26345a174fb	einsatz von algorithmischen skeletten im scheduling massiv paralleler system				Bodo Kalthoff	2002				EDA	-97.36489931075307	24.89502617994101	14270
d8336a5b4684287accefb7f1052049cc3483a0aa	analysis patterns in dimensional data modeling	dimensional data modeling;data warehousing;analysis;patterns	The construction of conceptual dimensional data models is one of the most important, fundamental and challenging tasks during the analysis phase in the systems development life cycle of a data warehouse system. Such data models are representing operational as well as strategic business requirements. Dimensional data models are used for implementing dimensional databases within the data warehouse system, which itself will be used for generating crucial information for decision-making. Although the enormous importance of conceptual dimensional data models is well known, the use of approved analysis patterns is not common practice. The non-consideration of analysis patterns can yield to poorly planned and therefore qualitative unproven dimensional data models respectively databases, which similarly yields to qualitative unproven generated decision-relevant information. Up to now the use of analysis patterns in dimensional data modeling is given no attention to in literature and in practice. This paper will overcome this gap in building data warehouse systems by introducing analysis patterns for dimensional data models which address well known and recurring problems in specific contexts.	business requirements;data model;data modeling;data structure;database;dimensional modeling;experience;knowledge base;requirement;software development process;systems development life cycle;theory;wiki	Stephan Schneider;Dirk Frosch-Wilke	2010		10.1007/978-3-642-27872-3_17	data modeling;data model;dimensional modeling;computer science;data science;data warehouse;analysis;data mining;database;pattern	DB	-74.87747467523147	13.443798152461609	14332
fb9db8dcf9ccf9c20abc043cb7ba8569dec95261	eine randbedingung für kubische splinefunktionen		Es wird eine Randbedingung angegeben, mit der kubische Splines hinreichend glatte Funktionen allein bei Vorgabe der Stützwerte bis zur Ordnung 3 approximieren. A boundary condition is given, such that cubic Splines approximate sufficiently smooth functions up to order 3 prescribing the knot values only.	approximation algorithm;cubic function;eine and zwei;spline (mathematics)	Klaus Kilberth	1973	Computing	10.1007/BF02239473	mathematics;mathematical analysis;spline (mathematics)	Theory	-96.5956757793481	35.88481918992577	14362
67569e3d22136bba82165501d49b24d5ac8704b5	caractérisation de diverses sémantiques pour des programmes logiques avec négation et application à la validation de programmes			linear algebra	Bernard Malfon	1994			linguistics;negation;philosophy	Crypto	-105.01496757076616	13.452604762899371	14370
e023ba9b721cc92043b6b58eeb88826ec474c0db	uma estratégia eficiente de treinamento para programação genética aplicada a deduplicação de registros		Genetic Programming (GP) is a machine learning technique effectively used in the record deduplication problem. GP adopts a very expensive training step that requires that all records in a database be compared against each other several times. In this paper, we propose a novel approach for training step based on clustering technique combined with a sliding window. This combination aims at minimize the number of comparisons required in the training step without affecting its results. Our experiments using real datasets show that it is possible to reduce the time cost of the training step up to 72.8% compared to the GP state of the art approach without a significant impact in the quality of generated solutions. Resumo. Programação Genética (PG) é uma técnica utilizada de forma eficaz na deduplicação de registros. Nela faz-se necessário realizar uma etapa de treinamento, em que cada registro é comparado com todos os outros na base de dados, tornando-a custosa. Neste artigo, propomos uma abordagem baseada na combinação de uma técnica de agrupamento e janela deslizante, visando minimizar a quantidade de comparações. Nossos experimentos com dados reais mostram que é possível reduzir o custo de treinamento da PG em até 72.8% comparado ao estado da arte sem uma redução significativa na qualidade das soluções geradas. 1. Introdução O problema de detecção e remoção de registros repetidos em um repositório é geralmente conhecido como deduplicação de registros [Koudas et al. 2006], que consiste em identificar e remover registros que são potencialmente os mesmos em uma base de dados.É uma tarefa complexa, que requer muito tempo e poder de processamento devido à grande quantidade de comparações necessárias para definir se um registro possui uma ou mais réplicas. Em [Carvalho et al. 2008b], os autores apresentaram uma abordagem para a identificação de registros duplicados em repositórios recorrendo a uma técnica de Aprendizado de Máquina conhecida como Programação Genética (PG). Essa técnica apresenta alta precisão no processo de deduplicação em bases de dados com diferentes características. Porém, possui alto custo computacional da PG, tendo em vista que na etapa de treinamento, que visa “ensinar” a técnica identificar as características relevantes de boas soluções, cada registro é comparado com todos os outros registros, tornando pouco viável sua adoção. Neste artigo propomos um método baseado na combinação de uma técnica de agrupamento e janela deslizante, para minimizar a quantidade de comparações exigidas na etapa de treinamento da PG. Os experimentos mostram que é possível tornar a etapa de treinamento da PG mais rápida mantendo o nível de qualidade das soluções, tendo em vista que técnica proposta obteve uma eficácia próxima da abordagem de [Carvalho et al. 2009] utilizado como baseline, com uma redução significativa no tempo de treinamento. 2018 SBC 33rd Brazilian Symposium on Databases (SBBD) August 25-26, 2018 Rio de Janeiro, RJ, Brazil	baseline (configuration management);cluster analysis;data deduplication;database;experiment;genetic programming;machine learning;numerical aperture;registered jack;tornado;uma acceleration architecture;unified model;virtual instrument software architecture;winsock	Davi Guimaraes;Moisés G. de Carvalho;Duivilly Brito	2018			database;computer science	ML	-107.21100013513347	36.51577201990654	14383
0383e6dec5f470914966f12639e61cbc1117c9a5	repeat-statement considered harmful? ergebnisse einer empirischen untersuchung	repeat-loop;programming;structured pro- gramming;while- loop;pascal;nassi-shneiderman-diagram	  		Knut Hildebrand;Jan-Armin Reepmeyer	1996	Informatik-Spektrum	10.1007/s002870050018	software engineering;considered harmful;computer science	Vision	-100.47203647823595	29.19017985877894	14397
9d271d35cd9cceb5c02e89911e2ef5f5dc17f23b	entwicklung einer rechnergestützten entwurfsmethode für optische mikrosysteme und deren anwendung auf einen heterodynempfänger				Ingo Sieber	1999				Theory	-101.3128182945922	26.59108092613786	14422
ce89cdc7508116546db6a8f5ab573dbf31cd8eb4	erp in project-driven organizations: a case-study from it industry in poland		The analysis of contemporary approaches to management illustrates the growing significance of the concept of project and project-driven organization. The goal of this study is to investigate what requirements should an ERP (Enterprise Resource Planning) system meet to support effectively management of a project-driven company. In doing so, this research builds on a case study of an ERP system implementation in Asseco System S.A., one of the Polish largest IT system integrators. Drawing from the experience of Asseco System S.A., this study discusses information problems, goals, considerations, and stages typical of an implementation project conducted in a project-driven organization. The analysis concludes with the evaluation of the implementation project results and formulation of critical requirements for an ERP system designed for project-driven organizations.	business process;disaster recovery;erp;enterprise resource planning;enterprise system;information needs;information processing;logistics;mathematical optimization;reference model;requirement;scott continuity	Jan Trabka;Piotr Soja	2013		10.1007/978-3-642-40855-7_3	business;commerce	SE	-72.42371521039509	8.507845557775424	14448
5a083d17b8c72cff3eb5b231b0676892adbbeaa0	on the evolution of reliability methods for critical software	reliability;formal methods;model checking;critical systems	The dream of software developers is a debugging tool that automatically finds all the potential errors in a quite readable and easy-to-locate format. In particular, this is sought desired by developers of concurrent programs for critical systems, such as control or communication systems. The unpredictable nature of this software and its large amount of potential behaviors makes it very prone to errors. Fortunately, the development of verification techniques during the last 20 years currently has motivated promising projects to obtain powerful tools. This paper summarizes the view of the past evolution and the current trend in this field.		María-del-Mar Gallardo;Jesús Martínez;Pedro Merino;Ernesto Pimentel	2006	Transactions of the SDPS		model checking;formal methods;computer science;theoretical computer science;software engineering;reliability;programming language	SE	-64.22770756856896	29.362067135204697	14454
28c3353072ba297c3d8488f31e5b2d045dd38df0	self-management concepts for relational database systems		Self-managing (or autonomic) databases are intended to reduce the total cost of ownership for a DBS by automatically adapting to evolving workloads and environments. To reach this goal, commercial database management systems (DBMS) have recently been equipped with self-management functions, which for example support the database administrator (DBA) in identifying the appropriate indexes or in sizing the memory areas. However, existing techniques suffer from several problems: First, they are often implemented as off-line tools that have to be explicitly triggered by a DBA. Second, they strictly focus on automating one particular administration task, without considering possible side-effects on other components. Third, their execution causes additional overhead for the DBS. Fourth, they follow best-effort approaches, which cannot be controlled by high-level goals (e.g. response time, throughput).#R##N##R##N#This work presents an alternative solution to the problem of DBS self-management, which avoids the drawbacks of the existing self-management functions. Instead of extending a DBMS with a set of component-specific self-management functions, the developed solution is designed as one single self-management loop, which has a system-wide view on all configuration decisions. As long as the workload of the system does not change and the goals are met, this self-management loop only performs very light-weight monitoring operations on the workload, performance, and state information. For this purpose, several workload shift detection solutions are described and compared in this work.#R##N#This work also comprises a workload classification solution, that groups similar workload events in order to further reduce the monitoring overhead. #R##N#Furthermore, the workload information is analysed for cyclic patterns in order to predict upcoming workload shifts.#R##N##R##N#Only when the system-wide self-management solution detects a workload shift or a violation of the goals, it performs a heavy-weight reconfiguration analysis. Given the current workload and state of the DBS, this reconfiguration analysis has to derive a new set of configuration parameter values that meet the goals in the best possible way. For this purpose the system-wide self-management solution employs a system model, which quantitatively describes the behaviour of the DBS using mathematical models. As creating a complete quantitative description of existing DBMS in a system model is a complex task, a graphical modelling approach (using the SysML modelling language) that supports the evolutionary refinement of models is used. At runtime, the system model is evaluated by the self-management logic using multi-objective optimization techniques, where the goal values are represented as constraints. With this approach the system-wide reconfiguration analysis is performed in a single step, allowing the immediate judgement of the side-effects on other components. #N#Selbstverwaltende (oder autonome) Datenbanken sollen die Betriebskosten fur Datenbanksysteme (DBS) reduzieren, indem sie sich automatisch an veranderliche Lastcharakteristiken und Umgebungsbedingungen anpassen. Um dieses Ziel zu erreichen haben die Hersteller kommerzieller Datenbankverwaltungssysteme (DBVS) begonnen, ihre Produkte mit Selbstverwaltungsfunktionen auszustatten, die den Datenbankadministrator beispielsweise bei der Bestimmung geeigneter Indizes oder bei der Festlegung der Grosen verschiedener Hauptspeicherbereiche unterstutzen. Doch die existierenden Ansatze leiden heute noch an zahlreichen Problemen: Zunachst sind diese oft als Offline-Werkzeuge konzipiert, die manuell durch den DBA gestartet werden mussen. Auserdem fokussieren sich ihre Analysen oft auf eine einzige administrative Aufgabe oder DBS-Komponente. Mogliche Seiteneffekte auf andere Komponenten werden nicht berucksichtigt. Auch der zusatzliche Aufwand, der bei kontinuierlicher Ausfuhrung der Selbstverwaltungsfunktionen auf dem DBS entsteht, stellt ein Problem dar. Weiterhin kann keine der existierenden Selbstverwaltungsfunktionen Zielwerte fur die Antwortzeit oder den Durchsatz berucksichtigen.#R##N##R##N#Diese Arbeit prasentiert eine alternative Losung fur die Selbstverwaltung von DBS, welche die Nachteile der existierenden Losungen vermeidet. Anstatt das DBVS mit einer Vielzahl komponenten-spezifischer Selbstverwaltungsfunktionen auszustatten ist das entwickelte Rahmenwerk als eine einzige zentrale Selbstverwaltungslogik konzipiert, die uber einen systemweiten Blick auf alle Konfigurationsentscheidungen verfugt. Solange sich die Lastcharakteristik des DBS nicht andert und die Zielvorgaben eingehalten werden, fuhrt diese Selbstverwaltungslogik nur sehr leichtgewichtige Uberwachungsfunktionen aus. Im Rahmen der Arbeit werden zu diesem Zweck verschiedene Techniken zur Erkennung von Anderungen in der Lastcharakteristik eines DBS vorgestellt und miteinander verglichen. Weiterhin wird eine Technik fur die Klassifikation von DBS-Anfragen beschrieben, die ahnliche Anfragen gruppiert und so den Uberwachungsaufwand reduziert. Es wird auserdem gezeigt, wie zyklische Anderungen an der Lastcharakteristik erkannt und vorhergesagt werden konnen.#R##N##R##N#Nur wenn die systemweite Selbstverwaltungslogik eine Anderung der Lastcharakteristik oder eine Verletzung der Zielvorgaben erkennt fuhrt diese eine schwergewichtige Rekonfigurationsanalyse durch. Ausgehend von der derzeitigen Nutzung des DBS und dessen aktuellem Zustand bestimmt diese Rekonfigurationsanalyse neue Werte fur die DBS-Konfiguration, so dass dieses die Zielvorgaben so gut wie moglich erfullt. Hierfur greift die systemweite Selbstverwaltungslogik auf ein Systemmodell zuruck, welches das Verhalten des DBS in Abhangigkeit von dessen Konfigurationen mittels mathematischer Modelle quantitativ beschreibt. Die Erstellung einer vollstandigen quantitativen Beschreibung des DBS-Verhaltens ist jedoch eine komplexe Aufgabe. Daher wird in dieser Arbeit die Modellierungssprache (SysML) fur die Definition der Systemmodelle eingesetzt, die auf Grund ihrer graphischen Darstellung eine evolutionare Verfeinerung der Modelle erlaubt. Zur Laufzeit wird das Systemmodell von der systemweiten Selbstverwaltungslogik mittels mehrkriterieller Optimierungstechniken ausgewertet, wobei die Zielwerte als Randbedingungen definiert werden. Mit diesem Ansatz kann die Rekonfigurationsanalyse in einem einzigen Schritt durchgefuhrt werden, so dass mogliche Seiteneffekte einer Konfigurationsanderung unmittelbar berucksichtigt werden konnen.	relational database management system;self-management (computer science)	Marc Holze	2012			engineering;electrical engineering;operations management;performance art	DB	-103.23949698898915	30.576033037537258	14480
6dab9497fdb933cdd380d37ae503f4feac368852	von der industrie lernen - steuerung der it nach industriellen maßstäben		Fur Finanzdienstleister ist die IT ein entscheidender Produktionsfaktor, der effektiv die strategischen Anforderungen moderner Hochleistungsorganisationen und effizient die notwendige Entwicklung neuer Produkte unterstutzen sollte. Dieser Beitrag beschreibt ein IT-Managementkonzept, das moderne Managementmethoden mit Konzepten der industriellen Entwicklung von Produkten zur nachhaltigen Steigerung der Effektivitat und Effizienz der IT nutzt. Durch die Transformation von Ideen einer industriellen Produktentwicklung auf Basis einer (IT-)Produktlinienorganisation sowie der Nutzung verbreiteter best practice Ansatze wie COBIT und ITIL wird die Bereitstellung der IT-Dienstleistungen (IT-Services) fur den anwendenden Finanzdienstleister professionalisiert. Der Beitrag beschreibt die dafur notwendige Einfuhrung der Produktlinienorganisation sowie die darauf aufbauenden und aus der Industrie abgeleiteten Rollen und Konzepte und deren praktischen Umsetzung in der Landesbank Baden-Wurttemberg. Im Vordergrund steht dabei die Darstellung eines ganzheitlichen, industriellen Masstaben genugenden IT-Managementframeworks. Das beschriebene IT-Managementkonzept ist dabei eine Zielvision, die teilweise bereits in der LBBW in die Praxis umgesetzt wurde.		Klaus Rausch;Andreas Rothe	2005			library science;knowledge management;computer science	Theory	-101.42727370513681	33.70853588339314	14532
dcc679ebcef768f551bbabdb2baecacd3d36a59c	die semantische struktur natürlicher sprache - wissensrepräsentation mit multinet			multinet	Michael M. Richter	2002	KI		multinet;linguistics;computer science	NLP	-97.67330291412415	20.964901539430848	14539
61568eb04374aaf71deae18d3bc3159f712ade8b	a just-in-time architectural knowledge sharing portal	portals;tool support;knowledge management;tool support architectural knowledge sharing;software architecture;decision making just in time architectural knowledge sharing portal architectural knowledge management software architecture;internet;architectural knowledge sharing;decision making process;knowledge sharing;integral functional;just in time;portals knowledge management software architecture decision making computer architecture computer science conference management programming guidelines connectors;software development management;software development management internet knowledge management portals software architecture	In recent years, management of architectural knowledge has become a more prominent theme in software architecture research. Although various specialized tools have been proposed for use in the architecting process, observations show that architects in industry have yet to meet a tool environment that matches their knowledge needs. In order to discover what architectural knowledge needs architects have, we conducted a study in a large organization. In this study we discovered that architects are especially in need for 'just-in-time architectural knowledge'. To fulfill this need we designed and implemented an architectural knowledge sharing portal. Our portal's integrated functionality supports architects in their decision-making process, by providing easy access to the right architectural knowledge at any given point in time.	accessibility;best practice;blog;comparison of command shells;documentation;just-in-time compilation;metamodeling;personalization;plug-in (computing);requirement;sharepoint;social capital;software architecture;software development;wiki	Rik Farenhorst;Ronald Izaks;Patricia Lago;Hans van Vliet	2008	Seventh Working IEEE/IFIP Conference on Software Architecture (WICSA 2008)	10.1109/WICSA.2008.20	architectural engineer;software architecture;decision-making;the internet;architectural pattern;computer science;systems engineering;engineering;knowledge management;software engineering;knowledge engineering;architectural technology;knowledge extraction;architectural plan;personal knowledge management;domain knowledge	SE	-63.37199774631307	16.48935628299143	14616
63ff21449904b10625bc09699d44957503e32e1d	evolution eines dv-gestützten informations- und kommunikationssystems zum instrument einer ganzheitlich ausgerichteten unternehmensführung im industriebetrieb				Ralph-Dieter Schrey	1992				HCI	-95.1766733136792	26.27243272477398	14628
e4031ea59b746a60a164ba6bf38f83eea0bcf5e7	making business systems in the telecommunication industry more customer-oriented		Market changes have forced telecommunication companies to transform their business. Increased competition, short innovation cycles, changed usage patterns, increased customer expectations and cost reduction are the main drivers. Our objective is to analyze to what extend transformation projects have improved the orientation towards the end-customers. Therefore, we selected 38 real-life case studies that are dealing with customer orientation. Our analysis is based on a telecommunication-specific framework that aligns strategy, business processes and information systems. The result of our analysis shows the following: transformation projects that aim to improve the customer orientation are combined with clear goals on costs and revenue of the enterprise. These projects are usually directly linked to the customer touch points, but also to the development and provisioning of products. Furthermore, the analysis shows that customer orientation is not the sole trigger for transformation. There is no one-fits-all solution; rather, improved customer orientation needs aligned changes of business processes as well as information systems related to different parts of the company.		Christian Czarnecki;Axel Winkelmann;Myra Spiliopoulou	2010		10.1007/978-1-4419-9790-6_14	business administration;process management;business;line of business;business activity monitoring	DB	-75.5956656262505	8.074926295253643	14704
f9b3e973fd3d64b6c5c71eb785df371e247aafcb	a report on the experiences of implementing an mt system for use in a commercial environment	commercial use;interes comercial;traduccion automatica;corporate language service;service process;financial services;proceso servicio;traduction automatique;processus service;interet commercial;machine translation machine;machine translation;automatic translation	This paper describes the process of implementing a machine translation system (MT system) and the problems and pitfalls encountered within this process at CLS Corporate Language Services AG, a language solutions provider for the Swiss financial services industry, in particular UBS AG and Zurich Financial Services. The implementation was based on the perceived requirements of large organizations, which is why the focus was more on practical rather than academic aspects. The paper can be roughly divided into three parts: (1) definition of the implementation process, co-ordination and execution, (2) implementation plan and customer/user management, (3) monitoring of the MT system and related maintenance after going live.		Anthony Clarke;Elisabeth Maier;Hans-Udo Stadler	2002		10.1007/3-540-45820-4_19	natural language processing;simulation;financial services;computer science;operating system;database;machine translation;computer security	OS	-72.31195605774532	16.73394756153465	14736
5597e181f919a3a13f667414bfa7a2b4e1cd8729	multisourcing and miscoordination in supply chain networks		This paper studies sourcing decisions of firms in a multitier supply chain when procurement is subject to disruption risk. We argue that features of the production process that are commonly encountered in practice (including differential production technologies and financial constraints) may result in the formation of inefficient supply chains, owing to the misalignment of the sourcing incentives of firms at different tiers. We provide a characterization of the conditions under which upstream suppliers adopt sourcing strategies that are suboptimal from the perspective of firms further downstream. Our analysis highlights that a focus on optimizing procurement decisions in each tier of the supply chain in isolation may not be sufficient for mitigating risks at an aggregate level. Rather, we argue that a holistic view of the entire supply network is necessary to properly assess and secure against disruptive events. Importantly, the misalignment we identify does not originate from cost or reliability asymmetr...		Kostas Bimpikis;Douglas Fearing;Alireza Tahbaz-Salehi	2018	Operations Research	10.1287/opre.2017.1708	mathematics;operations management;process management;scheduling (production processes);procurement;supply chain;supply network;incentive	ECom	-80.58287519624606	10.257351557511932	14768
97e8f966ee47194e68a872252c1598c2a4f09fd0	aplicações do approximate bayesian computation a controle de qualidade	approximate bayesian computation;preditivismo;controle de qualidade		approximation algorithm;computation	Thiago Feitosa Campos	2015			mathematical optimization;approximate bayesian computation;mathematics	ML	-105.65495567086451	18.06990648390301	14779
3067e6bbf78a305a674b0845cabf76344b4b64b4	2. dfn-forum kommunikationstechnologien verteilte systeme im wissenschaftsbereich, 27.05. - 28.05.2009 in münchen		Es wird um Beitragseinreichungen zu den nachfolgend aufgeführten The-menkreisen (TK) gebeten:	quad flat no-leads package;unified model	Alexander Clemm;Cisco;Thomas Eickermann;Forschungs;Markus Fidler;Alfred Geiger;Wolfgang Gentzsch;Eike Jessen;Tu München;Paul Müller;Bernhard Neumair;Gerhard Peter;Hochschule Heilbronn;Erwin P. Rathgeb;Universität Duis-Burg-Essen;Peter Schirmbacher;René Wies;Bmw Group	2009				NLP	-103.4024553871983	24.2945516547695	14788
0fe2a2e2546d98bcad528898ebd70c19b4b25aa9	assistenz von arbeitsprozessen auf der baustelle		Die zunehmende Digitalisierung im Handwerk fordert den vermehrten Einsatz von Informationsund Kommunikationstechnologien. Die Vermittlung der damit verbundenen neuen Anforderungen und die Unterstützung der Mitarbeiter sollte möglichst kontextbezogen und ortsunabhängig zur Verfügung stehen. Das Verbundprojekt SMARTWERK entwickelt dafür prototypisch für drei Szenarien (Baustellenbegehung und Dokumentation, Bedienung innovativer Maschinen auf der Baustelle, Arbeitssicherheit und Gesundheitsschutz) ein Assistenzsystem die SMARTWERK Assistance Suite (SWAS). Dabei wird ein partizipativer Prozess der Technikentwicklung verfolgt, der technische und inhaltliche Anforderungen sowie subjektive Akzeptanzaspekte fortlaufend evaluiert. Die so gewonnenen Ergebnisse werden in die Entwicklung der SWAS integriert und mögliche Kommunikationsstrategien zur Akzeptanzsteigerung abgeleitet.		Mareike Schmidt;Jan Spilski;Uta Schwertel;Michael Heil;Thomas Lachmann	2016				OS	-103.8547405845789	32.13881759588522	14792
637915a0e774e6cfef12caa902f2d7ccef024a84	human view dynamics - the nato approach				Holly A. H. Handley;Robert J. Smillie	2010	Systems Engineering	10.1002/sys.20133		DB	-94.86590701426903	21.40464138710525	14798
0b1deb30857515cf16ee0270e3d47bd645021fc7	abstract fog in the bottle - trends of computing in history and future		Microservices are a current trend that is known not only in academics. It is also used on an industrial scale. Nevertheless, microservices break with abstraction models like object orientation, to avoid code duplicates, or to have the code of behavior and data of one type of objects at one place. Thus, microservices break with learned and established concepts of programming. In this paper, we present historical developments, identify trends, and summarize our observations. Based on that, we provide suggestions for extending microservices to support more abstract programming concepts. In so doing, we suggest concrete strategies for our extensions based on already established concepts and without interfering with to the microservice concept.	code reuse;computer science;microservices;qr code;single source of truth	Marcus Hilbrich;Markus Frank	2018	2018 44th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)	10.1109/SEAA.2018.00089	market research;systems engineering;computer science;microservices;software;abstraction;object-orientation	SE	-70.22151532371363	33.90006533852943	14813
5e4747c77bb2b484e8a483b5479a6ba035ae1255	toward variability-aware testing	variability-aware analysis;reencode variability;variability-aware interpreter;unit test;model checker;whole product line;product line;brute-force fashion;variability-aware testing;entire product line;test case	We investigate how to execute a unit test for all products of a product line without generating each product in isolation in a brute-force fashion. Learning from variability-aware analyses, we (a) design and implement a variability-aware interpreter and, alternatively, (b) reencode variability of the product line to simulate the test cases with a model checker. The interpreter internally reasons about variability, executing paths not affected by variability only once for the whole product line. The model checker achieves similar results by reusing powerful off-the-shelf analyses. We experimented with a prototype implementation for each strategy. We compare both strategies and discuss trade-offs and future directions. In the long run, we aim at finding an efficient testing approach that can be applied to entire product lines with millions of products.	brute-force search;emoticon;heart rate variability;model checking;prototype;simulation;spatial variability;test case;unit testing	Christian Kästner;Alexander von Rhein;Sebastian Erdweg;Jonas Pusch;Sven Apel;Tillmann Rendel;Klaus Ostermann	2012		10.1145/2377816.2377817	real-time computing;simulation;engineering;operations management	SE	-63.0916475860098	38.35093135874488	14834
79fd2ac7354db7022a21b5f027c91e0f94e49cd7	improving globally distributed software development and support processes - a workflow view	software process improvement;global software engineering;software quality	We propose a new approach and related indicators for globally distributed software support and development based on a 3-year process improvement project in a globally distributed engineering company. The company develops, delivers and supports a complex software system with tailored hardware components and unique end-customer installations. By applying the domain knowledge from operations management on lead time reduction and its multiple benefits to process performance, the workflows of globally distributed software development and multitier support processes were measured and monitored throughout the company. The results show that the global end-to-end process visibility and centrally managed reporting at all levels of the organization catalyzed a change process toward significantly better performance. Due to the new performance indicators based on lead times and their variation with fixed control procedures, the case company was able to report faster bug-fixing cycle times, improved response times and generally better customer satisfaction in its global operations. In all, lead times to implement new features and to respond to customer issues and requests were reduced by 50%. Copyright © 2013 John Wiley & Sons, Ltd. Received 6 August 2012; Revised 3 May 2013; Accepted 15 May 2013	archive;benchmark (computing);customer relationship management;customer support;distributed computing;end-to-end principle;inventory;john d. wiley;logistics;loose coupling;material flow;multitier architecture;outsourcing;software development;software development process;software quality;software system;throughput	Teemu Tunkelo;Ari-Pekka Hameri;Yves Pigneur	2013	Journal of Software: Evolution and Process	10.1002/smr.1604	reliability engineering;personal software process;long-term support;verification and validation;team software process;software quality management;software engineering process group;software sizing;software project management;systems engineering;engineering;package development process;operations management;software development;software engineering;empirical process;management;software deployment;software quality control;goal-driven software development process;software development process;software quality	SE	-67.36104126866557	21.11961843428329	14861
827e724b0aa45756587513b02854eab14bfa83e9	an outsourcing model of software development	software development management outsourcing;outsourcing;warp x;theory methods;software engineering;warp x outsourcing model software development software engineering;software development;outsourcing model;outsourcing programming software engineering costs computer industry companies europe software tools software standards software systems;software development management	"""Software engineering is concerned with the theories, methods and tools which are needed to develop software for computers. Brooks (1987) also pointed out that software engineering is a man-made discipline that does not have any universal constants or """"natural laws"""" that would provide a clear theoretical platform or anchor points for the discipline. Many of the standards and practices in software engineering have been established or agreed upon by de facto market domination or by negotiation process by key players in the industry. As a result, these standards and """"laws"""" are not necessarily compatible with each other or constant. The overall goal of this research is to improve industrial practice of software engineering by presenting a new model of software development. For this purpose, a framework, tentatively named WARP-X, will be developed"""	computer;dominating set;namco warp & warp;outsourcing;software development;software engineering	Rasvan Constantinescu	2005	11th IEEE International Software Metrics Symposium (METRICS'05)	10.1109/METRICS.2005.11	personal software process;verification and validation;software engineering process group;software sizing;software verification;systems engineering;engineering;package development process;social software engineering;operations management;component-based software engineering;software development;software engineering;software construction;software walkthrough;software analytics;resource-oriented architecture;management;software deployment;software development process;software requirements;outsourcing;software system;software peer review	SE	-66.64342359569352	22.22174632549924	14899
c0d880e38d39a411df00bee5167dc7f621f3090e	designing project management systems	cybernetics;system approach;project management;project manager;system analysis and design;systems analysis cybernetics knowledge management project management;knowledge management;government agencies project management system designing system science system perspectives system theory management cybernetics system of systems;system theory;body of knowledge;monitoring;project management monitoring stability analysis humans context system analysis and design planning;complex system;systems analysis;stability analysis;planning;humans;context	The purpose of this paper is to develop the concept of project management system from the perspective of systems science. There is a need to extend the body of knowledge for project management. In particular, the application of systems perspectives and systems theory offers a significant opportunity to advance the current state of project management knowledge. Although there have been suggestions of systems approaches for project management, rigorous systems science has not been used to support these depictions. First, we develop the background and define a perspective of project management systems. Second, assumptions and principles are drawn from systems science to provide a foundation for project management systems. Third, a model for project management systems is developed from systems sciences and management cybernetics. Our initial explorations are promising, demonstrated by a case study application review using a complex system of systems (SoS) project encompassed multiple government agencies, and we offer future directions and implications for further model refinements, applications, and research into project management systems.	apple sos;complex system;management cybernetics;management system;system of systems;systems science;systems theory	Gamze Karayaz;Charles B. Keating;Morgan Henrie	2011	2011 44th Hawaii International Conference on System Sciences	10.1109/HICSS.2011.151	planning;project management;systems analysis;von neumann stability analysis;extreme project management;program management;work breakdown structure;project;cybernetics;system of systems;software project management;opm3;computer science;knowledge management;artificial intelligence;body of knowledge;estimation;management science;project management 2.0;project management triangle;management;project charter;systems theory;structured systems analysis and design method;project portfolio management	DB	-65.24271947630517	16.86127958169789	14957
f15941edcde36d125a3ac95c655b7b1a822416cd	standards and iteroperability in e-government initiatives	protocols;nist;electronic government open systems protocols iso standards nist data communication us government tcpip information systems bridges;information systems;iso standards;tcpip;bridges;data communication;electronic government;open systems;us government	Public administrations have been very much concerned since the 80's about the need of avoiding vendor lock-in when procuring themselves with IT infrastructure. At that time the standards profiles helped public administrations in this respect. The boost of e-government that has taken place in recent years has put this concern again in the agenda of public administrations. Interoperability has shown up as a principle in the conception and deployment of the e-government initiatives, and the interoperability frameworks have been the tool for implementing the principle. In this paper, the main e-government initiatives are presented and their policies in the field of standards and interoperability are analysed. The focus is on the degree of commitment with open standards that each e-government agency has made explicit in its interoperability framework.	e-government;interoperability;osi model;open-source software;posix;rm-odp;requirement;software deployment;vendor lock-in;web standards	Luis Guijarro-Coloma	2005	The 4th Conference on Standardization and Innovation in Information Technology, 2005.	10.1109/SIIT.2005.1563802	communications protocol;nist;computer science;software engineering;nist special publication 800-53;database;internet protocol suite;open system;world wide web;information system	EDA	-72.52484747717389	14.169978742830628	14974
aea2a23a241953b9be41672b46d5b75f0b51d4ce	prise en compte du réseau de sources pour la fusion d'informations			linear algebra	Thomas Bärecke;Marie-Jeanne Lesot;Herman Akdag;Bernadette Bouchon-Meunier	2011				Robotics	-104.93602809048227	14.499760383154031	14996
4303baea4ac4ed5ba67cc041798b2768409dd451	spezifikationstechniken für software-schnittstellen in fahrzeug- infotainmentsystemen		Die Benutzeroberfläche und die ihm zugrundeliegenden Softwarefunktionen werden bei Fahrzeug-Infotaintmentsystemen oftmals von unterschiedlichen Teams realisiert. Die Schnittstelle zwischen diesen beiden Softwareteilen muss daher exakt spezifiziert und zwischen allen Projektbeteiligten abgestimmt werden können. Den vorhandenen Beschreibungstechniken fehlen jedoch Ausdrucksmittel, um damit eine vollständige Spezifikation einer solchen Schnittstelle zu formulieren. Da sie zudem oftmals für eine ausschließlich maschinelle Verarbeitung konzipiert sind, sind sie für den manuellen Spezifikationsund Abstimmprozess ungeeignet. In diesem Aufsatz wird daher eine formale Beschreibungssprache vorgestellt, mit der sowohl der Aufbau einer Schnittstelle als auch deren Nutzung beschrieben werden kann. Darüber hinaus ermöglicht sie es, weitere Informationen zum Abstimmungsund Freigabestatus der Schnittstellenelemente zu hinterlegen. Die Notation der Sprache wurde mit dem Ziel entworfen, dass sie auch ohne spezielle Werkzeuge und ohne Kenntnisse der Zielplattform und des darin genutzten Kommunikationsframeworks genutzt werden kann. Aus den damit erstellten Schnittstellenspezifikationen kann per Codegenerator automatisiert zielsystemspezifischer Code erzeugt werden. Nach der Vorstellung der Sprache wird erläutert, wie sie in den Entwicklungsprozess eines SerienInfotainmentsystems eingeführt wurde und welche Auswirkungen sich dadurch auf den Spezifikationsund Abstimmungsvorgang ergeben. 1 Hintergrund und Motivation Moderne Infotainmentsysteme im Fahrzeug sind für die Kunden ein zunehmend bedeutendes Kaufkriterium und tragen wesentlich zur Marge der Hersteller bei. Sie bieten immer mehr Funktionen und aufwändigere Benutzeroberflächen (HMI). Ihre zunehmenden Softwareumfänge zusammen mit den kurzen Modellzyklen verlangen den Einsatz effizienter Entwicklungsmethodiken.	aldert van der ziel;eine and zwei;human–computer interaction;internet explorer;sie (file format);unified model	Simon Gerlach;Armin Widegreen	2011			operating system;software;computer science	OS	-102.78519950376553	31.44791752997633	15006
de14e0c53711c39f19357ccd8e5ef708ac3f2f5a	jugabilidad como medida de calidad en el desarrollo de videojuegos		Los videojuegos se han convertido en un campo de importante avance en el sector interactivo debido a su éxito comercial. Estos avances hacen que cada vez sea más importante analizar si la Experiencia del Usuario es adecuada dependiendo de la naturaleza del videojuego y de esta forma poder asegurar una calidad de uso óptima por parte del jugador, factor que puede repercutir en el éxito o fracaso de aceptación de los usuarios. Uno de los factores determinantes en la calidad de uso es la denominada ‘Jugabilidad’. En este trabajo tenemos como principal objetivo extender el nuevo estándar internacional ISO/IEC 25010, 2011 para la Calidad en Uso en base a la jugabilidad para poder analizar el grado de la experiencia interactiva, o grado de calidad desde el punto de vista de la interacción entre el jugador y juego, en busca de un mejor conocimiento e información que ayude a mejorar los procesos de evaluación y aseguramiento de la calidad del producto final tan demandados en la industria actual.	digital media player;han unification;iso/iec 42010;iso/iec 9126;linear algebra;os-tan;power-on reset;unique name assumption;uno	José Luis González Sánchez;Francisco Luis Gutiérrez Vela	2014			history;performance art	Crypto	-107.38385389305145	17.755021545214706	15039
09bec6b78051a9be7c55efb92729650717587d48	the role of dynamic capabilities in creating business value from is assets	creating;assets;bepress selected works;business creating value capabilities assets role dynamic;role;value;strategy;capabilities;is assets;business;dynamic capabilities;human agency;dynamic capabilities is assets strategy human agency context organizational performance;dynamic;organizational performance;context	This paper draws on and extends the emerging literature on dynamic capabilities to understand and explain the role ofinformation systems (IS) assets in creating business value. Our analysis identifies the critical roles of managerial actions andthe organizational context in identifying, resourcing and implementing IS-enabled competitive actions in delivering businessvalue. This paper extends earlier treatments of the relationship between IS assets and organizational strategy and performanceby explicitly accounting for the roles of human agency and context, which have not been adequately addressed in priorliterature. A research model for future research is proposed.	strategic management	Rajeev Sharma;Graeme G. Shanks	2011			business operations;knowledge management;business value;business;commerce	AI	-79.65242020905254	4.2870091088772595	15079
3969b1be1455d3b544fa12b4e73039e63e30e552	thermo-hydro-chemo-mechanical modeling of inner containments of nuclear reactor buildings in prestressed concrete. (modélisation du comportement thermo-hydro-chemo-mécanique des enceintes de confinement nucléaire en béton armé-précontraint)			reactor (software)	Ponleu Chhun	2017				Crypto	-102.99077160354514	16.740782647466467	15123
9d1008319866a8cbf35d7434a7febb497cb5366b	personal digital assistants in der funktionellen neurochirurgie	personal digital assistant	Bisher wurden für die Unterstützung der stereotaktischen Behandlung zentralmotorischer Störungen wie Tremor oder Dystonie Prozessrechner oder Personalcomputer eingesetzt. Diese Arbeit beschreibt den Einsatz von Personal Digital Assistants bei stereotaktischen Eingriffen, welche ausreichend Leistungsfähigkeit bieten um Biosignale zu visualisieren und zu analysieren sowie unter Zuhilfenahme von Algorithmenservern komplexe Signalanalysen ausführen können.	internet explorer;personal digital assistant;unified model	Michael Kroll;Hans-Gerd Lipinski	2001			embedded system;computer hardware;multimedia	Web+IR	-102.29224713658618	29.50365376985939	15127
923434fb2b5a66aa820a025371f88db67f0f5a74	benefits and barriers of electronic marketplace participation: an sme perspective	electronic commerce;trade barriers;e commerce;supply chain integration;swinburne;electronic marketplace;small to medium sized enterprises;trade barrier	There are concerns that despite government initiatives to promote adoption of electronic commerce, SMEs still fail to realise e-commerce related benefits. It may therefore, seem premature to discuss electronic marketplaces in the context of SMEs. However, if SMEs ignore e-marketplaces a number of problems can result. E-marketplaces present a significant threat to SMEs since they increase competition and leave non-participants vulnerable to more e-enabled firms. This paper examines the barriers and benefits of e-marketplace participation by SMEs. The nature of e-marketplaces is addressed and the benefits of participation are examined. Drawing on the literature, the barriers facing smaller firms in this environment are discussed. Identification of these barriers, such as lack of standards, supply chain integration and global trading, enables a greater understanding of how SMEs can plan effective strategies to gain from e-marketplace participation.	e-commerce;enterprise information management;know-how trading;online marketplace	Rosemary Stockdale;Craig Standing	2004	J. Enterprise Inf. Management	10.1108/17410390410548715	e-commerce;economics;computer science;marketing;trade barrier;management;commerce	AI	-80.70753469030589	6.007242162372531	15194
1e77dede70579507f44a0d03cf4c68aad221344a	towards a book publishers citation reports. first approach using the book citation index	publisher;citation analysis;social sciences;humanidades;humanities	La ausencia de libros y capítulos de libros en los índices de citas presentes en las bases de datos d e la Web of Science ha sido tradicionalmente una de sus más importantes debilidades. Sin embargo Thomson Reuters en Octubre de 2010 lanzó el Book Citation I ndex, un nuevo índice de citas que contaba con 29.618 libros y 379.082 capítulos de libros. Este p roducto ha abierto nuevas posibilidades para el aná lisis bibliométrico de campos como las Humanidades y las Ciencias Sociales. Precisamente el objetivo principal de esta nota es analizar a través de dife rent s indicadores las editoriales de los ámbitos d e Humanidades y Ciencias Sociales indexadas en el Bo ok Citation Index durante los años 2006-2011. Más concretamente se ha probado la posibilidad de desar rollar un ranking de editoriales de libros basado en la citación y la producción de las mismas. Para ello s e presentan una colección de rankings con seis indicadores bibliométricos para un total de 19 dis ciplinas científicas.	book citation index;call of duty: black ops;limbo;linear algebra;naruto shippuden: clash of ninja revolution 3;unique name assumption;web of science;web typography	Daniel Torres-Salinas;Nicolas Robinson-Garcia;Emilio Delgado López-Cózar	2012	CoRR		library science;social science;computer science;publishing;sociology;citation analysis	Theory	-109.16352313433526	13.878401070432938	15204
7fc54157c62c676dfb401a67c0d5901365a54195	vertragliche absicherung von bring your own device	ciencias juridicas;dcho procesal y penal;dcho civil y mercantil			Marian Arning;Flemming Moos;Maximilian Becker	2012	Computer und Recht	10.9785/ovs-cr-2012-592	linguistics	HCI	-95.88453548259619	22.125522335288963	15251
fd37c144ea9434590206ff074ce1f95a9662d07d	making spi happen: the roads to process implementation	practice pull;process push;software process improvement;process tailoring.;implementation success;comparative analysis;software process	Software Process Improvement (SPI) has been widely adopted by software organizations to enhance their capability to effectively deliver quality software. The approach has several positive merits. But many initiatives fail because the software processes are never adopted in practice. This paper offers a comparative analysis of the implementation strategies and outcomes of 18 SPI initiatives within Ericsson. The analysis draws upon concepts from the diffusion of innovations literature and leads to four different process implementation strategies – High Way, Country Road, Crossroads, and Dead End Street. These roads to software process implementation target different levels of practice and they rely on different mixtures of process push and practice pull. Our research suggests that the High Way with its combination of strong push and strong pull is the most promising road to implementation success, whereas the other roads imply serious barriers to success.	qualitative comparative analysis;software development process	Anna Börjesson Sandberg;Lars Mathiassen	2004			knowledge management;process management;software development process;management science;software engineering process group;empirical process (process control model);computer science	SE	-70.10997408231982	17.725957609392132	15272
a421d3742085da227d5295c4f46278aec57e82c6	ein polynomialer algorithmus zur bestimmung unabhängiger repräsentantensysteme	ngiger repr	Ohne Zusammenfassung		Ernst Specker	1976		10.1007/3-540-07805-3_6	theoretical computer science;computational science;computer science	Vision	-98.63830269872619	21.54850617236845	15332
f00bd35c6179d2689f7593c0d1702a7375b27565	das dienstleistungsangebot der deutschen bundespost für datenverkehr.				Elias Dietrich	1981	Informatik Spektrum		software engineering;computer science	Robotics	-93.85990741639044	26.179993470335358	15357
aba3cbe5a16346fb5a8479c2a64436c98ce8f978	assessing collaborative tools from an information-processing perspective: identification of value-added processes	groupware;collaborative tools collaborative software collaborative work collaboration competitive intelligence teamwork information systems software tools usability libraries;software performance evaluation;collaborative tools;teamwork informational mechanics assessing collaborative tool information processing value added processes information cycle taskwork related activity teamwork related activity competitive intelligence taskwork informational mechanics ci software;evaluation criteria;information management;information processing;competitive intelligence;software performance evaluation groupware competitive intelligence information management;value added	The authors explore the relevance of an information-processing perspective to collaboration. Based on the information cycle and inspired by the mechanics of collaboration, their model suggests that collaboration implies two types of informational activities: taskwork-related and teamwork-related. They present competitive intelligence as an example of collaborative projects, and CI taskwork informational mechanics, translated into criteria, to evaluate CI software. These criteria reveal the value-added processes that must be incorporated in a tool to transform information into intelligence. To assess the collaborative utility of CI tools, the paper suggests a number of teamwork informational mechanics that could be used to define another level of evaluation criteria.		France Bouthillier;Kathleen Shearer	2003		10.1109/ENABL.2003.1231398	competitive intelligence;human–computer interaction;information processing;computer science;knowledge management;value added;information management	HCI	-65.79069845558635	16.340769449317676	15437
4acd2f0449be9f18218e37ff6d3cbc0835674791	from tracking operations to iot-the small business perspective	qa75 electronic computers computer science szamitastechnika;small business sector small business perspective virtual representation off the shelf framework present day tracking application higher level functionalities inter organizational transparency internet of things concept track and trace framework;standards;szamitogeptudomany;small business perspective;virtual representation;production business ip networks observability object detection web and internet services context aware services databases subscriptions investments;inter organizational transparency;commerce;data mining;companies;off the shelf framework;small business sector;higher level functionalities;internet of things;servers;internet;internet commerce;track and trace framework;present day tracking application;present day;production;small business;small enterprise;off the shelf;internet of things concept;data models	Mapping individual items onto a virtual representation and keeping track of their properties now finds wide acceptance in larger enterprises and networks in the form of tracking and tracing. However, even if underlying technologies are ripe enough for off-the-shelf frameworks, small enterprises are still largely left unpenetrated due to present-day tracking applications still being optimized for massive use with little variability. Also, higher-level functionalities, such as inter-organizational transparency and integration of different networks - typically attributed to the ¿Internet of Things¿ concept are still awaiting wider implementation. The paper presents a track-and-trace framework along with pilot implementations focusing on the small-business sector and highlighting enhancement possibilities towards an Internet of things.	complex adaptive system;internet of things;microsoft outlook for mac;requirement;spatial variability;traceability;tracing (software);track and trace	Zsolt Kemény;Elisabeth Ilie Zudor;László Monostori	2009	2009 IEEE Conference on Emerging Technologies & Factory Automation	10.1109/ETFA.2009.5347154	e-commerce;embedded system;data modeling;the internet;simulation;virtual representation;telecommunications;computer science;engineering;knowledge management;operating system;world wide web;internet of things;server;computer network	Visualization	-76.93622322621705	15.401010273416405	15519
888dc9136d7dea73d78710d6f0d99ddca51e6159	wissensmanagement als strategischer e-government-baustein für verbraucherschutz, ernährung und landwirtschaft		In der Initiative BundOnline 2005 verpflichten sich die öffentlichen Institutionen, die wichtigsten Dienstleistungen bis 2005 elektronisch anzubieten. Damit wird ein wichtiger Beitrag geleistet, um die Kommunikation zwischen öffentlicher Verwaltung und den Bürgern effizienter zu gestalten. Der Schwerpunkt dieser Initiative liegt zunächst darin, den Bürgern wichtige Verwaltungsdienstleistungen online zur Verfügung zu stellen und Informationen der Verwaltung über einschlägige Portale abrufbar zu gestalten. Für die Kommunikation zwischen Verwaltung und Bürgern ist dies ein erster Schritt. In der Zusammenarbeit zwischen öffentlichen Institutionen in Bund und Ländern reicht dieser Ansatz jedoch noch nicht aus. Notwendig ist hier der Aufbau und die Nutzung von Wissensmanagement-Plattformen. Sie erst ermöglichen es, Informationen über die elektronisch organisierte Zusammenarbeit zu erstellen und zu nutzen. Auf diese Weise können Gremien mit örtlich verteilten Mitgliedern gemeinsame Dokumentenbestände mit unterschiedlichen Berechtigungen erarbeiten und dezentral pflegen. Dies gewährleistet einen stets aktuellen und von allen Seiten zugreifbaren Informationsraum. Der Beitrag beschreibt, welche methodischen und IT-technischen Bausteine für den Einsatz eines solchen WissensmanagementSystems notwendig sind und leitet zur Darstellung konkreter heute in der Praxis bereits eingesetzter Systeme über.	altran praxis;blitzkrieg;e-government;sie (file format);unified model;zentralblatt math	Jan Mark Pohlmann	2004				OS	-104.10065558510578	33.94756828248142	15521
cd6b47ca6897c0c21d3911f7778bdd9753bad2e4	a discriminant model for classifying software project performance	time overrun;discriminant analysis;software project risk;cost overrun;india	Project managers are concerned about completing the projects on time and cost. IT projects across the globe are notorious for their time and cost overruns. This paper presents output from a comprehensive study on software development risk and project outcome with respect to the projects executed by software companies in India. Based on the data collected from over 300 projects, the authors developed a discriminant model for predicting the project outcome category based on risk scores of a project. The discriminant models developed are seen to possess adequate prediction accuracy to be used in practice. The models can help the project managers in early detection of likely project failures and hence to initiate appropriate counter strategies.	discriminant	Sam Thomas;M. Bhasi	2016	IJITPM	10.4018/IJITPM.2016040104	basis of estimate;cost contingency;reliability engineering;systems engineering;engineering;operations management;linear discriminant analysis;project management triangle;project portfolio management	SE	-69.54154081823197	23.819969279986676	15533
c8c11fa69d7894be6e72534af23be61075d99b9d	geographic origin of libre software developers	software development process;data mining;geographical location;software development;biased sampling;geographical location data mining libre software free software open source software;free open source software;libre software;open source software;free software	This paper examines the claim that libre (free, open source) software involves global development. The anecdotal evidence is that developers usually work in teams including individuals residing in many different geographical areas, time zones and even continents and that, as a whole, the libre software community is also diverse in terms of national origin. However, its exact composition is difficult to capture, since there are few records of the geographical location of developers. Past studies have been based on surveying a limited (and sometimes biased) sample and extrapolating that sample to the global distribution of developers. In this paper we present an alternate approach in which databases are analyzed to create traces of information from which the geographical origin of developers can be inferred. Applying this technique to the SourceForge users database and the mailing lists archives from several large projects, we have estimated the geographical origin of more than one million individuals who are closely related to the libre software development process. The paper concludes that the result is a good proxy for the actual distribution of libre software developers working on global projects. 2008 Elsevier B.V. All rights reserved.	archive;database;extrapolation;location (geography);open-source software;proxy server;software developer;software development process;sourceforge;tracing (software)	Jesús M. González-Barahona;Gregorio Robles;Roberto Andradas-Izquierdo;Rishab Aiyer Ghosh	2008	Information Economics and Policy	10.1016/j.infoecopol.2008.07.001	sampling bias;crowdsourcing software development;computer science;software development;data mining;database;location;world wide web;software development process	SE	-65.47809640059604	36.376631936220754	15540
697ac6b50308e0d69eb3accacb21d505119b91d5	collaborative e-marketplaces containing clusters of smes: drivers and barriers in the local food sector	groupware;electronic commerce;information systems;marketing data processing;small to medium enterprises electronic commerce food manufacturing groupware marketing data processing question answering information retrieval;question answering information retrieval;collaboration;computer and information science;small to medium enterprises;food manufacturing;test bed;joints;support system;platform as a service sme clusters local food sector local food producer trustworthy collaborative e marketplace ethnographic approach questionnaires structured requirement contractual agreement collaboration service cloud computing;computer and information sciences computer science;informatik;business;datavetenskap datalogi;datavetenskap;interviews;production;driver circuits;collaboration business context driver circuits production interviews joints;computer science;data och informationsvetenskap;context;cloud computing	This paper explores the current context of collabo¬ration between small local food producers. The aim is to facilitate the design and maintenance of trust¬worthy collaborative e-marketplaces containing clusters of SMEs. An ethnographic approach was used and data was collected through observations, interviews and questionnaires. Our findings reveal both drivers to exploit and barriers to harness enabling trustworthy collaboration. Our current test bed is based on a research and design context that lacks mechanisms for governance. To take full advantage of the drivers and to tackle the barriers in a fruitful way, there is a need for a flexible infra¬structure that allow for structured requirements, contractual agreements and validation of proposed collaboration services. To address this, we take advantage of recent developments in cloud computing, more specifically the integration of Platform as a Service (PaaS) in the support system.	cloud computing;platform as a service;requirement;testbed	Alexandra Petrakou;Patrik Brandt;Rune Gustavsson;Päivi Jokela	2011	2011 44th Hawaii International Conference on System Sciences	10.1109/HICSS.2011.111	e-commerce;public relations;interview;cloud computing;computer science;knowledge management;marketing;operating system;software engineering;database;management;world wide web;information system;collaboration;testbed	EDA	-75.47955001568386	16.43797380005066	15571
18adf6b9f7d9ae72a3a299d3216c29daf29af70c	collect now-consume later on innovative products in electronic commerce	electronic commerce;chaotic dynamics;utility function;economic theory;technological fashions;consumer behavior;profitability;point of sale;point of view	In our paper we develop the idea that in the future electronic commerce will increasingly involve customers whose lack of time for consumption forces them to collect the products they purchase for later consumption. The peculiarity of these conditions at the point of sale will be discussed in detail from the perspective of economic theory. The analysis will elaborate how certain characteristics of utility functions as well as other characteristics of this consumer segment contribute to these peculiarities. As a result some lessons for the timing of innovations in the supply of information commodoities are derived. In particular it is shown why it might be profitable for suppliers in electronic commerce to produce waves of technological fashions. From a theoretical point of view it seems to be reasonable to use chaotic dynamics to describe this highly volatile market behavior.	chaos theory;e-commerce;money;point of view (computer hardware company);point of sale;volatile memory	Hardy Hanappi;Oliver Kump	2003	Decision Support Systems	10.1016/S0167-9236(02)00082-9	e-commerce;economics;computer science;marketing;advertising;point of sale;management;world wide web;consumer behaviour;commerce;profitability index	ECom	-74.82876320964299	4.634253061941919	15573
0a332dfbdafe5ad45b916900eca2b86427ec99af	erste erfahrungen mit dem virtuellen softwareprojekt		Das Pilotprojekt „Virtuelles Softwareprojekt“ ermöglicht Osnabrücker Studierenden erstmals, hochschulübergreifend an der in Oldenburg durchgeführten Lehrveranstaltung „Softwareprojekt“ teilzunehmen. Neue Medien wie beispielsweise Videokonferenzsysteme werden eingesetzt, um die Veranstaltung über die reine Präsenzlehre hinaus durchführen zu können. Ein wesentliches Ziel des Projektes ist neben der Durchführung von hochschulübergreifenden Lehrveranstaltungen die Evaluation von Multimedia-Angeboten für die Lehre. Der erste Durchlauf des Softwareprojektes erfolgt im WS 2002/2003, so dass über erste Erfahrungen berichtet werden kann.	internet explorer;unified model	Ludger Bischofs;Wilhelm Hasselbring;Hans-Jürgen Appelrath;Jürgen Sauer;Oliver Vornberger	2003			performance art;art	OS	-105.97678973790676	33.19526461566637	15605
a264c0411e9e4638977aaa0b81953c3f184b6b18	a critical realist perspective of enterprise architecture evolution: conditioning and outcomes	service oriented architecture;critical realism;enterprise architecture;soa	This paper investigates how Enterprise Architecture (EA) evolves due to emerging trends. It specifically explores how EA integrates the Service-oriented Architecture (SOA). Archer’s Morphogenetic theory is used as an analytical approach to distinguish the architectural conditions under which SOA is introduced, to study the relationships between these conditions and SOA introduction, and to reflect on EA evolution (elaborations) that then take place. The paper focuses on reasons for why EA evolution could take place, or not and what architectural changes could happen due to SOA integration. The research builds on sound theoretical foundations to discuss EA evolution in a field that often lacks a solid theoretical groundwork. Specifically, it proposes that critical realism, using the morphogenetic theory, can provide a useful theoretical foundation to study enterprise architecture (EA) evolution. The initial results of a literature review (a-priori model) were extended using explorative interviews. The findings of this study are threefold. First, there are five different levels of EA-SOA integration outcomes. Second, a mature EA, flexible and well-defined EA framework and comprehensive objectives of EA improve the integration outcomes. Third, the analytical separation using Archer’s theory is helpful in order to understand how these different integration outcomes are generated.	enterprise architecture framework;evolution;oracle soa suite;service-oriented architecture;service-oriented device architecture;stereo realist	Ayed Alwadain;Erwin Fielt;Axel Korthaus;Michael Rosemann	2014	Australasian J. of Inf. Systems		social science;epistemology;computer science;systems engineering;engineering;knowledge management;artificial intelligence;operations management;software engineering;service-oriented architecture;sociology;management;law;world wide web	DB	-75.18554958889429	15.832174856297383	15677
4036dc4e789295f8b2226963e09497ec9f9a4196	vorlesung auf abruf im internet: lecture on demand als baustein einer virtuellen universität		Freimut Bodendorf, geb. 08.06.1953, studierte Informatik mit Nebenfach Betriebswirtschaft an der Universität ErlangenNürnberg. Promotion in Wirtschaftsinformatik. Danach Abteilungsleiter an der Universität Freiburg i.Br., Professor für Wirtschaftsinformatik an der Fachhochschule Nürnberg, Lehrstuhlinhaber an der Universität Fribourg/Schweiz. Seit 1989 Inhaber des Lehrstuhls Wirtschaftsinformatik II an der Universität Erlangen-Nürnberg. Wichtige Forschungsgebiete umfassen Anwendungssysteme im nicht-industriellen Bereich, Electronic Business, Geschäftsprozessgestaltung, Mediengestützte Ausund Weiterbildung, Wissensmanagement und Telekooperation.	electronic business;internet	Freimut Bodendorf;Christian Bauer;Christian Langenbach;Manfred Schertler;Sascha Uelpenich	2000	Praxis der Informationsverarbeitung und Kommunikation	10.1515/PIKO.2000.137	computer network;computer science;the internet;world wide web	DB	-103.01125387277332	35.37193017490917	15741
a103ebf2aae1e6828cdeb2c45641664139db393b	omac: a discrete wavelet transformation based negotiation agent		This work describes an automated negotiation agent called OMAC which was awarded the joint third place in the 2012 Automated Negotiating Agent Competition (ANAC 2012). OMAC, standing for “Opponent Modeling and Adaptive Concession”, combines efficient opponent modeling and adaptive concession making. Opponent modeling is achieved through standard wavelet decomposition and cubic smoothing spline; concession-making is made through setting the best possible concession rate on the basis of the expected utilities of forthcoming counter-offers.	bilateral filter;computation;cubic function;smoothing spline;wavelet	Siqi Chen;Gerhard Weiss	2014		10.1007/978-4-431-54758-7_13	machine learning;wavelet;smoothing spline;negotiation;artificial intelligence;computer science	AI	-90.82340384869366	17.772203686612187	15764
ae9f5b5ad9b632ae732b12732c801d397a0276a8	"""""""adoption of the visual brainstorming technique in the open source software development process"""""""		The growth in the number of non-developer open source software (OSS) application users and the escalating use of these applications have both created a need for and interest in developing usable OSS. OSS communities are unclear about which techniques to use in each activity of the development process. The aim of our research is to adopt the visual brainstorming usability technique in the HistoryCal OSS project and determine the feasibility of adapting the technique for application. To do this, we participated as volunteers in the HistoryCal project. We used the case study research method to investigate technique application and community participation. We identified adverse conditions that were an obstacle to technique application and modified the technique to make it applicable. We can conclude from our experience that these changes were helpful for applying the technique, although it was not easy to recruit OSS users to participate in usability technique application.	open sound system;open-source software;software development process;usability	Lucrecia Llerena;Nancy Rodríguez;Pablo Gómez-Abajo;John W. Castro;Silvia Teresita Acuña	2018		10.1145/3183440.3194946	systems engineering;computer science;usable;software;brainstorming;visualization;requirements engineering;usability;open-source software development	HCI	-73.2814072113076	23.24068754271158	15798
92f0ad3acaa2db5a1e23fc5548a2780ab22945e2	controle d'accès pour les grandes infrastructures critiques. application au réseau d'énergie électrique	security;interoperability;access control;web services;information system;collaboration;critical infrastructure;resilience	En raison de ses vulnerabilites physiques et logiques, une infrastructure critique (IC) peut subir des defaillances, et en raison des interdependances entre IC, de simples defaillances peuvent avoir des consequences dramatiques sur lensemble de linfrastructure. Dans notre travail, nous nous concentrons principalement sur les systemes dinformation et de communication (lIIC : infrastructure dinformation critique) dedies au reseau du0027energie electrique. Nous proposons une nouvelle approche pour repondre aux problemes de securite que rencontre une IIC, plus particulierement, ceux lies au controle du0027acces et a la collaboration. Le but est doffrir a chaque organisation faisant partie de lIIC la possibilite de collaborer avec les autres, tout en maintenant un controle sur ses donnees et sa politique de securite internes. Nous avons modelise, et developpe PolyOrBAC, une plateforme de controle dacces collaboratif, basee sur le modele de controle dacces OrBAC et sur la technologie des Services Web, cette plateforme est applicable dans le contexte dune infrastructure critique en general, et plus particulierement dans le cadre dun reseau electrique.		Amine Baïna	2009			library science;sociology	Vision	-106.18608479029788	14.99322519873786	15831
c2ea3e27ec54a776b58e4386e5cbcc056881be1e	facial ageing and rejuvenation modeling including lifestyle behaviours, using biometrics-based approaches. (modélisation par approches biométriques du vieillissement et du rajeunissement numérique du visage, intégration de facteurs comportementaux liés au mode de vie)			biometrics;visage	Elham Farazdaghi	2017				Logic	-103.8148879572999	18.691789457413048	15862
50cb0ca77155ba75a569df19eaca1ba38658a691	servitization of business: an exploratory case study of customer perspective		The concept of servitization ‘adding value by adding services to products’ was first introduced by Vandermerwe and Rada in 1988, which in later became a popular topic for researchers in the academia, business and government. Today, it is widely recognized as an increasingly relevant business strategy for manufacturing firms to improve their competitive advantage in the market. In many cases, the necessity or application of servitization concept explained by researchers from organization perspective, especially for developed economy, but they were less attentive to discuss the issue from customer viewpoint in developing economy. Therefore, this paper aims to examine the needs of servitization from customer perspectives, particularly the IT industry of emerging market ‘Bangladesh’. The data was collected by the interviews of suppliers and customers in the IT industry of Bangladesh. The survey results showed that the current suppliers cannot satisfy the customer needs at this moment, because customers are not happy anymore with the IT goods only; they also require solutions, knowledge and reliability as well.	exploratory testing	Zahir Ahamed;Akira Kamoshida;Takehiro Inohara	2013		10.1007/978-94-007-7287-8_1	marketing;process management;customer advocacy	ML	-75.1307409135859	6.983547056279036	15906
c96bb0d5ed0f9f8f7ade2ecbb81a3d427bc60b8a	exploration et exploitation de l'espace de conception des transitions animées en visualisation d'information. (exploration and exploitation of the design space of animated transitions in information visualization)			iso 8601;information visualization	Maxime Cordeil	2013				HCI	-102.0755664795209	13.030755415000522	15925
84b11253061b60591d1505338fa6170ffa1dccc3	ergonomic considerations in product design through plm technologies		This article presents an integration of a product design methodology with emphasis in ergonomics with PLM. The articulation requires a comparative overview of the management levels offered by both approaches. PLM focuses on procedural activities and task performance and supports the ergonomic design methodology into a project and process management level in which decisions and control claims a mayor role. As result, workflow and indicators solutions attached to PLM strategy approach are structured accordingly to particular needs of the methodology in question.	human factors and ergonomics	Carolina Marroquín;Melisa Gaviria;Ricardo Mejía-Gutiérrez	2016		10.1007/978-3-319-54660-5_4	human factors and ergonomics;systems engineering;product lifecycle;business process modeling;design methods;engineering;product design;workflow	EDA	-66.33686972188899	13.141816873172763	15935
5c0bd4026067e5059702e0ff3706f6f050bf11f5	requirements engineering during complex isd: a sensemaking approach		This chapter describes the study that extends the previous research of social and organizational requirements engineering. The study suggests that requirement shaping during an ISD project can be described as a highly iterative sensemaking process of incongruence, filtering, negotiating and shifting. We studied two large e-commerce platform development projects by applying grounded theory and observed that attitudes and expectations about systems development among project participants filtered the understanding of IS requirements; negotiating between project participants resolved the issues caused by filtering and shifts in these attitudes and expectations facilitated changes in the understanding of requirements. This sensemaking process was highly iterative continuing the whole project lifetime and produced an IS product that exceeded the customeru0027s needs and expectations. We approached the subject with a theory of sensemaking and claim to provide a new interpretation of how technology is collectively constructed in organizations.	requirements engineering;sensemaking	Päivi Ovaska;Larry Stapleton	2007		10.1007/978-0-387-68772-8_16	systems engineering;engineering;knowledge management;software engineering	SE	-71.74984372698182	20.244465102109665	15963
e55b3702b08d5465a5fb6dff0e5bfa7baec2b92c	modélisation dynamique et temporelle de l'utilisateur pour un filtrage personnalisé de documents textuels				Rachid Arezki;Abdenour Mokrane;Gérard Dray;Pascal Poncelet;David William Pearson	2004				ML	-105.47083225376633	14.952887999439083	16204
00d553095c4910e7805ac4ceba12f6fc2703ea05	effects of stimulus type and of error-correcting code design on bci speller performance	brain computer interface;hamming distance;error correction code;event related potential erp;information theoretic	time → 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0	brain–computer interface;forward error correction	N. Jeremy Hill;Jason Farquhar;Suzanna Martens;Felix Bießmann;Bernhard Schölkopf	2008			brain–computer interface;hamming distance;error detection and correction;speech recognition;computer science;theoretical computer science;mathematics;statistics	ML	-108.16453599783989	32.60051789197005	16319
57629e31806ea994579c694b671f2316f65caadf	supporting open dataset publication decisions based on open source software reuse		Publishing and maintaining open data is a costly task for public institutions, that becomes even more challenging in the context of Smart Cities, where large amounts of varied data are generated from different domains. To optimize resources, they should prioritize the publication and maintenance of datasets most likely to generate social and economic impact. However, there is currently a lack of decision-support tools to help public sector data publishers to evaluate datasets on the light of their particular reuse goals. In this paper, we propose to suggest to data publishers the dataset categories with most potential impact, based on the impact of already published datasets of the same category. To measure impact, we propose a set of indicators based on the amount and quality of Open Source Software projects that use datasets. To aggregate indicators according to specific reuse goals, we provide an Analytic-Hierarchy-Process based tool.	aggregate data;code reuse;open sound system;open-source software;smart city	Alvaro E. Prieto;Jose-Norberto Mazón;Adolfo Lozano Tello;Luis Daniel Ibáñez	2018			data mining;open data;reuse;public sector;computer science;public institution;economic impact analysis;publishing;software	SE	-68.60164116500313	11.8535928593767	16376
11647a575ff02f14ffc5a7be0d1609728780549d	zum reduktionsverhalten von modulautomaten				Hans Kohlhase	1983	Elektronische Informationsverarbeitung und Kybernetik		pure mathematics;combinatorics;mathematics	NLP	-95.47407566702769	34.332629617650696	16393
a859bcffb9428a4883fd89f5b0a04aaa9c856320	uma ferramenta computacional para regulação social do discente				Rosângela Saraiva Carvalho	2017				DB	-105.50678314730919	18.847520277811547	16416
940e53a7fd3f47a68895f53ec0e53ff0119c2643	vertrauenswürdige chipkartenbasierte biometrische authentifikation		In dieser Arbeit stellen wir das Chipkartenbasierte Biometrische Identifikationssystem (CBI-System) vor. Dieses Template-On-Card System vereint die Vorteile von Chipkarten mit den Vorteilen der Biometrie, um eine höhere Überwindungssicherheit des Gesamtsystems zu gewährleisten. Ausgehend von den Sicherheitsanforderungen führen wir ein Protokoll ein, welches u.a. abgestufte Fehlbedienungszähler benutzt, um den Sicherheitsbedürfnissen der Chipkarte und des korrespondierenden Hostsystems Rechnung zu tragen. In einer Analyse des Systems zeigen wir dessen Stärken und Schwächen.	eine and zwei;unified model;vhf omnidirectional range	Gunter Laßmann;Matthias Schwan	2006			business	OS	-104.06490786229425	31.808784571710085	16418
944d813a574082e7c8c4e03ece215beaac10cc66	stalking the service level agreement: aim high, keep low			service-level agreement	Kevin R. Payne	1992			stalking;service-level agreement;computer security;business	NLP	-85.3461605870565	20.41396434673486	16427
de9f59602b33f6f90ef844a54d85ff25af25011a	characterizing the influence of continuous integration: empirical results from 250+ open source and proprietary projects		Continuous integration (CI) tools integrate code changes by automatically compiling, building, and executing test cases upon submission of code changes. Use of CI tools is getting increasingly popular, yet how proprietary projects reap the benefits of CI remains unknown. To investigate the influence of CI on software development, we analyze 150 open source software (OSS) projects, and 123 proprietary projects. For OSS projects, we observe the expected benefits after CI adoption, e.g., improvements in bug and issue resolution. However, for the proprietary projects, we cannot make similar observations. Our findings indicate that only adoption of CI might not be enough to the improve software development process. CI can be effective for software development if practitioners use CI's feedback mechanism efficiently, by applying the practice of making frequent commits. For our set of proprietary projects we observe practitioners commit less frequently, and hence not use CI effectively for obtaining feedback on the submitted code changes. Based on our findings we recommend industry practitioners to adopt the best practices of CI to reap the benefits of CI tools for example, making frequent commits.	best practice;compiler;continuous integration;feedback;open sound system;open-source software;software bug;software development process;test case	Akond Rahman;Amritanshu Agrawal;Rahul Krishna;Alexander Sobran	2018		10.1145/3278142.3278149	systems engineering;software engineering;computer science;software development;software;test case;software development process;devops;commit;best practice;mining software repositories	SE	-65.30768392571353	34.15799094412834	16455
25550b983c162f9e7c5cdb81340f751d948b117c	samebibl: sistema automático de migración a europeana para bibliotecas			europeana	María Luisa Díez Platas;Paloma Centenera	2016				Crypto	-106.19683232060972	17.626184749917655	16521
87b4943aec9c47b62985362daea74747d75d8d14	beyond production indicators: a novel smart farming application and system for animal welfare		In the last decade, there has been a growing public interest in the welfare of farm animals. These societal and economic factors have led to the development of smart farming applications, but many important features of animal welfare are either missing or underdeveloped in these applications. This paper proposes a novel smart farming system and application framework with an emphasis on animal welfare features for cows and pigs. The framework is based on concepts of openness, transparency and data sharing for all stakeholders which is stark contrast to other existing systems that are closed, often highly proprietary and almost entirely focused on production indicators. The system is based on a novel computing and sensing framework that integrates cloud and fog computing and deploys an Android-based mobile application called SmartHof. The key innovation in the system is the ability to embrace novel computing architectures, while enabling scalable data sharing, analysis and correlation relevant to animal welfare. We show that our system can be used to improve human-animal interactions as well as enhance social interactions between groups of animals in a farm setting, which is of great benefit not only in the context of animal welfare, but also to consumers, veterinarians and policy makers.	android;application framework;cloud computing;computer architecture;computer engineering;computer scientist;experiment;fog computing;ibm notes;interaction;mobile app;openness;scalability;wearable computer	Francisco Carpio;Admela Jukan;Ana Isabel Martín Sanchez;Nina Amla;Nicole Kemper	2017		10.1145/3152130.3152140	environmental resource management;public interest;agriculture;android (operating system);animal welfare;scalability;cloud computing;welfare;data sharing;business	HCI	-67.68716657921	10.385359212053105	16529
15273a4fd5592569a025455f1129a5c8ef85c7c0	how knowledge management can support the it security of egovernment services	integrated approach;administracion electronica;securite;ingenierie connaissances;knowledge management;base connaissance;administration publique;it security;administration electronique;electronic government;safety;base conocimiento;civil service;administracion publica;seguridad;knowledge base;knowledge engineering	Safeguarding security for eGovernment services is an essential ingredient for the success of such services. For this purpose, isolated security efforts are not sufficient. Integrated concepts are required. In the publicly funded project SKe, we are developing such an integrated approach. One component of this integrated approach is a knowledge management-based solution to support the dynamic aspects of IT security. The component an intelligent IT security console supports the daily work of the IT security personnel and supports them in systematically recording and using experiences in their work process. The component is being developed in cooperation with an application partner and is also used in projects with industrial partners.	computer security;experience;knowledge management	Markus Nick;Stephan Groß;Björn Snoek	2003		10.1007/3-540-44836-5_16	computer security model;cloud computing security;knowledge base;security through obscurity;security information and event management;security convergence;computer science;knowledge management;artificial intelligence;knowledge engineering;security service;security testing;computer security	SE	-66.5540768835464	7.272880930936697	16572
4509aab97f6c9a6c726c1411074e0f90f43b759d	negociación mediante argumentación en sistemas multiagente				Carles Sierra;Nicholas R. Jennings;Pablo Noriega;Simon Parsons	1998	Inteligencia Artificial, Revista Iberoamericana de Inteligencia Artificial		data mining;computer science	AI	-106.06989431974627	17.32521447493525	16578
4e98229864eb553ff7b2980bfa55ccc2ffcc4000	development of measures to assess dimensions of is operation transactions	critical dimension;outsourcing;partial least square;economic model;impartition;sous traitance;measurement problem;economie des organisations;organizational economics;information system;is research	Information Systems (IS) researchers often rely on organization economics models to describe and explain various lS management issues. While those models are found to be useful, measures are yet to be proposed to assess the dimensions of IS transactions. In this paper, we present the results of a study that was a first effort toward this end. The focus of the study was on one type of transaction, IS operations, in a particular management context, that of outsourcing. Measures were developed for four critical dimensions of IS operation transactions: asset specificity, measurement problem, origin of the most important investment, and governance mechanism. Data from 250 large Canadian firms were used to assess the measures, using the Partial Least Squares (PLS) technique.	information system;measurement problem;outsourcing;partial least squares regression;sensitivity and specificity	Benoit Aubert;Suzanne Rivard;Michel Patry	1994			operations management;sociology;management;operations research	SE	-82.48613600311504	7.954834956744883	16580
12e9c1fe89a2a0cbc0d25f3ef533d1dfc6c3f533	regelungsdefizite der cyber-crime-konvention und der e-tküv				Alexander Dix	2001	Datenschutz und Datensicherheit		computer security;internet privacy;computer science	NLP	-94.55266716541239	30.168586115032365	16606
42726bab9468d79bd8c5fd8708879dc1e62db41f	the bones of the system: a case study of logging and telemetry at microsoft	practices;data science;collaboration;boundary object;logging;software engineering;developer tools;interviews;telemetry;encoding;operating systems	Large software organizations are transitioning to event data platforms as they culturally shift to better support data-driven decision making. This paper offers a case study at Microsoft during such a transition. Through qualitative interviews of 28 participants, and a quantitative survey of 1,823 respondents, we catalog a diverse set of activities that leverage event data sources, identify challenges in conducting these activities, and describe tensions that emerge in data-driven cultures as event data flow through these activities within the organization. We find that the use of event data span every job role in our interviews and survey, that different perspectives on event data create tensions between roles or teams, and that professionals report social and technical challenges across activities.	activity recognition;dataflow;partial template specialization;requirement	Titus Barik;Robert DeLine;Steven M. Drucker;Danyel Fisher	2016	2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)	10.1145/2889160.2889231	simulation;interview;computer science;engineering;operating system;software engineering;data mining;telemetry;management;world wide web;encoding;collaboration;logging	SE	-74.4774954578848	22.68924579510286	16611
3fa676a9e7f0be1b51dd35a206a30c0db2138ae3	software architecture at a large financial firm	experience report;software architecture;financial industry	System builders have historically used informal software architecture models to understand options, make choices, and communicate with others. Research into software architecture over the past fifteen years has indicated that more precise architecture models may be beneficial. At a large financial firm, we applied precise software architecture techniques on four software projects and this experience has revealed a number of practical issues. We made the following observations across the projects: 1) Architecture models can be used to bridge gaps between business requirements and technology, 2) A small collection of techniques and a detail knob are practical and useful in a variety of projects, 3) Architecture modeling techniques amplify the skills of the architects, 4) A model of domain concepts and relationships is helpful when building architecture models, and 5) It is difficult to know when to stop adding detail to your architecture model. We believe that these observations motivate future research and can help practitioners make software architecture more effective in practice.	business requirements;control knob;make;requirement;software architecture	George Fairbanks;Kevin Bierhoff;Desmond D'Souza	2006		10.1145/1176617.1176729	enterprise architecture framework;functional software architecture;reference architecture;software architecture;space-based architecture;simulation;database-centric architecture;financial services;computer science;knowledge management;architecture domain;service-oriented modeling;enterprise architecture management;solution architecture;software architecture description;enterprise architecture;view model;resource-oriented architecture;data architecture;systems architecture;business architecture	SE	-66.55847098703705	22.62029142841924	16613
003754c3b8a6e8701e448e45163a6e60fa2e6ba4	model for performance evaluation in customs service management with dual hesitant fuzzy information		With the rapid development of Customs information construction, the employment and management of resources has become the important factor for the sound development of Customs practice. The application of large amount of new facilities and new technologies imposes higher requirements on the management and service level of China Customs. A framework planning and design of the Customs service management which is combined with the actual needs of the Customs service management will help to promote standardization of Customs technology management and working procedure. High quality service will provide a safe and reliable technology operation environment for various business reforms. In this paper, we investigate the multiple attribute decision making problems with the dual hesitant fuzzy information. Then, based on the induced OWG (IOWG) operator, this paper shall present the induced dual hesitant fuzzy Hamacher ordered weighted geometric (IDHFHOWG) operator. We have applied the IDHFHOWG operators to multiple attribute decision making for performance evaluation in customs service management with dual hesitant fuzzy = �	performance evaluation	Shu-Wen Wang;Xiangqian Ding;Zhi-Zai Ding	2016	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-151926	knowledge management;management science	HPC	-77.20962589048627	14.044891337147991	16621
9d928c11a63f1e14b8ab609c2d935616e6d86b29	eine mensch-maschine-schnittstelle zur rückführung der kippstabilität von arbeitsplattformen			eine and zwei;maschine	Rolf Kurt Truninger	1993			computer science	Vision	-99.53827975444027	25.555817956921306	16658
a03af464ddd9c51d69ee4c55c8bd707491fcd0c5	hmc-mac : un protocole mac hybride et multi-canal pour les réseaux de capteurs sans fil. (hmc-mac : hybrid multi-channel mac protocol for wireless sensor networks)			hybrid memory cube;sans institute	Rana Diab	2015				Mobile	-102.01925168260803	15.862929767284614	16661
3e85704dd3608e6ed896b41a7522d23e5e6a3656	smart documents - werkzeug für verwaltung 4.0		Smart Documents enthalten alle für die Vorgangsbearbeitung notwendigen Steuerungsund Protokollinformationen. Auf dieser Basis sind sie in der Lage, Ad-hoc-Workflows in und zwischen Behörden zu organisieren. Smart Documents stehen damit in Konkurrenz zu Austauschplattformen und Social Media Plattformen. In dem Beitrag werden die Stärken und Schwächen der einzelnen Ansätze miteinander verglichen und damit ein Einsatzprofil für smart Documents in der Verwaltung 4.0 erarbeitet.	hoc (programming language);sie (file format);social media	Siegfried Kaiser;Jeff Licker;Andreas Mayer	2016				Web+IR	-103.85657903837345	36.68138704532026	16692
71922e25b338769e1fe5e9caabea9b393637d7fd	assessing the documentation development effort in software projects	level 2;software documentation;software engineering;effort estimation;cost drivers;software development;effort estimation models	From the initial stages of software engineering, one of the most important practices to be carried out during the software development is a good documentation generation. Since then, this has become more and more important in the overall process of software production of any company, especially for those that have or are trying to achieve higher maturity levels. So for those organizations with a maturity level higher than CMMI level 2, or those that have to comply with the IS0 9000-3 standard, the elaboration and revision of all the components included in the project documentation need an appreciable effort from the development teams.#R##N##R##N#This means that the effort estimation models will adjust this effort driver, to the most accurate precision, in order to obtain correct estimates, which will be used generically and in local environments.#R##N##R##N#In order to do so, we have defined an experiment with the following objectives: To obtain the relationship between documentation effort and total development effort and to obtain updated factors for software documentation, according to the latest documentation standards and software development techniques.	documentation	Isaac Sánchez-Rosado;Pablo Rodríguez-Soria;Borja Martín-Herrera;Juan Jose Cuadrado-Gallego;José Javier Martínez-Herráiz;Alfonso González	2009		10.1007/978-3-642-05415-0_24	reliability engineering;personal software process;verification and validation;team software process;software engineering process group;software sizing;crowdsourcing software development;software project management;systems engineering;engineering;package development process;software design;software development;effort management;software engineering;analysis effort method;software construction;software walkthrough;software documentation;software metric;software peer review	SE	-68.01293303320678	23.010549409210704	16730
ae0fe335d050b7a8a5c366fa9657744373a1e0a8	evaluierung von simulationsverfahren für allgemeine, physikalisch basierte animationssysteme				Friedrich Wagner;Dieter Jackél	2002				NLP	-98.25400195047195	24.558856396062204	16749
78c29f8099fa36f5dacf9c5bdb6166dd8ad9f983	measuring and evaluating efficiency on it outsourcing operations through data envelopment analysis	performance management;efficiency;it outsourcing;data envelopment analysis;standardization;design science	Information Technology IT outsourcing is a set of IT services that require providers to manage a long relationship with multiple services that have a high degree of variance between clients. IT outsourcing operational contexts display multi-input and multi-output variables, so managers need guidance on developing suitable approaches in order to identify the set of variables to analyse. This work proposes a model based on Data Envelopment Analysis DEA, which is a linear programming technique able to manipulate multiple inputs and outputs. DEA allows the identification of the most efficient operation, which in turn enables providers to set the best operational strategy to follow. The results demonstrate the importance of quantitative measures in a dynamic business environment like IT outsourcing. To develop the authors' research, design science research was applied, and eighteen IT outsourcing contracts were used to demonstrate their model's utility. This work is a major contribution for measuring efficiency in IT outsourcing operations.	data envelopment analysis;outsourcing	João Correia dos Santos;Miguel Mira da Silva	2016	IJEIS	10.4018/ijeis.2016010101	performance management;economics;marketing;operations management;data envelopment analysis;management science;efficiency;management;standardization;commerce	Security	-77.75475210733951	9.01001082094589	16767
7f855c2366fdd26db0ffc9c169796f9e46fc9d04	a software development productivity model for mis environments	developpement logiciel;productivite;development;desarrollo;product model;productividad;costo;data base management system;desarrollo logicial;developpement;software development;systeme gestion base donnee;information system;productivity;sistema gestion base datos;systeme information;cout;sistema informacion	Presentation de 3 etudes empiriques sur le developpement de systeme d'informations de taille moyenne	management information system;software development	D. Ross Jeffery	1987	Journal of Systems and Software	10.1016/0164-1212(87)90016-1	productivity;input/output;software development;software engineering;information system	SE	-107.77318438029138	18.26667894067257	16798
4a5c1f79f64482de9998e6f20f94768ec9bb53e9	prototyping re experiments in the classroom: an experience report	customer interaction requirement engineering experiment prototyping educational environment industrial environment industrial constraint;experimental design;software;pedagogy requirements elicitation experimental design education;formal specification;industrial constraint;pedagogy;prototypes;training;requirements elicitation;software engineering;experience report;visualization;unified modeling language visualization software context training tutorials software engineering;educational environment;design of experiments;formal verification;tutorials;systems analysis;requirement engineering;unified modeling language;learning object;industrial environment;systems analysis design of experiments educational institutions formal specification formal verification prototypes;customer interaction;requirement engineering experiment prototyping;context	In this work we investigate the feasibility of prototyping industrial requirements engineering experiments within an educational environment, i.e. conducting a prestudy with students before performing the experiments in industry. We identify a set of constraints on the experimental design intended to make research participation more rewarding for our industrial partners and investigate the complexities of meeting both research and learning objectives within the same experiments. We report our observations and conclude that designing effective requirements experiments for an industrial environment, sensitive to industrial constraints, is a very difficult problem. Specific educational recommendations in visualization, prioritization, and customer interaction are also presented.	artificial neural network;clock rate;coupling (computer programming);decision model and notation;design of experiments;equivalent circuit;experiment;impedance matching;matching (graph theory);prototype;requirement;requirements engineering;simulation	Birgit Penzenstadler;David Callele	2010	2010 5th International Workshop on Requirements Engineering Education and Training	10.1109/REET.2010.5633112	systems engineering;engineering;software engineering;computer engineering	SE	-76.16367074448243	28.88922705000934	16854
ebb8bd374a201f1d1299742259ed98ac4e2a6151	übersetzung objektorientierter programmiersprachen - konzepte, abstrakte maschinen und praktikum java-compiler			java compiler	Bernhard Bauer;Riitta Höllerer	1998			programming language;java compiler;computer science	DB	-99.07018205818079	30.01479706463844	16891
479a664a5d585e984b46729da1e172d5dd2a3a48	individualisierungsmöglichkeiten im mobile tv - ein werbebasierter geschäftsmodellansatz		Während im asiatischen Raum Mobile TV bereits eine große Benutzergruppe erschlossen hat, befindet sich der europäische Mobile TV Markt weiterhin in der Entwicklungsphase. Eine Ausnahme stellt das italienische Mobile TV Angebot dar, das auf Basis eines direkten Erlösmodells nach einer Laufzeit von 6 Monaten (Ende 2006) 500.000 Kunden zählt. Die Akzeptanz von Mobile TV wird durch das Verhältnis von Kundenzahlungsbereitschaft zu gefordertem Nutzungsentgeld determiniert. Der Wechsel zu einem indirekten, werbefinanzierten Erlösmodell mit dem Ziel der Teiloder Vollsubventionierung monatlich geforderter Nutzungsentgelte ist durch das Potential des Mediums Mobile TV als Werbeträger und der damit verbundenen individualisierten Kundenansprache begünstigt. Zusätzlich verfügbare Kontextinformationen über den Kunden, wie z. B. der Aufenthaltsort, der Nutzungszeitpunkt und die Identität des Nutzers führen zu einer erhöhten Zahlungsbereitschaft der Werbetreibenden. Ziel dieses Artikels ist die konzeptionelle Umsetzung eines indirekten, werbefinanzierten Geschäftsmodells für Mobile TV. Darüber hinaus werden die möglichen Formen der Individualisierung im Mobile TV dargestellt und dessen Datenschutzverträglichkeit hinterfragt.	eine and zwei;internet explorer;mobile television	André Deuker;Mike Radmacher	2008			multimedia;transmitter;electrical engineering;computer science	Mobile	-104.96836878143742	34.3359804970294	17005
b522cff9c4221cfc540e0c5761f33a0279813a54	busting a myth: review of agile security engineering methods		Engineering methods are essential in software development, and form a crucial element in the design and implementation of software security. Security engineering processes and activities have a long and well-standardized history of integration with software development methods. The inception of iterative and incremental software development methods raised suspicions of an inherent incompatibility between the traditional non-agile security processes and the new agile methods. This suspicion still affects the attitude towards agile security. To examine and explore this myth, this study presents a literature review of a selected set of agile secure software development methods. A systematic literature method was used to find the definitive set of secure agile software development methods, of which a core set of 11 papers was selected for analysis, and the security activities documented in the methods were extracted. The results show a wide and well-documented adaptation of security activities in agile software development, with the observed activities covering the whole security development life cycle. Based on the analysis, the inherent insecurity of the agile software development methods can be declared to be a mere myth.	agile software development;application security;iterative and incremental development;iterative method;naruto shippuden: clash of ninja revolution 3;security engineering;software development process;software incompatibility;warez	Kalle Rindell;Sami Hyrynsalmi;Ville Leppänen	2017		10.1145/3098954.3103170	computer security;agile unified process;feature-driven development;software development process;extreme programming practices;empirical process (process control model);computer science;software security assurance;agile usability engineering;lean software development	SE	-67.93607766878846	21.528452873829313	17027
85aa7525b0309b76f5206a9fe562372d5a3a966b	a comparative study of the effects of pull request on github projects	pull request;github bug fixing pull request social impact;bug fixing;distributed version control system github project social involvement software development process distributed software development social network following mechanism watching mechanism pull request facility correlation study factor analysis mann whitney wilcoxon test bug report data active development activity bug fixing time;social impact;github;computer bugs social network services testing open source software software engineering market research;software development management configuration management program debugging project management social networking online	There is a trend in increased social involvement in software development process. Facilities supporting distributed software development and management have become a common practice in the community. Public involvement is further promoted by the incorporation of the social network features brought about by GitHub. The “following”and “watching”mechanisms, together with the pull-request facility, encourage wider and deeper involvement of the general public. While earlier studies have begun to study the possible effects of the increased publicity, their approaches are based on qualitative methods and their conclusions are only tentative. In this paper, we conduct a comparative study on the effects of pull request on 461 GitHub projects. Correlation study, factor analysis and MannWhitneyWilcoxon Test are conducted on the bug report data we gather from GitHub. From the empirical observations, we found that employing pull request can help increase the social impact of projects, resulting in more active development activity. However, it could also lead to prolonged bug fixing time.	agile software development;bug tracking system;distributed computing;distributed version control;factor analysis;randomness;social network;software development process	Jing Liu;Jiahao Li;Lulu He	2016	2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)	10.1109/COMPSAC.2016.27	simulation;computer science;engineering;artificial intelligence;operating system;software engineering;database;management;world wide web;computer security	SE	-73.30458142173266	26.804199517329156	17041
929a50fc4167fb936874f647ba7a89ea541df22e	applying usability engineering in intermod agile development methodology. a case study in a mobile application		This paper explains when and how to integrate aspects of usability engineering in the agile development process proposed by the InterMod methodology. The aim of InterMod is to facilitate the accurate development of high-quality interactive software. This is accomplished by means of agile software engineering activities and continuous assessment in which certain usability evaluation techniques have been suitably integrated. Such integration brings benefits to the early steps of the development process. On the one hand, this integration promotes development tailored to users’ expectations. On the other hand, it helps to plan the agile process of activities. In terms of developing a mobile application, the use of prototypes in early stages of the development process has been considered as being quite beneficial for organizing the workflow. Using heuristic evaluations and user tests has also been valuable when grouping evaluations in specific iterations.	agile software development;display resolution;evaluation function;formal verification;heuristic evaluation;human–computer interaction;intermodulation;iteration;java platform, standard edition;log analysis;mobile app;organizing (structure);paper prototyping;requirement;software engineering;ultima online;usability engineering;user interface	Begoña Losada;Maite Urretavizcaya;Juan Miguel López;Isabel Fernández de Castro	2013	J. UCS	10.3217/jucs-019-08-1046	usability goals;simulation;agile unified process;agile usability engineering;requirement;software engineering;usability engineering;empirical process;lean software development;software development process;usability inspection	SE	-73.28900155971795	23.43825859017375	17047
c8c7782287cc93dd134b7ae0ff0daeff8a56adda	técnicas de indexação de grandes conjuntos de dados complexos com valores de atributos faltantes			bibliothèque de l'école des chartes	Safia Brinis	2016				Crypto	-105.49562564991595	15.941190760929057	17051
c53262be5d323db7047e0b84d72c61cdaa67db82	prioritizing maintainability defects based on refactoring recommendations	finding prioritization;dataflow analysis;software quality	As a measure of software quality, current static code analyses reveal thousands of quality defects on systems in brown-field development in practice. Currently, there exists no way to prioritize among a large number of quality defects and developers lack a structured approach to address the load of refactoring. Consequently, although static analyses are often used, they do not lead to actual quality improvement. Our approach recommends to remove quality defects, exemplary code clones and long methods, which are easy to refactor and, thus, provides developers a first starting point for quality improvement. With an empirical industrial Java case study, we evaluate the usefulness of the recommendation based on developers’ feedback. We further quantify which external factors influence the process of quality defect removal in industry software development.	code refactoring;java;software bug;software development;software quality;static program analysis	Daniela Steidl;Sebastian Eder	2014		10.1145/2597008.2597805	reliability engineering;computer science;systems engineering;engineering;software engineering;data mining;software quality control;software quality	SE	-64.13372708387759	34.71188899916331	17055
6d522f3b0e172e77b8deac510c82c279d83f015a	crm-prozess-outsourcing in der telekommunikationsindustrie		Die qualitativ-empirische Studie zeigt, ob und welche Customer-Relationship-Management-(CRM-)Prozesse bei Telekommunikationsunternehmen ausgelagert werden. Die Entscheidungen für oder gegen ein Outsourcing lassen sich teilweise auf der Basis des Transaktionskostenansatzes begründen. Im Wesentlichen werden nur operative CRM-Prozesse ausgelagert. Dabei sind vor allem Prozesse von niedrigerer Komplexität und strategischer Bedeutung betroffen. Komplexere Prozesse werden nur dann ausgelagert, wenn sie nicht zugleich von hoher strategischer Bedeutung sind. Allerdings liefert dieses Modell nicht für alle Auslagerungsentscheide bezüglich CRM-Prozessen plausible Begründungen, weshalb weitere Motive und Gründe für ein CRM-Prozess-Outsourcing herangezogen werden.	customer relationship management;gesellschaft für informatik;outsourcing;sie (file format);v-model;vhf omnidirectional range	Konrad Walser;Thomas Myrach;Marin Gimpert	2008	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03341174	management;marketing;engineering;outsourcing	Security	-101.33992228452885	34.41494532209704	17066
7edbd9113e5da3607c8f1ce6cede2074baaa0954	foreword: quality in ict service management	ict service management	services economy. Web services, service-oriented architecture, self-service systems and cloud computing all involve a shift from product to service-centric thinking in the domains of computer science and information systems. The growth of IT services in terms of process management, frameworks and standards has been immense. ITIL, ISO/IEC 20000, CoBIT, ISO 27000 and CMMI all address service needs today. However, this shift to services in IT has not been accompanied by increased scientific understanding of the concepts of service quality and of the measurement of service quality. The majority of efforts have been limited to the implementation of SERVQUAL and asking simple questions of customers when service interactions are completed. Additional efforts are needed to understand the role of IT services within the context of more complex service systems made of technology, process and people connected through a value proposition with the aim of a dynamic value co-creation between customers and external/internal service systems. An alignment is needed between the quality of IT services and its contribution to the value of the service systems. Papers in this track contribute to establish better foundations for a rethink of IT service quality measurement in terms of its design and of its monitoring. The first three presented papers are dealing with the IT service management context in general, while the first paper is more focused on the security quality issue. In “Using DEMO to Identify IT Services”, C. Mendes, J. Ferreira and M. Mira Da Silva propose and validate a systematic method for accurately identifying the services of the organisation to be part of the Service Catalog which is central in the setting-up of an IT Service Management. The second paper ”A Method for Identifying IT Services Using Incidents” presents a complementary approach to the one proposed in the previous paper. M. Rosa, N. Gama and M. Mira Da Silva propose a method to identify services through incidents based on a reference catalog. In “Using a CRM Approach for Implementing an Information System to Support ITIL”, A. Vieira, S. Figueiredo and M. Mira Da Silva are considering the information system support needed for the implementation of IT Service Management within an organization. A requirements engineering approach is proposed to elicit the requirements for this system. The fourth paper “On Optimizing the Path to Information Security Compliance” focuses on the specific security quality. M. Dieguez, C. Cares and S. Sepulveda discuss preliminary ideas regarding the elaboration of a framework addressing the problem of reaching some control-based security standard from the perspective of an optimization problem. Last but not least, I would like also to thank my colleague Marion Lepmets from Public Research Centre Henri Tudor who act as a very efficient co-chair in the elaboration of this track. Foreword Quality in ICT Service Management	cobit;capability maturity model integration;cloud computing;computer science;itil;information security;information system;interaction;marion tinsley;mathematical optimization;optimization problem;optimizing compiler;quality of service;requirement;requirements engineering;servqual;service-oriented architecture;service-oriented device architecture;web service	Eric Dubois	2012	2012 Eighth International Conference on the Quality of Information and Communications Technology	10.1109/QUATIC.2012.74	engineering management;operations management;management science	DB	-74.80259304110754	10.298269575128808	17100
54916513d6231604f26702e4c85332eae2098a51	executing process models - activity and project management	automatic control;project management;software process enactment;requirements software product development process model execution activity management project management resource oriented planning resource oriented control software development process integrated software engineering environment software process enactment;resource oriented control;process enactment;project manager;resource management;instantiation;planning software development management project management;software development process;resource oriented planning;software engineering;process model execution;requirements;activity management;software engineering environment;project management predictive models software engineering programming humans automation resource management software development management process planning automatic control;skill role dependency;cascade mode;project process interface;predictive models;planning;planning and control;humans;software product development;process model;process planning;programming;integrated software engineering environment;software development management;software process;automation	Developing software products is both a technical and a managerial challenge. The integration of these two areas (the logical/technical prescription of the process model with the resource-oriented planning and control of project management), however, still needs further discussion and clarification. We discuss the relation of the components of a software development process and their counterparts in project management. We also show how an integrated software engineering environment handles software process enactment based on both activities defined via a process model and on requirements resulting from project management.		Gerhard Chroust;Stefan Hardt	1996		10.1109/ECBS.1996.494562	project management;personal software process;change management;verification and validation;team software process;software engineering process group;software project management;computer science;systems engineering;engineering;knowledge management;package development process;resource management;software development;software engineering;automatic control;process management;application lifecycle management;management process;project management 2.0;empirical process;project management triangle;management;goal-driven software development process;software development process;project planning	SE	-64.819410999124	21.24913592733756	17160
457f15dc232d8cc895684e9e5f721b667dd75090	angepaßte informatik - aufgaben für den software-entwickler	den software-entwickler;te informatik	Die globale Themenstellung fordert zunachst zur Prazisierung und Abgrenzung heraus. Der Begriff Anpassung legt die Frage nahe: Wer past sich wem an? Wenn uberhaupt: Mit welchem Ziel? Erst dann kann die Frage versuchsweise beantwortet werden, welche Aufgaben sich daraus fur den Software-Entwickler ergeben.		H. Feltl	1983		10.1007/978-3-642-69298-7_30	software engineering;software;computer science	Crypto	-102.39141808346453	32.58424552891888	17208
49678318f25d7c7e7512ebeb7182cebe9af9cd3e	planung entlang der supply chain	supply chain	Im Rahmen dieses Statements wird unter dem Begriff Planung sowohl die klassische Aktionsplanung als auch die Ablaufplanung (Scheduling) zusammengefasst. Entlang der Supply Chain treten eine Reihe von Planungsproblemen auf, die gelöst werden müssen, damit eine Supply Chain auf taktischer als auch operative Ebene effizient agieren kann. Zum Lösen dieser Probleme ist heute eine IT-Unterstützung fest etabliert. Beispielhafte Problemklassen, die im Kontext von Supply Chains zu bewältigen sind, umfassen:	eine and zwei;schedule (project management)	René Schumann;Jürgen Sauer	2007			operations management;business;supply chain	AI	-101.13902307287472	33.938631965751014	17236
b7030e755db11b87b2430b48b8bd71ee3b7c6e72	an effective change recommendation approach for supplementary bug fixes	change recommendation;supplementary bug fixes;random walk;genetic algorithm	Bug fixing is one of the most important activities during software development and maintenance. A substantial number of bugs are often fixed more than once due to incomplete initial fixes which need to be followed up by supplementary fixes. Automatically recommending relevant change locations for supplementary bug fixes can help developers to improve their productivity. It also help improve the reliability of systems by highlighting locations that a developer potentially needs to change to completely remove a bug. Unfortunately, a recent study by Park et al. shows that many change recommendation techniques do not work for supplementary bug fixes. In this paper, to advance the capabilities of existing change recommendation techniques, we propose an effective approach named SupLocator to recommend relevant locations (i.e., methods) that need to be changed for supplementary bug fixes. Based on various relationships among methods, classes, and packages in the source code (such as containment, inheritance, historical co-change, etc.), SupLocator extracts six change relationship graphs. Next, SupLocator performs random walk on each of the 6 graphs, and for each it outputs a ranked list of candidate change locations. Finally, SupLocator combines these six ranked lists by leveraging genetic algorithm. To investigate the benefits of SupLocator, we perform experiments on three projects, i.e., Eclipse JDT, Eclipse SWT, and Equinox p2. The experimental results show that on average SupLocator can achieve top-1, top-5, and top-10 accuracies, mean reciprocal rank (MRR), and mean average precision (MAP) of 0.51, 0.65, 0.67, 0.58 and 0.32 for the three projects, which improve the best variants of the approach proposed by Park et al. by 1523.09, 639.70, 550.62, 919.41, and 1478.44 %, respectively. It also improves the approach proposed by Saul et al. in terms of top-1, top-5, and top-10 accuracies, MRR, and MAP by 71.81, 29.54, 18.30, 47.24, and 56.60 %, respectively. Statistical tests show that the improvements are statistically significant.	eclipse;equinox;experiment;genetic algorithm;information retrieval;mean squared error;significant figures;software bug;software development;standard widget toolkit	Xin Xia;David Lo	2016	Automated Software Engineering	10.1007/s10515-016-0204-z	simulation;computer science;data mining;world wide web	SE	-64.44582341875947	35.11710068928716	17238
f815637c45d401097a770aaea51820ae30a12ec6	experiences et realisations du bureau canadien des traductions dans le domaine de l'automatisation de la traduction		De 1973 ~ ce d o u r , l e Bureau dee t r a d u c t i o n s du 3 e o r 6 t a f i a t d ' E t a t du Canada a eubven t ionn~ l a r e c h e r c h e en t r a d u o . t ion a u t o ~ a t i q u e au moyen de maroh~s de d~veloppement c o n c l u s aveo l ' U n i v e ~ s i t ~ de H o n t r ~ a l . I 1 e e t i e s u des t r a v a u x du ~roupe de r e c h o r o h e TAUH de o e t t e u n i v e r e i t ~ deux e y s t ~ e e , den t M~t~o, u t l l i e ~ d e p u i s 1977 pour t r a d u i ~ e dee b u l l e t i n s m ~ t ~ o r o l o g i q u e e , e t A v i a t i o n , a c t u e l l e m e n t ~ l ° ~ t a t de p r o t o t y p e l i m i t ~ au s o u s l a n g a g e de manuel d ° e n t r e t i e n d ° a v i o n s e t , p l u s p a l * t i o u l i ~ r e a e n t , d e s o i z ~ u i t s h y d r a u l i q u e e d ' u n p a t r o u i l l e u r m a r i t i m e du m i n i e t ~ r e cansd i en de l a D6fenae n a t i o n e l e . S u i t e ~ une ~ v a l u a t l o n du sye t~ . .e A v i a t i o n en 1979-1980 e t ~ une 6rude de f a l e a b l l i t 6 de son e x t e n s i o n aux manuels d ' e n t r e t i e n de 1 °~quipement 6 1 e o t r o n i q u e , i l a ~t~ d~oid~ de ne pus en poureulvre le d~veloppement, En effet, il eubelste, d ' u n e p a r t , hombre de p r o b l ~ e s qui e x i g e n t q u ' o n r e o u l e l e e f r o n t l ~ r e e dee o o n n a l e s a n c e e aoqu i see . ~ ce d o u r , done qu°on p o u r e u i v e l e e r e o h e ~ h e e , pour a t t e i n d r e l °obJeo%~f i n i t i a l l a t r a d u o t i o n s ans i n t e r v e n t i o n humaine ou a u t o m a t i q u e . D ' a u t r e p a s t e l e e b e e o i n s du Bureau dee t r a d u o t i o n s ~e ~ u e t i f i e n t pus de pour s .u iv re s e u l l ° e n t r e p r i e e ° La s i t u a t i o n e e t o l a i r e : l a t r a d u o t i o n a u t o m a t i q u e , r 6 a l i e a b l e dane l e cue de s o u s l a n g ~ e s r e e t r e i n t e c o , h e c e l u i dee b u l l e t i n s m 6 t 6 o r o l e g i q u e s , demeure une s o l u t i o n ~ l o n e J	amiga hombre chipset;artificial intelligence;dns-based authentication of named entities;dead-end elimination;emoticon;linear algebra	Fernand Gobeil	1982				Robotics	-106.60615340962563	16.200142203368713	17284
be1473e8e479ccee4cfee253232b0b9593824a59	exploration autonome et cartographie topologique en environnement inconnu référencées vision omnidirectionnelle		Ce papier propose trois approches iteratives et intelligentes de planification de vue pour la numerisation 3D du0027objets sans connaissance a priori de leurs formes. La premiere methode est une approche simple et naive basee sur la generation du0027un ensemble de points de vue par echantillonnage regulier de lu0027enveloppe englobante des donnees acquises. La deuxieme methode est basee sur une analyse de lu0027orientation des differentes parties acquises. La troisieme methode vise a explorer les parties de lu0027objet qui figurent dans la limite du champ de visibilite et est basee sur un couplage de la visibilite angulaire avec la visibilite reelle par lancer de rayons. Les resultats de numerisation du0027objets de differentes classes de complexite sont presentes et prouvent lu0027efficacite et la robustesse de nos approches.		Romain Marie;Ouiddad Labbani-Igbida;El Mustapha Mouaddib	2014	Traitement du Signal	10.3166/ts.31.221-243	calculus;mathematics;performance art	Vision	-105.66523009334952	14.580173296544878	17287
49c489a70ae8f7ceba0576872afb7ae8b971c665	konzepte, implementierung und optimierung von programmen zur zeitlichen logiksimulation von cmos-gate-array-schaltungen			cmos;gate array	Ralf-Dieter Mayas;Udo Porsch	1990				EDA	-103.29367711350947	27.190004229539166	17294
da96442a2f67834a0de0a9ae24bfeaa387783509	mobile kompetenzerfassung zur gezielten unterstützung von kompetenzentwicklungsprozessen in der dualen ausbildung	research article	Für die Berufsausbildung im dualen System liegen im Gegensatz zu vielfältigen Konzepten in der beruflichen Weiterbildung bisher wenige Ansätze zur Umsetzung einer prozessund entwicklungsorientierten Kompetenzerfassung vor. Dieser Beitrag stellt den Kompetenz-Check zur browsergestützten Kompetenzerfassung im Rahmen betrieblicher Lernund Arbeitsprozesse vor. Das Instrument wird als Softwareelement des berufswissenschaftlichen Projekts Kompetenzwerkstatt – Mein Beruf entwickelt und fokussiert die Reflexion von Kompetenzen durch Selbstund Fremdeinschätzung sowie geleitetes Feedback.	vhf omnidirectional range	Barbara Knauf;Axel Duerkop;Sönke Knutzen	2014			psychology	Robotics	-107.21433153794734	33.33046830151225	17308
fc7fb71b057a328f4020ba899bb125e3c2301d85	document engineering als ansatz für eine überbetriebliche nachhaltigkeitsberichterstattung	internet;computer science	Die Nachhaltigkeitsberichterstattung befindet sich im Wandel durch den Ubergang einer papiergestutzten zu einer Web-basierten Form. Zugleich verandert sich die freiwillige in eine verpflichtende Berichterstattung in der Europaischen Union ab 2017. Unternehmen stehen durch Lieferketten und elektronischen Datenaustausch im standigen Kontakt mit Zulieferern, Kunden und weiteren Interessensgruppen. Eine weitgehend transparente und verursachergerechte Darstellung der unternehmerischen Aktivitaten endet nicht an den Unternehmensgrenzen. Fur ein Unternehmensnetzwerk fehlt eine Strukturvorgabe, die eine uberbetriebliche Nachhaltigkeitsberichterstattung, z. B. bei Industrieparks, ermoglicht. Diese Arbeit entwickelt mittels des Document Engineering eine Strukturvorgabe, ein Austauschformat mittels einer eXtensible Business Reporting Language Taxonomie sowie ein Prozessmodell zur Beschreibung von Aufgaben und Rollen der Akteure im Rahmen einer uberbetrieblichen Nachhaltigkeitsberichterstattung.	document engineering;eine and zwei	Andreas Solsbach	2015			library science;document engineering;computer science	SE	-103.21166943210979	34.36905954862749	17326
20f70c06ebae31f639280ed7df953439bf0c8d88	bverfg: antiterrordatei		Die Antiterrordatei ist in ihren Grundstrukturen verfassungsgemäß. Jedoch genügt sie hinsichtlich ihrer Ausgestaltung im Einzelnen den verfassungsrechtlichen Anforderungen nicht. Dies hat der Erste Senat des Bundesverfassungsgerichts in einem heute verkündeten Urteil entschieden. Bis zu einer Neuregelung, längstens jedoch bis zum 31. Dezember 2014, dürfen die verfassungswidrigen Vorschriften unter Maßgaben weiter angewendet werden.	sie (file format)	Bverfg Antiterrordatei	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0303-y		Crypto	-104.71509072785835	33.392321122297474	17339
d48c5d98380293b990dc698fac36832385a50a07	towards financial planning as a service	planning financial management monitoring companies information systems cloud computing;information systems;service oriented architecture financial management planning;financial management;companies;monitoring;financial planning;soa financial planning as a service fiplaas financial crisis financial planning process;planning;information system;electronic computers computer science;service oriented architecture;cloud computing	"""The financial crisis has recalled the importance of proper financial planning. Companies which are organized as a multitude of legal entities are in particular affected by planning irregularities. To optimize the financial planning process and to cope with the challenges, we propose our service model """"Financial Planning as a Service"""" (FiPlaaS). This approach allows companies to redesign their planning processes according to SOA principles and to achieve substantial improvements in performance."""	entity;service-oriented architecture	Jochen Martin;Simon Caton;Tobias Conte;Christof Weinhardt	2011	2011 IEEE International Conference on Services Computing	10.1109/SCC.2011.64	financial modeling;financial management;accounting management;knowledge management;marketing;strategic financial management;business	Robotics	-71.23557367734604	15.121597537456285	17374
f8c41f4d8bf6cb79d8ef162db5a7a88818f7af40	usability und smart home: aktuelle herausforderungen und implikationen	smart home;usability;talk	Smart Home wird immer mehr zu einem Mainstream-Thema. Während sich früher vor allem technikaffine Personen mit dem Thema auseinandergesetzt haben, wird heute auch in „normalen“ Haushalten für den Einsatz entsprechender Hardund Softwarelösungen geworben. Dies impliziert als nur eine von vielen Herausforderungen, dass die Lösungen einer breiten Nutzergruppe mit verschiedenen Eigenschaften zugänglich sein müssen. Im Rahmen des Usability-Engineering-Prozesses einer SmartHome-Anwendung haben wir durch verschiedene Evaluationen solche Herausforderungen und Fragestellungen identifiziert und diskutieren in diesem Paper mögliche Lösungsansätze.	eine and zwei;home automation;smart tv;triple des;usability engineering;vhf omnidirectional range	Sandra Schering;Jasmin Kuhn;Michael Jendryschik	2015			construction engineering;engineering;multimedia		-97.06467817019532	29.53815744508473	17385
88b5cb8f6069b3955d8cd84c0a25aa7c117522c7	some successful approaches to software reliability modeling in industry	architecture based reliability models;software reliability growth models;reliability modeling;operational profile;sensitivity studies;product design;software reliability growth model;software reliability	Over the past three years, we have been actively engaged in both software reliability growth modeling and architecture-based software reliability modeling for projects at Lucent Technologies. Our goal has been to include software into the overall reliability evaluation of a product design using either or both of these two fundamentally different approaches. During the course of our application efforts to real projects, we have identified practical difficulties with each approach. The application of software reliability growth models, for example, is plagued by widespread use of ad hoc test environments, and the use of architecture-based software reliability models is plagued by a large number of unknown parameters. In this paper, we discuss our methods for overcoming these and other practical difficulties. In particular, we show how calibration factors can be defined and used to adjust for the mismatch between the test and operational profiles of the software. We also present two useful ways to do sensitivity analyses that help alleviate the problem of so many uncertainties in the architecture-based modeling approach. We illustrate our methods with case studies, and offer comments on further work that is required to more satisfactorily bridge the gap between theory and applications in this research area.	reliability engineering;software quality;software reliability testing	Daniel R. Jeske;Xuemei Zhang	2005	Journal of Systems and Software	10.1016/j.jss.2003.10.024	reliability engineering;verification and validation;simulation;software sizing;systems engineering;engineering;software design;software reliability testing;software development;software design description;software engineering;software construction;product design;software deployment;software quality;software metric;avionics software	SE	-63.150095626635725	30.475972824686085	17387
3690e7b54a409bc7fba06baf2ca1dc14996ed35d	zur erstellung der spezifikation von prozessrechner-software				Jochen Ludewig	1981				NLP	-97.04147025975386	23.106640977672992	17478
f2b4db48f23b8c8786e9e95d809e34e867828b40	ausdifferenzierung eines componentware-pps-systems in richtung auf branchen und betriebstypen				Marc Braun	1999				Crypto	-97.42416135346272	23.66944818524047	17510
9a1a7f51e44300fde83b081018d7bd3687e42ff7	understanding the front-end of large-scale engineering programs	large scale engineering programs;program front end;complexity;planning mistakes;planning	Large engineering programs like sociotechnical infrastructure constructions of airports, plant constructions, or the development of radically innovative, high-tech industrial products such as electric vehicles or aircraft are affected by a number of serious risks, and subsequently commonly suffer from large cost overruns. Significant problems in program execution can be traced back to practices performed, or more frequently not performed, in the so-called “fuzzy front end” of the program. The lack of sufficient and effective efforts in the early stages of a program can result in unstable, unclear and incomplete requirements, unclear roles and responsibilities within the program organization, insufficient planning, and unproductive tensions between program management and systems engineering. This study intends to clarify the importance of up-front planning to improve program performance, to propose a model for the front-end of large-scale engineering programs based on a review of existing, suitable models in literature and to better understand the complexity drivers that are impeding reliable planning and common planning mistakes made in large-scale engineering	complexity;control theory;device driver;front and back ends;new product development;requirement;sociotechnical system;subject matter expert turing test;systems engineering	Sebastian Lucae;Eric Rebentisch;Josef Oehmen	2014		10.1016/j.procs.2014.03.079	planning;environmental design and planning;complexity;simulation;computer science;data mining;algorithm	SE	-71.7813859409292	19.557363653716383	17511
abf424ede3fbea6bda4a41c21cf6383fb9e4fd22	the students' perspectives on applying design thinking for the design of mobile applications		Design Thinking (DT) is relevant for companies committed to developing a more creative and innovative application. DT provides a human-centered view of technological artifact design. Therefore, it is important to learn DT in Computer Science and Software Engineering courses as an analytic and creative process, in order to better prepare students for the software development industry. We conducted an empirical study with 17 postgraduate students in the context of mobile applications design. We used coding procedures from the Grounded Theory method for analyzing the obtained qualitative data. Based on the results, we identified some difficulties that participants experienced in using different DT techniques. The results of this study can help teachers understand the difficulties faced by students in learning DT and, consequently, help them to look for new teaching strategies for their classes. Moreover, these results can contribute to the software industry showing the competitive advantages of using DT in the design of the applications under development, especially in mobile applications.	computer science;mobile app;second-generation programming language;self-replication;software development;software engineer;software engineering;software industry;usability;user experience	Natasha M. Costa Valentim;William Oliveira da Silva;Tayana Conte	2017	2017 IEEE/ACM 39th International Conference on Software Engineering: Software Engineering Education and Training Track (ICSE-SEET)	10.1109/ICSE-SEET.2017.10	software development;systems engineering;competitive advantage;coding (social sciences);empirical research;computer science;grounded theory;software;design thinking;creativity	SE	-71.9366044507362	22.852116216397857	17545
6cb70563d363997b8777670932fac9d809fb9b14	an overview of r&d activities in europe on critical information infrastructure protection (ciip)	protection information;sistema critica;information infrastructure;systeme critique;securite informatique;logique floue;logica difusa;fuzzy logic;computer security;physics;critical system;proteccion informacion;information protection;seguridad informatica;information system;critical infrastructure;systeme information;sistema informacion	In recent years there has been an increasing R&D interest in critical infrastructures and their protection. However, this represents a still very immature field of research with very fuzzy and confused boundaries. This paper reports an initial overview of R&D activities in Europe on this topic to illustrate the state of art and to emphasize the major areas of research but also to identify the most relevant lacks.		Sandro Bologna;Giovanni Di Costanzo;Eric A. M. Luiijf;Roberto Setola	2006		10.1007/11962977_8	fuzzy logic;information infrastructure;computer science;critical infrastructure;operations research;computer security;information protection policy;information system	Mobile	-67.50446443337677	6.40453930717509	17606
0738ba0e59116339a73089844893f533a119e521	e-diagnosis: knowledge management and organizational chance in virtual times	knowledge management;organizational chance;virtual time	This paper discusses E-diagnosis, i.e., organizational diagnosis in electronic terms. E-diagnosis is taken as an instrument of meaningful knowledge construction for managers, based on a set of data and organizational information obtained in almost real time. Actually, based on a criticism of conventional modes of organizational status assessment, the intention is to configure a virtual mode of approaching the problem faced by those who manage — how to assure organizational long term survival. Attention is not focused too much in Information Technology — IT, however current IT advances are considered and taken as a support to organizational virtualization. Thus, the possibility of assuring appropriate information for managerial decision processes is delineated considering four dimensions — format, content, time, and cultural space.	knowledge management	P. S. Grave;F. A. Gimenez;Ana Mendes;J. M. Crubellate	2000			organizational learning;data management;knowledge management;process management;personal knowledge management;knowledge value chain	DB	-70.53354732099044	8.068461273998167	17701
ba7ab3e085465aa0a4a6d75bb949e5962fd2b262	prise en compte de l'usager enseignant dans la conception des eiao. illustration dans calques 3d	en francais	Cette these a pour theme la conception du0027environnements interactifs du0027apprentissage avec ordinateur (EIAO). Lu0027une des difficultes de ce domaine est que les solutions proposees sont rarement acceptees par les enseignants car non conformes a leur propre conception pedagogique de lu0027enseignement a dispenser. Lu0027objectif du travail est donc de prendre en compte les souhaits des enseignants des la conception du produit, en identifiant et categorisant les differents besoins pedagogiques, pour pouvoir offrir a lu0027enseignant prescripteur (celui qui utilise le logiciel) un environnement ouvert ou il pourra choisir la configuration adaptee a sa pedagogie. Le champ du0027application que nous avons choisi est celui de lu0027enseignement de la geometrie dans lu0027espace, via la realisation du0027un logiciel de type micromonde, calques 3d. Afin du0027atteindre les objectifs fixes, nous avons collabore, lors de la conception du logiciel, avec deux groupes du0027enseignants auteurs qui ont enrichi la maquette par leurs approches variees. Pour en favoriser le developpement, nous avons mis en place un formalisme, les contextes du0027utilisation de logiciels pedagogiques, permettant aux enseignants auteurs du0027exprimer leurs choix de presentation des connaissances et les activites quu0027ils souhaitent mettre en place autour de ces connaissances. Ce formalisme nous a permis en retour du0027extraire les informations pertinentes a implanter et de choisir les representations internes adequates. Ces documents ont ainsi servi de support a la negociation entre enseignants auteurs et informaticiens pour lu0027obtention du0027un accord sur les connaissances geometriques embarquees dans le logiciels et leurs presentations externes a lu0027interface.	european internet accessibility observatory;linear algebra	Nicolas van Labeke	1999			philosophy;performance art	Crypto	-105.98850032775897	14.77892780934134	17749
23ff45f679d1b75d98c5ac66af2443bf8d736e5d	training pre-assessment: is it feasible?	it implementation strategies;electronic mail;qualitative data;end user innovation;software package;training program;critical success factor	This paper reports of a study of the impacts of doing preassessments on the outcomes of software training. Preassessment is defined here as a pre-training interview des&ned to learn the needs of the trainee and to gain insights into training design that can aid the trainee. The context of the study was a training program for a database retrieval software package in a medium-sized manufacturing company. Approximately half the trainees received pre-assessments. The method of training was also varied so that half of each group (those with or without pre-assessments) were exposed to either applications-based (relevant problem focused) or a construct-based (generic training approach) training. Both quantitative and qualitative data were gathered through questionnaires, quizzes, and interviews. There was no firm evidence to accept the value of pre-assessments, but the evidence was not strong enough to reject using pre-assessments. Thepaper discusses some potential critical success factors for making pre-assessments more effective.		Conrad Shayo;Lorne Olfman;Ricardo Teitelroit;Claes Nordahl;Matthew Rodriguez	1996		10.1145/238857.238903	computer science;systems engineering;software engineering;computer engineering	ML	-89.74700842001592	5.578858238450848	17756
e142ace15df7a9a1bac1551dd2d0350cc2917592	knowledge management and creativity in software engineering - the foundations of agility		Software development is a knowledge intensive activity and its success depends on knowledge and creativity of the developers. In the last years the traditional perspective on software development is changing and agile methods have received considerable attention. Among other attributes, the agilists claim that fostering knowledge sharing and creativity is one of the keys to response to common problems and challenges of software development today. The development of new software products requires the generation of novel and useful ideas. The purpose of this paper is to provide an understanding of knowledge management and creativity in relation with new software engineering trends. The implications of these findings are considered, and some possible directions for future research are suggested.	agile software development;knowledge management;software engineering	Broderick Crawford;Claudio León de la Barra;Ricardo Soto;Sanjay Misra;Eric Monfroy	2013		10.5220/0004447802650272	knowledge management;social software engineering;management science	SE	-70.16650395146401	21.586484469336195	17761
5ff7f995663fb2e3052990fbfa0a9a8afd40a63c	opus: entwurf und realisierung eines erweiterbaren, objektorientierten dokumentenverarbeitungssystems			libopus	Christian Vetterli	1991			art history;opus;computer science	AI	-100.65598261892696	27.036447595940494	17869
0476fb0257939341a75a9fc77350e4af433557cd	trusting robots : contributions to dependable autonomous collaborative robotic systems. (vers des robots collaboratifs autonomes sûrs de fonctionnement)		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Trusting robots : Contributions to dependable autonomous collaborative robotic systems Jérémie Guiochet	archive;autonomous robot;comefrom;dependability;hal;linear algebra;trust (emotion)	Jérémie Guiochet	2015				Robotics	-107.63091520908473	9.525484412768185	17877
064c0e738a0f91c100e76fe7f65d3609ba149e94	information technology projects - leaving the 'magic' to the 'wizards'	business and management;critical systemic thinking;management system;information technology;computing;contextual inquiry;systems analysis;organizational change;contextual analysis;information system;business information systems;business value;requirement specification;systems development;systemvetenskap informationssystem och informatik med samhallsvetenskaplig inriktning	In this paper, we explore the significant challenges relating to investment in IT in business. Information technology does not in itself deliver business value. We highlight the complexities that are often ignored in management of IT projects. If the management system in an organization is ineffective, then installing information technologies does not constitute a ‘magic wand’ that will generate prosperity. It can only generate value if attention is paid to the design of the system for use at the same time that technological systems are developed. The authors explore how IT benefits require attention from management generally, and show that investment in IT projects cannot be left to ‘IT experts’ alone. We point out that undue reliance on rational planning is unsatisfactory, as it ignores contextual dependencies in organizational life. Criteria by which the success/failure of projects is to be judged must go beyond a focus on timescales, budgets and ‘requirement specifications’. We suggest that the criteria need to be expanded to embrace usefulness of resultant systems, as perceived by organizational staff as they attempt to use them in carrying out their work. (Less)	wizard (software)	Peter M. Bednar;Christine E. Welch	2008		10.1007/b137171_36	engineering;knowledge management;operations management;management	SE	-76.79293101605465	10.216432503784793	17883
d1545615ec92d958591b6a8ea8663e9f7fefc2e5	workflow analyse für investitionsgüter - bericht aus der praxis	mensch maschineinteraktion;investitionsguter;nutzungskontextanalyse;other;ethnographie		altran praxis	Beata Schwichtenberg;Barbara Knapp;Holger Oortmann	2010			praxis;knowledge management;workflow;engineering	NLP	-94.88270532266623	27.181713999494498	17919
5d3a6923a612d1112a121fbefe237753f57a836d	bsnet: a three-layer business service correlation network model	silicon;social network services;social networking services;service orientation;collaboration;service management;service correlation mining;who what how correlation network bsnet three layer business service correlation network model enterprise information system services oriented business ecosystem organization business service management internet of service business model formal model;service strategic alliance models;service correlation mining business service correlation network services oriented business ecosystem sobe service strategic alliance models;strategic alliance;internet business data processing;business model;internet;ecosystems;business data processing;enterprise information system;network model;business;business correlation social network services ecosystems collaboration silicon quality of service;internet of services;correlation;quality of service;network services;business service correlation network;services oriented business ecosystem sobe	"""With the advancement of enterprise information system, services-oriented business ecosystem (SOBE) has became an important pattern for the organization and management of the massive business services. At the same time, Internet of Service (IOS) provides a business model in which service vendors and consumers can interactive with each other via the Internet. This paradigm makes it possible that services in SOBE be managed in an autonomous and coordinated manner. The challenge here is to really coordinate the distributed services and federate them to achieve the benefits of SOA. To address these shortcomings, this paper presents """"BSNet"""", a formal model of the SOBE. The model consists of a three-layer business service correlation network which describes the relationships in SOBE. In fact, it is a """"who-what-how"""" correlation network construction of SOBE. Furthermore the expanded value of this model to business service management is shown. Finally, a simulation-base case study using BSNet to organize and manage SOBE is presented."""	autonomous robot;business ecosystem;enterprise information system;federated identity;mathematical model;multitier architecture;network model;programming paradigm;recursion;simulation	Keman Huang;Yushun Fan;Wei Tan	2011	2011 IEEE Ninth International Conference on Dependable, Autonomic and Secure Computing	10.1109/DASC.2011.182	business model;ecosystem;the internet;quality of service;service management;computer science;knowledge management;network model;silicon;management;correlation;enterprise information system;collaboration	DB	-74.46760993870028	8.49346957707707	17922
2725ee89affdf2bf1b418b8f887d9b78b3743b75	manufacturing supply chain applications: modeling computer assembly operations for supply chain integration	performance measure;supply chain integration;supply chain;business process	Factory operations have been modeled for years to understand the relationship between the different design and policy factors and the performance measures of interest. The increasing awareness of the need to manage factories as a link in the supply chain places a corresponding requirement for an enhanced approach for factory modeling. This paper describes the modeling of a computer assembly factory for supply chain integration by including aspects of inbound and outbound logistics and relevant business processes. Lessons are drawn based on the experience.	business process;end-to-end principle;inbound marketing;logistics;simulation	Sanjay Jain;Ngai Fong Choong;William G. K. Lee	2002			supply chain risk management;demand chain;supply chain management;value chain;service management;supply chain;process management;business process;manufacturing engineering	AI	-75.33038481066966	8.16043065006293	17960
a59243179444fe7553ba7a9b6fde5b3465f8931f	web-application development projects by online communities: which practices favour innovation?		Purpose#R##N##R##N##R##N##R##N##R##N#The purpose of this paper is to propose an in-depth analysis of online communities of practice that support the innovative development of web applications. The analysis is aimed at understanding the preeminent characteristics of communities of practice that can favour the process of innovation (conceptualisation and realization of a web application) and if these characteristics differ in the diverse phases of a software development project (requirement specification, design, implementation and verification).#R##N##R##N##R##N##R##N##R##N#Design/methodology/approach#R##N##R##N##R##N##R##N##R##N#The authors adopted a multiple case study research design, selected 29 communities of practice related to the development of web applications and classified them recognizing the different practices that refer to the different phases of the innovation process of web-applications software development. Finally, the authors focussed on seven communities comparing five important dimensions for each one.#R##N##R##N##R##N##R##N##R##N#Findings#R##N##R##N##R##N##R##N##R##N#The results of the empirical analysis show that the best practices are different, considering the different phases of the project, and that these practices can be strategies directed at members to attract them and also, strategies directed at the community to permit collaboration.#R##N##R##N##R##N##R##N##R##N#Originality/value#R##N##R##N##R##N##R##N##R##N#The paper proposes an important and new insight into the management of virtual communities of practice (VCoP). The authors supposed that the ways to manage a VCoP could depend on project phases. In particular, the management practices of community should differ according to the different project phases, i.e. requirements specification, design, implementation and verification of the software. Literature in this sense presented only research focussed on the different effects of virtualness on teams depending on the length of team duration and on communication efforts.	online community;web application	Alessandro Annarelli;Cinzia Battistella;Fabio Nonino	2017	Industrial Management and Data Systems	10.1108/IMDS-10-2015-0440	systems engineering;engineering;knowledge management;marketing;management science;management	SE	-68.47584630016861	17.40732627481677	17965
9d7d9dddc4bd4420b82f7323e842cbb60b175620	verteilt agierendes system zur bereitstellung von geometrie- und bild-basierten approximationen für das multiresolution rendering				Karsten Hilbert	2010			rendering (computer graphics);computer graphics (images);computer science	Visualization	-100.80851902385798	22.50807751655405	17975
5f608b6e892a08df39ef98d5f6c8e58e22dfe36c	enterprise architecture, des problèmes pratiques à l'innovation	modele entreprise;architecture systeme;markets;mercado;processus metier;modelo empresa;strategic alignment;business model;estrategia empresa;industry;innovation;ingeniero consejero;marche;consultant;algorithme evolutionniste;proceso oficio;arquitectura sistema;algoritmo evolucionista;information system;evolutionary algorithm;ingenieur conseil;system architecture;innovacion;is urbanisation;firm strategy;strategie entreprise;enterprise architecture;systeme information;business process;sistema informacion	A number of Enterprise Architecture (EA) frameworks, methods and tools are available on the market, already used in administrations, companies, and proposed by consultants. Organisations are able to solve a number of issues using them, but these approaches generate new risks too, and some issues remain open. What are the next evolutions to cope with these risks and issues? We believe that research has already anticipated these risks and solved some of these issues that organisations are dealing with -or will have to face in a near future. The purpose of this paper is to draw from these lessons learned in research a few guidelines to face the next generation of challenges of EA.	enterprise architecture	Camille Salinesi;Laure-Hélène Thevenet	2008	Ingénierie des Systèmes d'Information	10.3166/isi.13.1.75-105	business model;innovation;evolutionary algorithm;enterprise architecture;business process;operations research;strategic alignment;information system	Crypto	-68.73855336290409	6.791118559861251	18013
4cc5943b5424fb801a01d0b80ea282198a9b82b0	zur bedeutung von sicherheit in interorganisationellen workflows.				Gaby Herrmann;Günther Pernul	1997	Wirtschaftsinformatik		data mining;computer science;workflow	DB	-95.21423926546227	28.584422496710825	18028
c72e16f169ea27547fa4189b2032b906261e1027	entwurf, implementierung und test einer it-architektur für einen mobilen gesundheitscoach: das beispiel personal health manager	schlüsselwörter: betriebliches gesundheitsmanagement;mobiles informationssystem;architektur;implementierung.;bewegungsprogramm	Der Personal Health Manager (PHM) ist ein IT-gestütztes Bewegungsprogramm um körperlich inaktive Menschen an einen aktiveren Lebensstil heranzuführen. Für den PHM wurden Software, Hardware, persönliche und computervermittelte Dienstleistungen zu einer kostengünstigen und größenskalierbaren Lösung kombiniert, die aber in gewissem Maße individualisierbar ist. Die Anforderungen an die Lösung wurden systematisch aus der Literatur und in Workshops mit Experten und Anwendern erhoben, in eine Architektur überführt und implementiert. Die Lösung wurde im betrieblichen Gesundheitsmanagement von zwei Großunternehmen eingesetzt und evaluiert. Vielen Teilnehmern kam die Flexibilität und Ortsunabhängigkeit der Betreuung entgegen und es konnten messbare Erfolge bei der Steigerung der Aktivität und bei der Verbesserung medizinischer Parameter erzielt werden. Schlüsselwörter: Betriebliches Gesundheitsmanagement, Bewegungsprogramm, Mobiles Informationssystem, Architektur, Implementierung.	eine and zwei;information system;unified model	Sebastian Esch;Uta Franziska Knebel;Jan Marco Leimeister;Helmut Krcmar	2009			operating system;computer science	OS	-100.28012585415628	33.14685017224075	18034
ee7ab0ca9199c117ac40517d3bd05d775ad2781c	the right model for continuous experimentation	agile software development;customer development;lean software development;software development process;lean startup;113 computer and information sciences;continuous experimentation;a1 refereed journal article;software architecture;product development	Context: Development of software-intensive products and services increasingly occurs by continuously deploying product or service increments, such as new features and enhancements, to customers. Product and service developers must continuously find out what customers want by direct customer feedback and usage behaviour observation. Objective: This paper examines the preconditions for setting up an experimentation system for continuous customer experiments. It describes the RIGHT model for Continuous Experimentation (Rapid Iterative value creation Gained through High-frequency Testing), illustrating the building blocks required for such a system. Method: An initial model for continuous experimentation is analytically derived from prior work. The model is matched against empirical case study findings from two startup companies and further developed. Results: Building blocks for a continuous experimentation system and infrastructure are presented. Conclusions: A suitable experimentation system requires at least the ability to release minimum viable products or features with suitable instrumentation, design and manage experiment plans, link experiment results with a product roadmap, and manage a flexible business strategy. The main challenges are proper, rapid design of experiments, advanced instrumentation of software to collect, analyse, and store relevant data, and the integration of experiment results in both the product development cycle and the software development process. ∗Corresponding author Email addresses: fabian.fagerholm@helsinki.fi (Fabian Fagerholm), alejandro.sanchezguinea@uni.lu (Alejandro Sanchez Guinea), hanna.maenpaa@cs.helsinki.fi (Hanna Mäenpää), juergen.muench@cs.helsinki.fi, juergen.muench@reutlingen-university.de (Jürgen Münch) Preprint submitted to Journal of Systems and Software May 12, 2016		Jürgen Münch;Fabian Fagerholm;Alejandro Sánchez Guinea;Hanna Mäenpää	2017	Journal of Systems and Software	10.1016/j.jss.2016.03.034	software architecture;simulation;computer science;systems engineering;engineering;software development;operating system;software engineering;agile software development;management;lean software development;software development process;new product development	SE	-67.79261306876323	19.590769859348455	18047
757f283ecdf4a4c1ca1bd50d13ccb3cbcac8ab3d	data mining im einsatz - praxisbeispiele und trends	data mining		data mining	Roland Grund	2004			data mining;computer science	DB	-95.10638164973919	27.014975222748294	18054
964fb49a73eb7051a858e3336f20153513a7281b	turkey's smart grid roadmap project for electrical distribution systems in vision 2035		As conventional electrical networks evolve to be smarter, large-scale investments are required for new technological systems. This transformation creates the need to develop smart grid roadmaps for each national, regional or municipal-level network. After the liberalization of the electrical distribution sector in Turkey, smart grid implementation activities and R&D efforts have accelerated. In this context, the Turkey Smart Grid Roadmap (TR-SGR) Project was initiated as one of the maj or milestones in providing a detailed guideline for the future of smart grids in Turkey. In this paper, an overview of the proj ect and the Clustering Based Smart Grid Maturity Model (C-SGMM) are introduced. An evaluation of the maturity level of the distribution network in Turkey is provided. In addition, the Turkey 2035 smart grid vision and its main objectives are presented and key points in the 2025 project-based action plan are described.		Kahraman Yumak;Gokhan Tosun;Ozden Ercin;Gokhan Batar;Murat Can Sinim	2018	2018 IEEE PES Innovative Smart Grid Technologies Conference Europe (ISGT-Europe)	10.1109/ISGTEurope.2018.8571730		HPC	-70.33379453434151	15.591267208925471	18109
ae3827cb09f21697e70dd8ae0ca84a5ebbdad193	übergreifendes risiko-management für die gesamte supply chain: vision oder realistische chance?		"""Supply Chain übergreifendes Risiko-Management ist nu r möglich, wenn alle Supply Chain Partner bekannt sind und sich vert rauensvoll über Risiken austauschen. Um zu verdeutlichen, wie schwer dies ist, werden zunächst grundsätzliche Voraussetzungen für ein systematisches Risiko-Ma nagement erläutert und dann beispielhaft die Supply Chains für den IPod von Apple und für Doraden aus dem Senegal skizziert. 1 Risiko-Management: auf dem Papier, aber nicht in den Köpfen Der Ausbruch des Vulkans Eyjafjallajökull in Island hat den Produktfluss in mehreren Lieferketten zum Stillstand gebracht. So konnten be ispi lsweise Opel, Daimler, BMW und der Automobilzulieferer Bosch nicht wie geplant produzieren. Bei BMW standen die Fließbänder in den Werken München, Dingolfing u d Regensburg für zwei Tage still und die Fertigstellung von rund 7000 Fahrzeugen mus ste verschoben werden [Ve10]. Können sich Unternehmen gegen solche Krisen mit ein em geeigneten RisikoManagement (RM) absichern? BMW erläutert im Geschäf tsbericht 2010 auf sieben Seiten, wie (gut) das interne Risiko-Management fun ktio iert (S.63-69). Dass es trotzdem zu Stillständen in der Produktion kam, kann dar an liegen, dass die Eintrittswahrscheinlichkeit oder die Schadenshöhe eines solchen Sz arios unterschätzt wurde oder das Risiko wurde akzeptiert, zum Beispiel weil die Kosten der Senkung bzw. von Gegenmaßnahmen zu hoch wären. Börsennotierte Aktiengesellschaften, eine GmbH oder eine GmbH & Co. KG sind bereits nach dem Gesetz zur Kontrolle und Transparenz im Unternehmensbereich (KonTraG) von 1998 verpflichtet, ein Risiko-ManagementSystem (RMS) aufzubauen [Ke09]. In der Ausgestaltung sind sie jedoch frei. Laut einer Studie der Deutschen Bank [DB09] in der 400 Finanzentscheider im Jahr 2009 zu m RMS in ihrem Unternehmen befragt wurden, halten über 80% der befragten Unter nehmensvertreter ein RMS für wichtig oder sehr wichtig. Auf der anderen Seite ge ben aber auch 36% der Befragten an (noch) kein „systematisches“ RMS aufgebaut zu haben . 92% „identifizieren Risiken“, 54% nutzen „Risikokennzahlen“ und nur noch 16% verf ügen über Prämienbudgets zur Risikoabsicherung. Daher stellt sich zunächst die F rage, was bei der Einführung eines systematischen RMS zu beachten ist. Daraus werden d an ie großen Herausforderungen deutlich, die ein Supply Chain übergreifendes R M mit sich bringt. 2 Aufbau eines systematischen Risiko-Managements 2.1 Erläuterung der Begriffe Die Norm """"ISO 31000:2009 Risk management – guidel ines on principles and implementation of risk management"""" kann sowohl als Leitf aden für den Aufbau eines RMS als auch für das operative RM dienen. Herausgehoben wird in der Norm, dass RM eine Managementaufgabe ist, die als Top-down-Ansatz gele bt w rden muss. Die Unternehmensführung muss das Thema fortlaufend unterstützen und die Risiken müssen auch aus den unteren operativen Einheiten abgefragt werden. Die Abfrage, das Sammeln, Bewerten und Aggregieren von Risiken muss einer Abteilun g als klare Verantwortung übertra-"""	die (integrated circuit);eine and zwei;gesellschaft für informatik;intentionally blank page;internet explorer;kasparov's gambit;risk management;sie (file format);unified model	Birgit Gampl	2014			operations management	OS	-102.71018216310928	33.97661139279696	18116
9ae179707827426cd1867a53d35adf70dd7998d2	quantifying the impact of requirements definition and management process maturity on project outcome in large business application development	successful ca development;empirical study;on budget;rdm maturity;on time;commercial application ca development;on function;survey;requirements discovery and management rdm	Using data from two surveys of people knowledgeable about requirements for, and the success of the development of, large commercial applications (CAs) in hundreds of large organizations from around the world, this paper reports a high positive correlation between an organization’s requirements definition and management (RDM) maturity and that organization’s successful performance on CA development projects. Among the organizations that responded with a filled survey, an organization that is assessed at a high RDM maturity is significantly more successful in its CA development projects than is an organization that is assessed at a low RDM maturity, when success in CA development projects is measured as (1) delivering CAs on-time, on-budget, and on-function, (2) meeting the business objectives of these projects, and (3) the perceived success of these projects. This paper presents a comprehensive framework for RDM, describes a quality RDM process, and describes RDM maturity and how to measure it. It describes the two surveys, the first of which ended up being a pilot for the second, which was designed taking into account what was learned from the first survey. The paper concludes with advice to practitioners on the application of the RDM maturity framework in any organization that wishes to improve its RDM and its performance in the development of large CAs.	business software;capability maturity model;iag;rdm (lighting);requirement	Keith Ellis;Daniel M. Berry	2012	Requirements Engineering	10.1007/s00766-012-0146-3	systems engineering;engineering;knowledge management;operations management;empirical research	SE	-72.64558313659366	19.999066670224636	18123
2dc554cf8d493107c0abdd38d80130bbb30bd067	harmonised digital forensic investigation process model	computer forensics;parallel processing computer forensics iterative methods;digital forensics planning information systems analytical models guidelines;iterative methods;model information systems security digital forensics process;parallel processing;parallel actions harmonised digital forensic investigation process model information security information technology formalised process iterative model	Digital forensics gained significant importance over the past decade, due to the increase in the number of information security incidents over this time period, but also due to the fact that our society is becoming more dependent on information technology. Performing a digital forensic investigation requires a standardised and formalised process to be followed. There is currently no international standard formalising the digital forensic investigation process, nor does a harmonised digital forensic investigation process exist that is acceptable in this field. This paper proposes a harmonised digital forensic investigation process model. The proposed model is an iterative and multi-tier model. The authors introduce the term “parallel actions”, defined as the principles which should be translated into actions within the digital forensic investigation process (i.e. principle that evidence's integrity must be preserved through the process and that chain of evidence must be preserved). The authors believe that the proposed model is comprehensive and that it harmonises existing state-of-the-art digital forensic investigation process models. Furthermore, we believe that the proposed model can lead to the standardisation of the digital forensic investigation process.	admissible heuristic;information security;iteration;multitier architecture;process modeling;prototype;requirement	Aleksandar Valjarevic;Hein S. Venter	2012	2012 Information Security for South Africa	10.1109/ISSA.2012.6320441	parallel processing;computer science;data mining;iterative method;computer security;computer forensics	Web+IR	-75.21381545249051	14.138473942870071	18150
6883a1814a84beddfd9d3fb914af72cfecd61bd0	datenqualität: eine organisatorische und technische herausforderung - erfahrungen von der dblp-bibliographie			eine and zwei	Michael Ley	2007			computer science	NLP	-100.90966529068726	28.218493424350562	18174
534f42ae7ab068d8c1b9cb42ba8639280a7dc0a6	obstáculos ao ensino dos métodos de avaliação da engenharia semiótica				Silvia Amélia Bim	2009				Crypto	-105.85407569846774	18.41608964683488	18175
d5a0cca66ab7d56201c2c269bb4af38093138932	differenzierung von provokationen und artefakten in den on-line gemessenen vitalparametern der rechnergestützten intensivüberwachung			online and offline	Thomas Wolf	1988				Theory	-96.81117791557178	24.04625840758146	18176
5f10f9169839ad36b300a849d98058fef99b8720	testing bpr common wisdom	organizational support business process reengineering project organizational benefits productivity product quality service quality cost savings organizational environment quality project resources;testing business process re engineering productivity costs information technology conference management management information systems project management information management delay effects;systems analysis;business data processing;quality control systems re engineering systems analysis business data processing human resource management reviews;reviews;quality control;business process reengineering;human resource management;systems re engineering	The purpose of this research was to empirically determine what benefits were realized by organizations that have undertaken a Business Process Reengineering (BPR) project. The survey’s respondents indicated that they were general& satis$ed with their BPR projects. The findings suggest that BPR enabled organizations to increase productivity+ to raise the qua@ of products and services, to increase costs sm,ings, and to improve the quality of the organizational environment. The success factors, which Iead to these advantages, are the compliance with BPR principles, the methodological rigor of the BPR approach and the diversity of the project resources, in turn determined by the level of organizational support. Introduction Business Process Reengineering (BPR) is the fundamental rethinking and radical redesign of business processes to achieve dramatic improvements in critical aspects of performance, such as cost, quality, service and speed, based on the innovative use of information technologies. BPR is a new approach which has quickly become an important preoccupation for Information System executives and is clearly an important business priority for IS managers [27,10]. Studies show that 88% of major American organizations have already undertaken or currently undertake a BPR project. While IS managers participated in an average of 1.6 BPR projects in 1992, this figure grew to 4.4 projects in 1993, an increase of 175% [20]. In 1994, 476 members of the Society for Information Management rated BPR as a very important management trend, along with the focus on consumers, the change in organizational culture, and the alignment of IT with business strategy. As reported in a recent survey, BPR applies as much to the public sector as to the private sector [3]. Several authors, practitioners and researchers have stated that BPR enables organizations to obtain a number of important advantages such as a drastic reduction in Proceedings of the 29th Annual Hawaii International Conference on System Sciences 1996 Suzanne RIVARD Ecole des H EC Mont&al, Quebec Canada costs, a reduction of errors and delays, and an increase in client satisfaction; in brief, an overall improvement in organizational efficiency and effectiveness [33,42,13,19]. However, the undertaking of such a project deserves careful consideration since there is contradictory evidence about the success rate of these projects. While it has been reported by Michael Hammer that as many as 70% of all BPR efforts fail 1351, a success rate of 70% has recently been observed in a survey conducted by Bergeron and Limayem [4] on Canadian firms. In view of the lack of strong evidence, this research study aims to determine empirically what specific advantages hmpe been obtained@om Business Process Reengineering and what are the success factors that determine these advantages? Business Process Reengineering The origins of Business Process Reengineering can be traced to the 1950’s when organizations first began to research ways of improving their performance by using information technology. Although current management philosophies have inherited a certain number of these methods and techniques, the underlying concepts of BPR, as we now know it, date from the 1990’s. BPR has evolved from the management ideas that have been developed over the last decades. It has originated from a variety of movements, all of which sought to improve business processes and product quality. Davenport [lo] has noted six significant inlluences: the total quality approach, the industrial engineering era, the systems approach, the socio-technical approach, the difbrsion of technological innovations and the use of information systems for competitive advantage. The sudden interest in BPR coincides with the productivity paradox, namely that organizations, despite their massive investments in the information technologies over the last fifteen years, have been rather unsuccessful in showing a direct effect of IT on productivity [3 1.12,32]. Although the application of IT has permitted jobs to be completed more quickly; they are not necessarily being performed more effectively. Management’s widespread acceptance of this fact, coupled with the publication in 1990 of Michael 1060-3425/96 $5.00	blender (software);business process;code refactoring;industrial engineering;information management;information system;job stream;sociotechnical system;strategic management	François Bergeron;Louis Raymond;Marie-Claude Boudreau;Suzanne Rivard	1996		10.1109/HICSS.1996.495322	systems analysis;quality control;business process reengineering;opm3;knowledge management;human resource management;process management;management;business process modeling	SE	-75.20707358784557	10.153569850546916	18191
755b83a77060704ef4fe5069960d5992b2f75fd7	insight into a method co-change pattern to identify highly coupled methods: an empirical study	software maintenance;method genealogy association rules evolutionary coupling life span modification occurrence rate method co change pattern;software maintenance data mining open systems public domain software;data mining;software maintenance method co change pattern highly coupled methods pinpoint design deficiency software system pattern identification method association rules method co change history code clone effect clone fragments open source software systems detect methods mmcgs pattern methods appearing in multiple commit groups pattern semantic change proneness reduction evolutionary coupling minimization clone refactoring;cloning software systems couplings association rules history java manuals;public domain software;open systems	In this paper, we describe an empirical study of a unique method co-change pattern that has the potential to pinpoint design deficiency in a software system. We automatically identify this pattern by inspecting the method co-change history using reasonable constraints on method association rules. We also investigate the effect of code clones on the method co-changes identified according to the pattern, because there is a common intuition that clone fragments from the same clone class often require corresponding changes to ensure they remain consistent with each other. According to our in-depth investigation on hundreds of revisions of seven open-source software systems considering three types of clones (Type 1, Type 2, Type 3), our identified pattern helps us detect methods that are logically coupled with multiple other methods and that exhibit a significantly higher modification frequency than other methods. We call the methods detected by the pattern MMCGs (Methods appearing in Multiple Commit Groups) considering the pattern semantic. MMCGs can be considered as the candidates for restructuring in order to minimize coupling as well as to reduce the change-proneness of a software system. According to our observation, code clones have a significant effect on method co-changes as well as on MMCGs. We believe that clone refactoring can help us minimize evolutionary coupling among methods.	angular defect;association rule learning;chomsky hierarchy;code refactoring;coupling (computer programming);entity;nsa product types;open-source software;pattern language;programmer;qr code;sensor;software system	Manishankar Mondal;Chanchal Kumar Roy;Kevin A. Schneider	2013	2013 21st International Conference on Program Comprehension (ICPC)	10.1109/ICPC.2013.6613838	real-time computing;state pattern;computer science;systems engineering;engineering;operating system;software engineering;data mining;adapter pattern;open system;software maintenance;public domain software;specification pattern	SE	-63.5921030316109	35.51574492439397	18212
c5d40741d2afd3bb8f9c9ca6ee39e6594156a1f5	vom primat der anwendungen				Helmut Reimer	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0057-6	internet privacy;computer security;computer science	NLP	-94.63619197414432	30.042935642504307	18281
a5fb4a1541047a2addd3a293c34d07f81c6591fb	integrierte flugzeugrumpf- und kabinenentwicklung mit graphenbasierten entwurfssprachen				Martin Motzer	2016				Crypto	-99.03629401151983	27.079688509594106	18299
4bde092ad88ca19b3225785efe4a22f41001a640	cloud computing. technik, sicherheit und rechtliche gestaltung			cloud computing	Mark Bedner	2013				NLP	-97.20682248823296	28.350109678462672	18342
0624357d912f2e5dabe1f167139a3e791057a1ae	on the use of tricoherent analysis to detect non-linear wave-wave interactions	statistique;fonction tricoherence;lossy medium;nonlinear phenomena;normalisation;phenomene non lineaire;medio dispersor;interaccion onda;normalizations;spectrum;wave interaction;higher order;fenomeno no lineal;statistical properties;confidence interval;calcul numerique;numerical computation;calculo numerico;normalizacion;analyse spectrale;statistics;analisis espectral;interaction onde;cumulant;spectral analysis;higher order spectral analysis;non linear phenomenon;natural experiment;standardization;estadistica;milieu dissipatif;statistical properties of estimators	Afin de decrire les effets non-lineaires dans un milieu dissipatif, il est possible d'utiliser l'approche par interaction de trois ou quatre ondes. L'analyse spectrale d'ordre superieur est necessaire pour identifier les ondes en interaction dans les signaux stochastiques. Le spectre de bicoherence, qui est le spectre cumulant normalise du troisieme ordre, a ete utilise dans de nombreuses etudes pour analyser l'interaction de trois ondes dans des experiences numeriques, de laboratoire ou naturelles. Ici, nous developpons le spectre de tricoherence pour detecter les interactions de quatre ondes, calculons les proprietes statistiques du trispectre et des estimateurs de tricoherence, de meme que l'intervalle de confiance pour ce dernier, et presentons le resultat d'estimations numeriques de la tricoherence utilisant des signaux synthetiques	interaction;nonlinear system	V. Kravtchenko-Berejnoi;F. Lefeuvre;V. Krasnossel'skikh;D. Lagoutte	1995	Signal Processing	10.1016/0165-1684(94)00136-N	spectrum;higher-order logic;confidence interval;natural experiment;mathematics;standardization;statistics;cumulant	SE	-106.02467424380055	16.50057272491291	18367
226b6fe12755f911a33ac34d558aa7a43fa1506e	empirical study on the performance of epc contractor management module: a chinese case	empirical study;project management;performance management;china metallurgical corporation;performance china epc construction industry management module;procurement;construction module;performance;construction industry;project management construction industry markov processes;chinese case;construction industry markov processes procurement project management companies;income distribution;satisfiability;companies;management module;project management epc contractor management module chinese case management income distribution markov state transition matrix ahp method china metallurgical corporation construction module construction industry;management income distribution;literature review;performance model;epc contractor management module;common sense;it management;markov processes;point of view;china;markov state transition matrix;state transition;ahp method;epc	"""The home-and-abroad literature review shows that calculating the performance coefficients between EPC Program and its management module has not been found from the EPC contractor's viewpoint. It is emphasized that management is the main source of benefit, and the essence of EPC module is a kind of instrument producing the performance or benefit. This article, from the EPC contractor's point of view, builds EPC management function performance model, analyzes EPC management income distribution patterns of EPC management module, and constructs Markov state transition matrix by using expert scoring method and AHP method to calculate the performance contribution stability of EPC contractor's management module and to predict the stability of the EPC performance management module. The empirical study of the Branch Company of the 20th China Metallurgical Corporation shows that although the performance coefficients (0.13,0.06,0.3,0.2,0.31) in the module do not meet the pattern of """"E-P-C"""" in EPC management, in which the additional values of the three elements appear decreasing, the coefficients satisfy the pattern of a “smiling” curve, by which it means that a shape of “high at two ends, low in the middle” reflects a relationship between the importance attached to the module and the performance income coefficients resulted from the module. Judging from common sense, it is the construction module (C) that should be at the bottom of the “smiling” curve, not the procurement module (P). The company, therefore, should adjust its focus in the management module to raise its base line in the procurement module so as to create a more reasonable performance income distribution curve."""	electronic product code		2010		10.1109/ICEE.2010.1294	project management;performance management;income distribution;economics;procurement;performance;systems engineering;engineering;operations management;management;china	ECom	-85.19427437739597	8.455533759504522	18415
ba87d509fbc2b910b7b6eea3bc72eddd24bfa8e1	globale computer-reservierungssysteme und neue informations-, kommunikations- und reservierungs-technologien im internationalen luftverkehr und tourismus unter besonderer berücksichtigung des reisemarktes lateinamerika, karibik				Monika Echtermeyer	1997				Crypto	-100.71853449750678	27.267950443298027	18473
ced8fb1df87a58c3fe4fd1335fb0f7de147f7fd7	erweitere dokumentgrammatiken als grundlage innovativer xml-tools			xml	Henning Lobin	2003	it - Information Technology	10.1524/itit.45.3.143.20203	computer science;data mining;database	HCI	-96.87026453261942	30.89367918910827	18526
315fed7e74c2c54bbd362ba77414b82d755f16a0	proof-theoretic notions for software maintenance	software maintenance	Abstract We discuss proof-theoretic notions as a useful tool to deal with software maintenance in a formal setting.	software maintenance;theory	Reinhard Kahle	2000	Electr. Notes Theor. Comput. Sci.	10.1016/S1571-0661(05)80048-9	long-term support;verification and validation;computer science;social software engineering;software framework;software development;software design description;software construction;software walkthrough;software maintenance;software deployment;software requirements;software quality	Logic	-62.877828885244604	26.26847282426565	18533
c1b808122b10e9df2a1570a1aa636819b9994eba	environmental labelling of mobile phones : lca standardisation process	lca standardisation;ict;environmental labelling;mobile phones	The mobile phone market is constantly evolving. Retailers and manufacturers offer a larger number of features to customers: a mobile network more and more efficient (2G, 3G then 4G), handsets with computer features, navigation, gaming, etc. This progress involves the use of more efficient and reduced electronic components: larger display panels with higher resolution, more powerful microprocessors and more memory available. One of today’s most important problematic is the emergence of environmental consciousness. In this context, various studies based on LCA have been recently conducted by the mobile phones retailers and manufacturers to understand to which extend their product could contribute to the environmental issues. One of these studies goals is to provide information to consumers on the environmental impacts of mobile phones. These initiatives are supplemented by the French and European environmental labelling programs. Moreover, methodologies for LCA are also evolving. For example, the JRC, the European Union's scientific and technical research laboratory, advocated a series of recommendations in order to reduce uncertainty about the impact from LCA results [1]. However, there are two main constraints in the creation of an environmental labelling dedicated to mobile phones. Firstly, the time between designing a mobile phone and its marketing is very short. Time to perform LCA studies is thus limited. Secondly, mobile phones market share is large and submitted to an important turnover. The development of easy-to-use methodologies and tools with quick return on investment is necessary. In this context, how can we provide a reliable environmental labelling while meeting the criteria of cost and time? This article deals with the environmental labelling scheme of mobile phones developed by SFR, a French telecommunications company. First of all, this article summarizes the LCA results uncertainties caused by two main aspects: the need to update life cycle inventories datasets (LCI datasets) faces the lack of availability of these data with the manufacturers and the need to develop the methodology to monitor the market and scientific advances. Secondly, the article will address various solutions that have been implemented in relation to these issues. Finally this article will detail the future challenges about methodological and standardisation. Index Terms — Environmental labelling, ICT, mobile phones, LCA standardisation.	consciousness;electronic component;emergence;inventory;liquid contact indicator;microprocessor;mobile phone	Damien Prunel;Etienne Lees-Perasso;Axel Roy;Catherine Moulin	2014		10.2991/ict4s-14.2014.27	business;risk analysis (engineering);mobile phone;return on investment;labelling;information and communications technology;market share;european union;cellular network	HCI	-72.91179590790716	4.916970700121947	18566
e4e3ec7ddebc98bc8a50584aecb3b251023c31d8	"""abschlußbericht des projektes """"erkundung von berufs- und tätigkeitsfeldern von computerlinguistinnen"""" (in folgen)"""		"""Nachdem sich der Arbeitskreis """"Ausbildung und Berufsperspektiven"""" bisher vorwiegend mit Ausbildungsfragen befaßt hatte, starteten einige Mitglieder Ende 1986 eine Initiative, die die berufliche Tätigkeit von ComputerlinguistInnen thematisiert. Dazu wurde auf der Basis freier Mitarbeit was die lange Bearbeitungszeit erklärt eine Projektgruppe (im folgenden BCL) mit sechs Mitgliedern gegründet, die sich die """"Erkundung von Berufsund Tätigkeitsfeldern von ComputerlinguistInnen"""" zur Aufgabe gemacht hat. Diese Erkundung sollte durch eine Fragebogen-Aktion erfolgen. Ziele des Projektes waren: Die Fragensammlung wurde mit einigen ComputerlinguistInnen außer halb des Projekts kritisch getestet und daraufhin geändert. Es blieb aber insgesamt ein Fragebogen, der das Interesse der Projektmitglieder spiegelt und an dem """"Experten in Befragung"""" mehreres auszusetzen hatten. Mit unserem Ansatz entschieden wir uns dafür, ein Gespräch mit den Befragten zu beginnen, was auch einige von ihnen so verstanden haben: das bezeugen sowohl Gesprächsangebote als auch eine Reihe bissiger und launiger Kommentare zu den Fragen. Der Fragebogen ist in dieser Hinsicht nicht mit anderen aus der wissenschaftlichen Forschung zu vergleichen, die, und sei es durch Hochrechnungen, empirisch haltbare Aussagen anstreben. Zu diesem wenig professionellen Vorgehen sahen wir uns durch zwei """"Sachzwänge"""" berechtigt: Fragenkomplexe enthielten Fragen nach Fakten, sowie Fragen nach deren Einschätzung bzw. nach der Zufriedenheit der Befragten mit ihrer individuellen Ausbildung und ihrer Berufssituation: Fragen nach wünschenswerten Änderungen in beiden Bereichen waren angeschlossen. Ein vollständig ausgefüllter Fragebogen enthält demnach Angaben von Fakten, Bewertungen und Meinungsäußerungen. Wir mischten Frageformen, die Textantworten oder Zahlenangaben erforderten, mit solchen, die MenueVorgaben machten."""	binary combinatory logic;eine and zwei;machten	Magdalene Lutz-Hensel	1989	LDV Forum		computer science;information retrieval;performance art	OS	-105.22472959737256	34.01019841577811	18574
9672b31c933f7c0a020f68c4d30eeea6c1d43915	bandits-manchots contextuels : précision globale versus individuelle				Nicolas Gutowski;Tassadit Amghar;Fabien Chhel;Olivier Camp	2018				NLP	-102.39577724282505	22.92395824836534	18625
6cd9851ba147aa97183dfc07723f8e914d5a6595	recognizing dynamic fields in network traffic with a manually assisted solution		Payloads of packets transmitted over network contain dynamic fields that represent many kinds of real world objects. In many different applications, there is a need to recognize and sometimes replace these fields. In this paper, we present a manually assisted solution for searching and annotating dynamic fields in message payloads, specifically focusing on web environment. Our tool provides a simple and intuitive graphical user interface for annotating dynamic fields.		Jarko Papalitsas;Jani Tammi;Sampsa Rauti;Ville Leppänen	2018		10.1007/978-3-319-77712-2_20	real-time computing;network packet;graphical user interface;computer science	HPC	-63.1753910266033	58.66639438809186	18646
7941451b7b68de680dfa7b7963f8ee5e7f2c50eb	helios - heidelberg laparoscopic intervention and operation simulator		Das HELIOS Phantom (Heidelberg Laparoscopic Intervention and Operation Simulator) stellt ein menschennahes Phantom mit einem Torso aus Kunststoff und Organen aus Silikon auf der Basis einer Computertomographie eines Patienten dar. Das Phantom dient als Evaluationsplattform für sämtliche Belange in der computerund roboterassistierten Chirurgie, des Weiteren ist es als Trainingsphantom für die laparoskopische Chirurgie nutzbar. Mit dem HELIOS Phantom wird die Lücke zwischen den abstrakten in-vitro Evaluationsmodalitäten (z.B. geometrische Phantome) und den realistischen aber aufwendigen in-vivo Experimenten (z.B. Tierversuche) geschlossen. Mittels Rapid Prototyping wurden der Torso und die Organe in 3D Form ausgedruckt. Grundlage hierfür war das durch Segmentierung des CT Datensatzes entwickelte virtuelle Modell des Patientenkörpers. Besonderheit des HELIOS Phantoms ist die Möglichkeit der Herstellung eines Pneumoperitoneums für die laparoskopische Chirurgie. Schlüsselworte: realistisches Operationsphantom, Evaluationsplattform, laparoskopisches Trainingsphantom	helios;phantom reference;rapid prototyping;v-model;video-in video-out	J. Wünscher;Hannes Kenngott;Martin Wagner;Felix Nickel;Beat Peter Müller-Stich	2012			abdominal wall;laparoscopic surgery;imaging phantom;simulation;modular design;breathing;haptic technology;rapid prototyping;computer science;segmentation	Security	-107.04939266237034	29.449237764628254	18694
3390264bb86ff211c5798ea0bf445ac8397cf8d9	wandel von der telekommunikation zu unified communications: veränderungsprozesse für unternehmen durch internetbasierte innovation			gesellschaft für informatik	Ralf Lehmann	2012				OS	-96.07332406713147	26.397636112414716	18745
bf02d01dd161b1b99754c4611e997747bf9d69c6	proposta de uma base de citações da literatura científica por meio da extração automática de dados do scielo: por meio da extração automática de dados do scielo			power-on reset;scielo	Max Cirino de Mattos	2013				Security	-106.10449483042554	18.299477435596177	18781
2bfe6a68c3da322fb4a4cac40ff08fda451e0c9f	an explanatory analysis on eclipse beta-release bugs through in-process metrics	in process metrics;development process;beta release bugs;retrospective analysis	Failures after the release of software products are expensive and time-consuming to fix. Each of these failures has different reasons pointing into different portions of code. We conduct a retrospective analysis on bugs reported after beta release of Eclipse versions. Our objective is to investigate what went wrong during the development process. We identify six in-process metrics that have explanatory effects on beta-release bugs. We conduct statistical analyses to check relationships between files and metrics. Our results show that files with beta-release bugs have different characteristics in terms of in-process metrics. Those bugs are specifically concentrated on Eclipse files with little activity: few edits by few committers. We suggest that in-process metrics should be investigated individually to identify beta-release bugs. Companies may benefit from such a retrospective analysis to understand characteristics of failures. Corrective actions can be taken earlier in the process to avoid similar failures in future releases.	committer;eclipse;sensor;software bug;software release life cycle	Ayse Tosun Misirli;Brendan Murphy;Thomas Zimmermann;Ayse Basar Bener	2011		10.1145/2024587.2024595	reliability engineering;real-time computing;engineering;data mining	SE	-64.20678431559594	34.777170640811356	18888
4ba4b950007251f551693e45fd05b5dc8c2d78c2	kontextsensitive dienste auf basis von open-source-software		Dieser Beitrag fasst die Ergebnisse einer Diplomarbeit zusammen, in der ein Konzept für die Bereitstellung von Diensten sowie deren kontextsensitive Auswahl und Nutzung entwickelt und prototypisch umgesetzt wurde. Die Umsetzung erfolgte dabei auf Basis von Open-Source-Software und offenen Standards aus dem Bereich des Semantic Web.	die (integrated circuit);open-source software;semantic web	Thorsten Teschke;Jörn von Ahsen;Maximilian Bergmann	2009			world wide web;semantic web;software;computer science	AI	-102.40437838079957	34.19984009690506	18897
2151fc8d6048b6a9a274b01083e5b703cc24bd76	distribution and continuity of developers' contributions in oss projects: a case study		Open Source Software (OSS) is usually developed by geographically-distributed developers in a collaborative manner. Different developers exhibit different behaviors and make diversified contributions to OSS projects. Objective of this paper is to discover individualized characteristics and common patterns of how developers contribute to OSS projects. Continuity is used to delineate how a developer actively contributes to the project over time. Case studies on two OSS projects reveal some significant phenomena on the distribution of developers’ contributions relative to absolute time and relative to the milestones (i.e., releases) of OSS projects. We have found that OSS developers’ contributions exhibit the “temporal locality”, and most of the releases of an OSS project are dominated by the contributions of a limited number of developers. Keywords– Open Source Software; social development; developers’ contributions; continuity; temporal distribution	locality of reference;open sound system;open-source software;scott continuity	Zhongjie Wang;Dewayne E. Perry;Xiaofei Xu	2016		10.18293/SEKE2016-008	computer science;systems engineering	SE	-75.30433999308936	21.266157850703983	18908
c7a24dc59477a7e2fda9b3642faffcfc93532510	hybrid software and systems development in practice: perspectives from sweden and uganda		Many organizations are adapting the use of hybrid software development approaches by combining traditional methods with flexible agile practices. This paper presents the initial results from the survey on the use of hybrid software and systems approaches. The results are from twenty one respondents from Sweden and Uganda. Our results show that the iterative model is the most widely used process model in both Sweden and Uganda. However, the traditional process models are also used in combination with the more agile models like Scrum. From the results, we also show that the large sized companies face the biggest problems during implementation of agility since they have to adhere to standards and control measures.		Joyce Nakatumba-Nabende;Benjamin Kanagwa;Regina Hebig;Rogardt Heldal;Eric Knauss	2017		10.1007/978-3-319-69926-4_30	management science;systems engineering;software development process;engineering;iterative and incremental development;software;software development;agile software development;process modeling;scrum	SE	-68.71480577616725	19.590672484594077	18923
c0a121a7cb2417182c3825d5d5d2495d791b0f8d	zum datenschutz				Alois Potton	1995	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1995.18.3.183		NLP	-97.56513915536651	28.16585216159873	18948
2c0a103a7e1351a315336012836ee7b49d0f4517	a educação na sociedade de informação e o dever fundamental estatal de inclusão digital	doctoralthesis;inclusao digital;direitos fundamentais;sociedade da informacao;direito educacional;direito a informacao	A utilizacao das tecnologias da informacao e da comunicacao pelo homem originou profundas mudancas, especialmente, nos âmbitos juridico, economico e social. Uma dessas refere-se ao reconhecimento de um novo modelo social denominado Sociedade da Informacao, cujo cerne equivale a utilizacao da informacao como bem juridico mais relevante, capaz de servir de criterio para que as pessoas possam ser incluidas socialmente e para producao de conhecimento, o qual tem sido o principal elemento para aferir o grau de desenvolvimento tecnologico e economico, atualmente, das nacoes. Por isso, exercer o direito de liberdade de acesso a informacao a partir de uma reflexao critica, bem como compreender como lidar com a quantidade e diversidade de informacoes, tem sido funcao primordial para os individuos alcancarem sua autodeterminacao no meio eletronico. Todavia, para que essa finalidade ocorra faz-se necessario que o Estado atue visando a correcao das desigualdades faticas no acesso aos recursos materiais e imateriais do citado meio, mediante, em especial, a preparacao integral das pessoas para o uso das citadas tecnologias, o que tem sido um relevante problema nos paises em desenvolvimento, a exemplo do Brasil. Essa funcao deve se realizar pela oferta de politicas publicas de inclusao digital a serem interpretadas como deveres fundamentais estatais de mesma importância que aqueles de demais areas sociais. Ocorre que a educacao, da maneira como tem sido ofertada, nao tem, eficientemente, alcancado esse fim, razao pela qual sua reinvencao tornou-se medida necessaria e urgente no sentido de direcionar o aprendiz a aprender a aprender, de forma continuada, e a despertar o anseio por transformar a si proprio e a realidade social em que vive. Para tanto, cabe a associacao ao seu conteudo da educacao em direitos humanos e fundamentais, por ser a forma de humanizacao apta a conscientizar o homem de seus direitos e responsabilidades no uso das informacoes em formato digital, permitindo-o empoderar-se de seu real status de cidadao. Assim, esse compreende o novo significado a ser ofertado para aquele valor diante dos reflexos da era tecnologica. Nessa linha, o caminho para a implantacao efetiva desse novo conceito para educacao, primeiramente, relaciona-se a seara previa a sua insercao nas ordens juridicas, pois, com base na teoria critica dos direitos humanos de Herrera Flores, essa deve ser entendida como um produto cultural no intuito de ser contextualizada as peculiaridades daquela sociedade, alem de utilizar a metodologia relativa a Andragogia (Educacao para Adultos), segundo a qual, por meio de bases teoricas de Malcolm Knowles e Paulo Freire, tem-se o procedimento viavel a possibilitar a concretizacao do referido direito fundamental quando aplicado na realidade social tecnologica brasileira, objetivando a realizacao da dignidade humana dos seus cidadaos e, por conseguinte, de um dos ditames do Estado Democratico de Direito.	numerical aperture	Catarine Gonçalves Acioli	2015			philosophy;performance art	Vision	-106.19094117195968	18.153258743821816	18951
add541da0e9742984c274f6adb92c6909e6b234b	differentiated services-konzepte und erste erfahrungen	differentiated service	Dr.-Ing. Richard Hofmann, Studium der Elektrotechnik an der Universität Erlangen-Nürnberg, Promotion 1993. Leiter der Gruppe Messung, Modellierung und Bewertung von Rechensystemen am Lehrstuhl Informatik 7 der Universität Erlangen (Prof. Dr.-Ing. U. Herzog). Seit 1998 Leiter des DFG-Projektes „Methodik und Werkzeuge zur Entwicklung optimierter Echtzeitsysteme im Kontext von SDL/MSC und VHDL“. Forschungsschwerpunkte: Monitoring, Rapid Prototyping, HW/SW-Codesign.	differentiated services;rapid prototyping;vhdl	Ursula Hilgers	2000	Praxis der Informationsverarbeitung und Kommunikation	10.1515/PIKO.2000.81	differentiated service;computer science	OS	-99.69418242913994	32.15129995217116	18974
57347bd412e55dc8ac3bf7a486cb973b56280c94	a study on a combined model in business intelligence for improving electronic insurance	quality function deployment;kano model;business intelligence;electronic insurance	Business intelligence is one of the tools of IT in business and Information systems for management have been just developed theoretically, and have never fulfilled the demands of organizations, practically. The establishment and marketing of electronic insurance demands the readiness of tools and the foundation of IT. Business intelligence provides the managers with a collection of tools, techniques and methods in order to help them in better understanding of business state. Business intelligence techniques are applied by an optimized pattern in electronic insurance industry which its basis is merging two significant models in this field known as Kano Model and Model of Quality Function Deployment (QFD). Kano Model tool is a questionnaire filled by customers which they should answer to the questions with two positive and negative alternatives. These answers will lead to understanding quality demands of customers and considering basic demands, practical demands as well as motivational ones. A Study on a Combined Model in Business Intelligence for Improving Electronic Insurance	information system;quality function deployment;software deployment	Mahdi Bazargani;Elnaz Namazi	2015	IJBIR	10.4018/IJBIR.2015010104	quality function deployment;computer science;knowledge management;artifact-centric business process model;kano model;data mining;electronic business;management science;business intelligence;business rule;new business development;line of business;business activity monitoring	DB	-78.79470045899282	8.077091717895014	18981
ac575172198eaf22364265c3cba89d64c3833f2f	extraction de code fonctionnel certifié à partir de spécifications inductives. (extraction of certified functional code from inductive specifications)				Pierre-Nicolas Tollitte	2013				PL	-104.14368012216876	13.171713460757536	19014
e84bc99cc8544cb8490a243e19f82f2207fcb331	loop invariants in floating point algorithms	verification resultat;boucle programme;rounding errors;arrondissement dirige;bucle programa;algorithme;algorithm;numerical algorithm;invariante;program loop;floating point;aritmetica intervalo;coma flotante;error redondear;interval arithmetic;arithmetique intervalle;invariant;rounding error;virgule flottante;erreur arrondi;algoritmo	It will be shown that by using directed roundings resp. enclosure sets for the exact values, the loop conditions and loop invariants of numerical algorithms can be generalized for computing in a discrete screen. On this way, in spite of rounding errors, it is possible to verify the received results. Thereby only inherent properties of the algorithms are used, which moreover guarantee that the loops terminate. Es wird gezeigt, daß unter Benutzung von gerichteten Rundungen bzw. Einschließungsmengen für die jeweils exakten Werte Schleifen-Bedingungen und Schleifen-Invarianten aus den für das exakte Rechnen aufgestellten numerischen Algorithmen auf naheliegende Weise für das Rechnen in Gleitpunktrastern verallgemeinert werden können. Dadurch ist trotz des Auftretens von Rundungsfehlern eine Verifikation der erhaltenen Ergebnisse möglich. Verwendet werden dazu nur dem Algorithmus innewohnende Eigenschaften, die gleichzeitig ein Terminieren der Schleifen bewirken.	algorithm;eine and zwei;loop invariant;numerical analysis;round-off error;rounding;terminate (software)	Karl-Udo Jahn	1993	Computing	10.1007/BF02243815	loop tiling;loop fusion;mathematical optimization;discrete mathematics;floating point;invariant;round-off error;mathematics;interval arithmetic;algorithm	HPC	-96.67541709180988	35.97218625778974	19027
c020a1b19f659912abd03a53226a0e7125620584	performative and lexical knowledge sharing in agile requirements		We present the results of our field study that describe how requirements knowledge was shared at an industrial software company using agile software practices. As is common in agile processes, the team did not capture requirements knowledge in a comprehensive specification document. Instead, requirements knowledge was captured in user stories, automated acceptance tests, personal notes, and conversations. We identified two modes of knowledge sharing: performative and lexical. Performative knowledge, which occurs through actions such as question-asking, gestures, and informal speeches, was observed in conversations and at the Scrum board. Lexical knowledge sharing, which occurs through inscribed texts, was observed in testing wiki and the software release documents. We found that the software team relied mainly on performative knowledge sharing. Although team members shared few written documents, they were able to effectively develop software that satisfied customer requirements. Results from our field study have implications for both agile practitioners and knowledge management. The former could encourage question-asking to provide opportunities for performative knowledge sharing. The latter could pay attention to personal management so that users can more effectively engage in performative knowledge sharing.	agile software development;requirement	Susan Elliott Sim;Rosalva E. Gallardo-Valencia	2013		10.1007/978-3-642-34419-0_9	acceptance testing;software;agile software development;user story;software release life cycle;performative utterance;knowledge sharing;computer science;knowledge management;scrum	Robotics	-70.79907812855805	24.835540545141168	19038
c81a8bc8851d99b254957ed70cfd82011bd95766	managing knowledge in it projects: a framework for enterprise system implementation	knowledge requirements;knowledge activities;enterprise systems;it projects;erp;project knowledge management	Purpose – The purpose of this study is to explore the knowledge management (KM) perspective of information technology (IT) projects based on enterprise system (ES) implementations. The study determined what knowledge is needed in each of the project phases (what for, from what sources), how this knowledge is transformed during the project (what knowledge activities are performed concerning this knowledge) and what knowledge-related artifacts are created. A KM framework for ES projects is formulated based upon the results. Design/methodology/approach – The research has a qualitative exploratory design based on multiple data sources: documentation, semi-structured interviews and participant observation. A coding procedure was applied with the use of a pre-defined list of codes, as derived from KM literature regarding knowledge types, actors, project phases and activities. Open coding was used to determine the role of each type of knowledge in the implementation process. Findings – The study examined the sig...	enterprise system	Przemyslaw Lech	2014	J. Knowledge Management	10.1108/JKM-01-2014-0006	knowledge base;enterprise system;organizational learning;knowledge integration;computer science;knowledge management;knowledge engineering;management science;personal knowledge management;knowledge value chain;domain knowledge	Web+IR	-68.00478193571614	13.729218065507819	19067
cc3b9e78e72c418729a1752107d2f322361221d9	performance evaluation framework design for smart sensor business		RFID is a technology to identify objects such as products and things with radio frequencies, which is recognized as a basic technology to realize ubiquitous society and has attracted significant attention of government, industries, and academic world. In addition, RFID has an enormous ripple effect as a killer application on a variety of business areas including logistics/distribution, military, or food/safety in particular because of a high identification rate, contactless identification media, propagation range, and scalability being able to connect and communicate with other communication networks. But there are insufficient studies of analyzing quantitative effects on economic effectiveness generated after implementing RFIDs through empirical analysis. Therefore, this study analyzed economic effect that can be obtained by implementing RFIDs into companies. Based on the study results, common effects were concentrated on the primary benefit, and the administration and management work had common effects of the third benefit.	contactless smart card;fractal dimension;inventory control;killer application;logistics;performance evaluation;radio frequency;radio-frequency identification;ripple effect;scalability;smart transducer;software propagation;telecommunications network;xfig	Hangbae Chang	2017	The Journal of Supercomputing	10.1007/s11227-017-2130-7	computer science;telecommunications network;distributed computing;scalability;government	HCI	-70.64540211436535	49.38544731057099	19154
b0692bd5877a4fe73f9e7e84105a77f1914259ae	environment information systems: study of the software productivity.	information system		information system	M. J. B. Garcia;Jean Claude Alvarez	1995			executive information system;global information system;information engineering;computer science;knowledge management;package development process;software development;software asset management;management information systems;systems development life cycle;software analytics;software deployment;information system;software system	SE	-64.21375506770104	21.678793304458917	19164
4f56652657ee193e38b6072b382963b00755b8b1	what's at steak? exploring engineering methodologies to identify existing generational boundaries impeding the strategic transfer of engineering and architectural knowledge (steak)	generational knowledge transfer;knowledge management;knowledge boundaries;knowledge transfer;knowledge management knowledge engineering;knowledge management methodologies strategic transfer of engineering and architectural knowledge steak pertinent engineering knowledge knowledge transfer boundary frameworks;knowledge management generational knowledge transfer knowledge transfer knowledge boundaries;knowledge transfer knowledge engineering organizations retirement industries cultural differences;knowledge engineering	This paper aims to explore the premise that without proper identification of the engineering generational knowledge transfer boundaries, there will be a significant loss of engineering knowledge. In order to share or transfer pertinent engineering knowledge at a pace equivalent to the increase in engineering retirements, the engineering generational knowledge transfer boundary must be clearly identified and defined. Identifying these boundaries will enable the strategic transfer of engineering and architectural knowledge (STEAK) across generational boundaries. Existing knowledge transfer boundary frameworks, models and methodologies will be explored to clearly identify the engineering generational knowledge transfer boundaries and create a STEAK Model. Relevant knowledge management methodologies can also be incorporated and used to categorize a set of core techniques to be used in this knowledge management process. The methodologies used to develop the STEAK Model will be aimed at bringing knowledge management benefits to an engineering organization. This model will be used to identify and illustrate a knowledge transfer structure that integrates engineering generational knowledge. This “inherent approach” will also be used to evaluate the implications associated with the loss of required knowledge held by exiting engineers if this knowledge is not imparted to incoming inexperienced engineers.	categorization;experience;garbage collection (computer science);knowledge management;relevance;software engineer	Santia M. Davis;Shahram Sarkani;Thomas A. Mazzuchi	2011	Proceedings of the 2011 15th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2011.5960214	organizational learning;computer science;knowledge management;artificial intelligence;body of knowledge;knowledge engineering;management science;personal knowledge management;knowledge value chain;domain knowledge	DB	-75.74689374452396	9.392985895716619	19187
b5a7d1a43cd977c72f7bb3ef21d0e306ea4bdf5a	towards improving adaptability of capability driven development methodology in complex environment		We are triggered to incorporate adaptability in information system designs and methodologies corresponding to complex and unpredictable environment of today and tomorrow and to complex adaptive systems they are aimed for. Adaptability as non-functional requirement is being portrayed and investigated from broad multidisciplinary perspective that influences how dynamic business-IT alignment can be accomplished. Capability Driven Development methodology has supported delivering dynamic capabilities by providing context-aware self-adaptive platform in the CaaS project implementations, as our case study. Along with the already incorporated mechanisms, components that enable adaptability, there is open space for further evolutionary and deliberate change towards becoming truly appropriate methodology for dynamic reconfigurations of capabilities in organizations and business ecosystems that operate in complexity and uncertainty. The analysis and evaluation of adaptability of the CDD methodology through three dimensions (complexity of the external and internal environment, managerial profiling and artifact-integrated components) in this paper conclude with instigation of starting points towards achieving higher adaptability for complexity of the CDD methodology.		Renata Petrevska Nechkoska;Geert Poels;Gjorgji Manceski	2018		10.1007/978-3-319-92898-2_2	implementation;systems engineering;dynamic capabilities;multidisciplinary approach;profiling (computer programming);computer science;information system;adaptability;non-functional requirement;complex adaptive system	Robotics	-73.31898427894804	11.094450934762389	19193
b603bc55696e099aafa1b254d465b24b4eb3dea4	perceived language complexity in github issue discussions and their effect on issue resolution		Modern software development is increasingly collaborative. Open Source Software (OSS) are the bellwether; they support dynamic teams, with tools for code sharing, communication, and issue tracking. The success of an OSS project is reliant on team communication. E.g., in issue discussions, individuals rely on rhetoric to argue their position, but also maintain technical relevancy. Rhetoric and technical language are on opposite ends of a language complexity spectrum: the former is stylistically natural; the latter is terse and concise. Issue discussions embody this duality, as developers use rhetoric to describe technical issues. The style mix in any discussion can define group culture and affect performance, e.g., issue resolution times may be longer if discussion is imprecise. Using GitHub, we studied issue discussions to understand whether project-specific language differences exist, and to what extent users conform to a language norm. We built project-specific and overall GitHub language models to study the effect of perceived language complexity on multiple responses. We find that experienced users conform to project-specific language norms, popular individuals use overall GitHub language rather than project-specific language, and conformance to project-specific language norms reduces issue resolution times. We also provide a tool to calculate project-specific perceived language complexity.	best-effort delivery;conformance testing;conformity;futures studies;issue tracking system;jargon;language model;open sound system;open-source software;overfitting;relevance;social network;software development;software engineering;threat (computer);tracing (software)	David Kavaler;Sasha Sirovica;Vincent Hellendoorn;Raúl Aranovich;Vladimir Filkov	2017	2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)		data science;theoretical computer science;computer science;software development;software;rhetoric;language model;language complexity;pragmatics;multimedia;fuzz testing;norm (social)	SE	-71.13292327557302	24.883648056237977	19198
f3059fb0c8e6a1acfa954d99336cdb3437fa21bb	initiative „sicheres online-banking“ gibt phishing keine chance		750 DuD • Datenschutz und Datensicherheit 30 (2006) 11  kation „OneTimePass mobile“ komfortabel via Funk. Die deutsche Rentenversicherung präsentierte ihren eService, der es Versicherten und Rentnern ermöglicht, Anträge und Anfragen online zu erledigen. Über die Authentisierung mit einer Signaturkarte können ohne Medienbruch Renten, Rehabilitationsmaßnahmen, bargeldlose Beitragsentrichtung und Kontenklärungen beantragt werde. Der österreichische Hersteller biometrischer Systeme ekey zeigte ekey WORLDwide, das anonyme Authentifizierungen für unterschiedliche Anwendungen, Programme und Dienste per Fingerabdruck bietet. Das Verfahren trennt die personenbezogenen Daten, die beim Anbieter verbleiben, von den biometrischen Daten, die in einem sicheren Rechenzentrum gespeichert sind. Dies verhindert den Missbrauch von Daten, weshalb die hochsichere Anwendung auch im elektronischen Zahlungsverkehr, Banking und Ticketing eingesetzt wird. Für die elektronische Handelsregisteranwendung erhielten Bundesnotarkammer und NotarNet eine Preisnominierung. Ca. 9.500 Notare und mehrere hundert Registergerichte bundesweit nutzen das Verfahren, das durch die automatisierte Weiterverarbeitung von Daten den Aufwand verringert und das Verfahren beschleunigt. Um der Menge der preiswürdigen Anwendungen, die sich um den Innovationspreis bewarben, besser gerecht werden zu können, hat TeleTrusT in diesem Jahr den besten Anwärtern auf den Preis die Möglichkeit eingeräumt, ihr Produkt auf der ISSE 2006 in Rom vor der versammelten europäischen Fachwelt zu präsentieren. Weitere Informationen unter: www.tsystems.de/innovationspreis und www.teletrust.de.	circa;eine and zwei;online banking;phishing;read-only memory;security engineering;unified model;vhf omnidirectional range	Helmut Reimer	2006	Datenschutz und Datensicherheit - DuD	10.1007/s11623-006-0219-x	world wide web;computer security	AI	-103.33963675507823	36.72545162267189	19204
06636c824dbfef434e099f5f170d9e8d4fbedb36	repeating the past experimental and empirical methods in system and software security	laufzeit;computersicherheit;analyse;software security;experiment	I propose a new method of analyzing intrusions: instead of analyzing evidence and deducing what must have happened, I find the intrusion-causing circumstances by a series of automatic experiments. I first capture process';s system calls, and when an intrusion has been detected, I use these system calls to replay some of the captured processes in order to find the intrusion-causing processes—the cause-effect chain that led to the intrusion. I extend this approach to find also the inputs to those processes that cause the intrusion—the attack signature. Intrusion analysis is a minimization problem—how to find a minimal set of circumstances that makes the intrusion happen. I develop several efficient minimization algorithms and show their theoretical properties, such as worst-case running times, as well as empirical evidence for a comparison of average running times. Our evaluations show that the approach is correct and practical; it finds the 3 processes out of 32 that are responsible for a proof-of-concept attack in about 5 minutes, and it finds the 72 out of 168 processes in a large, complicated, and difficult to detect multi-stage attack involving Apache and suidperl in about 2.5 hours. I also extract attack signatures in proof-of-concept attacks in reasonable time. I have also considered the problem of predicting before deployment which components in a software system are most likely to contain vulnerabilities. I present empirical evidence that vulnerabilities are connected to a component';s imports. In a case study on Mozilla, I correctly predicted one half of all vulnerable components, while more than two thirds of our predictions were correct.  #N#Ich stelle eine neue Methode der Einbruchsanalyse vor: Anstatt Spuren zu analysieren und daraus den Ereignisverlauf zu erschliesen, finde ich die einbruchsverursachenden Umstande durch automatische Experimente. Zunachst zeichne ich die Systemaufrufe von Prozessen auf. Nachdem ein Einbruch entdeckt wird, benutze ich diese Systemaufrufe, um Prozesse teilweise wieder einzuspielen, so dass ich herausfinden kann, welche Prozesse den Einbruch verursacht haben —die Ursache-Wirkungs-Kette. Ich erweitere diesen Ansatz, um auch die einbruchsverursachenden Eingaben dieser Prozesse zu finden — die Angriffs-Signatur. Einbruchsanalyse ist ein Minimierungsproblem — wie findet man eine minimale Menge von Umstanden, die den Einbruch passieren lassen? Ich entwickle einige effiziente Algorithmen und gebe sowohl theroretische Eigenschaften an, wie z.B. die Laufzeit im ungunstigsten Fall, als auch empirische Ergebnisse, die das mittlere Laufzeitverhalen beleuchten. Meine Evaluierung zeigt, dass unser Ansatz korrekt und praktikabel ist; er findet die 3 aus 32 Prozessen, die fur einen konstruierten Angriff verantwortlich sind, in etwa 5 Minuten, und er findet die 72 von 168 Prozessen, die fur einen echten, komplizierten, mehrstufigen und schwer zu analysierenden Angriff auf Apache und suidperl verantwortlich sind, in 2,5 Stunden. Ich kann ebenfalls Angriffs-Signaturen eines konstruierten Angriffs in vernunftiger Zeit erstellen. Ich habe mich auch mit dem Problem beschaftigt, vor der Auslieferung von Software diejenigen Komponenten vorherzusagen, die besonders anfallig fur Schwachstellen sind. Ich bringe empirische Anhaltspunkte, dass Schwachstellen mit Importen korrelieren. In einer Fallstudie uber Mozilla konnte ich die Halfte aller fehlerhaften Komponenten korrekt vorhersagen, wobei etwa zwei Drittel aller Vorhersagen richtig war.	application security	Stephan Neuhaus	2008			telecommunications;engineering;performance art	Logic	-100.70433185245773	32.99253221091809	19232
17b1fc94b5ed9827380d3299c5f7288831b56ec9	evaluation d'une mesure de similitude en classification supervisée : application à la préparation de données séquentielles. (supervised learning from sequential data)		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Evaluation d’une mesure de similitude en classification supervisée : application à la préparation de données séquentielles Sylvain Ferrandiz	archive;comefrom;hal;linear algebra;supervised learning	Sylvain Ferrandiz	2006				ML	-107.53138586602671	11.935782672969387	19248
3335bd27582d06dd2a41496b1d98a605a6bbfda9	exploring the dimensions of electronic government service quality		Information and communication technology is progressively evolving around the world. Organizations and providers of online services, have to keep up with technological advancements when providing services and meet the redoubling expectations of its customers. At a global level there is wider adoption of e-government, a term coined in the recent past to describe the methodology that implements technology efficiently with quality of service for the general public’s administration in a government setting. This research proposes a scale for measuring quality dimension in setting of e-government by an extensive review of literature from last 3 decades and by revising the SERVQUAL scale. The proposed scale is based on 25 items and six quality dimensions namely: reliability, responsiveness, ease of use\usability, website design\content, and security\ privacy. This research is fruitful for organizations to assess, measure, and improve the quality of service concerning the e-government services they offer. Keywords-component; Service quality, E-service quality, Egovernment service quality, Determinant of quality, measurements of quality, Factors of E-service quality, Measurement of quality	e-government;e-services;quality of service;responsiveness;servqual	Tasira Al Balushi;Saqib Ali	2016		10.18293/SEKE2016-061	computer science;systems engineering;service quality;government	Web+IR	-79.22190664385775	12.20057305573018	19255
0243a37359c275d69445098d59f7fd830885143a	construction, instantiation and analysis of a business ecosystem for autonomic future networks	autonomics;analytical models;complexity theory;biological system modeling;business model autonomics autonomic networking business ecosystem;autonomic networking;business communication;next generation networks business communication;business biological system modeling iptv ecosystems complexity theory analytical models ip networks;business model;business ecosystem;ecosystems;business model business ecosystem autonomic future networks;business;ip networks;next generation networks;iptv	Design, deployment and operations of future networks are expected to tackle a diverse range of business and technical challenges, such as how to empower networks with features of self-adapting to dynamic context and users' requirements, allowing for the emergence of disruptive business models and new industrial ecosystems. This paper focuses on defining and analysing two business scenarios in order to study the impacts of introducing autonomic networks. By identifying the business roles and relationships between them and business and strategic issues that may arise, we aim at establishing an overarching business ecosystem and a common reference model reflecting the challenges and opportunities of autonomic networking.	autonomic networking;business ecosystem;emergence;industrial robot;reference model;requirement;software deployment;universal instantiation	Vânia Gonçalves;Makis Stamatelatos;Antonio Manzalini;Beatriz Fuentes Arenaz;Markus Gruber;Christian Destré;Simon Delaere;Laurent Ciavaglia	2011	2011 15th International Conference on Intelligence in Next Generation Networks	10.1109/ICIN.2011.6081077	business analysis;business transformation;business requirements;systems engineering;knowledge management;artifact-centric business process model;business case;management science;business;business relationship management;new business development;business process modeling;business activity monitoring;business architecture	Mobile	-73.87848836143787	9.315750789003486	19275
03b51f062002b7569941656219861cf04dbb4571	unternehmenskultur in internet-unternehmen: gestaltungsmöglichkeiten durch gründer und führungskräfte				Carolina Catrin Schnitzler	2003				NLP	-97.17281814021267	23.367141452962052	19310
d2c1b6a396a6963f24aaa66d7fbea35cda1f02e3	e-shop-features from a customer's point of view - results of a conjoint analysis	conjoint analysis;point of view	Die wirtschaftliche Bedeutung des E-Commerce hat in den letzten Jahren weiter zugenommen, und es ist anzunehmen, dass zukünftig diese Entwicklung weiter anhält. Die Zahl der Unternehmen, die ihre Aktivitäten im Business-to-Consumer Bereich aufoder ausbauen, nimmt beständig zu. Aktuellen Studien zufolge wird das World Wide Web auch auf Seiten der Kunden als Transaktionsmedium zunehmend akzeptiert und genutzt. Nach Angaben des Hauptverbandes des Deutschen Einzelhandels entfielen 2000 lediglich 0,67 Prozent des Gesamtumsatzes von rund 740 Mrd. DM auf den Online-Handel (o.V. 2001a S. 1), doch Studien der GfK und TNS Emnid zufolge stiegen in Deutschland im Vergleichszeitraum des zweiten Halbjahrs 2000 und der ersten Hälfte 2001 sowohl der Umsatz im Onlinehandel um 50 Prozent (o.V. 2001b S.1) als auch die Zahl der Online-Einkäufer um 11 Prozent (o.V. 2001c S. 1). Ähnlich dem stationären Handel ist im WWW ein entscheidender Faktor bei der Kundengewinnung und Kaufrealisierung die direkte Schnittstelle zwischen Unternehmen und Kunden. Die vom Kunden wahrgenommene Schnittstelle stellt bei e-Shops die einzelne Webpage dar. Der Shopbenutzer beurteilt die einzelnen formalen und inhaltlichen Merkmale der Website hinsichtlich der Zweckmäßigkeit seiner Intentionsrealisierung. Diese subjektive Nutzenanalyse der Websiteelemente durch den Shopbesucher entscheidet maßgeblich über sein weiteres Verhalten im e-Shop. Die Kenntnis der Nutzenerwartungen und die Einschätzung der relativen Wichtigkeit der Shopelemente durch den Shopnutzer ist demnach als entscheidender Erfolgsfaktor einzustufen und sollte auch Gegenstand wissenschaftlicher Forschung sein. Die erste Fragestellung, Günter Silberer, Jan-Frederik Engelhardt und Nils Wasmuth	bibliothèque de l'école des chartes;e-commerce payment system;handel;job shop scheduling;paintshop pro;triple des;unified model;www;web page;world wide web	Günter Silberer;Jan-Frederik Engelhardt;Nils Wasmuth	2002	i-com	10.1524/icom.2002.1.2.024	computer science;conjoint analysis	DB	-102.47685108341263	36.224294726780435	19346
818f59b20688ca030ba767a60f78b7bf53f32767	measuring crm and scm benefits: a preliminary measurement model	benefits and impacts content analysis;customer relationship management;enterprise systems;swinburne;supply chain management;080609 information systems management	Organizations invest heavily in Customer Relationship Management (CRM) and Supply Chain Management (SCM) systems, and their related infrastructure, presumably expecting positive benefits to the organization. Assessing the benefits of such applications is an important aspect of managing such systems. Considering the salient differences between CRM and SCM applications with other intra-organizational applications, existing Information Systems benefits measurement models and frameworks are ill-suited to gauge benefits of inter-organizational systems. This paper reports the preliminary findings of a measurement model developed to assess benefits of CRM and SCM applications. The preliminary model, which reflects the characteristics of the Analytic Theory, is derived using a review of 55 academic studies and 44 papers from the practice. Six hundred and six identified benefits were then synthesized in to 74 non-overlapping benefits, arranged under six	customer relationship management;digital rights management;information system;organizational behavior	Wenjuan Wang;Darshana Sedera;Felix B. Tan	2009			systems engineering;engineering;marketing;operations management	Metrics	-78.309013668893	7.744820871654124	19358
57dd68cd55d29c72315a0c505ff2d659147654a7	github, technical debt, code formatting, and more	aadl;uml;continuous architecting;architecture analysis and design language;aqaf;software engineering;technical debt;architectural quality;machine learning;software development;model driven engineering;github;caffea;code formatting;architecture quality assurance framework;open source;continuous architecture framework for embedded and agile software development;code smells	This issue's column reports on papers from the 19th International Conference on Model Driven Engineering Languages and Systems, the 2016 ACM SIGPLAN International Conference on Software Language Engineering, the 12th International ACM SIGSOFT Conference on the Quality of Software Architectures, and the 13th Working IEEE/IFIP Conference on Software Architecture. Topics discussed include GitHub and open source, technical debt in model-driven engineering, a universal code formatter, assuring architectural quality, and continuous architecting.	technical debt	Jeffrey C. Carver;Jordi Cabot;Rafael Capilla;Henry Muccini	2017	IEEE Software	10.1109/MS.2017.51	unified modeling language;model-driven architecture;computer science;systems engineering;software development;software engineering;technical debt;programming language;code smell;computer engineering	Visualization	-62.98597781769465	25.579158684243858	19373
c50b3fe63a91013e9a9f3131a29a34b1b54a1b2a	ein neues teleteaching-konzept		Dipl.-lng. Olaf Götz, Informatikstudium an der TU Dresden mit den Schwerpunkten Systemprogrammierung und Leistungsbewertung von DV-Syste/ men. Von 1986 bis 1990 Mitarbeiter im l^ Datenverarbeitungszentrum Gera, ; 1990 bis 1996 Geschäftsführer eines BüroVDV-Unternehmens in Gera. Seit 1996 wissenschaftlicher Mitarbeiter im Rechenzentrum der Friedrich-SchillerUniversität Jena. Arbeitsgebiete: Applikationen in Hochgeschwindigkeitsnetzen, speziell Teleteaching, Videokonferenzsysteme, Audiound Videodatenübertragung. Gründung eines Referenzzentrums für multimediale Telekommunikation.		Olaf Götz;Bernd Fankhänel	1998	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1998.21.1.31	computer science;distributed computing	DB	-100.9283351238836	30.611529978699973	19382
cbb820dc467667568ae3fa6b9b3d434e7f12e9b3	business value of partner's it intensity: value co-creation and appropriation between customers and suppliers	business value of it;enterprise 2 0 technologies;it intensity;inter organizational relationships	There is a rapid increase in the use of enterprise technologies, such as enterprise portals, CRM, RFIDs, and partner interface systems. Often defined as Enterprise 2.0 technologies, social communication technologies, such as blogs and wikis are further increasing the range of ITs used by firms. Greater use of these Enterprise 2.0 technologies is changing the ways organizations transact with partners, as IT systems become predominant means to communicate, coordinate, analyse, conceptualize, and respond. As these technologies increase the information content of work, IT intensity of firms is becoming an increasingly important asset for doing business. To leverage enterprise technologies, firms are increasing IT intensity by making greater investments in more modular, user-friendly, integrated, and customized ITs. Greater IT intensity changes how a firm transacts business and inter-organizational relationships. However, the effects of increased IT intensity on inter-organizational relationships are not clear. In this study, we address this gap and assess how a firm’s IT intensity influence inter-organizational value. Using the data from customer-supplier dyads, we examine partner-related value creation, co-creation, and appropriation of value between firms within customer-supplier relationships. Using the Compustat database as our source of financial information from publicly-traded firms, we identify 5868 unique dyadic pairs of customer-supplier over the period 1991 to 2005 and hypotheses are tested using a sample of 15,028 customer-supplier dyad-years. IT spending for each firm is based on data available from InformationWeek magazine. Our results indicate that a partner’s IT usage co-creates value for both partners. We show a strong positive relation between customer and supplier IT spending intensity and corresponding profitability— measured as the firm’s excess gross profit relative to industry levels — for both customer and supplier firms as well as the combined dyad. Also, contrary to views that larger customers exploit smaller suppliers, our study finds that an increased IT intensity enhances the probability of value being generated for both the partners in a dyad.		Pankaj Setia;Vernon J. Richardson;Rodney J. Smith	2015	Electronic Markets	10.1007/s12525-015-0189-7	marketing;operations management;business value;management;enterprise value;commerce	ECom	-82.58881021054204	6.437044576754279	19399
9b6196a4108a2570de6256c6598d11868bf21e9f	analyse spatiale et cartes animées : construction d'un prototype d'animation des dynamiques démographiques			prototype	Laurent Ségura	2003	Revue Internationale de Géomatique	10.3166/rig.13.93-105	computer graphics (images);animation;computer science	Crypto	-102.32245731517703	13.105295136920088	19474
4075c8b668bb91efe021c4265ede784067d5f918	an interview protocol for discovering and assessing collaboration engineering opportunities	protocols business data processing groupware;non profit organization;protocols;groupware;community of practice;collaborative work;nonprofit organizations interview protocol collaboration engineering projects collaborative work high value recurring tasks value frequency model collaboration engineers large multinational organization;collaborative engineering;knowledge worker;protocols collaborative work international collaboration time to market frequency investments costs testing knowledge engineering standards organizations;business data processing;profitability;work practice	Collaboration engineering (CE) projects can run for months and can require substantial expenditures of effort and resources. CE is an approach to designing collaborative work practices for high-value recurring tasks and transferring those designs to practitioners to execute for themselves without the ongoing intervention of professional facilitators. Because CE projects can entail considerable cost, it would be useful to establish a basis for predicting whether such efforts would be likely to result in a self-sustaining and growing community of practice for the resulting work practice. In this paper we use the value frequency model (VFM) to derive an interview protocol to identify new CE opportunities and to assess whether a CE solution would be likely to succeed. We then test the protocol in two cases; one with experienced collaboration engineers in a large multinational organization and a second with a group of knowledge workers with no CE experience working with a variety of profit and non-profit organizations. The findings appear to be consistent with the theory, suggesting that the interview protocol may be a useful tool for discovering and assessing CE opportunities. We propose several directions for future research.		Robert O. Briggs;Alanah J. Davis;John D. Murphy	2008	Proceedings of the 41st Annual Hawaii International Conference on System Sciences (HICSS 2008)	10.1109/HICSS.2008.61	public relations;communications protocol;computer science;knowledge management;marketing;software engineering;management science;management;collaborative software;profitability index	SE	-82.22717596079923	5.758488136761536	19505
71291c7085a2b2b28adfb7bba6044a8892f6137e	erstellen von lautelementebibliotheken unter verwendung von phonemclustern auf der grundlage des lpc-sprachsyntheseverfahrens				Shahla Sehhati	1995				Crypto	-101.12884717106583	26.951110804604163	19529
44baf1510337098024fd1726767423fe2ec77ba8	what are the most important criteria for cloud service provider selection? a delphi study		Selecting an appropriate cloud service provider (CSP) is one of the most important challenges affecting sourcing performance. Although cloud computing (CC) relies on the principle of information technology outsourcing (ITO), it remains unclear if selection criteria for ITO provider hold true. Hence, the purpose of this research is to identify the most important criteria for the selection of cloud service providers (CSP). We do this by conducting a Delphi study which includes 16 cloud service decision makers across different cloud service models, company sizes, and industry types. Our results show consensus on CSP selection criteria and identify functionality, legal compliance, contract, geolocation of servers, and flex-ibility as top five CSP selection criteria. From a theoretical perspective, we demonstrate that results from ITO research hold true for CC research as differences in delivery model and arrangement between ITO and CC will be considered. Practitioners like CSP and cloud decision makers get guidance from our findings to conduct optimal cloud service investments. This is the first study which provides a com-prehensive view on relevant criteria for CSP selection.	delphi (online service)	Michael Lang;Manuel Wiesche;Helmut Krcmar	2016			legal compliance;knowledge management;marketing;cloud computing;geolocation;information technology;outsourcing;delphi method;server;computer science	HCI	-79.72643972358648	12.459593154286917	19537
0fad9d96dc3de272e98c5928e7fec58e10d7ff87	population games with networking applications	jeux d evolution jeux de population jeux stochastiques jeux differentiels champs moyens jeux avec contraintes reseaux sans fils gestion d energie allocation de ressources en francais;evolutionary games population games stochastic games differential games mean field games constrained games wireless networks energy management resource allocation	HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Population games with networking applications Hamidou Tembine	archive;comefrom;hal;linear algebra;population	Hamidou Tembine	2009			extensive-form game;sequential game;theoretical computer science;bayesian game;simulations and games in economics education;normal-form game;combinatorial game theory;screening game;population;geography;artificial intelligence	ML	-108.90954064643896	11.35498957239225	19559
73455863ff52cf8e84214fa238f3ea3bae385ae1	information technology, contract completeness, and buyer-supplier relationships	business to business;information technology;transaction cost;interorganizational systems;buyer supplier relationship;market orientation;incomplete contracts;business to business relationships;contract theory;supplier selection	The theory of incomplete contracts has been used to study the relationship between buyers and suppliers following the deployment of modern information technology to facilitate coordination between them. Previous research has sought to explain anecdotal evidence from some industries on the recent reduction in the number of suppliers selected to do business with buyers, by appealing to relationship-specific costs that suppliers may incur. In contrast, this paper emphasizes the fact that information technology enables greater completeness of buyer-supplier contracts through more economical monitoring of additional dimensions of supplier performance. The number of terms included in the contract is an imperfect substitute for the number of suppliers. Based on this result, alternative conditions are identified under which increased use of information technology leads to a reduction in the number of suppliers without invoking relationship-specific costs. Conditions are also identified when increased use of information technology leads to an increase in the number of suppliers.		Rajiv D. Banker;Joakim Kalvenes;Raymond A. Patterson	2000		10.1287/isre.1060.0083	contract theory;transaction cost;economics;marketing;operations management;microeconomics;supplier relationship management;management;information technology;commerce	Logic	-81.65710702216812	5.887011698515621	19620
e1c54d735d69b640041b35cb2f5fc2a66814a469	on the critical success factors for b2b e-marketplace	e commerce;critical success factors;e marketplace	B2B e-marketplaces have a profound influence on the traditional market and on the way business is conducted. All kinds of e-marketplaces are emerging and developing now, and we have witnessed both successes and failures among these e-marketplaces. However, the failures are far outnumber the successes. Under this background, the paper discusses the critical success factors for operating e-marketplaces from different perspectives. It is shown that the core of e-marketplaces is to build liquidity and capture value. Based on these analyses, comprehensive critical factors including functional factors, strategic factors and technical Factors are discussed for the success of electronic marketplaces; then a tentative framework for the analysis on the critical success factors is proposed.	e-commerce	Jijian Li;Liwei Li	2005		10.1145/1089551.1089576	marketing;operations management;business;commerce	AI	-80.3537212640686	5.953949492603559	19625
01cb0dc092196559ac10e6d889cfee45785137cc	integrating data analytics and simulation methods to support manufacturing decision making	analytical models;standards;manufacturing;optimization	Modern manufacturing systems are installed with smart devices such as sensors that monitor system performance and collect data to manage uncertainties in their operations. However, multiple parameters and variables affect system performance, making it impossible for a human to make informed decisions without systematic methodologies and tools. Further, the large volume and variety of streaming data collected is beyond simulation analysis alone. Simulation models are run with well-prepared data. Novel approaches, combining different methods, are needed to use this data for making guided decisions. This paper proposes a methodology whereby parameters that most affect system performance are extracted from the data using data analytics methods. These parameters are used to develop scenarios for simulation inputs; system optimizations are performed on simulation data outputs. A case study of a machine shop demonstrates the proposed methodology. This paper also reviews candidate standards for data collection, simulation, and systems interfaces.	data collection;decision making;extraction;hl7publishingsubsection <operations>;review [publication type];simulation;smart device;streaming media;sensor (device);standards characteristics	Deogratias Kibira;Qais Hatim;Soundar Kumara;Guodong Shao	2015	2015 Winter Simulation Conference (WSC)	10.1109/WSC.2015.7408324	simulation;engineering;data science;data mining;management science;manufacturing	Robotics	-65.83484731882879	11.992867747754719	19692
ca4e470f8e0bc270dd6824a2b95e60dd3a70c809	entwurf und implementierung eines simulators für fertigungssysteme			institut für dokumentologie und editorik	Chengyan Shi	1994				NLP	-101.74329451128187	27.007905957497123	19709
9f81c7bdeb536d0a95b5c1983e2dc7b5d5e7e1ba	alois potton hat das wort				Alois Potton	1991	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1991.14.4.263	computer science;distributed computing;artificial intelligence	NLP	-95.72487583817632	24.120869890328315	19717
8aa6e5ccc1613163ddfcae8b1ef9716f4a65baa9	a systems engineering hackathon – a methodology involving multiple stakeholders to progress conceptual design of a complex engineered product		This paper describes a novel hackathon-style system engineering process and its value as an agile approach to the rapid generation and development of early design concepts of complex engineered products–in this case a future aircraft. Complex product design typically requires a diverse range of stakeholders to arrive at a consensus of key decision criteria and design factors, which requires effective articulation and communication of information across traditional engineering and operational disciplines. The application of the methodology is highlighted by means of a case study inspired by Airbus where stakeholder involvement and internal collaboration among team members were essential to achieve a set of agreed goals. This paper shows that a hackathon grounded on systems engineering approaches and structured around the technical functions within an engineering company has the capability and capacity to communicate a coherent vision and rationale for the conceptual design of a complex engineered product. The hackathon method offers significant benefits to these stakeholders to better manage, prioritize, and decrease excessive complexities in the overall design process. A significant benefit of this agile process is that it can achieve useful results in a very short timeframe (i.e., 80% reduction), where it could take up to a year to accomplish compared with using current/regular internal methods.	agile software development;biconnected component;coherence (physics);design rationale;hackathon;systems engineering	Sara Saravi;Demetrios Joannou;R. S. Kalawsky;Melanie Rose Nova King;I. Marr;M. Hall;Peter C. Wright;Ranjit Ravindranath;A. Hill	2018	IEEE Access	10.1109/ACCESS.2018.2851384	multiple-criteria decision analysis;software;computer science;systems architecture;conceptual design;product design;systems engineering;stakeholder;design process;agile software development	HCI	-63.976506844333095	14.05080854793978	19758
373849b68b530cdf83f7d4bd4adfb90a357239df	erweiterter it-wertbeitrag durch green business		Innerhalb einer heutzutage komplexen Value bzw. Supply Chain ist eine Optimierung der Geschäftsprozesse in Bezug auf Nachhaltigkeit nur durch die unterstützende Leistung der IT zu realisieren. Von der IT wird hierbei zunehmend eine aktive Beraterrolle verlangt. Bei der nachhaltigen Optimierung von Strukturen und Prozessen hat sie aufgrund ihrer internen Erfahrungen die Möglichkeit, sich als Treiber sowie Enabler im Unternehmen zu etablieren und so eine Ausweitung des IT-Wertbeitrags zu erreichen. Meinungen interviewter Experten bzw. erste Ergebnisse einer Fallstudie belegen diese These. Dennoch existiert — wie unsere Analyse zeigt — noch kein praxistaugliches Konzept, das den Aufbau sowie den Einsatz der dafür notwendigen IT-Ressourcen im Rahmen eines Green-Business-Ansatzes thematisiert.	eine and zwei;internet explorer;sie (file format)	Markus Neumann;Marc Klages;Michael H. Breitner	2010	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340490	management;marketing;engineering	OS	-101.36230724952708	34.301334659454454	19851
97482e34f616d8f1534bcf28fda7dc4f24fd3681	informationsproduktion statt informationsverwaltung - neue selbstvergewisserung der mediendokumentation				Marlies Ockenfeld;Luzian Weisel	2018	Inf. Wiss. & Praxis	10.1515/iwp-2018-0009		DB	-97.01798911907237	23.40211866962694	19857
509b55c23b500f44d67e1922d49cd39ee746d3d4	b2b performance evaluation model		Many business firms are planning, or practicing B2B, however, analysis on the performance of companies achieved by B2B has not been made sufficiently, and there isn't any evaluation method to determine whether B2B has been planned and practiced in an appropriate way. Therefore, we proposed B2B performance Evaluation Model , which is able to make in-depth evaluation of the company's performance caused by B2B and the overall factors that causes the performance in the planning, implementation and practicing process. Evaluation Model is developed by the analysis of the current situation through interviews as well as the conceptual framework based on theoretical studies. We proposed 4 type B2B performance evaluation models: buyer-oriented B2B, seller-oriented B2B, e-Marketplace for Participants, and e-Marketplace for Intermediary. And each of them consist of three part of evaluation index; B2B initiation, B2B planning & implementation, and B2B performance evaluation. Validity of each evaluation factors was verified by surveying the six experts using the Delphi method, and the weights of each factors were proposed.		Hyogun Kym;Han-Hee Lee;Hui-Jin Kim;Christopher Lee	2001			knowledge management;computer science	Web+IR	-78.21992019166223	9.53921742787221	19860
15982244310c514e826299b1821c767a3f212bcf	transfert de connaissance pour la compréhension des images. (knowledge transfer for image understanding)			linear algebra	Praveen Kulkarni	2017				Vision	-105.52075515513269	14.174735459241257	19865
d54e7728b42daa69cf368faebfe1048bc4bde3d8	approach to introducing a statistical quality control	statistics control charts electronics industry quality control;standards organizations;data collection;defect density;quality prediction statistical quality control sumitomo electric industries limited sumitomo electric information systems company limited business system x r chart u chart defect detection process size indicator;organizations quality control process control control charts standards organizations accuracy java;accuracy;control chart;control charts;electronics industry;process control;statistics;statistical quality control;organizations;information system;electricity industry;quality control;defect detection;java;steady state	This paper describes some examples and points about implementing a statistical quality control in developing business systems in Sumitomo Electric Industries, Ltd. and Sumitomo Electric Information Systems Co., Ltd. Although the X-R chart is often used in statistical quality control, it is recommended to introduce the u-chart if defects are to be controlled in future. If a defect detection process such as a review or a test does not reach a statistical steady state that indicates a process is stable on the control chart, an appropriate control could be conducted by not only further standardizing the process, but also reviewing the definition of size indicators. Quality prediction can be made possible by accumulating defect data collected to create a control chart and analyzing the distributions of introduced defect densities at an organization level. If the accuracy of quality prediction is low, it can be enhanced by carrying out improvements to narrow the widths of distributions of introduced defect densities.	information system;software bug;steady state	Nobuhiro Nakamura;Satoru Takahashi;Shinji Kusumoto;Kousuke Nakatsuka	2011	2011 Joint Conference of the 21st International Workshop on Software Measurement and the 6th International Conference on Software Process and Product Measurement	10.1109/IWSM-MENSURA.2011.25	reliability engineering;systems engineering;engineering;operations management	SE	-70.33098526969272	15.083583471079985	19916
ef110576ba10e1fcb712c8376adc53cf6cb70a1b	build it and they will contribute? erfahrungen mit einer enterprise 2.0 plattform	workshop		enterprise 2.0	Markus Heckner;Martin Wünnenberg	2009			enterprise 2.0;knowledge management;business	OS	-93.59473125722705	26.937371102598444	20006
9bbb238c23019b912a13a9274f778b7d5dba4308	entwurf und implementierung einer methodenbank und nutzung in der informatikausbildung im maschineningenieurwesen			institut für dokumentologie und editorik	Christian Wittetschek	1989				NLP	-101.49287475108927	26.766388920885795	20015
80559306a02c1c8a0f9c69acbb7c2e9c26831d99	reference architecture for integration platforms		In addition to in-house applications, networked enterprises are increasingly using data and services from various external sources. Conversion of data to useful information and IT alignment with business goals are big challenges faced by these enterprises. Integration platforms (IPs) aid enterprises in solving such challenges. However, the large number of commercial and academic IPs currently available have created a new problem for enterprises, namely whether to build their own IP or buy/rent a existing IP. Also, how to choose from the plethora of different design/solution options that are available? This paper presents a study and analysis of 31 IPs to bring out best practices in IP design. Following a commonality analysis of IPs from different research domains, an IP reference architecture is proposed. The reference architecture will aid enterprises in making better IP design/solution choices. It can also contribute to IP research by acting as a common reference point for future IP analysis.	best practice;integration platform;interoperability;reference architecture;relevance;traffic collision avoidance system;word lists by frequency	Prince Mayurank Singh;Marten van Sinderen;Roel Wieringa	2017	2017 IEEE 21st International Enterprise Distributed Object Computing Conference (EDOC)	10.1109/EDOC.2017.24	data mining;systems engineering;computer science;software;best practice;reference architecture;interoperability	DB	-68.25734505877924	12.245563167879158	20032
9d80f8078abe114abec06a074263cbc0c53fb248	the unified modeling language: an inquiry into current practices and user perceptions		The Unified Modeling Language (UML) has become the de facto standard for systems development and has been promoted as a technology that will help solve some of the longstanding problems in the software industry. However, there is still little empirical evidence supporting the claim that UML is an effective approach to modeling software systems. Indeed, there is much anecdotal evidence suggesting the contrary, i.e. that UML is overly complex, inconsistent, incomplete and difficult to learn. This paper describes an investigation into the adoption and use of UML in the software development community. A web-based survey was conducted eliciting responses from users of UML throughout the world. Results indicate a wide diversity of opinion regarding UML, reflecting the relative immaturity of the technology as well as the controversy over its effectiveness. This paper discusses the results of the survey and charts the course for future research in UML usage.	chart;software development process;software industry;software system;unified modeling language;web application	Martin Grossman;Richard V. McCarthy;Jay E. Aronson	2004			computer science;systems engineering;knowledge management;applications of uml;data mining	SE	-71.39413934968498	23.83950010201048	20054
869cd318c543831544b22994ab47fc664d35cabd	software engineering beyond our planning horizon: automation for computer-based systems	system engineering;software engineering;formal method;engineering of computer based systems;software development;program development	Software development capabilities lag far behind society’s demands for better, cheaper, more reliable software. Software engineering being originally very much restricted to the idea of programming develops more and more into a universal discipline of systems engineering. We give a general introduction to a software engineering workshop dealing with mathematics and formal methods that help solve practical problems in the engineering of computer based systems and engineering automation. Some of its papers detail the circumstances under which such gains can be realized using currently known techniques, thus providing a snapshot of the current state of the art in the area. c © 2002 Elsevier Science B.V. All rights reserved.	approximation;automation;coherence (physics);computer science;formal methods;snapshot (computer storage);software development;software engineering;systems engineering;theory	Luqi;Manfred Broy	2002	Sci. Comput. Program.	10.1016/S0167-6423(01)00023-5	personal software process;verification and validation;computing;formal methods;software engineering process group;information engineering;software verification;search-based software engineering;computer science;systems engineering;social software engineering;component-based software engineering;software development;civil engineering software;software engineering;software construction;requirements engineering;systems development life cycle;software development process;software requirements;software system;computer engineering	SE	-65.52048855579997	24.826041148191123	20055
5e87755720f23656bbcfac9f3cc9bc8407f5f029	reasem: herramienta para la gestión de requisitos	computacion informatica;metodologia abc besoins sem;requirements engineer;requirements engineering;sistemas embebidos;ciencias basicas y experimentales;herramientas de gestion de requisitos;her r amientas de gestion de requisitos embedded systems;ingenieria de requisitos;her r amientas de gestion de requisitos	El proyecto del cual se deriva este articulo esta enmarcado en dos areas principales: la Ingenieria de Requisitos (IR) y los Sistemas Embebidos (SE), y tiene como objetivo el desarrollo de una herramienta que apoye la metodologia ABC-Besoins-SEM, concebida para la gestion de requisitos de Sistemas Embebidos (SE), en la perspectiva de la conceptualizacion de sistemas ubicuos, con uso intensivo de componentes de hardware/software.#R##N#Los aplicativos de IR existentes tienen algunas carencias, tales como: no ofrecer flexibilidad para permitir cambios de acuerdo al modelo de requisitos que plantea cada metodologia; no soportar la fase de elaboracion del modelo conceptual y su posterior conversion a un modelo que guie el diseno. Adicional a lo anterior, no se conocen herramientas centradas en la gestion de requisitos en el campo de sistemas embebidos, ni en su extension hacia los sistemas ubicuos.#R##N#En este articulo se presenta REASEM, herramienta para la gestion de requisitos. Esta aplicacion contiene las caracteristicas basicas para apoyar las fases de la Ingenieria de Requisitos, es decir: permite la identificacion, clasificacion y documentacion de requisitos. Adicionalmente permite la generacion de un modelo conceptual y su transformacion en un modelo de diseno.	linear algebra	Jorge Eduardo Gómez Maldonado;Germán Urrego-Giraldo;Liliana González	2009	RASI		philosophy;performance art	Vision	-107.46639356210096	17.56308583243725	20060
811a0076f86f2890a9d18506c7ceb87129304821	rechtsprechung zum computerrecht					2014	Computer und Recht	10.9785/ovs-cr-2014-10		Theory	-96.32050489161158	23.145388661749344	20070
63f56990d21e2c3b77b862a29ba6586203f8b526	u.s. bureau of land management: the perils of implementing strategic information technology		The case describes the challenges faced by IT managers at the U.S. Bureau of Land Management (BLM) in their efforts to upgrade the Bureau’s IT infrastructure while developing the largest, most complex strategic application ever attempted at the Bureau. After expending 15 years of effort and $400 million, the BLM cancelled the program. The case identifies obstacles faced by IT and non-IT managers in attempting to implement strategic information technology in large, complex organizations. Obstacles identified in this case include: the BLM’s culture of autonomy that tended to undermine support for the initiative, technological limitations that impacted the selection of technical standards, and organizational resource and knowledge constraints that adversely impacted the BLM’s ability to manage such a large IT development effort successfully.	technical standard	John C. Beachboard	2003	CAIS		engineering;environmental resource management;marketing;operations management;management;computer security	HCI	-79.81561439601298	6.8824395351452	20083
6cb74ec784d2fb9874893c94a4b056d2189eac09	combining business activity monitoring with the data warehouse for event-context correlation - examining the practical applicability of this bam approach	business activity monitoring;data warehouse	Business Activity Monitoring (BAM) is a term introduced by Gartner, Inc to define systems that serve to provide real-time access to critical business performance indicators to improve speed and effectiveness of business operations. Despite the emphasis of BAM on the provision of low latency views on enterprise performance, literature on BAM also indicates the technical feasibility of a BAM approach, which adds context from historical information stored in a data warehouse to real-time events detected by a BAM system so as to help enterprises improving understanding of current monitoring scenarios. However, at this point, there is a lack of studies that discuss the use of this approach to tackle real-world business problems. To improve practical understanding of the potential applicability of this BAM approach, this paper will present a synthesis of existing research on BAM and data warehouse to provide an objective basis for proposing feasible business scenarios for applying the combination of both technologies. This study reveals that the noted BAM approach empowers operational managers to respond in a more precise manner to the occurrence of events by enabling a better understanding of the nature of the detected event.	business activity monitoring;real-time computing;real-time locating system;real-time transcription	Gabriel Cavalheiro;Ajantha Dahanayake;Richard J. Welke	2006			computer science;data science;data warehouse;data mining;database;business activity monitoring	HCI	-74.12397248631234	12.33374409903267	20125
7c7be925da11d7dc075a5390f4397847f165a793	linear combinations of radioactive decay models for generational garbage collection	garbage collection;radioactive decay model	"""#""""%$& (' )""""& *""""% """"+ , """" $& . , . """"& """"/ * """"102, """"/ , """"& . 3, 405 6 $/,7 8 902 ' ': ;""""& """"&< = > """"% """"& : ' ? """"@$% ' ' """"%$/ BA : 3 = C02,: .DE : 6 """"% """"/ 'F$% ' ' """"%$& HGJIK """"H L$% 3 : 4 L @ ? $& M?"""" """"%$H %N7 * E """"%' O ;""""H 4 P """"HQR : """". 9 * E """"%' ' @ !#""""%$& P' )""""& *""""% 3 S RN * %A """"% ;""""&$% ' '8N302, """"% 3 , """"1 ' T U '8N V%""""1 , """" """"&'= 4 M?""""W X , """"% """"& $H 'U ;""""& ) S $%""""Y 7 * ' """"Y """"% """"& : ' $& ' ' """"%$& %G Z , """"[ ; : N\ ;""""& #01""""%""""% ] * E """"%' ( , HM? N? """"& ^_< """"% """"/ ';$% ' ' """"%$/ ` : L * E """"&' 9 ,: 4 9 a HM? . , """"` """"&0J '= """"& ^ < 9 """"% """"& : ' $% ' ' """"%$& . 9 S , """"% S $H ' ' N7$% * ' """"&bcA """"%M?""""% ) P, , '8N7 = """"H ' V%""""H 3$% ' ' """"%$& %G1d 9' """"H 4 .$& 6 : O ^ ? $/ M """"@ """"%$H %N6 * E """"%' %AR ^e """"& """"& 4 : ':$% ' ' """"%$& 9 """"%'8N $& * ;""""& 8 M?""""*02 8 ,5 """"% ' V%""""H f """"% """"& : '2$% ' ' """"&$& BA.""""%M?""""& 5 4 , F ; : NRG 1. INTRODUCTION & RELATED WORK g`h i%j hHkRlSm n o-o l m&paq_n r L """"%$ , ' N ,: 4 S 4 $% ' '8N """"&^ $&'= * L """"H $ ,: ' """"(, """"H s """"Wt uEAFvHw Ayx z4{_G gFl/r;l/i h paq_n r;h o """"@$% ' ' """"%$& | M """"F , """"|, """"H E }0y 7 ` * """"F """"% %A DE 402 s L """"& """"& 4 L ;""""&$H """" , """"&N[ ) """"% ~ f !#""""%$& L * ' U """" A : $% ' ' """"&$& @ , """"% """"3 """"% """"/ @ 8c""""& """"% R F *""""% t8v%w AUvH4{_G X S """"% """"& : '2 : """"+$% ' ' """"&$& """"& * 6 $& ' ' """"%$& 2NR """"& ` """"& """"& 4 ` * """"| ) """"%QE """"% R '8NL ,: ( '= """"& 2 """"& ^ """"/ %A: *1$% ' 'B , """"%  n ErEkRl/i/ 9i/ p $% ' ' """"&$& %G } L 6""""&c P |$/, $& """"& V%""""` , """"1 , """"% """"/ $% ' """"&'= 4 , L ;""""&^ }0y""""%""""& W !#""""%$& ' 8 -""""& *""""% U : , """"3 ;""""& ) S $%""""7 . """"% """"& : ' """"3$% ' ' """"%$& BAK@""""% N 1 D?""""& | """"H """"H , @ Y """"H ' V%""""% """"/b ; """"% R ' ? $/ M """"4 """"%$% HN] * E """"%' * !#""""%$& ' )""""& *""""% * ,E . """"% """"& """"% R 2 6 ME 3' """"| ;""""& #01""""%""""% X * 1 , ` ;""""% ^ """"/< F )  """"% """"& 4 : 'O$% ' ' """"%$& [ : X * F , @ * HG } 6 $% ' 4 HAEy D """"& P$% ! """"%$& """"H 3 , 9 """"& """"& 4 : ' $% ' ' """"%$/ 01 '= ;""""& )  2 ;""""& """"&   `0y """"9 ,:  ^e """"% """"& ' $& ' ' """"%$& + 2 , """"@ ? $& M?""""7 """"%$H %N * E """"&'.t x4{_G O$% ' $% ' 4 """"H S , P , 1 . . O. """"& ^_< P """"% """"& : ' $& ' ' """"%$& y $& ' '8N* ;""""& 0y """"2 ,: * ^e """"% """"& : ' $% '8^ Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Copyright 2002 ACM X-XXXXX-XX-X/XX/XX ...  5.00. ' """"%$& P ) P , """"y ? $/ M """"@ """"%$H %N7 * E """"%'aA? . @ M """"%' i l/rcl/.h o8 n o Rl/i/ Pi  p """"& """"& 4 : '@$% ' ' """"%$/ ( U 7Nf EM?""""% R ~ ;""""& * ;""""& """"& 7t z {_G Z , F $% 4M?""""/ NRA: : , """"@ """"H ' VH 4 + ,: 4 @9' UX % U 4^ """" @ !#""""%$& (E : $&""""X$% ' ' """"%$/ , """" \ ' 8 , 6 ;""""%,: HM?""""% 6 $/,7' D?""""2 3 ' """"& ^_< .$& ' ' """"%$& HA?' """"% 6 D E """"/ a 4M  $y U ^ M?""""% R B @ 2 3 ' """"P 7""""& E 8 """"O a * ' N@ ' """"/ ^e< T ' 8 , * """"% """"& 4 : 'U ? 4 : """"$% ' ' """"%$& >t8v4xRA3v% A@x EA xRv&{_G>I 4 U """"% ~ : a : """"& ;""""% : """"% R ' N X % L """"% """"% $ ,~ 5 * ' """"&^ *""""% R """"H 7M 4 = 4 P ; , """"y """"% """"/0` '8^e ' """"& ^_< 1 : SR """"& a 4ME  $ Rl-Hl/i i l  }n o Rl/i/ Pi  p ' , * O 7 """"% """"% $ , ^}QR : ' 8 #N * ' """"& *""""% ^ P B $ , """"& *""""y L ? HM AR """"% * | ,: O , """"% """"` ' """"& ^ < | ' 8 , * F 4 """"QE 8 """"UME = ' """"*t ¡ A: A ¢ Acx w {_G # | a $/ HA , """"% """"9 ' """"/ ^e< T$% ' ' """"&$& T ;""""& ) ]$% EM?""""& E : ' NR """"& ^_< |$% ' ' """"%$& U Y """"%M """"& 'T $&^e E """"& M?""""7 ;""""% $ , S 4 D %G @ ( , """"U , """"& 2,: : cA , """"U""""&b ;""""& *""""% R '; """"% '8 | ' * , H0£ ,: NR """"& ^_< 3$% ' ' """"%$& * ;""""& ¤ '= """"& ^_< 6$% ' ' """"%$& * *""""+ , """"& ( ;""""% $/, S DE t  A@¢ {_G9ME """"% R '8N~ *""""+ * ;""""& ) ¥ ;""""& """"& 02 8 ,WN? """"& ^_< $% ' ' """"%$& KA9 *""""L ;""""/ ;""""& """"& 02 8 ,¦ ' """"& ^_< $& ' ' """"%$& KA9 W S RN+ ;""""/ § ; , """"@ *""""U02 8 , """"% 8 , """"/ HG ̈ ,RN ©Jy D """"& H : 'yQR """"& W$& $&""""& , """"7 , """"% """"& 8^ $H ' M 2' """"y ;""""& #01""""%""""% NR """"& ^_<  """"% """"& '  ^ """"& """"& 4 : 'K$& ' ' """"%$& (,: 1 1 ;""""%""""% 0y""""& """"% KA L0y""""@ 3 H0 D¦ ,: 4 *QR """"% s02 8 ,s """"% ? 4 s YNR """"& ^_< 6M?""""& ' """"& ^_<  """"& """"& 4 : '1$% ' ' """"%$/ t x x4{_G Z , """"L ? $& M?""""S """"/^ $H %N~ * E """"%'2 S , """"+ ME W' """" A2 L02,: 4 ©a@ ~ , """" ; : NRA 02, """"& """" , """" , """"% """"& $H 'O""""/«*$% """"% $& """"& @ 9NR """"& ^_< ~ ' """"& ^_< L$% ' ' """"%$& \$% $& = """" A` * ^e """"& """"& 4 : 'F$& '8^ ' """"%$& + S '=© # ( , 2 : ;""""/ |1 """"' """"H |$% 6 | O $& M?""""7 """"/^ $H %N * E """"%' F S$H ' $% ' """"7 S D ¬4$% F 4 L, """" * | * ; ^ R 9 , """"& """"& $H ' """"% $& . K * V%""""H 3""""&«*$% """"% $&N T ) . """"%M?""""& ' """"H ' V&""""H f ? """"X$% ' ' """"%$/ %G Z , """"% """" $H ' $& ' L , H0­ ,: , """"/ """"6 * ' """"6' """"6 ,  M """"% U * @ ,: 4  """"L ;""""/ ^ """"& ( 8 """"H \ ) XN? """"& ^_< ($& ' ' """"%$& ) ® * S ,: """" ;""""& """"& """"% \ X ' """"/ ^e< X$& ' ' """"%$& KG­} \ , : ;""""& HA , """"( ME Y' """"( ;""""H * * +$% * ' """"&b~4^} *""""& 'y ^ a $%"""" A ` ) """"@ """"% """"H 4 $/, 02 ' ' : """"H '8NS , H0£ ,: 4 ` , 2 ($/ : """"3 4M?""""& * ' 8<:$H 4 BG*(N$H ' $% '= 4 7 ' + , H0 ,: ^e """"& """"& 4 : '|$% ' ' """"&$& * ' '8N~ S ) a S '2 ,: 4 U a $&"""" Ac02, $/,Y """"& @ ,: 4 U ^e """"& """"& 4 : 'O ? """" $% ' ' """"%$/ \ * """"%'  ̄ Y R E ~$% * * """"( ;""""/ #0y""""&""""% fNR """"/ ^ < | : ( ' """"& ^_< F """"% """"& 4 : '$% ' ' """"&$& BG Z , """" R E s """"/02 L 3 ,: 4 * """"& ' """"H s""""% * 8 $H '1 : """"% 3 | ^ ! """"&$& ' 8 -""""& *""""% %AB F """"% ; """"%  : """"% ;""""% """"% R '8NX RN+E """"& 4ME  $L : U """"% Wt  A:x  {_A """"% 2 ,: 4 2' """"H F$% 6 ` T ? $&^ 0 500000 1e+06 1.5e+06 2e+06 2.5e+06 3e+06 0 1e+06 2e+06 3e+06 4e+06 5e+06 6e+06 7e+06 B yt es L iv e Bytes Allocated earley11 ! """"$# &% (' )*# %+ (, """". /&01 2 34 2% .56 7#& / 8!9: ( ( %; 2 8<8= , >% 8!9 >%1 7#? ; >%@""""8A /B3C 7# D 2 8E%F,B / GH / I 7# ;JFK L2MHN O>,BPHLRQHQ>SFTRU ,(VHWFX L Y(SHT , / ZO7[>\RW]UFK+9 / GR#:8A 2^?% _a` ,Bbc,cd ef'@)*# + 8= % @ / .%7# >56%1 # g ch( ( :8= + """": h( 6% ; % .""""i / GF 7 (/A """": 7 j8A Cki56#? > ; j8= ; %l8= %7 ? 2 > 9c3 7# !/c :8I9m 6 """" 9c3? n %+ 7# ;# h( o9 /4 ?GR > p 'g0$ GR# /B R o / A%7# >56%g# >5q8! G2#&% 2 A%7 h h( %*""""r B8 # j8= I56# GR#s # 4 /c n > 2 Z / % > t""""r B8u # 8= % = / ('v)*# 4# """"-wf """"& """"g%7# nwx h( s 9?y >GF %A % 8! G2#z >%7%C 7# /{ # &#? 2 |H (/B >% ( 7 (/} """"g 7# 4 skf~  9?3 p ,$ / s 7#? &# """"wx """"v """"g (/ wf h( > } 9?y >GF %A % 8! G2# (/ ; # /Z 7#  (8 %* 2 / / / E j8= <kr ; n cGF 7 (/:p ';)*# %7 C """" 7# o n 8= (% + /? C%7# >56% 7# 9 ( ;#? """" """" # C cGF > 4 9?yn GR 7%+ 2 C (/ wf h( > '* n > 7 / E%7 GR# 8E%+ >%7 7%g /4 A% 5; B #4 : (,:56 7# # A# """"wx """"r A """"$ (/ wf h( > v 9?yn >GF 7%; (/& # I 2 . """"@#? """"1 /v 2 7 (/m' M?""""L """"%$H %N * E """"&' ) """"% ¦ """"H : '8N[ R E (! ¦ ` * E E^ """"&' ' | , """"1' 8 -""""/ *""""& O : !#""""%$& O  """"H ' * %G# 7 : 4 $& ' HA S RNL * y """"|M?""""& N30y""""%' '; * E """"&' ' """"H * RN* ' """"H 4 `$% 3 : 4^ 5 | }0y Y $& M?""""X """"%$H %Nf * E """"%' %A. '8 , ,s , """"& """"( ^ *  ' '8NW """"/ * """"L ;""""/ """"S""""HQR ' 7 """"H $/, """"H cT """"%"""" dT """"*vU | """"&b * ' """" G Z , """"* , """"% """"& $H '`$H ' $% ' L F , 3 ;""""& 3 S %NW , """"& """"& """" 4M """"P ,R B ,: 4 02 ' 'R""""%M?""""% R ' '8N@, """"%' 02 8 ,U , """"P ' """"&  S 4 $/, 6 * ` 6 , """"@ * 2 8 ' """" ? 4 : """"$% ' ' """"%$& %G y y , """"|M """"& N*' """"H HA , """"& """"@$H ' $& ' `, """"%' S 3""""/b ' ( *""""@ , """"y """"% ;""""H 4 ' """"` 9 V%V%' U """"& T ,: 4 1 4 """"` = """"% L """"& M?""""H """"/b ;""""/ *""""& E 'c : """"% 2 O ? 4 : """"$% ' ' """"%$& st ¡ A  A:¢ {_G 2. MODELS OF OBJECT LIFETIMES 2.1 Generational hypotheses } ( * ` * %A , """"@ * ' 8 #N* """"| `N? 3 !#""""%$& ` 3 $ ,¦, , """"& 3 ,: ¦ ) * ' ¦ E! """"%$& %G Z , 1l h  kRl/r;l/i h paq_n r;h o   n p  l/ q) t8vH ABv v Acx z4{T 2 ` """" O ' ' * %A 2 2""""% ^ ;""""&$% ' '8NL' D?""""%'8N6 """"% $& ;""""y a ^} ' ' R$H 3 * O ) P02, $/, , """"L ;""""& ) S $%""""* y ? """" $& ' ' """"%$& f  * $& 8 $H '_AO : ;""""H 4 F * ;""""U """" """"%M?""""% ( O ^} ' ' R$H ( * `0` """"& ! t w {_G Z , """"& """"+ * 6 $/,~' """"% S""""%ME = """"% $&""""X , """"  pai n rRk[kRl/r;l/i h paq_n r;h o   n p  l/ q) A;02, $/,( ; ' 4 """"% @ 3 """"% M?"""" $% """"%' Y ;""""& }0y""""%""""% """"X : ¦ * ' 8 #NW """" """"%M?""""% ¦ ) L' ^e' M?""""H f E! """"&$& Xt8v v A|vHuEA v%¢ A;x z {_G  ? $/ M """"( """"%$H %N¦ * E """"%' 3 * ' NY , 7 , """"* * ' }NW 4 """" : """"% ;""""% """"% R | ` """" AK , """"&N+ 4 )N """"% 8 , """"& @ , """"30y""""% D+ , """"| 7 """"% """"& : 'c,RN ; , """"% %GP £' """"% `$% 6 S }0y S | * """" ? $& M?""""6 """"%$H %N * E """"%' F02 ' 'T 4 =N+ , """"U01""""H D """"% """"/ ';,RN ; , """"& P ' """"% . 8 y """"% """"% """"& 4 """"% 1 R  U """"` ^ ? $/ M """"+ """"%$% HNs * E """"%'aGJ ' """"H 4 S$% 3 : 4 5 U '8Nf #01 ? $& M?"""" """"&$H %N( * E """"%' y02 ' 'B 2 )N , """"U 3 """"% """"& ^ : 'B,RN ; , """"% %G 2.2 Equilibrium models F lf&Eqao q_j&i q- *nH?l&o ` !#""""%$& 7' )""""& *""""% 7  ( * E """"%'O ,: 4 4 <:""""% 2 , """"@ ) ' ' H02 , """"%"""" * % D nc  ( c v G6 .nUn?j Hl m&pa1m h r*j l`m nR  h i l @pen|&l ly  l/p  l/i p  l  h i lsp  l¦/hRSlsn?j 4l m&pjh r:Jp  l~o q   lfn?j Hl m&pafn sn rclsn i *n i l[kRl/r;l/i h paqan r ~m h r>j l5 q- paq-rEk Eq-  l /i nR p  l5Rl h?]n?j% 4l m&pa@n |p  n &l2kRl/rcl/i h paq_n r  j $ l/i-%n i3q-rEkLh k?h i%j hHkRlm n o-o l m&paq_n r 9q-p  q-r~p  n &l*kRl/r;l/i h paq_n r xLj&Ep7n?j Hl m&pa  h2  l(r;n[n p  l/i+ q) paq)r: k Eq-  q-rRk m  h i h?m&p}l/i q- paq_m&p  h p6q k  p1j l6lf¡  o n q-p}l  j  h7kRl/r;l/i h  paq_n r:h o;k?h i%j hHkRl6m n o)o l m&pen i7¢ D nc  ( c­xEG6  l/i lWlf¡ q) paXh  i n?j h?j&qao q-p  Rl/r  q-p  /Er;m% paq_n ro£ &n i *n i peh o q-p    m  p  h pj:%n i6l h?m  r;l/2o  h o-o nHm h p}l  n?j% 4l m&p ¤ 1p  l  i n?j h?j&qao q-p  p  h pm¤+9qao-oT qel6j l/pa1l l/rfhHkRl/$¥§¦Xh r:+¥n ̈ q-`k q   l/rWj  © a« a ¬ £  ¥ i­ ¥ D nc  ( c>w G6  lhR*n  r pSn +o q   l  pen i hHkRlWi l h?m  l/h r lf&Eqao q_j&i q- .¢ | * *v1 HN  , 9""""HQR ' * E """"&'  """"y , """"y ^ $& * ;""""& }0y""""%""""% ~' M?"""" : f """"H $ ,: ' """" E! """"&$& %A` E! """"&$& * ,: $% E ¦ ; R """"& 3 : W E! """"%$&  ,: 4 3 K HAO E! """"%$/ 7 ,  """"& -""""/ '= """"& 7 E! """"%$/ 6 : W !#""""%$&  ,: 4 """"& -""""& 7 XNR """"&  !#""""%$& %A L U ,BGP | * *x@ HN 9 ,: 4 . , """"2 * K ^ ! """"&$& @' 8 -""""/ *""""& | F """"% ;""""& : """"& E y O , """"U *"""" 4 F02, $/,+ + E! """"%$/ $& """"H 4 """"H KGL | * w( %N U ,: 4 , """"H [ """"L """"% $ , """"%  """"H N """" G:®@ """"P , """"% """"y *  """"y$% * ' """"& """"%'8NU """"% '8^ $ A y , """"&N """"  """"H : ' """" $% * * """"@ ;""""/ #0y""""&""""% ( """"H ' }N $& ' 8 #NRG 2.3 Radioactive decay models  ? $/ M """"¦ """"&$H %N * E """"%'| ( ' ' NJ ;""""%$% 8<:""""H RNJ 8 ( """" : 4 *""""& """"/ HA , """"U,: ' =^e' 8 )""""+ ̄KG d 9""""%M?""""& N !#""""%$& 9 ,: 4 O P' M?""""` 4 P RN *"""" ¥§¦ A , """"y : ' 8 }N ,: 4 U , """"3 E! """"%$/ 02 ' '9 ' '. ;""""6 ' M?""""* @ *"""" ¥ ¦±° ¥ *2 a  ¥ ¦H$"""	a* search algorithm;ambient occlusion;border gateway protocol;business architecture;byte;display resolution;emoticon;garbage collection (computer science);geforce 7 series;grammatical framework;job control (unix);netware;noise reduction;query expansion;shebang (unix);wordnet	William D. Clinger;Fabio V. Rojas	2006	Sci. Comput. Program.	10.1016/j.scico.2006.02.005	real-time computing;simulation;computer science;garbage collection;programming language	Theory	-89.58367340709742	21.891673503881883	20294
b36e8bb715ea7e2de44be433df0ed3a2ffca7434	strong agile metrics: mining log data to determine predictive power of software metrics for continuous delivery teams		ING Bank, a large Netherlands-based internationally operating bank, implemented a fully automated continuous delivery pipe-line for its software engineering activities in more than 300 teams, that perform more than 2500 deployments to production each month on more than 750 different applications. Our objective is to examine how strong metrics for agile (Scrum) DevOps teams can be set in an iterative fashion. We perform an exploratory case study that focuses on the classification based on predictive power of software metrics, in which we analyze log data derived from two initial sources within this pipeline. We analyzed a subset of 16 metrics from 59 squads. We identified two lagging metrics and assessed four leading metrics to be strong.		Hennie Huijgens;Robert Lamping;Dick Stevens;Hartger Rothengatter;Georgios Gousios;Daniele Romano	2017		10.1145/3106237.3117779	software analytics;computer science;software metric;empirical process (process control model);devops;continuous delivery;data mining;agile software development;predictive power;reliability engineering;scrum	SE	-68.86740971036542	23.427629920733946	20351
dd25619e5d3fa15ef4309ac2a7759869f8709d55	applying soft systems methodology to multimedia systems requirements analysis	multimedia information systems;systems development life cycle;multimedia systems;requirement analysis;soft systems methodology;systems development lifecycle;soft system methodology;discussion paper	The Soft Systems Methodology (SSM) was used to identify requirements for the development of one or more information systems for a local company. The outcome of using this methodology was the development of three multimedia information systems. This paper discusses the use of the SSM when developing for multimedia environments. Namely, this paper covers the problems with traditional methods of requirements analysis (which the SSM addresses), how the SSM can be used to elicit multimedia information system requirements, and our personal experience of the method. Our personal experience is discussed in terms of the systems we developed using the SSM.	information system;prototype;requirement;requirements analysis;soft systems methodology;system requirements	D. Z. Butt;Tim Fletcher;Stephen G. MacDonell;Brian E. Norris;William B. L. Wong	1996			computer science;systems engineering;database;multimedia;systems design	SE	-65.00787572880394	16.6234504574131	20357
aa3972066ee2f8f2ab432b5b66ab024e1b4a1c36	supply chain structure, product recalls, and firm performance: empirically investigating recall drivers and recall financial performance relationships	dissertation	This dissertation links globalization, sourcing strategies and structure, and product quality and firm performance in global supply chain management. Globalization, both in sourcing and markets, has been a popular business strategy within the last two decades. At the same time, product recalls are, according to both media and research sources, on the rise (Hora, Bapuji, & Roth, 2011). Attempts have consequently been made to link the two. In fact, according to Marucheck, Greis, Mena, & Cai, (2011), the most globalized industries make the most recalls. The dissertation investigates the association between globalization of sourcing and sales and product quality and safety as assessed through product recalls in two essays. Specifically, in the first essay, the research looks at a firm’s sourcing practices and global market reach and how they relate to a firm’s product quality and safety glitches that result in recalls. In this essay, we first look at firm level sourcing behavior (make or buy, buy inshore or offshore, concentrated or diversified supply base, and concentrated or diversified international supply base) and how each of these factors relate to product recalls. Referencing agency theory, contract manufacturing either inshore or offshore may lead to lower quality performance. Having many suppliers and across many countries may make a supply chain very complex. From the transactions cost economics, supply chain complexity is considered to have an effect on supply chain coordination costs and consequently supply chain performance as measured by product conformance. In the second essay, the research takes broad look at the recall–performance relationship. Intuitively, one would believe that, given the associated costs of recalls and closer scrutiny by media, consumers, and government, recalls should be on the decline. However, anecdotal evidence points to the contrary. For instance, Mattel/Fisher Price made over 13 different recalls affecting millions of products between 2008 and 2011, subsequent to the infamous 2007 recalls that affected millions of toys for similar reasons.i Toyota up to the end of 2012, made around	conformance testing;fisher information;glitch;markov chain;realms of the haunting;strategic management;toys;word lists by frequency	Adams B. Steven	2015	Decision Sciences	10.1111/deci.12135	public relations;types of research methods and disciplines;economics;marketing;operations management	AI	-85.57821334201165	6.609539252428566	20436
9888b2ecec3f203f2c672e47d9245b9628ec1560	rechnergestütztes faktenrecherche-/faktenverarbeitungssystem unter nutzung von kleinrechnern				Lothar Beck	1983				NLP	-99.65230092348824	26.28132908438732	20438
dba0a158f4ddd8b7c16838eae85a55f5deda8627	creating a software performance engineering team - lessons learned			performance engineering;software performance testing	Gregory Dawe	2006			engineering;personal software process;software engineering process group;software performance testing;systems engineering	SE	-64.03505071320825	25.024763442832583	20442
49136f21af9b83fa89f6f89bb70f93ec20ee34ed	supplier and customer involvement on new product performance	product development;china;modularity	Purpose – Recent studies have found inconsistent findings on the impact of supplier and customer involvement on new product development. This study thus aims to explore what contextual factors affect supplier and customer involvement altogether and how such involvement affects new product performance.Design/methodology/approach – The study used structural equation modelling to analyze empirical survey data from 251 manufacturers in Hong Kong.Findings – The study found that modular design, product innovation, and internal coordination are positively correlated with the supplier and customer involvement. Such involvement and product innovation lead to better new product performance.Research limitations/implications – The study is limited to the use of cross‐sectional data and a single key informant approach, and the industry structure of the sampled industries.Practical implications – The study examines the contextual factors of supplier and customer involvement and how such involvement relates to new produ...		Antonio K. W. Lau	2011	Industrial Management and Data Systems		voice of the customer;supply chain management;economics;marketing;operations management;supplier relationship management;customer retention;new product development;commerce	DB	-82.24519557482132	4.268495290529882	20447
fc1a2cea8b61e58c724befcb9b8857795655ba6d	reverse method engineering: methode und softwareunterstützung zur konstruktion und adaption semiformaler informationsmodellierungstechniken			method engineering	Christian Seel	2010				DB	-103.20920547774574	24.578604070055565	20466
62d65ddc17ef98f219c1e0bd14a70615647876ea	why teach reverse engineering?	plagiarism;program understanding;course development;obfuscate;software evolution and maintenance;software engineering;client server;internet;software evolution;legacy systems;legacy system;reengineering;software reverse engineering;reverse engineering	Software reverse engineering is a fascinating discipline of software engineering. But it has failed to attract attention from students. Largely due to the facts that many universities around the world do not offer relevant courses, developing new software has always been considered superior then to maintain existing systems. But owing to the arrival of the internet, and client-server technology. Many organizations wish to adapt their existing systems. Thus the trend has somewhat shifted towards software evolution and maintenance. And now, more than ever before we need software engineers who can work effectively with legacy systems. In this paper I wish to highlight importance of incorporating Reverse engineering concepts and techniques into software engineering curriculum. I will start with a brief overview of reverse engineering concepts, and then discuss advantages of teaching reverse engineering.	client–server model;failure;legacy system;reverse engineering;server (computing);software engineer;software engineering;software evolution	Muhammad Raza Ali	2005	ACM SIGSOFT Software Engineering Notes	10.1145/1082983.1083004	personal software process;computing;software engineering process group;information engineering;computer science;systems engineering;engineering;software evolution;social software engineering;component-based software engineering;software development;software engineering;software walkthrough;software analytics;legacy system;software requirements;reverse engineering;software archaeology;computer engineering	SE	-66.85436432639729	24.704158456090692	20483
42a7deec4d6c47bcd8684a6815bfa2237004dd89	sicherheitsanalyse biometrischer, auf dem software as a service prinzip basierender authentifizierungssysteme			software as a service	Florian Obergrusberger	2014				SE	-94.7258716748612	28.741678946155883	20531
c8de8cc7ed9ea0dbf75ac5486984f980667c605d	globalisierung der tk-überwachung				Johann Bizer	1999	Datenschutz und Datensicherheit		computer security;internet privacy;computer science	NLP	-94.38513950135061	30.185923081843338	20533
039c2825ad42d63a8928a0197ebe380e46a9c187	energy-efficient straggler mitigation for big data applications on the clouds. (amélioration de l'efficacité énergétique de la prévention de stragglers pour les applications big data sur les clouds)		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Energy-efficient Straggler Mitigation for Big Data Applications on the Clouds Tien-Dat Phan		Tien-Dat Phan	2017				ML	-108.10797946447225	10.420239171914929	20567
a853d548b7310f9aeab336f4a9938b95e65cd513	evidence on economies of scale in software development	software development;economies of scale	Researchers and practitioners have found it useful for cost estimation and productivity evaluation purposes to think of software development as an economic production process, whereby inputs, most notably the effort of systems development professionals, are converted into outputs (systems deliverables), often measured as the size of the delivered system. One central issue in developing such models is how to describe the production relationship between the inputs and outputs. In particular, there has been much discussion about the existence of either increasing or decreasing returns to scale. The presence or absence of scale economies at a given size are important to commercial practice in that they influence productivity. A project manager can use this knowledge to scale future projects so as to maximiT~ the productivity of software development effort. The question of whether the software development production process should be modelled with a non-linear model is the subject of some recent controversy. This paper examines the issue of non-linearities through the analysis of 11 datasets using, in addition to standard parametric tests, new statistical tests with the non-parametric Data Envelopment Analysis (DEA) methodology. Results of this analysis support the hypothesis of significant non-linearities, and the existence of both economies and diseconomies of scale in software development.	data envelopment analysis;linear model;nonlinear system;parametric design;software development process	Rajiv D. Banker;Hsihui Chang;Chris F. Kemerer	1994	Information & Software Technology	10.1016/0950-5849(94)90083-3	computer science;systems engineering;engineering;economies of scale;software development;software engineering;management science;management	SE	-85.39820261460015	9.33468410846511	20613
2cc14caf2b0958c622d54fbf6caa9dc5414c9e36	how fields are used in java: an empirical study	libraries;software;open source java applications;software quality data encapsulation java;empirical study;code analysis;object oriented designs;object oriented design;information hiding;probability density function;size measurement;data mining;empirical study information hiding non private fields code analysis;data encapsulation;empirical evidence;information hiding principle;non private fields;open source java applications java information hiding principle software quality object oriented designs;java programming profession open source software software engineering computer science software quality information analysis voting computer languages quality control;couplings;software quality;java;open source	The information hiding principle is generally accepted as one that if followed leads to higher quality software than if it is not followed. To follow the information hiding principle in object-oriented designs the advice is to avoid non-private fields. There is, however, little empirical evidence as to whether or not this advice is being followed. This paper presents the results of an empirical study of 100 open-source Java applications to determine to what degree non-private fields are declared, and to what extend they are used. The study indicates that it is not uncommon (albeit not that terribly common) to declare non-private fields, but then not take advantage of that access.	advice (programming);enumerated type;java;nice (unix);open-source software;simulation;standard library;uncontrolled format string	Ewan D. Tempero	2009	2009 Australian Software Engineering Conference	10.1109/ASWEC.2009.19	probability density function;empirical evidence;computer science;theoretical computer science;object-oriented design;software engineering;data mining;database;coupling;programming language;information hiding;empirical research;java;software quality;static program analysis	SE	-64.545217663715	36.083193867341194	20643
4d165afa3fb6d885f58dd731c32d0330f270c4e9	projekt der deutsche wortschatz	projekt der deutsche wortschatz	Die Sammlung und Aufarbeitung lexikalischer Daten ist bei größeren Projekten häufig auf mehrere Mitwirkende verteilt, wichtiger Bestandteil ist aber auch die zentrale Koordinierung und Qualitätskontrolle der erfaßten Daten. Ziel des vorgestellten Projektes ist es, eine völlig neue Art einer „selbstorganisierenden“ Koordinierung zu erproben. Die Aufgabenstellung ist wegen des Wunsches nach einer großen Zahl von Mitwirkenden einfach gewählt: Ziel ist die Erfassung eines möglichst großen Teils des deutschen Fachwortschatzes. Die Erfassung erfolgt mit Hilfe einer vorgegebenen Software durch Mitarbeiter aus den verschiedensten Fachrichtungen auf freiwilliger Basis, die Qualitätskontrolle wird ebenfalls dezentral organisiert, indem bereits erfaßtes Material zur Diskussion gestellt wird und Änderungen vorgeschlagen werden können. Die Rolle der zentralen Koordinierung beschränkt sich dabei auf die (halbautomatische) Organisation des Informationsflusses und eine allgemeine Aufsichtsfunktion.	eine and zwei;es evm	Uwe Quasthoff	1997			computer science	Crypto	-104.10973571725143	33.37685506619249	20658
3ea03bcc69a3bac61b304629976f42104dbdb149	risikoorientierte prozessmodelle in bpmn - stand des wissens und potenziale				Saskia Greiner	2013		10.1007/978-3-642-35030-6_20		Crypto	-98.14710707515285	22.883498706599354	20662
9e015860bfb2cd0c85f6a5692a4643e05052351a	stromversorgung und -übertragung sowie lastdeckung in europa und mit fokus auf österreich		Das Übertragungsnetz gewährleistet seit jeher den sicheren, überregionalen Austausch von elektrischer Energie und stellt damit eine zentrale Funktion im Gesamtsystem dar. Auf nationaler Ebene ist das Übertragungsnetz in Österreich das Bindeglied zwischen den neun Bundesländern bzw. den wesentlichen Verteilernetzbetreibern in Österreich. International ist das Übertragungsnetz der Austrian Power Grid AG (APG) eine zentrale Infrastruktur in Mitteleuropa und, mit der Ausnahme der Slowakei, mit allen Nachbarländern direkt verbunden. Die ersten vergleichbaren Konzepte zur weiträumigen Stromübertragung gehen auf die Anfänge des 20. Jahrhunderts zurück. Die damalige Konzeption der partnerschaftlichen Störaushilfe sowie der synergetischen Nutzung verschiedener Erzeugungstechnologien zum Zweck der Erhöhung der Versorgungssicherheit und Systemeffizienz ist heute aktueller denn je, wenngleich sich die Player im System drastisch verändert haben. Die gemeinsame Preiszone mit Deutschland hat bereits eine lange Vorgeschichte. Seit der Liberalisierung wurde der grenzüberschreitende Stromhandel sukzessive weiterentwickelt. Uneingeschränkten Stromhandel gibt es in Europa bisweilen nur zwischen Österreich und Deutschland. Die Energiewende, vorwiegend vorangetrieben durch den Ausbau Erneuerbarer Energieträger in Deutschland, gekoppelt mit der Möglichkeit des internationalen Stromhandels, hat in der Folge auch die Strompreise in Österreich gesenkt. Die Konsequenz sind einerseits vergleichsweise günstige Preise für Industrieund Endkunden, andererseits jedoch ein zunehmend schwierigeres wirtschaftliches Umfeld für konventionelle Kraftwerksanlagen.	die (integrated circuit);eine and zwei;europa	Gerhard Christiner	2017	Elektrotechnik und Informationstechnik	10.1007/s00502-017-0544-9	engineering;electronic engineering;performance art	DB	-103.89843622468753	33.88387966640084	20668
af71fc299f14a07f622ffa8c021f432b0beae964	sicherstellen semantischer integrität im big data umfeld - problemstellung und lösungsansatz		In diesem Beitrag wird die Notwendigkeit des konsequenten Einsatzes von IT-gestützten Modellen im Systems Engineering, exemplarisch aus Sicht der Raumfahrtindustrie, motiviert und dabei auf aktuell existierende Anforderungen und Probleme eingegangen. Aus wissenschaftlich-technischer Sicht wird dabei auf Problemstellungen aus dem Bereich Big Data, insbesondere auf problematische Aspekte zur Etablierung einer konsistenten Semantik auf der Modellierungsebene und zur Laufzeit, fokussiert. Es wird ein Ausblick auf einen entwickelten Ansatz zur Addressierung der identifizierten Herausforderungen skizziert, welcher auf einem methodischen Vorgehensmodell und relevanten technischen Lösungsbausteinen basiert.	big data;systems engineering	Tobias Hoppe;Harald Eisenmann;Alexander Viehl;Oliver Bringmann;Christian Hennig	2014			philosophy;performance art	DB	-101.32505366993156	33.74984014718809	20767
81b3a717cad0e5792ffa23be67914767aadc690d	an integrated model for business process measurement	performance measure;business process measure;analytic hierarchy process;modeling technique;measurement;integrable model;conceptual model;multiple criteria;web service;business process model;real world application;software industry;business process management;business process re engineering;applied research;management information system;business process;software implementation;competitive advantage;design methodology	Business process management has been a very active subject in practice, software industry and research for the last ten years. Many important contributions are in the business process modeling and its software implementation. Development of Business process modeling software and its ability of using Web Services are key factors for the popularity of the subject. Now businesses are increasingly capable of designing and redesigning business processes to improving business operations and reap benefits, even gaining a competitive advantage. However, research in the evaluation of business processes is lacking behind those of modeling techniques. Past studies have been either on the internal quantitative performance measures or on the satisfaction of customers using qualitative measures. In this paper an attempt is made to combine all relevant measures (with respect to the goals of the business process) into one overall measure. The overall measure is to reflect all stakeholders’ perspective and importance on the goals of business process in question. The conceptual model is believed to be a promising tool. Some issues of the model are highlighted and briefly discussed for future research.	additive model;business process;computation;hoc (programming language);process modeling;software industry;web service	Vincent C. Yen	2009	Business Proc. Manag. Journal	10.1108/14637150911003757	web service;analytic hierarchy process;economics;design methods;systems engineering;engineering;knowledge management;business process management;conceptual model;marketing;management information systems;management science;business process;management;business process modeling;competitive advantage;measurement	Web+IR	-80.47910053261114	9.273253126666965	20773
18b5ec4fb46a85adcd67e7ad277907b60580c655	using global pairs for reducing software development time	cycle time;project management;project manager;distributed team;software development;group work;self organization;global software development;software process	"""With globalization, many software corporations have engineering groups working in different time zones. While a globally distributed team with engineers in different time-zones has been leveraged successfully in maintenance for reducing response time, not much work has been done on reducing the time in a development project, and globally distributed teams are mostly used to provide capacity benefit. We propose the use of global-pairs as a simple method of organizing global resources for leveraging time zone differences for reducing the cycle time. Instead of assigning tasks to individual resources, a project can assign tasks to global-pairs, each having one resource working in one time zone and the other in opposite time zone. Each global-pair is self-organizing and divides the work in a manner such that work within a task progresses continuously, thereby reducing the time to complete the assigned task by up to a half. Use of global pairs does not unduly complicate project management -- a key difficulty in global software development -- as a project looks same as before, except that some of the resources now """"work faster"""". Initial experiment with a global pair in the coding phase of a live project suggests that the concept is feasible and can reduce the cycle time significantly."""	organizing (structure);response time (technology);self-organization;software development	Pankaj Jalote;Arvind Gupta	2011		10.1145/1953355.1953372	project management;team software process;self-organization;simulation;work breakdown structure;cycle time variation;computer science;systems engineering;engineering;software development;software engineering;project management 2.0;project management triangle;management;software development process	SE	-67.58537674764735	21.07508827141938	20782
7d3cc6f79e72fa95d960c338d9644bb15f234922	strategy, ownership and space: the logistics of collaborative interaction	mensch und computer 2013 workshopband		logistics	Robert Porzel;Adeel Naveed;Yuting Chen;Marc Herrlich	2013			knowledge management;operations management;business;management	HCI	-91.65863849793143	24.8461460360738	20802
024d3d498872238941dd568865d41babb485a389	an empirical investigation of system changes to frame links between design decisions and ilities	adaptability;evolvability	Maintaining system performance in the presence of uncertainties in design and operating environments is both challenging and increasingly essential as system lifetimes grow longer. In response to perturbations brought on by these uncertainties, such as disturbances, context shifts, and shifting stakeholder needs, systems can continue to deliver value by being either robust or changeable. These lifecycle properties, sometimes called “ilities”, have been proposed as means to achieve system value sustainment in spite of changes in contexts or needs. Intentionally designing for these lifecycle properties is an active area of research, and no consensus has formed regarding how these and other “ilities” might trade off. This paper describes ongoing research that investigates empirical examples of system changes in order to characterize these changes and to develop a categorization scheme for framing and clarifying design approaches for proactively creating ilities in a system. Example categories from the data for system changes include: the perturbation trigger for the change, the type of agent executing the system change, and the valid lifecycle phase for execution. In providing a structured means to identify system change characteristics, this paper informs future research by framing possible relationships between ilities and design choices that enable them. © 2012 Published by Elsevier Ltd. Selection	categorization;cluster analysis;computer science;data mining;framing (world wide web);heuristic (computer science);institute for operations research and the management sciences;non-functional requirement;systems engineering	J. Clark Beesemyer;Adam M. Ross;Donna H. Rhodes	2012		10.1016/j.procs.2012.01.010	simulation;artificial intelligence;data mining;management science	AI	-73.41678342485163	11.195133940085062	20833
888c74ca86b86dc9e3e4120eb9e0f510f6096f34	processus d'acquisition d'un dictionnaire de sigles et de leurs définitions à partir d'un corpus		"""De nombreux domaines comme la biologie ou la médecine voient naître chaque jour de nouveaux termes et abréviations, notamment des sigles. Un s igle est un ensemble de lettres initiales servant d’abréviation, par exemple """"RATP"""" peut ê tre associé à la définition (aussi appelée expansion) """"Régie Autonome des Transports Parisie ns"""". Nos travaux ont consisté à développer un logiciel afin de faciliter l’acquisition ou l’ enrichissement de dictionnaires en extrayant automatiquement, à partir de diverses sources, l es igles et leur(s) définition(s). Une fois ces dictionnaires constitués, l’approche AcroDef que nous avons proposée dans (Roche et Prince (2007)) consiste à établir la définition pertinent e d’un sigle présent dans un document. Dans ces documents, la définition n’est pas toujours présent e d’où la difficulté du traitement. Dans ce contexte, il est donc essentiel d’avoir à dispositio n un dictionnaire adapté, ce qui justifie les travaux présentés dans cet article. De nombreuses méthodes pour extraire les sigles et leur(s) d éfinition(s) ont été développées (Larkey et al. (2000); Okazaki et Ananiadou (2006)). La plup art des approches de détection de sigles dans les textes s’appuient sur l’utilisation de ma rqueurs spécifiques associés à des heuristiques adaptées. Certains travaux récents (Okazaki et Ananiadou (2006)) consistent à associer ces approches à des mesures statistiques spécifiqu es po r améliorer la qualité des méthodes d’acquisition de dictionnaires. L’approche que n ous avons développée se compose de deux étapes successives qui sont détaillées dans la secti on 2."""	bibliothèque de l'école des chartes;grand dictionnaire terminologique;linear algebra;lo que tú quieras oír;prince;reactions to the november 2015 paris attacks;relevance;sword art online: progressive;word lists by frequency	Vladislav Matviico;Nicolas Muret;Mathieu Roche	2008			capacitive sensing;electromagnetic coil;transformer;interrupter;current transformer;fault (power engineering);fault detection and isolation;electrical engineering;computer science;circuit breaker	Crypto	-106.06580756624328	13.900831800812599	20843
6921030d6f8e352c87d3858a211394152ee52b93	r&d and catch-up effect among software-as-a-service firms: a stochastic frontier approach	software as a service;spillover	Since its inception, SaaS market has been one of the fastest growing segments in the software industry. This paper is the first attempt to measure the productivity of pure-SaaS firms by adopting a stochastic frontier approach. Using an annual dataset from 2002 to 2009, we conduct a two-stage analysis. In the first stage, we derive the efficiency scores of each SaaS firm. We found average technical efficiency has been increasing due to catch-up effect in recent years. In the second stage’s analysis, R&D investments are found to be negatively associated with SaaS firm’s technical efficiency. Our results also show that R&D investments significantly contribute to the 1-year growth of technical efficiency of SaaS firms.	fastest;software as a service;software industry	Chunmian Ge;Ke-Wei Huang	2011				SE	-83.82100403601018	7.205506562470902	20978
232f219ae49aa7f78e9755c2aae89e92d0def0e0	maschinelle übersetzung - ein überblick		Die Idee der formalen Manipulation von Sprachen geht auf die philosophischen Traditionen von Geheimund Universalsprachen, wie sie Ramon Llull oder Gottfried Wilhelm Leibniz begründet haben, zurück. Bis heute ist die Maschinelle Übersetzung (MÜ) Königsdisziplin der Sprachverarbeitung geblieben: Die Fortschritte seit den ersten praktischen Versuchen sind auf den ersten Blick nur bescheiden. Dabei haben sich im Verlauf der Jahrzehnte zahlreiche unterschiedliche Ansätze zur MÜ gebildet. Nach einer von linguistischen Theorien dominierten Phase stehen seit Beginn der 1990er Jahre wiederentdeckte mathematische Methoden im Vordergrund. Im vorliegenden Beitrag werden die wichtigsten Ansätze eingebettet in ihren historischen Kontext vorgestellt. Besonderes Augenmerk gilt dabei dem regelbasierten und dem statistischen Ansatz.	internet explorer;sie (file format)	Daniel Stein	2009	JLCL		performance art;philosophy		-104.30523074258689	33.69183553705634	21000
b1d49a662031f0d8bdd0f8a5bff3bd5acbbc90d7	räumliche videoconferencing-ansätze: effizienz und soziale präsenz im konflikt	research article			Jörg Hauber	2008	i-com	10.1524/icom.2008.0012	multimedia;videoconferencing;sociology	Logic	-96.01443314746261	27.645567165973613	21024
9a9643601989088ace41382b3c1cc61e1b4d5633	blockchain-oriented software engineering: challenges and new directions		In this work, we acknowledge the need for software engineers to devise specialized tools and techniques for blockchain-oriented software development. Ensuring effective testing activities, enhancing collaboration in large teams, and facilitating the development of smart contracts all appear as key factors in the future of blockchain-oriented software development.	bitcoin;smart contract;software development;software engineer	Simone Porru;Andrea Pinna;Michele Marchesi;Roberto Tonelli	2017	2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C)		software design description;software peer review;systems engineering;software engineering;software construction;package development process;software development;computer engineering;personal software process;software engineering process group;social software engineering;engineering	SE	-66.76766424581481	23.21919097304349	21069
19ac1501158eeb6fd2b8e7f5747b09cd0c4d4259	a study on classification of insider threat using markov chain model			insider threat;markov chain	Dong-Wook Kim;Sung-Sam Hong;Myung-Mook Han	2018	TIIS	10.3837/tiis.2018.04.027	distributed computing;machine learning;insider threat;computer science;markov chain;artificial intelligence	ML	-64.46129175887472	60.11905452201312	21073
34c3acc44a42dd93bcd57826439097fd8aaf8f48	i don't remember what my designation is: classifying indian software workers		The success of Indian software industry is attributed largely to the quality of workforce it holds. Harnessing the software workforce is indispensable to India to maintain its growth in the global software services industry. Given this, need to reflect on the nature of software workforce necessitates an understanding of occupational classification in India. Review of literature shows that occupational classification of software workers is outdated, and is not adequately studied. On the basis of the work content, present paper classifies the software workers into four categories: writers, developers, designers and supervisors. Data for the paper was collected through task inventory and semi-structured interviews primarily from two software firms located in Bangalore.	semiconductor industry;software industry	P. Vigneswara Ilavarasan;Arun Kumar Sharma	2005				SE	-82.31736601625232	12.891858399779752	21091
263e27a727f3826cd325308d0c38a4ab0c2b8aad	a primer on nosql databases for enterprise architects: the cap theorem and transparent data access with mongodb and cassandra			apache cassandra;cap theorem;data access;mongodb;nosql;primer	Fumbeya Marungo	2018			nosql;cap theorem;database;computer science;data access;enterprise architecture	OS	-96.53035550402932	31.469087939364172	21140
5f0d0f56ac8f65e20508bd6e4877dbf1e3245a95	rahmenbedingungen für den it-einsatz in der hochschulverwaltung	den it-einsatz;der hochschulverwaltung			Uwe Marquardt	2001				Vision	-101.13069866543654	27.342827498902253	21169
7e609849527a8927f1983cf3c61bf2eaffefd499	research on the reduction of human resources cost by data mining technology-a case study of government social insurance	human resource;data mining	A connector is disclosed for connecting together plies, or wythes, of pre-cast concrete wall or ceiling panels which have the necessity of being cast in several plies or layers. The connector joins together first and second concrete layers with an intervening insulation layer. Also disclosed is a method for creating these concrete panels using the connector and an insert tool for use in inserting the connector.	data mining	Kuo-Chung Lin;Ching-Long Yeh;Meng-Jong Kuan	2009			business;social insurance;ceiling (aeronautics);data mining;government;joins;human resources	HCI	-71.69404434646962	7.625586438183535	21179
0d7b7934593d2cd68f41593371f9f339820c8faa	résolution parallèle de sous-buts indépendants dans le graphe de connexion de r. kowalski				Christian Percebois;Ivan Futó;Irène Durand;C. Simon;B. Bonhoure	1986				Crypto	-104.92770536976994	14.655745915064374	21185
6ccf5150d5debb13be1c75cd49a0ee316ab26e37	identification of necessary factors for successful implementation of erp systems	successful implementation;necessary factors;erp systems	The identification of factors which are necessary for successful implementation of enterprise resource planning (ERP) systems is of great importance to many organizations. ERP systems have to be configured and implemented, often by a team of business analysts and consultants over a period of months or years. The process is lengthy and expensive, and may include extensive business process re-engineering. Given that the investment in these systems, including both the package and associated implementation costs, is measured in millions of dollars, failure to meet deadlines and budgets may result in substantial company loss. However, the literature on the ERP implementation process, and the factors which either facilitate or impede its progress, is not extensive. This research reports the first stage of a research program which seeks to understand successful implementation of ERP systems. The objective, of the first phase was to identify what factors are necessary for successful ERP implementation, where success is understood as adherence to time and budgetary constraints. To accomplish this objective the authors studied 42 implementation projects by interviewing 10 senior members of multiple’ ERP implementation teams. Based on these interviews, 10 candidate necessary factors for successful implementation of ERP systems are identified. Of these 10, three are of paramount importance. They are management support of the project team and of the implementation process, a project team which has the appropriate balance of business and technical skills, and commitment to the change by all stakeholders. The next phase of the research will involve in-depth case studies to explore the relationship between these factors and broader contextual and process issues.	enterprise resource planning	Anne N. Parr;Graeme G. Shanks;Peta Darke	1999			business;business process;process management;implementation;enterprise resource planning;interview;project team;budget constraint	Robotics	-77.08838625238134	9.963286117081902	21192
88e870b97d5549a5f8fc7a74a2ed2c87ff61a0fd	an evaluation of technical efficiency and managerial correlates of solid waste management by welsh smes using parametric and non-parametric techniques	forecasting;reliability;project management;information systems;maintenance;soft or;information technology;solid waste management;packing;environmental policy;stochastic frontier analysis;operations research;location;investment;journal;journal of the operational research society;inventory;purchasing;history of or;logistics;technical efficiency;support group;marketing;scheduling;production;communications technology;computer science;operational research;efficiency measurement;data envelope analysis;european union;environmental regulation;applications of operational research;or society;economic growth;jors;management science;infrastructure	Strong economic growth and environmental regulation stimulus make Welsh small and medium enterprises' (SMEs) sustainability performance merit investigation in the context of European Union (EU) sustainability initiatives. This is due in part to strong economic growth and the stimulus provided by environmental regulation. We use stochastic frontier analysis, a parametric econometric technique to generate estimates of the technical efficiency of solid waste management by 299 Welsh SMEs in 2003. We demonstrate that the ranking and efficiency scores of the Welsh SMEs studied correlate significantly with non-parametric data envelopment analysis efficiency measures and are related to the use of environmental auditing practices and the use of local business support groups, but not to monitoring of waste expenditures and publication of environmental policies.		James J. Cordeiro;Joseph Sarkis;D. Vazquez-Brust;L. Frater;J. Dijkshoorn	2012	JORS	10.1057/jors.2011.22	project management;logistics;inventory;economics;forecasting;investment;computer science;marketing;operations management;reliability;management science;location;management;operations research;information technology;scheduling	DB	-84.10002706185196	7.399789945465484	21202
93500a2fbf5b4ff7892fea096b007d69f3232143	datenschutz in europa - plädoyer für einen neubeginn	ciencias juridicas;dcho procesal y penal;dcho civil y mercantil		europa	Jochen Schneider;Niko Härting	2014	Computer und Recht	10.9785/cr-2014-0507		Theory	-102.95535019144656	27.235178494733734	21215
4ff5461af939f5ab50d9c5c2cd76095c0e195529	the new branch columbus project at royal bank of scotland: the implementation of large-scale business process re-engineering	gestion entreprise;restructuration;project management;aplicacion;project manager;information technology;restructuracion;firm management;technologie information;organizacion proyecto;banking system;control problem;large scale;client server;reingenieria;estudio caso;reingenierie;business process re engineering bpr;etude cas;gestion projet;administracion empresa;it management;tecnologia informacion;application;reengineering;business process;royal bank of scotland	Copyright (c) 1997 Elsevier Science B.V. All rights reserved. The paper examines the findings from a longitudinal case study on the implementation of a large scale business process re-engineering (BPR) project at the Royal Bank of Scotland. The New Branch Columbus project was conceived to radically restructure the traditional branch banking system. It represented a major organizational, managerial and technical college. The research found important barriers impeding BPR at the bank. Many originated with the development and implementation of critical information technologies underpinning the project. The structural separation of the business units and IT division engendered disagreements amongst senior managers and IT staff about the key strategic and operational aims of the Columbus project. Project managers were faced with a control problem in managing permanent and contract technical staff working with the latest client server technology. Senior business and IT managers tended to under-estimate the technical difficulties of interfacing PC based client server technology with the mainframe system. Faced with these challenges, efforts to implement large-scale BPR became diluted in practice.	business process;columbus	Wendy L. Currie;Leslie P. Willcocks	1996	J. Strategic Inf. Sys.	10.1016/S0963-8687(96)80004-7	project management;economics;business process reengineering;engineering;electrical engineering;marketing;operations management;business process;management;operations research;information technology;client–server model	DB	-81.2201617220459	8.393359706345025	21239
f77dcd021d7bcf85fc5b4671766fcb6b689b1406	a group decision making approach for evaluation of erp critical success factors using fuzzy ahp	user interface development;software;user interfaces business process re engineering decision making enterprise resource planning management of change software engineering;mathematical model equations companies pragmatics software;pragmatics;change management;change management group decision making erp critical success factors fuzzy ahp analytical hierarchy process business process reengineering software development user interface;user interface;fuzzy ahp;fuzzy ahp enterprise resource planning critical success factors;companies;software engineering;erp system;critical success factors;erp;software development;enterprise resource planning;mathematical model;management of change;group decision making;erp implementation;fuzzy analytic hierarchy process;business process re engineering;analytical hierarchy process;critical success factor;business process reengineering;user interfaces	Although ERP systems have lots of advantages for the organization, the ERP implementation is not straightforward and involves significant risks. Several studies have conducted to identify the critical success factors (CSFs) in the ERP implementation process, but most of them are lacking of systematic efforts to classify and evaluate CSFs. To achieve this aim, a structured methodology based on a fuzzy analytical hierarchy process is proposed to rank a set of critical success factors related to ERP implementation process. The proposed methodology has been implemented at a refrigerator manufacturer company in Iran. The results of this study show that “Managers and employees readiness to change”, “Top management Support”, “Business Process Reengineering”, “Software and user interface development” and “Change management” are five top CSFs.	analytical hierarchy;business process;code refactoring;erp;enterprise resource planning;enterprise system;fuzzy logic;user interface	Mohsen Sadegh Amal Nick;Ayyub Ansarinejad;Samad Ansarinejad;Loghman Hatami Shirkouhi	2010	2010 Fourth UKSim European Symposium on Computer Modeling and Simulation	10.1109/EMS.2010.42	systems engineering;knowledge management;process management;business	SE	-76.85710507196734	10.97133397804893	21275
eef5bf140948af54e29a5a547205a5ae642ed6df	transformative influence of business processes on the business model: classifying the state of the practice in the software industry	business studies;corporate modelling;dp industry;inference mechanisms;strategic planning;strategy;business model;kpi;business data processing;software industry;management of change;business process	Fast changing business environments often force companies to rethink and renew their established business model. Often though, decisions to make changes to the current business model are made too late, when the current business is already struggling. One way to overcome this challenge is to continuously monitor business processes in operations and to adjust the business model according to changes in business processes. This paper clarifies the influence of business processes on the business model. Based on a literature review, expert interviews and inductive reasoning, we derive a classification framework for receiving new insights into the maturity of current KPI-systems and their strategic importance with regards to business model changes. While some companies consider the connection as so important that they set up sophisticated performance measurement systems, others rely much less on process KPIs to initiate business model changes. Investigating these differences marks a promising starting point for future research.	business process;capability maturity model;inductive reasoning;software industry;system of measurement	Amir Bonakdar;Tobias Weiblen;Christina Di Valentin;Theresa Zeissner;Anton Pussep;Markus Schief	2013	2013 46th Hawaii International Conference on System Sciences	10.1109/HICSS.2013.573	business model;business analysis;business transformation;strategic planning;business domain;business requirements;strategy;knowledge management;artifact-centric business process model;business process management;marketing;operations management;performance indicator;business case;electronic business;management science;business process model and notation;process management;business process;business process discovery;management;business rule;new business development;philosophy of business;business studies;business process modeling;line of business;business activity monitoring;business architecture	DB	-74.65997522491361	9.004849391444955	21304
de65343049fc06f24730b116737c72f06793cfa3	toward a business model reference for interoperability services	design artifact;reference model;business model;interoperability service utilities;enterprise interoperability;information management	The importance of interoperability for businesses is undoubted. After an evolution from electronic data interchange to interoperability in electronic business and enterprise interoperability both the scientific and the practitioners’ community are today discussing the notion of interoperability service utilities. Furthermore, researchers are studying decentralized and distributed interoperability approaches such as peer-to-peer networks, for example. However, a comprehensive investigation of business models for such decentralized approaches to interoperability is still missing. Drawing from recent literature on business modeling on the one hand and interoperability research on the other hand this paper designs a business model reference for interoperability services. The business model reference assumes interoperability information as an economic good and is applied in two case studies and evaluated from multiple perspectives. The paper contributes to the scientific body of knowledge as it proposes a novel design artifact which lays the foundation for a number of future research opportunities. 2013 Elsevier B.V. All rights reserved.	electronic billing;electronic business;electronic data interchange;enterprise interoperability;modeling perspective;peer-to-peer;reference model;requirement	Boris Otto;Verena Ebner;Ehsan Baghi;Ran M. Bittmann	2013	Computers in Industry	10.1016/j.compind.2013.06.017	business model;semantic interoperability;interoperability;reference model;computer science;engineering;knowledge management;marketing;data mining;database;information management;ws-i basic profile;cross-domain interoperability	Web+IR	-69.29176023821803	11.092237160180845	21400
eb4c46424b2a3da090821c978a6ceec0748029de	zum einfluss von datenstruktur und stichprobenumfang auf die trennwirksamkeit von diskriminanzanalysen mit verschiedenen dichteschätzern				Hans-Joachim Kaiser	1986				NLP	-99.99626065984292	26.775650443486086	21461
3be1c32c3635847dd7efee7b89dc98d6097703e1	nutzbarmachung genetischer algorithmen für den automatisierten entwurf flexibler s-bahn-betriebsregime (using genetic algorithms for the automatic design of flexible timetables in suburban railways)			genetic algorithm;schedule	Thomas Albrecht	2006	Automatisierungstechnik	10.1524/auto.2006.54.3.105	simulation;engineering;transport engineering	EDA	-93.70137043207944	23.741329317608905	21475
5f110a5582afb9dc33080d67b00f41476d1e8184	un langage temps réel dynamique pour scénariser l'interaction musicien-machine				José Echeveste	2014	Technique et Science Informatiques	10.3166/tsi.33.587-626		Logic	-104.60906243611352	15.350154858490086	21512
902908a55e70461da75a2f906d3eb7f16f133301	ontologiebasierte kennzahlenentwicklung für virtual production intelligence				Christian Buescher	2015				AI	-97.03891099313283	21.63334711013697	21522
7575de538c94d168a6de865e1ecacdde10162b08	applicability of software reliability growth modeling in the quality assurance phase of a large business software vendor	software metrics;quality assurance;software;industrial case study;quantitative analysis software reliability growth modeling quality assurance phase business software vendor agile process organization;software reliability quality assurance software quality application software testing predictive models computer industry operating systems computer applications data analysis;quality assurance phase;business software vendor;system under test;testing;agile process organization;quantitative analysis;organizations;qualitative reasoning;software reliability growth model;software reliability;software reliability software metrics software quality;software quality;software reliability growth modeling;data models	Software reliability growth modeling aims to use data on experienced failures for prediction of future quality levels. We analyze the applicability of this approach in the context of business software that is still in the quality assurance phase and has not been released to the customer yet. We find that the approach is not applicable in our research setup that is characterized by an agile process organization. We identify qualitative reasons why the models' assumptions are violated in our industrial case study and conduct a quantitative analysis whether data availability challenges can be addressed by mapping issue tracking data as the only available data source to the required system under test execution time. The derived metrics support managers in their decision whether their processes are suited for software reliability growth modeling.	agile software development;business software;database;embedded software;issue tracking system;run time (program lifecycle phase);software quality;software reliability testing;system under test;test effort	Arne Beckhaus;Lars M. Karg;Gerrit Hanselmann	2009	2009 33rd Annual IEEE International Computer Software and Applications Conference	10.1109/COMPSAC.2009.196	software security assurance;reliability engineering;quality assurance;personal software process;verification and validation;software quality management;computer science;systems engineering;software reliability testing;software development;software engineering;software construction;software deployment;software quality control;software quality;software metric;software quality analyst;software peer review	SE	-63.45225420403604	30.844949507610607	21586
fdde0e6eb30f696fe43f9ea437e4c65451e7197a	know risk - know fun		Die aktuellen Veränderungen in der Finanzindustrie lösen nicht nur in der Finanzbranche weitreichende Veränderungen aus. Es wird stärker als bisher die Aufgabe der Unternehmen sein, dass die richtigen Mittel zum richtigen Zeitpunkt effizient eingesetzt werden. Denn die hohen finanziellen Belastungen beim Scheitern von IT-Projekten und Software-Entwicklungsprojekten können Unternehmen bis an den Rand der wirtschaftlichen Bedrohung führen. Eine „Garantierte Qualität“ muss daher der höchste Anspruch industrieller Software-Entwicklung sein und bleiben. Die Erreichung einer „Garantierten Qualität“ stellt dabei aber immer noch eine große Herausforderung dar. Bisher wird typischerweise eine umfassende Behandlung von Qualität durch Qualitätsmodelle und darauf aufbauenden Bewertungsmethoden erwartet. Eine „Garantierte Qualität“ im Rahmen einer effizienten Abwicklung von ITProjekten oder Software-Entwicklungsprojekten zu erreichen, wird allerdings nicht durch die Auswahl des richtigen Qualitätsmodells bestimmt. Der Erfolg hängt vielmehr davon ab, wie professionell die möglichen Projekt-Risiken und ProjektUnsicherheiten identifiziert, bewertet und gemanagt werden. Strukturiertes und pro-aktives Risikomanagement wird in der heutigen Zeit für jedes Unternehmen überlebensnotwendig. Gerade in der aktuellen weltwirtschaftlichen Situation wird sich zeigen, wer Risiken und Unsicherheiten erfolgreich identifizieren und managen kann. Oliver Mäckel, seit 1997 als Safetyund Risikomanager und Gutachter sowohl für softwareintensive Systeme als auch für Großanlagen unterwegs, hinterfragt in seinem Vortrag die gängigen Qualitätsmodelle und Risikoanalysestandards. Ferner werden in seinem Vortrag zudem Möglichkeiten und Szenarien diskutiert, wie man sich den Herausforderungen effektiv stellen kann.	die (integrated circuit);eine and zwei;gesellschaft für informatik;internet explorer;parity (physics)	Oliver Mäckel	2009			choline;pharmacology;medicine	OS	-106.15005748838612	33.29239757174013	21651
7bdf08fd50c0b232cda8533392393272f50f2248	it-strategie und it-controlling im wandel am beispiel eines großunternehmens	it strategy			Heidi Heilmann	2001	HMD - Praxis Wirtschaftsinform.		marketing;technology strategy;process management;engineering	Robotics	-93.79307081422598	27.462207843295424	21679
d048c87bd154c5cb34192cb603cd0530f1331bb0	an integral it continuity framework for undisrupted business operations	integrated approach;service provider;risk management;undisrupted business operation it continuity business continuity risk cluster it service provider;dp management business continuity risk management;business continuity;dp management;business continuity companies disaster management programmable logic arrays portfolios insurance availability data security	In this paper we present an IT continuity framework which deals with business continuity issues within organizations. The approach is based on an optimal mix between five groups of continuity measures that are associated with three risk clusters. Most organizations do have some continuity measures in case their level of operation is disrupted. However, these continuity measures are often isolated from each other and do not form an integral approach. They neither do cover the entire incident field. This framework supports the uniformity that exists among known continuity measures. Because of its generic nature, IT service providers can use the framework to organize their (existing) IT continuity portfolio in order to provide an optimal continuity solution to their customers.	business continuity;circuit complexity;scott continuity	Remko Helms;S. Van Oorschot;J. Herweijer;M. Plas	2006	First International Conference on Availability, Reliability and Security (ARES'06)	10.1109/ARES.2006.27	recovery time objective;actuarial science;knowledge management;operations management;business;disaster recovery	SE	-69.05086340588628	8.64733124223938	21680
67346fd301031a9a00e361aaad8b16aa40753c84	using influence diagrams to aid the management of software change	software management;decision process;resource availability;influence diagram	In a large software management programme, the number of software changes and enhancements requested for inclusion in the next software release often far exceeds the implementation resources available. Thus, during the preceding months before the final decision is made on which changes to include, there needs to be a way of incorporating all the different factors that influence these possible changes into a coherent set of information to enable good decisions to be made. This paper describes the use of influence diagrams to implement a risk model to formalise the combining of these different factors to aid the decision process. This model not only reflects the likelihood of all the necessary criteria for a requested change to be viable being met, but also considers the financial or other benefits to the organisation that would result from the change being included in the next software release.	coherence (physics);financial risk modeling;influence diagram;software project management;software release life cycle	Colin J. Burgess;Ilesh Dattani;Gordon Hughes;John H. R. May;Kearton Rees	2001	Requirements Engineering	10.1007/PL00010358	reliability engineering;change management;influence diagram;computer science;systems engineering;software development;management science	SE	-71.21013449000043	19.44176583136267	21714
e0b5f0e01757b42739f0d157b33c2cc1ca1c961c	software development for computers and communication at nec	control systems;application software;communication system software;software development;production;national electric code;productivity;programming;software quality;embedded software;programming national electric code software quality productivity application software production costs embedded software communication system software control systems	T o accommodate the expanding use of computers, planners at NEC in Tokyo are projecting increased communications between systems. We already think of the coming decades as the C&C age the computing and communications age. We recognize too that C&C systems and equipment need a great deal of software. We haxe begun efforts to meet this demand by increasing software production and the number of software engineers. And at NEC, software quality remains as important as production.	computer;haxe;software development;software engineer;software quality	Kiichi Fujino	1984	Computer	10.1109/MC.1984.1659000	programming;personal software process;medical software;long-term support;national electrical code;verification and validation;productivity;application software;software sizing;embedded software;computer science;control system;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;operating system;software engineering;software construction;software walkthrough;resource-oriented architecture;software measurement;management;software deployment;software quality;software system;avionics software;software peer review	SE	-68.45166659331598	27.9997378521316	21735
c48e11a2c4be2fc446a3b008a22aa971c6eefd75	software requirements - objects, functions, and states			requirement;software requirements;state (computer science)	Alan M. Davis	1993				Theory	-62.93136731703444	24.78130519892294	21745
cd8629cfcb2161e70136984296e4d63037ba3746	online workload, performance and scalability of a database production system: a case study	databases;projected business growth scalability database production system enterprises advanced computing technologies cost saving computer downsizing business success customer site online work load characterization performance evaluation;information systems;performance evaluation;database management systems;cost saving;production system;software performance evaluation;system performance;computer aided software engineering;program testing;systems analysis;business data processing;business;scalability databases production systems computer aided software engineering business system testing costs system performance information systems hardware;production systems;system testing;scalability;program testing software performance evaluation systems analysis database management systems business data processing;hardware	Today, enterprises are seeking solutions to integrate their business functions by using advanced computing technologies. Meanwhile, these enterprises are cutting the information centers’ budgets to lower the costs. Computer downsizing becomes essential for cost saving. However, computer downsizing also threatens those enterprises whose business success depends heavily on delivering fast, accurate service to customers. System performance is the number one issue followed by the scalability. This paper presents an experimental study conducted on a system that mimicked a production system installed at a customer site. The experiment was designed to focus on the online workload characterization and the performance evaluation when the use of the system changed along with the projected business growth.	database;experiment;performance evaluation;production system (computer science);scalability	Mei-Chen Hsueh	1993		10.1109/CMPSAC.1993.404178	simulation;computer science;systems engineering;engineering;operating system;software engineering;database;computer performance;production system	DB	-65.44860348445407	39.96148946894597	21782
c15e5f63c33696bd9bb4fa4477503e9fa96485de	the impact of information lifecycle management process in the nigerian financial sector	money;banking;securities trading;business modelling;simulation;equity capital markets;financial services;life cycles;banks;cheque processing;cash transactions;finance sector;information management;information lifecycle management;nigeria;business information systems;financial sector	The main objective of this paper focuses on the theoretical and practical approaches in the banking sector, with emphasis being placed on financial service operations of cheque processing and securities trading, and in managing financial information. The banking sector was identified as it is presently the most vibrant and emerging sector in the financial services in Nigeria, which was mentioned in the Financial Times. In 2007, the banking sector has been the driving force behind Nigeria’s equity, which is in excess of $3.3bn in equity capital market transactions. The banks that were investigated in this research paper included banks that incorporate functions in the equity market as part of their daily operations and in the possession of relevant information on securities trading as well as information on cheque processing procedures. The paper concludes by suggesting that, there is above average knowledge and understanding of ILM within the financial sector in Nigeria. Therefore, it was recommended that the application of ILM techniques should be improved upon in the management of information in the Nigerian financial sector and to obtain the best results at every stage of the information lifecycle.	financial times;offset binary;social capital	Wafi Al-Karaghouli;Eniola B. Fadare	2010	IJBIS	10.1504/IJBIS.2010.034008	biological life cycle;economics;financial services;broker-dealer;computer science;electrical engineering;money;marketing;finance;management information systems;equity capital markets;financial system;information management;management;investment banking;commerce	DB	-84.88104583405065	4.969061933573567	21816
618c9f58732800fc35497bc45b0dfb3d52fe0a36	experience feedback in product lifecycle management		Abstract Given the popularity of industrial enterprises for Product Lifecycle Management (PLM) information systems capable of supporting the entire product development process, we see the emergence of new needs and new research directions in the operation of these dynamic complex environments. Reference standards are applicable to the services and industries which bring innovation and technologies to a fast-growing and demanding market. To obtain perfect control of business risks and performance and to ensure “zero defect”, standards specific to the fields of transport, emergency (IRIS IN 9100 …) and generic standards (ISO 9001 …) are more restrictive. They involve full transparency and rigor in flawless quality management processes and monitoring products. In this field, knowledge management is paramount; it helps improve overall performance of industrial systems by structuring the information assets acquired by the company stakeholders. In a way, it is the substantive development of our research. We detailed the approach adopted to implement the Experience Feedback (EF) system dedicated to the product in the PLM business. We presented a first action with the objective of formalizing the implicit experiences generated following the response to a triggering event. In this work, we mainly considered negative events for which the information to be collected are clearly identified. We propose an approach combining Problem Solving and EF adapting the level of commitment to the criticality or importance of the problem addressed. To instantiate this approach in PLM, we have chosen to rely on the Change Management Process (CMP) because, firstly, it involves changes in product data and, secondly, it usually concerns driving developments for correction or improvement of the technical specifications related to the production process.		Philippe Clermont;Bernard Kamsu-Foguem	2018	Computers in Industry	10.1016/j.compind.2017.11.002	information system;new product development;systems engineering;quality management;business process;change management;product lifecycle;business risks;engineering;product management	DB	-70.47515658474784	8.049171322348295	21853
a7f99e8d022b027d1905d12cbb7fd42d47868179	integration einer serviceorientierten architektur beim sächsischen landeskontrollverband e. v.-dargestellt am beispiel der plattform fitness monitoring		Der Erfolg eines landwirtschaftlichen Dienstleisters leitet sich entscheidend daraus ab, wie er es versteht, seine Prozesse, seine Mitarbeiter und seine Daten miteinander zu verbinden. Dies gilt nicht nur innerhalb des Unternehmens, sondern auch nach außen, z. B. mit Kunden, Lieferanten und Partnern. Für dieses Zusammenwirken haben sich serviceorientierte Architekturen bestens bewährt.	internet explorer	Hartmut Berger	2010				DB	-104.0003855139405	33.07264503390676	21896
19656f85940f4b0e0f79471f90774ac440a21a03	strategic information systems and competitiveness: are firms ready for an ist-driven competitive challenge?	gestion entreprise;methode empirique;information systems as a competitive weapon;competitividad;metodo empirico;empirical method;firm management;estrategia;strategic information systems planning;strategy;planificacion;competitivity;administracion empresa;planning;strategic information systems;information system;planification;competitivite;strategie;systeme information;sistema informacion	Strategic planning for information systems technology (IST) and its use for competitive advantage have been discussed for some time. However, such research focuses on the planning method and experience of firms that have been successful in their efforts to use IST for competitive advantage. Not much attention has been paid to less successful organizations and to what they are doing to prepare themselves for IST-driven competition. This paper presents a study conducted among small-to-medium size firms showing that a large fraction of these businesses place surprisingly little emphasis on planning for information systems (IS) and these business have a rather low level of awareness of the potential impact of IS planning on competitiveness. These results point to the fact that organizations need help in becoming more proactive in linking IS planning to their competitive strategy.	competitive analysis (online algorithm);strategic information system	Constanza Hagmann;Cynthia S. McCahon	1993	Information & Management	10.1016/0378-7206(93)90067-4	planning;economics;strategy;engineering;operations management;empirical research;strategic information system;management;operations research;information system	ECom	-82.59718577894651	9.308185421431006	21924
a2728595e6ce56543fd3560c622d11a4d30606c7	modélisation statistique appliquée à la propagation atmosphérique des ondes électromagnétiques et à l'observation des précipitations. (statistical modeling applied to the atmospheric propagation of electromagnetic waves and remote sensing of precipitation)		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Modélisation statistique appliquée à la propagation atmosphérique des ondes électromagnétiques et à l’observation des précipitations Cécile Mallet		Cécile Mallet	2009				Crypto	-107.7011219070949	11.468888995059716	21955
fb016193056a1b8771867ec5deec0fae65b9f8af	découverte de lemmes par instanciation de métavariables dans les preuves par récurrence			substitution (logic)	Moussa Demba;Khaled Bsaïes	2002				Crypto	-104.1174963368271	13.042387815017372	21987
12da32e1b15ee74327634da6ad873c68682afe91	framework for improved capture of usability requirements through usage-centred design		This research makes an in-depth examination and comparison of plan-driven and agile methods in software design to justify the need for a more balanced approach that combines the controlling and disciplining capabilities of the former with the flexibility of the latter. It also examines the concept of software usability and the process of gathering requirements in software engineering. It is noted that pure agile methodologies tend to ignore usability for end users, hence the attention to User-Centred Design (UrCD). Software development methods based on UrCD attempt to alleviate this neglect, but they too are not sufficiently grounded in traditional plan-driven approaches that can adequately target usability concerns, especially during the planning phase of development. Capturing usability requirements could be key to ensuring a high degree of software usability for end users. It is suggested that Usage-Centred Design (UgCD), with its focus on actual software usage rather than users per se, can satisfy this need for greater software usability through increasing the likelihood of achieving a more complete and precise capture of usability requirements. This methodology introduced by Constantine combines task modelling as its plan-driven phase for identifying users, roles and essential tasks with an agile iterative component for facilitating continuous consultation with users to also enable refinements to be made to the requirements. The focus in this study is on the requirements analysis phase of UgCD to demonstrate how it can be applied for better capturing usability requirements in terms of completeness and preciseness. The usability aspects analysed are learnability, rememberability, efficiency, reliability, and user satisfaction. Research was carried out involving a survey, interviews and a demonstration of UgCD at a higher education institution in Saudi Arabia during a revision of an e-learning software, and a further follow on survey and interview. The survey investigated existing usability requirements gathering practices, and the current methods used for the sake of ensuring and thereafter testing for usability. The interviews provided insight into these developer practices to especially ascertain how well they are able to capture usability requirements for particular aspects of usability and their awareness of these aspects. A total of 212 software developers working in higher education institutions throughout the Saudi kingdom participated in the survey, 20 of them participated further in the interviews from three different cities, and the UgCD demonstration was held at one higher education institution. The survey analysis included frequency, factor and correlational analyses, and the interviewee responses were analysed using thematic analysis.  The list of usability requirements captured during the UgCD demonstration was compared to the original capture at the time of construction and to the pre-UgCD period when usability questionnaires were being used. The UgCD implementation enabled a 7.5-fold increase in completeness and 43% improvement in preciseness compared with the original capture, and a 2.5 gain in completeness and 24% improvement in preciseness compared to the requirements captured using usability questionnaires. The pre-UgCD survey results and interview findings are also presented and discussed that show a need to promote not only UgCD, but also to raise awareness of usability itself and make developers appreciate its importance. This led to developing a framework of principles for implementing UgCD, which is presented to guide developers in capturing usability requirements for enhanced software usability. However, it is noted that in line with the need to understand and promote usability, developers also need to be encouraged to consult frequently with their potential and existing users and become accustomed to holding frequent meetings with them. These changes would be necessary in order to be able to implement UgCD fully. Regardless, the potential of UgCD is established at least with respect to its capability to make developers and users focus on usability and in capturing a more complete and precise set of usability requirements that pertain to a wide range of usability aspects. Also, the post-UgCD survey with the meeting participants and interview with the leading developer give further positive indications for the success of the UgCD trial, and its potential for being used to enhance software usability.	requirement;usability	Kholod Jeza Alotaibi	2015			usability goals;pluralistic walkthrough;think aloud protocol;web usability;component-based usability testing;cognitive walkthrough;simulation;usability;human–computer interaction;agile usability engineering;systems engineering;engineering;system usability scale;usability engineering;universal usability;software documentation;heuristic evaluation;usability lab;usability inspection	EDA	-72.07240475202855	23.56951799962465	22004
00d13509571365d8840c7a5897fa13504870eeaa	state-of-the-art of design, evaluation, and operation methodologies in product service systems	pss operation methodologies pss om;product service system pss;pss design methodologies pss dm;pss evaluation methodologies pss em	Product service systems (PSS) – integration of products and services – with aims to achieve economic profit and reduce environmental impacts, is a hot issue in academia. The purpose of this study is to comprehend the state-of-the-art in the field of PSS design, evaluation, and operation methodologies (PSS-DEOM) by conducting a systematic literature review. Up to 258 publications related to PSS-DEOM were reviewed and divided into three categories: PSS design methodologies (PSS-DM), PSS evaluation methodologies (PSS-EM), and PSS operation methodologies (PSS-OM). Based on the findings, future research trends were proposed and discussed.		Min Qu;Suihuai Yu;Dengkai Chen;Jianjie Chu;Baozhen Tian	2016	Computers in Industry	10.1016/j.compind.2015.12.004	engineering;electrical engineering;operations management;engineering drawing	EDA	-71.9386491982376	6.850827473047768	22073
20518f09c916f68e525e5de51a8cc23446819126	direkte standardisierung bei den mantel-haenszel schätz- und testprozeduren				Knut M. Wittkowski	1994			statistics;cochran–mantel–haenszel statistics;psychology	HCI	-97.80241369360806	26.636051568653084	22079
69c1b88b0c04ab5a8723501b06eb4d4383a6efbb	miteilungen der schweizer informatiker gesellschaft · 4/2002					2002	Informatik-Spektrum	10.1007/s002870200225		NLP	-95.40801292827658	21.37053441013536	22127
5865f39862ab7531fac21c008fbb23155e3f8d7f	referenzprozesse für elektronische ausschreibungen aus sicht des industriellen einkaufs	gestion integrada;gestion integree;commerce electronique;entreprise;comercio electronico;compra;empresa;integrated management;information management;firm;achat;information system;systeme information;electronic trade;purchases;sistema informacion	Many companies and purchasing departments only possess a limited knowledge about the modelling of inter-company business processes for electronic procurement. In the past the discussion about electronic procurement was mostly focused on technical aspects. This article introduces a reference process model for procurement auctions. The process model is made up of a basic process, which describes a minimal process for procurement auctions, and a number of process alternatives, which allow for the adoption of the basic process to changing parameters and individual company requirements.	gesellschaft für informatik	Jana Buchwalter;Walter Brenner;Rüdiger Zarnekow	2002	Wirtschaftsinformatik	10.1007/BF03250859	procurement;computer science;information management;management;information system	Crypto	-68.68906434245041	5.036504143040973	22153
f68605487be50696cda2b8f98469f113569d4db9	efficiency and sustainability assessment for a group of farmers in the brazilian amazon	long period;non parametric regression;brazilian amazon;regression;data envelopment analysis;sustainability assessment;iso efficiency tiers;efficiency measurement;data envelope analysis;family farms	The aim of this paper is to use DEA models to evaluate sustainability in agriculture. Several variables are taken into account and the resulting efficiency is measured by comparison. The performance of family farms is analysed here (variables: farmed area, work force, and production). As agricultural sustainability depends on the maintenance of systems of production for long periods of time, the models were run for the years of 1986 and 2002. Tiered DEA models were used to group farmers in sustainability categories. Non-parametric regression models were used to identify the factors affecting the efficiency measurements. All the results indicate that the majority of the farmers increased their efficiency along the time. These improvements may support the existence of sustainability.	benchmark (computing);foremost;multitier architecture;production system (computer science);semiconductor consolidation;shader;technical support;whole earth 'lectronic link	Eliane Gonçalves Gomes;João Carlos Correia Baptista Soares de Mello;Geraldo da Silva e Souza;Lidia Angulo Meza;João Alfredo de Carvalho Mangabeira	2009	Annals OR	10.1007/s10479-008-0390-6	economics;computer science;environmental resource management;operations management;data envelopment analysis;mathematics;welfare economics	SE	-85.98185376853847	8.402093357443562	22180
4c8b77e99251aef8472eb8827d4917b391df756c	an analysis of techniques and tools for requirements elicitation in model-driven web engineering methods	elicitation;requirements;model driven web engineering	Until now, is well-known that Requirements Engineering RE is one of the critical factors for success software. In current literature we can find several reasons of this affirmation. One particular phase, which is vital for developing any new software application is the Requirements Elicitation, is spite of this, most of the development of new software fail because of wrong elicitation phase. Several proposals exist for Requirements Elicitation in Software Engineering, but in the current software development market is focusing on the development of Web and mobile applications, specially using Model-Driven methods, that's the reason why we asume that it is necessary to know the Elicitation techniques applied in Model-Driven Web Engineering. To do this, we selected the most representative methods such as NDT, UWE and WebML. We have reviewed 189 publications from ACM, IEEE, Science Direct, DBLP and World Wide Web. Publications from the RE literature were analyzed by means of the strict consideration of the current techniques for Requirements Elicitation.	model-driven integration;requirement;requirements elicitation;web engineering	José Alfonso Aguilar;Anibal Zaldívar;Carolina Tripp Barba;Sanjay Misra;Roberto Bernal;Abraham Ocegueda	2015		10.1007/978-3-319-21410-8_40	requirements analysis;requirements management;expert elicitation;computer science;requirement;requirements elicitation;data mining;requirements engineering;software requirements	SE	-64.63859807617636	19.118999614894204	22193
2c089d1aa38ffcffdc986b0d3ee6303c14b22cdb	"""bericht über das 6. jahrestreffen der gi-fachgruppe """"deduktionssysteme"""""""				Ulrich Furbach;Ulrich Hedtstück;Wolfgang Wernecke	1990	KI			Vision	-98.32409771316489	25.667177688768035	22202
27d9db355d096c7815eac5c66ed4668dd5cad8d8	traduction de requêtes relationnelles en requêtes objets (odmg-93)				Ahmed Mostefaoui;Jacques Kouloumdjian	1998				Crypto	-107.15670871164036	14.548293299328916	22246
ee3f8641e38babcc2231aa4f92a4f01323045db7	ein universalrelation-frontend für sql			sql	Hans Hermann Brüggemann;Bernd Teßmer	1993	GI Datenbank Rundbrief		database;sql;computer science	NLP	-96.70563570966536	31.123513195539722	22266
bcaea9483f42efa48545183424b51ce199b429de	anwendung der digitalen systemsimulation zur untersuchung des mengen- und zeitverhaltens von fertigungsprozessen mit grossserienfertigung				Wilfried Mascolus	1981				Crypto	-101.10921884146221	25.682678384669543	22306
9a2c4fb64b05475cefac801390ff0e0da65530cc	process and product success in information systems development	entreprise;methode empirique;organization management;analisis datos;implementation;efficiency;metodo empirico;empresa;empirical method;usuario;satisfaccion;utilisateur;satisfaction;ejecucion;data analysis;eficacia;firm;efficacite;analyse donnee;user;information system;gestion organizacion;systeme information;gestion organisation;information system development;sistema informacion	Several guidelines and methods for ensuring success of development projects have been introduced in the information systems (IS) literature. In this paper, their contribution to explaining variation in different success criteria are empirically investigated with the data gathered from recent IS development projects in major Finnish companies. Competent system analysts and users, appropriate development methods and management support were found important for the success of the development process. These factors did not, however, explain the success of an IS as a product in terms of its quality and its impact on the organization. Instead, product success was heavily dependent on the characteristics of the investment, especially the novelty of the system and the specificity of the design. Advanced IS organization was positively related with both process and product success, but two widely promoted mechanisms for initiating development projects steering committee and strategic IS planning were not positively associated with any of the success criteria. The results of this study imply that managers should emphasize different factors in IS development depending on the type of investment and relevant success criteria in each situation and that there is a clear need for research on finding and justifying new IS investments providing an appropriate balance between expected payoff and risk.	information system;sensitivity and specificity;software development process	Timo Saarinen;Markku Sääksjärvi	1992	J. Strategic Inf. Sys.	10.1016/0963-8687(92)90016-P	user;economics;computer science;engineering;operations management;efficiency;data analysis;critical success factor;empirical research;implementation;management;operations research;information system;new product development	SE	-82.94967141265839	9.316933590445826	22313
c52567028a2f8b66464bfd3691d7476fe078f974	test selection practices in a large it company. (les pratiques de sélection de test dans une grande entreprise d'informatique)				Vincent Blondeau	2017				EDA	-106.02265983965583	15.588056445877035	22323
3d1cdaffebfaf2f9b624b6857aaa257745fe1b81	certics - an iso/iec 15504 conformance model for software technological development and innovation		The Brazilian Government established a public policy instrument to identify and stimulate software production resulting from technology development and innovation carried out in Brazil. In order to accomplish this effort, CERTICS software process assessment methodology was created and established in Brazil. Its construction has been based on the reality of local software development organizations, in effort to achieve consensus within the community of interest, and guided by methodological references including the ISO/IEC 15504 (SPICE) Standard. CERTICS Methodology includes an Assessment Reference Model and an Assessment Method. This article presents the CERTICS Assessment Reference Model and statements on how it is compliant with ISO/IEC 15504 Requirements for Process Reference Models, Process Assessment Models and Organizational Maturity Models.	conformance testing;iso/iec 15504	Clenio F. Salviano;Angela Maria Alves;Giancarlo Nuti Stefanuto;Sonia T. Maintinguer;Carolina V. Mattos;Camila Zeitoum	2014		10.1007/978-3-319-13036-1_5	iso/iec 9126;reliability engineering;iso/iec 12207;iso 29110;systems engineering;engineering;software engineering;iso/iec 15504;iec 62304;software development process	SE	-70.22047666233077	15.264756790815582	22332
92f656f6e57b2b4c7b0f74ecf5ccea3b45680ee5	sicherheitslücke anwendungssoftware		752 DuD • Datenschutz und Datensicherheit 30 (2006) 11  liegt. Der externe Kommunikationspartner kann über SafeGuard WebMail auch selber neue Nachrichten sowie Anhänge sicher per E-Mail verschicken. Für den internen Benutzer ändert sich nichts, da SafeGuard WebMail in Verbindung mit SecurE-Mail Gateway die sichere E-Mail Kommunikation automatisch im Hintergrund realisiert. SafeGuard WebMail von Utimaco ergänzt SecurE-Mail Gateway, die etablierte Plattform für zentrale E-Mail Sicherheit. Das SecurE-Mail Gateway bietet somit neben S/MIME und OpenPGP, zwei weitere zertifikatslose Verfahren an, um E-Mail in wichtigen Geschäftsprozessen und bei gesetzlichen Anforderungen sicher austauschen zu können. Neben SafeGuard WebMail steht auch SafeGuard PrivateCrypto zur Verfügung. Dieses Modul sorgt für die Verschlüsselung von E-Mails am zentralen SecurE-Mail Gateway. Der Empfänger kann diese geschützte E-Mail dann komfortabel per Passwort-Eingabe lokal entschlüsseln. Weitere Informationen über Utimaco und SecurE-Mail Gateway unter www.utimaco.de /smgw.	eine and zwei;pretty good privacy;s/mime;unified model;webmail	Helmut Reimer	2006	Datenschutz und Datensicherheit - DuD	10.1007/s11623-006-0223-1			-103.98650249422114	36.76792355222053	22342
b87af40558fb656e90924be7345194ebeb639c21	kohärenzprüfung von verhaltensspezifikationen gegen spezifische eigenschaften des operationellen kontexts	qualitatssicherung;anforderungsspezifikation;anforderungsanalyse;software engineering;requirements engineering;operationeller kontext;000 informatik informationswissenschaft allgemeine werke 000 informatik wissen systeme 000 informatik informationswissenschaft allgemeine werke;fakultat fur wirtschaftswissenschaften;systemkontext	In der Anforderungsspezifikation eines Systems werden Eigenschaften definiert, die das System an seiner Schnittstelle zur Umgebung aufweisen muss, um im Betrieb seinen Zweck zu erfullen. Eine Vielzahl von Untersuchungen zeigt, dass Fehler in der Anforderungsspezifikation zu erheblichen negativen Konsequenzen sowohl im Entwicklungsprozess des Systems als auch im Systembetrieb fuhren konnen. Fehler in der Anforderungsspezifikation sind dabei oftmals auf Koharenzbruche gegenuber dem operationellen Kontext zuruckzufuhren, d. h. auf ungultige oder unvollstandige Annahmen uber die Umgebung, in der das System betrieben werden soll.  #R##N#Im Rahmen des Dissertationsvorhabens wurde ein teilautomatisierter Ansatz entwickelt, der darauf abzielt, Koharenzbruche in der Anforderungsspezifikation von Systemen gegenuber dem operationellen Kontexts dieser Systeme aufzudecken. Die Arbeit fokussiert dabei auf die Verhaltensspezifikation als Teil der Anforderungsspezifikation sowie auf Eigenschaften des operationellen Kontexts in der statisch-strukturellen Perspektive. Der entwickelte Ansatz setzt sich aus einem Rahmenwerk zur Modellierung des operationellen Kontexts in der statisch-strukturellen Perspektive und einem Katalog von Formalismen zusammen, durch deren Anwendung Koharenzbruche in der Verhaltensspezifikation teilautomatisiert aufgedeckt werden konnen. Zur Evaluation des Ansatzes wurde dieser exemplarisch auf die Verhaltensspezifikation eines von Komplexitat und Umfang her praxistypischen Systems angewendet. Zum Nachweis der technischen Umsetzbarkeit des Ansatzes wird ein Werkzeugprototyp vorgestellt. #R##N#Der entwickelte Ansatz liefert einen Beitrag im Hinblick auf Techniken zur differenzierten Modellierung des operationellen Kontexts von Systemen in der statisch-strukturellen Perspektive und zur teilautomatisierten analytischen Qualitatssicherung von Anforderungsspezifikationen.		Thorsten Weyer	2010			performance art;philosophy	Crypto	-103.70918879288669	31.151708567495305	22389
d3c0b532245e2869ee2d2b03b534cc203ea6370d	towards an effective component testing approach supported by a case tool			computer-aided software engineering	Fernando Raposo da Camara Silva;Eduardo Santana de Almeida;Silvio Romero de Lemos Meira	2008			reliability engineering;unit testing;computer-aided software engineering;computer science	SE	-63.166257409652786	26.534206444824314	22394
9f04f436ec936cb070570b439653a88fe0744fda	empirical research on effecting factors of csr report of commercial banks in china	independent directors proportion csr report commercial banks china corporate social responsibility financial services economic health social responsibility information disclosure index asset quality risk control;commercial banks csr disclosures index;corporate social responsibility;asset quality;banking;csr report;empirical study;independent directors proportion;effecting factors;green products;behavioural sciences computing banking;behavioural sciences computing;impact factor;socially responsible;economic health;effecting factors commercial banks corporate social responsibility report commercial banks csr disclosures index;correlation business communities banking indexes green products;financial services;social development;commercial banks;indexes;importance value;indexation;business;risk control;corporate social responsibility report;information disclosure;correlation;communities;social responsibility information disclosure index;china;empirical research	Corporate social responsibility is an important value orientation of economic and social development. As financial services intermediaries, the commercial banks for a country's economic health are particularly important. Actively fulfilling their social responsibilities is also an effective way to enhance the competitiveness of banks. In-depth study on the disclosure status and impact factors of commercial banks' social responsibility reports has an important significance to improve the performance of Chinese banks. This paper applied the annual social responsibility reports of China's commercial banks from 2005 to 2008 as study samples, established the social responsibility information disclosure index evaluation system combining with the characteristics of banking. The empirical study of the quality and influencing factors of banks' social responsibility information disclosure found that (1) the information disclosure of social responsibility of China's banks was better on the overall; (2) bank size, whether the listed or not, and the times were important factors; (3) the impact of asset quality, risk control, the proportion of independent directors were not very stable, and bank performance did not show a significant effect. According empirical findings, this paper made the corresponding recommendations for improving commercial banks' CSR disclosures.			2010		10.1109/ICEE.2010.1293	accounting;economics;marketing;finance;empirical research;management;commerce	HCI	-85.04636314094279	7.178324577437606	22402
929f4f1b008f4838497eaea9fcb8bbd1ae2674cf	determinação da capacidade de uso da terra do município de são manuel (sp), obtido por meio do sistema de informações geográficas (sig) - idrisi	sistemas de informacao geografica;solo uso;tese de doutorado;geoprocessing;geoprocessamento;idrisi programa de computador		power-on reset;terrset geospatial monitoring and modeling software	Osmar Delmanto Junior	2003			cartography;geography	Security	-105.4756404364229	17.8171301498987	22432
4edfb1845a3bf6c753d30bc24e215011a5cdd77d	einsatz der mikrorechentechnik zur kontrolle und steuerung von technologischen spezialausrüstungen in der elektronikindustrie				Thomas Büttner	1985				Vision	-101.3563649987033	26.163521418465212	22459
abb485d955e09bf63dfad304de68d88650a4a6f8	einsatz und nutzen einer metaebene für föderierte datenbanksysteme am beispiel der molekularbiologie		Werden Daten aus mehreren, unterschiedlichen Datenhaltungssystemen benotigt, ist es sinnvoll, fur deren Integration ein foderiertes Datenbanksystem (FDBS) einzusetzen. Dies gilt nicht nur fur den kommerziellen Bereich, sondern ist ebenfalls fur wissenschaftliche Anwendungsgebiete wie die Molekularbiologie interessant. In diesem Papier stellen wir im Rahmen des Projekts Moby Dick einen Ansatz vor, der die lokalen Systeme mit Hilfe einer Metaebene in das FDBS einbindet. Dadurch ermoglichen wir die explizite Darstellung der Zusammenhange zwischen den Schemata der lokalen Systeme und demjenigen des FDBS, was einerseits die Arbeit des Datenbankintegrators (DBI), anderseits die Abfrageverarbeitung unterstutzt. Ausserdem erfullt die Metaebene zwei wichtige Anforderungen der Molekularbiologie: die Moglichkeit, das Datenmodell des FDBS zu erweitern und diejenige, anwendungsspezifische Metadaten und Metamethoden zu modellieren.		Barbara Rieche;Klaus R. Dittrich	1995			history;performance art	Crypto	-104.02257987785916	32.894566090069546	22572
354cf26252f72e1a831a92c760c55791a32e674e	actionscript für programmierer - mit flash anspruchsvolle anwendungen erstellen			actionscript	Regina Müller	2003				DB	-98.2100887792793	26.848151811612546	22582
3d4e9f0051702e1c6628d839fd413bf9bc0c5780	jazzing up eclipse with collaborative tools	collaborative tools;software development	Collaboration is an integral part of software development, occurring through tools inside and outside the IDE. This paper presents an overview of the Jazz project, which seeks to integrate collaborative capabilities into the Eclipse IDE, enabling small teams of software developers to work together more productively.	collaborative software;eclipse;floor and ceiling functions;jazz (computer);software developer;software development	Li-Te Cheng;Susanne Hupfer;Steven I. Ross;John F. Patterson	2003		10.1145/965660.965670	computer science;systems engineering;software development;software engineering;world wide web	HCI	-64.02166482612847	23.09052467879433	22656
6ad4e335b4b1bb9a72738dc486cfa623e9574846	contract renewal decisions in it-outsourcing: a survey in the netherlands		Increasingly, outsourcing companies decline to renew their contracts automatically at the end of their duration [1, 2]. Furthermore, only a very few contracts are renewed in sole-source contract negotiations. Switching IT outsourcing suppliers is becoming more common [3]. Organizations send out Requests for Proposal instead and may select a new provider for their Information Technology (IT) services. The costs of selection and knowledge transfer processes, switching costs, are substantial [4, 5, 6]. Service delivery continuity is also under pressure when a transfer to a new provider is made [8, 9]. What are the considerations in contract renewal decisions for IT services? The findings presented will be useful for client companies facing contract renewal decisions. In the current, increasingly mature outsourcing market, qualitative factors are considered most important in deciding contract renewal versus switching suppliers, as outsourcing companies are now well capable of negotiating a market-conform price [10]. In this research project, we focus on qualitative as well as financial factors related to switching suppliers. Furthermore, termination provisions in contracts are important. How can service delivery continuity be assured while switching your supplier? This results in a framework for contract renewal decision making in IT outsourcing containing motives, switching costs, risks and contract good practices.	outsourcing	Erik Beulen	2016		10.1007/978-3-319-47009-2_10	actuarial science;business;market economy	ECom	-82.80658130258252	6.77316242313429	22677
7759fd3c327c4d707135b7a549a17d4c29683ec1	dreidimensionale computermodelle anatomischer und pathologischer strukturen in der hals/nasen-ohrenheilkunde: e. prototyp				Henry Lee Seldon	1988				NLP	-97.317956713011	24.15010683043107	22690
137c281f34f3c736f70aeb750f3f414cc916a007	adaptive and reconfigurable software systems and architectures	dynamic reconfiguration;software architecture;networked services;adaptation	HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Editorial Adaptive and reconfigurable software systems and architectures Slim Kallel, Ismail Bouassida Rodruigez, Khalil Drira		Slim Kallel;Ismael Bouassida Rodriguez;Khalil Drira	2016	Journal of Systems and Software	10.1016/j.jss.2016.09.011	embedded system;software architecture;real-time computing;computer science;software engineering;distributed computing;software system;adaptation	ML	-108.45561544638956	9.463334943640604	22777
ca8fd4cfb34802393c8cd79343d9e41939453cab	estimating the size of changes for evolving object oriented systems: a case study	software cost estimation;software measurement;software maintenance;product life cycle;software systems;object oriented programming software maintenance software cost estimation;versions compliance check;size measurement;object oriented programming;development process;software maintenance object oriented systems size related measures software cost estimation software product life cycle;software product life cycle;effort prediction;experience report;iterative methods;object oriented systems;impact analysis;effort estimation;object oriented modeling predictive models size measurement software measurement life estimation costs iterative methods software maintenance software systems lab on a chip;object oriented;lab on a chip;object orientation;predictive models;life estimation;size related measures;traceability;empirical evaluation;object oriented modeling	Size related measures have traditionally been the basis for effort estimation models to predict costs of software activities along the entire software product life cycle. Object-Oriented (OO) systems are developed and evolve by adding/removing new classes and modifying existing entities. We propose an approach to predict the size of changes of evolving OO systems based on the analysis of the classes impacted by a change request. Our approach can be used both in iterative development processes or during software maintenance. A first empirical evaluation of the proposed approach has been obtained by applying our tools to the postrelease evolution of OO software systems available on the net. The systems were analyzed, and models to predict added/modified LOCs from added/modified classes were statistically validated. In the paper preliminary results of the above outlined evaluation is presented.	approximation error;change request;coefficient;cost estimation in software engineering;edit distance;entity;independent set (graph theory);intermediate representation;iteration;iterative and incremental development;library of efficient data types and algorithms;mega man zx;public-domain software;software maintenance;software release life cycle;software system;traceability;visual intercept	Giuliano Antoniol;Gerardo Canfora;Andrea De Lucia	1999		10.1109/METRIC.1999.809746	reliability engineering;real-time computing;computer science;systems engineering;engineering;software engineering;object-oriented programming	SE	-63.311403607246326	33.84079325907983	22815
c09389b723ac55587e67c633558693750dc018b7	una investigación empírica sobre el modelado dinámico uml y oml			oml;unified modeling language;unique name assumption	Mari Carmen Otero;José Javier Dolado	2002			programming language;unified modeling language;computer science	Robotics	-108.33526460077864	19.081798270726143	22869
64c76f779896fdbffea1bd472e568d7ff63150ba	quality, success, communication and contribution in open source software		Free and open source software projects are often perceived to be of high quality. To a great extend the success of open source software seems to be due to an implicit but effective connection between communication and contributions in its development process. In this paper, we present a snapshot of the state the art on quality and success of Open Source Software (OSS) based on a review of the literature. For each of these concepts, we describe various measures considered in the literature and a number of methods by which they are obtained. Contributions to an Open Source Software (OSS) project are made through communication among developers and users. We elaborate on the concrete notions of communication and contribution in Open Source Software (OSS) and their links.	angela mclean (biologist);display resolution;information system;information systems success model;open sound system;open-source software;relevance;snapshot (computer storage);theory	Sara Santos Fernandes	2011	ECEASST	10.14279/tuj.eceasst.48.816	computer science;software development;software engineering;software walkthrough;world wide web;software quality;software peer review	SE	-65.19379801090844	23.933104131665203	22875
fb773fe3b580beb8ecfac4b64c6007669d4d533a	simulation interaktiv bewegter objekte mit hinderniskontakten	bewegung;starrer korper;hindernis;mensch maschine kommunikation;tastwahrnehmung;kontakt;handhabung;simulation virtuelle realitat	Die interaktive Handhabung starrer Korper in virtuellen Welten erfordert die Simulation eines Objektverhaltens, welches physikalisch plausibel und intuitiv korrekt ist. Andernfalls ware eine solche Simulation fur praktische Anwendungen ungeeignet. Physikalisch plausibles Verhalten impliziert, das die aus Objektkollisionen resultierenden Bewegungsbeschrankungen im Rahmen der Bewegungssimulation berucksichtigt werden. Dieser Beitrag stellt ein Verfahren zur Simulation interaktiv bewegter Objekte mit Hinderniskontakten vor, bei welchem alle Kontaktsituationen durch eine minimale Menge automatisch bestimmter Punktkontakte reprasentiert werden. Die daraus abgeleiteten Bewegungsbeschrankungen dienen als Randbedingungen fur die Simulation der Objektbewegungen. Die vorgeschlagene Vorgehensweise erlaubt auch die Nachbildung von Reibungseffekten. Die Approximationseigenschaften dieser Nachbildung werden sowohl durch theoretische als auch durch empirische Untersuchungen diskutiert.  #N#The interactive manipulation of rigid bodies in virtual environments requires the simulation of an object behaviour, which is physically plausible and intuitively correct. Otherwise such a simulation would be useless for practical applications. Physically plausible behaviour implies that motion restictions due to object collisions are taken into account during the motion simulation. This constribution presents a method for the motion simulation of interactively controlled objects wiht obstacle contacts, representing any contacts situation by a minimal set of automatically determined point contacts. The motion restrictions derived from this set are the basis for the simulation of object motions. The proposed method also allows the simulation of friction effects, the approximation properties of which are discussed on the basis of both a theoretical and an empirical analysis.	simulation	Matthias Buck	1999			computer science;artificial intelligence;mechanical engineering	Crypto	-108.1017544569239	31.401602581137936	22892
33ab32c23f6a3af49bc59b59a827bea42f5db3da	mobile computing als datenquelle für den betrieblichen umweltschutz		Das Mobile Computing ist neben dem Cloud Computing eines der stärksten Trends der letzten Jahre . D r rasante Anstieg von Entwicklungen in den Bereichen mobile Endgeräte und mobile Anwendungen beeinflusst auch zune hmend den betrieblichen Kontext. Während in der Anfangsphase noch die Inform ationsbereitstellung, z.B. für Außendienstmitarbeiter im Vordergrund stan d, werden zunehmend auch mobile Anwendungen zur Datenerfassung im Produktionsbereich eingesetzt. Die Möglichkeit für die Betriebliche Umweltinformatik den Prozess der Datenerfassung zu digitalisieren, minimiert mögliche Übertragungsfeh ler und dient auch als weitere Datenquelle für den Betrieblichen Umweltschutz und den darin eingesetzten Betrieblichen Umweltinformationssystemen (BUI). Das hier vorliegende Paper soll einen theoretischen Diskurs fördern. Es werden die Gründe für den Einsatz des Mobile Computings aufgezeigt, bevor die Szenarien für ein e mobile Datenerfassung und die Anforderungen an die Daten vorgestellt werden. De sweiteren werden die Einsatzgebiete anhand der Aspekte von BUIS aufgezeigt und die Herausforderungen bei der Einführung von mobilen Lösungen diskutiert. 1 Motivation und Hintergrund In den letzten 10 Jahren ist der Einsatz von mobilen Endgeräten im privaten Bereich massiv angestiegen, dazu sind z.B. die Marktanteile der Smartphones 1 u d Tablets förmlich explodiert und der Trend hält weiter an. Es ist zwar nicht davon a uszugehen, dass der klassi che Markt der PC ́s vollständig verdrängt wird, aber auch der Privatmarkt setzt Impulse für das betriebliche Umfeld. So ist zu erkennen, das IKT Projek te mit Fokussierung auf mobile Lösung stärker zu nehmen. Die anfänglichen Einsatzfelder, w ie die Unterstützung von Außendienstmitarbeitern mit Informationen, erweitern sich stets 1 vgl. http://www.handelsblatt.com/unternehmen/it -medien/boom-haelt-an-smartphones -verdraengen -einfachhandys/7783696.html , abgerufen am 18.04.2013 2 vgl. http://www.schaffrath.de/medien -entwicklung/mobil/app-entwicklung/news -detail/article/apps -fuermobile-geraete-2012-wichtiger-markttrend-fuer-unternehmen/ , abgerufen am 18.04.2013	cloud computing;die (integrated circuit);gesellschaft für informatik;mobile computing;smartphone;stan (fan)	Peter Krehahn;Volker Wohlgemuth	2013			operating system;mobile computing;computer science	Web+IR	-103.59666729539856	37.090042645259345	22934
375b5dba9ca4720480e13a87c888bff951d4b18b	enterprise systems implementation success in the shakedown phase	netherlands;erp;enterprise resource planning;university;success factors	Enterprise systems (ES) are popular in both business and academia: many organizations adopt an ES and much has been published on the topic. However, we argue not much is known about success (and its contributing factors) during the different moments of an ES implementation, although this is highly relevant for practice. This study considers the relevant success factors during the shakedown phase of an ES implementation. We use a framework that incorporates three dimensions of success: user, correspondence, and system success. Each success dimension has its own set of success factors. We empirically study an ES implementation in its shakedown phase at a large university in the Netherlands, through conducting interviews and a survey. Results show that data accuracy, troubleshooting, and user support were rated the most important for ES implementation success, whereas business process reengineering (BPR), customization, and again data accuracy were evaluated the best for this ES implementation.		Evert-Jan Start;Marijn G. A. Plomp;Bart van den Hooff	2013			systems engineering;engineering;knowledge management;operations management	Logic	-79.06081711305764	8.673857271843882	22982
57cee6a9099a7f98c2ce7ddfb14ece320eb024d4	aufbau eines referenzkorpus zur deutschsprachigen internetbasierten kommunikation als zusatzkomponente für die korpora im projekt 'digitales wörterbuch der deutschen sprache' (dwds)		Dieser Beitrag gibt einen Überblick über die laufenden Arbeiten im Projekt „Deutsches Referenzkorpus zur internetbasierten Kommunikation“ (DeRiK), in dem ein Korpus zur Sprachverwendung in der deutschsprachigen internetbasierten Kommunikation aufgebaut wird. Das Korpus ist als eine Zusatzkomponente zu den Korpora im BBAW-Projekt „Digitales Wörterbuch der deutschen Sprache“ (DWDS, http://www.dwds.de) konzipiert, die die geschriebene deutsche Sprache seit 1900 dokumentieren. Wir geben einen Überblick über die Motivation und Konzeption des Korpus sowie über die Projektziele (Abschnitte 2 und 3) und berichten über ausgewählte Anforderungen und Vorarbeiten im Zusammenhang mit der Korpuserstellung: a) die Integration des Korpus in die Korpusinfrastruktur des DWDS-Projekts (Abschnitt 4); b) die Entwicklung eines Schemas für die Repräsentation der strukturellen und linguistischen Besonderheiten von IBKKorpora auf der Basis der Repräsentationsformate der Text Encoding Initiative (TEI-P5) (Abschnitt 5). Der Artikel schließt mit einer Skizze der Anwendungsszenarien für das Korpus in der korpusgestützten Sprachanalyse und der gegenwartssprachlichen Lexikographie (Abschnitt 6) sowie mit einem Ausblick (Abschnitt 7).	bielefeld conspiracy;die (integrated circuit);eine and zwei;emoticon;german research centre for artificial intelligence;text encoding initiative	Michael Beißwenger;Lothar Lemnitzer	2013	JLCL		history;performance art	OS	-105.92497543754969	36.41686662233324	23004
3991ddeb6d456b49cbe5cec9b46c1d0c092a2506	untersuchung effizienter verfahren zur bewegungssimulation deformierbarer körper				Oliver Deussen	1996			computer science	NLP	-101.10455457186508	25.691399553702187	23018
a82de8562cdcf8f6467666c8aa5550abf8620450	savunma projelerinde çevik metodolojiler		Özet. Günümüz Savunma Sanayi yazılım projeleri uzun takvimlerde, uluslararası standartlara uygun ve kısıtlı kaynaklar kullanılarak gerçekleştirilmektedir. Genellikle Savunma Sanayi projeleri geliştirilirken kontratsal olarak Şelale modeli uygulanmasına karar verilmektedir. Ancak Şelale modeli izlemek, projenin son safhasında yapılan değişikliklerin pahalıya mal olması, risklerin zamanında öngörülememesi, büyük takımlar içerisindeki iletişimin sağlıklı kurulamaması gibi sonuçlara yol açmaktadır. Bütün bu etkenler, Savunma Sanayi firmalarını, proje geliştirirken yeni yazılım geliştirme süreçleri arayışına sürüklemektedir. Savunma projelerindeki mevcut problemleri en aza indirebilmek için şirketimiz AYESAŞ'ta Çevik yöntemler uygulanmıştır. Örneğin, büyük takımlar arasındaki iletişim kopukluğunu azaltmak için yapılan işlerdeki bilgi aktarımı günlük yapılan kısa süreli toplantılarla sağlanmıştır. Çevik metotlarının kullanılması, takım üyelerinin Sprint (koşu) boyunca yapacağı işleri görebilmesi açısından da fayda sağlamıştır. Böylece proje yönetimi, planlanan ve gerçekleşen eforun farkını minimuma indirip takvime uyabilmiştir. Ayrıca, riskler zamanında öngörülmüş ve gerekli önlemler alınabilmiştir. AYESAŞ, CMMI Seviye 3 uyumlu yazılım süreçlerine sahip bir firmadır. Kontratsal ve süreçsel gereklerden ötürü Çevik metotları mevcut yazılım süreçlerine uygularken bazı uyarlamalar gerçekleştirilmiştir. Bu uyarlamalar sayesinde hem CMMI Seviye 3 uyumlu süreç kriterleri sağlanmış, hem de Çevik metotların prensipleri korunmuştur. Bu uyarlamalara örnek olarak, dokümantasyon gereksinimlerinin Sprint hedefine (Sprint Goal) dahil edilmesi, “bitti tanımı” (definition of done) ve Sprint hedefinin Sprint sonucu çıkacak ürüne/ürün parçasına göre belirlenmesi (Örneğin Sprint ürünü bir doküman setiyse, bitti tanımı ve Sprint hedefi bu doküman setinin eş gözden geçirilmiş olarak yayınlanması olabilir), organizasyonel yapının değişmeden Scrum rollerinin tanımlanması verilebilir. Bu makalede, AYESAŞ’ta savunma projeleri geliştirirken kullanılan Çevik metodolojiler ve bunların CMMI Seviye 3 uyumlu AYESAŞ yazılım süreçlerine uyarlanması anlatılmaktadır.	binary prefix;capability maturity model integration;scrum (software development);sprint (software development)	Burcu Nalbant;Mert Biçakçi	2015			engineering	ML	-100.60870826745672	33.02973705971555	23061
a223ad6f8493f185c301e7ba04014258cf6bd5ce	a dataflow perspective for business process integration	inter organizational data errors;business to business;process integration;process design;dataflow;thesis;business process management;workflow;workflow management system;missing data;data flow;private information;business process integration	Business process integration has become prevalent as business increasingly crosses organizational boundaries. To address the issue of protecting organizations’ competitive knowledge and private information while also enabling business-to-business (B2B) collaboration, past research has focused mainly on customized public and private process design, as well as structural correctness of the integrated workflow. However, a dataflow perspective is important for business process integration. This article presents a data-flow perspective using workflow management and mathematical techniques to address data exchange problems in independent multistakeholder business process integration in dynamic circumstances. The research is conducted following a design science paradigm. We build artifacts that include interorganizational workflow concepts, a workflow model, and a public dataset calculation method. The use of the proposed artifacts is illustrated by applying them to a real-world case in the Shenzhen (Chaiwan) port. The utility of the artifacts is evaluated through interviews with practitioners in industry. We conclude that this research complements the control-flow perspective in the interorganizational workflow management area and also contributes to B2B information-sharing literature; further, the dataflow formalism can help practitioners to formally provide the right data at the right time in dynamic circumstances.	business process;control flow;correctness (computer science);dataflow;personally identifiable information;programming paradigm;semantics (computer science)	Xitong Guo;Sherry X. Sun;Douglas R. Vogel	2008		10.1145/2629450	workflow;xpdl;computer science;systems engineering;knowledge management;artifact-centric business process model;business process management;management science;business process model and notation;process management;business process;event-driven process chain;process mining;business process discovery;business rule;business process modeling;workflow management system;workflow engine;workflow technology	DB	-73.11084419733376	10.587226642308647	23064
682b6e827cbc6d7e93ffe1f1fba53038d0e4da66	untersuchung der parameterempfindlichkeit zeitoptimaler regelkreise mit linearen zeitinvarianten strecken				Norbert Becker	1984			control engineering;engineering	Vision	-105.12682399913466	24.937828457612042	23068
4441cc92066b831e02fba093a23a33fd75448cbd	emsy - ein modellierungskonzept für ökologische und biologische systeme unter besonderer berücksichtigung ihrer dynamischen veränderung				Adelinde M. Uhrmacher	1992				Crypto	-103.21134167375813	23.726874150368715	23070
9e75d8c717e4e452ab61d30ead3671027267bce8	getting at ephemeral flaws	software engineering;ephemeral flaws;reported bugs;software developers;software engineering research;empirical studies;software dependability;software development	Software rarely works as intended when it is initially written. Things go wrong, and developers are commonly understood to form theories and strategies to deal with them. Much of this knowledge relates to ephemeral flaws rather than reported bugs, and is not captured in the software record. As a result, these flaws and understanding about them are neglected in software engineering research. In this paper we describe a study designed to elicit stories from software developers about problems they encounter in their daily work. We also offer preliminary thoughts about the utility of retrospective interviewing in getting at information about ephemeral flaws.	software bug;software developer;software engineering;theory	Tamara Lopez;Marian Petre;Bashar Nuseibeh	2012	2012 5th International Workshop on Co-operative and Human Aspects of Software Engineering (CHASE)		computer science;systems engineering;engineering;software engineering;empirical research;management;world wide web	SE	-67.21088237243109	28.50784324137719	23109
98489b7d2a1c6311f7675f0b07d05935dcb442d0	se fit: software engineering forum der it transferinstitute		Software Engineering ist eine Ingenieursdisziplin, die von einem regen Austausch zwischen Wirtschaft und Wissenschaft profitiert. Es gibt deshalb einige innerund außeruniversitäre Institute, die sich der Zusammenarbeit mit Unternehmen in Forschung und Entwicklung und dem Transfer von Wissen und Technologien verschrieben haben. Unternehmen und wissenschaftliche Einrichtungen profitieren von diesem Austausch gleichermaßen.	eine and zwei;java platform, standard edition;software engineering	Michael Felderer;Wilhelm Hasselbring	2016			engineering ethics;engineering;software engineering	SE	-99.96975291555815	32.15866903072246	23114
6e864fc68cbbd181a6caed53127f3de98d21a0f0	towards collecting sustainability data in supply chains with flexible data collection processes		Nowadays, OEMs from many domains (e.g., electronics and automotive) face rising pressure from customers and legal regulations to produce more sustainable products. This involves the reporting and publishing of various sustainability indicators. However, the demands of legal entities and customers constitute a tremendous challenge as products in these domains comprise various components and sub-components provided by suppliers. Hence, sustainability data collection must be executed along the entire supply chain. In turn, this involves a myriad of different automated and manual tasks as well as quickly changing situations. In combination with potentially long-running processes, these issues result in great process variability that cannot be predicted at design time. In the SustainHub project, a dedicated information system for supporting data collection processes is developed. This paper provides three contributions: (1) it identifies core challenges for sustainable supply chain communication, (2) it reviews state-of-the-art technical solutions for such challenges, and (3) it gives a first overview of the approach we are developing in the SustainHub project to address the challenges. By achieving that, this comprehensive approach has the potential to unify and simplify supply chain communication in the future.	entity;heart rate variability;holism;information system;literal (mathematical logic);microsoft outlook for mac;report;requirement;run time (program lifecycle phase)	Gregor Grambow;Nicolas Mundbrod;Jens Kolb;Manfred Reichert	2013		10.1007/978-3-662-46436-6_2	engineering;operations management;management science;operations research	HCI	-64.46528769705516	9.404018895137966	23253
cc6ad9e6aac3dba99bb0815d621d2681df62f458	optimierung kennfeldbasierender reglerstrukturen mit hilfe von verallgemeinerten genetischen algorithmen				Markus Schröder	1997				Crypto	-101.23230534210447	25.703305820271463	23263
3c3d30bbdaa8ca01eaaf4b7956a0c8de8942ffbc	lippenmodellierung zur merkmalsgewinnung für die audio-visuelle spracherkennung				Michael Vogt	1998				Robotics	-98.29187269515364	23.77977435621232	23314
857f1fdfd4d86ddf368a21d6e7f7cdbb3cec6ff5	reporting usability defects: a systematic literature review	usability systematics software engineering testing human computer interaction bibliographies;usability defect reporting systematic review test management user interface usability testing	Usability defects can be found either by formal usability evaluation methods or indirectly during system testing or usage. No matter how they are discovered, these defects must be tracked and reported. However, empirical studies indicate that usability defects are often not clearly and fully described. This study aims to identify the state of the art in reporting of usability defects in the software engineering and usability engineering literature. We conducted a systematic literature review of usability defect reporting drawing from both the usability and software engineering literature from January 2000 until March 2016. As a result, a total of 57 studies were identified, in which we classified the studies into three categories: reporting usability defect information, analysing usability defect data and key challenges. Out of these, 20 were software engineering studies and 37 were usability studies. The results of this systematic literature review show that usability defect reporting processes suffer from a number of limitations, including: mixed data, inconsistency of terms and values of usability defect data, and insufficient attributes to classify usability defects. We make a number of recommendations to improve usability defect reporting and management in software engineering.	software bug;software engineering;system testing;systematic review;usability engineering	Nor Shahida Mohamad Yusop;John Grundy;Rajesh Vasa	2017	IEEE Transactions on Software Engineering	10.1109/TSE.2016.2638427	usability lab;web usability;computer science;system usability scale;usability inspection;usability engineering;usability;agile usability engineering;usability goals;systems engineering	SE	-64.93420164317715	32.7860317778664	23338
07d0c307bbfa65504c13aaaa8172868a02a98b14	open services for lifecycle collaboration: ein ansatz zur unterstützung der zusammenarbeit in der produktentwicklung	informationsvernetzung;social software;industrie 4 0;wissensmanagement;informationssysteme;workshop		open services for lifecycle collaboration	Stefan Paschke;Selver Softic	2014			computer science;systems engineering;software engineering;mechanical engineering	HCI	-93.38534182333666	27.479773162245678	23419
9188bb3c696a920915e1e118a199cbb2e477d9b3	hmims: hazardous materials incident management system for air force fire departments	incidence;management system;aplicacion espacial;conception;intelligence artificielle;materials;environmental protection;protection environnement;materiau;material;diseno;artificial intelligence;amenagement gestion;design;inteligencia artificial;proteccion medio ambiente;application spatiale;incidencia;space application	Edison, A. S. Propagation of an error: @-sheet structures. Trends Biochem. Sci. 1990, I S , 216-217. Seressiotis, A,; Bailey, J. E. MPS: An artificially intelligent software system for the analyis and synthesis of metabolic pathways. Biotechnol. Bioeng. 1988, 3 l . 587-602. Goryanin, 1. 1.; Shevelev, E. L.; Yunus, 1. A. Software for data bank on enzymes and metabolic pathways. Stud. Biophys. 1989, 29,	artificial intelligence;incident management;intel edison;management system;software propagation;software system	Belgin D. Barkenbus;Beverly C. Zygmunt;Jerome E. Dobson	1991	Journal of Chemical Information and Computer Sciences	10.1021/ci00001a025	design;incidence;management system	AI	-103.1400735785718	18.054117997517523	23459
e46c5f7670fd79819486d9f918300184d7c7f5f0	on cancellative set families		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. On Cancellative Set Families János Körner, Blerina Sinaimeri	archive;comefrom;hal;linear algebra	János Körner;Blerina Sinaimeri	2007	Combinatorics, Probability & Computing	10.1017/S0963548307008413	mathematics;computer hardware;discrete mathematics;laser scanning	ML	-107.17027286112592	10.946947672350854	23461
a36e629e19ab6ad487ae60e76bd238930532be2d	okm : une extension des k-moyennes pour la recherche de classes recouvrantes		Résumé. Dans cet article nous abordons le problème de la classification (ou clustering) dans le but de découvrir des classes avec recouvrements. Malgré quelques avancées récentes dans ce domaines, motivées par des besoins applicatifs importants (traitements des données multimédia par exemple), nous constatons l’absence de solutions théoriques à ce problème. Notre étude consiste alors à proposer une nouvelle formulation du problème de classification par partitionnement, adaptée à la recherche d’un recouvrement des données en classes d’objets similaires. Cette approche se fonde sur la définition d’un critère objectif de qualité d’un recouvrement et d’une solution algorithmique visant à optimiser ce critère. Nous proposons deux évaluations de ce travail permettant d’une part d’appréhender le fonctionnement global de l’algorithme sur des données simples (vitesse de convergence, visualisation des résultats) et d’autre part d’évaluer quantitativement le bénéfice d’une telle approche sur une application de classification de documents textuels.	algorithm;bibliothèque de l'école des chartes;cluster analysis;council for educational technology;fuzzy clustering;linear algebra;nouvelle ai;partition problem	Guillaume Cleuziou	2007			mathematics	ML	-106.5239262364397	13.706494968132162	23473
383df8052f58126ee095379f1b59b351a6c8a749	software developments for industrial research	information mining;process support;software development;knowledge engineering	Industrial research is under the same pressures as most other organisations: it has to deliver results with fewer resources, and in particular in less time. Software based systems are often seen as one way to reach this goal. This paper shows a number of cases and directions where software based systems are currently required, and the approaches that are commonly taken to reach these results, as well as new approaches taken to enhance the productivity of industrial research. This field is fast becoming a computer intensive effort and will stay this way.		Maurice Schlumberger	1994	Future Generation Comp. Syst.	10.1016/0167-739X(94)90026-4	software engineering process group;computer science;package development process;social software engineering;software development;knowledge engineering;data mining;management science;software walkthrough;software metric	SE	-66.99252821218154	20.179246378101514	23480
a9eebe500db49eecd6638d65e1a73b1eac46e8db	extraktion und separation von konturen und formen in realen szenen mit dynamischen neuronalen netzen				Lothar Weitzel	1998				ML	-100.35614342204825	24.315332836396557	23525
61867f42ae5af616c8f8babdb2e252b9f7ab90bd	contributions à la modélisation, l'évaluation de performances et la commande des systèmes à événements discrets. (contribution to modeling, performance evaluation and control of discrete event systems)			linear algebra;performance evaluation	Rabah Boukra	2013				Robotics	-103.72849034487018	15.67839268155484	23570
176735c04e8a4b2aca46a4be208bd7ef2e53e0b8	psychophysiologische beanspruchung und leistung in abhängigkeit von systemresponsezeiten am bildschirmarbeitsplatz				Johanna-Maria Alexander	1987				Theory	-95.89025215907083	21.891368207116937	23575
a8a0545470dbea043351001b682a3b1124338775	business ecosystems and new venture business models: an exploratory study of participation in the lead to win job-creation engine		.............................................................................................................................. ii Acknowledgment ............................................................................................................... iii Table of Chapters ............................................................................................................... iv List of Tables ..................................................................................................................... ix List of Figures .................................................................................................................... x		Steven M. Muegge;Mel Mezen	2017	IJTM	10.1504/IJTM.2017.10006162		DB	-92.82457571566465	24.080187268250693	23594
08e55a085d73f6bfe42ad0f6606de7e74deccf75	dismantling the mystique: the changing role of documentation	design and development;ease of use;product development	The value of a product, whether a simple garden tool or a multimillion dollar computer, depends on how well it fulfills the function for which it was designed. If a product is difficult to use, it is unlikely its full capability will be utilized.  One of the primary influences on the role of documentation today is the increasing emphasis on “ease of use”. Although the products of a high technology company are complex, the accompanying documentation does not necessarily have to mirror that complexity. Documentation must be designed and developed so that it aids the user in maximizing the usefulness of the tool that it describes.  Within the computer industry, it appears that documentation rarely receives any attention until the design and development cycle nears completion. It is usually produced by programmers and developers with little understanding of how good documentation is developed. This process has resulted in a widespread fear and misunderstanding surrounding computer software and hardware; a mystique that computers are difficult to use or understand. However, if the flow of information during the product development cycle is restructured, a significant improvement in documentation and users' attitudes could take place.  This paper discusses in general the factors influencing documentation today, how documentation has been done in the past and the problems that resulted from that process, some techniques to restructure the development cycle to eliminate these problems, and the benefits both internal and external of these new techniques.	complexity;computer;documentation;ibm research;mainframe computer;matrox mystique;mission assurance;new product development;open road tolling;programmer;requirement;usability	Karen Haider	1982		10.1145/800067.802100	common source data base;simulation;systems engineering;engineering;operations management;technical documentation;internal documentation	HCI	-69.66042555589604	26.30493807538952	23620
0306d920ac292632b1c029b8c927259ad5352c3e	cloud data governance maturity model		To ensure data governance in cloud computing, it is important to build-in data governance in the planning, strategy and the design phases of cloud computing and adapt a data governance program architecture which makes sure that regular and governance related tasks, are deployed correctly. Cloud data governance requirements must be linked to the business goals in organisations, when they adopt cloud computing. Cloud data governance is an executive level concern in many organisations today, but a method for credible, reliable, and cost-efficient cloud data governance maturity assessment has been lacking. In order to identify and explore the strength and weaknesses of a particular organization's data governance in cloud computing, this paper proposed as a cloud data governance maturity model and is intended as a tool to evaluate the ability of organizations to meet the objectives of data governance for cloud computing. The maturity model helps organisations understand their current level of data governance before and after adopting cloud computing based on key dimension for cloud data governance. More importantly, the cloud data governance maturity model can identify a path for future growth in, an organisation toward the ultimate goal which invariably follows an understood and established path. This paper will describe the cloud data governance maturity model and explains how organizations can leverage it to help them govern the use of data more effectively in the cloud environment.	capability maturity model;cloud computing;cost efficiency;data governance;requirement;software architecture	Majid Al-Ruithe;Elhadj Benkhelifa	2017		10.1145/3018896.3036394	data mining;systems engineering;computer science;data architecture;data management;data security;cloud computing;big data;data integrity;data modeling;data governance	HPC	-73.10732559332885	12.401572885884905	23632
e5a200292599279c58d822caee62a77cf7d7a855	modellprojekte und -regionen der gesundheitstelematik	gestion integrada;modelizacion;carte a puce;gestion integree;telematics;healthcare;red www;salud publica;telematique;reseau web;integrated management;modelisation;ehealth;gesundheitstelematik;internet;smart cards;telematica;sante publique;world wide web;telemedizin;modeling;public health	This article presents an overview of existing currently active or planned model projects in healthcare-telematics in Germany. To this purpose a couple of test regions have been established in order to prepare the introduction and implementation of smart cards (patient cards, healthcare professional cards) in the German healthcare system. At its end, the article does also include a table presenting an overview of web pages where further information with respect to these projects can be found.		Marc Thomas Bauer;Stefan Kirn	2005	Wirtschaftsinformatik	10.1007/BF03254902	smart card;the internet;systems modeling;public health;telecommunications;computer science;ehealth;telematics;world wide web	NLP	-95.64284489367508	12.825772521396035	23636
452d11952075d25e78b4f3ad3222f3af28fe3420	ein beitrag zu implementierung von signalverarbeitungsalgorithmen in messcomputern				Bernd Schneegast	1988				Crypto	-100.61451182154175	25.002841249478152	23684
3fe8d3418fb327bb116a5abc1698e431e5839b30	empirical validation of structural complexity metric and complexity management for engineering systems	system value;structural complexity;development effort;empirical validation;complexity management framework;perception of complexity	Quantitative assessment of structural complexity is essential for characterization of engineered complex systems. In this paper, we describe a quantitative measure for structural complexity, conduct an empirical validation study of the structural complexity metric, and introduce a complexity management framework for engineering system development. We perform empirical validation of the proposed complexity metric using simple experiments using ball and stick models and show that the development effort increases superlinearly with increasing structural complexity. The standard deviation of the build time for ball and stick models is observed to vary superlinearly with structural complexity. We also describe a generic statistical procedure for building such cost estimation relationships with structural complexity as the independent variable. We distinguish the notion of perception of complexity as an observer-dependent property and contrast that with complexity, which is a property of the system architecture. Finally, we introduce the notion of system value based on performance-complexity trade space and introduce a complexity management framework for system development. C⃝ 2016 Wiley Periodicals, Inc. Syst Eng 19: 193–206, 2016	complex systems;experiment;john d. wiley;mit engineering systems division;rate of convergence;structural complexity (applied mathematics);systems architecture	Kaushik Sinha;Olivier L. de Weck	2016	Systems Engineering	10.1002/sys.21356	reliability engineering;structural complexity;complexity;computer science;systems engineering;mathematics;management science;complexity management	SE	-70.4211177576788	31.77492939713634	23686
e97502b23c9ddcef68d1c3a417f888895e7a89aa	theoretical system administration	impartial method;system administration strategy;statistical dynamic;system administration policy;earlier research;analytical method;best information;theoretical system administration;user practice	In order to develop system administration strategies which can best achieve organizations’ goals, impartial methods of analysis need to be applied, based on the best information available about needs and user practices. This paper draws together several threads of earlier research to propose an analytical method for evaluating system administration policies, using statistical dynamics and the theory of games.	game theory;system administrator	Mark Burgess	2000			simulation;computer science;operations management;management science	ML	-65.6968102217437	5.153717410996967	23689
0ec6f8f05ec4b41fcbd3cca47c0a0c85ccfc0b91	zur bestimmung und visualisierung von kontaktflächen zwischen caput femoris und acetabulum aus computertomographie-schnittbildserien				O. J. Grolle;P. C. Müller;Dietrich Peter Pretschner;M. Nehrlich;P. Lindner	1994			anatomy;acetabulum;caput femoris;biology	Theory	-101.20311748221582	22.161016786415242	23769
1c9ea178a7bc482554e94a617a3b75abbf5ef55e	emerging organizational structure for knowledge-oriented teamwork using genetic algorithm	match;knowledge sharing and support;knowledge sharing;communication cost;organizational knowledge;genetic algorithm;knowledge economy;organizational structure	Organizations have historically sought efficiency improvements through different combinations of materials, components, production and processes to get better performance. However, in this age of the knowledge economy, the new organizational management has shifted its focus to the proper use of the knowledge of employees to create greater output and performance. There is a recent trend towards flat organizations and team-orientated structures, therefore this study will concentrate on the knowledge-oriented teamwork. To construct the fitting team structure, we solve the problem in two stages. In the first stage, we assign the proper tasks to the proper members to achieve a good match for effective usage of organizational knowledge. In the second stage, we solve the problem of insufficient knowledge within the organizational structure generated in the first stage by adjusting the positions of members to improve the mutual coordination and knowledge sharing and support. We applied a basic genetic algorithm (BGA) to solve the problems in both the stages. Five factors, such as member/task number, the number of knowledge types, the number of task types, the average complexity of each member’s knowledge types and the average complexity of task knowledge types, are considered to generate different types of problems. Computational results show that the BGA is able to find optimal knowledge matching for small-sized problems in the first stage, and that the BGA is able to improve the organizational structure generated in the first stage in order to reduce the communication cost of knowledge support among the members in the second stage. 2009 Elsevier Ltd. All rights reserved.	ball grid array;computation;genetic algorithm;mutual information;requirement;schedule (computer science);software release life cycle	Hsiao-Tzu Huang;Chuen-Lung Chen	2009	Expert Syst. Appl.	10.1016/j.eswa.2009.03.062	organizational structure;organizational learning;genetic algorithm;knowledge economy;computer science;knowledge management;management science;knowledge value chain	AI	-87.76323567765397	7.011086202275101	23783
87820327001ca9ed7601c03b6e7cb26c6256a2ff	xml : un formalisme de représentation intermédiaire entre données semi-structurées et représentation par objets		Dans cet article, nous analysons les liens existant entre : (1) des donnees brutes, heterogenes et sans structure fixe, dites donnees semi-structurees (DSS), (2) le langage de description de documents XML, (3) et les systemes de representation de connaissances par objets (RCO). Les besoins de manipuler des DSS et de resoudre des problemes en exploitant des DSS --- integration de bases de donnees, gestion de documents sur le Web, fouille de textes --- ont conduit a lu0027emergence du0027un certain nombre de formalismes de representation. lu0027etude de ces formalismes montrent quu0027ils ont des caracteristiques tres similaires au langage XML et aux systemes de RCO. Nous analysons egalement, comment XML, avec les outils qui lui sont associes et lu0027essor quu0027il connait, peut servir de passerelle entre DSS et RCO, les systemes de RCO servant de base pour la resolution de problemes necessitant des DSS. Nous concluons en discutant les elements importants dont il faut tenir compte pour combiner les avantages de XML et des systemes de RCO dans la prise en compte de DSS et la resolution de problemes impliquant des DSS.	semiconductor industry;xml	Rim Al Hulou;Amedeo Napoli;Emmanuel Nauer	2000			xml;linguistics;sociology	Crypto	-107.03986685785732	13.911416617311916	23786
ebe4f1f630e5cf93b058b52e5ce4c4862403a78d	strategic channel alignment - perspectives on the combination of physical and virtual distribution channels		Extensive integration of online and offline channels is often considered the preferable strategy for multi channel retailing. However, empirical findings contradict this assumption and show that retailers choose divergent multi channel strategies. In this paper, we present a model of strategic channel alignment and define four alignment perspectives that can help to reconstruct and interpret decisions on multi channel strategies as an alignment of general marketing strategy and online strategy. An application of the model to the cases of four prominent and successful players from the grocery retailing industry shows that although the companies pursue fundamentally different multi channel strategies, they are all examples of successful alignment and mature multi channel strategies.	online and offline;web strategy	Claas Müller-Lankenau;Kai Wehmeyer;Stefan Klein	2005				HCI	-79.52397683932799	6.770343501294977	23789
641320b1434fd370b8af370a3a58d4b237730331	the contribution of tool testing to the challenge of responding to an it adversary (keynote)		The investigator is being presented with more data and more types of data to analyze. The investigator cannot work without tools. Tools are needed to acquire and analyze the data and solve the case. If the accuracy of any tools is successfully challenged in a court of law, then any results based on the tools can be suppressed and not presented. Even if an investigation is not going to any formal proceeding, the investigator wants to know the limitations of any tools used in an investigation. This can best be accomplished by an independent assessment of the tools. This paper describes the Computer Forensics Tool Testing (CFTT) project at the National Institute of Standards and Technology (NIST) in the United States. Currently, the CFTT project is developing tool specifications, test plans, test procedures, and test sets. The results provide the information necessary for toolmakers to improve tools, for users to make informed choices about acquiring and using computer forensics tools, and for interested parties to understand the tools capabilities. Our approach for testing computer forensic tools is based on well-recognized international methodologies for conformance testing and quality testing	adversary (cryptography);computer forensics;computer science;conformance testing;consensus (computer science);fortran;test plan	James R. Lyle	2006			simulation;blanking;electrical engineering;timer;artificial heart;ventricle;sense amplifier;amplifier;engineering;pulse (signal processing);pulse generator	SE	-77.90673653168781	23.76619546764329	23828
d6b4e44e616394536d4716fe703322599dafd4bd	market forces and future drivers	fabrication;commerce electronique;deregulacion;comercio electronico;markets;fabricacion;articulo sintesis;marche financier;red www;mercado;direct television satellite broadcasting;article synthese;technology;television via satelite;analyse tendance;trend analysis;telecomunicacion via satelite;aerospace industry;long terme;telecommunication par satellite;telephony;long term;marche concurrentiel;direct broadcasting by satellite;largo plazo;internet;red celular;cell network;reseau cellulaire;marche;technologie;manufacturing;financial market;telecommunication satellite;dereglementation;world wide web;deregulation;reseau www;industria aeroespacial;open market;radiodiffusion directe par satellite;satellite telecommunication;review;television directe par satellite;satelite telecomunicacion;industrie aerospatiale;electronic trade;telephonie;mercado financiero;analisis tendencia;tecnologia	In recent years there has been an explosion of interest in new satellite systems, witness the fact that in the US alone the Federal Communications Commission has received 43 filings in response to four recent Notice of Proposed Rule Makings. This paper reviews (in Part I) some of the underlying reasons for this surge of interest, as well as the filings themselves. A combination of factors seems to be at work, including a) the enormous growth in telecommunications worldwide (fueled by increased global trade, the enormous growth of the World Wide Web and e-commerce, deregulation, and the introduction of new services) and b) changes in the structure of the commercial satellite communication industry (such as the entry of new players, e.g., Motorola and vertical integration of satellite manufacturers - Hughes, Loral, Lockheed Martin into services). In Part II the prospects for the long-term future of the industry are examined, where it is concluded that, despite all the present interest, satellites will likely see continued use only where they offer unrivalled competitive advantages, such as for broadcasting, reaching mobile platforms and areas presently lacking adequate terrestrial communications facilities.	device driver	John V. Evans	2000	Space Communications		deregulation;trend analysis;telecommunications;engineering;manufacturing;telephony;fabrication;operations research;financial market;technology	OS	-68.54109716352671	5.766621156988116	23896
951ae1ad4a182eec73935fdbc21a75ba9f2c556d	software stability in software reengineering	stability software maintenance reverse engineering wrapping costs business process re engineering companies maintenance engineering software systems computer science;software maintenance;heterogeneous computing;quality improvement;maintenance cost;software stability;software engineering;forward engineering;legacy integration;systems re engineering software maintenance;software reengineering forward engineering legacy integration reverse engineering software engineering software maintenance software stability;software reengineering;legacy system;legacy reengineering process software stability software reengineering heterogeneous computing environment legacy system;legacy reengineering process;reverse engineering;heterogeneous computing environment;systems re engineering	Legacy systems won't evolve well in today's modern computing environments without reengineering. Unfortunately, most reengineering projects are only concerned about whether the systems can be seamlessly integrated into the environments and usually ignore the quality in the improvement of the legacy systems. We all agree that it would be better to observe both integration and quality improvement implemented in the reengineering process. Software stability makes this possible in the reengineering process so that the new systems can run in a heterogeneous computing environment but also be stable enough to reduce the maintenance costs and efforts. In this paper, a connection between the stability modeling and reengineering process for legacy system is described. A preliminary study on techniques for building a better stable system will be presented although the techniques are still not very promising yet. We will also discuss the issues and challenges of applying software stability into the legacy reengineering process.	code refactoring;heterogeneous computing;legacy system	Chia-Chu Chiang	2007	2007 IEEE International Conference on Information Reuse and Integration	10.1109/IRI.2007.4296705	quality management;computer science;software engineering;software maintenance;legacy system;symmetric multiprocessor system;reverse engineering	SE	-67.81154135656817	26.585217925070797	23960
fbdd8ef20e97000c97b2d80d5a801ac87910e8ee	the impact of boundary spanning capability, cultural differences on success of offshore information system outsourcing - from the vendors' perspective	domain knowledge gaps;culture differences;language barriers;offshore information system outsourcing;boundary spanning capability;offshore information systems;culture;outsourcing success;china;cultural differences;is outsourcing	Effective communication between clients and vendors in offshore IS outsourcing requires spanning various boundaries such as cultural differences, language barriers and domain knowledge gaps to ensure efficacious information transmission through clients and vendors. How to overcome these boundaries is an important question. This paper takes culture differences as a mediator to study the impact of vendors’ boundary spanning capability on success of offshore IS outsourcing. The research model is empirically tested on 102 offshore IS outsourcing projects from 20 vendors in China. The results suggest that vendors’ boundary spanning capability significantly improves outsourcing success. Moreover, we find that culture differences partial mediate the relationship between boundary spanning capability and outsourcing success.	file spanning;information system;outsourcing	Bo Yang;Yuan Yuan;Mingzhu Liu	2014	IJNVO	10.1504/IJNVO.2014.065086	operations management;knowledge process outsourcing;china;culture;commerce	Web+IR	-81.58536685915833	4.723085817869064	23973
fff9f5efa8f62e7810401b1c55eb3d51b541208b	mitteilungen der gi im informatik spektrum · 165. folge		dium bisher Vertreterinnen und Vertreter der Dienstleistungsunternehmen (Banken, Versicherungen etc.), der Selbständigen, der Fachhochschulen, der Schulen und der öffentlichen Verwaltung. Besonders junge NachwuchsInformatikerinnen und -Informatiker sowie Personen aus dem akademischen Mittelbau und den mittleren Ebenen der Firmen und der Verwaltung sind im Präsidium zu wenig vertreten. Bitte senden Sie Ihre Vorschläge formlos bis spätestens Freitag, den 30. April 2004, per E-Mail direkt an mich <reinermann@dhv-speyer.de> oder per Post an die folgende Anschrift:	sie (file format)	Matthias Jarke	2003	Informatik-Spektrum	10.1007/s00287-003-0368-y		OS	-103.77190120642854	34.61351610559187	23978
cade92c4e10414e7894e4c68f0e19e290722bd69	optimisation des tournées d'inspection des voies	tournees de vehicules industrielles;industrial vehicle routing;benders decomposition;heuristique mathematique;decomposition de benders;generation de colonnes;column generation;mathematical heuristic	La SNCF utilise plusieurs engins specialises pour ausculter les fissures internes du rail. La frequence d'auscultation de chaque rail est fonction du tonnage cumule qui passe dessus. La programmation des engins d'auscultations ultrasonores est aujourd'hui decentralisee. Dans le cadre d'une etude de reorganisation, la SNCF souhaite etudier la faisabilite de l'optimisation de certaines tournees d'inspection. Dans le cadre de cette these de doctorat, l'optimisation de la programmation des engins d'auscultation a ultrasons est etudiee. Une modelisation mathematique sous forme de probleme de tournees sur arcs generalisant plusieurs problemes academiques est proposees. Une methode de resolution exacte, appliquant la decomposition de Benders, est detaillee. A partir de cette approche, une heuristique de generation de colonnes et de contraintes est presentee et analysee numeriquement sur des donnees reelles de 2009. Enfin, un logiciel industriel developpe autour de cette approche est presente.	mathematical optimization	Sébastien Lannez	2010			calculus;benders' decomposition;philosophy	Crypto	-105.7102350044034	15.496304098038285	24001
009a1605b8da564db87a6f330f04022273238f49	informatics: the infrastructure for quality assessment and quality improvement	quality improvement;quality assessment			Susan J. Grobe	1995	Journal of the American Medical Informatics Association : JAMIA	10.1136/jamia.1995.96010396	computer science	NLP	-74.94715110643338	34.986912504818896	24041
19dee98ef2236830d2938c4f84b4c66e110f3559	increasing understanding of the modern testing perspective in software product development projects	software testing;project management;best practice;software development process;software testing product development system testing programming project management conference management quality management iterative methods best practices quality assurance;project management program testing software development management;program testing;software development;product development software testing software development projects v model waterfall model;software development management;software process;product development	Testing can be difficult to integrate into software development. Approaches to software testing in relation to implementing software are based on the V-model of testing. The software process behind the V-model is the traditional waterfall model, and as such the traditional testing approaches cannot take iterative, incremental and agile approaches to developing software into account	agile software development;iteration;software development process;software testing;v-model;waterfall model	Maaret Pyhäjärvi;Kristian Rautiainen;Juha Itkonen	2003		10.1109/HICSS.2003.1174707	non-regression testing;test strategy;project management;development testing;personal software process;verification and validation;software performance testing;system integration testing;software project management;computer science;acceptance testing;package development process;software reliability testing;software development;software engineering;iterative and incremental development;software construction;software testing;management;goal-driven software development process;software development process;software quality analyst;software peer review	SE	-64.56923090095583	27.104411421788818	24099
c67e669a9f480f86413b2b7de50f423b1a041424	approche biomimétique coopérative pour la visualisation de grands graphes multidimensionels		Face à la quantité sans cesse grandissante de données stockées, les algorithmes de fouille et de visualisation de données doivent pouvoir être capable de traiter de grandes quantités de données. Une des solutions est d’effectuer un prétraitement des données permettant la réduction de la dimension des données sans perte significative d’informations. L’idée est donc de réduire l’ensemble de descripteurs avant de faire appel à la méthode de visualisation sous forme d’un graphe.	estdomains;linear algebra;sans institute	Lydia Boudjeloud;Hanene Azzag	2010			data science;visualization;computer science	Crypto	-105.8661462175712	13.877842724068028	24133
1ff2b4563301daec29b78a9595f8744cda435e42	teaching software testing methods based on diversity principles	software;software testing;software testing education software subspace constraints industries diversity methods;software quality program testing;software quality assurance;industries;software quality software testing method diversity principle;educational software;subspace constraints;program testing;test methods;software testing method;diversity principle;work in progress;software quality;diversity methods	Software testing is the primary approach to support software quality assurance. Many novel software testing methods have been proposed to achieve various tasks in recent years. It is a challenge to teach these new testing methods and classical testing methods within limited time. This paper reports our work in progress on the new teaching approach to software testing methods based on diversity principles.	software quality assurance;software testing	Zhenyu Chen;Jinyu Zhang;Bin Luo	2011	2011 24th IEEE-CS Conference on Software Engineering Education and Training (CSEE&T)	10.1109/CSEET.2011.5876111	test strategy;reliability engineering;verification and validation;software performance testing;system integration testing;computer science;systems engineering;acceptance testing;software reliability testing;software engineering;software construction;operational acceptance testing;software testing	SE	-65.08835047876634	26.924498645801677	24137
6ec4fb622c62d9c729f664551447d3cbdce258a0	"""the concept of """"ba"""" applied to software knowledge"""	software knowledge;knowledge creation;software process	"""Software development is a knowledge-intensive activity. Software products usually start as a simple idea, or a vision, and then progress towards a final deliverable product. Along this evolution, there is a lot of knowledge that is captured, organized, and shared, leading to new knowledge, both as a whole and within specific development activities. The concept of """"Ba"""" provides a foundation to advance individual and collective knowledge, which describes knowledge creation as a spiral involving tacit and explicit knowledge: the Socialization, Externalization, Combination, Internalization model (a.k.a. SECI model). By applying this foundation to software development, we found issues that may hinder the effective knowledge management cycle. In this paper, we present a vision and a set of requirements for tools to overcome such issues and therefore better support the whole process of software knowledge evolution."""	computer vision;knowledge management;requirement;socialization;software development	Nuno Flores;Ademar Aguiar;Hugo Sereno Ferreira	2014		10.1145/2593702.2593713	personal software process;team software process;software engineering process group;software mining;computer science;systems engineering;engineering;knowledge management;software design;software development;software design description;body of knowledge;software engineering;knowledge-based systems;knowledge engineering;management science;procedural knowledge;knowledge extraction;software walkthrough;personal knowledge management;knowledge value chain;management;goal-driven software development process;software development process;domain knowledge	SE	-66.9595332127146	20.05345536052193	24165
c0910c336c4a5fc0346f1293fea15eba1f42f26e	a comprehensive review and proposed framework to design lean storage and handling systems	warehouse design;storage systems;storage handling system design;handling systems;lean warehousing;materials handling;performance measures;storage utilisation;productivity;buffering	The unprecedented increase in adoption of e-commerce in recent times asks for more efficient, flexible and agile warehousing due to product variants. All previous reviews broadly focus on warehouse design and operations ignoring the major function of providing effective buffering and efficient materials handling. Appropriate storage and handling device selection during warehouse design is significant as it improves materials movement, storage utilisation and productivity. This decision should be taken with adequate thought and care as it affects operating costs and performance throughout the lifespan of the warehouse. This paper critically reviews the current state-of-art of storage-handling systems literature and allied design issues as per the defined taxonomy. The objective is to investigate design issues from lean perspective, and the findings reveal the interrelationship between performance measures, solution approaches and wastes affecting leanness. The conceptual framework is presented to facilitat...		Bhavin Shah;Vivek Khanzode	2015	IJAOM	10.1504/IJAOM.2015.075025	productivity;economics;computer science;systems engineering;data buffer;engineering;knowledge management;operations management	EDA	-79.49167072362636	8.606205841279237	24166
26e8c3bfa3da848f4f6a86e82b969e2d8a03e11e	offen historische daten und karten (ohdm) (open historic data and maps)		OHDM is a platform that allows interested amateurs and professionals to store historical card data and location and time-related information. OHDM is open and free. It expands the idea of Open Street Map (OSM) by a temporal dimension and provides more ways of storing data. OHDM is part of the Open Data Movement. Zusammenfassung OHDM ist eine Plattform, die es interessierten Laien und Profis erlaubt, historische Kartendaten und ortsund zeitgebundene Informationen abzulegen. OHDM ist offen und frei. Es erweitert die Idee von Open Street Map (OSM) um eine zeitliche Dimension und bietet mehr Möglichkeiten der Speicherung von Daten. OHDM versteht sich als Teil der Open Data Bewegung. 1 Motivation Die Erhebung, Zusammenführung und Auswertung von Kartenund Umweltdaten ist aufwendig. Es gibt aber Beispiele wie Webanwendungen interessierte Laien zur Mitarbeit gewinnen können und dabei sinnvolle und hilfreiche Ergebnisse erzeugen können. Open Street Map (OSM) ist ein Beispiel dafür, wie eine sehr große Anzahl interessierter (Laien-) Kartograph_innen Kartenmaterial produziert, dass vor allem in Europa erstaunlich präzise ist. In Teilbereichen wie Radwegekarten gilt OSM als präziseste Karte überhaupt. Tagungsband UIS 2017 242 OSM hat einen klaren Fokus: Es ist eine Plattform auf der Freiwillige Geometrien einstellen können und die daraus aktuelle Karten produziert. OSM bietet aber nur rudimentäre Möglichkeiten, historische Daten zu speichern und nahezu keine Möglichkeiten, zusätzliche Informationen zu hinterlegen. Es erlaubt lediglich die Ablage von Beschreibungen und von Links. Das soll nicht als Kritik verstanden werden – OSM ist ein Dienst für aktuelle Karten; mehr nicht. Das Konzept von OSM ließe sich aber in zwei Richtungen erweitern: Einmal könnten historische Kartendaten verwaltet werden können und zum anderen könnten aktuelle und historische statistische und Umweltdaten gespeichert werden. Genau das ist das Ziel von Open Historical Data Map (OHDM), dessen Konzept im Rahmen einer Lehrveranstaltung an der HTW Berlin entstand. Die Machbarkeit des Projektes kann gezeigt werden und wir hoffen, dass wir es bald auch mit Unterstützung der Staatsbibliothek Berlin fertig stellen können. 2 Basisstruktur von OHDM OHDM unterscheidet zwei Basisstrukturen: Geografische Objekte und Geometrien. Das ist wahrhaftig nichts neues, erstaunlicherweise macht OSM diese Trennung nicht, sondern speichert lediglich Geometrien mit einer, wenn überhaupt vorhandenen, impliziten Semantik. Geografische Objekte kann alles sein, was auch mit einer Geometrie auf der Erde beschreiben werden kann. Das können Gebäude und Straßen sein, aber auch Überschwemmungen, radioaktive Wolken wie sie leider zuweilen von Atomkraftwerken freigesetzt werden usw. Objekte können semantisch beschrieben werden und auf externe Quellen verweisen. Öffentliche Datenquellen biete sich an, wie bspw. Denkmalschutz, Katasterdaten, aber auch Wikipedia oder Open Data Portale. Statistische und Umweltinformationen lassen sich mit Geoobjekte verknüpfen. Geografische Objekte haben oder hatten in jedem Fall eine Beziehung zu einer Geometrie, die die aktuelle oder ehemalige Position des Objektes auf der Erde beschreibt. Objekte können ihre Position ändern. Wolken bewegen sich. Aber auch 45 siehe http://osm.org Tagungsband UIS 2017 243 Bauwerke werden manchmal verschoben (z.B. Siegessäule in Berlin). In dem Fall bleiben die Objekte gleich, aber die Position, d.h. damit die Geometrie ändert sich. Andererseits beschreibt eine Geometrie ein Gebäude, dessen Funktion sich ändern kann. Die Maße bleiben identisch, aber die Nutzung und damit die Semantik = das Objekt ändert sich. Ein Beispiel ist die HTW in Berlin die unter anderem die Gebäude des ehemaligen Kabelwerks Oberspree nutzt. Die Geometrie der Gebäude ist identisch, die Objekte nicht. Die Datenstruktur wurde an anderer Stelle beschrieben [Schwotzer 2016], Erläuterungen finden sich auch auf dem Software-Repository [OHDM 2017]. 3 (geplante) Funktionen von OHDM und Status OHDM wird wie OSM Tools anbieten, um historisches Gegebenheiten als Geometrien zu beschreiben. Es wird Anwendungen für Smartphones geben und Webanwendungen. Außerdem wird es Importschnittstellen für vorhandene historische Geodaten geben. Daran wird gearbeitet. Es sollen aber auch Möglichkeiten bestehen, weitere Informationen zu den Objekten zu speichern und dabei wird explizit auch an Umweltinformationen gedacht, dazu mehr im kommenden Abschnitt. Die meisten Arbeiten wurden bisher auf Seiten des Kartenmaterials geleistet. Wir sehen drei Quellen historischer Daten • Zeitzeugen der jüngeren Vergangenheit können Daten einstellen wie das bereits bei OSM erfolgt. So kennen viele noch die ehemaligen Straßennamen z.B. aus der DDR. In sehr wenigen Fällen werden diese bereits in OSM hinterlegt. Da sie aber nur schwer auf der Karte erkennbar sind, wird diese Möglichkeit selten genutzt. Historiker_innen und Archäolog_innen erstellen nicht selten Datenmaterial. Wir wollen mit OHDM eine bequeme Plattform anbieten, um die Daten auch dort einzustellen und daraus historische Karten erzeugen zu können. • Die Staatsbibliothek von Berlin hat eine der größten Kartensammlungen Europas. Studenten von uns haben in Kooperation mit ihr und einem Berliner Unternehmen untersucht wie sich Geometrien aus alten Karten extrahieren und Tagungsband UIS 2017 244 in OHDM integrieren lassen. Sie nutzten dazu Methoden der automatischen Bilderkennung [2]. • OSM ist Quelle historischer Daten. Wir werden einmal jährlich die Daten von OSM in OHDM integrieren. Die historischen Kartendaten sollen Grundlage sein, um weitere Daten anzuhängen. Sobald man z.B. eine Karte von Preußen wie OSM nutzen kann, könnte man dort auch statische Informationen hinterlegen bzw. verlinken, die ihrerseits auch im Netz vorliegen. Naturereignisse wie Überschwemmungen oder Industrieunfälle sind räumliche und zeitliche Phänomene, die sich mit OHDM speichern und visualisieren lassen (werden). Wir nutzen in OHDM PostGIS und Geoserver als WMS Server. Unsere Infrastruktur ist in der Lage die weltweiten OSM-Daten zu verwalten und daraus Karten zu erzeugen. Ein Prototyp ist zu finden unter [Prototyp 2017]. Es ist zu beachten, dass wir das Caching zu Testzwecken bewusst deaktiviert haben. Die Karten wird jedes mal vom Server erzeugt. Das geht – aus unserer Sicht – im Untersekundenbereich erstaunlich schnell. (Der Server ist auch nicht reserviert als WMS-Server. Wenn es länger dauert, liegt das mit hoher Sicherheit an einer umfänglichen Datenbankoperation. Wir tauschen auch manchmal die Datenbasis aus.) 4 Warum noch eine Plattform? Tatsächlich gibt es all diese Funktionen bereits in unterschiedlichen Systemen. Vermessungsämter, Denkmalschutzbehörden, Umweltbehörden, Landesplanung usw. usf. verfügen über eine Fülle von Informationen. Die Verknüpfung von Informationen ist aber in aller Regel zeitaufwendig erzeugt oftmals aber interessante Resultate. In OSM gibt es allein in Deutschland eine halbe Millionen Nutzer. OSM verfügt derzeit über mehrere Milliarden Geometrien, die allesamt von unbezahlten Freiwilligen aufgenommen und in das System integriert wurden. Die OSM Daten wuchsen schneller mit breiterer Verfügbarkeit von GPS fähigen Smartphones. Mobile Nutzer_innen nutzten die Fähigkeiten der Geräte, um freie und offene Kartendaten zu produzieren. Das machen sie dezentral, sie stimmen sich über Wikis ab oder organisieren dezentral Treffen. Es ist eine weltweite Community Tagungsband UIS 2017 245 entstanden, die wertvolles produziert – was, unter vorgehaltener Hand, auch professionelle Kartograph_innen zugeben. Immer mehr Studierende arbeiten mit Sensoren, die Umweltdaten messen. Offene und freie Hardware-Plattformen wie Raspberry-PI und Arduino sind kostengünstig und erlauben die Erfassung von Umweltdaten auch für interessierte Laien. Genau so entstand vor etwas über einem Jahrzehnt OSM. Da waren ein paar „Verrückte“, die allen Ernstes die Welt mit ihren GPS-Receivern neu vermessen wollten. Ein Jahrzehnt später ist dies erledigt. Derzeit spielt eine wachsende Anzahl Interessierter mit Sensoren herum und sammeln Daten. Das erfolgt unstrukturiert und kann zunächst nur belächelt werden. Wir geben davon aus, dass es keine zehn Jahre dauert, um diese Daten zu einem wertvollen Hilfsmittel für professionelle Arbeit zu machen, auch und vor allem für Umweltinformatiker_innen. ODHM sieht sich als Plattform für eine netzbasierte Crowdanwendungn für (historische) Karten und Umweltdaten und sieht sich damit auch im Kontext der Open Data Initiative. Alle Daten und die gesamte Software von OHDM ist frei verfügbar [OHDM 2017]. 5 Literaturverzeichnis Hirsch, Thomas; Westphal, Florian; Saeger, Kai; Schwotzer, Thomas (2016b): Vectorisation of historical maps Exploring Old Maps (workshop), Luxembourg, June, 8. 2016, In: https://exploringoldmaps.uni.lu/content/download/706/3738/version/1/file/eomproc.pdf zuletzt aufgerufen am 03.08.2017 Schwotzer, Thomas (2016a): Open Historical Data Map – work in progress, summary of a presentation of the workshop Exploring Old Maps (workshop), Luxembourg, June, 8. 2016 (https://exploringoldmaps.uni.lu/2016). Script: (https://www.researchgate.net/publication/303818952_Open_Historical_Data_Map_OHD M_-_work_in_progress) zuletzt aufgerufen am 03.08.2017 OHDM auf GitHub (2017): https://github.com/OpenHistoricalDataMap zuletzt aufgerufen am 03.08.2017 Prototyp (2017): http://ohdm.net/ zuletzt aufgerufen am 30.08.2017	arduino;citeseerx;die (integrated circuit);eine and zwei;europa;gesellschaft für informatik;global positioning system;institut für dokumentologie und editorik;intentionally blank page;internet explorer;list of concept- and mind-mapping software;mit/gnu scheme;map;openstreetmap;postgis;raspberry pi 3 model b (latest version);sie (file format);smartphone;software repository;unified model;vhf omnidirectional range;wiki;wikipedia;zentralblatt math	Thomas Schwotzer	2017					-102.83361996686524	35.731851406888566	24198
12de4b8d83eb73590f229e7cf7be05b57ce6922a	performance analyse einer biologisch motivierten steuerungsstrategie		In den letzten Jahren konzentrierten sich die meisten Arbeiten in der Hand-Auge Koordination darauf Regelungsstrategien zu entwickeln, die es erlauben mit schwach kalibrierten oder sogar unkalibrierten Hand-Auge Systemen zu arbeiten. Ein gebrauchlicher Ansatz ist es den Regelkreis mit Hilfe von visuellem Feedback zu schliesen (visual servoing), obwohl das kontinuierliche und schnelle Bildverarbeitung erfordert. Im Gegensatz dazu wurde von uns eine Strategie entwickelt, die durch die Integration von schwachem, asynchronem visuellem Feedback Kalibrierungsfehler kompensieren kann. Diese Strategie ist motiviert aus Ergebnissen der Neurowissenschaften, die zeigen, das der Mensch beim Greifen nach Gegenstanden nur schwaches visuelles Feedback benotigt, selbst in den Fallen in denen das visuelle Feedback bewust gestort wird. Eine weitere Eigenschaft des Menschen ist, das er seine Greifbewegung sehr weich an eine Zielanderung anpassen kann, fur den Fall, das das Ziel wahrend der Bewegung springt (double-steptarget). Auch dieses Phanomen wird durch die untersuchte Strategie nachgebildet.		Michael Sorg;Georg Passig;Alexa Zierl;Georg Färber	2000		10.1007/978-3-642-59576-9_29	art;performance art	NLP	-106.69703609157537	32.11466054686693	24285
7b8e158bb8573842d3d5201dab840d4dc867722f	egovsim: a model for calculating the financial gains of governmental services transformation, for administration and citizens	printing;analytical models;standards cost model;tool support;costing;digital public services;costs business electronic government costing gain measurement information analysis sustainable development productivity collaboration portals;biological system modeling;public administration activity based costing government data processing open systems;financial gains;activity based costing;governmental services transformation;formal method;cross organisational interoperability;electronic government;unified modeling language;analytical cost calculations;information need;cross organisational interoperability egovsim financial gains governmental services transformation digital public services electronic government standards cost model activity based costing analytical cost calculations;public service;open systems;egovsim;government data processing;service provision;cost model;public administration;automation	Targeting systematic and formal methods for measuring the impact of interoperability on digital public services is emerging as an important research challenge in electronic government. The eGOVSIM model that is proposed in this paper aims to provide administrations with a tool to calculate the gains from digitising and making interoperable services for citizens and businesses. The paper presents existing methods for calculating the cost of services for the administration and the service consumers, such as the Standards Cost Model (SCM) and the Activity Based Costing (ABC). Then it goes on presenting a toolset for analytical cost calculations based on the various process steps and the information needs of each governmental service. The tool supports the definition of several service provision scenarios, such as front/back office system interoperability, cross-system or cross-organisational interoperability allowing the calculation of time, effort and cost elements and relevant gains from the application of each scenario.	e-government;formal methods;information needs;interoperability	Yannis Charalabidis;Dimitris Askounis	2010	2010 43rd Hawaii International Conference on System Sciences	10.1109/HICSS.2010.175	public relations;formal methods;computer science;knowledge management;marketing;management science;management;activity-based costing	EDA	-72.06773032463796	14.068400772838746	24312
0ebf02f7b04865f872b4d29de287a8395a2880bc	vision 3d non calibrée : contributions à la reconstruction projective et étude des mouvements critiques pour l'auto-calibrage. (uncalibrated 3d vision: contributions to projective reconstruction and study of the critical motions for self-calibration)			linear algebra;nvidia 3d vision	Peter F. Sturm	1997				Vision	-104.46807036630142	11.108522687573483	24315
566e2ec0db85d841be517a5e1277c19a32704c3a	enterprise and organizational modeling and simulation		Business process management (BPM), business process reengineering (BPR), and business process innovation (BPI) have been the primary strategies adopted by several organizations to manage their business successfully along with IT. In the last few years, the concept of BPM, BPR, and BPI has been a hot topic among the IS community, which is evident in the degree of literatures devoted to it. Due to the dynamic nature of this research area, this paper aims to add knowledge to the existing ones by answering (1) what is the current level of development on BPM, BPR, and BPI within AIS basket of top journals and Science Direct database? and (2) what are the potential future research directions on BPM, BPR, and BPI?. A total of 55 articles from the AIS basket of top journals and 61 articles from the Science Direct database are analyzed based on the year of publications, AIS geographical regions, approaches adopted by the author/s, components of BPM areas and industrial application covered, and potential future research directions are discussed.	beam propagation method;business process interoperability;code refactoring;simulation	Joseph Barjis;Ashish Gupta;Amir Meshkat	2013		10.1007/978-3-642-41638-5		DB	-75.5877175234357	9.051483395358677	24321
cd61d6e547cecb31ef6dcf003890cc90c9d7404c	talea: an extensible framework for e-business integration		This paper describes Talea [12], a platform aimed at supporting the development of web-based e-business applications. Talea is a software designed and developed within Diadi 2000 [4], a Piedmont Region project co-founded within the European Structural Funds framework. The main goal of Diadi 2000 is to support the technology transfer to SME (SME) in the Piedmont Region, in order to increase their competitiveness and technological development. We will briefly describe the context in which the Diadi 2000 project has been conceived and carried on, since it is very important to understand the motivations underlying Talea architecture and functionality. Italian SME, especially in the north-west area (Piedmont), are traditionally reluctant to the introduction of technological innovation. Their business strategies are usually based on wellestablished practices, in which face-to-face interaction plays a major role and new technologies, or new business models, are often considered with suspicion and distrust. For example, the majority of SME currently have a web site, but a very small number of these sites are actually integrated with their business activities (transaction management, customer care, marketing, etc.)1. In this perspective, the Enterprise Application Integration process [1], [15] must start from a change in mental attitudes towards innovation and thus the main goal of the Diadi 2000 project is to convince SME that the exploitation of ICT technologies could represent a real added value to their business. In particular, the project, by means of the Talea software platform, aims at introducing Semantic Web technologies, and in particular shared and customizable ontologies, in	distrust;electronic business;enterprise application integration;ontology (information science);semantic web;transaction processing;web application	Guido Levi;Andrea Vagliengo;Anna Goy	2006		10.1007/978-1-84628-714-5_45	business;semantic web;architecture;knowledge management;enterprise application integration;ontology (information science);electronic business;added value;small number;business model	SE	-70.07885016717928	8.81094431385187	24331
81768c0ad3d19fd8300ebf344ebfcec84f32bc63	optische verfahren zur abstands-und topografiebestimmung / optical methods to measure distance and topography			topography	Hans J. Tiziani	1991	it - Informationstechnik	10.1524/itit.1991.33.1.5		Vision	-100.86204891683965	21.643891208129233	24335
bc64469e6e5e9b0e6c42b3a7fd1e9dd027f0c08f	les arbres vsg : une nouvelle approche multimodèles de la visualisation. (vsg trees : a new multi-model approach of visualization)			linear algebra;nouvelle ai	Yann Lanuel	1994				Visualization	-104.81287783660572	13.888030262895233	24342
a3dd27fc6e2f226c1aa998071d201629b8ce6a8a	users continuous authentication in computers networks (autenticação contínua de usuários em redes de computadores)			authentication;computer	Maria Ines Lopes Brosso	2006				Crypto	-94.18471266028885	30.351736925320917	24364
ca6d3fd2f221657c017ef07293eb285ab54be7f4	verkettung natürlichsprachlicher bausteine zur sprachsynthese: anforderungen, techniken und evaluierung				Volker Kraft	1997				Crypto	-98.59578478593227	24.06314131859352	24387
749fb5d46757bcd7c7629f92ce32d83407f9fec8	quality assurance in the erp5 development process	quality assurance;software quality assurance;software development process;development process;requirement analysis;design and implementation;enterprise resource planning;enterprise modeling;free open source software;open source	The design and implementation of an ERP involves capturing the information necessary for implementing a system that supports integrated enterprise management, starting at the enterprise modeling level and finishing at the coding level. Unfortunately, in both academic and industrial communities, large quantities of papers focus on ERP deployment management, keeping specific development issues aside most of times. Research on specific techniques for developing ERP software – open source or proprietary, is rather deficient. This paper aims to help filling this gap by presenting a development process for the open source ERP5 system, highlighting the Quality Assurance (QA) techniques used, and the tools that support it. The proposed process covers the different abstraction layers involved, and supplies customized Enterprise, Requirements, Analysis, Design, and Implementation workflows. Each of these workflows is accompanied by one or more QA activities to assure the quality of every modeling and implementation artifact delivered.	erp;enterprise modelling;enterprise resource planning;open-source software;requirement;requirements analysis;software deployment;software quality assurance	Rogério Atem de Carvalho;Renato de Campos;Rafael Manhaes Monnerat	2007		10.1007/978-0-387-75902-9_76	program assurance;software security assurance;functional software architecture;reliability engineering;quality assurance;personal software process;qa/qc;verification and validation;enterprise software;software project management;systems engineering;package development process;software development;software engineering;software construction;empirical process;software deployment;software quality control;software development process;software quality;software quality analyst;software peer review	SE	-66.69155286513134	22.57724686745843	24427
3e0b3eed739bee5fe6c0c5ad4f91c0b0cc8a9e8f	qualification et amélioration de la précision de systèmes de balayage laser mobiles par extraction d'arêtes. (edge-based accuracy assessment and improvement of mobile laser scanning systems)		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Qualification et amélioration de la précision de systèmes de balayage laser mobiles par extraction d’arêtes Martyna Poreba		Martyna Poreba	2014				Logic	-106.61524882555346	11.283194038680708	24453
049b1f3144a1aec02f7d6773f39b5a68b6c33875	integration of knowledge management and e-learning		Knowledge management (KM) and e-learning are two concepts that address the requirements of lifelong learning. Over the past several years, there has been an increasing focus on the integration of knowledge management and e-learning systems. By 2003, 70% of organizations implementing knowledge management were linking it with e-learning technically and organizationally (Gartner, 2000). The integration of knowledge management and e-learning enables the creation of great synergies in organizations and business applications. In this article, these two concepts will be presented and their integration will be discussed in detail. Background	knowledge management;requirement;synergy	Dongming Xu;Huaiqing Wang	2011			program management;business;information management;business relationship management;data management;content management;knowledge management;organizational learning;personal knowledge management	DB	-69.60169476946575	8.654950310286589	24461
ce36615c5746f5ecde6e2eeac2ce189b2ab91047	decoding technology transfer through experiences at microsoft		Technology transfer is an important form of collaboration between software engineering researchers and industrial practitioners. Despite benefits to both parties, it remains a huge challenge to carry out a technology transfer successfully. Based on the experiences at Microsoft, this talk discusses some key aspects in technology transfer, including technology readiness, partnership building, and one team as collaboration model.	software engineering	Dongmei Zhang	2018	2018 IEEE/ACM 5th International Workshop on Software Engineering Research and Industrial Practice (SER&IP)	10.1145/3195546.3195553	systems engineering;decoding methods;software;general partnership;technology readiness;engineering	SE	-66.92099740258527	23.714006875073327	24474
4f5ee8bda396dab4938f835094cd92db1fc75a85	modelagem em simulação computacional do cristal e superfícies do bazr'o ind. 3' e srzro ind. 3': propriedades eletrônicas e estruturais	ciencia;bazr o ind 3;tese de doutorado;modeling and computational simulation of crystal		ciphertext indistinguishability	Prescila Glaucia Christianini Buzolin	2010			engineering;mineralogy;performance art;cartography	Vision	-105.47820340468475	18.57441223691362	24493
db74059320c0c9b1f7472b0eede7ff23ddcbe5b7	collaboration in agile software development: concept and dimensions			agile software development	Dinesh Batra;Weidong Xia;Mingyu Zhang	2017	CAIS		engineering;extreme programming practices;agile unified process;software development;empirical process (process control model);software development process;personal software process;agile usability engineering;systems engineering;lean software development	Robotics	-64.76470067460568	22.49693339462761	24499
3180f2d7e433a0659f7a08c6a51c740a2cf34516	platform on platform (pop) model for meta-networking: a new paradigm for networks of the future		"""In this research essay, the authors envision a Platform-on-Platform (PoP) model to understand the (r)evolutionary nature of future networks, with examples and constructs from the two most pervasive networks, namely the Internet and the mobile cellular networks. First, they articulate how PoP model is conceptualized on the economic principles of n-sided markets and discuss associated network effects for the platforms to attain critical mass for sustainability. Then, the authors attempted to analyze the enablers of the PoP including open systems and standards and their effect on the success of PoP. Next, they apply the principles of PoP to two use cases – Internet of Things and Enterprise Mobility, and indicate the relevant research issues that need to be addressed. The authors concluded with remarks on the importance of security as a platform, which in their opinion has not been given due importance thus far, and the related avenues of research for the reliability and sustainability of future networks. DOI: 10.4018/jbdcn.2013010101 2 International Journal of Business Data Communications and Networking, 9(1), 1-10, January-March 2013 Copyright © 2013, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. First, we describe the model, called Platform on Platform (PoP) in this paper, with examples and constructs from the two most pervasive networks, namely the Internet and the mobile cellular networks. Second, we consider the mobile wireless network as the case in hand to establish our model with a detailed analysis of its dynamics. Third, we digress a bit to take up the “open system” movement to show how it is helping our cause – the more open the platform is, the more mature it is and the more amenable it is to (r)evolution. We analyze this development in order to bolster our argument for PoP model of meta-networking. Fourth, we apply our model to the most happening in-thing in enterprise networking viz. mobile cloud platform for business-scale IT. Finally, we wind up with a few cautions about the impending security challenges in our proposed model. 2. PLATFORM ON PLATFORM (POP) MODEL Let us first try to understand that every network – be it wired or wireless – be it high speed or low speed – be it multicast or broadcast – be it voice or video or multimedia is basically a “platform” (Evans & Schmalensee, 2010). We are now-a-days familiar with the term ‘platform’ due to rise in the popularity of cloud computing where Platform-as-as-Service (PaaS) is one of the offerings along with Software-as-a-Service (SaaS) and Infrastructure-as-a-Service (IaaS) (McAfee, 2011). The concept of platform is also age old in economics and that concept has been used by researchers to explain the behavior of the Internet – arguably the best network ever designed on this universe. According to Wikipedia, “two-sided markets, also called two-sided networks, are economic platforms having two distinct user groups that provide each other with network benefits”. Common examples of platforms having two sided markets are eBay, Facebook, Skype, and Google. Extending this simple definition to n-sides, we can write ‘multisided markets or multi-sided networks are platforms having multiple distinct user groups that provide each other with network benefits’. Examples of n-sided platforms are galore today; an operating system, like Android, is a 3-sided platform – users, app developers, and handset manufacturers forming the 3 sides. Definitely, the main driver behind the development of any intermediary (aka platform) is economies of scale offered by the market that links two or more distinct but interdependent groups of customers. The earliest telephone exchange or a modern day router or a simple N×N switch is also a platform in its very basic mode – connecting just two sides. In this framework, the Internet is a worldwide available platform; every intranet is a company-wide platform; every LAN is a campus-wide platform; every WAN is a global-scale platform; so on and so forth. For instance, TV network is another good example of a mass-scale platform, though its ‘platform utility’ has not been explored to the fullest extent till today. So we are ready to accept a network as a platform. Now let us consider this quote: “Twosided platform businesses with low costs of reversing participation status have become more important with the rise of the Internet. Platform businesses add value by facilitating interaction of various sorts between customers who are attracted to the platform at least in part by network externalities. This constraint, which is two-dimensional for two-sided platforms, does not involve production scale economies or fixed costs” (Evans & Schmalensee, 2010). An interesting observation indeed! The authors have equated the Internet with a 2-sided market sans “production scale economies or fixed costs”. Multisided markets have been around for decades, but they’re proliferating rapidly today as modern information and communications technology (ICT) creates more opportunities for organizing complex markets via ICT-based exchanges. Similarly, one can also consider the world-wide mobile network as another global “platform”, which is however not that mature as the Internet is as a 2-sided (or may be n-sided) market. But, per se, every network – small or big – has the potential to mature into an n-sided market or platform although it all depends on 8 more pages are available in the full version of this document, which may be purchased using the """"Add to Cart"""" button on the product's webpage: www.igi-global.com/article/platform-platform-pop-modelmeta/77658?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Communications and Social Science, InfoSciSelect, InfoSci-Digital Marketing, E-Business, and E-Services eJournal Collection, InfoSci-Surveillance, Security, and Defense eJournal Collection, InfoSci-Journal Disciplines Business, Administration, and Management. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2"""	android;interdependence;internet of things;intranet;librarian;mobile cloud computing;mobile phone;multicast;open system (computing);operating system;organizing (structure);paradigm;pervasive informatics;platform as a service;reversing: secrets of reverse engineering;router (computing);sans institute;software as a service;telephone exchange;video;viz: the computer game;web page;wikipedia	Debashis Saha;Varadharajan Sridhar	2013	IJBDCN	10.4018/jbdcn.2013010101	computer science;distributed computing	Metrics	-75.87624720196916	18.048593086772577	24541
a2ff0836a1da53667a0f39934b7c1d630a5c44e9	referenzmodellierung von prozessketten als instrument des supply chain managements	supply chain management			Jan Remmert	2002			supply chain management;process management;supply chain;business	Crypto	-93.85912735572059	27.502174689423835	24560
7ec0dc8ff7a1ae49daf55f94c2607fb94c7e8dd6	hin zu mehr sichtbarkeit und wertschätzung in der softwareentwicklung	cscw;ubiquitous computing	In vielen Unternehmen kann aktuell ein Strukturwandel, u. a. bedingt durch die Einführung von Enterprise 2.0-Lösungen, beobachtet werden. Infolge flacherer Hierarchien und flexiblerer Teams entstehen awareness gaps und damit einhergehend eine reduzierte institutionelle Anerkennung. Das Ambient Surface-System hat zum Ziel, die Sichtbarkeit von Tätigkeiten zu erhöhen. Erste Untersuchungen zeigen einen großen Bedarf nach Transparenz auf und damit die Notwendigkeit auf die zuvor genannten Entwicklungen zu reagieren.	eine and zwei	Jan Schwarzer;Lorenz Barnkow;Peter Kastner;Kai von Luck	2013			social software;enterprise 2.0;ubiquitous computing;human–computer interaction;computer-supported cooperative work;multimedia;engineering	OS	-96.55588831781499	29.562941291232814	24575
852f4ec7eb83e303ea9f9cf5f3871388b07b9bf9	das neue ersatzteillager und verteilzentrum der mercedes benz ag in germersheim		In der Automobilindustrie haben Kundendienst und Teilevertrieb zu einer neuen logistischen Herausfotderung gefuhrt. Die Versorgung von Kunden und Werkstatten mit autombilherstelletspezifischen Teilen und Zubehor innerhalb kurzester Zeit, sind ein wichtiger Faktor bei der Sicherung der Absatzmarkte geworden. Dieser logistischen Herausforderung hat sich die Mercedes Benz AG gestellt. In vorbildlicher Weise wurde ein Verteilzentrum fur Mercedes Benz Originalteile und Zubehor in Germersheim errichtet. Die Planung der Automatisierung und deren Realisierung wurden durch die SIEMENS AG Unternehmensbereich AUT (AUT 4) durchgefuhrt.	mercedes-euklid	Dietmar Engelke	1992		10.1007/978-3-642-77810-0_64	performance art;art	Logic	-105.00563810835563	32.93023322484445	24594
5e9fade4932013cafdf974fc1cd0766eebb56c48	"""zur kombinatorik von """"n-in-a-row"""" and blockadespielen - overflow"""				Ralph Gasser;Jürg Nievergelt	1990	Informatik Spektrum		software engineering;computer science	Robotics	-93.70295808493962	25.54296169217386	24632
d8bf1061d3b9eb23a51f23f450503771caa15e84	role of it in business process reengineering	reorganization;business process re engineering companies information technology industries productivity;improvement;information technology;industries;companies;organizational transformation it information technology business process reengineering bpr;industrial production;organizational transformation;productivity;methodology;business process re engineering;business process reengineering;reorganization business process reengineering methodology improvement organizational transformation;business process;organisational aspects business process re engineering;organisational aspects	Business Process Reengineering is a discipline in which extensive research has been done and numbers of methodologies are introduced. But what seems to be lacking in these methodologies is a structured approach. In this paper an attempt has been made to study and understand the meaning of Business Process Reengineering and the role of information technology in BPR, different reasons of its failure and few recommendations are proposed for the smooth working of BPR in any large organizations.	business process;code refactoring	Deepak Kumar;Anita Bhatia	2011	2011 International Conference on Recent Trends in Information Systems	10.1109/ReTIS.2011.6146838	business process reengineering;systems engineering;knowledge management;process management;business;business process;business process modeling	DB	-73.81968753273343	9.659750133270972	24648
baeeb0c5b20c4f371afb488392001b27fdd30340	soluções analíticas para o modelo de barabási-albert de crescimento de redes	modelos computacionais;redes de computadores;tese			Ricardo Melo Ferreira	2016				Crypto	-106.12001196077743	17.83083618704996	24693
2f88dbee73e675603ef178cddb95338a4e097abc	scientific software communities	special issues and sections;special issues and sections software development scientific computing computer applications;software engineering;computer applications;scientific computing scientific software knowledge sharing reproducible research open source extensible software;software development;scientific computing	The articles in this issue provide some examples of how a more considered focus on the software development process can feed the development of science. Two different approaches to reproducible software practices, an approach on maintaining documentation for important base libraries, and a discussion on ways of extending a software library’s functionality to keep it relevant as a community evolves over time. These topics challenge the boundaries of what software can be for an individual and for a community. The authors expose eaknesses in our state-of-the-art practices with an eye towards a sustainable future. By using these techniques, we avoid numerous withdrawn results—a current crisis due to reliance on software without verification.		Andy R. Terrel;Michael Tobis;George K. Thiruvathukal	2015	Computing in Science and Engineering	10.1109/MCSE.2015.21	computational science;personal software process;verification and validation;computing;software engineering process group;crowdsourcing software development;computer science;package development process;backporting;social software engineering;software framework;software development;software design description;software construction;data mining;software walkthrough;computer applications;software analytics;resource-oriented architecture;software deployment;software metric;software system;software peer review	SE	-65.34462803751761	24.466423639518492	24697
31cdb90e8c4c84e0ade571ed231dbed10517c16b	grundlagen für eine quantitative, semantikbasierte informationstheorie			eine and zwei	Peter Baumann	1990				Vision	-101.76535263597187	25.266125472675785	24736
191f2e87e5924a8a2cb768ac8c6dc232b85af322	small and medium enterprises sourcing software as a service – a dynamic perspective on is capabilities	is capabilities;small and medium enterprises;dynamic capabilities;software as a service;080600 information systems	Software as a Service (SaaS) is a promising approach for Small and Medium Enterprises (SMEs) firms, in particular those that are focused on growing fast and leveraging new technology, due to the potential benefits arising from its inherent scalability, reduced total cost of ownership and the ease of access to global innovations. This paper proposes a dynamic perspective on IS capabilities to understand and explain SMEs sourcing and leveraging SaaS. The model is derived from contextualizing the IS capabilities of Feeny and Willcocks (1998) to SMEs and SaaS and combining it with the dynamic capabilities framework of Teece (2007) . We conclude that SMEs sourcing and leveraging SaaS require leadership, business systems thinking and informed buying for sensing and seizing SaaS opportunities and require leadership and vendor development for transforming in terms of aligning and realigning specific tangible and intangible assets.	causal model;cyclic redundancy check;scalability;software as a service;the australian;total cost of ownership	Nagarajan Venkatachalam;Erwin Fielt;Michael Rosemann;Shane Mathews	2012			computer science;knowledge management;marketing;software as a service;commerce	HCI	-77.74030523852463	5.62399497774927	24763
3a9b35db119b21ef85d4533e919cb951abf0e45f	an application profile for research collaboration and information management	metadata;information management;application profiles;research management systems	Purpose – The purpose of this paper is to design an application profile that will enable interoperability among research management systems, support research collaboration, and facilitate the management of research information. Design/methodology/approach – The approach is based on the Singapore Framework for Dublin Core Application Profile, a framework for designing metadata schemas for maximum interoperability. The application profile is built from gathering stakeholders’ requirements in research community and integrates four types of research information, i.e., information on researchers, research projects, research outputs, and research reports, which benefits researchers, research managers, and funding agencies. Findings – The resultant application profile is evaluated against widely used similar metadata schemas and requirements; and is found to be more comprehensive than the existing schemas and meets the collected requirements. Furthermore, the application profile is deployed with a prototype of r...	information management	Chariya Nonthakarn;Vilas Wuwongse	2015	Program	10.1108/PROG-02-2014-0007	systems engineering;engineering;knowledge management;data mining	DB	-68.89544804526426	9.523001873055838	24860
fff38100cd0d130beeef2f2c13b5eb8a28eb2e35	the software process: a parallel approach through problem solving and program development	program development;software process;problem solving	First-year computer science students are receiving early introduction to the software process through a problem solving and program development approach. We present a methodology that addresses the needs and difficulties of students learning programming, incorporating the tasks required for solving problems and writing programs. This approach allows for incremental exposure to the complex field of software engineering, consistent with the level of the introductory computing course, while providing the learner with fundamental skills applicable to other domains. The correlation between the software process and the problem solving/program development approach is also demonstrated.	problem solving	Fadi P. Deek	1999	Computer Science Education	10.1076/csed.9.1.43.3812	computational science;personal software process;computing;team software process;design process;software engineering process group;computer science;software design;social software engineering;theoretical computer science;software framework;software development;software engineering;iterative and incremental development;software construction;software walkthrough;empirical process;management;goal-driven software development process;software development process;software metric;software system	Logic	-65.83283685729853	26.312488296089015	24871
98ae8d089169c4df530cc34ede3c6a97e7cd89d2	anbieterübergreifende konfiguration komplexer dienstleistungsportfolios: ein anwendungsfall im bereich erneuerbarer energien		Im Bereich erneuerbarer Energien existiert eine große Anzahl von Dienstleistungsanbietern. Dieser Fakt trägt zusammen mit der zunehmenden Komplexität von Dienstleistungen dazu bei, dass es für Kunden schwieriger wird, passende Angebote zu wählen. In diesem Beitrag wird ein Ansatz vorgestellt, mit dem Dienstleister ihr Portfolio anhand eines Standardportfolios der Domäne präsentieren können. Der damit einhergehende Anstieg der Transparenz ist sowohl für Kunden als auch für Anbieter von Vorteil. 1 Einleitung Am Dienstleistungsmarkt stellen verschiedene Anbieter komplexe Portfolios bereit, mit denen sie Kunden ihre Dienstleistungen präsentieren. Dabei sind in vielen Branchen die Zusammensetzung und Beschreibung ähnlicher bzw. gleicher Dienstleistungen zwischen den Anbietern sehr heterogen. Abweichungen sind insbesondere in der Strukturierung und Terminologie zu finden. Durch die dadurch entstehende mangelnde Vergleichbarkeit verschiedener Angebote steigt einerseits das Kaufrisiko der Kunden. Andererseits bedeutet dies für den Anbieter unter Umständen eine geringere Kundenzufriedenheit, da eine Lücke im Verständnis zwischen dem, was der Kunde von der Dienstleistung erwartet und dem, was der Anbieter leistet, entstehen kann [ZBP93]. Eine vereinheitlichte Methode zur Gestaltung von Portfolios zum optimierten Suchen und Finden von Dienstleistungen kann entsprechend zu einer Erhöhung der Markttransparenz beitragen und für Kunden und Anbieter erhebliche Mehrwerte generieren [Moe07]. Zielsetzung des Forschungsprojektes EUMONIS ist die Entwicklung einer Softwareund Systemplattform für Energieund Umweltmonitoringsysteme zur Erbringung konkreter industrieller Dienstleistungen im Bereich erneuerbare Energien (EE). Diese Dienstleistungen werden durch Softwareservices repräsentiert. Mittels eines Standard1 Dieser Beitrag wurde ermöglicht durch die Förderung des Projekts „EUMONIS“ (www.eumonis.org) mit Mitteln des Bundesministeriums für Bildung und Forschung (BMBF). Das Projekt (FKZ 01IS10033D und 01IS10033K) wird betreut vom Projektträger im Deutschen Zentrum für Luftund Raumfahrt (PT-DLR).	dynamic language runtime;eine and zwei;gesellschaft für informatik;microsoft office project portfolio server;sie (file format)	Michael Becker;Stephan Klingner;Michael Sonnenberg	2014				OS	-102.21165042283971	34.175790941817944	24889
9665a9e166276eff59cc738c43aedd8d3aece516	modeling and simulation in systems engineering whither simulation based acquisition	modelizacion;system engineering;concepcion ingenieria;engineering design;simulation systeme;modeling and simulation;conception ingenierie;developpement produit;modelisation;system simulation;modeling;simulacion sistema;desarrollo producto;simulation based acquisition;product development	Simulation and modeling are major assets in the engineering of systems of all types. This two-part series addresses the much expanded role for M&S that is due to the prospect that evolutionary and adaptive engineering efforts are the wave of the future. The Department of Defense's Simulation BasedAcquisition initiative is a case in point, but some critical issues need to be addressed to bring it to fruition. In this first part, we set the background in systems engineering, information technology and the new role of complex adaptive system models that are changing our view of organizations as machines to organizations as organisms.		Andrew P. Sage;Stephen R. Olson	2001	Simulation	10.1177/003754970107600207	simulation;systems modeling;systems engineering;engineering;modeling and simulation;new product development	EDA	-62.89001472990611	12.163015894424602	24896
155de0ec486030ae2f33fccf9e876bd99dff1e17	gerald gerlach neuer gma-vorsitzender		154 at – Automatisierungstechnik 55 (2007) 3 / DOI 10.1524/auto.2007.55.3.154 © Oldenbourg Wissenschaftsverlag Neuer Vorsitzender der VDI/VDE-Gesellschaft Messund Automatisierungstechnik (GMA) ist Professor Dr.-Ing. habil. Gerald Gerlach (48). Damit steht er ab 1.1.2007 für drei Jahre an der Spitze der etwa 13.000 Mitglieder starken Fachgesellschaft des Vereins Deutscher Ingenieure (VDI) und des Verbandes Elektrotechnik Elektronik Informationstechnik (VDE). Gerald Gerlach ist seit 1997 Mitglied des Beirats und seit 2000 stellvertretender Vorsitzender der GMA. Gerald Gerlach neuer GMA-Vorsitzender	desktop virtualization;german terminology association;gesellschaft für informatik;intel gma;virtual distributed ethernet	Bernd Reißenweber	2007	Automatisierungstechnik	10.1524/auto.2007.55.3.154-1	polymer science;control engineering;engineering	Crypto	-99.28540438161875	29.70833999819461	24998
fe454b3658fd044f13af5946eb4d4ecc4e72a676	examination of platform and differentiating elements in product family design	mass customization;product platform;product family;product family design;product design	The problems of mass customization, portfolio design, and platform design all pose a common challenge to the designer: knowing how to partition a set of product variants to maximize commonality and simultaneously achieve sufficient differentiation for purposes of customization. This research focuses on the particular issue of how differences between platform elements and differentiating elements are evidenced in the product layout or configuration. The premise of this research is that certain architectural properties, such as modularity, vary between platform and differentiating elements. In particular, certain measures of commonality offer an appropriate set of indices for evaluating these differences in a systematic and repeatable manner. Both function and physical solution commonality provide a descriptor with which to distinguish and rank platform and differentiating elements. By evaluating components of a product in terms of function commonality, physical solution commonality, and modularity, a comparison can be made between platforms and differentiating elements with respect to these indices. The hypothesis of this work is that platforms are integrated and the non-common differentiating elements are, relative to the platforms, more modular. While anecdotal evidence exists to support this idea, the purpose of this work is to evaluate two existing product families as a means for analyzing this hypothesized relation. The M. Van Wie · R. B. Stone (B) Department of Interdisciplinary Engineering, University of Missouri-Rolla, Rolla, USA e-mail: rstone@umr.edu H. Thevenot · T. Simpson Department of Industrial & Manufacturing Engineering, Penn State University, University Park, USA result of this research is a descriptive set of knowledge that illustrates distinguishing factors between platform and differentiating elements. The data specifically demonstrates the differences in modularity between platforms and differentiating elements, thus suggesting how this design aspect can and should be addressed during design. While not the focus of this study, future research involving a more prescriptive approach to design can directly benefit from the results. The knowledge gained in this work serves as a foundation for addressing portfolio design where both customization and commonality are key issues.	email;internet explorer;modularity (networks);relation (database);simpson's rule	Michael Van Wie;Robert B. Stone;Henri J. Thevenot;Timothy W. Simpson	2007	J. Intelligent Manufacturing	10.1007/s10845-007-0005-0	mass customization;systems engineering;engineering;marketing;product design	DB	-80.42723069961771	6.8162156375518315	25095
6741e0a9424af1e4b15dbbc16a51f014b7609f91	erfahrungen beim softwareorientierten entwurf eines portablen betriebsleitsystems des öffentlichen personennahverkehrs	ffentlichen personennahverkehrs	Als Betriebsleitsystem wird im offentlichen Personenverkehr ein Informationssystem bezeichnet, das dem Betreiber der Verkehrsmittel einen vollstandigen und genauen Uberblick uber den Betriebszustand gibt und ihm damit erlaubt, kurzfristig dispositiv oder langerfristig planend sein Verkehrsangebot qualitativ zu verbessern und den Einsatz der Verkehrsmittel zu optimieren /Girnau/.		Walter Sonnenberg	1981		10.1007/978-3-662-01089-1_43		Crypto	-104.45903797785658	32.30705977815266	25096
576b55f4280fe8a30dc2698ce5464ef3214e252f	evaluating the performance of the taiwanese hotel industry using a weight slacks-based measure	performance measure;efficiency;tourism;data envelopment analysis;hotels;operating characteristic;performance measurement;data envelope analysis;productivity growth	The purpose of this paper is threefold: to assess the performance of 55 international tourist hotels in Taiwan in 2001 in terms of managerial, occupancy, and catering efficiencies; to analyze hotel operating characteristics, which might explain the variation in managerial efficiencies across these hotels; and to measure productivity growth in the 34 international tourist hotels over the years 1990–2001. Empirical results indicate that (1) the marketing for lodging services was not operated efficiently in 2001; (2) the hotels operated poorly both at the levels of occupancy and catering efficiencies in 2001; (3) there is a weak tendency for a hotel with relative high catering efficiency to go with good occupancy efficiency; (4) differences in operating variables, such as the floor space of catering department, the number of guest rooms, the closeness of a hotel to CKS international airport, and the number of employees do have a significant influence upon hotel performance; and finally, (5) about 61.76% of hotels had annual productivity changes over time.		Shinn Sun;Wen-Min Lu	2005	APJOR	10.1142/S0217595905000595	economics;marketing;operations management;data envelopment analysis;management	Robotics	-84.84130712238162	7.477929107352236	25115
657398c9864af55fb005d57dc129d59800a4177a	zur repräsentation von kontrollstrukturen und von wissen in der musteranalyse	der musteranalyse;sentation von kontrollstrukturen und;von wissen;zur repr	Zu den wesentlichen Komponenten eines Systems zur Analyse von Mustern gehoren unter anderem ein Kontrollmodul und ein Modul, der Wissen uber die strukturellen Eigenschaften der Muster und den Problemkreis enthalt. In diesem Beitrag wird die Reprasentation der Kontrollstruktur und des Wissens mit Hilfe von hierarchischen Graphen (h-Graphen) diskutiert. Die Aufgabe des Kontrollmoduls besteht in der Auswahl weniger geeigneter Suchpfade im Problemlosungsgraphen. An einem Beispiel wird die Reprasentation des Kontrollmoduls mit einem h-Graphen erlautert. Mit Hilfe von Wissen ist es moglich, den Suchraum bei der Problemlosung einzugrenzen. Die Reprasentation von Wissen mit h-Graphen wird ebenfalls durch ein Beispiel erlautert.		Heinrich Niemann	1980		10.1007/978-3-642-67687-1_10		Crypto	-104.65447182324445	31.791116945251517	25159
9442bc2536073397f5f92a4ff5a3423f83daa824	conception et évaluation d'outils décisionnels pour des systèmes réactifs d'aide à la mobilité	heuristique;heuristic;pickup and delivery;vehicule partage;collecte et livraison;vehicule partage optimisation combinatoire transport collecte et livraison heuristique en francais;optimisation combinatoire;transport;vehicle sharing;combinatorial optimization;vehicle sharing combinatorial optimization transport pickup and delivery heuristic	Dans le cadre de cette these, nous nous interessons au traitement des problemes d’optimisation combinatoire lies a la conception d’outils de gestion des systemes de vehicules partages. Ces problemes sont proches des problemes de collecte et de livraison. Apres avoir realise une etude theorique sur des problemes d’optimisation combinatoire autour du transport et des methodes de resolutions, nous nous sommes interesses ici a trois problemes particuliers : le PPRV, le PPRV-PM et le PPRV-T. Le premier probleme est le Probleme de Planification du Redeploiement de Vehicules partages (PPRV). C’est une extension du One-commodity Pickup-and-Delivery Problem (1-PDP) car les vehicules partages sont indifferencies. Nous avons propose un modele lineaire et une heuristique utilisant le schema hybride ILS/VND. L’approche developpee repose sur la strategie « route-first, cluster-second » : on commence par construire une tournee geante, puis on l’ameliore par une procedure de perturbation et une recherche locale. Pendant la recherche locale, la contrainte de capacite des vehicules est momentanement relaxee et progressivement restauree ; la tournee geante obtenue est ensuite transformee en plusieurs tournees a l’aide de la procedure Split. Les deux problemes suivants sont consideres comme des extensions du PPRV en autorisant des livraisons partielles : PPRV avec Passage Multiple (PPRV-PM) et PPRV avec Transfert d’objets (PPRV-T). Nous proposons une approche de type « divide-first, route-second » pour la resolution du PPRV-PM. Elle consiste a effectuer d’abord un fractionnement de la demande, puis la resoudre a l’aide d’un schema hybride de type GRASP/VND. Le PPRV-T etend le PPRV-PM au transfert d’objets entre les transporteurs lors du passage sur un sommet. Nous avons reformule le PPRV-T comme un probleme de multi-flots couples sur un reseau dynamique. Nous avons propose une methode d’insertion basee sur cette modelisation.	linear algebra	Libo Ren	2012			philosophy;performance art	Crypto	-105.773535084643	15.644963808968662	25164
0284d4ae5e22ed8db7ccf8094f42e80922e7ecde	average waiting time of customers in a new queue system with different classes	change management;numerical model;customer differentiation;priority queue;business process re engineering bpr;process planning;customer service management;business process modelling bpm	Purpose – It is very complicated to keep the business processes under control since the business processes change rapidly and thus flexibility is an important attribute which businesses should possess in order to respond to rapid changes in the business environment. The purpose of this paper is to divide the companies' customers into different priority groups to be served according to their payment history and feedback in order to increase the companies' performance and profit and save the time of customers within high priority class which may lead to increase their satisfaction.Design/methodology/approach – The paper proposes a requirements engineering‐based approach for business process modelling to assist businesses maintain their performance in such an environment. The paper proposes a new numerical model to improve customer satisfaction in relation to delivery or service waiting time according to their priority class, particularly customers in the high priority class. A call centre at the selected te...		Youseef Alotaibi;Fei Liu	2013	Business Proc. Manag. Journal	10.1108/14637151311294903	customer to customer;economics;business process reengineering;systems engineering;artifact-centric business process model;marketing;operations management;change management;process management;business process;management;business process modeling;priority queue	Metrics	-77.14429822782267	12.60485705552496	25173
75d1660550e39cf657a25c11d7ce3c4031c279ab	kobil: idtoken für den npa in allen postbank finanzcentern erhältlich		men der Security Document World (SDW) Konferenz und Ausstellung in London statt. Der letzte große Test dieser Art wurde 2008 in Prag durchgeführt. In diesem Jahr wird der Fokus des Tests auf die Konformität zum neuen Sicherheitsstandard SAC, Supplemental Access Control, gelegt. Dieser Mechanismus wurde von der ICAO (Internationale zivile Luftfahrt Organisation) zum neuen Standard mit Wirkung ab 2015 definiert und stellt für die nächsten 10 bis 20 Jahre einen noch höheren Schutz bei der Zugriffsberechtigung auf Passdaten sicher. Ab 2015 werden somit ausschließlich elektronische Reisedokumente mit diesem Standard ausgegeben. Der Interoperabilitätstest wurde von secunet spezifiziert und ausgearbeitet und bietet Herstellern von Identitätsdokumenten sowie Anbietern und Integratoren von Prüfsystemen die Chance, frühzeitig vor Inkrafttreten des neuen Mechanismus ihre Produktionsund Prüfverfahren entsprechend zu testen. secunet wurde von Science Media Partners, dem Veranstalter der SDW, mit der Durchführung und Leitung des dreitägigen Testverfahrens beauftragt, an dem über 30 namhafte Passhersteller und Lieferanten von Passlesegeräten aus aller Welt teilnahmen.	gesellschaft für informatik;supplemental access control;vhf omnidirectional range	Finanzcentern erhältlich	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0189-8		Crypto	-103.5557141449497	35.314811780665735	25178
01738459b3b3b4f8265dcc9afaca1d6bf93f78a1	improving the systems engineering process with multilevel analysis of interactions	design for testability;systems engineering;complexity;system integration;design structure matrix;working paper	The systems engineering V (SE-V) is an established process model to guide the development of complex engineering projects (INCOSE, 2011). The SE-V process involves decomposition and integration of system elements through a sequence of tasks that produce both a system design and its testing specifications, followed by successive levels of build, integration, and test activities. This paper presents a method to improve SE-V implementation by mapping multilevel data into design structure matrix (DSM) models. DSM is a representation methodology for identifying interactions either between components or tasks associated with a complex engineering project (Eppinger & Browning, 2012). Multilevel refers to SE-V data on complex interactions that are germane either at multiple levels of analysis, e.g. component versus subsystem conducted either within a single phase or across multiple time phases, e.g. early or late in the SE-V process. This method extends conventional DSM representation schema by incorporating multilevel test coverage data as vectors into the off diagonal cells. These vectors provide a richer description of potential interactions between product architecture and SE-V integration test tasks than conventional domain mapping matrices (DMMs). We illustrate this method with data from a complex engineering project in the offshore oil industry. Data analysis identifies potential for unanticipated outcomes based on incomplete coverage of SE-V interactions during integration tests. Additionally, assessment of multilevel features using maximum and minimum function queries isolates all the interfaces that are associated with either early or late revelations of integration risks based on the planned suite of SE-V integration tests.	algorithm;complex system;coverage data;data aggregation;design for testing;design structure matrix;fault coverage;integration testing;interaction;mit engineering systems division;maxima and minima;multilevel model;process modeling;systems architecture;systems design;systems engineering;unintended consequences	Steven D. Eppinger;Nitindra R. Joglekar;Alison Olechowski;Terence Teo	2014	AI EDAM	10.1017/S089006041400050X	complexity;computer science;systems engineering;engineering;artificial intelligence;data mining;design for testing;design structure matrix;system integration;mechanical engineering	SE	-63.979886108698025	17.393698361324393	25181
531ffb36b203a5d0992ab375b906e88ec7573ac3	performance measurement und competency management in der praxis			altran praxis	Anita Graf	2002	HMD - Praxis Wirtschaftsinform.		engineering;knowledge management;praxis;performance measurement;competence (human resources)	Metrics	-93.63773518476917	27.57867697952041	25225
8211e96cebe55cc9ce5fd68a7651bdaddbe08f7d	metaphern in der informatik: modellbildung, formalisierung, anwendung				Carsten Busch	1998				Vision	-99.8559786566514	25.274196940027657	25275
b612c115d7112bf0e465c50f86aad23aca2db3b2	lte-advanced simulation framework based on omnet++	economie;lte advanced simulation framework based on omnet;naturel;sciences humaines;arts;conseiller;simulation;simulation framework;9783659596940;droit;musique;livre specialise;medical;technologie;3659596949;livres pour enfants et jeunes;sciences sociales;informatique;ecole et apprentissage;lte advanced;fiction;voyage;autres;omnet;978 3 659 59694 0	Long Term Evolution-Advanced (LTEAdvanced) is the most recent mobile telecommunication technology proposed by 3GPP. LTE-Advanced is applied in some countries, but still in development and testing phase, because of that, a simulation model is needed to test this technology. This paper introduce a LTEAdvanced simulation framework based on OMNeT++ IDE (open source). The proposed framework test results showed that it’s working properly and ready to be used. This framework can be considered as the beginning of the LTE-Advanced simulation model based on OMNeT++.	compaq lte;open-source software;simulation	Muhsen Hammoud;Abid Abdelouahab	2012	CoRR		simulation;engineering;artificial intelligence;operations research	EDA	-109.45720561242497	11.970151130822932	25278
e6b0aca6eecb09eaffeafc17833e18873be1a44b	secure business processes optimization system	business process	In this article are described security-related aspects implemented on the first stages of a project which has as the main target retaining the experience acquired by the experts in a business area of an enterprise, to later on train junior employees and help in decision making processes. To create this knowledge base, the designed system, based on business rules and information provided by the experts, can train and help the new employees to learn the experience previously acquired by the experts. It is critical to keep this information out of reach from unauthorized personnel, due to the high economic cost an intrusion and access to this information could suppose.	authorization;information;knowledge base	Antonio Sarasa Cabezuelo;Daniel Ruiz-Zorrilla Gonzalo;Marcos Muiños Martín	2004			computer science;business requirements;process management;knowledge base;business system planning;business process management;european union;new business development;business case;business rule	HCI	-69.4949687068325	13.906385665260627	25293
d2538773127c5a4cf09310734b5a8bb01d187d06	mitteilungen der gesellschaft für informatik 186. folge			gesellschaft für informatik		2007	Informatik-Spektrum	10.1007/s00287-007-0169-1		Vision	-96.70227073565484	24.571588990500818	25326
c2c6731c461ead7600b244bb91d7c3b2c1b0badc	software verification and validation(position statement)	representation of solids;computer graphics;geometric data bases;computational geometry;geometric modelling;cad cam	Logicon was an original advocate of software verification and validation (V&V). We began performing V&V for the Air Force when the control of critical functions in space and missile applications moved from hardware into software. Since these early beginnings, V&V has evolved at Logicon to embrace several complementary techniques for software evaluation. Current V&V methods rigorously test and analyze the software to ensure that it performs all intended functions and that it does not cause unintended functions to occur.	software verification and validation	Marilyn S. Fujii	1978		10.1145/800178.810133	simulation;software verification;computer science;theoretical computer science	SE	-69.39769490227842	32.6931037458335	25354
c0d5a0925f013cafdae966e5a547418a1dc5df49	software quality assurance	software quality assurance	Quality and quality assurance are difficult to define unambiguously in most industries, and this problem is even worse in the software industry. There is, also, a lack of agreement about the goals and functions of software quality assurance (SQA). SQA seems to have no distinctive role other than subjectively assessing the work of software developers and managers. The paper suggests that SQA should take responsibility for the company software metrics programme, and describes the research from the Alvey and the ESPRIT programmes which provide a useful starting point for QA staff. Not only would this give SQA staff a well-defined role, it would also provide the means to address the real issues which should be resolved to assure product quality, such as providing the means both to measure 'quality: and to obtain objective evidence of the costs and benefits of various software development techniques.	alvey;software developer;software development process;software industry;software metric;software quality assurance	Barbara A. Kitchenham	1989	Microprocessors and Microsystems - Embedded Hardware Design	10.1016/0141-9331(89)90045-8	software security assurance;qa/qc;verification and validation;software quality management;computer science;software quality control;software quality;software metric;software quality analyst	SE	-69.20402478844714	22.14401089654277	25383
5e5b9352f24829084af1c436dc2c26b0103741ac	using an issue-based hypertext system to capture the software life-cycle process	software life cycle		hypertext;software release life cycle	Mark Lease;Mac Lively;John J. Leggett	1990	Hypermedia		personal software process;long-term support;verification and validation;software sizing;human–computer interaction;computer science;package development process;backporting;software design;social software engineering;component-based software engineering;software development;software construction;software release life cycle;software walkthrough;software deployment;goal-driven software development process;software development process;software system;software peer review	SE	-63.415898833718906	25.437955742746986	25398
bb6d6348fd9848e3b55e45f675b39483c79f120a	analise e projeto de sistemas de controle fuzzy: uma abordagem no dominio da frequencia				Carlos Alberto Murari Pinheiro	2000				Logic	-105.83599826420324	17.85113472458026	25435
fe4f714405b05bbdab752a4e4da86566335e49b4	the role of it in a healthy business ecosystem: an exploratory study of the korean capital market from a keystone company's perspective	keystone;business ecosystem;korean capital market ecosystem;healthiness;it role	The business environmental structure is constantly being shaped by customer’s desires and market dynamics. A large number of loosely interconnected participants make up a business ecosystem, and offers a customized and complete set of products and services. In a business ecosystem, the competitiveness of a company is influenced by its own capability and its interrelated partners’ capabilities. Therefore, a company should enhance not only its competitiveness but also related companies’ capabilities. To do this, a company has to find its place in the business ecosystem to make a complete business strategy using IT. This paper provides business ecosystem strategies and academic guidelines from the perspective of a single company. Firstly, a business ecosystem perspective is conceptualized, and the importance of a keystone company’s role in the ecosystem is examined. Then, using a case study method, focus is put on the keystone’s IT capabilities that pave the way for a healthy business ecosystem. This paper explores the Korean Capital Market as an example of a business ecosystem and finds the role of IT, particularly from the perspective of a keystone company. Through this study, it is confirmed that the keystone company’s IT capabilities play an important role in the healthy business ecosystem. This paper provides guidelines to practitioners in keystone companies and gives ideas to IT researchers.	business ecosystem;competitive analysis (online algorithm);exploratory testing;keystone effect;strategic management	Hyeyoung Kim;Jae-Nam Lee;Jaemin Han	2008			environmental resource management;ecosystem valuation;business ecosystem;commerce	Web+IR	-77.69447483675917	6.0905001196388895	25459
b5762f73ecb5e86402e6fd31f1f41a0179cf2ca6	lebenslanger datenschutz: anforderungen an vertrauenswürdige infrastrukturen		Die Dynamik der Technikentwicklung in den vergangenen Jahren konfrontiert Datenschützer immer wieder aufs Neue mit Risiken für die Privatsphäre der Betroffenen — und es sieht so aus, als ob sich dies in den nächsten Jahren und Jahrzehnten nicht ändern wird. Konzepte für einen lebenslangen Datenschutz erfordern ein Umdenken vom kurzatmigen Systementwurf zu langfristigen und zukunftsfähigen Planungen.	gesellschaft für informatik	Marit Hansen;Sven Thomsen	2010	Datenschutz und Datensicherheit - DuD	10.1007/s11623-010-0088-1	computer science;internet privacy;computer security	ML	-103.64864145936467	36.505717157661294	25492
db5843e6affb49edf34545ee047553337b04cd44	optimal segmented polynomial l s -approximations	best approximation	Characteristic properties of such approximations are given. An algorithm providing good, but not necessarily best, approximations is also discussed. Es werden charakteristische Eigenschaften solcher Approximationen gegeben. Ein Algorithmus, der gute, aber nicht unbedingt beste Approximationen liefert, wird diskutiert.	algorithm;approximation;polynomial	John B. Kioustelidis	1981	Computing	10.1007/BF02243481	mathematical optimization;combinatorics;discrete mathematics;mathematics	Theory	-96.84332372022801	35.849499638651245	25508
f18fa38c44f7aa0d01a84d960e8524a1d7ec1085	performance evaluation and prediction of parallel applications. (évaluation et prédiction de performance d'applications parallèles)			performance evaluation	George S. Markomanolis	2014				HPC	-102.12359678743991	14.74001241348783	25521
2d6966280847b111286ff302797681c293f7229b	using history information to improve design flaws detection	software metrics;quality assurance;history;god class;software prototyping;software maintenance;program debugging software maintenance software prototyping software metrics quality assurance object oriented programming;object oriented programming;design flaws detection;large scale;semantic information;software evolution;automatic detection;object oriented;software metric;data class;diseases;humans;program debugging;object oriented programming design flaws detection god class data class software maintenance software evolution software metrics quality assurance;information analysis;history software maintenance diseases information analysis large scale systems software quality software metrics quality assurance object oriented programming humans;software quality;large scale systems	As systems evolve and their structure decays, maintainers need accurate and automatic identification of the design problems. Current approaches for automatic detection of design problems are not accurate enough because they analyze only a single version of a system and consequently they miss essential information as design problems appear and evolve over time. Our approach is to use the historical information of the suspected flawed structure to increase the accuracy of the automatic problem detection. Our means is to define measurements which summarize how persistent the problem was and how much maintenance effort was spent on the suspected structure. We apply our approach on a large scale case study and show how it improves the accuracy of the detection of god classes and data classes, and additionally how it adds valuable semantical information about the evolution of flawed design structures.	automatic identification and data capture;sensor	Daniel Ratiu;Stéphane Ducasse;Tudor Gîrba;Radu Marinescu	2004	Eighth European Conference on Software Maintenance and Reengineering, 2004. CSMR 2004. Proceedings.	10.1109/CSMR.2004.1281423	reliability engineering;quality assurance;computer science;systems engineering;engineering;software engineering;database;programming language;object-oriented programming;software metric	SE	-63.31905185814213	35.98937587511166	25526
f465d3422422b97acedb158540359cac0e793760	mudanças de opinião em redes complexas				André M. Timpanaro	2012				NLP	-104.89905031976276	18.64294284997848	25530
61e9dbbafcc54b4eb071df6d8d11dc2066820306	apprentissage de la complexité du corps-cerveau en robotique bio-inspirée		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Apprentissage de la Complexité du Corps-Cerveau en Robotique Bio-Inspirée Alexandre Pitti		Alex Pitti	2017			philosophy;performance art	Logic	-107.52609583455981	11.79564920763923	25565
0ca08b189f383cb061c103a11ede3109f5d03ddf	adaptive enterprise resilience management: adaptive action design research in financial services case study	adaptability;service;resilience;model driven;operations;architecture	"""Resilience is the ability of an enterprise to absorb, recover and adapt from a disruption. Being resilient is a complex undertaking for enterprises operating in a highly dynamic environment and striving for continuous efficiency and innovation. The challenge for enterprises is to offer and run a customer-centric and interdependent large portfolio of resilient services. The fundamental research question is: how to enable service resilience in the practical enterprise resilience context? This paper addresses this important research question, and reports findings from on-going (2014-2016) research on adaptive enterprise resilience management in an Australian financial services organization (FSO). This research is being conducted using the adaptive action-design research (ADR) method to iteratively research, develop and deliver the desired resilience framework in short increments. This paper presents the overall evolved adaptive enterprise resilience management framework and its """"service resilience"""" element details as one of the key outcomes from the second adaptive ADR increment."""	denial-of-service attack;interdependence;service-oriented architecture	Asif Gill;Eng Chew;David Kricker;Geoff Bird	2016	2016 IEEE 18th Conference on Business Informatics (CBI)	10.1109/CBI.2016.21	knowledge management;environmental resource management;operations management;socio-ecological system;business	HPC	-74.44944259691833	10.752050147296668	25574
ae9ee52cb8596d8194cbdfd71c44770ebe4f9131	évaluation de l'efficacité de dégradation et de décontamination cutanée du ceo2 vis-à-vis d'un composé organophosphoré, le paraoxon. (evaluating the effectiveness of ceo2 for the degradation and skin decontamination of an organophosphorus pesticide, paraoxon)			elegant degradation	Alicia Salerno	2016				Crypto	-103.5198438241274	17.711829465957305	25579
07d29672af390c33f127109f6363d91d7279e9e3	"""software engineering challenges of the """"net"""" generation"""	software engineering;net generation	The theme of the 2008 IEEE Conference on Software Engineering Education and Training (CSEE&T'08) was ''Educating the Net Generation of Software Engineers.'' The theme acknowledged the vital role that Internet technologies and applications play in the society and the importance of properly educating and training the ''Net'' generation of software engineers. The Net generation characterizes the current students who may have never known life without the Internet. Their early and ubiquitous exposure to technology has defined their styles, their modes of communication, their learning preferences, their social choices, and their entertainment preferences. Additionally, the realities of the software industry for which the Net generation need to prepare have shifted from that of the foundational beliefs and practices of many software engineering educators. Thus the educators need to become familiar with the Net era's teaching and training challenges, to investigate the peculiarities of educating and training Net software engineers, and to identify the necessary ingredients for success and for improving our teaching practices and course delivery methodologies. In addition, Gartner (http://www.gartner.com) has projected the world market for open source software to grow to $35B before the end of this decade. How do we need to change our curriculum to prepare students to develop open source software? The number of security attacks on software is growing exponentially each year. How do we teach students to build security into their software and to implement software consistent with privacy policies? Increasingly, software development teams are geographically distributed as teams are disbursed throughout the globe and as telecommuting is on the rise. Are students learning about communication and coordination practices for working in these distributed teams? As educators, how do we adjust our teaching to meet the personal preferences and technical challenges of the net generation of software engineers? These and similar open issues were addressed at the CSEE&T '08 in a number of keynotes, technical and experience papers, presentations, and workshops. A number of these were selected and further extended for the current issue of the Journal of Systems and Software. A summary of each article is provided below.	software engineering	Hossein Saiedian	2009	Journal of Systems and Software	10.1016/j.jss.2009.01.020	personal software process;team software process;simulation;software quality management;software engineering process group;crowdsourcing software development;computer science;engineering;knowledge management;social software engineering;software development;software engineering;software as a service;software walkthrough;management;software peer review	SE	-66.99740974107971	24.957060338356385	25620
b3789a4da285e1c01f6888e91050a459070808da	die permeabilität von stufenschichten und ihre ausnutzung für zerstörungsfreie leseverfahren		Es wird zunächst über Permeabilitätsmessungen an einer Permalloy-Stufenschicht als Funktion des Magnetisierungszustandes im Frequenzbereich von 1 bis 300 MHz berichtet. Darauf aufbauend wird ein nicht zerstörendes Leseverfahren mit Koinzidenzaufruf erläutert, bei dem die Permeabilität der aufgerufenen Schicht zur Anzeige der gespeicherten Information dient. Die hiermit erreichbare Speicherkapazität wird stark begrenzt durch Störungen, die von nicht ausreichend kompensierbarem Luftfluß herrühren. Es wird deshalb noch ein weiteres Leseverfahren beschrieben, bei dem an der aufgerufenen Schicht zwei Hochfrequenzfeider unterschiedlicher Frequenz überlagert werden. Eine der hierbei gebildeten Kombinationsfrequenzen wird als Lesesignal ausgenutzt. Auf diese Weise wird durch Frequenzselektion eine Trennung des Lesesignals von den Luftflußstörungen ermöglicht. Eine Abschätzung der Störsignale ergibt, daß damit Speicherkapazitäten von mehreren 10^ Worten bei Zugriffszeiten unter einer Mikrosekunde erreichbar sein sollten.	eine and zwei;es evm	L. Ness;Roland Schilling	1964	Elektronische Rechenanlagen	10.1524/itit.1964.6.16.126	embedded system;operating system;computer science	OS	-104.20234340435161	32.72322056272475	25623
4c2f1d82c2fbb1c6848055ff57b205b2e5305476	statistische fehleruntersuchung an systemsoftware - ein weg zur planmäßigen qualitätsverbesserung bei größeren softwareprodukten / α statistical error investigation of system software - a way towards a planed improvement in the quality of large scale software products				Karl-Heinrich Möller	1984	Elektronische Rechenanlagen	10.1524/itit.1984.26.16.239	embedded system;computer engineering;software;computer science;system software	SE	-93.1034597168366	25.646161068840396	25629
66026440829b02293cc50cde727d1a4186257a2d	dud recht		das Versehen zu entschuldigen. ▶ Die Gerichte sind bei der Auslegung und Anwendung des § 81g StPO gehalten, die Bedeutung und Tragweite dieses Grundrechts angemessen zu berücksichtigen ▶ Notwendig für die Anordnung einer Maßnahme nach § 81g StPO ist, dass wegen der Art oder Ausführung der bereits ab-geurteilten Straftat, der Persönlichkeit des Verurteilten oder sonstiger Erkenntnisse Grund zu der Annahme besteht, dass gegen ihn erneut Strafverfahren wegen Straftaten von erheb-licher Bedeutung zu führen sind. Die Prognoseentscheidung setzt voraus, dass ihr eine zureichen-de Sachaufklärung vorausgegangen ist und die für sie bedeutsa-men Umstände nachvollziehbar abgewogen werden.	citeseerx;die (integrated circuit);eine and zwei;link rot;sie (file format)	Anmerkung D Red;In Heft;Orientierungssätze	2014	Datenschutz und Datensicherheit - DuD	10.1007/s11623-014-0105-x		OS	-104.82202631186532	33.81381869699681	25682
76bf4802313331f7ca9bd26f5a4c9c1bc29f3ba3	using software theater for the demonstration of innovative ubiquitous applications	rapid iteration;prototypes;informal models;design evaluation;demonstration;scenarios	Software development has to cope with uncertainties and changing requirements that constantly arise in the development process. Agile methods address this challenge by adopting an incremental development process and delivering working software frequently. However, current validation techniques used in sprint reviews are not sufficient for emerging applications based on ubiquitous technologies. To fill this gap, we propose a new way of demonstration called Software Theater. Based on ideas from theater plays, it aims at presenting scenario-based demonstration in a theatrical way to highlight new features, new user experience and new technical architecture in an integrated performance. We have used Software Theater in more than twenty projects and the result is overall positive.	agile software development;information technology architecture;iterative and incremental development;requirement;scrum (software development);user experience	Han Xu;Stephan Krusche;Bernd Brügge	2015		10.1145/2786805.2803207	simulation;computer science;systems engineering;engineering;software development;software engineering;prototype;goal-driven software development process;software development process;computer engineering	SE	-65.24086065996023	22.522683859698013	25718
337477949291497493db1ad7cd91a0c13b806282	künstliche intelligenz - funktion und folgen		The contribution is addressed to Management; it deals with the questions arising from Artificial Intelligence		Frank Thomas	1991	Wirtschaftsinformatik		knowledge management;computer science	NLP	-94.38040786588716	21.956844344006743	25738
6ffd25e934eaa8ab4283fe88814e93871c2be856	una herramienta visual para la búsqueda semántica rdf		Resumen. La cantidad de información que uno o más usuarios de Internet generan para la Web Semántica está incrementando diariamente. Por esto, es necesario desarrollar herramientas que nos permitan mostrar esta información de una manera rápida, simple y fácil de entender. De acuerdo con esta premisa, hemos desarrollado una herramienta de visualización de datos semánticos, denominada DBPedia Search, capaz de: 1) consultar cualquier base de datos de tripletas que cuente con un endpoint de SPARQL y; 2) generar gráficos, mapas de calor y mapas de geolocalización de manera automática, con base en la información obtenida de la búsqueda realizada por el usuario. El objetivo principal es realizar una búsqueda y un análisis simplificados de los datos semánticos y presentarlos gráficamente.	bibliothèque de l'école des chartes;communication endpoint;dbpedia;el-fish;linear algebra;naruto shippuden: clash of ninja revolution 3;power-on reset;resource description framework;sparql;unique name assumption;uno	Joanna Alvarado-Uribe;Miguel González-Mendoza;Neil Hernández-Gress;Carlos Eli Escobar-Ruiz;Marcos Uriel Hernández-Camacho	2015	Research in Computing Science		world wide web;philosophy	Security	-107.91364126593581	16.18599310101046	25754
27c5c71f3c2d6873731b6cac1cc8d8ff03668303	necessity of using dynamic bayesian networks for feedback analysis into product development	bayesian network;product lifecycle management;computer graphics;product life cycle management;bayes methods;recycling bayes methods computer graphics customer satisfaction product life cycle management production engineering computing quality management;product life cycle;biological system modeling;bayesian methods;maintenance engineering;dynamic bayesian networks;production engineering computing;customer satisfaction;product use information;biological system modeling data models bayesian methods maintenance engineering;condition monitoring;dynamic bayesian network;graphical method;graphical methods;quality management system;customer satisfaction dynamic bayesian network feedback analysis product development customer knowledge product use information product lifecycle management economic organizational process recycling graphical method product improvement quality management;recycling;quality management;data models;bayesian networks;dynamic bayesian networks product lifecycle management product use information graphical methods bayesian networks;product development	Transformations into the modern business world is sustained by enhancement and improvement of strategies, systems and techniques towards evaluating and applying customer knowledge for the integration of Product Use Information (PUI) into product development, and meeting customer and market demands. In this paper the processing and modelling of PUI of many instances of one product type which is captured during the product use phase, e.g. condition monitoring data, failures or incidences of maintenance, raised by different graphical methods on the basis of a praxis and application scenario. Product Lifecycle Management (PLM) ensures a uniform data basis for supporting numerous engineering and economic organizational processes along the entire product life cycle - from the first product idea to disposal or recycling of the product. The processing and modelling of PUI raised by graphical methods like Bayesian Networks (BNs) or Dynamic Bayesian Networks (DBNs). In accordance, the product use knowledge leads back of the product development phase. This is used for discovering room for product improvements for the next product generation. Therefore the PUI of the different instances should be aggregated by applying fusion techniques to deduce/achieve generalized product improvements for a product type which is related to prospective research by focus on quality management systems and defining measures for customer satisfaction. As a result the significant aspect of this paper is to identify which graphical solution brings optimally the best results for the requirements of processing and modeling of PUI.	altran praxis;customer knowledge;dynamic bayesian network;graphical user interface;list of graphical methods;new product development;product type;prospective search;requirement	Susanne Dienst;Fazel Ansari;Alexander Holland;Madjid Fathi	2010	2010 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2010.5641887	maintenance engineering;quality management;service product management;computer science;product design specification;machine learning;bayesian network;product management;product design;dynamic bayesian network;new product development;product engineering	DB	-63.89004890755885	11.302202569797947	25770
38d1c6ef5474b94d339bcbda256cbf6066a81849	bridge methods: using a balanced project practice portfolio to integrate agile and formal process methodologies	project manager;best practice	"""This paper examines the non-linear nature of progress on software projects. It asserts that this uneven accomplishment stems from the continuous need to drive value quickly in response to a project manager or owner perceiving that a project is failing, near failure, or a least that the owning organization is """"loosing value"""" from either poor process or poor organizational choices of tools and development methods.It describes how using a balanced project practice portfolio to integrate agile and formal process methodologies can theoretically reduce the observed variance in project productivity caused by poorly applied or poorly selected """"best practices"""".Finally, it proposes a methodology that uses expected practice performance and combinations of practices to; identify missing practices, off-set poorly applied practices, and assess the quantity and types of practices required to smooth and optimize project performance outcomes."""	agile software development;bridge circuit;failure;nonlinear system	Stephen J. Cohen;William H. Money	2009	2009 42nd Hawaii International Conference on System Sciences	10.1109/HICSS.2009.607	computer science;knowledge management;marketing;management science;project management triangle;management;project charter;project planning;best practice;project portfolio management	SE	-70.2045422440962	22.04444479540827	25774
dcd523f108c838ff9a2392e1d14e341b65e11c27	a three-dimensional approach in evaluating erp software within the acquisition process	implementation;three dimensional;erp;enterprise resource planning;evaluation;functionality;technical	This paper is based on an extensive study of the evaluation process of the acquisition of an ERP software of four organizations. Three distinct process types and activities were found: vendorâ€™s evaluation, functional evaluation, and technical evaluation. This paper provides another perspective on evaluation and sets it apart as modality for action, whose intent is to investigate and uncover by means of specific defined evaluative activities all issues pertinent to ERP software that an organization can use in its decision to acquire a solution that will meet its needs (i.e., the assessment of the vendor, technology, and fit of a specific ERP software to a given organization).	enterprise resource planning	Jacques Verville;Christine Bernadas;Alannah Halingten	2005	IJEIS	10.4018/jeis.2005070101	reliability engineering;three-dimensional space;computer science;systems engineering;knowledge management;evaluation;implementation;management;law	ML	-77.68665430443214	9.82165115851433	25845
d840024b6accd112a3b35b67e7c284fe573e7a32	information processing design choices, strategy, and risk management performance	information processing design choice;organizational performance;it system;information processing theory;information technology;specific strategic posture;strategic contingency theory;u.s. life;domain offensive organization;front end;information processing design choices;risk management performance	We examined the relationship between information technology (IT) and organizational performance in the U.S. life/health insurance industry by applying and testing Galbraith's information processing theory and strategic contingency theory. Rather than focusing on resource allocations in IT, we instead examined the manner in which IT is deployed in organizations through information processing design choices. Our results suggest that while some information processing design choices are generally related to organizational performance, others should be matched to a specific strategic posture. For example, we found that all organizations benefit from using IT to increase cost-effectiveness. However, other uses of IT should be more closely aligned with an organization's strategy. In particular, domain offensive organizations should align their IT systems to focus on the front end of their operations and understanding customer needs, which will spur further innovation.	align (company);information processing theory;poor posture;risk management	James F. Fairbank;Giuseppe Joe Labianca;H. Kevin Steensma;Richard Metters	2006	J. of Management Information Systems		economics;risk management;information processing;knowledge management;marketing;operations management;strategic choice theory;management science;risk management information systems;management;law;information technology	HCI	-79.12171242966943	4.807087183935169	25856
cae2f423e3a7fb183d358c1efa56192baf406716	mass customization in supply chain level: development of a conceptual framework to manage and assess performance		Recent market interest on customized offers and intensive competi- tion on attracting market globally, lead companies to implement supply chain management to improve performance and gain competitive advantage. To this aim, Supply chain management in customer-oriented environment is pursuing the transition from traditional supply chain into concurrent flexible and efficient one. This paper aims to understand specifically how supply chain within this environment needs to be configured and managed in order to enable efficient customization for mass market. To reach this goal, a conceptual framework and list of indicators to support the framework have been developed and tested.		Mahnoosh Zebardast;Silvia Malpezi;Marco Taisch	2013		10.1007/978-3-642-41263-9_11	supply chain risk management;supply chain management;service management;knowledge management;marketing;operations management;supply chain;business	Robotics	-75.93177673983998	6.071147413323216	25871
e7ade0b786734a3678b4c61d480201927e548f69	the agile research penultimatum	research project management.;software engineering processes;agile research;agile methods;agile software development;software engineering;product development	Agile software development is a widely used and successful methodology for organizing and managing software product development in an industry setting. For academic research projects in Computer Science, the development of software is often a major component and the use of agile methods may be appropriate. The fundamental difference in how software engineering is performed in an academic research setting as compared with that of industry, however, means that a strict application of agile approaches may not be ideal. In this paper, we adapt the Agile Manifesto to the needs of an academic research project. Four case studies are presented, two from industry, one from academia, and one from an industry-academia collaborative project to support the adaptations, motivating a set of proposed agile research policies called the Agile Research Penultimatum.	agile software development;computer science;new product development;organizing (structure);software engineering	Thomas Way;Sandhya Chandrasekhar;Arun Murthy	2009			control network;communications system;electric power transmission;spare part;control channel;network management;computer network;permission;computer science;communication channel;systems engineering	SE	-65.92644801375664	20.415053892176925	25877
4d6b1b29155ddfee2edbb47ea918e05d320c20df	assessing an organization's capability to effectively implement its selected agile method(s): an objectives, principles, strategies approach	software prototyping;organizations couplings object recognition software measurement capability maturity model documentation;indicators;agile assessment;effectiveness;and strategies;adequacy;software prototyping organisational aspects software development management;indicators agile assessment adequacy capability effectiveness linkages among objectives principles and strategies;principles;capability;linkages among objectives;multilevel assessment view customized agile method organizational objectives agile assessment adequacy method effectiveness objectives principles and strategies ops framework agile philosophy objectives indicator values;software development management;organisational aspects	Agile methods provide an organization or a team with the flexibility to adopt a selected subset of principles and practices based on their culture, their values, and the types of systems that they develop. More specifically, every organization or team implements a customized agile method, tailored to better accommodate its needs. However, the extent to which a customized method supports the organizational objectives, i.e. the 'goodness' of that method, should be demonstrable. Existing agile assessment approaches focus on comparative analyses, or are limited in scope and application. In this research, we present a systematic, comprehensive approach to assessing the 'goodness' of agile methods. We examine an agile method based on (1) its adequacy, (2) the capability of the organization to support the adopted principles and practices specified by the method, and (3) the method's effectiveness. We employ the Objectives, Principles and Strategies (OPS) Framework to guide our assessment process. The Framework (a) specifies objectives of the agile philosophy, (b) identifies principles that support the objectives, (c) designates strategies that implement the principles, (d) defines linkages that relate objectives to principles, and principles to strategies, and (e) prescribes indicators for assessing the extent to which an organization supports the implementation and effectiveness of those strategies. The propagation of indicator values along the linkages provides a multi-level assessment view of the agile method. In this paper, we discuss our assessment approach and substantiation results.	agile software development;emoticon;ops5;software propagation	Shvetha Soundararajan;Osman Balci;James D. Arthur	2013	2013 Agile Conference	10.1109/AGILE.2013.9	agile unified process;agile usability engineering;systems engineering;engineering;knowledge management;management science;empirical process;lean software development	SE	-68.58164470597981	15.27266599213069	25910
a92f9a393949f0c0f30766e89397d42e5dffc751	icpabb: ein interaktives computerprogramm zur auswertung von blutspiegelkurven mit der bateman-funktion (mit stapelbetriebversion)				Elmar Kisslinger	1981				Crypto	-99.64626903695907	26.329186595017273	25973
7f241f2382e3585aa6c5526e499697a1acd21264	play-testing and requirements engineering: implications for research and teaching		In Requirements Engineering (RE) for large scale game systems, play-testing is an important activity that is used to validate requirements from players' perspective. Play-testers are not professionals that are involved in the process of RE. They are not professional testers, either. Yet, their feedback in terms of perceptions and experiences of the early prototypes of a game, have a decisive impact on what the RE-professionals do next in the RE process. This position paper presents a qualitative study that sought to discover who takes the role of play-testers and what kind of feedback play-testers generate in the early stages of RE for games. The case study responds to the observation that no textbook on RE or software engineering addresses play-testing as a phenomenon, and that classic Computer Science programs at universities teach testing techniques mostly in the context of embedded systems, hence students often are left with little opportunity to develop testing skills that build upon play-testing practices happening in the game development sector. The study therefore was aimed at identifying important implications that play-testing may have for research and teaching.	computer science;embedded system;experience;feedback;play store;playtest;requirement;requirements engineering;software engineering;video game development	Maya Daneva	2015	2015 IEEE/ACM 2nd International Workshop on Requirements Engineering and Testing		simulation;systems engineering;engineering;software engineering;requirements engineering;game testing	SE	-67.38495041902007	24.970473043569758	26012
314580ae8489b1b7bd99bb74c1e569f2ad08d635	integrated impact analysis for managing software changes	software;history;software maintenance;information retrieval;software couplings data mining maintenance engineering history information retrieval automation;software management;system monitoring;contextual information;statistical significance;maintenance engineering;data mining;public domain software;impact analysis;indexing;latent semantic indexing;indexation;management of change;maintenance issues integrated impact analysis software change management adaptive approach source code single snapshot textual change request latent semantic indexing impact set estimation best fit combination contextual information execution trace initial source code entity information retrieval dynamic analysis data mining developer knowledge source open source software systems;source code;couplings;empirical evaluation;system monitoring data mining indexing information retrieval management of change public domain software software maintenance software management;dynamic analysis;open source software;automation	The paper presents an adaptive approach to perform impact analysis from a given change request to source code. Given a textual change request (e.g., a bug report), a single snapshot (release) of source code, indexed using Latent Semantic Indexing, is used to estimate the impact set. Should additional contextual information be available, the approach configures the best-fit combination to produce an improved impact set. Contextual information includes the execution trace and an initial source code entity verified for change. Combinations of information retrieval, dynamic analysis, and data mining of past source code commits are considered. The research hypothesis is that these combinations help counter the precision or recall deficit of individual techniques and improve the overall accuracy. The tandem operation of the three techniques sets it apart from other related solutions. Automation along with the effective utilization of two key sources of developer knowledge, which are often overlooked in impact analysis at the change request level, is achieved.   To validate our approach, we conducted an empirical evaluation on four open source software systems. A benchmark consisting of a number of maintenance issues, such as feature requests and bug fixes, and their associated source code changes was established by manual examination of these systems and their change history. Our results indicate that there are combinations formed from the augmented developer contextual information that show statistically significant improvement over stand-alone approaches.	automation;benchmark (computing);bug tracking system;change request;curve fitting;data mining;information retrieval;open-source software;snapshot (computer storage);software feature;software system;tandem computers	Malcom Gethers;Bogdan Dit;Huzefa H. Kagdi;Denys Poshyvanyk	2012	2012 34th International Conference on Software Engineering (ICSE)	10.1109/ICSE.2012.6227172	maintenance engineering;system monitoring;search engine indexing;latent semantic indexing;computer science;operating system;automation;software engineering;data mining;database;dynamic program analysis;statistical significance;coupling;programming language;software maintenance;public domain software;information retrieval;source code	SE	-63.29595782940449	36.896622828401135	26038
b04d93f49b490de5a5e27d723feffda106596179	multimedia auf der überholspur, aber wohin?		Ein neues Zauberwort in der ITBranche heisst gegenwärtig Multimedia. Nicht selten entsteht der Eindruck Multimedia löse eine Vielzahl der heutigen und künftigen Anwendungsprobleme. Fantastische Nutzungsmöglichkeiten werden angepriesen die realistischen Bedürfnisse dafür fehlen allerdings noch sehr oft. Trotz der eher skeptisch zu betrachtenden Euphorie, lässt sich nicht abstreiten, dass gerade im Handel ein besonders grosses Potential für den Einsatz neuer multimedialer Systeme liegt. Hier werden traditionell schon seit Jahrzehnten in verschiedensten Ausprägungen multimediale Elemente z.B. für die Produktwerbung eingesetzt. Interaktive multimediale Informationsund Kommunikationssysteme werden durch die konsequente Integration digitalisierter Einzelelemente wie Bilder, Video, Ton, Text und Daten eine völlig neue Qualität in die verschiedenen Bereiche des Handels bringen. Mit der vorliegenden Ausgabe des EM-Newsletters möchten wir Ihnen einige interessante Beispiele für die verschiedenen Einsatzmöglichkeiten multimedialer Systeme im Handel vorstellen. Unsere Autoren aus Praxis und Forschung berichten Ihnen in diesem Zusammenhang über ihre vielfältigen Ideen, Erfahrungen und Projekte im Multimediabereich. Aus aktuellem Anlass finden Sie in dieser Ausgabe neben den Multimedia-Beiträgen auch einen kurzen Bericht über die neue elektronische Holzbörse des Schweizer Waldwirtschaftsverbandes.	altran praxis;eine and zwei;handel;handel-c;internet explorer;parity (physics);sie (file format);système universitaire de documentation;zentralblatt math	Teddy Ivanitzki	1993	Electronic Markets		economics;marketing;multimedia	OS	-102.51205550313249	30.026886832310378	26054
dc47c9a2ebf571934316949ef28f7ca49e04635f	ngn, all-ip, b3g: enabler für das future net?!		Unterschiedliche Vorstellungen und Begriffe prägen gegenwärtig die Vorstellungen und Visionen über die Weiterentwicklung des Internets. Forschungsund Entwicklungsarbeiten in Richtung Future Net werden unter Bezeichnungen wie NGN, all-IP oder aber auch B3G („beyond 3G Networks“) durchgeführt.	internet explorer;internets;next-generation network	Claudia Eckert;Kpatcha M. Bayarou;Sebastian Rohr	2003	Informatik-Spektrum	10.1007/s00287-003-0359-5	software engineering;computer science;next-generation network	AI	-101.51862311660722	36.348688831776215	26108
b17f45d5dce57c0d05a6502e790810cb35555993	warum facebook spaß macht: freudvolles erleben in sozialen netzwerkdiensten			facebook messenger	Danny Pannicke;Rüdiger Zarnekow;Stefanie Neumann	2012			computer science;multimedia	NLP	-104.42895044983683	37.375082165395284	26110
eadd6a9d707e4f8cf2cb552c0d163d1f0a755f82	valuation of software initiatives under uncertainty: concepts, issues, and techniques		State of the practice in software engineering economics often focuses exclusively on cost issues and technical considerations for decision making. Value-based software engineering (VBSE) expands the cost focus by also considering benefits, opportunities, and risks. Of central importance in this context is valuation, the process for determining the economic value of a product, service, or a process. Uncertainty is a major challenge in the valuation of software assets and projects. This chapter first introduces uncertainty along with other significant issues and concepts in valuation, and surveys the relevant literature. Then it discusses decision tree and options-based techniques to demonstrate how valuation can help with dynamic decision making under uncertainty in software development projects.	decision theory;decision tree;software development;software engineering;value (ethics)	Hakan Erdogmus;John M. Favaro;Michael Halling	2006		10.1007/3-540-29263-2_3	systems engineering;engineering;environmental resource management;management science	SE	-76.2212419975689	11.521341856117186	26145
ba5cedc5fbe95711425bb01d3e6e98ab77d05488	software development lifecycle models	rad;software systems;spiral;sdlc;incremental;vmodel;b model;unified;software development;wheel and spoke;software development life cycle;system development;waterfall;sen history column	This history column article provides a tour of the main software development life cycle (SDLC) models. (A lifecycle covers all the stages of software from its inception with requirements definition through to fielding and maintenance.) System development lifecycle models have drawn heavily on software and so the two terms can be used interchangeably in terms of SDLC, especially since software development in this respect encompasses software systems development. Because the merits of selecting and using an SDLC vary according to the environment in which software is developed as well as its application, I discuss three broad categories for consideration when analyzing the relative merits of SDLC models. I consider the waterfall model before the other models because it has had a profound effect on software development, and has additionally influenced many SDLC models prevalent today. Thereafter, I consider some of the mainstream models and finish with a discussion of what the future could hold for SDLC models.	application lifecycle management;requirement;software development process;software system;synchronous data link control;waterfall model	Nayan B. Ruparelia	2010	ACM SIGSOFT Software Engineering Notes	10.1145/1764810.1764814	p-modeling framework;long-term support;verification and validation;simulation;software sizing;computer science;systems engineering;engineering;backporting;social software engineering;software development;software design description;software engineering;iterative and incremental development;software construction;systems development life cycle;application lifecycle management;management;goal-driven software development process;software development process	SE	-66.50001974923926	23.52635442421814	26170
82ceab5cbb000f7ec6639c5ec722eb5bb1c4ccee	completeness and consistency of the system requirement specification		Although the System Requirement Specification, as a first formal and detailed document, is the base for the software project in classic software methodologies, there is a noticeable problem of assuring the completeness of this document. The lack of its completeness causes uncertainty of the project foundations. This was one of motivations for agile methodologies – if the SRS cannot be easily validated, if it can change in late project phases, then get rid of the SRS. Replace formal requirements with user stories. However user stories are also requirements mostly functional requirements. As agile methodologies focus on functional requirements, it is easy to forget quality requirements. In this paper we show the impact of quality requirements analysis on functional requirements exploration. Although in our experiment we noticed considerable large functional requirements increment, we went further and examined the impact of SRS consistency on its completeness. The research has shown that the increment of the revealed requirements count may be almost three times greater, compared to the standard requirement specification method.	agile software development;functional requirement;graph (abstract data type);requirements analysis;software development process;software project management;user story	Jaroslaw Kuchta	2016		10.15439/2016F468	sequential consistency	SE	-64.17743519909762	32.138317705212565	26188
6a0440c423d29ba1047ac14017a5f21a09412150	assessing an organization's preparedness for the virtual enterprise: the templet model	information systems;corporate modelling;virtual enterprises information management ansi standards sgml standards organizations technology management collaborative tools;organization virtual enterprise templet model hierarchical model information management survey;business data processing;information management;information systems business data processing corporate modelling;virtual enterprise;hierarchical model;field study	The CALS community has been developing virtual enterprise tools since the mid-1980s. This paper discusses the development of a model of an organization's virtual enterprise capability that draws on the experience and perceptions of the CALS practitioner community. The model, called the TEMPLET model, is a hierarchical model with four main capability elements: technology, information management, organization and process. Specific capabilities for each element are defined. The model was verified through a practitioner survey and a set of field studies. The relative importance of each element and item is discussed. Adjustments to the model are proposed as well as a reduced model that could be used to gain a quick picture of an organization. The TEMPLET model is of interest to practitioners as a model of an organization's VE capability. For the academic community, it provides a model that can be used to develop VE assessment and improvement capability tools. For both communities, it summarizes years of CALS experience and how it impacts on our understanding of the development of virtual enterprises.	virtual enterprise	Darren Meister	2000		10.1109/HICSS.2000.926885	computer science;knowledge management;marketing;software engineering;database;management science;information management;management;world wide web;information system;hierarchical database model;enterprise information system	DB	-78.06508432772272	8.52412817432558	26201
eff96cacf4dc6de43ff9ff257f95309a97445121	deteccao e delimitacao automatica de corpos hidricos em imagens sentinel-2: uma proposta de integracao do algoritmo fmask aos indices espectrais ndwi e mndwi.				Thales Vaz Penha;Mikhaela Aloisia Jessie Santos Pletsch;Celso Henrique Leite Silva;Thales Sehn Korting;Leila Maria Garcia Fonseca	2017			computer science;data mining;information retrieval	Vision	-105.61729960653506	16.848893971030694	26290
367ac79e6ce8f0b28a32d2b943e77ed7152010fb	design and implementation of training course for software process improvement engineers	analytical models;software;training;personnel;organizations;problem solving;data models	It is widely recognized that software process improvement (SPI) engineers need to be trained by software engineering groups to perform quality SPI activities. However, such engineers are required to have a wide range of skills, and therefore it is difficult to properly determine the scope and goal of training courses. To solve such problems, the group companies of Mitsubishi Electric Corporation have developed a training course for SPI engineers that can provide practical content in a short period by focusing on skills for solving the real problems that SPI engineers often encounter in the field. This paper describes the design and implementation of the course, and proves its effectiveness with a questionnaire survey answered after taking the course from which results show that 67.7% of the trainees find themselves much more skilled than before, and 89.8% believe this is due to taking the course.	capability maturity model integration;iso/iec 42010;international standard book number;requirement;software engineering institute;software engineering process group;software development process;software release life cycle;watts humphrey	Noriyoshi Kuno;Tsuyoshi Nakajima	2016	2016 23rd Asia-Pacific Software Engineering Conference (APSEC)	10.1109/APSEC.2016.065	data modeling;simulation;computer science;systems engineering;organization;engineering;software engineering;management science;management	SE	-66.2629852014869	26.02696453668296	26349
0e7ec5930207ab2398c3ac2e208c12ba8b48b71a	bestimmung der gemeinsamen streureaktanz des polsystems von synchronmaschinen	synchronmaschine;parameterbestimmung;gemeinsame streureaktanz;canay-reaktanz;synchronous machine;parameter determination;mutual leakage reactance;canay reactance	synchronmaschine;parameterbestimmung;gemeinsame streureaktanz;canay-reaktanz;synchronous machine;parameter determination;mutual leakage reactance;canay reactance		Hartmut Mrugowsky	2011	Elektrotechnik und Informationstechnik	10.1007/s00502-011-0033-5		Crypto	-104.71927506840849	25.576069365782185	26352
ec7973d61d8d8ad0d528e8c4add277bd871a5c34	insights from social network analysis -- case board interlocks in finnish game industry	social network services;technological innovation;measurement;industries;companies;ecosystems;games	In the world of networked innovation and ecosystems, flows of resources into the organization as well as between organizations are emphasized. This allows for using network measures for better understanding. In this study, we look at the case context of Finnish game industry, concentrating especially on inter-organizational flows of board networks or interlocks, and the possibilities of using SNA metrics for insights. The game industry has been very successful, with a turnover of 1.8 Billion Euros in 2014, and we explore the role of board interlocks in it. Our findings of the formal board member networks indicate that in contrast to the assumptions of high actor or node level metrics (degree and betweenness centrality) and the network level metrics (density and clustering), board interlocks are limited.	betweenness centrality;cluster analysis;ecosystem;interlock (engineering);social network analysis;trust metric	Arho Suominen;Nina Rilla;Juha Oksanen;Kaisa Still	2016	2016 49th Hawaii International Conference on System Sciences (HICSS)	10.1109/HICSS.2016.561	public relations;games;ecosystem;computer science;marketing;operations management;management;measurement	Visualization	-76.84995049543569	5.497495509008933	26418
4885beb887100000435216e053a0261600ee217f	microsoft interactive media products: worldwide usability and design practices	interactive media	"""Interface Design Director Senior User Experience, Usability and Product Interface Design Architect • Sixteen-year industry experience: Software, Web, Healthcare, Consumer Electronics, Interactive Television, and Print Advertising. • Seasoned experience in product interface usability, human factors, design psychology and user interface design standards. • Experienced senior user experience architect utilizing use case analysis and UML during requirements analysis, conceptual and logical design. • A specialist in product interfaces that are compelling, easy to understand """"out of the box"""" and efficient to use every day, ensuring customer satisfaction and product competitiveness early and throughout the product development life cycle."""	human factors and ergonomics;industrial and organizational psychology;interactive media;new product development;out of the box (feature);requirement;requirements analysis;software development process;thinking outside the box;unified modeling language;usability;user experience design;user interface design	John Geoffrey Corso	1997				HCI	-75.79986491124247	18.748341644995687	26431
9f7d13705bc486790961ba5d199fff98c117cae8	einführung: energiewende - unter dach und fach?			fach	Karl Dorfmeister	2015	Elektrotechnik und Informationstechnik	10.1007/s00502-015-0369-3		NLP	-97.95065804987497	26.19539226938505	26442
c11c9aa2217d4647840ec27b971972df099308ca	a study on customer satisfaction in mobile telecommunication market by using sem and system dynamic method	system dynamics modeling;system dynamics;customer satisfaction;mobile telecommunication;correlation coefficient	In this article, a new method is presented to research the mechanism of Customer Satisfaction (CS). Firstly, the research model of CS based on the TAM and ACSI is built. Secondly, some important correlation coefficients of research model can be got from the SEM method. Thirdly, with these correlation coefficients, the main functions of system dynamic model are built, and the evolution of the system is simluated with the help of VENSIM. At last, one simple example is designed by using the method and some meaningful conclusions are provided.	coefficient;ibm tivoli access manager;mathematical model;system dynamics;vensim	Yuanquan Li;Jiayin Qi;Huaying Shu	2007		10.1007/978-0-387-76312-5_48	marketing;operations management;business;commerce	AI	-84.17620275419533	9.900978585312561	26448
6bce01d17accdbd72cca663f20bbb55efaa5533a	quantitative measurement of scientific software quality: definition of a novel quality model			software quality	Bojana Koteska;Anastas Mishev;Ljupco Pejov	2018	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194018500146	systems engineering;computer science;data mining;software quality	SE	-63.15756821139982	27.217438705863664	26450
31e362acaaf9ceddcbe9d694eb7e8590717d8df0	towards the strategic analysis of agile practices		Agile methods are widely believed to have the pot ential to improve software processes. Given the variety of agile prac tices, organizations face difficult decisions on which ones to adopt. Recogniz ing that agile adoption is often motivated by strategic concerns such as marke t competitiveness or responsiveness to customer needs, this paper outlin es a framework for the strategic analysis of agile practices. The framewor k aims to support the decision making process leading to agile adoption. The frame work builds upon a knowledge base of experiences collected from empiri cal studies. Goal modeling techniques from requirements engineering are incorp orated in the form of a Strategies Graph. The graph resembles the Strategy Map from Balanced Scorecards familiar to many managers.	agile software development;experience;goal modeling;knowledge base;requirements engineering;responsiveness	Hesam Chiniforooshan Esfahani;Eric Kai-Hsiang Yu;Maria Carmela Annosi	2011			extreme programming practices;empirical process (process control model);agile software development;agile unified process;software;agile usability engineering;lean software development;systems engineering;engineering	AI	-72.55416036427515	9.289896337452308	26462
55ee0639d525ebdc86afd79aed8f8c2895472b77	bewertung der protokollarchitektur für die nahbereichskommunikation				Christian Cseh;Marcus Völker	1997				NLP	-99.06733285101961	23.67267420249974	26464
927ec2093d2099ba824cc2810ce31c81dfadd8e7	recsys'09 industrial keynote: top 10 lessons learned developing deploying and operating real-world recommender systems	service provider;real time;digital music;real world application;recommender system;lessons learned;real world applications;recommender systems	The number of online services providing users with real-time recommendations has increased exponentially over the last few years. Recommender Systems that were originally only accessible to a limited number of high-tech companies are now widely available through a growing number of both technical choices and vendors. The acceptance however, of automatically delivered recommendations by users depends on numerous factors that go far beyond the algorithms that constitute the major focus of researchers. This talk will share a number of lessons learned over the last ten years creating and operating recommender systems in a multitude of domains, from digital music to fitness plans through personal finance management, and in a multitude of business settings, from lightweight integrations to highly-coupled integrations within secure bank environments.	algorithm;coupling (computer programming);e-services;real-time computing;real-time transcription;recommender system	Francisco J. Martin	2009		10.1145/1639714.1639715	service provider;simulation;digital audio;computer science;machine learning;multimedia;world wide web;recommender system	Web+IR	-78.34137956682756	15.803358964901856	26465
9f276f5a32bbf88b9a58345b5675c870ba444c2e	adoption of factory of the future technologies		One of the main innovation potentials to maintain the long-term competitive advantages of the manufacturing sector in high-wage countries is the adoption and implementation of Factory of the Future technologies. Different types of existing Industry 4.0 maturity models open up opportunities of defining the company's strategic position – an important starting point. The presented impact indicator system extends those models to support the path towards the Factory of the Future. Its starting point is a qualitative evaluation of critical success factors, which allows a company to derive measures to utilize the company's innovation potential. Based on this strategic input, the core part of the developed approach is a strategic framework for the quantitative assessment of impacts on the operational performance of a company's value stream and innovation potential.	awareness;big data;capability maturity model;experience;holism;identification friend or foe;industry 4.0;machine learning;pin grid array;responsiveness	Christoph Biegler;Arko Steinwender;Alessandro Sala;Wilfried Sihn;Valerie Rocchi	2018	2018 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)	10.1109/ICE.2018.8436310	competitive advantage;process management;factory;business;critical success factor;value stream mapping	Robotics	-76.17771510661925	6.7901248819317335	26470
06a00c293efe3be66d0dfa5e8ef23f68c63b72d6	toward a model of information system development success: perceptions of information systems development team members	team member benefits;selected works;process quality;information system development success;team member satisfaction;bepress;is success failure;product quality	Many information systems development (ISD) projects are deemed a failure in the field. However, several practitioners and researchers argue these projects could actually be considered successful if we used a broader definition of software development project success. Answering the call for further research on what makes ISD projects successful, this paper describes the process used to build the model of ISD Success, which includes a thorough literature review to create an initial model followed by semi-structured interviews conducted to validate the model and to allow for the discovery of emergent constructs, sub-constructs, and hypotheses. The model is tested with data collected from practitioners using Partial Least Squares (PLS) analysis. The paper concludes with a discussion of the findings and conclusions.	angela mclean (biologist);artifact (software development);computer hardware;database;documentation;emergence;executable;information systems;information systems research;information system;partial least squares regression;semiconductor industry;software developer;software development process;source lines of code;systems theory	Lucian M. Zelazny;France Belanger;David Tegarden	2012			knowledge management;operations management;management	SE	-70.85735700749211	21.978799926695384	26472
7f2adc484a4868786735972421ec9655674b1672	numerical methods for hyperbolic equations of saint-venant type. (méthodes numériques pour des équations hyperboliques de type saint-venant)			numerical method	Chiara Simeoni	2002				Crypto	-103.16553938060488	16.880367571736645	26563
f68af7881d64a27c9511d1c380ebe2da36336a93	living it infrastructures — an ontology-based approach to aligning it infrastructure capacity and business needs		Changes in organizational processes often interact with changes in the IT infrastructure. Accounting for the structural and economic consequences of changes to the modern IT infrastructure remains a challenge, as their complexity can affect more than one business process, and the need to share a common understanding between the IT and the business management challenges current IT governance practices. An integrative perspective of business processes and IT resources would help meet these challenges, but despite some progress such a perspective remains to be developed. This paper proposes a domain ontology an Ontology for Linking Processes and IT infrastructure (OLPIT) – to model the relationship between IT resources and business processes for the purpose of measuring the business value of IT. The ontology was developed and evaluated in the context of a design research project conducted in the Hilti Corporation, an international manufacturing company, with the aim of defining how IT impacts the business and calculating the cost of IT services used.	ansi escape code;artificial intelligence;business process;business requirements;configuration management;database;futures studies;information system;interoperability;iterative method;microsoft outlook for mac;observable;ontology (information science);programming tool;prototype;protégé;real life;usability	Jan vom Brocke;Alessio Maria Braccini;Christian Sonnenberg;Paolo Spagnoletti	2014	Int. J. Accounting Inf. Systems	10.1016/j.accinf.2013.10.004	business transformation;knowledge management;artifact-centric business process model;business process management;environmental resource management;operations architecture;business case;management science;process management;business system planning;business relationship management;business process discovery;management;business rule;new business development;philosophy of business;business process modeling	AI	-73.24799314764859	8.970275190679692	26614
48478bd281fe553e04182a51f6322f73849c4b55	preismodelle für datenmarktplätze		Eine zunehmende Zahl von Anbietern nutzt das Cloud-Computing-Paradigma für einen Handel mit Daten und analytischen Dienstleistungen. In dieser qualitativen Studie präsentieren wir die Ergebnisse aus Interviews mit zwölf etablierten Anbietern. Unsere Ergebnisse zeigen insbesondere eine große Unsicherheit bezüglich der Preissetzung und Preismodellwahl. Ferner erlauben sie eine Abstraktion der betrachteten Marktplätze auf ein einheitliches Schema mit sieben Akteuren sowie sechs atomaren und zwei hybriden Preisstrategien abstrahieren. Darüber hinaus bietet diese Papier erstmals eine strukturierte Entscheidungshilfe für die Wahl eines geeigneten Preismodells für Datenmarktplätze und legt somit den Grundstein für eine algorithmische Unterstützung bei Preismodellwahl und Preisfindung.	cloud computing;eine and zwei;gesellschaft für informatik;handel;sie (file format)	Florian Stahl;Alexander Löser;Gottfried Vossen	2013	Informatik-Spektrum	10.1007/s00287-013-0751-7	world wide web;computer science;performance art	OS	-105.6935221356376	35.30413517186022	26695
9faa0ac4dd036905e6f9f35aa27e8de15436e01b	computer simulation of screen-film systems response based on incident x-ray beam (simulação do desempenho de sstemas écran-filme em função do feixe de raios x incidente)			computer simulation	Marcia Aparecida Silva	2001				Logic	-103.72213989595421	18.866662781749465	26738
620657e20e1364b6a4ff091205a4a827f62c3052	test de systèmes ubiquitaires avec prise en compte explicite de la mobilité. (test ubiquitous systems with explicit consideration of mobility )			linear algebra	Pierre André	2015				EDA	-104.60105943219106	15.288411659799248	26747
b6c2d4d53cc67332f8143fa30f96b8032b97950a	an empirical analysis of software volatility and related factors	software metrics;theoretical model;empirical analysis;software development;software metric;decision process;computer software;programming	Despite the belief that software enhancements must be designed into software applications, there is only little research that has rigorously investigated the relationships that exist between software characteristics and software volatility. The objective of this research is to investigate the relationship of software characteristics with software volatility and its theoretical model is based on two models for software volatility. In this study, software volatility refers to the frequency of enhancements per application. A survey of critical software applications used at a major integrated oil company was used to test the hypotheses. Findings indicate that complexity, software age, and program size are significant predicators for software volatility. These findings could assist companies in their decision process about choosing between maintaining existing software or replacing it, often at substantial financial cost.	volatility	Xiaoni Zhang;John C. Windsor	2003	Industrial Management and Data Systems	10.1108/02635570310470683	reliability engineering;personal software process;verification and validation;software sizing;economics;computer science;systems engineering;package development process;social software engineering;software development;software design description;software engineering;software construction;software walkthrough;software analytics;management;software deployment;software quality;software metric	SE	-65.79502360788616	28.993627460948264	26816
c3004d0166d48810384142e5b7471291c7f6c268	untersuchungen zum verfahren der zulässigen richtungen für drei aufgaben der nichtdifferenzierbaren optimierung				Edgar Großer	1986				NLP	-101.26736111326474	26.4274959515353	26828
840548f856ccf62eba86b5008c5b2aeed9f31af2	expansão de consultas utilizando indexação semântica latente.				Cristiane Amorim Mendes;Edleno Silva de Moura;Nivio Ziviani	2002			database;computer science	Crypto	-104.51742764485394	18.913811568780726	26872
3ad96b8f1a71f15ed955c720bdd88e8b9e0e0fa9	elaboration d'un modèle d'identité numérique adapté à la convergence. (development of a convergence-oriented digital identity framework)		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Elaboration d’un modèle d’identité numérique adapté à la convergence Christophe Kiennert		Christophe Kiennert	2012				ML	-107.8864372581689	11.375878323748852	26898
f857413218ea2f37a6ad1db3d4184fba80134a96	problème d'implantation de plateformes de logistiques durables en milieu urbain. (location problem of sustainable logistics platforms in urban areas)			logistics;milieu intérieur	Nadia Ndhaief	2018				ML	-99.4444022791264	15.709481549494976	26902
e1c4c6cb2516d0e4c89d5614b10d82e6d5c01a2c	building information systems development methods: synthesizing from a basis in both theory and practice	electrical capacitance tomography;foom;formal specification;information systems;theory and practice;requirements validation;systems analysis formal specification information systems software quality;formal specifications;requirements modelling information systems development methods methodological issues requirements engineering action research requirements validation foom high quality systems;requirements elicitation;software engineering;requirements engineering;methodological issues;quality requirement;systems analysis;requirement engineering;high quality systems;electronic switching systems;requirements modelling;information systems development methods;information system;information systems programming electrical capacitance tomography electronic switching systems software quality formal specifications software engineering;action research;programming;software quality;information system development	In this paper, we discuss some methodological issues associated with research into requirements engineering, and describe the benefits afforded to us by using action research to explore issues associated with requirements elicitation, modelling and validation. FOOM is a requirements engineering method which is designed to facilitate the development of high-quality, requirements-conformant information systems. In creating FOOM, an overriding concern has been to ensure both theoretic soundness and practical applicability within the target domain. We discuss in this paper the benefits of using action research as an enquiry mechanism for exploring issues associated with requirements elicitation, modelling and validation, and the way in which it formed a central part of the method’s evaluation and evolution.	information system;requirement;requirements elicitation;requirements engineering;theory	Danielle C. Fowler;Paul A. Swatman	1998		10.1109/ASWEC.1998.730918	reliability engineering;computer science;systems engineering;engineering;software engineering;formal specification;requirements engineering;information system	SE	-64.39961013866161	17.71654920125818	26906
7ec7091589c44420ddc1b916e0a0b020ca68d33d	leveraging it project lifecycle data to predict support costs	project management;project management costing information technology;costing;computer model;information technology;bayesian methods;bayesian method;support cost;information sharing;isbsg dataset it project lifecycle data support cost information sharing;computational modeling;isbsg dataset;computational modeling bayesian methods;it project lifecycle data	There is an intuitive notion that the costs associated with project support actions, currently deemed too high and increasing, are directly related to the effort spent during their development and test phases. Despite the importance of systematically characterizing and understanding this relationship, little has been done in this realm mainly due to the lack of proper tooling for both sharing information between IT project phases and learning from past experiences. To tackle this issue, in this paper we propose a solution that, leveraging existing IT project lifecycle data, is able to predict support costs. The solution has been evaluated through a case study based on the ISBSG dataset, producing correct estimates for more than 80% of the assessed scenarios1.	experience;systems development life cycle	Bruno Lopes Dalmazo;Weverton Luis da Costa Cordeiro;Abraham Lincoln Rabelo de Sousa;Juliano Araujo Wickboldt;Roben Castagna Lunardi;Ricardo Luis dos Santos;Luciano Paschoal Gaspary;Lisandro Zambenedetti Granville;Claudio Bartolini;Marianne Hickey	2011	12th IFIP/IEEE International Symposium on Integrated Network Management (IM 2011) and Workshops	10.1109/INM.2011.5990698	project management;bayesian probability;data science;data mining;project management triangle;management;information technology	Arch	-72.65943719148173	19.256163757818815	26941
acfb65de42bd0a2d7216269a24963870c3d9ad70	on constructing games with a convex set of equilibrium strategies	game theory;necessary and sufficient condition;convex set;bimatrix game	""""""" Necessary and sufficient conditions on a convex set C (of strategy pairs) are given tbr the existence of a 2 • n bimatrix game with equilibrium set C. This is done with the use of a geometriccombinatorial solution method for 2 x n bimatrix games. Zusammenfassung: Es werden notwendige und hinreichende Bedingungen an die konvexe Menge C der Strategiepaare for die Existenz eines 2 x n Bimatrix Spieles mit Gleichgewichtsmenge C aufgegeben. Dies wird durch eine geometrisch-kombinatorisehe L6sungsmethode fiir 2 • n Bimatrix Spiele erreicht."""	convex set;eine and zwei	Peter Borm;A. N. Gijsberts	1990	ZOR - Meth. & Mod. of OR	10.1007/BF01416739	bondareva–shapley theorem;game theory;mathematical optimization;combinatorics;lemke–howson algorithm;repeated game;mathematics;convex set;mathematical economics	ECom	-97.08843156561043	35.17950084622348	26947
9353f910cd39e85ec514ed3659f25d76d12b792a	evaluating web services: towards a framework for emergent	ciblage;economie;economia;web services adoption;methode empirique;empirical analysis;red www;organisation entreprise;inversion;metodo empirico;empirical method;contextual framework;reseau web;service web;food engineering;web service;software engineering;investment;enterprise organization;organizacion empresa;diffusion theory;service industry;blancado;targeting;innovation;service industries;internet;telecomunicacion;industrie service;telecommunication;investissement;software package;genie industriel alimentaire;world wide web;cross section;evaluation;economy;progiciel;ingenieria alimentaria;innovacion;paquete programa;is innovation;servicio web;evaluation framework	The paper develops an evaluation framework with specific reference to Web Services. It is argued that the essential characteristics for such an approach, noted as qualitative, are captured in these constructs through an augmentation of theoretical considerations and empirical findings. A review of the innovation and diffusion literature indicates a considerable amount of research where attention is given to a range of features which may support Web Service adoption. It is argued that the framework proposed in this paper is of value in highlighting the specific situations for an effective evaluation in this respect. The empirical analysis was undertaken within five UK firms. Each of these organizations represent different business sectors including, Telecommunication (two firms), Independent Software Package Vendor (ISV), Software Engineering and Food Services industries. The study involved a cross-section organizational case approach within each situation for factors affecting adoption. The evidence suggests that the empirical data complements traditional innovation and diffusion theories. However, emergent context is identified as a significant influence on potential web evaluation processes to ensure appropriate investment targeting. The findings are noted to guide analysts in determining critical aspects of the complex issues involved and present suggestions for further valid research. 2005 Elsevier B.V. All rights reserved.	coexist (image);emergence;independent software vendor;software engineering;theory;web service	Ray Hackney;Huinan Xu;Ashok Ranchhod	2006	European Journal of Operational Research	10.1016/j.ejor.2005.07.010	tertiary sector of the economy;simulation;economics;food engineering;marketing;operations management	Web+IR	-82.05763230110709	8.895932965676742	26966
c66f015c89d16fad7d9a3234c70e6fe33269f35d	éditorial: universités et grandes écoles : revoir la perception des entreprises			linear algebra	François Mazon	2013	BIAA		media studies;sociology;perception	Crypto	-106.01784827025752	16.04801273125805	26973
645e400bf9130d30ebd2dd6907e137a6e876cabf	factors affecting the success of open source software	intrinsic cues;system success;longitudinal effects;extrinsic cues;open source software	Abstract: With the rapid rise in the use of Open Source Software (OSS) in all types of applications, it is important to know which factors can lead to OSS success. OSS projects evolve and transform over time; therefore success must be examined longitudinally over a period of time. In this research, we examine two measures of project success: project popularity and developer activity, of 283 OSS projects over a span of 3 years, in order to observe changes over time. A comprehensive research model of OSS success is developed which includes both extrinsic and intrinsic attributes. Results show that while many of the hypothesized relationships are supported, there were marked differences in some of the relationships at different points in time lending support to the notion that different factors need to be emphasized as the OSS project unfolds over time.	open sound system;open-source software	Vishal Midha;Prashant Palvia	2012	Journal of Systems and Software	10.1016/j.jss.2011.11.010	simulation;systems engineering;engineering;world wide web	SE	-75.09103050057458	20.908061395317223	26983
77c94b99e0331ca54de52a92b6711b1dd1790345	mobile informations- und kommunikationsdienste: kooperativ, umweltschonend, sicher?		Das explosive Wachstum der Mobilkommunikation trägt die Informatik in alle Welt. Es verändert damit nicht nur die Kultur bei uns, sondern vor allem auch in Schwellenländern und in der Dritten Welt. Gleichzeitig stellt es aber auch die Forschung vor neue Herausforderungen. Die Beherrschung von Heterogenität und Informationsüberflutung, Benutzerfreundlichkeit, Sicherheit und Datenschutz bei der Kommunikation, und nicht zuletzt der hohe Energieund natürliche Ressourcenverbrauch erfordern zum Teil völlig neuartige informatische Konzepte im interdisziplinären Kontext mit Informationstechnik und Anwendungen. Im Vortrag werden diese Herausforderungen sowie einige Lösungen vorgestellt, die im Umfeld des Aachener Exzellenzclusters UMIC (Ultra-Highspeed Mobile Information and Communication) erarbeitet wurden.	vhf omnidirectional range	Matthias Jarke	2010				OS	-103.91681856307979	36.45203587105667	27009
0a5f664d83128f1d4b22b00df08cdd8ae3d15436	survivability analysis of network specifications	electrical capacitance tomography;telecommunication computing electrical capacitance tomography government fault tolerance performance analysis visualization power system modeling finance automation military computing;formal specification;finance;government;united states payment system;telecommunication computing;bank data processing computer network reliability formal specification data visualisation telecommunication computing graphs cheque processing;bank data processing;cheque clearance system;graphs;cheque processing;network specifications;intrusion events;data visualisation;computer dependent critical infrastructures;visualization;model checking;fault events;fault tolerance;abnormal events;performance analysis;essential service maintenance;survivability analysis;reliability analysis;power system modeling;fault injection;scenario graphs;cheque clearance system survivability analysis network specifications essential service maintenance abnormal events fault injection scenario graphs computer dependent critical infrastructures fault events intrusion events model checking global analysis reliability analysis united states payment system;military computing;computer network reliability;global analysis;automation	Survivability is the ability of a system to maintain a set of essential services despite the presence of abnormal events such as faults and intrusions. Ensuring system survivability has increased in importance as critical infrastructures have become heavily dependent on computers. In this paper we present a systematic method for performing survivability analysis of networks. A system architect injects fault and intrusion events into a given specification of a network and then visualizes the effects of the injected events in the form of scenario graphs. In our method, we automatically generate scenario graphs using model checking. Our method enables further global analysis, such as reliability analysis, where mathematical techniques used in different domains are combined in a systematic manner. We illustrate our ideas on an abstract model of the United States Payment	bayesian network;cops (software);communications protocol;computer;e-commerce;faceted classification;model checking;operations security;prototype;unicom system architect	S. Jha;Jeannette M. Wing;Richard C. Linger;Thomas A. Longstaff	2000		10.1109/ICDSN.2000.857597	model checking;reliability engineering;fault tolerance;real-time computing;visualization;computer science;operating system;automation;formal specification;distributed computing;global analysis;programming language;computer security;data visualization;government;computer network	SE	-63.210551897039856	60.41273074456058	27107
68ced116ee2d07bac1267f3a13dbd89b3376d5b8	die bearbeitung von beschwerden mithilfe von workflow-management-systemen: planung, administration, disposition und kontrolle				Reimer Studt	2003				Theory	-98.5486396952682	27.195033092991434	27131
586eba6f3e4e3bbb1ecf204ff7bec67f17b2f7e0	the impact of domain knowledge on the effectiveness of requirements idea generation during requirements elicitation	software educational institutions computer science computers text processing analysis of variance knowledge engineering;creativity;domain ignorance;requirements engineering brainstorming creativity domain awareness domain ignorance empirical software engineering importance of ignorance requirements elicitation;domain awareness;requirement idea generation effectiveness requirement engineering activities domain knowledge domain experts requirement elicitation team computer based system requirement analysts;brainstorming;empirical software engineering;requirements elicitation;requirements engineering;formal verification;software quality;importance of ignorance;problem solving;software quality formal verification problem solving	It is believed that the effectiveness of requirements engineering activities depends at least partially on the individuals involved. One of the factors that seems to influence an individual's effectiveness in requirements engineering activities is knowledge of the problem being solved, i.e., domain knowledge. While a requirements engineer's having in-depth domain knowledge helps him or her to understand the problem easier, he or she can fall for tacit assumptions of the domain and might overlook issues that are obvious to domain experts. This paper describes a controlled experiment to test the hypothesis that adding to a requirements elicitation team for a computer-based system in a particular domain, requirements analysts that are ignorant of the domain improves the effectiveness of the requirements elicitation team. The results, although not conclusive, show some support for accepting the hypothesis. The results were analyzed also to determine the effect of creativity, industrial experience, and requirements engineering experience. The results suggest other hypotheses to be studied in the future.	requirement;requirements elicitation;requirements engineering	Ali Niknafs;Daniel M. Berry	2012	2012 20th IEEE International Requirements Engineering Conference (RE)	10.1109/RE.2012.6345802	domain analysis;requirements analysis;software requirements specification;requirements management;brainstorming;business requirements;formal verification;computer science;systems engineering;engineering;knowledge management;requirement;software engineering;domain engineering;requirements elicitation;management science;requirements engineering;creativity;management;non-functional requirement;software requirements;domain knowledge;software quality	SE	-70.33178519888654	22.903880895195105	27136
0b0f773375ad551c298758851960f4531e154f32	quelques identités de l'analyse combinatoire			bibliothèque de l'école des chartes	Armel Mercier	1984	Discrete Mathematics	10.1016/0012-365X(84)90111-0	pure mathematics;combinatorics;mathematics	Theory	-103.26794645103891	12.69593682222988	27142
e7b26f7c692bd74ac9acd3261780708c7a352bf1	prognose von geldautomatenumsätzen mit sarimax-modellen: eine fallstudie		Die Optimierung der vorgehaltenen Geldmengen in Geldautomaten sowie deren Bestuckungsintervalle erfordert eine genaue Prognose der taglich an Geldautomaten abgehobenen Geldmengen. In dieser Arbeit wird im Rahmen einer Fallstudie der Nutzen konkurrierender Prognoseverfahren verglichen, wobei der Fokus auf SARIMAX-Modellen liegt. Diese berucksichtigen neben saisonalen Effekten auch kausale Kalendereffekte. Zusatzlich werden naive Prognoseverfahren sowie neuronale Netze als Benchmark herangezogen.	eine and zwei	Stephan Scholze;Ulrich Küsters	2007		10.1007/978-3-540-77903-2_44	applied mathematics;discrete mathematics;mathematics	NLP	-97.32285947172377	35.115693739373995	27177
4021b411a8bf287996991e496bee1e473770cfa3	construction et évolution de connaissances par confrontation de points de vue : prototype pour la recherche d'information scientifique	indexation et recherche d information;representation des connaissances;c30 documentation et information;ingenierie des connaissances centree utilisateurs;distance semantique;construction collaborative de connaissances;web 2 0;serendipite;decouverte interactive de connaissances	HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Construction et évolution de connaissances par confrontation de points de vue : prototype pour la recherche d’information scientifique Guillaume Surroca, Philippe Lemoisson, Clement Jonquet, Stefano A. Cerri	hal;interaction;linear algebra;maker faire;prototype;vue;web 2.0	Guillaume Surroca;Philippe Lemoisson;Clement Jonquet;Stefano A. Cerri	2014			sociology;performance art	Logic	-107.7611102161472	12.943943118818028	27180
fc3c5bbddb4056afacf6c85fa5962f214537a28e	domain-specific languages for agile urban policy modelling		In this paper we present a new approach of performing urban policy modelling and making with the help of ICT enabled tools. We present a complete policy cycle that includes creating policy plans, securing stakeholders and public engagement, implementation, monitoring, and evaluating a particular policy model. ICT enabled tools can be deployed at various stages in this cycle, but they require an intuitive interface which can be supported by domainspecific languages (DSLs) as the means to express policy modelling aspects such as computational processes and computer-readable policy rules in the words of the domain expert. In order to evaluate the use of such languages, we present a real-world scenario from the urbanAPI project. We describe how DSLs for this scenario would look like. Finally, we discuss strengths and limitations of our approach as well as lessons learnt.	agile software development;domain-specific language;human-readable medium;subject-matter expert	Michel Kraemer;David Ludlow;Zaheer Abbas Khan	2013		10.7148/2013-0673	systems engineering;knowledge management;management science	NLP	-63.756743905268124	15.496386846947367	27203
fc46628b6614bb97414a0b32d58a5ceb68d10c3b	business modelling agility: turning ideas into business	business modelling;radical innovation;business scrum;business model;business model innovation;disruptive business models;agility	Business Model Innovation is attracting more and more attention from business as well as from academics. Business Model Innovation deals with both technological and knowledge related changes that either may disrupt or sustain existing product/market strategies. Timing of Business Model Innovation both with regard to the right moment as well as speed of implementing competitive concepts becomes crucial. In this conceptual paper we discuss and evaluate possibilities for shortening the lead-time and increasing impact of Business Model Innovation aiming at low-end and new market disruptions. We are building our discussion on recent findings and identifying anomalies for further research by reflecting on exemplary business design cases.		Jukka Heikkilä;Marikka Heikkilä;Harry Bowman	2015			business model;business analysis;business transformation;product-service system;business requirements;knowledge management;artifact-centric business process model;business administration;marketing;business case;electronic business;process management;business;business relationship management;business process discovery;business rule;new business development;philosophy of business;business process modeling;line of business;business activity monitoring;business architecture	HCI	-75.0445063358949	7.236942886163962	27271
a5be02299a1d9cc551499538efd8811b697344d5	rhythms and oscillations : a vision for nanoelectronics. (rythmes et oscillations : une vision pour la nanoélectronique)			linear algebra	Damir Vodenicarevic	2017				Vision	-103.21444604828694	16.52560670618272	27282
ee17b4f70a9cfea93b110684e4be48232b02ec3b	fe meshes preparation for interactive analysis in virtual reality	architectuur virtuele werkelijkheid;architecture virtual reality	As product complexity and marketing competition increase, a collaborative product development is necessary for companies which develop high quality products in short lead-times. To support product actors from different fields, disciplines, and locations, wishing to exchange and share information, the representation of the actors’ viewpoints is the underlying requirement of the collaborative product development. The actors’ viewpoints approach was designed to provide an organisational framework following the actors’ perspectives in the collaboration, and their relationships, could be explicitly gathered and formatted. The approach acknowledges the inevitability of multiple integration of product information as different views, promotes gathering of actors’ interests, and encourages retrieved adequate information while providing support for integration through PLM and/or SCM collaboration. In this paper, a solution for neutral viewpoints representation is proposed. The product, process, and organisation information models are seriatim discussed. A series of issues referring to the viewpoints representation are discussed in detail. Based on XML standard, taking cyclone vessel as an example, an application case of part of product information modelling is stated.	collaborative product development;cyclone;display resolution;information model;new product development;xml	Hichem Geryville;Abdelaziz Bouras;Yacine Ouzrout;Nikolaos Sapidis	2006	CoRR	10.1007/978-2-287-48370-7	information model;computer science;knowledge management;scheduling;product management;new product development;product engineering	DB	-67.89024400678868	9.107147733549624	27326
73cc6ece0b932af0490f88829b7e29be3095e165	messungen in tp-orientierten systemen				Kornél Terplán	1979	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1.1979.2.2.101	computer science;distributed computing	NLP	-95.27628368629712	22.943582107182	27356
b2ebb30a06b04b1f4125928649340d256171160c	towards an evolutionary framework for agile requirements elicitation	elicitation;open space;agile methods;stakeholder involvement;ost;requirements elicitation;requirements;open space technology ost;agile methods ams;scenarios	Numerous reports document difficulties experienced with the development of requirements in software projects. Specifically problems include: developers have limited access to stakeholders, don't fully understand the problem domain and as a consequence, requirements are not well understood. Agile Methods (AMs) encourage stakeholder involvement throughout development however considerable difficulty remains in accommodating continuous negotiation between multiple diverse stakeholders in a given domain. This paper reports on progress to date for developing an evolutionary framework to improve the facilitation of agile requirements elicitation. A potential solution is offered and an initial study indicates positive results.	agile software development;problem domain;requirement;requirements elicitation	Sandra Kelly	2010		10.1145/1822018.1822078	requirements analysis;requirements management;agile unified process;agile usability engineering;systems engineering;engineering;knowledge management;operations management;requirement;requirements elicitation	SE	-69.41322855738629	22.016437878567736	27401
b099ff1b4ca75d2ecf8233cb13c5391922da044a	recherche d'information clinomique dans le dossier patient informatisé : modélisation, implantation et évaluation. (clinomics information retrieval in electronic health records : modelling, implantation and evaluation)			information retrieval;ion implantation	Chloé Cabot	2017				AI	-107.80498713959605	12.903473761060022	27439
d749b09aa2f3d3ec60b556dacfeefe733664a3da	data quality- and master data management - a hospital case	data governance;data management;data quality;hospital;master data management	Poor data quality prevents the analysis of data for decisions which are critical for business. It also has a negative impact on business processes. Nevertheless the maturity level of data quality- and master data management is still insufficient in many organizations nowadays. This article discusses the corresponding maturity of companies and a management cycle integrating data quality- and master data management in a case dealing with benchmarking in hospitals. In conclusion if data quality and master data are not properly managed, structured data should not be acquired in the first place due to the added expense and complexity.		Klaus Arthofer;Dominic Girardi	2017	Studies in health technology and informatics	10.3233/978-1-61499-759-7-259	data mining;master data management;business;data quality	DB	-71.66291577428262	11.49676731495914	27444
e13f75bbb96cee2107b15709b26ffe0200cf65dd	optimal deconvolution filter design based on orthogonal principle	modelizacion;optimisation;deconvolution filter;bloc diagramme;orthogonal principle;optimizacion;ruido;desconvolucion;algorithme;modelisation;algorithm;filter design;filter;bruit;deconvolution;filtre;optimization;principe orthogonale;diagrama conjunto;modeling;filtro;block diagram;noise;algoritmo	An optimal deconvolution filter design approach is introduced for multi-channel systems under colored noise. Unlike the use of classical variational calculus techniques, some algebraic methods like outer-inner factorization and orthogonal principle will be utilized to solve the proposed deconvolution problem. Then an optimal deconvolution filter with least order is obtained. It can be applied to both minimum-phase and nonminimum-phase systems. The design procedure is relatively simple and makes the solution to be computed easily. Zusmnmeaf~ung. Ein Ansatz zum Entwurf optimaler Entfaltungsfilter fiir Mehrkanal-systeme unter der Einwirkung von gef~irbtem Rauschen wird eingefiihrt. Anders als beim Gebrauch klassischer Techniken der Variationsrechnung werden einige algebraische Methoden wie die ~iuBere-innere Faktorisierung und das Orthogonalit~its-Prinzip angewandt, um das vorgestellte Entfaltungs-Problem zu 16sen. Dann erhfilt man ein optimales Entfaltungsfilter mit kleinstmSglicher Ordnung. Es l~il3t sich sowohl auf minimalals auch auf nichtminimal-phasige Systeme anwenden. Der Entwurfsgang ist verhfiltnism/iBig einfach, so dab die L6sung leicht berechnet werden kann. Rrsumr. Nous introduisons une approche optimale de conception de filtre de drconvolution pour des systrmes multi-canaux en prrsence de bruit colorr. A la diffrrence des techniques classiques de calcul variationnel, certaines mrthodes algrbriques telles la factorisation interne-externe et le principe d'orthogonalit6 seront ulilisres pour rrsoudre le problrme de drconvolution proposr. Un filtre de drconvolution optimal ayant le plus petit rang possible peut alors 8tre obtenu. Celui-ci peut &re appliqu6 la fois ~t des syst&nes ~t phase minimale et non minimale. Cette prockdure de conception est relativement simple et permet un calcul facile de la solution.	calculus of variations;colors of noise;deconvolution;filter design;internet explorer;linear algebra;minimum phase;monoid factorisation;système universitaire de documentation;unified model	Bor-Sen Chen;Sen-Chueh Peng	1991	Signal Processing	10.1016/0165-1684(91)90120-8	block diagram;computer vision;mathematical optimization;systems modeling;filter;computer science;noise;deconvolution;calculus;mathematics;blind deconvolution;filter design;algorithm;statistics;wiener deconvolution	Graphics	-98.21059718250393	35.87176540020384	27535
8e294f2132e06ec29538e9b0390475f88bc1cbbe	asynchronous process calculi for specification and verification of information hiding protocols		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Asynchronous Process Calculi for Specification and Verification of Information Hiding Protocols Romain Beauxis	archive;comefrom;hal;linear algebra;process calculus	Romain Beauxis	2009			constraint programming;asynchronous system;information hiding;theoretical computer science;denotational semantics;probabilistic logic;process calculus;concurrency;confluence;computer science;distributed computing	Logic	-109.27406862072891	10.245113475370891	27545
248a687999dd1c41e63fb35c94185e025aec20ae	arbeitslosigkeit bei informatikern: reaktion des arbeitsmarktes auf das ende des it-booms		Die vielfältige Qualifikationsstruktur bei IT-Fachleuten macht es schwer, die Situation der „echten“ Informatiker auf dem Arbeitsmarkt und ihre Betroffenheit durch Arbeitslosigkeit in den letzten zwei Jahren zu separieren. Auf der Basis von Arbeitsmarktdaten und begründeten Schätzungen wird deutlich, dass sich die Situation auch für die Informatiker wie für alle hochqualifizierten ITFachleute zwar verschlechtert hat, aber immer noch günstig ist im Vergleich zu IT-Fachleuten mit mittlerem oder ohne Berufsabschluss.	eine and zwei;internet explorer	Werner Dostal	2003			performance art;history	Crypto	-105.06363990227632	33.86390019670343	27556
40df9d08ffe11c6ea0ea3e679cf21617acb2ad45	reexamining the impact of information technology investment on productivity using regression tree and multivariate adaptive regression splines (mars)	regression tree;information technology;data mining;patient care;it investment;health care cost;productivity;multivariate adaptive regression splines;information technology investment;regression spline;regression splines;health care	As health care costs increased significantly in the 1990s, investments in information technology (IT) in the health care industry have also increased continuously in order to improve the quality of patient care and to respond to government pressure to reduce costs. Several studies have investigated the impact of IT on productivity with mixed conclusions. In this paper, we revisit this issue and re-examine the impact of investments in IT on hospital productivity using two data mining techniques, which allowed us to explore interactions between the input variables as well as conditional impacts. The results of our study indicated that the relationship between IT investment and productivity is very complex. We found that the impact of IT investment is not uniform and the rate of IT impact varies contingent on the amounts invested in the IT Stock, Non-IT Labor, Non-IT Capital, and possibly time.	contingency (philosophy);data mining;decision tree learning;interaction;multivariate adaptive regression splines;smoothing spline	Myung S. Ko;Kweku-Muata Osei-Bryson	2008	Information Technology and Management	10.1007/s10799-008-0036-z	econometrics;actuarial science;economics;multivariate adaptive regression splines;computer science;operations management;machine learning;information technology	HCI	-85.79319845671237	7.876769663781927	27581
1c8420f168ab8ae8b3411393a31670e19f976f90	improving construction industry process interoperability with industry foundation processes (ifp)		Abstract With massive amounts of information generated during the life cycle of large-scale construction projects, interoperability among project stakeholders’ information systems is a requirement for effective and timely communication, collaboration, and information exchange, and ultimately for project success. While data interoperability has been substantially improved by initiatives such as IFC (Industry Foundation Classes) standardizing construction industry data, emphasis on process interoperability which facilitates timely and effective exchange of information via interaction of workflow processes is in its early stage. By conforming to a reference model such as IFP (Industry Foundation Processes), project stakeholders can communicate and collaborate using workflow processes while abstracting the information exchange to essential items to preserve their privacy. This paper explores interoperability in the AEC/FM domain, reviews the main components of the IFP system, presents two IFP interoperability models, and discusses their relationships with the IFP system. The models are demonstrated with specific examples and implemented with a process customization framework based on workflow inheritance rules. Interoperability models that conform to the IFP system not only allow seamless information exchange but can also yield active interaction and communication among stakeholders.		Behrooz Golzarpoor;Carl T. Haas;Derek Rayside;Seokyoung Kang;Matthew Weston	2018	Advanced Engineering Informatics	10.1016/j.aei.2018.09.001	systems engineering;engineering;information system;industry foundation classes;interoperability;information exchange;reference model;exchange of information;project stakeholder;workflow	DB	-62.91862687234713	14.813114593057886	27585
03b48564a80aabb58cb9e4f2dc36bde97d7a0f5b	exceptional events classification in warehousing based on an integrated clustering method for a dataset with mixed-valued attributes		ABSTRACTAs an essential component of a supply chain, warehousing with a high operational management level can significantly enhance the efficiency of manufacturing. Practically, there are many exceptional events (EEs) that impede agile operation in warehousing, and disparate handling processes should be established according to the characteristics of the EEs. In this context, a classification methodology for the EEs based on a generalised criterion with mixed-valued attributes is presented in this study. The approaches for determining the initial clustering centres for a dataset with mixed-valued attributes are illustrated in accordance with the distribution regularities of values of numerical and categorical attributes. Subsequently, two algorithms without randomisation of the initial clustering centres are successively generated: one is a basic iterative algorithm and the other is an algorithm that can optimise the number of clusters automatically. The classification of EEs in warehousing by utilising t...	cluster analysis	Nailiang Li;Chang Zhang;Weixing Xie;Yupeng Li	2018	Int. J. Computer Integrated Manufacturing	10.1080/0951192X.2018.1509129	data mining;engineering;systems engineering;iterative method;categorical variable;supply chain;cluster analysis;agile software development;warehouse	Vision	-67.08285705472241	14.042627370346272	27586
3044006774fef6534e847bdac25017d34aef1337	bestimmung klinisch relevanter bewertungsparameter für diagnostische testprozeduren bei unvollständigen daten				U. Mansmann;U. Partzsch	1996				NLP	-99.51584375333049	26.053633366132654	27611
99eacd33d074b681270e6a55b237849405a7d0c0	challenges of structured reuse adoption - lessons learned		Adoption of structured reuse approaches in practice often poses multiple challenges. Research-industry collaborations are considered as suitable vehicle to mitigate adoption difficulties as well as to validate the applicability of scientific results. However, research cooperations with industry do not always live up to the expectations of either of the partners. Unfortunately for researchers and practitioners alike, insights behind the scenes of failed adoption and cooperation are often difficult to obtain. This hinders discussions on lessons learned by organizations during the adoption process and delays improvements. This paper aims to mitigate this issue by presenting lessons learned from interviews we conducted with practitioners in the context of a study on software reuse in industry. The study covered a wide range of aspects, including the process of reuse adoption. One of the participating companies had undertaken two attempts to adopt a form of structured reuse. However, both attempts did not succeed as expected. In our study, we identified tacit assumptions that were related to the encountered difficulties and present the lessons learned from the adoption approach. Furthermore, we report strategies that helped us to overcome the skepticism caused by a previous unsuccessful guided collaboration.	code reuse;goto;precondition	Veronika Bauer	2015		10.1007/978-3-319-26844-6_3	simulation;engineering;knowledge management;management science;management	HCI	-70.13787202547282	20.914576965528738	27621
ec8d71089d770d7c47156104c893a6559daa3f91	neuronale netze und qualitative wissensbasen in der integrativen umweltsystemanalyse				Jürgen Kropp	2000				Vision	-102.1436888142415	24.963675756579573	27623
d4d977242ba35b6e1b13e24a59244476ba2f69ad	business model innovation based on collaborative product development: a case study of taiwan design services	design chain integration;business model innovation;vertical disintegration;collaborative design;new product development	Due to the ever-increasing global competition in the market, most Taiwan companies have attempted to transform their business from OEM to ODM, and thus continue to create niche values. “One-stop Shopping” design services have emerged as an innovative business model during this trend, particularly in high-tech industries. In this model, a design company collaborates with various manufacturing companies in a product development chain, integrates different core competences, leverages individual resources, and thus offers complete product development services as a virtual enterprise. International customers can readily outsource NPD as a whole to the service team through the design company. This paper discusses such a business innovation based collaborations of SME’s. Important findings regarding the innovation are generalized from a case study of the electronics industry, including value creations, potential risks, and enabling methods. Finally, we propose a protective buffer theory that facilitates the execution of this business model.	asynchronous circuit;bottleneck (engineering);categorization;collaborative product development;new product development;niche blogging;oracle data mining;outsourcing;service innovation;spec#;vertical market software;virtual enterprise	Chih-Hsing Chu;Han-Chung Cheng	2005	IJEBM		product innovation;economics;engineering;artifact-centric business process model;marketing;operations management;advertising;business;mobile business development;product design;management;business rule;new business development;new product development;commerce	SE	-74.41317486492353	5.22072888083257	27651
483d5c5f6bdd297aaee8969c7fdb50ed2fbdc279	morphologie mathématique sur le cercle unité, avec applications aux teintes et aux textures orientées. (mathematical morphology on the unit circle, with applications to hues and to oriented textures)			mathematical morphology	Allan Hanbury	2002				Vision	-104.79821877762927	11.565530811263953	27657
3cc7b8f544ae07ff342c9d5be5bab34f5dcf4f65	soba: a tool support for story card based agile software development	agile software development	There is disclosed a core for use in casting a long concrete slab for forming a continuous hole extending alnog its length. The core comprises a relatively rigid, resilient elongated hollow body having closed opposite ends, and a contractible filling member made of an open-cell foamed material and filled in said hollow body. Also disclosed is a method of casting a long hollow concrete slab, using a core having the construction as aforesaid.	agile software development	Chetankumar Patel;Muthu Ramachandran	2008			software engineering;systems engineering;computer science;extreme programming practices;personal software process;software development;software development process;agile unified process;agile usability engineering;empirical process (process control model);lean software development	SE	-65.42915385034652	21.855880451569618	27665
07b88178f6933d38e56c90df2a34c28cc325ebc6	voraussetzungen und organisatorische wirkungen des informationsmanagements				Joachim Niedereichholz;Christoph Wentzel	1985	Angewandte Informatik		data science;information system;cartography;geography	Crypto	-99.80420342567898	20.71882118446899	27707
6997f243b7254aabba9ee2a686d3089464c29695	risikowahrnehmung, beurteilung des umgangs der behörden und beurteilung der unternehmerischen verantwortung in bezug auf drei umweltsituationen		In dieser Arbeit wurde einerseits das Verhaltnis zwischen der Risikowahrnehmung und der Beurteilung des Umgangs mit Umweltrisiken seitens der entsprechenden Umweltbehorden und andererseits das Verhaltnis zwischen der Risikowahrnehmung und der Beurteilung des Unternehmenssektors in Bezug auf drei wesentliche Themen untersucht: die endgultige Entsorgung von festen Siedlungsabfallen, die Abwasserreinigung der Stadt Cordoba und das erst vor Kurzem erlassene Waldschutzgesetz der Provinz Cordoba (Argentinien). Es wurden 197 Personenbefragungen mithilfe von Stichproben aus reprasentativen Bevolkerungsgruppen bezuglich der personlichen Wahrnehmung dieser durchgefuhrt. Man kann hinsichtlich aller Themen eine statistisch signifikante Korrelation zwischen der Wahrnehmung des Risikos fur die Umwelt und der Beurteilung des Umgangs der Behorden damit, als auch der unternehmerischen Verantwortung betrachten. Das Verhaltnis zwischen diesen Variablen andert sich nach der Segmentation der Stichproben in zwei Gruppen nach dem Wissensstand aber unter Beibehaltung der statistischen Signifikanz. Diese Arbeit zeigt Tendenzen auf und stellt ein erstes lokales Modell zwischen den untersuchten Variablen auf, die eine Hilfe sein konnen fur eine effektive Mitteilung von Umweltrisiken.		Carla Allende;Sebastián Diez;Héctor Macaño;Javier Britch	2013		10.1007/978-3-642-35030-6_36	history;performance art	NLP	-105.43423087097833	34.155912114914535	27729
29a7eafd85eac2bf4f35558e76df590379dbdd6e	an analysis of data sets used to train and validate cost prediction systems	software engineering;computing;standardisation;data sets;public domain;exhaustive search;meta analysis	OBJECTIVE - to build up a picture of the nature and type of data sets being used to develop and evaluate different software project effort prediction systems. We believe this to be important since there is a growing body of published work that seeks to assess different prediction approaches.METHOD - we performed an exhaustive search from 1980 onwards from three software engineering journals for research papers that used project data sets to compare cost prediction systems.RESULTS - this identified a total of 50 papers that used, one or more times, a total of 71 unique project data sets. We observed that some of the better known and easily accessible data sets were used repeatedly making them potentially disproportionately influential. Such data sets also tend to be amongst the oldest with potential problems of obsolescence. We also note that only about 60% of all data sets are in the public domain. Finally, extracting relevant information from research papers has been time consuming due to different styles of presentation and levels of contextural information.CONCLUSIONS - first, the community needs to consider the quality and appropriateness of the data set being utilised; not all data sets are equal. Second, we need to assess the way results are presented in order to facilitate meta-analysis and whether a standard protocol would be appropriate.		Carolyn Mair;Martin J. Shepperd;Magne Jørgensen	2005	ACM SIGSOFT Software Engineering Notes	10.1145/1082983.1083166	computing;public domain;computer science;engineering;data science;software engineering;data mining;world wide web	SE	-73.96476544858561	25.187689197244797	27758
183ec3147b5994e27e30b9720f1936f68ff492bb	austausch von trackingdaten in schmalbandigen funknetzen		Die Lagekarte ist eine zentrale Komponente militärischer Führungsinformationssysteme zur Unterstützung der Einsatzplanung und -durchführung. In der Lagekarte werden militärische Elemente (Truppenteile, Grenzen, Sperrgebiete etc.) vor dem Hintergrund von Vektorund Raster-Layern georeferenziert dargestellt (vgl. Abb. 1). In der heterogenen IT-Landschaft der Bundeswehr kommen verschiedene GIS-Produkte und Technologien zur Erzeugung der Lagekarte zum Einsatz. Hintergrund-Layer werden bspw. OGC-konform (per WFS, WMS oder WCS) bereitgestellt (vgl. KRÄMER 2009). Die in der Lagekarte dargestellten operationellen Daten stammen hingegen von den an einer militärischen Operation (z. B. Durchführung einer Patrouille) beteiligten Einheiten. Besonders wichtige operationelle Daten sind dabei GPS-Tracking-Informationen. Jede Einheit verfügt über einen Tracking-Service, der mittels eines angebundenen GPS-Trackers die eigene Position ermittelt und standardisiert (z. B. nach NATO Friendly Force Information Standard, NFFI) an die anderen beteiligten Einheiten und Gefechtsstände übermittelt. Beim Empfänger werden diese dann in Form von Symbolen (taktischen Zeichen) in der Lagekarte angezeigt.	eine and zwei;gps tracking unit;geographic information system;global positioning system;vhf omnidirectional range;web coverage service	Norman Jansen;Daniel Krämer;Marc Spielmann	2015	AGIT Journal	10.14627/537557034		DB	-106.57364033794093	33.30554120266347	27790
d3f0efa7ec213746e328e45aaa7c5310b74085db	die implementierung der eser-i-architektur im maschinenbefehlsniveau auf anlagen der klein- und mikrorechentechnik unter besonderer berücksichtigung der portabilität			die (integrated circuit)	Wolfgang Meissner	1987				NLP	-101.7184091228174	26.941606994891593	27796
12681d0ecefc990a7587af39b1251d87d92194c0	cebon: collaborative estimation based on negotiation	groupware;education collaborative software estimation groupware system collaborative work;collaborative work;estimation method;collaborative software estimation;software engineering groupware;software engineering;software estimations collaborative estimation software engineering;software estimations;collaborative estimation;collaboration collaborative software collaborative work computer science application software wideband programming proposals software engineering computer science education;groupware system	The software engineering community has been trying to find a way to get fast and accurate software estimations for many years. Although many methods have been proposed, they are not designed for novice persons. This paper proposes a collaborative estimation method based on negotiation. The method is applicable to small/medium-size projects (3-6 months) and it can be used by novice developers. The article also describes a software application supporting the process. The estimation method and the tool where evaluated in an academic scenario. The obtained results show this kind of tool is suitable for novice developers; however, an in-depth study must be made to determine the real effectiveness of the application.	newton's method;software engineering	Fabian Poblete;José A. Pino;Sergio F. Ochoa	2008	2008 12th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2008.4537048	personal software process;long-term support;verification and validation;software engineering process group;software sizing;human–computer interaction;computer science;package development process;social software engineering;component-based software engineering;software development;software engineering;software construction;software walkthrough;software analytics;resource-oriented architecture;software deployment;software requirements;collaborative software;software metric;software system;software peer review	SE	-67.12829964565483	26.06668086486406	27869
2e26dc8c47222ffde6145f915fa96ba3ba9aac32	zur bedeutung des nutzungskontextes im dokumentenmanagement: empirische befunde und technische lösungsansätze		Eine defizitäre Dokumentenverwaltung führt häufig zu schwerwiegenden Informationsverlusten. Die Erschließung und Klassifikation der Dokumente ist ein zentraler Ansatz, um sie recherchierbar und zugreifbar zu machen. Untersucht wurde, wie Dokumente in technischen Vorgängen dokumentiert und verwaltet wurden. Dabei zeigte sich, dass die Nutzungskontexte der Dokumente eine wichtige Bedeutung für den Dokumentenzugriff haben. Auf dieser Untersuchung aufbauend wird ein Konzept dargestellt, in dem die Nutzungskontexte effizient erfasst werden können. Die Kontexte ermöglichen die Suche nach Dokumenten anhand ursprünglicher Arbeitszusammenhänge. Beschrieben werden die entwickelten Tools, mit denen die Nutzungskontexte zu sichern und zu recherchieren sind. Erste Erfahrungen mit dem Einsatz dieser Tools schließen den Beitrag ab.	eine and zwei;intentionally blank page;internet explorer;sie (file format);unified model	Joachim Hinrichs;Jürgen Friedrich;Volker Wulf	2003			history;performance art	Logic	-105.18057321308649	34.59574887628811	27880
3b537ca6fa205cd52280215e265fccc7f7c76214	towards the evaluation of oss trustworthiness: lessons learned from the observation of relevant oss projects	oss adoption;lessons learned;oss quality;oss trustworthiness;open source software	To facilitate the adoption of open-source software (OSS) in industry, it is important to provide potential users (i.e., those who could decide to adopt OSS) with the means for evaluating the trustworthiness of OS products. This paper presents part of the work done in the QualiPSo project for this purpose. A set of factors that are believed to affect the perception of trustworthiness are introduced. In order to test the feasibility of deriving a correct, complete and reliable evaluation of trustworthiness on the basis of these factors, a set of well-known OSS projects have been chosen. Then, the possibility to assess the proposed factors on each project was verified: not all the factors appear to be observable or measurable. The paper reports what information is available to support the evaluation and what is not. This knowledge is considered to be useful to users, who are warned that there are still dark areas in the characterization of OSS products, and to developers, who should provide more data and characteristics on their products in order to support their adoption.	observable;open sound system;open-source software;operating system;trust (emotion)	Davide Taibi;Vieri Del Bianco;Davide Dalle Carbonare;Luigi Lavazza;Sandro Morasca	2008		10.1007/978-0-387-09684-1_37	systems engineering	SE	-73.01456423786645	20.813568363050308	27893
ed53f8d00e609c74c305e58e07903353d090bdce	integración de un sistema de información geográfica para algoritmos de particionamiento		Resumen. Para problemas de Particionamiento Geográfico (PG), se buscan agrupaciones de objetos de acuerdo a las condiciones geográficas. Generalmente, las respuestas del particionamiento geográfico en otros trabajos han sido mostradas textualmente o en un grafo, sin embargo, para problemas donde datos geográficos son los que se agrupan, representar gráficamente las particiones resultantes es un proceso complicado pero necesario. Esto implica que la agrupación use recursos adecuados para este propósito como geometría computacional o herramientas de interfaz con un Sistema de Información Geográfica (SIG). En este trabajo nos ocupamos de presentar una breve revisión del particionamiento geográfico y el proceso e implementación que hace posible observar resultados de opciones de particionamiento en mapas. Para este propósito se diseñó un conjunto de módulos que se comunican con un SIG. Este proceso suele iniciarse con la selección de datos que continua con la escogencia de un algoritmo de particionamiento geográfico en distintas categorías (compacto, homogéneo para variables poblacionales, P-mediana, multiobjetivo, Relajación Lagrangeana, homogéneo en el número de objetos, etc.). El resultado del particionamiento genera archivos de salida, sin embargo, el sistema acepta un documento de texto compuesto de una lista con los objetos gráficos y la relación al grupo que pertenecen. El procedimiento final está constituido de una interfaz con un SIG con el fin de distinguirlos resultados de las diferentes agrupaciones en mapas. A este sistema le hemos llamado Sistema de Interfaz Gráfico para Particionamiento (SIGP).	genera;han unification;las vegas algorithm;linear algebra;naruto shippuden: clash of ninja revolution 3;unique name assumption;breve	María Beatríz Bernábe Loranca;Rogelio González Velázquez	2014	Research in Computing Science		history;performance art	ML	-106.92174336316565	17.404674991861867	27896
cb414809ed6db6b19cb6c7fab5eb295d565474d6	supporting dss acceptability through a user-centered design methodology: experiences in emergency management	user centered design;emergency management	This paper presents a user-centered design methodology for Decision Support Systems (DSSs), which is specifically built to face the socio-technical gap that often impedes DSS acceptability by end users in real work environments. The methodology has been experimented in two case studies in the field of healthrelated emergencies, namely earthquake and pandemic flu management. Methodology application and results are described with specific focus on the phases of requirement analysis and system evaluation.	decision support system;end-user development;payment card industry data security standard;prototype;requirements analysis;sociotechnical system;system lifecycle;user-centered design	Pietro Baroni;Daniela Fogli;Massimiliano Giacomin;Giovanni Guida;Loredana Parasiliti Provenza;Michele Rossi;Marko Bohanec;Martin Znidarsic	2010		10.3233/978-1-60750-577-8-87	user-centered design;simulation;computer science;knowledge management;emergency management	HCI	-70.36326526265644	4.567215308632079	27898
0a56f82fc6d2e96b5bf03ca1f8499cfb038e2c60	kommunikation und regulierung		Sie wollen eine Universität vernetzen. Genauer, die ca. 30 über eine Stadt verteilten Campi einer Universität – aber Sie dürfen keine „aktiven Komponenten“ auf öffentlichem Gelände installieren. Bei meiner Planung des FDDI-Netzes der Universität Heidelberg Ende der Achtziger bin ich mit dieser Vorschrift, Teil der damals gültigen TKO (Telekommunikationsordnung), erstmals in eine Regulierungsfalle geraten.	circa;eine and zwei;i/o controller hub;sie (file format)	Lothar Binding	2003			history;performance art	OS	-104.26470548280946	34.614645037991416	27933
627abc9fc5eb1163706b249d14b84d38e3161cc1	monitoring the software development process with process mining		Software projects typically need to be monitored in detail regarding when what was done in order to demonstrate adherence to methodologies, rules, regulations, guidelines or best practices. To this end, it is of utmost importance to obtain factual knowledge from empirical evidence about the actual software development process. A major problem in this context is the lack of a centralized control of by a central system. Although it is hard to obtain full knowledge of the overall software development process, several cues can be gathered by analyzing pieces of information that are stored by supporting IT systems (e.g., issue trackers and version control). This position paper presents research in progress for extracting process knowledge from the historical data of software artifacts. This work extends the applicability of process mining techniques to software processes.	software development process	Saimir Bala;Jan Mendling	2018		10.1007/978-3-319-94214-8_34	software development process;systems engineering;position paper;software;best practice;bittorrent tracker;empirical evidence;information technology;engineering;process mining	SE	-68.44384173154374	21.785959150210587	27944
63bd9ac3db35b3c1da151b4dd167302dd06f11cb	begründungsverwaltung, beiträge zu einem workshop über reason maintenance, berlin, 9. oktober 1986, proceedings			reason maintenance		1988		10.1007/978-3-642-73385-7		HPC	-93.65718010160454	25.414366600502213	27955
325de4261c068df8742da13d92de4ce84a5da715	sehen und verstehen: der beitrag bildlicher information zur robusten sprachverarbeitung		Allgemeiner Überblick Ziel der Forschungsarbeiten im Arbeitsbereich NatS ist der Entwurf und die prototypische Realisierung komplexer sprachverarbeitender Systeme von der Analyse des Signals bis hin zur kommunikativen Bewertung. Vor dem Hintergrund unterschiedlicher Anwendungsbeispiele werden Voraussetzungen und	vhf omnidirectional range	Wolfgang Menzel	1998		10.1007/978-3-642-72283-7_16	psychoanalysis;verstehen;philosophy	OS	-103.78295920220326	29.09254012891901	27964
fdcd85406eed4988f0b6e25af71cd5895adbf5bf	spezifikation von unsicherem wissen in einem erweiteren expertisemodell				K. Christoph Ranze;Heiner Stuckenschmidt	1999				Vision	-97.07458194506131	23.11696873647208	27979
041fcb5952f0e79abaf94728f4672e9ad020ab71	mvs i/o subsystems: configuration management and performance analysis	configuration management	It's coming again, the new collection that this site has. To complete your curiosity, we offer the favorite mvs i o subsystems configuration management and performance analysis book as the choice today. This is a book that will show you even new to old thing. Forget it; it will be right for you. Well, when you are really dying of mvs i o subsystems configuration management and performance analysis, just pick it. You know, this book is always making the fans to be dizzy if not to find.	configuration management;input/output;profiling (computer programming)	H. Pat Artis	1992			reliability engineering;systems engineering;engineering;management science	OS	-64.28103848513385	24.92501960373063	27982
5bd0f4ca1c246fc502f477783186f7a92571f93e	der imsi-catcher		Seit 1997 geistert der „IMSI-Catcher“ durch die Medien. Damals veröffentlichte die DuD eine erste Beschreibung der technischen Funktionsweise des Geräts. Mit der Verabschiedung des Terrorismusbekämpfungsgesetzes geriet der IMSI-Catcher erneut in die Schlagzeilen. Als Beitrag zur Versachlichung der Diskussion werden im Folgenden die technischen Möglichkeiten und Gefahren des Geräts zusammenfassend dargestellt.	eine and zwei;imsi-catcher;triple des	Dirk Fox	2002	Datenschutz und Datensicherheit		computer security;internet privacy;imsi-catcher;computer science	Crypto	-103.67343983066702	36.53436892278982	28026
92c014ea325fb9794d008382c954f526ba281060	a knowledge based component/service repository to enhance analysts' domain knowledge for requirements analysis	design research;component based development;domain knowledge;requirements analysis	Knowledge of the business domain (e.g., insurance claim, human resources) is crucial to analysts’ ability to conduct good requirements analysis (RA). However, current practices afford little assistance to analysts in acquiring domain knowledge. We argue that traditional reuse repositories could be augmented by adding rich faceted information on component/services and artifacts such as businessprocess templates to help analysts acquire domain knowledge during RA. In this paper, we present the design of a Knowledge Based Component Repository (KBCR) for facilitating RA. Then, we report on the design and development of a KBCR prototype. We illustrate its application in a system that is populated with components and process templates for the auto insurance claim domain. An empirical study was conducted to assess its effectiveness in improving RA. Results showed that KBCR enhanced analysts’ business domain knowledge and helped them better prepare for RA. Our key research contribution is to offer analysts a rich repository (i.e., KBCR) containing domain knowledge that they could utilize to acquire domain knowledge that is crucial for carrying out RA. While repositories of reusable components have been employed for some time, no one has used such repositories to help analysts acquire domain knowledge in order improve the RA of the system. 2012 Elsevier B.V. All rights reserved.	business domain;faceted classification;population;prototype;requirement;requirements analysis;risk assessment;software repository;traffic collision avoidance system	Padmal Vitharana;Hemant K. Jain;Fatemeh Zahedi	2012	Information & Management	10.1016/j.im.2011.12.004	requirements analysis;design research;computer science;systems engineering;engineering;knowledge management;artificial intelligence;component-based software engineering;domain engineering;data mining;domain knowledge	HCI	-66.38783473861268	14.609560714491652	28045
863a63d2ab528eda3bc25730085df6ac6c1fa57f	next generation critical infrastructures: the push and pull to real-time	reliability;technological innovation;real time;public utilities;modems large scale systems crisis management transportation terrorism power system faults power system protection roads rails petroleum;public utilities critical infrastructures reliable services real time management organizational network;command and control;next generation;critical infrastructure;reliability public utilities real time systems;water transport;real time systems	Critical services such as electricity, water, transportation and telecommunication increasingly present us with a paradoxical situation. Society demands ever higher reliability of these services as we grow more dependent on them, while at the same time the conventional organizational means with which to ensure that high reliability are being dismantled. Deregulation, unbundling, technological innovation, new environmental requirements - all of these developments have made the provision of highly reliable services through critical infrastructures more and more the product of networks of organizations, rather than individual organizations. A key question for next generation infrastructures is therefore: how can networks of organizations, many with competing goals and interests, provide highly reliable services in the absence of conventional forms of command and control and in the presence of rapidly changing circumstances, technologies and demand? This work reports on extensive field research that suggests the answer is: critical infrastructures increasingly rely on real-time management to maintain reliability in the face of complexity and change.	next-generation network;real-time transcription	Mark de Bruijne	2004		10.1109/ICSMC.2004.1401266	command and control;computer science;critical infrastructure;reliability;computer security	Robotics	-66.16133052173694	9.460370312625031	28068
a1dade58c41ad0f65bbad22ec2955594b6a08c43	complexity is in the brain of the beholder: a psychological perspective on software engineering's ultimate challenge	reverse engineering	Complexity of software has been largely studied as a property of the code. We argue instead that complexity is a psychological phenomenon and should be studied from this perspective. The psychological literature however is structured in a way making of little practical usefulness. We propose a model based on isolated psychological facts connected by intuitive reasoning to fight complexity in a practical way. In this model, complexity corresponds to occurrences of cognitive overload in the working memory (WM), the bottleneck of cognition. Reducing complexity can be achieved by relieving the WM of some load by explicitly representing the internal mental constructs using external media such as software tools. We present a case study in which we used this model to produce a tool to reduce the complexity in program comprehension for large software systems. The tool was used in an industrial setting. We present here the mental constructs targeted and the details of the tool.	cognition;complexity;program comprehension;software engineering;software system	Iyad Zayour;Imad Moukadem;Issam A. R. Moghrabi	2013	JSW		computer science;artificial intelligence;operating system;machine learning;computer security;algorithm;programming complexity;reverse engineering	SE	-64.82908649115824	38.343659523191924	28093
d88015bf60447ac968c6fe5d5d9c926458e89331	der einsatz künstlicher neuronaler netze in regelungstechnischen anwendungen				Peter Firsching	1995				Vision	-100.47994652263232	26.54399779324569	28123
50301951a9bb9c2c4d1a7a6eb46dde044a8959fa	integrierte visualisierung kardialer mr-daten zur beurteilung von funktion, perfusion und vitalität des myokards		Zusammenfassung. Wir präsentieren die integrierte Visualisierung von linksventrikulären Funktionsparametern, First-Pass (FP) Perfusionsund Late Enhancement (LE) Daten für die Diagnostik der Koronaren Herzkrankheit (KHK). Die Visualisierung basiert auf einem 3dModell des linken Ventrikels und einfachen geometrischen Primitiven (Glyphen), deren Farbe und Größe in Abhängigkeit von den Datenwerten variieren. Die kombinierte Darstellung von Funktionsparametern und LE-Daten kann die Abgrenzung von temporär inaktivem, aber vitalem Myokard und Narbengewebe unterstützen. Eine Integration von FP-Perfusions-Daten ermöglicht zudem die Differenzierung von hibernating (chronisch minderdurchblutet) und stunned (verzögerte Erholung) Myokard.	eine and zwei	Lydia Paasche;Steffen Oeltze-Jafra;Frank Grothues;Anja Hennemuth;Caroline Kühnel;Bernhard Preim	2007		10.1007/978-3-540-71091-2_43	perfusion;internal medicine;cardiology;medicine	Logic	-106.96341695572522	29.62972031189522	28156
04092ebf0b450d753bc28d6d71a2841efbcaedb5	building a three dimensional work breakdown structure	software tool;project manager;software systems;functional programming;three dimensional;functional architecture;software architecture;work breakdown structure;functional model;interactive information system	With the proliferation of project management software tools, the growth of more and more complex software projects and the dissatisfaction and limitation of the capabilities of the current tools, more companies are looking at the possibility of developing their own project management tools. This paper presents the basic principles and considerations for developing the functional specifications for developing a three dimensional Work Breakdown Structure.  A metric for measuring the progress is presented. The metric states that, tracking the progress of the development of a software system is a function of the relative value of the outputs to be undertaken for each node of the software architecture, the phase in which the work will be undertaken and the tasks to complete the work.  A description of some of the basic considerations for generating a WBS, PERT, Gantt, and Manpower Distribution Graph are presented.	comparison of project management software;functional specification;gantt chart;program evaluation and review technique;software architecture;software system;value (ethics);work breakdown structure	Barry Katz;Naftali Lerman	1985	DATA BASE	10.1145/2147774.2147777	reference architecture;three-dimensional space;software architecture;personal software process;verification and validation;software sizing;work breakdown structure;software project management;computer science;systems engineering;engineering;function model;software framework;component-based software engineering;software development;software design description;software engineering;software construction;functionalism;database;software architecture description;functional programming;resource-oriented architecture;management;software deployment;software development process;software metric;software system;computer engineering;software peer review	SE	-63.396765347471145	25.91999733113724	28206
c746de12587a15836b3432292d901499c93a0c06	unternehmung ohne grenzen: konzepte, strategien und gestaltungsempfehlungen für das strategische management				Thorsten Blecker	1999				EDA	-100.37668024706643	27.160776520689257	28423
4b8ed4bde185f01f7977c75310492eb615a9053b	a landmark-based scalable semantic resource discovery scheme	estensibilidad;simulation ordinateur;evaluation performance;tecnologia electronica telecomunicaciones;resource discovery;performance evaluation;red semantica;hierarchized structure;equilibrio de carga;evaluacion prestacion;reseau ordinateur;conceptual analysis;semantic network;vector space;equilibrage charge;semantics;structure hierarchisee;semantica;semantique;analisis conceptual;computer network;informatique omnipresente;large scale;reseau semantique;load balancing;red informatica;ubiquitous computing;extensibilite;scalability;simulacion computadora;espace vectoriel;analyse conceptuelle;analisis semantico;tecnologias;escala grande;grupo a;analyse semantique;semantic resource discovery;espacio vectorial;article;computer simulation;ontology;estructura jerarquizada;semantic analysis;echelle grande	† The authors are with the School of Engineering, Information and Communications University, Republic of Korea. †† The author is with the Department of Computer Engineering, Sungkyunkawn University, Republic of Korea * This research is supported by the ubiquitous Computing and Network (UCN) Project, the Ministry of Information and Communication (MIC) 21st Century Frontier R&D Program in Korea. a) E-mail: kang@icu.ac.kr A Landmark-based Scalable Semantic Resource Discovery Scheme	centralized computing;computer engineering;dimensionality reduction;distributed hash table;domain-specific language;ontology (information science);scalability;semantic matching;simulation;ubiquitous computing	Saehoon Kang;Younghee Lee;Dongman Lee;Hee Yong Youn	2007	IEICE Transactions	10.1093/ietisy/e90-d.6.986	computer simulation;semantic computing;scalability;vector space;semantic grid;computer science;artificial intelligence;load balancing;ontology;data mining;semantics;semantic network;world wide web;ubiquitous computing	DB	-108.61777631179729	9.59455931572387	28493
e9a97767cdc963a42d1b607102773b4880f81a8c	measuring software methodology usage: challenges of conceptualization and operationalization	software metrics;conceptualization;software development management software metrics;measurement;empirical software engineering;software engineering;methodology usage;regression analysis software methodology usage measure conceptualization operationalization empirical software engineering technology acceptance;software measurement software engineering software performance programming laboratories joining processes regression analysis productivity software tools information systems;technology acceptance;development methodology;organizational performance;operationalization;software development management	Most software engineering research implicitly assumes that development methodologies are useful and that there is a direct relationship between software methodologies and their effects on organizational performance. However, a methodology cannot have an impact if it is not used. The purpose of this paper is, thus, to raise a number of challenges related to the conceptualization and Operationalization of methodology usage and to report on a study that compared subjective and objective operationalizations of usage. Results of regression analyses show that these operationalizations do not appear to be strongly related. While self-reported usage is related to self-reported measures of the independent variables of methodology acceptance in the study, the objective and computer-recorded measures show different and distinctly weaker links. There are several explanations to these seemingly contradictory results. Most importantly, the results of this study suggest a need for reconceptualization and better validation of methodology usage constructs in future, empirical software engineering research.	conceptualization (information science);experimental software engineering;software development process	Tore Dybå;Nils Brede Moe;Erik Arisholm	2005	2005 International Symposium on Empirical Software Engineering, 2005.	10.1109/ISESE.2005.1541852	reliability engineering;personal software process;verification and validation;software engineering process group;software sizing;computer science;systems engineering;knowledge management;social software engineering;software development;software construction;software walkthrough;empirical process;software analytics;software deployment;software development process;software quality;software metric;software peer review	SE	-66.25314174130753	30.0310731976521	28497
3fb68b27c229ac0fb60b43c2036b544941ace8cf	benutzerzentriertes design der nicht-visuellen navigation in gebäuden	navigation			Denise Prescher;Martin Spindler;Michael Weber;Gerhard Weber	2013			computer science	HCI	-95.54209886971654	22.106198375904476	28512
6c7be75ec9337587f299b905da3a5ff50759a32a	using orientor theory for coherent decision making for application landscape design		More than 30 years have past since the first enterprise architecture (EA) management framework has been published. While the field has reached a certain maturity in science and practice, a paradigm shift is just beginning. The emerging trend to regard an enterprise as a complex adaptive system might allow to redefine and achieve the holistic nature of EA management approaches. Thereby, the focus on static aspects of the architecture might be extended by taking behavioral aspects into account. In this paper, we argue (1) that currently available EA management approaches fall short in achieving the desired holism, i.e. viewing the system (application landscape) as a whole, (2) apply orientor theory to support decision making by deriving coordinated goals and principles for application landscape design and (3) show how a system-ofsystems approach of applied orientor theory could look like. We conclude the paper by sketching out an appropriate research agenda.	capability maturity model;causal filter;coherent;complex adaptive system;database;diagram;enterprise architecture;holism;microsoft outlook for mac;programming paradigm;system of systems	Alexander W. Schneider;Florian Matthes	2014			management science;architecture;enterprise architecture;landscape design;paradigm shift;complex adaptive system;holism;approaches of management;mathematics	DB	-67.3486244474762	9.694525189678169	28546
60e2c75369097208693f02f8de248edc05d6730d	a reengineering framework for evaluating a financial imaging system	evaluation performance;performance evaluation;image processing;securite;evaluacion prestacion;charpente;procesamiento imagen;conception;traitement image;imaging system;reconnaissance caractere;imaging;safety;resultat financier;diseno;formation image;design;formacion imagen;seguridad;character recognition;armadura;reconocimiento caracter;framework;financial result	T HIS article presents a framework for comparing and evaluating efforts in reengineering, or business process redesign. The framework is applied to the study of the reengineering of the securities processing function at the brokerage and financial services firm Merrill Lynch, comparing the firm’s old and new processes. The new process features image processing, character recognition, and extensive redesign. Reengineering, one of the latest trends in the information systems field, is defined by Hammer and Champy [4] as “the fundamental	business process;code refactoring;image processing;information system;optical character recognition	Henry C. Lucas;Donald J. Berndt;Greg Truman	1996	Commun. ACM	10.1145/229459.229470	design;simulation;image processing;computer science;programming language	Graphics	-68.41948240991987	6.632336094694058	28551
da6c64b4fb0ad30031ff7afc78367558df4b033c	modèles de traduction évolutifs. (evolutive translation models)				Frédéric Blain	2013				NLP	-104.76666375051245	13.745465234376383	28618
d6fa04b91edf0dd266e40a31d18f61029a5760f2	jfplc'94, iiièmes journées francophones de programmation logique et programmation par contraintes, 1994, bordeaux, france					1994				NLP	-105.1119913902893	16.22264681207684	28650
dd2c2b018eae253584981ae7766c801bdc9ed76d	interview zu rekrutierungsmaßnahmen durch das angebot von internet-spielen.				Wolfgang König;Carl-Günther Schleu	2000	Wirtschaftsinformatik	10.1007/BF03250709	the internet;knowledge management;world wide web;computer science	Vision	-95.44065342760788	27.778962144288588	28657
820788270a226113a49e1f76419bd306109673b7	"""interview with clemens daeschle on """"management of global software development at sap ag"""""""			software development	Alexander Maedche	2012	Business & Information Systems Engineering	10.1007/s12599-012-0209-5	computer science;operations management;software engineering;database	SE	-64.74665875105254	22.075058886460518	28661
8277c4496a6f1659245454365e39bdc240b652c3	a multiple perspectives evaluation of the factors affecting software development productivity in an outsourced it project	software development	The paper provides a model for examining the perceptions of the users and the outsourcing providers about what influences software development productivity. It is illustrated through a case study. the model is using a multicriteria decision analysis approach - the Analytic Hierarchy Process. This type of analysis of perceptions of the different stakeholders in an outsourcing relationship can be applied to other organisational environments to help improve the management of outsourced IT activities.	agile software development	O. Petkova;J. Dewald Roode;D. Petkov	2000	South African Computer Journal		management science;decision analysis;knowledge management;analytic hierarchy process;software development;computer science;outsourcing	SE	-78.15688349710646	8.793607985507508	28676
49aa9927507aabf486ead8df93df836259c0dace	organisational support: an empirical investigation into the effect of organisational support on the success of emerging market sourcing	model design;global sourcing;project management;emerging market;automotive industry;partial least square;project manager;innovation management;success factor;emerging market sourcing;organisational support;competitive advantage	“Global Sourcing” has received a great deal of attention recently, as companies strive for new sources of competitive advantage in the face of increasing global competition. Alongside the undisputed role that supplier management plays in assuring sourcing success, organisational aspects can also be shown to play an important part in the field of global sourcing. This paper is a first systematic attempt to identify the factors that can successfully promote the execution of sourcing projects in “emerging markets”. The success factors are derived from the literature of related areas of research. The analysis adopts an internal perspective, although external factors residing in the relationship with the supplier and the external environment are indirectly taken into account by incorporating research on project and innovation management—both very flexible approaches for highly uncertain environments. The findings allow the identification of clearly relevant success factors in sourcing from emerging markets and are integrated in a model designed to explain the impact of organisational support in this venture. The partial least squares method (PLS) is used to test the model on a set of 96 cases. The data originates from a survey of sourcing managers from Europe, mainly in the manufacturing and automotive industries.	citizen sourcing	Thomas Beckmann;Philipp Lindemann;Frank Straube	2009	Logistics Research	10.1007/s12159-009-0010-0	project management;economics;innovation management;automotive industry;marketing;operations management;business;strategic sourcing;management;emerging markets;competitive advantage;commerce	HCI	-78.66807836626717	4.544799940474343	28694
db7eec4811c0703956d5f7f0ee6974927cf68e34	rechtsprechung zum telekommunikationsrecht					2013	Computer und Recht	10.9785/ovs-cr-2013-437		Theory	-96.30780650840966	23.194317811908434	28712
5ee48db46984202b03c2b8f45705ff50e7261f05	ein beitrag zur lösung schwach strukturierter entscheidungssituationen in der ökonomie unter nutzung mathematischer, statistischer und kybernetischer methoden sowie der informatik				Friedrich Hartl	1989				NLP	-101.17397051740947	25.95612983843993	28724
324b8a7baa1fefb6312bf0419a7278387fda6850	digital forensic science: issues, methods, and challenges	cyber forensics;digital forensics;data recovery;cyber crime;incident response	Digital forensic science, or digital forensics, is the application of scientific tools and methods to identify, collect, and analyze digital (data) artifacts in support of legal proceedings. From a more technical perspective, it is the process of reconstructing the relevant sequence of events that have led to the currently observable state of a target IT system or (digital) artifacts. Over the last three decades, the importance of digital evidence has grown in lockstep with the fast societal adoption of information technology, which has resulted in the continuous accumulation of data at an exponential rate. Simultaneously, there has been a rapid growth in network connectivity and the complexity of IT systems, leading to more complex behavior that needs to be investigated. e goal of this book is to provide a systematic technical overview of digital forensic techniques, primarily from the point of view of computer science. is allows us to put the field in the broader perspective of a host of related areas and gain better insight into the computational challenges facing forensics, as well as draw inspiration for addressing them. is is needed as some of the challenges faced by digital forensics, such as cloud computing, require qualitatively different approaches; the sheer volume of data to be examined also requires new means of processing it.	artifact (software development);cloud computing;computation;computer science;lockstep (computing);observable;point of view (computer hardware company);time complexity;tree accumulation	Vassil Roussev	2016		10.2200/S00738ED1V01Y201610SPT019	simulation;computer science;data recovery;digital forensics;data mining;computer security;computer forensics	Graphics	-76.68125829995633	17.146018870907927	28808
f97736f7c2e1cde3c91daeaa5fcf3af999076df6	tiefes reinforcement-lernen auf basis visueller wahrnehmungen		Mit Hilfe des wertfunktionsbasierten Reinforcement Lernens (RL) konnten in letzter Zeit einige sehr beachtliche Erfolge beim Erlernen der Steuerung realer, dynamischer Systeme erzielt werden. Bestehende Ansätze sind aber immer noch auf die Lösung von Problemen mit sehr niedrigdimensionalen Zustandsräumen beschränkt. Diese Einschränkung verhindert bisher eine direkte Anwendung auf die von einer Kamera gewonnenen visuellen Wahrnehmungen und erfordert den Einsatz klassischer Bildverarbeitung zur Konstruktion eines geeigneten, niedrigdimensionalen Zustandsraums.	eine and zwei;reinforcement learning;système universitaire de documentation	Sascha Lange	2010				ML	-106.34093893851146	31.989450732992182	28828
3c65b43a951043751f6bd415c2a2cfbd5f213804	entscheidungsunterstützung für die planung regionaler projekte unter berücksichtigung nachhaltiger entwicklung		1 Motivation Der gesellschaftliche und politische Druck zu einer nachhaltigen Handlungsweise in vielen Bereichen ist in den vergangenen Jahren stark gestiegen. Dies führt unter anderem dazu, dass eine Vielzahl an einzelnen Software­Tools entwickelt worden, die Anwender bei diesem Problem unterstützend sollen.	eine and zwei	Nils Giesen;Tabassom Hashemi Farzad;Jorge Marx Gómez	2009			engineering	NLP	-103.81951691797242	32.99330477195332	28929
e5e466a1f6ab809bbf3d756c484ebacb5c21b8ee	buffer sizing methods to compare critical chain project management with critical path	project management;buffer management;critical path method;critical chain method;theory of constraints	Critical Chain Project Management (CCPM) provided a tangible progress to the Project Management Body of Knowledge. The critical chain project management (CCPM) differs from the traditional Critical Path Method (CPM) which includes never changing resource dependencies. CCPM improves the project plan by aggregating uncertainty into buffers at the end of activity paths. In this research, one hundred twenty random projects were generated and analyzed using Microsoft Project software according to the traditional CPM and the CCPM once using the sum of squares (SSQ) method and another using the cut & past (C&PM) method. CCPM-SSQ method revealed an average savings of 13% and 43% in duration and cost, with a standard deviation of 21 and 11 for duration and cost respectively. While the CCPM-C&PM method revealed an average overestimation of about 2% in duration and 43% savings in cost, with a standard deviation of 25 and 11 for duration and cost respectively. KeywoRdS Buffer Management, Critical Chain Method, Critical Path Method, Project Management, Theory of Constraints	critical path method	Mohammed Shurrab;Ghaleb Abbasi	2016	IJITPM	10.4018/IJITPM.2016070105	theory of constraints;project management;simulation;economics;operations management;critical path method;management	SE	-84.8361809108503	9.346224288190266	28930
f46e22cf0787d4d56231a75ab9a0fd3bcaa0c85d	sustainable process management - status quo and perspectives	communication system;process management;process design	  Sustainability in the context of information and communication systems is often discussed using the technical term “Green  IT”. However, Green IT-concepts often just address the infrastructure level of an information and communication system architecture.  Acknowledging the potentially huge contribution to sustainability improvements that lies in the adequate design of processes,  we discuss concepts to evaluate and compare different process designs with respect to sustainability considerations.    		Dennis Kundisch;Philipp Herrmann;Christian Meier	2010		10.1007/978-3-642-12494-5_9	systems engineering;knowledge management;environmental resource management;process management;management process	HCI	-70.6379579661069	7.407470377457821	29065
4bd8a5444c6df671b97012611b2a374011f1fbce	integrierte aktivitäten- und datenverwaltung zur systemgestützten kontroll- und datenflußsteuerung				Berthold Reinwald;Hartmut Wedekind	1992	Inform., Forsch. Entwickl.		computer engineering;computer-integrated manufacturing;data flow diagram;group method of data handling;telecommunications;computer science	NLP	-99.78023667479236	31.17830527479226	29079
4959d7c02313581fd6c23c082cca0c237e36b722	eye-tracking in usability-tests - die häufigsten fehler und wie man sie vermeiden kann	methoden;quantitativ;eye tracking;usability test;qualitativ;talk		eye tracking;internet explorer;sie (file format);usability	Kai Robin Grzyb;Alexander Rösler;Jana Rockstroh;Gesine Quint;Torsten Bartel	2016		10.18420/muc2016-up-0149	visual arts;art history;engineering	NLP	-97.61546925224604	27.44342981221046	29095
9e02ad1ef01fe7cff4790e6465221dadba149d3e	financial innovation: credit default hybrid model for sme lending		We propose an ANN/logistic credit risk hybrid model for SME lending.We find that the hybrid model is more accurate than either of the separate ones.Our study is one of few that sheds light on the hybrid model.Our study is one of few which focuses on credit risk models for SMEs.The hybrid model can help the bank decrease the errors in credit risk evaluations. Credit risk evaluation is an integral part of any lending process, and even more so for financial institutions involved in lending to SMEs. The importance of credit scoring has increased recently because of the financial crisis and increased capital requirements for banks. There are, however, only few studies that develop credit coring models for SME lending. The objective of this study is to introduce a novel, more accurate credit risk estimation approach for SMEs business lending. Based on traditional statistical methods and recent artificial intelligence (AI) techniques, we proposed a hybrid model which combines the logistic regression approach and artificial neural networks (ANN). In order to test the effectiveness and feasibility of the proposed hybrid model, we use the data of Finnish SMEs from the fiscal years 2004 to 2012. Our results suggest that the proposed ANN/logistic hybrid model is more accurate than either of the initial models ANN or logistic regression. This improvement in the accuracy of the credit scoring model decreases evaluation errors and has thereby many potential practical implications. First of all, a more accurate credit scoring model can result in better performance of the whole SME loan portfolio. Second, it can also result in lower capital requirements from the banks perspective and lower interest rates from the individual firm's perspective. Combined, these effects will enhance the banks competitiveness in the market for SME loans.		Kang Li;Jyrki Niskanen;Mikko Kolehmainen;Mervi Niskanen	2016	Expert Syst. Appl.	10.1016/j.eswa.2016.05.029	actuarial science;credit valuation adjustment	ECom	-83.77335491929992	7.541321704288328	29115
0ce14b5110451b01cf89d6722d48bb7c1a81d330	the impact of outsourcing on it business alignment and it flexibility: a survey in the german banking industry	banking industry	The ability to outsource IT has been suggested as a major driver of IT productivity. At the same time, the literature on the business value of IT suggests that IT business alignment and IT flexibility are important drivers for the performance of IT. But what is, then, the impact of outsourcing on these key value drivers? In this paper, we empirically show that firms with internal IT exhibit significantly better IT business alignment and IT flexibility.	americas conference on information systems;attribute–value pair;customer relationship management;outsourcing	Daniel Beimborn;Jochen Franke;Heinz-Theo Wagner;Tim Weitzel	2006			process management;business;retail banking;commerce	HCI	-81.35573675158307	5.244064770854433	29116
6a9f7f65d9c782657f1a05713bdf74796b99d40a	a mining method to create knowledge map by analysing the data resource		The fundamental step in measuring the robustness of a system is the synthesis of the so-called Process Map. This is generally based on the user’s raw data material. Process Maps are of fundamental importance towards the understanding of the nature of a system in that they indicate which variables are causally related and which are particularly important. This paper represent the system Map or business structure map to understand business criteria studying the various aspects of the company. The business structure map or knowledge map or Process map are used to increase the growth of the company by giving some useful measures according to the business criteria. This paper also deals with the different company strategy to reduce the risk factors. Process Map is helpful for building such knowledge successfully. Making decisions from such map in a highly complex situation requires more knowledge and resources. Keywords—business structure, knowledge map, robustness resources, system map.	cognitive map;domain analysis;e-commerce payment system;fuzzy rule;knowledge management;map;risk factor (computing);simulation;static program analysis	Arti Gupta;N. T. Deotale	2014	CoRR	10.14445/22315381/IJETT-V9P282	knowledge management;data mining;management science	AI	-74.50625160926427	12.668505089594875	29142
483d6e77e68bc0e3f0fab021f9fc1773543b9dca	ein wissensbasiertes diagnosesystem in der halbleiterfertigung				Gabriele Schmiedel;Klaus Winkelmann	1989	KI			Crypto	-97.48446263037422	23.99940922058094	29144
cf5480827472af47881228eafeb779c37ea0dd7b	ein generisches datenmodell für learning analytics autoren		Bei der Wahl eines geeigneten Datenmodells für Learning Analytics sind folgende Fragen zu beantworten: welche Lernplattformen sollen unterstützt werden, welche Art von Analysen, wie viel (oder wenig) personenbezogene Daten sollen genutzt werden, welche Kontextinformationen, kann Plattformunabhängigkeit erreicht werden, können die Daten oder Analyseverfahren ausgetauscht werden? Und können Standards eingesetzt werden? Der vorgestellte Ansatz für ein Datenmodell kann nicht alle Fragen beantworten, bietet aber ein einfaches und klares Modell, welches für verschiedene Plattformen und Analyseanforderungen geeignet ist. Dies wird durch einen generischen Ansatz erreicht: Lernobjekte werden bzgl. ihrer Interaktionsform in drei Kategorien eingeteilt; konkrete Typen von Lernobjekten aus bestimmten Plattformen oder für bestimmte Analysen werden nicht im Datenmodell beschrieben, sondern erst für eine konkrete AnalyseAnwendung definiert. Das gleiche gilt für Attribute der Lernobjekte und für Attribute der Nutzer bzw. Lerner, welche bezüglich eines konkreten Lehrund Lernkontextes definiert werden.	eine and zwei;internet explorer;v-model	Albrecht Fortenbacher;Marcus Klüsener;Sebastian Schwarzrock	2014			data science;learning analytics;computer science	DB	-107.12218096763273	34.57984250537242	29147
66b7b4c35b23a171cafeefc4e4cc21bbc4968422	algorithmen der sprachverarbeitung zur entwicklung eines vollsynthetischen sprachausgabesystems				Gerhard Rigoll	1991				Crypto	-100.10463095758477	25.462902258249326	29155
4534b8cc1db58ac20d9db8fd8cc4cb522dd3f55b	enhancing systems integration by incorporating business continuity drivers	top down;integrable system;integration;business continuity;systems analysis;system integration;enterprise information system;integral operator;computer hardware;design methodology	Purpose – The purpose of this paper is to present a framework for developing an integrated operating environment (IOE) within an enterprise information system by incorporating business continuity drivers. These drivers enable a business to continue with its operations even if some sort of failure or disaster occurs. Design/methodology/approach – Development and implementation of the framework are based on holistic and top-down approach. An IOE on server’s side of contemporary business computing is investigated in depth. Findings – Key disconnection points are identified, where systems integration technologies can be used to integrate platforms, protocols, data and application formats, etc. Downtime points are also identified and explained. A thorough list of main business continuity drivers (continuous computing (CC) technologies) for enhancing business continuity is identified and presented. The framework can be utilized in developing an integrated server operating environment for enhancing business continuity. Originality/value – This paper presents a comprehensive framework including exhaustive handling of enabling drivers as well as disconnection points toward CC and business continuity.	align (company);business continuity;customer relationship management;database;downtime;erp;enterprise information system;high availability;holism;information management;linux;mainframe computer;microsoft windows;operating environment;reflections of signals on conducting lines;scm;scott continuity;server (computing);system integration;top-down and bottom-up design;unix	Nijaz Bajgoric;Young B. Moon	2009	Industrial Management and Data Systems	10.1108/02635570910926609	integrable system;systems analysis;design methods;computer science;systems engineering;engineering;knowledge management;artifact-centric business process model;operations management;top-down and bottom-up design;business rule;new business development;business process modeling;disaster recovery;business activity monitoring;enterprise information system;system integration;business architecture	DB	-69.37646811779132	4.1935776523939925	29175
40c2028415d8c71a506c7fd4b1005933602e861f	anforderungen des praktikers an den computergestützten arbeitsplatz des organisators-ergebnisse einer qualitativen marktuntersuchung	anforderungen des;den computergest	Der Organisator der 70er Jahre war ein „Strukturtechniker“. Er beschaftigte sich vorwiegend mit statischen Strukturen der Unternehmensorganisation. Im Zuge der verstarkten Einfuhrung der Datenverarbeitung gewann die DV-Organisation stark an Bedeutung: die anforderungsgerechte Gestaltung von Anwendungssoftware, ihre organisatorische Einfuhrung sowie die effiziente Gestaltung der DV im Unternehmen selbst traten in den Mittelpunkt der Aktivitaten. Derzeit ist ein weiterer Wandel zu beobachten. Mit dem Selbstverstandnis des „Organisationsentwicklers“ bemuht sich eine neue Generation von Organisatoren, die burokratischen Elemente ihrer Tatigkeit abzubauen und durch ausgepragte Berucksichtigung der Bedurfnisse der betroffenen Menschen Akzeptanz fur ihre Systemanderungen zu erhalten.		Horst Strunz	1989		10.1007/978-3-642-83990-0_13		Crypto	-104.64962126363768	33.90805964540011	29177
51549f236c14283668cc38a07de1ef607ac0715c	sicherheit in elektrischen netzen durch einen nationalen diskurs - initiative zur gemeinsamen entwicklung einer sicheren smart grid-referenzarchitektur		1. IKT und Energienetze als grundlegende Infrastruktur unserer modernen Gesellschaft Der Paradigmenwechsel zu intelligenter, hoch automatisierter und auch ökologisch zukunftssicherer Energiebewirtschaftung ist ein Trend, der vor allem auch im Zusammenhang mit der Liberalisierung der Energiewirtschaft eine hohe Marktdynamik mit sich bringt. Neue Anforderungen des Marktes verlangen neue Systemarchitekturen und Technologieinnovationen. Unsere zukünftige Energieversorgung wird wesentlich von smarten Infrastrukturen abhängen, die durch einen weitreichenden Einsatz von Informationsund Kommunikationstechnologien (IKT) entstehen. Durch eine intelligent gesteuerte verteilte Energieproduktion, vor allem von erneuerbarer Energie, und durch bedarfsgerechte Energieverteilung bis hin zu einem Energiemanagement zu Hause (smart home) bauen wir zukünftige Smart Grid-Infrastrukturen, welche einen grundlegenden Beitrag für das Energiemanagement unserer Gesellschaft darstellen.1 IKT und Energienetze verschmelzen somit zu einem untrennbaren Ganzen eines Cyber Physical Systems.2 Der Energietransport und die Energieverteilung werden somit in zunehmendem Maße von moderner Informationsund Kommunikationstechnologie abhängig. Die potentiellen Auswirkungen dieser Abhängigkeiten sind mittlerweile beträchtlich. Der Ausfall von Energienetzen kann enorme wirtschaftliche Schäden verursachen bzw. ganze Staaten massiv beeinträchtigen.3 IKT-Infrastrukturen müssen daher neben dem klassischen Stromnetz als die wesentliche kritische Infrastruktur unserer Gesellschaft eingestuft werden.	eine and zwei;gesellschaft für informatik;home automation;vhf omnidirectional range	Helmut Leopold	2014	Elektrotechnik und Informationstechnik	10.1007/s00502-014-0240-y		OS	-102.23576957537334	36.86227022692195	29218
727290e4f4e8d959424b00f09aabcf049d195a1f	die logische rekonstruktion eines gegenstandsbereiches: eine fallstudie	logische rekonstruktion eines gegenstandsbereiches;eine fallstudie	In dieser Arbeit wird die Rekonstruktion von Aspekten eines Gegenstandsbereichs des LILOG-Systems vorgestellt. Im Vordergrund steht hier die Rekonstruktion eines Teils des Weltwissens, das fur das Verstehens eines naturlichsprachlichen Textes notwendig ist. Diese Rekonstruktion umfast die in diesem Text auftretenden Referenzobjekte und deren zugehorige Sortenhierarchie. Als Sortenbeschreibungssprache wurde eine Variante der logikbasierte Beschreibungs- sprache S0RTLLILOG LILOG-Projektes genommen. Die Moglichkeiten und Schwierigkeiten einer solchen Rekonstruktion werden aufgezeigt und diskutiert.	eine and zwei	Kai von Luck;Ralf Meyer;Thomas Pirlein	1989		10.1007/978-3-642-74688-8_34		NLP	-105.30762911362044	32.82453727092348	29223
f0e8f81cbb0c9695811c2a42ab8a03f431f3b629	an efficient algorithm for solving a special class of lp's	efficient algorithm;algorithme;algorithm;algorritmo;programacion lineal;mathematical programming;linear programming;programmation lineaire;programmation mathematique;programacion matematica	We consider LP's of the form max {cx|l≤Ax≤b, L≤x≤U} where,l,b,L,U are nonnegative andA is a 0–1 matrix which looks like “Manhattan Skyline”, i.e. the support of each row is contained in the support of every subsequent row. AnO(nm+nlogn) algorithm is presented for solving the problem. Wir betrachten Lineare Programme der Form {maxcx|1≤Ax≤b,L≤x≤U} mit nichtnegativen Vektorenl,b,L,U und einer 0–1 MatrixA, die von “Manhattan Skyline” Form ist, d. h. der Träger jeder Zeile vonA ist im Träger jeder folgenden Zeile enthalten. Wir stellen einenO(nm+nlogn)-Algorithmus zur Lösung solcher Probleme vor und untersuchen seinen Anwendungsbereich.	algorithm;vhf omnidirectional range	Walter Kern	1986	Computing	10.1007/BF02252513	mathematical optimization;linear programming;calculus;mathematics;algorithm	AI	-97.27430015450079	35.965038252177166	29228
3c24cad8031528dfcdb66631752bfefe42a8022e	agents and peer-to-peer computing : 4th international workshop, ap2pc 2005, utrecht, the netherlands, july 25, 2005 : revised papers	peer to peer computing	Trust and Reputation.- Optimizing an Incentives' Mechanism for Truthful Feedback in Virtual Communities.- A New View on Normativeness in Distributed Reputation Systems.- A Trust Management Scheme in Structured P2P Systems.- Incentive-Compatibility in a Distributed Autonomous Currency System.- Handling Free Riders in Peer-to-Peer Systems.- P2P Infrastructure.- Highly Available DHTs: Keeping Data Consistency After Updates.- Caching Indices for Efficient Lookup in Structured Overlay Networks.- Semantic Infrastructure.- A Semantic Marketplace of Negotiating Agents.- Semantic Web Service Composition Through a P2P-Based Multi-agent Environment.- Community and Mobile Applications.- A Low-Latency Peer-to-Peer Approach for Massively Multiplayer Games.- An Agent-Based Collaborative Framework for Mobile P2P Applications.- ACP2P: Agent-Community-Based Peer-to-Peer Information Retrieval - An Evaluation.- A Peer Ubiquitous Multi-agent Framework for Providing Nomadic Users with Adapted Information.		Ap Pc;Zoran Despotovic;Sam Joseph;Claudio Sartori	2006		10.1007/11925941	computer science;database;distributed computing;world wide web	HPC	-89.02914588405393	29.07950985504213	29231
fb6ffa30cfa5b440a31309d296920d791bbca107	a new adaptive lattice filter for the arma modeling of vector signals	spectre puissance;metodo cuadrado menor;traitement signal;methode moindre carre;least squares method;algoritmo adaptativo;recursive adaptive algorithm;algoritmo recursivo;simulation;arma model;simulacion;power spectrum;modelo arma;espectro potencia;convergence speed;adaptive algorithm;adaptive filters;algorithme recursif;algorithme adaptatif;signal processing;filtro adaptable;velocidad convergencia;modele arma;recursive algorithm;filtre adaptatif;procesamiento senal;vitesse convergence;least squares lattice;adaptive filter	Recently, a new efficient algorithm for the timeand order-recursive inversion of a special class of matrices, arising in the context of least-squares estimation problems, has been introduced, whose analysis part is slightly modified in this paper leading to a more symmetrical structure. Numerical results, showing the extremely fast convergence and excellent tracking capability of this algorithm, are presented and modified recursions, reducing the number of required square-root operations by the factor three, are introduced. Furthermore, a new structure for the so-called synthesis filter, which is derived from the analysis part of the algorithm considered, is proposed being more appropriate to the problem than the one given previously. Finally, the extension of the algorithm to the multichannel case is discussed. Zusammenfassung. K/irzlich wurde ein neuer effizienter Algorithmus fiir die zeitund ordnungsrekursive Inversion einer speziellen Klasse von Matrizen, wie sie im Zusammenhang mit der Methode der kleinsten Quadrate bei Schhtzproblemen auftreten, vorgestellt, dessen Analyseteil in dieser Arbeit leicht modifiziert wird, was zu einer symmetrischeren Struktur fiihrt. Numerische Ergebnisse, die die schnelle Konvergenz und die exzellenten Tracking-Eigenschaften dieses Algorithmus~zeigen, werden vorgestellt, und modifizierte Rekursionen, die die Anzahl der n6tigen Wurzeloperationen um den Faktor drei reduzieren, werden eingefiihrt. Oberdies wird eine neue Struktur f/ir das sogenannte Synthesefilter, das yon dem Analyseteil des betrachteten Algorithmus abgeleitet ist, vorgeschlagen, das dem Problem besser angepaBt ist als bevor. SchlieBlich wird die Erweiterung des Algorithmus auf den mehrkanaligen Fall diskutiert. R~sum~. Un nouvel algorithme efficient pour l'inversion r+cursive en temps et en ordre d'une classe particuliere de matrices 6manant dans le contexte de probl+mes d'estimation aux moindres carr+s a +t6 r6cemment introduit, et la partie analyse de celui-ci est 16g6rement modifi6e dans cet article pour conduire fi une structure plus sym~trique. Des r6sultats num6riques montrant la convergence extr~mement rapide et la capacit6 de poursuite excellente de cet algorithme sont pr6sent+s, et des rbcursions modifi6es, r~duisant le nombre de calcul de racines carr6es par un facteur trois, sont introduites. De plus, nous proposons une structure nouvelle pour lefiltre de synthkse, deriv6e de la partie analyse de l'algorithme consid+rb, du fair de sa plus grande ad+quation au probl6me que celle donn6e r6cemmenl. Finalement, nous discutons l'extension de cet algorithme au cas multi-canaux.	algorithm;eine and zwei;internet explorer;lattice phase equaliser;least squares;linear algebra;nouvelle ai;numerical method;recursion;sie (file format);unified model	Anton Kummert;Stephan Hartwig;Alfred Hypki	1992	Signal Processing	10.1016/0165-1684(92)90056-3	adaptive filter;computer vision;mathematical optimization;computer science;calculus;signal processing;mathematics;algorithm;statistics	ML	-98.09814678843625	35.96560061793097	29253
bb1f7e65a34fd292f4a3a28ce7053333832947c1	konstruktion und implementierung eines neuen verfahrens zur kompression von bilddaten				Jörg Haber	1999				Robotics	-101.11423548120096	25.851226470764978	29313
b1020f7612791554460e316024349a9d979b0c52	understanding the shape of java software	developpement logiciel;herencia;loi puissance;measurement;ecologia;structure programme;java programming;object oriented design;ley poder;heritage;dep;ecologie;langage java;ecology;conference item;estructura programa;object oriented;desarrollo logicial;software development;oriente objet;power law distributions;design;lenguaje java;power law;inheritance;program structure;orientado objeto;power law distribution;java language;java	Large amounts of Java software have been written since the language's escape into unsuspecting software ecology more than ten years ago. Surprisingly little is known about the structure of Java programs in the wild: about the way methods are grouped into classes and then into packages, the way packages relate to each other, or the way inheritance and composition are used to put these programs together. We present the results of the first in-depth study of the structure of Java programs. We have collected a number of Java programs and measured their key structural attributes. We have found evidence that some relationships follow power-laws, while others do not. We have also observed variations that seem related to some characteristic of the application itself. This study provides important information for researchers who can investigate how and why the structural relationships we find may have originated, what they portend, and how they can be managed.	ecology;java	Gareth Baxter;Marcus R. Frean;James W Noble;Mark Rickerby;Hayden Smith;Matt Visser;Hayden Melton;Ewan D. Tempero	2006		10.1145/1167473.1167507	design;power law;computer science;theoretical computer science;software development;programming language;java;algorithm;measurement	PL	-64.95599727662344	36.466891310842534	29332
9a5222701b9d626c92e6999542479c27536f9cf1	managing procurement spend using advanced compliance analytics	compliance analytics;cost saving;procurement;cplex;contracts;budgeting data processing;spend analysis;purchasing budgeting data processing business data processing competitive intelligence contracts data mining data warehouses internet procurement;data mining;portfolio optimization;purchasing;transaction data;internet;business data processing;data warehousing;optimization investments procurement companies engines;competitive intelligence;cplex compliance analytics procurement spend analysis data mining optimization spss modeler;optimization;business intelligence;data warehouses;spss modeler;analytic solution;procurement spending management advanced compliance analytics business enterprise procurement organization contract terms contract conditions legacy habit purchasing service prenegotiated contracts process education approval process steps query tools software solution spend compliance analytics cost savings web enabled advanced analytical solution compliance analytic tool compliance management advanced data mining techniques historical spend transactions portfolio optimization techniques budget business analytics business intelligence tools dashboards data warehousing	Often the processes for purchasing commodities and services within a business enterprise are centralized into a procurement organization. These purchases are often sourced from one or more suppliers, or vendors, based on contract terms and conditions (such as price, payment terms etc.), availability, and quality or legacy habit of purchasing service with known vendors. We have found that many organizations lack appropriate processes and disciplines to drive demand to preferred suppliers. Thus these enterprises are unable to leverage the value of the pre-negotiated contracts due to lack of process education, approval process steps or appropriate purchasing tools that could result in significant amounts of spending that would be considered not compliant (not being sourced through preferred suppliers). Depending upon the size of the organization, such transactions range from several million dollars to billions of dollars. Manually sifting or employing typical query tools to review large amounts of spend transaction data with multiple attributes to identify the level of non compliant spend and identify areas to take action is a daunting task. In this paper, we discuss a software solution for spend compliance analytics that includes measurements of cost savings due to increased compliance and identification of areas where spend tends to be non compliant. We have developed a web enabled advanced analytical solution called Compliance Analytics Tool (CAT) that embeds a two phase methodology for compliance management. In the first phase, we use advanced data mining techniques to segment a large amount of historical spend transactions to quickly identify promising areas of improvement, exploiting a multitude of purchasing attributes such as business unit, procurement category, suppliers, etc. The second phase employs portfolio optimization techniques to further focus on specific segments that provide maximum benefit based on desired compliance targets or available budget. We also discuss the solution architecture that integrates business analytics along with business intelligence tools, dashboards, and data warehousing.	business analytics;centralized computing;computer-assisted translation;data mining;gene ontology term enrichment;imperative programming;mathematical optimization;procurement;purchasing;routing;solution architecture;transaction data	Pawan Chowdhary;Markus Ettl;Amit Dhurandhar;Soumyadip Ghosh;Gopikrishnan Maniachari;Bruce Graves;Bill Schaefer;Yu Tang	2011	2011 IEEE 8th International Conference on e-Business Engineering	10.1109/ICEBE.2011.57	closed-form expression;the internet;procurement;computer science;marketing;operating system;data warehouse;transaction data;portfolio optimization;database;management;world wide web;computer security	DB	-71.63760444354524	7.148360062531583	29333
2da80b501e358d39ab0b22176b5faf5aecb7e4ae	performance orientierte systementwicklung am beispiel datenbankbasierter integrierter anwendungssysteme				André Scholz	2001				Crypto	-97.41815877145953	24.93347326391441	29336
0d2a0e67ef4cb5ab3d119899b616d90c669f0522	evaluating cross-organizational erp requirements engineering practices: a focus group study	qualitative research;enterprise resource planning companies packaging collaboration feedback software engineering reflection computer science project management resource management;systems analysis enterprise resource planning software engineering;focus group;empirical software engineering;software engineering;requirements engineering;focus group based validation cross organizational erp requirement engineering evaluation enterprise resource planning qualitative research approach focus group method software engineering software development;empirical software engineering requirements engineering enterprise resource planning;systems analysis;requirement engineering;software development;enterprise resource planning	This focus group study presents our first validation of practices for engineering the coordination requirements in cross-organizational Enterprise Resource Planning (ERP) projects. The study evaluates 13 practices addressing a variety of coordination aspects crucial to ERP projects. These practices are results in previously published research publications by the first author. The practices are formulated in response to practitioners' needs at ERP adopting organizations. The proposed practices have now reached the stage where we need some independent feedback as to the extent to which they fit the realities of practitioners. We perform this validation by means of a qualitative research approach, namely the focus group method. Current software engineering literature provides few examples of using focus groups in the evaluation of good software development practices. Because of this, providing reflections on our focus-group-based validation experiences will be of value to both the research community and practitioners.	amiga reflections;erp;enterprise resource planning;feedback;focus group;requirement;requirements engineering;software development;software engineering	Maya Daneva;Niv Ahituv	2010	2010 Fourth International Conference on Research Challenges in Information Science (RCIS)	10.1109/RCIS.2010.5507387	functional software architecture;systems analysis;requirements analysis;personal software process;verification and validation;enterprise systems engineering;enterprise software;software engineering process group;extreme programming practices;software project management;systems engineering;engineering;knowledge management;qualitative research;social software engineering;software development;requirement;focus group;software engineering;software construction;requirements engineering;management;human resource management system;enterprise planning system;software requirements	SE	-69.11416336128678	21.08097497417951	29353
ce720cbae2f966529dad23df70374daa4bfca241	ecosystem-inspired enterprise modelling framework for collaborative and networked manufacturing systems	enterprise modelling em;ecosystem theory;collaborative manufacturing network cmn;enterprise simulation;institutional repository research archive oaister;enterprise analysis and design	Rapid changes in the open manufacturing environment are imminent due to the increase of customer demand, global competition, and digital fusion. This has exponentially increased both complexity and uncertainty in the manufacturing landscape, creating serious challenges for competitive enterprises. For enterprises to remain competitive, analysing manufacturing activities and designing systems to address emergent needs, in a timely and efficient manner, is understood to be crucial. However, existing analysis and design approaches adopt a narrow diagnostic focus on either managerial or engineering aspects and neglect to consider the holistic complex behaviour of enterprises in a collaborative manufacturing network (CMN). It has been suggested that reflecting upon ecosystem theory may bring a better understanding of how to analyse the CMN. The research presented in this paper draws on a theoretical discussion with aim to demonstrate a facilitating approach to those analysis and design tasks. This approach was later operationalised using enterprise modelling (EM) techniques in a novel, developed framework that enhanced systematic analysis, design, and business-IT alignment. It is expected that this research view is opening a new field of investigation.	blackmagic fusion;ecosystem;emergence;enterprise modelling;holism	Amjad Fayoumi	2016	Computers in Industry	10.1016/j.compind.2016.04.003	manufacturing execution system;enterprise systems engineering;enterprise modelling;systems engineering;engineering;knowledge management;artificial intelligence;marketing;operations management;database;computer-integrated manufacturing;enterprise integration;management;enterprise life cycle;mechanical engineering	AI	-74.54996962359425	7.458070001589127	29396
c6cac3d8a291dceb7fa6342193c5241157eff0e3	laufzeitoptimierung und technologieabbildung in der logiksynthese unter verwendung von mehrbereichsdarstellungen boolescher funktionen				Endric Schubert	1996				ML	-98.47975298449552	25.206495201498736	29403
8d092d7bf8f9e21656ef4fcc7f2bf4059d3b7583	a sustainability lifecycle assessment of products and services for the extended enterprise evolution		Recently numerous companies are moving from products to services to create new business opportunities and increase the value perceived by the customers thanks to an extended value creation network. The research challenge is to support traditional manufacturing enterprises evaluating the shift from products to services as far as sustainability is concerned. While product sustai- nability can be assessed by several tools, the impacts of PSS (Product-Service Systems) are almost unexplored. This paper adopts a holistic approach to assess sustainability by estimating three main impacts: environmental, economical and social. The methodology is illustrated by means of an industrial case study fo- cusing on washing machines; it analyses the traditional scenario based on tangi- ble product selling with a vertical supply-chain, and an innovative PSS scenario proposing washing as a service within an extended network. Data comparison highlights the achievable benefits of PSS on sustainability.	extended enterprise	Margherita Peruzzini;Michele Germani;Eugenia Marilungo	2013		10.1007/978-3-642-41501-2_11	systems engineering;engineering;marketing;operations management	Theory	-75.11317921374967	7.0775684552115505	29446
4b419bedf1a7c19aa08506e6cafd90d59a386bdb	special feature: what are the information security risks in decision support systems and data warehousing?	information security;decision maker;decision support system;data warehousing	Decision support systems (DSSs) are increasingly used in decision-making. DSSs usually contain a huge amount of information, most of it classified. Decision-makers use this information as a basis when making decisions, some of which are crucial for the survival of the company. The information has to be reliable otherwise it can have disastrous effects on the company. Datawarehousing can be seen as a tool in a DSS. With datawarehousing we want to find crucial data for functioning as support in our decision-making. The information in a DSS should not be threatened, lost or misused. What about the information security risks in decision support systems? Can we protect ourselves against the information security risks connected to DSSs and datawarehousing?		Thomas Finne	1997	Computers & Security	10.1016/S0167-4048(97)84512-9	decision-making;decision support system;computer science;knowledge management;information security;management information systems;data mining;computer security;information security management	DB	-68.5199065479555	8.819790384013482	29478
a5d420bfe7d87c4c194066384f5ea4ad3c40c870	mobility and security management in femtocell networks. (gestion de la mobilité et de la securité dans les résaux femtocellulaires)			linear algebra;security management	Seifeddine Bouallegue	2016				Crypto	-101.77462987242315	16.36063476239894	29484
9896cea8ad41ab07267feb672efdb64f98cfb341	interwoven systems		Miteinander verwobene Systeme Informationsund Kommunikationstechnologie (IKT) ist inzwischen so allgegenwärtig, dass sie als zentraler Bestandteil unseres täglichen Lebens gilt. Diese Integration in unseren Alltag prägt nicht nur unsere Gesellschaft, sie beeinflusst auch die Modellierung, Entwicklung, Analyse und Wartung von IKT-Infrastrukturen. Die entstehenden technischen Systeme bieten zunehmend mehr Funktionalität an, werden gleichzeitig aber auch immer komplexer – objektive Zeugnisse dieser Beobachtung sind beispielsweise die Gesetze von Moore und Glass [1]. So können durch eine Einbettung von IKT-Funktionen auch Haushaltsgeräte wie Fernseher, Kühlschränke und sogar Thermostate [6] einen erweiterten Funktionsumfang bieten, wenn sie mit dem Internet verbunden sind. Doch nicht nur technische Systeme an sich werden so miteinander gekoppelt – eine Vielzahl bisher isolierter Systeme wächst zukünftig noch stärker zusammen. Damit werden gleichzeitig völlig neuartige Anwendungen ermöglicht. Ein sehr anschauliches Beispiel stellt die Energiewende dar [2]: War die Energieinfrastruktur in Deutschland bisher klar strukturiert (wenige Anbieter, große Kraftwerke, zentrale Steuerung) und im Wesentlichen ein in sich geschlossenes System, so wachsen zurzeit Energieund IT-Netze zusammen. Eine Vielzahl unsicherer Erzeuger werden dem Gesamtnetz hinzugefügt, verlässliche große Erzeuger werden abgeschaltet und die zentrale Steuerungsmöglichkeit wird reduziert, indem immer mehr unabhängige, heterogene Entitäten ihre eigenen Entscheidungen treffen – sei es bei der Abnahme oder der Erzeugung von Strom. Zusätzlich kommen neue Möglichkeiten hinzu, das Nutzungsverhalten von Verbrauchern zu beeinflussen: Smart Meter, tageszeitund lastabhängige Preise, einfacher Wechsel von Anbietern, etc. Veränderungen in der Nutzung und im Zusammenwirken von technischen Systemen führen zu einer Vielzahl von Implikationen hinsichtlich der Entwicklung und Beherrschung solcher Systeme: 1. Wir haben es typischerweise nicht mehr mit einem isolierten System zu tun, das wir in klassischer Weise eingrenzen, analysieren und somit steuern oder regeln können. Vielmehr handelt es sich um eine Vielzahl interagierender und sich gegenseitig beeinflussender Systeme. 2. Diese Teilsysteme sind so miteinander verwoben, dass eine Modularisierung und Abstraktion nur selten möglich ist – damit stoßen herkömmliche Techniken des Systementwurfs und der Systemsteuerung an ihre Grenzen und müssen folglich den neuen Gegebenheiten angepasst werden.	eine and zwei;intentionally blank page;internet explorer;sie (file format);smart meter;système universitaire de documentation;tun (product standard);unified model	Sven Tomforde;Jörg Hähner;Bernhard Sick	2014	Informatik-Spektrum	10.1007/s00287-014-0827-z		OS	-105.13146735435434	35.57784227446482	29514
9833b9aadb0d68b1cac59ef1409580fc7aba915e	typesafe modeling in text mining	information model;programming language;text mining;information retrieval;text processing;machine learning;domain specific language	class SensevalData (s: String ) extends Agent [String , Context ] { val file = new File(s) val trainDataReader = new STAXSensevalDataReader (file); val samples : List[ Ambiguity ] = trainDataReader . getAmbiguities . toList val words : java.util.List[ String ] = trainDataReader . getWords def process ( input : java.util.List[ Annotation [ String ]]) = samples .map( asAnnotation (_)) def asAnnotation (amb: Ambiguity ): Anno[ Context ] = { Annotations . create [ Context ]( classOf [ SensevalData ], amb. getContext :Context , amb. getContext . targetStart :Int , amb. getContext . targetEnd :Int) } override def toString = file. toURL . toString } SensevalSense Agent für Zugriff auf Zielworte der Daten (in Scala, Agent[Context, Ambiguity]): class SensevalSense (s: String ) extends Agent [Context , Ambiguity ] { val words : List[ String ] = Nil 66 Eine Definition des Text-Mining von http://en.wikipedia.org/wiki/Text_mining	anno 1602;eine and zwei;java;nil;scala;setcontext;text mining	Fabian Steeg	2011	CoRR		concept mining;natural language processing;text mining;information model;computer science;domain-specific language;data mining;programming language;temporal annotation;information retrieval;co-occurrence networks	ML	-106.88073611339574	36.10831304540436	29671
d217ca57c3bdbbff2e1808a30da7fcd6b72c58c9	entrepôts de contenu autour de xml et des services web			xml	Serge Abiteboul	2006			world wide web;xml;computer science	Crypto	-95.41142467331674	29.032454677006786	29679
f6021eb8c6786920ff5f5ec75f2d8b712013de1e	two stage business and it-alignment: initial experiences from portal implementation for non-traditional study formats of a university		Business and IT-alignment (BITA) is a continuous process aiming at aligning strategic and operational objectives and ways to implement them between the business divisions of an organization and its information technology. The work presented in this paper focuses on a specific aspect of BITA: the process of creating an alignment between stakeholders in an organization and the IT. In a project aiming at the implementation of of lifelong learning services, experiences were collected supporting a two stage BITA process. The organizational objective of the project was to offer tailormade learning possibilities at university level to new, non-traditional target groups. New study formats allow to start studying at any stage of life and offer appropriate IT support for new target groups and study formats. The central technological idea consists in a context-oriented, information technology portal for e-learning, the MyKOSMOS portal, with an individualized and demandbased supply of information for the learners.	experience	Kurt Sandkuhl;Holger Lehmann	2017		10.1007/978-3-319-69023-0_12	knowledge management;information system;computer science;information technology;lifelong learning	HCI	-71.38855347823254	9.940421960966582	29712
e0bfa032a4b4111fb20ae294961a13f9f4c65244	the essential client/server survival guide, 2nd edition	client server			Robert Orfali;Dan Harkey;Jeri Edwards	1996			client;operating system;internet authentication service;appleshare;database;fat client;world wide web;client–server model	Vision	-92.45516345827782	29.902828036895247	29826
ed0bbf0a1d8026da95851826197fee1f9aa9c0a7	entwicklungspolitische maßnahmen der deutschen bundespost im bereich digitaler dienste für die 2. hälfte der achtziger jahre	nahmen der;entwicklungspolitische ma;lfte der achtziger	Die gegenwartige technische Entwicklung im Fernmeldewesen ist weltweit durch das Schlagwort „Digitalisierung“ gekennzeichnet. Ausgelost durch die Elektronikentwicklung und der sinkenden Kosten insbesondere fur digital arbeitende Halbleiterbausteine stellt sich die Fernmeldetechnik in allen Bereichen, also auch bei Analogsignalen, auf digitale Vermittlung und Ubertragung um.		Jürgen Kanzow	1981		10.1007/978-3-642-67978-0_2	computer network;telecommunications;computer science	Theory	-104.82850919249505	34.228251682803226	29844
d813ff621c5824500577eecbd886624614f84693	calculating return on investment of training using process variation	organisation training;process variation;return on investment;software development process;training evaluation;software factory;training cost benefit analysis investment software development management statistical analysis;training investment;software factory return on investment training investment process variation organisation training software process improvement model training evaluation software development process statistical management production environment;software process improvement model;production environment;statistical management	Organizations have relied on training to increase the performance of their workforce. Also, software process improvement models suggest that training is an effective tool for institutionalizing a development process. Training evaluation becomes important for understanding the improvements resulting from the investments in training. Like other production process, the software development process is subject to natural and special causes of variation, and process improvement models recommend its statistical management. Return on investment (ROI) has already been proposed as an effective measure to evaluate training interventions. Nevertheless, when applying ROI in production environments, practitioners have not taken into consideration the effects of variation in production processes. This paper presents a method for calculating ROI that considers process variation; we argue that ROI results should be understood in accordance to statistical management guidance. The proposed method has been piloted at a software factory. The results of the case study are reported. These results show how to calculate ROI by taking into account the variation of a production process.	region of interest;software development process;software factory	Santiago Matalonga;Tomás San Feliu Gilabert	2012	IET Software	10.1049/iet-sen.2011.0024	return on investment;team software process;software engineering process group;systems engineering;engineering;knowledge management;development environment;process variation;empirical process;management;software development process	SE	-69.8168905193891	20.125378727493917	29852
42ec34060afeef7bb79d8d5ef7d29913bba399e3	qualifikationen für die postgraduale weiterbildung zum/r wissensmanager/in	poster			Richard Pircher;Edith Denman-Maier;Hanna Risku	2001				Robotics	-96.38055180713405	23.785934862908018	29857
8a3bc42291874cb1d1f9668071b3e1133bd5942b	une correspondance entre anneaux partiels et groupes				Patrick Simonetta	1997	J. Symb. Log.		division ring;solvable group;mathematics;algebra	Logic	-103.3012888142485	12.679273553443595	29869
512f16da2d9cd6e406371b2636aab24a07819d7e	arbeitsteilige konstruktion von software-architekturen mit dem werkzeug opus			libopus	Rainer Fehling;Wilhelm Schäfer	1994	Inform., Forsch. Entwickl.		software development;software engineering;programming team;software;systems architecture;computer science;opus	Theory	-93.13492502355462	25.97848347563581	29928
670407780733e4efff27935044096340d25caeb7	an approach from software reliability modeling to security modeling	software reliability;security model		software quality;software reliability testing	Charlie Yong-Sang Shim;Alireza Salehnia;Sung Y. Shin	2002			computer science;software deployment;software construction;software development;software verification and validation;software reliability testing;software security assurance;reliability engineering;social software engineering;software sizing	SE	-63.296074643670366	26.570735364750426	29940
c213015118248de7b842f67ddb8de32d8dbc1df4	third international workshop on reverse variability engineering (reve 2015)		Variability management of a product family is the core aspect of Software Product Line Engineering. The adoption of this mature approach requires a high upfront investment before being able to automatically generate product instances based on customer requirements. However, this adoption costs and risks could be reduced with an incremental approach, which mines existing assets and then transitions to full product line engineering. Those existing assets can be for instance similar product variants that were implemented using ad-hoc reuse techniques such as clone-and-own. Hence, there is a great need of bottom-up approaches that extract variability from the artifacts (across all the life cycle) of the legacy product variants and manage the consolidated variability. The REVE workshop series aims to bring together the Reengineering and Software Product Line Engineering communities to address this gap.	bottom-up proteomics;code refactoring;customer relationship management;heart rate variability;hoc (programming language);legacy system;requirement;software product line;spatial variability	Roberto Erick Lopez-Herrejon;Tewfik Ziadi;Jabier Martinez;Anil Kumar Thurimella;Mathieu Acher	2015		10.1145/2791060.2791062	systems engineering;engineering;operations management;management science;product management;new product development;product engineering	SE	-66.33470129096881	21.9443873844802	30000
85845ccde2259a1d6e257d2ad5fa546a06418675	modelle nebenläufiger prozesse - monoide, residuensysteme und automaten				Dietrich Kuske	1993				HCI	-99.7828698909271	22.814863727500857	30007
a0678ee7773fdc921ada9b238a5a5575a952328e	exact solutions for discrete graphical models: multicuts and reduction techniques	004;004 data processing computer science	In the past years, discrete graphical models have become a major conceptual tool to model the structure of problems in image processing – example applications are image segmentation, image labeling, stereo vision, and tracking problems. It is therefore crucial to have techniques which are able to handle the occurring optimization problems and to deliver good solutions. Because of the hardness of these inference problems, so far mainly fast heuristic methods were used which yield approximate solutions. In this thesis we present exact methods for obtaining optimal solutions for the energy minimization problem of discrete graphical models; image segmentation serves as the main application. Since these problems are NP-hard in general, it is clear that in order to be able to handle problem sizes occurring in real-world applications one has to either (a) reduce the size of the problems or (b) restrict oneself to special problem classes. Concerning (a), we develop a combination of existing and new preprocessing steps which transform models into equivalent yet less complex ones. Concerning (b), we introduce the so-called multicut approach to image analysis: This is a generalization of the min s-t cut method which allows for solving models of a certain structure significantly faster than previously possible or even solving them to global optimality for the first time at all. On the whole, we present methods which solve NP-hard problems to proven optimality and which in some cases are as fast or even faster than approximative methods. Zusammenfassung In den letzten Jahren entwickelten sich diskrete graphische Modelle zu einem grundlegenden Hilfsmittel, um die Struktur in der Bildverarbeitung auftretender Probleme zu modellieren – Beispielanwendungen sind etwa Bildsegmentierung, Bildlabeling, Stereosehen und Tracking-Probleme. Es ist daher essentiell, über Techniken zu verfügen, die mit den auftretenden Optimierungsproblemen umgehen und gute Lösungen liefern können. Aufgrund der Schwere dieser Probleme wurden bisher hauptsächlich heuristische Verfahren eingesetzt, die Näherungslösungen liefern. In der vorliegenden Arbeit präsentieren wir exakte Methoden, um optimale Lösungen des Energieminimierungsproblems diskreter graphischer Modelle zu erhalten; unsere Hauptanwendung ist dabei die Bildsegmentierung. Da die Probleme im Allgemeinen NP-schwer sind, ist es klar, dass man, um in der Praxis auftretende Problemgrößen behandeln zu können, entweder (a) die Größe der Probleme reduzieren oder (b) sich auf spezielle Problemklassen beschränken muss. Hinsichtlich (a) entwickeln wir eine Kombination von existierenden und neuen Vorverarbeitungsschritten, die ein Modell in ein äquivalentes, aber weniger komplexes umwandeln. Bezüglich (b) führen wir den sogenannten Multicut-Ansatz in die Bildverarbeitung ein: Dabei handelt es sich um eine Verallgemeinerung des Min-s-t-Cut-Verfahrens, die es ermöglicht, Probleme einer gewissen Struktur signifikant schneller als bisherige Methoden oder sogar erstmals überhaupt global optimal zu lösen. Insgesamt präsentieren wir Methoden, die NPschwere Probleme beweisbar optimal lösen und die in manchen Fällen genauso schnell oder sogar schneller sind als Näherungsverfahren. Acknowledgments Above all, I want to thank my supervisor Prof. Gerhard Reinelt. He aroused my interest in combinatorial optimization and offered me the possibility to do my PhD in his group. I got to know him as a supportive and reliable person, taking care of the students under his guidance. My second supervisor, Prof. Christoph Schnörr, introduced me to the field of image analysis in general and graphical models in particular. I am thankful to him for offering a complementing perspective from the viewpoint of application. I owe special gratitude to Jörg Kappes for his help throughout the past years – he always had an open door for me and was willingly sharing his experience. Thorsten Bonato and Stefan Wiesberg helped me to get Thorsten’s max cut code running with my instances. The evaluation of the superpixel algorithms was done in collaboration with Borislav Antic. Stefan Lörwald provided support with the new version of PORTA. Thanks to all of you! Being in between two research groups, I had a lot of people helping me with administrative tasks. Our secretaries Catherine Proux-Wieland, Anke Sopka, Karin Tenschert, Barbara Werner, and Evelyn Wilhelm were taming the bureaucratic beasts to make life easier. Thanks to our system administrators who were responsible for keeping our machines running: Georgios Nikolis, Adrian Dempwolff, Lucas Appelmann, Klaus Hornung, and Jacqueline Hammer. The members of our research group – Achim Hildenbrandt, Thomas Metz, Tuan Nam Nguyen, Marcus Oswald, Hanna Seitz, Khoa Vo, Pei Wang, and Stefan Wiesberg – provided a great and relaxed working atmosphere and, as well as the members of the groups “Database System Research”, “Parallel and Distributed Systems”, and “Image & Pattern Analysis”, enriched working days with discussions about scientific and non-scientific topics. I had the pleasure to be a member of the Research Training Group RTG 1653 “Spatio/Temporal Probabilistic Graphical Models and Applications in Image Analysis”. I am grateful to the German Research Foundation (DFG) for this support and to all colleagues associated to the group for being so helpful. Especially, I want to thank my fellow PhD students Borislav Antic, Fabian Bachl, Eva-Maria Didden, Johannes Dueck, Dominic Edelmann, Jochen Fiedler, Bernhard Kausler, Gabriell Máté, Annette Möller, Fabian Rathke, and Bernhard Schmitzer – I definitely would have missed something without you. For proofreading parts of this thesis I thank Stefan Wiesberg, Jörg Kappes, and Kira Augenstein – your comments were indeed helpful and improved this work. Of course, all remaining errors are my own. My parents Monika and Josef Speth deserve my heartfelt thanks for their unconditional support in all situations. Finally, I thank Kira Augenstein for her loving support.		Markus Speth	2014			mathematical optimization;combinatorics;mathematics;algorithm	AI	-97.43032079263861	36.331459022483166	30009
5d94673a55476988c0c0db3d037ae12b1bbb270e	"""""""dictionary dialog"""" - entwurf des funktionsumfangs für eine benutzerschnittstelle eines integrierten maschinellen/maschinenunterstützten übersetzungssystems und prototypische erstellung der bildschirmfolge für die funktion """"semantische relation"""""""			dictionary;eine and zwei;dialog	Anja Theuner	1992	IWBS Report			Crypto	-98.89353872224008	27.86433194662608	30011
78b46889ae33a837e99a434ba00e78f0e483fd75	drivers of agile software development use: dialectic interplay between benefits and hindrances	agile software development;training;dialectic theory;subjective norm;perceived hindrance;innovation adoption	Context: Agile software development with its emphasis on producing working code through frequent releases, extensive client interactions and iterative development has emerged as an alternative to traditional plan-based software development methods. While a number of case studies have provided insights into the use and consequences of agile, few empirical studies have examined the factors that drive the adoption and use of agile. Objective: We draw on intention-based theories and a dialectic perspective to identify factors driving the use of agile practices among adopters of this software development methodology. Method: Data for the study was gathered through an anonymous online survey of software development professionals. We requested participation from members of a selected list of online discussion groups, and received 98 responses. Results: Our analyses reveal that subjective norm and training play a significant role in influencing software developers’ use of agile processes and methods, while perceived benefits and perceived limitations are not primary drivers of agile use among adopters. Interestingly, perceived benefit emerges as a significant predictor of agile use only if adopters face hindrances to their agile practices. Conclusion: We conclude that research in the adoption of software development innovations should examine the effects of both enabling and detracting factors and the interactions between them. Since training, subjective norm, and the interplay between perceived benefits and perceived hindrances appear to be key factors influencing the adoption of agile methods, researchers can focus on how to (a) perform training on agile methods more effectively, (b) facilitate the dialog between developers and managers about perceived benefits and hindrances, and (c) capitalize on subjective norm to publicize the benefits of agile methods within an organization. Further, when managing the transition to new software development methods, we recommend that practitioners adapt their strategies and tactics contingent on the extent of perceived hindrances to the change. 2011 Elsevier B.V. All rights reserved.	agile software development;contingency (philosophy);documentation;emoticon;extreme programming;focus group;instability;interaction;iteration;iterative and incremental development;kerrison predictor;os/2;pair programming;requirement;software bug;software development process;software quality;t-norm;theory;dialog	Leo R. Vijayasarathy;Daniel E. Turk	2012	Information & Software Technology	10.1016/j.infsof.2011.08.003	systems engineering;engineering;knowledge management;software engineering;agile software development;management science;management	SE	-73.32700195615517	22.015652144852375	30012
c9a9add5fb342091dd5d7a02f031bc059807590d	the effect of information communication technology and corporate organizational reforms on productivity in japan: firm- level evidence	empirical study;information communication technology;e commerce;decentralization of decision making power;business relations;information and communication technology;organizational change;business process outsourcing;productivity;supply chain management;business process	Our main objective in this paper is to understand how Japanese firms can increase productivity by utilizing Information and Communication Technology (ICT). E-commerce, BPO (Business Process Outsourcing), and SCM (Supply Chain Management) are popular in Japan, so a new type of ICT might offer an opportunity for Japanese firms to change current business relations or to start up new ones. The novelty of this paper is in its empirical study of the combination of ICT promotion and a variety of business organizational changes needed to discover which type of business organizational change is suitable for raising productivity in Japan. For workplace organization within firms, we discuss the decentralization or centralization of decision-making power and the flattening of the corporate hierarchy. For business relational changes, we discuss the outsourcing of the business process and the start up of new business relations. Our main result is that in general, the promotion of ICT has better effects in reforms related to changes in business relations among business partners, rather than to reforms within a firm. Starting up new business relations that require planning and R&D show the best chances of raising productivity using ICT promotion.		Kazunori Minetaki	2008	The Review of Socionetwork Strategies	10.1007/s12626-008-0002-6	business model;business analysis;information and communications technology;business transformation;supply chain management;economics;business process reengineering;artifact-centric business process model;business administration;marketing;business case;electronic business;process management;business system planning;business process;business networking;business relationship management;management;new business development;philosophy of business;economic growth;commerce	HCI	-79.54827505026945	4.196193038073704	30019
bf442e02a8c8fe37f17bd11bc7fe68d85089a7b5	unterstützung von bos durch mobile crowd sensing in schadenslagen	hci;kriseninformatik;cscw;workshop	Schadenslagen der letzten Zeit, wie beispielsweise das Elbe-Hochwasser 2013, haben deutlich gezeigt, dass die Bevölkerung in ihnen bereits eine aktive Rolle einnimmt. Bürger organisieren sich untereinander und/ oder koordinieren Hilfsaktivitäten. Diese Hilfsaktivitäten lassen sich sowohl bei betroffenen Bürgern vor Ort, aber auch innerhalb sozialer Medien wiederfinden. Um dieses Potential durch professionellen Behörden und Organisationen mit Sicherheitsaufgaben erfassbar sowie nutzbar zu machen, sind Ansätze notwendig, welche die Bevölkerung gezielt anleiten und deren Maßnahmen koordinieren, da die Bürger sich sonst oftmals selbst in Gefahr begeben. In diesem Beitrag präsentieren wir ein auf dem Mobile Crowd Sensing basierendes Konzept, um Aktivitäten der Bevölkerung zu erfassen und gezielt Aufgaben, wie die Informationsbeschaffung oder physische Unterstützung, an die Bevölkerung weiterzureichen.	eine and zwei;intentionally blank page;internet explorer;open road tolling;unified model;vhf omnidirectional range	Thomas Ludwig;Tim Siebigteroth	2014			simulation;human–computer interaction;engineering	Mobile	-96.86064811316609	29.531310820500742	30062
b7c4307efb85004dbc16181e41512892f75a95c8	"""computer in industry special issue on """"interoperability and future internet for next-generation enterprises"""" editorial and state of the art"""	information systems social aspects;systemvetenskap informationssystem och informatik med samhallsvetenskaplig inriktning	Today’s global markets drive enterprises towards closer collaboration with customers, suppliers and partners. Interoperability problems constitute fundamental barriers to such collaboration. A characteristic of modern economic life is the requirement on continuous and rapid change and innovation. The success of an enterprise more and more depends on its ability to seamlessly interoperate with other agile enterprises, and to be able to adapt to actual or imminent changes. Flexible and adaptive interoperability of enterprises, with aligned business processes and information technology, thus emerges as a key business feature. This new enterprise reality calls for advanced technological support, preferably in harmony with technology developments of the Internet, which is our dominant universal communication and information infrastructure. The current special issue aims at contributing to a consolidation of the theoretical and empirical knowledge on enterprise interoperability, and at promoting novel ideas and early experience regarding the use and realization of the Future Internet vision to advance Enterprise Interoperability.	future internet;interoperability	Marten van Sinderen;Pontus Johnson;Guy Doumeingts	2013	Computers in Industry	10.1016/j.compind.2013.08.002	interoperability;computer science;systems engineering;engineering;knowledge management;artificial intelligence;marketing;operations management;database;management science;management;cross-domain interoperability;mechanical engineering	ML	-73.85342649288263	7.08231379623218	30078
035b1e3831f1be19c71bb06767880e23837368db	how schlumberger achieved networked information leadership by transitioning to a product-platform software architecture		“We have realized recently that the oil industry could move a little bit faster in the area of software platform. It’s a big focus for the coming future because the platforms are not open, so applications are not easily interoperable. And if they are not interoperable, then, these kinds of loops can’t be closed very well, and analytics cannot be run in real time as this system requires. So software interoperability and connection are absolutely essential ...” Ashok Belani, Schlumberger Executive Vice President of Technology, September 2013.3	interoperability;software architecture	Joseph J. Nehme;Shirish C. Srivastava;Horacio Bouzas;Laurent Carcasset	2015	MIS Quarterly Executive		robustness (computer science);systems engineering;knowledge management;customer satisfaction;engineering;architecture;software architecture;software;extensibility;tracing	SE	-75.83742971971137	18.226486169727465	30100
91df6ccded3c0251a9ea04318330b819a360046b	intellectual capital, knowledge management, knowledge economies and innovation: the case of small asset management firms in ireland	learning;intellectual capital;techno economic paradigm;small and medium sized enterprises;asset management industry;knowledge management;knowledge assets;ireland;knowledge economies;innovation;smes;knowledge economy;firm performance	The purpose of this study is to examine how Ireland-based small asset management firms (SAMFs) rely on their knowledge-based assets and practices in order to innovate and possibly generate organisational performance within a challenging industry, and within knowledge economies. This study considers three levels of analysis: firm level, industry level and technoeconomic paradigm (TEP) level. The study employed qualitative case study utilising semi-structured interviews (n = 35), observations and documentation. Results show that above average organisational performance results from innovation grounded in knowledge-based assets and methods, and the endeavour to achieve an alignment between firm, industry and TEP levels. This research provides empirical insights on small and medium enterprises (SMEs) knowledge assets and practices in an industry seldom studied. It also investigates the different interactions between knowledge management, intellectual capital, TEP and innovation.	assertion (software development);documentation;endeavour (supercomputer);holism;interaction;knowledge management;programming paradigm;semiconductor industry	Yasmina Khadir-Poggi;Mary Keating	2015	IJKL	10.1504/IJKL.2015.071620	superconducting magnetic energy storage;innovation;investment management;knowledge economy;knowledge management;marketing;knowledge value chain;management;economic growth;commerce	HCI	-79.288902895607	5.242915407383021	30112
17a603212784e72f72a5aed10b553b76cfeeaf03	zur prüfung der einhaltung von normen - begriffe, kriterien, modelle				Friedrich von Sydow	1985	Angewandte Informatik			NLP	-100.09164549805195	23.20356334320524	30190
da9a580c0241c3efe50d1d55c00cb075861684fd	real time business intelligence in supply chain analytics	information systems;service orientation;real time;customer loyalty;supply chain;business intelligence;information system;business analysis;supply chain management;competitive advantage;design methodology	Purpose – Rapid innovation and globalization have generated tremendous opportunities and choices in the marketplace for firms and customers. Competitive pressures have led to sourcing and manufacturing on a global scale resulting in a significant increase in products. The paper tries to identify the need for real time business intelligence (BI) in supply chain analytics.Design/methodology/approach – The paper provides argument and analysis of the advantages and hurdles in BI.Findings – The paper focuses on the necessity to revisit the traditional BI concept that integrates and consolidates information in an organization in order to support firms that are service oriented and seeking customer loyalty and retention. Enhancing effectiveness and efficiency of supply chain analytics using a BI approach is a critical component in a company's ability to achieve its competitive advantage.Originality/value – This paper furthers understanding of the issues surrounding the use of BI systems in supply chains.	real-time business intelligence	B. S. Sahay;Jayanthi Ranjan	2008	Inf. Manag. Comput. Security	10.1108/09685220810862733	business analysis;supply chain management;value chain;service management;computer science;marketing;operations management;supply chain;business intelligence;management;information system;commerce	AI	-75.75024762831794	5.831976902467705	30229
d1c9be617d5bf8dd16035d65cdfec636e954022e	a framework for cut-over management	release;deployment;itil;it project management;application specific cut over;project specific cut over;go live;release specific rollout;go live preparation;it service management	The purpose of this paper is to provide a governance structure for IT-related projects in order to assure a safeguarded and timely transition to a productive environment. This transitioning, which rarely exceeds a weekend, is colloquially called ‘cut-over’, ‘rollout’ or ‘deployment’. The governance structure is defined in accordance with a set of project-specific deliverables for a cascade-type procedural project-management model, which is integrated within an Information Technology Infrastructure Library (ITIL)-orientated service organization. This integration is illustrated by the use of a semi-agile release model. Due to the release model selected, which is particularly characterized by its bundling of projects for a release-specific rollout (as it is referred to in the project documentation), a new definition and interpretation of deployment from a generic ITIL perspective is required. The facilitated release model requires a distinction between a project-specific cut-over and a release-specific rollout . This separation gives rise to two types of go-live scenarios: one for each participating project and one for each release. Additionally, an interplay between cut-over planning for a project and rollout planning for a release becomes apparent. Projects should already incorporate cut-over related deliverables in the initial planning phase. Even though consulting methodologies such as ASAP (Accelerated SAP), recommend scattered, project-specific deliverables useful for cut-over planning, this publication off ers an integrated approach on how to prepare systematically for a project-specific cut-over with all required deliverables. The framework provided maps out ITIL’s release and deployment process by means of IT projects; furthermore it allows IT projects to interface easily with the ITIL change-management process.		Guido Nageldinger	2015	PeerJ Computer Science	10.7717/peerj-cs.29	simulation;information technology infrastructure library;financial management for it services;it portfolio management;software deployment	Theory	-69.40381975888984	15.148828920821513	30243
b21cdb127bf080a71670d6817e4ed7f9a8b889c1	einige praktische aspekte zu cad und ai bei verfahrenstechnischen problemlösungen		Das digitale Konzept heutiger Rechenmaschinen last lediglich eine Rechenunterstutzung der intellektuellen Tatigkeit beim Design zu, was die Aufnahme des Attributes “Aided” in die Disziplin “Computer Aided Design (CAD)” fordert. Eine weiterreichende Ubernahme intellektueller Anteile durch die Maschine wird durch die Disziplin der “Artificial Intelligence (AI)” gefordert, wobei im Gegensatz zu CAD die praktische Nutzanwendung kein unmittelbares Ziel ist, sondern die Simulation menschlicher Intelligenz primar im Vordergrund steht. Erkenntnisse, die in der Disziplin AI gewonnen wurden, werden zunehmend auch beim CAD zur Verbesserung der Module und zu deren Integration Verwendung finden.	computer-aided design	Gerhard A. Ostertag	1977		10.1007/978-3-642-46361-7_11	systems engineering;software engineering;mathematics	AI	-103.22842233089031	30.501947594416563	30301
3012538e52b16311d839ee042e3a17ed71ccb553	defect prediction using social network analysis on issue repositories	false alarm rate;software development process;defect prediction;network metrics;social network;community networks;social networks;detection rate;social network analysis;developer communication	People are the most important pillar of software development process. It is critical to understand how they interact with each other and how these interactions affect the quality of the end product in terms of defects. In this research we propose to include a new set of metrics, a.k.a. social network metrics on issue repositories in predicting defects. Social network metrics on issue repositories has not been used before to predict defect proneness of a software product. To validate our hypotheses we used two datasets, development data of IBM1 Rational ® Team Concert™ (RTC) and Drupal, to conduct our experiments. The results of the experiments revealed that compared to other set of metrics such as churn metrics using social network metrics on issue repositories either considerably decreases high false alarm rates without compromising the detection rates or considerably increases low prediction rates without compromising low false alarm rates. Therefore we recommend practitioners to collect social network metrics on issue repositories since people related information is a strong indicator of past patterns in a given team.	drupal;experiment;interaction;social network analysis;software bug;software development process;trust metric	Serdar Biçer;Ayse Basar Bener;Bora Caglayan	2011		10.1145/1987875.1987888	computer science;data science;data mining;computer security	Web+IR	-73.30859533507174	26.972435625983618	30304
9f4288cc989d06c257f4c70db853411585a71080	das öiag-unternehmensmodell: ein gesamtmodell für die unternehmensführung				Gerhard Buchinger;Anton Schwarz	1979	Informatik Spektrum		world wide web;software engineering;computer science	NLP	-93.81461402669663	26.143135276209264	30328
f38715d7d2194d8eb9fed252d777603bec484e56	the nature of end-user relationships in the development of electronic commerce applications	electronic commerce;transacting;dyads;ec end user relationships;end user;competitive advantage	The effectiveness of IT departments, and more specifically the developers of electronic commerce (EC) applications, and the value they are adding to their organizations in many cases are hampered by poor relationships between EC professionals and their end users. This situation impacts on EC professionals' ability to produce service and support of high quality that delivers competitive advantage for the company in the electronic commerce environment. This paper looks into the working relationship between EC developers and its end users. It describes EC-end user relationships as intriguing and complex and that these relationships should be seen and managed as multidimensional entities. Two such dimensions, namely the physical and abstract dimensions which form the basis of EC-end user relationships, enable one to fully describe the holistic nature of such relationships and encapsulate the important elements of a support-oriented organization, namely mutuality, belonging, and connection.	display resolution;e-commerce;entity;holism	A. C. Leonard;C. de Villiers	2000		10.1145/333334.333360	knowledge management;marketing;operations management;business	DB	-75.835579634912	6.6182446495196645	30367
2ac249222426d3b4f5f70272d61d94907fc4cd96	internet interconnection techno-economics: a proposal for assured quality services and business models	internet interconnection techno economics quality of service reference business rationale asq internetwork services internet interconnection ecosystem business model design framework key strategic decisions generic collaboration complex business interconnection assured quality services;interconnection;routing;collaboration;biological system modeling;quality of service business data processing internet;future internet;strategy;business model;internet;business biological system modeling internet collaboration routing economics quality of service;business data processing;assured quality service future internet interconnection business model strategy;business;assured quality service;economics;quality of service	"""The Internet is constructed by means of complex business interconnection agreements among multiple networks. However, the most commonly used agreements do not contain explicit Quality of Service reference. In this study a business rationale for Assured Service Quality (ASQ) inter-network services is presented and potential business models for their realization are proposed and analyzed. It is argued that ASQ products and business models could greatly enhance the health of the Internet interconnection ecosystem. A business model design framework that encompasses the key strategic decisions that would enable ASQ provisioning and generic collaboration is also provided. This framework is then elaborated using a number of off-net content delivery scenarios. Conclusions are hence drawn on the role of ASQ and ASQ-driven business models for the sustainable development of the """"Future Internet""""."""	design rationale;digital distribution;ecosystem;future internet;interconnection;provisioning;quality of service	Antonio Ghezzi;Manos Dramitinos;Eleni Agiatzidou;Finn Tore Johansen;Håkon Lønsethagen;Andrea Rangone;Raffaello Balocco	2014	2014 47th Hawaii International Conference on System Sciences	10.1109/HICSS.2014.95	business model;routing;the internet;quality of service;strategy;computer science;artifact-centric business process model;marketing;interconnection;electronic business;management;business rule;new business development;computer network;collaboration	Web+IR	-75.96180420852812	7.097338447177235	30375
bf71d86a6dff53b734d4e8c2e88e28c5e03596f3	organizational slack and information technology innovation adoption in smes	organizational slack;e commerce;information technology;bricolage;innovation;small and medium enterprise;technology adoption;innovation adoption	This study explores the relevant dimensions of organizational slack in small and medium enterprises (SMEs) and investigates their impact on adoption of different types of information technology (IT) innovations. Using recent data from a representative sample of 2,296 U.S. SMEs, we find that the slack-innovation relationships previously described in larger firms do not hold well for SMEs. Our results show potential slack (measured as access to external credit) to be a strong predictor of technology adoption in SMEs. By contrast, available slack appeared not to be a significant factor in SME innovation adoption. Moreover, the direction of the effects of potential slack was moderated by the capital-intensity of the innovation. In particular, e-commerce, which required lesser financial resources for SME adoption, was found to be pursued by those with lesser potential slack. We argue that, in some cases, innovation adoption may represent a form of “bricolage” by resource constrained SMEs.	slack variable	Jaume Franquesa;Alan A. Brandyberry	2009	IJEBR	10.4018/jebr.2009010102	e-commerce;innovation;economics;computer science;marketing;law;information technology;world wide web;commerce	HCI	-82.57286623297708	4.923082261924618	30378
ef0cc8139b959e4134edbcfbe601718397267162	mitteilungen der gesellschaft für informatik 219. folge (fortsetzung)		"""Die künftige Ausgestaltung eines offenen Regierungs-und Verwal-tungshandelns in Deutschland ist Thema eines Memorandums zu ,,Open Government """" , das die Fachgruppe ,,Verwaltungsin-formatik """" der Gesellschaft für Informatik e. V. (GI) herausge-geben hat. Dieses Handeln muss den Voraussetzungen des 21. (volks-)wirtschaftlicher Nutzen sind dazu wichtige Prämissen. Bei ,,Open Government """" geht es unter anderem um einen grundlegenden Paradigmen-und Perspektivwechsel. Immer mehr Bür-ger fordern die Öffnung von Staat und"""	gesellschaft für informatik;memorandum;unified model	Aus Vorstand;Und Präsidium	2012	Informatik-Spektrum	10.1007/s00287-012-0674-8		NLP	-102.79043747287909	34.807207374908764	30385
dddf16b7da612d81668cd9ecb4849ed4edcf4afa	praktiken der nutzerintegration im entwicklungsprozess von kmu	kmu;entwicklungsprozess;uux;nutzerintegration;qualitative studie;talk	Die Vorteile, Nutzer aktiv, früh und langfristig in Entwicklungsprozesse zu integrieren, um Fehlentwicklungen zu vermeiden und Nutzerbedürfnisse zu adressieren, sind nicht nur in der akademischen Forschung bekannt. Prozesse und Strukturen in Unternehmen der IKT-Branche sind bereits häufig agil implementiert. Dennoch schaffen es kleine und mittlere Unternehmen (KMU) oftmals nicht, die Potentiale einer Nutzerintegration konsequent auszuschöpfen. In Fallstudien wurden drei unterschiedliche KMU analysiert, wie sie die Stimme des Nutzers im Entwicklungsprozess berücksichtigen. Unterschiedliche Strategien der Nutzerintegration, die sich in Rollen und Werkzeugen, in Anforderungen und Problemen an das Nutzersample, Methoden und Datenaufbereitung widerspiegeln, werden beleuchtet. Unser Beitrag soll helfen, Herausforderungen und Probleme von KMU auf der Suche nach angemessenen und passgenauen Wegen der Nutzerintegration zu verstehen und Lösungen zu gestalten.	institut für dokumentologie und editorik;internet explorer;sie (file format);unified model	Oliver Stickel;Corinna Ogonowski;Timo Jakobi;Gunnar Stevens;Volkmar Pipek;Volker Wulf	2015				OS	-103.97715957148796	33.2346156824032	30396
e9fdc16646ec69d47f260b50bff959c1f74b9a26	"""die verletzlichkeit der """"informatisierten gesellschaft"""" und die verantwortung der informatiker/innen"""	verletzlichkeit der;verantwortung der informatiker;informatisierten gesellschaft			Klaus Brunnstein	1987				NLP	-97.70610904541542	24.5870634500177	30399
96ed009035a9ce06cf643fc52feaf3a7fe6c51a2	leistungsbewertung und entwurf von transportsystemen in vernetzten rechnern				Andreas Sasse	1994				Vision	-98.4657703901684	24.550506192086075	30407
76fdd654ac08fe4d3f767120e8cb2f445b8f65ec	pain, possibilities, and prescriptions industry trends in advanced functional verification	functional verification;statistical analysis;complex system	Today, many forces at play contribute to the gap between what we can fabricate (silicon capacity) and what we have time to design. In addition, there are forces at play that contribute to a gap between what we can design and what we realistically have time to verify (within a project's schedule). Nonetheless, we tape out complex systems all the time. Hence, the question arises, is the productivity gap real? And if so, what can we do to minimize its effects? This talk provides a statistical analysis of today's industry trends in the adoption of advanced functional verification (AFV) techniques, and then offers new models for improving AFV maturity within an organization.	pain	Harry Foster	2009		10.1007/978-3-642-19237-1_2	complex systems;simulation;computer science;artificial intelligence;software engineering;algorithm;functional verification	Logic	-78.75550249056293	17.442841710287436	30454
41d4c775c5a61deb19482797af95dd178f3a890e	arena: the arena product family: enterprise modeling solutions	enterprise modeling	This paper introduces the Arena suite of products for modeling, simulation, and optimization highlighting product architecture and technology features that are targeted toward successful deployment of simulation and Arena throughout an enterprise.	enterprise modelling;mathematical optimization;simulation;software deployment	Roderick J. Swets;Glenn Drake	2000				Metrics	-63.02588674833975	22.343891378077043	30460
0878a1627c553b867d9b9851c307eccbdfbc39bd	an information systems architecture model for public sector: from data processing state enterprises	data processing;public sector;information system	This paper describes a new framework for information systems (IS) design in public sector. The main goal is to present an information systems architecture (ISA) that comprises the integration of information flow, technology and business processes in public sector environment. First, we discuss the main differences between public and private sectors and their impact on the design of information systems. Issues such as different business goals (profit versus social achievements), discontinuity of administration policies and of staff commitment have direct impact on the success of information systems. This research is composed by three phases: theoretical foundation (information systems; ISA and public sector); case studies and the development of the information systems architecture model for public sector. Two basic questions are addressed: 1. How does an information systems architecture contributes for the information systems development in the public sector? 2. How to combine ISA and software in private and public organizations? The case study is carried in this research to verify the scenery of ISA and IS development process in enterprises. From the evidences fonts of the case study were selected: semi-structured interview and documents. People interviewed were: information managers; software developers and users, to obtain information about the IS development and utilization. Before begin the research, a pilot study was realized to verify the methodology adopted.	business process;enterprise architecture;information system;reflections of signals on conducting lines;semiconductor industry;software developer;software development process;systems architecture	Tania Fatima Calvi Tait;Roberto Carlos dos Santos Pacheco	2000			public relations;marketing;business;information system	SE	-70.36772555577744	5.946881575704634	30494
34cbc4d7851236f7e6727e310abe50336e842164	marketing budget allocation across countries: the role of international business cycles		A key conundrum facing organizations is how to adjust marketing budgets in response to the business cycle. While most firms use procyclical spending (spending less during economic contractions), academic studies often recommend countercyclical spending (spending more during contractions), which begs the following question: What is the right thing to do? The spending problem is compounded further when demand is not just driven by one country’s business cycle, but by the (nonsynchronized) business cycles of multiple countries, as is the case for tourism marketing aiming to attract tourists originating from different countries. We derive insights into the best way to allocate marketing budgets across countries under varying economic conditions. We show that the allocation decisions are driven by the procyclical versus countercyclical nature of three factors: unit sales, marketing effectiveness, and per-unit profit contribution. To study how unit sales and marketing effectiveness respond to the business cycle...		Yuri Peers;Harald J. van Heerde;Marnik G. Dekimpe	2017	Marketing Science	10.1287/mksc.2017.1046	marketing;microeconomics;economics;business marketing;international business;business cycle;marketing effectiveness;tourism;return on marketing investment;recession;new business development	DB	-83.66655716234736	6.239536034037157	30496
303de7dc6a7c1de4b83a3e4e98053353b03bd48b	a clustering approach to the operational resilience analysis of key resource supply chains (krsc): the case of fast moving consumer goods	pattern clustering;critical infrastructures;fast moving consumer goods;operational resilience clustering critical infrastructures fuzzy cognitive maps key resource supply chains;supply chains analytical models resilience solid modeling biological system modeling;fuzzy set theory;supply chain management fuzzy set theory pattern clustering;operational resilience;fuzzy cognitive maps;expert elicitation clustering approach operational resilience analysis key resource supply chains fast moving consumer goods interdependency modeling critical infrastructures fuzzy cognitive map theory impact assessment service disruption temporal frames qualitative approach cognitive approach;clustering;supply chain;key resource supply chains;fuzzy cognitive map;critical infrastructure;supply chain management	This paper presents a novel clustering approach to modeling interdependencies between critical infrastructures (CIs) and key resource supply chains. The approach is based on Fuzzy Cognitive Map (FCM) theory and the assessment of the impact of service disruption between infrastructures and relative supply chains. The authors discuss a pilot case study concerning the impact of infrastructure disruptions for different temporal frames (i.e. after one day, four days and three weeks) on the Fast Moving Consumer Goods (FMCG) supply chain. The study has been conducted affording a qualitative and cognitive approach based on expert elicitation. The paper concludes with a discussion of findings and current train of thought for future improvements of clustering approach.	cluster analysis;denial-of-service attack;fuzzy cognitive map;interdependence	Paolo Trucco;David Ward	2011	2011 IEEE International Conference on Industrial Engineering and Engineering Management	10.1109/IEEM.2011.6118064	supply chain management;fuzzy cognitive map;computer science;systems engineering;marketing;operations management;management science	SE	-81.24942825002157	12.285585132458994	30504
443f2858117ed3014f60e5312423114fb402cfb6	experiences in constructing a level-2 software engineering graduate curriculum	software engineering capability maturity model educational programs production educational products costs software performance software quality engineering management software standards;level 2;education and training;training;software engineering institute;training software engineering graduate curriculum software engineering institute capability maturity model projects software engineering education notional maturity model education;notional maturity model;software engineering;software performance;software engineering education;maturity model;computer science education;engineering management;capability maturity model;educational courses;production;software engineering graduate curriculum;software standards;educational programs;projects;training educational courses computer science education software engineering;educational products;software quality	This paper explores the application of the Software Engineering Institute's Capability Maturity Model to projects in graduate software engineering education. A notional maturity model for education and training is suggested. Actual experiences in injecting and using the model are described.	software engineering	David A. Umphress	1997		10.1109/SEDC.1997.592434	engineering management;personal software process;software engineering process group;systems engineering;engineering;social software engineering;software engineering;software peer review	SE	-65.82217531599844	26.75006832459281	30506
fd1cf24c6e1bda63231be69db8a1f8be995954f4	genetische programmierung einer algorithmischen chemie / von christian w. g. lasarczyk				Christian Lasarczyk	2007				NLP	-97.07571503230228	23.13531529087521	30587
dc560ae4678f175f0834149db085d7e3e1d73f36	using knowledge management to improve software process performance in a cmm level 3 organization	capability maturity model;knowledge management;organisational aspects;software quality;cmm level 3 organization;knowledge management;metric data;organizational software processes;quality software development;software organizations;software process performance improvement;software product quality	Developing quality software products in the schedule and considering planned costs has always been a challenge to software organizations. The quality of a software product depends heavily on the quality of the software process used to develop it. This fact has led organizations to invest in improving their organizational software processes. In this context, knowledge management can be used to support process improvement. We present the knowledge management approach adopted in a CMM level 3 organization to support organizational process tailoring to projects and process improvement based on metric data collected from past projects.	capability maturity model;knowledge management;organizational behavior;software development process	Ricardo de Almeida Falbo;Ligia S. Mota Borges;Fabio Feu Rosa Valente	2004	Fourth International Conference onQuality Software, 2004. QSIC 2004. Proceedings.	10.1109/QSIC.2004.1357957	reliability engineering;personal software process;verification and validation;team software process;software quality management;software engineering process group;software sizing;software project management;computer science;systems engineering;engineering;knowledge management;package development process;social software engineering;software development;software engineering;software construction;software walkthrough;software deployment;software quality control;goal-driven software development process;capability maturity model;software development process;software quality;software metric;software quality analyst;data collection;software peer review	SE	-69.03325623202245	21.142243120665903	30603
d62ce1764909ac2d74f2968758b86b155fcc52b7	das 3-stufige frame-repräsentationsschema - eine mehrdimensional modulare basis für die entwicklung von expertensystemkernen			eine and zwei	Roman Cunis	1992				DB	-100.37631085290907	25.426798640199703	30619
e2189ce9882ad6edbcbe8734ba8375b3b38ee80c	elektronische beweismittelsicherung auf der basis von computer forensik		Zusammenfassung: Die starke Wachstumsrate der Computerkriminalität (laut BKA Zuwachs von 2000 auf 2001 39,8 Prozent) und die hohe Dunkelziffer im Bereich der Wirtschaftskriminalität lässt die Computer Forensik als Instrument der Wiedergewinnung beweiskräftiger Daten und der Identifikation von Beweismaterial auf Computersystemen immer stärkere Bedeutung gewinnen. Zur Sicherung rechtserheblicher Daten sind neben der genauen Kenntnis von Hardund Software festgelegte Sicherungsstrategien und -techniken unerlässlich. Nur die umsichtige, kriminalistisch korrekte Begutachtung am Tatort, forensische Untersuchung geeigneter Originalkopien oder Images der Datenträger und durchgängige Protokollierung führen zu einem beweiskräftigen Resultat.	die (integrated circuit)	Peter Böhret;Reinhold Kern	2003			operating system;history	OS	-103.41728538375062	31.744636561293497	30646
ff186bfdf7af7338e5fc68be015a26c13963a672	nrw-jobverbund im deutschen forschungsnetz - erfahrungen und probleme beim betrieb	nrw-jobverbund im deutschen forschungsnetz			Jan von Knop	1985		10.1007/978-3-642-70285-3_25	software engineering;distributed computing;computer science	DB	-100.46562497739332	29.68315434406242	30901
8cf836dd3d8a28acb3dcd6d0d093adf332c4b648	die dagm - bemerkungen zu ihrer geschichte		Die Deutsche Arbeitsgemeinschaft fiir Mustererkennung (DAGM) wurde am 21.10.1976 in Munchen gegrundet. Als erster Vorsitzender der DAGM wurde ich gebeten, auf dem Dresdner Symposium einen Uberblick uber die Vorgeschichte und Geschichte der DAGM und allgemein uber die Entwicklung der Mustererkennung in Deutschland zu geben. Ich tue dies gerne nach bestem Wissen, mus aber jetzt schon um Nachsicht bitten, wenn ich nicht alle Alctivitaten erfast und gebuhrend gewurdigt haben sollte.		H. Marko	1992			history;performance art	Crypto	-103.9976501835446	34.88491715473198	30997
b5b777294b524ec27e540bdd5e397134a1539152	specification-based testing of reactive software: a case study in technology transfer	usability study;costs and benefits;specification based testing;technology transfer;feasibility study;cost effectiveness;context dependent;technical report	We describe a case study to transfer a specificationbased testing system from research to practice. We did the case study in two steps: first we conducted a feasibility study in a laboratory setting to estimate the potential costs and benefits of using the system. Next we conducted a usability study in an industrial setting to determine whether it would be effective in practice. Our focus in the laboratory was on the basic technology; our focus in the industrial setting has necessarily been on customizing that technology for a specific application. The feasibility study gave us a cost-effective way to identify general, context-independent issues, while the later industrial experience revealed specific, context-dependent obstacles to the use of our technology.	context-sensitive language;usability testing	Lalita Jategaonkar Jagadeesan;Lawrence G. Votta;Adam A. Porter;Carlos Puchol;J. Christopher Ramming	1998	Journal of Systems and Software	10.1016/S0164-1212(97)00170-2	feasibility study;simulation;cost-effectiveness analysis;computer science;systems engineering;engineering;cost–benefit analysis;technical report;context-dependent memory;management science	SE	-89.99772956716711	5.816206297379301	31021
d64eede4bcfe9a0a21acb175e4232a3af6769e1b	using functional defect analysis as an input for software process improvement: initial results	info eu repo semantics conferenceobject;defect data analysis;functional defects;process improvement	In this paper we present how functional defect analysis can be applied for software process improvement (SPI) purposes. Software defect data is shown to be one of the most important available management information sources for SPI decisions. Our preliminary analysis with three software companies’ defect data (11653 defects in total) showed that 65% of all the defects are functional defects. To better understand this mass, we have developed a detailed scheme for functional defect classification. Applying our scheme, defects can be classified with accuracy needed to generate practical results. The presented scheme is at initial stages of validation and has been tested with one software company’s defect data consisting of 1740 functional defects. Based on the classification we were able to provide the case organization with practical improvement suggestions.	cellular automaton;database;lero (software engineering);management information system;software bug;software development process;software engineering	Tanja Toroi;Anu Raninen;Hannu Vainio	2012		10.1007/978-3-642-31199-4_16	reliability engineering;computer science;systems engineering;engineering drawing	SE	-63.064446319426935	27.898108867491622	31031
382f88c785e4e8bc68c9e632567ca5731be9cd4d	to make or to buy? sourcing decisions at the zurich cantonal bank	it strategy;make or buy;banks;organizations;sourcing	The case study describes the IT situation at Zurich Cantonal Bank around the turn of the millennium. Incapable to fulfill the company’s strategic goals, it is shown how the legacy systems force the company into the decision to modify or to replace the old systems with standard software packages: to make or to buy? The case study introduces the bank’s strategic goals and their importance for the three make or buy alternatives. All solutions are described in detail; however, the bank’s decision is left open for students to decide. For a thorough analysis of the situation, the student is required to put himself in the position of the key decision maker at Zurich Cantonal Bank, calculating risks and balancing advantages and disadvantages of each solution. Six video interviews reveal further technical and interpersonal aspects of the decision-making process at the bank, as well as of the situation today.	legacy system;make	Katharina Reinecke;Abraham Bernstein;Stefanie Hauske	2008			organization;marketing;management;commerce	HCI	-74.1727105524857	4.75244461148144	31064
4b552923f374d7ea29721a43c975577842d1b766	hybrid value creation in the sports industry: the case of a mobile sports companion as it-supported product-service-bundle	field test;development process;service industry;production services;value creation;domain specificity;product development	Integrated product-service packages (hybrid products) can open new markets and target groups to companies. However, existing approaches to service or product development do not sufficiently address simultaneous development and domain-specific issues. A very promising new field for such bundles is the health and fitness industry. In this research, we designed and built an IT-supported training system for running, the Mobile Sports Companion (MSC), which closely interlocks a product and corresponding services using an iterative development process. We tested the pilot system with 14 recreational athletes. The results of the field test show that the MSC proved to be a promising tool to offer athletes an effective individual, flexible, and mobile training. However, the system, as it is, did not sufficiently represent the human trainer behind it, thus lowering its acceptance and the credibility of its recommendations. Our next step is to integrate features that could strengthen the athlete-trainer relationship. The MSC could turn out to be a promising field for future e-business applications in the sports service industry.	electronic business;iteration;iterative and incremental development;new product development	Jan Marco Leimeister;Uta Franziska Knebel;Helmut Krcmar	2010	IJISSS	10.4018/jisss.2010093002	tertiary sector of the economy;simulation;economics;engineering;marketing;operations management;management;software development process;new product development	HCI	-66.54080738203244	20.21854508056353	31096
84075221cac7b549d9f25a728d60ed1f7c5989db	metodologia e ferramentas para paralelização de laços perfeitamente aninhados com processamento heterogêneo				Cleber Silva F. da Luz	2018				Vision	-106.07569615529135	18.07327297201041	31162
d4e879ba1584fab3fadadc3616e5c7feb9e97d56	"""""""die meisten angriffe setzen eine gewisse naivität und gutgläubigkeit der benutzer voraus"""""""			eine and zwei		2016	Wirtschaftsinformatik & Management	10.1007/s35764-016-0012-z		OS	-101.08284626805916	27.907094518409746	31188
3633018c867caf70010cc655dbd9a064139347d7	strategic information revelation in collaborative design		Abstract Confidentiality preservation is of high concern in collaboration, which may involve the flow of sensitive information between collaborators. This concern is a potential barrier to forming collaborations that may otherwise enhance each collaborator’s individual contribution, and raises the need to study the trade-off between value gain and confidentiality loss from information exchange. In this paper, we analyze this trade-off by considering different revelation strategies in a collaborative design scenario. We propose a framework that provides a guideline for designers to evaluate their respective revelation strategies and thus make better decisions when choosing a particular revelation strategy in a design iteration. This framework utilizes concepts from Bayesian updating and quantifies the confidentiality lost and value gained for a particular revelation, providing a mathematical abstraction of the collaborative design process as a sequence of information revelation decisions. We illustrate the use of our proposed framework in an automobile suspension design scenario, and show the changes in performance (Alice’s and Bob’s objective function responses) and confidentiality (KL divergence) for each.		Adam Dachowicz;Siva Chaitanya Chaduvula;Mikhail J. Atallah;Ilias Bilionis;Jitesh H. Panchal	2018	Advanced Engineering Informatics	10.1016/j.aei.2018.04.004	engineering;systems engineering;management science;information exchange;information sensitivity;guideline;revelation;confidentiality;design process;abstraction;bayesian inference	HCI	-82.41646346096523	15.421240996244478	31256
aa69077778a0787660f63b54ba83be045a120592	recherche approximative de plus proches voisins		La recherche du0027images par le contenu au sein de grandes bases de donnees est un processus notoirement couteux. Il su0027avere que lu0027on peut fortement reduire ce cout si lu0027on effectue des recherches approximatives. Cet article propose une nouvelle methode de recherche approximative de plus proches voisins (ppv) qui permet un controle fin de la precision de la recherche. Ce controle su0027exprime au travers du0027un seul parametre qui indique la probabilite maximale de ne pas retrouver un des ppv exacts. Nous montrons de plus que cette methode est particulierement bien adaptee au cas de la recherche du0027images decrites par des descripteurs locaux. Dans ce cas, la multiplicite des descripteurs par image compense totalement lu0027imprecision de la recherche.		Sid-Ahmed Berrani;Laurent Amsaleg;Patrick Gros	2003	Technique et Science Informatiques	10.3166/tsi.22.1201-1230	database;computer science;performance art	Logic	-106.22650326432948	15.050432639361421	31269
1f5236342f0969c7ab59d02811fd686ab9673402	challenges of software recontextualization: lessons learned	management system;change management;recontextualization;lessons learned;software development;campus management systems;participatory design;business information systems;user involvement;software development and deployment	This paper describes the case of a complex and problem-ridden software development and deployment process: The implementation of a Campus Management system at a large university. Based on an understanding of software development as recontextualization process on the technical, organizational, human, and task level, critical factors for success or failure are analyzed. Results show that deficits in change management and organizational support account for a considerable amount of difficulties in the implementation process. Furthermore, individual characteristics and commitment of the users involved play a major role. Lessons learned for software introduction processes are discussed.	change management (engineering);management system;software deployment;software development	Monique Janneck	2010		10.1145/1753846.1754202	personal software process;change management;software engineering process group;software project management;knowledge management;social software engineering;software development;change management;software as a service;management system;management science;systems development life cycle;software walkthrough;software analytics;management;software deployment;software development process;software peer review	SE	-68.44748842787507	20.452060655126278	31276
4e96b3bdaa2cd6feb2625c901ed66aa27989e02b	an organizational assessment process in support of enterprise transformation	role assessment;enterprise transformation;assessment process span;organizational behavior;organizational assessment;assessment process;enterprise transformation process;next assessment cycle;five-phase assessment process model;organizational assessment process;assessment result	This paper provides a model of organizational assessment that in support of enterprise transformation. We argue that the assessment process spans beyond performing the assessment itself. For the assessment to provide the expected benefit, organizations must first of all create an environment ensuring a clear understanding of the role assessment plays in the enterprise transformation process. To this end they must promote open and frequent discussion about the current state of the enterprise and future goals. The assessment process must be carefully planned to ensure it runs effectively and efficiently and that assessment results are accurate and reliable. Assessment results must be analyzed and turned into specific recommendations and action plans. At the same time, the assessment process itself must be evaluated and adjusted, if necessary, for the next assessment cycle. Based on literature review and case studies of four large aerospace companies, we recommend a five-phase assessment process model that includes mechanisms to change organizational behavior through pre-assessment phases. It also allows for adjustment of the assessment process itself based on the results and experience of participants so that it better suits the organization's needs and practices.		Leyla Abdimomunova;Ricardo Valerdi	2010	Information, Knowledge, Systems Management	10.3233/IKS-2010-0165	systems engineering;engineering;knowledge management;operations management	DB	-69.67683741400376	19.6899186003267	31290
c57ca07413acbd160dc63eb82b7341a0dce16b4b	analyse et synthèse de l'implémentation de lois de contrôle-commande en précision finie- étude dans le cadre des applications automobiles sur calculateur embarquée -. (analysis and synthesis of the finite word length implementation of linear controllers or filters.- application to embedded automotiv			embedded system;string (computer science)	Thibault Hilaire	2006				Crypto	-103.60199503807148	15.731863227473058	31311
db13e721f3646b15b689602c9bcf258017667203	evolving taxonomy of business models for mobile service delivery platform	comparative analysis;business models;classification	The state of mobile technology and its widespread use has evolved drastically within the past several years. Cell phones with small monochrome displays – designed solely for phone calls and text messaging – have turned into miniaturized computers with dual-core processors. Combined with 3G standards such as UMTS, mobile devices nowadays offer almost the same freedom in exploring the Internet as desktop PCs do. Apple’s iPhone, Google’s Android, and the availability of mobile broadband Internet have changed the mobile landscape, and therefore the way in which mobile services are delivered to their users. Thus, we focus in this paper on the theory and implementation of four distinct platform models for mobile service delivery. Furthermore, we perform a classification of platform agility features, business and technology oriented, along with a comparative analysis of their effectiveness. © 2012 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of [MobiWIS-2012]	android;central processing unit;closed system;desktop computer;electronic business;email;itil;internet;internet access;mobile device;mobile phone;monochrome;multi-core processor;niche blogging;operating system;portals;qualitative comparative analysis;smartphone;surface web;symbian	Alexander Becker;A. Mladenowa;Natalia Kryvinska;Christine Strauss	2012		10.1016/j.procs.2012.06.083	mobile search;simulation;mobile web;gsm services;operating system;mobile technology;multimedia;mobile business development;mobile computing;world wide web;mobile payment	Mobile	-81.81573257556612	11.211051565495008	31346
18c4086c884031d25a0b871afef365ed8c940f4e	wisdom or madness? comparing crowds with expert evaluation in funding the arts	arts;theater	In fields as diverse as technology entrepreneurship and the arts, crowds of interested stakeholders are increasingly responsible for deciding which innovations to fund, a privilege that was previously reserved for a few experts, such as venture capitalists and grant-making bodies. Little is known about the degree to which the crowd differs from experts in judging which ideas to fund, and, indeed, whether the crowd is even rational in making funding decisions. Drawing on a panel of national experts and comprehensive data from the largest crowdfunding site, we examine funding decisions for proposed theater projects, a category where expert and crowd preferences might be expected to differ greatly. We instead find significant agreement between the funding decisions of crowds and experts. Where crowds and experts disagree, it is far more likely to be a case where the crowd is willing to fund projects that experts may not. Examining the outcomes of these projects, we find no quantitative or qualitative differences between projects funded by the crowd alone and those that were selected by both the crowd and experts. Our findings suggest that crowdfunding can play an important role in complementing expert decisions, particularly in sectors where the crowds are end users, by allowing projects the option to receive multiple evaluations and thereby lowering the incidence of “false negatives.”	benchmark (computing);crowdfunding;crowdsourcing;incidence matrix;madness;relevance;the wisdom of crowds	Ethan Mollick;Ramana Nanda	2016	Management Science	10.1287/mnsc.2015.2207	public relations;actuarial science;political science;management	HCI	-85.8603558740515	6.2462552134673786	31373
b91385e3cd4470e4579b94e8ad1a843f31a2ee65	programmverifikation unter verwendung der formalisierten darstellung der algorithmischen idee				Horst Friedrich	1984				Theory	-97.98607967008103	24.756543212251312	31396
e58df7c2d02df31c12f44de6bf3f4da189eab70e	"""does power matter in implementing ios integration? the """"transalation"""" and the obligatory passage point perspective"""	translation	IOS integration (IOSI) is becoming a competitive necessity in an industrial environment that emphasizes competition between supply chains. In the supply chain, dominant firms often try to exert their power to influence their dependent firms to implement IOSI. Misunderstanding about how power operates will impede firms for developing IOSI. Based on the circuits of power framework and the concept of obligatory passage point (OPP), this study identifies three factors that should mediate the effect of power on the implementation of IOSI, including competitive necessity, expected benefits, and firm readiness. We accordingly develop a theoretical model with nine hypotheses. Based on a sample of 135 manufacturing firms, seven out of the nine hypotheses receive empirical support using PLS. The findings show that the flows of exercised power and potential power into IOSI indeed circulate through those mediators. The theoretical and practical implications of the results contribute a better understanding of how power operates in developing IOSI.	open prosthetics project;partial least squares regression;theory;ios	Neil Chueh-An Lee;Eric T. G. Wang;Jeffrey C. F. Tai	2014				HCI	-82.08867360504189	5.086978511439493	31514
507b9eb6373a2e6edfa8003c7f29f35995d73248	an analysis of technical debt management through resources allocation policies in software maintenance process		This paper presents an analysis of technical debt management through resources allocation policies in software maintenance process during its operation to demonstrate how different strategies leads to the emergence of different behaviors along the evolution path. To achieve this objective, this work used the System Dynamic approach for building a computational simulation model based on extensive literature review and secondary data. Most of the works that applied the System Dynamics on software projects research, focused on initial phases of its life cycle, leaving a gap to be explored regarding the long-term behaviors of the operation and maintenance phases. The results demonstrated that the excessive focus on the perfective maintenance activities could be more costly than performing regular preventive maintenance to reduce the technical debt incurred, ending up with fewer functionalities deployed, higher backlog, lower productivity, lower maintainability and higher technical principal.	business requirements;computation;emergence;overhead (computing);simulation;software maintenance;system dynamics;technical debt;tree accumulation	Eduardo Ferreira Franco;Joaquim Rocha;Hamilton Carvalho;Martins Marcelo;Kechi Hirama	2016	CoRR		systems engineering;engineering;management science;management	AI	-70.85136691488472	19.916915269947875	31517
37f725cf7dd9c54746c229cfc15ebeddd1d63521	a novel approach to quantifying the influence of software process on project performance	null	Determining the appropriate process to be used is a key ingredient of project management. To this end, understanding the influence of activities on the project performance can facilitate the project management. However, quantifying such a relationship via traditional Multiple Linear Regression method tends to be challenging, for the amount of independent variables (activities in software process) is usually larger than the size of dataset. Aiming at such a problem, in this paper we propose a novel approach. By combing the Dantzig selector and Ordinary Least Squares (OLS) regression method, our approach can derive the regression model in such challenging situations, which further set the theoretical stage for studying the quantitive influences of software process on project performance.	acquiring bank;dantzig–wolfe decomposition;ordinary least squares;software development process;xfig	Jia-kuan Ma;Xiao-fan Tong;Ya-sha Wang;Gang Li	2011			systems engineering;empirical process;goal-driven software development process	AI	-70.82451936693364	23.253446549832507	31523
78ba7586427568f3be4664b51ac659a4c819ca9c	a proposal for the improvement of project's cost predictability using evm and historical data of cost	cpi;hypothesis tests;earned value management;cost performance index;project management;statistical control;mathematical model;accuracy;software metrics;statistical analysis	This paper proposes an extension of the Earned Value Management EVM technique through the integration of historical cost performance data of processes under statistical control as a means to improve the predictability of the cost of projects. The proposed technique was evaluated through a case-study in industry, which evaluated the implementation of the proposed technique in 22 software development projects Hypotheses tests with 95% significance level were performed, and the proposed technique was more accurate and more precise than the traditional technique for calculating the Cost Performance Index - CPI and Estimates at Completion - EAC.	software development	Adler Diniz de Souza	2013	2013 35th International Conference on Software Engineering (ICSE)		project management;reliability engineering;systems engineering;engineering;management;cost estimate;statistics	SE	-65.13675108417608	29.842956717379735	31600
76fac92b2d8812424ea9836fe1a7a1c379867dd8	enterprise soba: large-scale implementation of acceptance test driven story cards	agile software development;project management;technological innovation;story card based agile software development;soba;project manager;enterprise software development;testing;project management extreme programming story card based agile software development acceptance test driven story cards soba enterprise software development;testing enterprise soba acceptance test driven story cards agile software development waterfall based approaches extreme programming estimation communication requirements gathering;software engineering;acceptance test driven story cards;extreme programming;requirements gathering;computer architecture;large scale;waterfall based approaches;estimation;enterprise soba;software development;planning;communication;programming;large scale systems programming profession software testing project management asset management technological innovation feedback scalability computer architecture documentation	Agile software development has proven to be an effective alternative to the regimentation of waterfall-based approaches. Recent research by Patel and Ramachandran [17] has led to the innovation of Acceptance Test Driven Story Cards (SoBA). Implemented using Extreme Programming, preliminary findings show SoBA retains essential Agile attributes like feedback, flow and universal responsibility for quality [3] whilst delivering improvements to estimation, communication, requirements gathering and testing.	acceptance testing;agile software development;extreme programming;requirement;requirements elicitation;test-driven development;while	Patrick Onions;Chetankumar Patel	2009	2009 IEEE International Conference on Information Reuse & Integration	10.1109/IRI.2009.5211600	planning;project management;programming;requirements analysis;estimation;extreme programming;knowledge management;software development;software engineering;agile software development;database;software testing;management;world wide web	Robotics	-67.23357117090416	25.558109418432288	31601
4a570efdd608489071be2d10a6c2d07b3be7332a	konzept zur ausnahmebehandlung für funktionale programmiersprachen und dessen formale beschreibung				Manfred Bretz	1989				Vision	-101.10436230968594	25.83472114889904	31619
0fc2b637e260ac26d9288fe04cb352e428ea045c	empirical analysis of programming language adoption	survey research;programming language adoption	Some programming languages become widely popular while others fail to grow beyond their niche or disappear altogether. This paper uses survey methodology to identify the factors that lead to language adoption. We analyze large datasets, including over 200,000 SourceForge projects, 590,000 projects tracked by Ohloh, and multiple surveys of 1,000-13,000 programmers.  We report several prominent findings. First, language adoption follows a power law; a small number of languages account for most language use, but the programming market supports many languages with niche user bases. Second, intrinsic features have only secondary importance in adoption. Open source libraries, existing code, and experience strongly influence developers when selecting a language for a project. Language features such as performance, reliability, and simple semantics do not. Third, developers will steadily learn and forget languages. The overall number of languages developers are familiar with is independent of age. Finally, when considering intrinsic aspects of languages, developers prioritize expressivity over correctness. They perceive static types as primarily helping with the latter, hence partly explaining the popularity of dynamic languages.	(formerly ohloh);correctness (computer science);library (computing);niche blogging;programmer;programming language;reliability engineering;sourceforge;type system	Leo A. Meyerovich;Ariel S. Rabkin	2013		10.1145/2509136.2509515	natural language processing;fourth-generation programming language;computer science;third-generation programming language;programming paradigm;programming language;second-generation programming language;comparison of multi-paradigm programming languages	PL	-64.69351542133295	36.70426027424775	31624
1410dac879664dff6dc8d68eb470e9123968c8d9	l'optimisation par essaim particulaire				Maurice Clerc	2002	Technique et Science Informatiques		distributed computing;computer science	NLP	-100.5173466373328	16.999449515888163	31729
b9aee8caa7399df76e887f3b72772446d4e6cd70	marketing für investive service-leistungen				Werner H. Engelhardt;Martin Reckenfelderbäumer	1996	HMD - Praxis Wirtschaftsinform.		knowledge management;marketing;engineering	NLP	-93.01298031062865	24.10259109785351	31730
055a1576a260018e1296429575f2b4a48248430d	an exploratory study of the impact of information technology investment announcements on companies' values in japan	stock market;information technology;stock price;event study;business value;exploratory study;market value;information technology investment	This paper presents the results of an exploratory study that examined a possible connection between investments in Information Technology and changes in the market value of companies in Japan. The eventstudy methodology, which focuses on the change of stock price as a result of announcements about Information Technology investments, was applied. The main contribution of this project was to examine the connection between Information Technology investments and their perceived business value in Japan, where relatively little research on this topic was conducted. The results indicate that in Japan, the stock market may respond in different ways to similar announcements about investments in Information Technology.	exploratory testing	Narcyz Roztocki;Atsuko Imai	2003			finance;business;commerce	HCI	-83.53529524229559	5.305886418588778	31753
32d73f5894ff4d48e2cdb8fd6b3478c9c0aebf29	agile quality requirements engineering challenges: first results from a case study		Agile software development methods have become increasingly popular in the last years. Despite their popularity, they have been criticized for focusing on delivering functional requirements and neglecting the quality requirements. Several studies have reported this shortcoming. However, there is little known about the challenges organizations currently face when dealing with quality requirements. Based on a qualitative exploratory case study, this research investigated real life large-scale distributed Agile projects to understand the challenges Agile teams face regarding quality requirements. Eighteen semi-structured open-ended in-depth interviews were conducted with Agile practitioners representing six different organizations in the Netherlands. Based on the analysis of the collected data, we have identified nine challenges Agile practitioners face when engineering quality requirements in large-scale distributed Agile projects that could harm the implementation of the quality requirements and result in neglecting them.	agile software development;functional requirement;nonlinear gameplay;real life;requirements engineering;semiconductor industry	Wasim Alsaqaf;Maya Daneva;Roel Wieringa	2017	2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)	10.1109/ESEM.2017.61	systems engineering;computer science;requirements engineering;software;functional requirement;agile software development;government;scrum	SE	-66.70517597567802	23.446636287139295	31758
33f5170298353d5a1008fae77d7653919207047d	"""ein mediendidaktischer ansatz zur verknüpfenden vermittlung von fach- und medienkompetenz in der beruflichen qualifizierung - modellprojekt """"effekt"""""""				Sigrid Salzer	2011				Crypto	-99.51555331079682	26.799488945927372	31766
51af71a52a59d252fa7338ffdc35d9873eb0f82e	supply chain collaboration model based on drum-buffer-rope philosophy		Within supply chain, orders variation is a more often expressed, which creates disruptions along chain links, not only in the effective orders management, but also in global supply chain collaboration. In this approach, the research team proposes a collaboration model between chain links, respectively, formalization orders management based on the methodology theory of constraints (TOC) using Drum-Buffer-Rope (DBR) strategy. This model is analyzed and exemplified within the pages of this paper. The solution provided by philosophy TOC through DBR in supply chain focuses on exemplifying the delegation phenomenon of internal stock level at different chain links, when there are very small variations in customer order.	drum memory	Gabriela Prostean;A. Badea	2014		10.1007/978-3-319-18416-6_82	systems engineering;knowledge management;operations management	NLP	-75.7593468082534	8.61879515045632	31789
4154144307004907953a84f4423efcbf628e1dee	nubb: a network usage-based billing system	usage based billing;billing model;bandwidth;service design;data service	Beginning with the 2003-2004 academic year, Cornell University implemented a new billing model for data service designed to provide a fair and equitable rate structure for all users -- a Network Usage-Based Billing (NUBB) system where users pay according to the bandwidth they consume. This model ensured that network costs were covered, including anticipated upgrades, and that the costs were distributed in a way that reflected the usage patterns around campus. Now a mature billing model, this paper examines how this system was structured and implemented at Cornell, the support and administration required, the impact of changing to this system, customer perception of and response to the change, and its' effect on bandwidth utilization and management.	bandwidth management;computer security;disaster recovery plan;electronic billing;file sharing;overhead (computing);reduced cost;surround sound	M. Scott Walters	2005		10.1145/1099435.1099529	engineering;marketing;burstable billing;world wide web;computer security	Networks	-85.41544990129877	19.18550900689023	31811
91e0e7c879b37779b221a97058938c32c16d559e	rechnernetze in der industriellen produktion				Hartwig U. Steusloff	1987	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1987.10.1.6	computer science;distributed computing	Vision	-95.38455499512516	24.066154352223478	31814
63933a1549073bc4a290d62e7ed7b07b1782f37d	evaluation of usage-based reading—conclusions after three experiments	reading technique;perceived quality;empirical study;usage based reading;reading;software engineering;empirical evidence;datavetenskap datalogi;programvaruteknik;point of view;usage based;empirical evaluation;software inspection	Software inspections have been introduced in software engineering in order to detect faults before testing is performed. Reading techniques provide reviewers in software inspections with guidelines on how they should check the documents under inspection. Several reading techniques with different purposes have been introduced and empirically evaluated. In this paper, we describe a reading technique with the special aim to detect faults that are severe from a user’s point of view. The reading technique is named usage-based reading (UBR) and it can be used to inspect all software artefacts. In the series of experiments, a high-level design document is used. The main focus of the paper is on the third experiment, which investigates the information needed for UBR in the individual preparation and the meeting of software inspections. Hence, the paper discusses (1) the series of three experiments of UBR, (2) the individual preparation of the third experiment, and (3) the meeting part of the third experiment. For each of these three parts, results are produced. The main results are (1) UBR is an efficient and effective reading technique that can be used for user-focused software inspections, (2) UBR is more efficient and effective if the information used for UBR is developed prior to, instead of during the individual preparation, and (3) the meeting affects the UBR inspection in terms of increased effectiveness and decreased efficiency. In summary, the empirical evidence shows that UBR is an efficient and effective reading technique to be used by software organizations that produce software for which the user perceived quality is important.	experiment;high- and low-level;level design;software design description;software engineering;software inspection	Thomas Thelin;Per Runeson;Claes Wohlin;Thomas Olsson;Carina Andersson	2004	Empirical Software Engineering	10.1023/B:EMSE.0000013515.86806.d4	simulation;empirical evidence;computer science;engineering;software engineering;software inspection;empirical research;world wide web;reading	SE	-64.37199428926147	32.628005990889115	31820
da36cdceeff5a164cd5aaebef3f9c436bafcab56	post-deployment data: a recipe for satisfying knowledge needs in software development?	agile software development;software development;post deployment data;software usage data	In the field of improving software processes, one of the clear trends has been the ever tighter engagement of end users in the software development process. This is demonstrated by the shift from Agile processes to Continuous Deployment, which requires more rapid ways to validate the developed software and its value than is possible with traditional communication mechanisms and methods, such as face to face conversations with customers. While post-deployment data has been used for years as an extra data source - companies like Microsoft and Intuit have moved a few steps further from that already - we believe that there are numerous uncovered ways of taking advantage of post-deployment data in software development. In this paper, we study how automatically collected post-deployment data could be used for responding to knowledge needs of software development teams. The paper builds on data collected from a number of companies operating in Finland using a questionnaire study. The focus of questionnaire study was to approach post-deployment data - especially usage data - as means of getting information to support understanding of customer and end users.	adobe streamline;agile software development;continuous delivery;debugging;problem solving;software deployment;software development process;software engineering;usage data	Sampo Suonsyrjä;Laura Hokkanen;Henri Terho;Kari Systä;Tommi Mikkonen	2016	2016 Joint Conference of the International Workshop on Software Measurement and the International Conference on Software Process and Product Measurement (IWSM-MENSURA)	10.1109/IWSM-Mensura.2016.029	personal software process;long-term support;verification and validation;team software process;computer science;systems engineering;package development process;backporting;social software engineering;software development;software design description;software construction;software as a service;data mining;database;software walkthrough;empirical process;software analytics;lean software development;software deployment;goal-driven software development process;software development process;software metric;software peer review	SE	-69.3283005951982	25.030541845181425	31867
dcd425a83a248c3f93b030cafd9bf0cc48c32e52	important factors in erp systems implementations: result of the research in polish enterprises		In the article the problem of success factors in ERP systems implementations has been discussed. The review of the literature concerning success factors has been discussed and the collection of potential ERP implementation success factors was identified. Next, the result of research has been presented, where respondents have been asked about their opinion about the importance of subsequent factors for the implementation success. There were two groups of respondents: the first consisted of people from Polish enterprises implementing ERP systems and the second comprised experts working in ERP systems suppliers. On the basis of the research, the most important and necessary factors in the respondents’ opinions have been identified, as well as the least important ones.	erp;enterprise resource planning	Piotr Soja	2004				DB	-79.60337698255357	8.564991558334366	31914
ae7305f0eeb4208ae55170143f1859523c2b4194	entscheidbarkeit der theorie der linearen ordnung in l				Heinrich Herre;Helmut Wolter	1977	Math. Log. Q.	10.1002/malq.19770231802	pure mathematics;combinatorics;mathematics	DB	-95.44489040149124	34.30045261353043	31922
ea2e0c2e0f8f56a2fad2769c9a620d442d7513bd	shaping internet governance - regulatory challenges		ROLF WEBER ist eine der führenden Gestalten im europäischen Informationsrecht. Er hat sich schon sehr früh aufgrund seiner verschiedenen akademischen und anwaltlichen Kontakte für Fragen der Internet-Governance interessiert und hierzu profunde Monografien veröffentlicht. Ein solches Meisterwerk findet sich jetzt auch in dem vorliegenden Band über die regulatorischen Zugehensweisen zum Internet. Sehr schön werden zunächst einmal die verschiedenen Governance-Zugänge für die Informationsgesellschaft beschrieben (S. 1 ff.). Abgegrenzt werden hier vor allem die völkerrechtlichen Anstrengungen zur Verabschiedung internationaler Verträge (S. 11 ff.) von Ansätzen einer Selbstregulierung, einschliesslich einer Problematisierung der Schwächen eines solchen Ansatzes (S. 17 ff.). Dann folgt ein sehr wertvoller Abschnitt zu der historischen Entwicklung der internationalen Diskussion um Internet-Governance, insbesondere im Rahmen des WSIS (S. 25 ff.). Der organisatorische Rahmen der Internet-Governance wird ebenso beschrieben, voran die Sonderstellung des Icann (S. 39 ff.).	eine and zwei;lol;noise shaping;unified model;vhf omnidirectional range	Rolf H. Weber	2010		10.1007/978-3-642-04620-9	public relations;environmental resource management;political science;management science	OS	-101.12812482871664	34.69232955805316	31925
d435875526a8f4ae9953edfa988947136d7b432b	measuring and assessing software test processes using test data	software metrics;effectiveness software test process measurement software test process assessment large scale software systems technical issues managerial issues cost effectiveness continuous monitoring consistent measurement process oriented metrics based assessment pomba test problems dependent variables test intensity independent variables year 2000 problem transaction software systems test planning setup activities;software testing software measurement system testing large scale systems software systems phase measurement helium monitoring programming costs;data integrity;large scale systems program testing software metrics data integrity transaction processing;program testing;transaction processing;large scale systems	* This work was partially supported by the U. S. Army Research Laboratory under the contract DAKF-11-99-P-127. Abstract Testing of large-scale software systems is a complex and expensive process that involves both technical and managerial issues. To improve its cost-effectiveness, the process should be continuously monitored, consistently measured, and carefully assessed. This paper proposes an assessment methodology, called process-oriented metrics-based assessment (POMBA), towards this direction. Novel concepts include considering test problems as one of the dependent variables of the test process and the use of test intensity as one of the independent variables. As a proof-of-concept, the methodology is applied to test data collected from highlevel Y2K tests of seven large-scale transaction software systems. It is found that, in testing large-scale software, test problems that prevented completion of tests due to insufficient test planning and setup activities tend to occur frequently. This not only wastes resources but also affects the effectiveness of the overall process.	software system;software testing;test data;test plan	Yutao He;Herbert Hecht;Raymond A. Paul	2000		10.1109/HASE.2000.895470	reliability engineering;verification and validation;regression testing;test data generation;transaction processing;system integration testing;computer science;systems engineering;package development process;software reliability testing;software construction;test suite;data integrity;database;software testing;system under test;test script;software measurement;software deployment;test case;test management approach;software metric;software system;test harness	SE	-63.05994387474127	31.075050562598438	31946
43dc0a380872f8c8f32cf97bb811a321d86b9f63	analysis of macro-micro simulation models for service-oriented public platform: coordination of networked services and measurement of public values	public infrastructure;service orientation;small and medium size enterprise;business environment;service industry;economic impact;evaluation methodology;developing country;service sector;network services;public service;simulation model	When service sectors are a major driver for the growth of the world economy, we are challenged to implement service-oriented infrastructure as e-Gov platform to achieve further growth and innovation for both developed and developing countries. According to recent trends in service industry, it is clarified that main factors for the growth of service sectors are investment into knowledge, trade, and the enhanced capacity of micro, small, and medium-sized enterprises (MSMEs). In addition, the design and deployment of public service platform require appropriate evaluation methodology. Reflecting these observations, this paper proposes macro-micro simulation approach to assess public values (PV) focusing on MSMEs. Linkage aggregate variables (LAVs) are defined to show connection between macro and micro impacts of public services. As a result, the relationship of demography, business environment, macro economy, and socio-economic impact are clarified and their values are quantified from the behavioral perspectives of citizens and firms.	aggregate data;aggregate function;e-government;linkage (software);service-oriented device architecture;service-oriented infrastructure;simulation;software deployment	Yumiko Kinoshita	2009		10.1007/978-3-642-04280-5_26	environmental resource management;service delivery framework;operations management;service design;business;service economy;commerce	Web+IR	-76.88726922330717	6.242626100107258	31953
e363518dd71e433af65b343a4bd5f5d998715b91	un modelo simple para la detección del juicio de implicación textual entre sentencias		Resumen En el presente trabajo se propone un modelo para descubrir el juicio de implicación textual entre sentencias que incluye el juicio de contradicción. Se propone la selección de un conjunto de características léxicas, sintácticas y semánticas para la conformación de un modelo de clasificación. Los datos tanto de prueba como de entrenamiento fueron ofrecidos en el marco de la conferencia internacional Semeval 2014.	linear algebra;semeval	Saúl León;Darnes Vilariño Ayala;David Pinto;Mireya Tovar;Beatríz Beltrán	2014	Research in Computing Science		mathematics	Crypto	-107.4958585572515	14.526419344452991	31963
ca0020053771d6a2587b2f3149873dfd1fefacfb	dimensioning virtual organizations based on risk levels		In an increasingly competitive market, small and medium enterprises have the option to take advantage of collaboration opportunities to consort their core competencies to achieve an objective. In fact, this is the purpose of the so-called Virtual Organizations (OVs), which aim to attend a goal joining partner forces. However, when these Virtual Organizations are created, it is necessary to deal with the maximum number of participants involved in the process and the risk involved in these relationships, which should be measured through a well-defined process. This paper aims to present an approach to dimensioning the number of participants involved in the formation of a Virtual Organization composed of several service providers (SPs). This approach is based on the overall risk level of the participants and uses different Risk Analysis Methods to assess the suited number of participants to be part of a Virtual Organization.		Jonathan Emannoel Ferreira;Adriano Fiorese	2016		10.1007/978-3-319-31232-3_32	process management;service provider;core competency;virtual organization;small and medium-sized enterprises;business;risk analysis (business);dimensioning;perfect competition	HCI	-77.52196309346336	9.209752687259613	31976
13de6d19af2af16414e2375455e580d906ac189a	developing an environmental management information system to foster sustainable decision-making in the energy sector		We develop an environmental management information system (EMIS) that provides economic and environmental data to suppliers and consumers of electrical energy. This information-sharing fosters sustainable decision-making in accordance with individual preferences and results in time-shifting energy consumption, which ultimately improves the alignment of power supply and demand. In turn, this enhances the integration of renewable energy systems, reduces the use of fossil fuels, and increases energy efficiency. We develop the EMIS based on established architectures and embed it into the Energy Informatics Framework, where it is supposed to operate at the interface of energy supply and demand in a smart grid environment. To conceptualize, design, and evaluate the developed system, we rely on the well-acknowledged research methodology of design science. In line with that, we demonstrate the utility of the EMIS and discuss its benefits regarding sustainability aspects by means of a comprehensive scenario analysis. To sum up, the proposed EMIS applies the promising integration of energy and IS research by means of Energy Informatics and responds to the necessity of incorporating environmental sustainability aspects into both corporate and consumer decision-making.	education management information system;energy informatics;environmental resource management;fossil;power supply;scenario analysis;whole earth 'lectronic link	Christian Nuss	2015			environmental management system;knowledge management;environmental resource management;environmental sustainability index;sustainability;energy management	Robotics	-70.56501995707191	7.497778710432571	32031
fbeb7eb7c93a850fa146be3de7f409b58225a349	city-logistik der zukunft - im spannungsfeld von elektromobilität und digitalisierung		Die Anforderungen an den Transport von Gütern und insbesondere deren Distribution in urbanen Gebieten verändern sich mit zunehmender Geschwindigkeit. Anhaltende Globalisierung, kürzere Produktlebenszyklen, Urbanisierung und neue Technologien sind Treiber dieser Veränderungen. Hinzu kommen die wachsende Bedeutung des Onlinehandels, steigende Kundenanforderungen hinsichtlich Geschwindigkeit, Flexibilität und Qualität der Belieferung, sowie ein steigendes Umweltbewusstsein in der Bevölkerung. Zunehmende Auflagen in Städten, beispielsweise in Bezug auf die Reduktion von Lärm-, CO2oder Feinstaubemissionen sollen die Lebensqualität in Ballungszentren sichern und stellen vor allem Unternehmen des Wirtschaftsverkehrs vor zusätzliche Herausforderungen.	vhf omnidirectional range	Frank Straube;Jan Reipert;Dustin Schöder	2017	Wirtschaftsinformatik & Management	10.1007/s35764-017-0053-y		OS	-104.2041886515029	32.37897243256012	32067
7970b4e791316d0e70ad8b312ae9e6afbbb42684	automatische synthese von familienmodellen durch analyse von block-basierten funktionsmodellen		Um die steigende Komplexität in der Softwareentwicklung in der Automobilindustrie zu beherrschen, werden immer öfter modellbasierte Entwicklungsansätze, zum Beispiel mit block-basierten Modellen, genutzt. Modellvarianten werden dabei nicht selten durch Kopieren und Anpassen erzeugt. Dies führt zu einer Modellfamilie mit unterschiedlichen, aber verwandten Modellen und erschwert die Wartung, Qualitätssicherung und Weiterentwicklung der Modelle. In diesem Aufsatz wird ein Ansatz präsentiert, mit dem Unterschiede und Gemeinsamkeiten einer Modellfamilie automatisch gefunden und in ein Familienmodell überführt werden können. Das Familienmodell ermöglicht eine einheitliche Darstellung von Gemeinsamkeiten und Unterschieden aller Modelle und erleichtert so die Wartung, das Refactoring und die Qualitätssicherung der Modellvarianten.	code refactoring;eine and zwei;unified model	Sönke Holthusen;Peter Manhart;Ina Schaefer;Sandro Schulze;Christian F Singer;David Wille	2013			computer science	OS	-103.02042467614709	32.14421485309094	32085
dda723c15607714fa6f49cb516c1906421047e6a	rechtliche aspekte der nutzung von elektronischen gesundheitsdaten		Welche Regelungen auf europäischer Ebene bestimmen den Umgang mit elektronischen Gesundheitsdaten? Wie begegnen EU-Mitgliedsstaaten den Herausforderungen von elektronischer Patientenakte und elektronischem Rezept? Können Daten für Forschungszwecke genutzt werden?	gesellschaft für informatik;internet explorer	Sebastian Reimer;Jörg Artmann;Karl A. Stroetmann	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0052-y	internet privacy;computer science	ML	-103.70720891017625	36.207336145131805	32115
d93aed35b69ccc45b2feb2c0feb5381f8edd1a63	unix passwords			crypt (unix);password;unix	Douglas G. Conorich	1998	Information Systems Security	10.1201/1086/43302.7.1.19980301/31024.4		Security	-94.2871268077823	30.26481746337207	32149
bdee17fc346e772cc36b45a1aac92cccfeec0cb2	vorausschauende betriebsstrategie von hybridfahrzeugen mit backend-anbindung				Andreas Sauer;Franz Perschl;Hermann Rottengruber	2016	Automatisierungstechnik		engineering;control engineering;software engineering	Crypto	-93.29213937775958	25.583894009472154	32154
494ce7da88a4594065cfcd0f4fe313a7b47d8d3a	imprecisions diagnostic in source code deltas		Beyond a practical use in code review, source code change detection (SCCD) is an important component of many mining software repositories (MSR) approaches. As such, any error or imprecision in the detection may result in a wrong conclusion while mining repositories. We identified, analyzed, and characterized impressions in GumTree, which is the most advanced algorithm for SCCD. After analyzing its detection accuracy over a curated corpus of 107 C# projects, we diagnosed several imprecisions. Many of our findings confirm that a more language-aware perspective of GumTree can be helpful in reporting more precise changes.		Guillermo De la Torre;Romain Robbes;Alexandre Bergel	2018	2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)	10.1145/3196398.3196404	data mining;computer science;mining software repositories;software;change detection;source code;code review	SE	-63.7541230124172	35.97250528298495	32172
0ece481316ae18d1048043b24cea45c0242c1459	das projekt coagens aus sicht der sedus stoll ag				H.-J. Molter;Ulrich Pape;Michael Rüther	2003				NLP	-98.81480612691385	25.03586814357339	32174
a8e7d5edea3bc1096b59856e829ce67aefcc08db	guest editors' introduction: methods innovations for the empirical study of technology adoption and diffusion	technology adoption;methods innovation;empirical study;guest editor	The literature on technology adoption and diffusion is a highly mature area of Information Systems (IS) research, which requires a deft hand in research to support the creation of new contributions of knowledge. In this special issue, we focus on the application of various methods, including new ones, to shed light on research questions that have not been understood fully in prior research. In particular, we will showcase research that involves the application of event history analysis and spatial econometrics, as well as count data models to study frequencyrelated phenomena for changes and development in technology adoption and diffusion. We also include an article that employs game theory, as well as another work that begins with a market event study and then utilizes a blend of seemingly unrelated regression, two-stage least squares and three-stage least squares estimation. Finally, we include a new contribution on product diffusion that uses agentbased computational simulation of different user network structures. The lead-off article of the special issue focuses on new methods for empirical research in IS and e-commerce through the application of advanced econometric models that are underutilized in the literature. The title is ‘‘Event History, Spatial Analysis and Count Data Methods for Empirical Research in Information Systems,’’ and has been contributed by the special issue editors, Robert J. Kauffman and Angsana A. Techatassanasoontorn, and their coauthor, Bin Wang. The article showcases statistical analysis methods for empirical settings involving technology, information systems (IS) and e-commerce adoption. The salient characteristics of the research involve the time when an adoption event occurs, the duration of time between adoption events, the extent to which geographic or conceptual space influences adoption, and the relative frequency of adoption events over time. The authors provide a road map for understanding how different models can be applied across a number of core research areas in IS, and additional detailed and specific aspects of empirical settings in which they can be used to generate new knowledge. They also provide a reading on research that has occurred outside the IS and e-commerce areas, as a basis for illustrating the kinds of new knowledge that can be generated through the collection and analysis of interesting data sets. The authors draw several conclusions, including one that is especially relevant in another context—computational social science in the presence of large-scale data. The methods will be especially useful in support of the analysis of very large-scale data when events, time, space and frequency of outcomes are essential to understand. The next article is entitled ‘‘Analysis of Emerging Technology Adoption for the Digital Content Market,’’ contributed by Bih-Huang Jin and Yung-Ming Li. The authors begin by citing a research forecast from PricewaterhouseCoopers on the future state of the global entertainment and media market, which, they note, is expected to grow from US $1.3 trillion in 2009 to about US $1.7 trillion by 2014, representing approximately 5 % growth per annum. This growth in the digital content market is a new target for all kinds of information and services, and there are key issues related to service transformation and emerging technology adoption that require the attention of R. J. Kauffman Singapore Management University, Singapore, Singapore e-mail: rkauffman@smu.edu.sg	computation;computational social science;count data;data model;digital recording;e-commerce;econometric model;email;game theory;information system;least squares;ming li;plan;simulation;simultaneous equations model;spatial analysis	Robert J. Kauffman;Angsana A. Techatassanasoontorn	2012	Information Technology and Management	10.1007/s10799-012-0140-y	computer science;management science;management	HCI	-70.61252540308033	6.897424443781524	32187
e2fb5e5f129793b53c4606908cd513228b2e264b	the politics of standards and the ec	informatica;legislation;politica industrial;north america;america del norte;amerique du nord;amerique;normalisation;etats unis;cee;estados unidos;aspecto juridico;organismo normalizacion;legislacion;harmonization;legal aspect;organisme normalisation;normalizacion;technical barriers to trade;statistics;standardization institution;informatique;aspect juridique;eec;computer science;america;data flow;politique industrielle;standardization;harmonisation;industrial policy;transborder data flow;national institute of standards and technology	European legislation and power struggles in the standards arena are sparking fear of technical barriers to trade and prompting the American standards community to reevaluate its infrastructure. The National Institute of Standards and Technology may step up its role in order to negotiate at a governmental level with the EC.		Karen A. Frenkel	1990	Commun. ACM	10.1145/79204.79208	data flow diagram;industrial policy;computer science;standardization;statistics	HCI	-109.4587673325132	12.918510902286327	32208
a2d226fcadc408cf6ad942119f0f8c47d1fe7f0e	correction d'assemblages de composants impliquant des interfaces paramétrées		HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L’archive ouverte pluridisciplinaire HAL, est destinée au dépôt et à la diffusion de documents scientifiques de niveau recherche, publiés ou non, émanant des établissements d’enseignement et de recherche français ou étrangers, des laboratoires publics ou privés. Correction d’assemblages de composants impliquant des interfaces paramétrées Pascal André, Christian Attiogbé, Mohamed Messabihi	archive;comefrom;component-based software engineering;correctness (computer science);gene ontology term enrichment;hal;linear algebra;software development	Pascal André;Christian Attiogbé;Mohamed Messabihi	2009			performance art;philosophy	Crypto	-106.90967587809612	11.848587619552319	32231
e7ce4a2b778e52d2b5810d7af935b945e27989f5	software crowdsourcing for developing software-as-a-service	xiaolan xu wenjun wu ya wang yuchuan wu 软件外包 软件开发 框架模型 竞争网络 竞争性 生态系统 需求分析 代码实现 software crowdsourcing for developing software as a service;saas software crowdsourcing topcoder	Recently software crowdsourcing has become a viable development paradigm for Software-as-a-Service (SaaS) ecosystems. TopCoder, one of the largest competitive programming communities, enables enterprises to tap into its global talent pool and crowdsource a variety of SaaS development tasks including requirement analysis, architecture design, code, and testing. Many researchers have proposed auction-based modelling methods to characterize general software crowdsourcing. But there are few papers on the comprehensive analysis of SaaS crowdsourcing process and developer community. This paper introduces a holistic analysis framework to model the SaaS-oriented software crowdsourcing from two dimensions: individual behavior in crowdsourcing contests and collective competition in the community. The framework includes a game-theoretical model to describe the competitive nature of software crowdsourcing process. Moreover, the framework defines a competition network to characterize the topological properties of a crowdsourcing community for SaaS development. The analysis of this model indicates that the success of a competitive software crowdsourcing project essentially depends upon the networks of key participants with sufficient skills and dedication for the project. This is validated by a large historical data collected from the Top-Coder website over a ten-year period.	cloud computing;cloud storage;collective intelligence;competitive programming;crowdsourcing;ecosystem;holism;programming paradigm;requirements analysis;software as a service;software development;theory	Xiaolan Xu;Wenjun Wu;Ya Wang;Yuchuan Wu	2015	Frontiers of Computer Science	10.1007/s11704-015-4900-9	crowdsourcing software development;computer science;data science;software as a service;world wide web	Web+IR	-76.88509574623883	6.182187614407208	32295
9e718eabbd20b6d774cc25dd6201989633d17249	análisis comparativo de metodologías orientadas a agentes basado en evaluación de perfiles		En los últimos años han sido presentados varios trabajos de evaluación de metodologías orientadas a agentes abarcando enfoques cualitativos y cuantitativos y diferentes tipos de evaluaciones. Si bien estos estudios han presentado algunos resultados interesantes, sería particularmente relevante para el área poder contar con mejores instrumentos de comparación entre las evaluaciones actualmente disponibles que permitan incrementar la confiabilidad con respecto a los estudios existentes. Para el efecto, en este trabajo se propone la utilización de técnicas de análisis comparativo de perfiles, en particular calculando los coeficientes de Congruencia y Similaridad Configuracional, para corroborar eventuales similitudes entre evaluaciones de distintos autores y de distintas metodologías. Además, este tipo de análisis podría ser de utilidad para la elección de una metodología que tenga cierto nivel de Congruencia con respecto a un perfil ideal o deseado, ya sea en términos generales o por constructo (conjunto de criterios relacionados).	bibliothèque de l'école des chartes;han unification;linear algebra;naruto shippuden: clash of ninja revolution 3;power-on reset;unique name assumption	Luca Cernuzzi;Oscar Serafini;Roberto Sánchez;Michelle Chelli;Franco Zambonelli	2005			software engineering;systems engineering;computer science	Crypto	-107.19013022699465	17.97531087388091	32319
f54afdbb64287220af1fe62393fb29a80810b6c6	entwicklung eines flexiblen kraftwerksprogramms s.o.kr.a.t.e.s. mit simultanem lösungsverfahren in zusammenhang mit der untersuchung moderner kraftwerkskonzepte				Klaus Werner	1990				Crypto	-100.71651031908392	25.859720292250383	32323
fe32573bd576b331ce7bc4a06db1cc640771ed1e	aerodynamic and thermal modelling of effusion cooling in les. (modélisation aérodynamique et thermique des plaques multiperforées en les)				Romain Bizzari	2018				Crypto	-103.02409077245972	16.806237672960993	32333
84a66f6fb1b15da6b37aa4cf65af44b7f751de7d	anwendungsgerechte funktionalität von dv-systemen: simultanes und an prozessen orientiertes arbeiten		Anhand von zwei konkreten Beispielen aus dem Bereich der Produktentwicklung und Produktionsvorbereitung wird aufgezeigt, wie veranderte Organisationsstrukturen und Arbeitsablaufe zu veranderten Anforderungen an eine DV-technische Unterstutzung der betroffenen Mitarbeiter fuhren. Wissensbasierte Systeme konnen — entsprechend in existierende Anwendungssysteme eingebunden — in diesem Zusammenhang einen wesentlichen Beitrag zur Realisierung anwendungsgerechter Systemfunktionalitat liefern. Abschliesend werden Fragen bzgl. der Auswirkungen dieser Softwaretechnologie sowie der daraus folgenden Konsequenzen fur die Systementwicklung diskutiert.		K.-W. Jäger;N. Kratz	1993		10.1007/978-3-642-78486-6_29		Robotics	-104.64097948983317	32.68697364803646	32388
ea43e05b6c41ed5a3636101f21a581ce1183530a	experimental software engineering should concentrate on software evolution	experimental software engineering;software evolution	For the future of software engineering it is critical that we devote sufficient energies to software evolution commensurate with its socioeconomic implications. We propose that the area of experimental software engineering focus more on software analysis and understanding to reflect the needs of large, evolving software systems properly. Since the results of evolution experiments do not necessarily scale up, we argue that the experiments should be performed in situ using large systems such as telephone switching systems, banking systems, or health information systems which evolve naturally over decades. We outline two evolution experiments which aim to measure time and effort spent for certain evolution tasks using different software analysis and understanding strategies. Finally, our position is summarized by three theses.	experimental software engineering;software evolution	Hausi A. Müller	1992		10.1007/3-540-57092-6_111	personal software process;verification and validation;software engineering process group;software sizing;software verification;systems engineering;engineering;package development process;social software engineering;component-based software engineering;software development;software engineering;process engineering;software construction;software walkthrough;resource-oriented architecture;software deployment;software requirements;software system	SE	-66.47682424656725	24.638073915475996	32397
0cc3cd0c8f1f7db10e7284356250fc9c9c2a3d9a	applying agile practices to drive continuous improvement: a measured approach	continuous improvement;business value;competitive advantage	Successful businesses must sustain a competitive advantage and consistently deliver business value. In order to maximize business value, software projects must meet the challenge of delivering the right solution at the right time with high quality at the lowest cost. This requires a constant focus on eliminating waste, improving productivity and adapting to changing business needs.	agile software development;business requirements;display resolution	Robert Begg;Nazim H. Madhavji	2009		10.1145/1723028.1723100	business requirements;business value;management science;new business development;competitive advantage	DB	-70.0569505772248	21.94142340337995	32402
30c3c847f64abf6d16686b87d80b2a80410dcbe9	möglichkeiten der elektronischen datenverarbeitung in einem operativen bereich: darstellung am krankengut der universitätsfrauenklinik essen von 1973 bis 1983				Änne Erna Elfriede von Schöning	1988				Theory	-102.31993887441055	26.51996090919922	32428
51cc2237c1be4d7b4bb1e12f9c55def3b89e988a	krypto-angriffe über seitenkanäle		Alle Programme, die auf Computern und Mikrochips ausgeführt werden, auch Krypto- Algorithmen, beeinflussen physikalische Parameter der Hardware wie zum Beispiel den Stromverbrauch. Über solche sogenannten Seitenkanäle können Geheimnisse, die auf einem Chip verarbeitet werden, wie z. B. kryptographische Schlüssel, extrahiert werden. Um zu sicheren Implementierungen zu gelangen, muss dieser Angriffspfad berücksichtigt und entsprechende Gegenmaßnahmen während der Entwicklung getroffen werden.	internet explorer;unified model	Hermann Drexler;Lars Hoffmann	2014	Datenschutz und Datensicherheit - DuD	10.1007/s11623-014-0298-z	internet privacy;computer science		-104.16094148762177	35.89327070741928	32461
a45b887fa31e3f6de88f9b0d9ea30c06ae38073c	generisches verfahren zur präzisen pfadverfolgung für serienfahrzeuggespanne		In Anbetracht der fortschreitenden Automatisierung im Guterverkehr ist auch der Einsatz von Serienfahrzeugen erstrebenswert. Aus wissenschaftlicher Sicht besteht diesbezuglich ein Bedarf an prazisen und echtzeitfahigen Regelungsverfahren, die auch fur Fahrzeuge mit einachsigem Anhanger ein exaktes Abfahren vorgegebener Pfade insbesondere bei ruckwartsgerichteten Fahrmanovern gewahrleisten. In diesem Beitrag wird ein zweistufiges Regelungsverfahren vorgestellt, das diese Kriterien erfullt und sich generisch auf verschiedene Fahrzeuge des gleichen Gespanntyps ubertragen lasst. Daruber hinaus kann das vorgestellte Verfahren als Grundlage fur das autonome oder assistierte Fahren fungieren.	gesellschaft für informatik	Christian Schwarz;Christian Weyand;Dieter Zöbel	2009		10.1007/978-3-642-10284-4_13		Robotics	-104.80754760172995	32.03765971604589	32471
fe61fbabd80a05d711938459801fbd24b3f6004b	a robust optimization approach to the next release problem in the presence of uncertainties	search based software engineering;robust optimization;next release problem	The next release problem is a significant task in the iterative and incremental software development model, involving the selection of a set of requirements to be included in the next software release. Given the dynamic environment in which modern software development occurs, the uncertainties related to the input variables of this problem should be taken into account. In this context, this paper presents a formulation to the next release problem considering the robust optimization framework, which enables the production of robust solutions. In order to measure the “price of robustness”, which is the loss in solution quality due to robustness, a large empirical evaluation was executed over synthetical and real-world instances. Several next release planning situations were considered, including different number of requirements, estimating skills and interdependencies between requirements. All empirical results are consistent to show that the penalization with regard to solution quality is relatively small. In addition, the proposed model’s behavior is statistically the same for all considered instances, which qualifies it to be applied even in large-scale real-world software projects.	algorithm;ant colony optimization algorithms;best, worst and average case;control flow;control theory;eclipse;interdependence;iteration;iterative and incremental development;mathematical optimization;metaheuristic;nurse scheduling problem;open-source software;particle swarm optimization;penalty method;procedural generation;requirement;requirements engineering;robust optimization;robustness (computer science);software bug;software development process;software engineering;software quality assurance;software release life cycle	Matheus Paixão;Jerffeson Souza	2015	Journal of Systems and Software	10.1016/j.jss.2014.09.039	mathematical optimization;robust optimization;simulation;search-based software engineering;computer science;statistics;robustness	SE	-66.90927284016051	28.986256664158454	32500
54995d101ba4cfb3711c853e01267fa602572fdc	exploitation de la supervision faible pour l'analyse des vidéos. (leveraging weak supervision for video understanding)			exploit (computer security);linear algebra	Cristina Garcia Cifuentes	2012				Crypto	-104.92052582313801	14.256888656000392	32523
5cff732c13f15f32f9bbc2b310ec5bfc45de79b9	recommended practice: systems of systems considerations in the development of systems	iterative development systems of systems systems development technical cooperation program ttcp international organization systems engineering iso 15288;system or systems;risk system or systems system acquisition;risk;systems engineering iso standards organisational aspects;system acquisition	This paper presents the results of an international collaboration under The Technical Cooperation Program (TTCP), an international organization which collaborates on technical exchange and shared research. Developed under the Systems of Systems Work Stream of the Technical Panel on Systems Engineering and Modernization. Using ISO 15288 as a framework for integrating across the practical experiences of the nations, these recommended practices bring together the collective knowledge from across the US, UK, Canada and Australia on the SoS considerations that need to be addressed at key points in the system development process. The recommended practices are intended for use by systems engineers, program managers and acquisition oversight organizations in government and industry engaged in the development of defense systems in particular, but apply generally across large systems in other domains as well. The recommended practices were developed over a three year process of iterative development with activities in each nation with each iteration to review, apply and refine the information along with open input from industry and academia.	apple sos;iso/iec 15288;iteration;iterative and incremental development;system of systems;systems engineering;ttcp	Judith Dahmann;Ase Jakobsson;Kristen J. Baldwin;Denis Bertrand	2015	2015 Annual IEEE Systems Conference (SysCon) Proceedings	10.1109/SYSCON.2015.7116805	system of systems;system of systems engineering;systems engineering;engineering;knowledge management;software engineering;systems development life cycle;information system	SE	-69.68788983486503	17.632330843085064	32578
1de5c5b2a217ebef4ab5c828ff5e7e9190c83f66	una metodología a dos niveles para extender el metamodelo de uml			unified modeling language;unique name assumption	Josep M. Ribó Balust;Xavier Franch	2002			programming language;unified modeling language;computer science;extender	Crypto	-108.35677404622275	19.121210458263352	32583
3eb1eac00d634f82bab3e2a71b0fc4204136d736	unterstützung varianter strukturen in einem erweiterten relationalen datenmodell				Christian Kalus	1995				Vision	-98.75061321005205	24.140442134773323	32606
2ffbf6c1426e100c720cb3e831638bac56fb9d1b	vorwort der herausgeber				Timo Schmid;Markus Zwick	2017	AStA Wirtschafts- und Sozialstatistisches Archiv	10.1007/s11943-017-0204-x		NLP	-95.34674412163926	21.29693651042329	32612
6805f0650d6d199ccc5a73d158cf264bf120abac	mischen und wischen		So gut wie kein Unternehmen kann ohne es auskommen, das regelmasig stattfindende Strategiemeeting namlich. Es scheint ein Naturgesetz zu sein, dass ab und zu die generelle Richtung uberpruft und neu bestimmt werden muss. Das gilt erst recht in unternehmerisch schwierigen Zeiten, wo das Uberleben der Institution stark gefahrdet zu sein scheint. Das Alte muss verwischt und die Karten mussen neu gemischt werden. „Mischen und Wischen“ („Mission and Vision“) nennt man den entsprechenden Vorgang in Umkehrung der eigentlich logischer scheinenden Wisch-Misch-Reihenfolge. Das heist: Es sind sowohl missionarische als auch visionare Ergusse zur Perestroika (deutsch: Umgestaltung) gefordert. Ob sich solcherlei Bestrebungen dann aber in den Unternehmensalltag umsetzen lassen, steht auf einem vollig anderen Blatt.		Alois Potton	2009	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.2009.0015	computer science;computer network;performance art	NLP	-105.42166680583655	33.0104947498238	32615
0de0b5247ebeb5acfa55953fda627b873d155e7c	methoden zur epidemiologischen auswertung von mortalitätsdaten und ihre anwendung in der praxis			altran praxis	Nikolaus Becker	1983				Vision	-101.67156527343263	25.303231318041004	32632
167a0cce9c87dab7b988b4b095c9f028d28003c4	homogenized and analytical models for the diffusion mri signal. (modélisation du signal de l'irm de diffusion par des techniques analytiques et d'homogénéisation)				Simona Schiavi	2016				Vision	-103.09654853420777	17.133792838895612	32671
439814fe277f8409c0eb9b60b1addbc7d68e92e6	verbesserung der detektion sphärischer marker für die optische navigationschirurgie		In der computerund roboterassistierten Chirurgie werden aufgrund ihrer Flexibilität und Genauigkeit vorwiegend optische Navigationssysteme eingesetzt. Hierbei handelt sich um Stereokameramesssysteme die an Patienten und OPInstrumentarium angebrachte – normalerweise sphärische – retroreflektierende Marker messen, verfolgen und Lokalisationsaufgaben navigierter chirurgischer Eingriffe lösen. Dir Grundlage dieses Messprozesses bildet die Markerdetektion in aufgenommenen Kamerabildern. Zur Verbesserung der erzielbaren Navigationsgenauigkeit müssen Marker auch bei unvollständiger Erfassung, z.B. aufgrund von Verdeckungen oder Verunreinigungen, zuverlässig und präzise detektiert werden können. In diesem Beitrag präsentieren wir einen Algorithmus zur robusten und genauigkeitssteigernden Erkennung sphärischer Marker in Grauwertbildern. Unser Ansatz kann zuverlässig hochgradig verdeckte Marker in Bildern lokalisieren und deren Mittelpunktskoordinaten und Durchmesser präzise bestimmen. Schlüsselworte: Optische Navigationschirurgie, Marker-basiertes Tracking, Maschinelles Sehen, Computerund Roboterassistierte Chirurgie	unified model	Elmar Garcia;Christian Sültrop;Tino Hausotte	2011				HCI	-105.9186719263486	31.890871305606897	32676
bf2f2fb6103c94a676dd81f4acb2f03a666f9034	mejora de los procesos software utilizando simulacion e integracion de tecnicas		Resumen: Los modelos de procesos actuales como CMM, SPICE y otros recomiendan la aplicación de control estadístico y de guías de métricas para la definición, implementación y posterior evaluación de diferentes mejoras del proceso. Sin embargo, precisamente en este contexto no se ha considerado lo suficiente el modelado cuantitativo, reconocido en otras áreas como un elemento esencial para la adquisición de conocimiento. En este trabajo se describe la base conceptual y fundamental para el desarrollo de un marco enfocado a la mejora de procesos software que combina las técnicas de estimación tradicionales con la utilización extensiva de modelos dinámicos de simulación como herramienta para asesorar en el proceso de evolución entre los diferentes niveles de madurez propuestos por el modelo de referencia CMM. Tras una introducción a los conceptos fundamentales del modelado y simulación del proceso software y la justificación para la creación de dicho marco, se abordan las cuestiones necesarias para su desarrollo, tales como el enfoque conceptual y su estructura, prestando especial atención al paradigma de desarrollo de los modelos dinámicos de simulación que le dan soporte.	bibliothèque de l'école des chartes;capability maturity model;clara.io;dead sea scrolls;han unification;journal of systems and software;lh (complexity);linear algebra;naruto shippuden: clash of ninja revolution 3;power-on reset;putnam model;spice;simmons–su protocols;simulation;software engineering institute;software project management;system dynamics;unique name assumption	Mercedes Ruiz;Isabel Ramos;Miguel Toro	2001			operating system;software;computer science	Security	-107.49225019568017	17.912852854957713	32711
5d245a1152e71e3d0f0f57ea153f35ee32719b36	skinning vs. usability vs. branding	skinning;personalisierung;branding;informationsgestaltung;other;usability		internet branding;usability	Claudia S. Friedrich	2008			engineering;multimedia;advertising;engineering drawing	NLP	-96.38156826364083	29.352459846777805	32721
6d091c13730bb5dd8ddd365bf71a00fe92e61597	verwaltung hierarchisch-strukturierter dokumente mit dql.			doctrine	Detlev Ruland;Klaus Peter Kratzer	1988	Inform., Forsch. Entwickl.		software engineering;database;computer science	Crypto	-93.48847432361949	25.237584195547633	32753
201e5f4ac52124ec6fdf0801c92814f1296b8a31	research of scm system based on the internet of things on epc	radiofrequency;management system;companies;supply chain scm system internet of things epc system;supply chains;hot spot;internet of things;supply chain management internet;internet;scm;warehousing;supply chain;internet supply chains radiofrequency identification companies warehousing;radiofrequency identification;supply chain management;epc;the internet of things;scm epc the internet of things	Recently the research on the technology of the internet of things has become the hot spot, and how to lead it into the management system is the most difficult. The use of EPC system in the SCM system is the hot spot in the supply chain araa presently. This article has raised a conception and the basic framework of the Internet of Tings, and focused on the analysis to the Internet of Things especially the Chang Xiang SCMS, then clarify the application of principles of the EPC system in the SCM, finally interpret the details of the construction of the system and describe the implementation of the system.	electronic product code;hotspot (wi-fi);internet of things	Ying Xue	2011	2011 2nd International Symposium on Intelligence Information Processing and Trusted Computing	10.1109/IPTC.2011.59	supply chain management;supply chain;internet of things	Arch	-66.27332789417233	5.020950274175963	32810
b7a1aa610c0beada47759fca48ddd24a0ed84b86	a literature review on approaches for the retrospective utilisation of data in engineering change management		The paper provides a comprehensive literature research regarding the field of data analysis in engineering change management. The focus is on a posteriori analysis methods of engineering change data. After an introduction to the topic, identified a posteriori data analysis procedures in the engineering change management are listed and supplemented by further a priori analysis procedures. Furthermore, the a posteriori data analysis methods presented are compared on the basis of a catalogue of requirements.		Armin Tale-Yazdi;Niklas Kattner;Lucia Becerril;Udo Lindemann	2018	2018 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)	10.1109/IEEM.2018.8607569		DB	-66.28294283572639	12.630229220803011	32817
918b7acb4a0e75fab76661499363cbbc62d33938	kontraktbasiertes black-box testen von webservices		Mit der Webservice-Technologie erhält der zur Zeit bei weitem bekannteste und verbreitetste Umsetzungsversuch des SOA-Paradigmas verstärkten Einzug in die Praxis ([8]). Durch die plattformunabhängige und einfache Kombinierbarkeit von lose gekoppelten, auf standardisierter Webtechnologie basierenden Komponenten scheint man dem Ziel frei kombinierbarer, wiederverwendbarer und gut wartbarer Software ein Stück näher gekommen zu sein.	altran praxis;web service	Michael Averstegge	2007			heat transfer;alkyl;polyol;freon;polymer chemistry;hydrogen atom;benzotriazole;chemistry	Crypto	-100.7719435457958	27.86032970886957	32843
e55096ddf8aebb1eb4e19a77dff858770b1aa807	qualitätssteigernde maßnahmen bei der entwicklung von software-systemen im bauwesen durch objektrelationen				Udo Kolender	1997				Crypto	-100.16044303825677	25.375158891236953	32862
3da7267799692378e922bef8ef028f3eebcef96b	black box statt big brother: datenschutzkonforme videoüberwachung unter bdsg und dsgvo			black box	Jan-Michael Grages;Kai-Uwe Plath	2017	Computer und Recht	10.9785/cr-2017-1206	black box (phreaking);brother;performance art;history	Crypto	-96.6426053863384	26.492805347030572	32873
3bedcbbd910a2ecd7a12708aacb8ccab7c8c6800	ein formales modell für den entwurf von flexiblen kommunikationssystemen			v-model	Jiong Ou;Peter Brunmayr;Jan Haase;Christoph Grimm	2010				Theory	-103.45751976756495	26.050767597992486	32906
f2384ac20ecb732bfed7a70d7320a4cc8513f6ea	insidedog: the head: virtuelle realität in der veterinäranatomie				Nicolas Blanck	2003				NLP	-99.56787847722975	23.49385063702942	32961
10e887664b0e9d0b193e8dc8e92f6f1a8bfba5e5	the complementarity of information technology infrastructure and e-commerce capability: a resource-based assessment of their business value	back-end it infrastructure;business value;e-commerce capability;e-commerce investment;front-end e-commerce capability;firm performance;it infrastructure;business value;it payoff literature;information technology infrastructure;e-commerce capability;resource-based theory;it business-value literature;resource-based assessment	This study seeks to assess the business value of e-commerce capability and information technology (IT) infrastructure in the context of electronic business at the firm level. Grounded in the IT business-value literature and enhanced by the resource-based theory of the firm, we developed a research framework in which both the main effects and the interaction effects of e-commerce and IT on firm performance were tested. Within this theoretical framework, we formulated several hypotheses. We then developed a multidimensional e-commerce capability construct, and after establishing its validity and reliability, tested the hypotheses with empirical data from 114 companies in the retail industry. Controlling for variations of firm size and subindustry effects, our empirical analysis found a strong positive interaction effect between IT infrastructure and e-commerce capability. This suggests that their complementarity positively contributes to firm performance in terms of sales per employee, inventory turnover, and cost reduction. The results are consistent with the resource-based theory, and provide empirical evidence to the complementary synergy between front-end e-commerce capability and back-end IT infrastructure. Combined together, they become more effective in producing business value. Yet the value of this synergy has not been recognized in the IT payoff literature. The “productivity paradox” observed in various studies has been attributed to variation in methods and measures, yet we offer an additional explanation: ignoring complementarities in business value measurement implies that the impact of IT was seriously underestimated. Our results emphasized the integration of resources as a feasible path to e-commerce value—companies need to enhance the integration between front-end e-commerce capability and back-end IT infrastructure in order to reap the benefits of e-commerce investments.	complementarity (physics);complementarity theory;e-commerce;electronic business;synergy	Kevin Zhu	2004	J. of Management Information Systems		e-commerce;economics;computer science;marketing;operations management;business value;management;world wide web;commerce	HCI	-81.1980921140148	5.575144269831847	32966
7f8f348bae6194bb23629d45598f8c20f01a59cc	inférence des acteurs de la régulation des expressions géniques. (the inference of gene expression regulator actors)			bibliothèque de l'école des chartes;linear algebra	Laetitia Bourgeade	2015				Crypto	-102.3872612234111	11.663559435275236	33002
1c60e25ffa9ab36452b5f982cb15b87d32756791	incorporating innovation management practices to iso/iec 29110		Studies on Innovation management are often focused on large compa‐ nies and organizations. On the other side, small companies or VSE (Very Small Entities), constitute a significant part of the entrepreneurial landscape, and contribute – in a great extent – to the economic outputs of society and to the creation of employment. This is also valid for the system and software engineering business areas. Larger systems being built and deployed across Europe are usually built with the participation of small enterprises or research centers whose contri‐ butions have a key role in the resulting systems. Although these companies are sensitive to the importance of systematic innovation, most of the innovation models are targeted to large or medium enterprises and do not consider the specific characteristics of the system and software engineering industries. In this particular business area, innovation must consider two separate dimensions: (a) the oppor‐ tunities to innovate that system and software development companies may offer to their customers and prospects, and (b) the application of techniques to innovate in the software development processes, to achieve better performance and leverage process capabilities and company productivity. Both dimensions require a systematic integration of the innovation management processes with the mana‐ gerial and engineering processes of the organizations. This paper proposes an extension of the process model described in the ISO/ IEC 29110 standard to enable innovation management processes and activities addressed to VSE. The innovation activities and tools incorporated into the resulting model are based on existing innovation models, and on the feedback collected through interviews and surveys with different software development companies. SPEM (System and Software Process Engineering Metamodel) has been used as a process design framework to encode the resulting model and formally integrate innovation, managerial and engineering processes for VSE.	capability (systems engineering);encode;emoticon;entity;iso/iec 27002;iso/iec 42010;meta-process modeling;metamodeling;process modeling;software development;software engineering	Ricardo Eito-Brun	2017		10.1007/978-3-319-64218-5_2	process management;software development;leverage (finance);software development process;innovation management;business	SE	-69.12228727474042	18.653988780856427	33104
9902bff2a03c1f3d0e3d1b01ae375f12d4f43098	jfplc'98, septièmes journées francophones de programmation logique et programmation par contraintes, 27-29 mai 1998, nantes, france					1998				Crypto	-105.05676869841396	16.37897196868084	33149
80e5bed6979d436ffc0c59b87c178936b7cabe66	comparative analysis of two operational developments within it companies' servitization - microsoft and hp		Servitization is a time-consuming-, and needs to be persistent-, process at the companies, especially in the IT branch. Thus, a company must find itself properly, on which phase of this process it is operating in, to perform further accurate steps, to succeed in a short time with this development, since the competition in the IT industry is highly dynamic. Accordingly, we perform in this paper an analysis of the customization grade in relation to the degree of integration into the product/service provided by a company. The analysis is based on the segments evaluation a company operates on. We study also the Servitization change processes in different business segments, based on the real scenarios of two mayor players in the IT business &#x2013; Microsoft and HP, as well as revenue distribution/change within the ten years period.	aggregate data;cluster analysis;diversification (finance)	Lukas Bickel;Natalia Kryvinska	2017	2017 IEEE 5th International Conference on Future Internet of Things and Cloud (FiCloud)	10.1109/FiCloud.2017.28	operations management;personalization;market research;software;business;revenue;information technology;operations research	DB	-83.95639506378923	7.361715372904806	33161
e6cb48b0ad20349eb3e7a333f46921e24ca58e7e	a cscl-tool to conduct a practical training in software-engineering over the internet.	software engineering			Axel Hunger;Frank Schwarz;Stefan Werner	1999			software engineering process group;computer science;systems engineering;knowledge management;social software engineering;software engineering;software construction;software requirements	Security	-64.56418371413591	24.934376576126684	33163
