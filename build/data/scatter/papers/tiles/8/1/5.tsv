id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
0dbc70e5999ade2b90043c92a4b2883af8f3a321	an empirical analysis of zeus c&c lifetime	zeus malware;survival analysis;c2c lifetime	Botnets continue to pose a significant threat to network-based applications and communications over the Internet. A key mitigation strategy has been to take down command and control infrastructure of the botnets. The efficiency of those mitigation methods has not been extensively studied. In this paper we investigate several observable characteristics of botnet command and controls (C&C) and estimate the variability in the survival rate of these C&Cs and the factors that are related to such variability. Furthermore, we show that different type of mitigation efforts have different impact. Kaplan-Meier analysis is performed to evaluate C&C survival ratios in the particular case of the ZeuS botnet. Using a lasso penalized Cox regression model, we identify the factors that influence the lifetime of a C&C. Location, malware family type, registrar, hosting type and popularity are the fundamental factors that explain this variability. Our results show that location and type of hosting are the two factors that affect more significantly the C&C lifetime. Thus, ZeuS C&Cs in certain regions of Asia are prone to stay online longer that those located in Europe.	botnet;heart rate variability;internet;kaplan–meier estimator;lasso;malware;observable;zeus (malware)	Carlos Gañán;Orçun Çetin;Michel van Eeten	2015		10.1145/2714576.2714579	simulation;survival analysis;world wide web;computer security;zeus	Security	-65.80036572161845	49.61368583654582	33518
977961bdb1ab6f042c7b98b3ffeceff6270b8e26	army-backed flexible display effort: a symbol of public-private partnership	displays glass organic light emitting diodes prototypes manufacturing processes protection batteries collaboration us government defense industry;credit card sized device army backed flexible display effort public private partnership;military equipment;public private partnership;flexible displays;military systems computer displays military equipment;military systems;computer displays;pervasive military networks;flexible displays pervasive military networks;credit cards;physical properties	The primary driver behind the Army's interest in promoting flexible displays is that the technology's physical properties offer vastly superior, if unquantifiable, advantages in safety for its frontline troops. The Army envisions an initial application of the flexible displays as a credit-card-sized device on a foil substrate. The author looks briefly at the features and applications, technological challenges, and dual use principles, promise, and perils	flexible display	Greg Goth	2006	IEEE Pervasive Computing	10.1109/MPRV.2006.45	simulation;flexible display;computer security;physical property	Visualization	-67.3957299552318	49.02860625121812	34237
c1ba2f18a0481c2d9f917f281a5888128763d132	cooperative debugging with five hundred million test cases	distributed debugging;statistical debugging;statistical machine learning;random sampling;resource availability;dynamic instrumentation;cooperative bug isolation;static program analysis;software quality	The resources available for testing and verifying software are always limited, and through sheer numbers an application's user community will uncover many flaws not caught during development. The Cooperative Bug Isolation Project (CBI) marshals large user communities into a massive distributed debugging army to help programmers find and fix problems that appear after deployment. Dynamic instrumentation based on sparse random sampling provides our raw data; statistical machine learning techniques mine this data for critical bug predictors; static program analysis places bug predictors back in context of the program under study. We discuss CBI's dynamic, statistical, and static views of postdeployment debugging and show how these three different approaches join together to help improve software quality in an imperfect world.	debugging;machine learning;programmer;sampling (signal processing);software deployment;software quality;sparse matrix;static program analysis;test case;verification and validation;virtual community	Ben Liblit	2008		10.1145/1390630.1390632	sampling;shotgun debugging;real-time computing;computer science;software engineering;database;distributed computing;algorithmic program debugging;programming language;software quality;static program analysis	SE	-66.23899155609044	36.175106783098464	34559
87886ed4cb440ba1257b330b8bdb98a401fe8169	a visual approach to spot statistically-significant differences in event logs based on process metrics		This paper addresses the problem of comparing different variants of the same process. We aim to detect relevant differences between processes based on what was recorded in event logs. We use transition systems to model behavior and to highlight differences. Transition systems are annotated with measurements, used to compare the behavior in the variants. The results are visualized as transitions systems, which are colored to pinpoint the significant differences. The approach has been implemented in ProM, and the implementation is publicly available. We validated our approach by performing experiments using real-life event data. The results show how our technique is able to detect relevant differences undetected by previous approaches while it avoids detecting insignificant differences.	algorithm;american and british english spelling differences;control flow;experiment;feedback;location (geography);olap cube;programmable read-only memory;real life;sensor;transition system	Alfredo Bolt;Massimiliano de Leoni;Wil M. P. van der Aalst	2016		10.1007/978-3-319-39696-5_10	data science;data mining;database	SE	-63.190832978837264	45.4008494691238	34916
b01213ebeaec953fa7eff5cdca4cfc62f912db28	prof. ci: employing continuous integration services and github workflows to teach test-driven development		Teaching programming using Massive Open Online Courses (MOOCs) is gaining popularity due to their scalability and efficiency of knowledge distribution. However, participating in these courses usually means fully committing to the supplied programming environment in the browser. While this allows a consistent and controllable setup, learners do not gain experience with actual development tools, such as local code editors, testing frameworks, issue trackers or continuous integration (CI) services, which is critical for subsequent real-world projects. Furthermore, the tests for the functionality that is to be developed are oftentimes already available in MOOCs and simply need to be executed, leading to less involvement with developing appropriate tests. In order to tackle these issues while maintaining a high degree of automation and scalability, we developed Prof. CI, a novel approach to conducting online exercises. Prof. CI leverages the existing automation infrastructure that developers use daily, i.e. CI services and Github workflows, to teach test-driven development (TDD) practices. Participants work on their own repositories in Github and receive feedback and new challenges from the CI server when they push their code. We have successfully applied this approach in a pilot project with 30 undergraduate students learning the Ruby on Rails web development framework. Our evaluation shows that the exercise effectively increased studentsu0027 motivation to write tests for their code. We also present the results of participant surveys, studentsu0027 experiences and teachersu0027 observations.	capstone (cryptography);computer;continuous integration;control system;experience;integrated development environment;issue tracking system;list of unit testing frameworks;massive open online course;pl/i;programming language;programming tool;requirement;ruby on rails;scalability;server (computing);software requirements;test-driven development;travis ci;version control;web application;web development	Christoph Matthies;Arian Treffer;Matthias Uflacker	2017	2017 IEEE Frontiers in Education Conference (FIE)	10.1109/FIE.2017.8190589	systems engineering;web development;automation;computer science;software;scalability;workflow;bittorrent tracker;server;test-driven development	SE	-67.35853239465588	35.332632395127085	34939
30f09549aec7841f80e85260db01a3047a349bee	enhancing android application bug reporting	auto completion;android;bug reports;reproduction steps	The modern software development landscape has seen a shift in focus toward mobile applications as smartphones and tablets near ubiquitous adoption. Due to this trend, the complexity of these “apps” has been increasing, making development and maintenance challenging. Current bug tracking systems do not effectively facilitate the creation of bug reports with useful information that will directly lead to a bug’s resolution. To address the need for an improved reporting system, we introduce a novel solution, called Fusion, that helps reporters auto-complete reproduction steps in bug reports for mobile apps by taking advantage of their GUI-centric nature. Fusion links information, that reporters provide, to program artifacts extracted through static and dynamic analysis performed beforehand. This allows our system to facilitate the reporting process for developers and testers, while generating more reproducible bug reports with immediately actionable information.	bug tracking system;graphical user interface;mobile app;smartphone;software development	Kevin Moran	2015		10.1145/2786805.2807557	simulation;security bug;computer science;engineering;internet privacy;world wide web;android	SE	-65.86990365857483	34.904331741639545	35208
014dc9d2b9d112272648bddc8b006834667f6328	exception handling defects: an empirical study	statistics exception handling software fault tolerance;empirical study;measurement;java equations mathematical model density measurement software systems communities;software fault tolerance;defects;statistics;eclipse;exception handling;eclipse empirical study exception handling measurement defects;eclipse release exception handling defects programming languages software system failure high assurance systems exploratory study defect density analysis exception handling code source code statistics exception handling information extraction bug reports exception handling constructs defect risk	Exception handling mechanisms are a feature common in many programming languages. Improper handling of exceptions can cause failures in software systems. This is especially critical for high-assurance systems where software failures may have severe consequences. Understanding the impact of misusing exception handling is important for better utilization of these constructs. This paper presents an exploratory study to determine whether using exception handling is relatively risky by analyzing the defect densities of exception handling code and the overall source code. Also, statistics representing the prevalence of exception handling code are proposed. The study was conducted with six major Eclipse releases. Essential data was collected using custom scripts to extract exception handling information from the source code and exception handling defects information from bug reports. We found that the density of defects that are closely related to exception handling constructs is relatively high compared to the overall defect density. This implies a relationship between the use of exception handling constructs and the risk of defects. Further studies should be conducted to better determine proper ways to implement exception handling and the root causes of exception defects in the software systems.	eclipse;exception handling;programming language;software bug;software system	Puntitra Sawadpong;Edward B. Allen;Byron J. Williams	2012	2012 IEEE 14th International Symposium on High-Assurance Systems Engineering	10.1109/HASE.2012.24	exception handling;eclipse;reliability engineering;computer science;database;programming language;empirical research;software fault tolerance;measurement;statistics	SE	-63.268670940624446	34.84776496314029	35573
784c102230ef3a844ed86f45a5dbe169e6b47fb3	towards a secure and efficient system for end-to-end provenance	accuracy guarantee;secure host-level provenance;efficient system;provenance monitor;central question;provenance system;eeps vision;end-to-end provenance system;provenance collection;eeps effort;end-to-end provenance;initial exploration	Work on the End-to-End Provenance System (EEPS) began in the late summer of 2009. The EEPS effort seeks to explore the three central questions in provenance systems: (1) “Where and how do I design secure hostlevel provenance collecting instruments (called provenance monitors)?”; (2) “How do I extend completeness and accuracy guarantees to distributed systems and computations?”; and (3) “What are the costs associated with provenance collection?” This position paper discusses our initial exploration into these issues and posits several challenges to the realization of the EEPS vision.	computation;distributed computing;google summer of code	Patrick D. McDaniel;Kevin R. B. Butler;Stephen E. McLaughlin;Radu Sion;Erez Zadok;Marianne Winslett	2010			geography;database;internet privacy;world wide web	OS	-65.68544142727555	52.65143273747974	36777
64cddbeb12df9fdd7cf89671192a49aedf4b455a	referencing tool for reputation and trust in wireless sensor networks		Presently, there are not many literatures on the characterization of reputation and trust in wireless sensor networks (WSNs) which can be referenced by scientists, researchers and students. Although some research documents include information on reputation and trust, characterization of these features are not adequately covered. In this paper, reputation and trust are divided into various classes or categories and a method of referencing the information is provided. This method used results in providing researchers with a tool that makes it easier to reference these features on reputation and trust in a much easier way than if referencing has to be directed to several uncoordinated resources. Although the outcome of this work proves beneficial to research in the characterization of reputation and trust in WSNs, more work needs to be done in extending the benefits to other network systems.	category theory	Mohammad Abdus Salam;Alfred Sarkodee-Adoo	2015	CoRR		internet privacy;computer security;computational trust	ECom	-73.30251515203275	47.53171626472954	37757
569953060cc003d6d19a80f876540e0ab93782e3	correct: code reviewer recommendation in github based on cross-project and technology experience	libraries;cross project experience;pull request;software;code reviewer recommendation;history;collaboration;companies;servers;github;encoding;specialized technology experience	Peer code review locates common coding rule violations and simple logical errors in the early phases of software development, and thus reduces overall cost. However, in GitHub, identifying an appropriate code reviewer for a pull request is a non-trivial task given that reliable information for reviewer identification is often not readily available. In this paper, we propose a code reviewer recommendation technique that considers not only the relevant cross-project work history (e.g., external library experience) but also the experience of a developer in certain specialized technologies associated with a pull request for determining her expertise as a potential code reviewer. We first motivate our technique using an exploratory study with 10 commercial projects and 10 associated libraries external to those projects. Experiments using 17,115 pull requests from 10 commercial projects and six open source projects show that our technique provides 85%-- 92% recommendation accuracy, about 86% precision and 79%--81% recall in code reviewer recommendation, which are highly promising. Comparison with the state-of-the-art technique also validates the empirical findings and the superiority of our recommendation technique.	distributed version control;heuristic;library (computing);open-source software;programming language;software development	Mohammad Masudur Rahman;Chanchal Kumar Roy;Jason A. Collins	2016	2016 IEEE/ACM 38th International Conference on Software Engineering Companion (ICSE-C)	10.1145/2889160.2889244	computer science;software engineering;data mining;multimedia;management;world wide web;server;encoding;collaboration	SE	-63.73121414050843	36.6046455694149	37851
2e35c8334c60667090347b876f34d506b3c9a425	the prediction ability of experienced software maintainers	software maintenance electrical capacitance tomography cognition informatics application software testing decision making programming profession problem solving;empirical study;training software maintenance personnel software development management;decision aid;software maintenance;training;maintenance effort estimation models prediction ability experienced software maintainers software maintenance tasks norwegian software organization task specification confidence unexpected difficulties feedback quality training probabilistic thinking decision aids;effort estimation;personnel;software development management	This paper reports an empirical study of 109 randomly selected maintenance tasks in a large Norwegian software organization. When the maintainers had understood the maintenance task specifications, we asked whether they knew how to solve the task. A high confidence in knowing how to solve the task meant that the maintainers did not expect any major difficulties. Then, immediately after the task was completed, we asked whether there had been any major unexpected difficulties. A comparison of the answers gave the seemingly surprising result that one could not, except for corrective, small and simple maintenance tasks, have more confidence in the predictions of an experienced maintainer than the predictions of an inexperienced maintainer. We believe that better quality of the feedback on previous predictions and more training in probabilistic thinking are important means to improve the prediction abilities of maintainers. Decision aids, such as maintenance effort estimation models, should enable analysis of previous predictions and stimulate to probabilistic thinking.	cost estimation in software engineering;experience;experiment;mathematical model;randomness;software maintainer	Magne Jørgensen;Dag I. K. Sjøberg;Geir Kirkebøen	2000		10.1109/CSMR.2000.827317	reliability engineering;long-term support;systems engineering;engineering;knowledge management;software engineering;empirical research;software maintenance;software metric	SE	-65.54086865047289	32.52618996273848	39210
30ea1d7526f120b1275e045f4318e9fb57cc73de	predicting faults using the complexity of code changes	software metrics program diagnostics program verification software fault tolerance;software metrics;software;code change process;negative affect;program diagnostics;complexity metrics;complexity theory;history;fault prediction;software systems;software fault tolerance;program verification;software systems predictive models software measurement delay history lab on a chip information theory entropy project management;data mining;evolution biology;code changes complexity;uct;complexity measurement;entropy;change process;code change process fault prediction code changes complexity fault incidence complexity measurement complexity metrics;fault incidence;open source	Predicting the incidence of faults in code has been commonly associated with measuring complexity. In this paper, we propose complexity metrics that are based on the code change process instead of on the code. We conjecture that a complex code change process negatively affects its product, i.e., the software system. We validate our hypothesis empirically through a case study using data derived from the change history for six large open source projects. Our case study shows that our change complexity metrics are better predictors of fault potential in comparison to other well-known historical predictors of faults, i.e., prior modifications and prior faults.	incidence matrix;open-source software;software system	Ahmed E. Hassan	2009	2009 IEEE 31st International Conference on Software Engineering	10.1109/ICSE.2009.5070510	reliability engineering;entropy;computer science;systems engineering;theoretical computer science;software engineering;software fault tolerance;software metric;affect;software system	SE	-63.47957643903064	34.41861871462687	39552
de939b4b97312b00b13c37df23ff268c80a0d4fc	evaluation of test code quality with aspect-oriented mutations	developpement logiciel;product code;unit testing;orientado aspecto;programmation agile;software engineering;agile programming;extreme programming;programacion extrema;agile methodologies;desarrollo logicial;software development;programmation extreme;aspect oriented;source code;programacion agil;functional requirement;oriente aspect;open source	Along with growing popularity of agile methodologies and open source movement, unit testing has become one of the core practices in modern software engineering. It is particularly important in eXtreme Programming [1], which explicitly diminish the importance of other artifacts than source code and tests cases. In XP unit test cases not only verify if software meets functional requirements, but also enable refactoring, alleviate comprehension and provide guidance on how the production code should be used. Therefore, they contribute to many other important practices of XP, which explicitly or implicitly rely on their ability to effectively discover bugs. Mutation testing [2] is a technique used for verifying the quality of tests. It figures out how the test cases actually react to faulty response received from deliberately altered production code. High quality tests are expected to uncover any mutation of the source code which makes it to behave even slightly differently. Such modified code (called mutant) is killed when it causes at least one test case to fail. Despite of its advantages, mutation testing has not been widely adopted by software industry. The main drawback its high complexity: it usually includes multiple phases of mutating source code, compilation and running the tests. Therefore, the technique is in practice inapplicable for medium or large size systems. In the paper we present a prototype tool for mutation testing, which employs aspect-oriented programming (AOP) [3] to generate and execute mutants. It follows the control of existing test cases and examines how they deal with the altered production code, while significantly reducing time required to create and run mutants.	agile software development;aspect-oriented programming;code refactoring;compiler;extreme programming;functional requirement;mutation testing;open-source software;prototype;software bug;software engineering;software industry;test case;unit testing;verification and validation	Bartosz Bogacki;Bartosz Walter	2006		10.1007/11774129_26	real-time computing;computer science;operating system;agile software development;database;programming language;code refactoring;algorithm	SE	-64.1176721687422	34.73162150740831	40388
23101fb500e76f6b4833110fe81ce6397fa02395	an empirical study of design degradation: how software projects get worse over time	refactoring software projects software decay open source projects software defects;degradation;history;measurement;software maintenance;software systems;degradation measurement software systems java history couplers;couplers;java	Context: Software decay is a key concern for large, long-lived software projects. Systems degrade over time as design and implementation compromises and exceptions pile up. Goal: Quantify design decay and understand how software projects deal with this issue. Method: We conducted an empirical study on the presence and evolution of code smells, used as an indicator of design degradation in 220 open source projects. Results: The best approach to maintain the quality of a project is to spend time reducing both software defects (bugs) and design issues (refactoring). We found that design issues are frequently ignored in favor of fixing defects. We also found that design issues have a higher chance of being fixed in the early stages of a project, and that efforts to correct these stall as projects mature and the code base grows, leading to a build-up of problems. Conclusions: From studying a large set of open source projects, our research suggests that while core contributors tend to fix design issues more often than non-core contributors, there is no difference once the relative quantity of commits is accounted for. We also show that design issues tend to build up over time.	automatic bug fixing;code refactoring;code smell;commitment scheme;elegant degradation;hoc (programming language);open-source software;real life;scientific literature;software bug;software rot;technical debt	Iftekhar Ahmed;Umme Ayda Mannan;Rahul Gopinath;Carlos Jensen	2015	2015 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)	10.1109/ESEM.2015.7321186	reliability engineering;long-term support;verification and validation;team software process;degradation;software sizing;software project management;computer science;systems engineering;engineering;package development process;backporting;software design;social software engineering;software reliability testing;software development;software design description;software engineering;software rot;software construction;software walkthrough;software maintenance;java;software deployment;software metric;measurement;software quality analyst;software system;avionics software	SE	-64.29742437954118	34.60780390743682	40598
bedbe2029d39b4ba46c75078f91c07702fa517d5	challenges to error diagnosis in hadoop ecosystems	failure experience;following type;software incompatibility;hadoop ecosystem;initial idea;multiple layer;corresponding challenge;better trouble-shooting;error diagnosis;diagnosis tool;real world deployment;subtle error	Deploying a large-scale distributed ecosystem such as HBase/Hadoop in the cloud is complicated and error-prone. Multiple layers of largely independently evolving software are deployed across distributed nodes on third party infrastructures. In addition to software incompatibility and typical misconfiguration within each layer, many subtle and hard to diagnose errors happen due to misconfigurations across layers and nodes. These errors are difficult to diagnose because of scattered log management and lack of ecosystem-awareness in many diagnosis tools and processes. We report on some failure experiences in a real world deployment of HBase/Hadoop and propose some initial ideas for better trouble-shooting during deployment. We identify the following types of subtle errors and the corresponding challenges in trouble-shooting: 1) dealing with inconsistency among distributed logs, 2) distinguishing useful information from noisy logging, and 3) probabilistic determination of root causes.	apache hbase;apache hadoop;cloud computing;cognitive dimensions of notations;ecosystem;experiment;log management;probabilistic database;scalability;software deployment;software incompatibility;the australian	Jim Zhanwen Li;Siyuan He;Liming Zhu;Xiwei Xu;Min Fu;Leonard J. Bass;Anna Liu;An Binh Tran	2013			data mining;distributed computing;computer security	Networks	-63.37943948820532	42.01433183923195	40617
c2090587725f8a50956504974643c15732757e0d	spreadsheet testing in practice	software;manuals;training;testing;software engineering;interviews;encoding	Despite being popular end-user tools, spreadsheets suffer from the vulnerability of error-proneness. In software engineering, testing has been proposed as a way to address errors. It is important therefore to know whether spreadsheet users also test, or how do they test and to what extent, especially since most spreadsheet users do not have the training, or experience, of software engineering principles. Towards this end, we conduct a two-phase mixed methods study. First, a qualitative phase, in which we interview 12 spreadsheet users, and second, a quantitative phase, in which we conduct an online survey completed by 72 users. The outcome of the interviews, organized into four different categories, consists of an overview of test practices, perceptions of spreadsheet users about testing, a set of preventive measures for avoiding errors, and an overview of maintenance practices for ensuring correctness of spreadsheets over time. The survey adds to the findings by providing quantitative estimates indicating that ensuring correctness is an important concern, and a major fraction of users do test their spreadsheets. However, their techniques are largely manual and lack formalism. Tools and automated supports are rarely used.	cognitive dimensions of notations;correctness (computer science);semantics (computer science);software engineering;spreadsheet;two-phase locking	Sohon Roy;Felienne Hermans;Arie van Deursen	2017	2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER)	10.1109/SANER.2017.7884634	reliability engineering;computer science;systems engineering;software engineering	SE	-64.9831270071259	32.84101767334807	40723
0d9900edd1ad91a98d4aff16529143963efc16b0	mining a change-based software repository	degradation;change based software repository;software prototyping;application software;software maintenance;information retrieval;software systems;software refactoring;software refactoring change based software repository data mining versioning system information software evolution information repository;data mining;software performance;software evolution;system evolution;software prototyping configuration management data mining software maintenance;information repository;informatics;sampling methods;software design;frequency;versioning system information;software systems application software sampling methods informatics information retrieval degradation software design concrete frequency software performance;configuration management;concrete	Although state-of-the-art software repositories based on versioning system information are useful to assess the evolution of a software system, the information they contain is limited in several ways. Versioning systems such as CVS or SubVersion store only snapshots of text files, leading to a loss of information: The exact sequence of changes between two versions is hard to recover. In this paper we present an alternative information repository which stores incremental changes to the system under study, retrieved from the IDE used to build the software. We then use this change-based model of system evolution to assess when refactorings happen in two case studies, and compare our findings with refactoring detection approaches on classical versioning system repositories.	code refactoring;concurrent versions system;graphic art software;information repository;point of sale;sensor;software evolution;software repository;software system;system information (windows);version control	Romain Robbes	2007	Fourth International Workshop on Mining Software Repositories (MSR'07:ICSE Workshops 2007)	10.1109/MSR.2007.18	sampling;application software;degradation;concrete;software performance testing;computer science;systems engineering;software evolution;software design;software engineering;frequency;data mining;database;configuration management;information repository;software maintenance;informatics;code refactoring;software system	SE	-63.02522870859483	35.97142841726944	42447
72c93f8dc9725ac241825e658d2be8153e3926f9	an informational versus network perspective on the information society	information society	A cell-based system for computation and communication. A cell is a well-defined structure that associates executable code and data into a basic computational module. A processor can traverse a cell and execute the instructions therein. Cells are arranged into a network with each cell linked to other cells by forward branches or other paths. A processor branches to a cell by loading its program counter with the address of the cell or by sending a packet of data across a communications network to activate remote processing in a cell. Cells have a path selection section for evaluating conditional branches and causing branches to be followed. Multiple branches may be followed in parallel from any cell. A tree-like organization is superimposed on the network by distinguishing one branch to each cell as a superbranch incorporating a return path (called path). A cell also has a convergence section that handles processors and threads of execution that return to that cell by this path (called recession). The convergence section implements rules that control which, if any, processors or threads continue to execute upon recession as well as rules for handling any resulting values associated with the processors or threads. The cellular computational module controls highly parallel and distributed processing and supports dynamic self-modification of the system. Information is acquired within the system not only through the acquisition of data and the modification of executable code within the cells, but also through the encoding of information and behavior into the structure of links that connect the cells.		Pernilla Gripenberg	2006	Inf. Soc.	10.1080/01972240600567246	public relations;computer science;sociology;international economics	AI	-68.40497013465065	45.6708475248312	43271
7fc058d0e2a23b7969e24b9aad871dfe6eabe4bf	analyzing performance of web-based metrics for evaluating reliability and maintainability of hypermedia applications	rs web application effort assessment rswaea;software metrics;user behaviour model graph method ubmg web metrics web page replacement algorithms web usability rs web application effort assessment rswaea;web based applications;biomedical measurements;empirical study;reliability;web usability;probability;web pages;performance analysis application software web pages usability information technology biomedical engineering maintenance engineering reliability engineering computer science broadband communication;software maintenance;web page replacement algorithms;information technology;client server systems;user behaviour model graph method ubmg;hyperdocuments;hypermedia;client server based web technologies;client server;information and communication technology;web design;hypermedia applications;effort estimation;estimation;user behaviour;indexation;web sites;web sites client server systems hypermedia software maintenance software metrics software reliability;web based system;web site usability index;user behavior;web metrics;web designers;point of view;usability;software reliability;web technology;web site usability index web based metrics hypermedia applications information technology user behavior model graph web page replacement algorithms rs web application effort assessment hyperdocuments web designers client server based web technologies;user behavior model graph;rs web application effort assessment;web based metrics	This paper has been designed to identify the Web metrics for evaluating the reliability and maintainability of hypermedia applications. In the age of information and communication technology (ICT), Web and the Internet, have brought significant changes in information technology (IT) and their related scenarios. Therefore in this paper an attempt has been made to trace out the Web-based measurements towards the creation of efficient Web centric applications. The dramatic increase in Web site development and their relative usage has led to the need of Web-based metrics. These metrics will accurately assess the efforts in the Web-based applications. Here we promote the simple, but elegant approaches to estimate the efforts needed for designing Web-based applications with the help of user behavior model graph (UBMG), Web page replacement algorithms, and RS Web Application Effort Assessment (RSWAEA) method. Effort assessment of hyperdocuments is crucial for Web-based systems, where outages can result in loss of revenue and dissatisfied customers. Here we advocate a simple, but elegant approach for effort estimation for Web applications from an empirical point of view. The proposed methods and models have been designed after carrying out an empirical study with the students of an advanced university class and Web designers that used various client-server based Web technologies. Our first aim was to compare the relative importance of each Web-based metric and method. Second, we also implemented the quality of the designs obtained based by constructing the User Behavior Model Graphs (UBMGs) to capture the reliability of Web-based applications. Thirdly, we use Web page replacement algorithms for increasing the Web site usability index, maintainability, reliability, and ranking. The results obtained from the above Web-based metrics can help us to analytically identify the effort assessment and failure points in Web-based systems and makes the evaluation of reliability of these systems simple.	behavior model;client–server model;cost estimation in software engineering;hypermedia;internet;page replacement algorithm;server (computing);usability;web application;web design;web page;world wide web	Sanjeev Dhawan;Rakesh Kumar	2008	2008 Third International Conference on Broadband Communications, Information Technology & Biomedical Applications	10.1109/BROADCOM.2008.73	web application security;web modeling;web analytics;web design;web standards;computer science;social semantic web;data mining;database;web intelligence;web engineering;world wide web;mashup	Web+IR	-70.5439187027177	37.620184069644004	43379
d6bc82e8f3af0d2d597e88a87d876dfd5c01ead7	dependable systems - wishful thinking or realistic expectation?	dependable systems	A system is dependable if you can trust it to work. This seems to a completely obvious, almost trivial definition. But the  question of what it means for a system to “work” is influenced by the type of system and the perspective of the user — among  other things. Depending on the function, reliability can be an important criterion, but in other cases it can be throughput,  response time, accuracy of computations, immunity against malicious attacks —this list could be continued for a while.    In addition to that, the discussion of dependability does not stop at the boundaries of a technical system. The interaction  between (human) actors and a technical system creates a new, larger system, for which dependability needs to be defined, too.  Thus dependability is not static property, determined by a set of design decisions, but a behavioural trait that strongly  depends on external influences. In particular, different users groups can have different perceptions of what they regard as  the system’s dependability.        The presentation will start out by precisely defining dependability as a user-dependent phenomenon. Based on this, we will  explore the technical means available for supporting the implementation of highly dependable systems by adequate methods and  corresponding tools.      	dependability	Andreas Reuter	2008		10.1007/978-3-540-78942-0_2	computer science	Logic	-69.0916384479653	38.22740133843029	43473
ec6ad7bddc365881740b302983cad65ff55f8c40	surfing the net for software engineering notes		This month’s topic will be a delicious tour of bad programming. For some reason, we’ve associated bad coding practice with pasta. We’ll talk about spaghetti code, ravioli code, lasagna code and see how the dishes smell. Despite the light-hearted, culinary metaphors for bad code, the software engineering community has been struggling for decades to characterize computer program quality. I’m not talking Quality Assurance here; I’m referring to good or bad computer programs. We speak of high cohesion, low coupling, comment density, program volume, complexity and other similar measures, but what do the numbers really mean? Is a program with a complexity of seven really better than a program with a complexity of 12? It depends. We have created coding standards and can use static analysis tools to automatically measure conformance to those standards, but does that guarantee “good” code? Maybe. In many ways, bad programming is a lot like pornography, you can’t define it, but you know it when you see it. We can say for sure that spaghetti code is characterized by multiple, confusing, often-inexplicable branches guarded by strange and exotic conditionals. Many programmers who cut their teeth in assembly or the FORTRAN or BASIC programming languages, befriended the goto statement as their principal control structure, You could do wonderful things such as “IF A+B = C, GOTO Line 348” or you could sidestep a complete a block of instructions and GOTO Line 918. These jumps made perfect sense to you at the time, but without comments or some kind of rationale for the control structures, the branches were extremely hard for an outside observer to understand. The spaghetti code is cooking. If the GOTO statement is the basic ingredient for spaghetti code, the recipe now includes other, more complex control structures made possible by advances in programming languages. Pointers, exception handlers, variant records, inheritance, overloaded procedures, and object interdependencies now contribute additional flavor to your spaghetti code cookbook. The spaghetti code article in Wikipedia describes how to make ravioli code by overuse of encapsulation to make a bunch of tiny, loosely coupled methods resembling the pasta pouches filled with bits of meat. You can also make lasagna code, a layered program structure with well-defined interfaces between the layers (corresponding to lasagna noodles) acting as facades for disorganized business logic in the lasagna filling. The Wikipedia article also describes spaghetti and meatballs; a form of object oriented bad programming where the objects (meatballs) are dependent on procedural code (spaghetti) that links them together. We’ll start our surfing expedition with a visit to one of the seminal papers on the dangers of uncontrolled gotos, a basic ingredient of spaghetti code. Then we’ll move on to other Internet resources to help you avoid turning your software into an evening meal.	basic;business logic;chaos theory;cohesion (computer science);complexity;computer program;conformance testing;control flow;design rationale;encapsulation (networking);exception handling;fortran;function overloading;goto;interdependence;loose coupling;pointer (computer programming);procedural programming;programmer;programming language;software engineering notes;spaghetti code;structured programming;uncontrolled format string;wikipedia	Mark Doernhoefer	2012	ACM SIGSOFT Software Engineering Notes	10.1145/2382756.2382780		SE	-70.14250623292801	34.15501153880153	43657
2095acfccc9750d681c78d919e3f884c64818aad	api usability at scale		Designing and maintaining useful and usable APIs remains challenging. At Google, we manage hundreds of externally visible web APIs. Here, we report on our experiences and describe six on-going challenges: resource allocation, empirically-grounded guidelines, communicating issues, supporting API evolution over time, usable auth, and usable client libraries at scale. Introduction Application Program Interfaces (APIs) are the way in which programmers access functionality created by others. Every substantive program written in every language today makes extensive use of APIs. It’s no surprise that their usability often dominates the experience of programmers. APIs have been used for decades to connect software modules on a single machine. With the rise of web services and microservice architectures, web APIs have become the primary user interface for many types of services being offered online. While the paper is not centered only on web APIs, we do focus on them (as opposed to standard libraries) a few times. When we do, we are generally referring to representational state transfer (REST) APIs over HTTP. However, the structure of the API (REST vs., say, Simple Object Access Protocol [SOAP]) and the communication protocol (e.g., HTTP vs. local connection) are orthogonal for the discussion. Despite their importance, there is comparatively little work on understanding API usability. A special interest group was held at the 2009 ACM CHI conference to discuss this problem, the result of which was the founding of apiusability.org (Daughtry, Farooq, Myers, & Stylos, 2009). As of the time of writing, some 50 publications have been listed on this site. A recent paper by Myers and Stylos (2016) provides a summary of the existing work and outlines the various techniques in use for understanding and improving API usability. In this experience report, we describe some of the major challenges that we have faced building usable APIs at Google and discuss some of our approaches to those challenges. We aim to show the kinds of problems that Google faces as a major API provider and to start a broader conversation as to how we might go about addressing these challenges. 1. Challenge 1: UX Resource Allocation Traditional usability evaluation techniques can be applied to APIs in order to measure, understand, and improve usability (Clarke, 2004), (Stylos et al., 2008). One of the most cited techniques is running API usability lab studies. This is effective, but not scalable, as participants with professional software experience and researchers with a blend of human-computer interaction, domain and technical knowledge are limited resources (Farooq & Zirkler, 2010). Replacing lab studies with design reviews has been explored by both Microsoft (Farooq & Zirkler, 2010) and Google (Macvean, Maly, & Daughtry, 2016); our experience so far suggests this can augment lab studies, but not replace them. We are beginning to explore having software engineers run their own studies for APIs, which Google has employed successfully in the past for other domains (Baki et al., 2013). This reduces the need to find qualified researchers but doesn’t address the time commitment or the burden of recruiting professional programmers as participants. Stylos and Myers (2007) described heuristics for how to prioritize research of API design decisions; Metric Data for a single API Opened API Explorer 6,067 sessions Clicked Execute 1,687 sessions Experienced 4XX error 47% (795 sessions) Achieved 2XX response 65% (1,099 sessions) Table 1 – Explorer usage over one week of data for a single Google API. Figure 1 – Percentage of Explorer sessions that encountered a 4XX error across 26 Google APIs. namely, prioritizing for decisions that developers make often and that severely affect API use. We are using two sources to find the APIs which create the most friction for our users: (1) API exploration usage data, and (2) API Customer Satisfaction surveys. We can identify invalid API requests by looking for responses with a 4XX status code (i.e. an error in the client request, as opposed to, say, an issue caused by the server of the API. For example, a 404 or 429 HTTP response code), and we can compute the percentage of these responses across APIs. The problem with this approach is that API log data doesn’t distinguish between calls that are placed when the developer is learning the API and calls that are run in production, making it difficult to distinguish between a hard-to-use API and existing buggy code. However, nearly all modern web APIs have a ‘try it out’ feature available online, such as the Google API Explorer1 or Swagger UI2. When we examine log data coming from such a tool, we know that a human is on the other side. Our hypothesis is that by exposing the Explorer data as usability metrics to the producers of those APIs, we can shine a light on problems and elicit positive change. As a first step, we explored a set of metrics for a small set of APIs. We can, for example, look at a success funnel on a per API basis, see Table 1. In isolation, these metrics are not actionable. While we want success rate to be higher, what constitutes a good success rate? As a next step, we took a look at the 26 most used APIs in Explorer in a one week period, see Figures 1, 2 and 3. We now have actionable information. Each graph exposes APIs that are outliers and need significant attention, while also showing us which APIs have further room for improvement. In Figure 1, we see that there are three APIs for whom almost everyone experiences a 4XX error at least once. We now know which APIs to focus on improving and can set a realistic numeric goal based on the less errorprone APIs (e.g., 40%). When we look at Figure 2, we see that many of our APIs average two 4XX errors per session. If you make an error, then the response should include enough information for you to fix the mistake. So, we know that we should look at the APIs in the > 3 range and try to bring them down close to 2. Figure 3 shows us the percentage of sessions that experienced success, where success is defined as achieving a syntactically correct (2XX) request. Again, we see a few APIs that are underperforming and room for improvement on many others. There are three downsides to these metrics, which must be remembered during interpretation. First, 1https://developers.google.com/apis-explorer/ 2http://swagger.io/swagger-ui/ Figure 2 – Mean number of 4XX errors encountered per Explorer session over 26 Google APIs. Figure 3 – Percentage of sessions that experienced a 2XX response over 26 Google APIs. while we know errors are a signal for usability problems, we don’t know exactly what usability issue(s) led to the erroneous request. Second, the problems they are experiencing could be usability problems with Explorer itself (the tool) as opposed to API usability issues. Third, we know from other research we have conducted that not every use of Explorer has a goal of achieving a 2XX response; for example, you may be trying to intentionally replicate a bug, or exploring the error messages that occur when you include invalid parameters. In practice, these three problems do not detract from the utility of the method. As long as the metrics guide follow-up evaluation, human investigation can eliminate falsepositives while also better understanding the specific usability problems. While we don’t include representative data here, we can also change the granularity of our metrics to expose problems on a per-method basis as opposed to a per-API basis. This can expose potentially confusing methods within a single API as well as providing UX researchers and software engineers more specific targets for lab studies or design reviews. Our next step is to broaden the scope of the data we include in the analysis to include all of the Google APIs exposed via Explorer and to expose the metrics to API producers. Having access to so many APIs will allow us to set benchmarks that the API producers can compare their API against (e.g., more than one standard deviation above or below the mean). We are also conducting exploratory analysis to establish whether we can reliably distinguish between the different types of usage we see in Explorer. Splitting off the data from those, for example, intentionally getting errors to replicate a bug, would help with the validity of the data, as well as opening up avenues for other interesting analysis. In parallel to our API log-file analysis, we are also exploring the application of customer satisfaction surveys to our APIs. Using a simple Likert-scale question (Likert, 1932), which asks users to rate their overall satisfaction with an API on a 5-point scale between ‘Very dissatisfied’ and ‘Very satisfied’, we can begin to quantify user sentiment towards a particular API. By distributing surveys across our suite of APIs, we also begin to get a picture of how users perceive our services, and, as with the Explorer data, the ways in which one API may stack up against others in order to set benchmarks for improvement. Furthermore, this lightweight approach to surveying allows tracking against time, allowing us to, for example, gauge the impact of a new version of an API with the old. Surveying API consumers is difficult, given the fact that much of their interaction with the API will be spent within their IDE or text editor, writing code. We are exploring distribution of our surveys via an unobtrusive intercept survey method (Müller & Sedley, 2014), letting us target API consumers reading documentation. This approach may introduce a selection bias, as using the documentation is not a requirement for using an API, and users viewing the documentation may not have any experience with the API. None the less, when distributed equally and consistently across all of our APIs, we can uncover interesting trends. Much like with our API Explorer data, comparing sentiment across APIs provides a reference point for improvement.		Andrew Macvean;Luke Church;John Daughtry;Craig Citro	2016			usability lab	SE	-66.70695440598192	37.48209507341255	43804
b982b11f7b58e0d9934a751f54d9b3593c59c621	programmer variations in software debugging approaches	developpement logiciel;debugging;puesta a punto programa;mise au point programme;ingenieria logiciel;software engineering;costo;desarrollo logicial;software development;genie logiciel;cout	Abstract   As software costs continue to increase, the need to enhance programmer productivity increases. It is widely accepted that individual differences impact software development productivity. Due to the high percent of software development effort spent on testing and maintenance, an investigation of techniques used by programmer to change code can help identify methods that are effective and thus contribute to productivity improvement. In this study, we investigate program change rates as a potential productivity factor. The level of change activity both early and late in the debugging process and the quantity of changes made between test executions are among the factors investigated. We compute a programmer change profile based on these factors. The profiles are compared relative to the ratio of program changes to lines of code. Lower change rates early in the debugging process and lower change per execution rates were found for the programmers with the lower ratios of program changes to lines of code.	debugging;programmer	Doris L. Carver	1989	International Journal of Man-Machine Studies	10.1016/0020-7373(89)90010-2	real-time computing;input/output;computer science;software development;operating system;programming language;debugging	Arch	-66.40459429798835	32.380247927803595	44735
de0f73151aea57aff4f2d4c6e7875a7a790877ec	prioritising refactoring using code bad smells	refactoring;book item;software switches fault diagnosis encoding taxonomy systematics java;fault;software engineering;source code code bad smells duplicated code data clumps switch statements speculative generality message chains middle man software faults;system recovery;code bad smells;software development;fault code bad smells refactoring;source code;system recovery software engineering	We investigated the relationship between six of Fowler et al.'s Code Bad Smells (Duplicated Code, Data Clumps, Switch Statements, Speculative Generality, Message Chains, and Middle Man) and software faults. In this paper we discuss how our results can be used by software developers to prioritise refactoring. In particular we suggest that source code containing Duplicated Code is likely to be associated with more faults than source code containing the other five Code Bad Smells. As a consequence, Duplicated Code should be prioritised for refactoring. Source code containing Message Chains seems to be associated with a high number of faults in some situations. Consequently it is another Code Bad Smell which should be prioritised for refactoring. Source code containing only one of the Data Clumps, Switch Statements, Speculative Generality, or Middle Man Bad Smell is not likely to be fault-prone. As a result these Code Bad Smells could be put into a lower refactoring priority.	code refactoring;code smell;duplicate code;software developer;speculative execution	Min Zhang;Nathan Baddoo;Paul Wernick;Tracy Hall	2011	2011 IEEE Fourth International Conference on Software Testing, Verification and Validation Workshops	10.1109/ICSTW.2011.69	code bloat;real-time computing;code review;computer science;software development;software engineering;redundant code;fault;programming language;computer security;code refactoring;code smell;source code	SE	-64.0218658940801	35.76255511894235	44830
0c69e16d3537ae3afc058116c4ac365a0d75a56d	shadow patching: minimizing maintenance windows in a virtualized enterprise environment	virtualisation business data processing input output programs program debugging software maintenance;deterministic file io operations shadow patching maintenance windows virtualized enterprise environment software lifecycle it environment service disruption maintenance window sophisticated live patching techniques patch management technique virtualization capabilities disk activities complex software patching operation;software maintenance engineering merging monitoring testing conferences servers	Software is growing bigger and more complex, which results in bugs and defects being no longer dealt as exceptions, but rather as normal artifacts in a software's lifecycle. In fact, many patches are released by vendors on a preset schedule. This implies that managing patches in a correct and timely manner has become an important factor in smoothly running an IT environment. However, when a patch is applied, the affected software is often required to stop temporarily, which can cause a disruption of service. The down time is commonly called a maintenance window. Although sophisticated live patching techniques have been previously proposed, their applicability in practice is very limited. In this paper, we propose a novel patch management technique based on commonly available virtualization capabilities. It allows system administrators to perform a majority of the patch work outside of the maintenance window, such as downloading patches, installing them, and performing post-installation testing and fixes. By capturing the disk activities and replaying them during the actual maintenance window, we can transform a complex software patching operation to a series of more deterministic file I/O operations, and thus, reducing maintenance window from hours to minutes.	delta encoding;denial-of-service attack;download;downtime;experiment;input/output;installation testing;microsoft windows;online and offline;patch (computing);regression testing;shadow copy;smoothing;software bug;software developer;software maintenance;system administrator	Duy Le;Jidong Xiao;Hai Huang;Haining Wang	2014	10th International Conference on Network and Service Management (CNSM) and Workshop	10.1109/CNSM.2014.7014154	embedded system;real-time computing;maintenance mode;backporting;operating system;computer security;computer network	SE	-63.4221060827708	43.18076387843417	45408
663942485e6c8a3d6961658729c1365139a75e16	automated cyber-attack scenario generation using the symbolic simulation	한국시뮬레이션학회;jong keun lee;the korea society for simulation;automated cyber attack scenario generation using the symbolic simulation;syng yup ohn;information assurance;sung do chi;networked systems;scenario generation;2004 jeju international simulation multiconference parti;min woo lee;simulation environment;numerical simulation;jang so lee	The major objective of this paper is to propose the automated cyber-attack scenario generation methodology based on the symbolic simulation environment. Information Assurance is to assure the reliability and availability of information by preventing from attack. Cyber-attack simulation is one of noticeable methods for analyzing vulnerabilities in the information assurance field, which requires variety of attack scenarios. To do this, we have adopted the symbolic simulation that has extended a conventional numeric simulation. This study can 1) not only generate conventional cyber-attack scenarios but 2) generate cyber-attack scenarios still unknown, and 3) be applied to establish the appropriate defense strategies by analyzing generated cyber-attack. Simulation test performed on sample network system will illustrate our techniques.	symbolic simulation	Jong-Keun Lee;Min-Woo Lee;Jang-Se Lee;Sung-Do Chi;Syng-Yup Ohn	2004		10.1007/978-3-540-30583-5_41	computer simulation;simulation;computer science;artificial intelligence;computer security	Logic	-63.673665108669404	59.48621112669931	45804
85735755347c9f2370ebe1223551365694b22945	big data clone detection using classical detectors: an exploratory study	shuffling framework;big data;clone corpus;clone detection;scalability	Big data analysis is an emerging research topic in various domains, and clone detection is no exception. The goal is to create big data inter-project clone corpora across open-source or corporate-source code repositories. Such corpora can be used to study developer behavior and to reduce engineering costs by extracting globally duplicated efforts into new APIs and as a basis for code completion and API usage support. However, building scalable clone detection tools is challenging. It is often impractical to use existing state-of-the-art tools to analyze big data because the memory and execution time required exceed the average user’s resources. Some tools have inherent limitations in their data structures and algorithms that prevent the analysis of big data even when extraordinary resources are available. These limitations are impossible to overcome if the source code of the tool is unavailable or if the user lacks the time or expertise to modify the tool without harming its performance or accuracy. In this research, we have investigated the use of our shuffling framework for scaling classical clone detection tools to big data. The framework achieves scalability on commodity hardware by partitioning the input dataset into subsets manageable by the tool and computing resources. A non-deterministic process is used to randomly ‘shuffle’ the contents of the dataset into a series of subsets. The tool is executed for each subset, and its output for each is merged into a single report. This approach does not require modification to the subject tools, allowing their individual strengths and precision to be captured at an acceptable loss of recall. In our study, we explored the performance and applicability of the framework for the big data dataset, IJaDataset 2.0, which consists of 356 million lines of code from 25,000 open-source Java projects. We begin with a computationally inexpensive version of our framework based on pure random shuffling. This versionwas successful at scaling the tools to IJaDataset but required many subsets to achieve a desirable recall. Using our findings, we incrementally improved the framework to achieve a satisfactory recall using fewer resources. We investigated the use of efficient file tracking and file-similarity heuristics to bias the shuffling algorithm toward subsets of the dataset that contain undetected clone pairs. These changes were successful in improving the recall performance of the framework. Our study shows that the framework is able to achieve up to 90–95% of a tool’s native recall using standard hardware. Copyright © 2014 John Wiley & Sons, Ltd. Received 9 October 2013; Revised 20 March 2014; Accepted 28 May 2014	algorithm;application programming interface;big data;commodity computing;data structure;duplicate code;exception handling;heuristic (computer science);image scaling;java;john d. wiley;open-source software;randomness;repository (version control);run time (program lifecycle phase);scalability;sensor;source lines of code;text corpus	Jeffrey Svajlenko;Iman Keivanloo;Chanchal Kumar Roy	2015	Journal of Software: Evolution and Process	10.1002/smr.1662	scalability;big data;computer science;engineering;software engineering;data mining;database;world wide web	SE	-66.6201056910189	36.649085443963614	45860
e2f00b57e1fced05d81a4cd84ffb27fc32328790	surfing the net for software engineering notes		It’s been about five years since I’ve done a column featuring nothing but open source software, so I figured it’s time to do it again. Regular readers know that I am a big fan of free and open source software, sometimes referred to by the acronym FOSS. Not only does FOSS provide for an immediate source of reuse code, thereby shortening the development cycle, but the ability of the developer to modify the software provides an additional tailoring feature not usually available to uses of commercial off the shelf (COTS) software.	chief information officer;commercial software;information assurance;internet;open-source software;regular expression;software engineering notes	Mark Doernhoefer	2011	ACM SIGSOFT Software Engineering Notes	10.1145/1968587.1968591		SE	-68.55878434084116	35.62036053159773	46476
41ec021de4a1fd62acfc83918cf8669bb7edcd81	spotlight on testing: stability, performance and operational testing of lanl hpc clusters	software reliability program testing;serviceability;spot reliability accessibility serviceability ras performance testing stability testing operational testing test framework high performance computing test driven development;reliability;performance test;measurement;test driven development;high performance computing;spot;maintenance engineering;testing;performance testing;usability requirements spotiight operational testing lanl hpc clusters system management high performance computing clusters large scale hpc cluster installation stability system testing;early warning;operational testing;large scale;stability testing;program testing;accessibility;lanl;high performance computer;stability analysis;configuration interaction;testing measurement stability analysis hardware maintenance engineering supercomputers;ras;test framework;software reliability;system management;supercomputers;hardware	Testing is sometimes a forgotten component of system management, but it becomes very important in the realm of High Performance Computing (HPC) clusters. Many large-scale HPC cluster installations are one of a kind, with unknown issues and unexpected behaviors. First, the initial installation may uncover complex configuration interactions that are only apparent at scale; Stability becomes a critical feature of early system testing. Second, Performance may be significantly impacted by small changes to the system. Third, after initial shakeout, users expect a system that is reliable on their terms; ongoing Operational tests verify reliability, and provide early warning of developing problems. A robust test suite should address all of these test categories, and present both tests and results in a manner that meets usability requirements. We will describe Los Alamos National Laboratory's current test suite, and the development project to expand the suite to cover these areas and provide better tools for analysis and reporting.	acceptance testing;computer;feedback;interaction;operational semantics;performance;requirement;robustness (computer science);scheduling (computing);software performance testing;sparse matrix;supercomputer;system testing;systems design;systems management;test suite;usability;virtual community	Georgia Pedicini;Jennifer B Green	2011	2011 International Conference for High Performance Computing, Networking, Storage and Analysis (SC)	10.1145/2063348.2063382	maintenance engineering;serviceability;test-driven development;von neumann stability analysis;parallel computing;systems management;simulation;software performance testing;computer science;accessibility;operating system;warning system;reliability;operational acceptance testing;software testing;software quality;measurement;statistics	HPC	-66.15336262265242	39.06045225746167	46780
72ccce4045e48c06d6d11671645bf256fafcb957	a stochastic model of attack process for the evaluation of security metrics	attack process;stochastic modeling;semi markov chain;cyber security;quantitative security evaluation;attack modeling;security metrics	To trust a computer system that is supposed to be secure, it is necessary to predict the degree to which the system’s security level can be achieved when operating in a specific environment under cyber attacks. In this paper, we propose a state-based stochastic model for obtaining quantitative security metrics representing the level of a system’s security. The main focus of the study is on how to model the progression of an attack process over time. The basic assumption of our model is that the time parameter plays the essential role in capturing the nature of an attack process. In practice, the attack process will terminate successfully, possibly after a number of unsuccessful attempts. What is important is, indeed, the estimation of how long it takes to be conducted. The proposed stochastic model is parameterized based on a suitable definition of time distributions describing attacker’s actions and system’s reactions over time. For this purpose, probability distribution functions are defined and assigned to transitions of the model for characterizing the temporal aspects of the attacker and system behavior. With the definition of the distributions, the stochastic model will be recognized to be a semi-Markov chain. This mathematical model will be analytically solved to calculate the desirable quantitative security metrics, such as mean time to security failure and steady-state security. The proposed method shows a systematic development of the stochastic modeling techniques and concepts, used frequently in the area of dependability evaluation, for attack process modeling. Like any other modeling method, the proposed model is also constructed based on some underlying assumptions, which are specific to the context of security analysis. 2013 Published by Elsevier B.V.	color gradient;computer;dependability;markov chain;mathematical model;process modeling;semiconductor industry;steady state;stochastic modelling (insurance);terminate (software)	Jaafar Almasizadeh;Mohammad Abdollahi Azgomi	2013	Computer Networks	10.1016/j.comnet.2013.03.011	computer security model;simulation;computer science;stochastic;computer security;statistics	Metrics	-64.35901064418151	59.3586672378822	47888
ab20822984860615e2e0da2dab88e35d4e3a2414	applying computational intelligence for enhancing the dependability of multi-cloud systems using docker swarm	reliability;virtualization;fuzzy reasoning;virtual machining;engines;containers;cloud computing	Multi-cloud systems have been gaining popularity due to the several benefits of the multi-cloud infrastructure such as lower level of vendor lock-in and minimize the risk of widespread data loss or downtime. Thus, the multi-cloud infrastructure enhances the dependability of the cloud-based system. However, it also poses many challenges such as nonstandard and inherent complexity due to different technologies, interfaces, and services. Consequently, it is a challenging task to design multi-cloud dependable systems. Virtualization is the key technology employed in the development of cloud-based systems. Docker has recently introduced its container-based virtualization technology for the development of software systems. It has newly launched a distributed system development tool called Swarm, which allows the development of a cluster of multiple Swarm nodes on multiple clouds. Docker Swarm has also incorporated several dependability attributes to support the development of a multi-cloud dependable system. However, making Swarm cluster always available requires minimum three active manager nodes which can safeguard one failure. This essential condition for the dependability is one of the main limitations because if two manager nodes fail suddenly due to the failure of their hosts, then Swarm cluster cannot be made available for routine operations. Therefore, this paper proposes an intuitive approach based on Computational Intelligence (CI) for enhancing its dependability. The proposed CI-based approach predicts the possible failure of the host of a manager node by observing its abnormal behaviour. Thus, this indication can automatically trigger the process of creating a new manager node or promoting an existing node as a manager for enhancing the dependability of Docker Swarm.	cloud computing;computation;computational intelligence;computer cluster;dependability;distributed computing;docker;downtime;earthbound;effective-;multicloud;simulation;software system;swarm;vendor lock-in;virtualbox;x86 virtualization	Nitin Naik	2016	2016 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2016.7850194	embedded system;real-time computing;simulation;engineering	Embedded	-63.44477968586635	43.10688784950865	48343
4c535cd6557b148cc048686ec64e20291b61c698	characteristics of useful code reviews: an empirical study at microsoft		Over the past decade, both open source and commercial software projects have adopted contemporary peer code review practices as a quality control mechanism. Prior research has shown that developers spend a large amount of time and effort performing code reviews. Therefore, identifying factors that lead to useful code reviews can benefit projects by increasing code review effectiveness and quality. In a three-stage mixed research study, we qualitatively investigated what aspects of code reviews make them useful to developers, used our findings to build and verify a classification model that can distinguish between useful and not useful code review feedback, and finally we used this classifier to classify review comments enabling us to empirically investigate factors that lead to more effective code review feedback.  In total, we analyzed 1.5 millions review comments from five Microsoft projects and uncovered many factors that affect the usefulness of review feedback. For example, we found that the proportion of useful comments made by a reviewer increases dramatically in the first year that he or she is at Microsoft but tends to plateau afterwards. In contrast, we found that the more files that are in a change, the lower the proportion of comments in the code review that will be of value to the author of the change. Based on our findings, we provide recommendations for practitioners to improve effectiveness of code reviews.	commercial software;open-source software;plateau effect	Amiangshu Bosu;Michaela Greiler;Christian Bird	2015	2015 IEEE/ACM 12th Working Conference on Mining Software Repositories		code review;empirical evidence;interview;computer science;engineering;operating system;software engineering;data mining;reliability;programming language;world wide web	SE	-65.62386124725084	33.747018728317265	50240
7be846b321a5d9a842cb129db3abc1d0e8a1d6f2	contributing to the bottom line: optimizing reliability-cost-schedule tradeoff and architecture scalability through test technology	software testing;file servers;software cost estimation;object oriented computing reliability cost schedule tradeoff architecture scalability software testing stop test decision economic model automated load test generation performance modeling web servers server side processing;software performance evaluation;economic model;software architecture;internet;program testing;object oriented;distributed object management;performance model;test generation;web server performance;software testing system testing cost function object oriented modeling fault detection automatic testing web server scalability context modeling application software;distributed object management software reliability software cost estimation software architecture program testing software performance evaluation file servers internet;software reliability	A challenging problem in software testing is finding the optimal point at which costs justify the stop-test decision. We first present an economic model that can be used to evaluate the consequences of various stop-test decisions. We then discuss two approaches for assessing performance, automated load test generation in the context of empirical testing and performance modeling, and illustrate how these techniques can affect the stop-test decision. We then illustrate the application of these two techniques to evaluating the performance of Web servers that performs significant server-side processing through object-oriented (OO) computing. Implications of our work for Web server performance evaluation in general are discussed.	optimizing compiler;scalability	D. Boyd;D. Cura;Willa K. Ehrlich;R. Gotberg;Rema Hariharan;Paul Reeser	2000		10.1109/ISSRE.2000.885867	reliability engineering;file server;software architecture;real-time computing;the internet;software performance testing;computer science;engineering;economic model;operating system;software engineering;database;software testing;object-oriented programming;software quality	EDA	-65.08750854135846	39.890420784255866	52228
4d5cb9260ca93915eb93c8b8958dd5818d146b35	dual-mode transmission networks for dtv	digital video broadcasting;value added services;primary tv network;chinese digitalization process;digital tv;dtv;functionality description;video on demand broadcast channels digital video broadcasting interactive television;indexing terms;structure function;interactive tv;servers;scale free;broad storage tv;single channel;indexing;streaming media;broadcast channels;dual mode transmission networks;self organized parallel broadcasting technology;video on demand;bandwidth;services on demand dual mode transmission networks dtv chinese digitalization process value added services primary tv network broad storage tv self organized parallel broadcasting technology uniform content locator functionality description digital interactive tv services;self organization;tv;broadcasting;uniform content locator;digital interactive tv services;digital tv tv broadcasting broadcast technology digital video broadcasting digital audio broadcasting sun costs multimedia communication iptv job shop scheduling;interactive television;services on demand	Chinese digitalization process of television hasn 't achieved anticipated goals as yet. No new value-added services for consumers, dissymmetrical development between service patterns and operation patterns, and the enormous input cost, are the dominant factors. To address these issues, a new dual-mode transmission networks for DTV (DMTN) is proposed in this study, in which the primary TV network is superimposed by a complementary framework based on broad-storage TV (BSTV). The necessity of congregating hot TV resources is discussed via analyzing the scale-free properties in DMTN. At the same time, the self-organized parallel broadcasting technology (SPBT) and uniform content locator (UCL) are studied in DMTN to utilize availably transmission channels and to help consumers to communicate with each other expediently. Experiment is designed and conducted, including system structure, functionality description, experiment parameters, and experiment results. Experimental results show that DMTN can provide not only traditional TV services on schedule, but also digital interactive TV services on demand using a single channel. DMTN is able to meet many individual consumers needs for video information, change the operation pattern of broadcast and television industry, and become an effective approach to advance the national informatization in low cost.	cluster analysis;degree distribution;e-government;feedback;online locator service;self-organization;service-oriented architecture;television;television set	Ling Xing;Jianguo Ma;Xian-He Sun;Youping Li	2008	IEEE Transactions on Consumer Electronics	10.1109/TCE.2008.4560117	digital television;telecommunications;computer science;multimedia;interactive television	Mobile	-72.08271007975007	42.42588084590487	53382
87d8459284fea576d2529d7325d8b32849c56d5f	perl debugger - pocket reference: because no one writes perfect code	perfect code		debugger;hamming bound;handbook;perl	Richard Foley	2004			parallel computing;computer science;theoretical computer science;programming language	Crypto	-91.3512002447724	33.08819760580839	53531
85714cd3a9aaa4f7448b2a075e28b026e9f3c7ef	understanding and implementing computer network protocols through a lab project	student experiments;formal specification;network protocol;testing and debugging;computer networks;computer network;transport protocols;computer science education;computational science and engineering;program testing;undergraduate student;educational courses;open systems computer science education transport protocols educational courses student experiments computer networks program debugging program testing;source code;link layer;program debugging;open systems interconnection reference model computer network protocols computer communications senior undergraduate students computer science computer engineering data link layer working network stack formal specifications source code writing lab project network protocol software writing network protocol debugging network protocol testing educational issues;computer science education transport protocols student experiments computer networks software debugging software testing open systems;open systems	This paper describes a lab project in computer communications and networks for senior undergraduate students in computer science and engineering. Given detailed specifications, students are asked to implement a data link layer (DLL) that integrates correctly with other provided layers to obtain a complete working network stack. This lab gives the students the opportunity to learn how to read formal specifications for a network project and write a complete piece of source code. It provides a comprehensive environment for students to write software for a network protocol, test and debug it, and observe its working behavior. In this paper, the authors present a technical description of the project and a discussion of related educational issues.		M. Watheq El-Kharashi;Glen Darling;Brent Marykuca;Gholamali C. Shoja	2002	IEEE Trans. Education	10.1109/TE.2002.1024621	communications protocol;link layer;computer science;electrical engineering;computational science and engineering;theoretical computer science;software engineering;formal specification;open system;transport layer;computer engineering;source code	Arch	-71.66497932774288	35.98006683604485	53606
7d3a67a51117dd95b93dabb5b5ecf62d10333e75	early software quality prediction based on software requirements specification using fuzzy inference system.		Software Requirements Specification (SRS) is the key fundamental document formally listing down the customer expectations from the software to be built. Any weakness or fault injected at this stage in the requirements is expected to ripple towards the following phases of software development life cycle resulting in development of a software system of poor quality. Software quality prediction promises to raise alarms about the quality of the end product at earlier stages. It becomes more challenging as we move earlier in stages because of limited information is available at earlier stages. Therefore little effort has been put in literature to predict software quality at SRS stage. This position paper presents a novel approach of prediction of software quality using SRS. SRS document is converted into a graph and different parameters including readability index, complexity, size and an estimation of coupling are extracted. These parameters are fed into a Fuzzy Inferencing System (FIS) to predict the quality of the end product. The proposed model has been evaluated on a sample of student projects and has shown reasonable performance.		Muhammad Hammad Masood;Malik Jahan Khan	2018		10.1007/978-3-319-95957-3_75	artificial intelligence;software quality;fuzzy logic;computer science;software requirements specification;software system;position paper;machine learning;reliability engineering;systems development life cycle;software;software requirements	SE	-63.44368808993108	33.12432638056078	54280
c667866043a72ebb4a4f0acdcb7d87ff43397ae7	adaptive rule loading and session control for securing web-delivered services	web services adaptive systems knowledge based systems learning artificial intelligence security of data;web application firewall;off line monitoring mode;session control web application firewall input validation reinforcement learning xss sql injection;reinforcement learning;rule based;http session listener;runtime protection mechanism;adaptive rule loading;arctic;servers;time factors;web service security;arctic system;adaptive systems;system resources utilization;sql injection;reinforcement learning technique;web services;adaptive reinforcement learning control technique;session control;input validation;web intrusion check;user behavior;j2ee container servlet filter;learning artificial intelligence;programmable control adaptive control learning arctic control systems monitoring security costs admission control delay;session admission control;security;information filters;xss;arctic system adaptive rule loading session control web service security adaptive reinforcement learning control technique web intrusion check rule based model validation rule set in line control mode off line monitoring mode reinforcement learning technique session admission control system resources utilization runtime protection mechanism http session listener j2ee container servlet filter;security of data;rule based model;knowledge based systems;validation rule set;admission control;in line control mode	In this paper, we present Arctic, an adaptive reinforcement learning control technique for web intrusion check. A rule-based model is designed to describe the requirement of vulnerability detection. The whole validation rule set is divided into multiple sections,and each can be enabled in either in-line control mode or off-line monitoring mode based on the observation and analysis of user behaviors, balancing security and system cost. For the different sizes of in-line validation rules, we use the reinforcement learning technique to adjust the session admission control, maintaining the response time in an acceptable level as well as maximizing the utilization of system resources. We design a runtime protection mechanism using a HTTP session listener and servlet filters in the J2EE container to intercept HTTP requests and responses. Preliminary results of our implementation are presented in this paper.	algorithm;hypertext transfer protocol;java platform, enterprise edition;logic programming;online and offline;protection mechanism;reinforcement learning;response time (technology);validation rule;visual intercept	Yu Zhang;Vugranam Sreedhar;Lin Luo;Shun Xiang Yang	2009	2009 Congress on Services - I	10.1109/SERVICES-I.2009.37	real-time computing;computer science;world wide web;computer security	ML	-63.847461387250824	55.868848903734246	54750
2ffcd27d4713997ca70e119325f67cbfde46e1f3	a tale of four kernels	software metrics;quality attributes;nontrivial software artifact linux operating systems solaris operating systems freebsd operating systems windows operating systems development processes source code file organization code structure code style data organization;opensolaris;freebsd;development process;comparison;wrk comparison freebsd linux open source opensolaris proprietary software;kernel linux operating systems open source software software quality software engineering permission technology management aggregates construction industry;operating system;system development;linux;source code;proprietary software;operating system kernels;software quality file organisation operating system kernels software metrics;software quality;wrk;open source;file organisation	The FreeBSD, GNU/Linux, Solaris, and Windows operating systems have kernels that provide comparable facilities. Interestingly, their code bases share almost no common parts, while their development processes vary dramatically. We analyze the source code of the four systems by collecting metrics in the areas of file organization, code structure, code style, the use of the C preprocessor, and data organization. The aggregate results indicate that across various areas and many different metrics, four systems developed using wildly different processes score comparably. This allows us to posit that the structure and internal quality attributes of a working, non-trivial software artifact will represent first and foremost the engineering requirements of its construction, with the influence of process being marginal, if any.	aggregate data;artifact (software development);c preprocessor;foremost;freebsd;gnu;linux;list of system quality attributes;marginal model;microsoft windows;operating system;programming style;requirement	Diomidis Spinellis	2008	2008 ACM/IEEE 30th International Conference on Software Engineering	10.1145/1368088.1368140	real-time computing;computer science;operating system;software engineering;database;software development process;linux kernel;software quality;software metric;source code	SE	-64.73495012219703	37.39288700284162	54756
4865886ba04d1a09d51ceefaccb30b79dbec92f0	evolutionary based moving target cyber defense	moving target defense;directed mutation;computer security	A Moving Target (MT) defense constantly changes a system's attack surface, in an attempt to limit the usefulness of the reconnaissance the attacker has collected. One approach to this defense strategy is to intermittently change a system's configuration. These changes must maintain functionality and security, while also being diverse. Finding suitable configuration changes that form a MT defense is challenging. There are potentially a large number of individual configurations' settings to consider, without a full understanding of the settings' interdependencies.  Evolution-based algorithms, which formulate better solutions from good solutions, can be used to create a MT defense. New configurations are created based on the security of previous configurations and can be periodically implemented to change the system's attack surface. This approach not only has the ability to discover new, more secure configurations, but is also proactive and resilient since it can continually adapt to the current environment in a fashion similar to systems found in nature.  This article presents and compares two genetic algorithms to create a MT defense. The primary difference between the two is based on their approaches to mutation. One mutates values, and the other modifies the domains from which values are chosen.	attack surface;genetic algorithm;interdependence;mutation (genetic algorithm);proactive parallel suite	David J. John;Robert W. Smith;William H. Turkett;Daniel A. Cañas;Errin W. Fulp	2014		10.1145/2598394.2605437	simulation;engineering;communication;computer security	Security	-65.75085871110065	59.938619265659824	55658
cedf2cc20266d9e52fd4bd7e7c55b4a14d4e0c81	where is the bug and how is it fixed? an experiment with practitioners		Research has produced many approaches to automatically locate, explain, and repair software bugs. But do these approaches relate to the way practitioners actually locate, understand, and fix bugs? To help answer this question, we have collected a dataset named DBGBENCH --- the correct fault locations, bug diagnoses, and software patches of 27 real errors in open-source C projects that were consolidated from hundreds of debugging sessions of professional software engineers. Moreover, we shed light on the entire debugging process, from constructing a hypothesis to submitting a patch, and how debugging time, difficulty, and strategies vary across practitioners and types of errors. Most notably, DBGBENCH can serve as reality check for novel automated debugging and repair techniques.	debugging;open-source software;patch (computing);reality check (tv series);software bug;software engineer	Marcel Böhme;Ezekiel O. Soremekun;Sudipta Chattopadhyay;Emamurho Ugherughe;Andreas Zeller	2017		10.1145/3106237.3106255	algorithmic program debugging;debugging;shotgun debugging;software bug;computer science;software;data mining;database	SE	-65.31537600517031	35.91627408881043	56090
13c6a884c6a9531dc8557d831d3bcd845df4c1ee	mining software history to improve software maintenance quality: a case study	software;history;process measurement;software maintenance;windows operating system;risk management;software maintenance operating systems computers program testing;software maintenance quality;software systems;testing;data mining;statistical model;microsoft process measurement maintenance process risk management binary change tracer bct;bct;microsoft;program testing;binary change tracer;binary change tracer tool software maintenance quality windows operating system software regression statistical model;maintenance process;binary change tracer tool;software maintenance software quality history predictive models data mining software systems error correction software testing software standards decision trees;predictive models;software regression;predictive regression;operating systems computers;data models	Errors in software updates can cause regressions failures in stable parts of the system. The Binary Change Tracer collects data on software projects and helps predict regressions in software projects.	patch (computing);software maintenance;software regression	Alexander Tarvo	2009	IEEE Software	10.1109/MS.2009.15	reliability engineering;statistical model;data modeling;personal software process;long-term support;verification and validation;team software process;software sizing;risk management;software project management;computer science;systems engineering;engineering;package development process;backporting;software reliability testing;software development;software engineering;software construction;database;predictive modelling;software testing;software walkthrough;software analytics;software maintenance;software deployment;software regression;software quality;software quality analyst;software system	SE	-63.505763848068405	33.920353953731635	58043
1e6008278923030ce82e2405306696e21e42a683	analyzing the effects of test driven development in github		"""Testing is an integral part of the software development lifecycle, approached with varying degrees of rigor by different process models. Agile process models recommend Test Driven Development (TDD) as a key practice for reducing costs and improving code quality. The objective of this work is to perform a cost-benefit analysis of this practice. Previous work by Fucci et al. [2, 3] engaged in laboratory studies of developers actively engaged in test-driven development practices. Fucci et al. found little difference between test-first behaviour of TDD and test-later behaviour. To that end, we opted to conduct a study about TDD behaviours in the """"wild"""" rather than in the laboratory. Thus we have conducted a comparative analysis of GitHub repositories that adopts TDD to a lesser or greater extent, in order to determine how TDD affects software development productivity and software quality. We classified GitHub repositories archived in 2015 in terms of how rigorously they practiced TDD, thus creating a TDD spectrum. We then matched and compared various subsets of these repositories on this TDD spectrum with control sets of equal size. The control sets were samples from all GitHub repositories that matched certain characteristics, and that contained at least one test file. We compared how the TDD sets differed from the control sets on the following characteristics: number of test files, average commit velocity, number of bug-referencing commits, number of issues recorded, usage of continuous integration, number of pull requests, and distribution of commits per author. We found that Java TDD projects were relatively rare. In addition, there were very few significant differences in any of the metrics we used to compare TDD-like and non-TDD projects; therefore, our results do not reveal any observable benefits from using TDD."""	agile software development;archive;continuous integration;floor and ceiling functions;java;mike lesser;observable;qualitative comparative analysis;software development process;software quality;test-driven development;velocity (software development)	Neil C. Borle;Meysam Feghhi;Eleni Stroulia;Russell Greiner;Abram Hindle	2018		10.1145/3180155.3182535	real-time computing;software development process;software quality;systems engineering;agile software development;software development;commit;computer science;process modeling;java;test-driven development	SE	-65.7902310256353	33.997839281442545	58388
e1142c1c4475567385510f0ff4205af4c9e60483	automatic generation of extended dependency graphs for network security	analytical models;telecommunication security telecommunication network management;automated modeling situational awareness network security network management dependency graphs impact prediction root cause analysis;availability;network security;network management domain extended dependency graphs automatic generation network security computational model administrative staff security relevant events;security computational modeling servers monitoring availability predictive models analytical models;situational awareness;servers;dependency graphs;computational modeling;monitoring;telecommunication security;root cause analysis;predictive models;network management;automated modeling;impact prediction;security;telecommunication network management	We introduce a computational model for networks that is suitable for supporting the administrative staff in estimating the threat that is caused by security relevant events, for identifying possible root causes for these events and for making predictions about the impact of attacks or countermeasures against attacks. We refer to expertise from the network management domain and extend the common methodologies to meet the demands of network security. We also describe how this model can be created and updated in an automatic way.	algorithm;artificial neural network;computation;computational model;countermeasure (computer);network model;network security	Heiko Günther;Marko Jahnke	2012	37th Annual IEEE Conference on Local Computer Networks	10.1109/LCN.2012.6423590	network management;situation awareness;availability;root cause analysis;computer science;network security;data mining;predictive modelling;computational model;computer security;server;computer network	Logic	-63.27270624209591	60.43204581211075	58408
92456379ccb20de5ac603fa291d5b68ecf26853c	are you still smelling it?: a comparative study between java and kotlin language		Java is one of the most widely used programming languages. However, Java is a verbose language, thus one of the main drawbacks of the language is that even simple tasks often entail writing a significant amount of code. In some cases, writing too much code might lead to certain code smells, which are violations of fundamental design that can negatively impact the overall quality of programs. To allow programmers to write concise code, JetBrains created a new language named Kotlin. Nevertheless, few studies have evaluated whether Kotlin leads to concise and clearer code in comparison to Java. We conjecture that due to Java's verbosity, programs written in Java are likely to have more code smells than Kotlin programs. Therefore, we set out to evaluate whether some types of code smells are more common in Java programs. To this end, we carried out a large-scale empirical study involving more than 6 million lines of code from programs available in 100 repositories. We found that on average Kotlin programs have less code smells than Java programs.	code smell;java;kotlin;programmer;programming language;source lines of code	Matheus Flauzino;Júlio Veríssimo;Ricardo Mingarini Terra;Elder Cirilo;Vinicius H. S. Durelli;Rafael Serapilha Durelli	2018		10.1145/3267183.3267186	kotlin;programming language;code smell;empirical research;constructed language;verbosity;code refactoring;java;computer science;source lines of code	PL	-64.32217999544041	36.62098178519729	59257
920780e4f07bc2f3d4f0c786643479fc66f79d06	web application performance: realistic work load for stress test	stress testing		web application	Mark M. Maccabee;Sheng Ma	2002			stress testing;web application;stress test;load testing;reliability engineering;computer science	HPC	-64.52512989862068	39.81579776392417	60090
1b574145f44e6336d4d1f13132b7566e43c26e31	sequence, tree and graph at the tip of your java classes			java	Øyvind Eide	2014			programming language;java;computer science;graph	NLP	-91.42261452745028	33.17020945520823	60686
84ee8976d89b385f39c544629d8deffb3c74272d	monitoring bottlenecks in achieving release readiness: a retrospective case study across ten oss projects	bottleneck identification;exploratory case study;retrospective analysis;release readiness	Context: Not releasing software on time can cause substantial loss in revenue. Continuous awareness of the product release status is required. Release readiness is a time-dependent attribute of the status of the product release, which aggregates the degree of satisfaction of a portfolio of release process and product measures.  Goal: At different stages of a release cycle, the goal is to understand frequencies and pattern of occurrence of factors affecting project success by restricting the status of release readiness (called bottlenecks).  Method: As a form of explorative case study research, we analyzed ten open source software (OSS) projects taken from the GitHub repository. As a retrospective study covering a period of 28 weeks, we monitored eight release readiness attributes and identified their impact on release readiness over time across the ten projects.  Results: Feature completion rate, Bug fixing rate, and Features implemented were observed as the most frequent bottlenecks. The most frequent transition between bottlenecks is from Pull-request completion rate to Bug fixing rate. With the exception of Pull-request completion rate, no significant differences were found in occurrence of bottleneck factors between early and late stage of the release cycle.  Conclusions: We received an initial understanding of the most frequent bottleneck factors for release readiness and their likelihood of subsequent occurrence. This is intended to guide the effort spent on improving release engineering.	bottleneck (software);open sound system;open-source software;release engineering;software release life cycle	S. M. Didar Al Alam;S. M. Shahnewaz;Dietmar Pfahl;Günther Ruhe	2014		10.1145/2652524.2652549	simulation;systems engineering;engineering;operations management	SE	-65.36792251188132	34.33567769483166	61037
f977f7a265546d8bc626cfad1c8a8e48e4a33aec	developer recommendation for crowdsourced software development tasks	systems;information systems;technology;theory methods;science technology;recommender system crowdsourced software development tasks developer recommendation developer task matching software deliverables content based recommendation techniques registration history winner history mining machine learners topcoder crowdsourcing platform;computer science;software engineering data mining learning artificial intelligence recommender systems;software crowdsourcing history reliability feature extraction accuracy testing	Crowdsourced software development utilises an open call format to attract geographically distributed developers to accomplish various types of software development tasks. Although the open call format enables wide task accessibility, potential developers must choose from a dauntingly large set of task options (usually more than one hundred available tasks on TopCoder each day). Inappropriate developer-task matching may lower the quality of the software deliverables. In this paper, we employ content-based recommendation techniques to automatically match tasks and developers. The approach learns particular interests from registration history and mines winner history to favour appropriate developers. We measure the performance of our approach by defining accuracy and diversity metrics. We evaluate our recommendation approach by introducing 4 machine learners on 3,094 historical tasks from TopCoder. The evaluation results show that promising accuracy and diversity are achievable (accuracy from 50% to 71% and diversity from 40% to 52% when recommending reliable developers).We also provide advice extracted from our results to guide the crowdsourcing platform in building a recommender system in practice.	accessibility;baseline (configuration management);cambridge structural database;crowdsourcing;programming paradigm;recommender system;social network;software bug;software development;wisdom of the crowd	Ke Mao;Ye Yang;Qing Wang;Yue Jia;Mark Harman	2015	2015 IEEE Symposium on Service-Oriented System Engineering	10.1109/SOSE.2015.46	crowdsourcing software development;computer science;systems engineering;artificial intelligence;data science;operating system;software engineering;data mining;database;world wide web;computer security;technology	SE	-66.92453491851774	36.44647366179805	61043
002e52d752687c23a965f9e225a6767cba79935f	a controlled experiment in program testing and code walkthroughs/inspections	debugging;data processing;controlled experiment;testing;program verification;code walkthroughs;code inspections;software reliability;personnel selection	This paper describes an experiment in program testing, employing 59 highly experienced data processing professionals using seven methods to test a small PL/I program. The results show that the popular code walkthrough/inspection method was as effective as other computer-based methods in finding errors and that the most effective methods (in terms of errors found and cost) employed pairs of subjects who tested the program independently and then pooled their findings. The study also shows that there is a tremendous amount of variability among subjects and that the ability to detect certain types of errors varies from method to method.	cognitive walkthrough;documentation;heart rate variability;n-gram;pl/i;personnel selection;programmer;software walkthrough;spatial variability;subroutine;unit testing;warez	Glenford J. Myers	1978	Commun. ACM	10.1145/359588.359602	real-time computing;simulation;data processing;computer science;software engineering;software testing;code coverage;programming language;debugging;software quality	SE	-63.8295902818281	33.418305357934294	61099
f6e9dd4f208263b1fe8632add4b0a2e9b911b601	enabling decentralised management through federation	relationship management;management system;articulo sintesis;analisis estructural;article synthese;gestion red;multimedia streaming;semantics;carta de datos;decentralized system;frequency response;requirement analysis;reponse frequence;respuesta frecuencia;semantic mapping;masquage;telecomunicacion;policy based management;enmascaramiento;mappage;telecommunication;multimedia communication;federation;gestion reseau;sistema descentralizado;masking;mapping;network management;systeme decentralise;analyse structurale;analisis semantico;analyse semantique;communication multimedia;review;structural analysis;management;use case;semantic analysis;telecommunications;generalization capability	Cross-domain management is an increasingly important concern in network management and such management capability is a key-enabler of many emerging computing environments. This paper analyses the requirements for management systems that aim to support flexible and general capability sharing between autonomously managed domains. It introduces a novel Layered Federation Model to structure this requirements analysis and describes the Federal Relationship Manager (FRM) which instantiates several layers of this model. The FRM combines semantic mapping management and authority delegation technologies to help solve several of the general management problems that are encountered whenever organisations enter into resource sharing agreements. An overview of related work on federation and the technical underpinnings of our approach are discussed and our particular relevance to real world problems is explained through two service-centric use cases for operator HAN owner federations. Finally, experimental results are presented to highlight the practical advantages of our approach.	relevance;requirement;requirements analysis;semantic mapper	Kevin Feeney;Rob Brennan;John Keeney;Hendrik Thomas;David Lewis;Aidan Boran;Declan O'Sullivan	2010	Computer Networks	10.1016/j.comnet.2010.07.006	use case;network management;requirements analysis;frequency response;simulation;telecommunications;decentralised system;computer science;masking;management system;semantics;structural analysis;operations research;computer security	DB	-64.87967472327517	48.06773685524624	61406
7316016ca3584ec30a87cf8df0992c2433811996	wearable context aware terminal for maintenance personnel	busqueda informacion;sensibilidad contexto;signal strength;wireless local area network;context aware;informatique mobile;maintenance;information retrieval;biometrie;localization;biometrics;biometria;terminal;localizacion;information access;localisation;recherche information;contexto;comportement utilisateur;contexte;mantenimiento;wireless lan;user behavior;sensibilite contexte;mobile computing;reseau local sans fil;context;comportamiento usuario	In modern process industries, a vast amount of information is gained during the process operation. Therefore it is difficult for the operators to build up a clear picture of the overall status of the process. Intelligent Systems Group has managed a project where a large production line is gradually divided into smaller and smaller subprocesses, from which diagnostic and performance data describing the behaviour of the process is produced. The project has developed generic hierarchical monitoring methods that are capable of refining subprocess performance data into overall process status information. Methodological Basics The basis of the methodology is in the hierarchical division of the plant into controllable subparts: process, subprocess, function and unit. This division follows the practical needs in process monitoring and control environment. The emphasis is on making the process accessible to the various user groups related to the process operation. It helps the operator to internalise process functions and connections more easily and makes learning more sensible. Further development, such as planning and implementing new operations in the plant, benefits from a clear map that points to the new function’s place and its interactions. Process disturbances are easier to diagnose when there are distinct areas to explore and as a consequence, recovery actions can be reached fast. In general, hierarchical division into controllable subparts acts as a platform for development projects and structures in a consistent manner covering all the operations required in running a process plant. In the unit level, several calculation and scaling methods were applied. They contain operations such as input control output standard deviation, rate of change, and absolute and relative deviations to the calculation machinery following the hierarchical structure. Unit level indices are aggregated to their corresponding function node by taking the maximum of their absolute value. Function level values are averaged to their top level subprocesses. The same principle is adopted in the process level calculation. A top level process node can serve as input to other higher level monitoring systems. It is possible to connect the nodes freely omitting the pure tree structure. All calculations, beginning from unit level, are performed in a normalised scale, for example 0-100. The scaling selection made is maintained from bottom to top in order to avoid rescaling. Various weighting, classification and hysteresis mechanisms have been designed in a proactive manner to meet the anticipated needs for more sophisticated information aggregation and reduction methods. The start up of the method implementation, however, has been intentionally kept very simple, because we want to develop an approach that is also tangible to the mill personnel. Case 1: Paper Machine A primary concern in papermaking is to reduce quality variations and improve process efficiency. The reasons for process upsets fall into two broad categories: some are obvious to process operators and others remain partly hidden. A tool that systematically reduces information flow and points to most probable subprocesses causing the upset can help the personnel to discover the reasons for poor performance. In this case we developed a prototype monitoring system for a SC paper machine at UPMKymmene Kajaani Mills in Finland. The first phase prototype has been in continuous on-line operation from the beginning of 2002. Its operation during process upsets has been observed and pros and cons have been registered for further development. Case 2: Steel Plate Mill Successful temperature control during heating, rolling and cooling of a plate is an essential part of steel plate manufacturing. There are targets for temperatures and temperature profiles after heating, rolling and accelerated cooling. There is a need for a system that monitors temperatures of the process and can help operators to locate units that cause disturbances in the temperatures. The developed system has been installed at the Rautaruukki Steel’s steel plate rolling line. This line is part of the larger process of steel manufacturing and is the final stage in the process. The rolling line consists of the following subprocesses: heating of the slabs, rolling of the slabs, cooling of the plates, and further processing of the steel plates. The operation of the rolling line was evaluated by performance indices. The indices were fed into the lowest level nodes, and from these indices the hierarchical system calculated the performance indices for each hierarchical level. The values of the nodes were visualised for the user. The system’s inputs were fuzzified results of analysed temperature measurements of steel plates. Fuzzified performance indices of furnaces were used as inputs. The hierarchical structure gave an effective resource for a user to focus on monitoring from process level to unit level. The hierarchical structure highlighted the disturbances that are not usually discovered easily. Typically, there are dozens of control loops in the automation sys-	child process;class implementation file;computer cooling;control flow;experiment;hysteresis;image scaling;interaction;midlet;mobile phone;online and offline;process state;prototype;server (computing);tree structure;volume rendering;wearable computer	Heikki Ailisto;Ville Haataja;Vesa Kyllönen;Mikko Lindholm	2003		10.1007/978-3-540-39863-9_12	signal strength;embedded system;internationalization and localization;computer science;operating system;mobile computing;world wide web;computer security;biometrics	HPC	-75.20510868088311	37.39333266564066	61621
86f15d3cdaa8e41c9a565269eecc973475f8f798	a study of video-on-demand learning system in e-learning platform	periodic broadcasting scheme e learning video on demand learning system edge server;edge server;periodic broadcasting scheme;electronic commerce;video broadbcasting e learning platform video on demand learning system vod learning system edge server;e commerce;computer aided instruction;e learning system;learning systems electronic learning bandwidth network servers broadcasting computer science education computer networks educational technology business commercialization;learning system;video on demand;e learning;education system;video on demand learning system;video on demand computer aided instruction electronic commerce;distributed architecture	E-learning concerns an education system based on computer and network technology and has become one of the most potential e-commerce business. As one kind of e-learning system, video-on-demand (VOD) learning system can offer learners additional approach to absorb new knowledge without the restriction of time and place. Many researches have proved that bandwidth is a key factor to commercialize VOD system. Centralized and distributed architectures of VOD learning system are proposed in this paper. Edge server is proposed to share the burden of Core Server and handle demands directly. Broadcasting popular videos by using periodic broadcasting scheme can effectively reduce the network bandwidth.	centralized computing;e-commerce;multicast;server (computing);versant object database	Ping Zhang;Weizhong Liu;Xuecheng Zou	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.52	e-commerce;simulation;computer science;operating system;database;multimedia;world wide web	DB	-70.81475206012196	47.45661013198488	62428
2cbc17905a585bd19a0af579ccfaeabc29286dba	code clones: reconsidering terminology		This report discusses terminology choices and considerations relating to copied or redundant code within software systems, i.e., relating to “code clones.” Inadequacies of existing terminology are raised and alternative terms are discussed.	qr code;software system	Andrew Walenstein	2006			software system;redundant code;terminology;database;computer science	SE	-63.74259374382727	35.59917329873011	64001
93494b72394a0de196a45d343e0d0929340ed85c	a method of network security situation assessment based on hidden markov model		In the network security situation assessment based on hidden Markov model, the establish of state transition matrix is the key to the accuracy of the impact assessment. The state transition matrix is often given based on experience. However, it often ignores the current status of the network. In this paper,based on the game process between the security incidents and protect measures,we improve the efficiency of the state transition matrix by considering the defense efficiency. Comparative experiments show the probability of the network state generated by improved algorithm is more reasonable in network security situation assessment.	hidden markov model;markov chain;network security	Shuang Xiang;Yanli Lv;Chunhe Xia;Yuanlong Li;Zhihuan Wang	2015		10.1007/978-981-10-0356-1_65	machine learning;causal markov condition;markov blanket;pattern recognition;data mining;markov process;markov model	Crypto	-64.37723497292582	60.068310672627824	65026
49d8960d427ab7c43af8f256156e97f1121ea2e4	panel 2 report: autonomic communication roadmap	network management;autonomous control	Situated and Autonomic Communication (AC) research roadmap needs to be addressed from a mixture of viewpoints. What are the market drivers for AC? Can we really automate SLA? Does it help AC to radically depart from TCP/IP? Do we know all new requirements for networking software, auto- and re-configuration? How autonomics shall transform network management? What's the role of governance in autonomic control hierarchy, and do we know how hierarchy should emerge? These and similar questions were used to set the scene for the panel discussion on AC roadmap.	autonomic computing	Mikhail I. Smirnov	2005		10.1007/11687818_28	real-time computing;simulation;engineering;computer security	Robotics	-69.73693097556398	41.95938782686662	68211
27b638b9de3125ae822d5562a1d7640f487fb302	improving network operations with intelligent agents	intelligent agent	I ntelligent agents are autonomous and adaptcreating agents, agent-managers for deploying and managing agents across a network, and sample ive software programs that accomplish their tasks by executing preassigned commands intelligent agents that are ready to run and which can be customized by the user for particular needs. remotely. System administrators, network managers, and software developers can create and The agent-manager concept is not new. The manager–agent relationship is intrinsic to most use intelligent agents to execute critical processes including performance monitoring, fault detection standard network management protocols, including the Simple Network Management Protocol and restoral, and asset management. With the concept enjoying increasing acceptance, vendors are (SNMP) used to manage TCP/IP networks. In fact, SNMP agents are widely available for all kinds of offering integrated development environments for network devices, including bridges, routers, hubs, multiplexers and switches. Nathan Muller is an independent consultant in Huntsville, AL, specIn the SNMP world, agents respond to polls ializing in advanced technology marketing and education. In his 25 from an SNMP management station that requests years of industry experience, he has written extensively on many information on the operational status of the variaspects of computers and communications, having published twelve ous devices on the network. Based on that inforbooks and over 1000 articles. He has held numerous technical and marketing positions with such companies as Control Data Corp., mation, agents are then directed by the managePlanning Research Corp., Cable & Wireless Communications, ITT ment station to get more data, set management Telecom, and General DataComm Inc. He has an MA in Social and variables, or generate traps when specified Organizational Behavior from George Washington University. events occur. However, the agents used in conjunction with *Correspondence to: Nathan J. Muller, 1930 Wrenwood Drive SE, Hunstville, AL 35803, USA. Email: nmullerKddx.com SNMP are not very efficient. To retrieve the col-	autonomous robot;computer;email;fault detection and isolation;integrated development environment;intelligent agent;internet protocol suite;multiplexer;network switch;organizational behavior;router (computing);simple network management protocol;software developer;system administrator	Nathan J. Muller	1997	Int. Journal of Network Management	10.1002/(SICI)1099-1190(199705/06)7:3%3C116::AID-NEM239%3E3.0.CO;2-Q	agent architecture;intelligent computer network;intelligent decision support system;computer science;artificial intelligence;operations research;intelligent agent	AI	-74.56779442957082	39.637563103578145	68418
54fdb5aca5292f441a9440556529646e5bb81ae0	evaluating the usefulness and the ease of use of a web-based inspection data collection tool	databases;inspection software tools instruments software engineering computer science cost accounting monitoring databases data analysis councils;software metrics;information resources;inspection techniques;world wide web ease of use web based tool inspection data collection tool software tools user acceptance technology acceptance model questionnaire based measurement user perspective usefulness tool usage wips experiment computer science students professional software developers inspection techniques;instruments;subjective measurement;questionnaire based measurement;web based tool;data collection;information technology;technology acceptance model;inspection tool support;controlled experiment;inspection;software engineering;user perspective;ease of use;professional software developers;empirical evidence;data analysis;cost accounting;human factors;internet;monitoring;factor analysis;tool usage;process support;computer science students;software development;councils;tools and techniques;world wide web;software metrics information resources internet user interfaces human factors software tools;software tools;experiment;computer science;usefulness;coded modulation;wips;user interfaces;user acceptance;inspection data collection tool;perceived usefulness	This paper contributes a valid and reliable measure ment instrument in the form of a questionnaire to determine, from a user’s perspective, the usefulnes s and ease of use of a Web-based Inspection Process Support tool (WIPS) that we developed for inspectio n data collection. The questionnaire is built upon the work of Fred Davis on perceived usefulness, eas e of use, and usage of information technology. To validate the questionnaire and its underlying model as well as to evaluate WIPS, we performed a controlled experiment with computer science students a s ubjects. The subjects performed inspection of a code module and used WIPS for collecting defect and effort data. Once they had completed the code inspection, they filled out the usefulness and ease of use questionnaire. Our experimental results provide empirical evidence that the questionnaire is a reliable measurement instrument (cronbach alpha: 0.84 for usefulness; 0. 82 for ease of use). Factor analysis revealed that the questionnaire items discriminate between two di fferent concepts: usefulness and ease of use. Since WIPS received high ratings for both concepts, we ca n conclude that the subjects consider WIPS useful and easy to use. These results, together with the f act that usefulness was significantly correlated to selfpredicted future usage, imply that our subjects pre fer d WIPS over paper-based forms for inspection data collection. We are aware that a single experiment does not prov ide conclusive evidence. Hence, we consider our results as a baseline against which other researche rs can compare their results when utilizing the pre sented questionnaire. However, its use is not limit ed to inspection tools, but applies to the usefulne ss/ ease of use evaluation of tools and techniques in g eneral. To demonstrate this, we present preliminary results of a controlled experiment we are currently performing with professional software developers i n an industrial setting to evaluate different inspect ion techniques.	baseline (configuration management);computer science;factor analysis;fred (chatterbot);software bug;software developer;usability;wireless intrusion prevention system	Oliver Laitenberger;Horst M. Dreyer	1998		10.1109/METRIC.1998.731237	experiment;the internet;empirical evidence;usability;inspection;human–computer interaction;computer science;systems engineering;engineering;software development;data mining;factor analysis;data analysis;user interface;information technology;wireless intrusion prevention system;software metric;statistics;cost accounting;data collection	SE	-65.46847197694936	32.746196372496854	68521
0fd323563a8c6959762e166c9a6cb0297f37f296	enabling statistical analysis of suppressed tabular data		For decades, NSOs have usedcomplementary cell suppression for disclosure limitation of tabular data, magnitude data in particular. Indications of its continued use abound, even though suppression thwarts statistical analysis of both the expert and the novice. We introduce methods for creating alternative tables that the NSO can release unsuppressed, while ensuring within statistical certainty that their analysis is conformal with analysis of the original.	table (information)	Lawrence H. Cox	2014		10.1007/978-3-319-11257-2_1	data mining	Logic	-64.32133169132861	53.57083343603759	68655
b3c30cc756577374d8a813e2f002d66858a3b123	a conceptual replication study on bugs that get fixed in open source software		"""Bugs dominate the corrective maintenance and evolutionary changes in large-scale software systems. The topic of bugs has been extensively investigated and reported in the literature. Unfortunately, the existential question of all """"whether a reported bug will be fixed or not"""" has not received much attention. The paper presents an empirical study on four open source projects to examine the factors that influence the likelihood of a bug getting fixed or not. Overall, our study can be contextualized as a conceptual replication of a previous study on Microsoft systems from a commercial domain. The similarities and differences in terms of the design, execution, and results between the two studies are discussed. It was observed from these systems that the reputations of the reporter and assigned developer to fix it, and the number of comments on a bug have the most substantial impact on its probability to get fixed. Moreover, we formulated a predictive model from features available as soon as a bug is reported to estimate whether it will be fixed or not. Intra and inter (cross) project validations were performed. Precision and Recall metrics were used to assess the predictive model. Their values were recorded in the 60% to 70% range."""	eclipse;evaluation function;lr parser;libreoffice;linux;logistic regression;open-source software;precision and recall;predictive modelling;reputation;software bug;software system;support vector machine	Haoren Wang;Huzefa H. Kagdi	2018	2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)	10.1109/ICSME.2018.00039	software bug;software system;systems engineering;support vector machine;computer science;empirical research;data mining;software;corrective maintenance;precision and recall	SE	-64.27025370771604	34.794108458856094	69766
88997c8b7daa74cd822d82bf33581c8fa966a347	code review quality: how developers see it	software;review quality;electronic mail;measurement;developer perception;data mining;code review;face;computer science;computer bugs;survey	In a large, long-lived project, an effective code review process is key to ensuring the long-term quality of the code base. In this work, we study code review practices of a large, open source project, and we investigate how the developers themselves perceive code review quality. We present a qualitative study that summarizes the results from a survey of 88 Mozilla core developers. The results provide developer insights into how they define review quality, what factors contribute to how they evaluate submitted code, and what challenges they face when performing review tasks. We found that the review quality is primarily associated with the thoroughness of the feedback, the reviewer's familiarity with the code, and the perceived quality of the code itself. Also, we found that while different factors are perceived to contribute to the review quality, reviewers often find it difficult to keep their technical skills up-to-date, manage personal priorities, and mitigate context switching.	context switch;open-source software;software quality	Oleksii Kononenko;Olga Baysal;Michael W. Godfrey	2016	2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)	10.1145/2884781.2884840	face;software bug;code review;computer science;systems engineering;software engineering;data mining;measurement	SE	-65.8618402669658	33.469677444531065	70404
b5b398c4580c739810fa9de874e57cf16e7f988e	how preprocessor annotations (do not) affect maintainability: a case study on change-proneness		Preprocessor annotations (e.g., #ifdef in C) enable the development of similar, but distinct software variants from a common code base. One particularly popular preprocessor is the C preprocessor, cpp. But the cpp is also widely criticized for impeding software maintenance by making code hard to understand and change. Yet, evidence to support this criticism is scarce. In this paper, we investigate the relation between cpp usage and maintenance effort, which we approximate with the frequency and extent of source code changes. To this end, we mined the version control repositories of eight open- source systems written in C. For each system, we measured if and how individual functions use cpp annotations and how they were changed. We found that functions containing cpp annotations are generally changed more frequently and more profoundly than other functions. However, when accounting for function size, the differences disappear or are greatly diminished. In summary, with respect to the frequency and extent of changes, our findings do not support the criticism of the cpp regarding maintainability.	approximation algorithm;c preprocessor;commitment scheme;compiler;conditional compilation;experiment;heart rate variability;java annotation;list comprehension;mined;program comprehension;proxy server;software maintenance;version control	Wolfram Fenske;Sandro Schulze;Gunter Saake	2017		10.1145/3136040.3136059	maintainability;computer science;data mining;database;software;source code;criticism;software maintenance;preprocessor	SE	-64.65797297330684	36.94982458240298	70904
abd1af98b9deb895e7d03aeec1187d16a2058533	deploying lightweight processes (poster session)	metaobject protocols;byte code rewriting;reflection;java	2. Why lightweight processes? Lightweight processes arise due to the need to speed up delivery, coupled with the desire to follow a disciplined development process. Although large teams might need lots of process, smaller teams can get away with less process. A key aspect that all lightweight processes have to balance is controlling programmers tendencies to “code first and ask questions afterwards” a Cowboy Coder approach that is often incorrectly labeled “Hacking”.	cowboy coding;light-weight process;programmer	Jens Coldewey;Jutta Eckstein;Pete McBreen;Christa Schwanninger	2000		10.1145/367845.368034	real-time computing;reflection;computer science;database;programming language;java	SE	-70.24243210479763	34.03092695104915	71333
14c517bb6a59ce5eaef6aa8900470245f7c63863	studying the fix-time for bugs in large open source projects	low priority;three dimensions;mining software repositories;software maintenance;projection method;fixed time;empirical software engineering;sensitivity analysis;random forest;bug fix time;open source	Background: Bug fixing lies at the core of most software maintenance efforts. Most prior studies examine the effort needed to fix a bug (fix-effort). However, the effort needed to fix a bug may not correlate with the calendar time needed to fix it (fix-time). For example, the fix-time for bugs with low fix-effort may be long if they are considered to be of low priority.  Aims: We study the fix-time for bugs in large open source projects.  Method: We study the fix-time along three dimensions: (1) the location of the bug (e.g., which component), (2) the reporter of the bug, and (3) the description of the bug. Using these three dimensions and their associated attributes, we examine the fix-time for bugs in two large open source projects: Eclipse and Mozilla, using a random forest classifier.  Results: We show that we can correctly classify ~65% of the time the fix-time for bugs in these projects. We perform a sensitivity analysis to identify the most important attributes in each dimension. We find that the time of the filing of a bug and its location are the most important attributes in the Mozilla project for determining the fix-time of a bug. On the other hand, the fix-time in the Eclipse project is highly dependant on the severity of the bug. Surprisingly, the priority of the bug is not an important attribute when determining the fix-time for a bug in both projects.  Conclusion: Attributes affecting the fix-time vary between projects and vary over time within the same project.	bug tracking system;eclipse;open-source software;random forest;software bug;software maintenance	Lionel Marks;Ying Zou;Ahmed E. Hassan	2011		10.1145/2020390.2020401	random forest;three-dimensional space;real-time computing;computer science;software engineering;machine learning;data mining;projection method;software maintenance;software regression;world wide web;sensitivity analysis	SE	-64.61971243201472	34.745688400434666	71362
4090be6e90b7478b2cf98c31f6813da16c609f45	acm tosem: faqs and figures	formal specification;failure;software verification;object z;stakeholder;testing;do 178b;requirements;model checking;software safety;risk;derived requirements;model abstraction;consistency;specification testing	It's been a while since I've written a column on TOSEM. One reason for this is, of course, that I simply haven't gotten to it. The other reason for this is because of you: I've had few, if any, questions or comments about TOSEM from the SEN readership. If this was because everything at TOSEM was perfect and we were so transparent that you knew everything we knew, I'd be thrilled. But that's just never the case. So, please send me email with your comments, questions, concerns, TOSEM-related jokes, or whatever.		David Notkin	2007	ACM SIGSOFT Software Engineering Notes	10.1145/1241572.1241574	model checking;requirements analysis;stakeholder;do-178b;software verification;computer science;engineering;software engineering;formal specification;risk;database;software testing;consistency;programming language;algorithm	SE	-69.23201877460394	32.64288056498023	72120
84605fcf24f648a560dcab5e061a42ec91594c53	on mining sensor network software repositories	cross cutting concerns;mining software repositories;sensor network;wireless sensor network;operating system;typical development;wireless sensor networks;open source	Wireless Sensor Network (WSN) software is typically developed in one of the two prominent WSN operating systems: TinyOS or Contiki. Both of these operating systems are open-source projects and basically frameworks for WSN developers. In this paper, we study the software repositories of these two projects. Software repositories provide a wealth of information on software projects and their development. Based on the mined information, we explore the TinyOS and Contiki commit history and compare them to an open-source embedded operating system, Ethernut. As a second step, we explore WSN-specific artifacts and mine TinyOS software for cross-cutting concerns. Most of the relations we find are not cross-cutting. Nevertheless, we do find cross-cutting concerns that are resource-related.	contiki;cross-cutting concern;embedded operating system;embedded system;ethernut;mined;open-source software;software repository;tinyos	Andreas Loukas;Matthias Woehrle;Koen Langendoen	2011		10.1145/1988051.1988057	real-time computing;wireless sensor network;engineering;key distribution in wireless sensor networks;nesc;world wide web;computer security;software system	SE	-66.57566429613327	37.084193467733456	73197
f5ff22c94091dae343ec6246caafa78d8ad36ff8	predicting rankings of software verification competitions		Soware verication competitions, such as the annual SV-COMP, evaluate soware verication tools with respect to their eectivity and eciency. Typically, the outcome of a competition is a (possibly category-specic) ranking of the tools. For many applications, such as building portfolio solvers, it would be desirable to have an idea of the (relative) performance of verication tools on a given verication task beforehand, i.e., prior to actually running all tools on the task. In this paper, we present a machine learning approach to predicting rankings of tools on verication tasks. e method builds upon so-called label ranking algorithms, which we complement with appropriate kernels providing a similarity measure for verication tasks. Our kernels employ a graph representation for soware source code that mixes elements of control ow and program dependence graphs with abstract syntax trees. Using data sets from SV-COMP, we demonstrate our rank prediction technique to generalize well and achieve a rather high predictive accuracy. In particular, our method outperforms a recently proposed feature-based approach of Demyanova et al. (when applied to rank predictions).	abstract syntax tree;algorithm selection;android;automated planning and scheduling;graph (abstract data type);kernel (operating system);learning to rank;linear algebra;machine learning;malware;similarity measure;software verification;systemverilog;tree (data structure);warez	Mike Czech;Eyke Hüllermeier;Marie-Christine Jakobs;Heike Wehrheim	2017	CoRR		learning to rank;graph (abstract data type);machine learning;artificial intelligence;similarity measure;software;source code;mathematics;software verification;ranking;abstract syntax	ML	-62.87515508165503	39.15288111204001	73385
22aaa543842ba7cd627d5ec564443be0e278f419	influence of identifier length and semantics on the comprehensibility of source code		Identifiers are essential for the understanding of source code. Programmers can name them arbitrarily, which is a major source for hard to understand code. We investigated how an identifier’s length and semantics affect program comprehensibility. In a controlled experiment, we showed that identifier names using proper words lead to a faster defect detection than identifier names using abbreviated words or single letters.	identifier;programmer;software bug	Johannes Hofmeister;Janet Siegmund;Daniel V. Holt	2016	Softwaretechnik-Trends		programming language;computer science;source code;identifier;semantics	SE	-64.097375842129	36.83086428116237	73799
0d71b88e2c9b499ac0d36ad327a5a6d78f53c27c	personalized defect prediction	master thesis;defect prediction;software reliability change classification machine learning personalized defect prediction;machine learning;change classification;linux;program compilers java linux;program compilers;software reliability;predictive models vectors mars syntactics computer bugs training feature extraction;java;jackrabbit personalized defect prediction separate prediction model coding styles commit frequencies experience levels different defect patterns software defect prediction c software projects java software projects linux kernel postgresql xorg eclipse lucene	Many defect prediction techniques have been proposed. While they often take the author of the code into consideration, none of these techniques build a separate prediction model for each developer. Different developers have different coding styles, commit frequencies, and experience levels, causing different defect patterns. When the defects of different developers are combined, such differences are obscured, hurting prediction performance. This paper proposes personalized defect prediction-building a separate prediction model for each developer to predict software defects. As a proof of concept, we apply our personalized defect prediction to classify defects at the file change level. We evaluate our personalized change classification technique on six large software projects written in C and Java-the Linux kernel, PostgreSQL, Xorg, Eclipse, Lucene and Jackrabbit. Our personalized approach can discover up to 155 more bugs than the traditional change classification (210 versus 55) if developers inspect the top 20% lines of code that are predicted buggy. In addition, our approach improves the F1-score by 0.01-0.06 compared to the traditional change classification.	eclipse;f1 score;java;linux;personalization;postgresql;programming style;software bug;source lines of code;x.org server	Tian Jiang;Lin Tan;Sunghun Kim	2013	2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)	10.1109/ASE.2013.6693087	computer science;engineering;operating system;software engineering;data mining;database;programming language;java;linux kernel;software quality	SE	-62.94025037938057	35.87272990048619	74566
1b97ccd0910501609429426b84b3b1241bda4c8e	web-based troubleshooter generation for system administration	computer system administration;html code;computers;fault diagnosis web based troubleshooter generation computer system administration trouble diagnosis html code client server interface;web pages;history;computational modeling information science intelligent systems web pages html history circuit faults voltage computer simulation computer science;computer debugging;troubleshooting;client server systems;computer administration;data mining;web applications;automatic generation;html;automatic generation web applications troubleshooting computer administration;client server;internet;internet client server systems computer debugging fault diagnosis;web based troubleshooter generation;trouble diagnosis;web server;titanium;client server interface;fault diagnosis	This paper proposes a method for generating a Web-page based troubleshooter, which diagnoses troubles about computer system administration. This troubleshooter digs out several possible causes (hypotheses) from the current status of a trouble, and then examines those hypotheses in turn. After the cause is identified, it will present a solution to fix the trouble. To illustrate the status of a trouble, possible causes,examination methods and presentation of a solution, WebPages (hereafter, info pages) are used, which are defined in HTML code. From the info pages that explain each status of troubleshooting, the method this paper presents generates troubleshooter client/server interface, a stack of status history and titled links to the next info pages. This paper also describes two ways to easily implement this method on both of a client side and a server side.	client-side;client–server model;computer;html;server (computing);server-side;system administrator	Takao Shimomura;Kenji Ikeda;Muneo Takahashi	2009	2009 WRI World Congress on Computer Science and Information Engineering	10.1109/CSIE.2009.205	titanium;web application;the internet;html;computer science;operating system;troubleshooting;web page;data mining;database;world wide web;web server;client–server model	Web+IR	-62.91872530544336	54.57768265657662	75750
32fb82a6fa08b839de3fcd6b81dbea777db61463	installation change control within a large system operating environment			change control;operating environment	Norman Rudikoff	1984			real-time computing;operating environment;engineering;change control	Robotics	-72.82569118978431	36.08015848804026	76361
ef8e3e4b1b936b1dc49497ab2ec402c1842650f3	an empirical study on refactoring activity		This paper reports an empirical study on refactoring activity in three Java software systems. We investigated some questions on refactoring activity, to confirm or disagree on conclusions that have been drawn from previous empirical studies. Unlike previous empirical studies, our study found that it is not always true that there are more refactoring activities before major project release date than after. In contrast, we were able to confirm that software developers perform different types of refactoring operations on test code and production code, specific developers are responsible for refactorings in the project, refactoring edits are not very well tested. Further, floss refactoring is more popular among the developers, refactoring activity is frequent in the projects, majority of bad smells once occurred they persist up to the latest version of the system. By confirming assumptions by other researchers we can have greater confidence that those research conclusions are generalizable.	code refactoring;code smell;java;software developer;software release life cycle;software system	Mohammad Iftekharul Hoque;Vijay Nag Ranga;Anurag Reddy Pedditi;Rachitha Srinath;Md Ali Ahsan Rana;Md Eftakhairul Islam;Afshin Somani	2014	CoRR		reliability engineering;systems engineering;engineering;software engineering	SE	-64.22326054404493	34.78765691128414	76379
394682c66bc354696da22b90153da8e3780d9ef4	automating web application testing from the ground up: experiences and lessons learned in an industrial setting		Automating web application testing is a very tricky process due to inherent complexity, dynamic behavior(s) in web pages, differences in the way browsers render the same content (especially on different form factors), and so on. Yet manual testing is not a practical option, and such automation is a must in the interests of effectiveness and efficiency, because of the large number of browsers/devices that users can choose from, and also given the rapid software development cycles of today. This paper discusses our efforts at Varidesk to automate web tests against our main website – which offers many features and content, but is also a true eCommerce site where users from around the globe can purchase a very broad variety of active workspace solutions that we offer. Our solution was developed in-house, from the ground up, and leveraged and extended freely available automation and test libraries such as Selenium WebDriver and NUnit respectively. We talk about the challenges we faced and how we overcame them, as well as provide technical insights on real-world concerns such as managing test brittleness, and integrating the web tests into an existing Continuous Integration and Continuous Deployment (CI/CD) pipeline. Part of the novelty of this paper is that we are also transparent on the rationale behind our decision to build versus buy, and how we managed resources, especially in terms of cost. We also present lessons learned, and encouraged by the success that we have observed, hope that the results will be beneficial to academia and practitioners alike.	complexity;computer form factor;continuous integration;design rationale;devops;docker;e-commerce;library (computing);mapper;manual testing;nunit;requirement;robustness (computer science);seamless3d;selenium;software deployment;software development;web 2.0;web application;web page;web testing;workspace	Vidroha Debroy;Lance Brimble;Matthew Yost;Archana Erry	2018	2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)	10.1109/ICST.2018.00042	web testing;automation;real-time computing;computer science;web page;novelty;workspace;software deployment;systems engineering;manual testing;software development	SE	-67.43772973849762	36.38771906744394	76580
4957b62108031ec4bfa34962590665ee1c38c3c7	predicting method crashes with bytecode operations	agile;prediction method;business models;monitoring system;software development;digitization;integrated enterprise;classification accuracy;management;high performance;open source	Software monitoring systems have high performance overhead because they typically monitor all processes of the running program. For example, to capture and replay crashes, most current systems monitor all methods; thus yielding a significant performance overhead. Lowering the number of methods being monitored to a smaller subset can dramatically reduce this overhead. We present an approach that can help arrive at such a subset by reliably identifying methods that are the most likely candidates to crash in a future execution of the software. Our approach involves learning patterns from features of methods that previously crashed to classify new methods as crash-prone or non-crash-prone. An evaluation of our approach on two large open source projects, ASPECTJ and ECLIPSE, shows that we can correctly classify crash-prone methods with an accuracy of 80--86%. Notably, we found that the classification models can also be used for cross-project prediction with virtually no loss in classification accuracy. In a further experiment, we demonstrate how a monitoring tool, RECRASH could take advantage of only monitoring crash-prone methods and thereby, reduce its performance overhead and maintain its ability to perform its intended tasks.	aspectj;crash (computing);eclipse;open-source software;overhead (computing)	Sunghun Kim;Thomas Zimmermann;Rahul Premraj;Nicolas Bettenburg;Shivkumar Shivaji	2013		10.1145/2442754.2442756	business model;embedded system;real-time computing;simulation;computer science;software development;operating system;agile software development;management;world wide web;computer security	SE	-63.69472481041041	38.599843998322676	77094
46c1023741a3eeb9e881d5ef6ca99d8dc50c495f	user interface defect detection by hesitation analysis	user difficulty instance detection user interface defect detection hesitation analysis;hesitation analysis;user interfaces humans laboratories usability delay testing computer errors computer interfaces error analysis failure analysis;user interface;false alarm rate;testing;interface design;user interfaces human factors;user difficulty instance detection;failure analysis;error analysis;human factors;user experience;ground truth;humans;user interface defect detection;computer interfaces;usability;user interfaces;computer errors;defect detection	Delays and errors are the frequent consequences of people having difficulty with a user interface. Such delays and errors can result in severe problems, particularly for mission-critical applications in which speed and accuracy are of the essence. User difficulty is often caused by interface-design defects that confuse or mislead users. Current techniques for isolating such defects are time-consuming and expensive, because they require human analysts to identify the points at which users experience difficulty; only then can diagnosis and repair of the defects take place. This paper presents an automated method for detecting instances of user difficulty based on identifying hesitations during system use. The method's accuracy was evaluated by comparing its judgments of user difficulty with ground truth generated by human analysts. The method's accuracy at a range of threshold parameter values is given; representative points include 92% of periods of user difficulty identified (with a 35% false-alarm rate); 86% (24% false-alarm rate); and 20% (3% false-alarm rate). Applications of the method to addressing interface defects are discussed	algorithm;collision detection;file system permissions;ground truth;heuristic (computer science);international conference on dependable systems and networks;mission critical;potential method;sensor;software bug;system configuration;usability testing;user interface	Robert W. Reeder;Roy A. Maxion	2006	International Conference on Dependable Systems and Networks (DSN'06)	10.1109/DSN.2006.71	user experience design;simulation;human–computer interaction;computer science;human factors and ergonomics;user interface;world wide web	Robotics	-67.92361187088538	38.64099976944278	78064
2b4fe5f0681937b7f386823382fff13722a3a422	a validation of object-oriented design metrics as quality indicators	fault prone classes;developpement logiciel;information management system;software metrics;prediccion;life cycle model;errors;information management systems;data set;computer languages;erreur;ciclo desarrollo;object oriented methods;information systems;sequential life cycle model;life cycle;langage c;object oriented design;validacion;software maintenance;metric validation;resource management;software systems;software development process;metric;software quality indicators;object oriented programming;software engineering;computer programming;quality indicator;c language;design method;computer programming languages;life durability;object oriented;desarrollo logicial;software development;class maintenance changes;cycle developpement;object oriented software development;object oriented design metrics;quantitative analysis;system testing;metrico;validation;predictive models;prediction model;technical report;c language object oriented methods software metrics software quality software maintenance information systems object oriented languages;c programming language;object oriented analysis;software development object oriented design metrics software quality indicators fault prone classes class maintenance changes metric validation information management systems sequential life cycle model object oriented analysis c programming language data set;programmation orientee objet;programming object oriented modeling software systems software maintenance design methodology computer languages predictive models resource management system testing costs;programming;prediction;object oriented languages;object oriented modeling;software quality;error prediction model;metrique;lenguaje c;design methodology;langage programmation ordinateur	This paper presents the results of a study conducted at the University of Maryland in which we experimentally investigated the suite of Object-Oriented (OO) design metrics introduced by [Chidamber&Kemerer, 1994]. In order to do this, we assessed these metrics as predictors of fault-prone classes. This study is complementary to [Li&Henry, 1993] where the same suite of metrics had been used to assess frequencies of maintenance changes to clas es. To perform our validation accurately, we collected data on the development of eight medium-sized information management systems based on identical requirements. All eight projects were developed using a sequential life cycle model, a well-known OO analysis/design method and the C++ programming language. Based on experimental results, the advantages and drawbacks of these OO metrics are discussed. Several of Chidamber&Kemerer’s OO metrics appear to be useful to predict class fault-proneness during the early phases of the life-cycle. We also showed that they are, on our data set, better predictors than “traditional” code metrics, which can only be collected at a later phase of the software development processes. Key-words: Object-Oriented Design Metrics; Error Prediction Model; Object-Oriented Software Development; C++ Programming Language. * V. Basili and W. Melo are with the University of Maryland, Institute for Advanced Computer Studies and Computer Science Dept., A. V. Williams Bldg., College Park, MD 20742 USA. {basili | melo}@cs.umd.edu L. Briand is with the CRIM, 1801 McGill College Av., Montréal (Québec), H3A 2N4, Canada. lbriand@crim.ca Technical Report, Univ. of Maryland, Dep. of Computer Science, College Park, MD, 20742 USA. April 1995. CS-TR-3443 2 UMIACS-TR-95-40 1 . Introduction	ada;cesg listed adviser scheme;cs games;computer science;experiment;information management;molecular dynamics;refinement (computing);requirement;rework (electronics);software bug;software development process;software engineering;software metric;the c++ programming language;victor basili	Victor R. Basili;Lionel C. Briand;Walcélio L. Melo	1996	IEEE Trans. Software Eng.	10.1109/32.544352	reliability engineering;computer science;systems engineering;software engineering;management information systems;database;programming language;object-oriented programming	SE	-66.52570786924596	32.54085974685149	78608
d75b5684ac8536eb51afbdda00ed2768f260ba8c	a code refactoring dataset and its assessment regarding software maintainability	empirical study code refactoring software maintainability;software maintainability code refactoring dataset processing excessive open dataset source code metrics open source systems quality attributes source code classes clone metrics;source code software public domain software software maintenance software metrics software reliability;measurement cloning open source software correlation java complexity theory	It is very common in various fields that there is a gap between theoretical results and their practical applications. This is true for code refactoring as well, which has a solid theoretical background while being used in development practice at the same time. However, more and more studies suggest that developers perform code refactoring entirely differently than the theory would suggest. Our paper encourages the further investigation of code refactorings in practice by providing an excessive open dataset of source code metrics and applied refactorings through several releases of 7 open-source systems. As a first step of processing this dataset, we examined the quality attributes of the refactored source code classes and the values of source code metrics improved by those refactorings. Our early results show that lower maintainability indeed triggers more code refactorings in practice and these refactorings significantly decrease complexity, code lines, coupling and clone metrics. However, we observed a decrease in comment related metrics in the refactored code.	code refactoring;complexity;list of system quality attributes;open-source software;software bug;software metric	István Kádár;Péter Hegedüs;Rudolf Ferenc;Tibor Gyimóthy	2016	2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)	10.1109/SANER.2016.42	kpi-driven code analysis;reliability engineering;software visualization;long-term support;verification and validation;software sizing;computer science;package development process;backporting;software framework;software development;software engineering;software construction;software testing;programming language;software maintenance;software deployment;code refactoring;software quality;static program analysis	SE	-64.18561049738129	34.72579054496557	80016
4e04ecdaec2587f6ff91f7664021a69893fe15f6	mental representations of expert procedural and object-oriented programmers in a software maintenance task	software maintenance;program comprehension;mental representation;object oriented	This study examines the mental representations formed during program comprehension and maintenance by procedural and object-oriented (OO) experts. The programmer’s mental representation reflects comprehension of a program and guides tasks carried out on the program, such as debugging and modifications. The goals of the research were three-fold: (a) to determine if and how the mental representations of procedural and OO experts differ, (2) to investigate the initial mental representation formed while comprehending a moderately large program and (3) to examine the evolution of the mental representations of procedural and OO experts over time as they carried out several modifications of the same program. Fifteen expert procedural programmers and 15 expert object-oriented programmers studied and then performed three program modifications during two sessions which were 7—10 days apart. They answered two question sets designed to elicit the categories of knowledge present in their mental representations at different times. The initial mental representation of the OO participants was dominated by problem domain-based knowledge and contained relatively little detailed program information. The procedural participants’ initial representation was more balanced, containing domain-based knowledge and also substantial program detail. After performing the modifications, the procedural participants’ representations remained essentially the same, while those of the OO participants became more balanced with respect to the program and domain elements. The results suggest that, regardless of paradigm, expert programmers build a mixed mental representation of a larger program, which includes detailed program knowledge as well as domain-based knowledge. ( 1999 Academic Press	business object;debugging;domain analysis;domain model;domain-driven design;knowledge-based systems;level of detail;list comprehension;mental representation;problem domain;procedural programming;program comprehension;programmer;programming paradigm;question answering;software maintenance;tracing (software);word lists by frequency	Cynthia L. Corritore;Susan Wiedenbeck	1999	Int. J. Hum.-Comput. Stud.	10.1006/ijhc.1998.0236	simulation;computer science;knowledge management;mental representation;object-oriented programming;software maintenance	HCI	-70.20548646386372	35.08992233924786	80163
36031b98996941479e0e4513d69bf9e6eb51c7c8	hardening cloud and datacenter systems against misconfigurations: principles and tool support		Author(s): Xu, Tianyin | Advisor(s): Zhou, Yuanyuan | Abstract: Misconfigurations (a.k.a., configuration errors from a system’s standpoint) are among the dominant causes of today’s catastrophic system failures that turn down cloud-scale services and affect hundreds of millions of end users. Despite their wide adoption, traditional fault-tolerance and failure-recovery techniques are not effective in dealing with configuration errors, especially in large-scale software systems deployed in cloud and datacenters. To make the matters worse, even the tolerance and recovery mechanisms themselves are often misconfigured in the real world, which impairs the immune system of the entire cloud and datacenters.This dissertation explores two fundamental questions towards the solutions for the inevitable misconfigurations—how to build reliable cloud and datacenter systems in the face of configuration errors; moreover, how to prevent misconfigurations in the first place by better configuration design. The goal is to enable software systems to proactively anticipate and defend against misconfigurations, rather than reacting to their manifestations and consequences. This dissertation presents three key principles of systems design and implementation for hardening cloud and datacenter systems against misconfigurations—anticipating misconfigurations, early detection of configuration errors, and simplicity-oriented configuration design. The dissertation demonstrates that applying these principles can effectively defend cloud and datacenter systems against misconfigurations. Moreover, the dissertation presents the corresponding techniques and tool support that can automatically and systematically apply these principles to existing systems software. The main technical insight is that configurations are essentially used by the systems, while configuration errors are mostly manifested through the faulty execution that uses erroneous configuration values. Therefore, by analyzing the system’s code that usesconfiguration values, one can understand and make use of system-level information of configurations to build defense against potential errors. This dissertation first presents Spex that enables systems to anticipate misconfigurations. Spex automatically infers configuration constraints from a system’s source code, and then leverages the constraints to test the system’s resilience to misconfigurations and detect error-prone configuration design/handling. On step further, the dissertation introduces PCheck to automatically generate checking code which captures configuration errors at the system’s initialization phase to prevent their late manifestations and the corresponding failure damage.Going beyond, this dissertation presents simplicity-oriented configuration design towards more usable and less error-prone software configuration. The key idea is to apply the user-centric philosophy to design configuration as an interface—configurations are essentially the interface for controlling and customizing system behavior, but have rarely been treated as it is. The dissertation shows that configurations in today’s systems software can be significantly simplified and effectively navigated, with the understanding of how they are actually used in the field.	data center	Tianyin Xu	2017			configuration design;software system;real-time computing;systems design;software;software configuration management;source code;cloud computing;reliability engineering;engineering;hardening (computing)	HPC	-63.17347482623521	42.158779269123414	80645
6951cc884294ca24670dd16ccd9988d416f78af9	evaluating seed selection for information diffusion in mobile social networks		The integration of social networks with mobile communication has led to the rise of a new paradigm, the mobile social network (MSN). Recently, MSN has emerged as a new hot spot of research attracting much interest from both academia and industrial sectors. For instance, MSN opens new horizon for information diffusion-based applications such as viral marketing. Thus, it is a fundamental issue to select an efficient subset of seed-nodes (i.e. initial sources) in a MSN such that targeting them initially will maximize the information diffusion to interested nodes. This paper studies the problem of identifying the best seeds through whom the information can be diffused in the network in order to maximize the content utility (i.e. a quantitative metric that determines how satisfied are the users). A multi- layer model that combines the social relationships and the mobile network in order to design an efficient information diffusion is proposed. Based on this multi-layer model, different seed selection approaches are proposed for information diffusion environment (e.g. mobile advertising) where users have heterogeneous interests for the different information generated in the network. Simulation results show the effectiveness of multi-layer based seed selection approaches comparing to a classical approach.	best practice;layer (electronics);mobile social network;programming paradigm;seed;simulation	Farouk Mezghani;Manel Mezghani;Ahmad Kaouk;André-Luc Beylot;Florence Sèdes	2017	2017 IEEE Wireless Communications and Networking Conference (WCNC)	10.1109/WCNC.2017.7925787	simulation;telecommunications;data mining	Mobile	-69.30348883265881	51.57969655675112	80919
ae515bc8caf49e36ced6c39a380fd51075869ae4	expert maintenance systems in telecommunication networks	telecommunication networks;expert system	Our survey of some 40 network maintenance expert systems reveals their main shortcoming, which is the difficulty to acquire troubleshooting knowledge both when initializing the expert system and after its deployment. Additionally, the state-of-the-art troubleshooting expert systems do not optimize troubleshooting cost. We present the AO* algorithm to generate a network troubleshooting expert system which minimizes the expected troubleshooting cost and learns better troubleshooting techniques during its operation.	algorithm;expert system;software deployment	Yuval Lirov;On-Ching Yue	1991	Journal of Intelligent and Robotic Systems	10.1007/BF00314937	reliability engineering;computer science;systems engineering;engineering;artificial intelligence;data mining;expert system	AI	-64.49732818775676	41.491603349669205	81735
7e6e79dc09852ee91ee41e4a8c8bb711dbd7440c	a defect dependency based approach to improve software quality in integrated software products		Integrated software products are complex in design. They are prone to defects caused by integrated and non-integrated modules of the entire integrated software suite. In such software products, a small proportion of defects are fixed as soon as they are reported. Rest of the defects are targeted for fixes in future product release cycles. Among such targeted defects, most of them seem to be insignificant and innocuous in the current version but have the potential to become acute in future versions. In this paper, we propose an approach to study defect dependency of the reported defect using a dependency metric. Identifying the dependency of a defect in an integrated product suite can help the product stake-owners to prioritize them and help improve software quality.	integrated software;real-time computing;software bug;software industry;software quality;software release life cycle;software suite;time complexity	Sai Anirudh Karre;Y. Raghu Reddy	2015	2015 International Conference on Evaluation of Novel Approaches to Software Engineering (ENASE)		reliability engineering;verification and validation;regression testing;software sizing;computer science;systems engineering;engineering;software reliability testing;software engineering;yttrium;software construction;data mining;software testing;software maintenance;software regression;software quality;software metric;measurement;software quality analyst	SE	-63.61979102138119	33.927285920704286	82508
15e5d994940fc154d6dffb1ea3464fe1088fe962	diagnosing the root-causes of failures from cluster log files	system recovery correlation methods file organisation mainframes parallel machines pattern clustering statistical analysis;mainframes;cluster system failure;manuals;pattern clustering;kernel;reliability;diagnostic tool;log files;lustre file system;fdiag;root cause;ranger supercomputer;heating;correlation methods;data mining;correlators;system event log;system recovery;statistical correlation analysis;statistical analysis;fdiag cluster log file system event log cluster system failure software component system hardware root cause statistical correlation analysis texas advanced computing center ranger supercomputer lustre file system;file system;correlation kernel data mining manuals supercomputers correlators heating;cluster system;cluster log file;software component;statistical correlation analysis resilient cluster systems reliability syslog files;resilient cluster systems;parallel machines;correlation;syslog files;supercomputers;system hardware;texas advanced computing center;correlation analysis;file organisation	System event logs are often the primary source of information for diagnosing (and predicting) the causes of failures for cluster systems. Due to interactions among the system hardware and software components, the system event logs for large cluster systems are comprised of streams of interleaved events, and only a small fraction of the events over a small time span are relevant to the diagnosis of a given failure. Furthermore, the process of troubleshooting the causes of failures is largely manual and ad-hoc. In this paper, we present a systematic methodology for reconstructing event order and establishing correlations among events which indicate the root-causes of a given failure from very large syslogs. We developed a diagnostics tool, FDiag, to extract the log entries as structured message templates and uses statistical correlation analysis to establish probable cause and effect relationships for the fault being analyzed. We applied FDiag to analyze failures due to br eakdowns in interactions between the Lustre file system and its clients on the Ranger supercomputer at the Texas Advanced Computing Center (TACC). The results are positive. FDiag is able to identify the dates and the time periods that contain the significant events which eventually led to the occurrence of compute node soft lockups.	causality;clustered file system;component-based software engineering;cyberinfrastructure;data logger;deployment environment;end-to-end principle;hoc (programming language);information source;interaction;lustre;primary source;randomness extractor;real-time clock;supercomputer;system administrator;turing;ranger	Edward Chuah;Shyh-Hao Kuo;Paul Hiew;William-Chandra Tjhi;Gary Kee Khoon Lee;John Hammond;Marek T. Michalewicz;Terence Hung;James C. Browne	2010	2010 International Conference on High Performance Computing	10.1109/HIPC.2010.5713159	lustre;parallel computing;kernel;real-time computing;computer science;component-based software engineering;operating system;reliability;root cause;distributed computing;correlation;statistics	HPC	-63.39654462754491	41.67233139475027	82735
e853ec83542f304f8d7920656be1e6ba5100ceed	is the groping ir field ready for a costly crash program?	groping ir field;costly crash program	groping ir field;costly crash program		Leonard Uhr	1966	Commun. ACM	10.1145/365278.365281	simulation;computer security	PL	-72.59145379332094	34.017379393462846	82820
040961efa2ea332d63e7bf16eff1db56a688572b	image matching for branding phishing kit images			image registration;phishing	Chengcui Zhang;Rupak Kharel;Song Gao;Jason Britt	2013			internet privacy;world wide web;computer security	Vision	-66.4071605759794	57.01670188568551	84733
f4f39233a9ae2fbe4ee2e4cbbf0b7fac7b1231c3	computational science and its applications -- iccsa 2015		Software systems erode during development, which results in high maintenance costs in the long term. Is it possible to narrow down where exactly this erosion happens? Can we infer the future erosion based on past code changes? In this paper we investigate code ownership and show that a further step of code quality decrease is more likely to happen due to the changes in source files modified by several developers in the past, compared to files with clear ownership. We estimate the level of code ownership and maintainability changes for every commit of three open-source and one proprietary software systems. With the help of Wilcoxon rank test we compare the ownership values of the files in commits resulting maintainability increase with those of decreasing the maintainability. Three tests out of the four gave strong results and the fourth one did not contradict them either. The conclusion of this study is a generalization of the already known fact that common code is more error-prone than those of developed by fewer developers. This result could be utilized in identifying the “hot spots” of the source code from maintainability point of view. A possible IDE plug-in, which indicates the risk of decreasing the maintainability of the source code, could help the architect and warn the developers.	cognitive dimensions of notations;computation;computational science;hotspot (wi-fi);integrated development environment;open-source software;plug-in (computing);software quality;software system	Marina L. Gavrilova;Ana Rocha;C Torre;David Taniar;Bernady O. Apduhan	2015		10.1007/978-3-319-21413-9		SE	-64.7269153313236	34.80893822942277	85208
e3342134e80be9604633b6572b8e522ee5713876	assessing reliability risk using fault correction profiles	reliability risk metrics;process improvement reliability risk metrics fault correction profile failure detection fault correction;software process improvement;failure detection;goddard space flight center;risk management;software fault tolerance;event detection;accuracy;fault correction;discrete cosine transforms;error correction;fault correction profile;fault diagnosis predictive models event detection fault detection software reliability nasa software quality risk management accuracy discrete cosine transforms;fault detection;predictive models;process improvement;error detection;risk management software reliability error detection error correction software process improvement software fault tolerance;nasa;software reliability;software quality;fault diagnosis	Building on the concept of the fault correction profile - a set of functions that predict fault correction events as a function of failure detection events - introduced in previous research, we define and apply reliability risk metrics that are derived from the fault correction profile. These metrics assess the threat to reliability of an unstable fault correction process. The fault correction profile identifies the need for process improvements and provides information for developing fault correction strategies. Applying these metrics to the NASA Goddard Space Flight Center fault correction process and its data, we demonstrate that reliability risk can be measured and used to identify the need for process improvement.	control theory;threat (computer)	Norman F. Schneidewind	2004	Eighth IEEE International Symposium on High Assurance Systems Engineering, 2004. Proceedings.	10.1109/HASE.2004.1281738	reliability engineering;real-time computing;error detection and correction;fault coverage;risk management;computer science;computer security;software quality;statistics	Arch	-63.27381555428326	32.480919204749775	85212
64c3c983e4eb2cdf921afacd3e1256767d2c5c40	software metrics fluctuation: a property for assisting the metric selection process	object oriented metrics;software evolution;fluctuation	ContextSoftware quality attributes are assessed by employing appropriate metrics. However, the choice of such metrics is not always obvious and is further complicated by the multitude of available metrics. To assist metrics selection, several properties have been proposed. However, although metrics are often used to assess successive software versions, there is no property that assesses their ability to capture structural changes along evolution. ObjectiveWe introduce a property, Software Metric Fluctuation (SMF), which quantifies the degree to which a metric score varies, due to changes occurring between successive system's versions. Regarding SMF, metrics can be characterized as sensitive (changes induce high variation on the metric score) or stable (changes induce low variation on the metric score). MethodSMF property has been evaluated by: (a) a case study on 20 OSS projects to assess the ability of SMF to differently characterize different metrics, and (b) a case study on 10 software engineers to assess SMF's usefulness in the metric selection process. ResultsThe results of the first case study suggest that different metrics that quantify the same quality attributes present differences in their fluctuation. We also provide evidence that an additional factor that is related to metrics' fluctuation is the function that is used for aggregating metric from the micro to the macro level. In addition, the outcome of the second case study suggested that SMF is capable of helping practitioners in metric selection, since: (a) different practitioners have different perception of metric fluctuation, and (b) this perception is less accurate than the systematic approach that SMF offers. ConclusionsSMF is a useful metric property that can improve the accuracy of metrics selection. Based on SMF, we can differentiate metrics, based on their degree of fluctuation. Such results can provide input to researchers and practitioners in their metric selection processes.	aggregate function;compiler;list of system quality attributes;open-source software;quantum fluctuation;self-replicating machine;software metric;software quality assurance;software system;usability	Elvira-Maria Arvanitou;Apostolos Ampatzoglou;Alexander Chatzigeorgiou;Paris Avgeriou	2016	Information & Software Technology	10.1016/j.infsof.2015.12.010	reliability engineering;software evolution;software engineering;data mining	SE	-65.33978812117635	33.81232811217046	85811
8cf1054902798de7cb5dcea4202a13d35a8a2766	on the need for training failure prediction algorithms in evolving software systems	web services software performance evaluation software reliability system recovery;software performance evaluation;evolving systems;system recovery;virtual machines;dependability;web services;receiver operating characteristic area under curve failure prediction algorithm training evolving software systems prediction performance web serving system fault injection fault virtualization roc auc;virtualization training software virtual machining testing servers prediction algorithms;fault injection;software reliability;virtual machines failure prediction evolving systems fault injection dependability;failure prediction	Failure prediction is a promising technique to improve dependability of computer systems, in particular when it is important to foresee incoming failures and take corrective actions to avoid downtime or data corruption. Failure prediction is especially adequate in long running systems where internal errors accumulate and eventually lead to failures. The problem is that such systems do evolve. The workload and even the system itself changes over time, and this may affect the performance of the failure predictor. However, training failure prediction algorithms is a complex and time-consuming task and should be performed only when needed. Thus, it is important to understand if a system change affects prediction performance, to avoid running the target system with an ineffective predictor and prevent unnecessary retraining efforts. In this work we study the performance of a failure predictor when used to forecast failures in a web-serving system subject to successive updates. We observe and analyze the variation of performance in terms of ROC-AUC using fault injection and virtualization for the generation of the data needed for the assessment. Our results suggest that re-training is indeed necessary.	algorithm;apache tomcat;dependability;downtime;elegant degradation;fault injection;gene prediction;hardware virtualization;kerrison predictor;receiver operating characteristic;software system	Ivano Irrera;João Durães;Marco Vieira	2014	2014 IEEE 15th International Symposium on High-Assurance Systems Engineering	10.1109/HASE.2014.38	web service;reliability engineering;real-time computing;simulation;computer science;engineering;virtual machine;operating system;dependability;computer security;software quality	Arch	-63.70486545147423	39.76088710055659	85966
6ba287e46671972eb7a357e3ebe83177fe998402	a security evaluation and testing methodology for open source software embedded information security system	security evaluation;calculateur embarque;execution time;information security;surveillance;real time;securite donnee;monitoring system;vigilancia;test case generation;monitoring;generation test;temps reel;logiciel libre;boarded computer;tiempo real;test generation;temps execution;software libre;monitorage;information system;tiempo ejecucion;monitoreo;generacion prueba;security of data;calculador embarque;systeme information;open source software;sistema informacion	NOTES: The sections and modules are based on the 2.0 model still. However, with this version the OSSTMM is bridging to the new 3.0 structure. After a year and a half, we have collected more than enough information to ensure better and more thorough security testing however the current format did not suffice for the collected information. The newer format will ensure that the new material will best accommodate maximum knowledge transfer.	bridging (networking);information security;open-source software;security testing	Sung-Ja Choi;Yeon-hee Kang;Gang-Soo Lee	2005		10.1007/11424826_23	embedded system;computer science;information security;operating system;computer security;information system	Security	-63.107760806539645	51.941105730924484	86317
eabb5921d28d83a6daf4f5adc61a8415f385655e	direction and scope of comprehension-related activities by procedural and object-oriented programmers: an empirical study	program understanding;program maintenance;empirical study;bottom up;broad program view program comprehension related activities procedural programming object oriented programming empirical study professional programmers software maintenance activities program modifications top down approach program understanding bottom up approach activity scope programming paradigm;software maintenance;top down;program comprehension;professional aspects reverse engineering software maintenance object oriented programming;object oriented programming;mental models;programming profession educational institutions information science electrical capacitance tomography tellurium electronic switching systems information analysis;object oriented;professional aspects;reverse engineering	This study examines the direction and scope of comprehension-related activities of professional programmers carrying out several comprehension and maintenance activities over time. Procedural and object-oriented (OO) programmers studied a program and subsequently performed modifications during two sessions. Results showed that the OO programmers tended to use a strongly top-down approach to program understanding during an early phase of study of the program but increasingly used a bottom-up approach during the maintenance tasks. The procedural programmers used a more bottom-up orientation throughout all activities. The scope of the activities was greater for the procedural than for the OO programmers. However, regardless of paradigm, the programmers over time built a broad, rather than a localized, view of the program.	bottom-up parsing;internationalization and localization;list comprehension;procedural programming;program comprehension;programmer;programming paradigm;top-down and bottom-up design	Cynthia L. Corritore;Susan Wiedenbeck	2000		10.1109/WPC.2000.852488	pair programming;computer science;systems engineering;software engineering;top-down and bottom-up design;programming language;object-oriented programming	SE	-70.13062657012506	34.895291099749016	86993
db960da3afd72659cd4b6088e0b67d6d86e4844c	a pragmatic means for measuring the complexity of source code ensembles	software metrics;software;hm index;complexity theory;bibliometrics source code ensembles complexity measurement software metrics higher order code ensembles hm index software engineering;software engineering;source code ensembles complexity measurement;indexes;code quality and complexity software metrics;complexity theory software software metrics indexes software engineering;higher order code ensembles;bibliometrics;code quality and complexity	Most of the software metrics known and applied today are measured on a per file or even per function basis so that it is difficult to interpret their results for higher-order code ensembles such as components or whole systems. In order to overcome this weakness, we propose the hm-Index as a simple metric to condense the dependencies, i.e. the Fan-out, between source units in such code ensembles into a single number. As it is inspired by the h-Index in bibliometrics, it is based on a well-known procedure that already had significant impact in a different field. We expect the hm-Index to become a simple metric for comparing the code complexity of different components or systems in software engineering and present promising preliminary results from real-world systems confirming our assumption in this paper.	bibliometrics;fan-out;programming complexity;software engineering;software metric;world-system	Oliver Hummel;Stefan Burger	2013	2013 4th International Workshop on Emerging Trends in Software Metrics (WETSoM)	10.1109/WETSoM.2013.6619340	kpi-driven code analysis;software visualization;software sizing;halstead complexity measures;computer science;theoretical computer science;software construction;data mining;weighted micro function points;software quality;software metric;static program analysis	SE	-63.21928251666792	34.950332017623786	87309
f8f37e4741d69ec481e0b64ee1b07fc3b0e263aa	identifying architectural problems through prioritization of code smells	agglomerations;software evolution;architectural problems;code smells	Architectural problems constantly affect evolving software projects. When not properly addressed, those problems can hinder the longevity of a software system. Studies have revealed that a range of architectural problems are reflected in source code through two or more code smells. However, a software project often contains thousands of code smells and many of them have no relation to architectural problems. Thus, developers may feel discouraged to identify architectural problems if they are not equiped with means to focus their attention in a reduced set of locations in their system to start with. However, state-of-the-art techniques fall short in assisting developers in the prioritization of code smells that are likely to indicate architectural problems in a program. As a consequence, developers struggle to effectively focus on (groups of) smells that are architecturally relevant, i.e., smells that contribute to a critical design problem. This work presents and evaluates a suite of criteria for prioritizing groups of code smells as indicators of architectural problems in evolving systems. These criteria are supported by a tool called JSpIRIT. We have assessed the prioritization criteria in the context of more than 23 versions of 4 systems, analyzing their effectiveness for spoting locations of architectural problems in the source code. The results provide evidence that one of the proposed criteria helped to correctly prioritize more than 80 (locations of) architectural problems, alleviating tedious manual inspections of the source code vis-a-vis with the architecture. This prioritization criteria would have helped developers to discard at least 500 code smells having no relation to architectural problems in the analyzed systems.	code smell;emergence;software project management;software system	Santiago A. Vidal;Everton T. Guimarães;Willian Nalepa Oizumi;Alessandro F. Garcia;Jorge Andrés Díaz Pace;Claudia Marcos	2016	2016 X Brazilian Symposium on Software Components, Architectures and Reuse (SBCARS)	10.1109/SBCARS.2016.11	reliability engineering;architectural pattern;computer science;systems engineering;computer security;code smell	SE	-64.227960126347	34.32544852773903	88343
a529b3bc947a12b9c774fda65ef8e2f2f2ddd7a1	analyzing and predicting effort associated with finding and fixing software faults	software fix implementation effort;predictions;failure;system failures;computer programs;sampling;keywords software faults and failures;machine learning;algorithms;analysis;computer systems performance;prediction	Context : Software developers spend a significant amount of time fixing faults. However, not many papers have addressed the actual effort needed to fix software faults. Objective: The objective of this paper is twofold: (1) analysis of the effort needed to fix software faults and how it was affected by several factors and (2) prediction of the level of fix implementation effort based on the information provided in software change requests. Method: The work is based on data related to 1200 failures, extracted from the change tracking system of a large NASA mission. The analysis includes descriptive and inferential statistics. Predictions are made using three supervised machine learning algorithms and three sampling techniques aimed at addressing the imbalanced data problem. Results: Our results show that (1) 83% of the total fix implementation effort was associated with only 20% of failures. (2) Both post-release failures and safety-critical failures required more effort to fix than pre-release and non-critical counterparts, respectively; median values were two or more times higher. (3) Failures with fixes spread across multiple components or across multiple types of software artifacts required more effort. The spread across artifacts was more costly than spread across components. (4) Surprisingly, some types of faults associated with later life-cycle activities did not require significant effort. (5) The level of fix implementation effort was predicted with 73% overall accuracy using the original, imbalanced data. Oversampling techniques improved the overall accuracy up to 77% and, more importantly, significantly improved the prediction of the high level effort, from 31% to 85%. Conclusions: This paper shows the importance of tying software failures to changes made to fix all associated faults, in one or more software components and/or in one or more software artifacts, and the benefit of studying how the spread of faults and other factors affect the fix implementation effort. © 2017 Elsevier B.V. All rights reserved.	algorithm;component-based software engineering;failure;high-level programming language;inferential theory of learning;machine learning;oversampling;sampling (signal processing);software developer;supervised learning;tracking system	Margaret Hamill;Katerina Goseva-Popstojanova	2017	Information & Software Technology	10.1016/j.infsof.2017.01.002	data mining;computer science;component-based software engineering;software;real-time computing;statistical inference;tracking system;tying	SE	-64.63687459699547	32.87862073689959	88564
4c709a861f8be42b8e535593eb1e826b7112ec66	legacy system exorcism by pareto's principle	software metrics;legacy software;refactoring;component based systems;pair programming;agile development;pareto principle;software metric;legacy system;reengineering;software quality;open source	Exorcism is mainly thought of as the rite of driving out the Devil and his demons from possessed persons. This text is about the same process except here the target is a legacy software system. The target system was a major component based system having been developed over 7 years by 30 to 60 people continuously under a classic plan driven approach. The Pareto Principle, or 80/20 rule as it is often called, is used as the framework to prioritize activities in a major reengineering initiative on the system from limited resources. The initiative's main focus was to increase the developer productivity in the maintenance project in the system by 25 percent. Typical agile practices were the inspiration for many of the changes implemented through the project.A measurement program is presented for validating success, and the XRadar open source tool is used for measuring the program. In one year, the productivity increase was above 30 percent. There seems to be a high correlation between productivity and the implementation of the agile practices such as short iterations, daily standup-meetings and pair programming as substitutes with the practice of a formal QA regime. During the same period the error proneness of the system decreased with several magnitudes and our definition of the internal software quality increased by 22 percent. Hence, based on our measurements, the increased productivity was not substituted by lower quality in the system - on the contrary.	agile software development;code refactoring;cognitive dimensions of notations;iteration;legacy system;open-source software;pair programming;pareto efficiency;software quality assurance;software system	Kristoffer Kvam;Rodin Lie;Daniel Bakkelund	2005		10.1145/1094855.1094959	simulation;computer science;software development;legacy system;software metric	SE	-64.68113980782961	34.12235620222673	88785
b8845f6f0f44b35dd5e1b4abe408eed9b71929ac	the role of mpi in development time: a case study	parallel software;maximum productivity improvement;ongoing hpc project;hpc system;dominant programming model;development effort;alternate parallel programming model;development time;case study;version control history;regression testing history;effective use;history;parallel programming model;productivity;version control;computational modeling;message passing;regression testing;science communication;programming;parallel programming;source code;programming model;data mining;mpi;software engineering;debugging;testing	There is widespread belief in the computer science community that MPI is a difficult and time-intensive approach to developing parallel software. Nevertheless, MPI remains the dominant programming model for HPC systems, and many projects have made effective use of it. It remains unknown how much impact the use of MPI truly has on the productivity of computational scientists. In this paper, we examine a mature, ongoing HPC project, the Flash Center at the University of Chicago, to understand how MPI is used and to estimate the time that programmers spend on MPI-related issues during development. Our analysis is based on an examination of the source code, version control history, and regression testing history of the software. Based on our study, we estimate that about 20% of the development effort is related to MPI. This implies a maximum productivity improvement of 25% for switching to an alternate parallel programming model.	best practice;computer science;debugging;extrapolation;high productivity computing systems;message passing interface;parallel computing;parallel programming model;programmer;real life;regression testing;software engineering;source lines of code;triangulation (geometry);version control	Lorin Hochstein;Forrest Shull;Lynn B. Reid	2008	2008 SC - International Conference for High Performance Computing, Networking, Storage and Analysis	10.1145/1413370.1413405	science communication;programming;computer architecture;productivity;regression testing;parallel computing;message passing;computer science;revision control;message passing interface;operating system;distributed computing;software testing;programming paradigm;programming language;debugging;computational model;source code;parallel programming model	HPC	-67.64692393201223	34.112391064541484	90776
18e6fc7855308b631dfafec8b4c64a2b3a91328b	an empirical study of the personnel overhead of continuous integration		Continuous Integration (CI) is a software development practice where changes to the codebase are compiled and automatically checked for software quality issues. Like any software artifact (e.g., production code, build specifications), CI systems require an investment of development resources in order to keep them running smoothly. In this paper, we examine the human resources that are associated with developing and maintaining CI systems. Through the analysis of 1,279 GitHub repositories that adopt Travis CI (a popular CI service provider), we observe that: (i) there are 0 to 6 unique contributors to CI-related development in any 30-day period, regardless of project size, and (ii) the total number of CI developers has an upper bound of 15 for 99.2% of the studied projects, regardless of overall team size. These results indicate that service-based CI systems only require a small proportion of the development team to contribute. These costs are almost certainly outweighed by the reported benefits of CI (e.g., team communication and time-to-market for new content).	artifact (software development);compiler;continuous integration;smoothing;software development;software quality;travis ci	Marco Manglaviti;Eduardo Coronado-Montoya;Keheliya Gallaba;Shane McIntosh	2017	2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR)	10.1109/MSR.2017.31	service provider;data mining;market research;empirical research;software quality;software development;software;codebase;computer science;human resources	SE	-65.99768282366662	33.53972185626824	90815
7b9818818c0236bf173f79ef077d22df77cb9342	applying the submission multiple tier (smt) matrix to detect impact on developer interest on open source project survivability	conference proceeding	There is a significant relationship between project activity and developer interest on Open Source (OS) projects. Total project activity submission count number can be an indicator for gauging developer interest. The higher the project activity submission of a project is, the larger developer interest in a project. My paper proposed that applying a Submission Multiple Tier (SMT) matrix can detect the impact of developer interest on project activity. Results showed more volume of OS projects with low project activity than high. Activity submission results also showed that developers are more likely to review than correct projects, with the first priority to find and fix bugs. Further research is needed to determine the impact of project activity type on developer motivation to contribute, participate and support OS projects.	multitier architecture;operating system;software bug	Bee Bee Chua	2014		10.1007/978-3-642-55128-4_8	computer science;operating system;software engineering;data mining;database;world wide web	SE	-66.01873257995886	33.793949321621945	91145
a060a4be76d6789113df800da0f20aa62ac99990	transfer learning with bellwethers to find good configurations.		As software systems grow in complexity, the space of possible configurations grows exponentially. Within this increasing complexity, developers, maintainers, and users cannot keep track of the interactions between all the various configuration options. Finding the optimally performing configuration of a software system for a given setting is challenging. Recent approaches address this challenge by learning performance models based on a sample set of configurations. However, collecting enough data on enough sample configurations can be very expensive since each such sample requires configuring, compiling and executing the entire system against a complex test suite. The central insight of this paper is that choosing a suitable source (a.k.a. “bellwether”) to learn from, plus a simple transfer learning schemewill often outperformmuchmore complex transfer learning methods. Using this insight, this paper proposes BEETLE, a novel bellwether based transfer learning scheme, which can identify a suitable source and use it to find near-optimal configurations of a software system. BEETLE significantly reduces the cost (in terms of the number of measurements of sample configuration) to build performance models. We evaluate our approach with 61 scenarios based on 5 software systems and demonstrate that BEETLE is beneficial in all cases. This approach offers a new highwater mark in configuring software systems. Specifically, BEETLE can find configurations that are as good or better as those found by anything else while requiring only 7 th of the evaluations needed by the state-of-the-art.	compiler;experiment;interaction;software system;test suite	Vivek Nair;Rahul Krishna;Tim Menzies;Pooyan Jamshidi	2018	CoRR		theoretical computer science;software system;computer science;transfer of learning;test suite	SE	-63.072507887056716	38.21179447120831	92055
8e9733f75e2aeead1ea64485359770e70f898b57	towards a classification of bugs to facilitate software maintainability tasks		Software maintainability is an important software quality attribute that defines the degree by which a software system is understood, repaired, or enhanced. In recent years, there has been an increase in attention in techniques and tools that mine large bug repositories to help software developers understand the causes of bugs and speed up the fixing process. These techniques, however, treat all bugs in the same way. Bugs that are fixed by changing a single location in the code are examined the same way as those that require complex changes. After examining more than 100 thousand bug reports of 380 projects, we found that bugs can be classified into four types based on the location of their fixes. Type 1 bugs are the ones that fixed by modifying a single location in the code, while Type 2 refers to bugs that are fixed in more than one location. Type 3 refers to multiple bugs that are fixed in the exact same location. Type 4 is an extension of Type 3, where multiple bugs are resolved by modifying the same set of locations. This classification can help companies put the resources where they are needed the most. It also provides useful insight into the quality of the code. Knowing, for example, that a system contains a large number of bugs of Type 4 suggests high maintenance efforts. This classification can also be used for other tasks such as predicting the type of incoming bugs for an improved bug handling process. For example, if a bug is found to be of Type 4 then it should be directed to experienced developers.	chomsky hierarchy;nsa product types;netbeans ide;open-source software;software bug;software developer;software quality;software system	Mathieu Nayrolles;Abdelwahab Hamou-Lhadj	2018	2018 IEEE/ACM 1st International Workshop on Software Qualities and their Dependencies (SQUADE)	10.1145/3194095.3194101	empirical research;maintainability;real-time computing;software quality;task analysis;software system;software;speedup;software bug;computer science	SE	-64.24440819108467	34.97309298508251	93772
4eb688bf4b46984d644aa229cb19adf9d159aeed	understanding the impact of rapid releases on software quality	release cycle;testing;bugs;software release;software quality	Many software companies are shifting from the traditional multi-month release cycle to shorter release cycles. For example, Google Chrome and Mozilla Firefox release new versions every 6 weeks. These shorter release cycles reduce the users’ waiting time for a new release and offer better feedback and marketing opportunities to companies, but it is unclear if the quality of the software product improves as well, since developers and testers are under more pressure. In this paper, we extend our previous empirical study of Mozilla Firefox on the impact of rapid releases on quality assurance with feedback by Mozilla project members. The study compares crash rates, median uptime, and the proportion of pre- and post-release bugs in traditional releases with those in rapid releases, and we also analyze the source code changes made by developers to identify potential changes in the development process. We found that (1) with shorter release cycles, users do not experience significantly more pre- or post-release bugs (percentage-wise) and (2) bugs are fixed faster, yet (3) users experience these bugs earlier during software execution (the program crashes earlier). Increased integration activity and propagation of harder bugs to later versions account for some of these findings. Overall, our case study suggests that a clear release engineering process with thorough automation is one of the major challenges when switching to rapid releases.	crash (computing);firefox;google chrome;proxy server;rapid refresh;rapid application development;release engineering;release management;software architecture;software bug;software industry;software propagation;software quality assurance;software release life cycle;software system;uptime	Foutse Khomh;Bram Adams;Tejinder Dhaliwal;Ying Zou	2014	Empirical Software Engineering	10.1007/s10664-014-9308-x	long-term support;real-time computing;simulation;computer science;engineering;operations management;software engineering;software release life cycle	SE	-65.17789020547615	34.22105599070476	93793
812ab37f445ce20794065b3cd90268f7d2eac30d	adversarial co-evolution of attack and defense in a segmented computer network environment		In computer security, guidance is slim on how to prioritize or configure the many available defensive measures, when guidance is available at all. We show how a competitive co-evolutionary algorithm framework can identify defensive configurations that are effective against a range of attackers. We consider network segmentation , a widely recommended defensive strategy, deployed against the threat of serial network security attacks that delay the mission of the networku0027s operator. We employ a simulation model to investigate the effectiveness over time of different defensive strategies against different attack strategies. For a set of four network topologies, we generate strong availability attack patterns that were not identified a priori. Then, by combining the simulation with a co-evolutionary algorithm to explore the adversariesu0027 action spaces, we identify effective configurations that minimize mission delay when facing the attacks. The novel application of co-evolutionary computation to enterprise network security represents a step toward course-of-action determination that is robust to responses by intelligent adversaries. 1	attack patterns;computer security;evolutionary algorithm;evolutionary computation;network security;network segmentation;network topology;simulation	Erik Hemberg;Joseph R. Zipkin;Richard W. Skowyra;Neal Wagner;Una-May O'Reilly	2018		10.1145/3205651.3208287	attack patterns;operator (computer programming);machine learning;distributed computing;artificial intelligence;network topology;enterprise private network;computer science;computation;network security;network segmentation;evolutionary algorithm	Security	-65.68709290734144	59.975531138231865	94478
b0fcbce3acbdeae0dbf12478d16753747eb31557	experimental evaluation of software design principles: an investigation into the effect of module coupling on system modifiability	coupling;program design;metric;conception programme;couplage;experimental evaluation;fiabilite logiciel;software design;module programme;software reliability;metrique;program module	Abstract   The importance of the scientific investigations of software design principles is discussed, and an experimental investigation of the importance of the design principle of module coupling is described. One important dimension of coupling, as promoted by the authors of the structured design methodology, is that of global variable vs. parameterized methods of intermodule communication. It is shown that different proposed software metrics provide conflicting conclusions as to the preferred method of intermodule communication. The three experiments reported herein were performed in university software engineering courses taken by graduate students and upper level undergraduate majors in computer science. They address the effect of global vs. parameterized interfaces on system modifiability. While the type of modification being performed significantly influenced the modifiability of the system, there were no consistent effects due to the type of coupling present in the system.	software design	John B. Lohse;Stuart H. Zweben	1984	Journal of Systems and Software	10.1016/0164-1212(84)90029-3	reliability engineering;simulation;metric;computer science;systems engineering;engineering;software design;software engineering;program design language;coupling;software quality	SE	-67.64768960350901	32.757309456568464	94667
1d0d7fdcfe140f20f81abc957e0284bab34d6a9a	concurrency bugs in open source software: a case study	computer communication networks;information systems and communication service;computer applications;it in business;computer systems organization and communication networks;processor architectures	Concurrent programming puts demands on software debugging and testing, as concurrent software may exhibit problems not present in sequential software, e.g., deadlocks and race conditions. In aiming to increase efficiency and effectiveness of debugging and bug-fixing for concurrent software, a deep understanding of concurrency bugs, their frequency and fixing-times would be helpful. Similarly, to design effective tools and techniques for testing and debugging concurrent software, understanding the differences between non-concurrency and concurrency bugs in real-word software would be useful. This paper presents an empirical study focusing on understanding the differences and similarities between concurrency bugs and other bugs, as well as the differences among various concurrency bug types in terms of their severity and their fixing time, and reproducibility. Our basis is a comprehensive analysis of bug reports covering several generations of five open source software projects. The analysis involves a total of 11860 bug reports from the last decade, including 351 reports related to concurrency bugs. We found that concurrency bugs are different from other bugs in terms of their fixing time and severity while they are similar in terms of reproducibility. Our findings shed light on concurrency bugs and could thereby influence future design and development of concurrent software, their debugging and testing, as well as related tools.	concurrency (computer science);concurrent computing;deadlock;debugging;multiversion concurrency control;open-source software;race condition;software bug	Sara Abbaspour Asadollah;Daniel Sundmark;Sigrid Eldh;Hans A. Hansson	2017	Journal of Internet Services and Applications	10.1186/s13174-017-0055-2	debugging;software construction;computer science;software framework;real-time computing;package development process;long-term support;software development;software reliability testing;concurrent object-oriented programming	SE	-63.13559050186638	34.86311075098154	94789
b84be65bdfa3db4dde8a3784dd253aa7671d576c	guiding bug triage through developer analysis in bug reports	software maintenance;bug fixing;bug report analysis;developer recommendation	An important part of software maintenance is bug report analysis during bug-fixing, especially for large-scale software projects. Since bugs reported to the bug repository need to be fixed, triagers are responsible to identify appropriate developers to execute the fix. Previous research focused on optimizing this process, such as by duplicate detection and use of developer recommendations for reducing the workload of triagers. However, there were scant studies that analyzed developer roles (e.g. reporter and assignee) in the bug-fixing process. Therefore, in this paper, we perform an in-depth empirical study of the different roles that developers perform in bug resolution. By extracting the factors that affect bug resolution from the analysis results, we propose a novel bug triage algorithm to recommend the appropriate developers to fix a given bug. We implement the proposed recommendations on the Eclipse and Mozilla Firefox projects, with the results showing that the new bug triage algorithm can effectively recommend which experts should fix given bugs.	software bug	Tao Zhang;Geunseok Yang;Byungjeong Lee;Alvin T. S. Chan	2016	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194016500170	security bug;computer science;software engineering;data mining;database;software maintenance;world wide web	SE	-64.38525044217565	34.836647345918145	95042
d2fba2a3014ee14d378cc6af65df55699fca1389	do automatic refactorings improve maintainability? an industrial case study	complexity theory;measurement;iso iec 25010;software systems;companies;coding issues;encoding;software maintainability;object oriented modeling;automatic refactoring	Refactoring is often treated as the main remedy against the unavoidable code erosion happening during software evolution. Studies show that refactoring is indeed an elemental part of the developers' arsenal. However, empirical studies about the impact of refactorings on software maintainability still did not reach a consensus. Moreover, most of these empirical investigations are carried out on open-source projects where distinguishing refactoring operations from other development activities is a challenge in itself. We had a chance to work together with several software development companies in a project where they got extra budget to improve their source code by performing refactoring operations. Taking advantage of this controlled environment, we collected a large amount of data during a refactoring phase where the developers used a (semi)automatic refactoring tool. By measuring the maintainability of the involved subject systems before and after the refactorings, we got valuable insights into the effect of these refactorings on large-scale industrial projects. All but one company, who applied a special refactoring strategy, achieved a maintainability improvement at the end of the refactoring phase, but even that one company suffered from the negative impact of only one type of refactoring.	code refactoring;elemental;hoc (programming language);human factors and ergonomics;information source;open-source software;software development;software evolution;software metric;software system;traceability;undocumented feature;video-in video-out	Gábor Szoke;Csaba Levente Nagy;Péter Hegedüs;Rudolf Ferenc;Tibor Gyimóthy	2015	2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)	10.1109/ICSM.2015.7332494	reliability engineering;systems engineering;engineering;software engineering;code refactoring;maintainability;encoding;measurement;software system	SE	-64.50706474034905	34.27721618842122	95871
64ae900cf6243aa51184e7a8906f64a76c6d4449	adaptive root cause analysis for self-healing in 5g networks		Root cause analysis (RCA) is a common and recurring task performed by operators of cellular networks. It is done mainly to keep customers satisfied with the quality of offered services and to maximize return on investment (ROI) by minimizing and where possible eliminating the root causes of faults in cellular networks. Currently, the actual detection and diagnosis of faults or potential faults is still a manual and slow process often carried out by network experts who manually analyze and correlate various pieces of network data such as, alarms, call traces, configuration management (CM) and key performance indicator (KPI) data in order to come up with the most probable root cause of a given network fault. In this paper, we propose an automated fault detection and diagnosis solution called adaptive root cause analysis (ARCA). The solution uses measurements and other network data together with Bayesian network theory to perform automated evidence based RCA. Compared to the current common practice, our solution is faster due to automation of the entire RCA process. The solution is also cheaper because it needs fewer or no personnel in order to operate and it improves efficiency through domain knowledge reuse during adaptive learning. As it uses a probabilistic Bayesian classifier, it can work with incomplete data and it can handle large datasets with complex probability combinations. Experimental results from stratified synthesized data affirmatively validate the feasibility of using such a solution as a key part of self-healing (SH) especially in emerging self-organizing network (SON) based solutions in LTE Advanced (LTE-A) and 5G.	algorithm;bayesian network;bayesian programming;compaq lte;configuration management;deep learning;fault detection and isolation;mathematical optimization;naive bayes classifier;network theory;organizing (structure);pareto efficiency;region of interest;self-management (computer science);self-organization;stratified sampling;tracing (software);uncertain data	Harrison Mfula;Jukka K. Nurminen	2017	2017 International Conference on High Performance Computing & Simulation (HPCS)	10.1109/HPCS.2017.31	performance indicator;root cause;real-time computing;fault detection and isolation;probabilistic logic;bayesian network;adaptive learning;cellular network;computer science;root cause analysis	HPC	-64.51258082811476	41.54446492390757	96450
647b16e4e1c5015e4703edb9b0de638233b3e36d	cost-aware vulnerability prediction: the harmless approach		Society needs more secure software. But predicting vulnerabilities is difficult and existing methods are not applied in practical use due to various limitations. The goal of this paper is to design a vulnerability prediction method in a cost-aware manner so that it can balance the percentage of vulnerabilities found against the cost of human effort on security review and test. To this purpose, this paper presents HARMLESS, an incremental vulnerability prediction tool. HARMLESS is an active learner that (a) builds a support vector machine on the source code files reviewed to date; then (b) suggests what other source code files might have vulnerabilities and need to be reviewed next. A unique feature of HARMLESS is that HARMLESS can estimate the number of remaining vulnerabilities. To the best of our knowledge, HARMLESS is the first tool providing such estimation in the arena of vulnerability prediction. Using that estimator, HARMLESS can guide the security review and test to any level of desired recall, i.e. percentage of vulnerabilities found. In experiments on a case study of Mozilla Firefox project, HARMLESS found 90, 95, 99% of known vulnerabilities by reviewing and testing 26, 33, 45% of the source code files, respectively.	active learning (machine learning);best practice;core dump;emoticon;experiment;feedback;firefox;software bug;software project management;stack trace;supervised learning;support vector machine;text mining;tracing (software);vulnerability (computing)	Zhe Yu;Christopher Theisen;Hyunwoo Sohn;Laurie A. Williams;Tim Menzies	2018	CoRR		theoretical computer science;data mining;active learning;computer science;source code;support vector machine;software;vulnerability	Security	-64.00355000157093	37.88363928248497	96536
753084df632264d0d3fb7d0fc71ea5d2bb6851f9	a study of repetitiveness of code changes in software evolution	source code software;software maintenance;automatic programming;code change repetitiveness software evolution java projects source lines of code sloc code change revisions automatic program repair code change learning;software evolution repetitive code changes;source code software automatic programming java software maintenance;software vegetation databases history maintenance engineering libraries programming;java	In this paper, we present a large-scale study of repetitiveness of code changes in software evolution. We collected a large data set of 2,841 Java projects, with 1.7 billion source lines of code (SLOC) at the latest revisions, 1.8 million code change revisions (0.4 million fixes), 6.2 million changed files, and 2.5 billion changed SLOCs. A change is considered repeated within or cross-project if it matches another change having occurred in the history of the project or another project, respectively. We report the following important findings. First, repetitiveness of changes could be as high as 70-100% at small sizes and decreases exponentially as size increases. Second, repetitiveness is higher and more stable in the cross-project setting than in the within-project one. Third, fixing changes repeat similarly to general changes. Importantly, learning code changes and recommending them in software evolution is beneficial with accuracy for top-1 recommendation of over 30% and top-3 of nearly 35%. Repeated fixing changes could also be useful for automatic program repair.	java;software evolution;source lines of code	Hoan Anh Nguyen;Anh H. T. Nguyen;Tung Thanh Nguyen;Tien N. Nguyen;Hridesh Rajan	2013	2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)	10.1109/ASE.2013.6693078	kpi-driven code analysis;codebase;code review;computer science;software development;software engineering;software construction;redundant code;database;code coverage;programming language;software maintenance;java;source lines of code;software quality;static program analysis;source code	SE	-64.35053915598512	34.92700938058546	96705
e62bf046fb4165d603a9b0b8df673e50f0de3809	introducing and analysis of the windows 8 event log for forensic purposes	media;digital technology and the creative economy	All operating systems are employing some sort of logging mechanism to track and note users activities and Microsoft Windows is not an exception. Log Analysis is one of the important parts of Windows forensics process. The Windows event log system introducing in Windows NT was released with a new feature for Microsoft Windows family and since then went through several major changes and updates. The event log experienced major updated in Windows 8. This paper first introduces Windows 8 event log format and then proceeds with explaining methods for analyzing the logs for digital investigation and incident handling. The main contributions of this paper are introducing Windows8 logging service and forensic examination of it.		Javad Talebi;Ali Dehghantanha;Ramlan Mahmod	2014		10.1007/978-3-319-20125-2_13	media;computer science;group policy;software versioning;windows vista;operating system;commit charge;world wide web;vbscript;computer security;dll hell;next-generation secure computing base	Crypto	-63.30830517246916	50.015867978706694	97025
902e1be121e7b9f63b8cd54ce025f0deaa4d5a92	metrics for gerrit code review		Code reviews are a widely accepted best practice in modern software development. To enable easier and more agile code reviews, tools like Gerrit have been developed. Gerrit provides a framework for conducting reviews online, with no need for meetings or mailing lists. However, even with the help of tools like Gerrit, following and monitoring the review process becomes increasingly hard, when tens or even hundreds of code changes are uploaded daily. To make monitoring the review process easier, we propose a set of metrics to be used with Gerrit code review. The focus is on providing an insight to velocity and quality of code reviews, by measuring different review activities based on data, automatically extracted from Gerrit. When automated, the measurements enable easy monitoring of code reviews, which help in establishing new best practices and improved review process.	agile software development;best practice;gerrit;velocity (software development)	Samuel Lehtonen;Timo Poranen	2015				SE	-65.66736791114954	34.74915096804867	98005
91cbfc0f94204557ad635df6a7486813d835e178	entropy based bug prediction using support vector regression	software metrics;entropy polynomials support vector machines complexity theory computer bugs kernel;support vector machines;software maintenance;software performance evaluation;performance improvement entropy based bug prediction support vector regression software defect prediction software engineering code churn past bugs refactoring approach file size performance measurement mathematical models bug occurrence monitoring bug fixing software reliability growth models continuous software code changes code change complexity svr;support vector machines entropy program debugging regression analysis software maintenance software metrics software performance evaluation software reliability;regression analysis;entropy;program debugging;software reliability;entropy bug prediction support vector regression complexity of code change	Predicting software defects is one of the key areas of research in software engineering. Researchers have devised and implemented a plethora of defect/bug prediction approaches namely code churn, past bugs, refactoring, number of authors, file size and age, etc by measuring the performance in terms of accuracy and complexity. Different mathematical models have also been developed in the literature to monitor the bug occurrence and fixing process. These existing mathematical models named software reliability growth models are either calendar time or testing effort dependent. The occurrence of bugs in the software is mainly due to the continuous changes in the software code. The continuous changes in the software code make the code complex. The complexity of the code changes have already been quantified in terms of entropy as follows in Hassan [9]. In the available literature, few authors have proposed entropy based bug prediction using conventional simple linear regression (SLR) method. In this paper, we have proposed an entropy based bug prediction approach using support vector regression (SVR). We have compared the results of proposed models with the existing one in the literature and have found that the proposed models are good bug predictor as they have shown the significant improvement in their performance.	code refactoring;kerrison predictor;mathematical model;software bug;software engineering;software reliability testing;support vector machine	V. B. Singh;K. K. Chaturvedi	2012	2012 12th International Conference on Intelligent Systems Design and Applications (ISDA)	10.1109/ISDA.2012.6416630	support vector machine;entropy;regression testing;software sizing;search-based software engineering;computer science;software reliability testing;theoretical computer science;machine learning;software construction;data mining;software testing;software maintenance;software regression;software quality;regression analysis;software metric;static program analysis	SE	-63.441418202896315	34.74373403635562	98265
1fc262bbb19b5ff0ec48ec4912d9f75c15917ce7	pilot: a framework that understands how to do performance benchmarks the right way	computers;performance evaluation;measurement uncertainty;tuning;benchmark testing;throughput	Carrying out even the simplest performance benchmark requires considerable knowledge of statistics and computer systems, and painstakingly following many error-prone steps, which are distinct skill sets yet essential for getting statistically valid results. As a result, many performance measurements in peer-reviewed publications are flawed. Among many problems, they fall short in one or more of the following requirements: accuracy, precision, comparability, repeatability, and control of overhead. This is a serious problem because poor performance measurements misguide system design and optimization. We propose a collection of algorithms and heuristics to automate these steps. They cover the collection, storing, analysis, and comparison of performance measurements. We implement these methods as a readily-usable open source software framework called Pilot, which can help to reduce human error and shorten benchmark time. Evaluation of Pilot on various benchmarks show that it can reduce the cost and complexity of running benchmarks, and can produce better measurement results.	algorithm;benchmark (computing);cognitive dimensions of notations;computer;distributed mode loudspeaker;documentation;heuristic (computer science);human error;issue tracking system;mathematical optimization;open-source software;overhead (computing);pilot;performance evaluation;repeatability;requirement;sensor;software framework;systems design;systems theory;wiki	Yan Li;Yash Gupta;Ethan L. Miller;Darrell D. E. Long	2016	2016 IEEE 24th International Symposium on Modeling, Analysis and Simulation of Computer and Telecommunication Systems (MASCOTS)	10.1109/MASCOTS.2016.31	benchmark;throughput;real-time computing;simulation;computer science;data mining;statistics;measurement uncertainty	Arch	-64.29152578368002	33.04570118409424	98537
05070a6c63571ac264640a47a70771c369cd2c18	a formal evaluation of data flow path selection criteria	critere selection;computers;developpement logiciel;digital computers;prueba;computer program;software testing;evaluation performance;software testing information science computer science marine vehicles programming profession contracts terminology;path selection;general and miscellaneous mathematics computing and information science;infeasible path problem formal evaluation data flow path selection criteria data flow relationships subsumption hierarchy syntactic information;syntactic information;performance evaluation;performance test;fault tolerant;selection criterion;information science;estudio comparativo;evaluacion prestacion;flot donnee;formal evaluation;flowcharting;software engineering flowcharting;contracts;flujo datos;ingenieria logiciel;criterio seleccion;test;data flow relationships;software engineering;performance testing;testing 990200 mathematics computers;etude comparative;marine vehicles;programming profession;desarrollo logicial;research programs;data flow processing;software development;comparative study;genie logiciel;data flow path selection criteria;terminology;evaluation;computer science;data flow;programming;infeasible path problem;fault tolerant computers;process evaluation;subsumption hierarchy	A number of path selection criteria have been proposed throughout the years. Unfortunately, little work has been done on comparing these criteria. To determine what would be an effective path selection criterion for revealing errors in programs, we have undertaken an evaluation of these criteria. This paper reports on the results of our evaluation of path selection criteria based on data flow relationships. We show how these criteria relate to each other, thereby demonstrating some of their strengths and weaknesses. In addition, we suggest minor changes to some criteria that improve their performance. We conclude with a discussion of the major limitations of these criteria and directions for future research.	dataflow architecture	Lori A. Clarke;Andy Podgurski;Debra J. Richardson;Steven J. Zeil	1989	IEEE Trans. Software Eng.	10.1109/32.41326	information science;computer science;engineering;artificial intelligence;theoretical computer science;software engineering;software testing;programming language;algorithm	SE	-67.53659817922053	33.07762312184705	98567
92a2b5fbe50f66b63346d0e1f1c7cf674cfd5e1b	quantifying failure risk of version switch for rolling upgrade on clouds	virtual machining;software systems;web services cloud computing configuration management markov processes quality of service risk management virtual machines;cloud operation;rolling upgrade;fault tolerant systems;risk;risk software dependability cloud operation rolling upgrade stochastic model;fault tolerance;software dependability;stochastic model;switches fault tolerance fault tolerant systems software systems virtual machining;switches;aws failure risk quantification industry technique online dynamic software update rolling upgrade updates wave rolling version switch point cloud platform virtual machine instances backup images quality of service discrete markov chains dtmc amazon web service	Rolling upgrade is an industry technique for online dynamic software update. A rolling upgrade updates a small number of instances in an old version to a new version at a time and the operation is repeated in a wave rolling until all of the instances have been upgraded. In many cases, the software needs to avoid interactions between different versions. One common simple approach is to make instances version aware, and then a version switch point can be chosen to deactivate the old service and activate the new service. On a Cloud platform, upgrades can be implemented simply through replacing old virtual machine instances with ones in new versions, and during the process of rolling upgrade various failures may present. If an instance fails, a new instance has to be launched from the backup images, which in most software systems are in an old version and cannot be simply replaced to a new version if the new software and the new service have not been stable for the sake of reliability and stability. Thus the progress of the rolling upgrade is not guaranteed, and indeed the number of upgraded instances can sometimes decrease. We aim to determine the probability that, after switching the versions at a selected point, the number of working instances may sometime fall below the amount needed for a desired Quality of Service. In this paper, we stochastically quantify the risk with a family of discrete Markov chains (DTMC). The evaluation in both Amazon Web Service (AWS) and simulation reveals that our technique can well predict the risks after given version switch points.	amazon web services;apache wave;backup;cloud computing;experiment;interaction;internet;markov chain;mathematical optimization;oldversion.com;patch (computing);quality of service;risk management;scheduling (computing);simulation;software system;virtual machine;web service	Daniel Sun;Leonard J. Bass;Alan Fekete;Vincent Gramoli;An Binh Tran;Sherry Xu;Liming Zhu	2014	2014 IEEE Fourth International Conference on Big Data and Cloud Computing	10.1109/BDCloud.2014.16	fault tolerance;real-time computing;simulation;network switch;computer science;stochastic modelling;operating system;risk;software system	Theory	-63.475203598396384	43.18683129570256	99665
4b56e88b2918c7eea0c015878895fc95e712105a	experience report on the effect of software development characteristics on change distribution	industrial case study;experience report;oil and gas;software development;software changes;software reuse;software quality	This paper reports on an industrial case study in a large Norwegian Oil and Gas company (StatoilHydro ASA) involving a reusable Java-class framework and an application that uses that framework. We analyzed software changes from three releases of the framework and the application. On the basis of our analysis of the data, we found that perfective and corrective changes account for the majority of changes in both the reusable framework and the nonreusable application. Although adaptive changes are more frequent and has longer active time in the reusable framework, it went through less refactoring compared to the non-reusable application. For the non-reusable application we saw preventive changes as more frequent and with longer active time. We also found that designing for reuse seems to lead to fewer changes, as well as we saw a positive effect on doing refactoring.	asa carriage control characters;code refactoring;control theory;design rule for camera file system;ibm notes;java;requirement;software development;software quality	Anita Gupta;Reidar Conradi;Forrest Shull;Daniela Cruzes;Christopher Ackermann;Harald Rønneberg;Einar Landre	2008		10.1007/978-3-540-69566-0_15	reliability engineering;systems engineering;engineering;software development;software engineering;software quality	SE	-64.59319383709263	34.22733753115918	99918
e2593f113da82f71304f7dba4ec796a8f859d68a	multilayered impact evaluation model for attacking missions	software;complexity theory;probability;measurement;complexity theory probability monitoring computational modeling measurement sun software;computational modeling;monitoring;sun;target range attack impact evaluation model mission	In practical application scenarios, direct attacking on a target system to test the impact of attack methods may expose an attacker's intent and result in the difficulty in evaluating the attack method. Therefore, it is essential to design a controllable target range for testing and evaluating the attack impact. In this paper, we construct an attack test platform in order to evaluate the attack impact from different attack tools or the combinations of these attack tools. According to “vulnerability-asset-service-mission” (VASM) relationship, we design a multilayered evaluation model VASM, which includes a four-layer information structure: vulnerability layer, asset layer, service layer, and mission layer, from bottom to top. Considering that each asset may have one or more vulnerabilities, we score the attack impact on each asset based on attack probability and vulnerability and calculate the operational capacity of an asset after an attack. Since services may be provided jointly by one or more assets, we calculate the attack impact on services utilizing the dependencies among assets. The attack impact can be transmitted layer by layer from bottom to top through the dependencies among nodes. Finally, we can obtain the attack impact on missions. We use an actual logistics management and tracking system as the target range and verify the effectiveness and validity of our evaluation model, i.e., VASM, on goods delivery. Experimental results show that VASM cannot only assess the attack impact directly but also conform to the actual situations accurately.	logistics;service layer;tracking system	Yan Sun;Tin Yu Wu;Xinwei Liu;Mohammad S. Obaidat	2016	IEEE Systems Journal	10.1109/JSYST.2014.2344048	reliability engineering;simulation;telecommunications;computer science;engineering;probability;computational model;computer security;measurement;statistics;computer network	Security	-65.20457893763535	59.42341487721493	100107
228d008ebca6daf583451c3323cd51c07f543c8a	comprehension of object-oriented software cohesion: the empirical quagmire	software metrics;information systems;computer science software maintenance educational institutions information systems software measurement software tools data structures fault detection skeleton hamming distance;software measurement;software maintenance;object oriented software;object oriented programming;c language object oriented programming reverse engineering software metrics;software engineering;skeleton;class methods;conference paper;empirical evidence;object oriented metric suite;c language;hamming distance;object oriented;data structures;fault detection;object oriented software cohesion comprehension;software tools;computer science;class methods object oriented software cohesion comprehension object oriented metric suite lack of cohesion of methods metric maintainability large c systems;maintainability;reverse engineering;lack of cohesion of methods metric;large c systems	It is a little over ten years sinc e Chidamber and Kemerer's obje ct-oriented (OO) metric suite which included the Lack of Cohesion Of Methods (LCOM) metric was rst proposed [9]. Despite considerable e ort both theoretically and empirically sinc e then, the softwar eengineering community is still no ne arer nding a generally ac cepte d de nition or me asure of OO cohesion. Y et,achieving highly cohesive software is a cornerstone of software comprehension and hence, maintainability. In this pap er, we suggest a number of suppositions as to why a de nition has eluded (and we feel will continue to elude) us. We supp ortthese suppositions with empirical evidence from three large C++ systems and a cohesion metric based on the parameters of the class methods; we also draw from other related work. Two major conclusions emerge from the study. Firstly, any sensible cohesion metric does at least provide insight into the featur es of the systems being analysed. Se condly however, and less reassuringly, the deeper the investigative search for a de nitive measur eof cohesion, the more problematic its understanding becomes; this casts serious doubt on the use of cohesion as a meaningful featur eof obje ct-orientation and its viability as a tool for software comprehension.	c++;computer science;hamming distance;list comprehension;open road tolling;sinc function	Steve Counsell;Emilia Mendes;Stephen Swift	2002		10.1109/WPC.2002.1021308	reliability engineering;data structure;computer science;systems engineering;software engineering;programming language;object-oriented programming	SE	-64.38570941557758	35.759633521196704	100165
23076c7bd2a9ac5709fe06aa10cbb057a2a1cdae	cognitive complexity as a quantifier of version to version java-based source code change: an empirical probe		Abstract Context It has been often argued that it is challenging to modify code fragments from existing software that contains files that are difficult to comprehend. Since systematic software maintenance includes an extensive human activity, cognitive complexity is one of the intrinsic factors that could potentially contribute to or impede an efficient software maintenance practice, the empirical validation of which remains vastly unaddressed. Objective This study conducts an experimental analysis in which the software developeru0027s level of difficulty in comprehending the software: the cognitive complexity, is theoretically computed and empirically evaluated for estimating its relevance to actual software change. Method For multiple successive releases of two Java-based software projects, where the source code of a previous release has been substantively used in a novel release, we calculate the change results and the values of the cognitive complexity for each of the versionu0027s source code Java files. We construct eight datasets and build predictive models using statistical analysis and machine learning techniques. Results The pragmatic comparative examination of the estimated cognitive complexity against prevailing metrics of software change and software complexity clearly validates the cognitive complexity metric as a noteworthy measure of version to version source code change.		Loveleen Kaur;Ashutosh Mishra	2019	Information & Software Technology	10.1016/j.infsof.2018.09.002	programming complexity;data mining;cognitive complexity;source code;computer science;theoretical computer science;software;software maintenance;java	Logic	-63.883916983880006	35.59610493385492	100592
619cef25ac0f4ebed127140baa286895cf6b6c89	a format statement in scratchpad	format statement	In [1] Lops i l lustrates the usefulness of hav ing a var ie ty of internal represen ta t ions for Simplification. While this is undoubted ly a good idea no cur ren t a lgebra ic sys tem has been e n d o w e d with such a mul t i tude of in terna l forms. Indeed most cu r ren t symbol ic sys tems ca r ry out all compu ta t i ons in a single internal form, a fo rm which the user has little con t ro l over and which if direct ly expressed in ma themat i ca l f o rm is o f ten inconven ien t fo r user in te rp re ta t ion . A n a l t e rna te a p p r o a c h to mult iple in terna l fo rms is the new F O R M A T s ta t emen t in S C R A T C H P A D by which the user can des igna te f rom a wide range of possible r ep resen ta t ions one which is most appropr i a t e for the cur ren t express ion to be displayed. This s t a t emen t t akes the form: f o r m a t = < c o d e > , w h e r e some present ly a l lowed codes are:	code;fo (complexity);hardware-assisted virtualization;naruto shippuden: clash of ninja revolution 3;scratchpad memory;text simplification	James H. Griesmer;Richard D. Jenks;David Y. Y. Yun	1975	ACM SIGSAM Bulletin	10.1145/1088309.1088317	programming language	AI	-91.09541602341538	33.11778413348908	101050
8d87a04d2a87095bbf37c5e53c972428b3c27dc4	samekana: a browser extension for including relevant web links in issue tracking system discussion forum	software;google;bibliography samekana including relevant web links issue tracking system discussion forum google issue tracker bugzilla maintenance team bug report descriptions issue tracing system web sites google chromium developers web references google chromium issue tracking system bug report types bug resolution time data characterization building productivity tool issue tracking system comments google chromium web browser extension google chromium web store;developer productivity tool mining software repositories msr empirical software engineering and measurements esem software maintenance mining bug reports;computer crashes;software maintenance;google chromium browsers internet discussion forums computer crashes software;discussion forums;developer productivity tool;browsers;online front ends;empirical software engineering and measurements esem;internet;web sites online front ends;chromium;web sites;mining software repositories msr;mining bug reports	Several widely used Issue tracking systems (such as Google Issue Tracker and Bugzilla) contains an integrated threaded discussion forum to facilitate discussion between the development and maintenance team (bug reporters, bug triagers, bug fixers and quality assurance managers). We observe that several comments (and even bug report descriptions) posted to issue tracing system contains links to external websites as references to knowledge sources relevant to the discussion. We conduct a survey (and present the results of the survey) of Google Chromium Developers on the importance and usefulness of web references in issue tracking system comments and the need of a web-browser extension which facilitates easy organization and inclusion of web-links in the post. We conduct a characterization study on an experimental dataset from Google Chromium Issue Tracking system and present results on the distribution of number of links in the dataset, categorization of links into pre-defined classes (such as blogs, community based Q&A websites, developer discussion forums, version control system), correlation of number and types of links with various bug report types (such as security, crash, regression and clean-up) and relation between presence of links and bug resolution time. Survey results and data characterization study motivate the need of building a developer productivity tool to facilitate web-link (as references) organization and inclusion in issue tracking system comments. We present a Google Chromium Web Browser Extension called as Samekana and publish the extension on Google Chromium Web Store which can be freely downloaded by users worldwide. The extension contains features such as annotating (using tags, title and description) and saving web references pertaining to multiple bug reports and tasks and then posting it as bibliography (for easy citation and reference) in issue tracking system comments.	blog;browser extension;bug tracking system;bugzilla;categorization;chromium (web browser);comment (computer programming);control system;conversation threading;crash (computing);google chrome;heart rate variability;issue tracking system;open-source software;organizing (structure);software maintenance;tag (metadata);version control;web search engine	Denzil Correa;Sangeeta Lal;Apoorv Saini;Ashish Sureka	2013	2013 20th Asia-Pacific Software Engineering Conference (APSEC)	10.1109/APSEC.2013.15	chromium;computer science;engineering;software engineering;data mining;database;software maintenance;world wide web	SE	-63.64112603823623	36.50837772923228	101957
544fe1a03e1c2af6f4e26235a99a69536ba19fd1	understanding vicious cycles in server clusters	web server vicious cycles server clusters automated on line service troubleshooting performance problems diagnostics failed components large scale systems discriminative sequence mining anomalous sequences performance management correlation analysis continuous variables;file servers;program diagnostics;interactive complexity;performance evaluation;performance management;continuous variable;web services computer facilities file servers large scale systems performance evaluation program diagnostics;large scale system;prior knowledge;adaptive components;data center;a priori knowledge;complex data;performance troubleshooting interactive complexity data center adaptive components;performance troubleshooting;web services;computer facilities;statistical techniques;color servers voltage control monitoring computer bugs software degradation;large scale systems;correlation analysis	"""In this paper, we present an automated on-line service for troubleshooting performance problems in server clusters caused by unintended vicious cycles. The tool complements a large volume of prior performance troubleshooting and diagnostic literature for server farms that identifies problems arising due to resource bottlenecks or failed components. We show that unintended interactions between components in large-scale systems can cause performance problems even in the absence of bottlenecks or failures. Our tool leverages discriminative sequence mining to identify anomalous sequences of events that are candidates for blame for the performance problem. The tool looks for patterns consistent with """"vicious cycles"""" or unstable behavior, as such patterns, when present, are most likely to be problematic. It highlights candidates that are semantically conflicting, such as those arising when different performance management mechanisms make adjustments in conflicting directions. Our approach offers two key advantages in performance troubleshooting. First, it does not require detailed prior knowledge of the underlying system to diagnose the problem. Second, contrary to simple statistical techniques, such as correlation analysis, that work well for continuous variables, our scheme can also identify chains of events (labels) that may explain the root cause of a problem. Our service is deployed on a web server testbed of 17 machines. To make the comparison of our scheme to prior work more concrete, we first reproduce two real-life problem scenarios reported in earlier literature, then explore a third, new case study. In all cases, our tool reports the patterns that explain the cause of the problem without requiring detailed a priori knowledge."""	bottleneck (software);control theory;data mining;distributed computing;elegant degradation;graph coloring;heuristic;interaction;online and offline;pattern recognition;real life;sequential pattern mining;server (computing);server farm;software as a service;testbed;web server	Mohammad Maifi Hasan Khan;Jin Heo;Shen Li;Tarek F. Abdelzaher	2011	2011 31st International Conference on Distributed Computing Systems	10.1109/ICDCS.2011.73	web service;file server;data center;performance management;a priori and a posteriori;simulation;computer science;operating system;data mining;database;distributed computing;law;world wide web;computer security;statistics;complex data type	HPC	-63.65238794410878	40.477772187224836	102319
8185a57accfc5217f3e7223dc82e7c75e5199f40	effective message synchronization methods for multiplayer online games with maps	online game;nve;client server architecture;architecture client serveur;on line;en linea;videojuego;hombre;message;multiplayer online games;video game;jeu video;message synchronization;synchronisation;waiting period;client server;synchronization;human;arquitectura cliente servidor;en ligne;sincronizacion;homme	A solution for the message synchronization problem of the clientserver based game system is to wait for a certain period of time (waiting period) until the server processes the messages from clients. However, identifying a suitable waiting period proves challenging. In this paper, we develop two methods to determine the waiting period using the probability of interaction among participants and ranking of the delay among participants. Our methods take advantage of the property of games with geographical mapping, where each participant usually interacts with other participants only in the immediate surroundings. Simulation is performed for the evaluation of the methods and the shows that the proposed methods produce better results with lower average unfair ratio while keeping the same responsiveness compared to the method with prefixed waiting period. 2008 Elsevier Ltd. All rights reserved.	algorithm;interaction;max;responsiveness;server (computing);simulation;synchronization (computer science)	Doowon Paik;Chung-Ha Yun;Jooyeon Hwang	2008	Computers in Human Behavior	10.1016/j.chb.2008.03.004	synchronization;real-time computing;simulation;computer science;distributed computing;world wide web;client–server model	Web+IR	-73.90044276743221	45.09954598258789	102542
42ccef59ceeed35ab2f97915c44652043df83ff6	a case of soft system methodology (ssm): interacting aspect modelling of customer satisfaction in video stream service over wireless and mobile network	radio networks;look up table;video streaming;video streaming customer satisfaction mobile radio quality of service radio networks;business strategy;customer loyalty;qos;customer satisfaction;customer care soft system methodology interacting aspect modelling customer satisfaction video stream service wireless network mobile network customer loyalty market opportunity quality of service parameters quality of user experience factors business strategy service stakeholders pricing;mobile radio;user experience;qoe;look up table lut modelling;soft system methodology;quality of service;look up table lut modelling qos qoe soft system methodology ssm;soft system methodology ssm;streaming media customer satisfaction mobile communication quality of service mobile computing table lookup problem solving;problem solving;mobile network	Customer satisfaction has become essential in any service due to its positive influence to customer loyalty and further market opportunity. In video stream service over wireless and mobile network, customer satisfaction is determined by many interacting aspects. It includes objective Quality of Service (QoS) parameters and subjective Quality of user Experience (QoE) factors. In addition, customer satisfaction is also determined by business strategy that applied by service stakeholders e.g. pricing and customer care. Some issues arise due to interaction between these aspects. These issues are difficult to be addressed by creative and logical problem solving strategy. This paper discusses Soft System Methodology (SSM) to elucidate what the actual problem of these interacting aspects. It is expressed through seven consecutive stages of SSM that illustrate problem solving process from unstructured problem to structured problem. This paper also proposes a methodology to model the interacting aspects in determining customer satisfaction.	customer relationship management;interaction;problem solving;quality of service;soft systems methodology;strategic management;streaming media;user experience;way to go	Herman;Azizah Abd. Rahman;Yoanda Alim Syahbana	2011	2011 UKSim 5th European Symposium on Computer Modeling and Simulation	10.1109/EMS.2011.72	service level requirement;voice of the customer;simulation;loyalty business model;marketing;operations management;customer reference program;customer intelligence;business;customer service assurance;service quality	AI	-72.44250979936322	40.28334993896896	103014
92061abc20f96f7c6d500466ea66b662b43d3f76	an empirical study of clone density evolution and developer cloning tendency	maintenance engineering;companies;software engineering;cloning;open source software;java	Code clones commonly occur during software evolution. They impact the effort of software development and maintenance, and therefore they need to be monitored. We present a large-scale empirical study (237 open-source Java projects maintained by 500 individuals) that investigates how the number of clones changes throughout software evolution, as well as the tendency of individual developers to introduce clones. Our results will set a point-of-reference against which development teams can compare and, if needed, adjust.	java;open-source software;software development;software evolution	Brent van Bladel;Alessandro Murgia;Serge Demeyer	2017	2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER)	10.1109/SANER.2017.7884672	reliability engineering;long-term support;team software process;systems engineering;engineering;package development process;software development;software engineering	SE	-64.44930570759881	34.243854543904654	103339
6476989d1daee71da22854cd73d26a0e339165fc	quantifying the evolution of ttcn-3 as a language	data mining;language evolution;quantitative analysis;repository mining;ttcn 3	Ten years of maintenance, nine published revisions of the standards for the Testing and Test Control Notation version 3 (TTCN-3), more than 500 change requests since 2006, and 10 years of activity on the official TTCN-3 mailing list add up to a rich history, not unlike that of many successful Open Source Software (OSS) projects. In this article, we contemplate TTCN-3 in the context of software evolution and examine its history quantitatively. We mined the changes in the textual content of the standards, the data in change requests from the past 5 years, and the mailing list archives from the past 10 years. In addition, to characterize the use of the TTCN-3 we investigated the meta-data of the contributions at the TTCN-3 User Conference, and the use of language constructs in a large-scale TTCN-3 test suite. Based on these data sets, we first analyze the amount, density, and location of changes within the different parts of the standard. Then, we analyze the activity and focus of the user community and the maintenance team in both the change request management system and the official TTCN-3 mailing list. Finally, we analyze the distribution of contributions at the TTCN-3 User Conference across different topics over the past 8 years and construct use anomalies during the development of a large-scale test suite. Our findings indicate that the TTCN-3 is becoming increasingly stable as the overall change density and intensity, as well as the number of change requests are decreasing, despite the monotonous increase in the size of the standards.	archive;beta normal form;change request;compaq lte;interactivity;microsoft outlook for mac;mined;open sound system;programming language;software evolution;ttcn-3;test suite;virtual community	Philip Makedonski;Jens Grabowski;Florian Philipp	2013	International Journal on Software Tools for Technology Transfer	10.1007/s10009-013-0282-1	computer science;quantitative analysis;software engineering;data mining;database;programming language;world wide web;algorithm	SE	-67.93719326325684	34.373256789987515	103386
7b9d15f1dcb683631995342e6cb3f3e415f93446	introduction to future networks management architectures and mechanisms	communications technology;critical infrastructure;future internet;current issue;socio-technical point;future networks management architecture;network operator;mobile service;service provider;next generation network;integrated service	In this chapter, current issues of the Internet are addressed and arising problems of future Internet from socio-technical point of view are tackled. The future Internet considered as a Next Generation Network (NGN) will provide integrated services, i.e. interactive, multimedia, data, real-time, and mobile services. The focus will be placed on the end-user for whom this information and communications technologies (ICT) are primarily designed for. The user's dependence on ICT is rising, being tied to increasing complexity of critical infrastructures (CIs) interdependencies. No wonder that also other stakeholders (service providers and network operators) have to be in the focus.		Iztok Starc	2012		10.1007/978-3-642-30382-1_20	simulation;computer science;knowledge management;multimedia	Arch	-69.92733499741364	41.284183816499635	103487
dc1af1ac4e616aa507b37851dea75598f41cd20d	analyzing and predicting software integration bugs using network analysis on requirements dependency network	requirements dependency;network analysis;bug prediction	Complexity, cohesion and coupling have been recognized as prominent indicators of software quality. One characterization of software complexity is the existence of dependency relationships. Moreover, the degree of dependency reflects the cohesion and coupling between software elements. Dependencies in the design and implementation phase have been proven to be important predictors of software bugs. We empirically investigated how requirements dependencies correlate with and predict software integration bugs, which can provide early estimates regarding software quality and thus facilitate decision making early in the software lifecycle. We conducted network analysis on the requirements dependency networks of three commercial software projects. Significant correlation is observed between most of our network measures and the number of bugs. Furthermore, many network measures demonstrate significantly greater values for higher severity (or a higher fixing workload). Afterward, we built bug prediction models using these network measures and found that bugs can be predicted with high accuracy and sensitivity, even in cross-project and cross-company contexts. We further identified the dependency type that contributes most to bug correlation, as well as the network measures that contribute more to bug prediction. These observations show that the requirements dependency network can be used as an early indicator and predictor of software integration bugs.	cohesion (computer science);commercial software;coupling (computer programming);kerrison predictor;programming complexity;requirement;social network analysis;software bug;software development process;software quality;system integration	Junjie Wang;Qing Wang	2014	Requirements Engineering	10.1007/s00766-014-0215-x	reliability engineering;regression testing;real-time computing;network analysis;computer science;data mining;software regression	SE	-63.48855983167678	34.573914356429704	104241
05883578bfca065d8b41e6858816a7eb5d698e57	yo variability! jhipster: a playground for web-apps analyses	web apps;variability related analyses	Though variability is everywhere, there has always been a shortage of publicly available cases for assessing variability-aware tools and techniques as well as supports for teaching variability-related concepts. Historical software product lines contains industrial secrets their owners do not want to disclose to a wide audience. The open source community contributed to large-scale cases such as Eclipse, Linux kernels, or web-based plugin systems (Drupal, WordPress). To assess accuracy of sampling and prediction approaches (bugs, performance), a case where all products can be enumerated is desirable. As configuration issues do not lie within only one place but are scattered across technologies and assets, a case exposing such diversity is an additional asset. To this end, we present in this paper our efforts in building an explicit product line on top of JHipster, an industrial open-source Web-app configurator that is both manageable in terms of configurations (≈ 163,000) and diverse in terms of technologies used. We present our efforts in building a variability-aware chain on top of JHipster's configurator and lessons learned using it as a teaching case at the University of Rennes. We also sketch the diversity of analyses that can be performed with our infrastructure as well as early issues found using it. Our long term goal is both to support students and researchers studying variability analysis and JHipster developers in the maintenance and evolution of their tools.	drupal;eclipse;heart rate variability;jhipster;linux;open-source software;sampling (signal processing);software bug;software product line;spatial variability;web application;wordpress	Axel Halin;Alexandre Nuttinck;Mathieu Acher;Xavier Devroey;Gilles Perrouin;Patrick Heymans	2017		10.1145/3023956.3023963	web application;simulation;computer science;systems engineering;engineering;software engineering;programming language;management	SE	-67.0985586318197	36.14880216440668	104971
7a9c0f2ed34012c0ae691e00b641047234064f91	refactoring prediction using class complexity metrics	complexity metrics	In the lifetime of a software product, development costs are only the tip of the iceberg. Nearly 90% of the cost is maintenance due to error correction, adoptation and mainly enhancements. As Belady and Lehman (Lehman and Belady, 1985) state that software will become increasingly unstructured as it is changed. One way to overcome this problem is refactoring. Refactoring is an approach which reduces the software complexity by incrementally improving internal software quality. Our motivation in this research is to detect the classes that need to be rafactored by analyzing the code complexity. We propose a machine learning based model to predict classes to be refactored. We use Weighted Naïve Bayes with InfoGain heuristic as the learner and we conducted experiments with metric data that we collected from the largest GSM operator in Turkey. Our results showed that we can predict 82% of the classes that need refactoring with 13% of manual inspection effort on the average.	code refactoring;error detection and correction;experiment;heuristic;lászló bélády;machine learning;naive bayes classifier;programming complexity;software quality	Yasemin Kösker;Burak Turhan;Ayse Basar Bener	2008			halstead complexity measures;computer science	SE	-64.5086389109986	34.190580639676774	105025
df00e7ee94e97b7883437c02c971a70471b96368	structural clones: an evolution perspective		Structural clones are recurring patterns of simple code clones in software that represent a bigger picture of similarity in software (e.g. software design). Elevating the analysis of cloning to structural clone level helps in better clone management in terms of clone understanding, maintenance and evolution. In this paper, we propose a systematic approach to study structural clone evolution in software versions. We use our approach to analyze the evolutionary behavior of structural clones and also compare it with the evolution of simple clones. We performed experiments on different versions of three Java systems. Our analysis of structural clone evolution reveals interesting evolutionary characteristics of clones. For example, one finding is that simple clones are more frequently changed than structural clones whereas average lifetime of structural clones is less than that of simple clones. Study of clone evolution is helpful for identifying maintenance implications of clones and for devising better clone management systems.	evolution;experiment;java;software design;software versioning	Jaweria Kanwal;Hamid Abdul Basit;Onaiza Maqbool	2018	2018 IEEE 12th International Workshop on Software Clones (IWSC)	10.1109/IWSC.2018.8327313	software system;clone (java method);software;software versioning;software design;software maintenance;java;computer science;bioinformatics	SE	-63.72158948694304	35.58520458553048	105100
cb23dfc0f607e5dc2c64676213320baa92d883fb	practices and tools for better software testing		Automated testing (hereafter referred to as just `testing') has become an essential process for improving the quality of software systems. In fact, testing can help to point out defects and to ensure that production code is robust under many usage conditions. However, writing and maintaining high-quality test code is challenging and frequently considered of secondary importance. Managers, as well as developers, do not treat test code as equally important as production code, and this behaviour could lead to poor test code quality, and in the future to defect-prone production code. The goal of my research is to bring awareness to developers on the effect of poor testing, as well as helping them in writing better test code. To this aim, I am working on 2 different perspectives: (1) studying best practices on software testing, identifying problems and challenges of current approaches, and (2) building new tools that better support the writing of test code, that tackle the issues we discovered with previous studies. Pre-print: https://doi.org/10.5281/zenodo.1411241		Davide Spadini	2018		10.1145/3236024.3275424	computer science;software system;software engineering;theoretical computer science;best practice;software quality;identifying problems;software;code review	SE	-64.62835859611916	33.90415171162768	106124
9c1864aa1d7ed24d6004257b247874ba795ac65c	an empirical study of web-based inspection meetings	groupware;empirical study;groupware support empirical study world wide web inspection meetings software engineering defect detection rework reduction empirical evaluation internet distributed software inspections restructured inspection process discussion forums voting remote inspections false positives filtering;best practice;software fault tolerance;inspection;software engineering;software quality internet software development management groupware inspection software fault tolerance;inspection collaborative software software engineering best practices internet collaborative work software tools discussion forums voting filtering;internet;discussion forum;false positive;empirical evaluation;software inspection;face to face;software quality;software development management	Software inspections are a software engineering “best practice” for defect detection and rework reduction. In this paper, we describe an empirical evaluation with using a tool aiming to provide Internet groupware support for distributed software inspections. The tool is based on a restructured inspection process where inspection meetings have the only goal of removing false positives rather than finding additional defects. In place of face-to-face meetings, the tool provides web-based discussion forums and support for voting. We present an empirical study of nine remote inspections which were held as part of a university course. We investigated whether all collected defects are worth to be discussed as a group. Results show that discussions for filtering out false positives (non true defects) might be restricted to defects which were discovered by only one inspector.	best practice;collaborative software;distributed computing;rework (electronics);software bug;software engineering;software inspection;web application	Filippo Lanubile;Teresa Mallardo	2003		10.1109/ISESE.2003.1237984	reliability engineering;engineering;data mining;computer security	SE	-66.86138736365044	34.31748847505876	107176
e6a101f5f20e533d3355501ebddf5cc194cb8d48	assessing the impact of bad smells using historical information	institutional repositories;design principle;empirical study;fedora;software maintenance;software systems;vital;design defects;bad smells;software evolution;design flaws;code clone;source cede;vtls;software quality;ils	Our aim is to gain a better understanding of the relationship between bad smells and design principle violations, in order to better identify the root causes of a given set of bad smells and target refactoring efforts more effectively. In particular, knowing which bad smells point to important design problems would help to focus developers' efforts. In this position paper we argue that such knowledge requires the empirical study of the evolution of software systems: on the one hand because design problems and their symptoms take time to develop, on the other hand because we need to relate maintenance activity to bad smells to measure their relative importance. We illustrate how existing studies of the evolution of a particular kind of bad smell, code clones, have led to further insights into the harmfulness of cloning.	code refactoring;code smell;qr code;software system	Angela Lozano;Michel Wermelinger;Bashar Nuseibeh	2007		10.1145/1294948.1294957	reliability engineering;systems engineering;engineering;software evolution;software engineering;empirical research;software maintenance;computer security;software quality;code smell;software system	SE	-64.03294317158813	35.00000759129642	107524
56365836f10fba062ff14ab146bf77fa452b4fd7	a critical analysis of current oo design metrics	measurement;object oriented metrics;metrics;oo;object oriented;smalltalk;system development	Chidamber and Kemerer (C&K) outlined some initial proposals for language-independent OO design metrics in 1991. This suite is expanded on by C&K in 1994 and the metrics were tested on systems developed in C++ and Smalltalk™. The six metrics making up the C&K suite can be criticised for a number of reasons. This does not make them bad metrics; on the contrary the C&K work represents one of the most thorough treatments of the subject at the current time. However, the authors explicitly state ...there is no reason to believe that the proposed metrics will be found to be comprehensive, and further work could result in additions, changes and possible deletions from this suite. This analysis will serve to make other researchers and practitioners aware of some of the problems that may arise from using these measures. As a by-product, the axioms of E. Weyuker (1983) come under scrutiny in terms of their applicability to object-oriented metrics.	c++;language-independent specification;smalltalk	Tobias Mayer;Tracy Hall	1999	Software Quality Journal	10.1023/A:1008900825849	reliability engineering;computer science;systems engineering;programming language;object-oriented programming;metrics;measurement	SE	-63.88906059721927	35.61560250800746	108285
c720c9ba8bf349872a0da4374fd5d55fc4d3a161	the impact of human factors on the participation decision of reviewers in modern code review		Modern Code Review (MCR) plays a key role in software quality practices. In MCR process, a new patch (i.e., a set of code changes) is encouraged to be examined by reviewers in order to identify weaknesses in source code prior to an integration into main software repositories. To mitigate the risk of having future defects, prior work suggests that MCR should be performed with sufficient review participation. Indeed, recent work shows that a low number of participated reviewers is associated with poor software quality. However, there is a likely case that a new patch still suffers from poor review participation even though reviewers were invited. Hence, in this paper, we set out to investigate the factors that are associated with the participation decision of an invited reviewer. Through a case study of 230,090 patches spread across the Android, LibreOffice, OpenStack and Qt systems, we find that (1) 16%-66% of patches have at least one invited reviewer who did not respond to the review invitation; (2) human factors play an important role in predicting whether or not an invited reviewer will participate in a review; (3) a review participation rate of an invited reviewers and code authoring experience of an invited reviewer are highly associated with the participation decision of an invited reviewer. These results can help practitioners better understand about how human factors associate with the participation decision of reviewers and serve as guidelines for inviting reviewers, leading to a better inviting decision and a better reviewer participation.	android;human factors and ergonomics;libreoffice;memory card reader;patch (computing);software quality;software repository	Shade Ruangwan;Patanamon Thongtanunam;Akinori Ihara;Kenichi Matsumoto	2018	Empirical Software Engineering	10.1007/s10664-018-9646-1	data mining;software;source code;software quality;android (operating system);computer science;code review	SE	-65.79686928942682	33.59991808205144	108623
9f6c45588ad288485e428baea5078f252efb0e82	supervisory decision making in emergency response application	telecommunication network reliability;wireless mesh networks decision making discrete event systems emergency management petri nets telecommunication network reliability;emergency management;color petri net decision making supervisory control;discrete event systems;wireless mesh networks;system recovery organizations petri nets emergency services decision making supervisory control complexity theory;petri nets;color petri net supervisory decision making emergency response application failure emergency response scenario limited information access delayed information access communication infrastructure information reliability in time information delivery wireless mesh discrete event system modeling technique supervisory control solution organizational level unclear termination incomplete message transfer deadlock free path	Two main causes of failure in an emergency response scenario are in communication leading to limited or delayed access to the information and delayed or poor decision making. A good choice of communication infrastructure to provide reliable and in-time delivery of information in early stage of an emergency response saves lives and money. Given that a wireless mesh is deployed or another communication infrastructure exists, the next effort is to send data from the field to decision makers off the field to improve decision making. In this paper, we use discrete event system modeling technique to illustrate how use of supervisory control solutions on on a discrete event system model can improve communication at organizational level. We present challenges and lessons learned from several real-life drills we have participated such as unclear termination or incomplete message transfer. We delineate a supervisory control solution that with higher authority and expertise can improve decision making by canceling a path and enforcing a deadlock-free path.	deadlock;real life;systems modeling;wireless mesh network	Raheleh B. Dilmaghani;Ramesh R. Rao	2013	2013 IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops)	10.1109/PerComW.2013.6529557	real-time computing;computer science;computer security;petri net;emergency management	Robotics	-77.56904307771413	33.82180080921371	108809
afa73ee82c00d9690c4a0507cecc037c0511465f	automatic security assessment of critical cyber-infrastructures	graph theory;control systems;circuit faults;lattices;authorisation;automatic security assessment;automatic generation;network topology;online event aggregator;network connectivity;network model;unified modeling language;mathematical model;security unified modeling language object oriented modeling control systems mathematical model lattices circuit faults;scada system;workflow model;power grid;security assessment;dynamic critical cyber infrastructure;access control;power grids;electric power;scada systems;static critical cyber infrastructure;security;attack graph automatic security assessment dynamic critical cyber infrastructure static critical cyber infrastructure electrical power grid network model workflow model scada system network connectivity access control online event aggregator;attack graph;object oriented modeling;power system control;electrical power grid;scada systems authorisation graph theory power grids power system control;dynamic properties	This research investigates the automation of security assessment of the static and dynamic properties of cyber infrastructures, with emphasis on the electrical power grid. We describe a network model representing the static elements of a cyber infrastructure including devices, services, network connectivity, vulnerabilities, and access controls. The dynamic elements include workflow models of the operating procedures, processes and the state of a working power grid. We introduce a toolkit that with a little manual assistance can automatically generate these models from specifications, continuously update attributes from online event aggregators, and perform security assessment. The assessment reveals whether observed anomalies about the system could indicate possible security problems and permit dynamic ranking of alternative recovery procedures to minimize the total risk. We motivate the use of the tool-chain by showing an example scenario where the recovery procedure recommended to minimize security risk depends on the current state of system as well as the network topology.	access control;computer-integrated manufacturing;feedback;model checking;network model;network topology;recovery procedure;scalability;toolchain;vulnerability (computing)	Zahid Anwar;Ravinder Shankesi;Roy H. Campbell	2008	2008 IEEE International Conference on Dependable Systems and Networks With FTCS and DCC (DSN)	10.1109/DSN.2008.4630105	unified modeling language;electric power;computer science;information security;access control;graph theory;theoretical computer science;network model;lattice;mathematical model;security service;distributed computing;authorization;computer security;network topology;computer network;scada	SE	-63.42610834486583	60.21403854125048	108835
115d78520c81e25b230d141994c3c83a7ee0271b	investigating the cost-effectiveness of reinspections in software development	phase detection;investments;software cost estimation;project management;requirements document;costs and benefits;yield estimation;inspection;software performance;requirements document cost effectiveness reinspections software development cost benefit model;code inspection;code review;program testing;cost benefit model;systems analysis;object oriented;scheduling;software development;cost effectiveness;programming inspection costs scheduling yield estimation software quality project management investments software performance phase detection;reinspections;software cost estimation software quality inspection program testing systems analysis;programming;software inspection;software quality;empirical methods	Software inspection is one of the most effective methods to detect defects. Reinspection repeats the inspection process for software products that are suspected to contain a significant number of undetected defects after an initial inspection. As a reinspection is often believed to be less efficient than an inspection an important question is whether a reinspection justifies its cost. In this paper we propose a cost-benefit model for inspection and reinspection. We discuss the impact of cost and benefit parameters on the net gain of a reinspection with empirical data from an experiment in which 31 student teams inspected and reinspected a requirements document. Main findings of the experiment are: a) For reinspection benefits and net gain were significantly lower than for the initial inspection. Yet, the reinspection yielded a positive net gain for most teams with conservative cost-benefit assumptions. b) Both the estimated benefits and number of major defects are key factors for reinspection net gain, which emphasizes the need for appropriate estimation techniques.	emoticon;requirement;software development;software inspection	Stefan Biffl;Bernd G. Freimut;Oliver Laitenberger	2001		10.1109/ICSE.2001.919090	project management;reliability engineering;simulation;computer science;systems engineering;engineering;software engineering;software inspection	SE	-64.96558879864617	33.082904790341345	109295
39129c0a15b74715a261c6c1342195d4084cf818	an empirical study on performance bugs for highly configurable software systems	empirical study;performance;configuration	Modern computer systems are highly-configurable, complicating the testing and debugging process. The sheer size of the configuration space makes the quality of software even harder to achieve. Performance is one of the key aspects of non-functional qualities, where performance bugs can cause significant performance degradation and lead to poor user experience. However, performance bugs are difficult to expose, primarily because detecting them requires specific inputs, as well as a specific execution environment (e.g., configurations). While researchers have developed techniques to analyze, quantify, detect, and fix performance bugs, we conjecture that many of these techniques may not be effective in highly-configurable systems. In this paper, we study the challenges that configurability creates for handling performance bugs. We study 113 real-world performance bugs, randomly sampled from three highly-configurable open-source projects: Apache, MySQL and Firefox. The findings of this study provide a set of lessons learned and guidance to aid practitioners and researchers to better handle performance bugs in highly-configurable software systems.	computer;debugging;elegant degradation;firefox;mysql;open-source software;randomness;sensor;software bug;software system;user experience	Xue Han;Tingting Yu	2016		10.1145/2961111.2962602	real-time computing;simulation;bebugging;performance;systems engineering;engineering;configuration;empirical research;debugging	SE	-63.90866455166193	33.40434921065808	111629
1b0f815d8288e7bf422f6aa57c58aeaa2cc25201	(un)reliability budgets: finding balance between innovation and reliability		Mountain View office for over a decade. He has worked on a variety of projects, where he authored a number of open-source software packages. roth@google.com G oogle is constantly changing our software to implement new, useful features for our users. Unfortunately, making changes is inherently risky. Google services are quite complex, and any new feature might accidentally cause problems for users. In fact, most outages of Google services are the result of deploying a change. As a consequence, there is an inherent tension between the desire to innovate quickly and to keep the site reliable. Google manages this tension by using a metrics-based approach called an unreliability budget, which provides an objective metric to guide decisions involving tradeoffs between innovation and reliability. Structural Tension The tension between innovation and change is reflected most strongly in the relationship between the SRE team and the corresponding Product Development team for any given application. This is partly due to the inherent conflict between the two teams' goals. Product Development's performance is largely evaluated based on product velocity, so they have incentive to get new code out as quickly as possible. However, SRE's performance is evaluated based on how reliable the service is, which means they are generally motivated to push back against a high rate of change. In addition, there is information asymmetry between the two teams. The product developers have more visibility into the time and effort involved in writing and releasing their code, while the SREs have more visibility into the service's reliability. This inherent structural tension between Product Development and SRE manifests itself in disagreements in a number of areas where it is important to find the right balance between innovation and change. Here are some of the areas: Software Fault Tolerance. When writing software, it's important to anticipate the possible failure modes and ensure that the software will handle them. However, there are an almost infinite number of ways in which software can fail, and product developers do not have an infinite amount of time to address those cases. Spending too little time on this results in brittle software, thus increasing outages; spending too much time on this means that it takes longer to finish the software, thus decreasing innovation. What is the right balance? Testing. Too little testing results in bad, unreliable software. Too much testing can delay the software from ever being released and increase ongoing code …		Mark D. Roth	2015	;login:			SE	-66.3600055281059	33.42309710715213	112254
a507838172eec4d3ce266c15c93d11b02e5d50dc	getting more from requirements traceability: requirements testing progress	software metrics;software;progress related metrics;reverse engineering requirements traceability requirements testing progress test monitoring requirements coverage automated analysis;testing measurement context lattices software vectors monitoring;measurement;lattices;requirements coverage;software development requirements traceability requirements testing progress progress related metrics modified condition decision coverage source code level reverse engineer;source code level;requirements testing progress;testing;software engineering;program testing;vectors;monitoring;software metrics program testing reverse engineering software engineering;software development;reverse engineer;test monitoring;requirements traceability;context;reverse engineering;modified condition decision coverage;automated analysis	Requirements Engineering (RE) and Testing are important steps in many software development processes. It is critical to monitor the progress of the testing phase to allocate resources (person-power, time, computational resources) properly, and to make sure the prioritization of requirements are reflected during testing, i.e. more critical requirements are given higher priority and tested well. In this paper, we propose a new metric to help stakeholders monitor the progress of the testing phase from a requirements perspective, i.e. which requirements are tested adequately, and which ones insufficiently. Unlike existing progress related metrics, such as code coverage and MC/DC (modified condition/decision) coverage, this metric is on the requirements level, not source code level. We propose to automatically reverse engineer this metric from the existing test cases of a system. We also propose a method to evaluate this metric, and report the results of three case studies. On these case studies, our technique obtains results within 75.23% - 91.11% of the baseline on average.	baseline (configuration management);code coverage;computation;computational resource;requirement;requirements engineering;requirements traceability;reverse engineering;software development process;test case;test suite	Celal Ziftci;Ingolf Krüger	2013	2013 7th International Workshop on Traceability in Emerging Forms of Software Engineering (TEFSE)	10.1109/TEFSE.2013.6620148	reliability engineering;software requirements specification;requirements management;requirement prioritization;white-box testing;business requirements;systems engineering;engineering;software engineering;non-functional testing;system testing;requirements traceability	SE	-63.49984277752435	32.43861851307847	113115
3ecf22100603e0e778fe7e27f1311fb9b82cf9cc	a cyber attack modeling and impact assessment framework	graph theory;computer network security;camiac architecture malefactor behavior representation security metrics risk analysis procedures near real time mode event analysis prognosis mechanisms security assessment attack graph generation security evaluation cyber attack modeling and impact assessment component architecture;risk analysis;risk analysis computer network security graph theory;security computational modeling measurement real time systems analytical models algorithm design and analysis prototypes;anytime algorithms attack modeling attack graphs security metrics impact assessment	The paper suggests a framework for cyber attack modeling and impact assessment. It is supposed that the common approach to attack modeling and impact assessment is based on representing malefactors' behavior, generating attack graphs, calculating security metrics and providing risk analysis procedures. The main aspects outlined are achieving near-real time mode, event analysis and prognosis mechanisms, security and impact assessment. To optimize the attack graph generation and security evaluation we apply an anytime approach to have the result at any time by applying a set of algorithms with different timelines and precision. The architecture of the Cyber Attack Modeling and Impact Assessment Component (CAMIAC) is proposed. We present the prototype of the component, the results of experiments carried out, and comparative analysis of the techniques used.	academy;anytime algorithm;experiment;it risk management;knowledge level;online and offline;prototype;qualitative comparative analysis;real-time clock;real-time computing;software deployment;timeline	Igor V. Kotenko;Andrey Chechulin	2013	2013 5th International Conference on Cyber Conflict (CYCON 2013)		computer security model;reliability engineering;computer science;data mining;computer security	SE	-63.408479267023786	60.31026937328086	114517
4975cd3eb5a75e31a1d22848f8ec2699d4b2df04	nearest neighbor sampling for cross company defect predictors: abstract only	nearest neighbor;defect lifecycle;product development	Several research in defect prediction focus on building models with available local data (i.e. within company predictors). To employ these models, a company should have a data repository, where project metrics and defect information from past projects are stored. However, few companies apply this practice. In a recent work, we have shown that cross company data can be used for building predictors with the cost of increased false alarms. Thus, we argued that the practical application of cross-company predictors is limited to mission critical projects and companies should starve for local data. In this paper, we show that nearest neighbor (NN) sampling of cross-company data removes the increased false alarm rates. We conclude that cross company defect predictors can be practical tools with NN sampling, yet local predictors are still the best and companies should keep starving for local data.	mission critical;research data archiving;sampling (signal processing);software bug	Burak Turhan;Ayse Basar Bener;Tim Menzies	2008		10.1145/1390817.1390824	engineering;data science;machine learning;data mining	SE	-65.08643413214438	32.49784986946018	114988
cafca50a8ec2320d66b37ef0cf9349872ead61e4	the problem of conceptualization in god class detection: agreement, strategies and decision drivers	information systems applications incl internet;software engineering programming and operating systems;programming languages compilers interpreters;software engineering;computer science general	The concept of code smells is widespread in Software Engineering. Despite the empirical studies addressing the topic, the set of context-dependent issues that impacts the human perception of what is a code smell has not been studied in depth. We call this the code smell conceptualization problem. To discuss the problem, empirical studies are necessary. In this work, we focused on conceptualization of god class. God class is a code smell characterized by classes that tend to centralize the intelligence of the system. It is one of the most studied smells in software engineering literature. A controlled experiment that extends and builds upon a previous empirical study about how humans detect god classes, their decision drivers, and agreement rate. Our study delves into research questions of the previous study, adding visualization to the smell detection process, and analyzing strategies of detection. Our findings show that agreement among participants is low, which corroborates previous studies. We show that this is mainly related to agreeing on what a god class is and which thresholds should be adopted, and not related to comprehension of the programs. The use of visualization did not improve the agreement among the participants. However, it did affect the choice of detection drivers. This study contributes to expand empirical evidences on the impact of human perception on detecting code smells. It shows that studies about the human role in smell detection are relevant and they should consider the conceptualization problem of code smells.	centralisation;code smell;conceptualization (information science);context-sensitive language;god object;sensor;software engineering	José Amancio M. Santos;Manoel G. Mendonça;Cleber Pereira dos Santos;Renato Lima Novais	2014	Journal of Software Engineering Research and Development	10.1186/s40411-014-0011-9	engineering;software development;software engineering;code smell	SE	-64.66753135912407	35.634323128576895	116586
3094c7e4a33a623e35637bc4416a9dc7b4560276	a comprehensive study of the predictive accuracy of dynamic change-impact analysis	impact analysis;accuracy study;impact prediction	The correctness of software is affected by its constant changes. For that reason, developers use change-impact analysis to identify early the potential consequences of changing their software. Dynamic impact analysis is a practical technique that identifies potential impacts of changes for representative executions. However, it is unknown how reliable its results are because their accuracy has not been studied. This paper presents the first comprehensive study of the predictive accuracy of dynamic impact analysis in two complementary ways. First, we use massive numbers of random changes across numerous Java applications to cover all possible change locations. Then, we study more than 100 changes from software repositories, which are representative of developer practices. Our experimental approach uses sensitivity analysis and execution differencing to systematically measure the precision and recall of dynamic impact analysis with respect to the actual impacts observed for these changes. Our results for both types of changes show that the most cost-effective dynamic impact analysis known is surprisingly inaccurate with an average precision of 38-50% and average recall of 50-56% in most cases. This comprehensive study offers insights on the effectiveness of existing dynamic impact analyses and motivates the future development of more accurate impact analyses.	autoregressive integrated moving average;correctness (computer science);information retrieval;java;precision and recall;software repository	Haipeng Cai;Raúl A. Santelices	2015	Journal of Systems and Software	10.1016/j.jss.2015.02.018	reliability engineering;simulation;computer science;data mining;accuracy paradox	SE	-63.66081210712605	35.460804105605625	117892
5e9b05a29f7421d76338185f9450cc7e48493861	a look at the dynamics of the javascript package ecosystem	measurement;metadata;testing;data mining;ecosystems;node js;javascript;software ecosystem analysis;software packages	The node package manager (npm) serves as the frontend to a large repository of JavaScript-based software packages, which foster the development of currently huge amounts of server-side Node. js and client-side JavaScript applications. In a span of 6 years since its inception, npm has grown to become one of the largest software ecosystems, hosting more than 230, 000 packages, with hundreds of millions of package installations every week. In this paper, we examine the npm ecosystem from two complementary perspectives: 1) we look at package descriptions, the dependencies among them, and download metrics, and 2) we look at the use of npm packages in publicly available applications hosted on GitHub. In both perspectives, we consider historical data, providing us with a unique view on the evolution of the ecosystem. We present analyses that provide insights into the ecosystem's growth and activity, into conflicting measures of package popularity, and into the adoption of package versions over time. These insights help understand the evolution of npm, design better package recommendation engines, and can help developers understand how their packages are being used.	client-side;download;javascript;package manager;server (computing);server-side	Erik Wittern;Philippe Suter;Shriram Rajagopalan	2016	2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR)	10.1145/2901739.2901743	ecosystem;computer science;package development process;operating system;software engineering;data mining;database;software testing;javascript;metadata;world wide web;measurement	SE	-66.60355631840281	35.865151736618486	118045
5fbc8a814de570193d29797b15c7cc8a6071b584	an event correlation based approach to predictive maintenance		Predictive maintenance aims at enabling proactive scheduling of maintenance, and thus prevent unexpected equipment failures. Most approaches focus on predicting failures occurring within individual sensors. However, a failure is not always isolated. It probably formed by propagation of trivial anomalies, which are widely regarded as events, among sensors and devices. In this paper, we propose an event correlation discovery algorithm to capture correlations among anomalies/failures. Such correlations can show us lots of clues to the propagation paths. We also extend our previous service hyperlink model to encapsulate such correlations and propose a service-based predictive maintenance approach. Moreover, we have made extensive experiments to verify the effectiveness of our approach.	event correlation	Meiling Zhu;Chen Chung Liu;Yanbo Han	2018		10.1007/978-3-319-96893-3_18	predictive maintenance;artificial intelligence;computer science;machine learning;event correlation;hyperlink;scheduling (computing)	AI	-63.395460060967686	42.10887560554355	120924
f26dacd9aea3633a96b2d5333c8fc5722de68245	database exploration and bellman		Large industrial-scale databases tend to be poorly structu red, dirty, and very confusing. There are many reasons for this disorder, not the least of which is that e application domains themselves are poorly structured, dirty and confusing. As data analysts, w e are often called upon to mine, clean, or otherwise analyze these databases. In this article, we describ e the types of problems we have encountered, tools and techniques we have developed to address these prob l ms, and directions for future work.	application domain;clean;database;digital revolution;dirty bit;reverse engineering;software engineer;structure mining	Theodore Johnson;Amit Marathe;Tamraparni Dasu	2003	IEEE Data Eng. Bull.		data science;data mining;database;computer science	DB	-68.57041451397023	33.740343952706056	120951
52a0cf3062f72e3e02aea68172807ad6c364bad9	privacy in statistical databases	computer communication networks;data encryption;database management;data structure;information theory;data security	For decades, NSOs have used complementary cell suppression for disclosure limitation of tabular data, magnitude data in particular. Indications of its continued use abound, even though suppression thwarts statistical analysis of both the expert and the novice. We introduce methods for creating alternative tables that the NSO can release unsuppressed, while ensuring within statistical certainty that their analysis is conformal with analysis of the original.	database;table (information);zero suppression	Josep Domingo-Ferrer	2014		10.1007/978-3-319-11257-2	data modeling;privacy software;database theory;semi-structured data;h.235;client-side encryption;data model;computer science;probabilistic database;information security;data administration;database model;data mining;database;data security;internet privacy;database testing;database design	DB	-64.3127980779425	53.57567287859514	121094
ad1a364fd7e0c76e8fee73cf3468200bd9df3ada	riskindroid: machine learning-based risk analysis on android		Risk analysis on Android is aimed at providing metrics to users for evaluating the trustworthiness of the apps they are going to install. Most of current proposals calculate a risk value according to the permissions required by the app through probabilistic functions that often provide unreliable risk values. To overcome such limitations, this paper presents RiskInDroid, a tool for risk analysis of Android apps based on machine learning techniques. Extensive empirical assessments carried out on more than 112 K apps and 6 K malware samples indicate that RiskInDroid outperforms probabilistic methods in terms of precision and reliability.	android;machine learning	Alessio Merlo;Gabriel Claudiu Georgiu	2017		10.1007/978-3-319-58469-0_36	computer science;trustworthiness;android (operating system);probabilistic logic;probabilistic method;malware;machine learning;artificial intelligence;risk analysis (business)	Security	-64.2756502904584	59.40364998074817	121231
9644efa993e49db7cb699f9e8bdb330020ebbb1b	positive test bias in software testing among professionals: a review	software testing;human computer interaction;software engineering;software specification	"""Abst rac t . Fundamental but virtually unexplored issues in human-computer interaction involve the roles of biases in software engineering tasks. In studies of naturalistic testing tasks, as well as ones which follow common laboratory models in this area, we have found ample evidence that testers have positive test bias. This bias is manifest as a tendency to execute about four times as many positive tests, designed to show that """"the program works,"""" as tests which challenge the program. In our prior work, we have found that the expertise of the subjects, the completeness of the software specifications, and the presence/absence of program errors may reduce positive test bias. Skilled computer scientists invent specifications to test in the absence of actual specifications, but still exhibit positive test bias."""	computer scientist;human–computer interaction;software engineering;software testing;test case	Laura M. Leventhal;Barbee Teasley;Diane S. Rohlman;Keith Instone	1993		10.1007/3-540-57433-6_50	personal software process;medical software;software requirements specification;verification and validation;regression testing;system integration testing;software verification;computer science;acceptance testing;package development process;social software engineering;software reliability testing;software development;software construction;software testing;software walkthrough;software deployment;software quality;software system;software peer review	SE	-65.29385057464985	32.3252987065769	121540
ec7d80105342cfb050b775f2411e88f253db63de	the value of architecturally significant information extracted from patterns for architecture evaluation: a controlled experiment	architectural design;control group;data mining computer architecture application specific processors software architecture software quality australia performance analysis programming concrete documentation;information extraction;software performance evaluation;controlled experiment;data mining;software engineering;computer architecture;software architecture;undergraduate student;software quality software architecture software performance evaluation;architecture evaluation;performance analysis;software architecture design software architecture evaluation architecturally significant information from pattern asip information;application specific processors;software architecture evaluation;software architecture design;asip information;architecturally significant information from pattern;programming;software quality;documentation;australia;concrete	We have developed an approach to identify and capture architecturally significant information from patterns (ASIP), which can be used to improve architecture design and evaluation. Our experimental goal was to evaluate whether the use of the ASIP improves the quality of scenarios developed to evaluate software architecture. Out of 24 subjects 21 were experienced software engineers who had returned to University for a postgraduate studies and remaining 3 were fourth year undergraduate students. All participants were taking a course in software architecture. The participants were randomly assigned to two groups of equal size. Both groups developed scenarios for architecture evaluation. One group (treatment group) was given ASIP information the other (control group) was not. The outcome variable was the quality of the scenarios produced by each participant working individually. The treatment group participants also completed a post-experiment questionnaire. Our results support the hypothesis that ASIP information assists scenario development in the context of architecture evaluation.	application-specific instruction set processor;australian software engineering conference;experiment;list of system quality attributes;randomness;software architecture;software documentation;software engineer;the australian;wang tile	Muhammad Ali Babar;Barbara A. Kitchenham;Piyush Maheshwari	2006	Australian Software Engineering Conference (ASWEC'06)	10.1109/ASWEC.2006.52	software architecture;computer science;systems engineering;engineering;software engineering;programming language;information extraction;computer engineering	SE	-68.12987680235548	32.790507843761475	121625
22275c83381cebb3b3ba65c69cca410200aa34ce	a historical dataset for the gnome ecosystem	data mining;public domain software;software development management;source coding;gnome ecosystem;gnome projects;historical datasets;open source software ecosystem;source code analysis;source code mining;source code related information	We present a dataset of the open source software ecosystem Gnome from a social point of view. We have collected historical data about the contributors to all Gnome projects stored on git.gnome.org, taking into account the problem of identity matching, and associating different activity types to the contributors. This type of information is very useful to complement the traditional, source-code related information one can obtain by mining and analyzing the actual source code. The dataset can be obtained at https://bitbucket.org/mgoeminne/sgl-flossmetric-dbmerge.	activity recognition;bitbucket;database schema;gnome;open-source software;software ecosystem	Mathieu Goeminne;Maëlick Claes;Tom Mens	2013	2013 10th Working Conference on Mining Software Repositories (MSR)		kpi-driven code analysis;computer science;data mining;database;public domain software;world wide web;source code	SE	-66.63664115308978	36.09581645979188	122217
0f715fb1448c82313a131d7b0669bf58bbc48ecf	object driven performance testing in web applications	programming environments software performance evaluation computational complexity information resources program testing;information resources;programming environments;normal conducting;performance test;complexity object driven performance testing web applications web sites simulated environment performance parameters;software performance evaluation;life testing stress application software software testing system testing consumer electronics cities and towns electronic commerce time to market acoustic testing;program testing;computational complexity;simulation environment	Performance of many Web sites depends on the load on the site at peak time under varying conditions. Performance testing is normally conducted in reasonably simulated environment with the help of performance testing tools. However, performance of a Web site depends on various parameters and each parameter must be tested under varying stress levels. It is not possible to draw a common denominator for performance parameters to test the Web site due to complexity of Web sites. Different parts of the Web site must be tested with different parameters under varying condition and stress level. In such circumstances, it is necessary to decompose the Web site into many components, which represents the behavior of various business components. These business components are mapped to various objects that truly represent the behavior and structure of the part of the web site. These objects are subjected to performance testing with different parameters and stress levels. This paper addresses the new testing process, which uses the concept of decomposing the behavior of the Web site into testable components, which are mapped onto testable objects. These testable objects are subjected to performance testing under varied performance parameters and stress levels.	web application	B. M. Subraya;S. V. Subrahmanya	2000		10.1109/APAQ.2000.883774	test strategy;black-box testing;web modeling;real-time computing;simulation;orthogonal array testing;software performance testing;performance engineering;white-box testing;system integration testing;systems engineering;engineering;software reliability testing;cloud testing;software testing;non-functional testing;system testing;stress testing	SE	-65.35147968509924	39.9672872748529	122234
27f9dc04606f67dbe9ded691806bd092a01d059e	high-mcc functions in the linux kernel	linux kernel;software complexity;code regularity;perceived complexity;mccabe cyclomatic complexity	McCabe’s Cyclomatic Complexity (MCC) is a widely used metric for the complexity of control flow. Common usage decrees that functions should not have an MCC above 50, and preferably much less. However, the Linux kernel includes more than 800 functions with MCC values above 50, and over the years 369 functions have had an MCC of 100 or more. Moreover, some of these functions undergo extensive evolution, indicating that developers are successful in coping with the supposed high complexity. Functions with similarly high MCC values also occur in other operating systems and domains, including Windows. For example, the highest MCC value in FreeBSD is 1316, double the highest MCC in Linux. We attempt to explain all this by analyzing the structure of high-MCC functions in Linux and showing that in many cases they are in fact well-structured (albeit we observe some cases where developers indeed refactor the code in order to reduce complexity). Moreover, human opinions do not correlate with the MCC values of these functions. A survey of perceived complexity shows that there are cases where high MCC functions were ranked as having a low complexity. We characterize these cases and identify specific code attributes such as the diversity of constructs (not only a switch but also ifs) and nesting that correlate with discrete increases in perceived complexity. These observations indicate that a high MCC is not necessarily an impediment to code comprehension, and support the notion that complexity cannot be fully captured using simple syntactic code metrics. In particular, we show that regularity in the code (meaning repetitions of the same pattern of control structures) correlates with low perceived complexity.	code refactoring;control flow;cyclomatic complexity;freebsd;linux;microsoft windows;operating system;software metric	Ahmad Jbara;Adam Matan;Dror G. Feitelson	2012	2012 20th IEEE International Conference on Program Comprehension (ICPC)	10.1007/s10664-013-9275-7	real-time computing;computer science;engineering;theoretical computer science;software engineering;mathematics;cyclomatic complexity;linux kernel;algorithm;programming complexity	SE	-63.73715760887522	34.92805452853024	122368
4195bb866103d8cfb2e580ff9ec4813a52278da7	software aging analysis of the android mobile os	software;degradation;androids;measurement;aging;humanoid robots;computer bugs	Mobile devices are significantly complex, feature-rich, and heavily customized, thus they are prone to software reliability and performance issues. This paper considers the problem of software aging in Android mobile OS, which causes the device to gradually degrade in responsiveness, and to eventually fail. We present a methodology to identify factors (such as workloads and device configurations) and resource utilization metrics that are correlated with software aging. Moreover, we performed an empirical analysis of recent Android devices, finding that software aging actually affects them. The analysis pointed out processes and components of the Android OS affected by software aging, and metrics useful as indicators of software aging to schedule software rejuvenation actions.	android;mobile operating system;responsiveness;software aging;software feature;software rejuvenation;software reliability testing	Domenico Cotroneo;Francesco Fucci;Antonio Ken Iannillo;Roberto Natella;Roberto Pietrantuono	2016	2016 IEEE 27th International Symposium on Software Reliability Engineering (ISSRE)	10.1109/ISSRE.2016.25	reliability engineering;embedded system;real-time computing;simulation;software bug;degradation;computer science;engineering;humanoid robot;software reliability testing;operating system;software aging;measurement	SE	-65.28163793446508	38.01516354179771	122521
3853552ead24e0974e9c1a599fb69ed8562acf72	evaluation of accuracy in design pattern occurrence detection	software metrics;benchmark suite design pattern occurrence detection software engineering problem fine grained metric;measurement techniques;object oriented methods;object oriented design;application software;software performance evaluation;software systems;natural languages;software engineering;fine grained metric;datorlingvistik;benchmark suite;evaluation measure;software engineering problem;restructuring;design pattern;datavetenskap datalogi;datavetenskap;evaluation;software tools;patterns;software performance evaluation object oriented methods software engineering software metrics;computational linguistics;computer science;design methodology software systems computer science natural languages software engineering measurement techniques reverse engineering software tools application software software quality;design pattern occurrence detection;object oriented design methods;reengineering;software quality;reverse engineering;design methodology;restructuring patterns object oriented design methods measurement techniques evaluation reverse engineering reengineering	Detection of design pattern occurrences is part of several solutions to software engineering problems, and high accuracy of detection is important to help solve the actual problems. The improvement in accuracy of design pattern occurrence detection requires some way of evaluating various approaches. Currently, there are several different methods used in the community to evaluate accuracy. We show that these differences may greatly influence the accuracy results, which makes it nearly impossible to compare the quality of different techniques. We propose a benchmark suite to improve the situation and a community effort to contribute to, and evolve, the benchmark suite. Also, we propose fine-grained metrics assessing the accuracy of various approaches in the benchmark suite. This allows comparing the detection techniques and helps improve the accuracy of detecting design pattern occurrences.	anti-pattern;benchmark (computing);sensor;software design pattern;software engineering	Niklas Pettersson;Welf Löwe;Joakim Nivre	2010	IEEE Transactions on Software Engineering	10.1109/TSE.2009.92	reliability engineering;application software;design methods;business process reengineering;computer science;systems engineering;evaluation;computational linguistics;object-oriented design;software engineering;restructuring;design pattern;pattern;natural language;software quality;reverse engineering;software metric;software system	SE	-63.08357946480703	34.82135966424035	124530
87cd61462d720a17141d16ec86beeed19bb764d7	identifying code smells with collaborative practices: a controlled experiment	program comprehension;software degradation;controlled experiment;collaborative practices;code smells	Code smells are often considered as key indicators of software quality degradation. If code smells are not systematically removed from a program, its continuous degradation may lead to either major maintenance effort or the complete redesign of the system. For several reasons, software developers introduce smells in their code as soon as they start to learn programming. If novice developers are ought to become either proficient programmers or skilled code reviewers, they should be early prepared to effectively identify code smells in existing programs. However, effective identification of code smells is often not a non-trivial task in particular to a novice developer working in isolation. Thus, the use of collaborative practices may have the potential to support developers in improving their effectiveness on this task at their early stages of their careers. These practices offer the opportunity for two or more developers analyzing the source code together and collaboratively reason about potential smells prevailing on it. Pair Programming (PP) and Coding Dojo Randori (CDR) are two increasingly adopted practices for improving the effectiveness of developers with limited or no knowledge in software engineering tasks, including code review tasks. However, there is no broad understanding about the impact of these collaborative practices on the effectiveness of code smell identification. This paper presents a controlled experiment involving 28 novice developers, aimed at assessing the effectiveness of collaborative practices in the identification of code smells. We compared PP and CDR with solo programming in order to better distinguish their impact on the effective identification of code smells. Our study is also the first in the literature to observe how novice developers work individually and together to identify smells. Our results suggest that collaborative practices contribute to the effectiveness on the identification of a wide range of code smells. Our findings can also be used in practice to guide educators, researchers or teams on improving detection and training on code smell identification.	arithmetic coding;code smell;elegant degradation;isolation (database systems);pair programming;programmer;software developer;software engineering;software quality;structure of observed learning outcome	Roberto Felicio Oliveira;Bernardo José da Silva Estácio;Alessandro F. Garcia;Sabrina Marczak;Rafael Prikladnicki;Marcos Kalinowski;Carlos José Pereira de Lucena	2016	2016 X Brazilian Symposium on Software Components, Architectures and Reuse (SBCARS)	10.1109/SBCARS.2016.18	simulation;systems engineering;engineering;solid;world wide web;code smell	SE	-64.67129640419616	34.03759124437793	124826
3400c9754de4b1487ceff92740216181e2599af7	wi-fi alliance: connecting everyone and everything, everywhere		Describes the formation, activities, and mission of the Wi-Fi Alliance. More than 750 member companies from across the Wi-Fi ecosystem come together in Wi-Fi Alliance with the shared vision to connect everyone and everything, everywhere, while providing the best possible Wi-Fi user experience. In 2000 Wi-Fi Alliance adopted the term “Wi-Fi” for IEEE 802.11-standards based products, and since then more than 35,000 Wi-Fi devices have earned the Wi-Fi Alliance Wi-Fi CERTIFIED™ designation, which assures buyers that the Wi-Fi devices they use provide interoperability across vendors, backward compatibility, and the highest industry-standard security protections.		Ian Sherlock	2017	IEEE Communications Standards Magazine	10.1109/MCOMSTD.2017.8082572	backward compatibility;alliance;interoperability;user experience design;business;marketing	Vision	-67.44149498450439	50.58172290197955	128202
be5e400d94e01f402616577a924ac937803b2e4d	an experimental evaluation of capture-recapture in software inspections	software metrics;software inspections;fault content estimation;experimental software engineering;software development;software metric;experimental evaluation;capture recapture;software inspection	The use of capture-recapture to estimate the residual faults in a software artifact has evolved as a promising method. However, the assumptions needed to make the estimates are not completely fulfilled in software development, leading to an underestimation of the residual fault content. Therefore, a method employing a filtering technique with an experience factor to improve the estimates of the residual faults is proposed in this paper. An experimental study of the capture-recapture method with this correction method has been conducted. It is concluded that the correction method improves the capturerecapture estimate of the number of residual defects in the inspected document.	artifact (software development);content-control software;experiment;mark and recapture;software development;software inspection	Claes Wohlin;Per Runeson;Johan Brantestam	1995	Softw. Test., Verif. Reliab.	10.1002/stvr.4370050403	reliability engineering;verification and validation;real-time computing;software sizing;software verification;computer science;systems engineering;engineering;software reliability testing;software engineering;software testing;software metric;software quality analyst	SE	-63.9625196815515	32.36341126974566	128860
336779ddf9658da01dfabb4390010df03575ed26	the execute operations-a fourth mode of instruction sequencing		Instruction S e q u e n c i n g Modes Classically, digital computers have had two basic modes of sequencing instructions. In the first, normal sequencing, each instruction has a unique successor which may be defined by an instruction counter or by a next instruction address within the insm~ction itself. The second mode is the seleetior~ of an alternate sequence by a branching, skipping, or suppression operation. A third mode of sequencing, program interruption, has been recognized more recently [1], although computers as early as UN~vxc I contained rudimentary interruption provisions. In this mode, execution of a sequenee of instructions may be interrupted at an arbitrary point, and specification of the next instruction in this case is completely independent of the last instruction executed. Provision may or may nol~ be made for saving the current location in the interrupted sequence. In branching, the selection of an alternate instrttction implies the selection of a new sequence, i.e., the alternate instruction specifies or implies (through an instruction counter) its own successor. The same may be true of interruption; or, an interruptior~ syst, em may be defined so that the interrupting instruction does not change the instruction counter. In this case the interrupting instruction , if a branch, m a y specify its own successor, but if it does not, ~,he successor is implied by the last instruction of the interrupted sequence [2]. It is often desirable for an instruction sequence ~co execute a single, noninterrupt, ing instruction which does not specify or imply its own successor. For this purpose the Execute operations have been independently developed by several groups. These may be considered a fourth mode of instruction sequencing. The four modes can be summarized briefly by stating the four possible relationships between an original sequence A and a second sequence B: Normal sequencing A keeps control Branching A gives control to B Interruption B Zakes control from A Executing A lends control to B. The address of an Execute operation specifies, directly or indirectly, an instruction to be executed. When the object instruetiot~ has been completed, the instruction next in order after the Execute instruction itself is performed. Thus, the location of the object instruction does 168 Communications of the ACM Mode of 5~J not imply the location of its successor. This is e(:ltfivaleni; to indirect addressing except ~hat the whole instruci:io~ :~ not just the address, is selected …	addressing mode;communications of the acm;computer;interrupt;interruption science;program counter;zero suppression	Frederick P. Brooks	1960	Commun. ACM	10.1145/367149.367168	bioinformatics	Arch	-68.38588289206918	45.67158854340745	129526
04e996c3da241067f04404ce176b7e3fe518d70a	an integrated system for data backup and supervision of activities (with management of the natural language) in e-learning contexts	lenguaje natural;electronic learning;architecture systeme;web learning;integrable system;langage naturel;e learning environments;online learning;alert systems;security system;supervision activities;intelligent agents;voice over internet protocol;alert system;agent intelligent;security systems;natural language;e learning;aiml;intelligent agent;arquitectura sistema;artificial intelligence markup language;agente inteligente;data loss;information system;system architecture;systeme information;voip;data backup;sistema informacion;e leaming environments;chatbot	This article describes an integrated system managed by an artificial agent (ChatBot) whose knowledge base has been realised in Artificial Intelligence Markup Languange (AIML). The system is able to constantly supervise the activities of the servers and, at the same time, realise backup distribution to safeguard the data in e-learning contexts. It also interacts with a Private Automatic Branch eXchange (PABX) for the management of the Voice over Internet Protocol (VoIP) telephone system. This system has been conceived as support for the management of web sections and, in particular, web-learning (w-learning) platforms. The purpose is to be able to watch the platform's activity all the time to immediately 'warn' when there are problems deriving from the platform contents and warn the technical area in case of failures in the server system that contains the w-learning platform. In addition, the backup system guarantees having a frequently updated file of the data present on the various servers on which the e-learning platform leans so that safety can be guaranteed in case of the permanent loss of the data present on the servers.	backup;natural language	Orlando De Pietro;Giovanni Frontera	2008	IJWGS	10.1504/IJWGS.2008.021496	simulation;computer science;artificial intelligence;operating system;voice over ip;database;distributed computing;aiml;world wide web;computer security;intelligent agent	ML	-67.14203367275138	53.939933703015434	130063
a510e02efe622b639b423b4ec4fd7de8d89a3680	network security situation awareness for industrial control system under integrity attacks		Due to the wide implementation of communication networks, industrial control systems are vulnerable to malicious attacks, which could cause potentially devastating results. Adversaries launch integrity attacks by injecting false data into systems to create fake events or cover up the plan of damaging the systems. In addition, the complexity and nonlinearity of control systems make it more difficult to detect attacks and defense it. Therefore, a novel security situation awareness framework based on particle filtering, which has good ability in estimating state for nonlinear systems, is proposed to provide an accuracy understanding of system situation. First, a system state estimation based on particle filtering is presented to estimate nodes state. Then, a voting scheme is introduced into hazard situation detection to identify the malicious nodes and a local estimator is constructed to estimate the actual system state by removing the identified malicious nodes. Finally, based on the estimated actual state, the actual measurements of the compromised nodes are predicted by using the situation prediction algorithm. At the end of this paper, a simulation of a continuous stirred tank is conducted to verify the efficiency of the proposed framework and algorithms.	algorithm;complexity;control system;malware;network security;nonlinear system;particle filter;simulation;telecommunications network	Genghong Lu;Dongqin Feng	2018	2018 21st International Conference on Information Fusion (FUSION)	10.23919/ICIF.2018.8455208	estimator;artificial intelligence;machine learning;telecommunications network;computer science;network security;industrial control system;real-time computing;particle filter;situation awareness;voting;control system	Mobile	-64.17976359625372	57.716443208947766	131183
389a54f8840fffc2a8a26763e477a0129eb0b4ac	a digital tv agent system for broadcast and web information hybrid	digital broadcasting systems;electronic program guide;dtv agent systems;information sources;web pages;broadband network;information retrieval;digital tv;internet search;web information retrieval;agent systems;communication service	The development of various digital broadcasting services and the rapid growth of broadband network infrastructure have accelerated the convergence of broadcasting and communication services. To show the potentiality of hybrid or convergence technologies, we designed and implemented a hybrid Electronic Program Guide (EPG) agent system for digital broadcasting systems, which provides comprehensive information from broadcast and web information sources. The implemented hybrid EPG agent system can provide detailed information for a specific program by combining broadcast information and web information retrieved from the scattered web pages. The methods of searching the URLs that contain the related information for a specific TV program and retrieving the related information from the selected web pages are proposed.		Sangmin Oh;Jongtae Lim	2007		10.1007/978-3-540-72830-6_25	web development;web modeling;computer science;web page;multimedia;web intelligence;world wide web;information retrieval;web server;broadband networks	ECom	-72.77023728358091	42.74129811619929	134228
8a5c48b9e81f7b9fb8c1319774a67007c6008d2e	physical health data mining of college students based on drf algorithm	drf algorithm;data mining;data scheduling	College physical education in China is facing a new reform in the context of informationization, and informatization is the focus of this reform. The physical health data mining of college students was studied in the paper from the perspective of cloud data. Firstly, the unified scheduling of students’ physique health data resources under cloud environment was analyzed. Secondly, in-depth research was conducted on the Yam system. And a new type of data mining and scheduling model Luna Scheduler was designed based on DRF algorithm. This model optimized Yam Capacity Scheduler in terms of scheduling algorithm, fine-grained resources classification, etc. Finally, the algorithm and model were tested, and the parameter configuration that could improve the throughput of Yam was given.	algorithm;data mining	Baohong Xue;Ting Liu	2018	Wireless Personal Communications	10.1007/s11277-018-5410-5	computer science;throughput;informatization;data mining;scheduling (computing);algorithm;cloud computing	HCI	-68.68641126121307	47.99475922177844	134459
aaa4764a8759c0d81be417184457bbe4ca5048fb	shorter identifier names take longer to comprehend	time measurement;semantics;psychology;syntactics;c languages;context;software quality	Developers spend the majority of their time comprehending code, a process in which identifier names play a key role. Although many identifier naming styles exist, they often lack an empirical basis and it is not quite clear whether short or long identifier names facilitate comprehension. In this paper, we investigate the effect of different identifier naming styles (letters, abbreviations, words) on program comprehension, and whether these effects arise because of their length or their semantics. We conducted an experimental study with 72 professional C# developers, who looked for defects in source-code snippets. We used a within-subjects design, such that each developer saw all three versions of identifier naming styles and we measured the time it took them to find a defect. We found that words lead to, on average, 19% faster comprehension speed compared to letters and abbreviations, but we did not find a significant difference in speed between letters and abbreviations. The results of our study suggest that defects in code are more difficult to detect when code contains only letters and abbreviations. Words as identifier names facilitate program comprehension and can help to save costs and improve software quality.	identifier	Johannes Hofmeister;Janet Siegmund;Daniel V. Holt	2017		10.1109/SANER.2017.7884623	natural language processing;identifier;computer science;programming language;world wide web	HCI	-64.25849249861812	36.75244455426968	134572
6f1631357252d6145d86b086f17a27e6e7b0eaca	how to design a program repair bot? insights from the repairnator project		"""Program repair research has made tremendous progress over the last few years, and software development bots are now being invented to help developers gain productivity. In this paper, we investigate the concept of a """"program repair bot"""" and present Repairnator. The Repairnator bot is an autonomous agent that constantly monitors test failures, reproduces bugs, and runs program repair tools against each reproduced bug. If a patch is found, Repairnator bot reports it to the developers. At the time of writing, Repairnator uses three different program repair systems and has been operating since February 2017. In total, it has studied 11 523 test failures over 1 609 open-source software projects hosted on GitHub, and has generated patches for 15 different bugs. Over months, we hit a number of hard technical challenges and had to make various design and engineering decisions. This gives us a unique experience in this area. In this paper, we reflect upon Repairnator in order to share this knowledge with the automatic program repair community."""	autonomous agent;autonomous robot;autonomous system (internet);continuous integration;failure;open-source software;optimization problem;software bug;software deployment;software development;software quality;video game bot	Simon Urli;Zhongxing Yu;Lionel Seinturier;Martin Monperrus	2017	2018 IEEE/ACM 40th International Conference on Software Engineering: Software Engineering in Practice Track (ICSE-SEIP)	10.1145/3183519.3183540		SE	-65.61331669703307	35.95543783447158	134767
10b44e6c850152dbcbfe22ee578c16565943b598	"""the ai approach to ml and enlarging the """"es certification bottleneck"""""""				Yves Kodratoff	1989			database;certification;bottleneck;computer science	Logic	-72.86824990994323	34.09447083902425	134990
3635141c7e3ed8190de4d799d06a71b027c32975	failure prediction based on log files using random indexing and support vector machines	log files;support vector machine svm;random indexing;event sequence data;failure prediction	Research problem: The impact of failures on software systems can be substantial since the recovery process can require unexpected amounts of time and resources. Accurate failure predictions can help in mitigating the impact of failures. Resources, applications, and services can be scheduled to limit the impact of failures. However, providing accurate predictions sufficiently ahead is challenging. Log files contain messages that represent a change of system state. A sequence or a pattern of messages may be used to predict failures. Contribution: We describe an approach to predict failures based on log files using Random Indexing (RI) and Support Vector Machines (SVMs). Method: RI is applied to represent sequences: each operation is characterized in terms of its context. upport Vector Machine (SVM) vent sequence data og files SVMs associate sequences to a class of failures or non-failures. Weighted SVMs are applied to deal with imbalanced datasets and to improve the true positive rate. We apply our approach to log files collected during approximately three months of work in a large European manufacturing company. Results: According to our results, weighted SVMs sacrifice some specificity to improve sensitivity. Specificity remains higher than 0.80 in four out of six analyzed applications. Conclusions: Overall, our approach is very reliable in predicting both failures and non-failures.	data logger;mega man zx;random indexing;sensitivity and specificity;software system;support vector machine	Ilenia Fronza;Alberto Sillitti;Giancarlo Succi;Mikko Terho;Jelena Vlasenko	2013	Journal of Systems and Software	10.1016/j.jss.2012.06.025	computer science;machine learning;pattern recognition;data mining	HPC	-63.770429617860664	39.749818444489364	136480
25d1ca4e5b2746a2bab97145df75ca757b8cf137	an exploratory study of the evolution of software licensing	empirical study;mining software repositories;software licenses;software maintenance;software licenses empirical study evolution mining software repositories open source systems;open source systems;software engineering software licensing evolution free and open source software systems foss software maintenance;code reuse;system integration;licenses java law kernel monos devices;exploratory study;free and open source software;open source;evolution	Free and open source software systems (FOSS) are distributed and made available to users under different software licenses, mentioned in FOSS code by means of licensing statements. Various factors, such as changes in the legal landscape, commercial code licensed as FOSS, or code reused from other FOSS systems, lead to evolution of licensing, which may affect the way a system or part thereof can be subsequently used. Therefore, it is crucial to monitor licensing evolution. However, manually tracking the licensing evolution of thousands of files is a daunting task.  After presenting several cases of the effects of licensing evolution, we propose an approach to automatically track changes occurring in the licensing terms of a system. Then, we report an empirical study of the licensing evolution of six different FOSS systems. Results show that licensing underwent frequent and substantial changes.	commercial code (communications);evolution;open-source software;software license;software system	Massimiliano Di Penta;Daniel M. Germán;Yann-Gaël Guéhéneuc;Giuliano Antoniol	2010	2010 ACM/IEEE 32nd International Conference on Software Engineering	10.1145/1806799.1806824	verification and validation;engineering;package development process;backporting;social software engineering;software framework;software development;software engineering;software construction;software as a service;evolution;database;software walkthrough;software analytics;software maintenance;software deployment;world wide web;software system;system integration;software peer review	SE	-63.41245297304077	36.4855842280462	138362
8164a03cb8165c2692327e75d28ba839936f77ca	correctness is not enough	human computer interaction;software engineering	The usual aim of spreadsheet audit is to verify correctness. There are two problems with this: first, it is often difficult to tell whether the spreadsheets in question are correct, and second, even if they are, they may still give the wrong results. These problems are explained in this paper, which presents the key criteria for judging a spreadsheet and discusses how those criteria can be achieved	correctness (computer science);failure;process (computing);regular expression;software quality;spreadsheet;usability	Louise Pryor	2008	CoRR		computer science;software engineering;data mining;programming language	PL	-69.05519082351185	32.7113149924601	139705
358e93a9be458e0714ffc41cf82d01109d1258b5	llr-based sentiment analysis for kernel event sequences	kernel;data mining;monitoring;malware;dictionaries;context	Behavior-based analysis of dynamically executed binaries has become a widely used technique for the identification of suspected malware. Most solutions rely on function call patterns to determine whether a sample is exhibiting malicious behavior. These system and API calls are usually regarded individually and do not consider contextual information or process inter-dependencies. In addition, the patterns are often fixed in nature and do not adapt to changing circumstances on the system environment level. To address these shortcomings, this paper proposes a sentiment extraction and scoring system capable of learning the maliciousness inherent to n-grams of kernel events captured by a real-time monitoring agent. The approach is based on calculating the log likelihood ratio (LLR) of all identified n-grams, effectively determining neighboring sequences as well as assessing whether certain event combinations incline towards the benign or malicious. The extraction component automatically compiles a WordNet-like sentiment dictionary of events, which is subsequently used to score unknown traces of either individual processes, or a session in its entirety. The system was evaluated using a large set of real-world event traces collected on live corporate workstations as well as raw API call traces created in a dedicated malware analysis environment. While applicable to both scenarios, the introduced solution performed best for our abstracted kernel events, generating both new insight into malware–system interaction and assisting with the scoring of hitherto unknown application behavior.	anomaly detection;application programming interface;bigram;binary file;data dictionary;environment variable;grams;information extraction;kernel (operating system);lucas–lehmer–riesel test;malware analysis;n-gram;natural language;operating system;real-time clock;sentence extraction;sentiment analysis;tracing (software);vii;wordnet;workstation	Robert Luh;Sebastian Schrittwieser;Stefan Marschalek	2017	2017 IEEE 31st International Conference on Advanced Information Networking and Applications (AINA)	10.1109/AINA.2017.47	kernel;computer science;operating system;data mining;database;malware;world wide web;computer security;statistics	SE	-63.081063998163984	58.75349894649468	140534
5acc3ac163c078a5fdb6fe12949865f6256dc5fc	the effect of poor source code lexicon and readability on developers' cognitive load		It has been well documented that a large portion of the cost of any software lies in the time spent by developers in understanding a programu0027s source code before any changes can be undertaken. One of the main contributors to software comprehension, by subsequent developers or by the authors themselves, has to do with the quality of the lexicon, (i.e., the identifiers and comments) that is used by developers to embed domain concepts and to communicate with their teammates. In fact, previous research shows that there is a positive correlation between the quality of identifiers and the quality of a software project. Results suggest that poor quality lexicon impairs program comprehension and consequently increases the effort that developers must spend to maintain the software. However, we do not yet know or have any empirical evidence, of the relationship between the quality of the lexicon and the cognitive load that developers experience when trying to understand a piece of software. Given the associated costs, there is a critical need to empirically characterize the impact of the quality of the lexicon on developersu0027 ability to comprehend a program. In this study, we explore the effect of poor source code lexicon and readability on developersu0027 cognitive load as measured by a cutting-edge and minimally invasive functional brain imaging technique called functional Near Infrared Spectroscopy (fNIRS). Additionally, while developers perform software comprehension tasks, we map cognitive load data to source code identifiers using an eye tracking device. Our results show that the presence of linguistic antipatterns in source code significantly increases the developersu0027 cognitive load.	anti-pattern;eye tracking;identifier;lexicon;open-source software;program comprehension;refactoring software, architectures, and projects in crisis;software project management;tracking system	Sarah Fakhoury;Yuzhan Ma;Venera Arnaoudova;Olusola O. Adesope	2018		10.1145/3196321.3196347	readability;data mining;computer science;identifier;lexicon;comprehension;software;human–computer interaction;program comprehension;cognitive load;source code	SE	-66.47358863578205	32.961408967800736	140570
3e892eb3cd3ab2cefc7f22e8db3f4002c26f7b18	how difficult are novice code writing tasks? a software metrics approach	software metrics;assessment	In this paper we report on an empirical study into the use of software metrics as a way of estimating the difficulty of code writing tasks. Our results indicate that software metrics can provide useful information about the difficulties inherent in code writing in first year programming assessment. We conclude that software metrics may be a useful tool to assist in the design and selection of questions when setting an examination.	software metric	Jacqueline L. Whalley;Nadia Kasto	2014				SE	-65.51817848781586	32.843613273912474	141345
6741753c4d816907d247fa56de0a88d4caad4050	in this issue		I would like to wish all readers a very happy and successful 2015. This issue includes three regular papers and a special section. The regular papers deal with a range of topics related to software quality such as software validation, security, and software reliability growth models. Software validation is tremendously important and is an essential part of the software development industry. The paper ‘‘Automating test-based inspection of design models,’’ by Anne Rocha, Franklin Ramalho, and Patricia Machado presents an automated guided inspection technique that can reduce the gap between input and output models and help to validate test cases. The technique takes as input natural language test cases and transforms these using a UML tool into executable test cases. The technique uses the sequence diagrams of the test cases to find divergences from the test cases. The authors use three case studies to show that the technique uncovers approximately twice as many defects as other manual techniques. The second of our regular papers deals with the development of secure software. In ‘‘Security quality model: an extension of Dromey’s model,’’ Saad Zafar, Misbah Mehboob, Asma Naveed, and Bushra Malik propose a quality model for security which can be used to identify security defects. The authors propose an automation of the security quality model using a central repository which could be used for audit purposes. In ‘‘A method for predicting open source software residual defects,’’ Najeeb Ullah proposes a method to help select the best software reliability growth model for predicting the reliability of an open-source component. The technique was validated empirically using 21 releases of seven open-source software projects. It was found that no particular software reliability growth model consistently outperformed any of the others. The special section includes extended papers on Software Quality and Maintainability. The guest editors, Yijun Yu and Yiannis Kanellopoulos, have worked hard to bring this	executable;franklin electronic publishers;input/output;malware;natural language;open-source software;population dynamics;sequence diagram;software development;software quality;software verification and validation;test case;uml tool;unified modeling language;yousef saad	Rachel Harrison	2015	Software Quality Journal	10.1007/s11219-015-9269-3		SE	-64.13765251437489	37.786077105591616	141477
718ff3f7083750e64892538b1a719937eaffd3c3	understanding customer problem troubleshooting from storage system logs	case report;storage system;log analysis	Customer problem troubleshooting has been a critically important issue for both customers and system providers. This paper makes two major contributions to better understand this topic. First, it provides one of the first characteristic studies of customer problem troubleshooting using a large set (636,108) of real world customer cases reported from 100,000 commercially deployed storage systems in the last two years. We study the characteristics of customer problem troubleshooting from various dimensions as well as correlation among them. Our results show that while some failures are either benign, or resolved automatically, many others can take hours or days of manual diagnosis to fix. For modern storage systems, hardware failures and misconfigurations dominate customer cases, but software failures take longer time to resolve. Interestingly, a relatively significant percentage of cases are because customers lack sufficient knowledge about the system. We observe that customer problems with attached system logs are invariably resolved much faster than those without logs. Second, we evaluate the potential of using storage system logs to resolve these problems. Our analysis shows that a failure message alone is a poor indicator of root cause, and that combining failure messages with multiple log events can improve low-level root cause prediction by a factor of three. We then discuss the challenges in log analysis and possible solutions.	computer data storage;high- and low-level;log analysis	Weihang Jiang;Chongfeng Hu;Shankar Pasupathy;Arkady Kanevsky;Zhenmin Li;Yuanyuan Zhou	2009			simulation;computer science;operating system;troubleshooting;computer data storage;data mining;database	OS	-63.76609007081814	40.29654126686707	142145
6c1c25aa2b86f6a65f62e4a677849254e99fe375	is structural subtyping useful? an empirical study	empirical study;object oriented language;java programming;indicators;object oriented programming;classification;computer programs;java programming language;scientific research;language design;structural properties;open source;automation	Structural subtyping is popular in research languages, but all mainstream object-oriented languages use nominal subtyping. Since languages with structural subtyping are not in widespread use, the empirical questions of whether and how structural subtyping is useful have thus far remained unanswered. This study aims to provide answers to these questions. We identified several criteria that are indicators that nominally typed programs could benefit from structural subtyping, and performed automated and manual analyses of open-source Java programs based on these criteria. Our results suggest that these programs could indeed be improved with the addition of structural subtyping. We hope this study will provide guidance for language designers who are considering use of this subtyping discipline.	ibm notes;information systems;java;nominal type system;open-source software;programmer;programming language;structural type system	Donna Malayeri;Jonathan Aldrich	2009		10.1007/978-3-642-00590-9_8	object-based language;computer science;database;programming language;object-oriented programming;algorithm	SE	-65.04061535389609	36.8640038000991	142334
019ca699dbe2e9fed80044fd0e9949e9e31ebb04	the art of enbugging	separation of concern;preventing bugs enbugging separation of concerns semantics shy code oo code;object oriented programming;object oriented;subspace constraints tv switches programming profession logic encapsulation computer bugs layout testing java;object oriented programming program debugging;program debugging	"""software construction M any books and articles discuss debug-ging techniques: how to track down and correct the errors that, like sneaky little bugs, crept into our programs when we weren't watching. Referring to errors as """" bugs """" is a pleasant anthropomorphic distraction that lets a programmer avoid direct blame, but it does several disservices in the process. The largest of these is probably the concept that bugs somehow spontaneously appear in source code. They do not. We put those errors in the code ourselves. In fact, on a bad day you might feel that you aren't programming at all, but rather enbugging the code—putting the bugs in. But it's actually more insidious than that. We rarely put bugs in directly; instead , we might set up conditions that will trick us into putting in bugs later. How can we prevent this? One of the best ways to keep future bugs out is to maintain a proper """" separation of concerns """" —that is, design the code so that classes and modules have clear, well-defined, and isolated responsibilities and well-understood semantics. But in real life, that's tricky. Getting it right takes experience, which means getting it wrong a lot of times and learning to do it better. Fortunately , we've got a few handy shortcuts to help you out. The fundamental goal (while we're in an anthropomorphic mood) is to write shy code—code that doesn't reveal too much of itself to anyone else and doesn't talk to others any more than is necessary. Shy code keeps to itself, not like that gossipy neighbor who's involved in everyone else's comings and goings. Shy code would never show its """" privates """" to """" friends, """" as some more promiscuous C++ code might. This month we'll examine some ways to help us create shy code. Although we are primarily looking at object-oriented examples , the same principles apply to procedural code as well. Tell, don't ask A distinction of OO code (or code written in that style in any language) is the idea of issuing a command to some entity to get something done. You see this explicitly in languages such as Smalltalk and Ruby, where method invocation is viewed as messages being passed between objects, not as function calls. In Java, C++, and similar languages, the fact that method invocation looks an awful lot like a function call tends to distract …"""	bad day (viral video);book;c++;debugging;gnu variants;handy backup;handy board;java;procedural programming;programmer;real life;ruby;separation of concerns;smalltalk;software bug;software construction;subroutine	Andy Hunt;Dave Thomas	2003	IEEE Software	10.1109/MS.2003.1159022	code bloat;real-time computing;object code;computer science;theoretical computer science;software engineering;programming language;object-oriented programming;code smell;program animation;source code	PL	-70.14620158412413	34.159107834340396	143029
0445e8478b0ad2b412867fd5c1d5917541c18273	strategies for avoiding text fixture smells during software evolution	configuration management;program testing;public domain software;software maintenance;automated testing;automated tests;code refactoring;fixture-related test smells;open source systems;setup code;setup management strategies;software evolution;test code quality;text fixture smell avoidance;maintenance;test evolution;test fixture smells	An important challenge in creating automated tests is how to design test fixtures, i.e., the setup code that initializes the system under test before actual automated testing can start. Test designers have to choose between different approaches for the setup, trading off maintenance overhead with slow test execution. Over time, test code quality can erode and test smells can develop, such as the occurrence of overly general fixtures, obscure inline code and dead fields. In this paper, we investigate how fixture-related test smells evolve over time by analyzing several thousand revisions of five open source systems. Our findings indicate that setup management strategies strongly influence the types of test fixture smells that emerge in code, and that several types of fixture smells often emerge at the same time. Based on this information, we recommend important guidelines for setup strategies, and suggest how tool support can be improved to help in both avoiding the emergence of such smells as well as how to refactor code when test smells do appear.	cluster analysis;code refactoring;code smell;continuous integration;emergence;inline expansion;open-source software;overhead (computing);software evolution;software quality;software system;system under test;test automation;test design;test fixture;turing test	Michaela Greiler;Andy Zaidman;Arie van Deursen;Margaret-Anne D. Storey	2013	2013 10th Working Conference on Mining Software Repositories (MSR)		market research;reliability engineering;dispersion;computer science;systems engineering;engineering;software evolution;software engineering;software testing;configuration management;software maintenance;java;public domain software;engineering drawing;code refactoring;code smell;software system	SE	-64.05018996432365	34.60465324891789	143253
1a54d102af8e7d7c8a7d5ea1463ae67e9b75a646	assessing programming language impact on development and maintenance: a study on c and c++	software;developer productivity;empirical study;high level languages;statistical analysis c language productivity public domain software software maintenance;complexity theory;measurement;mysql;programming language;software maintenance;firefox;software quality developer productivity empirical studies high level languages software evolution;maintenance engineering;testing;open source projects;development process;software fires complexity theory testing computer bugs measurement maintenance engineering;public domain software;comparative advantage;c language;statistical analysis;software evolution;blender;software development;mysql programming language software development software maintenance c language productive development developer productivity statistical analysis open source projects firefox blender vlc;vlc;empirical studies;productivity;fires;computer bugs;high level language;productive development;software quality;open source;product development	Billions of dollars are spent every year for building and maintaining software. To reduce these costs we must identify the key factors that lead to better software and more productive development. One such key factor, and the focus of our paper, is the choice of programming language. Existing studies that analyze the impact of choice of programming language suffer from several deficiencies with respect to methodology and the applications they consider. For example, they consider applications built by different teams in different languages, hence fail to control for developer competence, or they consider small-sized, infrequently-used, short-lived projects. We propose a novel methodology which controls for development process and developer competence, and quantifies how the choice of programming language impacts software quality and developer productivity. We conduct a study and statistical analysis on a set of long-lived, widely-used, open source projects - Firefox, Blender, VLC, and MySQL. The key novelties of our study are: (1) we only consider projects which have considerable portions of development in two languages, C and C++, and (2) a majority of developers in these projects contribute to both C and C++ code bases. We found that using C++ instead of C results in improved software quality and reduced maintenance effort, and that code bases are shifting from C to C++. Our methodology lays a solid foundation for future studies on comparative advantages of particular programming languages.	blender (software);c++;firefox;futures studies;mysql;open-source software;programming language;software quality;vlc media player	Pamela Bhattacharya;Iulian Neamtiu	2011	2011 33rd International Conference on Software Engineering (ICSE)	10.1145/1985793.1985817	maintenance engineering;computer science;systems engineering;engineering;software development;operating system;software engineering;programming language;empirical research;high-level programming language	SE	-64.600332443698	33.84815592405642	143899
9558e29db4995f8a51a953bfbf9f7b2f4531c03a	in the news		"""In the NewsWhose Bug Is It Anyway: The Battle over Handling Software FlawsAttacks exploit vulnerabilities in software code. They come in many forms: logic attacks, Trojan horses, worms and viruses, and variants of each. They serve a host of purposes: corporate espionage, white-collar crime, social \""""hacktivism,\"""" terrorism, and notoriety. Greater connectivity, more complex software, and the persistence of older protocols ensure growing vulnerability. Although marathon patching sessions have become the norm for harried IT administrators, even top-of-the-line patch management can't keep up with malicious code's growing sophistication. What happens when a software vulnerability is discovered? To establish agreed-on \""""best practices\"""" to guide the process of reporting bugs, several companies have come together to form the Organization for Internet Safety. There is also a set of informal guidelines called RFPolicy, the open source equivalent of the OIS recommendations.A Trip to South AfricaAlan Davis describes his sabbatical teaching in Cape Town, South Africa."""		Georges G. Grinstein;Anne C. Lear	1996	Revista espanola de medicina nuclear	10.1109/MMUL.1996.10017		Crypto	-66.68656447900354	54.975650844757254	145255
b100a0cdc7dabc6b36c4b54e361342489dc34aa5	improving regression testing in continuous integration development environments (keynote)		"""In continuous integration development environments, software engineers frequently integrate new or changed code with the mainline codebase. Merged code is then regression tested to help ensure that the codebase remains stable and that continuing engineering efforts can be performed more reliably. Continuous integration is advantageous because it can reduce the amount of code rework that is needed in later phases of development, and speed up overall development time. From a testing standpoint, however, continuous integration raises several challenges.   Chief among these challenges are the costs, in terms and time and resources, associated with handling a constant flow of requests to execute tests. To help with this, organizations often utilize farms of servers to run tests in parallel, or execute tests """"in the cloud"""", but even then, test suites tend to expand to utilize all available resources, and then continue to expand beyond that.   We have been investigating strategies for applying regression testing in continuous integration development environments more cost-effectively. Our strategies are based on two well-researched techniques for improving the cost-effectiveness of regression testing – regression test selection (RTS) and test case prioritization (TCP). In the continuous integration context, however, traditional RTS and TCP techniques are difficult to apply, because these techniques rely on instrumentation and analyses that cannot easily be applied to fast-arriving streams of test suites.   We have thus created new forms of RTS and TCP techniques that utilize relatively lightweight analyses, that can cope with the volume of test requests. To evaluate our techniques, we have conducted an empirical study on several large data sets. In this talk, I describe our techniques and the empirical results we have obtained in studying them."""		Gregg Rothermel	2018		10.1145/3278186.3281454	empirical research;industrial engineering;regression testing;speedup;rework;software;codebase;cloud computing;computer science;server	SE	-65.49216674104025	34.47878141855471	145934
0b00ce0c9f60f8bd2a95fc559b550f8c478ae0e0	bulk fixing coding issues and its effects on software quality: is it worth refactoring?	histograms;manuals;measurement;iso iec 25010;software systems;companies;coding issues;measurement encoding companies histograms software systems manuals;iso iec 25010 software quality maintainability coding issues antipatterns;antipatterns;global improvement bulk fixing coding issues software system quality source code software product refactoring operation;software quality software maintenance;encoding;software quality;maintainability	The quality of a software system is mostly defined by its source code. Software evolves continuously, it gets modified, enhanced, and new requirements always arise. If we do not spend time periodically on improving our source code, it becomes messy and its quality will decrease inevitably. Literature tells us that we can improve the quality of our software product by regularly refactoring it. But does refactoring really increase software quality? Can it happen that a refactoring decreases the quality? Is it possible to recognize the change in quality caused by a single refactoring operation? In our paper, we seek answers to these questions in a case study of refactoring large-scale proprietary software systems. We analyzed the source code of 5 systems, and measured the quality of several revisions for a period of time. We analyzed 2 million lines of code and identified nearly 200 refactoring commits which fixed over 500 coding issues. We found that one single refactoring only makes a small change (sometimes even decreases quality), but when we do them in blocks, we can significantly increase quality, which can result not only in the local, but also in the global improvement of the code.	care-of address;code refactoring;code smell;requirement;sensor;software quality;software system;source lines of code;video-in video-out	Gábor Szoke;Gabor Antal;Csaba Levente Nagy;Rudolf Ferenc;Tibor Gyimóthy	2014	2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation	10.1109/SCAM.2014.18	verification and validation;team software process;software quality management;software sizing;computer science;package development process;backporting;software development;software engineering;software rot;software construction;histogram;software testing;software walkthrough;software maintenance;anti-pattern;software deployment;software quality control;code refactoring;software quality;maintainability;software metric;encoding;measurement;software quality analyst;software system	SE	-64.46147692833433	34.45815210202297	145973
43b928d351cb4af6bf8b987b2e425c575dbf615b	to fork or not to fork: fork motivations in sourceforge projects	code forking;113 computer and information sciences;kota2011;code reuse;a4 conference proceedings;software development;software programming;open source software;sourceforge	A project fork occurs when software developers take a copy of source code from one software package and use it to begin an independent development work that is maintained separately from its origin. Although forking in open source software does not require the permission of the original authors, the new version, nevertheless, competes for the attention of the same developers that have worked on the original version. The motivations developers have for performing forks are many, but in general they have received little attention. In this paper, we present the results of a study of forks performed in SourceForge (http://sourceforge.net/) and list the developers’ motivations for their actions. The main motivation, seen in close to half of the cases of forking, was content modification; either adding content to the original program or focusing the content to the needs of a specific segment of users. In a quarter of the cases the motivation was technical modification; either porting the program to new hardware or software, or improving the	boolean algebra;design rationale;fork (software development);forking lemma;open-source software;software developer;sourceforge	Linus Nyman;Tommi Mikkonen	2011	IJOSSP	10.4018/jossp.2011070101	computer science;software development;operating system;software engineering;fork;programming language;management;world wide web	SE	-70.17215559929075	34.21420058890447	146161
6ae5872d0056b2245544efc2b31a237f58755cef	what if i had no smells?		What would have happened if I did not have any code smell? This is an interesting question that no previous study, to the best of our knowledge, has tried to answer. In this paper, we present a method for implementing a what-if scenario analysis estimating the number of defective files in the absence of smells. Our industrial case study shows that 20% of the total defective files were likely avoidable by avoiding smells. Such estimation needs to be used with the due care though as it is based on a hypothetical history (i.e., zero number of smells and same process and product change characteristics). Specifically, the number of defective files could even increase for some types of smells. In addition, we note that in some circumstances, accepting code with smells might still be a good option for a company.	code smell;scenario analysis	Davide Falessi;Barbara Russo;Kathleen Mullen	2017	2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)	10.1109/ESEM.2017.14	computer science;data mining;code smell;maintenance engineering;software;technical debt;scenario analysis	SE	-64.97884720165169	35.207738408733256	147062
edf643eed9a5f31e1a345ba0ddb1d3cf7762d8cb	an automated code smell and anti-pattern detection approach		Today, software maintenance is more expensive than development costs. As class complexity increases, it is increasingly difficult for new programmers to adapt to software projects, causing the cost of the software to go up. Therefore, itu0027s important to produce faultless and understandable code. Moreover, software projects are not developed by one person alone; even a small-scale project needs 3 or more participants working on the code at the same time. Producing well designed code during the development stage has a significant value because this process makes software projects more understandable and leads to higher code quality. Consequently, the cost of software project maintenance will decrease. Code smells and anti-patterns are symptoms of poorly designed code. The aforementioned tendencies of software projects increase the possibility of poor implementations and code imperfections. Therefore it is necessary to detect and refactor poorly designed code. This paper describes an attempt to achieve their detection.	anti-pattern;code smell;pattern recognition	Sevilay Velioglu;Yunus Emre Selçuk	2017		10.1109/SERA.2017.7965737	software construction;real-time computing;kpi-driven code analysis;code smell;backporting;computer science;package development process;static program analysis;team software process;software sizing	SE	-64.22048421324341	34.346684555093226	147457
2bc15e81a5df474e106c098d343e972b500e945b	sensor attack detection in the presence of transient faults	security and protection;unauthorized access;process control systems;real time and embedded systems	This paper addresses the problem of detection and identification of sensor attacks in the presence of transient faults. We consider a system with multiple sensors measuring the same physical variable, where some sensors might be under attack and provide malicious values. We consider a setup, in which each sensor provides the controller with an interval of possible values for the true value. While approaches exist for detecting malicious sensor attacks, they are conservative in that they treat attacks and faults in the same way, thus neglecting the fact that sensors may provide faulty measurements at times due to temporary disturbances (e.g., a tunnel for GPS). To address this problem, we propose a transient fault model for each sensor and an algorithm designed to detect and identify attacks in the presence of transient faults. The fault model consists of three aspects: the size of the sensor's interval (1) and an upper bound on the number of errors (2) allowed in a given window size (3). Given such a model for each sensor, the algorithm uses pairwise inconsistencies between sensors to detect and identify attacks. In addition to the algorithm, we provide a framework for selecting a fault model for each sensor based on training data. Finally, we validate the algorithm's performance on real measurement data obtained from an unmanned ground vehicle.	algorithm;fault model;global positioning system;malware;sensor;unmanned aerial vehicle	Junkil Park;Radoslav Ivanov;James Weimer;Miroslav Pajic;Insup Lee	2015		10.1145/2735960.2735984	embedded system;real-time computing;engineering;brooks–iyengar algorithm;process control;control theory;computer security	Mobile	-64.25571567723068	57.64458439181864	147904
c7e4ac8d8aca6a8af86de8da4fa8920e8d63c8e8	an investigation of bad smells in object-oriented design	object oriented system error object oriented design class error identification;design engineering;object oriented design;information technology;object oriented system error;object oriented programming;software engineering;process design;empirical evidence;computer architecture;object oriented systems;surgery computer errors software engineering computer architecture design engineering computer science process design java statistical analysis information technology;class error identification;system recovery;statistical analysis;systems analysis;surgery;systems analysis object oriented programming system recovery;computer science;computer errors;java	Bad smells are used to identify problematic classes in object-oriented design. Although intuitively making sense, the promise that bad smells can indicate the quality of design has not been validated by empirical evidence. This paper presents the results from an investigation that explored the relationship between the bad smells and the errors in an object-oriented system. The investigation found that some bad smells are positively associated with class errors	code smell	Raed Shatnawi;Wei Li	2006	Third International Conference on Information Technology: New Generations (ITNG'06)	10.1109/ITNG.2006.31	process design;systems analysis;empirical evidence;computer science;theoretical computer science;object-oriented design;software engineering;programming language;object-oriented programming;java;information technology;code smell	SE	-63.65344741842835	34.265164041920826	148644
40a55910049ff4753446b4ef5f19ff22b72e533d	empirical model for predicting high, medium and low severity faults using object oriented metrics in mozilla firefox	mozilla firefox;software bugs;neural networks;object oriented metrics;logistic regression;error proneness;bugzilla;software faults;error severity	There have been numerous studies to predict the error proneness of class. If software testers have only a very limited amount of time left to conduct testing, knowing where the most severe errors are likely to occur in a system is more helpful than just knowing where errors are likely to occur. This paper describes how we calculated various object oriented metrics of three versions of Mozilla Firefox. And after that how we collected all the bugs along with their severity levels in these versions of Firefox using Bugzilla database and associated bugs with class. Logistic regression and neural network techniques are followed to predict the error proneness of class under error category. The findings suggest that various metrics can be used to predict error proneness of class under error category. Neural network approach can predict high and medium severity errors more accurately than the low severity errors.	firefox	Satwinder Singh;Puneet Mittal;K. S. Kahlon	2013	IJCAT	10.1504/IJCAT.2013.054345	reliability engineering;software bug;computer science;machine learning;data mining;logistic regression;artificial neural network	Robotics	-63.55796448869594	34.858472667162644	149517
e7d60eee70ee2322217f220d7e578689c6baa5d0	firms'involvement in open source projects: a controversial role	quality metric;software design quality;professional development;software project success;software design;firms involvement;user satisfaction;open source	In this paper, we focus on Community OS projects with the goal of understanding whether the involvement of firms through their professional developers has an impact on the quality of the software product and on its overall success. We distinguish between two main typologies of firms’ involvement: Development firms contributions and Non-development firms contributions. The paper posits that a higher percentage of code contributed by paid developers has a positive impact of project success and size. However, it also puts forward a negative impact of non-development firms contribution on software design quality. Hypotheses are tested on a sample of 643 applications from the SourceForge.net repository, corresponding to 5,335 versions. Data were collected by means of an online questionnaire and a tool developed ad hoc to calculate software design quality metrics. Empirical findings support our hypotheses. Overall, our data confirm that firms are significantly investing in OS projects and that they can play a crucial role in determining projects’ success when they also take active part in code development. However, most of them are taking a short-term perspective that does not focus on quality. This may lead to higher costs and a lower user satisfaction in the long term.	computer user satisfaction;hoc (programming language);operating system;software design;sourceforge	Eugenio Capra;Chiara Francalanci;Francesco Merlo;Cristina Rossi Lamastra	2008			software review;personal software process;long-term support;verification and validation;team software process;software project management;systems engineering;knowledge management;social software engineering;software development;software engineering;software walkthrough;software deployment;software quality control;software quality;software peer review	SE	-65.98419803214524	33.28366025234255	149562
12d4c92f0a3a70538ed609bf6f7b603e44d11abd	execution anomaly detection in distributed systems through unstructured log analysis	performance measure;distributed system;histograms;log files;learning model;log analysis;anomaly detection;training;unstructured log analysis technique;finite state automaton execution anomaly detection large scale distributed systems unstructured log analysis technique;execution anomaly detection;data mining;text messaging;finite state automaton log analysis distributed system problem diagnosis;security of data distributed programming;automatic detection;feature extraction;distributed programming;finite state automaton;source code;entropy;large scale distributed systems;large scale systems learning automata measurement timing;security of data;algorithm design and analysis;problem diagnosis;timing	Detection of execution anomalies is very important for the maintenance, development, and performance refinement of large scale distributed systems. Execution anomalies include both work flow errors and low performance problems. People often use system logs produced by distributed systems for troubleshooting and problem diagnosis. However, manually inspecting system logs to detect anomalies is unfeasible due to the increasing scale and complexity of distributed systems. Therefore, there is a great demand for automatic anomalies detection techniques based on log analysis. In this paper, we propose an unstructured log analysis technique for anomalies detection. In the technique, we propose a novel algorithm to convert free form text messages in log files to log keys without heavily relying on application specific knowledge. The log keys correspond to the log-print statements in the source code which can provide cues of system execution behavior. After converting log messages to log keys, we learn a Finite State Automaton (FSA) from training log sequences to present the normal work flow for each system component. At the same time, a performance measurement model is learned to characterize the normal execution performance based on the log mes-sages’ timing information. With these learned models, we can automatically detect anomalies in newly input log files. Experiments on Hadoop and SILK show that the technique can effectively detect running anomalies.	algorithm;anomaly detection;apache hadoop;automaton;data logger;distributed computing;experiment;finite-state machine;log analysis;refinement (computing);silk	Qiang Fu;Jian-Guang Lou;Yi Wang;Jiang Li	2009	2009 Ninth IEEE International Conference on Data Mining	10.1109/ICDM.2009.60	algorithm design;entropy;anomaly detection;real-time computing;feature extraction;computer science;theoretical computer science;machine learning;data mining;histogram;source code	Embedded	-63.05925201007386	58.818226237570926	149744
919e7024e2ae2fd9d0b892a5c7bba75ea87fd57f	a gp effort estimation model utilizing line of code and methodology for nasa software projects	software;line of code;genetic program;software cost estimation;project management;gp effort estimation model;nasa software;nasa software projects;genetic programming;software engineering;lines of code;computational modeling;mathematical model software computational modeling estimation nasa genetic programming equations;effort estimation;estimation;nasa software software cost estimation software engineering genetic programming;mathematical model;genetic algorithms;line of code gp effort estimation model genetic programming nasa software projects software cost estimation model;nasa;software development management;software cost estimation model;software development management genetic algorithms project management software cost estimation	There is still an urgent need of finding a mathematical model which can provide an accurate relationship between the software project effort/cost and the cost drivers. A powerful algorithm which can optimize such a relationship via developing a mathematical relationship between model variables is urgently needed. In this paper, we explore the use of GP to develop a software cost estimation model utilizing the effect of both the developed line of code and the used methodology during the development. An application of estimating the effort for some NASA software projects is introduced. The performance of the developed Genetic Programming (GP) based model was tested and compared to known models in the literature. The developed GP model was able to provide good estimation capabilities compared to other models.	algorithm;cost estimation in software engineering;genetic programming;mathematical model;software development effort estimation;software project management;source lines of code;victor basili	Alaa F. Sheta;Alaa Al-Afeef	2010	2010 10th International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2010.5687251	project management;genetic programming;estimation;simulation;genetic algorithm;computer science;mathematical model;computational model;source lines of code;statistics	SE	-62.85293417861707	32.835512328215465	150083
471ea948c49712287335dd73004402c2693b0301	towards a principle-based classification of structural design smells		Fred Brooks in his book “The Mythical Man Month” describes how the inherent properties of software (i.e. complexity, conformity, changeability, and invisibility) make its design an “essential” difficulty. Good design practices are fundamental requisites to address this difficulty. One such good practice is that a software designer should be aware of and address “design smells” that can manifest as a result of his design decisions. However, our study of the vast literature on object-oriented design smells reveals the lack of an effective organization of smells that could better guide a designer in understanding and addressing potential issues in his design. In order to address this gap, we have adopted a novel approach to classify and catalog a number of recurring structural design smells based on how they violate key object oriented (OO) design principles. To evaluate the usefulness of our design smell catalog, we first asked Siemens CT DC AA architects to use it to identify design smells in their projects, and later elicited feedback from them about their experience. The feedback received indicates that these architects found the catalog to be very useful. In this paper, we present our catalog, classification, and naming scheme for design smells and also highlight several interesting observations and insights that result from our work.	conformity;design smell;feedback;fred (chatterbot);manifest (transportation);software design;the mythical man-month	S. G. Ganesh;Tushar Sharma;Girish Suryanarayana	2013	Journal of Object Technology	10.5381/jot.2013.12.2.a1	code smell;software;systems engineering;design elements and principles;computer science;object-oriented programming;software design;invisibility	SE	-64.34377420556102	35.09607635777959	151410
e716f2d8c9d6fea0578269f3d2438ee7e4156a0d	source code patterns of buffer overflow vulnerabilities in firefox		We investigated 50 randomly selected buffer overflow vulnerabilities in Firefox. The source code of these vulnerabilities and the corresponding patches were manually reviewed and patterns were identified. Our main contribution are taxonomies of errors, sinks and fixes seen from a developer’s point of view. The results are compared to the CWE taxonomy with an emphasis on vulnerability details. Additionally, some ideas are presented on how the taxonomy could be used to improve the software security education.		Felix Schuckert;Max Hildner;Basel Katt;Hanno Langweg	2018		10.18420/sicherheit2018_08	operating system;static program analysis;source code;buffer overflow;computer science	SE	-63.82645292187907	37.36353857699357	151691
33fbe3422cd4ddf2fe63f6f62925dcb23abd802d	do comments explain codes adequately?: investigation by text filtering	group 1;source code;comments;fault prone module;distance	"""Comment lines in the software source code include descriptions of codes, usage of codes, copyrights, unused codes, comments, and so on. It is required for comments to explain the content of written code adequately, since the wrong description in the comment may causes further bug and confusion in maintenance.  In this paper, we try to clarify a research question: """"In which projects do comments describe the code adequately?"""" To answer this question, we selected the group 1 of mining challenge and used data obtained from Eclipse and Netbeans. Since it is difficult to answer the above question directly, we define the distance between codes and comments. By utilizing the fault-prone module prediction technique, we can answer the alternative question from the data of two projects. The result shows that Eclipse project has relatively adequate comments."""	code;comment (computer programming);eclipse;experiment;netbeans ide	Yukinao Hirata;Osamu Mizuno	2011		10.1145/1985441.1985482	computer science;theoretical computer science;data mining;distance;algorithm;source code	SE	-64.17433296984873	36.77819408821549	152701
7923fa609d3c1f753d4d99086bfadc19f39bd077	“cloning considered harmful” considered harmful: patterns of cloning in software	software systems;clone analysis;code clone;clone detection;open source software;reverse engineering	Literature on the topic of code cloning often asserts that duplicating code within a software system is a bad practice, that it causes harm to the system’s design and should be avoided. However, in our studies, we have found significant evidence that cloning is often used in a variety of ways as a principled engineering tool. For example, one way to evaluate possible new features for a system is to clone the affected subsystems and introduce the new features there, in a kind of sandbox testbed. As features mature and become stable within the experimental subsystems, they can be migrated incrementally into the stable code base; in this way, the risk of introducing instabilities in the stable version is minimized. This paper describes several patterns of cloning that we have observed in our case studies and discusses the advantages and disadvantages associated with using them. We also examine through a case study the frequencies of these clones in two medium-sized open source software systems, the Apache web server and the Gnumeric spreadsheet application. In this study, we found that as many as 71% of the clones could be considered to have a positive impact on the maintainability of the software system.	code refactoring;code smell;open-source software;server (computing);software system;spreadsheet;testbed;web server;xojo	Cory Kapser;Michael W. Godfrey	2008	Empirical Software Engineering	10.1007/s10664-008-9076-6	real-time computing;computer science;systems engineering;engineering;software engineering;world wide web;reverse engineering;software system	SE	-63.99419024140027	35.32982580514843	153061
07ec5431442bf08667fd1ee195b5aa4f94d999af	organization of programming knowledge of novices and experts	concept formation;analysis of variance	This article reports on an experiment on the organization and use of programming knowledge. Novice and expert programmers made timed decisions about the structure and function of short and familiar FORTRAN code segments, similar to those in introductory programming textbooks. It was found that experts were faster and more accurate than novices, in spite of the simplicity of the materials. Functional decisions, which require analysis of the code, were slower than syntactic decisions for both groups, but were significantly slower for novices than for experts. This result suggests that the ability to extract and use functional information is characteristic of expertise in programming. Novices are less adept at using functional information, even when dealing with very small, simple programs appropriate to their own level of experience. The results of this study suggest that the difference between novice and expert programmers lies in the quality as well as the quantity of their knowledge.	code segment;fortran;programmer	Susan Wiedenbeck	1986	JASIS	10.1002/(SICI)1097-4571(198609)37:5%3C294::AID-ASI3%3E3.0.CO;2-H	data science;data mining;computer science;knowledge level;aptitude;computer program;artificial intelligence;fortran;concept learning	HCI	-69.89523221317955	36.00543928929541	154406
d8d41fe42256a9b57398953fc6f61da22aea8e80	investigating the relationship between code smell agglomerations and architectural concerns: similarities and dissimilarities from distributed, service-oriented, and mobile systems		Context: software architects often decide on strategies before incorporating an asset (e.g., components) in software systems. At the same time, they are responsible for preventing code and architectural degradation caused by design problems. Problem: groups of code smells (a.k.a. agglomeration of code smells) have been recognized as a source of design problems, but no previous study has analyzed the relationship between such agglomerations and different types of software. Different types of software have different needs in terms of implementation of architectural concerns, which can lead to consequential variations in the way how code smells agglomerate. Goal: this study aims to understand how a varied set of projects and their respective architectural concerns relates to code smells agglomerations. Method: our study analyses the history of 15 Open Source Software (OSS) projects split as three groups of distributed, service-oriented, and mobile project types. It mines the projects for code smells and architectural concerns (identified from injected components). It agglomerates instances of code smells around these concerns, and analyzes them according to the grouped projects. Results/Discussion: the agglomerations of smells tend to follow a stratified pattern in which they group themselves through ramifications of similarities and dissimilarities of concerns and project types.	anti-pattern;code smell;elegant degradation;open sound system;open-source software;service-oriented architecture;service-oriented software engineering;software architect;software system	Luis Paulo da Silva Carvalho;Renato Lima Novais;Manoel G. Mendonça	2018		10.1145/3267183.3267184	software system;code smell;systems engineering;architecture;urban agglomeration;software;computer science;economies of agglomeration	SE	-63.69902546925901	34.409044208188504	154514
8d01941333c85eb9d3e91fba026cab9398cd785d	alternative sources of information for code smell detection: postcards from far away	detectors;history;measurement;software systems;feature extraction;context	Code smells have been defined as symptoms of poor design and implementation choices. Previous studies showed the negative impact of code smells on the comprehensibility and maintainability of code. For this reasons, several detection techniques have been proposed. Most of them rely on the analysis of the properties extractable from the source code. In the context of this work, we highlight several aspects that can possibly contribute to the improvement of the current state of the art and propose our solutions, based on the analysis on how code smells are actually introduced as well as the usefulness of historical and textual information to realize more reliable code smell detectors. Finally, we present an overview of the open issues and challenges related to code smell detection and management that the research community should focus on in the next future.	code smell;sensor	Fabio Palomba	2016	2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)	10.1109/ICSME.2016.26	detector;simulation;feature extraction;computer science;engineering;software engineering;data mining;computer security;code smell;measurement;software system	SE	-63.92976860809563	35.602558704066205	154589
74cee84b14c9f5031261bc2498befa6646efb710	"""rdb """"universal"""" servers giving real ordbs a bad name"""			amiga rigid disk block	Won Young Kim	1997	JOOP		database;computer science;server	Theory	-89.36978009362254	32.477092258356045	155110
3a1e9f17e1a98e17d3bcc5dbee09f920bfee2eee	3-dimensional root cause diagnosis via co-analysis	large scale system;co analysis;diagnosis	With the growth of system size and complexity, reliability has become a major concern for large-scale systems. Upon the occurrence of failure, system administrators typically trace the events in Reliability, Availability, and Serviceability (RAS) logs for root cause diagnosis. However, RAS log only contains limited diagnosis information. Moreover, the manual processing is time-consuming, error-prone, and not scalable. To address the problem, in this paper we present an automated root cause diagnosis mechanism for large-scale HPC systems. Our mechanism examines multiple logs to provide a 3-D fine-grained root cause analysis. Here, 3-D means that our analysis will pinpoint the failure layer, the time, and the location of the event that causes the problem.  We evaluate our mechanism by means of real logs collected from a production IBM Blue Gene/P system at Oak Ridge National Laboratory. It successfully identifies failure layer information for the failures during 23-month period. Furthermore, it effectively identifies the triggering events with time and location information, even when the triggering events occur hundreds of hours before the resulting failures.	blue gene;cognitive dimensions of notations;complexity;p system;scalability;system administrator	Ziming Zheng;Li Yu;Zhiling Lan;Terry Jones	2012		10.1145/2371536.2371571	real-time computing;operating system;medical diagnosis;data mining;database;computer security	Networks	-63.424979930871984	41.75389682652168	155143
995761c7a2e8de3e52207a0730e1fb2136c45b0d	data mining for predictors of software quality	classification trees;cart;data mining;fault prone modules;software process metrics;software product metrics;software quality;telecommunications;knowledge discovery	"""""""Knowledge discovery in data bases"""" (KDD) for software engineering is a process for finding useful information in the large volumes of data that are a byproduct of software development, such as data bases for configuration management and for problem reporting. This paper presents guidelines for extracting innovative process metrics from these commonly available data bases. This paper also adapts the Classification And Regression Trees algorithm, CART, to the KDD process for software engineering data. To our knowledge, this algorithm has not been used previously for empirical software quality modeling. In particular, we present an innovative way to control the balance between misclassification rates. A KDD case study of a very large legacy telecommunications software system found that variables derived from source code, configuration management transactions, and problem reporting transactions can be useful predictors of software quality. The KDD process discovered that for this software development environment, out of forty software attributes, only a few of the predictor variables were significant. This resulted in a model that predicts whether modules are likely to have faults discovered by customers. Software developers need such predictions early in development to target software enhancement techniques to the modules that need improvement the most."""	algorithm;configuration management;data mining;database;decision tree learning;integrated development environment;kerrison predictor;software developer;software development;software engineering;software feature;software quality;software system	Taghi M. Khoshgoftaar;Edward B. Allen;Wendell D. Jones;John P. Hudepohl	1999	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194099000309	verification and validation;software engineering process group;software sizing;software mining;computer science;artificial intelligence;package development process;backporting;data science;software development;software engineering;software construction;data mining;database;knowledge extraction;software walkthrough;software analytics;software deployment;goal-driven software development process;software quality;software metric;software quality analyst;software system	SE	-64.77168079559982	32.63759723197082	155192
4d09a7fa69ff25cf20eb053281cb89b72562b675	css corpus for reproducible analysis		Reproducibility of research heavily depends on the availability of the datasets from the experiments in the context of metaprogramming, the corpus of the code that was used to run the analyses and transformations. In the case of CSS, the problem is even more acute since the web is a constantly changing environment where the same address can refer to a frequently changing artefact. In this report, we explain how we created a corpus of CSS les as a part of our project of building a framework for analysing style sheets. We also include two case studies of explanatory nature showing how style sheets from various websites go about coding conventions and about code duplication. We believe this work will be useful for other CSS researchers to compare techniques they develop, on a uniform yet realistic dataset.	cascading style sheets;duplicate code;experiment;metaprogramming;style sheet (web development);text corpus;visual artifact	Nico de Groot;Vadim Zaytsev	2016			computer science	NLP	-64.72163882242937	37.10415868278617	156439
a20def90994cab53b1e5202147848bb5bd4891a4	alert detection in system logs	computers;kernel;log analysis;probability density function;anomaly detection;fault detection anomaly detection log analysis hpc information theory;data mining;hpc;fault detection;production;supercomputers data mining usa councils information entropy laboratories production systems costs detection algorithms personnel fault detection;entropy;information entropy;message terms alert detection system logs nodeinfo unsupervised algorithm anomaly detection information entropy;security of data;supercomputers;information theory;security of data entropy;tagging	We present Nodeinfo, an unsupervised algorithm for anomaly detection in system logs. We demonstrate Nodeinfo's effectiveness on data from four of the world's most powerful supercomputers: using logs representing over 746 million processor-hours, in which anomalous events called alerts were manually tagged for scoring, we aim to automatically identify the regions of the log containing those alerts. We formalize the alert detection task in these terms, describe how Nodeinfo uses the information entropy of message terms to identify alerts, and present an online version of this algorithm, which is now in production use. This is the first work to investigate alert detection on (several) publicly-available supercomputer system logs, thereby providing a reproducible performance baseline.	algorithm;anomaly detection;baseline (configuration management);entropy (information theory);supercomputer	Adam J. Oliner;Alexander Aiken;Jon Stearley	2008	2008 Eighth IEEE International Conference on Data Mining	10.1109/ICDM.2008.132	entropy;probability density function;anomaly detection;kernel;information theory;computer science;data science;theoretical computer science;data mining;mathematics;fault detection and isolation;statistics;entropy	DB	-63.08341053824766	58.89912783320465	157352
cf6f1c5f463ae5292f1c55c929f2d3db14ad2d45	testing mapreduce programs: a mapping study	software;systematics;search engines;testing;data mining;data models;java	The MapReduce (MR) programming model is widely used in the development of parallel applications involving large data sets. Many research papers focus on quality attributes associated to the environments that execute MR programs. However, the test of such programs can be considered a challenger and an open research subject. Considering this fact, this paper presents results from a mapping study about testing of MR programs. The mapping searched by papers related to MR program test, which were analyzed according to the following dimensions: purpose, tools and environments, testing techniques, and criteria and types of fault. The achieved outcomes serve as motivation to stimulate and direct future research in this field.	list of system quality attributes;mapreduce;open research;programming model	Luiz Carlos Camargo;Silvia Regina Vergilio	2013	2013 32nd International Conference of the Chilean Computer Science Society (SCCC)	10.1109/SCCC.2013.10	computer science;data mining;database;world wide web	SE	-67.08115272090734	34.77314885041888	157858
abd1be23746d72c12c94f6dca345a043ae4c9563	smells like teen spirit: improving bug prediction performance using the intensity of code smells		Code smells are symptoms of poor design and implementation choices. Previous studies empirically assessed the impact of smells on code quality and clearly indicate their negative impact on maintainability, including a higher bug-proneness of components affected by code smells. In this paper we capture previous findings on bug-proneness to build a specialized bug prediction model for smelly classes. Specifically, we evaluate the contribution of a measure of the severity of code smells (i.e., code smell intensity) by adding it to existing bug prediction models and comparing the results of the new model against the baseline model. Results indicate that the accuracy of a bug prediction model increases by adding the code smell intensity as predictor. We also evaluate the actual gain provided by the intensity index with respect to the other metrics in the model, including the ones used to compute the code smell intensity. We observe that the intensity index is much more important as compared to other metrics used for predicting the buggyness of smelly classes.	baseline (configuration management);code smell;experiment;kerrison predictor;performance;software quality	Fabio Palomba;Marco Zanoni;Francesca Arcelli Fontana;Andrea De Lucia;Rocco Oliveto	2016	2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)	10.1109/ICSME.2016.27	reliability engineering;database index;simulation;software bug;computer science;data mining;predictive modelling;computational model;measurement	SE	-63.58653529265325	34.9192406512351	159133
3b5d022d3c3ad1e49a433a8b41aa274ad5592cc8	a hybrid expert system/neural network traffic advice system	neural network;expert system	"""traffic management in the Southern Californian telephone network. The system has been the display of exception conditions and advice. Exceptions are shown highlighted on a map of incorporation in the system. Ke~word Codes: 1.2.1, 1.2.6, C.2.3 Ke~words: Applications and Expert Systems, Learning, Network Operations Introduction implementation of a real-time autonomous expert system which would aid network management of the Pacific Bell Southern Californian telephone network [GOOD92]. The """""""""""" ultimate aim of the project was to produce and automatically implement recommendations for had to be written down, and coded for use in a computer system while retaining flexibility and openness to change. problems arise. Examples are single random overloads of traffic on a given route, high volume phone-in conditions, disasters such as earthquakes, unusual calling patterns such as occur on Mother's Day, killer trunks, which are trunks that seize a call attempt and immediately release additional problems that have to be diagnosed. software~"""	advice (programming);autonomous robot;code;computer;exception handling;expert system;killer application;microsoft word for mac;openness;race condition;real-time transcription	Rodney M. Goodman;Barry Ambrose;Hayes Latin;Sandee Finnell	1993			computer science	Networks	-66.70813168402111	54.97272105332827	159663
b7669efce4e8b2545077fa1bf10481d7f5992d36	a multidimensional empirical study on refactoring activity	multidimensional empirical study;strong alignment;release date;refactoring activity;smell resolution;individual contribution;individual refactoring;applied refactorings;different type;refactorings focus;refactoring decision	In this paper we present an empirical study on the refactoring activity in three well-known projects. We have studied five research questions that explore the different types of refactorings applied to different types of sources, the individual contribution of team members on refactoring activities, the alignment of refactoring activity with release dates and testing periods, and the motivation behind the applied refactorings. The studied projects have a history of 12, 7, and 6 years, respectively. We have found that there is very little variation in the types of refactorings applied on test code, since the majority of the refactorings focus on the reorganization and renaming of classes. Additionally, we have identified that the refactoring decision making and application is often performed by individual refactoring “managers”. We have found a strong alignment between refactoring activity and release dates. Moreover, we found that the development teams apply a considerable amount of refactorings during testing periods. Finally, we have also found that in addition to code smell resolution the main drivers for applying refactorings are the introduction of extension points, and the resolution of backward compatibility issues. Copyright c © 2013 Nikolaos Tsantalis, Victor Guana, Eleni Stroulia, and Abram Hindle. Permission to copy is hereby granted provided the original copyright notice is reproduced in copies made.	application programming interface;backward compatibility;checkstyle;code refactoring;code smell;duplicate code;findbugs;open-source software;pmd;partial template specialization;refinement (computing);software developer;software factory;software quality;sonar;test-driven development;victor pan	Nikolaos Tsantalis;Victor Guana;Eleni Stroulia;Abram Hindle	2013			data mining	SE	-65.81886566298336	34.939827848282945	160538
1639e5e76aa585f9d88cfdd8b3d58d1433b7286f	continuous validation of performance test workloads	performance testing;continuous testing;workload characterization;workload comparison;execution logs	The rise of large-scale software systems poses many new challenges for the software performance engineering field. Failures in these systems are often associated with performance issues, rather than with feature bugs. Therefore, performance testing has become essential to ensuring the problem-free operation of these systems. However, the performance testing process is faced with a major challenge: evolving field workloads, in terms of evolving feature sets and usage patterns, often lead to “outdated” tests that are not reflective of the field. Hence performance analysts must continually validate whether their tests are still reflective of the field. Such validation may be performed by comparing execution logs from the test and the field. However, the size and unstructured nature of execution logs makes such a comparison unfeasible without automated support. In this paper, we propose an automated approach to validate whether a performance test resembles the field workload and, if not, determines how they differ. Performance analysts can then update their tests to eliminate such differences, hence creating more realistic tests. We perform six case studies on two large systems: one open-source system and one enterprise system. Our approach identifies differences between performance tests and the field with a precision of 92 % compared to only 61 % for the state-of-the-practice and 19 % for a conventional statistical comparison.	enterprise system;failure;open-source software;performance engineering;software bug;software performance testing;software system	Mark D. Syer;Weiyi Shang;Zhen Ming Jiang;Ahmed E. Hassan	2016	Automated Software Engineering	10.1007/s10515-016-0196-8	real-time computing;simulation;engineering;data mining	SE	-64.13578780725902	39.682846392919764	160682
f433b8e67f5491379ce7cd91afa5814de130b32c	how much information is needed for usage-based reading? -- a series of experiments	reading technique;program debugging software engineering inspection;usage based reading;inspection software engineering bioreactors communication system software computer science technology planning fault detection testing engineering management;bioreactors;software document;software inspections;software development process;testing;communication system software;inspection;software engineering;design specifications;technology planning;engineering management;prioritized use cases;fault detection;experiments;datavetenskap datalogi;software development fault detection;program debugging;computer science;programvaruteknik;software inspection;use case;checklist based reading usage based reading experiments software inspections software development fault detection software document prioritized use cases design specifications;checklist based reading	Software inspections are regarded as an important technique to detect faults throughout the software development process. The individual preparation phase of software inspections has enlarged its focus from only comprehension to also include fault searching. Hence, reading techniques to support the reviewers on fault detection are needed. Usage-based reading (UBR) is a reading technique, which focuses on the important parts of a software document by using prioritized use cases. This paper presents a series of three UBR experiments on design specifications, with focus on the third. The first experiment evaluates the prioritization of UBR and the second compares UBR against checklist-based reading. The third experiment investigates the amount of information needed in the use cases and whether a more active approach helps the reviewers to detect more faults. The third study was conducted at two different places with a total of 82 subjects. The general result from the experiments is that UBR works as intended and is efficient as well as effective in guiding reviewers during the preparation phase of software inspections. Furthermore, the results indicate that use cases developed in advance are preferable compared to developing them as part of the preparation phase of the inspection.	experiment	Thomas Thelin;Per Runeson;Claes Wohlin;Thomas Olsson;Carina Andersson	2002		10.1109/ISESE.2002.1166932	real-time computing;computer science;systems engineering;software engineering	NLP	-63.92266457945018	32.680648328576744	160938
2a55949236342117db799d3d5f554b128206d4c4	computer-mediated group support, anonymity, and the software inspection process: an empirical investigation	anonymity;collaborative software inspection software quality programming control systems impedance laboratories error correction software systems software tools;negative affect;groupware;control group;group support system;software process improvement;software quality assurance;seeded errors;controlled experiment design;group support systems;software quality assurance computer mediated group support anonymity software inspection process ego involvement personality conflicts inspection team members suboptimal outcomes computer based inspection team based inspection software inspection group support systems group member anonymity software code complexity seeded errors;human factors;program testing;human factors groupware software quality software development management program testing software process improvement;laboratory experiment;software inspection;software quality;software development management	In software inspection, a key principle endorsed by Fagan (1986) is openness. However, scholars have recently questioned the efficacy of openness. For example, some argue that ego-involvement and personality conflicts that become more transparent due to openness might impede inspection. Still others point out that familiarity and (preexisting) relationships among inspection team members negatively affect the comprehensiveness in detection of defects. This brings up concerns if the openness as originally envisioned by Fagan may in fact lead to suboptimal outcomes. As the trend towards computer-based inspection continues, we believe that anonymity could play a positive role in overcoming some of the drawbacks noted in team-based inspection. Drawing upon the literature on software inspection and group support systems, this research proposes possible influences of group member anonymity on the outcome of computer-mediated software inspection and empirically examines the validity of the posited relationships in a set of controlled laboratory experiments. Two different inspection tasks with varying levels of software code complexity are employed. While both the control groups (i.e., teams without anonymity) and treatment groups (i.e., teams with support for anonymity) consume more or less the same time in performing the inspection tasks, the treatment groups are more effective in identifying the seeded errors in the more complex task. Treatment groups also express a more positive attitude toward both code inspection tasks. The findings of the study suggest a number of directions for future research.	software inspection	Padmal Vitharana;K. Ramamurthy	2003	IEEE Trans. Software Eng.	10.1109/TSE.2003.1178054	reliability engineering;simulation;anonymity;computer science;systems engineering;engineering;human factors and ergonomics;operating system;software engineering;software inspection;management;software quality;scientific control;affect	SE	-65.64052277001178	32.54575810558373	161570
2f4a89431dcf7c2fadf88d0ea1d70ef207597475	alternative approaches for the use of metrics to order programs by complexity	complexite;metodologia;estudio comparativo;weighting;complejidad;metric;ingenieria logiciel;complexity;ponderacion;software engineering;methodologie;etude comparative;scheduling;nombre complexite cyclomatique mccabe;metrique halstead;ordonnancement programme;comparative study;genie logiciel;metrico;ordonamiento;evaluation;ponderation;evaluacion;methodology;ordonnancement;metrique	With many program complexity metrics available, it is difficult to rank programs by complexity: the different metrics can give different indications. There are two parts to this problem. First, because different metrics can measure the same program attribute, we need a method of evaluating a given program attribute based on the values of all metrics that measure this attribute. Second, because different metrics can measure distinct program attributes, we need a method of evaluating the overall program complexity based on the values of all program attributes. This article compares two methods of simultaneously detecting those aspects of software complexity measured by the Halstead metrics and the McCabe cyclomatic complexity number	complexity	Taghi M. Khoshgoftaar;John C. Munson;David L. Lanning	1994	Journal of Systems and Software	10.1016/0164-1212(94)90064-7	complexity;metric;halstead complexity measures;computer science;theoretical computer science;evaluation;operating system;software engineering;comparative research;methodology;weighting;scheduling;algorithm	Logic	-67.57692374428483	33.14305475930761	161724
b2be359e4ac10defaeee978c56d3637fa70d8b6b	predicting fault-prone classes with design measures in object-oriented systems	software metrics;software performance evaluation;software performance evaluation object oriented programming inheritance software metrics;object oriented programming;object oriented systems;object oriented;fault detection;empirical validation;software development;fault proneness fault prone class prediction design measures object oriented systems object oriented coupling cohesion inheritance measures fault detection system classes testing product measurement oo systems software quality method invocations inheritance hierarchies;fault detection inspection software quality object oriented modeling predictive models software measurement system testing frequency large scale systems particle measurements;inheritance	The paper aims at empirically exploring the relationships between existing object oriented coupling, cohesion, and inheritance measures and the probability of fault detection in system classes during testing. The underlying goal of such a study is to better understand the relationship between existing product measurement in OO systems and the quality of the software developed. It is shown that by using a subset of existing measures, accurate models can be built to predict in which classes most of the faults are likely to lie in. By inspecting 48% of the classes, it is possible to find 95% of the faults. Besides the size of classes, the frequency of method invocations and the depth of inheritance hierarchies seem to be the main driving factors of fault proneness.		Lionel C. Briand;John W. Daly;D. Victor Porter;Jürgen Wüst	1998		10.1109/ISSRE.1998.730898	reliability engineering;verification and validation;real-time computing;computer science;systems engineering;component-based software engineering;software development;software engineering;software construction;programming language;object-oriented programming	PL	-63.15060634653182	34.47478441789612	161974
54aff8e2ebff97157596470abfe490121970ddc7	developing a mechanism to study code trustworthiness	organization;readability;conference paper;trusted systems;code degradations;programmer trust	When software code is acquired from a third party or version control repository, programmers assign a level of trust to the code. This trust prompts them to use the code as-is, make minor changes, or rewrite it, which can increase costs and delay deployment. This paper discusses types of degradations to code based on readability and organization expectations and how to present that code as part of a study on programmer trust. Degradations were applied to sixteen of eighteen Java classes that were labeled as acquired from reputable or unknown sources. In a pilot study, participants were asked to determine a level of trustworthiness and whether they would use the code without changes. The results of the pilot study are presented to provide a baseline for the continuance of the study to a larger set of participants and to make adjustments to the presentation environment to improve user experience.	baseline (configuration management);java;programmer;rewrite (programming);software deployment;trust (emotion);user experience;version control	Charles Walter;Rose F. Gamble;Gene M. Alarcon;Sarah A. Jessup;Chris Calhoun	2017			computer science;organization;software engineering;management;world wide web;computer security	SE	-66.24935031898374	33.79096819100336	162173
3baa05d309b23f81a117f6d89155f341cc3cb908	an empirical study of bug fixing rate	empirical study;history;computer bugs correlation history computer aided software engineering open source software entropy;computer aided software engineering;mozilla bug fixing rate software development software maintenance open source software community eclipse;statistical analysis;bug fixing rate;bug reports;entropy;software maintenance program debugging public domain software;correlation;computer bugs;bug reports bug fixing rate empirical study statistical analysis;open source software	Bug fixing is one of the most important activities in software development and maintenance. A software project often employs an issue tracking system such as Bugzilla to store and manage their bugs. In the issue tracking system, many bugs are invalid but take unnecessary efforts to identify them. In this paper, we mainly focus on bug fixing rate, i.e., The proportion of the fixed bugs in the reported closed bugs. In particular, we study the characteristics of bug fixing rate and investigate the impact of a reporter's different contribution behaviors to the bug fixing rate. We perform an empirical study on all reported bugs of two large open source software communities Eclipse and Mozilla. We find (1) the bug fixing rates of both projects are not high, (2) there exhibits a negative correlation between a reporter's bug fixing rate and the average time cost to close the bugs he/she reports, (3) the amount of bugs a reporter ever fixed has a strong positive impact on his/her bug fixing rate, (4) reporters' bug fixing rates have no big difference, whether their contribution behaviors concentrate on a few products or across many products, (5) reporters' bug fixing rates tend to increase as time goes on, i.e., Developers become more experienced at reporting bugs.	bugzilla;eclipse;experiment;hotfix;issue tracking system;open-source software;report;software bug;software development;software project management	Weiqin Zou;Xin Xia;Weiqiang Zhang;Zhenyu Chen;David Lo	2015	2015 IEEE 39th Annual Computer Software and Applications Conference	10.1109/COMPSAC.2015.57	entropy;real-time computing;software bug;security bug;computer science;operating system;empirical research;computer-aided software engineering;software regression;world wide web;correlation	SE	-64.74640454259828	34.825454786591266	163402
72754fea1d843a931d6bbb02378ea2fa9415ca61	a comparative study on vulnerabilities in categories of clones and non-cloned code	cloning software systems measurement maintenance engineering encoding history;clone aware software development noncloned code code clones code smells bug proneness clone free source code program faults software systems;source code software software engineering	Code clones are serious code smells. To investigate bug-proneness of clones as opposed to clone-free source code, earlier attempts have studied the stability of code clones and their contributions to program faults. This paper presents a comparative study on different types of clones and non-cloned code on the basis of their vulnerabilities, which may lead to software defects and issues in future. The empirical study along this new dimension examines source code of 97 software systems and derives results based on quantitative analysis with statistical significance. The findings from this work add to our under-standing of the characteristics and impacts of clones, which can be useful in clone-aware software development and in devising techniques for minimizing the negative impacts of code clones.	code refactoring;code smell;java;open-source software;pradeep tapadiya;qr code;software bug;software development;software system;vulnerability (computing)	Md. R. Islam;Minhaz Fahim Zibran	2016	2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)	10.1109/SANER.2016.90	real-time computing;computer science;software engineering;programming language;code refactoring	SE	-63.454280396989915	35.03604313101452	163658
b42f56d47d120eebce734653ba822946d9c454dd	a scientific evaluation of the misuse case diagrams visual syntax	cognitive evaluation;misuse cases diagrams;visual syntax	ContextMisuse case modeling is a well-known technique in the domain of capturing and specifying functional security requirements. Misuse case modeling provides a mechanism for security analysts to consider and account for security requirements in the early stages of a development process instead of relying on generic defensive mechanisms that are augmented to software systems towards the latter stages of development. ObjectiveMany research contributions in the area of misuse case modeling have been devoted to extending the notation to increase its coverage of additional security related semantics. However, there lacks research that evaluates the perception of misuse case models by its readers. A misread or misinterpreted misuse case model can have dire consequences downstream leading to the development of an insecure system. MethodThis paper presents an assessment of the design of the original misuse case modeling notation based on the Physics of Notations framework. A number of improvements to the notation were suggested. A survey and a controlled experiment were carried out to compare the cognitive effectiveness of the new notation in comparison to the original notation. ResultsThe survey had 55 participants for have mostly indicated that the new notation is more semantically transparent than the original notation. The results of the experiment show that subjects reading diagrams developed using the new notation performed their tasks an average 6min quicker, while in general the subjects performed their tasks in approximately 14.5min. The experimental tasks only required subjects reading diagrams and not creating them. ConclusionThe main finding of this paper is that the use of colors and icons has improved the readability of misuse case diagrams. Software engineering notations are usually black and white. It is expected that the readability of other software notations will improve if they utilize colors and icons.	diagram;misuse case	Faisal Saleh;Mohamed El-Attar	2015	Information & Software Technology	10.1016/j.infsof.2015.05.002	computer science;engineering;artificial intelligence;software engineering;cognitive evaluation theory;database;programming language;algorithm	SE	-65.30171010125008	36.9919780367034	164447
385bc13347e4d6d8ad3edb1505939fd392cc81f4	pushing relevant artifact annotations in collaborative software development	information space;annotations;javadoc;software development;group memory;collaborative software development;pushing;context;tagging	"""Recent techniques show the benefits of attaching community generated knowledge to artifacts in an information space and presenting it to subsequent readers. We argue that such knowledge may also be relevant to the readers of artifacts which link to this target. Such situations are particularly frequent in software development, where a lack of awareness of critical directives associated with an invoked function can lead to costly errors. We describe how eMoose, a group memory-aid for this domain, addresses these problems by visually """"pushing"""" annotated knowledge from invocation targets into the invoking code. Similar techniques could potentially be applied to other development phases and to other domains."""	artifact (software development);collaborative software;software development	Uri Dekel;James D. Herbsleb	2008		10.1145/1460563.1460565	computer science;software development;data mining;management;world wide web;information retrieval	HCI	-71.55451986942347	32.394870004634896	164528
99446d242827555cb976b7729b87774f09aabf4c	differentiation of unknown functions in macsyma	unknown function	Code which handles the differentiation of unknown functions in MACSYMA in a clean way has been written. In this paper we describe this implementation.	macsyma	Jeffrey P. Golden	1985	ACM SIGSAM Bulletin	10.1145/1089402.1089405	computer science;distributed computing;algorithm	OS	-79.9536414954398	34.26841096273881	165504
aaa08a0f01e0953e92ce4a238b48869fba360312	do developers focus on severe code smells?	software metrics software maintenance;empirical study refactoring code smell;severity indicators code smells software refactoring large scale source code maintainability indicators;software java software metrics computer bugs reliability conferences	Code smells are structures in the code that suggestthe possibility of refactoring. To prioritize code smells in large-scale source code, several tools for refactoring calculate theirseverity based on software metrics. Although several metrics are known as maintainability indicators, it is still unclear whether these severity indicators are in line with developer's perception. In this paper, we investigate whether developers focus on severe code smells. The result shows that developers focus on only particular types of severe smells and refactoring do not decrease the severity of code smell significantly.	code refactoring;code smell;god object;java;software metric;software system	Tsubasa Saika;Eunjong Choi;Norihiro Yoshida;Shusuke Haruna;Katsuro Inoue	2016	2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)	10.1109/SANER.2016.117	software security assurance;reliability engineering;software visualization;long-term support;verification and validation;code review;computer science;package development process;software development;software engineering;software construction;software testing;software walkthrough;programming language;software maintenance;code refactoring;software quality;static program analysis;software peer review	SE	-63.69424972022003	34.75773423400208	165519
3ae24613974622f4fc362e89131b390404a2f27e	on the use of hidden markov model to predict the time to fix bugs		A significant amount of time is spent by software developers in investigating bug reports. It is useful to indicate when a bug report will be closed, since it would help software teams to prioritise their work. Several studies have been conducted to address this problem in the past decade. Most of these studies have used the frequency of occurrence of certain developer activities as input attributes in building their prediction models. However, these approaches tend to ignore the temporal nature of the occurrence of these activities. In this paper, a novel approach using Hidden Markov models (HMMs) and temporal sequences of developer activities is proposed. The approach is empirically demonstrated in a case study using eight years of bug reports collected from the Firefox project. We provide additional details below. In a software bug repository, recorded developer activities occur sequentially. For example, activity C (a certain person has been copied on the bug report) is followed by activity A (bug confirmed and assigned to a named developer), which in turn is followed by activity Z (bug reached status resolved). Additional piece of information is developersu0027 level of expertise, such as novice (N), intermediate (M) , or experienced (E) , at the time of report creation. We combine these data together to produce a sequence of temporal activities associated with bug reports in the Firefox bug repository.		Mayy Habayeb;Syed Shariyar Murtaza;Andriy V. Miranskyy;Ayse Basar Bener	2018	IEEE Transactions on Software Engineering	10.1109/TSE.2017.2757480	software bug;predictive modelling;real-time computing;data mining;software;computer science;hidden markov model	SE	-64.51028243898921	35.03651392871534	166628
c070ba9c481ad610d697f421525592fa18e9e0fb	an empirical study of software aging manifestations in android	low memory killer;response time;android;software aging	Software aging phenomenon has been widely observed in Android mobile operating system, which will make a great influence on people's life. In this paper we present an empirical study on the manifestations of aging-related bugs in Android operating system. By conducting a set of experiments through building various aging conditions in Android, we clarify the fact that the aging-related bugs injected in Android are with several manifestation patterns from two angles of view (Users' and System's viewpoints), depending on their location (Dalvik Heap or Native Heap), process priorities (cached, persistent, background, foreground and etc.). To show the new features of software aging in Android, the differences of software aging manifestations between Android and Linux are further explored in this work.	android;experiment;linux;mobile operating system;software aging;software bug	Yu Qiao;Zheng Zheng;Fangyun Qin	2016	2016 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)	10.1109/ISSREW.2016.19	embedded system;simulation;computer science;engineering;operating system;software aging;response time;computer security;android	SE	-65.412631043278	38.15847940926954	167769
526df67d3b432e23b557b0aaf472798aa7f2112e	social network analysis of online marketplaces	email driven electronic contract management system;intra enterprises workflows;internal enterprise workflow;electronic mail;management system;life cycle;life cycle management;ibm pilot programs web based electronic contract management system email driven electronic contract management system security faults intra enterprises workflows internal enterprise workflow multi tenants hosting capability email notifications watermarking signature information life cycle management;contracts;multi tenants hosting capability;electronic mail contracts counting circuits business waste management monitoring security watermarking productivity acceleration;internet;email notifications;internet business data processing contracts electronic mail;business data processing;ibm pilot programs;web based electronic contract management system;security faults;watermarking signature information	This paper presents a preliminary effort on visualization and analysis of social networks for online marketplaces. We use one of the most popular e-business models, eBay, as a case study. By extracting relevant data, we generate tree structure displays using 'Prefuse' interactive visualization toolkit, and study the social interaction among sellers and buyers, across geographical boundaries. We also illustrate how this study can improvise our understanding of online customer interaction patterns. Such an analysis could lead to possible enhancements to the current e-business models.	electronic business;interactive visualization;online marketplace;prefuse;social network analysis;tree structure;vtk	Pushpa Kumar;Kang Zhang	2007	IEEE International Conference on e-Business Engineering (ICEBE'07)	10.1109/ICEBE.2007.27	biological life cycle;contract management;the internet;marketing;operating system;software engineering;management system;database;management;law;world wide web;computer security;product life-cycle management	Visualization	-66.39717257903338	44.77976558830018	167803
46cfa92337ff77089156d278355d1f4d8c366bb6	characterizing verification of bug fixes in two open source ides	quality assurance;empirical study;tracking system;mining software repositories;software computer bugs testing inspection data mining quality assurance software engineering;software verification;exploratory analyses bug fixes open source ide bug repositories software product process quality software verification process eclipse netbeans quality assurance teams mass verifications;program verification;public domain software;empirical study mining software repositories bug tracking systems software verification;program debugging;bug tracking systems;quality assurance program debugging program verification public domain software;open source	Data from bug repositories have been used to enable inquiries about software product and process quality. Unfortunately, such repositories often contain inaccurate, inconsistent, or missing data, which can originate misleading results. In this paper, we investigate how well data from bug repositories support the discovery of details about the software verification process in two open source projects, Eclipse and NetBeans. We have been able do identify quality assurance teams in NetBeans and to detect a well-defined verification phase in Eclipse. A major challenge, however, was to identify the verification techniques used in the projects. Moreover, we found cases in which a large batch of bug fixes is simultaneously reported to be verified, although no software verification was actually done. Such mass verifications, if not acknowledged, threatens analyses that rely on information about software verification reported on bug repositories. Therefore, we recommend that the exploratory analyses presented in this paper precede inferences based on reported verifications.	eclipse;integrated development environment;item unique identification;missing data;netbeans ide;open-source software;operational definition;repository (version control);software bug;software quality assurance;software verification;test automation	Rodrigo R. G. Souza;Christina von Flach G. Chavez	2012	2012 9th IEEE Working Conference on Mining Software Repositories (MSR)	10.1109/MSR.2012.6224301	software security assurance;quality assurance;verification and validation;regression testing;software bug;tracking system;software verification;security bug;computer science;package development process;software development;software engineering;software construction;database;software testing;empirical research;public domain software;software regression;world wide web;software quality;software metric;software quality analyst;software peer review	SE	-65.17150929155751	35.03868348920736	169501
5f54c3c57e3bc3f9821314150f81ee9e18f716b8	performance testing: far from steady state	databases;electronic commerce;testing dp industry electronic commerce internet performance evaluation;performance evaluation;performance test;dp industry;production system;extrapolation;industries;testing;think time variability;load testing tools;system performance;performance testing;think time variability performance testing load testing tools performance emulation;time factors;internet;tuning;single user performance testing industry standard load testing tools it system quality production systems;production systems;single user performance testing;industry standard load testing tools;testing throughput industries time factors databases extrapolation tuning;performance emulation;it system quality;throughput;steady state	The dot com era ushered in a number of industry standard load testing tools. While there is no doubt that these tools have helped improve the quality of IT systems, performance testing in the IT industry is far from steady state. There are still severe gaps between performance test results and production systems performance in IT projects. This paper proposes a number of areas where performance testing needs to improve radically, several of which can be incorporated in to load testing tools. Examples are also provided of simple analytics during single user performance testing to demonstrate the effectiveness of this extra but necessary step in the testing process.	emulator;extrapolation;load testing;production system (computer science);software performance testing;steady state;technical standard;test automation;user research	Rajesh K. Mansharamani;Amol Khanapurkar;Benny Mathew;Rajesh Subramanyan	2010	2010 IEEE 34th Annual Computer Software and Applications Conference Workshops	10.1109/COMPSACW.2010.66	e-commerce;reliability engineering;black-box testing;simulation;software performance testing;performance engineering;white-box testing;computer science;engineering;artificial intelligence;computer performance;production system	SE	-65.28206175545859	39.94516998805545	170128
15aedf2bcffdedfa9b627cebf83ba44dfb4e5cd8	establishing phishing provenance using orthographic features	phishing provenance;unsupervised learning;feature selection techniques phishing provenance orthographic features phishing message detection cybercriminals modified global k mean method;phishing message detection;feature selection techniques;electronic mail;modified global k means;probability density function;k means;computer crime;data mining;objective function;html;feature elimination;clustering;orthographic features;feature extraction;clustering algorithms;feature selection;experimental evaluation;modified global k means clustering feature selection feature elimination;clustering algorithms credit cards uniform resource locators internet computer security information security laboratories informatics information technology reliability engineering;modified global k mean method;cybercriminals	After phishing message detection, determining the provenance of phishing messages and websites is the second step to tracing cybercriminals. In this paper, we present a novel method to cluster phishing emails automatically using orthographic features. In particular, we develop an algorithm to cluster documents and remove redundant features at the same time. After collecting all the possible features based on observation, we adapt the modified global k-mean method repeatedly, and generate the objective function values over a range of tolerance values across different subsets of features. Finally, we identify the appropriate clusters based on studying the distribution of the objective function values. Experimental evaluation of a large number of computations demonstrates that our clustering and feature selection techniques are highly effective and achieve reliable results.	algorithm;cluster analysis;computation;computer cluster;email;feature selection;loss function;newton's method;optimization problem;orthographic projection;phishing	Liping Ma;John Yearwood;Paul A. Watters	2009	2009 eCrime Researchers Summit	10.1109/ECRIME.2009.5342604	computer science;data mining;internet privacy;world wide web	Web+IR	-62.9387582456057	53.646655963840345	170995
ff1670e58bc658d567cef6374df3ccd534d17a7f	surfing the net for software engineering notes		Systems developers have a variety of options when it comes to storing data. From traditional hard disks to magnetic tape and newer static storage devices, a developer faces a complicated set of decisions when determining the best storage technology to use for persistent data storage. Each storage technology offers different levels of performance, reliability, expandability, and complexity of implementation and maintenance. Even when you select a given technology or storage medium, there are additional options that can be applied that affect the total solution. For example, if you select a traditional hard disk storage solution, do you want to RAID your disks and, if so, what RAID level to you need? Does your system need a SAN or a NAS and what’s the difference between the two? This month we’ll take a look as some websites that can help you narrow down the choices for data storage and help explain the pros and cons for some of the various technologies.	complexity;computer data storage;disk storage;hard disk drive;network-attached storage;raid;software engineering notes;software developer;static random-access memory;storage networking industry association;storage area network;wikipedia	Mark Doernhoefer	2011	ACM SIGSOFT Software Engineering Notes	10.1145/2020976.2021010		OS	-68.66913112564872	35.668206558085735	171126
1a79a548e025747b17ac67d9814649a169721123	attribution required: stack overflow code snippets in github projects		Stack Overflow (SO) is the largest Q&A website for developers, providing a huge amount of copyable code snippets. Using these snippets raises various maintenance and legal issues. The SO license requires attribution, i.e., referencing the original question or answer, and requires derived work to adopt a compatible license. While there is a heated debate on SO's license model for code snippets and the required attribution, little is known about the extent to which snippets are copied from SO without proper attribution. In this paper, we present the research design and summarized results of an empirical study analyzing attributed and unattributed usages of SO code snippets in GitHub projects. On average, 3.22% of all analyzed repositories and 7.33% of the popular ones contained a reference to SO. Further, we found that developers rather refer to the whole thread on SO than to a specific answer. For Java, at least two thirds of the copied snippets were not attributed.	java;software repository;stack overflow	Sebastian Baltes;Richard Kiefer;Stephan Diehl	2017	2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C)	10.1109/ICSE-C.2017.99	computer science;empirical research;license;world wide web;software;thread (computing);research design;database;copy and paste programming;attribution;java	SE	-68.26364051667124	35.65278638834804	173338
58bf5fd11d285bba1ef2053b003ed9b89df96a8d	impact of tool support in patch construction		In this work, we investigate the practice of patch construction in the Linux kernel development, focusing on the differences between three patching processes: (1) patches crafted entirely manually to fix bugs, (2) those that are derived from warnings of bug detection tools, and (3) those that are automatically generated based on fix patterns. With this study, we provide to the research community concrete insights on the practice of patching as well as how the development community is currently embracing research and commercial patching tools to improve productivity in repair. The result of our study shows that tool-supported patches are increasingly adopted by the developer community while manually-written patches are accepted more quickly. Patch application tools enable developers to remain committed to contributing patches to the code base. Our findings also include that, in actual development processes, patches generally implement several change operations spread over the code, even for patches fixing warnings by bug detection tools. Finally, this study has shown that there is an opportunity to directly leverage the output of bug detection tools to readily generate patches that are appropriate for fixing the problem, and that are consistent with manually-written patches.		Anil Koyuncu;Tegawendé F. Bissyandé;Dongsun Kim;Jacques Klein;Martin Monperrus;Yves Le Traon	2017		10.1145/3092703.3092713	systems engineering;computer science;debugging;leverage (finance);automation;linux kernel	SE	-65.67817588998368	33.36448775134361	173466
3e6535461fc556d2536de4a308c40617cf47a182	estimating the survival rate of mutants		Mutation testing is often used to assess the quality of a test suite by analyzing its ability to distinguish between a base program and its mutants. The main threat to the validity/ reliability of this assessment approach is that many mutants may be syntactically distinct from the base, yet functionally equivalent to it. The problem of identifying equivalent mutants and excluding them from consideration is the focus of much recent research. In this paper we argue that it is not necessary to identify individual equivalent mutants and count them; rather it is sufficient to estimate their number. To do so, we consider the question: what makes a program prone to produce equivalent mutants? Our answer is: redundancy does. Consequently, we introduce a number of program metrics that capture various dimensions of redundancy in a program, and show empirically that they are statistically linked to the rate of equivalent mutants. 1 EQUIVALENT MUTANTS Mutation testing is typically used to assess the effectiveness of test suites, by analyzing to what extent a test suite T can distinguish between a base program P and a set of mutants thereof, say P1, P2, ... PN (Debroy and Wong, 2010; Debroy and Wong, 2013; V. and W.E., 2010; Ma et al., 2005; Zemı́n et al., 2015). A recurring source of aggravation in mutation testing is the presence of equivalent mutants: some mutants may be syntactically distinct from the base program, yet be functionally indistinguishable from it (i.e. compute the same function). Equivalent mutants distort the analysis of the test suite’s effectiveness, because when a test suite fails to distinguish a mutant Pi from the base program P, we do not know whether this is because Pi is equivalent to P, or because T is not sufficiently effective at detecting faults. Ideally, we want to quantify the effectiveness of a test suite T , not by the ratio of the mutants it distinguishes over the total number of mutants (N), but rather by the ratio of the mutants it distinguishes over the number of non-equivalent (distinguishable) mutants. Many researchers (Aadamopoulos et al., 2004; Papadakis et al., 2014; Schuler and Zeller, 2010; Just et al., 2013; Nica and Wotawa, 2012) have addressed this problem by proposing means to identify (and exclude from consideration) mutants that are equivalent to the base program. In this paper, we propose an alternative approach, which does not seek to identify which mutants are equivalent to the base, but merely to estimate their number. To do so, we consider the research question (RQ3) raised by Yao et al (Yao et al., 2014): What are the causes of mutant equivalence? Our answer: Redundancy in the program. Consequently, we define a number of software metrics that capture various forms of redundancy, discuss why we believe they are prone to produce equivalent mutants, then run an experiment that appears to bear out conjecture out. This is work in progress; we are fairly confident that our analytical arguments are sound, and we are encouraged by the preliminary empirical results. Following common usage, we say that a mutant has been killed by a test data set T if and only if execution of the mutant on T exhibits a distinct behavior from the original program P; consequently, when a mutant goes through test data T and shows the same behavior as P, we say that it has survived the test. Also, we use the term survival rate of a program P to designate the ratio (or percentage) of mutants of P that are found to survive the execution of test data T . For the purpose of our study, we use the semantic metrics introduced in (Mili et al., 2014), which we briefly review in section 2. In section 3 we discuss why we feel that the semantic metrics introduced in section 2 are good indicators of the number of potentially equivalent mutants that a program P may yield.	distortion;mutation testing;redundancy (engineering);sensor;software metric;test data;test suite;turing completeness;word lists by frequency;yao graph	Imen Marsit;Mohamed Nazih Omri;Ali Mili	2017		10.5220/0006392802080213	computer science;data mining;mutant;survival rate;bioinformatics	SE	-63.663539475678505	36.744418119206706	175403
680de0b6c9d5d2b1037028aefd32668fd094a384	using supervised learning to guide the selection of software inspectors in industry		Software development is a multi-phase process that starts with requirement engineering. Requirements elicited from different stakeholders are documented in natural language (NL) software requirement specification (SRS) document. Due to the inherent ambiguity of NL, SRS is prone to faults (e.g., ambiguity, incorrectness, inconsistency). To find and fix faults early (where they are cheapest to find), companies routinely employ inspections, where skilled inspectors are selected to review the SRS and log faults. While other researchers have attempted to understand the factors (experience and learning styles) that can guide the selection of effective inspectors but could not report improved results. This study analyzes the reading patterns (RPs) of inspectors recorded by eye-tracking equipment and evaluates their abilities to find various fault-types. The inspectors' characteristics are selected by employing ML algorithms to find the most common RPs w.r.t each fault-types. Our results show that our approach could guide the inspector selection with an accuracy ranging between 79.3% and 94% for various fault-types.	algorithm;artificial neural network;correctness (computer science);eye tracking;fault reporting;information;nl (complexity);natural language;neural networks;radio frequency;requirement;requirements engineering;software development;software inspection;supervised learning	Maninder Singh;Gursimran Singh Walia;Anurag Goswami	2018	2018 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)	10.1109/ISSREW.2018.00-38	data mining;supervised learning;reliability engineering;computer science;software;ambiguity;requirements engineering;software requirements specification;statistical classification;software development;ranging	SE	-64.71834722145547	33.050126705760505	175554
0da3dc21d84f7e5c0d0972e2a7854acc2286838a	universal personal communications: emergence of a paradigm shift in the communications industry	transportation networks;hierarchical structure;regulatory policy;emerging technology;universal service;customer value;paradigm shift;community networks;mobility management;communication service	It is postulated that today we are in the midst of a major paradigm shift in the communications industry. The essence of this paradigm shift is a transition from today's universal telephone service which has been perfected over the past 100 years, to a future communication service environment, referred to as universal personal communication. Under this new paradigm, communications will be person based in contrast to the predominantly location-based communication environment of today. Societal trends, evolving global standards for communication, regulatory policies, and emergent technologies are seen as the forces driving such a transition. Universal personal communications will be characterized by flexible access to universal services permittingmore enduser control which will result in personalization and customization of such services. Furthermore, the centralized intelligence focus of today's communication networks needs to evolve toward a focus where network intelligence can be migrated to the periphery of the core transport network. The viability of universal personal communication will be critically dependent upon how well it addresses the end customer value proposition. Two key elements of this proposition are transparency of mobility and personalization of service environments. A zonal service environment model which classifies and characterizes these various service environments in terms of common communication parameters is proposed. This model is built around hierarchical structures for both cellular and digital wireless transmission, and can be viewed as critical towards the realization of transparent mobility management and personalization of services.	emergence;programming paradigm	J. E. Russell	1994	IJWIN	10.1007/BF02107415	paradigm shift;simulation;personal communications service;telecommunications;computer science;knowledge management;emerging technologies;computer network	Robotics	-69.96440142774185	41.203442791309946	176081
f8efba4e7232850e233a263f6e78b8d57e71d30d	standard error classification to support software reliability assessment	standard error;difference scheme;software development;software reliability	A standard software error classification is viable based on experimental use of different schemes on Hughes-Fullerton projects. Error classification schemes have proliferated independently due to varied emphasis on depth of casual trace-ability and when error data was collected. A standard classification is proposed that can be applied to all phases of software development. It includes a major casual category for design errors. Software error classification is a prerequisite both for feedback for error prevention and detection, and for prediction of residual errors in operational software.	software bug;software development;software quality;software reliability testing	John B. Bowen	1980		10.1145/1500518.1500638	reliability engineering;software sizing;computer science;software reliability testing;data mining;software metric;statistics	SE	-63.7696101217312	32.35009083723394	176972
461a137a2d54d75dc234fee48b065e29234fb08f	how we refactor, and how we know it	measurement tool;software tool;refactoring;history;java software tools refactoring;tool support;software maintenance;bepress selected works;refactoring tools;computer software development software refactoring;arrays;research and development;mylyn developers research and development refactoring tools randomly sampled code eclipse developers;software tools;root canal refactoring;version control;software tools software maintenance;floss refactoring;root canal;java;root canal refactoring refactoring refactoring tools floss refactoring	Refactoring is widely practiced by developers, and considerable research and development effort has been invested in refactoring tools. However, little has been reported about the adoption of refactoring tools, and many assumptions about refactoring practice have little empirical support. In this paper, we examine refactoring tool usage and evaluate some of the assumptions made by other researchers. To measure tool usage, we randomly sampled code changes from four Eclipse and eight Mylyn developers and ascertained, for each refactoring, if it was performed manually or with tool support. We found that refactoring tools are seldom used: 11 percent by Eclipse developers and 9 percent by Mylyn developers. To understand refactoring practice at large, we drew from a variety of data sets spanning more than 39,000 developers, 240,000 tool-assisted refactorings, 2,500 developer hours, and 12,000 version control commits. Using these data, we cast doubt on several previously stated assumptions about how programmers refactor, while validating others. Finally, we interviewed the Eclipse and Mylyn developers to help us understand why they did not use refactoring tools and to gather ideas for future research.	code refactoring	Emerson R. Murphy-Hill;Chris Parnin;Andrew P. Black	2012	IEEE Trans. Software Eng.	10.1109/TSE.2011.41	computer science;revision control;systems engineering;software engineering;programming language;software maintenance;java;code refactoring	SE	-64.81278080090983	34.06164539356511	176988
eef9f75fb23b678b0573149e633098cbbc403309	using the city metaphor for visualizing test-related metrics	measurement urban areas visualization software buildings data visualization software engineering;city metaphor software testing visualization;code quality city metaphor test related metrics visualization software visualization techniques codemetropolis minecraft game engine source code virtual city code metrics code elements;source code software computer games program testing software metrics software quality	Software visualization techniques and tools play an important role in system comprehension efforts of software developers in the era of increasing code size and complexity. They enable the developer to have a global perception on various software attributes with the aid of different visualization metaphors and tools. One such tool is CodeMetropolis which is built on top of the game engine Minecraft and which uses the city metaphor to show the structure of the source code as a virtual city. In it, different physical properties of the city and the buildings are related to various code metrics. Up to now, it was limited to represent only code related artifacts. In this work, we extend the metaphor to include properties of the tests related to the program code using a novel concept. The test suite and the test cases are also associated with a set of metrics that characterize their quality (such as coverage and specialization), but also reveal new properties of the system itself. In a new version of CodeMetropolis, gardens representing code elements will give rise to outposts that characterize properties of the tests and show how they contribute to the quality of the code.	artifact (software development);experiment;fault coverage;game engine;minecraft;partial template specialization;software developer;software metric;software visualization;test case;test suite;virtual world	Gergõ Balogh;Tamás Gergely;Árpád Beszédes;Tibor Gyimóthy	2016	2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)	10.1109/SANER.2016.48	kpi-driven code analysis;software visualization;verification and validation;simulation;computer science;package development process;social software engineering;theoretical computer science;software framework;software development;software engineering;software construction;software testing;software walkthrough;software analytics;software deployment;imagix 4d;software quality;static program analysis;software system	SE	-63.76126210739333	33.37926933628069	177013
230d4b4485201598878f81d0a965a225b77a2ece	bad words: finding faults in spirit's syslogs	syslogs;system monitoring;software fault tolerance;system monitoring entropy linux software fault tolerance;linux cluster;spirit linux cluster;spirit linux cluster bad words syslogs fault detection false positive rate information entropy;false positive rate;fault detection;bad words;linux;entropy;information entropy;programming profession fault detection humans clustering algorithms grid computing laboratories usa councils computer science supercomputers monitoring;information theoretic	"""Accurate fault detection is a key element of resilient computing. Syslogs provide key information regarding faults, and are found on nearly all computing systems. Discovering new fault types requires expert human effort, however, as no previous algorithm has been shown to localize faults in time and space with an operationally acceptable false positive rate. We present experiments on three weeks of syslogs from Sandia's 512-node """"Spirit"""" Linux cluster, showing one algorithm that localizes 50% of faults with 75% precision, corresponding to an excellent false positive rate of 0.05%. The salient characteristics of this algorithm are (1) calculation of nodewise information entropy, and (2) encoding of word position. The key observation is that similar computers correctly executing similar work should produce similar logs."""	algorithm;computation;computer cluster;entropy (information theory);experiment;fault detection and isolation;linux;supercomputer	Jon Stearley;Adam J. Oliner	2008	2008 Eighth IEEE International Symposium on Cluster Computing and the Grid (CCGRID)	10.1109/CCGRID.2008.107	system monitoring;entropy;real-time computing;computer cluster;false positive rate;computer science;syslog;theoretical computer science;operating system;database;distributed computing;linux kernel;fault detection and isolation;software fault tolerance;entropy	Arch	-62.931914997068105	41.0839987614669	177347
cae33591423f0656144caea1280aabf8dcee6a9e	a clustering approach to improving test case prioritization: an industrial case study	pattern clustering;industrial case study;regression testing;complexity theory;history;measurement;costing;software systems;software fault tolerance;microsoft dynamics ax clustering approach test case prioritization industrial case study regression testing quality control software cost data correlation fault detection software repository code coverage code complexity industrial software product;testing;test case prioritization tecniques;industrial case study regression testing test case prioritization tecniques clustering approach;program testing;fault detection;clustering approach;regression analysis;statistical testing;statistical testing costing pattern clustering program testing quality control regression analysis software fault tolerance software quality;quality control;software quality;testing complexity theory history fault detection measurement software systems	Regression testing is an important activity for controlling the quality of a software product, but it accounts for a large proportion of the costs of software. We believe that an understanding of the underlying relationships in data about software systems, including data correlations and patterns, could provide information that would help improve regression testing techniques. We conjecture that if test cases have common properties, then test cases within the same group may have similar fault detection ability. As an initial approach to investigating the relationships in massive data in software repositories, in this paper, we consider a clustering approach to help improve test case prioritization. We implemented new prioritization techniques that incorporate a clustering approach and utilize code coverage, code complexity, and history data on real faults. To assess our approach, we have designed and conducted empirical studies using an industrial software product, Microsoft Dynamics Ax, which contains real faults. Our results show that test case prioritization that utilizes a clustering approach can improve the effectiveness of test case prioritization techniques.	cluster analysis;code coverage;data mining;fault detection and isolation;microsoft dynamics ax;programming complexity;regression testing;software metric;software repository;software system;source lines of code;test case	Ryan Carlson;Hyunsook Do;Anne M. Denton	2011	2011 27th IEEE International Conference on Software Maintenance (ICSM)	10.1109/ICSM.2011.6080805	reliability engineering;statistical hypothesis testing;quality control;regression testing;test data generation;computer science;systems engineering;engineering;software engineering;data mining;software testing;test management approach;fault detection and isolation;software quality;software fault tolerance;activity-based costing;regression analysis;measurement;software system	SE	-62.948854617388875	33.51452891088862	177637
4a30acd5e13c87898c095ac4b2766ecd5b3c0821	how software developers use work breakdown relationships in issue repositories	software;manuals;information retrieval;contextual information;electric breakdown;software engineering;automatic crash reporting;logic gates;guidelines;deduplication;call stack trace;duplicate crash report;duplicate bug reports;free open source software;encoding;computer bugs	Software developers use issues as a means to describe a range of activities to be undertaken on a software system, including features to be added and defects that require fixing. When creating issues, software developers expend manual effort to specify relationships between issues, such as one issue blocking another or one issue being a sub-task of another. In particular, developers use a variety of relationships to express how work is to be broken down on a project. To better understand how software developers use work breakdown relationships between issues, we manually coded a sample of work breakdown relationships from three open source systems. We report on our findings and describe how the recognition of work breakdown relationships opens up new ways to improve software development techniques.	blocking (computing);open-source software;software developer;software development process;software system	C. Albert Thompson;Gail C. Murphy;Marc Palyart;Marko Gasparic	2016	2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR)	10.1145/2901739.2901779	software bug;data deduplication;logic gate;computer science;engineering;operating system;software engineering;data mining;database;programming language;world wide web;encoding	SE	-62.85443162959755	37.050697721061645	179470
69bcb13fca53d806dc80c443b2f9f6d12633f70b	quantitative cyber risk reduction estimation methodology for a small scada control system	scada;control systems;general and miscellaneous mathematics computing and information science;probability;risk analysis;targets control system;risk management;risk management control systems computer security risk analysis hidden markov models probability scada systems data security system testing laboratories;risk reduction;cyber security;computer security;control system;hidden markov models;directed graph;remedial action;time to compromise;scada system;system testing;scada systems;security;99 general and miscellaneous mathematics computing and information science;data security	We propose a new methodology for obtaining a quantitative measurement of the risk reduction achieved when a control system is modified with the intent to improve cyber security defense against external attackers. The proposed methodology employs a directed graph called a compromise graph, where the nodes represent stages of a potential attack and the edges represent the expected time-to-compromise for differing attacker skill levels. Time-to-compromise is modeled as a function of known vulnerabilities and attacker skill level. The methodology was used to calculate risk reduction estimates for a specific SCADA system and for a specific set of control system security remedial actions. Despite an 86% reduction in the total number of vulnerabilities, the estimated time-to-compromise was increased only by about 3 to 30% depending on target and attacker skill level.	average-case complexity;computer security;control system security;directed graph;vulnerability (computing)	Miles A. McQueen;Wayne F. Boyer;Mark A. Flynn;George A. Beitel	2006	Proceedings of the 39th Annual Hawaii International Conference on System Sciences (HICSS'06)	10.1109/HICSS.2006.405	computer science;control system;data mining;database;world wide web;computer security;scada	EDA	-63.48782625732408	60.26187591214884	179716
27f610438576339100024fc8f6c6156f8131507c	middleware – software support in items identification by using the uhf rfid technology		This article deals with RFID technology, which is a part of automatic identification and data capture. Nowadays, the identification of items in logistic sector is carried through barcodes. In this article we would like to specify, how items can be located in metal container, identified in the transmission process of logistics chain by UHF RFID technology. All results are verified by measurement in our AIDC laboratory, which is located at the University of Žilina. Our research contains of 12 different types of orientation tags and antennas and more than 1000 tests. Our identification performance was close to 100 %. All tested items have been located in metal container. The results of our research bring the new point of view and indicate the ways of using UHF RFID technology in logistic applications. The utilization of the RFID technology in logistics chain is characterized at the end of this article.		Peter Kolarovszki;Juraj Vaculík	2013		10.1007/978-3-319-11569-6_28	embedded system;operating system;world wide web	Mobile	-66.17528465934812	47.10854450287763	179850
3850b642ca042607e698628d4d1c2cbe49416e26	program comprehension techniques improve software inspections: a case study	program understanding;program diagnostics;program comprehension;inspection computer aided software engineering software performance costs programming software maintenance software measurement software testing data privacy;training;inspection;computer science education reverse engineering inspection program debugging program diagnostics training;computer science education;cost effectiveness;program debugging;software inspection;peer reviews program comprehension techniques software inspections case study cost effective mechanism software defect removal customer discovered defects training perceived deficiencies formal measures informal measures program understanding effectiveness formal technical reviews;reverse engineering	Software inspections are widely regarded as a costeffective mechanism for removing defects in software, though performing them does not always reduce the number of customer-discovered defects. We present a case study in which an attempt was made to reduce such defects through inspection training that introduced program comprehension ideas. The training was designed to address the problem of understanding the artifact being reviewed, as well as other perceived deficiencies of the inspection process itself. Measures, both formal and informal, suggest that explicit training in program understanding may improve inspection effectiveness.	list comprehension;program comprehension;software inspection	Stan Rifkin;Lionel E. Deimel	2000		10.1109/WPC.2000.852487	reliability engineering;personal software process;verification and validation;cost-effectiveness analysis;software engineering process group;fagan inspection;inspection;computer science;systems engineering;engineering;package development process;social software engineering;software development;operating system;software engineering;software construction;software inspection;software testing;software technical review;software walkthrough;software maintenance;software deployment;reverse engineering;software metric;static program analysis;software system;software peer review	SE	-64.35038577513629	32.474803448561005	180334
53b50b69c45d7b84467a7ec3a7c3fbe9589318fb	computing and diagnosing changes in unit test energy consumption	004;energy oracles	We present a tool that, using a team's existing test cases, performs repeated measurements of energy consumption based on instructions executed, objects generated, and blocking latency, generating a distribution of energy use estimates for each test run, recording these distributions in a time series of distributions over time. Then, when these distributions change substantially, we inform the developer of this change, and offer them diagnostic information about the elements of their code potentially responsible for the change and the inputs responsible. Through this information, we believe that developers will be better enabled to relate recent changes in their code to changes in energy consumption, enabling them to better incorporate changes in software energy consumption into their software evolution decisions.	blocking (computing);software evolution;test case;time series;unit testing;wiki	Andrew Jensen Ko;Michal Young;James H. Andrews;Brian P. Robinson;Mark Grechanik	2010			real-time computing;simulation;computer science;operations management	SE	-63.718419732304426	38.55359797236112	180793
e243bf52e5571ea58fc256ea2c8d2f2cdbf7e4a0	applying and evaluating concern-sensitive design heuristics	software metrics;empirical study;aspect oriented software development;false negative;design evaluation;crosscutting concerns;aspect oriented;modularity;false positive;software design;design heuristics	Manifestation of crosscutting concerns in software systems is often an indicative of design modularity flaws and further design instabilities as those systems evolve. Without proper design evaluation mechanisms, the identification of harmful crosscutting concerns can become counter-productive and impractical. Nowadays, metrics and heuristics are the basic mechanisms to support their identification and classification either in object-oriented or aspect-oriented programs. However, conventional mechanisms have a number of limitations to support an effective identification and classification of crosscutting concerns in a software system. In this paper, we claim that those limitations are mostly caused by the fact that existing metrics and heuristics are not sensitive to primitive concern properties, such as either their degree of tangling and scattering or their specific structural shapes. This means that modularity assessment is rooted only at conventional attributes of modules, such as module cohesion, coupling and size. This paper proposes a representative suite of concern-sensitive heuristic rules. The proposed heuristics are supported by a prototype tool. The paper also reports an exploratory study to evaluate the accuracy of the proposed heuristics by applying them to seven systems. The results of this exploratory analysis give evidences that the heuristics offer support for: (i) addressing the shortcomings of conventional metrics-based assessments, (ii) reducing the manifestation of false positives and false negatives in modularity assessment, (iii) detecting sources of design instability, and (iv) finding the presence of design modularity flaws in both object-oriented and aspect-oriented programs. Although our results are limited to a number of decisions we made in this study, they indicate a promising research direction. Further analyses are required to confirm or refute our preliminary findings and, so, this study should be seen as a stepping stone on understanding how concerns can be useful assessment abstractions. We conclude this paper by discussing the limitations of this exploratory study focusing on some situations which hinder the accuracy of concern-sensitive heuristics.		Eduardo Figueiredo;Cláudio Sant'Anna;Alessandro F. Garcia;Carlos José Pereira de Lucena	2012	Journal of Systems and Software	10.1016/j.jss.2011.09.060	reliability engineering;aspect-oriented programming;type i and type ii errors;computer science;systems engineering;engineering;software design;software engineering;heuristics;data mining;modularity;empirical research;software metric	EDA	-63.093636763998695	35.31953821800597	183485
0daa2ce07463f0f243374187cddaa2a5d55a5961	exploring theory of cognition for general theory of software engineering	computers;computer languages;programming language;general theory of software engineering;ada programming language;theory of cognitions;program comprehension;computer and information science;cognitive theory;production computer languages assembly software engineering cognition computers predictive models;software engineering;assembly program cognition theory software engineering act r programming language comprehension c program;assembly;natural sciences;theoretical modeling;act r;programming theory;computer programming languages;cognition;production;predictive models;language comprehensions;c programming language;computational linguistics;general theory;comprehension tasks;program assemblers assembly language c language cognitive systems;program comprehension act r programming language general theory of software engineering	In recent years, there has been significant interest in general theories of software engineering. In this article, we explore the utility of a theory of cognition, ACT-R, as a component of such a general theory. The ACT-R theory was instantiated to predict the effort of programming language comprehension for two cases: (i) a C program, and (ii) the corresponding Assembly program. An experiment was then conducted to generate empirical data on the two comprehension tasks. The theoretical predictions were compared to the empirical results.  The theoretical model predicted that the effort of understanding the considered program in C is 37% of the effort of understanding a comparable program written in Assembly. The experiment generated 33% as the corresponding percentage number. The concordance between theoretical model and experimental data was surprisingly high, encouraging further investigations into the utility of cognitive theories in software engineering.	act-r;assembly language;cognition;concordance (publishing);programming language;software engineering;theory	Pontus Johnson;Mathias Ekstedt	2015	2015 IEEE/ACM 4th SEMAT Workshop on a General Theory of Software Engineering	10.1109/GTSE.2015.9	natural language processing;computer science;programming language	SE	-68.31405940701306	32.54128225038636	184889
afabbd5abb2e1858f12849720bed06d36524545d	the effectiveness of software metrics in identifying error-prone classes in post-release software evolution process	empirical study;object oriented metrics;class error proneness;software evolution;software metric;prediction model;error severity categories;design evolution;open source software;open source	Many empirical studies have found that software metrics can predict class error proneness and the prediction can be used to accurately group error-prone classes. Recent empirical studies have used open source systems. These studies, however, focused on the relationship between software metrics and class error proneness during the development phase of software projects. Whether software metrics can still predict class error proneness in a system's post-release evolution is still a question to be answered. This study examined three releases of the Eclipse project and found that although some metrics can still predict class error proneness in three error-severity categories, the accuracy of the prediction decreased from release to release. Furthermore, we found that the prediction cannot be used to build a metrics model to identify error-prone classes with acceptable accuracy. These findings suggest that as a system evolves, the use of some commonly used metrics to identify which classes are more prone to errors becomes increasingly difficult and we should seek alternative methods (to the metric-prediction models) to locate error-prone classes if we want high accuracy.	cognitive dimensions of notations;software evolution;software metric	Raed Shatnawi;Wei Li	2008	Journal of Systems and Software	10.1016/j.jss.2007.12.794	reliability engineering;computer science;systems engineering;software evolution;software engineering;data mining;predictive modelling;empirical research;software metric	SE	-64.05348517514143	34.60800800261698	185810
bf2256adafe536f70cc1606013853e79330e4fb5	exploring decision drivers on god class detection in three controlled experiments	empirical study;god class;controlled experiment;code smell;decision drivers	"""Context: Code smells define potential problems in design of software. However, some empirical studies on the topic have shown findings in opposite direction. The misunderstanding is mainly caused by lack of works focusing on human role on code smell detection. Objective: Our aim is to build empirical support to exploration of the human role on code smell detection. specifically, we investigated what issues in code make a human identify a class as a code smell. We called these issues decision drivers. Method: We performed a controlled experiment and replicated it twice. We asked participants to detect god class (one of the most known smell) on different software, indicating what decision drivers they adopted. Results: The stronger drivers were """"class is high complex"""" and """"method is misplaced"""". We also found the agreement on drivers' choice is low. Another finding is: some important drivers are dependent of alternative support. In our case, """"dependency"""" was an important driver only when visual resources were permitted. Conclusion: This study contributes with the comprehension of the human role on smell detection through the exploration of decision drivers. This perception contributes to characterize what we called the """"code smell conceptualization problem""""."""	code smell;conceptualization (information science);experiment;god object;list comprehension	José Amancio M. Santos;Manoel G. Mendonça	2015		10.1145/2695664.2695682	simulation;computer science;programming language;empirical research;computer security;god object;code smell	SE	-64.63458799141156	35.642875482657786	186595
54e85ba897f5d0ab88898536367780083579dd96	do code smells reflect important maintainability aspects?	code smells maintainability evaluation;expert systems;measurement;software maintenance;maintenance engineering;software maintenance expert systems java;interviews;encoding;maintenance engineering interviews java software maintenance measurement encoding;java systems code smells design flaws code maintainability expert based maintainability assessments;maintainability evaluation;java;code smells	Code smells are manifestations of design flaws that can degrade code maintainability. As such, the existence of code smells seems an ideal indicator for maintainability assessments. However, to achieve comprehensive and accurate evaluations based on code smells, we need to know how well they reflect factors affecting maintainability. After identifying which maintainability factors are reflected by code smells and which not, we can use complementary means to assess the factors that are not addressed by smells. This paper reports on an empirical study that investigates the extent to which code smells reflect factors affecting maintainability that have been identified as important by programmers. We consider two sources for our analysis: (1) expert-based maintainability assessments of four Java systems before they entered a maintenance project, and (2) observations and interviews with professional developers who maintained these systems during 14 working days and implemented a number of change requests.	change request;code refactoring;code smell;java;need to know;programmer;software maintainer;static program analysis	Aiko Fallas Yamashita;Leon Moonen	2012	2012 28th IEEE International Conference on Software Maintenance (ICSM)	10.1109/ICSM.2012.6405287	maintenance engineering;reliability engineering;interview;computer science;systems engineering;engineering;software engineering;programming language;software maintenance;java;maintainability;code smell;encoding;measurement	SE	-63.91094310769193	34.740223190028196	187874
e823608ac5092b5ea32e145a8851f1857afbe426	software implementation of a secure socket layer (ssl) accelerator based on kernel thread	tecnologia electronica telecomunicaciones;apache;ssl accelerator;kernel thread;web server;tecnologias;grupo a		ssl acceleration;thread (computing);transport layer security	Euiseok Nahm;Byungjo Min;Jin Bae Park;Hagbae Kim	2004	IEICE Transactions		embedded system;computer science;operating system;ssl acceleration;world wide web;web server	Security	-91.25207539246153	35.36554405585382	188064
8ddcef6a72ac97f1891f10e149ebcbe344ef0724	the peek measurement program	computer program;measurement;metric;programme peek;medida;mesure;program complexity;metrique;programme ordinateur;complexite programme	A computer program called PEEK has been written to measure PL/I computer programs. The PEEK system makes three types of measurements of PL/I programs. PEEK measures (1) basic statistics, (2) cyclomatic complexity, and (3) software science metrics. Each of these types of measures gives a different insight into the nature of the particular computer program that is measured. The PEEK program has been developed as the central tool for doing a set of experiments in program measurement. Future versions of PEEK may be tailored as tools for developing and maintaining computer programs.	computer program;cyclomatic complexity;experiment;pl/i;peek	James L. Elshoff	1984	SIGMETRICS Performance Evaluation Review	10.1145/1041831.1041835	simulation;metric;measurement	SE	-67.60563232678464	33.13984475212555	188492
c8eb4de02f0614969f9e1681b8125deeb0060fd4	a taxonomy and an initial empirical study of bad smells in code	empirical study;refactoring;software maintenance;software performance evaluation;software maintenance program compilers object oriented programming software quality software performance evaluation;taxonomy software maintenance software systems software quality programming internet software measurement cloning visualization logic;object oriented programming;software engineering;correlations taxonomy empirical study bad code smells code quality software quality object oriented context;taxonomy;program compilers;subjective evaluation;software quality;bad smells in code	This paper presents research in progress, as well as tentative findings related to the empirical study of so called bad code smells. We present a taxonomy that categorizes similar bad smells. We believe the taxonomy makes the smells more understandable and recognizes the relationships between smells. Additionally, we present our initial findings from an empirical study of the use of the smells for evaluating code quality in a small Finnish software product company. Our findings indicate that the taxonomy for the smells could help explain the identified correlations between the subjective evaluations of the existence of the smells.	code smell;evolutionary taxonomy;software quality	Mika Viking Mäntylä;Jari Vanhanen;Casper Lassenius	2003		10.1109/ICSM.2003.1235447	reliability engineering;verification and validation;software sizing;computer science;engineering;social software engineering;software framework;software development;software engineering;software construction;solid;programming language;object-oriented programming;empirical research;software maintenance;code refactoring;software quality;code smell;taxonomy	SE	-63.62012383874476	34.703836613052104	190837
2e70c8298805d81abf814bc29ca7b65434dd2bf0	an empirical study of adoption of software testing in open source projects	development team size;software;project development characteristics;software testing;empirical study;computer languages;bug finding;project management;bug reporters;bepress selected works;software quality program debugging program testing programming languages project management public domain software;open source projects;test cases;software computer bugs correlation software testing computer languages writing;public domain software;test cases empirical study software testing adequacy;program testing;software development efforts;programming languages software testing open source projects software development efforts software quality systems bug finding error finding software projects test case correlation project development characteristics project size development team size bug reporters;software projects;empirical study software testing adequacy test cases;writing;adequacy;error finding;program debugging;correlation;project size;computer bugs;test case correlation;software quality;programming languages;software quality systems	Testing is an indispensable part of software development efforts. It helps to improve the quality of software systems by finding bugs and errors during development and deployment. Huge amount of resources are spent on testing efforts. However, to what extent are they used in practice? In this study, we investigate the adoption of testing in open source projects. We study more than 20,000 non-trivial software projects and explore the correlation of test cases with various project development characteristics including: project size, development team size, number of bugs, number of bug reporters, and the programming languages of these projects.	ansi c;altered level of consciousness;c++;open-source software;php;programming language;software bug;software deployment;software development;software metric;software system;software testing;test case;test suite	Pavneet Singh Kochhar;Tegawendé F. Bissyandé;David Lo;Lingxiao Jiang	2013	2013 13th International Conference on Quality Software	10.1109/QSIC.2013.57	test strategy;project management;development testing;long-term support;verification and validation;team software process;software bug;crowdsourcing software development;system integration testing;software project management;computer science;systems engineering;engineering;acceptance testing;package development process;software development;software engineering;software construction;software testing;programming language;empirical research;writing;public domain software;test case;correlation;software development process;software quality;software quality analyst	SE	-64.11621035043314	33.49682651014577	190922
87139a67cb821b25e83414694f5b8d39b14c66a3	predicting function changes by mining revision history	databases;atomic measurements;modeling and prediction measurement;history;measurement;software measurement;software maintenance;information technology;software systems;maintenance engineering;data mining;software engineering;functional dependency;software engineering data analysis data mining;revision history mining;data analysis;hybrid approach;postgresql database;impact analysis;function history;programming profession;software development;performance analysis;modeling and prediction;predictive models;source code;function dependency;history software maintenance databases information technology computer science data mining performance analysis software systems programming profession predictive models;computer science;change propagation;postgresql database function change prediction revision history mining software development impact analysis data mining function dependency function history;function change prediction;open source	Software is consistently changing and evolving to new circumstances. Modifications to software do not always involve changes to a single, well-encapsulated module. Software developers are often faced with modification task that involve changes to source code artifacts such as function and comments that are spread across the code base. Developer must ensure that related entities are updated accordingly to be consistent with changes. In this paper, we propose hybrid approach that combines the best of data mining and impact analysis techniques to improve the overall performance (precision and recall) of change propagation heuristics. Our aim is to investigate the Function co-change in large software systems over period of time by utilizing various heuristics such as Function dependencies and History. It is not always every heuristic is good predictor for each entity. Therefore, we augment our effort to provide recommendations to programmers based on the prediction of heuristics that are best for entity needed to be changed. In this paper, we identify the best performing change propagation heuristic based on empirical case study, using a large open source system PostgreSQL database. This database consists of 31,000 functions and 1,493 files over the period of 12 years.	belief revision;data mining;entity;heuristic (computer science);kerrison predictor;open-source software;postgresql;precision and recall;programmer;software developer;software propagation;software system	Haroon Malik;Elhadi M. Shakshuki	2010	2010 Seventh International Conference on Information Technology: New Generations	10.1109/ITNG.2010.19	maintenance engineering;computer science;artificial intelligence;data science;software development;software engineering;machine learning;data mining;database;predictive modelling;functional dependency;data analysis;software maintenance;software measurement;information technology;measurement;software system;source code	SE	-63.437487791206884	34.541803962577404	190949
bef10af6ca29e2133ceb90fc363863364f2102a3	attributes that predict which features to fix: lessons for app store mining		Requirements engineering is assessed as the most important phase of the software development process. This process is especially challenging for app developers, who tend to gather crowd-based feedback after releasing their apps. This feedback is often voluminous, posing prioritization challenges for developers identifying features to fix or add. While previous work has identified frequently mentioned features, and some effort has been dedicated towards providing various prioritization and classification techniques, these do not quite address the prioritization challenge faced by app developers given voluminous app reviews. In fact, there is also need to assess the scale of app reviews' usefulness. We use content analysis and regression to contribute towards this cause by exploring the usefulness of app reviews, and the attributes that predict which app features to fix, respectively. Our outcomes show that reviews tended to either provide information of little value (i.e., no actionable information) or highlighted problems that may directly affect the functionality of app features. For two different apps, we also observe that features that were mentioned the most (the feature frequency attribute) in lower ranked reviews provided by users had the strongest predictive power for identifying severely broken features (as perceived by a developer). However, the ordering did not match with the frequency with which reports were made by users. There were also variances in the attributes that predict which features to fix, for the reviews of different apps. Review mining and prioritization challenges remain given variances in app reviews' content and structure. These findings also point to the need to redesign app review interfaces to consider how reviews are captured.	app store;requirements engineering;software development process	Sherlock A. Licorish;Bastin Tony Roy Savarimuthu;Swetha Keertipati	2017		10.1145/3084226.3084246	software development process;empirical research;management science;data mining;prioritization;app store;computer science;requirements engineering;content analysis;ranking;text mining	SE	-66.01587559285908	33.629027369100115	190976
5f6b69547b7f57ff789b2e069a1c28103d299d2e	local cyber-physical attack with leveraging detection in smart grid		A well-designed attack in the power system can cause an initial failure and then results in large-scale cascade failure. Several works have discussed power system attack through false data injection, line-maintaining attack, and line-removing attack. However, the existing methods need to continuously attack the system for a long time, and, unfortunately, the performance cannot be guaranteed if the system states vary. To overcome this issue, we consider a new type of attack strategy called combinational attack which masks a line-outage at one position but misleads the control center on line outage at another position. Therefore, the topology information in the control center is interfered by our attack. We also offer a procedure of selecting the vulnerable lines of its kind. The proposed method can effectively and continuously deceive the control center in identifying the actual position of line-outage. The system under attack will be exposed to increasing risks as the attack continuously. Simulation results validate the efficiency of the proposed attack strategy.	algorithm;breadth-first search;cascading failure;combinational logic;cyber-physical system;downtime;simulation;sun outage;vii	Hwei-Ming Chung;Wen-Tai Li;Chau Yuen;Wei-Ho Chung;Chao-Kai Wen	2017	2017 IEEE International Conference on Smart Grid Communications (SmartGridComm)	10.1109/SmartGridComm.2017.8340712	cascading failure;mathematics;application layer ddos attack;packet drop attack;timing attack;reflection attack;real-time computing;side channel attack;smurf attack;computer security;pre-play attack	EDA	-64.11750082746292	57.52084663747232	191345
d9f69d88c9458050b2ae732dddc3b05943066b7e	myths in software engineering: from the other side	distributed development;development teams;code coverage;empirical software engineering;software engineering;people;failures;static analysis;software assertions;software inspection	An important component of Empirical Software Engineering (ESE) research involves the measurement, observation, analysis and understanding of software engineering in practice. Results analyzed without understanding the contexts in which they were obtained can lead to wrong and potentially harmful interpretation. There exist several myths in software engineering, most of which have been accepted for years as being conventional wisdom without having been questioned. In this talk we will deal briefly with a few popular myths in software engineering ranging from testing and static analysis to distributed development and highlight the importance of context and generalization.	experimental software engineering;extensible storage engine;interpretation (logic);static program analysis	Nachiappan Nagappan	2010		10.1007/978-3-642-13977-2_2	personal software process;verification and validation;software engineering process group;software verification;computer science;package development process;social software engineering;component-based software engineering;software development;software engineering;software construction;software inspection;code coverage;software walkthrough;software analytics;software deployment;static analysis;software requirements;software quality;software system;software peer review	SE	-63.93180460318127	35.378034806673035	191423
48e798751a126e3315e6f99887b05765ebe9d5fa	prompt damage identification for system survivability	damage assessment;computer security;survivable systems;infection susceptibility;communication graph;survivable system;timestamp;malicious attacks;self healing;damage identification;fault identification;advance warning;damage containment	Survivable systems must identify and isolate any damage as quickly as possible to avoid infection epidemic and outbreak in case of a malicious attack. Any delay during the fault detection and isolation process may lead to system unavailability and is unacceptable in mission-critical applications. In this paper a model is presented to perform damage assessment, fault identification and advance warning. The objective is to help confine the damage propagation (direct or transitive), while making the system survive ongoing attacks and performing necessary self-healing. Our major contribution is the study of the patterns of interconnection communications among applications and the use of communication graphs in damage identification and containment.		Yanjun Zuo	2008	IJICS	10.1504/IJICS.2008.022490	timestamp;simulation;computer science;computer security	Security	-62.969181842319486	59.969762852735926	192803
60bcb992f3d31b14bf571bf6ed40447d08ea3624	detection of requirement errors and faults via a human error taxonomy: a feasibility study	human errors;software requirements;software quality improvement	Background: Developing correct software requirements is important for overall software quality. Most existing quality improvement approaches focus on detection and removal of faults (i.e. problems recorded in a document) as opposed identifying the underlying errors that produced those faults. Accordingly, developers are likely to make the same errors in the future and fail to recognize other existing faults with the same origins. Therefore, we have created a Human Error Taxonomy (HET) to help software engineers improve their software requirement specification (SRS) documents. Aims: The goal of this paper is to analyze whether the HET is useful for classifying errors and for guiding developers to find additional faults. Methods: We conducted a empirical study in a classroom setting to evaluate the usefulness and feasibility of the HET. Results: First, software developers were able to employ error categories in the HET to identify and classify the underlying sources of faults identified during the inspection of SRS documents. Second, developers were able to use that information to detect additional faults that had gone unnoticed during the initial inspection. Finally, the participants had a positive impression about the usefulness of the HET. Conclusions: The HET is effective for identifying and classifying requirements errors and faults, thereby helping to improve the overall quality of the SRS and the software.	human error;requirement;software developer;software engineer;software quality;software requirements	Wenhua Hu;Jeffrey C. Carver;Vaibhav K. Anu;Gursimran Singh Walia;Gary L. Bradshaw	2016		10.1145/2961111.2962596	reliability engineering;computer science;systems engineering;engineering;software engineering;data mining;software requirements;software quality analyst	SE	-64.75089904628109	33.10077145674984	192864
1371f5bfc12e6f1f516269fe16ef41b065d915cf	effect of software evolution on software metrics: an open source case study	software metrics;object oriented metrics;software complexity;object oriented software;revisions;software evolution;versions;laws of software evolution;software development;software metric;open source	Software needs to evolve in order to be used for a longer period. The changes corresponding to corrective, preventive, adaptive and perfective maintenance leads to software evolution. In this paper we are presenting the results of study conducted on 13 versions of JHot Draw and 16 versions of Rhino released over the period of 10 years. We measured Object Oriented Metrics and studied the changes in the measured values over different releases of two medium sized software developed using Java. We also investigated the applicability of Lehman's Law of Software Evolution on Object Oriented Software Systems using different measures. We found that Lehman's laws related with increasing complexity and continuous growth are supported by the data and computed metrics measure.	java;open-source software;software evolution;software metric;software system	Kalpana Johari;Arvinder Kaur	2011	ACM SIGSOFT Software Engineering Notes	10.1145/2020976.2020987	reliability engineering;software visualization;long-term support;verification and validation;software sizing;computer science;systems engineering;engineering;package development process;backporting;software evolution;social software engineering;component-based software engineering;software development;software design description;software engineering;software construction;software walkthrough;software analytics;software maintenance;software measurement;software metric	SE	-64.65020886593976	33.64716839040508	192924
ca73c02c73a317e9f0522fc3530415be13631d84	examining requirements change rework effort: a study	software maintenance;software management;software engineering;journal article;lines of code;effort estimation;user involvement	Although software managers are generally good at new project estimation, their experience of scheduling rework tends to be poor. Inconsistent or incorrect effort estimation can increase the risk that the completion time for a project will be problematic. To continually alter software maintenance schedules during software maintenance is a daunting task. Our proposed framework, validated in a case study confirms that the variables resulting from requirements changes suffer from a number of problems, e.g., the coding used, end user involvement and user documentation. Our results clearly show a significant impact on rework effort as a result of unexpected errors that correlate with 1) weak characteristics and attributes as described in the program’s source lines of code, especially in data declarations and data statements, 2) lack of communication between developers and users on a change effects, and 3) unavailability of user documentation. To keep rework effort under control, new criteria in change request forms are proposed. These criteria are shown in a proposed framework; the more case studies that are validated, the more reliable the result will be in determining the outcome of effort rework estimation.	change request;cost estimation in software engineering;requirement;rework (electronics);scheduling (computing);software bug;software documentation;software maintenance;source lines of code;unavailability	Bee Bee Chua;June M. Verner	2010	CoRR	10.5121/ijsea.2010.1304	reliability engineering;software sizing;systems engineering;engineering;effort management;software engineering;software maintenance;source lines of code	SE	-64.92827415896704	33.028918322498654	193363
bd8ffed03ef91fbde7b1b6a142edd88cae7e712c	repositories with public data about software development	repository of repositories;meta repositories;project repositories;software engineering research;software development;code forges	Empirical research on software development based on data obtained from project repositories and code forges is increasingly gaining attention in the software engineering research community. The studies in this area typically start by retrieving or monitoring some subset of data found in the repository or forge, and this data is later analyzed to find interesting patterns. However, retrieving information from these locations can be a challenging task. Meta-repositories providing public information about software development are useful tools that can simplify and streamline the research process. Public data repositories that collect and clean the data from other project repositories or code forges can help ensure that research studies are based on good quality data. This paper provides some insight as to how these metarepositories (sometimes called a ”repository of repositories”, RoR) of data about open source projects should be used to help researchers. It describes in detail two of the most widely used collections of data about software development: FLOSSmole and FLOSSMetrics.	adobe streamline;data retrieval;database schema;forge;open-source software;software development;software engineering;software repository;sourceforge;stu megan	Jesús M. González-Barahona;Daniel Izquierdo-Cortazar;Megan Squire	2010	IJOSSP	10.4018/jossp.2010040101	software project management;computer science;package development process;software development;software engineering;software construction;data mining;database;management;world wide web	SE	-66.40475283277533	36.10703232416861	193481
71f2cee17f5bc37ce7ac9f46ec5fcaf305f6c8c5	workload dependent fault analysis		"""Online transaction failures often show up as """"500: Internal Server Error"""" in web server access logs. In many instances determining the root cause of the failure is a difficult task. It could either be a bug associated with a specific HTTP request alone or the result of an undesirable state created by previous HTTP transactions. The latter case, which we call workload dependent faults, are relatively difficult to diagnose or even reproduce. In this paper we present a methodology to detect and identify such disruptive workload pattern for any web based IT system - in other words determine a specific set of HTTP transactions (or URL's) causing an internal error on the access of a specific URL. Only web server logs are used as input."""	hypertext transfer protocol;list of http status codes;server (computing);server log;software bug;software development process;system administrator;web application;web server	Mehul Nalin Vora;Manoj Karunakaran Nambiar	2017	2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)	10.1109/ISSREW.2017.31	real-time computing;workload;software bug;web application;web server;root cause;computer science;data modeling;server;database transaction	Arch	-63.72310605900845	39.748342778580174	193854
de76242b3438f933c6677af28e7adb6aa9323500	a systematic and comprehensive investigation of methods to build and evaluate fault prediction models	verification;modeling technique;receiver operator characteristic;data mining;machine learning;confusion matrix;cost effectiveness;source code;prediction model;classification accuracy;legacy system;fault prediction models	This paper describes a study performed in an industrial setting that attempts to build predictive models to identify parts of a Java system with a high fault probability. The system under consideration is constantly evolving as several releases a year are shipped to customers. Developers usually have limited resources for their testing and would like to devote extra resources to faulty system parts. The main research focus of this paper is to systematically assess three aspects on how to build and evaluate fault-proneness models in the context of this large Java legacy system development project: (1) compare many data mining and machine learning techniques to build fault-proneness models, (2) assess the impact of using different metric sets such as source code structural measures and change/fault history (process measures), and (3) compare several alternative ways of assessing the performance of the models, in terms of (i) confusion matrix criteria such as accuracy and precision/recall, (ii) ranking ability, using the receiver operating characteristic area (ROC), and (iii) our proposed cost-effectiveness measure (CE). The results of the study indicate that the choice of fault-proneness modeling technique has limited impact on the resulting classification accuracy or cost-effectiveness. There is however large differences between the individual metric sets in terms of cost-effectiveness, and although the process measures are among the most expensive ones to collect, including them as candidate measures significantly improves the prediction models compared with models that only include structural measures and/or their deltas between releases – both in terms of ROC area and in terms of CE. Further, we observe that what is considered the best model is highly dependent on the criteria that are used to evaluate and compare the models. And the regular confusion matrix criteria, although popular, are not clearly related to the problem at hand, namely the cost-effectiveness of using fault-proneness prediction models to focus verification efforts to deliver software with less faults at less cost. ! 2009 Elsevier Inc. All rights reserved.	adaboost;best practice;c4.5 algorithm;cos;confusion matrix;data mining;delta encoding;focus group;java;legacy system;machine learning;overfitting;predictive modelling;receiver operating characteristic;software verification;trusted computer system evaluation criteria;unit testing;usability	Erik Arisholm;Lionel C. Briand;Eivind B. Johannessen	2010	Journal of Systems and Software	10.1016/j.jss.2009.06.055	reliability engineering;verification;cost-effectiveness analysis;confusion matrix;computer science;engineering;operating system;machine learning;data mining;predictive modelling;legacy system;receiver operating characteristic;statistics;source code	SE	-63.03942347134348	34.398405682599765	194120
cddccd78a5601fc165f67efaad5c533fb2a4782b	towards electronic commerce via science park multi-extranets	network management and security;electronic commerce;enterprise networks;small firms;internet use;information exchange;extranets;cost models;open standards;open standard;cost model;mobile user	This paper is devoted to examining of the new emerging area of the Internet use, namely, ‘Extranets’. This is often referred as a ‘third wave’ of the universal Internet. Definitions and examples of Extranet are given. Extranets are compared with better known intergroupware and the concepts of Communications , Collaboration, andCo-ordinationare illustrated. The notion of a multi-Extranet is introduced as a special case typically found in the Science Park (SP) environments. Three types of organizations using the facilities of the SP and having different relationships with its multi-Extranet are distinguished as follows: (a) ‘normal’ firms which will have their own Intranets and access to the Internet either on their own or via SP facilities; (b) ‘small’ firms, which will obtain access to the Internet via SP facilities and with the only Intranet, which will be actually Extranet; (c) ‘large’ firms which, perhaps, will not bother to connect to the SP facilities at all. Open application standards are discussed and a suite of standards supported by the consortium established by Netscape Communications is briefly presented. The roles of network management and associated security issues are outlined as crucial for the success of electronic commerce. The existing experience of running Intranets is discussed and accepted as applicable for Extranets and criteria are identified for choosing a planning strategy for the building of Extranets. Based on the existing experience, the ‘top 5” problems have been identified such as Internal Information Exchange , Discussions , Line-of-Business Applications , CollaborationsandLink to Partners. Typical cost items are identified and cost models are discussed for the cases such as cost of running Web-sites of various complexity, access expenses for mobile users/ workers (via mobile telephones and ISDN connections) as well as losses caused by the downtime. Two typical phases for the building of an Extranet are suggested: (1) is focusing on the applications and standards which will help to solve the above mentioned ‘top 5’ problems, and (2) is devoted to future development of the Extranet and ‘flourishing’ of the links with the customers as well as electronic commerce facilities. q 1999 Elsevier Science B.V. All rights reserved.	downtime;e-commerce;emoticon;extranet;information exchange;integrated services digital network;internet;intranet;mobile phone	Algirdas Pakstas	1999	Computer Communications	10.1016/S0140-3664(99)00132-2	e-commerce;open standard;telecommunications;computer science;operating system;computer security;computer network	Security	-71.35557817552191	44.83612895803588	194458
9123064a38e0a46ddc070e38481df13743e8675c	a cost analysis of typical computer viruses and defenses	computer risk analysis;cost analysis;computer viruses	Various properties of computer viruses have been studied at length by many authors [1], but one of the areas where research results are relatively rare is evaluation of the costs of defenses. In this paper, we explore the costs of computer virus defenses in typical computing environments. † Copyright c © ASP, 1990 ASP Press, PO Box 81270, Pittsburgh, PA 15217	checksum;computer virus;cryptography;image scanner;ptc integrity	Frederick B. Cohen	1991	Computers & Security	10.1016/0167-4048(91)90040-K	simulation;computer science;cost–benefit analysis;operations research;computer security;computer virus	Crypto	-63.416515333457504	55.183159892150584	195184
9effdca2b76d1ce8d43a4051a163e65e32da6ba7	towards assessing representativeness of fault injection-generated failure data for online failure prediction	software fault injection;software faults representativeness;software fault tolerance;synthetic failure data representativeness online failure prediction software fault injection software faults representativeness;synthetic failure data representativeness;online failure prediction;software measurement estimation testing training predictive models data models;software fault representativeness fault injection generated failure data online failure prediction system dependability mitigation actions realistic software fault injection computer systems failure related data representativeness failure related data assessment g swfit representativeness estimation	Online Failure Prediction allows improving system dependability by foreseeing incoming failures at runtime, enabling mitigation actions to be taken in advance, though prediction systems' learning and assessing is hard due to the scarcity of failure data. Realistic software fault injection has been identified as a valid solution for addressing the scarcity of failure data, as injecting software faults (the most occurring on computer systems) increases the probability of a system to fail, hence allowing the collection of failure-related data in short time. Moreover, realistic injection permits the emulation of software faults likely to exist in the target system after its deployment. However, besides the representativeness of the software faults injected is recognized as a necessary condition for generating valid failure data, studies on the representativeness of generated failure-related data has still not been addressed. In this work we present a preliminary study towards the assessment the representativeness of failure-related data by using G-SWFIT realistic software fault injection technique. We here address the definition of concepts and metrics for the representativeness estimation and assessment.	computer;dependability;emulator;fault injection;run time (program lifecycle phase);software deployment	Ivano Irrera;Marco Vieira	2015	2015 IEEE International Conference on Dependable Systems and Networks Workshops	10.1109/DSN-W.2015.24	reliability engineering;real-time computing;computer science;operating system;data mining;software fault tolerance	SE	-63.57072656435455	40.31285937989447	195556
955f43158b6d6297333031ed1c8f1926ed383571	on using c++ and object-orientation in cs1: the message is still more important than the medium	dynamic programming;permutation graph;object oriented;software reusability	Most current approaches to modernizing CS1 revolve around the use of C++ and/or object-orientation. Although the two are not exclusively tied to one another, it is important to pause and consider the potential pitfalls of current approaches. Having identified those pitfalls, this paper presents an approach to CS1 that avoids those pitfalls while focusing students' attention on the real message: software reusability.	c++	Michael R. Wick	1995		10.1145/199688.199840	real-time computing;computer science;theoretical computer science;operating system;software engineering;dynamic programming;permutation graph;distributed computing;programming language;object-oriented programming	ML	-70.13886574838159	34.40041358382466	195570
54707d293faf8604ea16a338958ca67c41251015	guest editorial: special issue on predictive models for software quality		Software systems are increasingly large and complex, making activities related to ensuring software quality increasingly difficult. In this context, techniques able to automatically retrieve knowledge from software data in order to improve software quality are highly desirable. Predictive modelling has been showing promising results in this area. For instance, it can be used to learn the relationship between features retrieved from software processes, software usage or software itself and certain properties of interest, e.g., the presence of bugs, the likelihood of changes leading to crashes and the presence of code smells. Such knowledge can be particularly useful to improve the quality of large and complex systems. With this in mind, this special issue aims at investigating predictive models for software quality. We solicited submissions that provide an in depth understanding of when, why and how algorithms to create predictive models work in the context of software quality. We believe that such understanding will greatly benefit the software quality community, given that it will improve the external validity of studies and provide insights into how to improve algorithms further. Following an open call for papers, the special issue received a total of 11 submissions, one of which was withdrawn. The remaining 10 submissions were peer-reviewed by experts in the field. At the end, four papers were selected for inclusion in this special issue:	algorithm;code smell;complex systems;external validity;predictive modelling;software bug;software quality;software system	Leandro L. Minku;Ayse Basar Bener;Burak Turhan	2018	Software Quality Journal	10.1007/s11219-018-9409-7	systems engineering;computer science;software quality	SE	-63.49221756846536	33.13886199321938	197433
484b64cb47dd170900f35136136ef95e15664179	developer identification methods for integrated data from various sources	different activity;mining data;different entity;integrated data;different identity;data structure;different context;different tool;various source;developer identification method;different kind;new data source;different repository;data mining;software evolution;software engineering	Studying a software project by mining data from a single repository has been a very active research field in software engineering during the last years. However, few efforts have been devoted to perform studies by integrating data from various repositories, with different kinds of information, which would, for instance, track the different activities of developers. One of the main problems of these multi-repository studies is the different identities that developers use when they interact with different tools in different contexts. This makes them appear as different entities when data is mined from different repositories (and in some cases, even from a single one). In this paper we propose an approach, based on the application of heuristics, to identify the many identities of developers in such cases, and a data structure for allowing both the anonymized distribution of information, and the tracking of identities for verification purposes. The methodology will be presented in general, and applied to the GNOME project as a case example. Privacy issues and partial merging with new data sources will also be considered and discussed.		Gregorio Robles;Jesús M. González-Barahona	2005	ACM SIGSOFT Software Engineering Notes	10.1145/1082983.1083162	data structure;computer science;software evolution;software engineering;data mining;database;world wide web	SE	-66.54642831003815	36.12248931702111	197810
a481910a336fda9bdc59fde5635eda550824fd69	the art and science of analyzing software data; quantitative methods		Using the tools of quantitative data science, software engineers that can predict useful information on new projects based on past projects. This tutorial reflects on the state-of-the-art in quantitative reasoning in this important field. This tutorial discusses the following: (a) when local data is scarce, we show how to adapt data from other organizations to local problems; (b) when working with data of dubious quality, we show how to prune spurious information; (c) when data or models seem too complex, we show how to simplify data mining results; (d) when the world changes, and old models need to be updated, we show how to handle those updates; (e) when the effect is too complex for one model, we show to how reason over ensembles.	data mining;data science;emoticon;software engineer	Tim Menzies;Leandro L. Minku;Fayola Peters	2015	2015 IEEE/ACM 37th IEEE International Conference on Software Engineering		data modeling;verification and validation;test data generation;xml;data quality;data transformation;computer science;data science;software development;software engineering;software construction;data mining;database;programming language;static program analysis	SE	-68.46051941803691	33.69817436388618	198893
bb44e9f31788f25b57234e13246563d003986b85	judging a commit by its cover: correlating commit message entropy with build status on travis-ci	cross entropy;software;travis ci;build status;training;n gram language model;data mining;computational modeling;commit message;github;entropy;open source	"""Developers summarize their changes to code in commit messages. When a message seems """"unusual"""", however, this puts doubt into the quality of the code contained in the commit. We trained n-gram language models and used cross-entropy as an indicator of commit message """"unusualness"""" of over 120,000 commits from open source projects. Build statuses collected from Travis-CI were used as a proxy for code quality. We then compared the distributions of failed and successful commits with regards to the """"unusualness"""" of their commit message. Our analysis yielded significant results when correlating cross-entropy with build status."""	cross entropy;language model;n-gram;open-source software;software quality;travis ci	Eddie Antonio Santos;Abram Hindle	2016	2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR)	10.1145/2901739.2903493	commit;entropy;real-time computing;computer science;operating system;data mining;database;cross entropy;computational model;computer security	SE	-64.22851430191574	34.841880193094575	199141
222a5d6e5322875896dbf463a3641837406cb62c	evaluating the quality of open source software	quality attributes;version control system;tools and techniques;process quality attributes;source code;product quality;sqo oss;product quality attributes;open source software;open source	Traditionally, research on quality attributes was either kept under wraps within the organization that performed it, or carried out by outsiders using narrow, black-box techniques. The emergence of open source software has changed this picture allowing us to evaluate both software products and the processes that yield them. Thus, the software source code and the associated data stored in the version control system, the bug tracking databases, the mailing lists, and the wikis allow us to evaluate quality in a transparent way. Even better, the large number of (often competing) open source projects makes it possible to contrast the quality of comparable systems serving the same domain. Furthermore, by combining historical source code snapshots with significant events, such as bug discoveries and fixes, we can further dig into the causes and effects of problems. Here we present motivating examples, tools, and techniques that can be used to evaluate the quality of open source (and by extension also proprietary) software.	black box;bug tracking system;control system;database;digital library;emergence;list of system quality attributes;open platform;open-source software;software development;version control;wiki	Diomidis Spinellis;Georgios Gousios;Vassilios Karakoidas;Panagiotis Louridas;Paul J. Adams;Ioannis Samoladas;Ioannis Stamelos	2009	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2009.02.058	verification and validation;software quality management;computer science;revision control;software development;database;world wide web;software quality control;software quality;software quality analyst;source code	SE	-65.91021846285639	34.62336077173319	199444
47513679fd90eec8941e92af7ab65da60b6dcf42	do software developers understand open source licenses?		Software provided under open source licenses is widely used, from forming high-profile stand-alone applications (e.g., Mozilla Firefox) to being embedded in commercial offerings (e.g., network routers). Despite the high frequency of use of open source licenses, there has been little work about whether software developers understand the open source licenses they use. To our knowledge, only one survey has been conducted, which focused on which licenses developers choose and when they encounter problems with licensing open source software. To help fill the gap of whether or not developers understand the open source licenses they use, we conducted a survey that posed development scenarios involving three popular open source licenses (GNU GPL 3.0, GNU LGPL 3.0 and MPL 2.0) both alone and in combination. The 375 respondents to the survey, who were largely developers, gave answers consistent with those of a legal expert's opinion in 62% of 42 cases. Although developers clearly understood cases involving one license, they struggled when multiple licenses were involved. An analysis of the quantitative and qualitative results of the study indicate a need for tool support to help guide developers in understanding this critical information attached to software components.	build automation;component-based software engineering;dos;dynamic linker;embedded system;firefox;gnu;interaction;multiphoton lithography;open-source license;open-source software;router (computing);software developer	Daniel A. Almeida;Gail C. Murphy;Greg Wilson;Mike Hoye	2017	2017 IEEE/ACM 25th International Conference on Program Comprehension (ICPC)			SE	-67.6105459402494	36.637838803421864	199699
6fe1a9a403b0e81e8ad094b687bd08cb870a5ec3	designing a memory aid to support software developers	human memory;awareness;javadoc;software development;documentation	Developers rely on knowledge of project artifacts to avoid usage errors and on knowledge of their activities to maintain orientation and trace decisions. Unfortunately, human memory is unreliable, and existing documentation practices are costly and limited in their ability to draw attention to preserved knowledge. We propose a unified memory aid aimed at addressing these problems using episodic and contextual presentations of lightweight subjective knowledge elements supplied by the developers and objective events elicited from IDE monitors. In particular, directives on call targets are pushed into the attention of client code authors.	directive (programming);documentation;glossary of computer graphics;software developer	Uri Dekel	2008		10.1145/1449814.1449894	simulation;awareness;documentation;computer science;software development;multimedia;programming language	SE	-71.55441836064034	32.39411449641186	199716
